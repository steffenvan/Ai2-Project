<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.7685485">
Easy and Hard Constraint Ranking in Optimality Theory:*
Algorithms and Complexity
</note>
<author confidence="0.923293">
Jason Eisner
</author>
<affiliation confidence="0.93732">
Dept. of Computer Science / University of Rochester
</affiliation>
<email confidence="0.455328">
Rochester, NY 14607-0226 USA / jason@cs.rochester.edu
</email>
<sectionHeader confidence="0.962106" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998829052631579">
We consider the problem of ranking a set of OT con-
straints in a manner consistent with data. (1) We
speed up Tesar and Smolensky&apos;s RCD algorithm to
be linear on the number of constraints. This finds a
ranking such that each attested form x, beats or ties
a particular competitor yz. (2) We generalize RCD
so each xi beats or ties all possible competitors. (3)
Alas, if the surface form of xi is only partially ob-
served, then an NP-hardness construction suggests
that it is effectively necessary to consider all possi-
ble rankings or surface forms. (4) Merely checking
that a single (given) ranking is consistent with data
is coN P-complete if the surface forms are fully ob-
served and .A1-complete if not (since OT generation
is OptP-complete).(5) Determining whether any con-
sistent ranking exists is coNP-hard (but in g) if the
surface forms are fully observed, and Ei-complete if
not. (6) Generation (P) and ranking (NP-complete)
in derivational theories are easier than in OT.
</bodyText>
<sectionHeader confidence="0.993769" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997924461538462">
Optimality Theory (OT) is a grammatical
paradigm that was introduced by Prince and
Smolensky (1993) and suggests various compu-
tational questions, including learnability.
Following Gold (1967) we might ask: Is the
language class {L(g) : g is an OT grammar}
learnable in the limit? That is, is there a learn-
ing algorithm that will converge on any OT-
describable language L(g) if presented with an
enumeration of its grammatical forms?
In this paper we consider an orthogonal ques-
tion that has been extensively investigated by
Tesar and Smolensky (1996), henceforth T&amp;S.
Rather than asking whether a learner can even-
tually find an OT grammar compatible with an
unbounded set of positive data, we ask: How
efficiently can it find a grammar (if one exists)
compatible with a finite set of positive data?
We will consider successively more realistic
versions of the problem, as described in the ab-
stract. The easiest version turns out to be eas-
* Many thanks go to Lane and Edith Hemaspaandra
for references to the complexity literature, and to Bruce
Tesar for comments on an earlier draft.
ier than previously known. The harder versions
turn out to be harder than previously known.
</bodyText>
<sectionHeader confidence="0.988072" genericHeader="introduction">
2 Formalism
</sectionHeader>
<bodyText confidence="0.996827">
An OT grammar g consists of three elements,
any or all of which may need to be learned:
</bodyText>
<listItem confidence="0.9827">
• a set L of underlying forms produced by
a lexicon or morphology,
• a function Gen that maps any underlying
form to a set of candidates, and
• a vector = (C1, C2, Cy) of con-
straints, each of which is a function from
candidates to natural numbers.
</listItem>
<bodyText confidence="0.897639">
C, is said to rank higher than (or outrank)
C1 in if i &lt; j. We say x satisfies C, if
C2(x) = 0, else x violates C.
The grammar g defines a relation that
</bodyText>
<equation confidence="0.696153666666667">
maps each u E to the candidate(s)
def
x E Gen(u) for which the vector Cl(x)
</equation>
<bodyText confidence="0.921159304347826">
(Ci(x), C2(X), . . . C(x) is lexicographically
minimal. Such candidates are called optimal.
One might then say that the grammatical
forms are the pairs (u, x) of this relation. But
for simplicity of notation and without loss of
generality, we will suppose that the candidates
x are rich enough that u can always be recov-
ered from x.1 Then u is redundant and we may
simply take the candidate x to be the grammat-
ical form. Now the language L(g) is simply the
image of under g. We will write ux for the
underlying form, if any, such that x E Gen(u).
An attested form of the language is a candi-
date x that the learner knows to be grammatical
(i.e., x E L(g)). y is a competitor of x if they
are both in the same candidate set: ux = uy. If
x, y are competitors with e(y) &lt; 0(x), we say
that y beats x (and then x is not optimal).
&apos;This is necessary in any case if the constraints C, (x)
are to depend on (all of) u. In general, we expect that
each candidate x E Gen(u) encodes an alignment of the
underlying form u with some possible surface form s, and
C, (x) evaluates this pair on some criterion.
</bodyText>
<page confidence="0.995293">
22
</page>
<bodyText confidence="0.99837052631579">
An ordinary learner does not have access to
attested forms, since observing that x E L(G)
would mean observing an utterance&apos;s entire
prosodic structure and underlying form, which
ordinarily are not vocalized. An attested set
of the language is a set X such that the learner
knows that some x E X is grammatical (but not
necessarily which x). The idea is that a set is at-
tested if it contains all possible candidates that
are consistent with something a learner heard.2
An attested surface set the case considered
in this paper is an attested set all of whose el-
ements are competitors; i.e., the learner is sure
of the underlying form but not the surface form.
Some computational treatments of OT place
restrictions on the grammars that will be con-
sidered. The finite-state assumptions (Elli-
son, 1994; Eisner, 1997a; Frank and Satta, 1998;
Karttunen, 1998; Wareham, 1998) are that
</bodyText>
<listItem confidence="0.998852125">
• candidates and underlying forms are repre-
sented as strings over some alphabet;
• Gen is a regular relation;3
• each C3 can be implemented as a
weighted deterministic finite-state automa-
ton (WDFA) (i.e., C3 (X) is the total weight
of the path accepting x in the WDFA);
• L and any attested sets are regular.
</listItem>
<bodyText confidence="0.99387325">
The bounded-violations assumption (Frank
and Satta, 1998; Karttunen, 1998) is that the
value of C3(x) cannot increase with a, but is
bounded above by some k.
In this paper, we do not always impose these
additional restrictions. However, when demon-
strating that problems are hard, we usually
adopt both restrictions to show that the prob-
lems are hard even for the restricted case.
2 This is of course a simplification. Attested sets corre-
sponding to laugh and laughed can represent the learner&apos;s
uncertainty about the respective underlying forms, but
not the knowledge that the underlying forms are related.
In this case, we can solve the problem by packaging the
entire morphological paradigm of laugh as a single candi-
date, whose attested set is constrained by the two surface
observations and by the requirement of a shared under-
lying stem. (A k-member paradigm may be encoded in
a form suitable to a finite-state system by interleaving
symbols from 2k aligned tapes that describe the k under-
lying and k surface forms.) Alas, this scheme only works
within disjoint finite paradigms: while it captures the
shared underlying stem of laugh and laughed, it ignores
the shared underlying suffix of laughed and frowned.
</bodyText>
<footnote confidence="0.73017">
3Ellison (1994) makes only the weaker assumption
that Gen(u) is a regular set for each u.
</footnote>
<bodyText confidence="0.9995253">
Throughout this paper, we follow T&amp;S in
supposing that the learner already knows the
correct set of constraints C = {C1, C2, • • • Cn},
but must learn their order e = Kc,, C2, • • • Ca),
known as a ranking of C. The assumption fol-
lows from the OT philosophy that C is univer-
sal across languages, and only the order of con-
straints differs. The algorithms for learning a
ranking, however, are designed to be general for
any C, so they take C as an input.4
</bodyText>
<sectionHeader confidence="0.964098" genericHeader="method">
3 RCD as Topological Sort
</sectionHeader>
<bodyText confidence="0.999774">
T&amp;S investigate the problem of ranking a
constraint set C given a set of attested
forms xi, ... xm, and corresponding competitors
ynz. The problem is to determine a rank-
ing C such that for each i, C(x) &lt; C(y2) lexi-
cographically. Otherwise x, would be ungram-
matical, as witnessed by yz.
In this section we give a concise presentation
and analysis of T&amp;S&apos;s Recursive Constraint
Demotion (RCD) algorithm for this problem.
Our presentation exposes RCD&apos;s connection to
topological sort, from which we borrow a simple
bookkeeping trick that speeds it up.
</bodyText>
<subsectionHeader confidence="0.99955">
3.1 Compiling into Boolean Formulas
</subsectionHeader>
<bodyText confidence="0.999333857142857">
The first half of the RCD algorithm extracts
the relevant information from the {x,} and
{y2}, producing what T&amp;S call mark-data pairs.
We use a variant notation. For each con-
straint C E C, we construct a negation-free,
conjunctive-normal form (CNF) Boolean for-
mula 0(C) whose literals are other constraints:
</bodyText>
<equation confidence="0.984485">
(C)= A V C&apos;
i:C(xj)&gt;C(yi) C1 :C1(xj)&lt;C1 (yi)
</equation>
<bodyText confidence="0.88875405882353">
4Again this is an oversimplification. Given the vari-
ety of constraints already proposed in the phonological
literature, n = ICI would have to be extremely large for
C to include all possible cross-linguistic constraints. The
methods here are probably impractical for such large n,
since they are designed to work on arbitrary C and there-
fore spend some time on each constraint separately, if
only to read it from the input. An alternative would be
to tailor an algorithm to a particular constraint set C,
making it possible to exploit that set&apos;s internal struc-
ture. Consider e.g. Eisner&apos;s proposal (1997b; 1997a)
that C is the union of two simple parametric constraint
families. Note that such an algorithm would not have
time to output a total ranking of C by enumeration; it
might output a concise representation of the ranking, or
a short prefix C1,. . . Ck that is sufficient to determine
which forms (or which attested forms) are grammatical.
</bodyText>
<page confidence="0.997212">
23
</page>
<bodyText confidence="0.9987265">
The interpretation of the literal C&apos; in 0(C) is
that C&apos; is ranked before C. It is not hard to
see that a constraint ranking is a valid solution
if it satisfies 0(C) for every C. For example, if
0(d) = (a V b V c) A (b V eV f), this means that
d must be outranked by either a, b or c (else xi
is ungrammatical) and also by either b, e or f
(else x2 is ungrammatical).
How expensive is this compilation step? Ob-
serve that the inner term VC:C1(x,)&lt;C(m) CI is
independent of C, so it only needs to be com-
puted and stored once. Call this term D2. We
first construct all m of the disjunctive clauses
D2, requiring time and storage 0 (mn). Then
we construct each of the n formulas 0(C) =
Az:c(x2)&gt;c(y,)D, as a list of pointers to up to m
clauses, again taking time and storage 0 (mn).
The computation time is 0 (mn) for the steps
we have already considered, but we must add
0 (mnE), where E is the cost of precomputing
each C(x2) or C(y) and may depend on prop-
erties of the constraints and input forms.
We write M(= 0 (mn)) for the exact stor-
age cost of the formulas, i.e., M = &gt; ,021 +
Ec O(C) I where 10(C)1 counts only the num-
ber of conjuncts.
</bodyText>
<subsectionHeader confidence="0.999756">
3.2 Finding a Constraint Ranking
</subsectionHeader>
<bodyText confidence="0.99989515">
The problem is now to find a constraint ranking
that satisfies 0(C) for every C E C. Consider
the special case where each 0(C) is a simple
conjunction of literals that is, (Vi)D = 1.
This is precisely the problem of topologically
sorting a directed graph with n vertices and
Ec 10(C)I = M/2 edges. The vertex set is C,
and 0(C) lists the parents of vertex C, which
must all be enumerated before C.
Topological sort has two well-known 0(M +
n) algorithms (Cormen et al., 1990). One is
based on depth-first search. Here we will focus
on the other, which is: Repeatedly find a vertex
with no parents, enumerate it, and remove it
and its outgoing edges from the graph.
The second half of T&amp;S&apos;s RCD algorithm is
simply the obvious generalization of this topo-
logical sort method (to directed hypergraphs,
in fact, formally speaking). We describe it as a
function RcD(C, 0) that returns a ranking d:
</bodyText>
<listItem confidence="0.890507833333333">
1. If C = 0, return (). Otherwise:
2. Identify a C1 E C such that 0(C1) is empty.
(C1 is surface-true, or &amp;quot;undominated.&amp;quot;)
3. If there is no such constraint, then fail: no
ranking can be consistent with the data.
4. Else, for each C E C, destructively remove
from 0(C) any disjunctive clause D, that
mentions
5. Now recursively compute and return C =
(Ci, RcD(C — {C1},0)).
Correctness of RcD(C, 0) is straightforward,
by induction on n = C. The base case n =
0 is trivial. For n &gt; 0: 0(C1) is empty and
therefore satisfied. 0(C) is also satisfied for all
other C: any clauses containing Ci are satisfied
because Ci outranks C, and any other clauses
are preserved in the recursive call and therefore
satisfied by the inductive hypothesis.
</listItem>
<bodyText confidence="0.999834833333333">
We must also show completeness of
RcD(C, 0): if there exists at least one cor-
rect answer B, then the function must not fail.
Again we use induction on n. The base case
= 0 is trivial. For n &gt; 0: Observe that 0(B1)
is satisfied in B, by correctness of B. Since Bi
is not outranked by anything, this implies that
0(B1) is empty, so RCD has at least one choice
for C1 and does not fail. It is easy to see that b&apos;
with Ci removed would be a correct answer for
the recursive call, so the inductive hypothesis
guarantees that that call does not fail either.
</bodyText>
<subsectionHeader confidence="0.997823">
3.3 More Efficient Bookkeeping
</subsectionHeader>
<bodyText confidence="0.999467428571429">
T&amp;S (p. 61) analyze the RCD function as tak-
ing time 0(mn2); in fact their analysis shows
more precisely 0 (M n). We now point out that
careful bookkeeping can make it operate in time
0(M + n), which is at worst 0 (mn) provided
&gt; 0. This means that the whole RCD al-
gorithm can be implemented in time 0 (mnE),
i.e., it is bounded by the cost of applying all the
constraints to all the forms.
First consider the special case discussed
above, topological sort. In linear-time topolog-
ical sort, each vertex maintains a list of its chil-
dren and a count of its parents, and the program
maintains a list of vertices whose parent count
has become 0. The algorithm then requires only
0(1) time to find and remove each vertex, and
0(1) time to remove each edge, for a total time
of 0(M n) plus 0(M + n) for initialization.
We can organize RCD similarly. We change
our representations (not affecting the compi-
lation time in 9.1). Constraint C need not
</bodyText>
<page confidence="0.997788">
24
</page>
<bodyText confidence="0.999984">
store 0(C). Rather, C should maintain a list
of pointers to clauses D, in which it appears as
a disjunct (cf. &amp;quot;a list of its children&amp;quot;) as well as
the integer 10(C)1 (cf. &amp;quot;a count of its parents&amp;quot;).
The program should maintain a list of &amp;quot;undomi-
nated&amp;quot; constraints for which 10(C)1 has become
0. Finally, each clause D, should maintain a list
of constraints C such that D, appears in 0(C).
Step 2 of the algorithm is now trivial: remove
the head C1 of the list of undominated con-
straints. For step 4, iterate over the stored list
of clauses D, that mention Ci. Eliminate each
such D, as follows: iterate over the stored list
of constraints C whose 0(C) includes D, (and
then reset that list to empty), and for each such
C, decrement 10(C)1, adding C to the undomi-
nated list if 10(C)1 becomes 0.
The storage cost is still 0(M +n). In particu-
lar, 0(C) is now implicitly stored as 10(C)1 back-
pointers from its clauses D,, and D, is now im-
plicitly stored as 1D21 backpointers from its dis-
juncts (e.g., C1). Since RCD removes each con-
straint and considers each backpointer exactly
once, in 0(1) time, its runtime is 0(M + n).
In short, this simple bookkeeping trick elim-
inates RCD&apos;s quadratic dependence on n, the
number of constraints to rank. As already
mentioned, the total runtime is now domi-
nated by 0(mnE), the preprocessing cost of
applying all the constraints to all the input
forms. Under the finite-state assumption, this
can be be more tightly bounded as 0(n •
total size of input forms) = 0(71 • E, Ixz I +
since the cost of running a form through a
WDFA is proportional to the former&apos;s length.
</bodyText>
<subsectionHeader confidence="0.896116">
3.4 Alternative Algorithms
</subsectionHeader>
<bodyText confidence="0.927231066666666">
T&amp;S also propose an alternative to RCD called
Constraint Demotion (CD), which is perhaps
better-known. (They focus primarily on it, and
the textbook of (Kager, 1999) devotes a chapter
to it.) A disjunctive clause D, (compiled as in
9.1) is processed roughly as follows: for each
C such that D, is an unsatisfied clause of 0(C),
greedily satisfy it by demoting C as little as pos-
sible. CD repeatedly processes D1, ... Dm until
all clauses in all formulas are satisfied.
CD can be efficiently implemented so that
each pass through all clauses takes time propor-
tional to M. But it is easy to construct datasets
that require n + 1 passes. So the ranking step
can take time 12(Mn), which contrasts unfavor-
ably with the 0(M + n) time for RCD.
CD does have the nice property (unlike RCD)
that it maintains a constraint ranking at all
times. An &amp;quot;online&amp;quot; (memoryless) version of CD
is simply to generate, process, and discard each
clause D, upon arrival of the new data pair
x2, yz; this converges, given sufficient data. But
suppose one wishes to maintain a ranking that is
consistent with all data seen so far. In this case,
CD is slower than RCD. Modifying a previously
correct ranking to remain correct given the new
clause D, requires at least one pass through all
clauses D1, D, (as slow as RCD) and up to
n+1 passes (as slow as running CD on all clauses
from scratch, ignoring the previous ranking).
</bodyText>
<sectionHeader confidence="0.982172" genericHeader="method">
4 Considering All Competitors
</sectionHeader>
<bodyText confidence="0.999973333333333">
The algorithms of the previous section only en-
sure that each attested form x, is at least as har-
monic as a given competitor yz: C(x) &lt; o(yz).
But for x, to be grammatical, it must be at least
as harmonic as all competitors. We would like
a method that ensures this. Such a method will
rank a constraint set C given only a set of at-
tested forms {x1, ... xm}.
Like T&amp;S, whose algorithm for this case is
discussed in we will assume that we have
an efficient computation of the OT generation
function OPT(0, u). (See e.g. (Ellison, 1994;
Tesar, 1996; Eisner, 1997a).) This returns the
subset of Gen (u) on which o(.) is lexicographi-
cally minimal, i.e., the set of grammatical out-
puts for u. For purposes of analysis, we let P be
a bound on the runtime of our OPT algorithm.
We will discuss this runtime further in
</bodyText>
<subsectionHeader confidence="0.992356">
4.1 Generalizing RCD
</subsectionHeader>
<bodyText confidence="0.999800285714286">
We propose to solve this problem by running
something like our earlier RCD algorithm, but
considering all competitors at once.
First, as a false start, let us try to construct
the requirements 0(C) in this case. Consider
the contribution of a single x, to a particular
0(C). x, demands that for any competitor y
such that C(x) &gt; C(y), C must be outranked
by some C&apos; such that Ci(x2) &lt; Ci(y). One set
of competitors y might all add the same clause
(a V b V c) to 0(C); another set might add a
different clause (b V d V e).
The trouble here is that 0(C) may become
intractably large. This will happen if the con-
</bodyText>
<page confidence="0.987902">
25
</page>
<bodyText confidence="0.99975875">
straints are roughly orthogonal to one another.
For example, suppose the candidates are bit
strings of length n, and for each k, there ex-
ists a constraint OFF‘k preferring the kth bit to
be zero.5 If x, = 1000 • • • 0, then 0(OPP1) con-
tains all 2n-1 possible clauses: for example, it
contains (OPP2 V OPP4 V OPP5) by virtue of the
competitor y = 0101100000.... Of course, the
conjunction of all these clauses can be drasti-
cally simplified in this case, but not in general.
Therefore, we will skip the step of construct-
ing formulas 0(C). Rather, we will run some-
thing like RCD directly: greedily select a con-
straint C1 that does not eliminate any of the
attested forms x, (but that may eliminate some
of its competitors), similarly select C2, etc.
In our new function RcDALL(C, fi, {x2}), the
input includes a partial hierarchy B listing the
constraints chosen at previous steps in the re-
cursion. (On a non-recursive call, B = 0.)
</bodyText>
<listItem confidence="0.9984405">
1. If C = 0, return (). Otherwise:
2. By trying all constraints, find a constraint
C1 such that (Vi)x, E °PTO&amp;quot;, nxi
3. If there is no such constraint, then fail: no
ranking can be consistent with the data.
4. Else recursively compute and return 0 =
</listItem>
<bodyText confidence="0.9735386">
(C1, RcDALL(C — {C1}, CO, {x2}))
It is easy to see by induction on ICI that
RcDALL is correct: if it does not fail, it al-
ways returns a ranking o such that each x, is
grammatical under the ranking (B, C). It is
also complete, by the same argument we used
for RCD: if there exists a correct ranking, then
there is a choice of C1 for this call and there
exists a correct ranking on the recursive call.
The time complexity of RCDALL is 0(7nn2P).
Preprocessing and compilation are no longer
necessary (that work is handled by OPT). We
note that if OPT is implemented by succes-
sive winnowing of an appropriately represented
candidate set, as is common in finite-state ap-
proaches, then it is desirable to cache the sets
returned by OPT at each call, for use on the
recursive call. Then OPT((B, C1), ux, ) need not
be computed from scratch: it is simply the sub-
set of OPT(B, ux,) on which C1(.) is minimal.
</bodyText>
<footnote confidence="0.915535">
5OFFk (x) simply extracts the kth bit of x. We will
later denote it as
</footnote>
<subsectionHeader confidence="0.964779">
4.2 Alternative Algorithms
</subsectionHeader>
<bodyText confidence="0.999941756756757">
T&amp;S provide a different, rather attractive so-
lution to this problem, which they call Error-
Driven Constraint Demotion (EDCD). This is
identical to the &amp;quot;online&amp;quot; CD algorithm of 9.4,
except that for each attested form x that is
presented to the learner, EDCD automatically
chooses a competitor yE OPT(0, ux), where o
is the ranking at the time.
If the supply of attested forms xi, ... xn, is
limited, as assumed in this paper, one may it-
erate over them repeatedly, modifying C, until
they are all optimal. When an attested form x is
suboptimal, the algorithm takes time 0(71E) to
compile x,y into a disjunctive clause and time
0(n) to process that clause using CD.6
T&amp;S show that the learner converges af-
ter seeing at most 0(n2) suboptimal attested
forms, and hence after at most 0(n2) passes
through xi,. . . x. Hence the total time is
0(n3E rn,n2P), where P is the time required
by OPT. This is superficially worse than our
RcDALL, which takes time 0(mn2P), but re-
ally the same since P dominates (see 0).
Nonetheless, g will discuss a genuine sense
in which RcDALL is more efficient than EDCD
(and MRCD), thanks to the more limited infor-
mation it gets from OPT.
Algorithms that adjust constraint rankings
or weights along a continuous scale include the
Gradual Learning Algorithm (Boersma, 1997),
which resembles simulated annealing, and max-
imum likelihood estimation (Johnson, 2000).
These methods have the considerable advantage
that they can deal with noise and free variation
in the attested data. Both algorithms repeat
until convergence, which makes it difficult to
judge their efficiency except by experiment.
</bodyText>
<sectionHeader confidence="0.993317" genericHeader="method">
5 Incompletely Observed Forms
</sectionHeader>
<bodyText confidence="0.9999786">
We now add a further wrinkle. Suppose the
input to the learner specifies only C together
with attested surface sets {Xi}, as defined in
P, rather than attested forms. This version of
the problem captures the learner&apos;s uncertainty
</bodyText>
<footnote confidence="0.967528166666667">
6Instead of using CD on the new clause only, one may
use RCD to find a ranking consistent with all clauses
generated so far. This step takes worst-case time 0(n2)
rather than 0(n) even with our improved algorithm, but
may allow faster convergence. Tesar (1997) calls this
version Multi-Recursive Constraint Demotion (MRCD).
</footnote>
<page confidence="0.995791">
26
</page>
<bodyText confidence="0.9987919">
about the full description of the surface mate-
rial. As before, the goal is to rank C in a manner
consistent with the input.
With this wrinkle, even determining whether
such a ranking exists turns out to be surpris-
ingly harder. In g we will see that it is actually
E14-complete. Here we only show it NP-hard,
using a construction that suggests that the NP-
hardness stems from the need to consider expo-
nentially many rankings or surface forms.
</bodyText>
<subsectionHeader confidence="0.713126">
5.1 NP-Hardness Construction
</subsectionHeader>
<bodyText confidence="0.998752">
Given n, we will be considering finite-state OT
grammars of the following form:
</bodyText>
<listItem confidence="0.961220833333333">
• ,C = {€}.
• Gen (6) = En, the set of all length-n strings
over the alphabet E = {1, 2, ... n}. (This
set can be represented with a straight-line
DFA of n + 1 states and n2 arcs.)
• C = {E ARLY 3 : 1 &lt;j &lt; n}, where for any
x E E*, the constraint EARLY(X) counts
the number of digits in x before the first
occurrence of digit j, if any. For example,
EARLY3(2188353) = EARLY3(2188) = 4.
(Each such constraint can be implemented
by a WDFA of 2 states and 2n arcs.)
</listItem>
<bodyText confidence="0.986220363636364">
EARLY/ favors candidates in which j ap-
pears early. The ranking KEARLY5, EARLY8,
EARLY&apos;, favors candidates of the form
581 • • • ; no other candidate can be grammatical.
Given a directed graph G with Ti vertices
identified by the digits 1,2, ... Ti. A path in
G is a string of digits jij2j3 • • • jk such that G
has edges from ji to j2, 12 to j3, ... and jk-1 to
jk. Such a string is called a Hamilton path
if it contains each digit exactly once. It is an
NP-complete problem to determine whether an
arbitrary graph G has a Hamilton path.
Suppose we let the attested surface set X1 be
the set of length-n paths of G. This is a reg-
ular set that can be represented in space pro-
portional to n}G1, by intersecting the DFA for
Gen(E) with a DFA that accepts all paths of G.7
Now (C, {X1}) is an instance of the ranking
problem whose size is 0(n1G1). We observe that
any correct ranking algorithm succeeds if G has
7The latter DFA is isomorphic to G plus a start state.
The states are 0,1, ...n; there is an arc from j to j&apos;
(labeled with j&apos;) iff j = 0 or G has an edge from j to j&apos;.
a Hamilton path. Why? A ranking is a vector
C = (EARLY31, EARLY,,), where ji, jn is
a permutation of 1, n. The optimal form un-
der this ranking is in fact the string ji • • • jn.
A string is consistent with Xi if it is a path
of G, so the ranking 0 is consistent with Xi
if ji in is a Hamilton path of G. If such a
ranking exists, the algorithm is bound to find it,
and otherwise to return a failure code. Hence
the ranking problem of this section is NP-hard.
</bodyText>
<subsectionHeader confidence="0.913064">
5.2 Discussion
</subsectionHeader>
<bodyText confidence="0.99990982051282">
The NP-hardness effectively means that (un-
less P = NP) no general algorithm can always
do better than checking each ranking or each
possible surface form individually. This is not
quite obvious, since in general, NP-hardness or
coN P-hardness can also arise from the difficulty
of checking whether a particular one of the
surface forms is compatible with a particular
one of the constraint rankings (see 0). How-
ever, that is not the case here, since the con-
straints EARLY/ used in our construction inter-
act in a simple and tractable way. (In particu-
lar, the winnowed candidate set after the first k
constraints, OPT (KEARLY3, , EARLY/), c), is
simply ji • • • jkE&amp;quot;, a regular set that may be
represented as a DFA of size 0(n2).)
Note that our construction shows NP-
hardness for even a restricted version of the
ranking problem: finite-state grammars and fi-
nite attested surface sets. The result holds up
even if we also make the bounded-violations as-
sumption (see V): the violation count can stop
at n, since EARLY3 need only work correctly on
strings of length n. We revise the construction,
modifying the automaton for each EARLY3 by
intersection (more or less) with the straight-line
automaton for En. This enlarges the input to
the ranking algorithm by a factor of 0(n).
By way of mitigating this stronger result, we
note that the construction in the previous para-
graph bounds 1X,1 by Ti! and the number of vio-
lations by n. These bounds (as well as ICI = n)
increase with the order n of the input graph. If
the bounds were imposed by universal grammar,
the construction would not be possible and NP-
hardness might not hold. Unfortunately, any
universal bounds on 1X21 or ICI would hardly be
small enough to protect the ranking algorithm
from having to solve huge instances of Hamilton
</bodyText>
<page confidence="0.990404">
27
</page>
<bodyText confidence="0.999847666666667">
path.8 As for bounded violations, the only real
reason for imposing this restriction is to ensure
that the OT grammar defines a regular rela-
tion (Frank and Satta, 1998; Karttunen, 1998).
In recent work, Eisner (2000) argues that the
restriction is too severe for linguistic descrip-
tion, and proposes a more general class of &amp;quot;di-
rectional constraints&amp;quot; under which OT gram-
mars remain regular.9 If this relaxed restric-
tion is substituted for a universal bound on vio-
lations, the ranking problem remains NP-hard,
since each EARLY3 is a directional constraint.
A more promising &amp;quot;way out&amp;quot; would be to uni-
versally restrict the size or structure of the au-
tomaton that describes the attested set. The
set used in our construction was quite artificial.
However, in g we will answer all these ob-
jections: we will show the problem to be
complete, using a natural attested set and
binary-valued finite-state constraints (which,
however, will not interact as simply).
</bodyText>
<subsectionHeader confidence="0.990146">
5.3 Available Algorithms
</subsectionHeader>
<bodyText confidence="0.999972823529412">
The NP-hardness results above suggests that ex-
isting algorithms designed for this ranking prob-
lem are either incorrect or intractable on certain
cases. Again, this does not rule out efficient al-
gorithms for variants of the problem see e.g.
footnote 4 nor does it rule out algorithms that
tend to perform well in the average case or on
small inputs or on real data.
T&amp;S proposed an algorithm for this problem,
RIP/CD, but left its efficiency and correctness
for future research (p. 39); Tesar and Smolen-
sky (2000) show that it is not guaranteed to
succeed. Tesar (1997) gives a related algorithm
based on MRCD (see 0.2), but which some-
times requires iterating over all the candidates
in an attested surface set; this might easily be
intractable even when the set is finite.
</bodyText>
<sectionHeader confidence="0.88407" genericHeader="method">
6 Complexity of OT Generation
</sectionHeader>
<bodyText confidence="0.999760333333333">
The ranking algorithms in H4.1-4.2 relied on
the existence of an algorithm to compute the in-
dependently interesting &amp;quot;language production&amp;quot;
</bodyText>
<footnote confidence="0.930693571428571">
8We expect attested sets X, to be very large
especially in the more general case where they reflect un-
certainty about the underlying form. That is why we de-
scribe them compactly by DFAs. A universal constraint
set C would also have to be very large (footnote 4).
9A1lowing directional constraints would not change
any of the classifications in this paper.
</footnote>
<bodyText confidence="0.99684325">
function OPT(0, u), which maps underlying u
to the set of optimal candidates in Gen (u).
In this section, we consider the computational
complexity of some functions related to OPT:19
</bodyText>
<listItem confidence="0.988458631578947">
• OPTVAL(e, u): returns minxeGen(u) 0(x).
This is the violation vector shared by all
the optimal candidates x E OPT(C, u).
• OPTVALZ(0, u): returns &amp;quot;yes&amp;quot; if the last
component of the vector OPTVAL(0, u) is
zero. This decision problem is interesting
only because if it cannot be computed effi-
ciently then neither can OPTVAL.
• BEATABLE(0, (ki, kn)): returns &amp;quot;yes&amp;quot;
iff OPTVAL(e, u)
• BEsT(C, u, (ki, kn)): returns &amp;quot;yes&amp;quot; if
OPTVAL(e, u) =
• CHEcK(d , x): returns &amp;quot;yes&amp;quot; if x
OPT(, u). This checks whether an at-
tested form is consistent with C.
• CHECKSSET(d, X): returns &amp;quot;yes&amp;quot; if
CHECK(, x) for some x E X. This checks
whether an attested surface set (namely X)
is consistent with C.
</listItem>
<bodyText confidence="0.999954">
These problems place a lower bound on the diffi-
culty of OT generation, since an algorithm that
found a reasonable representation of OPT(C,
(e.g., a DFA) could solve them immediately,
and an algorithm that found an exemplar x E
OPT(C, u) could solve all but CHECKSSET im-
mediately. g will relate them to OT learning.
</bodyText>
<subsectionHeader confidence="0.997175">
6.1 Past Results
</subsectionHeader>
<bodyText confidence="0.964979538461538">
Under finite-state assumptions, Ellison (1994)
showed that for any fixed d, a representa-
tion of OPT(C, u) could be generated in time
0(lul log u), making all the above problems
tractable. However, Eisner (1997a) showed gen-
eration to be intractable when d was not fixed,
but rather considered to be part of the input
as is the case in an algorithm like RcDALL that
learns rankings. Specifically, Eisner showed
that OPTVALZ is NP-hard. Similarly, Wareham
(1998, theorem 4.6.4) showed that a version of
1-9All these functions take an additional argument Gen,
which we suppress for readability.
</bodyText>
<page confidence="0.997273">
28
</page>
<bodyText confidence="0.999821294117647">
BEATABLE is NP-hard.11- (We will obtain more
precise classifications below.)
To put this another way, the worst-case com-
plexity of generation problems is something like
0(lul log n) times a term exponential in C.
Thus there are some grammars for which gen-
eration is very difficult by any algorithm. So
when testing exponentially many rankings (5),
a learner may need to spend exponential time
testing an individual ranking.
We offer an intuition as to why generation can
be so hard. In successive-winnowing algorithms
like that of (Eisner, 1997a), the candidate set
begins as a large simple set such as E*, and is
filtered through successive constraints to end up
(typically) as a small simple set such as the sin-
gleton {x1}. Both these sets can be represented
and manipulated as small DFAs. The trouble is
that intermediate candidate sets may be com-
plex and require exponentially large DFAs to
represent. (Recall that the intersection of DFAs
can grow as the product of their sizes.)
For example, Eisner&apos;s (1997a) NP-hardness
construction (see W.1) led to such an
intermediate candidate set, consisting of
all permutations of n digits. Such a
set arises simply from a hierarchy such
as (PROJECT,,. PROJECT, SHORT), where
PROJECT(X) = 0 provided that j appears (at
least once) in x, and SHORT(X) = 1. (Adding
a lower-ranked constraint that prefers x to en-
code a path in a graph G forces OPT to search
for a Hamilton path in G, which demonstrates
NP-hardness of OPTVALZ.)
</bodyText>
<subsectionHeader confidence="0.998245">
6.2 Relevant Complexity Classes
</subsectionHeader>
<bodyText confidence="0.985051196721312">
The reader may recall that P C NP fl coNP C
NP U coNP C DP C Al4 = pNP c E/4 = NpNP.
We will review these classes as they arise. They
are classes of decision problems, i.e., func-
tions taking values in {yes,no}. Hardness and
completness for such classes are defined via
many-one (Karp) reductions: g is at least as
hard as f iff (V x) f (x) = g (T (x)) for some func-
tion T(x) computable in polynomial time.
OptP is a class of integer-valued functions, in-
troduced and discussed by Krentel (1988). Re-
call that NP is the class of decision problems
that can be solved in polytime by a nondeter-
11Wareham also gave hardness results for versions of
BEATABLE where some parameters are bounded or fixed.
ministic Turing machine (NDTM): each control
branch of the machine checks a different possi-
bility and gives a yes/no answer, and the ma-
chine returns the disjunction of the answers. For
coNP, the machine returns the conjunction of
the answers. For OptP, each branch writes a bi-
nary number, and the machine returns the min-
imum (or maximum) of these answers.
A canonical example (analogous to OPTVAL)
is the Traveling Salesperson problem finding
the minimum cost TsPVAL(G) of all tours of an
integer-weighted graph G. It is OptP-complete
in the sense that all functions f in OptP can
be metrically reduced to it (Krentel, 1988,
p. 493). A metric reduction solves an instance
of f by transforming it to an instance of g and
then appropriately transforming the integer re-
sult of g: (Vx) f (x) = T2(x, g(Ti(x))) for some
polytime-computable functions T, : E* E*
and T2 : E* x N —&gt; N.
Krentel showed that OptP-complete problems
yield complete problems for other classes under
broad conditions. The question TsPVAL(G) &lt;
k is of course the classical TSP decision prob-
lem, which is NP-complete. (It is analo-
gous to BEATABLE.) The reverse question
TsPVAL(G) &gt; k (which is related to CHECK) is
coNP-complete. The question TsPVAL(G) = k
(analogous to BEST) is therefore in the class
DP = {L, n L2 : Ll E NP and L2 E coNP}
(Papadimitriou and Yannakakis, 1982), and it
is complete for that class. Finally, suppose
we wish to ask whether the optimal tour is
unique (like OPTVALZ and CHECKSSET, this
asks about a complex property of the optimum).
Papadimitriou (1984) first showed this question
to be complete for = PNP, the class of
languages decidable in polytime by determin-
istic Turing machines that have unlimited ac-
cess to an oracle that can answer NP questions
in unit time. (Such a machine can certainly
decide uniqueness: It can compute the integer
TsPVAL(G) by binary search, asking the oracle
for various k whether or not TsPVAL(G) &lt; k,
and then ask it a final NP question: do there
exist two distinct tours with cost TsPVAL(G)?)
</bodyText>
<subsectionHeader confidence="0.950629">
6.3 New Complexity Results
</subsectionHeader>
<bodyText confidence="0.98647825">
It is quite easy to show analogous results for
OT generation. Our main tool will be one of
Krentel&apos;s (1988) OptP-complete problems: Min-
imum Satisfying Assignment. If 0 is a CNF
</bodyText>
<page confidence="0.996821">
29
</page>
<bodyText confidence="0.997067913043478">
boolean formula on n variables, then MsA(0)
returns the lexicographically minimal bitstring
b1b2 • • • b7, that represents a satisfying assign-
ment for 0, or 1n if no such bitstring exists.12
We consider only problems where we can
compute C(x), or determine whether x E
Gen(u), in polytime. We further assume that
Gen produces only candidates of length polyno-
mial in the size of the problem input or more
weakly, that our functions need not produce cor-
rect answers unless at least one optimal candi-
date is so bounded.
Our hardness results (except as noted) apply
even to OT grammars with the finite-state and
bounded-violations assumptions (2). In fact,
we will assume without further loss of general-
ity (Ellison, 1994; Frank and Satta, 1998; Kart-
tunen, 1998) that constraints are {0, 1}-valued.
Notation: We may assume that all formu-
las 0 use variables from the set {vi, v2, ...}.
Let (0) be the maximum i such that vz ap-
pears in 0. We define the constraint Co to map
strings of at least f(0) bits to {0, 1}, defining
Co(bi • • • bn) = 0 if 0 is true when the variables
v, are instantiated to the respective values b2.
So Co prefers bitstrings that satisfy 0.
If we do not make the finite-state assump-
tions, then any Co can be represented trivially
in size 101. Under the finite-state assumptions,
however, we must represent Co as a WDFA.
While this is always possible (A, V, correspond
to intersection, union, and complementation of
regular sets), we necessarily take care in this
case to use only Co whose WDFAs are polyno-
mial in 101. In particular, if 0 is a disjunction of
(possibly negated) literals, such as b2 V b3 V -ib7,
then the WDFA needs only 40) + 2 states.
We begin by showing that OPTVAL(e, u) is
OptP-complete. It is obvious under our restric-
tions that it is in the class OptP indeed it is a
perfect example. Each nondeterministic branch
of the machine considers some string x of length
&lt; P(In1), simply writing the bitstring C(x) if
x E Gen(u) and ln otherwise.
To show OptP-hardness, we metrically reduce
MsA(0) to OPTVAL, where 0 = Arzn_1 D, is in
</bodyText>
<footnote confidence="0.9802732">
12Krentel&apos;s presentation is actually in terms of Maxi-
mum Satisfying Assignment, which merely reverses the
roles of 0 and 1. Also, Krentel does not mention that
0 can be restricted to (3)CNF, but his proof of OptP-
hardness makes this important fact clear.
</footnote>
<bodyText confidence="0.99083006122449">
CNF. Let n = (0), and put ,C = {c} and
Gen(c) = {0, 1}71. Then MsA(0) = the last
Ti bits of min(07n1n, OPTVAWCD„ • • • CDm
0).13
Because OPTVAL is OptP-complete, Krentel&apos;s
theorem 3.1 says it is complete for FPNP, the
set of functions computable in polynomial time
using an oracle for NP. This is the function class
corresponding to the decision class PNP =
Next we show that BEATABLE(d, u, ic) is
NP-complete. It is obviously in NP. For
NP-hardness, observe that CNF-SAT(0) =
BEATABLE( (CD„ • . • CD), c, KO, 0, • • • 0, 1)),
where again 0 = AT±1 D2, n = f(0), and
Gen(c) = {0, 1}n.
Next consider CHEGE(0, x). This is sim-
ply -IBEATABLE(d, ux, OW). Even when re-
stricted to calls of this form, BEATABLE remains
NP-complete. To show this, we tweak the above
construction so we can write C(x) (for some x)
in place of (0, 0, ... 0, 1). Add the new element
E to Gen(€), and extend the constraint defini-
tions by putting CD, (€) = 0 if i &lt; m. Then
CNF-SAT(0) = BEATABLE(d, c, OW). There-
fore CHECK is coN P-complete.
Next we consider BEsT(d, u,I4 This prob-
lem is in DP for the same simple reason that
the question TsPVAL(G) = k is (see above).
If we do not make the finite-state assump-
tions, it is also Dr-hard by reduction from the
DP-complete language SAT-UNSAT = {0#0 :
çó E SAT, b SAT} (Papadimitriou and Yan-
nakakis, 1982), as follows: SAT-UNsAT(0#&apos;0) =
BEsT((Co, E, (0, 1)), renaming variables as
necessary so that 0 uses only v1, ... Vr and ,0
uses only vr+i, ... vs, and Gen (€) = {0, 1}r+s•
It is not clear whether BEST remains Dr-hard
under the finite-state assumptions. But con-
sider a more flexible variant RANGE(0, u, ki, k2)
that asks whether OPTVAL(0, u) is between
and k; inclusive. This is also in DP,
and is Dr-hard because SAT-UNsAT(0#0) =
RANGE((CD„ . • CD„, Cm, • • • CD&apos; ,), c, KO, . . .
0,0, .. 1) , (0, .. 0,1, . . 1), where 0, //), Gen are
as before and 0 = AT-1 Dz, = Arzn21 D.
Finally, we show that the decision prob-
13Without the finite-state assumptions, we could
more simply write MsA(0) = OPTVAL(C01, C),€),
where 03 = A -,v3.
</bodyText>
<page confidence="0.996038">
30
</page>
<bodyText confidence="0.998587352941177">
lem CHEcKSSET(0, X) is A14-comp1ete. It
is in A by an algorithm similar to the
one used for TSP uniqueness above: since
BEATABLE can be determined by an NP oracle,
we can find OPTVAL(0, u) by binary search.14
An additional call to an NP oracle decides
CHEcKSSET(C, X) by asking whether there is
any x E X such that 0(x) = OPTVAL(d, u).
The reduction to show Ai-hardness is from
a Ai-complete problem exhibited by Krentel
(1988, theorem 3.4): MsAisb accepts 0 if the
final (least significant) bit of MsA(0) is 0.
Given 0, we use the same grammar as when
we reduced MSA to OPTVAL. MSAisb accepts
if OPTVAL found a satisfying assignment and
the last bit of this optimal assignment was 0:
i.e., MsAi8b(0) = CHEcKSSET((CD,, • • • CD,
</bodyText>
<subsubsectionHeader confidence="0.581046">
C),ON0,11n-10).15
</subsubsectionHeader>
<bodyText confidence="0.999966571428571">
Note that we did not have to use an unrea-
sonable attested surface set as in 0.1. The
set ONO, 11n-10 means that the learner has
observed only certain bits of the utterance
exactly the kind of partial observation that we
expect. So even some restriction to &amp;quot;reason-
able&amp;quot; attested sets is unlikely to help.
</bodyText>
<sectionHeader confidence="0.838949" genericHeader="method">
7 Complexity of OT Ranking
</sectionHeader>
<bodyText confidence="0.999706">
We now consider two ranking problems. These
ask whether C can be ranked in a manner con-
sistent with attested forms or attested sets:
</bodyText>
<listItem confidence="0.868325">
• R
</listItem>
<bodyText confidence="0.732928666666667">
—ANKABLE(C, {xl, xm}): returns &amp;quot;yes&amp;quot;
if there is a ranking C of C such that
CHEcK(0, x,) for all i.
</bodyText>
<listItem confidence="0.896257">
• RANKABLESSET(C, {X,. X}): returns
</listItem>
<bodyText confidence="0.979260463768116">
&amp;quot;yes&amp;quot; if there is a ranking C of C such that
CHEcKSSET(C, X,) for all i.
We do not have an exact classification of
RANKABLE at this time. Interestingly, the spe-
cial case where m = 1 and the constraints take
values in {0, 1} (which has sufficed to show most
of our hardness results) is coN P-complete the
same as CHECK, which only verifies a solution.
&amp;quot;This takes polynomially many steps provided that
the integer C(x) is bounded by 2&amp;quot;) for some polyno-
mial q (as it is under the finite-state assumptions). We
have already assumed above that lx1 itself is polynomial
on the input size, at least for optimal x.
15We can similarly show that OPTVALZ is not merely
NP-hard (Eisner, 1997a) but A-complete, at least if
we drop the finite-state assumptions: MsAtsb(0) =
OPTVALZ(Co, C, Con-v„ ), €)•
Here RANKABLE need only ask whether there
exists any y E Gen(n1) that satisfies a proper
superset of the constraints that xl satisfies. For
if so, x1 cannot be optimal under any rank-
ing, and if not, then we can simply rank the
constraints that xl satisfies above the others.
This immediately implies that the special case
is in coNP. It also implies it is coNP-hard: us-
ing the grammar from our proof that CHECK
is coNP-hard (6.3), we write CNF-SAT(0) =
-1RANKABLE(C, {€}).
As an upper bound on the complexity of
RANKABLE, we saw in 0.1 that the RCDALL
algorithm of 0 can decide RANKABLE with
0(n2m) calls to OPT (where n = In
fact, it suffices to call CHECK rather than
OPT (since RCDALL only tests whether x, E
OPT(. • •)). Since CHECK E coNP, it follows
that RANKABLE is in Pc°NP = PNP = A14.
Notice that while Tesar&apos;s EDCD and MRCD
algorithms (4.2) can also decide RANKABLE
with polynomially many calls to OPT or, bet-
ter, to OPTVAL, since they do not use y ex-
cept to compute C(y). But they cannot get by
with calls to CHECK as RCDALL does. OPTVAL
is &amp;quot;harder&amp;quot; than CHECK (FP-complete vs.
coNP-complete). This is a reason to prefer
RCDALL to EDCD and MRCD.
RANKABLESSET is certainly in E14, since it
may be phrased in 3V form as (3d, {x, E X,})
(Vi, y, E Gen(ux,)) o(x„) &lt; o(y„). We saw in 0
that it is NP-hard even when the constraints in-
teract simply. One suspects it is Ai-hard, since
merely verifying a solution (i.e., CHEcKSSET)
is A14-complete (6.3). We now show that is ac-
tually Ei-hard and therefore Ei-complete.
The proof is by reduction from the canonical
E14-complete problem QSAT2(0, r), where 0 =
D, is a CNF formula with 40) &gt; r &gt; 0.
This returns &amp;quot;yes&amp;quot; if
3b1,... br-abr+i, bs0(bi,... bs),
def
where s = .40) and 0(bi,...b8) denotes the
truth value of 0 when the variables vi, n, are
bound to the respective binary values bl bs.
Given an instance of QSAT2 as above, put
= {€} and Gen(c) = u X where
X = {0,1} 2. Let C = {CD, , • • •
r
Cv„ Gr , C1, *X}, where all con-
straints have range {0,1}, we extend CD, over
X by defining it to be satisfied (i.e., take value
</bodyText>
<page confidence="0.999581">
31
</page>
<bodyText confidence="0.998122162162162">
0) on all candidates in X, and we define *X
to be satisfied on exactly those candidates not
in X. As before, G, and C are satisfied on
a candidate if its ith bit is 1 or 0 respectively,
regardless of whether the candidate is in X.
We now claim that QSAT2(0, r) =
RANKABLESSET(C, {X}). The following
terminology will be useful in proving this:
Given a bit sequence b = b1,. br, define a
b-satisfier to be a bit string bl • • • brb,±1. bs
such that 0(bi, ... be). For 1 &lt;i &lt;r, let B„ B,
denote the constraints G„ respectively if
b, = 1, or vice-versa if b, = 0. We then say
that a ranking d of C is 6-compatible if B,
precedes B, in C for every 1 &lt; i &lt; r.
Observe that a candidate y E Gen(c) is a g-
satisfier if it satisfies the constraints Bl, . Br
and C Di, and *X. From this it is not
difficult to see that if d is a 6-compatible rank-
ing, then y beats x (i.e., C(y) &lt; C(x)) for any
6-satisfier y and any x E X.16
Suppose RANKABLESSET(C, {X}). Then
choose x E X and a ranking of C such that
x is optimal (i.e., CHEcK(0, x)). For each 1 &lt;
i &lt; r, let b, = 1 if Cr, is ranked before C_„, in
0, otherwise b, = 0. Then Ô is a 6-compatible
ranking. Since x E X is optimal, there must be
no b-satisfiers y, i.e., QSAT2(0, r).
Conversely, suppose Q S AT2 (0, r ) . This
means we can choose b1, br such that there
are no 6-satisfiers._ Let C = (CD,,. • •cD„,,
Bl, Br, B1,. B, , *X). Observe that x =
bi • • • br2 E X satisfies the first m + r of the
constraints; this is optimal (i.e., CHEcK(C, x)),
since any better candidate would have to be a
b-satisfier.17 Hence there is a ranking C consis-
tent with X, i.e., RANKABLESSET(C, { X }).
</bodyText>
<sectionHeader confidence="0.933874" genericHeader="method">
8 Optimization vs. Derivation
</sectionHeader>
<bodyText confidence="0.891600785714286">
The above results mean that OT generation and
ranking are hard. We will now see that they are
harder than the corresponding problems in de-
terministic derivational theories, assuming that
the complexity classes discussed are distinct.
160(y‘
) = d(x) is impossible: only x violates *X. And
0(y) &gt; o(x) is impossible, for if x _satisfies any con-
straint that y violates, namely some B„ then it violates
a higher-ranked constraint that y satisfies, namely B.
17Since it would have to satisfy the first m r con-
straints plus a later constraint, which could only be *X.
A derivational grammar consists of the fol-
lowing elements (cf. P):
</bodyText>
<listItem confidence="0.99498725">
• an alphabet E;
• a set L C E* of underlying forms;
• a vector 1 = (R1, ... Rn) of rules, each of
which is a function from E* to E*.
</listItem>
<bodyText confidence="0.926017133333334">
— def
The grammar maps each x E L to R(x)
117,0 • • • oR2 oRi (X). If all the rules are polytime-
computable (i.e., in the function class FP), then
so is i. (By contrast, the OT analogue OPT
is complete for the function class FPNP.) It fol-
lows that the derivational analogues of the de-
cision problems given at the start of 0 are in
P18 (whereas we have seen that the OT versions
range from NP-complete to Al-complete).
How about learning? The rule ordering
problem ORDERABLES SET takes as input a set
R. of possible rules, a unary integer n, and a set
of pairs {(ni, ... (um, X,,,„)} where u, E E*
and X, C E*. It returns &amp;quot;yes&amp;quot; if there is a a rule
sequence fi E Rn such that (Vi)/4(u2) E X. It
is clear that this problem is in NP. This makes
it easier than its OT analogue RANKABLES SET
and possibly easier than RANKABLE.
For interest, we show that ORDERABLES SET
and its restricted version ORDERABLE (where
the attested sets X, are replaced by attested
forms x2) are NP-complete. As usual, our result
holds even with finite-state restrictions: we
require the rules in R. to be regular relations
(Johnson, 1972). The hardness proof is by
reduction from Hamilton Path (defined in
5.1). Given a directed graph G with vertices
1, 2, ... n, put E = {#, 0, 1, 2, ... n}. Each
string we consider will be either € or a permuta-
tion of E. Define MOVE3 to be a rule that maps
aj13#&apos;yi to al(3#&apos;yij for any i, j E E, a, /3,7 E E*
such that i = 0 or else G has an edge from i
to j, and acts as the identity function on other
strings. Also define ACCEPT to be a rule that
maps #a to € for any a E E*, and acts as
the identity function on other strings. Now
ORDERABLE({MOVE1, MOVER, ACCEPT}, 72+
1, {(12 • • • n#0, €)}) decides whether G has a
Hamilton path.
18However, Wareham (1998) analyzes a more power-
ful derivational approach where the rules are nondeter-
ministic: each R, is a relation rather than a function.
Wareham shows that generation in this case is NP-hard
(Theorem 4.3.3.1). He does not consider learning.
</bodyText>
<page confidence="0.999262">
32
</page>
<sectionHeader confidence="0.994964" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999932024390244">
The reader is encouraged to see the abstract for
a summary of our most important results. Our
main conclusion is a warning that OT may carry
huge computational burdens. When formulat-
ing the OT learning problem, even small nods
in the direction of realism quickly drive the com-
plexity from linear-time up through coNP (for
multiple competitors) into the higher complex-
ity classes (for multiple possible surface forms).
Intuitively, an OT learner must both pick a
constraint ranking (a) and check that an at-
tested form beats all competitors under that
ranking (V). By contrast, a derivational learner
need only pick a rule ordering (a).
One constraint ranking problem we consider,
RANKABLESSET, is in fact a rare &amp;quot;natural&amp;quot; ex-
ample of a problem that is complete for the
higher complexity class El4 (aV). Some other
learning problems were already known to be
complete (Ko and Tzeng, 1991), but ours is dif-
ferent in that it uses only positive evidence.
This paper leaves some theoretical questions
open. Most important is the exact classification
of RANKABLE. Second, we are interested in any
cases where problem variants (e.g., accepting vs.
rejecting the finite-state assumptions) differ in
complexity. Third, in the same spirit, param-
eterized complexity analyses (Wareham, 1998)
may help identify sources of hardness.
We are also interested in more realistic ver-
sions of the phonology learning problem. We
are especially interested in the possibility that
C has internal structure, as discussed in footnote
4, and in the problem of learning from general
attested sets, not just attested surface sets.
Finally, in light of our demonstrations that
efficient algorithms are highly unlikely for the
problems we have considered, we ask: Are there
restrictions, reformulations, or randomized or
approximate methods that could provably make
OT learning tractable in some sense?
</bodyText>
<sectionHeader confidence="0.99868" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999241328125">
Paul Boersma. 1997. How we learn variation, op-
tionality, and probability. In Proc. of the Institute
of Phonetic Sciences 21, U. of Amsterdam, 43-58.
T. H. Cormen, C. E. Leiserson, and R. L. Rivest.
1990. Introduction to Algorithms. MIT Press.
Jason Eisner. 1997a. Efficient generation in prim-
itive Optimality Theory. In Proceedings of
ACL/EACL, 313-320, Madrid, July.
Jason Eisner. 1997b. What constraints should OT
allow? Talk handout, Linguistic Society of Amer-
ica. Rutgers Optimality Archive ROA-204.
Jason Eisner. 2000. Directional constraint evalu-
ation in Optimality Theory. In Proceedings of
COLING, Saarbriicken, Germany, August.
T. Mark Ellison. 1994. Phonological derivation in
Optimality Theory. Proceedings of COLING.
Robert Frank and Giorgio Satta. 1998. Optimal-
ity Theory and the generative complexity of
constraint violability. Computational Linguistics,
24(2):307-315.
E. M. Gold. 1967. Language identification in the
limit. Information and Control, 10:447-474.
C. Douglas Johnson. 1972. Formal Aspects of
Phonological Description. Mouton.
Mark Johnson. 2000. Context-sensitivity and
stochastic &amp;quot;unification-based&amp;quot; grammars. Talk
presented at the CLSP Seminar Series, Johns
Hopkins University, February.
Rene Kager. 1999. Optimality Theory. Cambridge
University Press.
Lauri Karttunen. 1998. The proper treatment of op-
timality in computational phonology. In Proceed-
ings of International Workshop on Finite-State
Methods in NLP, 1-12, Bilkent University.
Ker-I Ko and Wen-Guey Tzeng. 1991. Three
complete problems in computational learning the-
ory. Computational Complexity, 1:269-310.
Mark W. Krentel. 1988. The complexity of op-
timization problems. Journal of Computer and
System Sciences, 36(3):490-509.
C. H. Papadimitriou and M. Yannakakis. 1982. The
complexity of facets (and some facets of complex-
ity). In Proc. of the 14th Annual Symposium on
Theory of Computing, 255-260, New York. ACM.
Christos H. Papadimitriou. 1984. On the complex-
ity of unique solutions. JACM, 31(2):392-400.
A. Prince and P. Smolensky. 1993. Optimality The-
ory: Constraint interaction in generative gram-
mar. Ms., Rutgers U. and U. Colorado (Boulder).
Bruce Tesar and Paul Smolensky. 1996. Learnabil-
ity in Optimality Theory (long version). Techni-
cal Report JHU-CogSci-96-3, Johns Hopkins Uni-
versity, October. Shortened version appears in
Linguistic Inquiry 29:229-268,1998.
Bruce Tesar and Paul Smolensky. 2000. Learnability
in Optimality Theory. MIT Press, Cambridge.
Bruce Tesar. 1996. Computing optimal descriptions
for Optimality Theory grammars with context-
free position structures. In Proceedings of ACL.
Bruce Tesar. 1997. Multi-recursive constraint de-
motion. Rutgers Optimality Archive ROA-197.
Harold Todd Wareham. 1998. Systematic Param-
eterized Complexity Analysis in Computational
Phonology. Ph.D. thesis, University of Victoria.
</reference>
<page confidence="0.999365">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.711587">
<title confidence="0.999437">Easy and Hard Constraint Ranking in Optimality Theory:* Algorithms and Complexity</title>
<author confidence="0.999979">Jason Eisner</author>
<affiliation confidence="0.991986">Dept. of Computer Science / University of</affiliation>
<address confidence="0.78708">NY 14607-0226 USA /</address>
<abstract confidence="0.99525175">We consider the problem of ranking a set of OT constraints in a manner consistent with data. (1) We speed up Tesar and Smolensky&apos;s RCD algorithm to be linear on the number of constraints. This finds a such that each attested form or ties particular competitor (2) We generalize RCD each beats or ties competitors. (3) if the surface form of is only partially observed, then an NP-hardness construction suggests that it is effectively necessary to consider all possible rankings or surface forms. (4) Merely checking a ranking is consistent with data is coN P-complete if the surface forms are fully oband if not (since OT generation is OptP-complete).(5) Determining whether any consistent ranking exists is coNP-hard (but in g) if the surface forms are fully observed, and Ei-complete if not. (6) Generation (P) and ranking (NP-complete) in derivational theories are easier than in OT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
</authors>
<title>How we learn variation, optionality, and probability.</title>
<date>1997</date>
<booktitle>In Proc. of the Institute of Phonetic Sciences 21, U. of Amsterdam,</booktitle>
<pages>43--58</pages>
<contexts>
<context position="21215" citStr="Boersma, 1997" startWordPosition="3831" endWordPosition="3832"> learner converges after seeing at most 0(n2) suboptimal attested forms, and hence after at most 0(n2) passes through xi,. . . x. Hence the total time is 0(n3E rn,n2P), where P is the time required by OPT. This is superficially worse than our RcDALL, which takes time 0(mn2P), but really the same since P dominates (see 0). Nonetheless, g will discuss a genuine sense in which RcDALL is more efficient than EDCD (and MRCD), thanks to the more limited information it gets from OPT. Algorithms that adjust constraint rankings or weights along a continuous scale include the Gradual Learning Algorithm (Boersma, 1997), which resembles simulated annealing, and maximum likelihood estimation (Johnson, 2000). These methods have the considerable advantage that they can deal with noise and free variation in the attested data. Both algorithms repeat until convergence, which makes it difficult to judge their efficiency except by experiment. 5 Incompletely Observed Forms We now add a further wrinkle. Suppose the input to the learner specifies only C together with attested surface sets {Xi}, as defined in P, rather than attested forms. This version of the problem captures the learner&apos;s uncertainty 6Instead of using </context>
</contexts>
<marker>Boersma, 1997</marker>
<rawString>Paul Boersma. 1997. How we learn variation, optionality, and probability. In Proc. of the Institute of Phonetic Sciences 21, U. of Amsterdam, 43-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Cormen</author>
<author>C E Leiserson</author>
<author>R L Rivest</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>1990</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10565" citStr="Cormen et al., 1990" startWordPosition="1881" endWordPosition="1884">ct storage cost of the formulas, i.e., M = &gt; ,021 + Ec O(C) I where 10(C)1 counts only the number of conjuncts. 3.2 Finding a Constraint Ranking The problem is now to find a constraint ranking that satisfies 0(C) for every C E C. Consider the special case where each 0(C) is a simple conjunction of literals that is, (Vi)D = 1. This is precisely the problem of topologically sorting a directed graph with n vertices and Ec 10(C)I = M/2 edges. The vertex set is C, and 0(C) lists the parents of vertex C, which must all be enumerated before C. Topological sort has two well-known 0(M + n) algorithms (Cormen et al., 1990). One is based on depth-first search. Here we will focus on the other, which is: Repeatedly find a vertex with no parents, enumerate it, and remove it and its outgoing edges from the graph. The second half of T&amp;S&apos;s RCD algorithm is simply the obvious generalization of this topological sort method (to directed hypergraphs, in fact, formally speaking). We describe it as a function RcD(C, 0) that returns a ranking d: 1. If C = 0, return (). Otherwise: 2. Identify a C1 E C such that 0(C1) is empty. (C1 is surface-true, or &amp;quot;undominated.&amp;quot;) 3. If there is no such constraint, then fail: no ranking can</context>
</contexts>
<marker>Cormen, Leiserson, Rivest, 1990</marker>
<rawString>T. H. Cormen, C. E. Leiserson, and R. L. Rivest. 1990. Introduction to Algorithms. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient generation in primitive Optimality Theory.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL/EACL,</booktitle>
<pages>313--320</pages>
<location>Madrid,</location>
<contexts>
<context position="4866" citStr="Eisner, 1997" startWordPosition="866" endWordPosition="867">alized. An attested set of the language is a set X such that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additional restrictio</context>
<context position="16860" citStr="Eisner, 1997" startWordPosition="3035" endWordPosition="3036">the previous ranking). 4 Considering All Competitors The algorithms of the previous section only ensure that each attested form x, is at least as harmonic as a given competitor yz: C(x) &lt; o(yz). But for x, to be grammatical, it must be at least as harmonic as all competitors. We would like a method that ensures this. Such a method will rank a constraint set C given only a set of attested forms {x1, ... xm}. Like T&amp;S, whose algorithm for this case is discussed in we will assume that we have an efficient computation of the OT generation function OPT(0, u). (See e.g. (Ellison, 1994; Tesar, 1996; Eisner, 1997a).) This returns the subset of Gen (u) on which o(.) is lexicographically minimal, i.e., the set of grammatical outputs for u. For purposes of analysis, we let P be a bound on the runtime of our OPT algorithm. We will discuss this runtime further in 4.1 Generalizing RCD We propose to solve this problem by running something like our earlier RCD algorithm, but considering all competitors at once. First, as a false start, let us try to construct the requirements 0(C) in this case. Consider the contribution of a single x, to a particular 0(C). x, demands that for any competitor y such that C(x) &gt;</context>
<context position="30157" citStr="Eisner (1997" startWordPosition="5420" endWordPosition="5421">hecks whether an attested surface set (namely X) is consistent with C. These problems place a lower bound on the difficulty of OT generation, since an algorithm that found a reasonable representation of OPT(C, (e.g., a DFA) could solve them immediately, and an algorithm that found an exemplar x E OPT(C, u) could solve all but CHECKSSET immediately. g will relate them to OT learning. 6.1 Past Results Under finite-state assumptions, Ellison (1994) showed that for any fixed d, a representation of OPT(C, u) could be generated in time 0(lul log u), making all the above problems tractable. However, Eisner (1997a) showed generation to be intractable when d was not fixed, but rather considered to be part of the input as is the case in an algorithm like RcDALL that learns rankings. Specifically, Eisner showed that OPTVALZ is NP-hard. Similarly, Wareham (1998, theorem 4.6.4) showed that a version of 1-9All these functions take an additional argument Gen, which we suppress for readability. 28 BEATABLE is NP-hard.11- (We will obtain more precise classifications below.) To put this another way, the worst-case complexity of generation problems is something like 0(lul log n) times a term exponential in C. Th</context>
<context position="41373" citStr="Eisner, 1997" startWordPosition="7436" endWordPosition="7437">l i. We do not have an exact classification of RANKABLE at this time. Interestingly, the special case where m = 1 and the constraints take values in {0, 1} (which has sufficed to show most of our hardness results) is coN P-complete the same as CHECK, which only verifies a solution. &amp;quot;This takes polynomially many steps provided that the integer C(x) is bounded by 2&amp;quot;) for some polynomial q (as it is under the finite-state assumptions). We have already assumed above that lx1 itself is polynomial on the input size, at least for optimal x. 15We can similarly show that OPTVALZ is not merely NP-hard (Eisner, 1997a) but A-complete, at least if we drop the finite-state assumptions: MsAtsb(0) = OPTVALZ(Co, C, Con-v„ ), €)• Here RANKABLE need only ask whether there exists any y E Gen(n1) that satisfies a proper superset of the constraints that xl satisfies. For if so, x1 cannot be optimal under any ranking, and if not, then we can simply rank the constraints that xl satisfies above the others. This immediately implies that the special case is in coNP. It also implies it is coNP-hard: using the grammar from our proof that CHECK is coNP-hard (6.3), we write CNF-SAT(0) = -1RANKABLE(C, {€}). As an upper bound</context>
</contexts>
<marker>Eisner, 1997</marker>
<rawString>Jason Eisner. 1997a. Efficient generation in primitive Optimality Theory. In Proceedings of ACL/EACL, 313-320, Madrid, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>What constraints should OT allow? Talk handout, Linguistic Society of America. Rutgers Optimality Archive ROA-204.</title>
<date>1997</date>
<contexts>
<context position="4866" citStr="Eisner, 1997" startWordPosition="866" endWordPosition="867">alized. An attested set of the language is a set X such that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additional restrictio</context>
<context position="16860" citStr="Eisner, 1997" startWordPosition="3035" endWordPosition="3036">the previous ranking). 4 Considering All Competitors The algorithms of the previous section only ensure that each attested form x, is at least as harmonic as a given competitor yz: C(x) &lt; o(yz). But for x, to be grammatical, it must be at least as harmonic as all competitors. We would like a method that ensures this. Such a method will rank a constraint set C given only a set of attested forms {x1, ... xm}. Like T&amp;S, whose algorithm for this case is discussed in we will assume that we have an efficient computation of the OT generation function OPT(0, u). (See e.g. (Ellison, 1994; Tesar, 1996; Eisner, 1997a).) This returns the subset of Gen (u) on which o(.) is lexicographically minimal, i.e., the set of grammatical outputs for u. For purposes of analysis, we let P be a bound on the runtime of our OPT algorithm. We will discuss this runtime further in 4.1 Generalizing RCD We propose to solve this problem by running something like our earlier RCD algorithm, but considering all competitors at once. First, as a false start, let us try to construct the requirements 0(C) in this case. Consider the contribution of a single x, to a particular 0(C). x, demands that for any competitor y such that C(x) &gt;</context>
<context position="30157" citStr="Eisner (1997" startWordPosition="5420" endWordPosition="5421">hecks whether an attested surface set (namely X) is consistent with C. These problems place a lower bound on the difficulty of OT generation, since an algorithm that found a reasonable representation of OPT(C, (e.g., a DFA) could solve them immediately, and an algorithm that found an exemplar x E OPT(C, u) could solve all but CHECKSSET immediately. g will relate them to OT learning. 6.1 Past Results Under finite-state assumptions, Ellison (1994) showed that for any fixed d, a representation of OPT(C, u) could be generated in time 0(lul log u), making all the above problems tractable. However, Eisner (1997a) showed generation to be intractable when d was not fixed, but rather considered to be part of the input as is the case in an algorithm like RcDALL that learns rankings. Specifically, Eisner showed that OPTVALZ is NP-hard. Similarly, Wareham (1998, theorem 4.6.4) showed that a version of 1-9All these functions take an additional argument Gen, which we suppress for readability. 28 BEATABLE is NP-hard.11- (We will obtain more precise classifications below.) To put this another way, the worst-case complexity of generation problems is something like 0(lul log n) times a term exponential in C. Th</context>
<context position="41373" citStr="Eisner, 1997" startWordPosition="7436" endWordPosition="7437">l i. We do not have an exact classification of RANKABLE at this time. Interestingly, the special case where m = 1 and the constraints take values in {0, 1} (which has sufficed to show most of our hardness results) is coN P-complete the same as CHECK, which only verifies a solution. &amp;quot;This takes polynomially many steps provided that the integer C(x) is bounded by 2&amp;quot;) for some polynomial q (as it is under the finite-state assumptions). We have already assumed above that lx1 itself is polynomial on the input size, at least for optimal x. 15We can similarly show that OPTVALZ is not merely NP-hard (Eisner, 1997a) but A-complete, at least if we drop the finite-state assumptions: MsAtsb(0) = OPTVALZ(Co, C, Con-v„ ), €)• Here RANKABLE need only ask whether there exists any y E Gen(n1) that satisfies a proper superset of the constraints that xl satisfies. For if so, x1 cannot be optimal under any ranking, and if not, then we can simply rank the constraints that xl satisfies above the others. This immediately implies that the special case is in coNP. It also implies it is coNP-hard: using the grammar from our proof that CHECK is coNP-hard (6.3), we write CNF-SAT(0) = -1RANKABLE(C, {€}). As an upper bound</context>
</contexts>
<marker>Eisner, 1997</marker>
<rawString>Jason Eisner. 1997b. What constraints should OT allow? Talk handout, Linguistic Society of America. Rutgers Optimality Archive ROA-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Directional constraint evaluation in Optimality Theory.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Saarbriicken, Germany,</location>
<contexts>
<context position="26694" citStr="Eisner (2000)" startWordPosition="4833" endWordPosition="4834">nd the number of violations by n. These bounds (as well as ICI = n) increase with the order n of the input graph. If the bounds were imposed by universal grammar, the construction would not be possible and NPhardness might not hold. Unfortunately, any universal bounds on 1X21 or ICI would hardly be small enough to protect the ranking algorithm from having to solve huge instances of Hamilton 27 path.8 As for bounded violations, the only real reason for imposing this restriction is to ensure that the OT grammar defines a regular relation (Frank and Satta, 1998; Karttunen, 1998). In recent work, Eisner (2000) argues that the restriction is too severe for linguistic description, and proposes a more general class of &amp;quot;directional constraints&amp;quot; under which OT grammars remain regular.9 If this relaxed restriction is substituted for a universal bound on violations, the ranking problem remains NP-hard, since each EARLY3 is a directional constraint. A more promising &amp;quot;way out&amp;quot; would be to universally restrict the size or structure of the automaton that describes the attested set. The set used in our construction was quite artificial. However, in g we will answer all these objections: we will show the proble</context>
</contexts>
<marker>Eisner, 2000</marker>
<rawString>Jason Eisner. 2000. Directional constraint evaluation in Optimality Theory. In Proceedings of COLING, Saarbriicken, Germany, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mark Ellison</author>
</authors>
<title>Phonological derivation in Optimality Theory.</title>
<date>1994</date>
<booktitle>Proceedings of COLING.</booktitle>
<contexts>
<context position="4852" citStr="Ellison, 1994" startWordPosition="863" endWordPosition="865">ily are not vocalized. An attested set of the language is a set X such that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additio</context>
<context position="6473" citStr="Ellison (1994)" startWordPosition="1134" endWordPosition="1135">se, we can solve the problem by packaging the entire morphological paradigm of laugh as a single candidate, whose attested set is constrained by the two surface observations and by the requirement of a shared underlying stem. (A k-member paradigm may be encoded in a form suitable to a finite-state system by interleaving symbols from 2k aligned tapes that describe the k underlying and k surface forms.) Alas, this scheme only works within disjoint finite paradigms: while it captures the shared underlying stem of laugh and laughed, it ignores the shared underlying suffix of laughed and frowned. 3Ellison (1994) makes only the weaker assumption that Gen(u) is a regular set for each u. Throughout this paper, we follow T&amp;S in supposing that the learner already knows the correct set of constraints C = {C1, C2, • • • Cn}, but must learn their order e = Kc,, C2, • • • Ca), known as a ranking of C. The assumption follows from the OT philosophy that C is universal across languages, and only the order of constraints differs. The algorithms for learning a ranking, however, are designed to be general for any C, so they take C as an input.4 3 RCD as Topological Sort T&amp;S investigate the problem of ranking a cons</context>
<context position="16833" citStr="Ellison, 1994" startWordPosition="3031" endWordPosition="3032">uses from scratch, ignoring the previous ranking). 4 Considering All Competitors The algorithms of the previous section only ensure that each attested form x, is at least as harmonic as a given competitor yz: C(x) &lt; o(yz). But for x, to be grammatical, it must be at least as harmonic as all competitors. We would like a method that ensures this. Such a method will rank a constraint set C given only a set of attested forms {x1, ... xm}. Like T&amp;S, whose algorithm for this case is discussed in we will assume that we have an efficient computation of the OT generation function OPT(0, u). (See e.g. (Ellison, 1994; Tesar, 1996; Eisner, 1997a).) This returns the subset of Gen (u) on which o(.) is lexicographically minimal, i.e., the set of grammatical outputs for u. For purposes of analysis, we let P be a bound on the runtime of our OPT algorithm. We will discuss this runtime further in 4.1 Generalizing RCD We propose to solve this problem by running something like our earlier RCD algorithm, but considering all competitors at once. First, as a false start, let us try to construct the requirements 0(C) in this case. Consider the contribution of a single x, to a particular 0(C). x, demands that for any co</context>
<context position="29994" citStr="Ellison (1994)" startWordPosition="5391" endWordPosition="5392">d , x): returns &amp;quot;yes&amp;quot; if x OPT(, u). This checks whether an attested form is consistent with C. • CHECKSSET(d, X): returns &amp;quot;yes&amp;quot; if CHECK(, x) for some x E X. This checks whether an attested surface set (namely X) is consistent with C. These problems place a lower bound on the difficulty of OT generation, since an algorithm that found a reasonable representation of OPT(C, (e.g., a DFA) could solve them immediately, and an algorithm that found an exemplar x E OPT(C, u) could solve all but CHECKSSET immediately. g will relate them to OT learning. 6.1 Past Results Under finite-state assumptions, Ellison (1994) showed that for any fixed d, a representation of OPT(C, u) could be generated in time 0(lul log u), making all the above problems tractable. However, Eisner (1997a) showed generation to be intractable when d was not fixed, but rather considered to be part of the input as is the case in an algorithm like RcDALL that learns rankings. Specifically, Eisner showed that OPTVALZ is NP-hard. Similarly, Wareham (1998, theorem 4.6.4) showed that a version of 1-9All these functions take an additional argument Gen, which we suppress for readability. 28 BEATABLE is NP-hard.11- (We will obtain more precise</context>
<context position="35687" citStr="Ellison, 1994" startWordPosition="6375" endWordPosition="6376">7, that represents a satisfying assignment for 0, or 1n if no such bitstring exists.12 We consider only problems where we can compute C(x), or determine whether x E Gen(u), in polytime. We further assume that Gen produces only candidates of length polynomial in the size of the problem input or more weakly, that our functions need not produce correct answers unless at least one optimal candidate is so bounded. Our hardness results (except as noted) apply even to OT grammars with the finite-state and bounded-violations assumptions (2). In fact, we will assume without further loss of generality (Ellison, 1994; Frank and Satta, 1998; Karttunen, 1998) that constraints are {0, 1}-valued. Notation: We may assume that all formulas 0 use variables from the set {vi, v2, ...}. Let (0) be the maximum i such that vz appears in 0. We define the constraint Co to map strings of at least f(0) bits to {0, 1}, defining Co(bi • • • bn) = 0 if 0 is true when the variables v, are instantiated to the respective values b2. So Co prefers bitstrings that satisfy 0. If we do not make the finite-state assumptions, then any Co can be represented trivially in size 101. Under the finite-state assumptions, however, we must re</context>
</contexts>
<marker>Ellison, 1994</marker>
<rawString>T. Mark Ellison. 1994. Phonological derivation in Optimality Theory. Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Frank</author>
<author>Giorgio Satta</author>
</authors>
<title>Optimality Theory and the generative complexity of constraint violability.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--2</pages>
<contexts>
<context position="4890" citStr="Frank and Satta, 1998" startWordPosition="868" endWordPosition="871">sted set of the language is a set X such that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additional restrictions. However, when demons</context>
<context position="26645" citStr="Frank and Satta, 1998" startWordPosition="4824" endWordPosition="4827">nstruction in the previous paragraph bounds 1X,1 by Ti! and the number of violations by n. These bounds (as well as ICI = n) increase with the order n of the input graph. If the bounds were imposed by universal grammar, the construction would not be possible and NPhardness might not hold. Unfortunately, any universal bounds on 1X21 or ICI would hardly be small enough to protect the ranking algorithm from having to solve huge instances of Hamilton 27 path.8 As for bounded violations, the only real reason for imposing this restriction is to ensure that the OT grammar defines a regular relation (Frank and Satta, 1998; Karttunen, 1998). In recent work, Eisner (2000) argues that the restriction is too severe for linguistic description, and proposes a more general class of &amp;quot;directional constraints&amp;quot; under which OT grammars remain regular.9 If this relaxed restriction is substituted for a universal bound on violations, the ranking problem remains NP-hard, since each EARLY3 is a directional constraint. A more promising &amp;quot;way out&amp;quot; would be to universally restrict the size or structure of the automaton that describes the attested set. The set used in our construction was quite artificial. However, in g we will ans</context>
<context position="35710" citStr="Frank and Satta, 1998" startWordPosition="6377" endWordPosition="6380">nts a satisfying assignment for 0, or 1n if no such bitstring exists.12 We consider only problems where we can compute C(x), or determine whether x E Gen(u), in polytime. We further assume that Gen produces only candidates of length polynomial in the size of the problem input or more weakly, that our functions need not produce correct answers unless at least one optimal candidate is so bounded. Our hardness results (except as noted) apply even to OT grammars with the finite-state and bounded-violations assumptions (2). In fact, we will assume without further loss of generality (Ellison, 1994; Frank and Satta, 1998; Karttunen, 1998) that constraints are {0, 1}-valued. Notation: We may assume that all formulas 0 use variables from the set {vi, v2, ...}. Let (0) be the maximum i such that vz appears in 0. We define the constraint Co to map strings of at least f(0) bits to {0, 1}, defining Co(bi • • • bn) = 0 if 0 is true when the variables v, are instantiated to the respective values b2. So Co prefers bitstrings that satisfy 0. If we do not make the finite-state assumptions, then any Co can be represented trivially in size 101. Under the finite-state assumptions, however, we must represent Co as a WDFA. W</context>
</contexts>
<marker>Frank, Satta, 1998</marker>
<rawString>Robert Frank and Giorgio Satta. 1998. Optimality Theory and the generative complexity of constraint violability. Computational Linguistics, 24(2):307-315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<date>1967</date>
<booktitle>Language identification in the limit. Information and Control,</booktitle>
<pages>10--447</pages>
<contexts>
<context position="1394" citStr="Gold (1967)" startWordPosition="220" endWordPosition="221"> single (given) ranking is consistent with data is coN P-complete if the surface forms are fully observed and .A1-complete if not (since OT generation is OptP-complete).(5) Determining whether any consistent ranking exists is coNP-hard (but in g) if the surface forms are fully observed, and Ei-complete if not. (6) Generation (P) and ranking (NP-complete) in derivational theories are easier than in OT. 1 Introduction Optimality Theory (OT) is a grammatical paradigm that was introduced by Prince and Smolensky (1993) and suggests various computational questions, including learnability. Following Gold (1967) we might ask: Is the language class {L(g) : g is an OT grammar} learnable in the limit? That is, is there a learning algorithm that will converge on any OTdescribable language L(g) if presented with an enumeration of its grammatical forms? In this paper we consider an orthogonal question that has been extensively investigated by Tesar and Smolensky (1996), henceforth T&amp;S. Rather than asking whether a learner can eventually find an OT grammar compatible with an unbounded set of positive data, we ask: How efficiently can it find a grammar (if one exists) compatible with a finite set of positive</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>E. M. Gold. 1967. Language identification in the limit. Information and Control, 10:447-474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Douglas Johnson</author>
</authors>
<title>Formal Aspects of Phonological Description.</title>
<date>1972</date>
<publisher>Mouton.</publisher>
<contexts>
<context position="47095" citStr="Johnson, 1972" startWordPosition="8550" endWordPosition="8551">et R. of possible rules, a unary integer n, and a set of pairs {(ni, ... (um, X,,,„)} where u, E E* and X, C E*. It returns &amp;quot;yes&amp;quot; if there is a a rule sequence fi E Rn such that (Vi)/4(u2) E X. It is clear that this problem is in NP. This makes it easier than its OT analogue RANKABLES SET and possibly easier than RANKABLE. For interest, we show that ORDERABLES SET and its restricted version ORDERABLE (where the attested sets X, are replaced by attested forms x2) are NP-complete. As usual, our result holds even with finite-state restrictions: we require the rules in R. to be regular relations (Johnson, 1972). The hardness proof is by reduction from Hamilton Path (defined in 5.1). Given a directed graph G with vertices 1, 2, ... n, put E = {#, 0, 1, 2, ... n}. Each string we consider will be either € or a permutation of E. Define MOVE3 to be a rule that maps aj13#&apos;yi to al(3#&apos;yij for any i, j E E, a, /3,7 E E* such that i = 0 or else G has an edge from i to j, and acts as the identity function on other strings. Also define ACCEPT to be a rule that maps #a to € for any a E E*, and acts as the identity function on other strings. Now ORDERABLE({MOVE1, MOVER, ACCEPT}, 72+ 1, {(12 • • • n#0, €)}) decid</context>
</contexts>
<marker>Johnson, 1972</marker>
<rawString>C. Douglas Johnson. 1972. Formal Aspects of Phonological Description. Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Context-sensitivity and stochastic &amp;quot;unification-based&amp;quot; grammars. Talk presented at the CLSP Seminar Series,</title>
<date>2000</date>
<institution>Johns Hopkins University,</institution>
<contexts>
<context position="21303" citStr="Johnson, 2000" startWordPosition="3842" endWordPosition="3843"> at most 0(n2) passes through xi,. . . x. Hence the total time is 0(n3E rn,n2P), where P is the time required by OPT. This is superficially worse than our RcDALL, which takes time 0(mn2P), but really the same since P dominates (see 0). Nonetheless, g will discuss a genuine sense in which RcDALL is more efficient than EDCD (and MRCD), thanks to the more limited information it gets from OPT. Algorithms that adjust constraint rankings or weights along a continuous scale include the Gradual Learning Algorithm (Boersma, 1997), which resembles simulated annealing, and maximum likelihood estimation (Johnson, 2000). These methods have the considerable advantage that they can deal with noise and free variation in the attested data. Both algorithms repeat until convergence, which makes it difficult to judge their efficiency except by experiment. 5 Incompletely Observed Forms We now add a further wrinkle. Suppose the input to the learner specifies only C together with attested surface sets {Xi}, as defined in P, rather than attested forms. This version of the problem captures the learner&apos;s uncertainty 6Instead of using CD on the new clause only, one may use RCD to find a ranking consistent with all clauses</context>
</contexts>
<marker>Johnson, 2000</marker>
<rawString>Mark Johnson. 2000. Context-sensitivity and stochastic &amp;quot;unification-based&amp;quot; grammars. Talk presented at the CLSP Seminar Series, Johns Hopkins University, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rene Kager</author>
</authors>
<title>Optimality Theory.</title>
<date>1999</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="15038" citStr="Kager, 1999" startWordPosition="2701" endWordPosition="2702">ratic dependence on n, the number of constraints to rank. As already mentioned, the total runtime is now dominated by 0(mnE), the preprocessing cost of applying all the constraints to all the input forms. Under the finite-state assumption, this can be be more tightly bounded as 0(n • total size of input forms) = 0(71 • E, Ixz I + since the cost of running a form through a WDFA is proportional to the former&apos;s length. 3.4 Alternative Algorithms T&amp;S also propose an alternative to RCD called Constraint Demotion (CD), which is perhaps better-known. (They focus primarily on it, and the textbook of (Kager, 1999) devotes a chapter to it.) A disjunctive clause D, (compiled as in 9.1) is processed roughly as follows: for each C such that D, is an unsatisfied clause of 0(C), greedily satisfy it by demoting C as little as possible. CD repeatedly processes D1, ... Dm until all clauses in all formulas are satisfied. CD can be efficiently implemented so that each pass through all clauses takes time proportional to M. But it is easy to construct datasets that require n + 1 passes. So the ranking step can take time 12(Mn), which contrasts unfavorably with the 0(M + n) time for RCD. CD does have the nice proper</context>
</contexts>
<marker>Kager, 1999</marker>
<rawString>Rene Kager. 1999. Optimality Theory. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>The proper treatment of optimality in computational phonology.</title>
<date>1998</date>
<booktitle>In Proceedings of International Workshop on Finite-State Methods in NLP,</booktitle>
<pages>1--12</pages>
<institution>Bilkent University.</institution>
<contexts>
<context position="4907" citStr="Karttunen, 1998" startWordPosition="872" endWordPosition="873">e is a set X such that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additional restrictions. However, when demonstrating that prob</context>
<context position="26663" citStr="Karttunen, 1998" startWordPosition="4828" endWordPosition="4829">ous paragraph bounds 1X,1 by Ti! and the number of violations by n. These bounds (as well as ICI = n) increase with the order n of the input graph. If the bounds were imposed by universal grammar, the construction would not be possible and NPhardness might not hold. Unfortunately, any universal bounds on 1X21 or ICI would hardly be small enough to protect the ranking algorithm from having to solve huge instances of Hamilton 27 path.8 As for bounded violations, the only real reason for imposing this restriction is to ensure that the OT grammar defines a regular relation (Frank and Satta, 1998; Karttunen, 1998). In recent work, Eisner (2000) argues that the restriction is too severe for linguistic description, and proposes a more general class of &amp;quot;directional constraints&amp;quot; under which OT grammars remain regular.9 If this relaxed restriction is substituted for a universal bound on violations, the ranking problem remains NP-hard, since each EARLY3 is a directional constraint. A more promising &amp;quot;way out&amp;quot; would be to universally restrict the size or structure of the automaton that describes the attested set. The set used in our construction was quite artificial. However, in g we will answer all these obje</context>
<context position="35728" citStr="Karttunen, 1998" startWordPosition="6381" endWordPosition="6383">ment for 0, or 1n if no such bitstring exists.12 We consider only problems where we can compute C(x), or determine whether x E Gen(u), in polytime. We further assume that Gen produces only candidates of length polynomial in the size of the problem input or more weakly, that our functions need not produce correct answers unless at least one optimal candidate is so bounded. Our hardness results (except as noted) apply even to OT grammars with the finite-state and bounded-violations assumptions (2). In fact, we will assume without further loss of generality (Ellison, 1994; Frank and Satta, 1998; Karttunen, 1998) that constraints are {0, 1}-valued. Notation: We may assume that all formulas 0 use variables from the set {vi, v2, ...}. Let (0) be the maximum i such that vz appears in 0. We define the constraint Co to map strings of at least f(0) bits to {0, 1}, defining Co(bi • • • bn) = 0 if 0 is true when the variables v, are instantiated to the respective values b2. So Co prefers bitstrings that satisfy 0. If we do not make the finite-state assumptions, then any Co can be represented trivially in size 101. Under the finite-state assumptions, however, we must represent Co as a WDFA. While this is alway</context>
</contexts>
<marker>Karttunen, 1998</marker>
<rawString>Lauri Karttunen. 1998. The proper treatment of optimality in computational phonology. In Proceedings of International Workshop on Finite-State Methods in NLP, 1-12, Bilkent University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ker-I Ko</author>
<author>Wen-Guey Tzeng</author>
</authors>
<title>Three complete problems in computational learning theory.</title>
<date>1991</date>
<journal>Computational Complexity,</journal>
<pages>1--269</pages>
<contexts>
<context position="48891" citStr="Ko and Tzeng, 1991" startWordPosition="8875" endWordPosition="8878">ive the complexity from linear-time up through coNP (for multiple competitors) into the higher complexity classes (for multiple possible surface forms). Intuitively, an OT learner must both pick a constraint ranking (a) and check that an attested form beats all competitors under that ranking (V). By contrast, a derivational learner need only pick a rule ordering (a). One constraint ranking problem we consider, RANKABLESSET, is in fact a rare &amp;quot;natural&amp;quot; example of a problem that is complete for the higher complexity class El4 (aV). Some other learning problems were already known to be complete (Ko and Tzeng, 1991), but ours is different in that it uses only positive evidence. This paper leaves some theoretical questions open. Most important is the exact classification of RANKABLE. Second, we are interested in any cases where problem variants (e.g., accepting vs. rejecting the finite-state assumptions) differ in complexity. Third, in the same spirit, parameterized complexity analyses (Wareham, 1998) may help identify sources of hardness. We are also interested in more realistic versions of the phonology learning problem. We are especially interested in the possibility that C has internal structure, as d</context>
</contexts>
<marker>Ko, Tzeng, 1991</marker>
<rawString>Ker-I Ko and Wen-Guey Tzeng. 1991. Three complete problems in computational learning theory. Computational Complexity, 1:269-310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark W Krentel</author>
</authors>
<title>The complexity of optimization problems.</title>
<date>1988</date>
<journal>Journal of Computer and System Sciences,</journal>
<pages>36--3</pages>
<contexts>
<context position="32538" citStr="Krentel (1988)" startWordPosition="5831" endWordPosition="5832">rces OPT to search for a Hamilton path in G, which demonstrates NP-hardness of OPTVALZ.) 6.2 Relevant Complexity Classes The reader may recall that P C NP fl coNP C NP U coNP C DP C Al4 = pNP c E/4 = NpNP. We will review these classes as they arise. They are classes of decision problems, i.e., functions taking values in {yes,no}. Hardness and completness for such classes are defined via many-one (Karp) reductions: g is at least as hard as f iff (V x) f (x) = g (T (x)) for some function T(x) computable in polynomial time. OptP is a class of integer-valued functions, introduced and discussed by Krentel (1988). Recall that NP is the class of decision problems that can be solved in polytime by a nondeter11Wareham also gave hardness results for versions of BEATABLE where some parameters are bounded or fixed. ministic Turing machine (NDTM): each control branch of the machine checks a different possibility and gives a yes/no answer, and the machine returns the disjunction of the answers. For coNP, the machine returns the conjunction of the answers. For OptP, each branch writes a binary number, and the machine returns the minimum (or maximum) of these answers. A canonical example (analogous to OPTVAL) i</context>
<context position="39768" citStr="Krentel (1988" startWordPosition="7145" endWordPosition="7146">e and 0 = AT-1 Dz, = Arzn21 D. Finally, we show that the decision prob13Without the finite-state assumptions, we could more simply write MsA(0) = OPTVAL(C01, C),€), where 03 = A -,v3. 30 lem CHEcKSSET(0, X) is A14-comp1ete. It is in A by an algorithm similar to the one used for TSP uniqueness above: since BEATABLE can be determined by an NP oracle, we can find OPTVAL(0, u) by binary search.14 An additional call to an NP oracle decides CHEcKSSET(C, X) by asking whether there is any x E X such that 0(x) = OPTVAL(d, u). The reduction to show Ai-hardness is from a Ai-complete problem exhibited by Krentel (1988, theorem 3.4): MsAisb accepts 0 if the final (least significant) bit of MsA(0) is 0. Given 0, we use the same grammar as when we reduced MSA to OPTVAL. MSAisb accepts if OPTVAL found a satisfying assignment and the last bit of this optimal assignment was 0: i.e., MsAi8b(0) = CHEcKSSET((CD,, • • • CD, C),ON0,11n-10).15 Note that we did not have to use an unreasonable attested surface set as in 0.1. The set ONO, 11n-10 means that the learner has observed only certain bits of the utterance exactly the kind of partial observation that we expect. So even some restriction to &amp;quot;reasonable&amp;quot; attested s</context>
</contexts>
<marker>Krentel, 1988</marker>
<rawString>Mark W. Krentel. 1988. The complexity of optimization problems. Journal of Computer and System Sciences, 36(3):490-509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Papadimitriou</author>
<author>M Yannakakis</author>
</authors>
<title>The complexity of facets (and some facets of complexity).</title>
<date>1982</date>
<booktitle>In Proc. of the 14th Annual Symposium on Theory of Computing,</booktitle>
<pages>255--260</pages>
<publisher>ACM.</publisher>
<location>New York.</location>
<contexts>
<context position="34084" citStr="Papadimitriou and Yannakakis, 1982" startWordPosition="6099" endWordPosition="6102"> of g and then appropriately transforming the integer result of g: (Vx) f (x) = T2(x, g(Ti(x))) for some polytime-computable functions T, : E* E* and T2 : E* x N —&gt; N. Krentel showed that OptP-complete problems yield complete problems for other classes under broad conditions. The question TsPVAL(G) &lt; k is of course the classical TSP decision problem, which is NP-complete. (It is analogous to BEATABLE.) The reverse question TsPVAL(G) &gt; k (which is related to CHECK) is coNP-complete. The question TsPVAL(G) = k (analogous to BEST) is therefore in the class DP = {L, n L2 : Ll E NP and L2 E coNP} (Papadimitriou and Yannakakis, 1982), and it is complete for that class. Finally, suppose we wish to ask whether the optimal tour is unique (like OPTVALZ and CHECKSSET, this asks about a complex property of the optimum). Papadimitriou (1984) first showed this question to be complete for = PNP, the class of languages decidable in polytime by deterministic Turing machines that have unlimited access to an oracle that can answer NP questions in unit time. (Such a machine can certainly decide uniqueness: It can compute the integer TsPVAL(G) by binary search, asking the oracle for various k whether or not TsPVAL(G) &lt; k, and then ask i</context>
<context position="38610" citStr="Papadimitriou and Yannakakis, 1982" startWordPosition="6922" endWordPosition="6926">is form, BEATABLE remains NP-complete. To show this, we tweak the above construction so we can write C(x) (for some x) in place of (0, 0, ... 0, 1). Add the new element E to Gen(€), and extend the constraint definitions by putting CD, (€) = 0 if i &lt; m. Then CNF-SAT(0) = BEATABLE(d, c, OW). Therefore CHECK is coN P-complete. Next we consider BEsT(d, u,I4 This problem is in DP for the same simple reason that the question TsPVAL(G) = k is (see above). If we do not make the finite-state assumptions, it is also Dr-hard by reduction from the DP-complete language SAT-UNSAT = {0#0 : çó E SAT, b SAT} (Papadimitriou and Yannakakis, 1982), as follows: SAT-UNsAT(0#&apos;0) = BEsT((Co, E, (0, 1)), renaming variables as necessary so that 0 uses only v1, ... Vr and ,0 uses only vr+i, ... vs, and Gen (€) = {0, 1}r+s• It is not clear whether BEST remains Dr-hard under the finite-state assumptions. But consider a more flexible variant RANGE(0, u, ki, k2) that asks whether OPTVAL(0, u) is between and k; inclusive. This is also in DP, and is Dr-hard because SAT-UNsAT(0#0) = RANGE((CD„ . • CD„, Cm, • • • CD&apos; ,), c, KO, . . . 0,0, .. 1) , (0, .. 0,1, . . 1), where 0, //), Gen are as before and 0 = AT-1 Dz, = Arzn21 D. Finally, we show that th</context>
</contexts>
<marker>Papadimitriou, Yannakakis, 1982</marker>
<rawString>C. H. Papadimitriou and M. Yannakakis. 1982. The complexity of facets (and some facets of complexity). In Proc. of the 14th Annual Symposium on Theory of Computing, 255-260, New York. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos H Papadimitriou</author>
</authors>
<title>On the complexity of unique solutions.</title>
<date>1984</date>
<pages>31--2</pages>
<publisher>JACM,</publisher>
<contexts>
<context position="34289" citStr="Papadimitriou (1984)" startWordPosition="6135" endWordPosition="6136">plete problems for other classes under broad conditions. The question TsPVAL(G) &lt; k is of course the classical TSP decision problem, which is NP-complete. (It is analogous to BEATABLE.) The reverse question TsPVAL(G) &gt; k (which is related to CHECK) is coNP-complete. The question TsPVAL(G) = k (analogous to BEST) is therefore in the class DP = {L, n L2 : Ll E NP and L2 E coNP} (Papadimitriou and Yannakakis, 1982), and it is complete for that class. Finally, suppose we wish to ask whether the optimal tour is unique (like OPTVALZ and CHECKSSET, this asks about a complex property of the optimum). Papadimitriou (1984) first showed this question to be complete for = PNP, the class of languages decidable in polytime by deterministic Turing machines that have unlimited access to an oracle that can answer NP questions in unit time. (Such a machine can certainly decide uniqueness: It can compute the integer TsPVAL(G) by binary search, asking the oracle for various k whether or not TsPVAL(G) &lt; k, and then ask it a final NP question: do there exist two distinct tours with cost TsPVAL(G)?) 6.3 New Complexity Results It is quite easy to show analogous results for OT generation. Our main tool will be one of Krentel&apos;</context>
</contexts>
<marker>Papadimitriou, 1984</marker>
<rawString>Christos H. Papadimitriou. 1984. On the complexity of unique solutions. JACM, 31(2):392-400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Prince</author>
<author>P Smolensky</author>
</authors>
<title>Optimality Theory: Constraint interaction in generative</title>
<date>1993</date>
<contexts>
<context position="1302" citStr="Prince and Smolensky (1993)" startWordPosition="207" endWordPosition="210">t it is effectively necessary to consider all possible rankings or surface forms. (4) Merely checking that a single (given) ranking is consistent with data is coN P-complete if the surface forms are fully observed and .A1-complete if not (since OT generation is OptP-complete).(5) Determining whether any consistent ranking exists is coNP-hard (but in g) if the surface forms are fully observed, and Ei-complete if not. (6) Generation (P) and ranking (NP-complete) in derivational theories are easier than in OT. 1 Introduction Optimality Theory (OT) is a grammatical paradigm that was introduced by Prince and Smolensky (1993) and suggests various computational questions, including learnability. Following Gold (1967) we might ask: Is the language class {L(g) : g is an OT grammar} learnable in the limit? That is, is there a learning algorithm that will converge on any OTdescribable language L(g) if presented with an enumeration of its grammatical forms? In this paper we consider an orthogonal question that has been extensively investigated by Tesar and Smolensky (1996), henceforth T&amp;S. Rather than asking whether a learner can eventually find an OT grammar compatible with an unbounded set of positive data, we ask: Ho</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>A. Prince and P. Smolensky. 1993. Optimality Theory: Constraint interaction in generative grammar. Ms., Rutgers U. and U. Colorado (Boulder).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
<author>Paul Smolensky</author>
</authors>
<title>Learnability in Optimality Theory (long version).</title>
<date>1996</date>
<tech>Technical Report JHU-CogSci-96-3,</tech>
<pages>29--229</pages>
<institution>Johns Hopkins University,</institution>
<contexts>
<context position="1752" citStr="Tesar and Smolensky (1996)" startWordPosition="281" endWordPosition="284">(NP-complete) in derivational theories are easier than in OT. 1 Introduction Optimality Theory (OT) is a grammatical paradigm that was introduced by Prince and Smolensky (1993) and suggests various computational questions, including learnability. Following Gold (1967) we might ask: Is the language class {L(g) : g is an OT grammar} learnable in the limit? That is, is there a learning algorithm that will converge on any OTdescribable language L(g) if presented with an enumeration of its grammatical forms? In this paper we consider an orthogonal question that has been extensively investigated by Tesar and Smolensky (1996), henceforth T&amp;S. Rather than asking whether a learner can eventually find an OT grammar compatible with an unbounded set of positive data, we ask: How efficiently can it find a grammar (if one exists) compatible with a finite set of positive data? We will consider successively more realistic versions of the problem, as described in the abstract. The easiest version turns out to be eas* Many thanks go to Lane and Edith Hemaspaandra for references to the complexity literature, and to Bruce Tesar for comments on an earlier draft. ier than previously known. The harder versions turn out to be hard</context>
</contexts>
<marker>Tesar, Smolensky, 1996</marker>
<rawString>Bruce Tesar and Paul Smolensky. 1996. Learnability in Optimality Theory (long version). Technical Report JHU-CogSci-96-3, Johns Hopkins University, October. Shortened version appears in Linguistic Inquiry 29:229-268,1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
<author>Paul Smolensky</author>
</authors>
<title>Learnability in Optimality Theory.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="27968" citStr="Tesar and Smolensky (2000)" startWordPosition="5042" endWordPosition="5046">nd binary-valued finite-state constraints (which, however, will not interact as simply). 5.3 Available Algorithms The NP-hardness results above suggests that existing algorithms designed for this ranking problem are either incorrect or intractable on certain cases. Again, this does not rule out efficient algorithms for variants of the problem see e.g. footnote 4 nor does it rule out algorithms that tend to perform well in the average case or on small inputs or on real data. T&amp;S proposed an algorithm for this problem, RIP/CD, but left its efficiency and correctness for future research (p. 39); Tesar and Smolensky (2000) show that it is not guaranteed to succeed. Tesar (1997) gives a related algorithm based on MRCD (see 0.2), but which sometimes requires iterating over all the candidates in an attested surface set; this might easily be intractable even when the set is finite. 6 Complexity of OT Generation The ranking algorithms in H4.1-4.2 relied on the existence of an algorithm to compute the independently interesting &amp;quot;language production&amp;quot; 8We expect attested sets X, to be very large especially in the more general case where they reflect uncertainty about the underlying form. That is why we describe them com</context>
</contexts>
<marker>Tesar, Smolensky, 2000</marker>
<rawString>Bruce Tesar and Paul Smolensky. 2000. Learnability in Optimality Theory. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
</authors>
<title>Computing optimal descriptions for Optimality Theory grammars with contextfree position structures.</title>
<date>1996</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="16846" citStr="Tesar, 1996" startWordPosition="3033" endWordPosition="3034">ch, ignoring the previous ranking). 4 Considering All Competitors The algorithms of the previous section only ensure that each attested form x, is at least as harmonic as a given competitor yz: C(x) &lt; o(yz). But for x, to be grammatical, it must be at least as harmonic as all competitors. We would like a method that ensures this. Such a method will rank a constraint set C given only a set of attested forms {x1, ... xm}. Like T&amp;S, whose algorithm for this case is discussed in we will assume that we have an efficient computation of the OT generation function OPT(0, u). (See e.g. (Ellison, 1994; Tesar, 1996; Eisner, 1997a).) This returns the subset of Gen (u) on which o(.) is lexicographically minimal, i.e., the set of grammatical outputs for u. For purposes of analysis, we let P be a bound on the runtime of our OPT algorithm. We will discuss this runtime further in 4.1 Generalizing RCD We propose to solve this problem by running something like our earlier RCD algorithm, but considering all competitors at once. First, as a false start, let us try to construct the requirements 0(C) in this case. Consider the contribution of a single x, to a particular 0(C). x, demands that for any competitor y su</context>
</contexts>
<marker>Tesar, 1996</marker>
<rawString>Bruce Tesar. 1996. Computing optimal descriptions for Optimality Theory grammars with contextfree position structures. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
</authors>
<title>Multi-recursive constraint demotion. Rutgers Optimality Archive ROA-197.</title>
<date>1997</date>
<contexts>
<context position="22057" citStr="Tesar (1997)" startWordPosition="3964" endWordPosition="3965">until convergence, which makes it difficult to judge their efficiency except by experiment. 5 Incompletely Observed Forms We now add a further wrinkle. Suppose the input to the learner specifies only C together with attested surface sets {Xi}, as defined in P, rather than attested forms. This version of the problem captures the learner&apos;s uncertainty 6Instead of using CD on the new clause only, one may use RCD to find a ranking consistent with all clauses generated so far. This step takes worst-case time 0(n2) rather than 0(n) even with our improved algorithm, but may allow faster convergence. Tesar (1997) calls this version Multi-Recursive Constraint Demotion (MRCD). 26 about the full description of the surface material. As before, the goal is to rank C in a manner consistent with the input. With this wrinkle, even determining whether such a ranking exists turns out to be surprisingly harder. In g we will see that it is actually E14-complete. Here we only show it NP-hard, using a construction that suggests that the NPhardness stems from the need to consider exponentially many rankings or surface forms. 5.1 NP-Hardness Construction Given n, we will be considering finite-state OT grammars of the</context>
<context position="28024" citStr="Tesar (1997)" startWordPosition="5055" endWordPosition="5056">teract as simply). 5.3 Available Algorithms The NP-hardness results above suggests that existing algorithms designed for this ranking problem are either incorrect or intractable on certain cases. Again, this does not rule out efficient algorithms for variants of the problem see e.g. footnote 4 nor does it rule out algorithms that tend to perform well in the average case or on small inputs or on real data. T&amp;S proposed an algorithm for this problem, RIP/CD, but left its efficiency and correctness for future research (p. 39); Tesar and Smolensky (2000) show that it is not guaranteed to succeed. Tesar (1997) gives a related algorithm based on MRCD (see 0.2), but which sometimes requires iterating over all the candidates in an attested surface set; this might easily be intractable even when the set is finite. 6 Complexity of OT Generation The ranking algorithms in H4.1-4.2 relied on the existence of an algorithm to compute the independently interesting &amp;quot;language production&amp;quot; 8We expect attested sets X, to be very large especially in the more general case where they reflect uncertainty about the underlying form. That is why we describe them compactly by DFAs. A universal constraint set C would also </context>
</contexts>
<marker>Tesar, 1997</marker>
<rawString>Bruce Tesar. 1997. Multi-recursive constraint demotion. Rutgers Optimality Archive ROA-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harold Todd Wareham</author>
</authors>
<title>Systematic Parameterized Complexity Analysis in Computational Phonology.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Victoria.</institution>
<contexts>
<context position="4923" citStr="Wareham, 1998" startWordPosition="874" endWordPosition="875"> that the learner knows that some x E X is grammatical (but not necessarily which x). The idea is that a set is attested if it contains all possible candidates that are consistent with something a learner heard.2 An attested surface set the case considered in this paper is an attested set all of whose elements are competitors; i.e., the learner is sure of the underlying form but not the surface form. Some computational treatments of OT place restrictions on the grammars that will be considered. The finite-state assumptions (Ellison, 1994; Eisner, 1997a; Frank and Satta, 1998; Karttunen, 1998; Wareham, 1998) are that • candidates and underlying forms are represented as strings over some alphabet; • Gen is a regular relation;3 • each C3 can be implemented as a weighted deterministic finite-state automaton (WDFA) (i.e., C3 (X) is the total weight of the path accepting x in the WDFA); • L and any attested sets are regular. The bounded-violations assumption (Frank and Satta, 1998; Karttunen, 1998) is that the value of C3(x) cannot increase with a, but is bounded above by some k. In this paper, we do not always impose these additional restrictions. However, when demonstrating that problems are hard, w</context>
<context position="30406" citStr="Wareham (1998" startWordPosition="5462" endWordPosition="5463">tely, and an algorithm that found an exemplar x E OPT(C, u) could solve all but CHECKSSET immediately. g will relate them to OT learning. 6.1 Past Results Under finite-state assumptions, Ellison (1994) showed that for any fixed d, a representation of OPT(C, u) could be generated in time 0(lul log u), making all the above problems tractable. However, Eisner (1997a) showed generation to be intractable when d was not fixed, but rather considered to be part of the input as is the case in an algorithm like RcDALL that learns rankings. Specifically, Eisner showed that OPTVALZ is NP-hard. Similarly, Wareham (1998, theorem 4.6.4) showed that a version of 1-9All these functions take an additional argument Gen, which we suppress for readability. 28 BEATABLE is NP-hard.11- (We will obtain more precise classifications below.) To put this another way, the worst-case complexity of generation problems is something like 0(lul log n) times a term exponential in C. Thus there are some grammars for which generation is very difficult by any algorithm. So when testing exponentially many rankings (5), a learner may need to spend exponential time testing an individual ranking. We offer an intuition as to why generati</context>
<context position="47754" citStr="Wareham (1998)" startWordPosition="8689" endWordPosition="8690">ilton Path (defined in 5.1). Given a directed graph G with vertices 1, 2, ... n, put E = {#, 0, 1, 2, ... n}. Each string we consider will be either € or a permutation of E. Define MOVE3 to be a rule that maps aj13#&apos;yi to al(3#&apos;yij for any i, j E E, a, /3,7 E E* such that i = 0 or else G has an edge from i to j, and acts as the identity function on other strings. Also define ACCEPT to be a rule that maps #a to € for any a E E*, and acts as the identity function on other strings. Now ORDERABLE({MOVE1, MOVER, ACCEPT}, 72+ 1, {(12 • • • n#0, €)}) decides whether G has a Hamilton path. 18However, Wareham (1998) analyzes a more powerful derivational approach where the rules are nondeterministic: each R, is a relation rather than a function. Wareham shows that generation in this case is NP-hard (Theorem 4.3.3.1). He does not consider learning. 32 9 Conclusions The reader is encouraged to see the abstract for a summary of our most important results. Our main conclusion is a warning that OT may carry huge computational burdens. When formulating the OT learning problem, even small nods in the direction of realism quickly drive the complexity from linear-time up through coNP (for multiple competitors) int</context>
<context position="49283" citStr="Wareham, 1998" startWordPosition="8935" endWordPosition="8936">lem we consider, RANKABLESSET, is in fact a rare &amp;quot;natural&amp;quot; example of a problem that is complete for the higher complexity class El4 (aV). Some other learning problems were already known to be complete (Ko and Tzeng, 1991), but ours is different in that it uses only positive evidence. This paper leaves some theoretical questions open. Most important is the exact classification of RANKABLE. Second, we are interested in any cases where problem variants (e.g., accepting vs. rejecting the finite-state assumptions) differ in complexity. Third, in the same spirit, parameterized complexity analyses (Wareham, 1998) may help identify sources of hardness. We are also interested in more realistic versions of the phonology learning problem. We are especially interested in the possibility that C has internal structure, as discussed in footnote 4, and in the problem of learning from general attested sets, not just attested surface sets. Finally, in light of our demonstrations that efficient algorithms are highly unlikely for the problems we have considered, we ask: Are there restrictions, reformulations, or randomized or approximate methods that could provably make OT learning tractable in some sense? Referen</context>
</contexts>
<marker>Wareham, 1998</marker>
<rawString>Harold Todd Wareham. 1998. Systematic Parameterized Complexity Analysis in Computational Phonology. Ph.D. thesis, University of Victoria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>