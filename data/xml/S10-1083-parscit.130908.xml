<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015089">
<title confidence="0.986802">
PengYuan@PKU: Extracting Infrequent Sense Instance with the
Same N-gram Pattern for the SemEval-2010 Task 15
</title>
<affiliation confidence="0.9937465">
1Institute of Computational Linguistics, Peking University, Beijing, China
2Department of Computer Science, Harbin Institute of Technology, Harbin, China
</affiliation>
<email confidence="0.998264">
{liupengyuan,yusw}@pku.edu.cn,{tjzhao,liushui}@mtlab.hit.edu.cn
</email>
<note confidence="0.783852">
Peng-Yuan Liu1 Shui Liu2 Shi-Wen Yu1 Tie-Jun Zhao2
</note>
<sectionHeader confidence="0.971189" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933045454546">
This paper describes our infrequent sense
identification system participating in the
SemEval-2010 task 15 on Infrequent Sense
Identification for Mandarin Text to Speech
Systems. The core system is a supervised
system based on the ensembles of Naive
Bayesian classifiers. In order to solve the
problem of unbalanced sense distribution, we
intentionally extract only instances of
infrequent sense with the same N-gram pattern
as the complemental training data from an
untagged Chinese corpus – People’s Daily of
the year 2001. At the same time, we adjusted
the prior probability to adapt to the
distribution of the test data and tuned the
smoothness coefficient to take the data
sparseness into account. Official result shows
that, our system ranked the first with the best
Macro Accuracy 0.952. We briefly describe
this system, its configuration options and the
features used for this task and present some
discussion of the results.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999364666666667">
We participated in the SemEval-2010 task 15 on
Infrequent Sense Identification for Mandarin
Text to Speech Systems. This task required
systems to disambiguating the homograph word,
a word that has the same POS (part of speech)
but different pronunciation. In this case, we still
considered it as a WSD (word sense
disambiguation) problem, but it is a little
different from WSD. In this task, two or more
senses of the same word may correspond to one
pronunciation. That is, the sense granularity is
coarser than traditional WSD.
The challenge of this task is the much skewed
distribution in real text: the most frequent
pronunciation accounts for usually over 80%. In
fact, in the training data provided by the
organizer , we found that the sense distribution
of some words are distinctly unbalanced. For
each of these words, there are fewer than ten
instances of one sense whereas the dominant
sense instances are hundreds or more. At the
same time, according to the task description on
the task 15 of SemEval-
2010(http://semeval2.fbk.eu/semeval2.php?locati
on=tasks), the test dataset of this task is
intentionally divided into the infrequent
pronunciation instances and the frequent ones by
half and half. Apparently, if we use traditional
methods and only the provided training dataset
to train whatever classifier, it is very likely that
we will get an disambiguation result that all (at
least the overwhelming number) the test
instances of these words would be labeled with
the most frequent pronunciation (sense) tag.
Then our system is meaningless for the target of
the task is focused on the performance of
identifying the infrequent sense.
In order to solve the problem of the
unbalanced sense distribution in the training data
and the fairly balanced sense distribution in the
test data, we designed our PengYuan@PKU
system, which attempts to extract infrequent
sense instances only and adjust the prior
probability so as to counteract the problem as far
as possible. The core system is a supervised
system based on the ensembles of Naive
Bayesian classifiers. The complemental training
data is extracted from an untagged Chinese
corpus – People’s Daily of the year 2001
automatically. Besides the motivation of
investigating the function of our method of
compensating infrequent sense instances, we are
also interested in the role where the smoothness
plays when it encounters with such a data
sparseness here.
In section 2, we will describe our system that
includes the core classifier, its configuration
options and features. In section 3, we will show
the official results of this task and present some
analyses and discussions. Section 4 is related
</bodyText>
<page confidence="0.98218">
371
</page>
<bodyText confidence="0.76875825">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 371–374,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
works. The conclusion and future work are in
section 5.
</bodyText>
<sectionHeader confidence="0.988306" genericHeader="introduction">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.998042">
2.1 Naïve Bayesian Classifier and Features
</subsectionHeader>
<bodyText confidence="0.99869475">
For a naive Bayesian classifier, the joint
probability of observing a certain combination of
context features with a particular sense is
expressed as:
</bodyText>
<equation confidence="0.989178">
n
p(F,F2,...,F ,S) =p(S)∏P(F;IS) (1) i=1
</equation>
<bodyText confidence="0.999907375">
In equation (1), (F1, F2,..., Fn) is feature
variables, S is classification variable and p(S) is
the prior probability of classification variable.
Any parameter that has a value of zero
indicates that the associated word never occurs
with the specified sense value. These zero
values are smoothed by additive smoothing
method as expressed below:
</bodyText>
<equation confidence="0.9997785">
P(F  |Sk) = C(F,Sk)
C(Sk) +
</equation>
<bodyText confidence="0.999038571428571">
In equation (2), Xis the smoothness variable.
C(Sk) is the times of instances with Sk label.
C(Fi,Sk) is the concurrences times of Fi and Sk. N
is the times of total words in the corpus.
The features and their weights of context used
in one single Naive Bayesian classifier are
described in Table 1.
</bodyText>
<table confidence="0.817821357142857">
Features Description weights
w-i...wi Content words appearing 1
within the window of ±i
words on each side of the
target word
wj/j Word forms and their 3
jE[-3,3] position information of the
words at fixed positions
from the target word.
wk-1wk word bigrams appearing 1 when
k E (-i,i] within the window of ± i i&gt;3, else
3
Pk-1Pk POS bigrams appearing 1
kE(-i,i] within the window of ±i
</table>
<tableCaption confidence="0.995893">
Table 1: Features and their weights used in one
</tableCaption>
<subsectionHeader confidence="0.920273333333333">
Naive Bayesian classifier
2.2 Ensembles the Naïve Bayesian
Classifiers
</subsectionHeader>
<bodyText confidence="0.999846363636364">
The ensemble strategy of our system is like
Pederson (2000). The windows of context have
seven different sizes (i): 3, 5, 7, 9, 11, 13 and 15
words. The first step in the ensemble approach is
to train a separate Naive Bayesian classifier for
each of the seven window sizes.
Each of the seven member classifiers votes for
the most probable sense given the particular
context represented by that classifier; the
ensemble disambiguates by assigning the sense
that receives the majority of the votes.
</bodyText>
<subsectionHeader confidence="0.941295">
2.3 Infrequent Sense Instances Acquisition
</subsectionHeader>
<table confidence="0.998761">
N-gram Increasing Instances Number
(-1,1) 246
3-gram (-2,0) 229 1026(9135)
(0,2) 551
2-gram (-1,0) 1123 2967(9135)
(0,1) 1844
</table>
<tableCaption confidence="0.992776">
Table 2: The overview of the training data before and
after the extracting stage
</tableCaption>
<table confidence="0.999985666666667">
Target Sense Distribution
Words
Before After
(O)
(O+E3) (O+E2)
背 128 51 128 66 128 2621
车 503 83 503 83 503 194
澄清 168 13 168 16 168 23
冲 175 10 175 27 175 88
当 487 42 487 63 487 267
aif 134 44 134 44 134 49
见长 125 11 125 11 125 12
看 2020 8 2020 12 2020 25
落 300 3 300 6 300 32
没 268 3 268 4 268 45
上 1625 41 1625 346 1625 1625
系 144 13 144 15 144 33
R弟 136 8 136 9 136 16
应 1666 253 1666 847 1666 1567
攒 142 17 142 17 142 17
转 438 76 438 136 438 414
</table>
<tableCaption confidence="0.9581735">
Table 3: The sense distributions of the training data
before and after the extracting stage
</tableCaption>
<bodyText confidence="0.999928111111111">
Our system uses a special heuristic rule to extract
the sense labeled infrequent sense instances
automatically. The heuristic rule assumes that
one sense per N-gram which we testified initially
through investigating a Chinese sense-tagged
corpus STC (Wu et al., 2006). Our assumption is
inspired by the celebrated one sense per
collocation supposition (Yarowsky, 1993). STC
is an ongoing project of building a sense-tagged
</bodyText>
<footnote confidence="0.406081">
1 We intentionally control the sense distribution of word
(“ff”) and change it from approximately 2.5:1 to 1:2 so as
to investigate the influence.
</footnote>
<equation confidence="0.990079666666667">
, XE(0,1) (2)
+X
N
</equation>
<page confidence="0.98525">
372
</page>
<bodyText confidence="0.9999409375">
corpus which contained the sense-tagged 1, 2 and
3 months of People’s Daily of the year 2000.
According to our investigation, to any target
multi-sense word, given a specific N-gram (N&gt;1)
including the target word, we will expect to see
the same label that range from 88.6% to 99.2%
of the time on average. So, based on the training
data, we can extract instance with the same N -
gram pattern from the untagged Chinese corpus
and we assume if the N-gram is the same then
the sense-label is the same.
For all the 16 multiple-sense target words in
the training data of task 15, we found the N-gram
of infrequence sense instances and extracted2 the
instances with the same N-gram from People’s
Daily of the year 2001(about 116M bytes). We
extracted as many as possible until the total
number of them is equal to the dominant sense
instance number. We appointed the same N-gram
instances the same sense tag and (merge?) it into
the original training corpus. Table 2 and 3 show
the overview and the sense distribution of the
training data before and after the extracting stage.
Number 9135 in brackets of Table 2 is the
instance number of original training corpus. O,
O+E3, O+E2 in Table 3 mean original training
data, original training data plus extracted 3-gram
instances and original training data plus extracted
2-gram instances respectively. Limited to the
scale of the corpus, the unbalance sense
distribution of some words does not improve
much.
</bodyText>
<table confidence="0.897247">
2.4 Other Configuration Options
Systems Training Data p(S) λ
_3.001 O+E3 0.5 0.001
_3.1 O+E3 0.5 0.1
_2.001 O+E2 0.5 0.001
_2.1 O+E2 0.5 0.1
</table>
<tableCaption confidence="0.999787">
Table 4: The system configuration
</tableCaption>
<bodyText confidence="0.999690888888889">
To formula (1), we tune the prior probability of
classification variable p(S) as a constant to match
the sense distribution of test data. Considering
the data sparseness as there may have been in the
test stage, to formula (2), we set 2 kinds ofλto
investigate the effect of smoothness.
In total, we develop four systems based on
various configuration options. They are showed
in Table 4.
</bodyText>
<footnote confidence="0.84823">
2 In order to guarantee the extracted instances are not
duplicated in the training data or in the test data in case, our
system filters the repeated instances automatically if they
are already in the original training or test dataset.
</footnote>
<sectionHeader confidence="0.986696" genericHeader="background">
3 Results and Discussions
</sectionHeader>
<subsectionHeader confidence="0.94476">
3.1 Official Results
</subsectionHeader>
<table confidence="0.998384428571429">
System Micro Macro Rank
ID Accuracy Accuracy
_3.001 0.974 0.952 1/9
_3.1 0.965 0.942 2/9
_2.001 0.965 0.941 3/9
_2.1 0.965 0.942 2/9
Baseline 0.924 0.895
</table>
<tableCaption confidence="0.822017">
Table 5: Official results 1 of PengYuan@PKU
</tableCaption>
<table confidence="0.999956333333333">
Words Precision
_3.001 _3.1 _2.001 _2.1 baseline
IT 0.844 0.789 0.789 0.789 0.711
车 0.976 0.962 0.969 0.962 0.863
澄清 0.901 0.901 0.901 0.901 0.901
冲 0.978 0.989 0.978 0.989 0.957
当 0.925 0.853 0.864 0.853 0.925
合if 0.956 0.944 0.956 0.944 0.700
见长 0.971 0.956 0.956 0.956 0.956
看 0.998 0.997 0.997 0.997 0.996
落 0.987 0.974 0.974 0.974 0.987
没 0.956 0.963 0.971 0.963 0.956
上 0.983 0.975 0.969 0.975 0.978
系 0.924 0.949 0.937 0.949 0.886
兄弟 0.986 0.986 0.986 0.986 0.959
应 0.986 0.989 0.989 0.989 0.869
攒 0.875 0.900 0.875 0.900 0.838
转 0.981 0.946 0.953 0.946 0.844
</table>
<tableCaption confidence="0.993942">
Table 6: Official results 2 of PengYuan@PKU
</tableCaption>
<bodyText confidence="0.999181">
Macro Accuracy is the average disambiguation
precision of each target word. Micro Accuracy is
the disambiguation precision of total instances of
all words. For task 15 whose instance
distribution of the target words is very
unbalanced in the test dataset, Macro Accuracy
maybe a better evaluation indicator. Our systems
achieved from 1st to 4th position (ranked by
Macro Accuracy) out of all nine systems that
participated in this task. Our best system is
PengYuan@PKU_3.001 which uses original
training data plus extracted 3-gram instances as
our training data, P(S) is tuned to 0.5 andλis
equal to 0.001.
</bodyText>
<subsectionHeader confidence="0.998247">
3.2 Discussions
</subsectionHeader>
<bodyText confidence="0.99978725">
From the official result in Table 5 and Table 6
we can see, for this task, our classifier and
strategy of extracting infrequency instances is
effective. Basically, for each target word, the
</bodyText>
<page confidence="0.998255">
373
</page>
<bodyText confidence="0.999925925925926">
performances of our systems are superior to the
baseline.
From Table 6, we also see the performances of
our systems are influenced by different λ and
different instance extracting patterns.
Comparatively smaller probability λ of
nonoccurrence features is better. Using the
Extracting 3-gram instances is better than that of
using 2-gram. (By using the 3-gram method of
extracting instances, we obtain a better result
than that of 2-gram.)
Our original idea for the system is two-folds.
On one hand, we consider the relieving of data
sparseness through more instances extracted by
2-gram pattern can achieve a better performance
than that of 3-gram pattern, though the instances
extracted through 2-gram pattern induce more
noise. On the other hand, we assume that the
performance would be better if we had given a
larger probability of nonoccurrence features, for
this strategy favors more infrequent sense
instances. However the unbalance of sense
distribution in the real test data as is shown in
Table 5 went beyond our expectation. It is very
hard for us to evaluate our system from the
viewpoint of smoothness and instance sense
distribution.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999976666666667">
To our knowledge, the methods of auto-
acquiring sense-labeled instances include using
parallel corpora like Gale et al. (1992) and Ng et
al. (2003), extracting by monosemous relative of
WordNet like Leacock et al. (1998), Mihalcea
and Moldovan (1999), Agirre and Martinez
(2004), Martinez et al. (2006) and PengYuan et
al. (2008). The method proposed by Mihalcea
and Moldovan (2000) is also an effective way.
</bodyText>
<sectionHeader confidence="0.993531" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999582">
We participated in the SemEval-2010 task 15 on
Infrequent Sense Identification for Mandarin
Text to Speech Systems. Official results show
our system which extract infrequent sense
instances is effective.
For the future studies, we will focus on how to
identify the infrequent sense instances effectively
based on the plan to change the proposition
between dominant sense and infrequent sense
step by step.
</bodyText>
<sectionHeader confidence="0.998383" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9808055">
This work was supported by the project of
National Natural Science Foundation of China
(No.60903063) and China Postdoctoral Science
Foundation funded project (No.20090450007).
</bodyText>
<sectionHeader confidence="0.995716" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999802833333334">
Claudia Leacock, Martin Chodorow and George A.
Miller, Using Corpus Statistics and WordNet
Relations for Sense Identification. Computational
Linguistics, 1998, 24(1):147~166
David Mart�inez, Eneko Agirre and Xinglong Wang.
Word relatives in context for word sense
disambiguation. Proceedings of the 2006
Australasian Language Technology Workshop
(ALTW2006), 2006:42~50
David Yarowsky. 1993. One sense per collocation.
Proceedings of the ARPA Workshop on Human
Language Technology.
Eneko Agirre and David Mart�inez. Unsupervised
WSD based on automatically retrieved examples:
The importance of bias. Proceedings of the
International Conference on Empirical Methods in
Natural Language Processing, EMNLP,
2004:25~32
Hwee Tou Ng, Bin Wang, Yee Seng Chan. Exploiting
Parallel Texts for Word Sense Disambiguation: An
Empirical Study. Proceeding of the 41st ACL, 455-
462, Sappora, Japan.
Liu Peng-yuan Zhao Tie-jun Yang Mu-yun Li Zhuang.
2008. Unsupervised Translation Disambiguation
Based on Equivalent PseudoTranslation Model.
Journal of Electronics &amp; Information Technology.
30(7):1690-1695.
Rada Mihalcea and Dan I. Moldovan. 1999. An
automatic method for generating sense tagged
corpora. Proceedings of AAAI-99, Orlando, FL,
July, pages 461–466.
Rada Mihalcea and Dan .I. Moldovan. 2000. An
iterative approach to word sense disambiguation.
Proceedings of FLAIRS-2000, pages 219–223,
Orlando, FL, May.
Ted. Pedersen. 2000. A Simple Approach to Building
Ensembles of Naive Bayesian Classifiers for Word
Sense Disambiguation. Proceedings of the First
Annual Meeting of the North American Chapter
of the Association for Computational Linguistics,
pages 63-69, Seattle, WA, May.
Yunfang Wu, Peng Jin, Yangsen Zhang, and Shiwen
Yu. 2006. A Chinese corpus with word sense
annotation. Proceedings of ICCPOL-2006.
William A. Gale, Kenneth W. Church and David
Yarowsky. A method for disambiguating word
senses in a large corpus. Computers and the
Humanities, 26(2):415-539
</reference>
<page confidence="0.999015">
374
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208603">
<title confidence="0.689751">PengYuan@PKU: Extracting Infrequent Sense Instance with the</title>
<author confidence="0.475658">Same N-gram Pattern for the SemEval- Task</author>
<affiliation confidence="0.36209">of Computational Linguistics, Peking University, Beijing, China</affiliation>
<address confidence="0.772954">of Computer Science, Harbin Institute of Technology, Harbin, China</address>
<email confidence="0.93039">liupengyuan@mtlab.hit.edu.cn</email>
<email confidence="0.93039">yusw}@pku.edu.cn@mtlab.hit.edu.cn</email>
<email confidence="0.93039">{tjzhao@mtlab.hit.edu.cn</email>
<email confidence="0.93039">liushui@mtlab.hit.edu.cn</email>
<author confidence="0.99171">Shui Shi-Wen Tie-Jun</author>
<abstract confidence="0.998643391304348">This paper describes our infrequent sense identification system participating in the SemEval-2010 task 15 on Infrequent Sense Identification for Mandarin Text to Speech Systems. The core system is a supervised based on the ensembles of In order to solve the problem of unbalanced sense distribution, we intentionally extract only instances of infrequent sense with the same N-gram pattern as the complemental training data from an Chinese corpus Daily of the year 2001. At the same time, we adjusted the prior probability to adapt to the distribution of the test data and tuned the smoothness coefficient to take the data sparseness into account. Official result shows that, our system ranked the first with the best Macro Accuracy 0.952. We briefly describe this system, its configuration options and the features used for this task and present some discussion of the results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
<author>George A Miller</author>
</authors>
<title>Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics,</title>
<date>1998</date>
<pages>24--1</pages>
<contexts>
<context position="12858" citStr="Leacock et al. (1998)" startWordPosition="2123" endWordPosition="2126">at the performance would be better if we had given a larger probability of nonoccurrence features, for this strategy favors more infrequent sense instances. However the unbalance of sense distribution in the real test data as is shown in Table 5 went beyond our expectation. It is very hard for us to evaluate our system from the viewpoint of smoothness and instance sense distribution. 4 Related Work To our knowledge, the methods of autoacquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martinez (2004), Martinez et al. (2006) and PengYuan et al. (2008). The method proposed by Mihalcea and Moldovan (2000) is also an effective way. 5 Conclusion and Future Work We participated in the SemEval-2010 task 15 on Infrequent Sense Identification for Mandarin Text to Speech Systems. Official results show our system which extract infrequent sense instances is effective. For the future studies, we will focus on how to identify the infrequent sense instances effectively based on the plan to change the proposition between dominant sense and infrequ</context>
</contexts>
<marker>Leacock, Chodorow, Miller, 1998</marker>
<rawString>Claudia Leacock, Martin Chodorow and George A. Miller, Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics, 1998, 24(1):147~166</rawString>
</citation>
<citation valid="false">
<authors>
<author>David Mart�inez</author>
</authors>
<title>Eneko Agirre and Xinglong Wang. Word relatives in context for word sense disambiguation.</title>
<booktitle>Proceedings of the 2006 Australasian Language Technology Workshop (ALTW2006),</booktitle>
<pages>2006--42</pages>
<marker>Mart�inez, </marker>
<rawString>David Mart�inez, Eneko Agirre and Xinglong Wang. Word relatives in context for word sense disambiguation. Proceedings of the 2006 Australasian Language Technology Workshop (ALTW2006), 2006:42~50</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One sense per collocation.</title>
<date>1993</date>
<booktitle>Proceedings of the ARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="7330" citStr="Yarowsky, 1993" startWordPosition="1200" endWordPosition="1201">45 上 1625 41 1625 346 1625 1625 系 144 13 144 15 144 33 R弟 136 8 136 9 136 16 应 1666 253 1666 847 1666 1567 攒 142 17 142 17 142 17 转 438 76 438 136 438 414 Table 3: The sense distributions of the training data before and after the extracting stage Our system uses a special heuristic rule to extract the sense labeled infrequent sense instances automatically. The heuristic rule assumes that one sense per N-gram which we testified initially through investigating a Chinese sense-tagged corpus STC (Wu et al., 2006). Our assumption is inspired by the celebrated one sense per collocation supposition (Yarowsky, 1993). STC is an ongoing project of building a sense-tagged 1 We intentionally control the sense distribution of word (“ff”) and change it from approximately 2.5:1 to 1:2 so as to investigate the influence. , XE(0,1) (2) +X N 372 corpus which contained the sense-tagged 1, 2 and 3 months of People’s Daily of the year 2000. According to our investigation, to any target multi-sense word, given a specific N-gram (N&gt;1) including the target word, we will expect to see the same label that range from 88.6% to 99.2% of the time on average. So, based on the training data, we can extract instance with the sam</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>David Yarowsky. 1993. One sense per collocation. Proceedings of the ARPA Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eneko Agirre</author>
<author>David Mart�inez</author>
</authors>
<title>Unsupervised WSD based on automatically retrieved examples: The importance of bias.</title>
<booktitle>Proceedings of the International Conference on Empirical Methods in Natural Language Processing, EMNLP,</booktitle>
<pages>2004--25</pages>
<marker>Agirre, Mart�inez, </marker>
<rawString>Eneko Agirre and David Mart�inez. Unsupervised WSD based on automatically retrieved examples: The importance of bias. Proceedings of the International Conference on Empirical Methods in Natural Language Processing, EMNLP, 2004:25~32</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hwee Tou Ng</author>
<author>Bin Wang</author>
</authors>
<title>Yee Seng Chan. Exploiting Parallel Texts for Word Sense Disambiguation: An Empirical Study.</title>
<booktitle>Proceeding of the 41st ACL,</booktitle>
<pages>455--462</pages>
<location>Sappora, Japan.</location>
<marker>Ng, Wang, </marker>
<rawString>Hwee Tou Ng, Bin Wang, Yee Seng Chan. Exploiting Parallel Texts for Word Sense Disambiguation: An Empirical Study. Proceeding of the 41st ACL, 455-462, Sappora, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liu Peng-yuan</author>
</authors>
<title>Zhao Tie-jun Yang Mu-yun Li Zhuang.</title>
<date>2008</date>
<journal>Journal of Electronics &amp; Information Technology.</journal>
<pages>30--7</pages>
<marker>Peng-yuan, 2008</marker>
<rawString>Liu Peng-yuan Zhao Tie-jun Yang Mu-yun Li Zhuang. 2008. Unsupervised Translation Disambiguation Based on Equivalent PseudoTranslation Model. Journal of Electronics &amp; Information Technology. 30(7):1690-1695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Dan I Moldovan</author>
</authors>
<title>An automatic method for generating sense tagged corpora.</title>
<date>1999</date>
<booktitle>Proceedings of AAAI-99,</booktitle>
<pages>461--466</pages>
<location>Orlando, FL,</location>
<contexts>
<context position="12888" citStr="Mihalcea and Moldovan (1999)" startWordPosition="2127" endWordPosition="2130">d be better if we had given a larger probability of nonoccurrence features, for this strategy favors more infrequent sense instances. However the unbalance of sense distribution in the real test data as is shown in Table 5 went beyond our expectation. It is very hard for us to evaluate our system from the viewpoint of smoothness and instance sense distribution. 4 Related Work To our knowledge, the methods of autoacquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martinez (2004), Martinez et al. (2006) and PengYuan et al. (2008). The method proposed by Mihalcea and Moldovan (2000) is also an effective way. 5 Conclusion and Future Work We participated in the SemEval-2010 task 15 on Infrequent Sense Identification for Mandarin Text to Speech Systems. Official results show our system which extract infrequent sense instances is effective. For the future studies, we will focus on how to identify the infrequent sense instances effectively based on the plan to change the proposition between dominant sense and infrequent sense step by step. Acknow</context>
</contexts>
<marker>Mihalcea, Moldovan, 1999</marker>
<rawString>Rada Mihalcea and Dan I. Moldovan. 1999. An automatic method for generating sense tagged corpora. Proceedings of AAAI-99, Orlando, FL, July, pages 461–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Dan I Moldovan</author>
</authors>
<title>An iterative approach to word sense disambiguation.</title>
<date>2000</date>
<booktitle>Proceedings of FLAIRS-2000,</booktitle>
<pages>219--223</pages>
<location>Orlando, FL,</location>
<contexts>
<context position="13020" citStr="Mihalcea and Moldovan (2000)" startWordPosition="2148" endWordPosition="2151">. However the unbalance of sense distribution in the real test data as is shown in Table 5 went beyond our expectation. It is very hard for us to evaluate our system from the viewpoint of smoothness and instance sense distribution. 4 Related Work To our knowledge, the methods of autoacquiring sense-labeled instances include using parallel corpora like Gale et al. (1992) and Ng et al. (2003), extracting by monosemous relative of WordNet like Leacock et al. (1998), Mihalcea and Moldovan (1999), Agirre and Martinez (2004), Martinez et al. (2006) and PengYuan et al. (2008). The method proposed by Mihalcea and Moldovan (2000) is also an effective way. 5 Conclusion and Future Work We participated in the SemEval-2010 task 15 on Infrequent Sense Identification for Mandarin Text to Speech Systems. Official results show our system which extract infrequent sense instances is effective. For the future studies, we will focus on how to identify the infrequent sense instances effectively based on the plan to change the proposition between dominant sense and infrequent sense step by step. Acknowledgments This work was supported by the project of National Natural Science Foundation of China (No.60903063) and China Postdoctora</context>
</contexts>
<marker>Mihalcea, Moldovan, 2000</marker>
<rawString>Rada Mihalcea and Dan .I. Moldovan. 2000. An iterative approach to word sense disambiguation. Proceedings of FLAIRS-2000, pages 219–223, Orlando, FL, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedersen</author>
</authors>
<title>A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for Word Sense Disambiguation.</title>
<date>2000</date>
<booktitle>Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>63--69</pages>
<location>Seattle, WA,</location>
<marker>Pedersen, 2000</marker>
<rawString>Ted. Pedersen. 2000. A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for Word Sense Disambiguation. Proceedings of the First Annual Meeting of the North American Chapter of the Association for Computational Linguistics, pages 63-69, Seattle, WA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunfang Wu</author>
<author>Peng Jin</author>
<author>Yangsen Zhang</author>
<author>Shiwen Yu</author>
</authors>
<title>A Chinese corpus with word sense annotation.</title>
<date>2006</date>
<booktitle>Proceedings of ICCPOL-2006.</booktitle>
<contexts>
<context position="7229" citStr="Wu et al., 2006" startWordPosition="1184" endWordPosition="1187">134 44 134 49 见长 125 11 125 11 125 12 看 2020 8 2020 12 2020 25 落 300 3 300 6 300 32 没 268 3 268 4 268 45 上 1625 41 1625 346 1625 1625 系 144 13 144 15 144 33 R弟 136 8 136 9 136 16 应 1666 253 1666 847 1666 1567 攒 142 17 142 17 142 17 转 438 76 438 136 438 414 Table 3: The sense distributions of the training data before and after the extracting stage Our system uses a special heuristic rule to extract the sense labeled infrequent sense instances automatically. The heuristic rule assumes that one sense per N-gram which we testified initially through investigating a Chinese sense-tagged corpus STC (Wu et al., 2006). Our assumption is inspired by the celebrated one sense per collocation supposition (Yarowsky, 1993). STC is an ongoing project of building a sense-tagged 1 We intentionally control the sense distribution of word (“ff”) and change it from approximately 2.5:1 to 1:2 so as to investigate the influence. , XE(0,1) (2) +X N 372 corpus which contained the sense-tagged 1, 2 and 3 months of People’s Daily of the year 2000. According to our investigation, to any target multi-sense word, given a specific N-gram (N&gt;1) including the target word, we will expect to see the same label that range from 88.6% </context>
</contexts>
<marker>Wu, Jin, Zhang, Yu, 2006</marker>
<rawString>Yunfang Wu, Peng Jin, Yangsen Zhang, and Shiwen Yu. 2006. A Chinese corpus with word sense annotation. Proceedings of ICCPOL-2006.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and the Humanities,</title>
<pages>26--2</pages>
<marker>Gale, Church, Yarowsky, </marker>
<rawString>William A. Gale, Kenneth W. Church and David Yarowsky. A method for disambiguating word senses in a large corpus. Computers and the Humanities, 26(2):415-539</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>