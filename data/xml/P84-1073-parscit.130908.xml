<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.987472">
LR Parsers
For Natural Languages&apos;
</title>
<author confidence="0.96861">
Masaru Tomita
</author>
<affiliation confidence="0.813390666666667">
Computer Science Department
Carnegie-Mellon University
Pittsburgh, PA 15213
</affiliation>
<sectionHeader confidence="0.906921" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999830190476191">
MLR, an extended LR parser, is introduced, and its
application to natural language parsing is discussed.
An LR parser is a shift-reduce parser which is
deterministically guided by a parsing table. A parsing
table can be obtained automatically from a context-
free phrase structure grammar. LR parsers cannot
manage ,ambiguous grammars such as natural
language grammars, because their parsing tables
would have multiply-defined entries, which precludes
deterministic parsing. MLR, however, can handle
multiply-defined entries, using a dynamic
programming method. When an input sentence is
ambiguous, the MLR parser produces all possible
parse trees without parsing any part of the input
sentence more than once in the same way, despite the
fact that the parser does not maintain a chart as in
chart parsing. Our method also provides an elegant
solution to the problem of multi-part-of -speech words
such as &amp;quot;that&amp;quot;. The mul parser and its parsing table
generator have been implemented at Carnegie-Mellon
University.
</bodyText>
<sectionHeader confidence="0.996275" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9776995">
LR parsers [1, 2] have been developed originally for
programming language of compilers. An LII parser is a shift.
reduce parser which is deterministically guided by a parsing table
indicating what action should be taken next. The parsing table
can be obtained automatically from a context-free phrase
structure grammar, using an algorithm first developed by
DeRemer [5, 6]. We do not describe the algorithm here, reffering
the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers
have seldom been used for Natural Language Processing
probably because:
</bodyText>
<listItem confidence="0.9884716">
1. It has been thought that natural languages are not
context-free, whereas LR parsers can cleat only with
context-free languages.
2. Natural languages are ambiguous, while standard LR
parsers can not handle ambiguous languages.
</listItem>
<bodyText confidence="0.991883457142857">
The recent literature [8] shows that the belief &amp;quot;natural
languages are not context-free&amp;quot; is not necessarily true, and there
is no reason for us to give up the context-freedom of natural
languages. We do not discuss on this matter further, considering
the fact that even if natural languages are not context-free, a
fairly comprehensive grammar for a subset of natural language
sufficient for practical systems can be written in context-free
phrase structure. Thus, our main concern is how to cope with the
ambiguity of natural languages, and this concern is addressed in
the following section.
2 LR parsers and Ambiguous Grammars
If a given grammar is ambiguous,2 we cannot have a parsing
table in which every entry is uniquely defined; at least one entry of
its parsing table is multiply defined. It has been thought that, for
LR parsers, multiple entries are fatal because they make
deterministic parsing no longer possible.
Aho et. al. [3] and Shieber [121 coped with this ambiguity
problem by statically3 selecting one desired action out of multiple
actions, and thus converting multiply-defined entries into
uniquely-defined ones-With this approach, every input sentence
has no more than one parse tree. This fact is desirable for
programming languages.
For natural languages, however, it is sometimes necessary for a
parser to produce more than one parse tree. For example,
consider the following short story.
I saw the man with a telescope.
He should have bought it at the department store.
When the first sentence is read, there is absolutely no way to
resolve the ambiguity4 at that time. The only action the system
can take is to produce two parse trees and store them
somewhere for later disambiguation.
In contrast with Aho et. al. and Shieber, our approach is to
extend LR parsers so that they can handle multiple entries and
produce more than one parse tree if needed. We call the
extended LA parsers MLR parsers.
</bodyText>
<footnote confidence="0.945908166666667">
1 .hi
1 s research was sponsored by the Defense Advanced Research Projects
Agency (DOD), ARPA Order No. 3597, munitmed hy the Air Force Avionics
Laboratory Under Contract 1,339Ib 81 K.1539.. 1110 views and conclusions
contained in this document at those of the authors and should not be interpreted
as representing the nflicial policies, either expressod or implied, of the Defense
Advanced Research Projects Agency or the US Government.
2A grammar is ambiguous, if some input sentence can be parsed in more than
one way.
By statically&apos; , we mean the selection is done at parsing table construction
time.
I&amp;quot; have the telescope, or &amp;quot;the man&amp;quot; has the telescope.
</footnote>
<page confidence="0.998882">
354
</page>
<bodyText confidence="0.9931535">
of different parses have in the chart parsing method [10, 11]. The
idea should be made clear by the following example.
</bodyText>
<sectionHeader confidence="0.915109" genericHeader="method">
3 MLR Parsers
</sectionHeader>
<bodyText confidence="0.999489909090909">
An example grammar and its MLR parsing table produced by
the construction algorithm are shown in fig. 1 and 2, respectively.
The MLR parsing table construction algorithm is exactly the same
as the algorithm for LR parsers. Only the difference is that an
MLR parsing table may have multiple entries. Grammar symbols
starting with &amp;quot;*&amp;quot; represent pre-terminals. &amp;quot;sh n&amp;quot; in the action
table (the left part of the table) indicates the action &amp;quot;shift one
word from input buffer onto the stack, and go to state n&amp;quot;. &amp;quot;re n&amp;quot;
indicates the action &amp;quot;reduce constituents on the stack using rule
n&amp;quot;. &amp;quot;acc&amp;quot; stands for the action &amp;quot;accept&amp;quot;, and blank spaces
represent &amp;quot;en or&amp;quot;. Gob o table (the right part of the table) decides
to what state the parser should go after -a reduce action. The
exact definition and operation of LR parsers can be found in Aho
arid Ullman [4].
We can see that there are two multiple entries in the table; on
the rows of state 11 and 12 at the column of &amp;quot;&apos;prep&amp;quot;. As
mentioned above, once a parsing table has multiple entries,
deterministic parsing is no longer possible; some kind of non-
determinism is necessary. We shall see that our dynamic
programming approach, which is described below, is much more
efficient than conventional breath-first or depth-first search, and
makes MLR parsing feasible.
</bodyText>
<sectionHeader confidence="0.888214" genericHeader="method">
4 An Example
</sectionHeader>
<bodyText confidence="0.9877915">
In this section, we demonstrate, step by step, how our MLR
parser processes the sentence:
</bodyText>
<subsectionHeader confidence="0.641785">
I SAW A MAN WITH A TELESCOPE
</subsectionHeader>
<bodyText confidence="0.999595351351351">
using the grammar and the parsing table shown in fig 1 and 2.
This sentence is ambiguous, and the parser should accept the
sentence in two ways.
Until the system finds a multiple entry, it behaves in the exact
same manner as a conventional LR parser, as shown in fig 3-a
below. The number on the top (rightmost) of the stack indicates
the current state. Initially, the current state is 0. Since the parser
is looking at the word &amp;quot;I&amp;quot;, whose category is &amp;quot;•n&amp;quot;, the next action
&amp;quot;shift and goto state 4&amp;quot; is determined from the parsing table. The.
parser takes the word &amp;quot;I&amp;quot; away from the input buffer, and pushes
the preterminal &amp;quot;•n&amp;quot; onto the stack. The next word the parser is
looking at is &amp;quot;SAW&amp;quot;, whose category is &amp;quot;•v&amp;quot;, and &amp;quot;reduce using
rule 3&amp;quot; is determined as the next action. After reducing, the
parser determines the current state, 2, by looking at the
intersection of the row of state 0 and the column of &amp;quot;NP&amp;quot;, and so
on.
Our approach is basically pseudo-parallelism (breath-first
search). When a process encounters a multiple entry with n
different actions, the process is split into n processes, and they
are executed individually and parallelly. Each process is
continued until either an &amp;quot;error&amp;quot; or an &amp;quot;accept&amp;quot; action is found.
The processes are, however, synchronized in the following way:
When a process &amp;quot;shifts&amp;quot; a word, it waits until all other processes
&amp;quot;shift&amp;quot; the word. Intuitively, all processes always look at the
same word. After all processes shift a word, the system may find
that two or more processes are in the same state; that is, some
processes have a common state number on the top of their
stacks. These processes would do the exactly same thing until
that common state number is popped from their stacks by some
&amp;quot;reduce&amp;quot; action. In our parser, this common part is processed
only once. As soon as two or more processes in a common state
are found, they are combined into one process. This combining
mechanism guarantees that any part of an input sentence is
parsed no more than once in the same manner: This makes the
parsing much more efficient than simple breath-first or depth-first
search. Our method has the same effect in terms of parsing
efficiency that posting and recognizing common subconstituents
</bodyText>
<listItem confidence="0.9407939">
State *det
1 sh3
2
(1) S --&gt; NP VP 3
(2) S --&gt; S PP 4
(3) NP --&gt; *n 5
(4) NP --&gt; *det *n 6 sh3
(5) NP --&gt; NP PP 7 sh3
(6) PP --&gt; *prep NP 8
(7) VP --&gt; *v NP
</listItem>
<figure confidence="0.9784495">
10
11
12
Fig 1
NIXT -ACT ION NEXT-WOOD
sh 4
re 3 SAW
sh 7 SAW
7 sh3 A
7 *dot 3 sh 10 MAN
7 &apos;dot 3 on 10 re 4 WITH
7 NP 12 ro 7, sh 6 WI NI
</figure>
<figureCaption confidence="0.521036">
Fig 3-a
</figureCaption>
<bodyText confidence="0.970713666666667">
At this point, the system finds a multiple entry with two different
actions, &amp;quot;reduce 7&amp;quot; and &amp;quot;shift 6&amp;quot;. Both actions are processed in
parallel, as shown in fig 3-b.
</bodyText>
<table confidence="0.996132461538461">
*n sh7 &apos;prep $
sh4 sh6 acc
sh6
sh10
re3 re3 re3
re 2 re2
sh4
sh4
rel re 1
re5 re5 re5
re4 re4 re 4
re 6 re6,sh6 re6
re7,sh6 re 7
</table>
<figure confidence="0.930942391304348">
Fig 2
STACK
0
0 4
0 NP 2
0 NP 2 ov
0 NP 2
0 NP 2 •,,f
0 NP 2
NP PP VP S
2 1
5
9 8
11
12
355
0 NP 2 VP 8 Co I WITH
0 NP 2 .v 7 NP 12 &apos;prop 6 wait A
OS&apos; sh 6 WITH
0 NP 2 &amp;quot;v 7 NV 12 &amp;quot;prep 6 wait A
0 S 1 &apos;prop 6 sh 3 A
0 NP 2 &apos;v 7 NV 12 &apos;prop 6 sh 3 A
Fig 3-b
</figure>
<bodyText confidence="0.806012">
Here, the system finds that both processes have the common
state number, 6, on the top of their stacks. It combines two
processes into one, and operates as if there is only one process,
US sliown in fig 3-c.
</bodyText>
<figure confidence="0.956445916666667">
0 S I ammomm........prProP 6 SN 3 A
0 NP 2 / NP 124r
0 S I 0 &apos;dot 3 sh 10 TELESCOPE
ammoNommommils,.prop
0 NP 2 .v 7 NP
&apos;dot 3 &apos;n 10 re 4
0 S I tommilmmoommmilp.prop S
0 NP 2 ov 7 NP I2dr
0 S NP ro 6
memeeeme■jp•prop
0 NP 2 ov 7 NP 124r
Fig 3-c
</figure>
<bodyText confidence="0.978499">
The action &amp;quot;reduce 6&amp;quot; pops the common state number 6, and
the system can no longer operate the two processes as one. The
two processes are, again, operated in parallel, as shown in fig
</bodyText>
<figure confidence="0.98533225">
0 S 1 PP 5 re 2
0 NP 2 &apos;a 7 NP 12 PP 9 re 5
Os&apos; accept
0 NP 2 7 PP 12 re 7
</figure>
<figureCaption confidence="0.523272">
Fig 3-d
</figureCaption>
<bodyText confidence="0.960518428571429">
Now, one of the two processes is finished by the action
&amp;quot;accept&amp;quot;. The other process is still continued, as shown in fig
This process is also finished by the action &amp;quot;accept&amp;quot;. The
system has accepted the input sentence in both ways. It is
important to note that any part of the input sentence, including
the prepositional phrase &amp;quot;WITH A TELESCOPE&amp;quot;, is parsed only
once in the same way, without maintaining a chart.
</bodyText>
<sectionHeader confidence="0.984814" genericHeader="method">
5 Another Example
</sectionHeader>
<bodyText confidence="0.999812692307692">
Some English words belong to more than one grammatical
category. When such a word is encountered, the MLR parsing
table can immediately tell which of its categories are legal and
which are not. When more than one of its categories are legal,
the parser behaves as if a multiple entry were encountered. The
idea should be-made clear by the following example.
Consider the word &amp;quot;that&amp;quot; in the sentence:
That information is important is doubtful.
A sample grammar and its parsing table are shown in Fig. 4 and 5,
respectively. Initially, the parser is at state 0. The first word
&amp;quot;that&amp;quot; can be either &amp;quot;der or &amp;quot;that&amp;quot;, and the parsing table tells
us that both categories are legal. Thus, the parser processes &amp;quot;sh
5&amp;quot; and &amp;quot;sh 3&amp;quot; in parallel, as shown below.
</bodyText>
<figure confidence="0.7649251">
STACK NEXT ACTION NEXT WORD
SN 5, sh 3 fhat
Sb 5 That
sh 3 That
0 &apos;dot 5 sh 9 information
0 &apos;that 3 0 4 information
0 &apos;dot 5 on 9 re 2 is
0 &apos;that 3 40 4 re 3 is
0 NP 2 SN 6 Is
0 &apos;that 3 NP 2 sh 6 is
</figure>
<figureCaption confidence="0.929329">
Fig. 6-a
</figureCaption>
<bodyText confidence="0.995137">
At this point, the parser founds that both processes are in the
same state, namely state 2, and they are combined as one
process.
</bodyText>
<figure confidence="0.964989985074627">
acc
NP S VP
2 1
7
2 8
&apos;dot •n &apos;that
sh5 sh4 sh3
sh 5 sh4 sh3
0 NP 2 VP 8 Fig 3-e re •adj *be
0 S accopt
State
0
1
(1) S --&gt; NP VP 2 sh8
(2) NP --&gt; &apos;det &apos;n 3
(3) NP --&gt; *n 4 re3
(4) NP --&gt; &apos;that S 5
(5) VP --&gt; &apos;he &apos;adj 6 sh10
7 rel
8 re4
9 re2
Fig. 4 10 ro5
sh9
rel
re5
Fig. 5
356
IS
Important
Ii
63 66
77 99
172 205
74
45
121
47
51
108
XPL EULER FORTRAN ALGOL60
Terminals
Non-terminals
Productions
States 180 193 322 337
TableSize(byte) 2041 2687 3662 4264
0 NP .m■mmm7 2 sh 6
0 &apos;that 3 NP
0 NP .0•04 2 *be 6 sh 10
0 &apos;that 3 NP
0 NP &amp;quot;&amp;quot;p2 *be 6 •adj 10 re 5
0 oth=71
OMP sawmsamm), 2 VP 7 rel is
0 &apos;that 3 Nil
Fig. 6-b
The process is split into two processes again.
0 NP 2 VP 7 re 1 is
0 that 3 NP 2 VP 7 re 1 is
Os&apos; dERRONS is
0 that 3 S 8 re 4 Is
Fig. 6-c .
One of two processes detects &amp;quot;error&amp;quot; and halts; only the other
process goes on.
0 NP 2 sh 6 is
0 MP 2 &amp;quot;be 6 sh 10 doubtful
0 NP 2 be 8 •adj 10 re 5
0 NP 2 VP 7 re 1
Os&apos; SCC
</figure>
<figureCaption confidence="0.788254">
Fig. 6-d
</figureCaption>
<bodyText confidence="0.999859">
Finally, the sentence has been parsed in only one way. We
emphasize again that, in spite of pseudo-parallelism, each part of
the sentence was parsed only once in the same way.
</bodyText>
<sectionHeader confidence="0.986113" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.973779115384615">
The MLR parser and its parsing table generator have been
implemented at Computer Science Department, Carnegie-Mellon
University. The system is written in MACLISP and running on
Tops-20.
One good feature of an MLR parser (and of an LR parser) is
that, even if the parser is to run on a small computer, the
construction of the parsing table can be done on more powerful,
larger computers. Once a parsing table is constructed, the
execution time for parsing depends weakly on the number of
productions or symbols in a grammar. Also, in spite of pseudo-
parallelism, our MLR parsing is theoretically still deterministic.
This is because the number of processes in our pseudo-
parallelism never exceeds the number of states in the parsing
table.
One concern of our parser is whether the size of a parsing table
remains tractable as the size of a grammar grows. Fig. 6 shows
the relationship between the complexity of a grammar and its LR
parsing table (excerpt from Inoue [9]).
Fig. 6
Although the example grammars above are for programming
langauges, it seems that the size of a parsing table grows only in
proportion to the size of its grammar and does not grow rapidly.
Therefore, there is a hope that our MLR parsers can manage
grammars with thousands of phrase structure rules, which would
be generated by rule-schema and meta-rules for natural language
in systems such as GPSG [7].
</bodyText>
<sectionHeader confidence="0.99798" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.995043">
I would like to thank Takehiro Tokuda, Osamu
Watanabe, Jaime Carbonell and Herb Simon for
thoughtful comments on an earlier version of this
paper.
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997783525">
[1] Aho, A. V. and Ullman, J. D.
The Theory of Parsing. Translation and Compiling.
Prentice-Hall, Englewood Cliffs, N. J., 1972.
[2] Aho, A. V. and Johnson, S. C.
LR parsing.
Computing Surveys 6:2:99-124, 1974.
[3] Aho, A. V., Johnson, S. C. and Ullman, J. D.
Deterministic parsing of ambiguous grammars.
Comm. ACM 18:8:441-452, 1975.
[4] Aho, A. V. and Ullman, J. D.
Principles of Compiler Design.
Addison Wesley, 1977.
[5] Deremer, F. L
Practical Translators for LR(k) Languages.
PhD thesis, MIT, 1969.
[6) DeRemer, F. L
Simple LR(k) grammars.
Comm. ACM 14:7:453-460, 1971.
[7] Gazdar, G.
Phrase Structure Grammar.
D. Reidel, 1982, pages 131-186.
[8] Gazdar, G.
Phrase Structure Grammars and Natural Language.
Proceedings of the Eighth International Joint Conference
on Artificial Intelligence v.1, August, 1983.
[9] Inoue, K. and Fujiwara, F.
On LLC(k) Parsing Method of LR(k) Grammars.
Journal of Information Processing vol.6(no.4):pp.206-217,
1983.
[10] Kaplan, R. M.
A general syntactic processor.
Algorithmics Press, New York, 1973, pages 193-241.
[11) Kay, M.
The MIND system.
Algorithmics Press, New York, 1973, pages 155-188.
[12] Shieber, S. M.
Sentence Disambiguation by a Shift-Reduce Parsing
Technique.
Proceedings of the Eighth International Joint Conference
on Artificial Intelligence v.2, August, 1983.
</reference>
<page confidence="0.998013">
357
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.371826">
<title confidence="0.9948885">LR Parsers For Natural Languages&apos;</title>
<author confidence="0.994359">Masaru Tomita</author>
<affiliation confidence="0.999952">Computer Science Department Carnegie-Mellon University</affiliation>
<address confidence="0.999911">Pittsburgh, PA 15213</address>
<abstract confidence="0.984280619047619">MLR, an extended LR parser, is introduced, and its application to natural language parsing is discussed. An LR parser is a shift-reduce parser which is deterministically guided by a parsing table. A parsing table can be obtained automatically from a contextfree phrase structure grammar. LR parsers cannot manage ,ambiguous grammars such as natural language grammars, because their parsing tables would have multiply-defined entries, which precludes deterministic parsing. MLR, however, can handle multiply-defined entries, using a dynamic programming method. When an input sentence is ambiguous, the MLR parser produces all possible parse trees without parsing any part of the input sentence more than once in the same way, despite the fact that the parser does not maintain a chart as in chart parsing. Our method also provides an elegant solution to the problem of multi-part-of -speech words as &amp;quot;that&amp;quot;. The and its parsing table generator have been implemented at Carnegie-Mellon</abstract>
<note confidence="0.652715">University.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<title>The Theory of Parsing. Translation and Compiling. Prentice-Hall,</title>
<date>1972</date>
<location>Englewood</location>
<contexts>
<context position="1177" citStr="[1, 2]" startWordPosition="174" endWordPosition="175">h precludes deterministic parsing. MLR, however, can handle multiply-defined entries, using a dynamic programming method. When an input sentence is ambiguous, the MLR parser produces all possible parse trees without parsing any part of the input sentence more than once in the same way, despite the fact that the parser does not maintain a chart as in chart parsing. Our method also provides an elegant solution to the problem of multi-part-of -speech words such as &amp;quot;that&amp;quot;. The mul parser and its parsing table generator have been implemented at Carnegie-Mellon University. 1 Introduction LR parsers [1, 2] have been developed originally for programming language of compilers. An LII parser is a shift. reduce parser which is deterministically guided by a parsing table indicating what action should be taken next. The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer [5, 6]. We do not describe the algorithm here, reffering the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers have seldom been used for Natural Language Processing probably because: 1. It has been thought that natural languages are not contex</context>
</contexts>
<marker>[1]</marker>
<rawString>Aho, A. V. and Ullman, J. D. The Theory of Parsing. Translation and Compiling. Prentice-Hall, Englewood Cliffs, N. J., 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>S C Johnson</author>
</authors>
<title>LR parsing.</title>
<date>1974</date>
<journal>Computing Surveys</journal>
<pages>6--2</pages>
<contexts>
<context position="1177" citStr="[1, 2]" startWordPosition="174" endWordPosition="175">h precludes deterministic parsing. MLR, however, can handle multiply-defined entries, using a dynamic programming method. When an input sentence is ambiguous, the MLR parser produces all possible parse trees without parsing any part of the input sentence more than once in the same way, despite the fact that the parser does not maintain a chart as in chart parsing. Our method also provides an elegant solution to the problem of multi-part-of -speech words such as &amp;quot;that&amp;quot;. The mul parser and its parsing table generator have been implemented at Carnegie-Mellon University. 1 Introduction LR parsers [1, 2] have been developed originally for programming language of compilers. An LII parser is a shift. reduce parser which is deterministically guided by a parsing table indicating what action should be taken next. The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer [5, 6]. We do not describe the algorithm here, reffering the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers have seldom been used for Natural Language Processing probably because: 1. It has been thought that natural languages are not contex</context>
</contexts>
<marker>[2]</marker>
<rawString>Aho, A. V. and Johnson, S. C. LR parsing. Computing Surveys 6:2:99-124, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>S C Johnson</author>
<author>J D Ullman</author>
</authors>
<title>Deterministic parsing of ambiguous grammars.</title>
<date>1975</date>
<journal>Comm. ACM</journal>
<pages>18--8</pages>
<contexts>
<context position="2888" citStr="[3]" startWordPosition="449" endWordPosition="449">mmar for a subset of natural language sufficient for practical systems can be written in context-free phrase structure. Thus, our main concern is how to cope with the ambiguity of natural languages, and this concern is addressed in the following section. 2 LR parsers and Ambiguous Grammars If a given grammar is ambiguous,2 we cannot have a parsing table in which every entry is uniquely defined; at least one entry of its parsing table is multiply defined. It has been thought that, for LR parsers, multiple entries are fatal because they make deterministic parsing no longer possible. Aho et. al. [3] and Shieber [121 coped with this ambiguity problem by statically3 selecting one desired action out of multiple actions, and thus converting multiply-defined entries into uniquely-defined ones-With this approach, every input sentence has no more than one parse tree. This fact is desirable for programming languages. For natural languages, however, it is sometimes necessary for a parser to produce more than one parse tree. For example, consider the following short story. I saw the man with a telescope. He should have bought it at the department store. When the first sentence is read, there is ab</context>
</contexts>
<marker>[3]</marker>
<rawString>Aho, A. V., Johnson, S. C. and Ullman, J. D. Deterministic parsing of ambiguous grammars. Comm. ACM 18:8:441-452, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<title>Principles of Compiler Design.</title>
<date>1977</date>
<publisher>Addison Wesley,</publisher>
<contexts>
<context position="1628" citStr="[4]" startWordPosition="247" endWordPosition="247">rds such as &amp;quot;that&amp;quot;. The mul parser and its parsing table generator have been implemented at Carnegie-Mellon University. 1 Introduction LR parsers [1, 2] have been developed originally for programming language of compilers. An LII parser is a shift. reduce parser which is deterministically guided by a parsing table indicating what action should be taken next. The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer [5, 6]. We do not describe the algorithm here, reffering the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers have seldom been used for Natural Language Processing probably because: 1. It has been thought that natural languages are not context-free, whereas LR parsers can cleat only with context-free languages. 2. Natural languages are ambiguous, while standard LR parsers can not handle ambiguous languages. The recent literature [8] shows that the belief &amp;quot;natural languages are not context-free&amp;quot; is not necessarily true, and there is no reason for us to give up the context-freedom of natural languages. We do not discuss on this matter further, considering the fact that even if natural l</context>
<context position="5520" citStr="[4]" startWordPosition="894" endWordPosition="894">that an MLR parsing table may have multiple entries. Grammar symbols starting with &amp;quot;*&amp;quot; represent pre-terminals. &amp;quot;sh n&amp;quot; in the action table (the left part of the table) indicates the action &amp;quot;shift one word from input buffer onto the stack, and go to state n&amp;quot;. &amp;quot;re n&amp;quot; indicates the action &amp;quot;reduce constituents on the stack using rule n&amp;quot;. &amp;quot;acc&amp;quot; stands for the action &amp;quot;accept&amp;quot;, and blank spaces represent &amp;quot;en or&amp;quot;. Gob o table (the right part of the table) decides to what state the parser should go after -a reduce action. The exact definition and operation of LR parsers can be found in Aho arid Ullman [4]. We can see that there are two multiple entries in the table; on the rows of state 11 and 12 at the column of &amp;quot;&apos;prep&amp;quot;. As mentioned above, once a parsing table has multiple entries, deterministic parsing is no longer possible; some kind of nondeterminism is necessary. We shall see that our dynamic programming approach, which is described below, is much more efficient than conventional breath-first or depth-first search, and makes MLR parsing feasible. 4 An Example In this section, we demonstrate, step by step, how our MLR parser processes the sentence: I SAW A MAN WITH A TELESCOPE using the g</context>
</contexts>
<marker>[4]</marker>
<rawString>Aho, A. V. and Ullman, J. D. Principles of Compiler Design. Addison Wesley, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Deremer</author>
</authors>
<title>L Practical Translators for LR(k) Languages.</title>
<date>1969</date>
<journal>[6) DeRemer, F. L Simple LR(k) grammars. Comm. ACM</journal>
<tech>PhD thesis, MIT,</tech>
<pages>14--7</pages>
<contexts>
<context position="1532" citStr="[5, 6]" startWordPosition="228" endWordPosition="229">rt parsing. Our method also provides an elegant solution to the problem of multi-part-of -speech words such as &amp;quot;that&amp;quot;. The mul parser and its parsing table generator have been implemented at Carnegie-Mellon University. 1 Introduction LR parsers [1, 2] have been developed originally for programming language of compilers. An LII parser is a shift. reduce parser which is deterministically guided by a parsing table indicating what action should be taken next. The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer [5, 6]. We do not describe the algorithm here, reffering the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers have seldom been used for Natural Language Processing probably because: 1. It has been thought that natural languages are not context-free, whereas LR parsers can cleat only with context-free languages. 2. Natural languages are ambiguous, while standard LR parsers can not handle ambiguous languages. The recent literature [8] shows that the belief &amp;quot;natural languages are not context-free&amp;quot; is not necessarily true, and there is no reason for us to give up the context-freedom of natural </context>
</contexts>
<marker>[5]</marker>
<rawString>Deremer, F. L Practical Translators for LR(k) Languages. PhD thesis, MIT, 1969. [6) DeRemer, F. L Simple LR(k) grammars. Comm. ACM 14:7:453-460, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reidel</author>
</authors>
<date>1982</date>
<pages>131--186</pages>
<marker>[7]</marker>
<rawString>Gazdar, G. Phrase Structure Grammar. D. Reidel, 1982, pages 131-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Phrase Structure Grammars and Natural Language.</title>
<date>1983</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence v.1,</booktitle>
<contexts>
<context position="1971" citStr="[8]" startWordPosition="298" endWordPosition="298">ld be taken next. The parsing table can be obtained automatically from a context-free phrase structure grammar, using an algorithm first developed by DeRemer [5, 6]. We do not describe the algorithm here, reffering the reader to Chapter 6 in Aho and Ullman [4]. The LR parsers have seldom been used for Natural Language Processing probably because: 1. It has been thought that natural languages are not context-free, whereas LR parsers can cleat only with context-free languages. 2. Natural languages are ambiguous, while standard LR parsers can not handle ambiguous languages. The recent literature [8] shows that the belief &amp;quot;natural languages are not context-free&amp;quot; is not necessarily true, and there is no reason for us to give up the context-freedom of natural languages. We do not discuss on this matter further, considering the fact that even if natural languages are not context-free, a fairly comprehensive grammar for a subset of natural language sufficient for practical systems can be written in context-free phrase structure. Thus, our main concern is how to cope with the ambiguity of natural languages, and this concern is addressed in the following section. 2 LR parsers and Ambiguous Gram</context>
</contexts>
<marker>[8]</marker>
<rawString>Gazdar, G. Phrase Structure Grammars and Natural Language. Proceedings of the Eighth International Joint Conference on Artificial Intelligence v.1, August, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Inoue</author>
<author>F Fujiwara</author>
</authors>
<title>On LLC(k) Parsing Method of LR(k) Grammars.</title>
<date>1983</date>
<journal>Journal of Information Processing</journal>
<pages>6--4</pages>
<marker>[9]</marker>
<rawString>Inoue, K. and Fujiwara, F. On LLC(k) Parsing Method of LR(k) Grammars. Journal of Information Processing vol.6(no.4):pp.206-217, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
</authors>
<title>A general syntactic processor.</title>
<date>1973</date>
<pages>193--241</pages>
<publisher>Algorithmics Press,</publisher>
<location>New York,</location>
<contexts>
<context position="4599" citStr="[10, 11]" startWordPosition="732" endWordPosition="733">d hy the Air Force Avionics Laboratory Under Contract 1,339Ib 81 K.1539.. 1110 views and conclusions contained in this document at those of the authors and should not be interpreted as representing the nflicial policies, either expressod or implied, of the Defense Advanced Research Projects Agency or the US Government. 2A grammar is ambiguous, if some input sentence can be parsed in more than one way. By statically&apos; , we mean the selection is done at parsing table construction time. I&amp;quot; have the telescope, or &amp;quot;the man&amp;quot; has the telescope. 354 of different parses have in the chart parsing method [10, 11]. The idea should be made clear by the following example. 3 MLR Parsers An example grammar and its MLR parsing table produced by the construction algorithm are shown in fig. 1 and 2, respectively. The MLR parsing table construction algorithm is exactly the same as the algorithm for LR parsers. Only the difference is that an MLR parsing table may have multiple entries. Grammar symbols starting with &amp;quot;*&amp;quot; represent pre-terminals. &amp;quot;sh n&amp;quot; in the action table (the left part of the table) indicates the action &amp;quot;shift one word from input buffer onto the stack, and go to state n&amp;quot;. &amp;quot;re n&amp;quot; indicates the ac</context>
</contexts>
<marker>[10]</marker>
<rawString>Kaplan, R. M. A general syntactic processor. Algorithmics Press, New York, 1973, pages 193-241. [11) Kay, M. The MIND system. Algorithmics Press, New York, 1973, pages 155-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Sentence Disambiguation by a Shift-Reduce Parsing Technique.</title>
<date>1983</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence v.2,</booktitle>
<marker>[12]</marker>
<rawString>Shieber, S. M. Sentence Disambiguation by a Shift-Reduce Parsing Technique. Proceedings of the Eighth International Joint Conference on Artificial Intelligence v.2, August, 1983.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>