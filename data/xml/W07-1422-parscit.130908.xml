<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000390">
<title confidence="0.95758">
Semantic Inference at the Lexical-Syntactic Level for Textual Entailment
Recognition
</title>
<author confidence="0.752672">
Roy Bar-Haim†,Ido Dagan†, Iddo Greental‡, Idan Szpektor† and Moshe Friedman††Computer Science Department, Bar-Ilan University, Ramat-Gan 52900, Israel
‡Linguistics Department, Tel Aviv University, Ramat Aviv 69978, Israel
</author>
<email confidence="0.970914">
{barhair,dagan}@cs.biu.ac.il,greenta@post.tau.ac.il,
{szpekti,friedmm}@cs.biu.ac.il
</email>
<sectionHeader confidence="0.995451" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965214285714">
We present a new framework for textual en-
tailment, which provides a modular integra-
tion between knowledge-based exact infer-
ence and cost-based approximate matching.
Diverse types of knowledge are uniformly
represented as entailment rules, which were
acquired both manually and automatically.
Our proof system operates directly on parse
trees, and infers new trees by applying en-
tailment rules, aiming to strictly generate the
target hypothesis from the source text. In or-
der to cope with inevitable knowledge gaps,
a cost function is used to measure the re-
maining “distance” from the hypothesis.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999912081081081">
According to the traditional formal semantics ap-
proach, inference is conducted at the logical level.
However, practical text understanding systems usu-
ally employ shallower lexical and lexical-syntactic
representations, augmented with partial semantic
annotations. Such practices are typically partial and
quite ad-hoc, and lack a clear formalism that speci-
fies how inference knowledge should be represented
and applied. The current paper proposes a step to-
wards filling this gap, by defining a principled se-
mantic inference mechanism over parse-based rep-
resentations.
Within the textual entailment setting a system is
required to recognize whether a hypothesized state-
ment h can be inferred from an asserted text t.
Some inferences can be based on available knowl-
edge, such as information about synonyms and para-
phrases. However, some gaps usually arise and it
is often not possible to derive a complete “proof”
based on available inference knowledge. Such sit-
uations are typically handled through approximate
matching methods.
This paper focuses on knowledge-based infer-
ence, while employing rather basic methods for ap-
proximate matching. We define a proof system
that operates over syntactic parse trees. New trees
are derived using entailment rules, which provide a
principled and uniform mechanism for incorporat-
ing a wide variety of manually and automatically-
acquired inference knowledge. Interpretation into
stipulated semantic representations, which is often
difficult to obtain, is circumvented altogether. Our
research goal is to explore how far we can get with
such an inference approach, and identify the scope
in which semantic interpretation may not be needed.
For a detailed discussion of our approach and related
work, see (Bar-Haim et al., 2007).
</bodyText>
<sectionHeader confidence="0.99916" genericHeader="introduction">
2 Inference Framework
</sectionHeader>
<bodyText confidence="0.998087636363637">
The main contribution of the current work is a prin-
cipled semantic inference mechanism, that aims to
generate a target text from a source text using en-
tailment rules, analogously to logic-based proof sys-
tems. Given two parsed text fragments, termed
text (t) and hypothesis (h), the inference system (or
prover) determines whether t entails h. The prover
applies entailment rules that aim to transform t into
h through a sequence of intermediate parse trees.
For each generated tree p, a heuristic cost function is
employed to measure the likelihood of p entailing h.
</bodyText>
<page confidence="0.976841">
131
</page>
<bodyText confidence="0.6451115">
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 131–136,
Prague, June 2007. c�2007 Association for Computational Linguistics
</bodyText>
<equation confidence="0.93868">
ROOT
i 1
expletive VERB wha
itOTHER when PREP
i (
see VERB
obj mod
be N y
ROOT
i 1
r������������ ������������,wha
rainVERB
expletive
it OTHER when PREP
i (
r������������ � obj ������������,subj see VERB
mod
Mary NOUN be VERB by PREP yesterday NOUN John NOUN Mary NOUN yesterday NOUN
</equation>
<figure confidence="0.937600642857143">
mod ( N pcomp−n mod (
beautifulADJ John NOUN beautifulADJ
Source: it rained when beautiful Mary was seen by John yester- Derived: it rained when John saw beautiful Mary yesterday
day
sformation
subj V VERB obj �����������+
L R
NOUN be VERB by PREP N2 NOUN N1 NOUN
N1
pcomp−n1
N2
(b) Passive to active transformation (substitution rule). The dotted arc represents ali
NOUN
gnment.
</figure>
<bodyText confidence="0.940931545454545">
d relation labels are based on Minipar (Lin, 1998b)
If a complete proof is found (h was generated), the 3.2 Infere
prover concludes that entailment holds. Otherwise, nce Rules
entailment is determined by comparing the minimal
cost found during the proof search to some threshold
B.
om previously established ones.
an
d additional features that may be added during the
proof process. Edges are annotated with dependency
relations.
</bodyText>
<figure confidence="0.975706666666667">
(a) Application of passive to active tran
obj V VERB by
e 1�
</figure>
<figureCaption confidence="0.999974">
Figure 1: Application of inference rules. POS an
</figureCaption>
<sectionHeader confidence="0.938863" genericHeader="method">
3 Proof System
</sectionHeader>
<bodyText confidence="0.994731">
Like logic-based systems, our proof system consists
of propositions (t, h, and intermediate premises),
and inference (entailment) rules, which derive new
propositions fr
</bodyText>
<subsectionHeader confidence="0.99774">
3.1 Propositions
</subsectionHeader>
<bodyText confidence="0.985016">
Propositions are represented as dependency trees,
where nodes represent words, and hold a set of fea-
tures and their values. In our representation these
features include the word lemma and part-of-speech,
At each step of the proof an inference rule gener-
ates aderived tree d from a source tree s. A rule
is primarily composed of two templates, termed left-
hand-side (L), and right-hand-side (R). Templates
are dependency subtrees which may contain vari-
ables. Figure 1(b) shows an inference rule, where
V , N1 and N2 are common variables. L specifies
the subtree of s to be modified, and R specifies the
new generated subtree. Rule application consists of
the following steps:
L matching The prover first tries to match L in s.
L is matched in s if there exists aone-to-one node
mapping function f from L to s, such that: (i) For
each node u,
has the same features and feature
values as u. Variables match any lemma value in
(ii) For each edge u —* v in L, there is an
edge
—*
in s, with the same dependency
relation. If matching fails, the rule is not appli
f(u)
f(u).
</bodyText>
<equation confidence="0.763503416666667">
f(u)
f(v)
cable
to s. Otherwise, successful matching induces vari-
132
ROOT ROOT
i ( i (
V1 VERB V2 VERB
L wha ( R
when ADJ
i (
V2 VERB
</equation>
<figureCaption confidence="0.962477">
Figure 2: Temporal clausal modifier extraction (in-
troduction rule)
</figureCaption>
<bodyText confidence="0.999784488888889">
able binding b(X), for each variable X in L, defined
as the full subtree rooted in f(X) if X is a leaf, or
f(X) alone otherwise. We denote by l the subtree
in s to which L was mapped (as illustrated in bold
in Figure 1(a), left tree).
R instantiation An instantiation of R, which we
denote r, is generated in two steps: (i) creating a
copy of R; (ii) replacing each variable X with a
copy of its binding b(X) (as set during L matching).
In our example this results in the subtree John saw
beautiful Mary.
Alignment copying the alignment relation be-
tween pairs of nodes in L and R specifies which
modifiers in l that are not part of the rule structure
need to be copied to the generated tree r. Formally,
for any two nodes u in l and v in r whose matching
nodes in L and R are aligned, we copy the daugh-
ter subtrees of u in s, which are not already part of
l, to become daughter subtrees of v in r. The bold
nodes in the right part of Figure 1(b) correspond to
r after alignment. yesterday was copied to r due to
the alignment of its parent verb node.
Derived tree generation by rule type Our for-
malism has two methods for generating the derived
tree: substitution and introduction, as specified by
the rule type. With substitution rules, the derived
tree d is obtained by making a local modification to
the source tree s. Except for this modification s and
d are identical (a typical example is a lexical rule,
such as buy —* purchase). For this type, d is formed
by copying s while replacing l (and the descendants
of l’s nodes) with r. This is the case for the passive
rule. The right part of Figure 1(a) shows the derived
tree for the passive rule application. By contrast, in-
troduction rules are used to make inferences from a
subtree of s, while the other parts of s are ignored
and do not affect d. A typical example is inference
of a proposition embedded as a relative clause in s.
In this case the derived tree d is simply taken to be
r. Figure 2 presents such a rule that derives propo-
sitions embedded within temporal modifiers. Note
that the derived tree does not depend on the main
clause. Applying this rule to the right part of Figure
1(b) yields the proposition John saw beautiful Mary
yesterday.
</bodyText>
<subsectionHeader confidence="0.999393">
3.3 Annotation Rules
</subsectionHeader>
<bodyText confidence="0.9999339">
Annotation rules add features to parse tree nodes,
and are used in our system to annotate negation and
modality. Annotation rules do not have an R. In-
stead, nodes of L may contain annotation features.
If L is matched in a tree then the annotations are
copied to the matched nodes. Annotation rules are
applied to t and to each inferred premise prior to
any entailment rule application and these features
may block inappropriate subsequent rule applica-
tions, such as for negated predicates.
</bodyText>
<sectionHeader confidence="0.997967" genericHeader="method">
4 Rules for Generic Linguistic Structures
</sectionHeader>
<bodyText confidence="0.9997935">
Based on the above framework we have manually
created a rule base for generic linguistic phenomena.
</bodyText>
<subsectionHeader confidence="0.956579">
4.1 Syntactic-Based Rules
</subsectionHeader>
<bodyText confidence="0.999954571428571">
These rules capture entailment inferences associ-
ated with common syntactic structures. They have
three major functions: (i) simplification and canon-
ization of the source tree (categories 6 and 7 in Ta-
ble 1); (ii) extracting embedded propositions (cate-
gories 1, 2, 3); (iii) inferring propositions from non-
propositional subtrees (category 4).
</bodyText>
<subsectionHeader confidence="0.949233">
4.2 Polarity-Based Rules
</subsectionHeader>
<bodyText confidence="0.9995495">
Consider the following two examples:
John knows that Mary is here ==&gt;. Mary is here.
John believes that Mary is here 4�. Mary is here.
Valid inference of propositions embedded as verb
complements depends on the verb properties, and
the polarity of the context in which the verb appears
(positive, negative, or unknown) (Nairn et al., 2006).
We extracted from the polarity lexicon of Nairn et
al. a list of verbs for which inference is allowed in
positive polarity context, and generated entailment
</bodyText>
<page confidence="0.990316">
133
</page>
<table confidence="0.999447764705882">
# Category Example: source Example: derived
1 Conjunctions Helena’s very experienced and has played a long ⇒ Helena has played a long time on the tour.
time on the tour.
2 Clausal modi- But celebrations were muted as many Iranians ob- ⇒ Many Iranians observed a Shi’ite mourning
fiers served a Shi’ite mourning month. month.
3 Relative The assailants fired six bullets at the car, which car- ⇒ The car carried Vladimir Skobtsov.
clauses ried Vladimir Skobtsov.
4 Appositives Frank Robinson, a one-time manager of the Indians, ⇒ Frank Robinson is a one-time manager of the
has the distinction for the NL. Indians.
5 Determiners The plaintiffs filed their lawsuit last year in U.S. ⇒ The plaintiffs filed a lawsuit last year in U.S.
District Court in Miami. District Court in Miami.
6 Passive We have been approached by the investment banker. ⇒ The investment banker approached us.
7 Genitive Malaysia’s crude palm oil output is estimated to ⇒ The crude palm oil output of Malasia is esti-
modifier have risen by up to six percent. mated to have risen by up to six percent.
8 Polarity Yadav was forced to resign. ⇒ Yadav resigned.
9 Negation, What we’ve never seen is actual costs come What we’ve never seen is actual costs come down.
modality down. (* What we’ve seen is actual costs come down.)
</table>
<tableCaption confidence="0.999889">
Table 1: Summary of rule base for generic linguistic structures.
</tableCaption>
<bodyText confidence="0.99901825">
rules for these verbs (category 8). The list was com-
plemented with a few reporting verbs, such as say
and announce, assuming that in the news domain the
speaker is usually considered reliable.
</bodyText>
<subsectionHeader confidence="0.977861">
4.3 Negation and Modality Annotation Rules
</subsectionHeader>
<bodyText confidence="0.999972">
We use annotation rules to mark negation and
modality of predicates (mainly verbs), based on their
descendent modifiers. Category 9 in Table 1 illus-
trates a negation rule, annotating the verb seen for
negation due to the presence of never.
</bodyText>
<subsectionHeader confidence="0.980792">
4.4 Generic Default Rules
</subsectionHeader>
<bodyText confidence="0.9997185">
Generic default rules are used to define default be-
havior in situations where no case-by-case rules are
available. We used one default rule that allows re-
moval of any modifiers from nodes.
</bodyText>
<sectionHeader confidence="0.997575" genericHeader="method">
5 Lexical-based Rules
</sectionHeader>
<bodyText confidence="0.9999695">
These rules have open class lexical components, and
consequently are numerous compared to the generic
rules described in section 4. Such rules are acquired
either lexicographically or automatically.
The rules described in the section 4 are applied
whenever their L template is matched in the source
premise. For high fan-out rules such as lexical-based
rules (e.g. words with many possible synonyms),
this may drastically increase the size of the search
space. Therefore, the rules described below are ap-
plied only if L is matched in the source premise p
and R is matched in h.
</bodyText>
<subsectionHeader confidence="0.989242">
5.1 Lexical Rules
</subsectionHeader>
<bodyText confidence="0.999958875">
Lexical entailment rules, such as ‘steal —* take’ and
‘Britain —* UK’ were created based on WordNet
(Fellbaum, 1998). Given p and h, a lexical rule
lemma� —* lemmah may be applied if lemma�
and lemmah are lemmas of open-class words ap-
pearing in p and h respectively, and there is a path
from lemmah to lemma� in the WordNet ontology,
through synonym and hyponym relations.
</bodyText>
<subsectionHeader confidence="0.991509">
5.2 Lexical-Syntactic Rules
</subsectionHeader>
<bodyText confidence="0.999929111111111">
In order to find lexical-syntactic paraphrases and en-
tailment rules, such as ‘X strike Y —* X hit Y ’ and
‘X buy Y —* X own Y ’ that would bridge between p
and h, we applied the DIRT algorithm (Lin and Pan-
tel, 2001) to the first CD of the Reuters RCV1 cor-
pus1. DIRT does not identify the entailment direc-
tion, hence we assumed bi-directional entailment.
We calculate off-line only the feature vector of ev-
ery template found in the corpus, where each path
between head nouns is considered a template in-
stance. Then, given a premise p, we first mark all
lexical noun alignments between p and h. Next, for
every pair of alignments we extract the path between
the two nouns in p, labeled pathp„ and the corre-
sponding path between the aligned nouns in h, la-
beled pathh. We then on-the-fly test whether there
is a rule ‘path� —* pathh’ by extracting the stored
feature vectors of path� and pathh and measuring
</bodyText>
<footnote confidence="0.991823">
1http://about.reuters.com/researchandstandards/corpus/
</footnote>
<page confidence="0.997483">
134
</page>
<bodyText confidence="0.999940714285714">
their similarity. If the score exceeds a given thresh-
old2, we apply the rule to p.
Another enhancement that we added to DIRT is
template canonization. At learning time, we trans-
form every template identified in the corpus into
its canonized form3 using a set of morpho-syntactic
rules, similar to the ones described in Section 4. In
addition, we apply nominalization rules such as ‘ac-
quisition of Y by X → X acquire Y ’, which trans-
form a nominal template into its related verbal form.
We automatically generate these rules (Ron, 2006),
based on Nomlex (Macleod et al., 1998).
At inference time, before retrieving feature vec-
tors, we canonize pathp into pathcp and pathh into
pathch. We then assess the rule ‘pathcp → pathch’,
and if valid, we apply the rule ‘pathp → pathh’ to
p. In order to ensure the validity of the implicature
‘pathp → pathcp → pathch → pathh’, we canonize
pathp using the same rule set used at learning time,
but we apply only bi-directional rules to pathh (e.g.
conjunct heads are not removed from pathh).
</bodyText>
<sectionHeader confidence="0.968749" genericHeader="method">
6 Approximate Matching
</sectionHeader>
<bodyText confidence="0.9991612">
As mentioned in section 2, approximate matching
is incorporated into our system via a cost function,
which estimates the likelihood of h being entailed
from a given premise p. Our cost function C(p, h) is
a linear combination of two measures: lexical cost,
</bodyText>
<equation confidence="0.681993">
Clex(p, h)
C(p, h) = AClexSyn(p, h) + (1− A)Clex(p, h) (1)
</equation>
<bodyText confidence="0.999877166666667">
Let Th() be a (possibly partial) 1-1 mapping of the
nodes of h to the nodes of p, where each node
is mapped to a node with the same lemma, such
that the number of matched edges is maximized.
An edge u → v in h is matched in p if Th(u)
and Th(v) are both defined, and there is an edge
Th(u) → Th(v) in p, with the same dependency rela-
tion. ClexSyn(p, h) is then defined as the percentage
of unmatched edges in h.
Similarly, Clex(p, h) is the percentage of un-
matched lemmas in h, considering only open-class
words, defined as:
</bodyText>
<equation confidence="0.9744595">
− ElEh Score(l)
Clex(p, h) = 1 #OpenClassWords(h) (2)
</equation>
<footnote confidence="0.996513">
2We set the threshold to 0.01
3The active verbal form with direct modifiers
</footnote>
<bodyText confidence="0.99995">
where Score(l) is 1 if it appears in p, or if it is
a derivation of a word in p (according to Word-
Net). Otherwise, Score(l) is the maximal Lin
dependency-based similarity score between l and the
lemmas of p (Lin, 1998a) (synonyms and hyper-
nyms/hyponyms are handled by the lexical rules).
</bodyText>
<sectionHeader confidence="0.975631" genericHeader="method">
7 System Implementation
</sectionHeader>
<bodyText confidence="0.9999375">
Deriving the initial propositions t and h from the in-
put text fragments consists of the following steps:
(i) Anaphora resolution, using the MARS system
(Mitkov et al., 2002). Each anaphor was replaced by
its antecedent. (ii) Sentence splitting, using mxter-
minator (Reynar and Ratnaparkhi, 1997). (iii) De-
pendency parsing, using Minipar (Lin, 1998b).
The proof search is implemented as a depth-first
search, with maximal depth (i.e. proof length) of
4. If the text contains more than one sentence, the
prover aims to prove h from each of the parsed sen-
tences, and entailment is determined based on the
minimal cost. Thus, the only cross-sentence infor-
mation that is considered is via anaphora resolution.
</bodyText>
<sectionHeader confidence="0.991977" genericHeader="evaluation">
8 Evaluation
</sectionHeader>
<table confidence="0.9998555">
Dataset Task Full (run1) Avg.P Lexical (run2)
Acc. Acc. Avg.P
Test IE 0.4950 0.5021 0.5000 0.5379
Official IR 0.6600 0.6174 0.6450 0.6539
Results QA 0.7050 0.8085 0.6600 0.8075
SUM 0.5850 0.6200 0.5300 0.5927
All 0.6112 0.6118 0.5837 0.6093
Dev. All 0.6443 0.6699 0.6143 0.6559
</table>
<tableCaption confidence="0.996679">
Table 2: Empirical evaluation - results.
</tableCaption>
<bodyText confidence="0.994720214285714">
The results for our submitted runs are listed in Ta-
ble 2, including per-task scores. run1 is our full sys-
tem, denoted F. It was tuned on a random sample
of 100 sentences from the development set, result-
ing in A = 0.6 and 0 = 0.6242 (entailment thresh-
old). run2 is a lexical configuration, denoted L, in
which A = 0 (lexical cost only), 0 = 0.2375 and
the only inference rules used were WordNet Lexical
rules. We found that the higher accuracy achieved
by F as compared to L might have been merely due
to a lucky choice of threshold. Setting the threshold
to its optimal value with respect to the test set re-
sulted in an accuracy of 62.4% for F, and 62.9% for
and lexical-syntactic cost ClexSyn(p, h):
</bodyText>
<page confidence="0.973137">
135
</page>
<bodyText confidence="0.999962052631579">
L. This is also hinted by the very close average pre-
cision scores for both systems, which do not depend
on the threshold. The last row in the table shows
the results obtained for 7/8 of the development set
that was not used for tuning, denoted Dev, using the
same parameter settings. Again, F performs bet-
ter than L. F is still better when using an optimal
threshold (which increases accuracy up to 65.3% for
F and 63.9% for L. Overall, F does not show yet a
consistent significant improvement over L.
Initial analysis of the results (based on Dev) sug-
gests that the coverage of the current rules is still
rather low. Without approximate matching (h must
be fully proved using the entailment rules) the re-
call is only 4.3%, although the precision (92%) is
encouraging. Lexical-syntactic rules were applied
in about 3% of the attempted proofs, and in most
cases involved only morpho-syntactic canonization,
with no lexical variation. As a result, entailment was
determined mainly by the cost function. Entailment
rules managed to reduce the cost in about 30% of the
attempted proofs.
We have qualitatively analyzed a subset of false
negative cases, to determine whether failure to com-
plete the proof is due to deficient components of
the system or due to higher linguistic and knowl-
edge levels. For each pair, we assessed the reasoning
steps a successful derivation of h from t would take.
We classified each pair according to the most de-
manding type of reasoning step it would require. We
allowed rules that are presently unavailable in our
system, as long as they are similar in power to those
that are currently available. We found that while
the single dominant cause for proof failure is lack
of world knowledge, e.g. the king’s son is a mem-
ber of the royal family, the combination of miss-
ing lexical-syntactic rules and parser failures equally
contributed to proof failure.
</bodyText>
<sectionHeader confidence="0.998404" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999922285714286">
We defined a novel framework for semantic infer-
ence at the lexical-syntactic level, which allows a
unified representation of a wide variety of inference
knowledge. In order to reach reasonable recall on
RTE data, we found that we must scale our rule ac-
quisition, mainly by improving methods for auto-
matic rule learning.
</bodyText>
<sectionHeader confidence="0.996557" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999963454545454">
We are grateful to Cleo Condoravdi for making the
polarity lexicon developed at PARC available for
this research. We also wish to thank Ruslan Mitkov,
Richard Evans, and Viktor Pekar from University of
Wolverhampton for running the MARS system for
us. This work was partially supported by ISF grant
1095/05, the IST Programme of the European Com-
munity under the PASCAL Network of Excellence
IST-2002-506778, the Israel Internet Association
(ISOC-IL) grant 9022 and the ITC-irst/University of
Haifa collaboration.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999891806451613">
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In AAAI (to appear).
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. Language, Speech and Com-
munication. MIT Press.
Dekang Lin and Patrik Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 4(7):343–360.
Dekang Lin. 1998a. Automatic retrieval and clustering
of similar words. In Proceedings of COLING/ACL.
Dekang Lin. 1998b. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on Evalua-
tion of Parsing Systems at LREC.
C. Macleod, R. Grishman, A. Meyers, L. Barrett, and
R. Reeves. 1998. Nomlex: A lexicon of nominal-
izations. In EURALEX.
Ruslan Mitkov, Richard Evans, and Constantin Orasan.
2002. A new, fully automatic version of Mitkov’s
knowledge-poor pronoun resolution method. In Pro-
ceedings of CICLing.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. In Proceedings of ICoS-5.
Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A
maximum entropy approach to identifying sentence
boundaries. In Proceedings of ANLP.
Tal Ron. 2006. Generating entailment rules based on
online lexical resources. Master’s thesis, Computer
Science Department, Bar-Ilan University, Ramat-Gan,
Israel.
</reference>
<page confidence="0.998801">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.586791">
<title confidence="0.9978905">Semantic Inference at the Lexical-Syntactic Level for Textual Entailment Recognition</title>
<author confidence="0.909304">Iddo Idan Science Department</author>
<author confidence="0.909304">Bar-Ilan University</author>
<author confidence="0.909304">Ramat-Gan</author>
<address confidence="0.673093">Department, Tel Aviv University, Ramat Aviv 69978,</address>
<abstract confidence="0.998243666666667">We present a new framework for textual entailment, which provides a modular integration between knowledge-based exact inference and cost-based approximate matching. Diverse types of knowledge are uniformly represented as entailment rules, which were acquired both manually and automatically. Our proof system operates directly on parse trees, and infers new trees by applying enrules, aiming to strictly the source In order to cope with inevitable knowledge gaps, a cost function is used to measure the remaining “distance” from the hypothesis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Ido Dagan, Iddo Greental, and Eyal Shnarch.</title>
<date>2007</date>
<booktitle>In AAAI</booktitle>
<note>(to appear).</note>
<marker>Bar-Haim, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal Shnarch. 2007. Semantic inference at the lexicalsyntactic level. In AAAI (to appear).</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database. Language, Speech and Communication.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. Language, Speech and Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrik Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>4</volume>
<issue>7</issue>
<contexts>
<context position="13233" citStr="Lin and Pantel, 2001" startWordPosition="2209" endWordPosition="2213">ules Lexical entailment rules, such as ‘steal —* take’ and ‘Britain —* UK’ were created based on WordNet (Fellbaum, 1998). Given p and h, a lexical rule lemma� —* lemmah may be applied if lemma� and lemmah are lemmas of open-class words appearing in p and h respectively, and there is a path from lemmah to lemma� in the WordNet ontology, through synonym and hyponym relations. 5.2 Lexical-Syntactic Rules In order to find lexical-syntactic paraphrases and entailment rules, such as ‘X strike Y —* X hit Y ’ and ‘X buy Y —* X own Y ’ that would bridge between p and h, we applied the DIRT algorithm (Lin and Pantel, 2001) to the first CD of the Reuters RCV1 corpus1. DIRT does not identify the entailment direction, hence we assumed bi-directional entailment. We calculate off-line only the feature vector of every template found in the corpus, where each path between head nouns is considered a template instance. Then, given a premise p, we first mark all lexical noun alignments between p and h. Next, for every pair of alignments we extract the path between the two nouns in p, labeled pathp„ and the corresponding path between the aligned nouns in h, labeled pathh. We then on-the-fly test whether there is a rule ‘p</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrik Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 4(7):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<contexts>
<context position="4230" citStr="Lin, 1998" startWordPosition="638" endWordPosition="639">������,wha rainVERB expletive it OTHER when PREP i ( r������������ � obj ������������,subj see VERB mod Mary NOUN be VERB by PREP yesterday NOUN John NOUN Mary NOUN yesterday NOUN mod ( N pcomp−n mod ( beautifulADJ John NOUN beautifulADJ Source: it rained when beautiful Mary was seen by John yester- Derived: it rained when John saw beautiful Mary yesterday day sformation subj V VERB obj �����������+ L R NOUN be VERB by PREP N2 NOUN N1 NOUN N1 pcomp−n1 N2 (b) Passive to active transformation (substitution rule). The dotted arc represents ali NOUN gnment. d relation labels are based on Minipar (Lin, 1998b) If a complete proof is found (h was generated), the 3.2 Infere prover concludes that entailment holds. Otherwise, nce Rules entailment is determined by comparing the minimal cost found during the proof search to some threshold B. om previously established ones. an d additional features that may be added during the proof process. Edges are annotated with dependency relations. (a) Application of passive to active tran obj V VERB by e 1� Figure 1: Application of inference rules. POS an 3 Proof System Like logic-based systems, our proof system consists of propositions (t, h, and intermediate pr</context>
<context position="16222" citStr="Lin, 1998" startWordPosition="2743" endWordPosition="2744">and there is an edge Th(u) → Th(v) in p, with the same dependency relation. ClexSyn(p, h) is then defined as the percentage of unmatched edges in h. Similarly, Clex(p, h) is the percentage of unmatched lemmas in h, considering only open-class words, defined as: − ElEh Score(l) Clex(p, h) = 1 #OpenClassWords(h) (2) 2We set the threshold to 0.01 3The active verbal form with direct modifiers where Score(l) is 1 if it appears in p, or if it is a derivation of a word in p (according to WordNet). Otherwise, Score(l) is the maximal Lin dependency-based similarity score between l and the lemmas of p (Lin, 1998a) (synonyms and hypernyms/hyponyms are handled by the lexical rules). 7 System Implementation Deriving the initial propositions t and h from the input text fragments consists of the following steps: (i) Anaphora resolution, using the MARS system (Mitkov et al., 2002). Each anaphor was replaced by its antecedent. (ii) Sentence splitting, using mxterminator (Reynar and Ratnaparkhi, 1997). (iii) Dependency parsing, using Minipar (Lin, 1998b). The proof search is implemented as a depth-first search, with maximal depth (i.e. proof length) of 4. If the text contains more than one sentence, the prov</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998a. Automatic retrieval and clustering of similar words. In Proceedings of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of minipar.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on Evaluation of Parsing Systems at LREC.</booktitle>
<contexts>
<context position="4230" citStr="Lin, 1998" startWordPosition="638" endWordPosition="639">������,wha rainVERB expletive it OTHER when PREP i ( r������������ � obj ������������,subj see VERB mod Mary NOUN be VERB by PREP yesterday NOUN John NOUN Mary NOUN yesterday NOUN mod ( N pcomp−n mod ( beautifulADJ John NOUN beautifulADJ Source: it rained when beautiful Mary was seen by John yester- Derived: it rained when John saw beautiful Mary yesterday day sformation subj V VERB obj �����������+ L R NOUN be VERB by PREP N2 NOUN N1 NOUN N1 pcomp−n1 N2 (b) Passive to active transformation (substitution rule). The dotted arc represents ali NOUN gnment. d relation labels are based on Minipar (Lin, 1998b) If a complete proof is found (h was generated), the 3.2 Infere prover concludes that entailment holds. Otherwise, nce Rules entailment is determined by comparing the minimal cost found during the proof search to some threshold B. om previously established ones. an d additional features that may be added during the proof process. Edges are annotated with dependency relations. (a) Application of passive to active tran obj V VERB by e 1� Figure 1: Application of inference rules. POS an 3 Proof System Like logic-based systems, our proof system consists of propositions (t, h, and intermediate pr</context>
<context position="16222" citStr="Lin, 1998" startWordPosition="2743" endWordPosition="2744">and there is an edge Th(u) → Th(v) in p, with the same dependency relation. ClexSyn(p, h) is then defined as the percentage of unmatched edges in h. Similarly, Clex(p, h) is the percentage of unmatched lemmas in h, considering only open-class words, defined as: − ElEh Score(l) Clex(p, h) = 1 #OpenClassWords(h) (2) 2We set the threshold to 0.01 3The active verbal form with direct modifiers where Score(l) is 1 if it appears in p, or if it is a derivation of a word in p (according to WordNet). Otherwise, Score(l) is the maximal Lin dependency-based similarity score between l and the lemmas of p (Lin, 1998a) (synonyms and hypernyms/hyponyms are handled by the lexical rules). 7 System Implementation Deriving the initial propositions t and h from the input text fragments consists of the following steps: (i) Anaphora resolution, using the MARS system (Mitkov et al., 2002). Each anaphor was replaced by its antecedent. (ii) Sentence splitting, using mxterminator (Reynar and Ratnaparkhi, 1997). (iii) Dependency parsing, using Minipar (Lin, 1998b). The proof search is implemented as a depth-first search, with maximal depth (i.e. proof length) of 4. If the text contains more than one sentence, the prov</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998b. Dependency-based evaluation of minipar. In Proceedings of the Workshop on Evaluation of Parsing Systems at LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Macleod</author>
<author>R Grishman</author>
<author>A Meyers</author>
<author>L Barrett</author>
<author>R Reeves</author>
</authors>
<title>Nomlex: A lexicon of nominalizations.</title>
<date>1998</date>
<booktitle>In EURALEX.</booktitle>
<contexts>
<context position="14556" citStr="Macleod et al., 1998" startWordPosition="2434" endWordPosition="2437">.reuters.com/researchandstandards/corpus/ 134 their similarity. If the score exceeds a given threshold2, we apply the rule to p. Another enhancement that we added to DIRT is template canonization. At learning time, we transform every template identified in the corpus into its canonized form3 using a set of morpho-syntactic rules, similar to the ones described in Section 4. In addition, we apply nominalization rules such as ‘acquisition of Y by X → X acquire Y ’, which transform a nominal template into its related verbal form. We automatically generate these rules (Ron, 2006), based on Nomlex (Macleod et al., 1998). At inference time, before retrieving feature vectors, we canonize pathp into pathcp and pathh into pathch. We then assess the rule ‘pathcp → pathch’, and if valid, we apply the rule ‘pathp → pathh’ to p. In order to ensure the validity of the implicature ‘pathp → pathcp → pathch → pathh’, we canonize pathp using the same rule set used at learning time, but we apply only bi-directional rules to pathh (e.g. conjunct heads are not removed from pathh). 6 Approximate Matching As mentioned in section 2, approximate matching is incorporated into our system via a cost function, which estimates the l</context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>C. Macleod, R. Grishman, A. Meyers, L. Barrett, and R. Reeves. 1998. Nomlex: A lexicon of nominalizations. In EURALEX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
<author>Richard Evans</author>
<author>Constantin Orasan</author>
</authors>
<title>A new, fully automatic version of Mitkov’s knowledge-poor pronoun resolution method.</title>
<date>2002</date>
<booktitle>In Proceedings of CICLing.</booktitle>
<contexts>
<context position="16490" citStr="Mitkov et al., 2002" startWordPosition="2783" endWordPosition="2786"> as: − ElEh Score(l) Clex(p, h) = 1 #OpenClassWords(h) (2) 2We set the threshold to 0.01 3The active verbal form with direct modifiers where Score(l) is 1 if it appears in p, or if it is a derivation of a word in p (according to WordNet). Otherwise, Score(l) is the maximal Lin dependency-based similarity score between l and the lemmas of p (Lin, 1998a) (synonyms and hypernyms/hyponyms are handled by the lexical rules). 7 System Implementation Deriving the initial propositions t and h from the input text fragments consists of the following steps: (i) Anaphora resolution, using the MARS system (Mitkov et al., 2002). Each anaphor was replaced by its antecedent. (ii) Sentence splitting, using mxterminator (Reynar and Ratnaparkhi, 1997). (iii) Dependency parsing, using Minipar (Lin, 1998b). The proof search is implemented as a depth-first search, with maximal depth (i.e. proof length) of 4. If the text contains more than one sentence, the prover aims to prove h from each of the parsed sentences, and entailment is determined based on the minimal cost. Thus, the only cross-sentence information that is considered is via anaphora resolution. 8 Evaluation Dataset Task Full (run1) Avg.P Lexical (run2) Acc. Acc. </context>
</contexts>
<marker>Mitkov, Evans, Orasan, 2002</marker>
<rawString>Ruslan Mitkov, Richard Evans, and Constantin Orasan. 2002. A new, fully automatic version of Mitkov’s knowledge-poor pronoun resolution method. In Proceedings of CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rowan Nairn</author>
<author>Cleo Condoravdi</author>
<author>Lauri Karttunen</author>
</authors>
<title>Computing relative polarity for textual inference.</title>
<date>2006</date>
<booktitle>In Proceedings of ICoS-5.</booktitle>
<contexts>
<context position="9787" citStr="Nairn et al., 2006" startWordPosition="1617" endWordPosition="1620">They have three major functions: (i) simplification and canonization of the source tree (categories 6 and 7 in Table 1); (ii) extracting embedded propositions (categories 1, 2, 3); (iii) inferring propositions from nonpropositional subtrees (category 4). 4.2 Polarity-Based Rules Consider the following two examples: John knows that Mary is here ==&gt;. Mary is here. John believes that Mary is here 4�. Mary is here. Valid inference of propositions embedded as verb complements depends on the verb properties, and the polarity of the context in which the verb appears (positive, negative, or unknown) (Nairn et al., 2006). We extracted from the polarity lexicon of Nairn et al. a list of verbs for which inference is allowed in positive polarity context, and generated entailment 133 # Category Example: source Example: derived 1 Conjunctions Helena’s very experienced and has played a long ⇒ Helena has played a long time on the tour. time on the tour. 2 Clausal modi- But celebrations were muted as many Iranians ob- ⇒ Many Iranians observed a Shi’ite mourning fiers served a Shi’ite mourning month. month. 3 Relative The assailants fired six bullets at the car, which car- ⇒ The car carried Vladimir Skobtsov. clauses </context>
</contexts>
<marker>Nairn, Condoravdi, Karttunen, 2006</marker>
<rawString>Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen. 2006. Computing relative polarity for textual inference. In Proceedings of ICoS-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy approach to identifying sentence boundaries.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP.</booktitle>
<contexts>
<context position="16611" citStr="Reynar and Ratnaparkhi, 1997" startWordPosition="2800" endWordPosition="2803"> with direct modifiers where Score(l) is 1 if it appears in p, or if it is a derivation of a word in p (according to WordNet). Otherwise, Score(l) is the maximal Lin dependency-based similarity score between l and the lemmas of p (Lin, 1998a) (synonyms and hypernyms/hyponyms are handled by the lexical rules). 7 System Implementation Deriving the initial propositions t and h from the input text fragments consists of the following steps: (i) Anaphora resolution, using the MARS system (Mitkov et al., 2002). Each anaphor was replaced by its antecedent. (ii) Sentence splitting, using mxterminator (Reynar and Ratnaparkhi, 1997). (iii) Dependency parsing, using Minipar (Lin, 1998b). The proof search is implemented as a depth-first search, with maximal depth (i.e. proof length) of 4. If the text contains more than one sentence, the prover aims to prove h from each of the parsed sentences, and entailment is determined based on the minimal cost. Thus, the only cross-sentence information that is considered is via anaphora resolution. 8 Evaluation Dataset Task Full (run1) Avg.P Lexical (run2) Acc. Acc. Avg.P Test IE 0.4950 0.5021 0.5000 0.5379 Official IR 0.6600 0.6174 0.6450 0.6539 Results QA 0.7050 0.8085 0.6600 0.8075 </context>
</contexts>
<marker>Reynar, Ratnaparkhi, 1997</marker>
<rawString>Jeffrey C. Reynar and Adwait Ratnaparkhi. 1997. A maximum entropy approach to identifying sentence boundaries. In Proceedings of ANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tal Ron</author>
</authors>
<title>Generating entailment rules based on online lexical resources.</title>
<date>2006</date>
<tech>Master’s thesis,</tech>
<institution>Computer Science Department, Bar-Ilan University,</institution>
<location>Ramat-Gan,</location>
<contexts>
<context position="14516" citStr="Ron, 2006" startWordPosition="2429" endWordPosition="2430">h and measuring 1http://about.reuters.com/researchandstandards/corpus/ 134 their similarity. If the score exceeds a given threshold2, we apply the rule to p. Another enhancement that we added to DIRT is template canonization. At learning time, we transform every template identified in the corpus into its canonized form3 using a set of morpho-syntactic rules, similar to the ones described in Section 4. In addition, we apply nominalization rules such as ‘acquisition of Y by X → X acquire Y ’, which transform a nominal template into its related verbal form. We automatically generate these rules (Ron, 2006), based on Nomlex (Macleod et al., 1998). At inference time, before retrieving feature vectors, we canonize pathp into pathcp and pathh into pathch. We then assess the rule ‘pathcp → pathch’, and if valid, we apply the rule ‘pathp → pathh’ to p. In order to ensure the validity of the implicature ‘pathp → pathcp → pathch → pathh’, we canonize pathp using the same rule set used at learning time, but we apply only bi-directional rules to pathh (e.g. conjunct heads are not removed from pathh). 6 Approximate Matching As mentioned in section 2, approximate matching is incorporated into our system vi</context>
</contexts>
<marker>Ron, 2006</marker>
<rawString>Tal Ron. 2006. Generating entailment rules based on online lexical resources. Master’s thesis, Computer Science Department, Bar-Ilan University, Ramat-Gan, Israel.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>