<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998702333333333">
Development of the Concept Dictionary
- Implementation
of Lexical Knowledge
</title>
<author confidence="0.918138">
Tomoyoshi MATSUKA WA, Eiji YOKOTA
</author>
<affiliation confidence="0.868993">
Japan Electronic Dictionary Research Institute, Ltd. (EAR)
</affiliation>
<address confidence="0.736492">
Mita-Kokusai-Bldg. 4-28, Mita 1-chome,Minato-ku. Tokyo. 108. JAPAN
</address>
<email confidence="0.936754">
e-mail : matsu@edr5r.edr.co.jp
yoko@edr7r.edr.co.jp
</email>
<note confidence="0.6087455">
tel: 81-3-3798-5521,
fax: 81-3-3798-5335
</note>
<sectionHeader confidence="0.808208" genericHeader="abstract">
Summary
</sectionHeader>
<bodyText confidence="0.983171">
The methodology of development of the Concept Dictionary being compiled by EDR. which is to be a neutral dictionary
for semantic processing of natural languages available for various application systems, is described. The Concept Dictionary is
based on several linguistic semantic representation theories and consists of: a) concept descriptions, and b) the concept taxonomy.
Moreover, preference knowledge is being collected from output data of various testing systems.
</bodyText>
<sectionHeader confidence="0.997779" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.996137473684211">
A dictionary in which dependencies among 400,000 word senses of the English and Japanese languages are
described in detail (Concept Dictionary) is being developed by EDR. The goal of the development is to build a
neutral dictionary for natural language semantic processing that is available for various application systems.
The implementation of the dictionary is based on several linguistic semantic representation theories.
For a long time, a series of trials for describing dependencies among words or word senses by bundling
verbs, adjectives, etc., has been conducted. Establishing a deep case level and using a formalism independent
of each language, Fillmore developed a theory of representation of dependency among words (Fillmore 1968).
On the other hand, Fodor and Katz explained a mechanism of selecting interpretations of constituents in a
sentence by using a formalism composed of a semantic marker, distinguisher and selection restriction (Katz
and Fodor 1963). In contrast to these theories, Wilks proposed a point of view to consider word dependency
not as a constraint but as a preference (Wilks 1975). In addition, Schank proposed to abstract connotations
not only from senses of nouns but also those of verbs, and he named them &amp;quot;primitive actions&amp;quot; (Schank 1975).
These semantic representation theories have been reviewed and used in developing practical natural language
processing systems (Nagao 1985, etc.).
As such development of practical natural language processing systems progressed, the importance of
accumulating lexical descriptions became recognized by developers of such systems. That is, a dictionary large
enough in terms of both the granularity of semantic markers and the number of words or word senses became
necessary to build. Against the background of the situation, the development of the Concept Dictionary began
(Kakizaki 1987, Yokoi et. al. 1989, Uchida, 1990, Miike et. al. 1990a). The methodology of development of
</bodyText>
<page confidence="0.996032">
206
</page>
<bodyText confidence="0.3457652">
the Concept Dictionary, which consists of a) concept descriptions, which represent dependencies among
concepts and categories, and b) the concept taxonomy, which represent super-sub relations among concepts,
is described in sections 2 and 3. Preference knowledge, which represents preference order of concept
descriptions, is explained in section 4. In section 5, spheres of applications and limitations of the dictionary
are discussed.
</bodyText>
<sectionHeader confidence="0.476614" genericHeader="method">
2. Development of Concept Descriptions
</sectionHeader>
<tableCaption confidence="0.81322125">
Concept relations are described at the following three levels:
a) concept-concept relation descriptions
b) concept-category relation descriptions
c) category-category relation descriptions
</tableCaption>
<subsectionHeader confidence="0.916552">
2.1 Concept-concept Relation Descriptions
</subsectionHeader>
<bodyText confidence="0.9974385">
We are building an on-line corpus which includes 1,000,000 practical example sentences that are analyzed
lexically, syntactically and semantically for the most part manually (EDR corpus). Figure 1 is an example of
an entry of the corpus.
Firstly, (a) is the word sense selection (lexical analysis) section, where a word sense (concept) has been
selected for each word in the sentence. Secondly, (b) is the syntactic analysis section, where all binding
relations among words has been analyzed. Finally, (c) is the semantic analysis section, where the semantic
network representing the meaning of the sentence is decomposed into a set of triplets. These triplets
correspond to the following concept-concept relation descriptions:
</bodyText>
<tableCaption confidence="0.7833919375">
(1) cffenlarge —&lt;and&gt;–• Onew
cihrembership —&lt;object&gt;— c#new
cflbear —&lt;location&gt;–• c#it
c#bring —&lt;cause&gt;-* ctimembership
c#vulnerable —&lt;goal&gt;–• ctOpressure
c#fluid —&lt;modify&gt;–• c#still
c#fluid —&lt;object&gt;–• Othe_UN
c#fluid —&lt;modify&gt;–* c#structurally
cttmembership —&lt;object&gt;— dtenlarge
cftmembership —&lt;modify&gt;–• c#its
c#bring —&lt;goal&gt;--• c#bear
c#pressure —&lt;object&gt;— c#bring
c#vulnerable —&lt;and&gt;— ctftluid
c#vulnerable —&lt;modify&gt;— c#still
c#vulnerable —&lt;object&gt;— ctithe_U.N
c#vulnerable —&lt;modify&gt;— c#structurally
</tableCaption>
<bodyText confidence="0.967281">
As shown above, concept-concept relation descriptions are extracted directly from the semantic analysis
section (and word sense selection section) in the EDR Corpus. A method of collecting and selecting source
sentences for the EDR corpus is described in (Nakao 1990a) and a method of extracting concept descriptions
from the EDR corpus is explained in detail in (Nakao 1990b).
Source texts of the EDR corpus are selected so as to diversify as much as possible the concepts in them.
However, it is impossible to collect all concepts or concept relations from the corpus even if the amount of
texts is very large. To compensate for the shortage of examples, we also create example sentences and analyze
them lexically and semantically. Concept-concept relation descriptions are also extracted from the sentences.
</bodyText>
<page confidence="0.99084">
207
</page>
<note confidence="0.875563">
«Text No : 00040000187d : 6/13/90 from e0327003.ya I/4»
=» Structurally, the U.N. is still fluid artl vulnerable to the pressures that its new and enlarged memberships
are bringing to bear upon it.
</note>
<figure confidence="0.972533310344827">
STA LEX_Stan)SS (a) Wad Sense Selection Section
I structurally (structurally) &lt;ADV&gt;
ce(04.914)in_a_structurel_manner)
4.3 U.N. (U.N.) &lt;NOUN&gt;
cO(Z2ZZa)the_organization_named_UN•
still (still) &lt;ADV&gt;
crgOds013)even_up_to_now_or_then_and_at_this_or_that_mornent
10 fluid (fluid) &lt;AM&gt;
clt(Ob4848)unseuled;_not_fixed
13 vulnerable (vulnerable) &lt;ADS&gt;
c*(0,16e3Xo(_a_place_or_thing)weak:_not_well_proteand;_oesily_attacked
19 pressure (pressure) &lt;NOUN&gt;
c0(0d0545)trouble_that_causes_vutiety_and_dilTiculty
26 new (new) &lt;ADS&gt;
c11(0ea953)having_begun_or_been_made_only_a_shorvirne_ago_or_be(ore
30 °Mart (enlarge) &lt;VT&gt;
clt(Obad63)to_eause_to_grow_larger_or_wi4er
33 membership (membership) &lt;NOUN&gt;
c/(0c8477)the_state_of_being._or_status_as._a_member
37 bring (bring) &lt;VT&gt;
01(01,0168)to_cause_to_reach_a_certain_state
42 bear (bear) &lt;VI&gt;
ce(Oandf)to_ezert_pressure
SULEX_End)SS
U(SYN_Start)S5
I structurally
; 4 the_U.N.
:6. 13-3.5
: Basin ,13.2.M
</figure>
<construct confidence="0.432853083333333">
; 10 fluid ; 13.14
: 13 vulnerable fluid,_vulnanble --&gt;fluid,_vulnarable
: 15 ea . 19.3.S
: 17 the : 19-1.5 •
: 19 pressure pressure_s —&gt;the_pressure • &gt;the_preuure —&gt;to_the_pressure ;
22 that ; 37.5,5 :
: 24 its 33-2,1st
:26 new
; 28 and
; 30 enters enlarged —&gt;now.and_ailarged ; 33-1.M
; 33 membership &gt;membership —&gt;mernbership : 374.M
; 35 are
</construct>
<figure confidence="0.681271954545454">
bringing —&gt;are_bringing —&gt;tre_bringing —&gt;are_bringing ; 194.M
; 37 bring
:401* :42-1.5
:42 bear to_bear 37-3,14
: 44 upon :46-1.5
46 it upon_it 42-2.84
S2(SYN_End)S5
SS(SEM_Start)55
fb) Syntactic Analysis Seqiort
30 3 enlarged_ 26 new_ Sand &gt; •
33 2 membership.. 30 new_and_enlarged_ M object &lt;
33 3 membership_ 24 its M modify &gt;
42 2 bear_ 46 upon_it M location &gt;
37 4 are_bringing_ 42 to_bear_ M pal &gt;
37 5 are_bringing_ 33 membership_ M cause &gt;
19 4 the_pressuros_ 37 are_bringing_ M object &lt;
13 2 vulnerable_ 19 tu_tho_pressiires_ M goal &gt;
13 3 vulnerable_ 10 fluid Sand &gt; •
134 fluid._vulnerable_ 8 still_ M modify &gt;
136 is_fluid,irtilnerable_ 4.3 the_U.N._ M object &gt;
13 7 is_lluid,_vulnerable_ I structurally._ M modify &gt;
IS(SEM_End)SS (c) Semantic Analysis Section
</figure>
<figureCaption confidence="0.982157">
Figure 1. An Entry of the EDR Corpus
</figureCaption>
<page confidence="0.994294">
208
</page>
<subsectionHeader confidence="0.987443">
2.2 Concept-category Relation Descriptions
</subsectionHeader>
<bodyText confidence="0.935719">
If some concept-concept relations share a concept, it is possible to bundle them into a representation. For
example, concept-concept relation descriptions (2) can be bundled into a concept-category relation description
(4), if a super-sub relation (3) is also described simultaneously within the concept taxonomy. This level of
description corresponds to Fodor and Katz&apos;s representation using semantic markers and selection restrictions.
</bodyText>
<listItem confidence="0.423404571428571">
(2) c#break —&lt;object&gt;-• c#promise (to break a promise)
c#break —&lt;object&gt;— c#law (to break a law)
c#break —&lt;object&gt;-- c#Tule (to break a rule)
c#break —&lt;object&gt;— c#code (to break a code)
(3) (rules)
c#promise c#law\rule code
(4) c#break —&lt;object&gt;— (rules)
</listItem>
<subsectionHeader confidence="0.995429">
2.3 Category-category Relation Descriptions
</subsectionHeader>
<bodyText confidence="0.945636166666667">
In the previous section, we discussed the cases in which filler concepts of deep case patterns can be bundled
into categories, namely concept-category relations. Moreover, frame concepts in deep case patterns can also
be bundled and represented by categories (frame categories) (Ogino et. al. 1989). For example, the three
categories 01.2.6, 0 6.8.2 and 09.14.4 defined in Figure 2 (Hereafter, the notation &amp;quot;0&amp;quot; also means a
category,) bundle concepts and are linked with other categories to describe category-category relations (5), (6)
and (7) :
</bodyText>
<figure confidence="0.993234928571429">
(5) 01.2.6 —&lt;agent&gt;-•
01.2.6 —&lt;object&gt;-•
01.2.6 —&lt;implement&gt;-•
(6) 06.8.2 —&lt;agent&gt;-+
06.8.2 —&lt;object&gt;-•
06.8.2 —&lt;goal&gt;-•
(7) 09.14.4 —&lt;object&gt;--
(Animals)
(Physical_Objects)
(Parts_of_Animals)
(Human_Beings)
(Information) (Things_With_Information)
(Human_Beings) (Information_Accepters)
(Animals)
</figure>
<bodyText confidence="0.96603875">
This level of descriptions corresponds to Schank&apos;s representation using primitive actions, in a sense. For
example, 06.8.2 includes a connotation that can be represented by MTRANS, which is one of the primitive
actions, although other frame categories do not always correspond to a primitive action. In addition, relations
between verbs and adverbs, for example those mentioned in (Lakoff 1966), are also described at this level.
</bodyText>
<page confidence="0.996269">
209
</page>
<tableCaption confidence="0.738332416666667">
01.2.6 ((For_an_An i mal_to_Touc h_a _Ph ysic a I _Objec ()(W ith _a _Part _of _the_ Body ))
kagent&gt; : (Animals)
&lt;object&gt; : (Physical_Objects)
&lt;implement&gt; : (Parts_of_Animals)
(push (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: &amp;quot;a button&amp;quot;, &lt;implement&gt;: with &amp;quot;a finger&amp;quot;) ]
(press (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: against &amp;quot;a door&amp;quot;. &lt;implement&gt;: with &amp;quot;one&apos;s hands&amp;quot;) ]
(kick (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: &amp;quot;a ball&amp;quot;, &lt;implement&gt;: with &amp;quot;a foot&amp;quot;)
(step (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: on &amp;quot;a can&amp;quot;, &lt;implement&gt;: with &amp;quot;a foot&amp;quot;) ]
(grasp (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: &amp;quot;a ball&amp;quot;, &lt;implement&gt;: with &amp;quot;a hand&amp;quot;) ]
(lift (&lt;agent&gt;: &amp;quot;a person&amp;quot;, &lt;object&gt;: &amp;quot;a box&amp;quot;, &lt;implement&gt;: on &amp;quot;one&apos;s shoulder&amp;quot;)
06.8.2 ((For_Human_Beings)_To_SendAnformation)(To_Information_Accepter))
kagent&gt; : (Human_Beings) .
</tableCaption>
<construct confidence="0.5633528">
&lt;object&gt; : (Information) I (Things_with_Information) .
&lt;goal&gt; : (Human_Beings) I (Information_Accepters_other_than_Human_Beings)
(speak (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: about &amp;quot;the_story&amp;quot;, &lt;goal&gt;: to &amp;quot;her&amp;quot;)l
(tell (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;the_way&amp;quot;, &lt;goal&gt;: &amp;quot;the_traveler&amp;quot;)]
(describe (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;the_situation&amp;quot;, &lt;goal&gt;: in &amp;quot;the_bookll
(explain (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;the_plan&amp;quot;, &lt;goal&gt;: to &amp;quot;his_boss&amp;quot;)1
(write (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;his_name&amp;quot;, &lt;goal&gt;: on &amp;quot;the_sheet&amp;quot;)I
(input (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;the_data&apos;&apos;, &lt;goal&gt;: into &amp;quot;the_file&amp;quot;))
(copy (&lt;agent&gt;: &amp;quot;he&amp;quot;, &lt;object&gt;: &amp;quot;the_document&amp;quot;, &lt;goal&gt;: into &amp;quot;his_notebook&amp;quot;)1
09.14.4 (For_Functions_(Of_Human_Beings)_to_Become_Lower)
kobject&gt; : (Animals) )
cObeaten, cOgo_down, cOill, cOcollapse, cOdispirited
cOpyrosis, cOsinophobia, cOmalnutrition, etc.
(The notation &amp;quot; &amp;quot; is a deep case pattern to distinguish the category from the other categories at the
same fine semantic cluster, called &amp;quot;distinctive pattern&amp;quot;)
</construct>
<figureCaption confidence="0.7559445">
Figure 2. Categories 01.2.6, 06.8.2, 09.144 and Examples of Their Sub-Concepts
3 Development of the Concept Taxonomy
</figureCaption>
<bodyText confidence="0.999706222222222">
The two kinds of concept descriptions including categories, namely concept-category relation descriptions
and category-category relation descriptions, mentioned in the previous sections, must have their descendant
concept-concept relations in order to become useful. That is, concepts must be able to be actually classified
into categories included in such descriptions.
A concept can generally be classified into more than one categories (multiple classification). However it
is difficult to make exhaustive multiple classification from the beginning, because in the case of multiple
classification, we must compare concepts with categories mn times when there are m concepts and n
categories. In the case of exclusive classification using a distinctive tree whose leaves mean categories, on the
other hand, we must only compare concepts with nodes on the tree 0(m(log n)) times. Additionally, the
</bodyText>
<page confidence="0.988389">
210
</page>
<bodyText confidence="0.999884">
number of categories which share same sub-concepts with a category (cross categories) is generally much less
than the number of all categories. Moreover, it is not so difficult to make a list of cross categories for each
category (cross category list) in advance.
Considering the points mentioned above, we use the following method for concept classification : I)
exclusive classification : selecting categories which hardly share same sub-concepts (exclusive categories), and
making the first classification using a distinctive tree locating the exclusive categories at its leaf level. 2) cross
classification : making the second classification into categories other than exclusive categories, based on cross
category lists, and building a concept taxonomy from the results of the second classification. 3) improvement
of the Concept Dictionary : modifying the Concept Dictionary based on the results from tests using various
testing systems and automatic concept clustering from concept-concept relation descriptions. In the following
sections 3.1 and 3.2, we explain the first exclusive classification and the second cross classification
respectively. In section 3.3, we describe a method for modification of the Concept Dictionary.
</bodyText>
<subsectionHeader confidence="0.99693">
3.1 Exclusive Classification of Concepts
3.1.1 Classification into MONO-Categories
</subsectionHeader>
<bodyText confidence="0.9996236">
The first classification into categories for nominal concepts (MONO-concepts) is made by using the
MONO-concept taxonomy as shown in Figure 3 as a distinctive tree. That is, the classification starts from the
top node, decends along branches of the tree, and when reaching a node, compares the node&apos;s children nodes
with the input concept. This process is repeated, and if one of the leaves of the tree is reached, the
MONO-category corresponding to the leave should be selected.
</bodyText>
<figure confidence="0.996981421052632">
(MONO_Concepts)
(Animals) (Plants)
(Human_Beings)
Abstract Objects)
(Physical_Objects) (Places)
As:x
(Organizations)
(Hiiman_Anifacts)
•••
(Natural_Objects)
(Animate_ • bjects)
(Pans_of Animate_Objects)
(Human_Beings_with_Other_Characteristics))
(Characteristics_of Body)
(Children)
(Relatives)
(Occupations) (Appearance)
(Roles_in_a_Group) (Social_Positions)
(Races • Ethnic_Groups)
</figure>
<figureCaption confidence="0.999711">
Figure 3. the MONO-Concept Taxonomy
</figureCaption>
<page confidence="0.99001">
211
</page>
<bodyText confidence="0.9996515">
For example, in the case of the concept &amp;quot;c#police_man&amp;quot;, when we start with the question, &amp;quot;Is that a
physical object, a place or an abstract object?&amp;quot; (answer a physical object), and pass through the questions, &amp;quot;Is
that an animate object, a part of the body of an animate object, a natural object, a human artifact or an
organization?&amp;quot; (answer: an animate object), &amp;quot;Is that a human being, an animal or a plant?&amp;quot; (answer: a human
being), and &amp;quot;Is that a child, a relative, an occupation ...?&amp;quot; (answer: an occupation), then we can classify the
concept into the category (Occupations) .
</bodyText>
<subsectionHeader confidence="0.666014">
3.1.2 Classification into KOTO-Categories
</subsectionHeader>
<bodyText confidence="0.999867083333333">
As mentioned above, the first classification of the MONO-concepts is made by using the MONO-concept
taxonomy&apos;s hierarchy as a distinctive tree. On the other hand, the method for the first classification of verbal
concepts (KOTO-concepts) is not made by using the hierarchy as a distinctive tree but by semantic association
from the meanings of the concepts and examples of deap case patterns of the concepts.
The hierarchy has three levels. The highest level has been divided coarsely based on semantic association
(coarse semantic clusters; all can be seen in Figure 4). The second level has been also divided based on
semantic association (fine semantic clusters; all below coarse semantic cluster I can be seen in Figure 5).
On the contrary, the third level has been divided based on the deep case pattern shared by concepts
(KOTO-categories; all below fine semantic cluster • 1.2 can be seen in Figure 6), where one category has
only one deep case pattern which is specified with its distinctive pattern (expressed with the notation&amp;quot; (...] &amp;quot;
as in Figure 2). We have now 14 coarse semantic clusters, 253 fine semantic clusters and 984
KOTO-categories in the hierarchy.
</bodyText>
<tableCaption confidence="0.8134914">
(KOTO-Concepts)
*I&lt;SPATIAL_RELATIONS&gt; : relations among physical objects meaning states and changes in space
*2&lt;SPATIAL_ATTRIBUTES&gt; : attributes of physical objects meaning spatial measures in space
*3&lt;SOCIAL_RELATIONS&gt; : social relations among persons
tr4&lt;CLASS_RELATIONS&gt; : inclusive relations and comparative relations among objects
*5&lt;POSSESSION&gt; : relations among possessors and possessions
*6&lt;INFORMATION&gt; : relations among information and information processers
*7&lt;ESTIMATION&gt; : relations and attributes of objects meaning states and changes of their estimations
*8&lt;POSSIBILITY&gt; : relations and attributes of events meaning states and changes of possibilities
*9&lt;FUNCTION&gt; : relations and attributes of objects meaning states and changes of their functions
*10&lt;PROGRESS&gt; : relations and attributes of events meaning degrees of actualization
*1 I &lt;TIME&gt; : relations and attributes of events meaning temporal order or distance
*12&lt;QUANTITY&gt; : relations and attributes of objects meaning quantity or degree
*13&lt;OTHER_ATTRIBUTES&gt; : attributes other than those above
*14&lt;EXISTENCE&gt; : relations meaning appearance. continuance and disappearance of existences
</tableCaption>
<figureCaption confidence="0.96858">
Figure 4. Coarse Semantic Clusters and Their Definitions
</figureCaption>
<page confidence="0.906226">
212
</page>
<figure confidence="0.983898045454545">
* 1 &lt;SPAT1AL_RELATIONS&gt;
•1.1&lt;For_a_Physical_Object_itself_to_Change_in_Space&gt;
•1.2&lt;To_Touch_a_Place_or_Physical_Objects_in_Space&gt;
91. 3&lt;To_Separate_from_a_Thing_Touch ing_it_in_Space&gt;
• 1.4&lt;For_Physical_Objects_to_Unite_in_Space&gt;
• 1.5&lt;For_U ni ted_Ph ysica I_Objects_to_Se parate_in_S pace&gt;
51.6&lt;To_Move_Some_Distance_i n_S pace&gt;
01.7&lt;To_Move_Some_Distance_to_a_Di rection_in_S pace&gt;
•1.8&lt;To_Move_Inside_in_Space&gt;
• 1.9&lt;To_Move_Outside_in_Space&gt;
• 1.10&lt;To_A pproach_a_Goal _Some_Dis ta nce_in_S pace&gt;
• 1.1 1&lt;To_Leave_a_Source_Some_Distance_in_S pace&gt;
• 1.1 2&lt;For_Physical_Objects_to_Gather_at_Some_Discance_in_Space&gt;
• 1.13&lt;For_Physical_Objects_to_Disperse_from_Some_Distance_in_Space&gt;
• 1 .14&lt;For_Physical_Objects_to_Fill_in_S pace&gt;
• 1.1 5&lt;For_an_Angle_to_decrease_in_Space&gt;
• 1.16&lt;For_an_Angle_to_increase_in_Space&gt;
• 1.17&lt;For_Order_of_Physical_Objects_to_Change_in_Space&gt;
• 1.18&lt;For_a_Wearable_Object_to_Touch_a_Body&gt;
• 1.19&lt;For_a_Wearable_Object_to_Separate_from_a_Body&gt;
• 1.20&lt;To_Move_into_a_Body_Physiologically&gt;
• 1.2 1&lt;To_Move_out_of_a_Body_Physiologically&gt;
</figure>
<figureCaption confidence="0.998091">
Figure 5. Fine Semantic Clusters Below *l&lt;Spatial Relations&gt;
</figureCaption>
<table confidence="0.912490761904762">
• 1.2&lt;To_Touch_a_Place_or_Physical_Object_in_Space&gt;
01.2.1 ((For_a_Physical_Object)Jo_Touch_(Another_Physical_Object))
01 .2.2 ((For_a_Physical_ObjecO_To_Touch_another_Physical_Object)
01.2.3 ((For_an_AnimaI)_To_Touch_(A_Physical_Object)_Incentionally)
01 .2.4 ((For_an_AnimaD_To_Touch_a_Physical_Object_Imentionally)
01 .2.5 ((For_an_Incentional_Object)_To_Touch_a_Physical_Object_Intentionally)
01.2.6 ((For_an_Animal)_to_Touch_(A_Physical_Object)(With_a_Part_of_the_Body))
01.2.7 ((For_an_Animal)_to_Touch_a_Physical_Object_(With_a_Pan_of_the_Body))
01 .2.8 CFor_an_AnimalLto_Touch_(A_Physical_Object)_with_a_Part_of_the_Body)
01.2.9 ((For_an_Animal)_to_Touch_(A_Physical_Object)(With_an_Implement))
01.2.10 ((For_an_An ima I)_to_Touc h_( A _ Ph ys ic a I _Object)_ with _an_ I mplemen
01.2. II ((For_an_Intentional_Object)_to_Send_(A_Physical_Object)(To_Some_Place))
01.2.12 ((For_an_Animal)_to_Go_(to_Some_Place)_Intentionally)
01.2.13 ((For_a_Person)_io_Meet_withjanother_PersonUntentionally)
01.2.14 ((For_an_Animal)_m_Grasp_(A_Physical_Object)(With_a_Part_of_the_Body))
01.2.15 ((For_an_Animal)_to_Grasp_(A_Physical_Object)(With_an_Implement))
01 .2.16 ((For_an_Person)_to_Put_(A_Physical_Object)(On_Some_Place))
01,2. 17 ((For_an_Person)_to_Cause_( An_Animal_and_another_An imal)_to_Touch_Each_Other)
01 .2.18 ((For_an_Animal_and_another_Animal)_to_Touch_Each_Other)
01.2.19 ((For_an_Animal)_to_Touch_(An_Physical_Object))
01 .2.20 ((For_an_Intentional_Object)_to_Cause_a_Physical_Object_to_Touchja_Physical_Object)
</table>
<figureCaption confidence="0.883884">
Figure 6. KOTO-Categories Below • 1.2
</figureCaption>
<page confidence="0.997598">
213
</page>
<bodyText confidence="0.999683785714286">
The first classification of a concept into the KOTO-categories is made based on semantic association with
the concept and deap case patterns created with the concept. The procedures are as follows: I) assigning basic
concepts into KOTO-categories: classifying about 4,000 basic concepts into fine semantic clusters, describing
deep case patterns underlying example sentences created with the concepts and dividing the clusters into
KOTO-categories to make each of them have only one deap case pattern. 2) Establishing two indexes :
making a) a word index for retrieving categories by a word, and b) a case frame index for retrieving
categories by a deep case set. 3) Searching category candidates: a) searching category candidates by
associating basic concepts which seem to share a deap case pattern with the concept and retrieving the word
index by words meaning the basic concepts. b) In a case in that it is impossible to associate any basic concepts
with the concept, finding category candidates by creating example sentences, making deap case frames from
the sentences, and retrieving the case frame index by the frames to find category candidates. 4) Selecting a
category from the category candidates: classifying concepts into the most appropriate category by considering
from the following three points of view: a) the names of the categories and their upper clusters, b) the
distinctive patterns of the categories, and c) the basic concepts assigned to the categories.
</bodyText>
<subsectionHeader confidence="0.9909425">
3.2 Cross Classification of Concepts
Cross classification of concepts is made in the following way:
</subsectionHeader>
<bodyText confidence="0.99423925">
1) Making cross category lists for each exclusive categories. Types of cross relations are assorted into
the following three types: a) a cross category which implies an exclusive category, b) a cross
category which intersects an exclusive category, and c) a cross category which includes an exclusive
category.
2) Contrasting each concept classified into an exclusive categoriy and each cross category listed in the
cross category list of the exclusive category and judging whether or not the concept can be classified
into the cross category. Here in the above case c), all concepts in the exclusive category can be
automatically classified into the cross category.
</bodyText>
<subsectionHeader confidence="0.999687">
3.3 Improvement of the Concept Dictionary
</subsectionHeader>
<bodyText confidence="0.9873415">
Through the following procedures, categories which should be modified are found and improvement of the
Concept Dictionary is made:
</bodyText>
<listItem confidence="0.3332742">
1) Collecting negative examples:
When an answer other than correct answers is output from a testing system, an inappropriate
concept-concept relation must be found deduced from the Concept Dictionary by viewing a debugging
trace of the process of the system. Such concept-concept relations are collected as negative examples.
2) Collecting positive examples:
</listItem>
<bodyText confidence="0.85456">
When a correct answer is not output from a testing system, a concept-concept relation must be found
to be added to the Concept Dictionary. Moreover, all correct answers output from all testing systems
</bodyText>
<page confidence="0.99732">
214
</page>
<bodyText confidence="0.981728">
must have their corresponding concept-concept relations deduced from the Concept Dictionary. These
concept-concept relations are collected as positive examples.
</bodyText>
<sectionHeader confidence="0.757606" genericHeader="method">
3) Estimation:
</sectionHeader>
<subsectionHeader confidence="0.831102">
At a stage when negative and positive examples have been collected to some extent, the divisibility of
</subsectionHeader>
<bodyText confidence="0.886829">
each concept-category relation description and category-category relation description is estimated by
using the following formula:
</bodyText>
<figure confidence="0.6128875">
P(0
(8) D (I, m, n)
o P(i)
where P(i)
nm)
0 k 4 1.0 (a parameter),
n : the number of concepts under the category,
the number of incorrect classifications into the category,
m : the number of examples,
I : the number of negative examples.
The formula (8) is derived as follows:
We suppose that the concept-category (or category-category) relation description (9) is an object of our
estimation:
(9) a — rel B
that the number of the concepts classified under the category B is n:
bl b2 b,
</figure>
<figureCaption confidence="0.429341">
and that the number of (both negative and positive) examples is m and the number of negative examples in the
examples is 1:
</figureCaption>
<figure confidence="0.916273285714286">
(II) m examples
a — tel bi * a — tel b2
a — tel b, a — tel b,
a — tel b, (I negative examples)
a — tel b„
( (m-1) positive examples)
If the number of concepts which are under the category B but not appropriate for the concept description (9) is 1,
</figure>
<page confidence="0.841484">
215
</page>
<figure confidence="0.83794225">
the probability that I negative examples are found out of m examples is given by the formula (12).&apos;
(12) P(i) =
In
&apos;
</figure>
<bodyText confidence="0.746396666666667">
Therefore, the probability that the ratio of the concepts not appropriate for the description (9) to the concepts
located under the category B is more than k is given by the formula (8). Here we use Bayse&apos;s Theorem because
sellections of the number i are events independent from each other.
</bodyText>
<listItem confidence="0.493142">
4) Deletion of the concept descriptions:
</listItem>
<bodyText confidence="0.91573325">
In cases in that the value of the formula (8) is more than 0.9 when k = 0.9, the concept description
(9) is deleted from the Concept Dictionary and remaining positive examples are asserted as concept-
concept relation descriptions into the Concept Dictionary because most of the examples for the
description are negative.
</bodyText>
<subsectionHeader confidence="0.328544">
5) Division of categories
</subsectionHeader>
<bodyText confidence="0.971533166666667">
In cases in that the value of the formula (8) is more than 0.9 when k = 0.1, the category B is divided
in two in order to represent both a category satisfying the relation (9) and a category not satisfying the
relation (9) and all concepts under the category B is reclassified into the two categories because we
recognize that a) the number of examples are large enough for the estimation, and that b) the number of
negative examples is too large to neglect. Here if the divided two categories exist as sub-categories of
the category B in the concept taxonomy, the classification is not necessary.
</bodyText>
<subsectionHeader confidence="0.641204">
6) Accumulation of preference knowledge
</subsectionHeader>
<bodyText confidence="0.988523076923077">
In cases in that the value of the formula (8) is not more than 0.9 when k = 0.1, the collected negative
examples are translated to preference knowledge (for data structures and usages of preference
knowledge, see Section 4). From a debugging trace of a testing system, together with a negative
example, a concept, a word or a pronumciation corresponding to the negative example and a concept
description more appropriate than the negative example must be also gained. This information is
represented by preterence knowdedge with the following format (13) and accumulated:
(13) on &lt;concept&gt; I &lt;word&gt; I &lt;pronunciation&gt;
give preference to
&lt;a-more-appropriate-concept-description&gt;
over
&lt;a-negative-example-of-concept-description&gt;
We ii;&amp;quot;aYjuse Poisson distribution as an approximation to (12) if n is large. However. since 3,000, it is realistic to
calculate the formula (12).
</bodyText>
<page confidence="0.996671">
216
</page>
<listItem confidence="0.332424">
7) Clustering of concept-concept relation descriptions
</listItem>
<bodyText confidence="0.944785625">
Concept-concept relation descriptions remaining after all the above procedures are clustered by using
an optimal scaling or using DM-decomposition and a probability-based estimation and the gained
clusters are asserted as concept-category relation descriptions into the Concept Dictionary. The
clustering algorithms are explained in detail in (Nakao 1988, Matsukawa 1989).
8) Reconstruction of the concept taxonomy
Category-category relation descriptions are clustered and hierachized by using DM-decomposition and
set-relation calculations in order to bundle the descriptions into higher level categories. The
hierachization algorithm is explained in detail in (Matsukawa 1990a, 1990b, Yokota 1990).
</bodyText>
<sectionHeader confidence="0.982124" genericHeader="method">
4 Preference Knowledge
</sectionHeader>
<bodyText confidence="0.99973625">
All concepts, categories and concept descriptions have an ID number called concept ID. Knowledge for
ordering input sentence interpretations given by using the Concept Dictionary are represented by data
individually expressing the order of the concept IDs that co-occur with each word pronunciation, word and
concept, respectively (preference knowledge). We use the following three methods for ordering concept IDs:
</bodyText>
<listItem confidence="0.722788666666667">
a) Linear lists of concept IDs
b) Association lists of concept IDs and the concept IDs&apos; preference value
C) Directed graphs including arcs meaning preference relations between concept IDs
</listItem>
<bodyText confidence="0.999793666666667">
As mentioned in section 3.3, modification of the Concept Dictionary is made based on feedback
information from tests performed by various kinds of processes in application systems (testing systems).
Word sense selection and translation word candidates selection are ones of these processes. When an output
answer given by such a testing system is different from correct answers, the reason for the difference is
analyzed by viewing traces of processes of the system, and the Concept Dictionary and/or the preference
knowledge are/is modified. After such modifications, the correct answers become able to be selected by using
the Concept Dictionary and the preference knowledge. For example, the word &amp;quot;suspend&amp;quot; has five senses, as
shown in Figure 7. If the concept-concept relation shown in (14) is input, only two out of the five senses
match the relation. The two senses are shown in (15):
</bodyText>
<reference confidence="0.326264166666667">
(14) c#suspend —&lt;objecc&gt;—• c#police_man
(to suspend the policeman)
(15) 04.2.2 —&lt;object&gt;—. c#police_man
01.2.5 —&lt;object&gt;-- c#police_man
suspend c#(3cfe9b)_to_hang_something
c#(0db70c)_to_prevent_from_taking_part_in_a_team_for_a_time
</reference>
<page confidence="0.969333">
217
</page>
<figure confidence="0.997132739130435">
011.3.2 ((For_an_lntentional_Object)_to_Postpone_the_Time_Point_of_Occurrence_(of an_Event_Having_
a_Time_Point))
(&lt;agent&gt; : (Human_Beings) I (Organizations) .
&lt;object&gt;: (An_Event_Having_a_Time_Point)
04.2.2 ((For_a_Person_or_An_Organization)_to_Discharge_(Another_Person_or_Organization)(From_
a_Role_or_Occupation))
kagent&gt; : (Human_Beings) I (Organizations) .
&lt;object&gt; : (Human_Beings) I (Organizations)
&lt;source&gt; : (Occupations) I (Roles_in_Organizations) I (Organizations) I
01.2.5 ((For_an_Intentional_Object)_to_Cause_(A_Physical_Object)_to_Touch_
(Another_Physical_Object))
(&lt;agent&gt; : (Human_Beings) .
&lt;object&gt;: (Physical_Objects) .
&lt;goal&gt; : (Physical_Objects)
c#(3cfe9b)to_hang_something
c#(0db70c)to_prevent_from_taking_part_in_a_team_for_a_time
cO(Odb70b)to_put_off or_stop_for_a_piriod_of time
c#(0db70f)to_cause_a_rule_or_law_to_be_for_a_time_no_longer_in_force
•&lt;agent&gt; (Human_Beings) I (Organizations)
&lt;object&gt;--b, (Rules) I (Licenses)
c#(0db70a)to_hold_still_in_liquid_or_air
N*-----&lt;object&gt; c#dust I c#smog
suspend
</figure>
<figureCaption confidence="0.999836">
Figure 7. The Five Senses of Word &amp;quot;suspend&amp;quot; and Their Concept Descriptions
</figureCaption>
<bodyText confidence="0.5344195">
If we have preference knowledge on &amp;quot;c#police_man&amp;quot; as shown in (16), we can select only one sense out of
the two senses, namely &amp;quot;c#(0db70c)to_prevent_from_taking_part_in_a_team_f0r_a_time.&amp;quot;
</bodyText>
<reference confidence="0.372026142857143">
(16) on c#police_man
give preference to
04.2.2 —&lt;object&gt;-- (Human_Beings)
over
01.2.5 —&lt;object&gt;-- (Physical_Objects)
Moreover, such preference knowledge is given to each concept, word or pronunciation. For example,
&amp;quot;c#bird&amp;quot; and &amp;quot;c*abbit&amp;quot; have different preference knowledge as follows:
</reference>
<page confidence="0.994376">
218
</page>
<reference confidence="0.6463132">
(17) on ctfbird
give preference to
Orly —&lt;agent&gt;— (Intentional-Objects) :
over
c#hop —&lt;agent&gt;—• (Animals);
on clfrabbit
give preference to
dthop —&lt;agent&gt;—• (Animals) :
over
c#fly —&lt;agent&gt;—• (Intentional-Objects) :
</reference>
<bodyText confidence="0.881837">
By using this knowledge with the concept descriptions shown in Figure 8, Japanese sentences can be
properly translated, for example as shown in (18) (for a method for unification of concepts expressed by
different words or in different languages, see (Miike 1990b, Tominaga 1991)):
</bodyText>
<figure confidence="0.87574425">
(18) a) TORI - GA TOBU. •••■••■O A bird flies.
(a bird)
b) USAGI - GA TOBU. ---.. A rabbit hops.
(a rabbit)
</figure>
<bodyText confidence="0.964402142857143">
Preference knowledge is collected not only through processings of word sense selection and translation
word candidate selection, but also through those of structual disambiguation, paraphrasing and the like.
Therefore, the knowledge includes descriptions corresponding to lexical preference proposed by Ford,
Bresnan and Kaplan for structual disambiguation (Ford Bresnan and Kaplan 1982). Although such knowledge
provides just a bias of interpretations of ambiguous structures, the knowledge is indispensable for
deterministic sentence analysis without any knowledge about the discourse to be refered in order to use the
principle of parsimony , the principle of a priori plausibility, etc. (Crain and Steedman 1984, Hirst 1984).
</bodyText>
<sectionHeader confidence="0.999676" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999029">
Concept-category relations are similar to what are called selection restrictions. However, the goal of the
development of the Concept Dictionary is not to express word sense with minimum semantic markers such as
in (Katz and Fodor 1963). What is important is to actualize a methodology for weeding out incorrect, too
coarse or useless concept descriptions by using them on various application systems. For the purpose, we
may have redundant semantic markers (namely, categories) at the first stage and do have descriptions not
including semantic markers (namely, concept-concept relation descriptions).
</bodyText>
<page confidence="0.997477">
219
</page>
<table confidence="0.937338388888889">
01 1.6.4 ((For_An_Event_Having_A_Period_Or_A _Time _Point)_To_Get_Out_Of_Time_Order_(At_Some_Time)&gt;
kobject&gt;: (Events_Having_A_Period) (Events_Having_A_Time_Point) . &lt;source&gt;: (Time_Point) I
01.6.5 ((For_An_Intentional_Object)_To_Move_(From_Some_Place)(To_Some_Place)_Intentionally)
kagent&gt;: (Intentional_Objects) , &lt;source&gt;: (Places) , &lt;goal&gt;: (Places) 1
013.1.2 (For_A_Physical_Object_With_Color_Or_A_Color_ltself)_To_Change_Into_Another_Color)
kobject&gt;: (Physical_Objects_With_Color) (Values_Of Auribute_Color) c#colori
01.3.6 ((For_An_AnimakTo_Separate2From_A_Physical_Object_Or_A_Place))
kagent&gt;: (Animals) , &lt;source&gt;: (Physical_Objects) : (Places)
01 .1 1 .3 ((For_An_Animal)_To_Leave_Some_Distance_(From_An_Physical_Object_Or_A_Place))
(&lt;agent&gt;: (Animals) , &lt;source&gt;: (Physical_Objects) : (Places)
1.17.1 (For_Order_Of, JA_Physical_Object)(Against_A_Physical_Object)_To_Change_ln_Space)
\kobject&gt;: (Physical_Objects) : &lt;goal&gt;: (Physical_Objects) )
c#(3cead7)hop jump; hop; leap
c#(3cf4f6)discolor fade; discolor
c#( 1 00942)husten rush; husten; hurry
c#(3cef11)fly fly
c#(0e4bed)omit omit; skip
c#(100946)slap_on_the_cheek slap (on the cheek)
</table>
<figure confidence="0.782926727272727">
,..&lt;object&gt; --&gt; c#BINTA
&lt;goal&gt; --&gt; c#cheek
c#(100948)spread_bribes spread
&lt;object&gt; --bp c#bribe
c#(100941)blow_a_fuse blow
---&gt; c#fuse (-TOBU&amp;quot; and &amp;quot;BINTA&amp;quot; are Japanese words.)
TOBU
c#(10093d)jump_over
c#( 1 00947)run_away
jump (over)
run (away)
</figure>
<figureCaption confidence="0.999956">
Figure 8. The Translation Word Candidates of Pronunciation &amp;quot;TOBU&amp;quot; and Their Concept Descriptions
</figureCaption>
<page confidence="0.974688">
220
</page>
<bodyText confidence="0.997641">
We are compiling and improving the Concept Dictionary based on the results of many practical tests
performed by various application systems. Actually, however, the number of the application systems we are
using for testing dictionary data is only some dozen, and the functions we require the dictionary to fulfill are
just at the level of practical necessity for the systems. In other words, compared with &amp;quot;the whole knowledge&amp;quot;,
the Concept Dictionary actually lacks various parts. For example:
</bodyText>
<subsectionHeader confidence="0.762215">
I) Coverage of Concept Relations and Categories:
a) Coverage of concept relations:
</subsectionHeader>
<bodyText confidence="0.999031666666667">
The number of sentences in the EDR corpus is 1,000,000. As mentioned above, we also
create example sentences for some concepts and we use categories to describe concept relations.
However, the coverage of concept relations is incomplete. The situation is similar to that of
ordinary lexicography in that even if we had a very large corpus and aboundant lexicographers,
they could never completely assign example sentences covering all kinds of word co-
occurrences in all types of contexts
</bodyText>
<subsectionHeader confidence="0.35729">
b)Coverage of categories:
</subsectionHeader>
<bodyText confidence="0.999159333333333">
Some categories are useful to describe concept relations, while other categories are not. Since
the cost/performance of the implementation of useless categories is low, we do not implement
such categories in the concept taxonomy.
</bodyText>
<sectionHeader confidence="0.63149" genericHeader="conclusions">
2) Granularity of Concepts
</sectionHeader>
<bodyText confidence="0.869296166666667">
Since concepts, our representation primitives, are almost as fine as translation words&apos; senses in
bilingual dictionaries, it is impossible to implement knowledge including finer instances.
a) Real world instances:
From concept-concept relations, we can extract slots of a class in the real world. For example,
from the concept-concept relation shown in (19), we can extract slot &amp;quot;haveALid?&amp;quot; of class
&amp;quot;Otvessel&amp;quot; as shown in (20):
</bodyText>
<listItem confidence="0.485903">
(19) ctivessel —&lt;part_of&gt;— c#Iid
(20) Crtvessel
</listItem>
<bodyText confidence="0.8813394">
canHaveSlots: (haveALid?)
(Here we use the notation Cyc uses (Lenat and Guha 1989))
However, we cannot extract some attributes of real world instances from concept relation
descriptions. For example the value &amp;quot;yes&amp;quot; of the slot &amp;quot;have ALid?&amp;quot; shown at (21) can never be
decided with the Concept Dictionary:
</bodyText>
<reference confidence="0.918401">
(21) TbeVesselOnTheDeskInFrontOtMeA :00arnOnMarch3rdln 1991 JST
instance0f: C#vessel
haveALid?: yes
</reference>
<page confidence="0.996425">
221
</page>
<bodyText confidence="0.850879222222222">
b) Distinction of pragmatic referents:
Finer referents are used for describing pragmatic ambiguities of a sentence. For example, in
order to express pragmatically different interpretations, different referents are described into
each mental space, according to Fauconnier&apos;s theory (Fauconnier 1984). For example,
different interpretations of the sentence (22) require at least three different mental spaces and
six different referents of the word &amp;quot;president&amp;quot;.
(22) John believes that the president was a baby in 1929.
The Concept Dictionary can not give distinction of such referents although it can give predicate
concepts used in annotations for mental spaces.
</bodyText>
<sectionHeader confidence="0.997699" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995878">
Crain, S. and Steedman, M. (1984) &amp;quot;On not Being Led Up the Garden Path: The Use of Context by the Psychological
Parser&amp;quot;, in: Dowty, D. R. ; Karttunen. L. J. and Zwicky, A. M. (editors). Syntactic Thecry and How
People Parse Sentences, Carngridge University Press, 1984.
Fauconnier, G. (1984) Espaces Mentaux. Editions de Minuit.
Fillmore, C. J. (1968) &amp;quot;The Case for Case&amp;quot; in Bach E. and Harms R.T. (eds.), Universals in Linguistic Theory,
Holt, Rinehart axl Winston, Chicago.
Ford, M., Bresnan, J.W. and Kaplan, R.M. (1982) &amp;quot;A Competence-based theory of syntactic closure&amp;quot;, in: Bresnan, J.W.
(editor) The Mental Representatin of Grammatical Relations. Cambridge, Massashusens: The MIT
Press, 1982.
Hirst, G. J. (1984) Semantic Interpretation against Ambiguity, University Microfilms International, pp. 196-200.
Kakizaki, N. (1987) &amp;quot;Research and Development of an Electronic Dictionary&amp;quot;, Machine Translation Summit
pp.61-64.
Katz, J.J. and Fodor, J.A. (1963) -The Structure of a Semantic Theory&amp;quot;, Language 39, pp.170-210.
Lakofff G. (1966) &amp;quot;Stative Adjectives and Verbs in English&amp;quot;, Mathematical Linguistics and Automatic Translation
17, pp.1-16, Report to the National Science Foundation.
Lenat, D.B. and Guha, R.V. (1989) Building Large Knowledge-Based Systems, Addison-Wesley Publishing
Company. Inc., pp. 160-162.
Matsukawa, T., Nakamura, J. and Nagao. M. (1989) &amp;quot;An Algorithm of Word Clustering from Co-occurrence Data Using DM
Decomposition ard Statistical Estimation&amp;quot;. Information Processing Society of Japan, NL-72-9,
Matsukawa, T., Kishimoto, Y., Miike, S.. Yokota, E., Takai, S. and Amano, S. (1990a) &amp;quot;Construction of a Hierarchical
</reference>
<page confidence="0.967707">
222
</page>
<reference confidence="0.999225205882353">
Concept Classification Based On Compaction of Concept Descriptions&amp;quot;, Information Processing Society
of Japan, NL-78-6.
Matsulcawa, T., Nakazawa, M.. Adachi. H. and Amano, S. (1990b) &amp;quot;Basic Functions of the Environment for Binary Relation
Categorization&amp;quot;, Proceedings of 4Ith Conference of Information Processing Society of Japan.
7S-7.
Miike, S., Amano, S., Uchida, H. and Yokoi, T. (1990a) &amp;quot;The Structure and Function of the EDR Concept Dictionary&amp;quot;. TKE
&apos;90: Terminology and Knowledge Engineering, Frankfurt. 1NDEKS VERLAG.
Miike, S. (1990b) &amp;quot;How to Define Concepts for Electronic Dictionaries&amp;quot;, Proceedings of International Workshop
on Electronic Dictionaries, pp. 43-49. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo,
Japan,
Nagao, M., Tsujii, J. and Nakamura. J. (1985) &amp;quot;The Japanese Government Project for Machine Translation&amp;quot;, Computational
Linguistics, Vol 11, Numbers 2-3, April-September.
Nakao, Y. and Momiyama, Y. (1988) &amp;quot;Word Clustering by Word Bindings,&amp;quot; Information Processing Society of
Japan, NL-65-1.
Nakao, Y. and Uchida, H. (1990a) &amp;quot;Corpus for Developing Dictionary,&amp;quot; Euralex 4th International Congress.
Nakao, Y. (1990b) &amp;quot;How to Extract Dictionary Data from the EDR Copus&amp;quot;. Proceedings of International
Workshop on Electronic Dictionaries, pp. 58-62. TR-031, Japan Electronic Dictionary Research Institute,
Ltd. Tokyo, Japan.
Ogino, T., Yamamoto, Y. Kiyono. M, Nawata, M. and Uchida. H. (1989) &amp;quot;Verb Classification Based On the Semantic
Relation of Co-occurring Elements&amp;quot;, Information Processing Society of Japan. NL-71-2.
Schank, R. C. (1975). Conceptual Information Processing, North-Holland.
Tominaga, M., Miike, S., Uchida. H. and Yokoi, T. (1991) &amp;quot;Development of the EDR Concept Dictionary&amp;quot;, Second
Workshop of Japan-United Kingdom Bilateral Cooperative Research Programme on
Computational Linguistics, UMIST.
Uchida. H. (1990) &amp;quot;Electronic Dictionary&amp;quot;, Proceedings of International Workshop on Electronic
Dictionaries, pp. 23-42. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo, Japan.
Wilks, Y. (1975). &amp;quot;Preference Semantics&amp;quot;, in Keenan, Edward L. (ed.), Formal Semantics of Natural Language,
Cambridge University Press, pp.329-348.
Yokoi, T., Uchida. H., Amano, S. and Kiyono, M. (1989) &amp;quot;Research and Development of Large-Scale Electronic Dictionaries -
Current Status of the EDR Project&amp;quot;, Australian-Japanese Joint Symposium on Natural Language
Processing.
Yokota, E. (1990) &amp;quot;How to Organize a Concept Hierarchy&amp;quot;, Proceedings of International Workshop on
Electronic Dictionaries, pp. 50-57. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo,
Japan.
</reference>
<page confidence="0.999167">
223
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.322951">
<title confidence="0.987363666666667">Development of the Concept - Implementation of Lexical Knowledge</title>
<author confidence="0.975452">Tomoyoshi MATSUKA WA</author>
<author confidence="0.975452">Eiji YOKOTA</author>
<affiliation confidence="0.845691">Japan Electronic Dictionary Research Institute, Ltd. (EAR)</affiliation>
<address confidence="0.85696">Mita-Kokusai-Bldg. 4-28, Mita 1-chome,Minato-ku. Tokyo. 108. JAPAN</address>
<email confidence="0.8477155">e-mail:matsu@edr5r.edr.co.jpyoko@edr7r.edr.co.jp</email>
<phone confidence="0.9386345">tel: 81-3-3798-5521, fax: 81-3-3798-5335</phone>
<abstract confidence="0.9146542">Summary The methodology of development of the Concept Dictionary being compiled by EDR. which is to be a neutral dictionary for semantic processing of natural languages available for various application systems, is described. The Concept Dictionary is based on several linguistic semantic representation theories and consists of: a) concept descriptions, and b) the concept taxonomy. Moreover, preference knowledge is being collected from output data of various testing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>c#suspend —&lt;objecc&gt;—• c#police_man (to suspend the policeman)</title>
<date></date>
<marker></marker>
<rawString>(14) c#suspend —&lt;objecc&gt;—• c#police_man (to suspend the policeman)</rawString>
</citation>
<citation valid="true">
<title>04.2.2 —&lt;object&gt;—. c#police_man 01.2.5 —&lt;object&gt;-- c#police_man suspend c#(3cfe9b)_to_hang_something c#(0db70c)_to_prevent_from_taking_part_in_a_team_for_a_time</title>
<date></date>
<marker></marker>
<rawString>(15) 04.2.2 —&lt;object&gt;—. c#police_man 01.2.5 —&lt;object&gt;-- c#police_man suspend c#(3cfe9b)_to_hang_something c#(0db70c)_to_prevent_from_taking_part_in_a_team_for_a_time</rawString>
</citation>
<citation valid="true">
<title>on c#police_man give preference to 04.2.2 —&lt;object&gt;-- (Human_Beings) over 01.2.5 —&lt;object&gt;-- (Physical_Objects) Moreover, such preference knowledge is given to each concept, word or pronunciation. For example, &amp;quot;c#bird&amp;quot; and &amp;quot;c*abbit&amp;quot; have different preference knowledge as follows: (17) on ctfbird give preference to Orly —&lt;agent&gt;— (Intentional-Objects) : over</title>
<date></date>
<marker></marker>
<rawString>(16) on c#police_man give preference to 04.2.2 —&lt;object&gt;-- (Human_Beings) over 01.2.5 —&lt;object&gt;-- (Physical_Objects) Moreover, such preference knowledge is given to each concept, word or pronunciation. For example, &amp;quot;c#bird&amp;quot; and &amp;quot;c*abbit&amp;quot; have different preference knowledge as follows: (17) on ctfbird give preference to Orly —&lt;agent&gt;— (Intentional-Objects) : over</rawString>
</citation>
<citation valid="false">
<authors>
<author>chop —agent—•</author>
</authors>
<title>(Animals); on clfrabbit give preference to dthop —&lt;agent&gt;—• (Animals) : over</title>
<marker>—agent—•, </marker>
<rawString>c#hop —&lt;agent&gt;—• (Animals); on clfrabbit give preference to dthop —&lt;agent&gt;—• (Animals) : over</rawString>
</citation>
<citation valid="false">
<authors>
<author>cfly —agent—•</author>
</authors>
<booktitle>(21) TbeVesselOnTheDeskInFrontOtMeA :00arnOnMarch3rdln 1991 JST instance0f: C#vessel haveALid?: yes</booktitle>
<marker>—agent—•, </marker>
<rawString>c#fly —&lt;agent&gt;—• (Intentional-Objects) : (21) TbeVesselOnTheDeskInFrontOtMeA :00arnOnMarch3rdln 1991 JST instance0f: C#vessel haveALid?: yes</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>M Steedman</author>
</authors>
<title>On not Being Led Up the Garden Path: The Use of Context by the Psychological Parser&amp;quot;,</title>
<date>1984</date>
<editor>in: Dowty, D. R. ; Karttunen. L. J. and Zwicky, A. M. (editors).</editor>
<publisher>Carngridge University Press,</publisher>
<marker>Crain, Steedman, 1984</marker>
<rawString>Crain, S. and Steedman, M. (1984) &amp;quot;On not Being Led Up the Garden Path: The Use of Context by the Psychological Parser&amp;quot;, in: Dowty, D. R. ; Karttunen. L. J. and Zwicky, A. M. (editors). Syntactic Thecry and How People Parse Sentences, Carngridge University Press, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fauconnier</author>
</authors>
<title>Espaces Mentaux. Editions de Minuit.</title>
<date>1984</date>
<marker>Fauconnier, 1984</marker>
<rawString>Fauconnier, G. (1984) Espaces Mentaux. Editions de Minuit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>The Case for Case&amp;quot;</title>
<date>1968</date>
<booktitle>Universals in Linguistic Theory,</booktitle>
<editor>in Bach E. and Harms R.T. (eds.),</editor>
<location>Holt, Rinehart axl Winston, Chicago.</location>
<contexts>
<context position="1568" citStr="Fillmore 1968" startWordPosition="216" endWordPosition="217">t Dictionary) is being developed by EDR. The goal of the development is to build a neutral dictionary for natural language semantic processing that is available for various application systems. The implementation of the dictionary is based on several linguistic semantic representation theories. For a long time, a series of trials for describing dependencies among words or word senses by bundling verbs, adjectives, etc., has been conducted. Establishing a deep case level and using a formalism independent of each language, Fillmore developed a theory of representation of dependency among words (Fillmore 1968). On the other hand, Fodor and Katz explained a mechanism of selecting interpretations of constituents in a sentence by using a formalism composed of a semantic marker, distinguisher and selection restriction (Katz and Fodor 1963). In contrast to these theories, Wilks proposed a point of view to consider word dependency not as a constraint but as a preference (Wilks 1975). In addition, Schank proposed to abstract connotations not only from senses of nouns but also those of verbs, and he named them &amp;quot;primitive actions&amp;quot; (Schank 1975). These semantic representation theories have been reviewed and </context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Fillmore, C. J. (1968) &amp;quot;The Case for Case&amp;quot; in Bach E. and Harms R.T. (eds.), Universals in Linguistic Theory, Holt, Rinehart axl Winston, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ford</author>
<author>J W Bresnan</author>
<author>R M Kaplan</author>
</authors>
<title>A Competence-based theory of syntactic closure&amp;quot;,</title>
<date>1982</date>
<booktitle>The Mental Representatin of Grammatical Relations.</booktitle>
<editor>in: Bresnan, J.W. (editor)</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massashusens:</location>
<marker>Ford, Bresnan, Kaplan, 1982</marker>
<rawString>Ford, M., Bresnan, J.W. and Kaplan, R.M. (1982) &amp;quot;A Competence-based theory of syntactic closure&amp;quot;, in: Bresnan, J.W. (editor) The Mental Representatin of Grammatical Relations. Cambridge, Massashusens: The MIT Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Hirst</author>
</authors>
<title>Semantic Interpretation against Ambiguity,</title>
<date>1984</date>
<pages>196--200</pages>
<institution>University Microfilms International,</institution>
<marker>Hirst, 1984</marker>
<rawString>Hirst, G. J. (1984) Semantic Interpretation against Ambiguity, University Microfilms International, pp. 196-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kakizaki</author>
</authors>
<title>Research and Development of an Electronic Dictionary&amp;quot;,</title>
<date>1987</date>
<journal>Machine Translation Summit</journal>
<pages>61--64</pages>
<contexts>
<context position="2692" citStr="Kakizaki 1987" startWordPosition="386" endWordPosition="387">ve actions&amp;quot; (Schank 1975). These semantic representation theories have been reviewed and used in developing practical natural language processing systems (Nagao 1985, etc.). As such development of practical natural language processing systems progressed, the importance of accumulating lexical descriptions became recognized by developers of such systems. That is, a dictionary large enough in terms of both the granularity of semantic markers and the number of words or word senses became necessary to build. Against the background of the situation, the development of the Concept Dictionary began (Kakizaki 1987, Yokoi et. al. 1989, Uchida, 1990, Miike et. al. 1990a). The methodology of development of 206 the Concept Dictionary, which consists of a) concept descriptions, which represent dependencies among concepts and categories, and b) the concept taxonomy, which represent super-sub relations among concepts, is described in sections 2 and 3. Preference knowledge, which represents preference order of concept descriptions, is explained in section 4. In section 5, spheres of applications and limitations of the dictionary are discussed. 2. Development of Concept Descriptions Concept relations are descri</context>
</contexts>
<marker>Kakizaki, 1987</marker>
<rawString>Kakizaki, N. (1987) &amp;quot;Research and Development of an Electronic Dictionary&amp;quot;, Machine Translation Summit pp.61-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Katz</author>
<author>J A Fodor</author>
</authors>
<title>The Structure of a Semantic Theory&amp;quot;,</title>
<date>1963</date>
<journal>Language</journal>
<volume>39</volume>
<pages>170--210</pages>
<contexts>
<context position="1798" citStr="Katz and Fodor 1963" startWordPosition="249" endWordPosition="252">ionary is based on several linguistic semantic representation theories. For a long time, a series of trials for describing dependencies among words or word senses by bundling verbs, adjectives, etc., has been conducted. Establishing a deep case level and using a formalism independent of each language, Fillmore developed a theory of representation of dependency among words (Fillmore 1968). On the other hand, Fodor and Katz explained a mechanism of selecting interpretations of constituents in a sentence by using a formalism composed of a semantic marker, distinguisher and selection restriction (Katz and Fodor 1963). In contrast to these theories, Wilks proposed a point of view to consider word dependency not as a constraint but as a preference (Wilks 1975). In addition, Schank proposed to abstract connotations not only from senses of nouns but also those of verbs, and he named them &amp;quot;primitive actions&amp;quot; (Schank 1975). These semantic representation theories have been reviewed and used in developing practical natural language processing systems (Nagao 1985, etc.). As such development of practical natural language processing systems progressed, the importance of accumulating lexical descriptions became recog</context>
</contexts>
<marker>Katz, Fodor, 1963</marker>
<rawString>Katz, J.J. and Fodor, J.A. (1963) -The Structure of a Semantic Theory&amp;quot;, Language 39, pp.170-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakofff</author>
</authors>
<title>Stative Adjectives and Verbs in English&amp;quot;,</title>
<date>1966</date>
<journal>Mathematical Linguistics and Automatic Translation</journal>
<volume>17</volume>
<pages>1--16</pages>
<marker>Lakofff, 1966</marker>
<rawString>Lakofff G. (1966) &amp;quot;Stative Adjectives and Verbs in English&amp;quot;, Mathematical Linguistics and Automatic Translation 17, pp.1-16, Report to the National Science Foundation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Lenat</author>
<author>R V Guha</author>
</authors>
<title>Building Large Knowledge-Based Systems,</title>
<date>1989</date>
<pages>160--162</pages>
<publisher>Addison-Wesley Publishing Company. Inc.,</publisher>
<marker>Lenat, Guha, 1989</marker>
<rawString>Lenat, D.B. and Guha, R.V. (1989) Building Large Knowledge-Based Systems, Addison-Wesley Publishing Company. Inc., pp. 160-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M</author>
</authors>
<title>An Algorithm of Word Clustering from Co-occurrence Data Using DM Decomposition ard Statistical Estimation&amp;quot;.</title>
<date>1989</date>
<journal>Information Processing Society of Japan,</journal>
<pages>72--9</pages>
<marker>M, 1989</marker>
<rawString>Matsukawa, T., Nakamura, J. and Nagao. M. (1989) &amp;quot;An Algorithm of Word Clustering from Co-occurrence Data Using DM Decomposition ard Statistical Estimation&amp;quot;. Information Processing Society of Japan, NL-72-9,</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Matsukawa</author>
<author>Y Kishimoto</author>
<author>S Yokota Miike</author>
<author>E Takai</author>
<author>S</author>
<author>S Amano</author>
</authors>
<title>Construction of a Hierarchical Concept Classification Based On Compaction of Concept Descriptions&amp;quot;,</title>
<date>1990</date>
<journal>Information Processing Society of Japan,</journal>
<pages>78--6</pages>
<marker>Matsukawa, Kishimoto, Miike, Takai, S, Amano, 1990</marker>
<rawString>Matsukawa, T., Kishimoto, Y., Miike, S.. Yokota, E., Takai, S. and Amano, S. (1990a) &amp;quot;Construction of a Hierarchical Concept Classification Based On Compaction of Concept Descriptions&amp;quot;, Information Processing Society of Japan, NL-78-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H</author>
<author>S Amano</author>
</authors>
<title>Basic Functions of the Environment for Binary Relation Categorization&amp;quot;,</title>
<date>1990</date>
<booktitle>Proceedings of 4Ith Conference of Information Processing Society of Japan. 7S-7.</booktitle>
<marker>H, Amano, 1990</marker>
<rawString>Matsulcawa, T., Nakazawa, M.. Adachi. H. and Amano, S. (1990b) &amp;quot;Basic Functions of the Environment for Binary Relation Categorization&amp;quot;, Proceedings of 4Ith Conference of Information Processing Society of Japan. 7S-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miike</author>
<author>S Amano</author>
<author>H Uchida</author>
<author>T Yokoi</author>
</authors>
<title>The Structure and Function of the EDR Concept Dictionary&amp;quot;.</title>
<date>1990</date>
<booktitle>TKE &apos;90: Terminology and Knowledge Engineering,</booktitle>
<publisher>VERLAG.</publisher>
<location>Frankfurt.</location>
<marker>Miike, Amano, Uchida, Yokoi, 1990</marker>
<rawString>Miike, S., Amano, S., Uchida, H. and Yokoi, T. (1990a) &amp;quot;The Structure and Function of the EDR Concept Dictionary&amp;quot;. TKE &apos;90: Terminology and Knowledge Engineering, Frankfurt. 1NDEKS VERLAG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miike</author>
</authors>
<title>How to Define Concepts for Electronic Dictionaries&amp;quot;,</title>
<date>1990</date>
<booktitle>Proceedings of International Workshop on Electronic Dictionaries,</booktitle>
<pages>43--49</pages>
<institution>Japan Electronic Dictionary Research Institute, Ltd.</institution>
<location>Tokyo, Japan,</location>
<marker>Miike, 1990</marker>
<rawString>Miike, S. (1990b) &amp;quot;How to Define Concepts for Electronic Dictionaries&amp;quot;, Proceedings of International Workshop on Electronic Dictionaries, pp. 43-49. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo, Japan,</rawString>
</citation>
<citation valid="true">
<authors>
<author>J</author>
</authors>
<title>The Japanese Government Project for Machine Translation&amp;quot;,</title>
<date>1985</date>
<journal>Computational Linguistics, Vol</journal>
<volume>11</volume>
<pages>2--3</pages>
<location>April-September.</location>
<marker>J, 1985</marker>
<rawString>Nagao, M., Tsujii, J. and Nakamura. J. (1985) &amp;quot;The Japanese Government Project for Machine Translation&amp;quot;, Computational Linguistics, Vol 11, Numbers 2-3, April-September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Nakao</author>
<author>Y Momiyama</author>
</authors>
<title>Word Clustering by Word Bindings,&amp;quot;</title>
<date>1988</date>
<journal>Information Processing Society of Japan,</journal>
<pages>65--1</pages>
<marker>Nakao, Momiyama, 1988</marker>
<rawString>Nakao, Y. and Momiyama, Y. (1988) &amp;quot;Word Clustering by Word Bindings,&amp;quot; Information Processing Society of Japan, NL-65-1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Nakao</author>
<author>H Uchida</author>
</authors>
<title>Corpus for Developing Dictionary,&amp;quot;</title>
<date>1990</date>
<booktitle>Euralex 4th International Congress.</booktitle>
<marker>Nakao, Uchida, 1990</marker>
<rawString>Nakao, Y. and Uchida, H. (1990a) &amp;quot;Corpus for Developing Dictionary,&amp;quot; Euralex 4th International Congress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Nakao</author>
</authors>
<title>How to Extract Dictionary Data from the EDR Copus&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of International Workshop on Electronic Dictionaries,</booktitle>
<tech>TR-031,</tech>
<pages>58--62</pages>
<institution>Japan Electronic Dictionary Research Institute, Ltd.</institution>
<location>Tokyo, Japan.</location>
<contexts>
<context position="4994" citStr="Nakao 1990" startWordPosition="692" endWordPosition="693">d —&lt;modify&gt;–• c#still c#fluid —&lt;object&gt;–• Othe_UN c#fluid —&lt;modify&gt;–* c#structurally cttmembership —&lt;object&gt;— dtenlarge cftmembership —&lt;modify&gt;–• c#its c#bring —&lt;goal&gt;--• c#bear c#pressure —&lt;object&gt;— c#bring c#vulnerable —&lt;and&gt;— ctftluid c#vulnerable —&lt;modify&gt;— c#still c#vulnerable —&lt;object&gt;— ctithe_U.N c#vulnerable —&lt;modify&gt;— c#structurally As shown above, concept-concept relation descriptions are extracted directly from the semantic analysis section (and word sense selection section) in the EDR Corpus. A method of collecting and selecting source sentences for the EDR corpus is described in (Nakao 1990a) and a method of extracting concept descriptions from the EDR corpus is explained in detail in (Nakao 1990b). Source texts of the EDR corpus are selected so as to diversify as much as possible the concepts in them. However, it is impossible to collect all concepts or concept relations from the corpus even if the amount of texts is very large. To compensate for the shortage of examples, we also create example sentences and analyze them lexically and semantically. Concept-concept relation descriptions are also extracted from the sentences. 207 «Text No : 00040000187d : 6/13/90 from e0327003.ya</context>
</contexts>
<marker>Nakao, 1990</marker>
<rawString>Nakao, Y. (1990b) &amp;quot;How to Extract Dictionary Data from the EDR Copus&amp;quot;. Proceedings of International Workshop on Electronic Dictionaries, pp. 58-62. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nawata</author>
<author>M</author>
<author>H Uchida</author>
</authors>
<title>Verb Classification Based On the Semantic Relation of Co-occurring Elements&amp;quot;,</title>
<date>1989</date>
<booktitle>Information Processing Society of Japan.</booktitle>
<pages>71--2</pages>
<publisher>North-Holland.</publisher>
<marker>Nawata, M, Uchida, 1989</marker>
<rawString>Ogino, T., Yamamoto, Y. Kiyono. M, Nawata, M. and Uchida. H. (1989) &amp;quot;Verb Classification Based On the Semantic Relation of Co-occurring Elements&amp;quot;, Information Processing Society of Japan. NL-71-2. Schank, R. C. (1975). Conceptual Information Processing, North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H</author>
<author>T Yokoi</author>
</authors>
<title>Development of the EDR Concept Dictionary&amp;quot;,</title>
<date>1991</date>
<booktitle>Second Workshop of Japan-United Kingdom Bilateral Cooperative Research Programme on Computational Linguistics, UMIST.</booktitle>
<marker>H, Yokoi, 1991</marker>
<rawString>Tominaga, M., Miike, S., Uchida. H. and Yokoi, T. (1991) &amp;quot;Development of the EDR Concept Dictionary&amp;quot;, Second Workshop of Japan-United Kingdom Bilateral Cooperative Research Programme on Computational Linguistics, UMIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H</author>
</authors>
<title>Electronic Dictionary&amp;quot;,</title>
<date>1990</date>
<booktitle>Proceedings of International Workshop on Electronic Dictionaries,</booktitle>
<pages>23--42</pages>
<institution>Japan Electronic Dictionary Research Institute, Ltd.</institution>
<location>Tokyo, Japan.</location>
<marker>H, 1990</marker>
<rawString>Uchida. H. (1990) &amp;quot;Electronic Dictionary&amp;quot;, Proceedings of International Workshop on Electronic Dictionaries, pp. 23-42. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Preference Semantics&amp;quot;,</title>
<date>1975</date>
<booktitle>Formal Semantics of Natural Language,</booktitle>
<pages>329--348</pages>
<editor>in Keenan, Edward L. (ed.),</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="1942" citStr="Wilks 1975" startWordPosition="276" endWordPosition="277">rd senses by bundling verbs, adjectives, etc., has been conducted. Establishing a deep case level and using a formalism independent of each language, Fillmore developed a theory of representation of dependency among words (Fillmore 1968). On the other hand, Fodor and Katz explained a mechanism of selecting interpretations of constituents in a sentence by using a formalism composed of a semantic marker, distinguisher and selection restriction (Katz and Fodor 1963). In contrast to these theories, Wilks proposed a point of view to consider word dependency not as a constraint but as a preference (Wilks 1975). In addition, Schank proposed to abstract connotations not only from senses of nouns but also those of verbs, and he named them &amp;quot;primitive actions&amp;quot; (Schank 1975). These semantic representation theories have been reviewed and used in developing practical natural language processing systems (Nagao 1985, etc.). As such development of practical natural language processing systems progressed, the importance of accumulating lexical descriptions became recognized by developers of such systems. That is, a dictionary large enough in terms of both the granularity of semantic markers and the number of w</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks, Y. (1975). &amp;quot;Preference Semantics&amp;quot;, in Keenan, Edward L. (ed.), Formal Semantics of Natural Language, Cambridge University Press, pp.329-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Amano</author>
<author>S</author>
<author>M Kiyono</author>
</authors>
<title>Research and</title>
<date>1989</date>
<booktitle>Development of Large-Scale Electronic Dictionaries -Current Status of the EDR Project&amp;quot;, Australian-Japanese Joint Symposium on Natural Language Processing.</booktitle>
<marker>Amano, S, Kiyono, 1989</marker>
<rawString>Yokoi, T., Uchida. H., Amano, S. and Kiyono, M. (1989) &amp;quot;Research and Development of Large-Scale Electronic Dictionaries -Current Status of the EDR Project&amp;quot;, Australian-Japanese Joint Symposium on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Yokota</author>
</authors>
<title>How to Organize a Concept Hierarchy&amp;quot;,</title>
<date>1990</date>
<booktitle>Proceedings of International Workshop on Electronic Dictionaries,</booktitle>
<pages>50--57</pages>
<institution>Japan Electronic Dictionary Research Institute, Ltd.</institution>
<location>Tokyo, Japan.</location>
<contexts>
<context position="27916" citStr="Yokota 1990" startWordPosition="3790" endWordPosition="3791">tered by using an optimal scaling or using DM-decomposition and a probability-based estimation and the gained clusters are asserted as concept-category relation descriptions into the Concept Dictionary. The clustering algorithms are explained in detail in (Nakao 1988, Matsukawa 1989). 8) Reconstruction of the concept taxonomy Category-category relation descriptions are clustered and hierachized by using DM-decomposition and set-relation calculations in order to bundle the descriptions into higher level categories. The hierachization algorithm is explained in detail in (Matsukawa 1990a, 1990b, Yokota 1990). 4 Preference Knowledge All concepts, categories and concept descriptions have an ID number called concept ID. Knowledge for ordering input sentence interpretations given by using the Concept Dictionary are represented by data individually expressing the order of the concept IDs that co-occur with each word pronunciation, word and concept, respectively (preference knowledge). We use the following three methods for ordering concept IDs: a) Linear lists of concept IDs b) Association lists of concept IDs and the concept IDs&apos; preference value C) Directed graphs including arcs meaning preference r</context>
</contexts>
<marker>Yokota, 1990</marker>
<rawString>Yokota, E. (1990) &amp;quot;How to Organize a Concept Hierarchy&amp;quot;, Proceedings of International Workshop on Electronic Dictionaries, pp. 50-57. TR-031, Japan Electronic Dictionary Research Institute, Ltd. Tokyo, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>