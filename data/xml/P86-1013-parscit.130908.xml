<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.661831" genericHeader="abstract">
PARSING CONJUNCTIONS DETERMINISTICALLY
</sectionHeader>
<note confidence="0.548983">
Donald W. Kosy
</note>
<title confidence="0.576749666666667">
The Robotics Institute
Carnegie-Mellon University
Pittsburgh, Pennsylvania 15213
</title>
<sectionHeader confidence="0.945522" genericHeader="keywords">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.998688">
Conjunctions have always been a source of problems for natural
language parsers. This paper shows how these problems may be
circumvented using a rule-based, wait-and-see parsing strategy.
A parser is presented which analyzes conjunction structures
deterministically, and the specific rules it uses are described and
illustrated. This parser appears to be faster for conjunctions than
other parsers in the literature and some comparative timings are
given.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9672215">
In recent years, there has been an upsurge of interest in tech-
niques for parsing sentences containing coordinate conjunctions
(and, or and but) [1,2,3,45,8,9]. These techniques are intended
to deal with three computational problems inherent in conjunc-
tion parsing:
1. Since virtually any pair of constituents of the same
syntactic type may be conjoined, a grammar that ex-
plicitly enumerates all the possibilities seems need-
lessly cluttered with a large number of conjunction
rules.
2. If a parser uses a top-down analysis strategy (as is
common with ATN and logic grammars), it must
hypothesize a structure for the second conjunct with-
out knowledge of its actual structure. Since this
structure could be any that parallels some con-
stituent that ends at the conjunction, the parser must
generate and test all such possibilities in order to find
the ones that match. In practice, the combinatorial
explosion of possibilities makes this slow.
3. It is possible for a conjunct to have &amp;quot;gaps&amp;quot; (ellipsed
elements) which are not allowed in an unconjoined
constituent of the same type. These gaps must be
filled with elements from the other conjunct for a
proper interpretation, as in: / gave Mary a nickel and
Harry a dime.
The paper by Lesmo and Torasso [9] briefly reviews which tech-
niques apply to which problems before presenting their own ap-
proach.
Two papers in the list above [1,3] present deterministic, &amp;quot;wait-
and-see&amp;quot; methods for conjunction parsing. In both, however, the
discussion centers around the theory and feasibility of parsers
that obey the Marcus determinism hypothesis [10] and operate
with a limited-length lookahead buffer. This paper examines the
other side of the coin, namely, the practical power of the wait-
and-see approach compared to strictly top-down or bottom-up
methods. A parser is described that analyzes conjunction struc-
tures deterministically and produces parse trees similar to those
produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster
than either MSG or Fong &amp; Berwick&apos;s RPM device [5], and com-
parative timings are given. We conclude with some descriptive
comparisons to other systems and a discussion of the reasons
behind the performance observed.
</bodyText>
<sectionHeader confidence="0.990743" genericHeader="method">
OVERVIEW OF THE PARSER
</sectionHeader>
<bodyText confidence="0.997479285714286">
For the sake of a name, we will call the parser NEXUS since it
is the syntactic component of a larger system called NEXUS. This
system is being developed to study the problem of learning tech-
nical concepts from expository text. The acronym stands for
Non-Expert Understanding System.
NEXUS is a direct descendent of READER, a parser written by
Ginsparg at Stanford in the late 1970&apos;s [6]. Like all wait-and-see
parsers, it incorporates a stack to hold constituent structures
being built, some variables that record the state of the parse, and
a set of transition rules that control the parsing process. The
stack structures and state variables in NEXUS are almost the
same as in READER, but the rules have been rewritten to make
them cleaner, more transparent, and more complete.
There are two categories of rules. Segmentation rules are
responsible for finding the boundaries of constituents and creat-
ing stack structures to store these results. Recombination rules
are responsible for attaching one structure to another in syntac-
tically valid ways. Segmentation operations are separate from,
and always precede, recombination operations. All the rules are
encoded in Lisp; there is no separate rule interpreter.
Segmentation rules take as input a word from the input sen-
tence and a partial-parse of the sentence up to that word. The
rules are organized into procedures such that each procedure
implements those rules that apply to one syntactic word class.
When a rule&apos;s conditions are met, it adds the input word to the
partial-parse, in a way specified in the rule, and returns the new
partial-parse as output.
A partial-parse has three parts:
</bodyText>
<listItem confidence="0.723315272727273">
1. The stack: A stack (not a tree) of the data structures
which encode constituents. There are two types of
structures in the stack, one type representing clause
nuclei (the verb group, noun phrase arguments, and
adverbs of a clause), and the other representing
prepositional phrases. Each structure consists of a
collection of slots to be filled with constituents as the
parse proceeds.
2. The message (MSG): A symbol specifying the last
action performed on the stack. In general, this sym-
bol will indicate the type of slot the last input word
</listItem>
<page confidence="0.994932">
78
</page>
<bodyText confidence="0.967458333333333">
was inserted in.
3. The stack-message (MSG1): A list of properties of
the stack as a whole (e.g. the sentence is imperative).
The various types of slots comprising stack structures are defined
in Figure 1. VERB, PREP, ADV, NOTE, and FUNCTION slots are
filled during segmentation, while CASES and MEASURE slots are
added during recombination. NP slots are filled with noun
phrases during segmentation but may subsequently be aug-
mented by post-modifiers during recombination.
</bodyText>
<listItem confidence="0.757119">
• collapse the stack so that a structure below the top
becomes the new top
</listItem>
<bodyText confidence="0.9798579375">
. modify a slot in the top structure based on the infor-
mation provided by W
In addition, a rule will generally change the MSG variable, and
may insert or delete items in the list of stack messages.
The way the rules work is best shown by example. Suppose
the input is:
The children wore the socks on their hands.
The segmentation NEXUS performs appears in Fig. 2a. On the
left are the words of the sentence and their possible syntactic
classes. The contribution each word makes to the development
of the parse is shown to the right of the production symbol &amp;quot;= &gt;&amp;quot;.
We will draw the stack upside down so that successive parsing
states are reached as one reads down the page. The contents of
a stack structure are indicated by the accumulation of slot values
between the dashed-line delimiters (&amp;quot; &amp;quot;). Empty slots are not
shown.
</bodyText>
<figure confidence="0.661768125">
CLAUSES PREPOSITION STRUCTURES
VERB: verb phrase PREP: preposition
ADV: adverbs ADV: adverbs
NP1,NP2,NP3: noun phrases NP: noun phrase
NOTE: notes NOTE: notes
FUNCTION: clause function
MEASURE: rating MEASURE: rating
CASES: adjuncts
DEFINITIONS
Clause function
Hypothesized role of the clause in the sentence, e.g. main,
relative clause, infinitive adjunct, etc.
Notes
Segmentation rules can leave notes about a structure that will be
used in later processing.
Rating
</figure>
<figureCaption confidence="0.316396333333333">
A numerical measure of the syntactic and semantic acceptability
of the structure to be used in choosing between competing
possible parses.
</figureCaption>
<subsectionHeader confidence="0.829274">
Adjuncts
</subsectionHeader>
<bodyText confidence="0.9724665">
The prepositional phrases and subordinate clauses that turn out
to be adjuncts to this clause.
</bodyText>
<figureCaption confidence="0.994187">
Figure 1: Stack Structures
</figureCaption>
<bodyText confidence="0.987254615384615">
An English rendering of some segmentation rules for various
word classes is given in the Appendix. The tests in a rule depend
on the current word, the messages, and various properties of
structures in the/stack at the time the tests are made. As each
word is taken tom the input stream, all rules in its syntactic
class(es) are tried, in order, using the current partial parse. All
rules that succeed are executed. However, if the execution of
some rule stipulates a return, subsequent rules for that class are
ignored.
The actions a rule can take are of five main types. For a given
input word W, a rule can:
. continue filling a slot in the top stack structure by
inserting W
</bodyText>
<listItem confidence="0.983243666666667">
• begin filling a new slot in the top structure
. push a new structure onto the stack and begin filling
one of its slots
</listItem>
<bodyText confidence="0.814960636363636">
Input Word
Word Class MSG1 MSG Stack
-- -- nil BEGIN FUNCTION: MAIN
the A =&gt; ni NOUN NP1: the
children N =) ni NOUN NP1&apos;: the children
wore V =) ni VERB VERB: wore
the A =&gt; ni NOUN NP2: the
socks N,V =&gt; ni NOUN NP2&apos;: the socks
on P =&gt; ni PREP PREP: on
their N =&gt; ni NOUN NP: their
hands N,V =&gt; ni NOUN NP&apos;: their hands
</bodyText>
<figure confidence="0.9919115">
a. Segmentation
{wear PN
ISUB the children]
OBJ the socks]
ON their hands])
b. Recombination
</figure>
<figureCaption confidence="0.999977">
Figure 2: Parse of The children wore the socks on their hands
</figureCaption>
<bodyText confidence="0.999895722222222">
Before parsing begins, the three parts of a partial-parse are
initialized as shown on the first line. One structure is prestored in
the stack (it will come to hold the main clause of the input
sentence), the message is BEGIN, and MSG1 is empty. The pars-
ing itself is performed by applying the word class rules for each
input word to the partial-parse left after processing the previous
word. For example, before the word wore is processed,
MSG = NOUN, MSG1 is empty, and the stack contains one clause
with FUNCTION = MAIN and NP1 = the children. Wore is a verb
and so the Verb rules are tried. The third rule is found to apply
since there is a clause in the stack meeting the conditions. This
clause is the top one so there is no collapse. (Collapse performs
recombination and is described below.) The word wore is in-
serted in the VERB slot, MSG is set, and the rule returns the new
partial-parse.
It is possible for the segmentation process to yield more than
one new partial-parse for a given input word. This can occur in
two ways. First, a word may belong to several syntactic classes
</bodyText>
<page confidence="0.991447">
79
</page>
<bodyText confidence="0.976601596491228">
and when this is so, NEXUS tries the rules for each class. If rules
in more than one class succeed, more than one new partial-parse
is produced. As it happens, the two words in the example that are
both nouns and verbs do not produce more than one partial.
parse because the Verb rules don&apos;t apply when they are
processed. Second, a word in a given class can often be added
to a partial-parse in more than one way. The third and fifth Verb
rules, for example, may both be applicable and hence can
produce two new partial-parses. In order to keep track of the
possibilities, all active partial-parses are kept in a list and NEXUS
adds new words to each in parallel. The main segmentation con-
trol loop therefore has the following form:
For each word w in the input sentence do
For each word class C that w belongs to do
For each partial parse P in the list do
Try the C rules given w and P
Loop
Loop
Store all new partial-parses in the list
Loop
In contrast to segmentation rules, which add structures to a
partial-parse stack, recombination rules reduce a stack by joining
structures together. These rules specify the types of attachment
that are possible, such as the attachment of a post-modifier to a
noun phrase or the attachment of an adjunct to a clause. The
successful execution of a rule produces a new structure, with the
attachment made, and a rating of the semantic acceptability of
the attachment. The ratings are used to choose among different
attachments if more than one is syntactically possible.
There are three rating values -- perfect, acceptable, and un-
acceptable -- and these are encoded as numbers so that there
can be degrees of acceptability. When one structure is attached
to another, its rating is added to the rating of the attachment and
the sum becomes the rating of the new (recombined) structure. A
structure&apos;s rating thus reflects the ratings of all its component
constituents. Although NEXUS is designed to call upon an inter-
preter module to supply the ratings, currently they must be sup-
plied by interaction with a human interpreter. Eventually, we ex-
pect to use the procedures developed by Hirst [7]. There is also a
&apos;no-interpreter&apos; switch which can be set to give perfect ratings to
clause attachment of right-neighbor prepositional phrases, and
noun phrase (&amp;quot;low&amp;quot;) attachment of all other post-modifiers.
The order in which attachments are attempted is controlled by
the collapse procedure. Collapse is responsible for assem-
bling an actual parse tree from the structures in a stack. After
initializing the root of the tree to be the bottom stack structure,
the remaining structures are considered in reverse stack order so
that the constituents will be added to the tree in the order they
appeared (left to right). For each structure, an attempt is made to
attach it to some structure on the right frontier of the tree, starting
at the lowest point and proceeding to the highest. (Looking only
at the right frontier enforces the no-crossing condition of English
grammar.1 ) If a perfect attachment is found, no further pos-
sibilities are considered. Otherwise, the highest-rated attachment
is selected and collapse goes on to attach the next structure. If
no attachment is found, the input is ungrammatical with respect
to the specifications in the recombination rules.
</bodyText>
<tableCaption confidence="0.4220558">
1The no-crossing condition says that one constituent cannot be attached to a
non-neighboring constituent without attaching the neighbor first. For instance, if
constituents are ordered A, B, and C, then C cannot be attached to A unless B is
attached to A first. Furthermore, this implies that if B and C are both attached to
A, B is closed to further attachments.
</tableCaption>
<bodyText confidence="0.998770263157895">
After a stack has been collapsed, a formatting procedure is
called to produce the final output. This procedure is primarily
responsible for labeling the grammatical roles played by NPs and
for computing the tense of VERBs. It is also responsible for in-
serting dummy nouns in NP slots to mark the position of &amp;quot;wh-
gaps&amp;quot; in questions and relative clauses.
Figure 2b shows the tree NEXUS would derive for the ex-
ample. The code PN indicates past tense, and the role names
should be self-explanatory. During collapse, the interpreter
would be asked to rate the acceptability of each noun phrase by
itself, the acceptability of the clause with the noun phrases in it,
and the acceptability of the attachment. The former ratings are
necessary to detect mis-segmented constituents, e.g., to
downgrade &amp;quot;time flies&amp;quot; as a plausible subject for the sentence
Time flies like an arrow. By Hirst&apos;s procedure, the last rating
should be perfect for the attachment of the on-phrase to the
clause as an adjunct since, without a discourse context, there is
no referent for the socks on their hands and the verb wear ex-
pects a case marked by on.
</bodyText>
<sectionHeader confidence="0.996592" genericHeader="method">
CONJUNCTION PARSING
</sectionHeader>
<bodyText confidence="0.997043">
To process and and or, we need to add a coordinate conjunc-
tion word class (C) and three segmentation rules for it.2
</bodyText>
<listItem confidence="0.961673428571429">
1. If MSG = BEGIN,
Push a clause with FUNCTION = w onto stack.
Set MSG = CONJ and return.
2. If the topmost nonconjunct clause in the stack has VERB filled,
Push a clause with FUNCTION = w onto stack.
Set MSG = CONJ and return.
3. Otherwise,
</listItem>
<bodyText confidence="0.6927207">
Push a preposition structure with PREP = w onto stack.
Set MSG = PREP and return.
The first rule is for sentence-initial conjunctions, the second for
potential clausal conjuncts and the third is for cases where the
conjunction cannot join clauses. This last case arises when noun
phrases are conjoined in the subject of a sentence: John and
Mary wore socks. Note that the stack structure for a noun phrase
conjunct is identical to that for a prepositional phrase.
To handle gaps, we also need to add one rule each to the
Noun and Verb procedures. For Verb, the rule is:
</bodyText>
<listItem confidence="0.553809">
4. If MSG = CONJ,
</listItem>
<bodyText confidence="0.856615">
Set NP1 = !sub, VERB = w in top structure.
Set MSG = VERB and return.
</bodyText>
<listItem confidence="0.7537695">
For Noun:
5. If the top structure S is a clause conjunct with NP1 filled but
no VERB and there is another clause C in the stack with VERB
filled and more than one NG filled,
</listItem>
<bodyText confidence="0.843877666666667">
Copy VERB filler from C to S&apos;s VERB slot
If C has NP3 filled,
Transfer S&apos;s NP1 to NP2 and set S&apos;s NP1 = !sub.
Insert was new NG in S.
Set MSG = NOUN and return.
In both rules, !sub is a dummy placeholder for the subject of the
</bodyText>
<footnote confidence="0.802851666666667">
2The conjunction but is not syntactically interchangeable with and and or since
but cannot freely conjoin noun phrases: &apos;John but Mary wore socks. The rules
for but have not yet been developed.
</footnote>
<page confidence="0.994921">
80
</page>
<bodyText confidence="0.999734461538462">
clause. Rule 4 is for verbs that appear directly after a conjunction
and rule 5 is for transitive or ditransitive conjuncts with gapped
verb.
To specify attachments for conjuncts, we need some recom-
bination rules. In general, elements to be conjoined must have
very similar syntactic structure. They must be of the same type
(noun phrase, clause, prepositional phrase, etc.). If clauses, they
must serve the same function (top level assertion, infinitive, rela-
tive clause, etc.), and if non-finite clauses, any ellipsed elements
(wh-gaps) must be the same. If these conditions are met, an
attachment is proposed.
Additionally, in three situations, a recombination rule may also
modify the right conjunct:
</bodyText>
<listItem confidence="0.919920384615385">
1. A clause conjunct without a verb can be proposed as
a noun phrase conjunct.
2. A clause conjunct without a verb may also be
proposed as a gapped verb, as in: Bob saw Sue in
Paris and [Bob saw] Linda in London.
3. When constituents from the left conjunct are ellipsed,
they may have to be taken from the right conjunct, as
in the famous sentence: John drove through and
completely demolished a plate glass window. This
transformation is actually implemented in the final
formatting procedure since all of the trailing cases in
the right conjunct must be moved over to the left con-
junct if any such movement is warranted.
</listItem>
<bodyText confidence="0.959249571428571">
Since all these situations are structurally ambiguous, the inter-
preter is always called to rate the modifications. In situation 2, for
instance, it may be that there is no gap: Bob saw Sue in (Paris
and London) in the spring of last year. In situation 3, the gapped
element might come from context, rather than the right conjunct:
Ignoring the stop sign at the intersection, John drove through and
completely demolished his reputation as a safe driver. Hence,
only interpretation can determine which choice is most ap-
propriate.
Let us now examine how these rules operate by tracing
through a few examples. First, suppose the sentence from the
previous section were to continue with the words &amp;quot;and their feet&amp;quot;.
Rule 2 would respond to the conjunction, and the rest of the
segmentation would be:
</bodyText>
<table confidence="0.551466">
Input Word
Word Class MSG1 MSG Stack
and &gt; nil CONJ FUNCTION: AND
their = &gt; nil NOUN NP1: their
feet &gt; nil NOUN NP1&apos;: their feet
</table>
<bodyText confidence="0.899083357142857">
Thus, the noun rules would do what they normally do in filling the
first NP slot in a clause structure. If the sentence ended here,
recombination would conjoin the last two noun phrases, &amp;quot;their
hands&amp;quot; and &amp;quot;their feet&amp;quot;, as the complement of on, producing:
{wear PN
1 SUB the children]
OBJ the socks]
ON their hands (AND their feet)])
If, instead, the sentence did not end but continued with a verb
-- &amp;quot;froze&amp;quot;, say -- the segmentation would continue by adding this
word to the VERB slot in the top structure, which is open. As
before, the rules would do what they normally do to fill a slot.
Recombination would yield conjoined clauses:
{wear PN
</bodyText>
<note confidence="0.5271292">
ISUB the children]
OBJ the socks]
ON their hands]
AND (V freeze PN
[SUB their feet]))
</note>
<bodyText confidence="0.9704612">
Notice that the second clause is inserted as just another case
adjunct of the first clause. There is really no need to construct a
coordinate structure (wherein both clauses would be dominated
by the conjunction) since it adds nothing to the interpretation.
Moreover, as Dahl &amp; McCord point out [4], it is actually better to
preserve the subordination structure because it provides essen-
tial information for scoping decisions.
Now we move on to gaps. Consider a new right conjunct for
our original example sentence in which the subject is ellipsed:
The children wore the socks on their hands end froze their feet.
</bodyText>
<figure confidence="0.882681444444444">
Rule 4 would detect the gap and the resulting segmentation
would be:
Input Word
Word Class MSG1 MSG Stack
and C =) nil CONJ FUNCTION: AND
froze V = &gt; nil VERB NP1: !sub
VERB: froze
their N =&gt; nil NOUN NP2: their
feet N =&gt; nil NOUN NP2&apos;: their feet
Recombination would yield conjoined clauses with shared sub-
ject
{wear PN
ISUB the children]
OBJ the socks]
ON their hands]
AND (V freeze PN
[SUB !sub]
[OBJ their feed))
</figure>
<bodyText confidence="0.993618666666667">
The appearance of !sub in the second SUB slot tells the inter-
preter that the subject of the right conjunct is coreferential with
the subject of the left conjunct.
Finally, to illustrate rule 5, consider the sentence:
The children wore the socks on their hands and
John a lampshade on his head.
When the parser comes to &amp;quot;a&amp;quot;, rule 5 applies, the verb wore is
copied over to the second conjunct, and &amp;quot;a&amp;quot; is inserted into NP2.
Thus, the segmentation of the conjunct clause looks like this:
</bodyText>
<table confidence="0.593628222222222">
Input Word MSG1 MSG Stack
Word Class .&gt; nil CONJ FUNCTION: AND
and nil NOUN NP1: John
John .&gt; nil NOUN VERB: wore
a A =&gt; nil NOUN NP2: a
lampshade N =&gt; nil PREP NP2&apos;: a lampshade
on .&gt; nil NOUN PREP: on
his .&gt; nil NOUN NP: his
head N,V NP&apos;: his head
</table>
<footnote confidence="0.402986">
Recombination would produce the conjunction of two complete
clauses with no shared material.
</footnote>
<page confidence="0.998859">
81
</page>
<sectionHeader confidence="0.996342" genericHeader="evaluation">
RESULTS
</sectionHeader>
<bodyText confidence="0.993339">
Using the rules described above, NEXUS can successfully
parse all the conjunction examples given in all the papers, with
two exceptions. It cannot parse:
</bodyText>
<listItem confidence="0.99070625">
• conjoined adverbs, e.g., Slowly and stealthily, he
crept toward his victim.
• embedded clausal complement gaps, e.g., Max wants
to try to begin to write a novel and Alex a play.
</listItem>
<bodyText confidence="0.984883819444444">
The problem with these forms lies not so much in the conjunction
rules as in the rules for adverbs and clausal complements in
general. These latter rules simply aren&apos;t very well developed yet.
It is instructive to compare the NEXUS parser to that of Lesmo
&amp; Torasso. Like theirs, NEXUS solves the first problem men-
tioned in the introduction by using transition rules rather than a
more conventional declarative grammar. Also like theirs, NEXUS
solves the third problem by means of special rules which detect
gaps in conjuncts and which fill those gaps by copying con-
stituents from the other conjunct. Unlike theirs, however, NEXUS
delays recombination decisions as long as it can and so does not
have to search for possible attachments in some situations where
theirs does. For instance, in processing
Henry repeated the story John told Mary and Bob
told Ann his opinion.
their parser would first mis-attach [and Bob] to [Mary], then mis-
attach [and Bob told Ann] to [John told Mary]. Each time, a
search would be made to find a new attachment when the next
word of the input was read. NEXUS can parse this sentence
successfully without any mis-attachments at all.
It is also instructive to compare NEXUS to the work of Church.
His thesis [3] gives a detailed specification of a some fairly
elegant rules for conjunction (and several other constructions)
along with their linguistic and psycholinguistic justification. While
most of the rules are not actually exhibited, their specification
suggests that they are similar in many ways to those in NEXUS.
However, Church was primarily concerned with the implications
of determinism and limited memory, and so his parser, YAP, does
not defer decisions as long as NEXUS does. Hence, YAP could
not find, or ask for resolution of, the ambiguity in a sentence like:
I know Bob and Bill lett. YAP parses this as [I know Bob] and [Bill
left]. NEXUS would find both parses because the third and fifth
verb rules both apply when the verb lett is processed. Note that
these two parses are required not because of the conjunction,
but because of the verb know, which can take either a noun
phrase or a clause as its object. Only one parse would be needed
for unambiguous variations such as / know that Bob and Bill lett
and I know Bob and Bill knows me. In general, the conjunction
rules do not introduce any additional nondeterminism into the
grammar beyond that which was there already.
With respect to efficiency, the table below gives the execution
times in milliseconds for NEXUS&apos;s parsing of the sample sen-
tences tabulated in [5]. For comparison, the times from [5] for
MSG and RPM are also shown. All three systems were executed
on a Dec-20 and the times shown for each are just the time taken
to build parse trees: time spent on morphological analysis and
post-parse transformations is not included. MSG and RPM are
written in Prolog and NEXUS is written in Maclisp (compiled).
NEXUS was run with the &apos;no-interpreter&apos; switch turned on.
Sample Sentences MSG RPM NEXUS
Each man ate an apple and a pear. 662 292 112
John ate an apple and a pear. 613 233 95
A man and a woman saw each train. 319 506 150
Each man and each woman ate an apple. 320 503 129
John saw and the woman heard a man 788 834 275
that laughed.
John drove the car through and 275 1032 166
completely demolished a window.
The woman who gave a book to John 1007 3375 283
and drove a car through a window
laughed.
John saw the man that Mary saw and Bill 439 311 205
gave a book to laughed.
John saw the man that heard the woman 636 323 289
that laughed and saw Bill.
The man that Mary saw and heard gave 501 982 237
an apple to each woman.
John saw a and Mary saw the red pear. 726 770 190
In all cases, NEXUS is faster, and in the majority, it is more
that twice as fast as either other system. Averaging over all the
sentences, NEXUS is about 4 times faster than RPM and 3 times
faster than MSG.
</bodyText>
<sectionHeader confidence="0.998609" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999986">
The most innovative feature in NEXUS is its use of only two
kinds of stack structures, one for clauses and one for everything
else. When a structure is at the top of the stack, it represents a
top-down prediction of constituents yet to come, and words from
the input simply drop into the slots that are open to that class of
word. When a word is encountered that cannot be inserted into
the top structure nor into any structure lower in the stack, a new
structure is built bottom-up, the new word inserted in it, and the
parse goes on. When a word can both be inserted somewhere in
the stack and also in a new structure, all possible parses are
pursued in parallel. Thus, NEXUS seems to be a unique member
of the wait-and-see family since it is not always deterministic and
hence need not disambiguate until all information it could get
from the sentence is available.
The general efficiency of the parser is due primarily to its
separation of segmentation from recombination. This is a divide
and conquer strategy which reduces a large search space
-- grammatical patterns for words in sentences -- into two smaller
ones: (1) the set of grammatical patterns for simple phrases and
clause nuclei, and (2) the set of allowable combinations of stack
structures. Of course, search is still required to resolve structural
ambiguity, but the total number of combinations is much less.
It is not clear whether the parser&apos;s speed in the particular
cases above comes from divide and conquer or from the dif-
ferences between Prolog and Maclisp. Nevertheless, as systems
are built that require larger, more comprehensive grammars, and
that must deal with longer, more complicated sentences, the ef-
ficiency of wait-and-see methods like those presented here
should become increasingly important.
</bodyText>
<page confidence="0.998289">
82
</page>
<sectionHeader confidence="0.998519" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999893035714286">
[1] Berwick, R.C. (1983), &amp;quot;A Deterministic Parser With Broad
Coverage,&amp;quot; Proceedings of IJCAI 8, Karlsruhe, W. Germany,
pp. 710-712.
[2] Boguraev, B.K. (1983), &amp;quot;Recognising Conjunctions Within
the ATN Framework,&amp;quot; in K. Sparck-Jones and Y. Wilks
(eds.), Automatic Natural Language Parsing, Ellis Horwood.
[3] Church, K.W. (1980), &amp;quot;On Memory Limitations in Natural
Language Processing,&amp;quot; LCS TR-245, Laboratory for Com-
puter Science, MIT, Cambridge, MA.
[4] Dahl, V., and McCord, M.C. (1983), &amp;quot;Treating Coordination in
Logic Grammars,&amp;quot; American Journal of Computational
Linguistics, V. 9, No. 2, pp. 69-91.
[5] Fong, S, and Berwick, R.C. (1985), &amp;quot;New Approaches to
Parsing Conjunctions Using Prolog,&amp;quot; Proceedings of the
23rd ACL Conference, Chicago, pp. 118-126.
[6] Ginsparg, J. (1978), Natural Language Processing in an
Automatic Programming Framework, AIM-316, PhD. Thesis,
Computer Science Dept., Stanford University, Stanford, CA.
[7] Hirst, G. (in press), Semantic Interpretation and the Resolu-
tion of Ambiguity, New York: Cambridge University Press.
[8] Huang, X. (1984), &amp;quot;Dealing with Conjunctions in a Machine
Translation Environment,&amp;quot; Proceedings of COLING 84, Stan-
ford, pp. 243-246.
[9] Lesmo, L., and Torasso, P. (1985), &amp;quot;Analysis of Conjunctions
in a Rule-Based Parser&amp;quot;, Proceedings of the 23rd ACL
Conference, Chicago, pp. 180-187.
[10] Marcus, M. (1980), A Theory of Syntactic Recognition for
Natural Language, Cambridge, MA.: The MIT Press.
</reference>
<page confidence="0.999605">
83
</page>
<sectionHeader confidence="0.915402" genericHeader="method">
APPENDIX: SAMPLE SEGMENTATION RULES
WORD CLASS DEFINITIONS
</sectionHeader>
<bodyText confidence="0.983477242424242">
A: Article 1. The current input word is w.
Go begin new np with current word w. 2. The variable lastNP refers to the contents of the last NP slot filled In
M: Modifier the top structure.
It MSG = NOUN and LEGALNP(lastNP + w), 3. The predicate LEGALVP tests whether its argument is a syntac-
Else, Continue lastNP with w and return. tically well-formed (partial) verb phrase (auxiliaries + verb).
Go begin new np with w. 4. The predicate LEGALNP tests whether its argument is a syntac-
N: Noun tically well-formed noun phrase (article + Modifiers + nouns).
If MSG = NOUN &amp; w =that and lastNP can take a relative clause,
Push a clause with FUNCTION = THAT, NP1 = that onto stack.
Set MSG = THAT and return.
If MSG = NOUN or THAT &amp; LEGALNP(lastNP + w),
Continue lastNP with w.
If MSG = THAT, set MSG = NOUN and return.
If w is the only noun in lastNP, return.
If the top clause in the stack has no empty NP, return.
Beciin new no:
If MSG = THAT,
Replace NP1 with w.
Set MSG = NOUN and return.
If there a clause C in the stack with NP empty
&amp; C is below a relative clause with VERB filled,
Collapse stack down to C and insert was new NP.
Set MSG = NOUN.
If the top structure in the stack has NP empty,
Insert w as new NP.
Set MSG = NOUN and return.
if MSG = NOUN &amp; lastNP can take a relative clause starting with w,
Push a clause with FUNCTION = RC, NP1 = w onto stack.
Set MSG = NOUN and return.
If the topmost clause C in the stack has VERB filled,
&amp; C&apos;s VERB can take a clausal complement,
Push a clause with FUNCTION = WHAT, NP1 = w onto stack.
Set MSG = NOUN and return.
</bodyText>
<sectionHeader confidence="0.949632" genericHeader="method">
WORD CLASS
</sectionHeader>
<reference confidence="0.667487">
P: Preposition
If w= to &amp; next word is infinitive verb,
Push a clause with FUNCTION = INF, NP1 = !sub onto stack.
Set MSG = INF and return.
Else,
5. The predicate AGREES tests whether an NP and a verb agree in
number.
6. A structure S &amp;quot;has NP empty&amp;quot; ff S is either:
</reference>
<listItem confidence="0.900445">
• a preposition structure with NP empty;
• a clause with no NP filled;
• a clause with NP1 filled &amp; VERB filled &amp; either the verb is
transitive or it is ditransitive, passive form;
• a clause with NPI filled &amp; NP2 filled and verb is ditransitive,
not passive form.
7. A relative clause is a clause with FUNCTION = RC or THAT.
8. A subclause is a relative clause or a clause with FUNCTION = INF or
WHAT.
</listItem>
<sectionHeader confidence="0.605962" genericHeader="method">
NOTES
</sectionHeader>
<reference confidence="0.8413508">
1. Of course, this is just a subset of the rules NEXUS actually uses. Not
shown, for example, are rules for questions, adverbs, participles,
and many other important constructions.
2. Even in the full parser, there are no rules for determining the
internal structure of noun phrases. That task is handled by the
interpreter.
3. The noun rules will always insert a new NP constituent into an
empty NP slot if such a slot is available. Hence, they will always fill
NP3 in a clause with a ditransitive verb, and NP2 in clause which
can take a clausal complement, even if these noun phrases turn out
to be the initial NPs of relative or complement clauses. Such
misattachments are detected by the fourth and fifth verb rules,
which respond by generating the proper structures.
4. A clause with FUNCTION = THAT represents either a complement or
a relative clause. The choice is made when the stack is collapsed.
</reference>
<subsectionHeader confidence="0.684343">
Push a preposition structure with PREP = w onto stack.
</subsectionHeader>
<bodyText confidence="0.895991869565218">
Set MSG = PREP and return. 5. The word that as sole NP constituent is either the demonstrative
V: Verb pronoun or a placeholder for a subsequent WHAT complement
The choice is made when the stack is collapsed.
If MSG = BEGIN &amp; w not inflected,
Set NPI = YOU, VERB = w, NOTE = IMP.
Set MSG = VERB, insert IMP in MSG1, and return.
If MSG = VERB &amp; LEGALVP(VERB + w),
Continue VERB with wand return.
If there is a clause C in the stack with NP1 filled &amp; VERB empty
&amp; AGREES(w,NP1),
If C not top structure in stack, collapse stack down to C.
Set C&apos;s VERB = wand set MSG = VERB.
If C is a subclause, return.
If the top clause C in the stack has NP3 filled,
If C not top structure in stack, collapse stack down to C.
Push a clause with FUNCTION = THAT, VERB = w onto stack.
Transfer C&apos;s NP3 to NPI of new clause.
Set MSG = VERB and return.
If the topmost clause C with VERB filled can takes clause as NP2,
If C not top structure in stack, collapse stack down to C.
Push a clause with FUNCTION = WHAT, VERB = w onto stack.
If C&apos;s NP2 is filled, transfer C&apos;s NP2 to NP1 of new clause.
Set MSG = VERB and return.
</bodyText>
<page confidence="0.998237">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.938296">
<title confidence="0.998115">PARSING CONJUNCTIONS DETERMINISTICALLY</title>
<author confidence="0.999947">Donald W Kosy</author>
<affiliation confidence="0.9992175">The Robotics Institute Carnegie-Mellon University</affiliation>
<address confidence="0.999919">Pittsburgh, Pennsylvania 15213</address>
<abstract confidence="0.993417777777778">Conjunctions have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R C Berwick</author>
</authors>
<title>A Deterministic Parser With Broad Coverage,&amp;quot;</title>
<date>1983</date>
<booktitle>Proceedings of IJCAI 8,</booktitle>
<pages>710--712</pages>
<location>Karlsruhe, W.</location>
<contexts>
<context position="771" citStr="[1,2,3,45,8,9]" startWordPosition="105" endWordPosition="105">have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given. INTRODUCTION In recent years, there has been an upsurge of interest in techniques for parsing sentences containing coordinate conjunctions (and, or and but) [1,2,3,45,8,9]. These techniques are intended to deal with three computational problems inherent in conjunction parsing: 1. Since virtually any pair of constituents of the same syntactic type may be conjoined, a grammar that explicitly enumerates all the possibilities seems needlessly cluttered with a large number of conjunction rules. 2. If a parser uses a top-down analysis strategy (as is common with ATN and logic grammars), it must hypothesize a structure for the second conjunct without knowledge of its actual structure. Since this structure could be any that parallels some constituent that ends at the c</context>
<context position="1994" citStr="[1,3]" startWordPosition="310" endWordPosition="310">rser must generate and test all such possibilities in order to find the ones that match. In practice, the combinatorial explosion of possibilities makes this slow. 3. It is possible for a conjunct to have &amp;quot;gaps&amp;quot; (ellipsed elements) which are not allowed in an unconjoined constituent of the same type. These gaps must be filled with elements from the other conjunct for a proper interpretation, as in: / gave Mary a nickel and Harry a dime. The paper by Lesmo and Torasso [9] briefly reviews which techniques apply to which problems before presenting their own approach. Two papers in the list above [1,3] present deterministic, &amp;quot;waitand-see&amp;quot; methods for conjunction parsing. In both, however, the discussion centers around the theory and feasibility of parsers that obey the Marcus determinism hypothesis [10] and operate with a limited-length lookahead buffer. This paper examines the other side of the coin, namely, the practical power of the waitand-see approach compared to strictly top-down or bottom-up methods. A parser is described that analyzes conjunction structures deterministically and produces parse trees similar to those produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster than </context>
</contexts>
<marker>[1]</marker>
<rawString>Berwick, R.C. (1983), &amp;quot;A Deterministic Parser With Broad Coverage,&amp;quot; Proceedings of IJCAI 8, Karlsruhe, W. Germany, pp. 710-712.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
</authors>
<title>Recognising Conjunctions Within the ATN Framework,&amp;quot;</title>
<date>1983</date>
<booktitle>Automatic Natural Language Parsing, Ellis Horwood.</booktitle>
<editor>in K. Sparck-Jones and Y. Wilks (eds.),</editor>
<contexts>
<context position="771" citStr="[1,2,3,45,8,9]" startWordPosition="105" endWordPosition="105">have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given. INTRODUCTION In recent years, there has been an upsurge of interest in techniques for parsing sentences containing coordinate conjunctions (and, or and but) [1,2,3,45,8,9]. These techniques are intended to deal with three computational problems inherent in conjunction parsing: 1. Since virtually any pair of constituents of the same syntactic type may be conjoined, a grammar that explicitly enumerates all the possibilities seems needlessly cluttered with a large number of conjunction rules. 2. If a parser uses a top-down analysis strategy (as is common with ATN and logic grammars), it must hypothesize a structure for the second conjunct without knowledge of its actual structure. Since this structure could be any that parallels some constituent that ends at the c</context>
</contexts>
<marker>[2]</marker>
<rawString>Boguraev, B.K. (1983), &amp;quot;Recognising Conjunctions Within the ATN Framework,&amp;quot; in K. Sparck-Jones and Y. Wilks (eds.), Automatic Natural Language Parsing, Ellis Horwood.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>On Memory Limitations in Natural Language Processing,&amp;quot;</title>
<date>1980</date>
<tech>LCS TR-245,</tech>
<institution>Laboratory for Computer Science, MIT,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="771" citStr="[1,2,3,45,8,9]" startWordPosition="105" endWordPosition="105">have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given. INTRODUCTION In recent years, there has been an upsurge of interest in techniques for parsing sentences containing coordinate conjunctions (and, or and but) [1,2,3,45,8,9]. These techniques are intended to deal with three computational problems inherent in conjunction parsing: 1. Since virtually any pair of constituents of the same syntactic type may be conjoined, a grammar that explicitly enumerates all the possibilities seems needlessly cluttered with a large number of conjunction rules. 2. If a parser uses a top-down analysis strategy (as is common with ATN and logic grammars), it must hypothesize a structure for the second conjunct without knowledge of its actual structure. Since this structure could be any that parallels some constituent that ends at the c</context>
<context position="1994" citStr="[1,3]" startWordPosition="310" endWordPosition="310">rser must generate and test all such possibilities in order to find the ones that match. In practice, the combinatorial explosion of possibilities makes this slow. 3. It is possible for a conjunct to have &amp;quot;gaps&amp;quot; (ellipsed elements) which are not allowed in an unconjoined constituent of the same type. These gaps must be filled with elements from the other conjunct for a proper interpretation, as in: / gave Mary a nickel and Harry a dime. The paper by Lesmo and Torasso [9] briefly reviews which techniques apply to which problems before presenting their own approach. Two papers in the list above [1,3] present deterministic, &amp;quot;waitand-see&amp;quot; methods for conjunction parsing. In both, however, the discussion centers around the theory and feasibility of parsers that obey the Marcus determinism hypothesis [10] and operate with a limited-length lookahead buffer. This paper examines the other side of the coin, namely, the practical power of the waitand-see approach compared to strictly top-down or bottom-up methods. A parser is described that analyzes conjunction structures deterministically and produces parse trees similar to those produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster than </context>
<context position="22354" citStr="[3]" startWordPosition="3845" endWordPosition="3845">recombination decisions as long as it can and so does not have to search for possible attachments in some situations where theirs does. For instance, in processing Henry repeated the story John told Mary and Bob told Ann his opinion. their parser would first mis-attach [and Bob] to [Mary], then misattach [and Bob told Ann] to [John told Mary]. Each time, a search would be made to find a new attachment when the next word of the input was read. NEXUS can parse this sentence successfully without any mis-attachments at all. It is also instructive to compare NEXUS to the work of Church. His thesis [3] gives a detailed specification of a some fairly elegant rules for conjunction (and several other constructions) along with their linguistic and psycholinguistic justification. While most of the rules are not actually exhibited, their specification suggests that they are similar in many ways to those in NEXUS. However, Church was primarily concerned with the implications of determinism and limited memory, and so his parser, YAP, does not defer decisions as long as NEXUS does. Hence, YAP could not find, or ask for resolution of, the ambiguity in a sentence like: I know Bob and Bill lett. YAP pa</context>
</contexts>
<marker>[3]</marker>
<rawString>Church, K.W. (1980), &amp;quot;On Memory Limitations in Natural Language Processing,&amp;quot; LCS TR-245, Laboratory for Computer Science, MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Dahl</author>
<author>M C McCord</author>
</authors>
<title>Treating Coordination in Logic Grammars,&amp;quot;</title>
<date>1983</date>
<journal>American Journal of Computational Linguistics, V. 9,</journal>
<volume>2</volume>
<pages>69--91</pages>
<contexts>
<context position="2569" citStr="[4]" startWordPosition="395" endWordPosition="395">pers in the list above [1,3] present deterministic, &amp;quot;waitand-see&amp;quot; methods for conjunction parsing. In both, however, the discussion centers around the theory and feasibility of parsers that obey the Marcus determinism hypothesis [10] and operate with a limited-length lookahead buffer. This paper examines the other side of the coin, namely, the practical power of the waitand-see approach compared to strictly top-down or bottom-up methods. A parser is described that analyzes conjunction structures deterministically and produces parse trees similar to those produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster than either MSG or Fong &amp; Berwick&apos;s RPM device [5], and comparative timings are given. We conclude with some descriptive comparisons to other systems and a discussion of the reasons behind the performance observed. OVERVIEW OF THE PARSER For the sake of a name, we will call the parser NEXUS since it is the syntactic component of a larger system called NEXUS. This system is being developed to study the problem of learning technical concepts from expository text. The acronym stands for Non-Expert Understanding System. NEXUS is a direct descendent of READER, a parser written b</context>
<context position="19206" citStr="[4]" startWordPosition="3287" endWordPosition="3287">ntation would continue by adding this word to the VERB slot in the top structure, which is open. As before, the rules would do what they normally do to fill a slot. Recombination would yield conjoined clauses: {wear PN ISUB the children] OBJ the socks] ON their hands] AND (V freeze PN [SUB their feet])) Notice that the second clause is inserted as just another case adjunct of the first clause. There is really no need to construct a coordinate structure (wherein both clauses would be dominated by the conjunction) since it adds nothing to the interpretation. Moreover, as Dahl &amp; McCord point out [4], it is actually better to preserve the subordination structure because it provides essential information for scoping decisions. Now we move on to gaps. Consider a new right conjunct for our original example sentence in which the subject is ellipsed: The children wore the socks on their hands end froze their feet. Rule 4 would detect the gap and the resulting segmentation would be: Input Word Word Class MSG1 MSG Stack and C =) nil CONJ FUNCTION: AND froze V = &gt; nil VERB NP1: !sub VERB: froze their N =&gt; nil NOUN NP2: their feet N =&gt; nil NOUN NP2&apos;: their feet Recombination would yield conjoined </context>
</contexts>
<marker>[4]</marker>
<rawString>Dahl, V., and McCord, M.C. (1983), &amp;quot;Treating Coordination in Logic Grammars,&amp;quot; American Journal of Computational Linguistics, V. 9, No. 2, pp. 69-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fong</author>
<author>R C Berwick</author>
</authors>
<title>New Approaches to Parsing Conjunctions Using Prolog,&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd ACL Conference,</booktitle>
<pages>118--126</pages>
<location>Chicago,</location>
<contexts>
<context position="2639" citStr="[5]" startWordPosition="409" endWordPosition="409">ods for conjunction parsing. In both, however, the discussion centers around the theory and feasibility of parsers that obey the Marcus determinism hypothesis [10] and operate with a limited-length lookahead buffer. This paper examines the other side of the coin, namely, the practical power of the waitand-see approach compared to strictly top-down or bottom-up methods. A parser is described that analyzes conjunction structures deterministically and produces parse trees similar to those produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster than either MSG or Fong &amp; Berwick&apos;s RPM device [5], and comparative timings are given. We conclude with some descriptive comparisons to other systems and a discussion of the reasons behind the performance observed. OVERVIEW OF THE PARSER For the sake of a name, we will call the parser NEXUS since it is the syntactic component of a larger system called NEXUS. This system is being developed to study the problem of learning technical concepts from expository text. The acronym stands for Non-Expert Understanding System. NEXUS is a direct descendent of READER, a parser written by Ginsparg at Stanford in the late 1970&apos;s [6]. Like all wait-and-see p</context>
<context position="23685" citStr="[5]" startWordPosition="4071" endWordPosition="4071">he verb lett is processed. Note that these two parses are required not because of the conjunction, but because of the verb know, which can take either a noun phrase or a clause as its object. Only one parse would be needed for unambiguous variations such as / know that Bob and Bill lett and I know Bob and Bill knows me. In general, the conjunction rules do not introduce any additional nondeterminism into the grammar beyond that which was there already. With respect to efficiency, the table below gives the execution times in milliseconds for NEXUS&apos;s parsing of the sample sentences tabulated in [5]. For comparison, the times from [5] for MSG and RPM are also shown. All three systems were executed on a Dec-20 and the times shown for each are just the time taken to build parse trees: time spent on morphological analysis and post-parse transformations is not included. MSG and RPM are written in Prolog and NEXUS is written in Maclisp (compiled). NEXUS was run with the &apos;no-interpreter&apos; switch turned on. Sample Sentences MSG RPM NEXUS Each man ate an apple and a pear. 662 292 112 John ate an apple and a pear. 613 233 95 A man and a woman saw each train. 319 506 150 Each man and each woman ate</context>
</contexts>
<marker>[5]</marker>
<rawString>Fong, S, and Berwick, R.C. (1985), &amp;quot;New Approaches to Parsing Conjunctions Using Prolog,&amp;quot; Proceedings of the 23rd ACL Conference, Chicago, pp. 118-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ginsparg</author>
</authors>
<title>Natural Language Processing in an Automatic Programming Framework,</title>
<date>1978</date>
<tech>AIM-316, PhD. Thesis,</tech>
<institution>Computer Science Dept., Stanford University,</institution>
<location>Stanford, CA.</location>
<contexts>
<context position="3214" citStr="[6]" startWordPosition="505" endWordPosition="505">g &amp; Berwick&apos;s RPM device [5], and comparative timings are given. We conclude with some descriptive comparisons to other systems and a discussion of the reasons behind the performance observed. OVERVIEW OF THE PARSER For the sake of a name, we will call the parser NEXUS since it is the syntactic component of a larger system called NEXUS. This system is being developed to study the problem of learning technical concepts from expository text. The acronym stands for Non-Expert Understanding System. NEXUS is a direct descendent of READER, a parser written by Ginsparg at Stanford in the late 1970&apos;s [6]. Like all wait-and-see parsers, it incorporates a stack to hold constituent structures being built, some variables that record the state of the parse, and a set of transition rules that control the parsing process. The stack structures and state variables in NEXUS are almost the same as in READER, but the rules have been rewritten to make them cleaner, more transparent, and more complete. There are two categories of rules. Segmentation rules are responsible for finding the boundaries of constituents and creating stack structures to store these results. Recombination rules are responsible for </context>
</contexts>
<marker>[6]</marker>
<rawString>Ginsparg, J. (1978), Natural Language Processing in an Automatic Programming Framework, AIM-316, PhD. Thesis, Computer Science Dept., Stanford University, Stanford, CA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Hirst</author>
</authors>
<title>(in press), Semantic Interpretation and the Resolution of Ambiguity,</title>
<publisher>Cambridge University Press.</publisher>
<location>New York:</location>
<contexts>
<context position="11633" citStr="[7]" startWordPosition="1967" endWordPosition="1967">ting values -- perfect, acceptable, and unacceptable -- and these are encoded as numbers so that there can be degrees of acceptability. When one structure is attached to another, its rating is added to the rating of the attachment and the sum becomes the rating of the new (recombined) structure. A structure&apos;s rating thus reflects the ratings of all its component constituents. Although NEXUS is designed to call upon an interpreter module to supply the ratings, currently they must be supplied by interaction with a human interpreter. Eventually, we expect to use the procedures developed by Hirst [7]. There is also a &apos;no-interpreter&apos; switch which can be set to give perfect ratings to clause attachment of right-neighbor prepositional phrases, and noun phrase (&amp;quot;low&amp;quot;) attachment of all other post-modifiers. The order in which attachments are attempted is controlled by the collapse procedure. Collapse is responsible for assembling an actual parse tree from the structures in a stack. After initializing the root of the tree to be the bottom stack structure, the remaining structures are considered in reverse stack order so that the constituents will be added to the tree in the order they appeare</context>
</contexts>
<marker>[7]</marker>
<rawString>Hirst, G. (in press), Semantic Interpretation and the Resolution of Ambiguity, New York: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
</authors>
<title>Dealing with Conjunctions in a Machine Translation Environment,&amp;quot;</title>
<date>1984</date>
<booktitle>Proceedings of COLING 84,</booktitle>
<pages>243--246</pages>
<location>Stanford,</location>
<contexts>
<context position="771" citStr="[1,2,3,45,8,9]" startWordPosition="105" endWordPosition="105">have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given. INTRODUCTION In recent years, there has been an upsurge of interest in techniques for parsing sentences containing coordinate conjunctions (and, or and but) [1,2,3,45,8,9]. These techniques are intended to deal with three computational problems inherent in conjunction parsing: 1. Since virtually any pair of constituents of the same syntactic type may be conjoined, a grammar that explicitly enumerates all the possibilities seems needlessly cluttered with a large number of conjunction rules. 2. If a parser uses a top-down analysis strategy (as is common with ATN and logic grammars), it must hypothesize a structure for the second conjunct without knowledge of its actual structure. Since this structure could be any that parallels some constituent that ends at the c</context>
</contexts>
<marker>[8]</marker>
<rawString>Huang, X. (1984), &amp;quot;Dealing with Conjunctions in a Machine Translation Environment,&amp;quot; Proceedings of COLING 84, Stanford, pp. 243-246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lesmo</author>
<author>P Torasso</author>
</authors>
<title>Analysis of Conjunctions in a Rule-Based Parser&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd ACL Conference,</booktitle>
<pages>180--187</pages>
<location>Chicago,</location>
<contexts>
<context position="771" citStr="[1,2,3,45,8,9]" startWordPosition="105" endWordPosition="105">have always been a source of problems for natural language parsers. This paper shows how these problems may be circumvented using a rule-based, wait-and-see parsing strategy. A parser is presented which analyzes conjunction structures deterministically, and the specific rules it uses are described and illustrated. This parser appears to be faster for conjunctions than other parsers in the literature and some comparative timings are given. INTRODUCTION In recent years, there has been an upsurge of interest in techniques for parsing sentences containing coordinate conjunctions (and, or and but) [1,2,3,45,8,9]. These techniques are intended to deal with three computational problems inherent in conjunction parsing: 1. Since virtually any pair of constituents of the same syntactic type may be conjoined, a grammar that explicitly enumerates all the possibilities seems needlessly cluttered with a large number of conjunction rules. 2. If a parser uses a top-down analysis strategy (as is common with ATN and logic grammars), it must hypothesize a structure for the second conjunct without knowledge of its actual structure. Since this structure could be any that parallels some constituent that ends at the c</context>
</contexts>
<marker>[9]</marker>
<rawString>Lesmo, L., and Torasso, P. (1985), &amp;quot;Analysis of Conjunctions in a Rule-Based Parser&amp;quot;, Proceedings of the 23rd ACL Conference, Chicago, pp. 180-187.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language,</title>
<date>1980</date>
<publisher>The MIT</publisher>
<location>Cambridge, MA.:</location>
<contexts>
<context position="2199" citStr="[10]" startWordPosition="338" endWordPosition="338">gaps&amp;quot; (ellipsed elements) which are not allowed in an unconjoined constituent of the same type. These gaps must be filled with elements from the other conjunct for a proper interpretation, as in: / gave Mary a nickel and Harry a dime. The paper by Lesmo and Torasso [9] briefly reviews which techniques apply to which problems before presenting their own approach. Two papers in the list above [1,3] present deterministic, &amp;quot;waitand-see&amp;quot; methods for conjunction parsing. In both, however, the discussion centers around the theory and feasibility of parsers that obey the Marcus determinism hypothesis [10] and operate with a limited-length lookahead buffer. This paper examines the other side of the coin, namely, the practical power of the waitand-see approach compared to strictly top-down or bottom-up methods. A parser is described that analyzes conjunction structures deterministically and produces parse trees similar to those produced by Dahl &amp; McCord&apos;s MSG system [4]. It is much faster than either MSG or Fong &amp; Berwick&apos;s RPM device [5], and comparative timings are given. We conclude with some descriptive comparisons to other systems and a discussion of the reasons behind the performance obser</context>
</contexts>
<marker>[10]</marker>
<rawString>Marcus, M. (1980), A Theory of Syntactic Recognition for Natural Language, Cambridge, MA.: The MIT Press. P: Preposition If w= to &amp; next word is infinitive verb, Push a clause with FUNCTION = INF, NP1 = !sub onto stack. Set MSG = INF and return. Else, 5. The predicate AGREES tests whether an NP and a verb agree in number. 6. A structure S &amp;quot;has NP empty&amp;quot; ff S is either: 1. Of course, this is just a subset of the rules NEXUS actually uses. Not shown, for example, are rules for questions, adverbs, participles, and many other important constructions. 2. Even in the full parser, there are no rules for determining the internal structure of noun phrases. That task is handled by the interpreter. 3. The noun rules will always insert a new NP constituent into an empty NP slot if such a slot is available. Hence, they will always fill NP3 in a clause with a ditransitive verb, and NP2 in clause which can take a clausal complement, even if these noun phrases turn out to be the initial NPs of relative or complement clauses. Such misattachments are detected by the fourth and fifth verb rules, which respond by generating the proper structures. 4. A clause with FUNCTION = THAT represents either a complement or a relative clause. The choice is made when the stack is collapsed.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>