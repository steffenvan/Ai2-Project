<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011776">
<title confidence="0.967131">
FBK: Cross-Lingual Textual Entailment Without Translation
</title>
<author confidence="0.945805">
Yashar Mehdad Matteo Negri Jos´e Guilherme C. de Souza
</author>
<affiliation confidence="0.4775535">
FBK-irst FBK-irst FBK-irst &amp; University of Trento
Trento , Italy Trento, Italy Trento, Italy
</affiliation>
<email confidence="0.976288">
mehdad@fbk.eu negri@fbk.eu desouza@fbk.eu
</email>
<sectionHeader confidence="0.998369" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999400105263158">
This paper overviews FBK’s participation
in the Cross-Lingual Textual Entailment
for Content Synchronization task organized
within SemEval-2012. Our participation is
characterized by using cross-lingual matching
features extracted from lexical and semantic
phrase tables and dependency relations. The
features are used for multi-class and binary
classification using SVMs. Using a combi-
nation of lexical, syntactic, and semantic fea-
tures to create a cross-lingual textual entail-
ment system, we report on experiments over
the provided dataset. Our best run achieved
an accuracy of 50.4% on the Spanish-English
dataset (with the average score and the me-
dian system respectively achieving 40.7% and
34.6%), demonstrating the effectiveness of a
“pure” cross-lingual approach that avoids in-
termediate translations.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999720085106383">
So far, cross-lingual textual entailment (CLTE)
(Mehdad et al., 2010) has been applied to: i)
available TE datasets (“YES”/“NO” uni-directional
relations between monolingual pairs) transformed
into their cross-lingual counterpart by translating
the hypotheses into other languages (Negri and
Mehdad, 2010), and ii) machine translation evalu-
ation datasets (Mehdad et al., 2012b). The content
synchronization task represents a challenging appli-
cation scenario to test the capabilities of CLTE sys-
tems, by proposing a richer inventory of phenomena
(i.e. “Bidirectional”/“Forward”/“Backward”/“No
entailment” multi-directional entailment relations).
Multi-directional CLTE recognition can be seen
as the identification of semantic equivalence and in-
formation disparity between two topically related
sentences, at the cross-lingual level. This is a core
aspect of the multilingual content synchronization
task, which represents a challenging application sce-
nario for a variety of NLP technologies, and a shared
research framework for the integration of semantics
and MT technology.
The CLTE methods proposed so far adopt either
a “pivoting approach” (translation of the two in-
put texts into the same language, as in (Mehdad et
al., 2010)), or an “integrated solution” that exploits
bilingual phrase tables to capture lexical relations
and contextual information (Mehdad et al., 2011).
The promising results achieved with the integrated
approach still rely on phrasal matching techniques
that disregard relevant semantic aspects of the prob-
lem. By filling this gap integrating linguistically
motivated features, in our participation, we propose
an approach that combines lexical, syntactic and se-
mantic features within a machine learning frame-
work (Mehdad et al., 2012a).
Our submitted runs have been produced by train-
ing and optimizing multiclass and binary SVM clas-
sifiers, over the Spanish-English (Spa-Eng) devel-
opment set. In both cases, our results were posi-
tive, showing significant improvements over the me-
dian systems and average scores obtained by partic-
ipants. The overall results confirm the difficulty of
the task, and the potential of our approach in com-
bining linguistically motivated features in a “pure”
cross-lingual approach that avoids the recourse to
external MT components.
</bodyText>
<page confidence="0.971682">
701
</page>
<note confidence="0.713307">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 701–705,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.998222" genericHeader="introduction">
2 Experiments
</sectionHeader>
<bodyText confidence="0.999916714285714">
In our experiment we used the Spa-Eng portion of
the dataset described in (Negri et al., 2012; Negri
et al., 2011), consisting of 500 multi-directional en-
tailment pairs which was provided to train the sys-
tems and 500 pairs for the submission. Each pair in
the dataset is annotated with “Bidirectional”, “For-
ward”, “Backward” or “No entailment” judgements.
</bodyText>
<subsectionHeader confidence="0.985236">
2.1 Approach
</subsectionHeader>
<bodyText confidence="0.999255833333333">
Our system builds on the integration of lexical,
syntactic and semantic features in a supervised
learning framework. Our model builds on three
main feature sets, respectively derived from: i)
phrase tables, ii) dependency relations, and iii)
semantic phrase tables.
</bodyText>
<listItem confidence="0.677168">
1. Phrase Table (PT) matching: through
</listItem>
<bodyText confidence="0.996823153846154">
these features, a semantic judgement about entail-
ment is made exclusively on the basis of lexical
evidence. The matching features are calculated
with a phrase-to-phrase matching process. A phrase
in our approach is an n-gram composed of one
or more (up to 5) consecutive words, excluding
punctuation. Entailment decisions are assigned
combining phrasal matching scores calculated for
each level of n-grams (i.e. considering the number
of 1-grams, 2-grams,..., 5-grams extracted from H
that match with n-grams in T). Phrasal matches,
performed either at the level of tokens, lemmas, or
stems, can be of two types:
</bodyText>
<listItem confidence="0.9549512">
1. Exact: in the case that two phrases are identical
at one of the three levels (token, lemma, stem).
2. Lexical: in the case that two different phrases
can be mapped through entries of the resources
used to bridge T and H (i.e. phrase tables).
</listItem>
<bodyText confidence="0.999890470588235">
For each phrase in H, we first search for exact
matches at the level of token with phrases in T. If
no match is found at a token level, the other levels
(lemma and stem) are attempted. Then, in case of
failure with exact matching, lexical matching is per-
formed at the same three levels. To reduce redun-
dant matches, the lexical matches between pairs of
phrases which have already been identified as exact
matches are not considered.
Once the matching phase for each n-gram
level has been concluded, the number of matches
Matchn and the number of phrases in the hypoth-
esis H(n) is used to estimate the portion of phrases
in H that are matched at each level n (Equation 1).1
Since languages can express the same meaning with
different amounts of words, a phrase with length n
in H can match a phrase with any length in T.
</bodyText>
<equation confidence="0.979636666666667">
Matchn
Matchn = (1)
JH(n)
</equation>
<bodyText confidence="0.999384166666667">
In order to build English-Spanish phrase tables
for our experiments, we used the freely available
Europarl V.4, News Commentary and United
Nations Spanish-English parallel corpora released
for the WMT10 Shared Translation Task.2 We
run the TreeTagger (Schmid, 1995) and Snowball
stemmer (Porter, 2001) for preprocessing, and used
the Giza++ (Och and Ney, 2000) toolkit to align the
tokenized corpora at the word level. Subsequently,
we extracted the bi-lingual phrase table from the
aligned corpora using the Moses toolkit (Koehn et
al., 2007).
</bodyText>
<sectionHeader confidence="0.560236" genericHeader="method">
2. Dependency Relation (DR) matching tar-
</sectionHeader>
<bodyText confidence="0.908953636363636">
gets the increase of CLTE precision. By adding
syntactic constraints to the matching process,
DR features aim to reduce wrong matches often
occurring at the lexical level. For instance, the con-
tradiction between “Yahoo acquired Overture” and
“Overture compr´o Yahoo” is evident when syntax
(in this case subject-object inversion) is taken into
account, but can not be caught by bag-of-words
methods.
We define a dependency relation as a triple that
connects pairs of words through a grammatical rela-
tion. For example, “nsubj (loves, John)” is a depen-
dency relation with head loves and dependent John
connected by the relation nsubj, which means that
“John” is the subject of “loves”. DR matching cap-
tures similarities between dependency relations, by
combining the syntactic and lexical level. In a valid
match, while the relation has to be the same (“exact”
1When checking for entailment from H to T, the normaliza-
tion is carried out dividing the number of n-grams in H by the
number of n-grams in T. The same holds for dependency rela-
tion and semantic phrase table matching.
</bodyText>
<footnote confidence="0.986947">
2http://www.statmt.org/wmt10/
</footnote>
<page confidence="0.992512">
702
</page>
<bodyText confidence="0.997938181818182">
match), the connected words must be either the same
or semantically equivalent in the two languages. For
example, “nsubj (loves, John)” can match “nsubj
(ama, John)” and “nsubj (quiere, John)” but not
“dobj (quiere, John)”.
Given the dependency tree representations of T
and H, for each grammatical relation (r) we calcu-
late a DR matching score (Matchr, see Equation 2)
as the number of matching occurrences of r in T and
H (respectively DRr(T) and DRr(H)), divided by
the number of occurrences of r in H.
</bodyText>
<equation confidence="0.988513333333333">
matchr _
|match(DRr(T),DRr(H)) |(2)
|DRr(H)|
</equation>
<bodyText confidence="0.999974333333333">
In our experiments, in order to extract de-
pendency relation (DR) matching features, the
dependency tree representations of English and
Spanish texts have been produced with DepPattern
(Otero and Lopez, 2011). We then mapped the
sets of dependency relation labels for the English-
Spanish parser output into: Adjunct, Determiner,
Object, Subject and Preposition. The dictionary,
containing about 9M bilingual word pairs, created
during the alignment of the English-Spanish parallel
corpora provided the lexical knowledge to perform
matches when the connected words are different.
</bodyText>
<sectionHeader confidence="0.738495" genericHeader="method">
3. Semantic Phrase Table (SPT) matching:
</sectionHeader>
<bodyText confidence="0.999964483870968">
represents a novel way to leverage the integration
of semantics and MT-derived techniques. To this
aim, SPT improves CLTE methods relying on pure
lexical match, by means of “generalized” phrase
tables annotated with shallow semantic labels.
Semantically enhanced phrase tables, with entries in
the form “[LABEL] word1...wordn [LABEL]” (e.g.
“[ORG] acquired [ORG]”), are used as a recall-
oriented complement to the lexical phrase tables
used in machine translation (token-based entries like
“Yahoo acquired Overture”). The main motivation
for this augmentation is that word replacement with
semantic tags allows to match T-H tokens that do
not occur in the original bilingual parallel corpora
used for phrase table extraction. Our hypothesis
is that the increase in recall obtained from relaxed
matches through semantic tags in place of “out of
vocabulary” terms (e.g. unseen person, location, or
organization names) is an effective way to improve
CLTE performance, even at the cost of some loss in
precision. Semantic phrase tables, however, have
two additional advantages. The first is related to
their smaller size and, in turn, its positive impact
on system’s efficiency, due to the considerable
search space reduction. Semantic tags allow to
merge different sequences of tokens into a single tag
and, consequently, different phrase entries can be
unified to one semantic phrase entry. As a result, for
instance, the SPT used in our experiments is more
than 30% smaller than the original token-based one.
The second advantage relates to their potential im-
pact on the confidence of CLTE judgements. Since
a semantic tag might cover more than one token
in the original entry phrase, SPT entries are often
short generalizations of longer original phrases.
Consequently, the matching process can benefit
from the increased probability of mapping higher
order n-grams (i.e. those providing more contextual
information) from H into T and vice-versa.
Like lexical phrase tables, SPTs are extracted
from parallel corpora. As a first step, we annotate
the corpora with named-entity taggers (FreeLing in
our case (Carreras et al., 2004)) for the source and
target languages, replacing named entities with gen-
eral semantic labels chosen from a coarse-grained
taxonomy including the categories: person, location,
organization, date and numeric expression. Then,
we combine the sequences of unique labels into one
single token of the same label, and we run Giza++
(Och and Ney, 2000) to align the resulting seman-
tically augmented corpora. Finally, we extract the
semantic phrase table from the augmented aligned
corpora using the Moses toolkit (Koehn et al., 2007).
For the matching phase, we first annotate T and
H in the same way we labeled our parallel corpora.
Then, for each n-gram order (n=1 to 5, excluding
punctuation), we use the SPT to calculate a matching
score (SPT matchn, see Equation 3), as the num-
ber of n-grams in H that match with phrases in T
divided by the number of n-grams in H. The match-
ing algorithm is same as the phrase table matching
one.
</bodyText>
<equation confidence="0.6775365">
SPT matchn ISPTn(H) ∩ SPT(T) |(3)
= |SPTn(H)|
</equation>
<page confidence="0.995415">
703
</page>
<table confidence="0.9995188">
Run Features Classification Parameter selection Result
1 PT+SPT+DR Multiclass Entire training set 0.502
2 PT+SPT+DR Multiclass 2-fold cross validation 0.490
3 PT+SPT+DR Binary Entire training set 0.504
4 PT+SPT+DR Binary 2-fold cross validation 0.500
</table>
<tableCaption confidence="0.996165">
Table 1: Summary of the submitted runs and results for Spa-Eng dataset.
</tableCaption>
<table confidence="0.999097666666667">
Forward Backward No entailment Bidirectional
P R F1 P R F1 P R F1 P R F1
0.515 0.704 0.595 0.546 0.568 0.557 0.447 0.304 0.362 0.482 0.440 0.460
</table>
<tableCaption confidence="0.988066">
Table 2: Best run’s Precision/Recall/F1 scores.
</tableCaption>
<bodyText confidence="0.9994834">
In our supervised learning framework, the com-
puted PT, SPT and DR scores are used as sepa-
rate features, giving to an SVM classifier, LIBSVM
(Chang and Lin, 2011), the possibility to learn opti-
mal feature weights from training data.
</bodyText>
<subsectionHeader confidence="0.999236">
2.2 Submitted runs
</subsectionHeader>
<bodyText confidence="0.9999714">
In order to test our models under different condi-
tions, we set the CLTE problem both as two-way and
multiclass classification tasks.
Two-way classification casts multidirectional en-
tailment as a unidirectional problem, where each
pair is analyzed checking for entailment both from
left to right and from right to left. In this condi-
tion, each original test example is correctly clas-
sified if both pairs originated from it are correctly
judged (“YES-YES” for bidirectional, “YES-NO”
for forward, “NO-YES” for backward entailment,
and “NO-NO” for no entailment). Two-way clas-
sification represents an intuitive solution to capture
multidirectional entailment relations but, at the same
time, a suboptimal approach in terms of efficiency
since two checks are performed for each pair.
Multiclass classification is more efficient, but at
the same time more challenging due to the higher
difficulty of multiclass learning, especially with
small datasets. We also tried to use the parameter se-
lection tool for C-SVM classification using the RBF
(radial basis function) kernel, available in LIBSVM
package. Our submitted runs and results have been
obtained with the settings summarized in table 1.
As can be seen from the table, our best result has
been achieved by Run 3 (50.4% accuracy), which
is significantly higher than the average and median
score over the best runs obtained by participants
(44.0% and 40.7% respectively). The detailed re-
sults achieved by the best run are reported in Table
2. We can observe that our system is performing
well for recognizing the unidirectional entailment
(i.e. forward and backward), while the performance
drops over no entailment pairs. The low results for
bidirectional cases also reflect the difficulty of dis-
criminating the no entailment pairs from the bidi-
rectional ones. Looking at the detailed results, we
can observe a high recall in the forward and back-
ward entailment cases, which could be explained by
the effectiveness of the semantic phrase table match-
ing features aiming at coverage increase over lexi-
cal methods. Adding more linguistically motivated
features and weighting the non-matched phrases can
be a starting point to improve the overall results for
other cases (bidirectional and no entailment).
</bodyText>
<sectionHeader confidence="0.999572" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.999365333333333">
In this paper we described our participation to the
cross-lingual textual entailment for content synchro-
nization task at SemEval-2012. We approached this
task by combining lexical, syntactic and semantic
features, at the cross-lingual level without recourse
to intermediate translation steps. In spite of the
difficulty and novelty of the task, our results on
the Spanish-English dataset (0.504) prove the effec-
tiveness of the approach with significant improve-
ments over the reported average and median accu-
racy scores for the 29 submitted runs (respectively
40.7% and 34.6%).
</bodyText>
<sectionHeader confidence="0.998806" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9954455">
This work has been partially supported by the EU-
funded project CoSyne (FP7-ICT-4-248531).
</bodyText>
<page confidence="0.997156">
704
</page>
<sectionHeader confidence="0.996259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999553163934427">
X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.
FreeLing: An Open-Source Suite of Language An-
alyzers. In Proceedings of the 4th International
Conference on Language Resources and Evaluation
(LREC’04).
C.C. Chang and C.J. Lin. 2011. LIBSVM: A Library
for Support Vector Machines. ACM Transactions on
Intelligent Systems and Technology (TIST), 2(3).
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit for
Statistical Machine Translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions (ACL 2007).
Y. Mehdad, M. Negri, and M. Federico. 2010. Towards
Cross-Lingual Textual Entailment. In Proceedings of
the 11th Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics (NAACL HLT 2010).
Y. Mehdad, M. Negri, and M. Federico. 2011. Using
Bilingual Parallel Corpora for Cross-Lingual Textual
Entailment. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies (ACL HLT 2011).
Y. Mehdad, M. Negri, and M. Federico. 2012a. Detect-
ing Semantic Equivalence and Information Disparity
in Cross-lingual Documents. In Proceedings of the
ACL’12.
Y. Mehdad, M. Negri, and M. Federico. 2012b. Match
without a Referee: Evaluating MT Adequacy without
Reference Translations. In Proceedings of the Ma-
chine Translation Workshop (WMT2012).
M. Negri and Y. Mehdad. 2010. Creating a Bi-lingual
Entailment Corpus through Translations with Mechan-
ical Turk: $100 for a 10-day rush. In Proceedings of
the NAACL HLT 2010 Workshop on Creating Speech
and Language Data with Amazon’s Mechanical Turk,
pages 212–216. Association for Computational Lin-
guistics.
M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, and
A. Marchetti. 2011. Divide and conquer: Crowd-
sourcing the creation of cross-lingual textual entail-
ment corpora. In Proceedings of EMNLP 2011.
M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and
D. Giampiccolo. 2012. Semeval-2012 Task 8: Cross-
lingual Textual Entailment for Content Synchroniza-
tion. In Proceedings of the 6th International Workshop
on Semantic Evaluation (SemEval 2012).
F.J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proceedings of the 38th Annual
Meeting of the Association for Computational Linguis-
tics (ACL 2000).
P.G. Otero and I.G. Lopez. 2011. A Grammatical For-
malism Based on Patterns of Part-of-Speech Tags. In-
ternational journal of corpus linguistics, 16(1).
M. Porter. 2001. Snowball: A language for stemming
algorithms.
H. Schmid. 1995. Treetaggera language indepen-
dent part-of-speech tagger. Institut f¨ur Maschinelle
Sprachverarbeitung, Universit¨at Stuttgart.
</reference>
<page confidence="0.99855">
705
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.726501">
<title confidence="0.999853">FBK: Cross-Lingual Textual Entailment Without Translation</title>
<author confidence="0.973953">Yashar Mehdad Matteo Negri Jos´e Guilherme C de_Souza</author>
<affiliation confidence="0.959303">FBK-irst FBK-irst FBK-irst &amp; University of Trento</affiliation>
<address confidence="0.769714">Trento , Italy Trento, Italy Trento, Italy</address>
<email confidence="0.973426">mehdad@fbk.eunegri@fbk.eudesouza@fbk.eu</email>
<abstract confidence="0.99871955">This paper overviews FBK’s participation in the Cross-Lingual Textual Entailment for Content Synchronization task organized within SemEval-2012. Our participation is characterized by using cross-lingual matching features extracted from lexical and semantic phrase tables and dependency relations. The features are used for multi-class and binary classification using SVMs. Using a combination of lexical, syntactic, and semantic features to create a cross-lingual textual entailment system, we report on experiments over the provided dataset. Our best run achieved an accuracy of 50.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a “pure” cross-lingual approach that avoids intermediate translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>FreeLing: An Open-Source Suite of Language Analyzers.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04).</booktitle>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004. FreeLing: An Open-Source Suite of Language Analyzers. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Chang</author>
<author>C J Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<contexts>
<context position="12583" citStr="Chang and Lin, 2011" startWordPosition="1950" endWordPosition="1953">PT+SPT+DR Multiclass Entire training set 0.502 2 PT+SPT+DR Multiclass 2-fold cross validation 0.490 3 PT+SPT+DR Binary Entire training set 0.504 4 PT+SPT+DR Binary 2-fold cross validation 0.500 Table 1: Summary of the submitted runs and results for Spa-Eng dataset. Forward Backward No entailment Bidirectional P R F1 P R F1 P R F1 P R F1 0.515 0.704 0.595 0.546 0.568 0.557 0.447 0.304 0.362 0.482 0.440 0.460 Table 2: Best run’s Precision/Recall/F1 scores. In our supervised learning framework, the computed PT, SPT and DR scores are used as separate features, giving to an SVM classifier, LIBSVM (Chang and Lin, 2011), the possibility to learn optimal feature weights from training data. 2.2 Submitted runs In order to test our models under different conditions, we set the CLTE problem both as two-way and multiclass classification tasks. Two-way classification casts multidirectional entailment as a unidirectional problem, where each pair is analyzed checking for entailment both from left to right and from right to left. In this condition, each original test example is correctly classified if both pairs originated from it are correctly judged (“YES-YES” for bidirectional, “YES-NO” for forward, “NO-YES” for ba</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>C.C. Chang and C.J. Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions (ACL</booktitle>
<contexts>
<context position="6479" citStr="Koehn et al., 2007" startWordPosition="980" endWordPosition="983">h n in H can match a phrase with any length in T. Matchn Matchn = (1) JH(n) In order to build English-Spanish phrase tables for our experiments, we used the freely available Europarl V.4, News Commentary and United Nations Spanish-English parallel corpora released for the WMT10 Shared Translation Task.2 We run the TreeTagger (Schmid, 1995) and Snowball stemmer (Porter, 2001) for preprocessing, and used the Giza++ (Och and Ney, 2000) toolkit to align the tokenized corpora at the word level. Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007). 2. Dependency Relation (DR) matching targets the increase of CLTE precision. By adding syntactic constraints to the matching process, DR features aim to reduce wrong matches often occurring at the lexical level. For instance, the contradiction between “Yahoo acquired Overture” and “Overture compr´o Yahoo” is evident when syntax (in this case subject-object inversion) is taken into account, but can not be caught by bag-of-words methods. We define a dependency relation as a triple that connects pairs of words through a grammatical relation. For example, “nsubj (loves, John)” is a dependency re</context>
<context position="11454" citStr="Koehn et al., 2007" startWordPosition="1754" endWordPosition="1757">e annotate the corpora with named-entity taggers (FreeLing in our case (Carreras et al., 2004)) for the source and target languages, replacing named entities with general semantic labels chosen from a coarse-grained taxonomy including the categories: person, location, organization, date and numeric expression. Then, we combine the sequences of unique labels into one single token of the same label, and we run Giza++ (Och and Ney, 2000) to align the resulting semantically augmented corpora. Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al., 2007). For the matching phase, we first annotate T and H in the same way we labeled our parallel corpora. Then, for each n-gram order (n=1 to 5, excluding punctuation), we use the SPT to calculate a matching score (SPT matchn, see Equation 3), as the number of n-grams in H that match with phrases in T divided by the number of n-grams in H. The matching algorithm is same as the phrase table matching one. SPT matchn ISPTn(H) ∩ SPT(T) |(3) = |SPTn(H)| 703 Run Features Classification Parameter selection Result 1 PT+SPT+DR Multiclass Entire training set 0.502 2 PT+SPT+DR Multiclass 2-fold cross validati</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions (ACL 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<contexts>
<context position="1151" citStr="Mehdad et al., 2010" startWordPosition="154" endWordPosition="157"> dependency relations. The features are used for multi-class and binary classification using SVMs. Using a combination of lexical, syntactic, and semantic features to create a cross-lingual textual entailment system, we report on experiments over the provided dataset. Our best run achieved an accuracy of 50.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a “pure” cross-lingual approach that avoids intermediate translations. 1 Introduction So far, cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) has been applied to: i) available TE datasets (“YES”/“NO” uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation evaluation datasets (Mehdad et al., 2012b). The content synchronization task represents a challenging application scenario to test the capabilities of CLTE systems, by proposing a richer inventory of phenomena (i.e. “Bidirectional”/“Forward”/“Backward”/“No entailment” multi-directional entailment relations). Multi-directional CLTE r</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2010. Towards Cross-Lingual Textual Entailment. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</booktitle>
<contexts>
<context position="2459" citStr="Mehdad et al., 2011" startWordPosition="336" endWordPosition="339">parity between two topically related sentences, at the cross-lingual level. This is a core aspect of the multilingual content synchronization task, which represents a challenging application scenario for a variety of NLP technologies, and a shared research framework for the integration of semantics and MT technology. The CLTE methods proposed so far adopt either a “pivoting approach” (translation of the two input texts into the same language, as in (Mehdad et al., 2010)), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated approach still rely on phrasal matching techniques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguistically motivated features, in our participation, we propose an approach that combines lexical, syntactic and semantic features within a machine learning framework (Mehdad et al., 2012a). Our submitted runs have been produced by training and optimizing multiclass and binary SVM classifiers, over the Spanish-English (Spa-Eng) development set. In both cases, our results were positive, showing signif</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2011. Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL’12.</booktitle>
<contexts>
<context position="1457" citStr="Mehdad et al., 2012" startWordPosition="195" endWordPosition="198">0.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a “pure” cross-lingual approach that avoids intermediate translations. 1 Introduction So far, cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) has been applied to: i) available TE datasets (“YES”/“NO” uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation evaluation datasets (Mehdad et al., 2012b). The content synchronization task represents a challenging application scenario to test the capabilities of CLTE systems, by proposing a richer inventory of phenomena (i.e. “Bidirectional”/“Forward”/“Backward”/“No entailment” multi-directional entailment relations). Multi-directional CLTE recognition can be seen as the identification of semantic equivalence and information disparity between two topically related sentences, at the cross-lingual level. This is a core aspect of the multilingual content synchronization task, which represents a challenging application scenario for a variety of N</context>
<context position="2843" citStr="Mehdad et al., 2012" startWordPosition="392" endWordPosition="395">” (translation of the two input texts into the same language, as in (Mehdad et al., 2010)), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated approach still rely on phrasal matching techniques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguistically motivated features, in our participation, we propose an approach that combines lexical, syntactic and semantic features within a machine learning framework (Mehdad et al., 2012a). Our submitted runs have been produced by training and optimizing multiclass and binary SVM classifiers, over the Spanish-English (Spa-Eng) development set. In both cases, our results were positive, showing significant improvements over the median systems and average scores obtained by participants. The overall results confirm the difficulty of the task, and the potential of our approach in combining linguistically motivated features in a “pure” cross-lingual approach that avoids the recourse to external MT components. 701 First Joint Conference on Lexical and Computational Semantics (*SEM)</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2012a. Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents. In Proceedings of the ACL’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Match without a Referee: Evaluating MT Adequacy without Reference Translations.</title>
<date>2012</date>
<booktitle>In Proceedings of the Machine Translation Workshop (WMT2012).</booktitle>
<contexts>
<context position="1457" citStr="Mehdad et al., 2012" startWordPosition="195" endWordPosition="198">0.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a “pure” cross-lingual approach that avoids intermediate translations. 1 Introduction So far, cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) has been applied to: i) available TE datasets (“YES”/“NO” uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation evaluation datasets (Mehdad et al., 2012b). The content synchronization task represents a challenging application scenario to test the capabilities of CLTE systems, by proposing a richer inventory of phenomena (i.e. “Bidirectional”/“Forward”/“Backward”/“No entailment” multi-directional entailment relations). Multi-directional CLTE recognition can be seen as the identification of semantic equivalence and information disparity between two topically related sentences, at the cross-lingual level. This is a core aspect of the multilingual content synchronization task, which represents a challenging application scenario for a variety of N</context>
<context position="2843" citStr="Mehdad et al., 2012" startWordPosition="392" endWordPosition="395">” (translation of the two input texts into the same language, as in (Mehdad et al., 2010)), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated approach still rely on phrasal matching techniques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguistically motivated features, in our participation, we propose an approach that combines lexical, syntactic and semantic features within a machine learning framework (Mehdad et al., 2012a). Our submitted runs have been produced by training and optimizing multiclass and binary SVM classifiers, over the Spanish-English (Spa-Eng) development set. In both cases, our results were positive, showing significant improvements over the median systems and average scores obtained by participants. The overall results confirm the difficulty of the task, and the potential of our approach in combining linguistically motivated features in a “pure” cross-lingual approach that avoids the recourse to external MT components. 701 First Joint Conference on Lexical and Computational Semantics (*SEM)</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2012b. Match without a Referee: Evaluating MT Adequacy without Reference Translations. In Proceedings of the Machine Translation Workshop (WMT2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>Y Mehdad</author>
</authors>
<title>Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-day rush.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk,</booktitle>
<pages>212--216</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1387" citStr="Negri and Mehdad, 2010" startWordPosition="184" endWordPosition="187">eriments over the provided dataset. Our best run achieved an accuracy of 50.4% on the Spanish-English dataset (with the average score and the median system respectively achieving 40.7% and 34.6%), demonstrating the effectiveness of a “pure” cross-lingual approach that avoids intermediate translations. 1 Introduction So far, cross-lingual textual entailment (CLTE) (Mehdad et al., 2010) has been applied to: i) available TE datasets (“YES”/“NO” uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation evaluation datasets (Mehdad et al., 2012b). The content synchronization task represents a challenging application scenario to test the capabilities of CLTE systems, by proposing a richer inventory of phenomena (i.e. “Bidirectional”/“Forward”/“Backward”/“No entailment” multi-directional entailment relations). Multi-directional CLTE recognition can be seen as the identification of semantic equivalence and information disparity between two topically related sentences, at the cross-lingual level. This is a core aspect of the multilingual content synchronization task, </context>
</contexts>
<marker>Negri, Mehdad, 2010</marker>
<rawString>M. Negri and Y. Mehdad. 2010. Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-day rush. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 212–216. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Negri</author>
<author>L Bentivogli</author>
<author>Y Mehdad</author>
<author>D Giampiccolo</author>
<author>A Marchetti</author>
</authors>
<title>Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="3672" citStr="Negri et al., 2011" startWordPosition="518" endWordPosition="521">significant improvements over the median systems and average scores obtained by participants. The overall results confirm the difficulty of the task, and the potential of our approach in combining linguistically motivated features in a “pure” cross-lingual approach that avoids the recourse to external MT components. 701 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 701–705, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Experiments In our experiment we used the Spa-Eng portion of the dataset described in (Negri et al., 2012; Negri et al., 2011), consisting of 500 multi-directional entailment pairs which was provided to train the systems and 500 pairs for the submission. Each pair in the dataset is annotated with “Bidirectional”, “Forward”, “Backward” or “No entailment” judgements. 2.1 Approach Our system builds on the integration of lexical, syntactic and semantic features in a supervised learning framework. Our model builds on three main feature sets, respectively derived from: i) phrase tables, ii) dependency relations, and iii) semantic phrase tables. 1. Phrase Table (PT) matching: through these features, a semantic judgement abo</context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, and A. Marchetti. 2011. Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora. In Proceedings of EMNLP 2011. M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. 2012. Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="6296" citStr="Och and Ney, 2000" startWordPosition="951" endWordPosition="954">estimate the portion of phrases in H that are matched at each level n (Equation 1).1 Since languages can express the same meaning with different amounts of words, a phrase with length n in H can match a phrase with any length in T. Matchn Matchn = (1) JH(n) In order to build English-Spanish phrase tables for our experiments, we used the freely available Europarl V.4, News Commentary and United Nations Spanish-English parallel corpora released for the WMT10 Shared Translation Task.2 We run the TreeTagger (Schmid, 1995) and Snowball stemmer (Porter, 2001) for preprocessing, and used the Giza++ (Och and Ney, 2000) toolkit to align the tokenized corpora at the word level. Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007). 2. Dependency Relation (DR) matching targets the increase of CLTE precision. By adding syntactic constraints to the matching process, DR features aim to reduce wrong matches often occurring at the lexical level. For instance, the contradiction between “Yahoo acquired Overture” and “Overture compr´o Yahoo” is evident when syntax (in this case subject-object inversion) is taken into account, but can not be caught </context>
<context position="11273" citStr="Och and Ney, 2000" startWordPosition="1726" endWordPosition="1729">er n-grams (i.e. those providing more contextual information) from H into T and vice-versa. Like lexical phrase tables, SPTs are extracted from parallel corpora. As a first step, we annotate the corpora with named-entity taggers (FreeLing in our case (Carreras et al., 2004)) for the source and target languages, replacing named entities with general semantic labels chosen from a coarse-grained taxonomy including the categories: person, location, organization, date and numeric expression. Then, we combine the sequences of unique labels into one single token of the same label, and we run Giza++ (Och and Ney, 2000) to align the resulting semantically augmented corpora. Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al., 2007). For the matching phase, we first annotate T and H in the same way we labeled our parallel corpora. Then, for each n-gram order (n=1 to 5, excluding punctuation), we use the SPT to calculate a matching score (SPT matchn, see Equation 3), as the number of n-grams in H that match with phrases in T divided by the number of n-grams in H. The matching algorithm is same as the phrase table matching one. SPT matchn ISPTn(</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. Improved Statistical Alignment Models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P G Otero</author>
<author>I G Lopez</author>
</authors>
<title>A Grammatical Formalism Based on Patterns of Part-of-Speech Tags. International journal of corpus linguistics,</title>
<date>2011</date>
<pages>16--1</pages>
<contexts>
<context position="8390" citStr="Otero and Lopez, 2011" startWordPosition="1287" endWordPosition="1290">can match “nsubj (ama, John)” and “nsubj (quiere, John)” but not “dobj (quiere, John)”. Given the dependency tree representations of T and H, for each grammatical relation (r) we calculate a DR matching score (Matchr, see Equation 2) as the number of matching occurrences of r in T and H (respectively DRr(T) and DRr(H)), divided by the number of occurrences of r in H. matchr _ |match(DRr(T),DRr(H)) |(2) |DRr(H)| In our experiments, in order to extract dependency relation (DR) matching features, the dependency tree representations of English and Spanish texts have been produced with DepPattern (Otero and Lopez, 2011). We then mapped the sets of dependency relation labels for the EnglishSpanish parser output into: Adjunct, Determiner, Object, Subject and Preposition. The dictionary, containing about 9M bilingual word pairs, created during the alignment of the English-Spanish parallel corpora provided the lexical knowledge to perform matches when the connected words are different. 3. Semantic Phrase Table (SPT) matching: represents a novel way to leverage the integration of semantics and MT-derived techniques. To this aim, SPT improves CLTE methods relying on pure lexical match, by means of “generalized” ph</context>
</contexts>
<marker>Otero, Lopez, 2011</marker>
<rawString>P.G. Otero and I.G. Lopez. 2011. A Grammatical Formalism Based on Patterns of Part-of-Speech Tags. International journal of corpus linguistics, 16(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Porter</author>
</authors>
<title>Snowball: A language for stemming algorithms.</title>
<date>2001</date>
<contexts>
<context position="6237" citStr="Porter, 2001" startWordPosition="943" endWordPosition="944">e number of phrases in the hypothesis H(n) is used to estimate the portion of phrases in H that are matched at each level n (Equation 1).1 Since languages can express the same meaning with different amounts of words, a phrase with length n in H can match a phrase with any length in T. Matchn Matchn = (1) JH(n) In order to build English-Spanish phrase tables for our experiments, we used the freely available Europarl V.4, News Commentary and United Nations Spanish-English parallel corpora released for the WMT10 Shared Translation Task.2 We run the TreeTagger (Schmid, 1995) and Snowball stemmer (Porter, 2001) for preprocessing, and used the Giza++ (Och and Ney, 2000) toolkit to align the tokenized corpora at the word level. Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007). 2. Dependency Relation (DR) matching targets the increase of CLTE precision. By adding syntactic constraints to the matching process, DR features aim to reduce wrong matches often occurring at the lexical level. For instance, the contradiction between “Yahoo acquired Overture” and “Overture compr´o Yahoo” is evident when syntax (in this case subject-obje</context>
</contexts>
<marker>Porter, 2001</marker>
<rawString>M. Porter. 2001. Snowball: A language for stemming algorithms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Treetaggera language independent part-of-speech tagger. Institut f¨ur Maschinelle Sprachverarbeitung,</title>
<date>1995</date>
<location>Universit¨at Stuttgart.</location>
<contexts>
<context position="6201" citStr="Schmid, 1995" startWordPosition="938" endWordPosition="939"> the number of matches Matchn and the number of phrases in the hypothesis H(n) is used to estimate the portion of phrases in H that are matched at each level n (Equation 1).1 Since languages can express the same meaning with different amounts of words, a phrase with length n in H can match a phrase with any length in T. Matchn Matchn = (1) JH(n) In order to build English-Spanish phrase tables for our experiments, we used the freely available Europarl V.4, News Commentary and United Nations Spanish-English parallel corpora released for the WMT10 Shared Translation Task.2 We run the TreeTagger (Schmid, 1995) and Snowball stemmer (Porter, 2001) for preprocessing, and used the Giza++ (Och and Ney, 2000) toolkit to align the tokenized corpora at the word level. Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007). 2. Dependency Relation (DR) matching targets the increase of CLTE precision. By adding syntactic constraints to the matching process, DR features aim to reduce wrong matches often occurring at the lexical level. For instance, the contradiction between “Yahoo acquired Overture” and “Overture compr´o Yahoo” is evident wh</context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>H. Schmid. 1995. Treetaggera language independent part-of-speech tagger. Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>