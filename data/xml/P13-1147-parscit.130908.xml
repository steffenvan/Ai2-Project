<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001195">
<title confidence="0.998214">
Embedding Semantic Similarity in Tree Kernels for Domain Adaptation
of Relation Extraction
</title>
<author confidence="0.998979">
Barbara Plank∗ Alessandro Moschitti
</author>
<affiliation confidence="0.9985925">
Center for Language Technology QCRI - Qatar Foundation &amp;
University of Copenhagen, Denmark DISI - University of Trento, Italy
</affiliation>
<email confidence="0.995431">
bplank@gmail.com amoschitti@qf.org.qa
</email>
<sectionHeader confidence="0.993739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998579">
Relation Extraction (RE) is the task of
extracting semantic relationships between
entities in text. Recent studies on rela-
tion extraction are mostly supervised. The
clear drawback of supervised methods is
the need of training data: labeled data is
expensive to obtain, and there is often a
mismatch between the training data and
the data the system will be applied to.
This is the problem of domain adapta-
tion. In this paper, we propose to combine
(i) term generalization approaches such as
word clustering and latent semantic anal-
ysis (LSA) and (ii) structured kernels to
improve the adaptability of relation ex-
tractors to new text genres/domains. The
empirical evaluation on ACE 2005 do-
mains shows that a suitable combination
of syntax and lexical generalization is very
promising for domain adaptation.
</bodyText>
<sectionHeader confidence="0.999126" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.93441506">
Relation extraction is the task of extracting se-
mantic relationships between entities in text, e.g.
to detect an employment relationship between the
person Larry Page and the company Google in
the following text snippet: Google CEO Larry
Page holds a press announcement at its headquar-
ters in New York on May 21, 2012. Recent stud-
ies on relation extraction have shown that super-
vised approaches based on either feature or ker-
nel methods achieve state-of-the-art accuracy (Ze-
lenko et al., 2002; Culotta and Sorensen, 2004;
∗ The first author was affiliated with the Department of
Computer Science and Information Engineering of the Uni-
versity of Trento (Povo, Italy) during the design of the mod-
els, experiments and writing of the paper.
Zhang et al., 2005; Zhou et al., 2005; Zhang et
al., 2006; Bunescu, 2007; Nguyen et al., 2009;
Chan and Roth, 2010; Sun et al., 2011). How-
ever, the clear drawback of supervised methods is
the need of training data, which can slow down
the delivery of commercial applications in new
domains: labeled data is expensive to obtain, and
there is often a mismatch between the training data
and the data the system will be applied to. Ap-
proaches that can cope with domain changes are
essential. This is the problem of domain adapta-
tion (DA) or transfer learning (TL). Technically,
domain adaptation addresses the problem of learn-
ing when the assumption of independent and iden-
tically distributed (i.i.d.) samples is violated. Do-
main adaptation has been studied extensively dur-
ing the last couple of years for various NLP tasks,
e.g. two shared tasks have been organized on do-
main adaptation for dependency parsing (Nivre et
al., 2007; Petrov and McDonald, 2012). Results
were mixed, thus it is still a very active research
area.
However, to the best of our knowledge, there
is almost no work on adapting relation extraction
(RE) systems to new domains.1 There are some
prior studies on the related tasks of multi-task
transfer learning (Xu et al., 2008; Jiang, 2009)
and distant supervision (Mintz et al., 2009), which
are clearly related but different: the former is the
problem of how to transfer knowledge from old
to new relation types, while distant supervision
tries to learn new relations from unlabeled text
by exploiting weak-supervision in the form of a
knowledge resource (e.g. Freebase). We assume
the same relation types but a shift in the underlying
</bodyText>
<footnote confidence="0.991299333333333">
1Besides an unpublished manuscript of a student project,
but it is not clear what data was used. http://tinyurl.com/
bn2hdwk
</footnote>
<page confidence="0.89467">
1498
</page>
<note confidence="0.915917">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1498–1507,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999969214285714">
data distribution. Weak supervision is a promis-
ing approach to improve a relation extraction sys-
tem, especially to increase its coverage in terms of
types of relations covered. In this paper we ex-
amine the related issue of changes in the underly-
ing data distribution, while keeping the relations
fixed. Even a weakly supervised system is ex-
pected to perform well when applied to any kind of
text (other domain/genre), thus ideally, we believe
that combining domain adaptation with weak su-
pervision is the way to go in the future. This study
is a first step towards this.
We focus on unsupervised domain adaptation,
i.e. no labeled target data. Moreover, we consider
a particular domain adaptation setting: single-
system DA, i.e. learning a single system able to
cope with different but related domains. Most
studies on DA so far have focused on building
a specialized system for every specific target do-
main, e.g. Blitzer et al. (2006). In contrast, the
goal here is to build a single system that can ro-
bustly handle several domains, which is in line
with the setup of the recent shared task on pars-
ing the web (Petrov and McDonald, 2012). Par-
ticipants were asked to build a single system that
can robustly parse all domains (reviews, weblogs,
answers, emails, newsgroups), rather than to build
several domain-specific systems. We consider this
as a shift in what was considered domain adapta-
tion in the past (adapt from source to a specific tar-
get) and what can be considered a somewhat dif-
ferent recent view of DA, that became widespread
since 2011/2012. The latter assumes that the tar-
get domain(s) is/are not really known in advance.
In this setup, the domain adaptation problem boils
down to finding a more robust system (Søgaard
and Johannsen, 2012), i.e. one wants to build a
system that can robustly handle any kind of data.
We propose to combine (i) term generalization
approaches and (ii) structured kernels to improve
the performance of a relation extractor on new
domains. Previous studies have shown that lexi-
cal and syntactic features are both very important
(Zhang et al., 2006). We combine structural fea-
tures with lexical information generalized by clus-
ters or similarity. Given the complexity of feature
engineering, we exploit kernel methods (Shawe-
Taylor and Cristianini, 2004). We encode word
clusters or similarity in tree kernels, which, in
turn, produce spaces of tree fragments. For ex-
ample, “president”, “vice-president” and “Texas”,
“US”, are terms indicating an employment rela-
tion between a person and a location. Rather than
only matching the surface string of words, lexi-
cal similarity enables soft matches between similar
words in convolution tree kernels. In the empir-
ical evaluation on Automatic Content Extraction
(ACE) data, we evaluate the impact of convolu-
tion tree kernels embedding lexical semantic sim-
ilarities. The latter is derived in two ways with:
(a) Brown word clustering (Brown et al., 1992);
and (b) Latent Semantic Analysis (LSA). We first
show that our system aligns well with the state of
the art on the ACE 2004 benchmark. Then, we
test our RE system on the ACE 2005 data, which
exploits kernels, structures and similarities for do-
main adaptation. The results show that combining
the huge space of tree fragments generalized at the
lexical level provides an effective model for adapt-
ing RE systems to new domains.
</bodyText>
<sectionHeader confidence="0.96736" genericHeader="introduction">
2 Semantic Syntactic Tree Kernels
</sectionHeader>
<bodyText confidence="0.982373538461539">
In kernel-based methods, both learning and classi-
fication only depend on the inner product between
instances. Kernel functions can be efficiently and
implicitly computed by exploiting the dual formu-
lation: �i=1..l yiαiO(oi)O(o) + b = 0, where oi
and o are two objects, O is a mapping from an ob-
ject to a feature vector xz and O(oi)O(o) = K(oi, o)
is a kernel function implicitly defining such a map-
ping. In case of structural kernels, K determines
the shape of the substructures describing the ob-
jects. Commonly used kernels in NLP are string
kernels (Lodhi et al., 2002) and tree kernels (Mos-
chitti, 2006; Moschitti, 2008).
</bodyText>
<equation confidence="0.995671">
NP
PP
NP
E2
</equation>
<bodyText confidence="0.982771882352941">
clearly a limitation. For instance, the fragments
corresponding to governor from Texas and
head of Maryland are intuitively semanti-
cally related and should obtain a higher match
when compared to mother of them.
Semantic syntactic tree kernels (Bloehdorn
and Moschitti, 2007a; Bloehdorn and Moschitti,
2007b; Croce et al., 2011) provide one way to ad-
dress this problem by introducing similarity a that
allows soft matches between words and, conse-
quently, between fragments containing them. Let
N1 and N2 be the set of nodes in T1 and T2, re-
spectively. Moreover, let Ii(n) be an indicator
variable that is 1 if subtree i is rooted at n and
0 otherwise. The syntactic semantic convolution
kernel TKσ (Bloehdorn and Moschitti, 2007b)
over T1 and T2 is computed as TKσ(T 1, T2) =
</bodyText>
<equation confidence="0.9760315">
Pn1EN1,n2EN2 Aσ(n1, n2) where Aσ(n1, n2) =
Pn1EN1 Pn2EN2 Pi Ii(n1)Ii(n2) is computed ef-
</equation>
<bodyText confidence="0.926353">
ficiently using the following recursive defini-
tion: i) If the nodes n1 and n2 are ei-
ther different or have different number of chil-
dren then Aσ(n1, n2) = 0; else ii) If
n1 and n2 are pre-terminals then Aσ(n1,n2)
</bodyText>
<equation confidence="0.9827945">
= λQnc(n1)
j=1 Aσ(ch(n1,j),ch(n2,j)), where a
</equation>
<bodyText confidence="0.960401">
measures the similarity between the correspond-
ing children of n1 and n2; iii) If n1 and n2 have
</bodyText>
<equation confidence="0.9953495">
identical children: Aσ(n1, n2) = λQnc(n1)
j=1 (1 +
</equation>
<bodyText confidence="0.953791">
Aσ(ch(n1, j)), ch(n2, j)); else Aσ(n1, n2) = 0.
TKσ combines generalized lexical with structural
information: it allows matching tree fragments
that have the same syntactic structure but differ in
their terminals. After introducing related work, we
will discuss computational structures for RE and
their extension with semantic similarity.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999851203703704">
Semantic syntactic tree kernels have been previ-
ously used for question classification (Bloehdorn
and Moschitti, 2007a; Bloehdorn and Moschitti,
2007b; Croce et al., 2011). These kernels have
not yet been studied for either domain adaptation
or RE. Brown clusters were studied previously for
feature-based approaches to RE (Sun et al., 2011;
Chan and Roth, 2010), but they were not yet eval-
uated in kernels. Thus, we present a novel applica-
tion of semantic syntactic tree kernels and Brown
clusters for domain adaptation of tree-kernel based
relation extraction.
Regarding domain adaptation, several meth-
ods have been proposed, ranging from instance
weighting (Jiang and Zhai, 2007) to approaches
that change the feature representation (Daum´e III,
2007) or try to exploit pivot features to find
a generalized shared representation between do-
mains (Blitzer et al., 2006). The easy-adapt ap-
proach presented in Daum´e III (2007) assumes the
supervised adaptation setting and is thus not ap-
plicable here. Structural correspondence learn-
ing (Blitzer et al., 2006) exploits unlabeled data
from both source and target domain to find cor-
respondences among features from different do-
mains. These correspondences are then integrated
as new features in the labeled data of the source
domain. The key to SCL is to exploit pivot fea-
tures to automatically identify feature correspon-
dences, and as such is applicable to feature-based
approaches but not in our case since we do not as-
sume availability of target domain data. Instead,
we apply a similar idea where we exploit an en-
tire unlabeled corpus as pivot, and compare our
approach to instance weighting (Jiang and Zhai,
2007).
Instance weighting is a method for domain
adaptation in which instance-dependent weights
are assigned to the loss function that is mini-
mized during the training process. Let l(x, y, 0)
be some loss function. Then, as shown in Jiang
and Zhai (2007), the loss function can be weighted
by Oil(x, y, 0), such that Oi = p (x?) , where Ps
and Pt are the source and target distributions, re-
spectively. Huang et al. (2007) present an appli-
cation of instance weighting to support vector ma-
chines by minimizing the following re-weighted
function: minθ,ξ12||0||2 + C Pmi=1 Oiξi. Finding
a good weight function is non-trivial (Jiang and
Zhai, 2007) and several approximations have been
evaluated in the past, e.g. Søgaard and Haulrich
(2011) use a bigram-based text classifier to dis-
criminate between domains. We will use a binary
classifier trained on RE instance representations.
</bodyText>
<sectionHeader confidence="0.970839" genericHeader="method">
4 Computational Structures for RE
</sectionHeader>
<bodyText confidence="0.999920714285714">
A common way to represent a constituency-based
relation instance is the PET (path-enclosed-tree),
the smallest subtree including the two target enti-
ties (Zhang et al., 2006). This is basically the for-
mer structure PAF2 (predicate argument feature)
defined in Moschitti (2004) for the extraction of
predicate argument relations. The syntactic rep-
</bodyText>
<footnote confidence="0.884947">
2It is the smallest subtree enclosing the predicate and one
of its argument node.
</footnote>
<page confidence="0.975146">
1500
</page>
<bodyText confidence="0.999956096774194">
resentation used by Zhang et al. (2006) (we will
refer to it as PET Zhang) is the PET with enriched
entity information: e.g. E1-NAM-PER, including
entity type (PER, GPE, LOC, ORG) and mention
type (NAM, NOM, PRO, PRE: name, nominal,
pronominal or premodifier). An alternative ker-
nel that does not use syntactic information is the
Bag-of-Words (BOW) kernel, where a single root
node is added above the terminals. Note that in
this BOW kernel we actually mark target entities
with E1/E2. Therefore, our BOW kernel can be
considered an enriched BOW model. If we do not
mark target entities, performance drops consider-
ably, as discussed later.
As shown by Zhang et al. (2006), includ-
ing gold-standard information on entity and men-
tion type substantially improves relation extrac-
tion performance. We will use this gold infor-
mation also in Section 6.1 to show that our sys-
tem aligns well to the state of the art on the ACE
2004 benchmark. However, in a realistic setting
this information is not available or noisy. In fact,
as we discuss later, excluding gold entity informa-
tion decreases system performance considerably.
In the case of porting a system to new domains
entity information will be unreliable or missing.
Therefore, in our domain adaptation experiments
on the ACE 2005 data (Section 6.3) we will not
rely on this gold information but rather train a sys-
tem using PET (target mentions only marked with
E1/E2 and no gold entity label).3
</bodyText>
<subsectionHeader confidence="0.998879">
4.1 Syntactic Semantic Structures
</subsectionHeader>
<bodyText confidence="0.999827692307692">
Combining syntax with semantics has a clear ad-
vantage: it generalizes lexical information encap-
sulated in syntactic parse trees, while at the same
time syntax guides semantics in order to obtain an
effective semantic similarity. In fact, lexical infor-
mation is highly affected by data-sparseness, thus
tree kernels combined with semantic information
created from additional resources should provide
a way to obtain a more robust system.
We exploit this idea here for domain adaptation
(DA): if words are generalized by semantic simi-
larity L5, then in a hypothetical world changing
L5 such that it reflects the target domain would
</bodyText>
<page confidence="0.822578">
11
</page>
<bodyText confidence="0.97813055">
3In a setup where gold label info is included, the impact
of similarity-based methods is limited – gold information
seems to predominate. We argue that whenever gold data is
not available, distributional semantics paired with kernels can
be useful to improve generalization and complement missing
gold info.
allow the system to perform better in the target
domain. The question remains how to establish a
link between the semantic similarity in the source
and target domain. We propose to use an entire
unlabeled corpus as pivot: this corpus must be
general enough to encapsulate the source and tar-
get domains of interest. The idea is to (i) learn
semantic similarity between words on the pivot
corpus and (ii) use tree kernels embedding such
a similarity to learn a RE system on the source,
which allows to generalize to the new target do-
main. This reasoning is related to Structural Cor-
respondence Learning (SCL) (Blitzer et al., 2006).
In SCL, a representation shared across domains is
learned by exploiting pivot features, where a set
of pivot features has to be selected (usually a few
thousands). In our case pivots are words that co-
occur with the target words in a large unlabeled
corpus and are thus implicitly represented in the
similarity matrix. Thus, in contrast to SCL, we do
not need to select a set of pivot features but rather
rely on the distributional hypothesis to infer a se-
mantic similarity from a large unlabeled corpus.
Then, this similarity is incorporated into the tree
kernel that provides the necessary restriction for
an effective semantic similarity calculation. One
peculiarity of our work is that we exploit a large
amount of general data, i.e. data gathered from the
web, which is a different but also more challeng-
ing scenario than the general unsupervised DA set-
ting where domain specific data is available. We
study two ways for term generalization in tree ker-
nels: Brown words clusters and Latent Semantic
Analysis (LSA), both briefly described next.
</bodyText>
<equation confidence="0.9231088">
a) replace pos
NP
PP
NP
E2
</equation>
<page confidence="0.814885">
1501
</page>
<bodyText confidence="0.9999591">
evaluate different ways to integrate cluster infor-
mation into tree kernels, some of which are illus-
trated in Figure 2.
For LSA, we compute term similarity functions
following the distributional hypothesis (Harris,
1964), i.e. the meaning of a word can be described
by the set of textual contexts in which it appears.
The original word-by-word context matrix M is
decomposed through Singular Value Decomposi-
tion (SVD) (Golub and Kahan, 1965), where M
is approximated by UlSlVT
l . This approxima-
tion supplies a way to project a generic term wi
into the l-dimensional space using W = UlS1/2
l ,
where each row corresponds to the vectors zwi.
Given two words w1 and w2, the term similarity
function Q is estimated as the cosine similarity be-
tween the corresponding projections zw1, zw2 and
used in the kernel as described in Section 2.
</bodyText>
<sectionHeader confidence="0.999372" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999985107142857">
We treat relation extraction as a multi-class classi-
fication problem and use SVM-light-TK4 to train
the binary classifiers. The output of the classifiers
is combined using the one-vs-all approach. We
modified the SVM-light-TK package to include
the semantic tree kernels and instance weight-
ing. The entire software package is publicly avail-
able.5 For the SVMs, we use the same parameters
as Zhang et al. (2006): A = 0.4, c = 2.4 using the
Collins Kernel (Collins and Duffy, 2001). The pre-
cision/recall trade-off parameter for the none class
was found on held-out data: j = 0.2. Evalua-
tion metrics are standard micro average Precision,
Recall and balanced Fscore (F1). To compute sta-
tistical significance, we use the approximate ran-
domization test (Noreen, 1989).6 In all our exper-
iments, we model argument order of the relations
explicitly. Thus, for instance for the 7 coarse ACE
2004 relations, we build 14 coarse-grained classi-
fiers (two for each coarse ACE 2004 relation type
except for PER-SOC, which is symmetric, and one
classifier for the none relation).
Data We use two datasets. To compare our
model against the state of the art we use the ACE
2004 data. It contains 348 documents and 4,374
positive relation instances. To generate the train-
ing data, we follow prior studies and extract an
instance for every pair of mentions in the same
</bodyText>
<footnote confidence="0.999924666666667">
4http://disi.unitn.it/moschitti/Tree-Kernel.htm
5http://disi.unitn.it/ikernels/RelationExtraction
6http://www.nlpado.de/˜sebastian/software/sigf.shtml
</footnote>
<bodyText confidence="0.9541965">
sentence, which are separated by no more than
three other mentions (Zhang et al., 2006; Sun et
al., 2011). After data preprocessing, we obtained
4,327 positive and 39,120 negative instances.
</bodyText>
<table confidence="0.9991854">
ACE 2005 docs sents ASL relations
nw+bn 298 5029 18.8 3562
bc 52 2267 16.3 1297
cts 34 2696 15.3 603
wl 114 1697 22.6 677
</table>
<tableCaption confidence="0.999907">
Table 1: Overview of the ACE 2005 data.
</tableCaption>
<bodyText confidence="0.999867588235294">
For the domain adaptation experiments we use
the ACE 2005 corpus. An overview of the data
is given in Table 1. Note that this data is dif-
ferent from ACE 2004: it covers different years
(ACE 2004: texts from 2001-2002; ACE 2005:
2003-2005). Moreover, the annotation guidelines
have changed (for example, ACE 2005 contains no
discourse relation, some relation (sub)types have
changed/moved, and care must be taken for differ-
ences in SGM markup, etc.).
More importantly, the ACE 2005 corpus cov-
ers additional domains: weblogs, telephone con-
versation, usenet and broadcast conversation. In
the experiments, we use news (the union of nw
and bn) as source domain, and weblogs (wl), tele-
phone conversations (cts) and broadcast conversa-
tion (bc) as target domains.7 We take half of bc
as only target development set, and leave the re-
maining data and domains for final testing (since
they are already small, cf. Table 1). To get a feel-
ing of how these domains differ, Figure 3 depicts
the distribution of relations in each domain and Ta-
ble 2 provides the most frequent out-of-vocabulary
words together with their percentage.
Lexical Similarity and Clustering We applied
LSA to ukWaC (Baroni et al., 2009), a 2 billion
word corpus constructed from the Web8 using the
s-space toolkit.9 Dimensionality reduction was
performed using SVD with 250 dimensions, fol-
lowing (Croce et al., 2011). The co-occurrence
matrix was transformed by tfidf. For the Brown
word clusters, we used Percy Liang’s implemen-
tation10 of the Brown clustering algorithm (Liang,
2005). We incorporate cluster information by us-
</bodyText>
<footnote confidence="0.977339">
7We did not consider the usenet subpart, since it is among
the smaller domains and data-preprocessing was difficult.
8http://wacky.sslmit.unibo.it/
9http://code.google.com/p/airhead-research/
10https://github.com/percyliang/brown-cluster
</footnote>
<page confidence="0.984965">
1502
</page>
<figure confidence="0.712999333333333">
Distribution of relations across domains (normalized)
nw_bn bc cts wl
Domain
</figure>
<figureCaption confidence="0.897638">
Figure 3: Distribution of relations in ACE 2005.
</figureCaption>
<table confidence="0.998744428571429">
Dom Most frequent OOV words
bc insurance, unintelligible, malprac-
(24%) tice, ph, clip, colonel, crosstalk
cts uh, Yeah, um, eh, mhm, uh-huh, ˜,
(34%) ah, mm, th, plo, topic, y, workplace
wl title, Starbucks, Well, blog, !!,
(49%) werkheiser, undefeated, poor, shit
</table>
<tableCaption confidence="0.980892">
Table 2: For each domain the percentage of target
</tableCaption>
<bodyText confidence="0.984992086956522">
domain words (types) that are unseen in the source
together with the most frequent OOV words.
ing the 10-bit cluster prefix (Sun et al., 2011; Chan
and Roth, 2010). For the domain adaptation exper-
iments, we use ukWaC corpus-induced clusters as
bridge between domains. We limited the vocabu-
lary to that in ACE 2005, which are approximately
16k words. Following previous work, we left case
intact in the corpus and induced 1,000 word clus-
ters from words appearing at least 100 times.11
DA baseline We compare our approach to in-
stance weighting (Jiang and Zhai, 2007). We mod-
ified SVM-light-TK such that it takes a parameter
vector βi, .., βm as input, where each βi represents
the relative importance of example i with respect
to the target domain (Huang et al., 2007; Wid-
mer, 2008). To estimate the importance weights,
we train a binary classifier that distinguishes be-
tween source and target domain instances. We
consider the union of the three target domains as
target data. To train the classifier, the source in-
stances are marked as negative and the target in-
stances are marked as positive. Then, this classi-
</bodyText>
<footnote confidence="0.6264465">
11Clusters are available at http://disi.unitn.it/ikernels/
RelationExtraction
</footnote>
<table confidence="0.9982686">
Prior Work: Type P R F1
Zhang (2006), tree only K,yes 74.1 62.4 67.7
Zhang (2006), linear K,yes 73.5 67.0 70.1
Zhang (2006), poly K,yes 76.1 68.4 72.1
Sun &amp; Grishman (2011) F,yes 73.4 67.7 70.4
Jiang &amp; Zhai (2007) F,no 73.4 70.2 71.3
Our re-implementation: Type P R F1
Tree only (PET Zhang) K,yes 70.7 62.5 66.3
Linear composite K,yes 71.3 66.6 68.9
Polynomial composite K,yes 72.6 67.7 70.1
</table>
<tableCaption confidence="0.981741333333333">
Table 3: Comparison to previous work on the 7 re-
lations of ACE 2004. K: kernel-based; F: feature-
based; yes/no: models argument order explicitly.
</tableCaption>
<bodyText confidence="0.994425">
fier is applied to the source data. To obtain the
weights βi, we convert the SVM scores into pos-
terior probabilities by training a sigmoid using the
modified Platt algorithm (Lin et al., 2007).12
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="evaluation">
6 Results
</sectionHeader>
<subsectionHeader confidence="0.999854">
6.1 Alignment to Prior Work
</subsectionHeader>
<bodyText confidence="0.999951703703704">
Although most prior studies performed 5-fold
cross-validation on ACE 2004, it is often not clear
whether the partitioning has been done on the in-
stance or on the document level. Moreover, it is
often not stated whether argument order is mod-
eled explicitly, making it difficult to compare sys-
tem performance. Citing Wang (2008), “We feel
that there is a sense of increasing confusion down
this line of research”. To ease comparison for fu-
ture research we use the same 5-fold split on the
document level as Sun et al. (2011)13 and make
our system publicly available (see Section 5).
Table 3 shows that our system (bottom) aligns
well with the state of the art. Our best sys-
tem (composite kernel with polynomial expan-
sion) reaches an F1 of 70.1, which aligns well to
the 70.4 of Sun et al. (2011) that use the same data-
split. This is slightly behind that of Zhang (2006);
the reason might be threefold: i) different data par-
titioning; ii) different pre-processing; iii) they in-
corporate features from additional sources, i.e. a
phrase chunker, dependency parser and semantic
resources (Zhou et al., 2005) (we have on aver-
age 9 features/instance, they use 40). Since we
focus on evaluating the impact of semantic simi-
larity in tree kernels, we think our system is very
competitive. Removing gold entity and mention
</bodyText>
<footnote confidence="0.714298333333333">
12Other weightings/normalizations (like LDA) didn’t im-
prove the results; best was to take the posteriors and add c.
13 http://cs.nyu.edu/˜asun/pub/ACL11_CVFileList.txt
</footnote>
<figure confidence="0.982708375">
ART
GEN−AFF
ORG−AFF
PART−WHOLE
PER−SOC
PHYS
0.0 0.1 0.2 0.3 0.4
Proportion
</figure>
<page confidence="0.972477">
1503
</page>
<bodyText confidence="0.999904">
information results in a significant F1 drop from
66.3% to 54.2%. However, in a realistic setting
we do not have gold entity info available, espe-
cially not in the case when we apply the system
to any kind of text. Thus, in the domain adapta-
tion setup we assume entity boundaries given but
not their label. Clearly, evaluating the approach on
predicted mentions, e.g. Giuliano et al. (2007), is
another important dimension, however, out of the
scope of the current paper.
</bodyText>
<subsectionHeader confidence="0.995521">
6.2 Tree Kernels with Brown Word Clusters
</subsectionHeader>
<bodyText confidence="0.9994015">
To evaluate the effectiveness of Brown word clus-
ters in tree kernels, we evaluated different instance
representations (cf. Figure 2) on the ACE 2005 de-
velopment set. Table 4 shows the results.
</bodyText>
<table confidence="0.998287428571429">
P R F1
52.2 41.7 46.4
49.7 38.6 43.4
56.3 41.9 48.0
55.3 41.6 47.5
54.5 42.2 47.6
55.8 41.1 47.3
</table>
<tableCaption confidence="0.999546">
Table 4: Brown clusters in tree kernels (cf. Fig 2).
</tableCaption>
<bodyText confidence="0.999986">
To summarize, we found: i) it is generally a bad
idea to dismiss lexical information completely,
i.e. replacing or ignoring terminals harms perfor-
mance; ii) the best way to incorporate Brown clus-
ters is to replace the Pos tag with the cluster bit-
string; iii) marking all words is generally better
than only mentions; this is in contrast to Sun et
al. (2011) who found that in their feature-based
system it was better to add cluster information
to entity mentions only. As we will discuss, the
combination of syntax and semantics exploited in
this novel kernel avoids the necessity of restricting
cluster information to mentions only.
</bodyText>
<subsectionHeader confidence="0.999466">
6.3 Semantic Tree Kernels for DA
</subsectionHeader>
<bodyText confidence="0.999958475409836">
To evaluate the effectiveness of the proposed ker-
nels across domains, we use the ACE 2005 data
as testbed. Following standard practices on ACE
2004, the newswire (nw) and broadcast news (bn)
data from ACE 2005 are considered training data
(labeled source domain). The test data consists
of three targets: broadcast conversation, telephone
conversation, weblogs. As we want to build a sin-
gle system that is able to handle heterogeneous
data, we do not assume that there is further unla-
beled domain-specific data, but we assume to have
a large unlabeled corpus (ukWaC) at our disposal
to improve the generalizability of our models.
Table 5 presents the results. In the first three
rows we see the performance of the baseline
models (PET, BOW and BOW without mark-
ing). In-domain (col 1): when evaluated on the
same domain the system was trained on (nw+bn,
5-fold cross-validation). Out-of-domain perfor-
mance (cols 2-4): the system evaluated on the
targets, namely broadcast conversation (bc), tele-
phone conversation (cts) and weblogs (wl). While
the system achieves a performance of 46.0 F1
within its own domain, the performance drops to
45.3, 43.4 and 34.0 F1 on the target domains, re-
spectively. The BOW kernel that disregards syn-
tax is often less effective (row 2). We see also
the effect of target entity marking: the BOW ker-
nel without entity marking performs substantially
worse (row 3). For the remaining experiments we
use the BOW kernel with entity marking.
Rows 4 and 5 of Table 5 show the effect of
using instance weighting for the PET baseline.
Two models are shown: they differ in whether
PET or BOW was used as instance representa-
tion for training the discriminative classifier. In-
stance weighting shows mixed results: it helps
slightly on the weblogs domain, but does not help
on broadcast conversation and telephone conversa-
tions. Interestingly, the two models used to obtain
the weights perform similarly, despite the fact that
their performance differs (F1: 70.5 BOW, 73.5
PET); it turns out that the correlation between the
weights is high (+0.82).
The next part (rows 6-9) shows the effect of en-
riching the syntactic structures with either Brown
word clusters or LSA. The Brown cluster ker-
nel applied to PET (P WC) improves performance
over the baseline over all target domains. The
same holds also for the lexical semantic kernel
based on LSA (P LSA), however, to only two out
of three domains. This suggests that the two ker-
nels capture different information and a combined
kernel might be effective. More importantly, the
table shows the effect of adding Brown clusters or
LSA semantics to the BOW kernel: it can actually
hurt performance, sometimes to a small but other
times to a considerably degree. For instance, WC
applied to PET achieves an F1 of 47.0 (baseline:
45.3) on the bc domain, while applied to BOW it
hurts performance significantly, i.e. it drops from
</bodyText>
<figure confidence="0.996683714285714">
bc-dev
baseline
replace word
replace pos
replace pos only mentions
above word
above pos
</figure>
<page confidence="0.985852">
1504
</page>
<table confidence="0.999874875">
nw+bn (in-dom.) P: bc F1: P: cts F1: P: wl F1:
Baseline: P: R: F1: R: R: R:
PET 50.6 42.1 46.0 51.2 40.6 45.3 51.0 37.8 43.4 35.4 32.8 34.0
BOW 55.1 37.3 44.5 57.2 37.1 45.0 57.5 31.8 41.0 41.1 27.2 32.7
BOW no marking 49.6 34.6 40.7 51.5 34.7 41.4 54.6 30.7 39.3 37.6 25.7 30.6
PET adapted: P: R: F: P: R: F: P: R: F: P: R: F:
IW1 (using PET) 51.4 44.1 47.4 49.1 41.1 44.7 50.8 37.5 43.1 35.5 33.9 34.7
IW2 (using BOW) 51.2 43.6 47.1 49.1 41.3 44.9 51.2 37.8 43.5 35.6 33.8 34.7
With Similarity: P: R: F1: P: R: F1: P: R: F1: P: R: F1:
P WC 55.4 44.6 49.4 54.3 41.4 47.0 55.9 37.1 44.6 40.0 32.7 36.0
B WC 47.9 36.4 41.4 49.5 35.2 41.2 53.3 33.2 40.9 31.7 24.1 27.4
P LSA 52.3 44.1 47.9 51.4 41.7 46.0 49.7 36.5 42.1 38.1 36.5 37.3
B LSA 53.7 37.8 44.4 55.1 33.8 41.9 54.9 32.3 40.7 39.2 28.6 33.0
P+P WC 55.0 46.5 50.4 54.4 43.4 48.3 54.1 38.1 44.7 38.4 34.5 36.3
P+P LSA 52.7 46.6 49.5 53.9 45.2 49.2 49.9 37.6 42.9 37.9 38.3 38.1
P+P WC+P LSA 55.1 45.9 50.1 55.3 43.1 48.5† 53.1 37.0 43.6 39.9 35.8 37.8†
</table>
<tableCaption confidence="0.9432865">
Table 5: In-domain (first column) and out-of-domain performance (columns two to four) on ACE 2005.
PET and BOW are abbreviated by P and B, respectively. If not specified BOW is marked.
</tableCaption>
<bodyText confidence="0.999579333333333">
45.0 to 41.2. This is also the case for LSA ap-
plied to the BOW kernel, which drops to 41.9. On
the cts domain this is less pronounced. Only on
the weblogs domain B LSA achieves a minor im-
provement (from 32.7 to 33.0). In general, dis-
tributional semantics constrained by syntax (i.e.
combined with PET) can be effectively exploited,
while if applied ‘blindly’ – without the guide of
syntax (i.e. BOW) – performance might drop, of-
ten considerably. We believe that the semantic in-
formation does not help the BOW kernel as there is
no syntactic information that constrains the appli-
cation of the noisy source, as opposed to the case
with the PET kernel.
As the two semantically enriched kernels,
PET LSA and PET WC, seem to capture different
information we use composite kernels (rows 10-
11): the baseline kernel (PET) summed with the
lexical semantic kernels. As we can see, results
improve further: for instance on the bc test set,
PET WC reaches an F1 of 47.0, while combined
with PET (PET+PET WC) this improves to 48.3.
Adding also PET LSA results in the best perfor-
mance and our final system (last row): the com-
posite kernel (PET+PET WC+PET LSA) reaches
an F1 of 48.5, 43.6 and 37.8 on the target domains,
respectively, i.e. with an absolute improvement of:
+3.2%, +0.2% and +3.8%, respectively. Two out
of three improvements are significant at p &lt; 0.05
(indicated by † in Table 5). Moreover, the system
also improved in its own domain (first column),
therefore having achieved robustness.
By performing an error analysis we found that,
for instance, the Brown clusters help to general-
ize locations and professions. For example, the
baseline incorrectly considered ‘Dutch filmmaker’
in a PART-WHOLE relation, while our system
correctly predicted GEN-AFF(filmmaker,Dutch).
‘Filmmaker’ does not appear in the source, how-
ever ‘Dutch citizen’ does. Both ‘citizen’ and ‘film-
maker’ appear in the same cluster, thereby helping
the system to recover the correct relation.
</bodyText>
<table confidence="0.999465111111111">
Relation: bc SYS cts wl SYS
BL BL SYS BL
PART-WHOLE 37.8 43.1 59.3 52.3 30.5 36.3
ORG-AFF 60.7 62.9 35.5 42.3 41.0 42.0
PHYS 35.3 37.6 25.4 28.7 25.2 26.9
ART 20.8 37.9 34.5 43.5 26.5 40.3
GEN-AFF 30.1 33.0 16.8 18.6 21.6 28.1
PER-SOC 74.1 74.2 66.3 63.1 42.6 48.0
µ average 45.3 48.5 43.4 43.6 34.0 37.8
</table>
<tableCaption confidence="0.931493">
Table 6: F1 per coarse relation type (ACE
</tableCaption>
<bodyText confidence="0.9693593">
2005). SYS is the final model, i.e. last row
(PET+PET WC+PET LSA) of Table 5.
Furthermore, Table 6 provides the performance
breakdown per relation for the baseline (BL) and
our best system (SYS). The table shows that our
system is able to improve F1 on all relations for
the broadcast and weblogs data. On most rela-
tions, this is also the case for the telephone (cts)
data, although the overall improvement is not sig-
nificant. Most errors were made on the PER-SOC
</bodyText>
<page confidence="0.969327">
1505
</page>
<bodyText confidence="0.9998882">
relation, which constitutes the largest portion of
cts (cf. Figure 3). As shown in the same figure,
the relation distribution of the cts domain is also
rather different from the source. This conversation
data is a very hard domain, with a lot of disflu-
encies and spoken language patterns. We believe
it is more distant from the other domains, espe-
cially from the unlabeled collection, thus other ap-
proaches might be more appropriate, e.g. domain
identification (Dredze et al., 2010).
</bodyText>
<sectionHeader confidence="0.996964" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999983148148148">
We proposed syntactic tree kernels enriched by
lexical semantic similarity to tackle the portabil-
ity of a relation extractor to different domains.
The results of diverse kernels exploiting (i) Brown
clustering and (ii) LSA show that a suitable com-
bination of syntax and lexical generalization is
very promising for domain adaptation. The pro-
posed system is able to improve performance sig-
nificantly on two out of three target domains (up
to 8% relative improvement). We compared it to
instance weighting, which gave only modest or
no improvements. Brown clusters remained un-
explored for kernel-based approaches. We saw
that adding cluster information blindly might ac-
tually hurt performance. In contrast, adding lex-
ical information combined with syntax can help
to improve performance: the syntactic structure
enriched with lexical information provides a fea-
ture space where syntax constrains lexical similar-
ity obtained from unlabeled data. Thus, seman-
tic syntactic tree kernels appear to be a suitable
mechanism to adequately trade off the two kinds
of information. In future we plan to extend the
evaluation to predicted mentions, which necessar-
ily includes a careful evaluation of pre-processing
components, as well as evaluating the approach on
other semantic tasks.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998608875">
We would like to thank Min Zhang for discus-
sions on his prior work as well as the anony-
mous reviewers for their valuable feedback. The
research described in this paper has been sup-
ported by the European Community’s Seventh
Framework Programme (FP7/2007-2013) under
the grant #288024: LIMOSINE – Linguistically
Motivated Semantic aggregation engiNes.
</bodyText>
<sectionHeader confidence="0.986986" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99930179245283">
Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The WaCky Wide Web:
A Collection of Very Large Linguistically Processed
Web-Crawled Corpora. Language Resources and
Evaluation, pages 209–226.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain Adaptation with Structural Corre-
spondence Learning. In Conference on Empirical
Methods in Natural Language Processing, Sydney,
Australia.
Stephan Bloehdorn and Alessandro Moschitti. 2007a.
Combined syntactic and semantic kernels for text
classification. In ECIR, pages 307–318.
Stephan Bloehdorn and Alessandro Moschitti. 2007b.
Exploiting Structure and Semantics for Expressive
Text Kernels. In Conference on Information Knowl-
edge and Management, Lisbon, Portugal.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer,
Vincent J. Della Pietra, and Jenifer C. Lai. 1992.
Class-Based n-gram Models of Natural Language.
Computational Linguistics, 18:467–479.
Razvan C. Bunescu. 2007. Learning to extract rela-
tions from the web using minimal supervision. In
Proceedings ofACL.
Yee Seng Chan and Dan Roth. 2010. Exploiting
background knowledge for relation extraction. In
Proceedings of the 23rd International Conference
on Computational Linguistics (Coling 2010), pages
152–160, Beijing, China, August. Coling 2010 Or-
ganizing Committee.
Michael Collins and Nigel Duffy. 2001. Convolu-
tion Kernels for Natural Language. In Proceedings
of Neural Information Processing Systems (NIPS
2001).
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Semantic convolution kernels over
dependency trees: smoothed partial tree kernel. In
CIKM, pages 2013–2016.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the 42nd Annual Meeting on ACL, Barcelona,
Spain.
Hal Daum´e III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting of
ACL, pages 256–263, Prague, Czech Republic, June.
Mark Dredze, Tim Oates, and Christine Piatko. 2010.
We’re not in kansas anymore: Detecting domain
changes in streams. In Proceedings of EMNLP,
pages 585–595, Cambridge, MA.
Claudio Giuliano, Alberto Lavelli, and Lorenza Ro-
mano. 2007. Relation extraction and the influence
of automatic named-entity recognition. ACM Trans.
Speech Lang. Process., 5(1):2:1–2:26, December.
</reference>
<page confidence="0.80901">
1506
</page>
<reference confidence="0.999871481481482">
G. Golub and W. Kahan. 1965. Calculating the singu-
lar values and pseudo-inverse of a matrix. Journal of
the Society for Industrial and Applied Mathematics:
Series B, Numerical Analysis, 2(2):pp. 205–224.
Zellig Harris. 1964. Distributional structure. In Jer-
rold J. Katz and Jerry A. Fodor, editors, The Philos-
ophy of Linguistics. Oxford University Press.
Jiayuan Huang, Arthur Gretton, Bernhard Sch¨olkopf,
Alexander J. Smola, and Karsten M. Borgwardt.
2007. Correcting sample selection bias by unlabeled
data. In In NIPS. MIT Press.
Jing Jiang and Chengxiang Zhai. 2007. Instance
weighting for domain adaptation in NLP. In In ACL
2007, pages 264–271.
Jing Jiang. 2009. Multi-task transfer learning for
weakly-supervised relation extraction. In Proceed-
ings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th IJCNLP, pages
1012–1020, Suntec, Singapore.
Percy Liang. 2005. Semi-Supervised Learning for
Natural Language. Master’s thesis, Massachusetts
Institute of Technology.
Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng.
2007. A note on platt’s probabilistic outputs for
support vector machines. Mach. Learn., 68(3):267–
276.
Huma Lodhi, Craig Saunders, John Shawe-Taylor,
Nello Cristianini, and Chris Watkins. 2002. Text
classification using string kernels. Journal of Ma-
chine Learning Research, pages 419–444.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of
ACL-IJCNLP, pages 1003–1011, Suntec, Singapore,
August.
Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In Proceed-
ings of the 42nd Meeting of the ACL, Barcelona,
Spain.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In Proceedings of the 17th ECML, Berlin, Germany.
Alessandro Moschitti. 2008. Kernel methods, syntax
and semantics for relational text categorization. In
CIKM, pages 253–262.
Truc-Vien T. Nguyen, Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures
for relation extraction. In Proceedings of EMNLP
’09, pages 1378–1387, Stroudsburg, PA, USA.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing. In Proceed-
ings of the CoNLL Shared Task Session of EMNLP-
CoNLL, pages 915–932.
Eric W. Noreen. 1989. Computer-Intensive Methods
for Testing Hypotheses: An Introduction. Wiley-
Interscience.
Slav Petrov and Ryan McDonald. 2012. Overview of
the 2012 shared task on parsing the web. Notes of
the First Workshop on Syntactic Analysis of Non-
Canonical Language (SANCL).
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
Anders Søgaard and Martin Haulrich. 2011.
Sentence-level instance-weighting for graph-based
and transition-based dependency parsing. In Pro-
ceedings of the 12th International Conference on
Parsing Technologies, IWPT ’11, pages 43–47,
Stroudsburg, PA, USA.
Anders Søgaard and Anders Johannsen. 2012. Robust
learning in random subspaces: equipping NLP for
OOV effects. In Proceedings of Coling.
Ang Sun, Ralph Grishman, and Satoshi Sekine. 2011.
Semi-supervised relation extraction with large-scale
word clustering. In Proceedings ofACL-HLT, pages
521–529, Portland, Oregon, USA.
Mengqiu Wang. 2008. A re-examination of depen-
dency path kernels for relation extraction. In Pro-
ceedings of the 3rd International Joint Conference
on Natural Language Processing-IJCNLP.
Christian Widmer. 2008. Domain adaptation in
sequence analysis. Diplomarbeit, University of
T¨ubingen.
Feiyu Xu, Hans Uszkoreit, Hond Li, and Niko Felger.
2008. Adaptation of relation extraction rules to new
domains. In Proceedings of LREC’08, Marrakech,
Morocco.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2002. Kernel methods for relation
extraction. In Proceedings of EMNLP-ACL, pages
181–201.
Min Zhang, Jian Su, Danmei Wang, Guodong Zhou,
and Chew Lim Tan. 2005. Discovering relations
between named entities from a large raw corpus us-
ing tree similarity-based clustering. In Proceedings
of IJCNLP’2005, pages 378–389, Jeju Island, South
Korea.
Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both flat and structured features.
In Proceedings of COLING-ACL 2006, pages 825–
832.
GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of the 43rd Annual Meeting
ofACL), pages 427–434, Ann Arbor, Michigan.
</reference>
<page confidence="0.99353">
1507
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886262">
<title confidence="0.9994165">Embedding Semantic Similarity in Tree Kernels for Domain of Relation Extraction</title>
<author confidence="0.953333">Moschitti</author>
<affiliation confidence="0.9944225">Center for Language Technology QCRI - Qatar Foundation &amp; University of Copenhagen, Denmark DISI - University of Trento, Italy</affiliation>
<email confidence="0.961297">bplank@gmail.comamoschitti@qf.org.qa</email>
<abstract confidence="0.998928666666667">Relation Extraction (RE) is the task of extracting semantic relationships between entities in text. Recent studies on relation extraction are mostly supervised. The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. is the problem of adapta- In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains. The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetta</author>
</authors>
<title>The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>209--226</pages>
<contexts>
<context position="20524" citStr="Baroni et al., 2009" startWordPosition="3351" endWordPosition="3354">sation. In the experiments, we use news (the union of nw and bn) as source domain, and weblogs (wl), telephone conversations (cts) and broadcast conversation (bc) as target domains.7 We take half of bc as only target development set, and leave the remaining data and domains for final testing (since they are already small, cf. Table 1). To get a feeling of how these domains differ, Figure 3 depicts the distribution of relations in each domain and Table 2 provides the most frequent out-of-vocabulary words together with their percentage. Lexical Similarity and Clustering We applied LSA to ukWaC (Baroni et al., 2009), a 2 billion word corpus constructed from the Web8 using the s-space toolkit.9 Dimensionality reduction was performed using SVD with 250 dimensions, following (Croce et al., 2011). The co-occurrence matrix was transformed by tfidf. For the Brown word clusters, we used Percy Liang’s implementation10 of the Brown clustering algorithm (Liang, 2005). We incorporate cluster information by us7We did not consider the usenet subpart, since it is among the smaller domains and data-preprocessing was difficult. 8http://wacky.sslmit.unibo.it/ 9http://code.google.com/p/airhead-research/ 10https://github.c</context>
</contexts>
<marker>Baroni, Bernardini, Ferraresi, Zanchetta, 2009</marker>
<rawString>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The WaCky Wide Web: A Collection of Very Large Linguistically Processed Web-Crawled Corpora. Language Resources and Evaluation, pages 209–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<date>2006</date>
<booktitle>Domain Adaptation with Structural Correspondence Learning. In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="4768" citStr="Blitzer et al. (2006)" startWordPosition="765" endWordPosition="768">kly supervised system is expected to perform well when applied to any kind of text (other domain/genre), thus ideally, we believe that combining domain adaptation with weak supervision is the way to go in the future. This study is a first step towards this. We focus on unsupervised domain adaptation, i.e. no labeled target data. Moreover, we consider a particular domain adaptation setting: singlesystem DA, i.e. learning a single system able to cope with different but related domains. Most studies on DA so far have focused on building a specialized system for every specific target domain, e.g. Blitzer et al. (2006). In contrast, the goal here is to build a single system that can robustly handle several domains, which is in line with the setup of the recent shared task on parsing the web (Petrov and McDonald, 2012). Participants were asked to build a single system that can robustly parse all domains (reviews, weblogs, answers, emails, newsgroups), rather than to build several domain-specific systems. We consider this as a shift in what was considered domain adaptation in the past (adapt from source to a specific target) and what can be considered a somewhat different recent view of DA, that became widesp</context>
<context position="10361" citStr="Blitzer et al., 2006" startWordPosition="1684" endWordPosition="1687">Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feature representation (Daum´e III, 2007) or try to exploit pivot features to find a generalized shared representation between domains (Blitzer et al., 2006). The easy-adapt approach presented in Daum´e III (2007) assumes the supervised adaptation setting and is thus not applicable here. Structural correspondence learning (Blitzer et al., 2006) exploits unlabeled data from both source and target domain to find correspondences among features from different domains. These correspondences are then integrated as new features in the labeled data of the source domain. The key to SCL is to exploit pivot features to automatically identify feature correspondences, and as such is applicable to feature-based approaches but not in our case since we do not ass</context>
<context position="15541" citStr="Blitzer et al., 2006" startWordPosition="2533" endWordPosition="2536">e system to perform better in the target domain. The question remains how to establish a link between the semantic similarity in the source and target domain. We propose to use an entire unlabeled corpus as pivot: this corpus must be general enough to encapsulate the source and target domains of interest. The idea is to (i) learn semantic similarity between words on the pivot corpus and (ii) use tree kernels embedding such a similarity to learn a RE system on the source, which allows to generalize to the new target domain. This reasoning is related to Structural Correspondence Learning (SCL) (Blitzer et al., 2006). In SCL, a representation shared across domains is learned by exploiting pivot features, where a set of pivot features has to be selected (usually a few thousands). In our case pivots are words that cooccur with the target words in a large unlabeled corpus and are thus implicitly represented in the similarity matrix. Thus, in contrast to SCL, we do not need to select a set of pivot features but rather rely on the distributional hypothesis to infer a semantic similarity from a large unlabeled corpus. Then, this similarity is incorporated into the tree kernel that provides the necessary restric</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain Adaptation with Structural Correspondence Learning. In Conference on Empirical Methods in Natural Language Processing, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Combined syntactic and semantic kernels for text classification.</title>
<date>2007</date>
<booktitle>In ECIR,</booktitle>
<pages>307--318</pages>
<contexts>
<context position="8143" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="1323" endWordPosition="1326">ng from an object to a feature vector xz and O(oi)O(o) = K(oi, o) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T2, respectively. Moreover, let Ii(n) be an indicator variable that is 1 if subtree i is rooted at n and 0 otherwise. The syntactic semantic convolution kernel TKσ (Bloehdorn and Moschitti, 2007b) over T1 and T2 is computed as TKσ(T 1, T2) = Pn1EN1,n2EN2 Aσ(n1, n2) where Aσ(n1, n2) = Pn1EN1 Pn2EN2 Pi Ii(n1)Ii(n2) is computed efficiently u</context>
<context position="9608" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="1567" endWordPosition="1570">), where a measures the similarity between the corresponding children of n1 and n2; iii) If n1 and n2 have identical children: Aσ(n1, n2) = λQnc(n1) j=1 (1 + Aσ(ch(n1, j)), ch(n2, j)); else Aσ(n1, n2) = 0. TKσ combines generalized lexical with structural information: it allows matching tree fragments that have the same syntactic structure but differ in their terminals. After introducing related work, we will discuss computational structures for RE and their extension with semantic similarity. 3 Related Work Semantic syntactic tree kernels have been previously used for question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feat</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007a. Combined syntactic and semantic kernels for text classification. In ECIR, pages 307–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Exploiting Structure and Semantics for Expressive Text Kernels.</title>
<date>2007</date>
<booktitle>In Conference on Information Knowledge and Management,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="8143" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="1323" endWordPosition="1326">ng from an object to a feature vector xz and O(oi)O(o) = K(oi, o) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T2, respectively. Moreover, let Ii(n) be an indicator variable that is 1 if subtree i is rooted at n and 0 otherwise. The syntactic semantic convolution kernel TKσ (Bloehdorn and Moschitti, 2007b) over T1 and T2 is computed as TKσ(T 1, T2) = Pn1EN1,n2EN2 Aσ(n1, n2) where Aσ(n1, n2) = Pn1EN1 Pn2EN2 Pi Ii(n1)Ii(n2) is computed efficiently u</context>
<context position="9608" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="1567" endWordPosition="1570">), where a measures the similarity between the corresponding children of n1 and n2; iii) If n1 and n2 have identical children: Aσ(n1, n2) = λQnc(n1) j=1 (1 + Aσ(ch(n1, j)), ch(n2, j)); else Aσ(n1, n2) = 0. TKσ combines generalized lexical with structural information: it allows matching tree fragments that have the same syntactic structure but differ in their terminals. After introducing related work, we will discuss computational structures for RE and their extension with semantic similarity. 3 Related Work Semantic syntactic tree kernels have been previously used for question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feat</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007b. Exploiting Structure and Semantics for Expressive Text Kernels. In Conference on Information Knowledge and Management, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<date>1992</date>
<booktitle>Class-Based n-gram Models of Natural Language. Computational Linguistics,</booktitle>
<pages>18--467</pages>
<contexts>
<context position="6771" citStr="Brown et al., 1992" startWordPosition="1092" endWordPosition="1095">rs or similarity in tree kernels, which, in turn, produce spaces of tree fragments. For example, “president”, “vice-president” and “Texas”, “US”, are terms indicating an employment relation between a person and a location. Rather than only matching the surface string of words, lexical similarity enables soft matches between similar words in convolution tree kernels. In the empirical evaluation on Automatic Content Extraction (ACE) data, we evaluate the impact of convolution tree kernels embedding lexical semantic similarities. The latter is derived in two ways with: (a) Brown word clustering (Brown et al., 1992); and (b) Latent Semantic Analysis (LSA). We first show that our system aligns well with the state of the art on the ACE 2004 benchmark. Then, we test our RE system on the ACE 2005 data, which exploits kernels, structures and similarities for domain adaptation. The results show that combining the huge space of tree fragments generalized at the lexical level provides an effective model for adapting RE systems to new domains. 2 Semantic Syntactic Tree Kernels In kernel-based methods, both learning and classification only depend on the inner product between instances. Kernel functions can be effi</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Class-Based n-gram Models of Natural Language. Computational Linguistics, 18:467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
</authors>
<title>Learning to extract relations from the web using minimal supervision.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="1930" citStr="Bunescu, 2007" startWordPosition="302" endWordPosition="303"> following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independent and identic</context>
</contexts>
<marker>Bunescu, 2007</marker>
<rawString>Razvan C. Bunescu. 2007. Learning to extract relations from the web using minimal supervision. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Dan Roth</author>
</authors>
<title>Exploiting background knowledge for relation extraction.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>152--160</pages>
<location>Beijing, China,</location>
<contexts>
<context position="1972" citStr="Chan and Roth, 2010" startWordPosition="308" endWordPosition="311">Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independent and identically distributed (i.i.d.) samples is viola</context>
<context position="9853" citStr="Chan and Roth, 2010" startWordPosition="1606" endWordPosition="1609"> information: it allows matching tree fragments that have the same syntactic structure but differ in their terminals. After introducing related work, we will discuss computational structures for RE and their extension with semantic similarity. 3 Related Work Semantic syntactic tree kernels have been previously used for question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feature representation (Daum´e III, 2007) or try to exploit pivot features to find a generalized shared representation between domains (Blitzer et al., 2006). The easy-adapt approach presented in Daum´e III (2007) assumes the supervised adaptation s</context>
<context position="21761" citStr="Chan and Roth, 2010" startWordPosition="3531" endWordPosition="3534">wn-cluster 1502 Distribution of relations across domains (normalized) nw_bn bc cts wl Domain Figure 3: Distribution of relations in ACE 2005. Dom Most frequent OOV words bc insurance, unintelligible, malprac(24%) tice, ph, clip, colonel, crosstalk cts uh, Yeah, um, eh, mhm, uh-huh, ˜, (34%) ah, mm, th, plo, topic, y, workplace wl title, Starbucks, Well, blog, !!, (49%) werkheiser, undefeated, poor, shit Table 2: For each domain the percentage of target domain words (types) that are unseen in the source together with the most frequent OOV words. ing the 10-bit cluster prefix (Sun et al., 2011; Chan and Roth, 2010). For the domain adaptation experiments, we use ukWaC corpus-induced clusters as bridge between domains. We limited the vocabulary to that in ACE 2005, which are approximately 16k words. Following previous work, we left case intact in the corpus and induced 1,000 word clusters from words appearing at least 100 times.11 DA baseline We compare our approach to instance weighting (Jiang and Zhai, 2007). We modified SVM-light-TK such that it takes a parameter vector βi, .., βm as input, where each βi represents the relative importance of example i with respect to the target domain (Huang et al., 20</context>
</contexts>
<marker>Chan, Roth, 2010</marker>
<rawString>Yee Seng Chan and Dan Roth. 2010. Exploiting background knowledge for relation extraction. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 152–160, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Convolution Kernels for Natural Language.</title>
<date>2001</date>
<booktitle>In Proceedings of Neural Information Processing Systems (NIPS</booktitle>
<contexts>
<context position="17956" citStr="Collins and Duffy, 2001" startWordPosition="2940" endWordPosition="2943">d as the cosine similarity between the corresponding projections zw1, zw2 and used in the kernel as described in Section 2. 5 Experimental Setup We treat relation extraction as a multi-class classification problem and use SVM-light-TK4 to train the binary classifiers. The output of the classifiers is combined using the one-vs-all approach. We modified the SVM-light-TK package to include the semantic tree kernels and instance weighting. The entire software package is publicly available.5 For the SVMs, we use the same parameters as Zhang et al. (2006): A = 0.4, c = 2.4 using the Collins Kernel (Collins and Duffy, 2001). The precision/recall trade-off parameter for the none class was found on held-out data: j = 0.2. Evaluation metrics are standard micro average Precision, Recall and balanced Fscore (F1). To compute statistical significance, we use the approximate randomization test (Noreen, 1989).6 In all our experiments, we model argument order of the relations explicitly. Thus, for instance for the 7 coarse ACE 2004 relations, we build 14 coarse-grained classifiers (two for each coarse ACE 2004 relation type except for PER-SOC, which is symmetric, and one classifier for the none relation). Data We use two </context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>Michael Collins and Nigel Duffy. 2001. Convolution Kernels for Natural Language. In Proceedings of Neural Information Processing Systems (NIPS 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Semantic convolution kernels over dependency trees: smoothed partial tree kernel.</title>
<date>2011</date>
<booktitle>In CIKM,</booktitle>
<pages>2013--2016</pages>
<contexts>
<context position="8197" citStr="Croce et al., 2011" startWordPosition="1331" endWordPosition="1334">) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T2, respectively. Moreover, let Ii(n) be an indicator variable that is 1 if subtree i is rooted at n and 0 otherwise. The syntactic semantic convolution kernel TKσ (Bloehdorn and Moschitti, 2007b) over T1 and T2 is computed as TKσ(T 1, T2) = Pn1EN1,n2EN2 Aσ(n1, n2) where Aσ(n1, n2) = Pn1EN1 Pn2EN2 Pi Ii(n1)Ii(n2) is computed efficiently using the following recursive definition: i) If the nod</context>
<context position="9662" citStr="Croce et al., 2011" startWordPosition="1575" endWordPosition="1578">ldren of n1 and n2; iii) If n1 and n2 have identical children: Aσ(n1, n2) = λQnc(n1) j=1 (1 + Aσ(ch(n1, j)), ch(n2, j)); else Aσ(n1, n2) = 0. TKσ combines generalized lexical with structural information: it allows matching tree fragments that have the same syntactic structure but differ in their terminals. After introducing related work, we will discuss computational structures for RE and their extension with semantic similarity. 3 Related Work Semantic syntactic tree kernels have been previously used for question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feature representation (Daum´e III, 2007) or try to exploi</context>
<context position="20704" citStr="Croce et al., 2011" startWordPosition="3379" endWordPosition="3382">7 We take half of bc as only target development set, and leave the remaining data and domains for final testing (since they are already small, cf. Table 1). To get a feeling of how these domains differ, Figure 3 depicts the distribution of relations in each domain and Table 2 provides the most frequent out-of-vocabulary words together with their percentage. Lexical Similarity and Clustering We applied LSA to ukWaC (Baroni et al., 2009), a 2 billion word corpus constructed from the Web8 using the s-space toolkit.9 Dimensionality reduction was performed using SVD with 250 dimensions, following (Croce et al., 2011). The co-occurrence matrix was transformed by tfidf. For the Brown word clusters, we used Percy Liang’s implementation10 of the Brown clustering algorithm (Liang, 2005). We incorporate cluster information by us7We did not consider the usenet subpart, since it is among the smaller domains and data-preprocessing was difficult. 8http://wacky.sslmit.unibo.it/ 9http://code.google.com/p/airhead-research/ 10https://github.com/percyliang/brown-cluster 1502 Distribution of relations across domains (normalized) nw_bn bc cts wl Domain Figure 3: Distribution of relations in ACE 2005. Dom Most frequent OOV</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Semantic convolution kernels over dependency trees: smoothed partial tree kernel. In CIKM, pages 2013–2016.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on ACL,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1641" citStr="Culotta and Sorensen, 2004" startWordPosition="250" endWordPosition="253"> combination of syntax and lexical generalization is very promising for domain adaptation. 1 Introduction Relation extraction is the task of extracting semantic relationships between entities in text, e.g. to detect an employment relationship between the person Larry Page and the company Google in the following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Annual Meeting on ACL, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of ACL,</booktitle>
<pages>256--263</pages>
<location>Prague, Czech Republic,</location>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of ACL, pages 256–263, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Tim Oates</author>
<author>Christine Piatko</author>
</authors>
<title>We’re not in kansas anymore: Detecting domain changes in streams.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>585--595</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="34081" citStr="Dredze et al., 2010" startWordPosition="5657" endWordPosition="5660">lso the case for the telephone (cts) data, although the overall improvement is not significant. Most errors were made on the PER-SOC 1505 relation, which constitutes the largest portion of cts (cf. Figure 3). As shown in the same figure, the relation distribution of the cts domain is also rather different from the source. This conversation data is a very hard domain, with a lot of disfluencies and spoken language patterns. We believe it is more distant from the other domains, especially from the unlabeled collection, thus other approaches might be more appropriate, e.g. domain identification (Dredze et al., 2010). 7 Conclusions and Future Work We proposed syntactic tree kernels enriched by lexical semantic similarity to tackle the portability of a relation extractor to different domains. The results of diverse kernels exploiting (i) Brown clustering and (ii) LSA show that a suitable combination of syntax and lexical generalization is very promising for domain adaptation. The proposed system is able to improve performance significantly on two out of three target domains (up to 8% relative improvement). We compared it to instance weighting, which gave only modest or no improvements. Brown clusters remai</context>
</contexts>
<marker>Dredze, Oates, Piatko, 2010</marker>
<rawString>Mark Dredze, Tim Oates, and Christine Piatko. 2010. We’re not in kansas anymore: Detecting domain changes in streams. In Proceedings of EMNLP, pages 585–595, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Giuliano</author>
<author>Alberto Lavelli</author>
<author>Lorenza Romano</author>
</authors>
<title>Relation extraction and the influence of automatic named-entity recognition.</title>
<date>2007</date>
<journal>ACM Trans. Speech Lang. Process.,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="25506" citStr="Giuliano et al. (2007)" startWordPosition="4159" endWordPosition="4162">ngs/normalizations (like LDA) didn’t improve the results; best was to take the posteriors and add c. 13 http://cs.nyu.edu/˜asun/pub/ACL11_CVFileList.txt ART GEN−AFF ORG−AFF PART−WHOLE PER−SOC PHYS 0.0 0.1 0.2 0.3 0.4 Proportion 1503 information results in a significant F1 drop from 66.3% to 54.2%. However, in a realistic setting we do not have gold entity info available, especially not in the case when we apply the system to any kind of text. Thus, in the domain adaptation setup we assume entity boundaries given but not their label. Clearly, evaluating the approach on predicted mentions, e.g. Giuliano et al. (2007), is another important dimension, however, out of the scope of the current paper. 6.2 Tree Kernels with Brown Word Clusters To evaluate the effectiveness of Brown word clusters in tree kernels, we evaluated different instance representations (cf. Figure 2) on the ACE 2005 development set. Table 4 shows the results. P R F1 52.2 41.7 46.4 49.7 38.6 43.4 56.3 41.9 48.0 55.3 41.6 47.5 54.5 42.2 47.6 55.8 41.1 47.3 Table 4: Brown clusters in tree kernels (cf. Fig 2). To summarize, we found: i) it is generally a bad idea to dismiss lexical information completely, i.e. replacing or ignoring terminals</context>
</contexts>
<marker>Giuliano, Lavelli, Romano, 2007</marker>
<rawString>Claudio Giuliano, Alberto Lavelli, and Lorenza Romano. 2007. Relation extraction and the influence of automatic named-entity recognition. ACM Trans. Speech Lang. Process., 5(1):2:1–2:26, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Golub</author>
<author>W Kahan</author>
</authors>
<title>Calculating the singular values and pseudo-inverse of a matrix.</title>
<date>1965</date>
<journal>Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis,</journal>
<volume>2</volume>
<issue>2</issue>
<pages>205--224</pages>
<contexts>
<context position="17063" citStr="Golub and Kahan, 1965" startWordPosition="2786" endWordPosition="2789">ble. We study two ways for term generalization in tree kernels: Brown words clusters and Latent Semantic Analysis (LSA), both briefly described next. a) replace pos NP PP NP E2 1501 evaluate different ways to integrate cluster information into tree kernels, some of which are illustrated in Figure 2. For LSA, we compute term similarity functions following the distributional hypothesis (Harris, 1964), i.e. the meaning of a word can be described by the set of textual contexts in which it appears. The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965), where M is approximated by UlSlVT l . This approximation supplies a way to project a generic term wi into the l-dimensional space using W = UlS1/2 l , where each row corresponds to the vectors zwi. Given two words w1 and w2, the term similarity function Q is estimated as the cosine similarity between the corresponding projections zw1, zw2 and used in the kernel as described in Section 2. 5 Experimental Setup We treat relation extraction as a multi-class classification problem and use SVM-light-TK4 to train the binary classifiers. The output of the classifiers is combined using the one-vs-all</context>
</contexts>
<marker>Golub, Kahan, 1965</marker>
<rawString>G. Golub and W. Kahan. 1965. Calculating the singular values and pseudo-inverse of a matrix. Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis, 2(2):pp. 205–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1964</date>
<booktitle>The Philosophy of Linguistics.</booktitle>
<editor>In Jerrold J. Katz and Jerry A. Fodor, editors,</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="16842" citStr="Harris, 1964" startWordPosition="2751" endWordPosition="2752">at we exploit a large amount of general data, i.e. data gathered from the web, which is a different but also more challenging scenario than the general unsupervised DA setting where domain specific data is available. We study two ways for term generalization in tree kernels: Brown words clusters and Latent Semantic Analysis (LSA), both briefly described next. a) replace pos NP PP NP E2 1501 evaluate different ways to integrate cluster information into tree kernels, some of which are illustrated in Figure 2. For LSA, we compute term similarity functions following the distributional hypothesis (Harris, 1964), i.e. the meaning of a word can be described by the set of textual contexts in which it appears. The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965), where M is approximated by UlSlVT l . This approximation supplies a way to project a generic term wi into the l-dimensional space using W = UlS1/2 l , where each row corresponds to the vectors zwi. Given two words w1 and w2, the term similarity function Q is estimated as the cosine similarity between the corresponding projections zw1, zw2 and used in the kernel as described </context>
</contexts>
<marker>Harris, 1964</marker>
<rawString>Zellig Harris. 1964. Distributional structure. In Jerrold J. Katz and Jerry A. Fodor, editors, The Philosophy of Linguistics. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiayuan Huang</author>
<author>Arthur Gretton</author>
<author>Bernhard Sch¨olkopf</author>
<author>Alexander J Smola</author>
<author>Karsten M Borgwardt</author>
</authors>
<title>Correcting sample selection bias by unlabeled data. In</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<publisher>MIT Press.</publisher>
<marker>Huang, Gretton, Sch¨olkopf, Smola, Borgwardt, 2007</marker>
<rawString>Jiayuan Huang, Arthur Gretton, Bernhard Sch¨olkopf, Alexander J. Smola, and Karsten M. Borgwardt. 2007. Correcting sample selection bias by unlabeled data. In In NIPS. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Instance weighting for domain adaptation in NLP.</title>
<date>2007</date>
<booktitle>In In ACL</booktitle>
<pages>264--271</pages>
<contexts>
<context position="10173" citStr="Jiang and Zhai, 2007" startWordPosition="1655" endWordPosition="1658">r question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feature representation (Daum´e III, 2007) or try to exploit pivot features to find a generalized shared representation between domains (Blitzer et al., 2006). The easy-adapt approach presented in Daum´e III (2007) assumes the supervised adaptation setting and is thus not applicable here. Structural correspondence learning (Blitzer et al., 2006) exploits unlabeled data from both source and target domain to find correspondences among features from different domains. These correspondences are then integrated as new features in the labeled data of the source domain. </context>
<context position="11406" citStr="Jiang and Zhai (2007)" startWordPosition="1857" endWordPosition="1860">CL is to exploit pivot features to automatically identify feature correspondences, and as such is applicable to feature-based approaches but not in our case since we do not assume availability of target domain data. Instead, we apply a similar idea where we exploit an entire unlabeled corpus as pivot, and compare our approach to instance weighting (Jiang and Zhai, 2007). Instance weighting is a method for domain adaptation in which instance-dependent weights are assigned to the loss function that is minimized during the training process. Let l(x, y, 0) be some loss function. Then, as shown in Jiang and Zhai (2007), the loss function can be weighted by Oil(x, y, 0), such that Oi = p (x?) , where Ps and Pt are the source and target distributions, respectively. Huang et al. (2007) present an application of instance weighting to support vector machines by minimizing the following re-weighted function: minθ,ξ12||0||2 + C Pmi=1 Oiξi. Finding a good weight function is non-trivial (Jiang and Zhai, 2007) and several approximations have been evaluated in the past, e.g. Søgaard and Haulrich (2011) use a bigram-based text classifier to discriminate between domains. We will use a binary classifier trained on RE ins</context>
<context position="22162" citStr="Jiang and Zhai, 2007" startWordPosition="3598" endWordPosition="3601">, shit Table 2: For each domain the percentage of target domain words (types) that are unseen in the source together with the most frequent OOV words. ing the 10-bit cluster prefix (Sun et al., 2011; Chan and Roth, 2010). For the domain adaptation experiments, we use ukWaC corpus-induced clusters as bridge between domains. We limited the vocabulary to that in ACE 2005, which are approximately 16k words. Following previous work, we left case intact in the corpus and induced 1,000 word clusters from words appearing at least 100 times.11 DA baseline We compare our approach to instance weighting (Jiang and Zhai, 2007). We modified SVM-light-TK such that it takes a parameter vector βi, .., βm as input, where each βi represents the relative importance of example i with respect to the target domain (Huang et al., 2007; Widmer, 2008). To estimate the importance weights, we train a binary classifier that distinguishes between source and target domain instances. We consider the union of the three target domains as target data. To train the classifier, the source instances are marked as negative and the target instances are marked as positive. Then, this classi11Clusters are available at http://disi.unitn.it/iker</context>
<context position="23000" citStr="Jiang &amp; Zhai (2007)" startWordPosition="3738" endWordPosition="3741">o estimate the importance weights, we train a binary classifier that distinguishes between source and target domain instances. We consider the union of the three target domains as target data. To train the classifier, the source instances are marked as negative and the target instances are marked as positive. Then, this classi11Clusters are available at http://disi.unitn.it/ikernels/ RelationExtraction Prior Work: Type P R F1 Zhang (2006), tree only K,yes 74.1 62.4 67.7 Zhang (2006), linear K,yes 73.5 67.0 70.1 Zhang (2006), poly K,yes 76.1 68.4 72.1 Sun &amp; Grishman (2011) F,yes 73.4 67.7 70.4 Jiang &amp; Zhai (2007) F,no 73.4 70.2 71.3 Our re-implementation: Type P R F1 Tree only (PET Zhang) K,yes 70.7 62.5 66.3 Linear composite K,yes 71.3 66.6 68.9 Polynomial composite K,yes 72.6 67.7 70.1 Table 3: Comparison to previous work on the 7 relations of ACE 2004. K: kernel-based; F: featurebased; yes/no: models argument order explicitly. fier is applied to the source data. To obtain the weights βi, we convert the SVM scores into posterior probabilities by training a sigmoid using the modified Platt algorithm (Lin et al., 2007).12 6 Results 6.1 Alignment to Prior Work Although most prior studies performed 5-fo</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and Chengxiang Zhai. 2007. Instance weighting for domain adaptation in NLP. In In ACL 2007, pages 264–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
</authors>
<title>Multi-task transfer learning for weakly-supervised relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP,</booktitle>
<pages>1012--1020</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="3117" citStr="Jiang, 2009" startWordPosition="502" endWordPosition="503">f independent and identically distributed (i.i.d.) samples is violated. Domain adaptation has been studied extensively during the last couple of years for various NLP tasks, e.g. two shared tasks have been organized on domain adaptation for dependency parsing (Nivre et al., 2007; Petrov and McDonald, 2012). Results were mixed, thus it is still a very active research area. However, to the best of our knowledge, there is almost no work on adapting relation extraction (RE) systems to new domains.1 There are some prior studies on the related tasks of multi-task transfer learning (Xu et al., 2008; Jiang, 2009) and distant supervision (Mintz et al., 2009), which are clearly related but different: the former is the problem of how to transfer knowledge from old to new relation types, while distant supervision tries to learn new relations from unlabeled text by exploiting weak-supervision in the form of a knowledge resource (e.g. Freebase). We assume the same relation types but a shift in the underlying 1Besides an unpublished manuscript of a student project, but it is not clear what data was used. http://tinyurl.com/ bn2hdwk 1498 Proceedings of the 51st Annual Meeting of the Association for Computatio</context>
</contexts>
<marker>Jiang, 2009</marker>
<rawString>Jing Jiang. 2009. Multi-task transfer learning for weakly-supervised relation extraction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP, pages 1012–1020, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
</authors>
<title>Semi-Supervised Learning for Natural Language. Master’s thesis,</title>
<date>2005</date>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="20872" citStr="Liang, 2005" startWordPosition="3406" endWordPosition="3407">f how these domains differ, Figure 3 depicts the distribution of relations in each domain and Table 2 provides the most frequent out-of-vocabulary words together with their percentage. Lexical Similarity and Clustering We applied LSA to ukWaC (Baroni et al., 2009), a 2 billion word corpus constructed from the Web8 using the s-space toolkit.9 Dimensionality reduction was performed using SVD with 250 dimensions, following (Croce et al., 2011). The co-occurrence matrix was transformed by tfidf. For the Brown word clusters, we used Percy Liang’s implementation10 of the Brown clustering algorithm (Liang, 2005). We incorporate cluster information by us7We did not consider the usenet subpart, since it is among the smaller domains and data-preprocessing was difficult. 8http://wacky.sslmit.unibo.it/ 9http://code.google.com/p/airhead-research/ 10https://github.com/percyliang/brown-cluster 1502 Distribution of relations across domains (normalized) nw_bn bc cts wl Domain Figure 3: Distribution of relations in ACE 2005. Dom Most frequent OOV words bc insurance, unintelligible, malprac(24%) tice, ph, clip, colonel, crosstalk cts uh, Yeah, um, eh, mhm, uh-huh, ˜, (34%) ah, mm, th, plo, topic, y, workplace wl</context>
</contexts>
<marker>Liang, 2005</marker>
<rawString>Percy Liang. 2005. Semi-Supervised Learning for Natural Language. Master’s thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsuan-Tien Lin</author>
<author>Chih-Jen Lin</author>
<author>Ruby C Weng</author>
</authors>
<title>A note on platt’s probabilistic outputs for support vector machines.</title>
<date>2007</date>
<journal>Mach. Learn.,</journal>
<volume>68</volume>
<issue>3</issue>
<pages>276</pages>
<contexts>
<context position="23516" citStr="Lin et al., 2007" startWordPosition="3826" endWordPosition="3829">hang (2006), poly K,yes 76.1 68.4 72.1 Sun &amp; Grishman (2011) F,yes 73.4 67.7 70.4 Jiang &amp; Zhai (2007) F,no 73.4 70.2 71.3 Our re-implementation: Type P R F1 Tree only (PET Zhang) K,yes 70.7 62.5 66.3 Linear composite K,yes 71.3 66.6 68.9 Polynomial composite K,yes 72.6 67.7 70.1 Table 3: Comparison to previous work on the 7 relations of ACE 2004. K: kernel-based; F: featurebased; yes/no: models argument order explicitly. fier is applied to the source data. To obtain the weights βi, we convert the SVM scores into posterior probabilities by training a sigmoid using the modified Platt algorithm (Lin et al., 2007).12 6 Results 6.1 Alignment to Prior Work Although most prior studies performed 5-fold cross-validation on ACE 2004, it is often not clear whether the partitioning has been done on the instance or on the document level. Moreover, it is often not stated whether argument order is modeled explicitly, making it difficult to compare system performance. Citing Wang (2008), “We feel that there is a sense of increasing confusion down this line of research”. To ease comparison for future research we use the same 5-fold split on the document level as Sun et al. (2011)13 and make our system publicly avai</context>
</contexts>
<marker>Lin, Lin, Weng, 2007</marker>
<rawString>Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007. A note on platt’s probabilistic outputs for support vector machines. Mach. Learn., 68(3):267– 276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huma Lodhi</author>
<author>Craig Saunders</author>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
<author>Chris Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>419--444</pages>
<contexts>
<context position="7804" citStr="Lodhi et al., 2002" startWordPosition="1270" endWordPosition="1273"> new domains. 2 Semantic Syntactic Tree Kernels In kernel-based methods, both learning and classification only depend on the inner product between instances. Kernel functions can be efficiently and implicitly computed by exploiting the dual formulation: �i=1..l yiαiO(oi)O(o) + b = 0, where oi and o are two objects, O is a mapping from an object to a feature vector xz and O(oi)O(o) = K(oi, o) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris Watkins. 2002. Text classification using string kernels. Journal of Machine Learning Research, pages 419–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>1003--1011</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="3162" citStr="Mintz et al., 2009" startWordPosition="507" endWordPosition="510">ted (i.i.d.) samples is violated. Domain adaptation has been studied extensively during the last couple of years for various NLP tasks, e.g. two shared tasks have been organized on domain adaptation for dependency parsing (Nivre et al., 2007; Petrov and McDonald, 2012). Results were mixed, thus it is still a very active research area. However, to the best of our knowledge, there is almost no work on adapting relation extraction (RE) systems to new domains.1 There are some prior studies on the related tasks of multi-task transfer learning (Xu et al., 2008; Jiang, 2009) and distant supervision (Mintz et al., 2009), which are clearly related but different: the former is the problem of how to transfer knowledge from old to new relation types, while distant supervision tries to learn new relations from unlabeled text by exploiting weak-supervision in the form of a knowledge resource (e.g. Freebase). We assume the same relation types but a shift in the underlying 1Besides an unpublished manuscript of a student project, but it is not clear what data was used. http://tinyurl.com/ bn2hdwk 1498 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1498–1507, Sofia, Bulg</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACL-IJCNLP, pages 1003–1011, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow semantic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the ACL,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="12338" citStr="Moschitti (2004)" startWordPosition="2007" endWordPosition="2008">iξi. Finding a good weight function is non-trivial (Jiang and Zhai, 2007) and several approximations have been evaluated in the past, e.g. Søgaard and Haulrich (2011) use a bigram-based text classifier to discriminate between domains. We will use a binary classifier trained on RE instance representations. 4 Computational Structures for RE A common way to represent a constituency-based relation instance is the PET (path-enclosed-tree), the smallest subtree including the two target entities (Zhang et al., 2006). This is basically the former structure PAF2 (predicate argument feature) defined in Moschitti (2004) for the extraction of predicate argument relations. The syntactic rep2It is the smallest subtree enclosing the predicate and one of its argument node. 1500 resentation used by Zhang et al. (2006) (we will refer to it as PET Zhang) is the PET with enriched entity information: e.g. E1-NAM-PER, including entity type (PER, GPE, LOC, ORG) and mention type (NAM, NOM, PRO, PRE: name, nominal, pronominal or premodifier). An alternative kernel that does not use syntactic information is the Bag-of-Words (BOW) kernel, where a single root node is added above the terminals. Note that in this BOW kernel we</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>Alessandro Moschitti. 2004. A study on convolution kernels for shallow semantic parsing. In Proceedings of the 42nd Meeting of the ACL, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In Proceedings of the 17th ECML,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="7838" citStr="Moschitti, 2006" startWordPosition="1277" endWordPosition="1279">e Kernels In kernel-based methods, both learning and classification only depend on the inner product between instances. Kernel functions can be efficiently and implicitly computed by exploiting the dual formulation: �i=1..l yiαiO(oi)O(o) + b = 0, where oi and o are two objects, O is a mapping from an object to a feature vector xz and O(oi)O(o) = K(oi, o) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T2, respectively. Moreover, let Ii(</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In Proceedings of the 17th ECML, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel methods, syntax and semantics for relational text categorization.</title>
<date>2008</date>
<booktitle>In CIKM,</booktitle>
<pages>253--262</pages>
<contexts>
<context position="7856" citStr="Moschitti, 2008" startWordPosition="1280" endWordPosition="1281">el-based methods, both learning and classification only depend on the inner product between instances. Kernel functions can be efficiently and implicitly computed by exploiting the dual formulation: �i=1..l yiαiO(oi)O(o) + b = 0, where oi and o are two objects, O is a mapping from an object to a feature vector xz and O(oi)O(o) = K(oi, o) is a kernel function implicitly defining such a mapping. In case of structural kernels, K determines the shape of the substructures describing the objects. Commonly used kernels in NLP are string kernels (Lodhi et al., 2002) and tree kernels (Moschitti, 2006; Moschitti, 2008). NP PP NP E2 clearly a limitation. For instance, the fragments corresponding to governor from Texas and head of Maryland are intuitively semantically related and should obtain a higher match when compared to mother of them. Semantic syntactic tree kernels (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011) provide one way to address this problem by introducing similarity a that allows soft matches between words and, consequently, between fragments containing them. Let N1 and N2 be the set of nodes in T1 and T2, respectively. Moreover, let Ii(n) be an indicator</context>
</contexts>
<marker>Moschitti, 2008</marker>
<rawString>Alessandro Moschitti. 2008. Kernel methods, syntax and semantics for relational text categorization. In CIKM, pages 253–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Truc-Vien T Nguyen</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Convolution kernels on constituent, dependency and sequential structures for relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP ’09,</booktitle>
<pages>1378--1387</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1951" citStr="Nguyen et al., 2009" startWordPosition="304" endWordPosition="307"> snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independent and identically distributed (i.i</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2009</marker>
<rawString>Truc-Vien T. Nguyen, Alessandro Moschitti, and Giuseppe Riccardi. 2009. Convolution kernels on constituent, dependency and sequential structures for relation extraction. In Proceedings of EMNLP ’09, pages 1378–1387, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL,</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric W Noreen</author>
</authors>
<title>Computer-Intensive Methods for Testing Hypotheses: An Introduction.</title>
<date>1989</date>
<publisher>WileyInterscience.</publisher>
<contexts>
<context position="18238" citStr="Noreen, 1989" startWordPosition="2986" endWordPosition="2987">fiers is combined using the one-vs-all approach. We modified the SVM-light-TK package to include the semantic tree kernels and instance weighting. The entire software package is publicly available.5 For the SVMs, we use the same parameters as Zhang et al. (2006): A = 0.4, c = 2.4 using the Collins Kernel (Collins and Duffy, 2001). The precision/recall trade-off parameter for the none class was found on held-out data: j = 0.2. Evaluation metrics are standard micro average Precision, Recall and balanced Fscore (F1). To compute statistical significance, we use the approximate randomization test (Noreen, 1989).6 In all our experiments, we model argument order of the relations explicitly. Thus, for instance for the 7 coarse ACE 2004 relations, we build 14 coarse-grained classifiers (two for each coarse ACE 2004 relation type except for PER-SOC, which is symmetric, and one classifier for the none relation). Data We use two datasets. To compare our model against the state of the art we use the ACE 2004 data. It contains 348 documents and 4,374 positive relation instances. To generate the training data, we follow prior studies and extract an instance for every pair of mentions in the same 4http://disi.</context>
</contexts>
<marker>Noreen, 1989</marker>
<rawString>Eric W. Noreen. 1989. Computer-Intensive Methods for Testing Hypotheses: An Introduction. WileyInterscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
</authors>
<title>Overview of the 2012 shared task on parsing the web. Notes of the First Workshop on Syntactic Analysis of NonCanonical Language (SANCL).</title>
<date>2012</date>
<contexts>
<context position="2812" citStr="Petrov and McDonald, 2012" startWordPosition="448" endWordPosition="451">and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independent and identically distributed (i.i.d.) samples is violated. Domain adaptation has been studied extensively during the last couple of years for various NLP tasks, e.g. two shared tasks have been organized on domain adaptation for dependency parsing (Nivre et al., 2007; Petrov and McDonald, 2012). Results were mixed, thus it is still a very active research area. However, to the best of our knowledge, there is almost no work on adapting relation extraction (RE) systems to new domains.1 There are some prior studies on the related tasks of multi-task transfer learning (Xu et al., 2008; Jiang, 2009) and distant supervision (Mintz et al., 2009), which are clearly related but different: the former is the problem of how to transfer knowledge from old to new relation types, while distant supervision tries to learn new relations from unlabeled text by exploiting weak-supervision in the form of</context>
<context position="4971" citStr="Petrov and McDonald, 2012" startWordPosition="804" endWordPosition="807"> go in the future. This study is a first step towards this. We focus on unsupervised domain adaptation, i.e. no labeled target data. Moreover, we consider a particular domain adaptation setting: singlesystem DA, i.e. learning a single system able to cope with different but related domains. Most studies on DA so far have focused on building a specialized system for every specific target domain, e.g. Blitzer et al. (2006). In contrast, the goal here is to build a single system that can robustly handle several domains, which is in line with the setup of the recent shared task on parsing the web (Petrov and McDonald, 2012). Participants were asked to build a single system that can robustly parse all domains (reviews, weblogs, answers, emails, newsgroups), rather than to build several domain-specific systems. We consider this as a shift in what was considered domain adaptation in the past (adapt from source to a specific target) and what can be considered a somewhat different recent view of DA, that became widespread since 2011/2012. The latter assumes that the target domain(s) is/are not really known in advance. In this setup, the domain adaptation problem boils down to finding a more robust system (Søgaard and</context>
</contexts>
<marker>Petrov, McDonald, 2012</marker>
<rawString>Slav Petrov and Ryan McDonald. 2012. Overview of the 2012 shared task on parsing the web. Notes of the First Workshop on Syntactic Analysis of NonCanonical Language (SANCL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
<author>Martin Haulrich</author>
</authors>
<title>Sentence-level instance-weighting for graph-based and transition-based dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 12th International Conference on Parsing Technologies, IWPT ’11,</booktitle>
<pages>43--47</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11888" citStr="Søgaard and Haulrich (2011)" startWordPosition="1938" endWordPosition="1941">to the loss function that is minimized during the training process. Let l(x, y, 0) be some loss function. Then, as shown in Jiang and Zhai (2007), the loss function can be weighted by Oil(x, y, 0), such that Oi = p (x?) , where Ps and Pt are the source and target distributions, respectively. Huang et al. (2007) present an application of instance weighting to support vector machines by minimizing the following re-weighted function: minθ,ξ12||0||2 + C Pmi=1 Oiξi. Finding a good weight function is non-trivial (Jiang and Zhai, 2007) and several approximations have been evaluated in the past, e.g. Søgaard and Haulrich (2011) use a bigram-based text classifier to discriminate between domains. We will use a binary classifier trained on RE instance representations. 4 Computational Structures for RE A common way to represent a constituency-based relation instance is the PET (path-enclosed-tree), the smallest subtree including the two target entities (Zhang et al., 2006). This is basically the former structure PAF2 (predicate argument feature) defined in Moschitti (2004) for the extraction of predicate argument relations. The syntactic rep2It is the smallest subtree enclosing the predicate and one of its argument node</context>
</contexts>
<marker>Søgaard, Haulrich, 2011</marker>
<rawString>Anders Søgaard and Martin Haulrich. 2011. Sentence-level instance-weighting for graph-based and transition-based dependency parsing. In Proceedings of the 12th International Conference on Parsing Technologies, IWPT ’11, pages 43–47, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
<author>Anders Johannsen</author>
</authors>
<title>Robust learning in random subspaces: equipping NLP for OOV effects.</title>
<date>2012</date>
<booktitle>In Proceedings of Coling.</booktitle>
<contexts>
<context position="5588" citStr="Søgaard and Johannsen, 2012" startWordPosition="906" endWordPosition="909">nald, 2012). Participants were asked to build a single system that can robustly parse all domains (reviews, weblogs, answers, emails, newsgroups), rather than to build several domain-specific systems. We consider this as a shift in what was considered domain adaptation in the past (adapt from source to a specific target) and what can be considered a somewhat different recent view of DA, that became widespread since 2011/2012. The latter assumes that the target domain(s) is/are not really known in advance. In this setup, the domain adaptation problem boils down to finding a more robust system (Søgaard and Johannsen, 2012), i.e. one wants to build a system that can robustly handle any kind of data. We propose to combine (i) term generalization approaches and (ii) structured kernels to improve the performance of a relation extractor on new domains. Previous studies have shown that lexical and syntactic features are both very important (Zhang et al., 2006). We combine structural features with lexical information generalized by clusters or similarity. Given the complexity of feature engineering, we exploit kernel methods (ShaweTaylor and Cristianini, 2004). We encode word clusters or similarity in tree kernels, wh</context>
</contexts>
<marker>Søgaard, Johannsen, 2012</marker>
<rawString>Anders Søgaard and Anders Johannsen. 2012. Robust learning in random subspaces: equipping NLP for OOV effects. In Proceedings of Coling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ang Sun</author>
<author>Ralph Grishman</author>
<author>Satoshi Sekine</author>
</authors>
<title>Semi-supervised relation extraction with large-scale word clustering.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL-HLT,</booktitle>
<pages>521--529</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="1991" citStr="Sun et al., 2011" startWordPosition="312" endWordPosition="315">ess announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independent and identically distributed (i.i.d.) samples is violated. Domain adaptat</context>
<context position="9831" citStr="Sun et al., 2011" startWordPosition="1602" endWordPosition="1605">al with structural information: it allows matching tree fragments that have the same syntactic structure but differ in their terminals. After introducing related work, we will discuss computational structures for RE and their extension with semantic similarity. 3 Related Work Semantic syntactic tree kernels have been previously used for question classification (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b; Croce et al., 2011). These kernels have not yet been studied for either domain adaptation or RE. Brown clusters were studied previously for feature-based approaches to RE (Sun et al., 2011; Chan and Roth, 2010), but they were not yet evaluated in kernels. Thus, we present a novel application of semantic syntactic tree kernels and Brown clusters for domain adaptation of tree-kernel based relation extraction. Regarding domain adaptation, several methods have been proposed, ranging from instance weighting (Jiang and Zhai, 2007) to approaches that change the feature representation (Daum´e III, 2007) or try to exploit pivot features to find a generalized shared representation between domains (Blitzer et al., 2006). The easy-adapt approach presented in Daum´e III (2007) assumes the s</context>
<context position="19081" citStr="Sun et al., 2011" startWordPosition="3108" endWordPosition="3111">for PER-SOC, which is symmetric, and one classifier for the none relation). Data We use two datasets. To compare our model against the state of the art we use the ACE 2004 data. It contains 348 documents and 4,374 positive relation instances. To generate the training data, we follow prior studies and extract an instance for every pair of mentions in the same 4http://disi.unitn.it/moschitti/Tree-Kernel.htm 5http://disi.unitn.it/ikernels/RelationExtraction 6http://www.nlpado.de/˜sebastian/software/sigf.shtml sentence, which are separated by no more than three other mentions (Zhang et al., 2006; Sun et al., 2011). After data preprocessing, we obtained 4,327 positive and 39,120 negative instances. ACE 2005 docs sents ASL relations nw+bn 298 5029 18.8 3562 bc 52 2267 16.3 1297 cts 34 2696 15.3 603 wl 114 1697 22.6 677 Table 1: Overview of the ACE 2005 data. For the domain adaptation experiments we use the ACE 2005 corpus. An overview of the data is given in Table 1. Note that this data is different from ACE 2004: it covers different years (ACE 2004: texts from 2001-2002; ACE 2005: 2003-2005). Moreover, the annotation guidelines have changed (for example, ACE 2005 contains no discourse relation, some rel</context>
<context position="21739" citStr="Sun et al., 2011" startWordPosition="3527" endWordPosition="3530">com/percyliang/brown-cluster 1502 Distribution of relations across domains (normalized) nw_bn bc cts wl Domain Figure 3: Distribution of relations in ACE 2005. Dom Most frequent OOV words bc insurance, unintelligible, malprac(24%) tice, ph, clip, colonel, crosstalk cts uh, Yeah, um, eh, mhm, uh-huh, ˜, (34%) ah, mm, th, plo, topic, y, workplace wl title, Starbucks, Well, blog, !!, (49%) werkheiser, undefeated, poor, shit Table 2: For each domain the percentage of target domain words (types) that are unseen in the source together with the most frequent OOV words. ing the 10-bit cluster prefix (Sun et al., 2011; Chan and Roth, 2010). For the domain adaptation experiments, we use ukWaC corpus-induced clusters as bridge between domains. We limited the vocabulary to that in ACE 2005, which are approximately 16k words. Following previous work, we left case intact in the corpus and induced 1,000 word clusters from words appearing at least 100 times.11 DA baseline We compare our approach to instance weighting (Jiang and Zhai, 2007). We modified SVM-light-TK such that it takes a parameter vector βi, .., βm as input, where each βi represents the relative importance of example i with respect to the target do</context>
<context position="24080" citStr="Sun et al. (2011)" startWordPosition="3924" endWordPosition="3927">using the modified Platt algorithm (Lin et al., 2007).12 6 Results 6.1 Alignment to Prior Work Although most prior studies performed 5-fold cross-validation on ACE 2004, it is often not clear whether the partitioning has been done on the instance or on the document level. Moreover, it is often not stated whether argument order is modeled explicitly, making it difficult to compare system performance. Citing Wang (2008), “We feel that there is a sense of increasing confusion down this line of research”. To ease comparison for future research we use the same 5-fold split on the document level as Sun et al. (2011)13 and make our system publicly available (see Section 5). Table 3 shows that our system (bottom) aligns well with the state of the art. Our best system (composite kernel with polynomial expansion) reaches an F1 of 70.1, which aligns well to the 70.4 of Sun et al. (2011) that use the same datasplit. This is slightly behind that of Zhang (2006); the reason might be threefold: i) different data partitioning; ii) different pre-processing; iii) they incorporate features from additional sources, i.e. a phrase chunker, dependency parser and semantic resources (Zhou et al., 2005) (we have on average </context>
<context position="26330" citStr="Sun et al. (2011)" startWordPosition="4305" endWordPosition="4308">different instance representations (cf. Figure 2) on the ACE 2005 development set. Table 4 shows the results. P R F1 52.2 41.7 46.4 49.7 38.6 43.4 56.3 41.9 48.0 55.3 41.6 47.5 54.5 42.2 47.6 55.8 41.1 47.3 Table 4: Brown clusters in tree kernels (cf. Fig 2). To summarize, we found: i) it is generally a bad idea to dismiss lexical information completely, i.e. replacing or ignoring terminals harms performance; ii) the best way to incorporate Brown clusters is to replace the Pos tag with the cluster bitstring; iii) marking all words is generally better than only mentions; this is in contrast to Sun et al. (2011) who found that in their feature-based system it was better to add cluster information to entity mentions only. As we will discuss, the combination of syntax and semantics exploited in this novel kernel avoids the necessity of restricting cluster information to mentions only. 6.3 Semantic Tree Kernels for DA To evaluate the effectiveness of the proposed kernels across domains, we use the ACE 2005 data as testbed. Following standard practices on ACE 2004, the newswire (nw) and broadcast news (bn) data from ACE 2005 are considered training data (labeled source domain). The test data consists of </context>
</contexts>
<marker>Sun, Grishman, Sekine, 2011</marker>
<rawString>Ang Sun, Ralph Grishman, and Satoshi Sekine. 2011. Semi-supervised relation extraction with large-scale word clustering. In Proceedings ofACL-HLT, pages 521–529, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
</authors>
<title>A re-examination of dependency path kernels for relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd International Joint Conference on Natural Language Processing-IJCNLP.</booktitle>
<contexts>
<context position="23884" citStr="Wang (2008)" startWordPosition="3889" endWordPosition="3890">rebased; yes/no: models argument order explicitly. fier is applied to the source data. To obtain the weights βi, we convert the SVM scores into posterior probabilities by training a sigmoid using the modified Platt algorithm (Lin et al., 2007).12 6 Results 6.1 Alignment to Prior Work Although most prior studies performed 5-fold cross-validation on ACE 2004, it is often not clear whether the partitioning has been done on the instance or on the document level. Moreover, it is often not stated whether argument order is modeled explicitly, making it difficult to compare system performance. Citing Wang (2008), “We feel that there is a sense of increasing confusion down this line of research”. To ease comparison for future research we use the same 5-fold split on the document level as Sun et al. (2011)13 and make our system publicly available (see Section 5). Table 3 shows that our system (bottom) aligns well with the state of the art. Our best system (composite kernel with polynomial expansion) reaches an F1 of 70.1, which aligns well to the 70.4 of Sun et al. (2011) that use the same datasplit. This is slightly behind that of Zhang (2006); the reason might be threefold: i) different data partitio</context>
</contexts>
<marker>Wang, 2008</marker>
<rawString>Mengqiu Wang. 2008. A re-examination of dependency path kernels for relation extraction. In Proceedings of the 3rd International Joint Conference on Natural Language Processing-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Widmer</author>
</authors>
<title>Domain adaptation in sequence analysis.</title>
<date>2008</date>
<institution>Diplomarbeit, University of T¨ubingen.</institution>
<contexts>
<context position="22378" citStr="Widmer, 2008" startWordPosition="3638" endWordPosition="3640">r the domain adaptation experiments, we use ukWaC corpus-induced clusters as bridge between domains. We limited the vocabulary to that in ACE 2005, which are approximately 16k words. Following previous work, we left case intact in the corpus and induced 1,000 word clusters from words appearing at least 100 times.11 DA baseline We compare our approach to instance weighting (Jiang and Zhai, 2007). We modified SVM-light-TK such that it takes a parameter vector βi, .., βm as input, where each βi represents the relative importance of example i with respect to the target domain (Huang et al., 2007; Widmer, 2008). To estimate the importance weights, we train a binary classifier that distinguishes between source and target domain instances. We consider the union of the three target domains as target data. To train the classifier, the source instances are marked as negative and the target instances are marked as positive. Then, this classi11Clusters are available at http://disi.unitn.it/ikernels/ RelationExtraction Prior Work: Type P R F1 Zhang (2006), tree only K,yes 74.1 62.4 67.7 Zhang (2006), linear K,yes 73.5 67.0 70.1 Zhang (2006), poly K,yes 76.1 68.4 72.1 Sun &amp; Grishman (2011) F,yes 73.4 67.7 70</context>
</contexts>
<marker>Widmer, 2008</marker>
<rawString>Christian Widmer. 2008. Domain adaptation in sequence analysis. Diplomarbeit, University of T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feiyu Xu</author>
<author>Hans Uszkoreit</author>
<author>Hond Li</author>
<author>Niko Felger</author>
</authors>
<title>Adaptation of relation extraction rules to new domains.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC’08,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="3103" citStr="Xu et al., 2008" startWordPosition="498" endWordPosition="501"> the assumption of independent and identically distributed (i.i.d.) samples is violated. Domain adaptation has been studied extensively during the last couple of years for various NLP tasks, e.g. two shared tasks have been organized on domain adaptation for dependency parsing (Nivre et al., 2007; Petrov and McDonald, 2012). Results were mixed, thus it is still a very active research area. However, to the best of our knowledge, there is almost no work on adapting relation extraction (RE) systems to new domains.1 There are some prior studies on the related tasks of multi-task transfer learning (Xu et al., 2008; Jiang, 2009) and distant supervision (Mintz et al., 2009), which are clearly related but different: the former is the problem of how to transfer knowledge from old to new relation types, while distant supervision tries to learn new relations from unlabeled text by exploiting weak-supervision in the form of a knowledge resource (e.g. Freebase). We assume the same relation types but a shift in the underlying 1Besides an unpublished manuscript of a student project, but it is not clear what data was used. http://tinyurl.com/ bn2hdwk 1498 Proceedings of the 51st Annual Meeting of the Association </context>
</contexts>
<marker>Xu, Uszkoreit, Li, Felger, 2008</marker>
<rawString>Feiyu Xu, Hans Uszkoreit, Hond Li, and Niko Felger. 2008. Adaptation of relation extraction rules to new domains. In Proceedings of LREC’08, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-ACL,</booktitle>
<pages>181--201</pages>
<contexts>
<context position="1613" citStr="Zelenko et al., 2002" startWordPosition="245" endWordPosition="249"> shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation. 1 Introduction Relation extraction is the task of extracting semantic relationships between entities in text, e.g. to detect an employment relationship between the person Larry Page and the company Google in the following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismat</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2002</marker>
<rawString>Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2002. Kernel methods for relation extraction. In Proceedings of EMNLP-ACL, pages 181–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jian Su</author>
<author>Danmei Wang</author>
<author>Guodong Zhou</author>
<author>Chew Lim Tan</author>
</authors>
<title>Discovering relations between named entities from a large raw corpus using tree similarity-based clustering.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP’2005,</booktitle>
<pages>378--389</pages>
<location>Jeju Island, South</location>
<contexts>
<context position="1876" citStr="Zhang et al., 2005" startWordPosition="290" endWordPosition="293">between the person Larry Page and the company Google in the following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of l</context>
</contexts>
<marker>Zhang, Su, Wang, Zhou, Tan, 2005</marker>
<rawString>Min Zhang, Jian Su, Danmei Wang, Guodong Zhou, and Chew Lim Tan. 2005. Discovering relations between named entities from a large raw corpus using tree similarity-based clustering. In Proceedings of IJCNLP’2005, pages 378–389, Jeju Island, South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<pages>825--832</pages>
<contexts>
<context position="1915" citStr="Zhang et al., 2006" startWordPosition="298" endWordPosition="301">ompany Google in the following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the assumption of independ</context>
<context position="5926" citStr="Zhang et al., 2006" startWordPosition="962" endWordPosition="965">ed a somewhat different recent view of DA, that became widespread since 2011/2012. The latter assumes that the target domain(s) is/are not really known in advance. In this setup, the domain adaptation problem boils down to finding a more robust system (Søgaard and Johannsen, 2012), i.e. one wants to build a system that can robustly handle any kind of data. We propose to combine (i) term generalization approaches and (ii) structured kernels to improve the performance of a relation extractor on new domains. Previous studies have shown that lexical and syntactic features are both very important (Zhang et al., 2006). We combine structural features with lexical information generalized by clusters or similarity. Given the complexity of feature engineering, we exploit kernel methods (ShaweTaylor and Cristianini, 2004). We encode word clusters or similarity in tree kernels, which, in turn, produce spaces of tree fragments. For example, “president”, “vice-president” and “Texas”, “US”, are terms indicating an employment relation between a person and a location. Rather than only matching the surface string of words, lexical similarity enables soft matches between similar words in convolution tree kernels. In th</context>
<context position="12236" citStr="Zhang et al., 2006" startWordPosition="1990" endWordPosition="1993">g to support vector machines by minimizing the following re-weighted function: minθ,ξ12||0||2 + C Pmi=1 Oiξi. Finding a good weight function is non-trivial (Jiang and Zhai, 2007) and several approximations have been evaluated in the past, e.g. Søgaard and Haulrich (2011) use a bigram-based text classifier to discriminate between domains. We will use a binary classifier trained on RE instance representations. 4 Computational Structures for RE A common way to represent a constituency-based relation instance is the PET (path-enclosed-tree), the smallest subtree including the two target entities (Zhang et al., 2006). This is basically the former structure PAF2 (predicate argument feature) defined in Moschitti (2004) for the extraction of predicate argument relations. The syntactic rep2It is the smallest subtree enclosing the predicate and one of its argument node. 1500 resentation used by Zhang et al. (2006) (we will refer to it as PET Zhang) is the PET with enriched entity information: e.g. E1-NAM-PER, including entity type (PER, GPE, LOC, ORG) and mention type (NAM, NOM, PRO, PRE: name, nominal, pronominal or premodifier). An alternative kernel that does not use syntactic information is the Bag-of-Word</context>
<context position="17887" citStr="Zhang et al. (2006)" startWordPosition="2926" endWordPosition="2929"> two words w1 and w2, the term similarity function Q is estimated as the cosine similarity between the corresponding projections zw1, zw2 and used in the kernel as described in Section 2. 5 Experimental Setup We treat relation extraction as a multi-class classification problem and use SVM-light-TK4 to train the binary classifiers. The output of the classifiers is combined using the one-vs-all approach. We modified the SVM-light-TK package to include the semantic tree kernels and instance weighting. The entire software package is publicly available.5 For the SVMs, we use the same parameters as Zhang et al. (2006): A = 0.4, c = 2.4 using the Collins Kernel (Collins and Duffy, 2001). The precision/recall trade-off parameter for the none class was found on held-out data: j = 0.2. Evaluation metrics are standard micro average Precision, Recall and balanced Fscore (F1). To compute statistical significance, we use the approximate randomization test (Noreen, 1989).6 In all our experiments, we model argument order of the relations explicitly. Thus, for instance for the 7 coarse ACE 2004 relations, we build 14 coarse-grained classifiers (two for each coarse ACE 2004 relation type except for PER-SOC, which is s</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of COLING-ACL 2006, pages 825– 832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
<author>Jie Zhang</author>
<author>Min Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting ofACL),</booktitle>
<pages>427--434</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="1895" citStr="Zhou et al., 2005" startWordPosition="294" endWordPosition="297">arry Page and the company Google in the following text snippet: Google CEO Larry Page holds a press announcement at its headquarters in New York on May 21, 2012. Recent studies on relation extraction have shown that supervised approaches based on either feature or kernel methods achieve state-of-the-art accuracy (Zelenko et al., 2002; Culotta and Sorensen, 2004; ∗ The first author was affiliated with the Department of Computer Science and Information Engineering of the University of Trento (Povo, Italy) during the design of the models, experiments and writing of the paper. Zhang et al., 2005; Zhou et al., 2005; Zhang et al., 2006; Bunescu, 2007; Nguyen et al., 2009; Chan and Roth, 2010; Sun et al., 2011). However, the clear drawback of supervised methods is the need of training data, which can slow down the delivery of commercial applications in new domains: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. Approaches that can cope with domain changes are essential. This is the problem of domain adaptation (DA) or transfer learning (TL). Technically, domain adaptation addresses the problem of learning when the as</context>
<context position="24659" citStr="Zhou et al., 2005" startWordPosition="4022" endWordPosition="4025">the document level as Sun et al. (2011)13 and make our system publicly available (see Section 5). Table 3 shows that our system (bottom) aligns well with the state of the art. Our best system (composite kernel with polynomial expansion) reaches an F1 of 70.1, which aligns well to the 70.4 of Sun et al. (2011) that use the same datasplit. This is slightly behind that of Zhang (2006); the reason might be threefold: i) different data partitioning; ii) different pre-processing; iii) they incorporate features from additional sources, i.e. a phrase chunker, dependency parser and semantic resources (Zhou et al., 2005) (we have on average 9 features/instance, they use 40). Since we focus on evaluating the impact of semantic similarity in tree kernels, we think our system is very competitive. Removing gold entity and mention 12Other weightings/normalizations (like LDA) didn’t improve the results; best was to take the posteriors and add c. 13 http://cs.nyu.edu/˜asun/pub/ACL11_CVFileList.txt ART GEN−AFF ORG−AFF PART−WHOLE PER−SOC PHYS 0.0 0.1 0.2 0.3 0.4 Proportion 1503 information results in a significant F1 drop from 66.3% to 54.2%. However, in a realistic setting we do not have gold entity info available, e</context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang. 2005. Exploring various knowledge in relation extraction. In Proceedings of the 43rd Annual Meeting ofACL), pages 427–434, Ann Arbor, Michigan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>