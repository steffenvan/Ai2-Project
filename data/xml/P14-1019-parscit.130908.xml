<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000065">
<title confidence="0.9813685">
Steps to Excellence: Simple Inference with Refined Scoring of
Dependency Trees
</title>
<author confidence="0.998812">
Yuan Zhang, Tao Lei, Regina Barzilay, Tommi Jaaliliola Amir Globerson
</author>
<affiliation confidence="0.997523">
Massachusetts Institute of Technology The Hebrew University
</affiliation>
<email confidence="0.987601">
{yuanzh, taolei, regina, tommi}@csail.mit.edu gamir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.993551" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99990584">
Much of the recent work on depen-
dency parsing has been focused on solv-
ing inherent combinatorial problems as-
sociated with rich scoring functions. In
contrast, we demonstrate that highly ex-
pressive scoring functions can be used
with substantially simpler inference pro-
cedures. Specifically, we introduce a
sampling-based parser that can easily han-
dle arbitrary global features. Inspired
by SampleRank, we learn to take guided
stochastic steps towards a high scoring
parse. We introduce two samplers for
traversing the space of trees, Gibbs and
Metropolis-Hastings with Random Walk.
The model outperforms state-of-the-art re-
sults when evaluated on 14 languages
of non-projective CoNLL datasets. Our
sampling-based approach naturally ex-
tends to joint prediction scenarios, such
as joint parsing and POS correction. The
resulting method outperforms the best re-
ported results on the CATiB dataset, ap-
proaching performance of parsing with
gold tags.1
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999719222222222">
Dependency parsing is commonly cast as a max-
imization problem over a parameterized scoring
function. In this view, the use of more expres-
sive scoring functions leads to more challenging
combinatorial problems of finding the maximiz-
ing parse. Much of the recent work on parsing has
been focused on improving methods for solving
the combinatorial maximization inference prob-
lems. Indeed, state-of-the-art results have been ob-
</bodyText>
<footnote confidence="0.994481">
1The source code for the work is available at
http://groups.csail.mit.edu/rbg/code/
global/acl2014.
</footnote>
<bodyText confidence="0.999628756097561">
tained by adapting powerful tools from optimiza-
tion (Martins et al., 2013; Martins et al., 2011;
Rush and Petrov, 2012). We depart from this view
and instead focus on using highly expressive scor-
ing functions with substantially simpler inference
procedures. The key ingredient in our approach is
how learning is coupled with inference. Our com-
bination outperforms the state-of-the-art parsers
and remains comparable even if we adopt their
scoring functions.
Rich scoring functions have been used for some
time. They first appeared in the context of rerank-
ing (Collins, 2000), where a simple parser is used
to generate a candidate list which is then reranked
according to the scoring function. Because the
number of alternatives is small, the scoring func-
tion could in principle involve arbitrary (global)
features of parse trees. The power of this method-
ology is nevertheless limited by the initial set of
alternatives from the simpler parser. Indeed, the
set may already omit the gold parse. We dispense
with the notion of a candidate set and seek to ex-
ploit the scoring function more directly.
In this paper, we introduce a sampling-based
parser that places few or no constraints on the
scoring function. Starting with an initial candi-
date tree, our inference procedure climbs the scor-
ing function in small (cheap) stochastic steps to-
wards a high scoring parse. The proposal distri-
bution over the moves is derived from the scoring
function itself. Because the steps are small, the
complexity of the scoring function has limited im-
pact on the computational cost of the procedure.
We explore two alternative proposal distributions.
Our first strategy is akin to Gibbs sampling and
samples a new head for each word in the sentence,
modifying one arc at a time. The second strat-
egy relies on a provably correct sampler for first-
order scores (Wilson, 1996), and uses it within a
Metropolis-Hastings algorithm for general scoring
functions. It turns out that the latter optimizes the
</bodyText>
<page confidence="0.973116">
197
</page>
<note confidence="0.831804">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 197–207,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9995978">
score more efficiently than the former.
Because the inference procedure is so simple,
it is important that the parameters of the scoring
function are chosen in a manner that facilitates
how we climb the scoring function in small steps.
One way to achieve this is to make sure that im-
provements in the scoring functions are correlated
with improvements in the quality of the parse.
This approach was suggested in the SampleRank
framework (Wick et al., 2011) for training struc-
tured prediction models. This method was origi-
nally developed for a sequence labeling task with
local features, and was shown to be more effec-
tive than state-of-the-art alternatives. Here we ap-
ply SampleRank to parsing, applying several mod-
ifications such as the proposal distributions men-
tioned earlier.
The benefits of sampling-based learning go be-
yond stand-alone parsing. For instance, we can
use the framework to correct preprocessing mis-
takes in features such as part-of-speech (POS)
tags. In this case, we combine the scoring func-
tion for trees with a stand-alone tagging model.
When proposing a small move, i.e., sampling a
head of the word, we can also jointly sample its
POS tag from a set of alternatives provided by
the tagger. As a result, the selected tag is influ-
enced by a broad syntactic context above and be-
yond the initial tagging model and is directly opti-
mized to improve parsing performance. Our joint
parsing-tagging model provides an alternative to
the widely-adopted pipeline setup.
We evaluate our method on benchmark multi-
lingual dependency corpora. Our method outper-
forms the Turbo parser across 14 languages on av-
erage by 0.5%. On four languages, we top the best
published results. Our method provides a more
effective mechanism for handling global features
than reranking, outperforming it by 1.3%. In terms
of joint parsing and tagging on the CATiB dataset,
we nearly bridge (88.38%) the gap between in-
dependently predicted (86.95%) and gold tags
(88.45%). This is better than the best published
results in the 2013 SPMRL shared task (Seddah et
al., 2013), including parser ensembles.
</bodyText>
<sectionHeader confidence="0.999852" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99997012">
Earlier works on dependency parsing focused on
inference with tractable scoring functions. For in-
stance, a scoring function that operates over each
single dependency can be optimized using the
maximum spanning tree algorithm (McDonald et
al., 2005). It was soon realized that using higher
order features could be beneficial, even at the cost
of using approximate inference and sacrificing op-
timality. The first successful approach in this arena
was reranking (Collins, 2000; Charniak and John-
son, 2005) on constituency parsing. Reranking
can be combined with an arbitrary scoring func-
tion, and thus can easily incorporate global fea-
tures over the entire parse tree. Its main disadvan-
tage is that the output parse can only be one of the
few parses passed to the reranker.
Recent work has focused on more powerful in-
ference mechanisms that consider the full search
space (Zhang and McDonald, 2012; Rush and
Petrov, 2012; Koo et al., 2010; Huang, 2008). For
instance, Nakagawa (2007) deals with tractabil-
ity issues by using sampling to approximate
marginals. Another example is the dual decompo-
sition (DD) framework (Koo et al., 2010; Martins
et al., 2011). The idea in DD is to decompose the
hard maximization problem into smaller parts that
can be efficiently maximized and enforce agree-
ment among these via Lagrange multipliers. The
method is essentially equivalent to linear program-
ming relaxation approaches (Martins et al., 2009;
Sontag et al., 2011), and also similar in spirit to
ILP approaches (Punyakanok et al., 2004).
A natural approach to approximate global in-
ference is via search. For instance, a transition-
based parsing system (Zhang and Nivre, 2011)
incrementally constructs a parsing structure us-
ing greedy beam-search. Other approaches op-
erate over full trees and generate a sequence
of candidates that successively increase the
score (Daum´e III et al., 2009; Li et al., 2013;
Wick et al., 2011). Our work builds on one such
approach — SampleRank (Wick et al., 2011), a
sampling-based learning algorithm. In SampleR-
ank, the parameters are adjusted so as to guide the
sequence of candidates closer to the target struc-
ture along the search path. The method has been
successfully used in sequence labeling and ma-
chine translation (Haddow et al., 2011). In this
paper, we demonstrate how to adapt the method
for parsing with rich scoring functions.
</bodyText>
<sectionHeader confidence="0.981347" genericHeader="method">
3 Sampling-Based Dependency Parsing
with Global Features
</sectionHeader>
<bodyText confidence="0.9695745">
In this section, we introduce our novel sampling-
based dependency parser which can incorporate
</bodyText>
<page confidence="0.997162">
198
</page>
<bodyText confidence="0.86096725">
arbitrary global features. We begin with the no-
tation before addressing the decoding and learning
algorithms. Finally, we extend our model to a joint
parsing and POS correction task.
</bodyText>
<subsectionHeader confidence="0.996495">
3.1 Notations
</subsectionHeader>
<bodyText confidence="0.999934888888889">
We denote sentences by x and the corresponding
dependency trees by y E Y(x). Here Y(x) is the
set of valid (projective or non-projective) depen-
dency trees for sentence x. We use xj to refer
to the jth word of sentence x, and hj to the head
word of xj. A training set of size N is given as a
set of pairs D = {(x(i), y(i))1Ni=1 where y(i) is the
ground truth parse for sentence x(i).
We parameterize the scoring function s(x, y) as
</bodyText>
<equation confidence="0.998968">
s(x, y) = 0 · f(x, y) (1)
</equation>
<bodyText confidence="0.999963384615385">
where f(x, y) is the feature vector associated with
tree y for sentence x. We do not make any assump-
tions about how the feature function decomposes.
In contrast, most state-of-the-art parsers operate
under the assumption that the feature function de-
composes into a sum of simpler terms. For exam-
ple, in the second-order MST parser (McDonald
and Pereira, 2006), all the feature terms involve
arcs or consecutive siblings. Similarly, parsers
based on dual decomposition (Martins et al., 2011;
Koo et al., 2010) assume that s(x, y) decomposes
into a sum of terms where each term can be maxi-
mized over y efficiently.
</bodyText>
<subsectionHeader confidence="0.999306">
3.2 Decoding
</subsectionHeader>
<bodyText confidence="0.996503166666666">
The decoding problem consists of finding a valid
dependency tree y E Y(x) that maximizes the
score s(x, y) = 0 · f(x, y) with parameters 0.
For scoring functions that extend beyond first-
order arc preferences, finding the maximizing non-
projective tree is known to be NP-hard (McDonald
and Pereira, 2006). We find a high scoring tree
through sampling, and (later) learn the parameters
0 so as to further guide this process.
Our sampler generates a sequence of depen-
dency structures so as to approximate independent
samples from
</bodyText>
<equation confidence="0.946592">
p(yJx, T, 0) a exp (s(x, y)/T) (2)
</equation>
<bodyText confidence="0.928216">
The temperature parameter T controls how con-
centrated the samples are around the maximum
of s(x, y) (e.g., see Geman and Geman (1984)).
Sampling from target distribution p is typically as
hard as (or harder than) that maximizing s(x, y).
Inputs: 0, x, T0 (initial temperature), c (temperature
update rate), proposal distribution q.
</bodyText>
<equation confidence="0.99102375">
Outputs: y*
T ← T0
Set y0 to some random tree
y* ← y0
repeat
y&apos; ← q(·|x, yt, T, 0)
if s(x, y&apos;) &gt; s(x, y*) then
y* ← y&apos;
� 1, p(y&apos;)q(yt|y&apos;)
α = min
p(yt)q(y&apos;|yt)
Sample Bernouli variable Z with P[Z = 1] = α.
if Z = 0 then
yt+1 ←yt
else
yt+1 ← y&apos;
t ← t + 1
T ← c · T
until convergence
return y*
</equation>
<figureCaption confidence="0.9735055">
Figure 1: Sampling-based algorithm for decoding
(i.e., approximately maximizing s(x, y)).
</figureCaption>
<bodyText confidence="0.999956">
We follow here a Metropolis-Hastings sampling
algorithm (e.g., see Andrieu et al. (2003)) and
explore different alternative proposal distributions
q(y&apos;Jx, y, 0, T). The distribution q governs the
small steps that are taken in generating a sequence
of structures. The target distribution p folds into
the procedure by defining the probability that we
will accept the proposed move. The general struc-
ture of our sampling algorithm is given in Figure 1.
</bodyText>
<subsectionHeader confidence="0.956767">
3.2.1 Gibbs Sampling
</subsectionHeader>
<bodyText confidence="0.999986454545455">
Perhaps the most natural choice of the proposal
distribution q is a conditional distribution from p.
This is feasible if we restrict the proposed moves
to only small changes in the current tree. In our
case, we choose a word j randomly, and then sam-
ple its head hj according to p with the constraint
that we obtain a valid tree (when projective trees
are sought, this constraint is also incorporated).
For this choice of q, the probability of accepting
the new tree (α in Figure 1) is identically one.
Thus new moves are always accepted.
</bodyText>
<subsectionHeader confidence="0.950921">
3.2.2 Exact First-Order Sampling
</subsectionHeader>
<bodyText confidence="0.999981666666667">
One shortcoming of the Gibbs sampler is that it
only changes one variable (arc) at a time. This
usually leads to slow mixing, requiring more sam-
ples to get close to the parse with maximum
score. Ideally, we would change multiple heads
in the parse tree simultaneously, and sample those
choices from the corresponding conditional distri-
bution of p. While in general this is increasingly
difficult with more heads, it is indeed tractable if
</bodyText>
<page confidence="0.96722">
199
</page>
<figure confidence="0.759227409090909">
Inputs: x, yt, 0, K (number of heads to change).
Outputs: y&apos;
for i = 1 to JxJ do
inTree[i] +— false
ChangeNode[i] +— false
Set ChangeNode to true for K random nodes.
head[0] +— −1
for i = 1 to JxJ do
u +— i
while not inTree[u] do
if ChangeNode[u] then
head[u] +— randomHead(u, 0)
else
head[u] +— yt(u)
u +— head[u]
if LoopExist(head) then
EraseLoop(head)
u + —i
while not inTree[u] do
inTree[u] +— true
u +— head[u]
return Construct tree y&apos; from the head array.
</figure>
<figureCaption confidence="0.990166">
Figure 2: A proposal distribution q(y&apos;|yt) based
</figureCaption>
<bodyText confidence="0.996775125">
on the random walk sampler of Wilson (1996).
The function randomHead samples a new head for
node u according to the first-order weights given
by 0.
the model corresponds to a first-order parser. One
such sampling algorithm is the random walk sam-
pler of Wilson (1996). It can be used to obtain
i.i.d. samples from distributions of the form:
</bodyText>
<equation confidence="0.935434">
p(y) °C � wij, (3)
i→j∈y
</equation>
<bodyText confidence="0.999980333333333">
where y corresponds to a tree with a spcified root
and wij is the exponential of the first-order score.
y is always a valid parse tree if we allow multiple
children of the root and do not impose projective
constraint. The algorithm in Wilson (1996) iter-
ates over all the nodes, and for each node performs
a random walk according to the weights wij until
the walk creates a loop or hits a tree. In the first
case the algorithm erases the loop and continues
the walk. If the walk hits the current tree, the walk
path is added to form a new tree with more nodes.
This is repeated until all the nodes are included in
the tree. It can be shown that this procedure gen-
erates i.i.d. trees from p(y).
Since our features do not by design correspond
to a first-order parser, we cannot use the Wilson
algorithm as it is. Instead we use it as the proposal
function and sample a subset of the dependen-
cies from the first-order distribution of our model,
while fixing the others. In each step we uniformly
sample K nodes to update and sample their new
</bodyText>
<figure confidence="0.985538">
(a) original tree
ROOT It was not Black Monday
</figure>
<figureCaption confidence="0.998058">
Figure 3: An illustration of random walk sam-
</figureCaption>
<bodyText confidence="0.953736">
pler. The index on each edge indicates its order on
each walk path. The heads of the red words are
sampled while others are fixed. The blue edges
represent the current walk path and the black ones
are already in the tree. Note that the walk direc-
tion is opposite to the dependency direction. (a)
shows the original tree before sampling; (b) and
(c) show the walk path and how the tree is gener-
ated in two steps. The loop not—* Monday —* not
in (b) is erased.
heads using the Wilson algorithm (in the experi-
ments we use K = 4). Note that blocked Gibbs
sampling would be exponential in K, and is thus
very slow already at K = 4. The procedure is de-
scribed in Figure 2 with a graphic illustration in
Figure 3.
</bodyText>
<subsectionHeader confidence="0.99739">
3.3 Training
</subsectionHeader>
<bodyText confidence="0.999979642857143">
In this section, we describe how to learn the
adjustable parameters 0 in the scoring function.
The parameters are learned in an on-line fash-
ion by successively imposing soft constraints be-
tween pairs of dependency structures. We intro-
duce both margin constraints and constraints per-
taining to successive samples generated along the
search path. We demonstrate later that both types
of constraints are essential.
We begin with the standard margin constraints.
An ideal scoring function would always rank the
gold parse higher than any alternative. Moreover,
alternatives that are far from the gold parse should
score even lower. As a result, we require that
</bodyText>
<equation confidence="0.657914">
s(x(i), y(i)) − s(x(i), y) ? A(y(i), y) by (4)
</equation>
<bodyText confidence="0.941714">
where A(y(i), y) is the number of head mistakes
in y relative to the gold parse y(i). We adopt here
a shorthand Err(y) = A(y(i), y), where the de-
</bodyText>
<figure confidence="0.998002818181818">
ROOT It was not Black Monday
(b) walk path: not → Monday → not sssssssssss
&amp;quot; &amp;quot;&amp;quot;&amp;quot; → was
loop erased
2
3
ROOT It was not Black Monday
1
(c) walk path: Black — Monday — was
2
1
</figure>
<page confidence="0.974723">
200
</page>
<bodyText confidence="0.9998865625">
pendence on y(i) is implied from context. Note
that Equation 4 contains exponentially many con-
straints and cannot be enforced jointly for general
scoring functions. However, our sampling proce-
dure generates a small number of structures along
the search path. We enforce only constraints cor-
responding to those samples.
The second type of constraints are enforced be-
tween successive samples along the search path.
To illustrate the idea, consider a parse y that dif-
fers from y(i) in only one arc, and a parse y&apos; that
differs from y(i) in ten arcs. We cannot necessarily
assume that s(x, y) is greater than s(x, y&apos;) without
additional encouragement. Thus, we can comple-
ment the constraints in Equation 4 with additional
pairwise constraints (Wick et al., 2011):
</bodyText>
<equation confidence="0.985426">
s(x(i), y) − s(x(i), y&apos;) &gt; Err(y&apos;) − Err(y) (5)
</equation>
<bodyText confidence="0.999929214285714">
where similarly to Equation 4, the difference in
scores scales with the differences in errors with re-
spect to the target y(i). We only enforce the above
constraints for y, y&apos; that are consecutive samples
in the course of the sampling process. These con-
straints serve to guide the sampling process de-
rived from the scoring function towards the gold
parse.
We learn the parameters θ in an on-line fashion
to satisfy the above constraints. This is done via
the MIRA algorithm (Crammer and Singer, 2003).
Specifically, if the current parameters are θt, and
we enforce constraint Equation 5 for a particular
pair y, y&apos;, then we will find θt+1 that minimizes
</bodyText>
<equation confidence="0.924224333333333">
min ||0 − 0t||2 + Cξ
s.t. 0 · (f(x, y) − f(x, y&apos;)) ≥ Err(y&apos;) − Err(y) − ξ
(6)
</equation>
<bodyText confidence="0.999951">
The updates can be calculated in closed form. Fig-
ure 4 summarizes the learning algorithm. We re-
peatedly generate parses based on the current pa-
rameters θt for each sentence x(i), and use succes-
sive samples to enforce constraints in Equation 4
and Equation 5 one at a time.
</bodyText>
<subsectionHeader confidence="0.997871">
3.4 Joint Parsing and POS Correction
</subsectionHeader>
<bodyText confidence="0.999303571428571">
It is easy to extend our sampling-based parsing
framework to joint prediction of parsing and other
labels. Specifically, when sampling the new heads,
we can also sample the values of other variables at
the same time. For instance, we can sample the
POS tag, the dependency relation or morphology
information. In this work, we investigate a joint
</bodyText>
<equation confidence="0.984437931034483">
Inputs: D = {(x(i), y(i))}Ni=1.
Outputs: Learned parameters θ.
θ0 ← 0
for e = 1 to #epochs do
for i = 1 to N do
y0 ← q(·|x(i), yti
i , θt)
y+ = arg min 7 t. Err(y)
y∈ IEiE ,y0�
y− = arg max 7 t. Err(y)
iE
y∈ l� �y0�
ti+1
y← acceptOrReject(y0, yti
i , θt)
i
ti ← ti + 1
∇f = f(x(i), y+) − f(x(i), y−)
AErr = Err(y+) − Err(y−)
if AErr =6 0 and θt · ∇f &lt; AErr then
θt+1 ← updateMIRA(∇f, AErr, θt)
t ← t + 1
∇fg = f(x(i), y(i)) − f(x(i), yti
i )
if θt · ∇fg &lt; Err(yti
i ) then
θt+1 ← updateMIRA(∇fg, Err(yti
i ), θt)
t ← t + 1
</equation>
<figureCaption confidence="0.845098">
return Average of θ0, ... , θt parameters.
Figure 4: SampleRank algorithm for learning. The
rejection strategy is as in Figure 1. yti
</figureCaption>
<bodyText confidence="0.997372064516129">
i is the tith
tree sample of x(i). The first MIRA update (see
Equation 6) enforces a ranking constraint between
two sampled parses. The second MIRA update en-
forces constraints between a sampled parse and the
gold parse. In practice several samples are drawn
for each sentence in each epoch.
POS correction scenario in which only the pre-
dicted POS tags are provided in the testing phase,
while both gold and predicted tags are available
for the training set.
We extend our model such that it jointly learns
how to predict a parse tree and also correct the pre-
dicted POS tags for a better parsing performance.
We generate the POS candidate list for each word
based on the confusion matrix on the training set.
Let c(tg, tp) be the count when the gold tag is tg
and the predicted one is tp. For each word w, we
first prune out its POS candidates by using the vo-
cabulary from the training set. We don’t prune
anything if w is unseen. Assuming that the pre-
dicted tag for w is tp, we further remove those tags
t if their counts are smaller than some threshold
c(t, tp) &lt; α · c(tp, tp)2.
After generating the candidate lists for each
word, the rest of the extension is rather straight-
forward. For each sampling, let H be the set of
candidate heads and T be the set of candidate POS
tags. The Gibbs sampler will generate a new sam-
ple from the space H x T . The other parts of the
algorithm remain the same.
</bodyText>
<footnote confidence="0.9965185">
2In our work we choose α = 0.003, which gives a 98.9%
oracle POS tagging accuracy on the CATiB development set.
</footnote>
<page confidence="0.990507">
201
</page>
<figure confidence="0.998930733333333">
consecutive sibling
grandparent
g h m
eat with knife and fork
arc
h m
h m s
arbitrary sibling
É
h m s
grand-sibling
head bigram
h&apos; h m m+1
grand-grandparent
tri-siblings
</figure>
<figureCaption confidence="0.999397">
Figure 5: First- to third-order features.
</figureCaption>
<sectionHeader confidence="0.999088" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.995899333333333">
First- to Third-Order Features The feature
templates of first- to third-order features are
mainly drawn from previous work on graph-
based parsing (McDonald and Pereira, 2006),
transition-based parsing (Nivre et al., 2006) and
dual decomposition-based parsing (Martins et al.,
2011). As shown in Figure 5, the arc is the basic
structure for first-order features. We also define
features based on consecutive sibling, grandpar-
ent, arbitrary sibling, head bigram, grand-sibling
and tri-siblings, which are also used in the Turbo
parser (Martins et al., 2013). In addition to these
first- to third-order structures, we also consider
grand-grandparent and sibling-grandchild struc-
tures. There are two types of sibling-grandchild
structures: (1) inner-sibling when the sibling is
between the head and the modifier and (2) outer-
sibling for the other cases.
Global Features We used feature shown promis-
ing in prior reranking work Charniak and Johnson
(2005), Collins (2000) and Huang (2008).
</bodyText>
<listItem confidence="0.997753923076923">
• Right Branch This feature enables the model
to prefer right or left-branching trees. It counts
the number of words on the path from the root
node to the right-most non-punctuation word,
normalized by the length of the sentence.
• Coordination In a coordinate structure, the two
adjacent conjuncts usually agree with each other
on POS tags and their span lengths. For in-
stance, in cats and dogs, the conjuncts are both
short noun phrases. Therefore, we add differ-
ent features to capture POS tag and span length
consistency in a coordinate structure.
• PP Attachment We add features of lexical tu-
</listItem>
<figureCaption confidence="0.703668">
Figure 6: An example of PP attachment with coor-
dination. The arguments should be knife and fork,
not and.
</figureCaption>
<bodyText confidence="0.997670428571429">
ples involving the head, the argument and the
preposition of prepositional phrases. Generally,
this feature can be defined based on an instance
of grandparent structure. However, we also han-
dle the case of coordination. In this case, the ar-
guments should be the conjuncts rather than the
coordinator. Figure 6 shows an example.
</bodyText>
<listItem confidence="0.9182957">
• Span Length This feature captures the distribu-
tion of the binned span length of each POS tag.
It also includes flags of whether the span reaches
the end of the sentence and whether the span is
followed by the punctuation.
• Neighbors The POS tags of the neighboring
words to the left and right of each span, together
with the binned span length and the POS tag at
the span root.
• Valency We consider valency features for each
POS tag. Specifically, we add two types of va-
lency information: (1) the binned number of
non-punctuation modifiers and (2) the concate-
nated POS string of all those modifiers.
• Non-projective Arcs A flag indicating if a de-
pendency is projective or not (i.e. if it spans a
word that does not descend from its head) (Mar-
tins et al., 2011). This flag is also combined with
the POS tags or the lexical words of the head and
the modifier.
</listItem>
<bodyText confidence="0.982377222222222">
POS Tag Features In the joint POS correction
scenario, we also add additional features specifi-
cally for POS prediction. The feature templates
are inspired by previous feature-rich POS tagging
work (Toutanova et al., 2003). However, we are
free to add higher order features because we do
not rely on dynamic programming decoding. In
our work we use feature templates up to 5-gram.
Table 1 summarizes all POS tag feature templates.
</bodyText>
<sectionHeader confidence="0.998849" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99342">
Datasets We evaluate our model on standard
benchmark corpora — CoNLL 2006 and CoNLL
2008 (Buchholz and Marsi, 2006; Surdeanu et al.,
2008) — which include dependency treebanks for
14 different languages. Most of these data sets
</bodyText>
<figure confidence="0.985838714285714">
outer-sibling-grandchild
inner-sibling-grandchild
g h m s
g h m
gg
h m s t
h m gc s h s m gc
</figure>
<page confidence="0.990327">
202
</page>
<table confidence="0.998519555555556">
1-gram htii, hti, wi−2i, hti, wi−1i, hti, wii, hti, wi+1i,
hti, wi+2i
2-gram hti−1, tii, hti−2, tii, hti−1, ti, wi−1i,
hti−1, ti, wii
3-gram hti−1, ti, ti+1i, hti−2, ti, ti+1, i, hti−1, ti, ti+2i,
hti−2, ti, ti+2i
4-gram hti−2, ti−1, ti, ti+1i, hti−2, ti−1, ti, ti+2i,
hti−2, ti, ti+1, ti+2i
5-gram hti−2, ti−1, ti, ti+1, ti+2i
</table>
<tableCaption confidence="0.998274">
Table 1: POS tag feature templates. ti and wi de-
</tableCaption>
<bodyText confidence="0.99535285">
notes the POS tag and the word at the current posi-
tion. ti−x and ti+x denote the left and right context
tags, and similarly for words.
contain non-projective dependency trees. We use
all sentences in CoNLL datasets during training
and testing. We also use the Columbia Arabic
Treebank (CATiB) (Marton et al., 2013). CATiB
mostly includes projective trees. The trees are an-
notated with both gold and predicted versions of
POS tags and morphology information. Follow-
ing Marton et al. (2013), for this dataset we use
12 core POS tags, word lemmas, determiner fea-
tures, rationality features and functional genders
and numbers.
Some CATiB sentences exceed 200 tokens. For
efficiency, we limit the sentence length to 70 to-
kens in training and development sets. However,
we do not impose this constraint during testing.
We handle long sentences during testing by apply-
ing a simple split-merge strategy. We split the sen-
tence based on the ending punctuation, predict the
parse tree for each segment and group the roots of
resulting trees into a single node.
Evaluation Measures Following standard prac-
tice, we use Unlabeled Attachment Score (UAS)
as the evaluation metric in all our experiments.
We report UAS excluding punctuation on CoNLL
datasets, following Martins et al. (2013). For the
CATiB dataset, we report UAS including punctu-
ation in order to be consistent with the published
results in the 2013 SPMRL shared task (Seddah et
al., 2013).
Baselines We compare our model with the Turbo
parser and the MST parser. For the Turbo parser,
we directly compare with the recent published re-
sults in (Martins et al., 2013). For the MST parser,
we train a second-order non-projective model us-
ing the most recent version of the code3.
We also compare our model against a discrim-
inative reranker. The reranker operates over the
</bodyText>
<footnote confidence="0.74385">
3http://sourceforge.net/projects/mstparser/
</footnote>
<bodyText confidence="0.998969205128205">
top-50 list obtained from the MST parser4. We
use a 10-fold cross-validation to generate candi-
date lists for training. We then train the reranker
by running 10 epochs of cost-augmented MIRA.
The reranker uses the same features as our model,
along with the tree scores obtained from the MST
parser (which is a standard practice in reranking).
Experimental Details Following Koo and Collins
(2010), we always first train a first-order pruner.
For each word xi, we prune away the incoming
dependencies (hi, xi) with probability less than
0.005 times the probability of the most likely head,
and limit the number of candidate heads up to 30.
This gives a 99% pruning recall on the CATiB
development set. The first-order model is also
trained using the algorithm in Figure 4. Af-
ter pruning, we tune the regularization parameter
C = {0.1, 0.01, 0.001} on development sets for
different languages. Because the CoNLL datasets
do not have a standard development set, we ran-
domly select a held out of 200 sentences from the
training set. We also pick the training epochs from
{50, 100, 150} which gives the best performance
on the development set for each language. After
tuning, the model is trained on the full training set
with the selected parameters.
We apply the Random Walk-based sampling
method (see Section 3.2.2) for the standard de-
pendency parsing task. However, for the joint
parsing and POS correction on the CATiB dataset
we do not use the Random Walk method because
the first-order features in normal parsing are no
longer first-order when POS tags are also vari-
ables. Therefore, the first-order distribution is not
well-defined and we only employ Gibbs sampling
for simplicity. On the CATiB dataset, we restrict
the sample trees to always be projective as de-
scribed in Section 3.2.1. However, we do not im-
pose this constraint for the CoNLL datasets.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="evaluation">
6 Results
</sectionHeader>
<subsectionHeader confidence="0.654728">
Comparison with State-of-the-art Parsers Ta-
</subsectionHeader>
<bodyText confidence="0.999979333333333">
ble 2 summarizes the performance of our model
and of the baselines. We first compare our model
to the Turbo parser using the Turbo parser fea-
ture set. This is meant to test how our learning
and inference methods compare to a dual decom-
position approach. The first column in Table 2
</bodyText>
<footnote confidence="0.998974333333333">
4The MST parser is trained in projective mode for rerank-
ing because generating top-k list from second-order non-
projective model is intractable.
</footnote>
<page confidence="0.994126">
203
</page>
<table confidence="0.9997385">
Our Model (UAS) Turbo (UAS) MST 2nd-Ord. Best Published UAS Top-50 Top-500
(UAS) Reranker Reranker
Turbo Feat. Full Feat.
Arabic 79.86 80.21 79.64 78.75 81.12 (Ma11) 79.03 78.91
Bulgarian 92.97 93.30 93.10 91.56 94.02 (Zh13) 92.81 -
Chinese 92.06 92.63 89.98 91.77 91.89 (Ma10) 92.25 -
Czech 90.62 91.04 90.32 87.30 90.32 (Ma13) 88.14 -
Danish 91.45 91.80 91.48 90.50 92.00 (Zh13) 90.88 90.91
Dutch 85.83 86.47 86.19 84.11 86.19 (Ma13) 81.01 -
English 92.79 92.94 93.22 91.54 93.22 (Ma13) 92.41 -
German 91.79 92.07 92.41 90.14 92.41 (Ma13) 91.19 -
Japanese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 -
Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 -
Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37
Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21
Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 -
Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23
Average 88.87 89.23 88.72 86.86 89.33 87.92 -
</table>
<tableCaption confidence="0.996391">
Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the
</tableCaption>
<bodyText confidence="0.98725821875">
most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins
et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald
(2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns
shows UAS of the discriminative reranker.
shows the result for our model with an average of
88.87%, and the third column shows the results
for the Turbo parser with an average of 88.72%.
This suggests that our learning and inference pro-
cedures are as effective as the dual decomposition
method in the Turbo parser.
Next, we add global features that are not used by
the Turbo parser. The performance of our model
is shown in the second column with an average of
89.23%. It outperforms the Turbo parser by 0.5%
and achieves the best reported performance on
four languages. Moreover, our model also outper-
forms the 88.80% average UAS reported in Mar-
tins et al. (2011), which is the top performing sin-
gle parsing system (to the best of our knowledge).
Comparison with Reranking As column 6 of Ta-
ble 2 shows, our model outperforms the reranker
by 1.3%5. One possible explanation of this perfor-
mance gap between the reranker and our model is
the small number of candidates considered by the
reranker. To test this hypothesis, we performed
experiments with top-500 list for a subset of lan-
guages.6 As column 7 shows, this increase in the
list size does not change the relative performance
of the reranker and our model.
Joint Parsing and POS Correction Table 3
shows the results of joint parsing and POS cor-
rection on the CATiB dataset, for our model and
</bodyText>
<footnote confidence="0.990605142857143">
5Note that the comparison is conservative because we
can also add MST scores as features in our model as in
reranker. With these features our model achieves an average
UAS 89.28%.
6We ran this experiment on 5 languages with small
datasets due to the scalability issues associated with rerank-
ing top-500 list.
</footnote>
<bodyText confidence="0.999900558823529">
state-of-the-art systems. As the upper part of the
table shows, the parser with corrected tags reaches
88.38% compared to the accuracy of 88.46% on
the gold tags. This is a substantial increase from
the parser that uses predicted tags (86.95%).
To put these numbers into perspective, the bot-
tom part of Table 3 shows the accuracy of the best
systems from the 2013 SPMRL shared task on
Arabic parsing using predicted information (Sed-
dah et al., 2013). Our system not only out-
performs the best single system (Bj¨orkelund et
al., 2013) by 1.4%, but it also tops the ensem-
ble system that combines three powerful parsers:
the Mate parser (Bohnet, 2010), the Easy-First
parser (Goldberg and Elhadad, 2010) and the
Turbo parser (Martins et al., 2013)
Impact of Sampling Methods We compare two
sampling methods introduced in Section 3.2 with
respect to their decoding efficiency. Specifically,
we measure the score of the retrieved trees in test-
ing as a function of the decoding speed, measured
by the number of tokens per second. We change
the temperature update rate c in order to decode
with different speed. In Figure 7 we show the cor-
responding curves for two languages: Arabic and
Chinese. We select these two languages as they
correspond to two extremes in sentence length:
Arabic has the longest sentences on average, while
Chinese has the shortest ones. For both languages,
the tree score improves over time. Given sufficient
time, both sampling methods achieve the same
score. However, the Random Walk-based sam-
pler performs better when the quality is traded for
speed. This result is to be expected given that each
</bodyText>
<page confidence="0.99602">
204
</page>
<table confidence="0.999314625">
Dev. Set (≤ 70) Testing Set
POS Acc. UAS POS Acc. UAS
Gold - 90.27 - 88.46
Predicted 96.87 88.81 96.82 86.95
POS Correction 97.72 90.08 97.49 88.38
CADIM 96.87 87.4- 96.82 85.78
IMS-Single - - - 86.96
IMS-Ensemble - - - 88.32
</table>
<tableCaption confidence="0.985393">
Table 3: Results for parsing and corrective tagging
</tableCaption>
<bodyText confidence="0.9905895">
on the CATiB dataset. The upper part shows UAS
of our model with gold/predicted information or
POS correction. Bottom part shows UAS of the
best systems in the SPMRL shared task. IMS-
Single (Bj¨orkelund et al., 2013) is the best single
parsing system, while IMS-Ensemble (Bj¨orkelund
et al., 2013) is the best ensemble parsing system.
We also show results for CADIM (Marton et al.,
2013), the second best system, because we use
their predicted features.
</bodyText>
<figure confidence="0.994247769230769">
2.658x 104
Gibbs
Random Walk
2.6480 20 40 60 80 100
Toks/sec
(a) Arabic
x 104
1.9
1.899
1.898
1.8970 100 200 300 400 500 600 700 800
Toks/sec
(b) Chinese
</figure>
<figureCaption confidence="0.999527">
Figure 7: Total score of the predicted test trees as
</figureCaption>
<bodyText confidence="0.922062125">
a function of the decoding speed, measured in the
number of tokens per second.
iteration of this sampler makes multiple changes
to the tree, in contrast to a single-edge change of
Gibbs sampler.
The Effect of Constraints in Learning Our train-
ing method updates parameters to satisfy the pair-
wise constraints between (1) subsequent samples
on the sampling path and (2) selected samples and
the ground truth. Figure 8 shows that applying
both types of constraints is consistently better than
using either of them alone. Moreover, these re-
sults demonstrate that comparison between subse-
quent samples is more important than comparison
against the gold tree.
Decoding Speed Our sampling-based parser is an
</bodyText>
<figureCaption confidence="0.97453">
Figure 8: UAS on four languages when train-
ing with different constraints. “Neighbor” corre-
sponds to pairwise constraints between subsequent
samples, “Gold” represents constraints between a
single sample and the ground truth, “Both” means
applying both types of constraints.
</figureCaption>
<bodyText confidence="0.998910272727273">
anytime algorithm, and therefore its running time
can be traded for performance. Figure 7 illustrates
this trade-off. In the experiments reported above,
we chose a conservative cooling rate and contin-
ued to sample until the score no longer changed.
The parser still managed to process all the datasets
in a reasonable time. For example, the time that it
took to decode all the test sentences in Chinese and
Arabic were 3min and 15min, respectively. Our
current implementation is in Java and can be fur-
ther optimized for speed.
</bodyText>
<sectionHeader confidence="0.999343" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999907625">
This paper demonstrates the power of combining a
simple inference procedure with a highly expres-
sive scoring function. Our model achieves the best
results on the standard dependency parsing bench-
mark, outperforming parsing methods with elabo-
rate inference procedures. In addition, this frame-
work provides simple and effective means for joint
parsing and corrective tagging.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999833555555556">
This research is developed in collaboration with
the Arabic Language Technologies (ALT) group
at Qatar Computing Research Institute (QCRI)
within the IYAS project. The authors acknowledge
the support of the MURI program (W911NF-10-
1-0533, the DARPA BOLT program and the US-
Israel Binational Science Foundation (BSF, Grant
No 2012330). We thank the MIT NLP group and
the ACL reviewers for their comments.
</bodyText>
<figure confidence="0.998927666666667">
Danish Japanese Portuguese Swedish
UAS(%) 94
93
92
91
90
89
Both
Neighbor
Gold
2.656
Score
2.654
2.652
2.65
Score
Gibbs
Random Walk
</figure>
<page confidence="0.994289">
205
</page>
<sectionHeader confidence="0.989226" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708422018349">
Christophe Andrieu, Nando De Freitas, Arnaud
Doucet, and Michael I Jordan. 2003. An introduc-
tion to mcmc for machine learning. Machine learn-
ing, 50(1-2):5–43.
Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas,
Thomas Mueller, and Wolfgang Seeker. 2013.
(re)ranking meets morphosyntax: State-of-the-art
results from the SPMRL 2013 shared task. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 135–
145, Seattle, Washington, USA, October. Associa-
tion for Computational Linguistics.
Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In COLING,
pages 89–97.
Sabine Buchholz and Erwin Marsi. 2006. Conll-x
shared task on multilingual dependency parsing. In
Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning, pages 149–164.
Association for Computational Linguistics.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and maxent discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 173–180. Association for Computational Lin-
guistics.
Michael Collins. 2000. Discriminative reranking for
natural language parsing. In Proceedings of the
Seventeenth International Conference on Machine
Learning, ICML ’00, pages 175–182.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
The Journal of Machine Learning Research, 3:951–
991.
Hal Daum´e III, John Langford, and Daniel Marcu.
2009. Search-based structured prediction. Machine
learning, 75(3):297–325.
Stuart Geman and Donald Geman. 1984. Stochas-
tic relaxation, gibbs distributions, and the bayesian
restoration of images. Pattern Analysis and Machine
Intelligence, IEEE Transactions on, (6):721–741.
Yoav Goldberg and Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional depen-
dency parsing. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 742–750. Association for Computa-
tional Linguistics.
Barry Haddow, Abhishek Arun, and Philipp Koehn.
2011. Samplerank training for phrase-based ma-
chine translation. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, pages 261–
271. Association for Computational Linguistics.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In ACL, pages 586–
594.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, pages 1–11. Association for
Computational Linguistics.
Terry Koo, Alexander M Rush, Michael Collins,
Tommi Jaakkola, and David Sontag. 2010. Dual
decomposition for parsing with non-projective head
automata. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1288–1298. Association for Compu-
tational Linguistics.
Quannan Li, Jingdong Wang, Zhuowen Tu, and
David P Wipf. 2013. Fixed-point model for struc-
tured labeling. In Proceedings of the 30th Interna-
tional Conference on Machine Learning (ICML-13),
pages 214–221.
Andr´e FT Martins, Noah A Smith, and Eric P Xing.
2009. Concise integer linear programming formula-
tions for dependency parsing. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 1-Volume 1, pages 342–350. Association for
Computational Linguistics.
Andr´e FT Martins, Noah A Smith, Eric P Xing, Pe-
dro MQ Aguiar, and M´ario AT Figueiredo. 2010.
Turbo parsers: Dependency parsing by approxi-
mate variational inference. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 34–44. Association for
Computational Linguistics.
Andr´e FT Martins, Noah A Smith, Pedro MQ Aguiar,
and M´ario AT Figueiredo. 2011. Dual decompo-
sition with many overlapping components. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 238–249. As-
sociation for Computational Linguistics.
Andr´e FT Martins, Miguel B Almeida, and Noah A
Smith. 2013. Turning on the turbo: Fast third-order
non-projective turbo parsers. In Proceedings of the
51th Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics.
Yuval Marton, Nizar Habash, Owen Rambow, and
Sarah Alkhulani. 2013. Spmrl13 shared task sys-
tem: The cadim arabic dependency parser. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 76–
80.
Ryan T McDonald and Fernando CN Pereira. 2006.
Online learning of approximate dependency parsing
algorithms. In EACL.
</reference>
<page confidence="0.981256">
206
</page>
<reference confidence="0.999957097826087">
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic.
2005. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
pages 523–530.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proceedings of the
Tenth Conference on Computational Natural Lan-
guage Learning, pages 216–220. Association for
Computational Linguistics.
Tetsuji Nakagawa. 2007. Multilingual dependency
parsing using global features. In EMNLP-CoNLL,
pages 952–956.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiit,
and Svetoslav Marinov. 2006. Labeled pseudo-
projective dependency parsing with support vector
machines. In Proceedings of the Tenth Confer-
ence on Computational Natural Language Learning,
pages 221–225. Association for Computational Lin-
guistics.
Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav
Zimak. 2004. Semantic role labeling via integer
linear programming inference. In Proceedings of
the 20th international conference on Computational
Linguistics, page 1346. Association for Computa-
tional Linguistics.
Alexander M Rush and Slav Petrov. 2012. Vine prun-
ing for efficient multi-pass dependency parsing. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 498–507. Association for Computational Lin-
guistics.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie
Candito, Jinho D Choi, Rich´ard Farkas, Jennifer
Foster, Iakes Goenaga, Koldo Gojenola Gallete-
beitia, Yoav Goldberg, et al. 2013. Overview of the
spmrl 2013 shared task: A cross-framework evalua-
tion of parsing morphologically rich languages. In
Proceedings of the Fourth Workshop on Statistical
Parsing of Morphologically-Rich Languages, pages
146–182.
D. Sontag, A. Globerson, and T. Jaakkola. 2011. In-
troduction to dual decomposition for inference. In
Optimization for Machine Learning, pages 219–254.
MIT Press.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The
conll-2008 shared task on joint parsing of syntac-
tic and semantic dependencies. In Proceedings of
the Twelfth Conference on Computational Natural
Language Learning, pages 159–177. Association for
Computational Linguistics.
Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1, pages 173–180. Association for Compu-
tational Linguistics.
Michael L. Wick, Khashayar Rohanimanesh, Kedar
Bellare, Aron Culotta, and Andrew McCallum.
2011. Samplerank: Training factor graphs with
atomic gradients. In Lise Getoor and Tobias Schef-
fer, editors, Proceedings of the 28th International
Conference on Machine Learning, ICML 2011,
pages 777–784.
David Bruce Wilson. 1996. Generating random span-
ning trees more quickly than the cover time. In
Proceedings of the twenty-eighth annual ACM sym-
posium on Theory of computing, pages 296–303.
ACM.
Hao Zhang and Ryan McDonald. 2012. Generalized
higher-order dependency parsing with cube prun-
ing. In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 320–331. Association for Computational Lin-
guistics.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers-Volume 2, pages
188–193. Association for Computational Linguis-
tics.
Hao Zhang, Liang Huang Kai Zhao, and Ryan McDon-
ald. 2013. Online learning for inexact hypergraph
search. In Proceedings of EMNLP.
</reference>
<page confidence="0.998021">
207
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.256106">
<title confidence="0.996838">Steps to Excellence: Simple Inference with Refined Scoring Dependency Trees</title>
<author confidence="0.989127">Yuan Zhang</author>
<author confidence="0.989127">Tao Lei</author>
<author confidence="0.989127">Regina Barzilay</author>
<author confidence="0.989127">Tommi Jaaliliola Amir Globerson</author>
<affiliation confidence="0.574411">Massachusetts Institute of Technology The Hebrew</affiliation>
<email confidence="0.960596">taolei,regina,gamir@cs.huji.ac.il</email>
<abstract confidence="0.999424333333333">Much of the recent work on dependency parsing has been focused on solving inherent combinatorial problems associated with rich scoring functions. In contrast, we demonstrate that highly expressive scoring functions can be used with substantially simpler inference procedures. Specifically, we introduce a sampling-based parser that can easily handle arbitrary global features. Inspired by SampleRank, we learn to take guided stochastic steps towards a high scoring parse. We introduce two samplers for traversing the space of trees, Gibbs and Metropolis-Hastings with Random Walk. The model outperforms state-of-the-art results when evaluated on 14 languages of non-projective CoNLL datasets. Our sampling-based approach naturally extends to joint prediction scenarios, such as joint parsing and POS correction. The resulting method outperforms the best reported results on the CATiB dataset, ap-</abstract>
<intro confidence="0.484832">proaching performance of parsing with</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christophe Andrieu</author>
<author>Nando De Freitas</author>
<author>Arnaud Doucet</author>
<author>Michael I Jordan</author>
</authors>
<title>An introduction to mcmc for machine learning.</title>
<date>2003</date>
<booktitle>Machine learning,</booktitle>
<pages>50--1</pages>
<marker>Andrieu, De Freitas, Doucet, Jordan, 2003</marker>
<rawString>Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. 2003. An introduction to mcmc for machine learning. Machine learning, 50(1-2):5–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Ozlem Cetinoglu</author>
<author>Rich´ard Farkas</author>
<author>Thomas Mueller</author>
<author>Wolfgang Seeker</author>
</authors>
<title>(re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>135--145</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<marker>Bj¨orkelund, Cetinoglu, Farkas, Mueller, Seeker, 2013</marker>
<rawString>Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 135– 145, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction. In</title>
<date>2010</date>
<booktitle>COLING,</booktitle>
<pages>89--97</pages>
<contexts>
<context position="32826" citStr="Bohnet, 2010" startWordPosition="5615" endWordPosition="5616">pper part of the table shows, the parser with corrected tags reaches 88.38% compared to the accuracy of 88.46% on the gold tags. This is a substantial increase from the parser that uses predicted tags (86.95%). To put these numbers into perspective, the bottom part of Table 3 shows the accuracy of the best systems from the 2013 SPMRL shared task on Arabic parsing using predicted information (Seddah et al., 2013). Our system not only outperforms the best single system (Bj¨orkelund et al., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al., 2013) Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency. Specifically, we measure the score of the retrieved trees in testing as a function of the decoding speed, measured by the number of tokens per second. We change the temperature update rate c in order to decode with different speed. In Figure 7 we show the corresponding curves for two languages: Arabic and Chinese. We select these two languages as they correspond to two ext</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In COLING, pages 89–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="24394" citStr="Buchholz and Marsi, 2006" startWordPosition="4187" endWordPosition="4190">OS tags or the lexical words of the head and the modifier. POS Tag Features In the joint POS correction scenario, we also add additional features specifically for POS prediction. The feature templates are inspired by previous feature-rich POS tagging work (Toutanova et al., 2003). However, we are free to add higher order features because we do not rely on dynamic programming decoding. In our work we use feature templates up to 5-gram. Table 1 summarizes all POS tag feature templates. 5 Experimental Setup Datasets We evaluate our model on standard benchmark corpora — CoNLL 2006 and CoNLL 2008 (Buchholz and Marsi, 2006; Surdeanu et al., 2008) — which include dependency treebanks for 14 different languages. Most of these data sets outer-sibling-grandchild inner-sibling-grandchild g h m s g h m gg h m s t h m gc s h s m gc 202 1-gram htii, hti, wi−2i, hti, wi−1i, hti, wii, hti, wi+1i, hti, wi+2i 2-gram hti−1, tii, hti−2, tii, hti−1, ti, wi−1i, hti−1, ti, wii 3-gram hti−1, ti, ti+1i, hti−2, ti, ti+1, i, hti−1, ti, ti+2i, hti−2, ti, ti+2i 4-gram hti−2, ti−1, ti, ti+1i, hti−2, ti−1, ti, ti+2i, hti−2, ti, ti+1, ti+2i 5-gram hti−2, ti−1, ti, ti+1, ti+2i Table 1: POS tag feature templates. ti and wi denotes the POS</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6555" citStr="Charniak and Johnson, 2005" startWordPosition="1020" endWordPosition="1024">n the best published results in the 2013 SPMRL shared task (Seddah et al., 2013), including parser ensembles. 2 Related Work Earlier works on dependency parsing focused on inference with tractable scoring functions. For instance, a scoring function that operates over each single dependency can be optimized using the maximum spanning tree algorithm (McDonald et al., 2005). It was soon realized that using higher order features could be beneficial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD)</context>
<context position="21901" citStr="Charniak and Johnson (2005)" startWordPosition="3756" endWordPosition="3759">sic structure for first-order features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outersibling for the other cases. Global Features We used feature shown promising in prior reranking work Charniak and Johnson (2005), Collins (2000) and Huang (2008). • Right Branch This feature enables the model to prefer right or left-branching trees. It counts the number of words on the path from the root node to the right-most non-punctuation word, normalized by the length of the sentence. • Coordination In a coordinate structure, the two adjacent conjuncts usually agree with each other on POS tags and their span lengths. For instance, in cats and dogs, the conjuncts are both short noun phrases. Therefore, we add different features to capture POS tag and span length consistency in a coordinate structure. • PP Attachmen</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 173–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning, ICML ’00,</booktitle>
<pages>175--182</pages>
<contexts>
<context position="2341" citStr="Collins, 2000" startWordPosition="341" endWordPosition="342">csail.mit.edu/rbg/code/ global/acl2014. tained by adapting powerful tools from optimization (Martins et al., 2013; Martins et al., 2011; Rush and Petrov, 2012). We depart from this view and instead focus on using highly expressive scoring functions with substantially simpler inference procedures. The key ingredient in our approach is how learning is coupled with inference. Our combination outperforms the state-of-the-art parsers and remains comparable even if we adopt their scoring functions. Rich scoring functions have been used for some time. They first appeared in the context of reranking (Collins, 2000), where a simple parser is used to generate a candidate list which is then reranked according to the scoring function. Because the number of alternatives is small, the scoring function could in principle involve arbitrary (global) features of parse trees. The power of this methodology is nevertheless limited by the initial set of alternatives from the simpler parser. Indeed, the set may already omit the gold parse. We dispense with the notion of a candidate set and seek to exploit the scoring function more directly. In this paper, we introduce a sampling-based parser that places few or no cons</context>
<context position="6526" citStr="Collins, 2000" startWordPosition="1018" endWordPosition="1019">s is better than the best published results in the 2013 SPMRL shared task (Seddah et al., 2013), including parser ensembles. 2 Related Work Earlier works on dependency parsing focused on inference with tractable scoring functions. For instance, a scoring function that operates over each single dependency can be optimized using the maximum spanning tree algorithm (McDonald et al., 2005). It was soon realized that using higher order features could be beneficial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example i</context>
<context position="21917" citStr="Collins (2000)" startWordPosition="3760" endWordPosition="3761"> features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outersibling for the other cases. Global Features We used feature shown promising in prior reranking work Charniak and Johnson (2005), Collins (2000) and Huang (2008). • Right Branch This feature enables the model to prefer right or left-branching trees. It counts the number of words on the path from the root node to the right-most non-punctuation word, normalized by the length of the sentence. • Coordination In a coordinate structure, the two adjacent conjuncts usually agree with each other on POS tags and their span lengths. For instance, in cats and dogs, the conjuncts are both short noun phrases. Therefore, we add different features to capture POS tag and span length consistency in a coordinate structure. • PP Attachment We add feature</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative reranking for natural language parsing. In Proceedings of the Seventeenth International Conference on Machine Learning, ICML ’00, pages 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>3</volume>
<pages>991</pages>
<contexts>
<context position="17670" citStr="Crammer and Singer, 2003" startWordPosition="2976" endWordPosition="2979">aints in Equation 4 with additional pairwise constraints (Wick et al., 2011): s(x(i), y) − s(x(i), y&apos;) &gt; Err(y&apos;) − Err(y) (5) where similarly to Equation 4, the difference in scores scales with the differences in errors with respect to the target y(i). We only enforce the above constraints for y, y&apos; that are consecutive samples in the course of the sampling process. These constraints serve to guide the sampling process derived from the scoring function towards the gold parse. We learn the parameters θ in an on-line fashion to satisfy the above constraints. This is done via the MIRA algorithm (Crammer and Singer, 2003). Specifically, if the current parameters are θt, and we enforce constraint Equation 5 for a particular pair y, y&apos;, then we will find θt+1 that minimizes min ||0 − 0t||2 + Cξ s.t. 0 · (f(x, y) − f(x, y&apos;)) ≥ Err(y&apos;) − Err(y) − ξ (6) The updates can be calculated in closed form. Figure 4 summarizes the learning algorithm. We repeatedly generate parses based on the current parameters θt for each sentence x(i), and use successive samples to enforce constraints in Equation 4 and Equation 5 one at a time. 3.4 Joint Parsing and POS Correction It is easy to extend our sampling-based parsing framework </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. The Journal of Machine Learning Research, 3:951– 991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e John Langford</author>
<author>Daniel Marcu</author>
</authors>
<title>Search-based structured prediction.</title>
<date>2009</date>
<booktitle>Machine learning,</booktitle>
<pages>75--3</pages>
<marker>Langford, Marcu, 2009</marker>
<rawString>Hal Daum´e III, John Langford, and Daniel Marcu. 2009. Search-based structured prediction. Machine learning, 75(3):297–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Donald Geman</author>
</authors>
<title>Stochastic relaxation, gibbs distributions, and the bayesian restoration of images.</title>
<date>1984</date>
<journal>Pattern Analysis and Machine Intelligence, IEEE Transactions on,</journal>
<pages>6--721</pages>
<contexts>
<context position="10544" citStr="Geman and Geman (1984)" startWordPosition="1697" endWordPosition="1700">) that maximizes the score s(x, y) = 0 · f(x, y) with parameters 0. For scoring functions that extend beyond firstorder arc preferences, finding the maximizing nonprojective tree is known to be NP-hard (McDonald and Pereira, 2006). We find a high scoring tree through sampling, and (later) learn the parameters 0 so as to further guide this process. Our sampler generates a sequence of dependency structures so as to approximate independent samples from p(yJx, T, 0) a exp (s(x, y)/T) (2) The temperature parameter T controls how concentrated the samples are around the maximum of s(x, y) (e.g., see Geman and Geman (1984)). Sampling from target distribution p is typically as hard as (or harder than) that maximizing s(x, y). Inputs: 0, x, T0 (initial temperature), c (temperature update rate), proposal distribution q. Outputs: y* T ← T0 Set y0 to some random tree y* ← y0 repeat y&apos; ← q(·|x, yt, T, 0) if s(x, y&apos;) &gt; s(x, y*) then y* ← y&apos; � 1, p(y&apos;)q(yt|y&apos;) α = min p(yt)q(y&apos;|yt) Sample Bernouli variable Z with P[Z = 1] = α. if Z = 0 then yt+1 ←yt else yt+1 ← y&apos; t ← t + 1 T ← c · T until convergence return y* Figure 1: Sampling-based algorithm for decoding (i.e., approximately maximizing s(x, y)). We follow here a Me</context>
</contexts>
<marker>Geman, Geman, 1984</marker>
<rawString>Stuart Geman and Donald Geman. 1984. Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. Pattern Analysis and Machine Intelligence, IEEE Transactions on, (6):721–741.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>An efficient algorithm for easy-first non-directional dependency parsing.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>742--750</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="32878" citStr="Goldberg and Elhadad, 2010" startWordPosition="5620" endWordPosition="5623">er with corrected tags reaches 88.38% compared to the accuracy of 88.46% on the gold tags. This is a substantial increase from the parser that uses predicted tags (86.95%). To put these numbers into perspective, the bottom part of Table 3 shows the accuracy of the best systems from the 2013 SPMRL shared task on Arabic parsing using predicted information (Seddah et al., 2013). Our system not only outperforms the best single system (Bj¨orkelund et al., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al., 2013) Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency. Specifically, we measure the score of the retrieved trees in testing as a function of the decoding speed, measured by the number of tokens per second. We change the temperature update rate c in order to decode with different speed. In Figure 7 we show the corresponding curves for two languages: Arabic and Chinese. We select these two languages as they correspond to two extremes in sentence length: Arabic has the longest sen</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2010. An efficient algorithm for easy-first non-directional dependency parsing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 742–750. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Haddow</author>
<author>Abhishek Arun</author>
<author>Philipp Koehn</author>
</authors>
<title>Samplerank training for phrase-based machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>261--271</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8318" citStr="Haddow et al., 2011" startWordPosition="1310" endWordPosition="1313">g and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the target structure along the search path. The method has been successfully used in sequence labeling and machine translation (Haddow et al., 2011). In this paper, we demonstrate how to adapt the method for parsing with rich scoring functions. 3 Sampling-Based Dependency Parsing with Global Features In this section, we introduce our novel samplingbased dependency parser which can incorporate 198 arbitrary global features. We begin with the notation before addressing the decoding and learning algorithms. Finally, we extend our model to a joint parsing and POS correction task. 3.1 Notations We denote sentences by x and the corresponding dependency trees by y E Y(x). Here Y(x) is the set of valid (projective or non-projective) dependency tr</context>
</contexts>
<marker>Haddow, Arun, Koehn, 2011</marker>
<rawString>Barry Haddow, Abhishek Arun, and Philipp Koehn. 2011. Samplerank training for phrase-based machine translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 261– 271. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>586--594</pages>
<contexts>
<context position="7002" citStr="Huang, 2008" startWordPosition="1100" endWordPosition="1101">cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to </context>
<context position="21934" citStr="Huang (2008)" startWordPosition="3763" endWordPosition="3764">define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outersibling for the other cases. Global Features We used feature shown promising in prior reranking work Charniak and Johnson (2005), Collins (2000) and Huang (2008). • Right Branch This feature enables the model to prefer right or left-branching trees. It counts the number of words on the path from the root node to the right-most non-punctuation word, normalized by the length of the sentence. • Coordination In a coordinate structure, the two adjacent conjuncts usually agree with each other on POS tags and their span lengths. For instance, in cats and dogs, the conjuncts are both short noun phrases. Therefore, we add different features to capture POS tag and span length consistency in a coordinate structure. • PP Attachment We add features of lexical tuFi</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In ACL, pages 586– 594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--11</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27238" citStr="Koo and Collins (2010)" startWordPosition="4660" endWordPosition="4663">, we train a second-order non-projective model using the most recent version of the code3. We also compare our model against a discriminative reranker. The reranker operates over the 3http://sourceforge.net/projects/mstparser/ top-50 list obtained from the MST parser4. We use a 10-fold cross-validation to generate candidate lists for training. We then train the reranker by running 10 epochs of cost-augmented MIRA. The reranker uses the same features as our model, along with the tree scores obtained from the MST parser (which is a standard practice in reranking). Experimental Details Following Koo and Collins (2010), we always first train a first-order pruner. For each word xi, we prune away the incoming dependencies (hi, xi) with probability less than 0.005 times the probability of the most likely head, and limit the number of candidate heads up to 30. This gives a 99% pruning recall on the CATiB development set. The first-order model is also trained using the algorithm in Figure 4. After pruning, we tune the regularization parameter C = {0.1, 0.01, 0.001} on development sets for different languages. Because the CoNLL datasets do not have a standard development set, we randomly select a held out of 200 </context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1–11. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1288--1298</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6988" citStr="Koo et al., 2010" startWordPosition="1096" endWordPosition="1099">cial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natura</context>
<context position="9732" citStr="Koo et al., 2010" startWordPosition="1555" endWordPosition="1558">und truth parse for sentence x(i). We parameterize the scoring function s(x, y) as s(x, y) = 0 · f(x, y) (1) where f(x, y) is the feature vector associated with tree y for sentence x. We do not make any assumptions about how the feature function decomposes. In contrast, most state-of-the-art parsers operate under the assumption that the feature function decomposes into a sum of simpler terms. For example, in the second-order MST parser (McDonald and Pereira, 2006), all the feature terms involve arcs or consecutive siblings. Similarly, parsers based on dual decomposition (Martins et al., 2011; Koo et al., 2010) assume that s(x, y) decomposes into a sum of terms where each term can be maximized over y efficiently. 3.2 Decoding The decoding problem consists of finding a valid dependency tree y E Y(x) that maximizes the score s(x, y) = 0 · f(x, y) with parameters 0. For scoring functions that extend beyond firstorder arc preferences, finding the maximizing nonprojective tree is known to be NP-hard (McDonald and Pereira, 2006). We find a high scoring tree through sampling, and (later) learn the parameters 0 so as to further guide this process. Our sampler generates a sequence of dependency structures so</context>
<context position="30373" citStr="Koo et al. (2010)" startWordPosition="5188" endWordPosition="5191">2 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our model is shown in the second column with an a</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1288–1298. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quannan Li</author>
<author>Jingdong Wang</author>
<author>Zhuowen Tu</author>
<author>David P Wipf</author>
</authors>
<title>Fixed-point model for structured labeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 30th International Conference on Machine Learning (ICML-13),</booktitle>
<pages>214--221</pages>
<contexts>
<context position="7945" citStr="Li et al., 2013" startWordPosition="1247" endWordPosition="1250">rce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the target structure along the search path. The method has been successfully used in sequence labeling and machine translation (Haddow et al., 2011). In this paper, we demonstrate how to adapt the method for parsing with rich scoring functions. 3 Sampling-Based Dependency Parsing with Global Features In this section, we introduce our novel samplingbased dependency parser w</context>
</contexts>
<marker>Li, Wang, Tu, Wipf, 2013</marker>
<rawString>Quannan Li, Jingdong Wang, Zhuowen Tu, and David P Wipf. 2013. Fixed-point model for structured labeling. In Proceedings of the 30th International Conference on Machine Learning (ICML-13), pages 214–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>1</volume>
<pages>342--350</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7484" citStr="Martins et al., 2009" startWordPosition="1173" endWordPosition="1176"> inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In Sample</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andr´e FT Martins, Noah A Smith, and Eric P Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, pages 342–350. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
<author>Pedro MQ Aguiar</author>
<author>M´ario AT Figueiredo</author>
</authors>
<title>Turbo parsers: Dependency parsing by approximate variational inference.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>34--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30308" citStr="Martins et al. (2010)" startWordPosition="5176" endWordPosition="5179">1.79 92.07 92.41 90.14 92.41 (Ma13) 91.19 - Japanese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The</context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>Andr´e FT Martins, Noah A Smith, Eric P Xing, Pedro MQ Aguiar, and M´ario AT Figueiredo. 2010. Turbo parsers: Dependency parsing by approximate variational inference. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 34–44. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Noah A Smith</author>
<author>Pedro MQ Aguiar</author>
<author>M´ario AT Figueiredo</author>
</authors>
<title>Dual decomposition with many overlapping components.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>238--249</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1862" citStr="Martins et al., 2011" startWordPosition="265" endWordPosition="268">n Dependency parsing is commonly cast as a maximization problem over a parameterized scoring function. In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse. Much of the recent work on parsing has been focused on improving methods for solving the combinatorial maximization inference problems. Indeed, state-of-the-art results have been ob1The source code for the work is available at http://groups.csail.mit.edu/rbg/code/ global/acl2014. tained by adapting powerful tools from optimization (Martins et al., 2013; Martins et al., 2011; Rush and Petrov, 2012). We depart from this view and instead focus on using highly expressive scoring functions with substantially simpler inference procedures. The key ingredient in our approach is how learning is coupled with inference. Our combination outperforms the state-of-the-art parsers and remains comparable even if we adopt their scoring functions. Rich scoring functions have been used for some time. They first appeared in the context of reranking (Collins, 2000), where a simple parser is used to generate a candidate list which is then reranked according to the scoring function. Be</context>
<context position="7206" citStr="Martins et al., 2011" startWordPosition="1130" endWordPosition="1133">nking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches o</context>
<context position="9713" citStr="Martins et al., 2011" startWordPosition="1551" endWordPosition="1554"> where y(i) is the ground truth parse for sentence x(i). We parameterize the scoring function s(x, y) as s(x, y) = 0 · f(x, y) (1) where f(x, y) is the feature vector associated with tree y for sentence x. We do not make any assumptions about how the feature function decomposes. In contrast, most state-of-the-art parsers operate under the assumption that the feature function decomposes into a sum of simpler terms. For example, in the second-order MST parser (McDonald and Pereira, 2006), all the feature terms involve arcs or consecutive siblings. Similarly, parsers based on dual decomposition (Martins et al., 2011; Koo et al., 2010) assume that s(x, y) decomposes into a sum of terms where each term can be maximized over y efficiently. 3.2 Decoding The decoding problem consists of finding a valid dependency tree y E Y(x) that maximizes the score s(x, y) = 0 · f(x, y) with parameters 0. For scoring functions that extend beyond firstorder arc preferences, finding the maximizing nonprojective tree is known to be NP-hard (McDonald and Pereira, 2006). We find a high scoring tree through sampling, and (later) learn the parameters 0 so as to further guide this process. Our sampler generates a sequence of depen</context>
<context position="21233" citStr="Martins et al., 2011" startWordPosition="3654" endWordPosition="3657">. 2In our work we choose α = 0.003, which gives a 98.9% oracle POS tagging accuracy on the CATiB development set. 201 consecutive sibling grandparent g h m eat with knife and fork arc h m h m s arbitrary sibling É h m s grand-sibling head bigram h&apos; h m m+1 grand-grandparent tri-siblings Figure 5: First- to third-order features. 4 Features First- to Third-Order Features The feature templates of first- to third-order features are mainly drawn from previous work on graphbased parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al., 2006) and dual decomposition-based parsing (Martins et al., 2011). As shown in Figure 5, the arc is the basic structure for first-order features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outersibling for the other cases. Global Features We used feature</context>
<context position="23731" citStr="Martins et al., 2011" startWordPosition="4075" endWordPosition="4079">es the end of the sentence and whether the span is followed by the punctuation. • Neighbors The POS tags of the neighboring words to the left and right of each span, together with the binned span length and the POS tag at the span root. • Valency We consider valency features for each POS tag. Specifically, we add two types of valency information: (1) the binned number of non-punctuation modifiers and (2) the concatenated POS string of all those modifiers. • Non-projective Arcs A flag indicating if a dependency is projective or not (i.e. if it spans a word that does not descend from its head) (Martins et al., 2011). This flag is also combined with the POS tags or the lexical words of the head and the modifier. POS Tag Features In the joint POS correction scenario, we also add additional features specifically for POS prediction. The feature templates are inspired by previous feature-rich POS tagging work (Toutanova et al., 2003). However, we are free to add higher order features because we do not rely on dynamic programming decoding. In our work we use feature templates up to 5-gram. Table 1 summarizes all POS tag feature templates. 5 Experimental Setup Datasets We evaluate our model on standard benchmar</context>
<context position="30331" citStr="Martins et al. (2011)" startWordPosition="5180" endWordPosition="5183">92.41 (Ma13) 91.19 - Japanese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our mod</context>
</contexts>
<marker>Martins, Smith, Aguiar, Figueiredo, 2011</marker>
<rawString>Andr´e FT Martins, Noah A Smith, Pedro MQ Aguiar, and M´ario AT Figueiredo. 2011. Dual decomposition with many overlapping components. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 238–249. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Miguel B Almeida</author>
<author>Noah A Smith</author>
</authors>
<title>Turning on the turbo: Fast third-order non-projective turbo parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1840" citStr="Martins et al., 2013" startWordPosition="261" endWordPosition="264">d tags.1 1 Introduction Dependency parsing is commonly cast as a maximization problem over a parameterized scoring function. In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse. Much of the recent work on parsing has been focused on improving methods for solving the combinatorial maximization inference problems. Indeed, state-of-the-art results have been ob1The source code for the work is available at http://groups.csail.mit.edu/rbg/code/ global/acl2014. tained by adapting powerful tools from optimization (Martins et al., 2013; Martins et al., 2011; Rush and Petrov, 2012). We depart from this view and instead focus on using highly expressive scoring functions with substantially simpler inference procedures. The key ingredient in our approach is how learning is coupled with inference. Our combination outperforms the state-of-the-art parsers and remains comparable even if we adopt their scoring functions. Rich scoring functions have been used for some time. They first appeared in the context of reranking (Collins, 2000), where a simple parser is used to generate a candidate list which is then reranked according to th</context>
<context position="21507" citStr="Martins et al., 2013" startWordPosition="3697" endWordPosition="3700"> tri-siblings Figure 5: First- to third-order features. 4 Features First- to Third-Order Features The feature templates of first- to third-order features are mainly drawn from previous work on graphbased parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al., 2006) and dual decomposition-based parsing (Martins et al., 2011). As shown in Figure 5, the arc is the basic structure for first-order features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outersibling for the other cases. Global Features We used feature shown promising in prior reranking work Charniak and Johnson (2005), Collins (2000) and Huang (2008). • Right Branch This feature enables the model to prefer right or left-branching trees. It counts the number of words on the path from the root node to the right-most non-p</context>
<context position="26255" citStr="Martins et al. (2013)" startWordPosition="4501" endWordPosition="4504">0 tokens. For efficiency, we limit the sentence length to 70 tokens in training and development sets. However, we do not impose this constraint during testing. We handle long sentences during testing by applying a simple split-merge strategy. We split the sentence based on the ending punctuation, predict the parse tree for each segment and group the roots of resulting trees into a single node. Evaluation Measures Following standard practice, we use Unlabeled Attachment Score (UAS) as the evaluation metric in all our experiments. We report UAS excluding punctuation on CoNLL datasets, following Martins et al. (2013). For the CATiB dataset, we report UAS including punctuation in order to be consistent with the published results in the 2013 SPMRL shared task (Seddah et al., 2013). Baselines We compare our model with the Turbo parser and the MST parser. For the Turbo parser, we directly compare with the recent published results in (Martins et al., 2013). For the MST parser, we train a second-order non-projective model using the most recent version of the code3. We also compare our model against a discriminative reranker. The reranker operates over the 3http://sourceforge.net/projects/mstparser/ top-50 list </context>
<context position="30354" citStr="Martins et al. (2013)" startWordPosition="5184" endWordPosition="5187">panese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our model is shown in the seco</context>
<context position="32922" citStr="Martins et al., 2013" startWordPosition="5628" endWordPosition="5631">the accuracy of 88.46% on the gold tags. This is a substantial increase from the parser that uses predicted tags (86.95%). To put these numbers into perspective, the bottom part of Table 3 shows the accuracy of the best systems from the 2013 SPMRL shared task on Arabic parsing using predicted information (Seddah et al., 2013). Our system not only outperforms the best single system (Bj¨orkelund et al., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al., 2013) Impact of Sampling Methods We compare two sampling methods introduced in Section 3.2 with respect to their decoding efficiency. Specifically, we measure the score of the retrieved trees in testing as a function of the decoding speed, measured by the number of tokens per second. We change the temperature update rate c in order to decode with different speed. In Figure 7 we show the corresponding curves for two languages: Arabic and Chinese. We select these two languages as they correspond to two extremes in sentence length: Arabic has the longest sentences on average, while Chinese has the sho</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>Andr´e FT Martins, Miguel B Almeida, and Noah A Smith. 2013. Turning on the turbo: Fast third-order non-projective turbo parsers. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Sarah Alkhulani</author>
</authors>
<title>Spmrl13 shared task system: The cadim arabic dependency parser.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>76--80</pages>
<contexts>
<context position="25295" citStr="Marton et al., 2013" startWordPosition="4347" endWordPosition="4350">2-gram hti−1, tii, hti−2, tii, hti−1, ti, wi−1i, hti−1, ti, wii 3-gram hti−1, ti, ti+1i, hti−2, ti, ti+1, i, hti−1, ti, ti+2i, hti−2, ti, ti+2i 4-gram hti−2, ti−1, ti, ti+1i, hti−2, ti−1, ti, ti+2i, hti−2, ti, ti+1, ti+2i 5-gram hti−2, ti−1, ti, ti+1, ti+2i Table 1: POS tag feature templates. ti and wi denotes the POS tag and the word at the current position. ti−x and ti+x denote the left and right context tags, and similarly for words. contain non-projective dependency trees. We use all sentences in CoNLL datasets during training and testing. We also use the Columbia Arabic Treebank (CATiB) (Marton et al., 2013). CATiB mostly includes projective trees. The trees are annotated with both gold and predicted versions of POS tags and morphology information. Following Marton et al. (2013), for this dataset we use 12 core POS tags, word lemmas, determiner features, rationality features and functional genders and numbers. Some CATiB sentences exceed 200 tokens. For efficiency, we limit the sentence length to 70 tokens in training and development sets. However, we do not impose this constraint during testing. We handle long sentences during testing by applying a simple split-merge strategy. We split the sente</context>
<context position="34465" citStr="Marton et al., 2013" startWordPosition="5890" endWordPosition="5893"> Acc. UAS Gold - 90.27 - 88.46 Predicted 96.87 88.81 96.82 86.95 POS Correction 97.72 90.08 97.49 88.38 CADIM 96.87 87.4- 96.82 85.78 IMS-Single - - - 86.96 IMS-Ensemble - - - 88.32 Table 3: Results for parsing and corrective tagging on the CATiB dataset. The upper part shows UAS of our model with gold/predicted information or POS correction. Bottom part shows UAS of the best systems in the SPMRL shared task. IMSSingle (Bj¨orkelund et al., 2013) is the best single parsing system, while IMS-Ensemble (Bj¨orkelund et al., 2013) is the best ensemble parsing system. We also show results for CADIM (Marton et al., 2013), the second best system, because we use their predicted features. 2.658x 104 Gibbs Random Walk 2.6480 20 40 60 80 100 Toks/sec (a) Arabic x 104 1.9 1.899 1.898 1.8970 100 200 300 400 500 600 700 800 Toks/sec (b) Chinese Figure 7: Total score of the predicted test trees as a function of the decoding speed, measured in the number of tokens per second. iteration of this sampler makes multiple changes to the tree, in contrast to a single-edge change of Gibbs sampler. The Effect of Constraints in Learning Our training method updates parameters to satisfy the pairwise constraints between (1) subseq</context>
</contexts>
<marker>Marton, Habash, Rambow, Alkhulani, 2013</marker>
<rawString>Yuval Marton, Nizar Habash, Owen Rambow, and Sarah Alkhulani. 2013. Spmrl13 shared task system: The cadim arabic dependency parser. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 76– 80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Fernando CN Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="9583" citStr="McDonald and Pereira, 2006" startWordPosition="1532" endWordPosition="1535"> to the jth word of sentence x, and hj to the head word of xj. A training set of size N is given as a set of pairs D = {(x(i), y(i))1Ni=1 where y(i) is the ground truth parse for sentence x(i). We parameterize the scoring function s(x, y) as s(x, y) = 0 · f(x, y) (1) where f(x, y) is the feature vector associated with tree y for sentence x. We do not make any assumptions about how the feature function decomposes. In contrast, most state-of-the-art parsers operate under the assumption that the feature function decomposes into a sum of simpler terms. For example, in the second-order MST parser (McDonald and Pereira, 2006), all the feature terms involve arcs or consecutive siblings. Similarly, parsers based on dual decomposition (Martins et al., 2011; Koo et al., 2010) assume that s(x, y) decomposes into a sum of terms where each term can be maximized over y efficiently. 3.2 Decoding The decoding problem consists of finding a valid dependency tree y E Y(x) that maximizes the score s(x, y) = 0 · f(x, y) with parameters 0. For scoring functions that extend beyond firstorder arc preferences, finding the maximizing nonprojective tree is known to be NP-hard (McDonald and Pereira, 2006). We find a high scoring tree t</context>
<context position="21126" citStr="McDonald and Pereira, 2006" startWordPosition="3640" endWordPosition="3643"> Gibbs sampler will generate a new sample from the space H x T . The other parts of the algorithm remain the same. 2In our work we choose α = 0.003, which gives a 98.9% oracle POS tagging accuracy on the CATiB development set. 201 consecutive sibling grandparent g h m eat with knife and fork arc h m h m s arbitrary sibling É h m s grand-sibling head bigram h&apos; h m m+1 grand-grandparent tri-siblings Figure 5: First- to third-order features. 4 Features First- to Third-Order Features The feature templates of first- to third-order features are mainly drawn from previous work on graphbased parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al., 2006) and dual decomposition-based parsing (Martins et al., 2011). As shown in Figure 5, the arc is the basic structure for first-order features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is </context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan T McDonald and Fernando CN Pereira. 2006. Online learning of approximate dependency parsing algorithms. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="6301" citStr="McDonald et al., 2005" startWordPosition="981" endWordPosition="984"> for handling global features than reranking, outperforming it by 1.3%. In terms of joint parsing and tagging on the CATiB dataset, we nearly bridge (88.38%) the gap between independently predicted (86.95%) and gold tags (88.45%). This is better than the best published results in the 2013 SPMRL shared task (Seddah et al., 2013), including parser ensembles. 2 Related Work Earlier works on dependency parsing focused on inference with tractable scoring functions. For instance, a scoring function that operates over each single dependency can be optimized using the maximum spanning tree algorithm (McDonald et al., 2005). It was soon realized that using higher order features could be beneficial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider t</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a twostage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>216--220</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30285" citStr="McDonald et al. (2006)" startWordPosition="5172" endWordPosition="5175"> (Ma13) 92.41 - German 91.79 92.07 92.41 90.14 92.41 (Ma13) 91.19 - Japanese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used b</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a twostage discriminative parser. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 216–220. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
</authors>
<title>Multilingual dependency parsing using global features.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>952--956</pages>
<contexts>
<context position="7033" citStr="Nakagawa (2007)" startWordPosition="1104" endWordPosition="1105">ference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is</context>
</contexts>
<marker>Nakagawa, 2007</marker>
<rawString>Tetsuji Nakagawa. 2007. Multilingual dependency parsing using global features. In EMNLP-CoNLL, pages 952–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨uls¸en Eryiit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudoprojective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>221--225</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="21173" citStr="Nivre et al., 2006" startWordPosition="3646" endWordPosition="3649">e H x T . The other parts of the algorithm remain the same. 2In our work we choose α = 0.003, which gives a 98.9% oracle POS tagging accuracy on the CATiB development set. 201 consecutive sibling grandparent g h m eat with knife and fork arc h m h m s arbitrary sibling É h m s grand-sibling head bigram h&apos; h m m+1 grand-grandparent tri-siblings Figure 5: First- to third-order features. 4 Features First- to Third-Order Features The feature templates of first- to third-order features are mainly drawn from previous work on graphbased parsing (McDonald and Pereira, 2006), transition-based parsing (Nivre et al., 2006) and dual decomposition-based parsing (Martins et al., 2011). As shown in Figure 5, the arc is the basic structure for first-order features. We also define features based on consecutive sibling, grandparent, arbitrary sibling, head bigram, grand-sibling and tri-siblings, which are also used in the Turbo parser (Martins et al., 2013). In addition to these first- to third-order structures, we also consider grand-grandparent and sibling-grandchild structures. There are two types of sibling-grandchild structures: (1) inner-sibling when the sibling is between the head and the modifier and (2) outer</context>
<context position="30261" citStr="Nivre et al. (2006)" startWordPosition="5168" endWordPosition="5171">.94 93.22 91.54 93.22 (Ma13) 92.41 - German 91.79 92.07 92.41 90.14 92.41 (Ma13) 91.19 - Japanese 93.23 93.42 93.52 92.92 93.72 (Ma11) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global feat</context>
</contexts>
<marker>Nivre, Hall, Nilsson, Eryiit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨uls¸en Eryiit, and Svetoslav Marinov. 2006. Labeled pseudoprojective dependency parsing with support vector machines. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 221–225. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
<author>Dav Zimak</author>
</authors>
<title>Semantic role labeling via integer linear programming inference.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1346</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="7578" citStr="Punyakanok et al., 2004" startWordPosition="1189" endWordPosition="1192">and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the targ</context>
</contexts>
<marker>Punyakanok, Roth, Yih, Zimak, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zimak. 2004. Semantic role labeling via integer linear programming inference. In Proceedings of the 20th international conference on Computational Linguistics, page 1346. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>Slav Petrov</author>
</authors>
<title>Vine pruning for efficient multi-pass dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>498--507</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1886" citStr="Rush and Petrov, 2012" startWordPosition="269" endWordPosition="272">s commonly cast as a maximization problem over a parameterized scoring function. In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse. Much of the recent work on parsing has been focused on improving methods for solving the combinatorial maximization inference problems. Indeed, state-of-the-art results have been ob1The source code for the work is available at http://groups.csail.mit.edu/rbg/code/ global/acl2014. tained by adapting powerful tools from optimization (Martins et al., 2013; Martins et al., 2011; Rush and Petrov, 2012). We depart from this view and instead focus on using highly expressive scoring functions with substantially simpler inference procedures. The key ingredient in our approach is how learning is coupled with inference. Our combination outperforms the state-of-the-art parsers and remains comparable even if we adopt their scoring functions. Rich scoring functions have been used for some time. They first appeared in the context of reranking (Collins, 2000), where a simple parser is used to generate a candidate list which is then reranked according to the scoring function. Because the number of alte</context>
<context position="6970" citStr="Rush and Petrov, 2012" startWordPosition="1092" endWordPosition="1095">eatures could be beneficial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al</context>
<context position="30397" citStr="Rush and Petrov (2012)" startWordPosition="5192" endWordPosition="5195">) 93.40 - Portuguese 91.82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our model is shown in the second column with an average of 89.23%. It out</context>
</contexts>
<marker>Rush, Petrov, 2012</marker>
<rawString>Alexander M Rush and Slav Petrov. 2012. Vine pruning for efficient multi-pass dependency parsing. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 498–507. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, et al.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>146--182</pages>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D Choi, Rich´ard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, et al. 2013. Overview of the spmrl 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 146–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sontag</author>
<author>A Globerson</author>
<author>T Jaakkola</author>
</authors>
<title>Introduction to dual decomposition for inference.</title>
<date>2011</date>
<booktitle>In Optimization for Machine Learning,</booktitle>
<pages>219--254</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7506" citStr="Sontag et al., 2011" startWordPosition="1177" endWordPosition="1180">that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters a</context>
</contexts>
<marker>Sontag, Globerson, Jaakkola, 2011</marker>
<rawString>D. Sontag, A. Globerson, and T. Jaakkola. 2011. Introduction to dual decomposition for inference. In Optimization for Machine Learning, pages 219–254. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The conll-2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>159--177</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The conll-2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 159–177. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume</booktitle>
<volume>1</volume>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="24050" citStr="Toutanova et al., 2003" startWordPosition="4129" endWordPosition="4132">o types of valency information: (1) the binned number of non-punctuation modifiers and (2) the concatenated POS string of all those modifiers. • Non-projective Arcs A flag indicating if a dependency is projective or not (i.e. if it spans a word that does not descend from its head) (Martins et al., 2011). This flag is also combined with the POS tags or the lexical words of the head and the modifier. POS Tag Features In the joint POS correction scenario, we also add additional features specifically for POS prediction. The feature templates are inspired by previous feature-rich POS tagging work (Toutanova et al., 2003). However, we are free to add higher order features because we do not rely on dynamic programming decoding. In our work we use feature templates up to 5-gram. Table 1 summarizes all POS tag feature templates. 5 Experimental Setup Datasets We evaluate our model on standard benchmark corpora — CoNLL 2006 and CoNLL 2008 (Buchholz and Marsi, 2006; Surdeanu et al., 2008) — which include dependency treebanks for 14 different languages. Most of these data sets outer-sibling-grandchild inner-sibling-grandchild g h m s g h m gg h m s t h m gc s h s m gc 202 1-gram htii, hti, wi−2i, hti, wi−1i, hti, wii</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1, pages 173–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael L Wick</author>
<author>Khashayar Rohanimanesh</author>
<author>Kedar Bellare</author>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Samplerank: Training factor graphs with atomic gradients.</title>
<date>2011</date>
<booktitle>In Lise Getoor and Tobias Scheffer, editors, Proceedings of the 28th International Conference on Machine Learning, ICML 2011,</booktitle>
<pages>777--784</pages>
<contexts>
<context position="4403" citStr="Wick et al., 2011" startWordPosition="676" endWordPosition="679">ting of the Association for Computational Linguistics, pages 197–207, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics score more efficiently than the former. Because the inference procedure is so simple, it is important that the parameters of the scoring function are chosen in a manner that facilitates how we climb the scoring function in small steps. One way to achieve this is to make sure that improvements in the scoring functions are correlated with improvements in the quality of the parse. This approach was suggested in the SampleRank framework (Wick et al., 2011) for training structured prediction models. This method was originally developed for a sequence labeling task with local features, and was shown to be more effective than state-of-the-art alternatives. Here we apply SampleRank to parsing, applying several modifications such as the proposal distributions mentioned earlier. The benefits of sampling-based learning go beyond stand-alone parsing. For instance, we can use the framework to correct preprocessing mistakes in features such as part-of-speech (POS) tags. In this case, we combine the scoring function for trees with a stand-alone tagging mo</context>
<context position="7965" citStr="Wick et al., 2011" startWordPosition="1251" endWordPosition="1254">ng these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the target structure along the search path. The method has been successfully used in sequence labeling and machine translation (Haddow et al., 2011). In this paper, we demonstrate how to adapt the method for parsing with rich scoring functions. 3 Sampling-Based Dependency Parsing with Global Features In this section, we introduce our novel samplingbased dependency parser which can incorporate</context>
<context position="17121" citStr="Wick et al., 2011" startWordPosition="2880" endWordPosition="2883">neral scoring functions. However, our sampling procedure generates a small number of structures along the search path. We enforce only constraints corresponding to those samples. The second type of constraints are enforced between successive samples along the search path. To illustrate the idea, consider a parse y that differs from y(i) in only one arc, and a parse y&apos; that differs from y(i) in ten arcs. We cannot necessarily assume that s(x, y) is greater than s(x, y&apos;) without additional encouragement. Thus, we can complement the constraints in Equation 4 with additional pairwise constraints (Wick et al., 2011): s(x(i), y) − s(x(i), y&apos;) &gt; Err(y&apos;) − Err(y) (5) where similarly to Equation 4, the difference in scores scales with the differences in errors with respect to the target y(i). We only enforce the above constraints for y, y&apos; that are consecutive samples in the course of the sampling process. These constraints serve to guide the sampling process derived from the scoring function towards the gold parse. We learn the parameters θ in an on-line fashion to satisfy the above constraints. This is done via the MIRA algorithm (Crammer and Singer, 2003). Specifically, if the current parameters are θt, a</context>
</contexts>
<marker>Wick, Rohanimanesh, Bellare, Culotta, McCallum, 2011</marker>
<rawString>Michael L. Wick, Khashayar Rohanimanesh, Kedar Bellare, Aron Culotta, and Andrew McCallum. 2011. Samplerank: Training factor graphs with atomic gradients. In Lise Getoor and Tobias Scheffer, editors, Proceedings of the 28th International Conference on Machine Learning, ICML 2011, pages 777–784.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bruce Wilson</author>
</authors>
<title>Generating random spanning trees more quickly than the cover time.</title>
<date>1996</date>
<booktitle>In Proceedings of the twenty-eighth annual ACM symposium on Theory of computing,</booktitle>
<pages>296--303</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3620" citStr="Wilson, 1996" startWordPosition="556" endWordPosition="557">e tree, our inference procedure climbs the scoring function in small (cheap) stochastic steps towards a high scoring parse. The proposal distribution over the moves is derived from the scoring function itself. Because the steps are small, the complexity of the scoring function has limited impact on the computational cost of the procedure. We explore two alternative proposal distributions. Our first strategy is akin to Gibbs sampling and samples a new head for each word in the sentence, modifying one arc at a time. The second strategy relies on a provably correct sampler for firstorder scores (Wilson, 1996), and uses it within a Metropolis-Hastings algorithm for general scoring functions. It turns out that the latter optimizes the 197 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 197–207, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics score more efficiently than the former. Because the inference procedure is so simple, it is important that the parameters of the scoring function are chosen in a manner that facilitates how we climb the scoring function in small steps. One way to achieve this is to make su</context>
<context position="13165" citStr="Wilson (1996)" startWordPosition="2166" endWordPosition="2167">y difficult with more heads, it is indeed tractable if 199 Inputs: x, yt, 0, K (number of heads to change). Outputs: y&apos; for i = 1 to JxJ do inTree[i] +— false ChangeNode[i] +— false Set ChangeNode to true for K random nodes. head[0] +— −1 for i = 1 to JxJ do u +— i while not inTree[u] do if ChangeNode[u] then head[u] +— randomHead(u, 0) else head[u] +— yt(u) u +— head[u] if LoopExist(head) then EraseLoop(head) u + —i while not inTree[u] do inTree[u] +— true u +— head[u] return Construct tree y&apos; from the head array. Figure 2: A proposal distribution q(y&apos;|yt) based on the random walk sampler of Wilson (1996). The function randomHead samples a new head for node u according to the first-order weights given by 0. the model corresponds to a first-order parser. One such sampling algorithm is the random walk sampler of Wilson (1996). It can be used to obtain i.i.d. samples from distributions of the form: p(y) °C � wij, (3) i→j∈y where y corresponds to a tree with a spcified root and wij is the exponential of the first-order score. y is always a valid parse tree if we allow multiple children of the root and do not impose projective constraint. The algorithm in Wilson (1996) iterates over all the nodes, </context>
</contexts>
<marker>Wilson, 1996</marker>
<rawString>David Bruce Wilson. 1996. Generating random spanning trees more quickly than the cover time. In Proceedings of the twenty-eighth annual ACM symposium on Theory of computing, pages 296–303. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Ryan McDonald</author>
</authors>
<title>Generalized higher-order dependency parsing with cube pruning.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>320--331</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6947" citStr="Zhang and McDonald, 2012" startWordPosition="1088" endWordPosition="1091"> that using higher order features could be beneficial, even at the cost of using approximate inference and sacrificing optimality. The first successful approach in this arena was reranking (Collins, 2000; Charniak and Johnson, 2005) on constituency parsing. Reranking can be combined with an arbitrary scoring function, and thus can easily incorporate global features over the entire parse tree. Its main disadvantage is that the output parse can only be one of the few parses passed to the reranker. Recent work has focused on more powerful inference mechanisms that consider the full search space (Zhang and McDonald, 2012; Rush and Petrov, 2012; Koo et al., 2010; Huang, 2008). For instance, Nakagawa (2007) deals with tractability issues by using sampling to approximate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP appro</context>
<context position="30424" citStr="Zhang and McDonald (2012)" startWordPosition="5196" endWordPosition="5199">82 92.41 92.69 91.08 93.03 (Ko10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our model is shown in the second column with an average of 89.23%. It outperforms the Turbo parser b</context>
</contexts>
<marker>Zhang, McDonald, 2012</marker>
<rawString>Hao Zhang and Ryan McDonald. 2012. Generalized higher-order dependency parsing with cube pruning. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 320–331. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2,</booktitle>
<pages>188--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7716" citStr="Zhang and Nivre, 2011" startWordPosition="1211" endWordPosition="1214">ate marginals. Another example is the dual decomposition (DD) framework (Koo et al., 2010; Martins et al., 2011). The idea in DD is to decompose the hard maximization problem into smaller parts that can be efficiently maximized and enforce agreement among these via Lagrange multipliers. The method is essentially equivalent to linear programming relaxation approaches (Martins et al., 2009; Sontag et al., 2011), and also similar in spirit to ILP approaches (Punyakanok et al., 2004). A natural approach to approximate global inference is via search. For instance, a transitionbased parsing system (Zhang and Nivre, 2011) incrementally constructs a parsing structure using greedy beam-search. Other approaches operate over full trees and generate a sequence of candidates that successively increase the score (Daum´e III et al., 2009; Li et al., 2013; Wick et al., 2011). Our work builds on one such approach — SampleRank (Wick et al., 2011), a sampling-based learning algorithm. In SampleRank, the parameters are adjusted so as to guide the sequence of candidates closer to the target structure along the search path. The method has been successfully used in sequence labeling and machine translation (Haddow et al., 201</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 188–193. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang Kai Zhao</author>
<author>Ryan McDonald</author>
</authors>
<title>Online learning for inexact hypergraph search.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="30448" citStr="Zhang et al. (2013)" startWordPosition="5201" endWordPosition="5204">10) 91.47 - Slovene 86.19 86.82 86.01 83.25 86.95 (Ma11) 84.81 85.37 Spanish 88.24 88.21 85.59 84.33 87.96 (Zh13) 86.85 87.21 Swedish 90.48 90.71 91.14 89.05 91.62 (Zh13) 90.53 - Turkish 76.82 77.21 76.90 74.39 77.55 (Ko10) 76.35 76.23 Average 88.87 89.23 88.72 86.86 89.33 87.92 - Table 2: Results of our model, the Turbo parser, and the MST parser. “Best Published UAS” includes the most accurate parsers among Nivre et al. (2006), McDonald et al. (2006), Martins et al. (2010), Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Rush and Petrov (2012), Zhang and McDonald (2012) and Zhang et al. (2013). Martins et al. (2013) is the current Turbo parser. The last two columns shows UAS of the discriminative reranker. shows the result for our model with an average of 88.87%, and the third column shows the results for the Turbo parser with an average of 88.72%. This suggests that our learning and inference procedures are as effective as the dual decomposition method in the Turbo parser. Next, we add global features that are not used by the Turbo parser. The performance of our model is shown in the second column with an average of 89.23%. It outperforms the Turbo parser by 0.5% and achieves the </context>
</contexts>
<marker>Zhang, Zhao, McDonald, 2013</marker>
<rawString>Hao Zhang, Liang Huang Kai Zhao, and Ryan McDonald. 2013. Online learning for inexact hypergraph search. In Proceedings of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>