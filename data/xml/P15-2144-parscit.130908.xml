<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000499">
<title confidence="0.98214">
On the Importance of Ezafe Construction in Persian Parsing
</title>
<author confidence="0.997436">
Alireza Nourian*, Mohammad Sadegh RasooliQ, Mohsen Imany*, and Heshaam Faili&apos;
</author>
<affiliation confidence="0.999404">
*Department of Computer Engineering, Iran University of Science and Technlogy, Tehran, Iran
</affiliation>
<email confidence="0.567289">
{nourian,m imany}@comp.iust.ac.ir
</email>
<affiliation confidence="0.994282">
QDepartment of Computer Science, Columbia University, New York, NY, USA
</affiliation>
<email confidence="0.847425">
rasooli@cs.columbia.edu
</email>
<affiliation confidence="0.868056">
&apos;School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran
</affiliation>
<email confidence="0.988564">
hfaili@ut.ac.ir
</email>
<sectionHeader confidence="0.995379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99982075">
Ezafe construction is an idiosyncratic phe-
nomenon in the Persian language. It is a
good indicator for phrase boundaries and
dependency relations but mostly does not
appear in the text. In this paper, we show
that adding information about Ezafe con-
struction can give 4.6% relative improve-
ment in dependency parsing and 9% rela-
tive improvement in shallow parsing. For
evaluation purposes, Ezafe tags are man-
ually annotated in the Persian dependency
treebank. Furthermore, to be able to con-
duct experiments on shallow parsing, we
develop a dependency to shallow phrase
structure convertor based on the Persian
dependencies.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.972122555555556">
There have been many studies on improving syn-
tactic parsing methods for natural languages. Al-
though most of the parsing methods are language-
independent, we may still require some language
specific knowledge for improving performance.
Besides many studies on parsing morphologically
rich languages (Seddah et al., 2013; Seeker and
Kuhn, 2013), syntactic parsing for the Persian lan-
guage is not yet noticeably explored. Concretely
speaking, there are some recent work on depen-
dency parsing for Persian (Seraji et al., 2012;
Ghayoomi, 2012; Khallash et al., 2013) and very
few studies on shallow parsing (Kian et al., 2009).
The main focus of this paper is on the usefulness
of Ezafe construction in Persian syntactic process-
ing. Ezafe is an unstressed vowel -e that occurs at
the end of some words (-ye in some specific occa-
sions) that links together elements belonging to a
single constituent (Ghomeshi, 1997). It often ap-
proximately corresponds in usage to the English
preposition “of” (Abrahams, 2004). In the follow-
ing example, the first word has an Ezafe vowel:
fmontazere Ab
waiting for water
This is an idiosyncratic construction that ap-
pears in the Persian language with Perso-Arabic
script. This construction is similar to Idafa con-
struction in Arabic and construct state in Hebrew
(Habash, 2010). It is mostly used for showing a
possessive marker, adjective of a noun or connect-
ing parts of a name (i.e. first and last name) or ti-
tle. As a general statement, Ezafe occurs between
any two items that have some sort of connection
(Ghomeshi, 1997). Ezafe vowel is attached to
the head noun and to the modifiers that follow
it: attributive nouns, adjectival and prepositional
phrases (Samvelian, 2006). As depicted in Figure
1, this construction is very useful for disambiguat-
ing syntactic structures. The main issue here is
that Ezafe rarely appears in the written text. This
relies on the fact that Persian is written in Perso-
Arabic script and vowels are mostly not written.
There are few studies (Noferesti and Shamsfard,
2014; Asghari et al., 2014) on automatically find-
ing Ezafe construction. In this work, we modify
the part of speech tagset for the Persian words.
This is done by adding an indicator of Ezafe to
each part of speech (POS) tag and then train a su-
pervised tagger on the modified tags. We show
that having this modified tagset can both improve
dependency parsing and shallow parsing (chunk-
ing). We achieve 12.8% and 4.6% relative error re-
duction in dependency parsing with gold and auto-
waitingEzafe water
</bodyText>
<page confidence="0.758111">
877
</page>
<note confidence="0.253582333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 877–882,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figure confidence="0.998315105263158">
root
mos
npostmod
punc
sbj
posdep
root
sbj
punc
mos
posdep
npostmod
[.] [ ~Iƒ@][èAJ�ƒ �Q���Ó] [ø� ðP] [H. A�J»] root
. is black table+Ezafe on+Ezafe book
(a) First reading: The book is on the black table.
[.] [ ~Iƒ@] [èAJ�ƒ][;-- ø~ ðP H.A�J»] root
�
.is black table on+Ezafe book+Ezafe
(b) Second reading: The book on the table is black.
</figure>
<figureCaption confidence="0.991885">
Figure 1: This figure shows two different readings for the same sentence with different Ezafe construc-
tions. As shown in the trees, Ezafe affects both phrase boundaries and dependency relations.
</figureCaption>
<bodyText confidence="0.9679">
matic POS tags. We also achieve 31% and 9% rel-
ative error reduction in shallow parsing with gold
and automatic POS tags.
Our work is not only restricted to the effect of
Ezafe in parsing, but as a byproduct, we create an
open-source rule-based dependency to chunk con-
verter for the Persian language. We have also man-
ually tagged all words in the Persian dependency
treebank (Rasooli et al., 2013) with 99.6% anno-
tator agreement. This dataset is available for re-
search purposes.1
The main contributions of this paper are: 1)
showing the usefulness of Ezafe construction on
dependency parsing and chunking, 2) developing
a statistical chunker for the Persian language, 3)
enriching the Persian treebank with manual Ezafe
tags. The remainder of this paper is organized as
the following: we describe our approach and data
preparation in §2 and then conduct experiments in
§3. Error analysis and conclusion are made in §4
and §5.
</bodyText>
<sectionHeader confidence="0.960967" genericHeader="method">
2 Data Preparation
</sectionHeader>
<bodyText confidence="0.999978428571429">
We define a simple procedure to include the in-
formation about Ezafe construction in our data.
Concretely, we attach the Ezafe indicator to the
tags and train a POS tagger on the new tagset.
This idea is very similar to that of (Asghari et al.,
2014). Thanks to the presence of Ezafe feature in
the Peykare corpus (Bijankhan et al., 2011), we
can easily train a POS tagger on the new tagset.
We use the developed tagger to tag the dependency
treebank. Peykare corpus has approximately ten
million tokens and can give us a very accurate POS
tagger even with the finer-grained Ezafe tags. We
try this idea on two different tasks: dependency
parsing and shallow parsing.
</bodyText>
<footnote confidence="0.960044">
1http://dadegan.ir/catalog/ezafe
</footnote>
<subsectionHeader confidence="0.999177">
2.1 Chunking Data Preparation
</subsectionHeader>
<bodyText confidence="0.9971733125">
Unfortunately there is no standard chunking data
for the Persian language. To compensate for this,
we define the following rules to convert a depen-
dency tree (based on Dadegan treebank dependen-
cies (Rasooli et al., 2013)) to a shallow phrase
structure:
- We initialize every node (word) as a separate
chunk; e.g. verb creates a VP.
- If a node has a head or dependent belonging
to a chunk (without any gap), attach that node
to the same chunk.
- If a node is a preposition/postposition, attach
it to its next/previous dependent and create a
PP.
- A node with a dependency relation “non-
verbal element”, “verb particle”, or “enclitic
non-verbal element” belongs to the same VP
as its head.
- If a node is a particle, subordinating clause,
coordinating conjunction, or punctuation, we
should not create an independent chunk for
it.
- If a node is a “noun post modifier” or “Ezafe
dependent”, attach it to its parent chunk.
- If a node is a “conjunction of a noun” or
“conjunction of an adjective” and has a sib-
ling with either “Ezafe dependent” or “noun
post-modifier” dependency relation, it should
have the same chunk as its parent.
- If a node with pseudo-sentence POS has an
adverbial dependency with its parent, it cre-
ates an ADVP and otherwise a VP.
</bodyText>
<page confidence="0.98954">
878
</page>
<bodyText confidence="0.99996775">
Implementation of the above rules is available
in the Hazm toolkit.2 There are some minor excep-
tions in the above rules that are handled manually
in the toolkit.
</bodyText>
<sectionHeader confidence="0.999414" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999894666666667">
In this section we describe our experiments on
Ezafe tagging, parsing and also adding manual
Ezafe tags to the Persian dependency treebank.
</bodyText>
<subsectionHeader confidence="0.997899">
3.1 Automatic Ezafe Tagging
</subsectionHeader>
<bodyText confidence="0.999988571428572">
As mentioned in §2, we attach Ezafe feature in-
dicator to the tags and train a POS tagger on the
new tagset. We use Wapiti tagger (Lavergne et al.,
2010) to train a standard trigram CRF sequence
tagger model with standard transition features and
the following emission features: word form of the
current, previous and next word, combination of
the current word and next word, combination of
the current word and previous word, prefixes and
suffixes up to length 3, indicator of punctuation
and number (digit) for the current, previous and
next word. The tagger has an accuracy of 98.71%
with the original tagset and 97.33% with the mod-
ified tagset.
</bodyText>
<subsectionHeader confidence="0.998933">
3.2 Gold Standard Ezafe Tags
</subsectionHeader>
<bodyText confidence="0.999884666666667">
The Persian dependency treebank does not provide
gold Ezafe tags. In order to evaluate the effect of
gold Ezafe tags, we try to manually annotate Ezafe
in the treebank. This is done by six annotators
where all of them are native speakers and linguists.
The inter-annotator agreement of a small portion
of the data (one thousand sentences) is 99.6%. Our
manual investigation shows that almost half of the
disagreements was because of the mistakes and
not because of the complicated structure. Table
1 shows the statistics about the presence of Ezafe
tag for each specific POS.
</bodyText>
<subsectionHeader confidence="0.997914">
3.3 Chunking
</subsectionHeader>
<bodyText confidence="0.999913555555555">
We use Wapiti tagger (Lavergne et al., 2010) to
train a standard CRF tagger with IOB tags for
phrase chunking. The features include third or-
der transition features and emission features of
word form and POS for the current word, previ-
ous word and the word before it, the next word and
the word after it. As shown in Table 2 and 3, our
intuition holds for both gold and automatic tags.
We observe that using Ezafe on gold tags, gives
</bodyText>
<footnote confidence="0.950715">
2https://github.com/sobhe/hazm
</footnote>
<table confidence="0.998726125">
Tag Freq. Relative Freq. Ezafe %
N 190048 39.24% 34.22%
PREP 56376 11.64% 12.04%
ADJ 35902 7.41% 17.45%
PRENUM 6018 1.24% 1.21%
IDEN 835 0.17% 5.03%
POSNUM 560 0.12% 30.71%
other 194572 40.18% 00.10%
</table>
<tableCaption confidence="0.924583">
Table 1: Statistics about Ezafe for each POS tag in
the Persian dependency treebank.
</tableCaption>
<bodyText confidence="0.996892285714286">
us better performance compared to using coarse-
grained POS tags and also fine-grained POS tags
(FPOS) provided by the dependency treebank an-
notators. The tagset in Peykare corpus is very dif-
ferent from the treebank. Because of this incon-
sistency, we could not reproduce the results with
automatic FPOS tags trained on Peykare corpus.
Our experiments on training solely on the tree-
bank FPOS tags do not give us a reliable FPOS
tagger and this leads to very low parsing accuracy.
Therefore we do not conduct experiments with au-
tomatic FPOS tags. Table 3 shows the results with
automatic tags. As shown in the table, using the
the Ezafe tagset improves the chunking accuracy.
</bodyText>
<table confidence="0.999128">
Tagset Precision Recall F-Measure
POS 91.98% 90.37% 91.17%
FPOS 92.37% 90.92% 91.64%
POSe 93.88% 93.97% 93.92%
</table>
<tableCaption confidence="0.855506">
Table 2: Chunking results on the Persian de-
pendency treebank test data with gold POS tags.
FPOS refers to the fine-grained POS tags in the
Persian dependency treebank and POSe is the
modified Ezafe-enriched tagset.
</tableCaption>
<table confidence="0.999573666666667">
Tagset Tag Acc. Precision Recall F-Measure
POS 98.71% 89.44% 88.02% 88.72%
POSe 97.33% 90.42% 89.13% 89.77%
</table>
<tableCaption confidence="0.98926">
Table 3: Chunking results on the Persian depen-
dency treebank test data with automatic POS tags.
</tableCaption>
<subsectionHeader confidence="0.953423">
3.4 Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.995572333333333">
Similar to the chunking experiments, we provide
two sets of experiments to validate our hypothesis
about the importance of Ezafe construction. We
</bodyText>
<page confidence="0.997361">
879
</page>
<table confidence="0.9997248">
Tagset MaltParser YaraParser TurboParser
LAS UAS LAS UAS LAS UAS
POS 88.13% 90.69% 88.60% 91.17% 89.88% 92.25%
FPOS 88.46% 91.01% 89.02% 91.56% 89.98% 92.30%
POSe 89.12% 91.64% 89.91% 92.42% 90.85% 93.24%
</table>
<tableCaption confidence="0.9817655">
Table 4: Dependency Parsing results on the test data with different gold standard tagsets. UAS is the
unlabeled attachment score and LAS is the labeled attachment score.
</tableCaption>
<table confidence="0.99962725">
Tagset Tag acc. MaltParser YaraParser TurboParser
LAS UAS LAS UAS LAS UAS
POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59%
POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02%
</table>
<tableCaption confidence="0.999136">
Table 5: Dependency Parsing results on the test data with different automatic tagsets.
</tableCaption>
<bodyText confidence="0.999953866666667">
use three different off-the-shelf parsers: 1) Malt
parser v1.8 (Nivre et al., 2007), 2) Yara parser
v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo
parser v2.2 (Martins et al., 2013). We train Malt
with Covington non-projective algorithm (Cov-
ington, 1990) after optimizing it with Malt opti-
mizer (Ballesteros and Nivre, 2012), Yara with the
default settings (64 beam) and 10 training epochs
and Turbo with its default settings. The main rea-
son for picking these three parsers is that we want
to see the effect of Ezafe construction on a greedy
parser (Malt), beam parser (Yara), and a graph-
based parser (Turbo). As shown in Table 4 and
5, the parsing accuracy is improved across all dif-
ferent parsers by using the Ezafe tagset.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="method">
4 Error Analysis
</sectionHeader>
<bodyText confidence="0.996505">
In this section we provide some error analysis for
showing the effectiveness of our approach.
Effect on the common POS tags Our investiga-
tion on the development data shows that the depen-
dency attachment accuracy is improved by 6.5%
for adjectives and 6.2% for nouns. This is consis-
tent with our intuition because Ezafe construction
mostly occurs in nouns and adjectives. It is worth
noting that for some tags such as determiners the
Ezafe construction does not help.
Ezafe indicator as a feature We try to use
Ezafe as an independent feature in Malt parser.
This is done by adding the indicator in the fea-
ture column in CoNLL dependency format. We
then use Malt optimizer (Ballesteros and Nivre,
2012) to find the optimized feature setting. We see
that adding this feature gives us the same accuracy
improvement as having the modified tagset. This
shows that we do not really need to have a parser
that uses extra features to add Ezafe information.
Manual data investigation We randomly
picked some sentences from the development data
and observed the same effect as we could expect
from adding Ezafe to the tagset: the main gain is
on those sentences where the presence/absence of
Ezafe construction is crucial for making correct
decisions by the parser. For example, in the
following sub-sentence, the word &amp;t�g~ means
“China” but the dependency parser without
knowing Ezafe tag, confused it with the other
meaning: “ruffle” and created a “non-verbal
element” (light verb) dependency with the verb,
instead of making it an Ezafe dependent to the
previous word (Ég@ñƒ).
</bodyText>
<equation confidence="0.38049875">
vcl
... XP@X á~
g~ Ég@ñƒ P@ ¨A�¯X ... ...
�
</equation>
<bodyText confidence="0.921808222222222">
has China beaches+Ezafe from denfense
Effect on the training data size For investigat-
ing the benefit of Ezafe construction, we train Malt
parser on different data sizes starting from 50% of
the original size. This trend is depicted in Figure 2.
The interesting fact is that we can leverage Ezafe
construction and use only 70% of the training data
while reaching the accuracy of the original part of
speech tagset trained on the whole data.
</bodyText>
<figure confidence="0.934256266666667">
nve
moz
posdep
npp
posdep
880
50% 60% 70% 80% 90% 100%
Parsing LAS
89%
88%
87%
86%
POS
POSe
Training Data precentage
</figure>
<figureCaption confidence="0.99088375">
Figure 2: Trend on the data size and accuracy. As
shown by the horizontal dashed line, Ezafe tags
can improve over standard tags while having ap-
proximately 70% of the data.
</figureCaption>
<sectionHeader confidence="0.99803" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9985062">
In this paper we showed the effectiveness of Ezafe
construction as a robust feature for syntactic pars-
ing in Persian. One interesting direction for fur-
ther research would be to show the effect of this
feature in other natural language processing tasks.
</bodyText>
<sectionHeader confidence="0.965663" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999927777777778">
We thank Computer Research Center of Is-
lamic Sciences (CRCIS) for supporting us on
corpus annotation. We thank Parinaz Dadras,
Saeedeh Ghadrdoost-Nakhchi, Manouchehr
Kouhestani, Mostafa Mahdavi, Azadeh Mirzaei,
Neda Poormorteza-Khameneh, Morteza Rezaei-
Sharifabadi and Salimeh Zamani for helping us
on annotation and the three anonymous reviewers
for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998602" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999716453125">
Simin Abrahams. 2004. Modern Persian: a course-
book. Routledge.
Habibollah Asghari, Jalal Maleki, and Heshaam Faili.
2014. A probabilistic approach to persian ezafe
recognition. In Proceedings of the 14th Conference
of the European Chapter of the Association for Com-
putational Linguistics, pages 138–142, Gothenburg,
Sweden, April. Association for Computational Lin-
guistics.
Miguel Ballesteros and Joakim Nivre. 2012. Mal-
toptimizer: A system for maltparser optimization.
In Proceedings of the Eighth International Confer-
ence on Language Resources and Evaluation, pages
2757–2763, Istanbul, Turkey, May. European Lan-
guage Resources Association (ELRA).
Mahmood Bijankhan, Javad Sheykhzadegan, Moham-
mad Bahrani, and Masood Ghayoomi. 2011.
Lessons from building a Persian written corpus:
Peykare. Language Resources and Evaluation,
45:143–164.
Michael A Covington. 1990. Parsing discontinu-
ous constituents in dependency grammar. Compu-
tational Linguistics, 16(4):234–236.
Masood Ghayoomi. 2012. Word clustering for Per-
sian statistical parsing. In Advances in Natural Lan-
guage Processing, pages 126–137. Springer.
Jila Ghomeshi. 1997. Non-projecting nouns and the
ezafe: Construction in Persian. Natural Language
&amp; Linguistic Theory, 15(4):729–788.
Nizar Y Habash. 2010. Introduction to Arabic natural
language processing. Synthesis Lectures on Human
Language Technologies, 3(1):1–187.
Mojtaba Khallash, Ali Hadian, and Behrouz Minaei-
Bidgoli. 2013. An empirical study on the effect of
morphological and lexical features in Persian depen-
dency parsing. In Proceedings of the Fourth Work-
shop on Statistical Parsing of Morphologically-
Rich Languages, pages 97–107, Seattle, Washing-
ton, USA, October. Association for Computational
Linguistics.
Soheila Kian, Tara Akhavan, and Mehrnoush Shams-
fard. 2009. Developing a Persian chunker using a
hybrid approach. In International Multiconference
on Computer Science and Information Technology,
2009. IMCSIT’09, pages 227–234. IEEE.
Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504–513.
Association for Computational Linguistics, July.
Andr´e F. T. Martins, Miguel Almeida, and Noah A.
Smith. 2013. Turning on the turbo: Fast third-order
non-projective turbo parsers. pages 617–622.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav
Marinov, and Erwin Marsi. 2007. Maltparser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(02):95–135.
Samira Noferesti and Mehrnoush Shamsfard. 2014.
A hybrid algorithm for recognizing the position of
ezafe constructions in Persian texts. International
Journal of Interactive Multimedia and Artificial In-
telligence, 2(6):17–25.
</reference>
<page confidence="0.980003">
881
</page>
<reference confidence="0.995538823529412">
Mohammad Sadegh Rasooli and Joel Tetreault. 2015.
Yara parser: A fast and accurate dependency parser.
arXiv preprint arXiv:1503.06733.
Mohammad Sadegh Rasooli, Manouchehr Kouhestani,
and Amirsaeid Moloodi. 2013. Development of
a Persian syntactic dependency treebank. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
306–314.
Pollet Samvelian. 2006. When morphology does bet-
ter than syntax: the Ezafe construction in Persian.
Ms., Universit´e de Paris, (1997):1–54.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie
Candito, Jinho D. Choi, Richard Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola, Yoav
Goldberg, Spence Green, Nizar Habash, Marco
Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam
Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yan-
nick Versley, Veronika Vincze, Marcin Wolinski,
Alina Wroblewska, and Eric Villemonte de la Clerg-
erie. 2013. Overview of the SPMRL 2013 shared
task : Cross-framework evaluation of parsing mor-
phologically rich languages. Proceedings of the
Fourth Workshop on Statistical Parsing of Morpho-
logically Rich Languages, (October):146–182.
Wolfgang Seeker and Jonas Kuhn. 2013. Morphologi-
cal and syntactic case in statistical dependency pars-
ing. Computational Linguistics, 39(1):23–55.
Mojgan Seraji, Be´ata Megyesi, and Joakim Nivre.
2012. Dependency parsers for Persian. In Pro-
ceedings of the 10th Workshop on Asian Language
Resources, pages 35–44, Mumbai, India, December.
The COLING 2012 Organizing Committee.
</reference>
<page confidence="0.997968">
882
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.520583">
<title confidence="0.999944">On the Importance of Ezafe Construction in Persian Parsing</title>
<author confidence="0.89876">Mohammad Sadegh Mohsen</author>
<author confidence="0.89876">Heshaam</author>
<affiliation confidence="0.838401666666667">of Computer Engineering, Iran University of Science and Technlogy, Tehran, of Computer Science, Columbia University, New York, NY, &apos;School of Electrical and Computer Engineering, University of Tehran, Tehran,</affiliation>
<email confidence="0.987538">hfaili@ut.ac.ir</email>
<abstract confidence="0.990826176470588">Ezafe construction is an idiosyncratic phenomenon in the Persian language. It is a good indicator for phrase boundaries and dependency relations but mostly does not appear in the text. In this paper, we show that adding information about Ezafe construction can give 4.6% relative improvement in dependency parsing and 9% relative improvement in shallow parsing. For evaluation purposes, Ezafe tags are manually annotated in the Persian dependency treebank. Furthermore, to be able to conduct experiments on shallow parsing, we develop a dependency to shallow phrase structure convertor based on the Persian dependencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Simin Abrahams</author>
</authors>
<title>Modern Persian: a coursebook.</title>
<date>2004</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="2105" citStr="Abrahams, 2004" startWordPosition="315" endWordPosition="316">s not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction that appears in the Persian language with Perso-Arabic script. This construction is similar to Idafa construction in Arabic and construct state in Hebrew (Habash, 2010). It is mostly used for showing a possessive marker, adjective of a noun or connecting parts of a name (i.e. first and last name) or title. As a general statement, Ezafe occurs between any two items that have some sort of connection (Ghomeshi, 1997). Ezafe vowel is attached to the head noun and to </context>
</contexts>
<marker>Abrahams, 2004</marker>
<rawString>Simin Abrahams. 2004. Modern Persian: a coursebook. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Habibollah Asghari</author>
<author>Jalal Maleki</author>
<author>Heshaam Faili</author>
</authors>
<title>A probabilistic approach to persian ezafe recognition.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>138--142</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="3159" citStr="Asghari et al., 2014" startWordPosition="490" endWordPosition="493"> title. As a general statement, Ezafe occurs between any two items that have some sort of connection (Ghomeshi, 1997). Ezafe vowel is attached to the head noun and to the modifiers that follow it: attributive nouns, adjectival and prepositional phrases (Samvelian, 2006). As depicted in Figure 1, this construction is very useful for disambiguating syntactic structures. The main issue here is that Ezafe rarely appears in the written text. This relies on the fact that Persian is written in PersoArabic script and vowels are mostly not written. There are few studies (Noferesti and Shamsfard, 2014; Asghari et al., 2014) on automatically finding Ezafe construction. In this work, we modify the part of speech tagset for the Persian words. This is done by adding an indicator of Ezafe to each part of speech (POS) tag and then train a supervised tagger on the modified tags. We show that having this modified tagset can both improve dependency parsing and shallow parsing (chunking). We achieve 12.8% and 4.6% relative error reduction in dependency parsing with gold and autowaitingEzafe water 877 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Con</context>
<context position="5638" citStr="Asghari et al., 2014" startWordPosition="904" endWordPosition="907">dependency parsing and chunking, 2) developing a statistical chunker for the Persian language, 3) enriching the Persian treebank with manual Ezafe tags. The remainder of this paper is organized as the following: we describe our approach and data preparation in §2 and then conduct experiments in §3. Error analysis and conclusion are made in §4 and §5. 2 Data Preparation We define a simple procedure to include the information about Ezafe construction in our data. Concretely, we attach the Ezafe indicator to the tags and train a POS tagger on the new tagset. This idea is very similar to that of (Asghari et al., 2014). Thanks to the presence of Ezafe feature in the Peykare corpus (Bijankhan et al., 2011), we can easily train a POS tagger on the new tagset. We use the developed tagger to tag the dependency treebank. Peykare corpus has approximately ten million tokens and can give us a very accurate POS tagger even with the finer-grained Ezafe tags. We try this idea on two different tasks: dependency parsing and shallow parsing. 1http://dadegan.ir/catalog/ezafe 2.1 Chunking Data Preparation Unfortunately there is no standard chunking data for the Persian language. To compensate for this, we define the follow</context>
</contexts>
<marker>Asghari, Maleki, Faili, 2014</marker>
<rawString>Habibollah Asghari, Jalal Maleki, and Heshaam Faili. 2014. A probabilistic approach to persian ezafe recognition. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 138–142, Gothenburg, Sweden, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Joakim Nivre</author>
</authors>
<title>Maltoptimizer: A system for maltparser optimization.</title>
<date>2012</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation,</booktitle>
<pages>2757--2763</pages>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="12093" citStr="Ballesteros and Nivre, 2012" startWordPosition="1977" endWordPosition="1980">d attachment score. Tagset Tag acc. MaltParser YaraParser TurboParser LAS UAS LAS UAS LAS UAS POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59% POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02% Table 5: Dependency Parsing results on the test data with different automatic tagsets. use three different off-the-shelf parsers: 1) Malt parser v1.8 (Nivre et al., 2007), 2) Yara parser v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo parser v2.2 (Martins et al., 2013). We train Malt with Covington non-projective algorithm (Covington, 1990) after optimizing it with Malt optimizer (Ballesteros and Nivre, 2012), Yara with the default settings (64 beam) and 10 training epochs and Turbo with its default settings. The main reason for picking these three parsers is that we want to see the effect of Ezafe construction on a greedy parser (Malt), beam parser (Yara), and a graphbased parser (Turbo). As shown in Table 4 and 5, the parsing accuracy is improved across all different parsers by using the Ezafe tagset. 4 Error Analysis In this section we provide some error analysis for showing the effectiveness of our approach. Effect on the common POS tags Our investigation on the development data shows that the</context>
</contexts>
<marker>Ballesteros, Nivre, 2012</marker>
<rawString>Miguel Ballesteros and Joakim Nivre. 2012. Maltoptimizer: A system for maltparser optimization. In Proceedings of the Eighth International Conference on Language Resources and Evaluation, pages 2757–2763, Istanbul, Turkey, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahmood Bijankhan</author>
<author>Javad Sheykhzadegan</author>
<author>Mohammad Bahrani</author>
<author>Masood Ghayoomi</author>
</authors>
<title>Lessons from building a Persian written corpus: Peykare. Language Resources and Evaluation,</title>
<date>2011</date>
<pages>45--143</pages>
<contexts>
<context position="5726" citStr="Bijankhan et al., 2011" startWordPosition="919" endWordPosition="922">anguage, 3) enriching the Persian treebank with manual Ezafe tags. The remainder of this paper is organized as the following: we describe our approach and data preparation in §2 and then conduct experiments in §3. Error analysis and conclusion are made in §4 and §5. 2 Data Preparation We define a simple procedure to include the information about Ezafe construction in our data. Concretely, we attach the Ezafe indicator to the tags and train a POS tagger on the new tagset. This idea is very similar to that of (Asghari et al., 2014). Thanks to the presence of Ezafe feature in the Peykare corpus (Bijankhan et al., 2011), we can easily train a POS tagger on the new tagset. We use the developed tagger to tag the dependency treebank. Peykare corpus has approximately ten million tokens and can give us a very accurate POS tagger even with the finer-grained Ezafe tags. We try this idea on two different tasks: dependency parsing and shallow parsing. 1http://dadegan.ir/catalog/ezafe 2.1 Chunking Data Preparation Unfortunately there is no standard chunking data for the Persian language. To compensate for this, we define the following rules to convert a dependency tree (based on Dadegan treebank dependencies (Rasooli </context>
</contexts>
<marker>Bijankhan, Sheykhzadegan, Bahrani, Ghayoomi, 2011</marker>
<rawString>Mahmood Bijankhan, Javad Sheykhzadegan, Mohammad Bahrani, and Masood Ghayoomi. 2011. Lessons from building a Persian written corpus: Peykare. Language Resources and Evaluation, 45:143–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>Parsing discontinuous constituents in dependency grammar.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="12023" citStr="Covington, 1990" startWordPosition="1967" endWordPosition="1969">AS is the unlabeled attachment score and LAS is the labeled attachment score. Tagset Tag acc. MaltParser YaraParser TurboParser LAS UAS LAS UAS LAS UAS POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59% POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02% Table 5: Dependency Parsing results on the test data with different automatic tagsets. use three different off-the-shelf parsers: 1) Malt parser v1.8 (Nivre et al., 2007), 2) Yara parser v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo parser v2.2 (Martins et al., 2013). We train Malt with Covington non-projective algorithm (Covington, 1990) after optimizing it with Malt optimizer (Ballesteros and Nivre, 2012), Yara with the default settings (64 beam) and 10 training epochs and Turbo with its default settings. The main reason for picking these three parsers is that we want to see the effect of Ezafe construction on a greedy parser (Malt), beam parser (Yara), and a graphbased parser (Turbo). As shown in Table 4 and 5, the parsing accuracy is improved across all different parsers by using the Ezafe tagset. 4 Error Analysis In this section we provide some error analysis for showing the effectiveness of our approach. Effect on the co</context>
</contexts>
<marker>Covington, 1990</marker>
<rawString>Michael A Covington. 1990. Parsing discontinuous constituents in dependency grammar. Computational Linguistics, 16(4):234–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masood Ghayoomi</author>
</authors>
<title>Word clustering for Persian statistical parsing.</title>
<date>2012</date>
<booktitle>In Advances in Natural Language Processing,</booktitle>
<pages>126--137</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1639" citStr="Ghayoomi, 2012" startWordPosition="237" endWordPosition="238"> phrase structure convertor based on the Persian dependencies. 1 Introduction There have been many studies on improving syntactic parsing methods for natural languages. Although most of the parsing methods are languageindependent, we may still require some language specific knowledge for improving performance. Besides many studies on parsing morphologically rich languages (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction t</context>
</contexts>
<marker>Ghayoomi, 2012</marker>
<rawString>Masood Ghayoomi. 2012. Word clustering for Persian statistical parsing. In Advances in Natural Language Processing, pages 126–137. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jila Ghomeshi</author>
</authors>
<title>Non-projecting nouns and the ezafe: Construction in Persian.</title>
<date>1997</date>
<journal>Natural Language &amp; Linguistic Theory,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="2011" citStr="Ghomeshi, 1997" startWordPosition="301" endWordPosition="302">ges (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction that appears in the Persian language with Perso-Arabic script. This construction is similar to Idafa construction in Arabic and construct state in Hebrew (Habash, 2010). It is mostly used for showing a possessive marker, adjective of a noun or connecting parts of a name (i.e. first and last name) or title. As a general statement, Ezafe occurs between any two items that h</context>
</contexts>
<marker>Ghomeshi, 1997</marker>
<rawString>Jila Ghomeshi. 1997. Non-projecting nouns and the ezafe: Construction in Persian. Natural Language &amp; Linguistic Theory, 15(4):729–788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Y Habash</author>
</authors>
<title>Introduction to Arabic natural language processing.</title>
<date>2010</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="2406" citStr="Habash, 2010" startWordPosition="364" endWordPosition="365">ion in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction that appears in the Persian language with Perso-Arabic script. This construction is similar to Idafa construction in Arabic and construct state in Hebrew (Habash, 2010). It is mostly used for showing a possessive marker, adjective of a noun or connecting parts of a name (i.e. first and last name) or title. As a general statement, Ezafe occurs between any two items that have some sort of connection (Ghomeshi, 1997). Ezafe vowel is attached to the head noun and to the modifiers that follow it: attributive nouns, adjectival and prepositional phrases (Samvelian, 2006). As depicted in Figure 1, this construction is very useful for disambiguating syntactic structures. The main issue here is that Ezafe rarely appears in the written text. This relies on the fact tha</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Y Habash. 2010. Introduction to Arabic natural language processing. Synthesis Lectures on Human Language Technologies, 3(1):1–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mojtaba Khallash</author>
<author>Ali Hadian</author>
<author>Behrouz MinaeiBidgoli</author>
</authors>
<title>An empirical study on the effect of morphological and lexical features in Persian dependency parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of MorphologicallyRich Languages,</booktitle>
<pages>97--107</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1663" citStr="Khallash et al., 2013" startWordPosition="239" endWordPosition="242">e convertor based on the Persian dependencies. 1 Introduction There have been many studies on improving syntactic parsing methods for natural languages. Although most of the parsing methods are languageindependent, we may still require some language specific knowledge for improving performance. Besides many studies on parsing morphologically rich languages (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction that appears in the Persi</context>
</contexts>
<marker>Khallash, Hadian, MinaeiBidgoli, 2013</marker>
<rawString>Mojtaba Khallash, Ali Hadian, and Behrouz MinaeiBidgoli. 2013. An empirical study on the effect of morphological and lexical features in Persian dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of MorphologicallyRich Languages, pages 97–107, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soheila Kian</author>
<author>Tara Akhavan</author>
<author>Mehrnoush Shamsfard</author>
</authors>
<title>Developing a Persian chunker using a hybrid approach.</title>
<date>2009</date>
<booktitle>In International Multiconference on Computer Science and Information Technology, 2009. IMCSIT’09,</booktitle>
<pages>227--234</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="1723" citStr="Kian et al., 2009" startWordPosition="250" endWordPosition="253">ere have been many studies on improving syntactic parsing methods for natural languages. Although most of the parsing methods are languageindependent, we may still require some language specific knowledge for improving performance. Besides many studies on parsing morphologically rich languages (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncratic construction that appears in the Persian language with Perso-Arabic script. This construction is s</context>
</contexts>
<marker>Kian, Akhavan, Shamsfard, 2009</marker>
<rawString>Soheila Kian, Tara Akhavan, and Mehrnoush Shamsfard. 2009. Developing a Persian chunker using a hybrid approach. In International Multiconference on Computer Science and Information Technology, 2009. IMCSIT’09, pages 227–234. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lavergne</author>
<author>Olivier Capp´e</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Practical very large scale CRFs.</title>
<date>2010</date>
<booktitle>In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>504--513</pages>
<marker>Lavergne, Capp´e, Yvon, 2010</marker>
<rawString>Thomas Lavergne, Olivier Capp´e, and Franc¸ois Yvon. 2010. Practical very large scale CRFs. In Proceedings the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 504–513. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Miguel Almeida</author>
<author>Noah A Smith</author>
</authors>
<title>Turning on the turbo: Fast third-order non-projective turbo parsers.</title>
<date>2013</date>
<pages>617--622</pages>
<contexts>
<context position="11950" citStr="Martins et al., 2013" startWordPosition="1956" endWordPosition="1959">dency Parsing results on the test data with different gold standard tagsets. UAS is the unlabeled attachment score and LAS is the labeled attachment score. Tagset Tag acc. MaltParser YaraParser TurboParser LAS UAS LAS UAS LAS UAS POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59% POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02% Table 5: Dependency Parsing results on the test data with different automatic tagsets. use three different off-the-shelf parsers: 1) Malt parser v1.8 (Nivre et al., 2007), 2) Yara parser v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo parser v2.2 (Martins et al., 2013). We train Malt with Covington non-projective algorithm (Covington, 1990) after optimizing it with Malt optimizer (Ballesteros and Nivre, 2012), Yara with the default settings (64 beam) and 10 training epochs and Turbo with its default settings. The main reason for picking these three parsers is that we want to see the effect of Ezafe construction on a greedy parser (Malt), beam parser (Yara), and a graphbased parser (Turbo). As shown in Table 4 and 5, the parsing accuracy is improved across all different parsers by using the Ezafe tagset. 4 Error Analysis In this section we provide some error</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>Andr´e F. T. Martins, Miguel Almeida, and Noah A. Smith. 2013. Turning on the turbo: Fast third-order non-projective turbo parsers. pages 617–622.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>02</issue>
<contexts>
<context position="11850" citStr="Nivre et al., 2007" startWordPosition="1939" endWordPosition="1942">% 91.01% 89.02% 91.56% 89.98% 92.30% POSe 89.12% 91.64% 89.91% 92.42% 90.85% 93.24% Table 4: Dependency Parsing results on the test data with different gold standard tagsets. UAS is the unlabeled attachment score and LAS is the labeled attachment score. Tagset Tag acc. MaltParser YaraParser TurboParser LAS UAS LAS UAS LAS UAS POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59% POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02% Table 5: Dependency Parsing results on the test data with different automatic tagsets. use three different off-the-shelf parsers: 1) Malt parser v1.8 (Nivre et al., 2007), 2) Yara parser v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo parser v2.2 (Martins et al., 2013). We train Malt with Covington non-projective algorithm (Covington, 1990) after optimizing it with Malt optimizer (Ballesteros and Nivre, 2012), Yara with the default settings (64 beam) and 10 training epochs and Turbo with its default settings. The main reason for picking these three parsers is that we want to see the effect of Ezafe construction on a greedy parser (Malt), beam parser (Yara), and a graphbased parser (Turbo). As shown in Table 4 and 5, the parsing accuracy is improved across all</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007. Maltparser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(02):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samira Noferesti</author>
<author>Mehrnoush Shamsfard</author>
</authors>
<title>A hybrid algorithm for recognizing the position of ezafe constructions in Persian texts.</title>
<date>2014</date>
<journal>International Journal of Interactive Multimedia and Artificial Intelligence,</journal>
<volume>2</volume>
<issue>6</issue>
<contexts>
<context position="3136" citStr="Noferesti and Shamsfard, 2014" startWordPosition="486" endWordPosition="489">e (i.e. first and last name) or title. As a general statement, Ezafe occurs between any two items that have some sort of connection (Ghomeshi, 1997). Ezafe vowel is attached to the head noun and to the modifiers that follow it: attributive nouns, adjectival and prepositional phrases (Samvelian, 2006). As depicted in Figure 1, this construction is very useful for disambiguating syntactic structures. The main issue here is that Ezafe rarely appears in the written text. This relies on the fact that Persian is written in PersoArabic script and vowels are mostly not written. There are few studies (Noferesti and Shamsfard, 2014; Asghari et al., 2014) on automatically finding Ezafe construction. In this work, we modify the part of speech tagset for the Persian words. This is done by adding an indicator of Ezafe to each part of speech (POS) tag and then train a supervised tagger on the modified tags. We show that having this modified tagset can both improve dependency parsing and shallow parsing (chunking). We achieve 12.8% and 4.6% relative error reduction in dependency parsing with gold and autowaitingEzafe water 877 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th </context>
</contexts>
<marker>Noferesti, Shamsfard, 2014</marker>
<rawString>Samira Noferesti and Mehrnoush Shamsfard. 2014. A hybrid algorithm for recognizing the position of ezafe constructions in Persian texts. International Journal of Interactive Multimedia and Artificial Intelligence, 2(6):17–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Sadegh Rasooli</author>
<author>Joel Tetreault</author>
</authors>
<title>Yara parser: A fast and accurate dependency parser. arXiv preprint arXiv:1503.06733.</title>
<date>2015</date>
<contexts>
<context position="11901" citStr="Rasooli and Tetreault, 2015" startWordPosition="1947" endWordPosition="1950">89.12% 91.64% 89.91% 92.42% 90.85% 93.24% Table 4: Dependency Parsing results on the test data with different gold standard tagsets. UAS is the unlabeled attachment score and LAS is the labeled attachment score. Tagset Tag acc. MaltParser YaraParser TurboParser LAS UAS LAS UAS LAS UAS POS tagger 98.71% 85.34% 88.80% 85.90% 89.43% 87.28% 90.59% POSe tagger 97.33% 85.74% 89.24% 86.35% 89.86% 87.73% 91.02% Table 5: Dependency Parsing results on the test data with different automatic tagsets. use three different off-the-shelf parsers: 1) Malt parser v1.8 (Nivre et al., 2007), 2) Yara parser v0.2 (Rasooli and Tetreault, 2015), and 3) Turbo parser v2.2 (Martins et al., 2013). We train Malt with Covington non-projective algorithm (Covington, 1990) after optimizing it with Malt optimizer (Ballesteros and Nivre, 2012), Yara with the default settings (64 beam) and 10 training epochs and Turbo with its default settings. The main reason for picking these three parsers is that we want to see the effect of Ezafe construction on a greedy parser (Malt), beam parser (Yara), and a graphbased parser (Turbo). As shown in Table 4 and 5, the parsing accuracy is improved across all different parsers by using the Ezafe tagset. 4 Err</context>
</contexts>
<marker>Rasooli, Tetreault, 2015</marker>
<rawString>Mohammad Sadegh Rasooli and Joel Tetreault. 2015. Yara parser: A fast and accurate dependency parser. arXiv preprint arXiv:1503.06733.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Sadegh Rasooli</author>
<author>Manouchehr Kouhestani</author>
<author>Amirsaeid Moloodi</author>
</authors>
<title>Development of a Persian syntactic dependency treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>306--314</pages>
<contexts>
<context position="4841" citStr="Rasooli et al., 2013" startWordPosition="770" endWordPosition="773">e book on the table is black. Figure 1: This figure shows two different readings for the same sentence with different Ezafe constructions. As shown in the trees, Ezafe affects both phrase boundaries and dependency relations. matic POS tags. We also achieve 31% and 9% relative error reduction in shallow parsing with gold and automatic POS tags. Our work is not only restricted to the effect of Ezafe in parsing, but as a byproduct, we create an open-source rule-based dependency to chunk converter for the Persian language. We have also manually tagged all words in the Persian dependency treebank (Rasooli et al., 2013) with 99.6% annotator agreement. This dataset is available for research purposes.1 The main contributions of this paper are: 1) showing the usefulness of Ezafe construction on dependency parsing and chunking, 2) developing a statistical chunker for the Persian language, 3) enriching the Persian treebank with manual Ezafe tags. The remainder of this paper is organized as the following: we describe our approach and data preparation in §2 and then conduct experiments in §3. Error analysis and conclusion are made in §4 and §5. 2 Data Preparation We define a simple procedure to include the informat</context>
<context position="6339" citStr="Rasooli et al., 2013" startWordPosition="1016" endWordPosition="1019">., 2011), we can easily train a POS tagger on the new tagset. We use the developed tagger to tag the dependency treebank. Peykare corpus has approximately ten million tokens and can give us a very accurate POS tagger even with the finer-grained Ezafe tags. We try this idea on two different tasks: dependency parsing and shallow parsing. 1http://dadegan.ir/catalog/ezafe 2.1 Chunking Data Preparation Unfortunately there is no standard chunking data for the Persian language. To compensate for this, we define the following rules to convert a dependency tree (based on Dadegan treebank dependencies (Rasooli et al., 2013)) to a shallow phrase structure: - We initialize every node (word) as a separate chunk; e.g. verb creates a VP. - If a node has a head or dependent belonging to a chunk (without any gap), attach that node to the same chunk. - If a node is a preposition/postposition, attach it to its next/previous dependent and create a PP. - A node with a dependency relation “nonverbal element”, “verb particle”, or “enclitic non-verbal element” belongs to the same VP as its head. - If a node is a particle, subordinating clause, coordinating conjunction, or punctuation, we should not create an independent chunk</context>
</contexts>
<marker>Rasooli, Kouhestani, Moloodi, 2013</marker>
<rawString>Mohammad Sadegh Rasooli, Manouchehr Kouhestani, and Amirsaeid Moloodi. 2013. Development of a Persian syntactic dependency treebank. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 306–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pollet Samvelian</author>
</authors>
<title>When morphology does better than syntax: the Ezafe construction in Persian. Ms., Universit´e de Paris,</title>
<date>2006</date>
<contexts>
<context position="2808" citStr="Samvelian, 2006" startWordPosition="433" endWordPosition="434">r water This is an idiosyncratic construction that appears in the Persian language with Perso-Arabic script. This construction is similar to Idafa construction in Arabic and construct state in Hebrew (Habash, 2010). It is mostly used for showing a possessive marker, adjective of a noun or connecting parts of a name (i.e. first and last name) or title. As a general statement, Ezafe occurs between any two items that have some sort of connection (Ghomeshi, 1997). Ezafe vowel is attached to the head noun and to the modifiers that follow it: attributive nouns, adjectival and prepositional phrases (Samvelian, 2006). As depicted in Figure 1, this construction is very useful for disambiguating syntactic structures. The main issue here is that Ezafe rarely appears in the written text. This relies on the fact that Persian is written in PersoArabic script and vowels are mostly not written. There are few studies (Noferesti and Shamsfard, 2014; Asghari et al., 2014) on automatically finding Ezafe construction. In this work, we modify the part of speech tagset for the Persian words. This is done by adding an indicator of Ezafe to each part of speech (POS) tag and then train a supervised tagger on the modified t</context>
</contexts>
<marker>Samvelian, 2006</marker>
<rawString>Pollet Samvelian. 2006. When morphology does better than syntax: the Ezafe construction in Persian. Ms., Universit´e de Paris, (1997):1–54.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Richard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Wolinski, Alina Wroblewska, and Eric Villemonte de la Clergerie.</title>
<date>2013</date>
<journal>Overview of the SPMRL</journal>
<booktitle>Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages,</booktitle>
<location>(October):146–182.</location>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D. Choi, Richard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Wolinski, Alina Wroblewska, and Eric Villemonte de la Clergerie. 2013. Overview of the SPMRL 2013 shared task : Cross-framework evaluation of parsing morphologically rich languages. Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, (October):146–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Seeker</author>
<author>Jonas Kuhn</author>
</authors>
<title>Morphological and syntactic case in statistical dependency parsing.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="1444" citStr="Seeker and Kuhn, 2013" startWordPosition="204" endWordPosition="207">rsing. For evaluation purposes, Ezafe tags are manually annotated in the Persian dependency treebank. Furthermore, to be able to conduct experiments on shallow parsing, we develop a dependency to shallow phrase structure convertor based on the Persian dependencies. 1 Introduction There have been many studies on improving syntactic parsing methods for natural languages. Although most of the parsing methods are languageindependent, we may still require some language specific knowledge for improving performance. Besides many studies on parsing morphologically rich languages (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately correspo</context>
</contexts>
<marker>Seeker, Kuhn, 2013</marker>
<rawString>Wolfgang Seeker and Jonas Kuhn. 2013. Morphological and syntactic case in statistical dependency parsing. Computational Linguistics, 39(1):23–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mojgan Seraji</author>
<author>Be´ata Megyesi</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency parsers for Persian.</title>
<date>2012</date>
<booktitle>In Proceedings of the 10th Workshop on Asian Language Resources,</booktitle>
<pages>35--44</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="1623" citStr="Seraji et al., 2012" startWordPosition="233" endWordPosition="236">dependency to shallow phrase structure convertor based on the Persian dependencies. 1 Introduction There have been many studies on improving syntactic parsing methods for natural languages. Although most of the parsing methods are languageindependent, we may still require some language specific knowledge for improving performance. Besides many studies on parsing morphologically rich languages (Seddah et al., 2013; Seeker and Kuhn, 2013), syntactic parsing for the Persian language is not yet noticeably explored. Concretely speaking, there are some recent work on dependency parsing for Persian (Seraji et al., 2012; Ghayoomi, 2012; Khallash et al., 2013) and very few studies on shallow parsing (Kian et al., 2009). The main focus of this paper is on the usefulness of Ezafe construction in Persian syntactic processing. Ezafe is an unstressed vowel -e that occurs at the end of some words (-ye in some specific occasions) that links together elements belonging to a single constituent (Ghomeshi, 1997). It often approximately corresponds in usage to the English preposition “of” (Abrahams, 2004). In the following example, the first word has an Ezafe vowel: fmontazere Ab waiting for water This is an idiosyncrati</context>
</contexts>
<marker>Seraji, Megyesi, Nivre, 2012</marker>
<rawString>Mojgan Seraji, Be´ata Megyesi, and Joakim Nivre. 2012. Dependency parsers for Persian. In Proceedings of the 10th Workshop on Asian Language Resources, pages 35–44, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>