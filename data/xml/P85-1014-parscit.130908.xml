<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.773614">
New Approaches to Parsing Conjunctions Using Prolog
Sandiway Fong
Robert C. Berwick
Artificial Intelligence Laboratory
</title>
<author confidence="0.195192">
M.I.T.
</author>
<affiliation confidence="0.1651915">
545 Technology Square
Cambridge MA 02139, U.S.A.
</affiliation>
<sectionHeader confidence="0.944551" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999651157894737">
Conjunctions are particularly difficult to parse in tra-
ditional, phrase-based grammars. This paper shows how
a different representation, not based on tree structures,
markedly improves the parsing problem for conjunctions.
It modifies the union of phrase marker model proposed by
Goodall [19811, where conjunction is considered as the lin-
earization of a three-dimensional union of a non-tree based
phrase marker representation. A Pttot.OG grammar for con-
junctions using this new approach is given. It is far simpler
and more transparent than a recent phrase-based extra-
position parser conjunctions by Dahl anti McCord [19841.
Unlike the Dahl and McCord or ATN SYSCONJ approach,
no special trail machinery is needed for conjunction, be-
yond that required for analyzing simple sentences. While
of comparable efficiency, the new approach unifies under a
single analysis a host of related constructions: respectively
sentences, right node raising, or gapping. Another advan-
tage is that it is also completely reversible (without cuts),
and therefore can be used to generate sentences.
</bodyText>
<sectionHeader confidence="0.960892" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.93730964516129">
The problem addressed in this paper is to construct
a grammatical device for handling coordination in natural
language that is well founded in linguistic theory and yet
computationally attractive. The linguistic theory should
be powerful enough to describe all of the phenomenon in
coordination, but also constrained enough to reject all un-
grammatical examples without undue complications. It is
difficult to achieve such a line balance - especially since the
term grammatical itself is highly subjective. Some exam-
ples of the kinds of phenomenon that lutist be handled are
sho..vn in fig.
The theory should also be amenable to computer
implementation. For example, the representation of the
phrase marker should be conducive to both clean process
description and efficient implementation of the associated
operations as defined in the linguistic theory.
John and Mary went to the pictures
Simple constituent coordination
The fox and the hound lived in the fox hole and
kennel respectively
Constituent coordination with the &apos;respectively&apos;
reading
John and I like to program in Prolog and Hope
Simple constituent coordination but can have a col-
lective or respectively reading
John likes but I hate bananas
Non-constit I len t coordination
Bill designs cars and Jack aeroplanes
Gapping with &apos;respectively&apos; reading
The fox, the hound and the horse all went to market
Multiple conjuncts
</bodyText>
<subsectionHeader confidence="0.538903">
*John sang loudly and a carol
</subsectionHeader>
<bodyText confidence="0.501352">
Violation of coordination of likes
</bodyText>
<figure confidence="0.813907833333333">
*Who did Peter see and the car?
Violation or (&amp;quot;(11,rdinate strnetnee constraint
*I will catch Peter and John might the car
Gapping, hut component sentences contain unlike
auxiliary verbs
?The president left before noon and at 2. Gorbachev
</figure>
<figureCaption confidence="0.976015">
Fig 1: Example Sentences
</figureCaption>
<bodyText confidence="0.999143153846154">
The goal of the computer implementation is to pro-
duce a device that can both generate surface sentences given
a phrase marker representation and derive a phrase marker
representation given a surface sentences. The implementa-
tion should be as efficient as possible whilst preserving the
essential properties of the linguistic theory. We will present
an implementation which is transparent to the grammar
and perhaps cleaner 8: more modular than other systems
such as the interpreter for the Modilier Structure Cram-
mars (MSCs) of Dahl &amp; McCord [19831.
The MSC system will be compared with a simplified
implementation of the proposed device. A table showing
the execution time of both systems for sonic sample sen-
</bodyText>
<page confidence="0.997483">
118
</page>
<bodyText confidence="0.992626428571429">
tences will be presented. Furthermore, the advantages and
disadvantages of our device will be discussed in relation to
the MSC implementation.
Finally we can show how the simplified device can
be extended to deal with the issues of extending the sys-
tem to handle multiple conjuncts and strengthening the
constraints of the system.
</bodyText>
<subsectionHeader confidence="0.843256">
The RPM Representation
</subsectionHeader>
<bodyText confidence="0.970378545454546">
The phrase marker representation used by the theory
described in the next section is essentially that of the Re-
duced Phrase Marker (RPM) of Lasnik &amp; Kupin (19771. A
reduced phrase marker can be thought of as a set consist-
ing of monostrings and a terminal string satisfying certain
predicates. More formally, we have (fig. 2) :-
This representation of a phrase marker is equiva-
lent to a proper subset of the more common syntactic tree
representation. This means that some trees may not be
representable by an RPM and all RPMs may be re-cast as
trees. (For example, trees with shared nodes representing
</bodyText>
<figure confidence="0.818070857142857">
overlapping constituents are not allowed.) An example of
a valid RPM is given in fig. 3 :-
Sentence: Alice saw Bill
RPM representation:
S. Alice.saw.Bill. NP.saw.Bill. Alice.V.Bill.
Alice.VP.Alice.saw.NP1
Pig 3: An example of RPM representation
</figure>
<bodyText confidence="0.96335">
This RPM representation forms the basis of the
linguistic theory described in the next section. The set
representation has some desirable advantages over a tree
reptesentation in terms of both simplicity of description
and implementation of the operations.
</bodyText>
<subsectionHeader confidence="0.987479">
Goodall&apos;s Theory of Coordination
</subsectionHeader>
<bodyText confidence="0.994566025641026">
Goodall&apos;s idea in his draft. thesis [Goodall??! was to
extend the definition of Lasnik and Kupin&apos;s RPM to cover
coordination. The main idea behind this theory is to ap-
ply the notion that coordination results From the union of
phrase markers to the reduced phrase marker. Since RPMs
are sets, this has the desirable property that the union of
RPMs would just be the familiar set union operation. For
a computer implementation, the set union operation can be
realized inexpensively. In contrast, the corresponding op-
eration for trees would necessitate a much less simple and
efficient union operation than set. union.
However, the original definition of the RPM did
not envisage the union operation necessary for coordina-
tion. The RPM was used to represent 2-dimensional struc-
ture only. But under set union the RPM becomes a rep-
resentation of 3-dimensional structure. The admissibility
predicates dominates and precedes defined on a set of
monostrings with a single non-terminal string were inade-
quate to describe 3-dimensional structure.
Basically, Goodall&apos;s original idea was to extend the
dominates and precedes predicates to handle RPMs un-
der the set union operation. This resulted in the relations
e-dominates and e-precedes as shown in fig. 4 :-
Let E and N denote the set of terminals and
non-terminals respectively.
Let co, 0, x (E U N).
Let x, y, z E E.
Let A be a single non-terminal.
Let P be an arbitrary set.
Then co is a monostring w.r.t. &amp; N if yo E
E*.N.E&apos;.
Suppose p= zits and that co, E P where P
is a some set of strings. We can also define the
following predicates :-
y isas yo in P if xyz E P
ip dominates 0 in P if 0 = xxy. x 54 0 and
x A.
co precedes 0 in P if 3y s.t. y isa* tp in P.
ui = zyx and x A z.
</bodyText>
<equation confidence="0.969998">
Then :-
P is an RPM if 3A,z s.t. A,z P and
V(0, (p) C P then
</equation>
<footnote confidence="0.5626325">
0 dominates co in P or ip dominates 0 in P
or 0 precedes (c) in P or r precedes 0 in P.
</footnote>
<figureCaption confidence="0.670241">
Fig 2: Definition of an RPM
</figureCaption>
<page confidence="0.998236">
119
</page>
<bodyText confidence="0.9701785">
Assuming the definitions of fig. 2 and in addition
let w, 0, e E N)* and q, r, s, t, v E V. then
</bodyText>
<subsectionHeader confidence="0.77167">
e-dominates in P if dominates in
</subsectionHeader>
<bodyText confidence="0.990131">
P. xxw = eyfl = and y in P.
p e-precedes ik in P if y Ise* yo in P. v isa
in P. qyr svt in P. y 0 qyr and v svt
where the relation LI (terminal equivalence) is
defined as :-
</bodyText>
<equation confidence="0.591521">
z y in P if xxw E P and xyw E P
</equation>
<figureCaption confidence="0.997565">
Figure 4: Extended definitions
</figureCaption>
<bodyText confidence="0.993251454545454">
This extended definition, in particular - the notion
of equivalence forms the basis of the computational device
described in the next section. However since the size of the
RPM may be large, a direct implementation of the above
definition of equivalence is not computationally feasible. In
the actual system, an optimized but. equivalent alternative
definition is used.
Although these definitions suffice for most examples
of coordination, it is not sufficiently constrained enough to
reject some ungrammatical examples. For example, fig. 5
gives the RPM representation of &amp;quot;John sang loudly and
a carol&amp;quot; in terms of the union of the RPMs for the two
constituent sentences :-
The above example indicates that the extended RPM
definition of Goodall allows some ungrammatical sentences
to slip through. Although the device presented in the next
section doesn&apos;t make direct use of the extended definitions,
the notion of equivalence is central to the implementation.
The basic system described in the next section does have
this deficiency but a less simplistic version described later
is more constrained - at the cost of some computational
efficiency.
</bodyText>
<subsectionHeader confidence="0.763466">
Linearization and Equivalence
</subsectionHeader>
<bodyText confidence="0.987204">
Although a theory of coordination has been described
in the previous sections - in order for the theory to be put
into practice, there remain two important questions to be
answered :-
</bodyText>
<listItem confidence="0.9863406">
• How to produce surface strings from a set of sentences
to be conjoined?
• How to produce a set of simple sentences (i.e. sen-
tences without conjunctions) from a conjoined surface
string?
</listItem>
<bodyText confidence="0.988083285714286">
This section will show that the processes of lin-
earization and finding equivalences provide an answer to
both questions. For simplicity in the following discussion,
we assume that the number of simple sentences to be con-
joined is two only.
The processes of linearization and finding equiva-
Ipnces for generation can be defined as :-
</bodyText>
<figure confidence="0.71353675">
John sang loudly John.sang.loudly, S.
John sang a carol John.V.Ioudly,John.VP,
John.sang.AP,
NP .sang. loudly }
{John.sang.a.carol, S.
John.V.a.carol, John.VP,
John.sang.NP,
NP.sang.a.carol}
</figure>
<bodyText confidence="0.980950259259259">
(When these two 11Phiq are merged some of the elements
of the set do not satisfy Lasnik Kupin&apos;s original defi-
nition - these pairs are :-)
{John.sang.londly. John sang.a.carol}
{John.V.Ioudly. John.V.a.carol}
{NP.sang.loudly. NP.sang.a.carol}
(Mune of the above pairs musty the &amp;dominates predi-
cate - but they all satisfy &amp;precedes and hence the seri-
LCI We IN 40711) Led in114 au IIPM.)
Fig.5: An example of union of RPMs
Given a set of sentences and a set of candidates
which represent the set of conjoinahle pairs for
those sentences, linearization will output one or
more surface strings according to a fixed proce-
dure.
Given a set of sentences, finding equivalences
will produce a set of conjoinable pairs according
to the definition of equivalence of the linguistic
theory.
For generation the second process (finding equiva-
lences) is called first to generate a set of candidates which
is then used in the first, process (linearization) to generate
the surface strings. For parsing, the definitions still hold -
but the processes arc applied in reverse order.
To illustrate the procedure for linearization, con-
sider the following example of a set of simple sentences
(fig. 6)
</bodyText>
<page confidence="0.97051">
120
</page>
<bodyText confidence="0.992058444444444">
John liked ice-cream. Mary liked chocolate)
Mt of simple sentences
((John. Mary). {ice-cream. chocolate))
set of ronjoinable pairs
tational resources in not having to compare every element
of the set with every other element to generate all possible
equivalent strings - which would take 0(n2) time - where
n is the cardinality of the set. The corresponding term for
the modified definition (given in the next section) is 0(1).
</bodyText>
<figureCaption confidence="0.84316775">
Fig 6: Example of a set of simple sentences
Consider the plan view of the 3-dimensional repre-
sentation of the union of the two simple sentences shown in
lig. 7 :-
</figureCaption>
<figure confidence="0.987807666666667">
John
liked
Mary
</figure>
<figureCaption confidence="0.995938">
Fig 7: Example of 3-dimensional structure
</figureCaption>
<bodyText confidence="0.9785735">
The procedure of linearization would take the fol-
lowing path shown by the arrows in fig. 8 :-
</bodyText>
<figureCaption confidence="0.573809">
Fig 8: Example of linearization
</figureCaption>
<bodyText confidence="0.999966181818182">
Following the path shown we obtain the surface
string -John and Mary liked ice-cream and chocolate...
The set of conjoinable pairs is produced by the pro-
cess of finding equivalences. The definition of equivalence
as given in the description of the extended RPM requires
the generation of the combined RPM of the constituent sen-
tences. However it can be shown [Vong??1 by considering
the constraints imposed by the definitions of equivalence
and linearization, that the same set of equivalent terminal
strings can be produced just by using the terminal strings of
the RPM alone. There are considerable savings of compu-
</bodyText>
<subsectionHeader confidence="0.914388">
The Implementation in Prolog
</subsectionHeader>
<bodyText confidence="0.977899833333333">
This section describes a runnable specification written
in Prolog. The specification described also forms the basis
for comparison with the MSG interpreter or Dahl and Mc-
Cord. The syntax of the clauses to be presented is similar
to the Dec-10 Prolog [Bowen et al.19821 version. The main
differences are :-
</bodyText>
<listItem confidence="0.997955166666667">
• The symbols &amp;quot;:-&amp;quot; and &amp;quot;,&amp;quot; have been replaced by the
more meaningful reserved words &amp;quot;if&apos; and &amp;quot;and&amp;quot; re-
spectively.
• The symbol &amp;quot;.&amp;quot; is used as the list constructor and
&amp;quot;nil&amp;quot; is used to represent the empty list.
• Au an example, a Prolog clause may have the form :-
</listItem>
<equation confidence="0.483461">
a(X Y Z) if b(U V ... W) and c(R S T)
</equation>
<bodyText confidence="0.972607625">
where a,b &amp; c are predicate names and R,S,...,Z may
represent variables, constants or terms. (Variables
are distinguished by capitalization of the first charac-
ter in the variable name.) The intended logical read-
ing of the clause is :-
&amp;quot;a&amp;quot; holds if &amp;quot;b&amp;quot; and &amp;quot;c&amp;quot; both hold
for consistent bindings of the arguments
X,Y,...,Z, U,V,...,W, R,S,...,T
</bodyText>
<listItem confidence="0.9968685">
• Comments (shown in italics) may be interspersed be-
tween the arguments in a clause.
</listItem>
<subsectionHeader confidence="0.885656">
Parse and Generate
</subsectionHeader>
<bodyText confidence="0.999583555555556">
In the previous section the processes of linearization
and finding equivalences are described as the two compo-
nents necessary for parsing and generating conjoined sen-
tences. We will show how these processes can be combined
to produce a parser and a generator. The device used for
comparison with Dahl At McCord schame is a simplified
version of the device presented in this section.
First, difference lists are used to represent strings
in the following sections. For example, the pair (fig. 9) :-
</bodyText>
<figure confidence="0.536008">
ice cream
chocolate
liked
121
john.liked.ice-cream. Continuation. Continuation}
</figure>
<figureCaption confidence="0.969752">
Fig 9: Example of a difference list
</figureCaption>
<bodyText confidence="0.876800166666666">
is a difference list representation of the sentence &amp;quot;John
liked ice-cream&amp;quot;.
We can now introduce two predicates linearize and
equivalentpairs which correspond to the processes of lin-
earization and finding equivalences respectively (fig. 10) :-
linearize( pairs Si El and S2 E2 candidates Set
gives Sentence)
Linearize holds when a pair of difference lists
((Si. Ell St (S2. E2}) trid a set of candidates
(Set) are consistent with the string (Sentence)
as defined by the procedure given in the previ-
ous section.
</bodyText>
<equation confidence="0.942945">
equivalentpairs( X Y from Si S2)
</equation>
<bodyText confidence="0.7591878125">
Equivalentpairs holds when a substring X of
Si is equivalent, to a substring Y (4&apos;52 according
to the definition of equivalence in the linguistic
theory.
The definitions for parsing and generating are al-
most logically equivalent. llowever the sub-goals for pars-
ing arc in reverse order to the sub-goals for generating -
since .the Prolog interpreter would attempt to solve the
sub-goals in a left to right manner. Furthermore, the sub-
set relation rather than set equality is used in the definition
for parsing. We can interpret the two definitions as follows
(fig. 12) :-
Generate holds when Sentence is the con-
joined sentence resulting &amp;mu the linearization
of the pair of difference lists (Si. nil) and (S2.
nil) using as candidate pairs for conjoining, the
set of non-redundant pairs of equivalent termi-
nal strings (Set).
Parse holds when Sentence is the conjoined
sentence resulting from the linearization of the
pair of difference lists (Si. El) and (S2. E2)
provided that the set of candidate pairs for con-
joining (Subset) is a subset of the set of pairs
or equivalent terminal strings (Set).
Fig 12: Logical reading for generate &amp; parse
Fig 10: Predicates linearize de equivalentpairs
Additionally, let the ineta-logical predicate setof
as in &amp;quot;setof(Element Goal Set)&amp;quot; hold when Set is composed
of elenients of the form Element and that Set contains all
ances of Element that satisfy the goal Goal. The pred-
icates generate can now be defined in terms of these two
processes as follows (lig. I :-
</bodyText>
<construct confidence="0.625896363636364">
generate(Sentence from Si S2)
if setof(X.Y.nil in equivalentpairs(X Y
from Si S2) is Set)
and linearize( pair:: SI nil and S2 nil
candidates Set gives Sentence)
parse( Sentence giving Si El)
if 1;nearize(pairs SI El and S2 E2
candidates SubSet gives Sentence)
and setol(X.Y nil in equivalentpairs(X Y
from Si S2) is Set)
Fig Prolog definition for generate Se parse
</construct>
<bodyText confidence="0.9944544">
The subset relation is needed for the above defini-
tion of parsing because it can be shown [Fong??1 that the
process of linearization is more constrained (in terms of the
permissible conjoinable pairs) than the process of finding
equivalences.
</bodyText>
<subsectionHeader confidence="0.713943">
Linearize
</subsectionHeader>
<bodyText confidence="0.957395363636364">
We can also fashion a logic specification for the process
of linearization in the same manner. In this section we
will describe the cases corresponding to each Prolog clause
necessary in the specification of linearization. However, or
simplicity the actual Prolog code is not shown here. (See
Appendix A for the definition of predicate linearize.)
In the following discussion we assume that the tem-
plate for predicate linearize has the form &amp;quot;linearize( pairs
Si El and S2 E2 candidates Set gives Sentence)&amp;quot; shown
previously in lig. 10. There are three independent cases to
con:;iikr dnripg linearization :-
</bodyText>
<sectionHeader confidence="0.735016" genericHeader="method">
I. The Base Case.
</sectionHeader>
<bodyText confidence="0.9987228">
If the two difference lists ({St El} 14 (S2. E2}) are
both empty then the conjoined string (Sentence) is
also empty. This simply states that if two empty
strings are conjoined then the result is also an empty
string.
</bodyText>
<page confidence="0.996336">
122
</page>
<sectionHeader confidence="0.606265" genericHeader="method">
2. Identical Leading Substrings.
</sectionHeader>
<bodyText confidence="0.998664857142857">
The second case occurs when the two (non-empty)
difference lists have identical leading non-empLy sub-
strings. Then the conjoined string is identical to the
concatenation of that leading substring with the lin-
earization of the rest of the two difference lists. For
example, consider the linearization of the two frag-
ments &amp;quot;likes Mary&amp;quot; and &amp;quot;likes Jill&amp;quot; as shown in fig. 13
</bodyText>
<figure confidence="0.859768409090909">
Hikes Mary. likes Jill)
which can be linearized a.s:-
{likes XI
where X is the linearization
of strings (Mary. Jill)
Fig.13: Example of identical leading substrings
what linearizations the system would produce for an ex-
ample sentence. Consider the sentence &amp;quot;John and Bill liked
Mary&amp;quot; (fig. 15) :-
(John and Bill liked Mary)
would produce the strings:-
{John and Bill liked Mary.
John and Bill liked Mary)
with candidate set 0
{ John liked Mary, Bill liked Mary)
with candidate set ((John, Bill)}
(John Mary. Bill liked Mary)
with candidate set {(John. Bill liked))
{John. Bill liked Mary}
with candidate set ((John. Bill liked Mary))
Fig.15: Example of linearizations
3. Conjoining.
</figure>
<figureCaption confidence="0.976896222222222">
The last case occurs when the two pairs of (non-
empty) difference lists have no common leading sub-
string. Here, the conjoined string will be the con-
catenation of the conjunction of one of the pairs front
the candidate set, with the conjoined string resulting
from the linearization of the two strings with their re-
spective candidate substrings deleted. For example,
consider the linearization 14 the two sentences &amp;quot;John
likes Mary&amp;quot; and &amp;quot;Bill likes Jill&amp;quot; as shown in fig. 14 :-
</figureCaption>
<subsectionHeader confidence="0.590582">
{John likes Mary. Bill likes Jill)
</subsectionHeader>
<bodyText confidence="0.977009">
Givrn that the seketed candidate pair is {John. Bill),
Use euitio;ued :;e tilt nee ntmild he :-
All of the strings are then passed to the predicate
findequivalences which should pick out the second pair
of strings as the only grammatically correct linearization.
</bodyText>
<subsectionHeader confidence="0.924651">
Finding Equivalences
</subsectionHeader>
<bodyText confidence="0.9882016">
Goodall&apos;s definition of equivalence was that. two termi-
nal strings were said to be equivalent if they had the saute
left and right contexts. Furthermore we had previously as-
serted that the equivalent pairs could be produced without
searching the whole RPM. For example consider the equiv-
alent terminal strings in the two sentences &amp;quot;Alice saw Bill&amp;quot;
and &amp;quot;Mary saw Bill&amp;quot; (fig. 16) :-
{John and Bill X}
where X
is the linearization of strings (likes Mary, likes Jill)
</bodyText>
<subsectionHeader confidence="0.659149">
Exampie of eoupnuing substrings
</subsectionHeader>
<bodyText confidence="0.971473">
There are Sallie 11111)1ffilielliatiffil detailS that are dif-
ferent fer parsing in generating. (Sec appendix A.) However
the three Cases are the sante for both.
We can illustrate the above definition by showing
</bodyText>
<figure confidence="0.857808333333333">
(Alice :law Bill. Mary saw Bill)
would produce the equivalent pairs :-
(Alice saw Bill. Mary saw Bill)
(Alice. Mary)
(Alice saw. Mary saw)
Fig.16: Example or equivalent pairs
</figure>
<footnote confidence="0.958468">
We also make the following restrictions on Coodall&apos;s
definition :-
</footnote>
<page confidence="0.998176">
123
</page>
<bodyText confidence="0.9288778">
• If there exists two terminal strings X &amp; Y such that
X=xxf1 &amp; Y=xyfl, then x &amp; fl should be the strongest
possible left &amp; right contexts respectively - provided
x &amp; y are both nonempty. In the above example,
x=nil and fl=&amp;quot;saw Bill&amp;quot;, so the first and the third
pairs produccd are redundant.
In general, a pair or terminal strings are redundant
if they have the form (uv, uw) or (uv, xv), in which
case - they may be replaced by the pairs (v, w) and
(u, x) respectively.
</bodyText>
<listItem confidence="0.824224">
• In Goodall&apos;s definition any two terminal strings them-
selves are also a pair of equivalent terminal strings
(when x &amp; n are both null). We exclude this case as
it produces simple string concatenation of sentences.
</listItem>
<bodyText confidence="0.9946753">
The above restrictions imply that in fig. 16 the only
remaining equivalent pair ({Alice. Mary })is the correct one
for this example.
However, before finding equivalent. pairs for two
simple sentences, the process of finding equivalences must
check that the two sentences are actually grammatical. We
assume that, a recognizer/parser (e.g. a predicate parse(S
E)) already exists for determining the grammaticality of
simple sentences. Since the process only requires a yes/no
answer to grammaticality, any parsing or recognition sys-
tem for simple sentences can be used.
We can now specify a predicate findcandidates(X Y
Si S2) that holds when (X. Y1 is an equivalent pair from
the two grammatical simple sentences (SI. S21 as Mows
(lig. 17) :-
findcandidates(X and Y in S1 end S2)
if parse(S1 nil)
and parse(S2 nil)
and equiv(X Y Si S2)
where equiv is defined
</bodyText>
<equation confidence="0.940627">
Npthi(X Y XI Vi)
</equation>
<bodyText confidence="0.924394285714286">
if appern13(Clii X Omega X1)
and terminals(X)
and append3(C.Iti Y Omega Y1)
and ternainals(Y)
where ;IN....MI:(1,i 1,2 1. I) iii■lils when L.1
the emu...den:Ai imo . I LI.LZ 1.3. terminal:9&apos;X)
wiii &apos;II X is a he. I is terminal symbols only
</bodyText>
<subsubsectionHeader confidence="0.519295">
11g. 17: Logic definition of Vindcandidates
</subsubsectionHeader>
<bodyText confidence="0.966093">
Then the predicate findequivalences is simply de-
fined itS (fig. 18) :-
findequivalences(X and Y in Si and 52)
if findcandidates(X and Y in Si and S2)
and nut redundant(X Y)
where redundant implements the two restrictions described .
</bodyText>
<note confidence="0.614299">
Fig.18: Logic definition of Findequivalences
</note>
<subsectionHeader confidence="0.759757">
Comparison with MSGs
</subsectionHeader>
<bodyText confidence="0.998835566666667">
The following table (fig. 19) gives the execution times
in milliseconds for the parsing of sonic sample sentences
mostly taken from Dahl At. McCord [19831. Both systems
were executed using Dec-20 Prolog. The times shown for
the MSG interpreter is based on the time taken to parse and
build the syntactic tree only - the tune for the subsequent
ti ansformations was not included.
Sample MSG RPM
sentences system device
Each imul ate an at)* and a pear 662 292
John ate an apple and a pear 613 233
A man and a woman saw each train 319 506
Each man and each woman ate 320 503
an apple
John saw and the woman heard 788 834
a man that laughed
John (kiwi. the car through and 275 1032
comply&apos; ply demolished a window
The W011 UM who gave a hook to 1007 3375
John awl drove a ear through a
winilow laughed
.1‘,Iin SAW the Mall that Mary saw 439 311 I
and Bill gave a book to laughed i
John saw the man that heard the 636 323 i
woman that laughed and saw Bill 1
—
Ti,,&apos; man that Mary saw and heard 501. 982 I
gave at&apos; appie to each Woman I
John saw a and Mary saw the red 726 770
pear
</bodyText>
<subsectionHeader confidence="0.524615">
Fig. Ed: Timings for sonic sample sentences
</subsectionHeader>
<bodyText confidence="0.99541575">
From the timings we can conclude that the pro-
poxed device is comparable to the MS(1 system in terms
of computational efficiency. however, there are sonic other
advantages such as :-
</bodyText>
<listItem confidence="0.971645666666667">
• Transparency of the grammar - There is no need for
phrasal rules such as &amp;quot;S S and S&amp;quot; The device also
allows non-phrasal conjunction.
• Since no special grammar or particular phrase marker
representation is required, any parser can be used -
the device only requires an acctpt/reject answer.
</listItem>
<page confidence="0.946421">
124
</page>
<listItem confidence="0.9375772">
• The specification is not biased with respect to pars-
ing or generation. The implementation is reversible
allowing it to generate any sentence it can parse and
vice versa.
• Modularity of the device. The grammaticality of sen-
</listItem>
<bodyText confidence="0.96198119047619">
tences with conjunction is determined by the defini-
tion of equivalence. For instance, if needed we can
filter the equivalent terminals using semantics.
A Note on SYSCONJ
It is worthwhile to compare the phrase marker approach
to the ATN-based SYSCONJ mechanism. Like SYSCONJ, our
analysis is extragrammatical: we do not tamper with the
basic grammar, but add a new component that handles
conjunction. Unlike SYSCONJ, our approach is based on a
precise definition of &amp;quot;equivalent phrases&amp;quot; that attempts to
unify under one analysis many different types of coordina-
tion phenomena. SN&apos;Sr.ONJ relied on a rather complicated,
interrupt-driven method that restarted sentence analysis in
some previously recorded machine configuration, but with
the input sequence following the conjunction. This cap-
tures part of the &amp;quot;multiple planes&amp;quot; analysis of the phrase
marker approach, but without a precise notion of equiva-
lent phrases. Perhaps as a result, SYSCONJ handled only
ordinary conjunction, and not respectively or gapping read-
ings. In our apprmich, a simple change to the linearization
process allows II, te handle gapping.
</bodyText>
<subsectionHeader confidence="0.507287">
Extensions to the Basic Device
</subsectionHeader>
<bodyText confidence="0.984236913043478">
The device described in the previous section is a sim-
plified version for rough comparison with the MSC inter-
preter. however, the system can easily he generalized to
handle multiple conjuncts. The only additional phase re-
quired is to generate template:: for multiple readings. Also,
gapping can he handled just. by adding clauses to the defi-
nition of linearize - which allows a different path from that
of lig. 8 to be taken.
The simplified device permits some examples of un-
grammatical semence to lie par-ed as if corr-ct (lig. 5).
The modularity of the system allows its to constrain the
definition of equivalence still further. The extended defini-
tions in C4milalfs draft. theory were not included in his the-
sis f :ooda1184) pres Ii inably because it was not constrained
enough. Ilowever in iis thesis he proposes another defini-
tion of grammaticality using RPMs. This definition can he
used to constrain equivalence still further in our system at
a loss of sonic efficiency and generality. For example, the
requireil at predicate will need to it explicit. use
of the combined RPM. Therefore, a parser will need to pro-
duce a RPM representation as its phrase marker. The mod-
ifications necessary to produce the representation is shown
in appendix B.
</bodyText>
<sectionHeader confidence="0.994731" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997338">
This work describes research clone at the Artificial Intel-
ligence Laboratory of the Massachusetts Institute of Tech-
nology. Support for the Laboratory&apos;s artificial intelligence
research has been provided in part by the Advanced Re-
search Projects Agency of the Department of Defense un-
der Office of Naval Research contract N00011-80-C-0505.
The first author is also funded by a scholarship from the
Kennedy Memorial Trust.
</bodyText>
<sectionHeader confidence="0.998589" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.9070494">
Bowen et D.L. Bowen (ed.), L. Byrd, F.C.N. Pereira. L.M.
Pereira, D.H.D. Warren. Decsystetn-10 Prolog User&apos;s Man-
ual. University of Edinburgh. 1082.
Dahl Fl McCord: V. Datil and M.C. McCord. Treating Coordi-
nation in Logic Grammars. American .Journal of Compu-
tational Linguistics. Vol. 0, No. 2 (1083).
Fong??: Sandiway Fong. To appear in S.M. thesis - &amp;quot;Specifying
Coordination in Logic&amp;quot; - 1085
Goodall??: Grant Todd (;oodall. Draft - Chapter 2 (sections 2.1.
to 2.7)- Coordination.
Goodull84: Grant Todd (Ioodall, Parallel Sinn:tures in Syntax.
Ph.D thesis. University of California. San Diego (1084).
Lasnik I kupin: 11. Lasnik and J. Knoll&apos;. A restrictive theory
transforznational grammar. TI me, LingaiAies
(1977).
</reference>
<sectionHeader confidence="0.97321" genericHeader="method">
Appendix A: Linearization
</sectionHeader>
<bodyText confidence="0.54203725">
The fill Prolog specification for the predicate linearize is
given below.
/ Linearize for grneration /
/ terminatiny condition /
</bodyText>
<subsectionHeader confidence="0.455406">
linearize(pairs SI SI and 52 52
</subsectionHeader>
<bodyText confidence="0.467082">
randidaies List giviny nil) if ninivar(List)
/ appiicahie when me have it ii) 7100(114 sabstring /
</bodyText>
<footnote confidence="0.95046">
linearize( pairs SI El awl 52 E2
eutnmliil,uL es List giving Sentence)
it var(Sentence)
and not saine(St as El)
and not same(52 u.s E2)
</footnote>
<page confidence="0.996685">
125
</page>
<bodyText confidence="0.803874428571429">
and similar(S1 to S2 common Similar)
and not same(Similar as nil)
and reinove(Similar from Si leaving NewS1)
and remove(Similar from S2 leaving NewS2)
and linearize(pairs NewS1 El and NewS2 E2
candidates List. giving Rest OfSentence)
and append(Similar RestOfSentence Sentence)
</bodyText>
<figure confidence="0.69750575">
/ conjoin two substrings /
lirtearize(pairs SI El and S2 E2
candidates List giving Sentence)
if var(Sentence)
</figure>
<figureCaption confidence="0.6661185">
and inenther(Candl.Cand2.nil of List)
and not saine(S1 as El)
</figureCaption>
<bodyText confidence="0.770501428571429">
and riot saine(S2 as E2)
and remove( Cand l from Si leaving NewS1)
and remove(C.and2 from S2 leaving NewS2)
and conjoin(list (anil.( ad2.nil using &apos;and&apos;
giving Conjoined)
and delete(Cand I.Cand2.nil from List leaving NewList)
and linearize( pairs NewS1 El and NewS2 E2
</bodyText>
<reference confidence="0.590302888888889">
candidates Now List giving RestofSentence)
and append(Conjoined RestofSentence Sentence)
/ Linearize for parsing /
/ Terminating case /
finearize(pairs nil nil and nil nil
candidates List giving nil)
if var(List)
and saine(List (IA nil)
/ Case for common substring /
lito.a:ahc(pairs Coninunt.NewS1 nil and (&apos;omnion.NewS2 nil
randidates List giving Sentence)
if tonivar(Sentenee)
itidsame(ComillotalestOfSenti nee as Sentence)
and linearize(pair.s New I nil and NewS2 nil
candidates List givitoy Iti•st()1Sentt•tico)
/ Case for ranjoin
litivariztloairs St nil and 52 nil
candidnies Flativnt..flest. giving Sentonce)
</reference>
<bodyText confidence="0.9303196">
if nonvar(Sentence)
and appiaid. (( onjoitied to Rest0L-letitenee giving ticatolia.)
and conjoin(lisl Element using &apos;an&amp; litOrty ( onjoinod)
and .-aion•( Etc:tient its Cant! l.( d?..ttil)
and not ::ion•(( anil 1 as nil)
and not saine((alii12 as nil)
and linearize(pairs NewS I nil anti NewS&apos;2 nil
ea,uli II itt ii 3 pinny R.esi I )fsentenco)
and :iiiiietol(( &apos;anill New5I SI)
and apsoaol( &apos;and2 New82 52)
</bodyText>
<construct confidence="0.178308666666667">
/ append &apos; is a .special farm of alpend such that
the first list must be man-eating
atuaaul&apos; (11,:ol.ttil tIJ &apos;rail giving 114.ml:rail)
</construct>
<reference confidence="0.606927041666667">
aroolol• I .Seemal.Ot her:2 to Tail giving First.ltest)
if append &apos;iSeeolid.( &gt;thers giving Itcht)
:itoilattailto nil ramming nil)
10 Iiiat12.Toil? rommon nil)
if not :4.1,1,111e:ti11 as 111.0.112)
11&amp;quot;ad :rail I If) livad.l&apos;ail2 coon/ion flead.Rest)
if s. .1;Ir(Taill to Tat 12 ra„,, non [sit)
/ conjoin is reversible /
conjuiii(list First.Second.nil using Conjunct giving Conjoined)
if nonvar(First)
and nonvar(Second)
and append(First Conjtmet.Second Conjoined)
conjoin(list First.Second-nil using Conjunct giving Conjoined)
if nonvar(Conjoined)
and append( First (7onjunct.Second Conjoined)
reinove(nilfrom List leaving List)
reinove(Head.Tail from Ilead.Rest leaving List)
if remove( Tail from Rest leaving List)
delettifflead from nil leaving nil)
delete(Head from IItiad.Tail leaving Tail)
delete(Head front First .Rest leaving First.Tail)
if not saille(llead as First)
and delete( Head from Rest leaving Tail)
Appendix B: Building the RPM
</reference>
<bodyText confidence="0.960851416666667">
A RPM representation ,:an ht. built by ashling three extra
pat •wrm to each grammar nth. together with a call to a con-
eatenatilni rontini.. For exarit pie. consider the verb plira.se &amp;quot;liked
Mary” from the simple sentence &amp;quot;John liked Mary&amp;quot;. The nionos-
tring corresponding to the non-terminal VP is constructed by
taking the left itnil right contexts of &amp;quot;liked Mary and placing the
ntm-terniinal synthol VP inhetwisal them. In general, we have
mattething of the form :-
phrase( from Pointl to Point2
using Start to End g ivirty MS.RPM)
if isphrase(Pointl to Point2 RPM)
and binklmonostring(Start Pointl plus &apos;VP&apos;
</bodyText>
<reference confidence="0.5824921">
Point2 End MS)
where difference pairs {Start. Point 1}. {Point2. End} and
{Start. End} ref oresent the left cialtext, the right context and the
sentence string respectively. The concatenation routine build-
m000string is just :-
builihnonostring(Start Pointl plus NonTerminal
Point2 End MS)
if append(Pointl Left Start)
and append(Point2 Right End)
and append(Lelt NonTerminalRight MS)
</reference>
<page confidence="0.998069">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.923155">
<title confidence="0.998609">New Approaches to Parsing Conjunctions Using Prolog</title>
<author confidence="0.9763935">Sandiway Fong Robert C Berwick</author>
<affiliation confidence="0.993874">Artificial Intelligence Laboratory M.I.T.</affiliation>
<address confidence="0.9969135">545 Technology Square Cambridge MA 02139, U.S.A.</address>
<abstract confidence="0.99930825">Conjunctions are particularly difficult to parse in traditional, phrase-based grammars. This paper shows how a different representation, not based on tree structures, markedly improves the parsing problem for conjunctions. It modifies the union of phrase marker model proposed by Goodall [19811, where conjunction is considered as the linearization of a three-dimensional union of a non-tree based phrase marker representation. A Pttot.OG grammar for conjunctions using this new approach is given. It is far simpler and more transparent than a recent phrase-based extraposition parser conjunctions by Dahl anti McCord [19841. the Dahl and McCord or ATN no special trail machinery is needed for conjunction, beyond that required for analyzing simple sentences. While of comparable efficiency, the new approach unifies under a analysis a host of related constructions: sentences, right node raising, or gapping. Another advantage is that it is also completely reversible (without cuts), and therefore can be used to generate sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<editor>Bowen et D.L. Bowen (ed.), L. Byrd, F.C.N. Pereira.</editor>
<publisher>L.M.</publisher>
<marker></marker>
<rawString>Bowen et D.L. Bowen (ed.), L. Byrd, F.C.N. Pereira. L.M.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D H D Warren Pereira</author>
</authors>
<tech>Decsystetn-10 Prolog</tech>
<pages>1082</pages>
<institution>User&apos;s Manual. University of Edinburgh.</institution>
<marker>Pereira, </marker>
<rawString>Pereira, D.H.D. Warren. Decsystetn-10 Prolog User&apos;s Manual. University of Edinburgh. 1082.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dahl Fl McCord V Datil</author>
<author>M C McCord</author>
</authors>
<title>Treating Coordination in Logic Grammars.</title>
<journal>American .Journal of Computational Linguistics.</journal>
<volume>0</volume>
<pages>1083</pages>
<marker>Datil, McCord, </marker>
<rawString>Dahl Fl McCord: V. Datil and M.C. McCord. Treating Coordination in Logic Grammars. American .Journal of Computational Linguistics. Vol. 0, No. 2 (1083).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fong Sandiway</author>
</authors>
<title>Fong. To appear in S.M. thesis - &amp;quot;Specifying Coordination in Logic&amp;quot; -</title>
<pages>1085</pages>
<marker>Sandiway, </marker>
<rawString>Fong??: Sandiway Fong. To appear in S.M. thesis - &amp;quot;Specifying Coordination in Logic&amp;quot; - 1085</rawString>
</citation>
<citation valid="false">
<authors>
<author>Goodall Grant</author>
</authors>
<title>Todd (;oodall. Draft -</title>
<journal>Chapter</journal>
<volume>2</volume>
<note>to 2.7)- Coordination.</note>
<marker>Grant, </marker>
<rawString>Goodall??: Grant Todd (;oodall. Draft - Chapter 2 (sections 2.1. to 2.7)- Coordination.</rawString>
</citation>
<citation valid="true">
<title>Goodull84: Grant Todd (Ioodall, Parallel Sinn:tures in Syntax. Ph.D thesis.</title>
<date>1084</date>
<institution>University of California.</institution>
<location>San Diego</location>
<marker>1084</marker>
<rawString>Goodull84: Grant Todd (Ioodall, Parallel Sinn:tures in Syntax. Ph.D thesis. University of California. San Diego (1084).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Lasnik</author>
</authors>
<title>kupin: 11. Lasnik</title>
<date>1977</date>
<location>LingaiAies</location>
<marker>Lasnik, 1977</marker>
<rawString>Lasnik I kupin: 11. Lasnik and J. Knoll&apos;. A restrictive theory transforznational grammar. TI me, LingaiAies (1977).</rawString>
</citation>
<citation valid="false">
<title>candidates Now List giving RestofSentence) and append(Conjoined RestofSentence Sentence) / Linearize for parsing / / Terminating case /</title>
<marker></marker>
<rawString>candidates Now List giving RestofSentence) and append(Conjoined RestofSentence Sentence) / Linearize for parsing / / Terminating case /</rawString>
</citation>
<citation valid="false">
<title>finearize(pairs nil nil and nil nil candidates List giving nil) if var(List) and saine(List (IA nil) / Case for common substring /</title>
<booktitle>lito.a:ahc(pairs Coninunt.NewS1 nil and (&apos;omnion.NewS2 nil randidates List giving Sentence) if tonivar(Sentenee) itidsame(ComillotalestOfSenti nee as Sentence) and linearize(pair.s New I nil and NewS2 nil candidates List givitoy Iti•st()1Sentt•tico</booktitle>
<marker></marker>
<rawString>finearize(pairs nil nil and nil nil candidates List giving nil) if var(List) and saine(List (IA nil) / Case for common substring / lito.a:ahc(pairs Coninunt.NewS1 nil and (&apos;omnion.NewS2 nil randidates List giving Sentence) if tonivar(Sentenee) itidsame(ComillotalestOfSenti nee as Sentence) and linearize(pair.s New I nil and NewS2 nil candidates List givitoy Iti•st()1Sentt•tico)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Case</author>
</authors>
<title>for ranjoin litivariztloairs St nil and 52 nil candidnies Flativnt..flest. giving Sentonce) aroolol• I .Seemal.Ot her:2 to Tail giving First.ltest) if append &apos;iSeeolid.( &gt;thers giving Itcht) :itoilattailto nil ramming nil) 10 Iiiat12.Toil? rommon nil) if not :4.1,1,111e:ti11 as 111.0.112) 11&amp;quot;ad :rail I If) livad.l&apos;ail2 coon/ion flead.Rest) if s. .1;Ir(Taill to Tat 12 ra„,, non [sit) / conjoin is reversible / conjuiii(list First.Second.nil using Conjunct giving Conjoined) if nonvar(First) and nonvar(Second) and append(First Conjtmet.Second Conjoined) conjoin(list First.Second-nil using Conjunct giving Conjoined) if nonvar(Conjoined) and append(</title>
<booktitle>First (7onjunct.Second Conjoined) reinove(nilfrom List leaving List) reinove(Head.Tail from Ilead.Rest leaving List) if remove( Tail from Rest leaving List) delettifflead from nil leaving nil) delete(Head from IItiad.Tail leaving Tail) delete(Head front First .Rest leaving First.Tail) if not saille(llead as First) and delete( Head from Rest leaving Tail) Appendix B: Building the RPM Point2 End MS) where difference pairs {Start. Point 1}. {Point2. End} and {Start. End} ref oresent the</booktitle>
<marker>Case, </marker>
<rawString>/ Case for ranjoin litivariztloairs St nil and 52 nil candidnies Flativnt..flest. giving Sentonce) aroolol• I .Seemal.Ot her:2 to Tail giving First.ltest) if append &apos;iSeeolid.( &gt;thers giving Itcht) :itoilattailto nil ramming nil) 10 Iiiat12.Toil? rommon nil) if not :4.1,1,111e:ti11 as 111.0.112) 11&amp;quot;ad :rail I If) livad.l&apos;ail2 coon/ion flead.Rest) if s. .1;Ir(Taill to Tat 12 ra„,, non [sit) / conjoin is reversible / conjuiii(list First.Second.nil using Conjunct giving Conjoined) if nonvar(First) and nonvar(Second) and append(First Conjtmet.Second Conjoined) conjoin(list First.Second-nil using Conjunct giving Conjoined) if nonvar(Conjoined) and append( First (7onjunct.Second Conjoined) reinove(nilfrom List leaving List) reinove(Head.Tail from Ilead.Rest leaving List) if remove( Tail from Rest leaving List) delettifflead from nil leaving nil) delete(Head from IItiad.Tail leaving Tail) delete(Head front First .Rest leaving First.Tail) if not saille(llead as First) and delete( Head from Rest leaving Tail) Appendix B: Building the RPM Point2 End MS) where difference pairs {Start. Point 1}. {Point2. End} and {Start. End} ref oresent the left cialtext, the right context and the sentence string respectively. The concatenation routine buildm000string is just :-builihnonostring(Start Pointl plus NonTerminal Point2 End MS) if append(Pointl Left Start) and append(Point2 Right End) and append(Lelt NonTerminalRight MS)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>