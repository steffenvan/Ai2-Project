<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002173">
<title confidence="0.9901265">
Extraction of V-N-Collocations from Text Corpora:
A Feasibility Study for German
</title>
<author confidence="0.976431">
Elisabeth Breidt â€¢
</author>
<affiliation confidence="0.8556795">
Seminar fur Sprachwissenschaft
University of Tubingen
</affiliation>
<address confidence="0.480185">
Kleine Wilhelmstr. 113, D-72074 Tiibingen
</address>
<email confidence="0.458637">
breidttuarbuckle.sns.neuphilologie.uni-tuebingen.de
</email>
<sectionHeader confidence="0.65227" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996840428571429">
The usefulness of a statistical approach suggested by Church and Hanks
(1989) is evaluated for the extraction of verb-noun ( V-N) collocations from Ger-
man text corpora. Some motivations for the extraction of V-N collocations from
corpora are given and a couple of differences concerning the German language
are mentioned that have implications on the applicability of extraction methods
developed for English. We present precision and recall results for V-N collo-
cations with support verbs and discuss the consequences for further work on
the extraction of collocations from German corpora. Depending on the goal to
be achieved, emphasis can be put on a high recall for lexicographic purposes
or on high precision for automatic lexical acquisition, in each case leading to
a decrease of the corresponding other variable. Low recall can still be accept-
able if very large corpora (i.e. 50 - 100 million words) are available or if corpora
are used for special domains in addition to the data found in machine readable
(collocation) dictionaries.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999122807692308">
Collocations present an area that is important both for lexicography to improve their
coverage in modern dictionaries as well as for lexical acquisition in computational
linguistics, where the goal is to build either large reusable lexical databases (LDBs) or
specific lexica for specialized N LP-applications. We have tested the statistical approach
Mutual Information (MI), brought up by Church and Hanks (1989) for linguistics, for
a (semi- )automatic extraction of verb-noun (V-N) collocations from untag,ged German
text corpora. We try to answer the question how much can be done with an untagged
corpus and what might be gained by lemmatizing, POS-tagging or even superficial
parsing.
Choueka (1988) describes how to automatically extract word combinations from
English corpora as a preselection of collocation candidates to ease a lexicographer&apos;s
search for collocations. He only uses quantitative selection criteria, no statistical ones,
his main extraction criterion being frequency with a lower threshold of at least one
occurrence of the collocation in one million words. He mentions plans to define a
&apos;My thanks go to the ldS that made the two corpora available for research purposes, to Angelika
Storrer for her steady encouragement and many fruitful discussions, and to Mats Rooth and Matthias
Heyn who introduced me to the corpora tools. I am also greatful to the anonymous reviewers for their
helpful comments and constructive criticism.
&apos;binding degree on how strong the words of a collocation attract each other, which
would be similar in spirit to what is calculated with MI. The work described in Smadja
and McKeown (1990) arid Smaclja (1991a.b) is along the same lines as ours, though he
uses a different statistical calculation, a z-score, and tagged, lemmatized corpora. Some
properties specific to German, however, lead to a type of problem that needs different
treatment (section 3.3). Calzolari, Hindi (1990) use MI to extract compounds, fixed
expressions and collocations from an Italian corpus, but to our knowledge have not
evaluated their results so far.
</bodyText>
<sectionHeader confidence="0.958629" genericHeader="method">
2 Domain of Investigation
</sectionHeader>
<subsectionHeader confidence="0.958113">
2.1 What Do We Mean by &apos;Collocation&apos;?
</subsectionHeader>
<bodyText confidence="0.999608142857143">
Collocations in the sense of &apos;frequently cooccurring words&apos; can quite easily be extracted
from corpora by statistic means. From a linguistic point of view, however, a more re-
stricted use of the term is preferable which takes into account the difference between
what Sinclair (196(i) called casual vs. sig-nificant collocations. Casual word combina-
tions show a normal, free syntaginatic behaviour. In this paper, collocations shall refer
only to word combinations that have a certain affinity to each other in that they follow
combinatory restrictions not explainable with syntactic and semantic principles (e.g.
hammer a nail into sth. rather than &apos;beat a nail into sth.).
For collocations that are based on a verb and a. noun (preferably an object argument,
sometimes however the subject of an intransitive verb), three types of V-N combina-
tions are distinguished for German in the literature: verbal phrasemes (idioms) (e.g.
Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos
1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al.
(1992:7) and Barkema (1989:24) point out, the differences between these three types
are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations
from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not
distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combina-
tions with support verbs where the noun has lost its original meaning and which belong
to phrasemes (e.g. to take a fancy), and iii) collocational combinations of support verbs
with concrete or non-predicative nouns (e.g. to take a seat); we will refer to all these
cases as V-N collocations.
</bodyText>
<subsectionHeader confidence="0.996107">
2.2 Why V-N Collocations?
</subsectionHeader>
<bodyText confidence="0.999977">
Collocations are well suited for statistical corpora studies. The semantics of a colloca-
tion in the narrower sense according to Fleischer (1982:63f) is &amp;quot;given by the individual
semantics of its components, its meaning differs however in an unpredictable way from
the pure sum of its parts. A substantial cause for this unpredictable difference is the
frequency of occurrence and the probability with which the occurrence of one compo-
nent determines the occurrence of the other&apos; (our translation). The unpredictability
of a collocation is thus partly caused by the high cooccurrence frequency of its com-
ponents compared to the relative frequency of the single words. This holds even more
</bodyText>
<page confidence="0.997865">
75
</page>
<bodyText confidence="0.9970883">
for SVCs and phrasernes due to their (partly) non-compositional semantics.
In German, common nouns, proper names and abbreviations of names start with
an uppercase letter (sentence beginnings are changed to lowercase in the corpus). So
the verb-noun pattern was chosen for our study instead of possible others, because the
uppercase makes it possible to extract V-N collocations even from untagged corpora
if the verb is used as the key-word. The results of extracting V-N collocations give
good indications how promising the retrieval of collocations would be with POS-tagged
corpora. Besides, N-N combinations in German are mainly restricted to proper names,
and Adj-N collocations are not as extensive in our corpus due to the small number of
frequent and interesting adjectives.
</bodyText>
<sectionHeader confidence="0.979096" genericHeader="method">
3 Resources and Methods Used in the Study
</sectionHeader>
<bodyText confidence="0.999388375">
Two untagged corpora were used for our study, kindly supplied by the &apos;Institut fiir
deutsche Sprache&apos; (41S), Mannheim: the 2.7 million words (Mannheimer Korpus
(MEI) which contains approx. 73% fiction and scientific/philosophical literature and
about 27% newspaper texts, and the &apos;Bonner Zeitungskorpus&apos; (BZK), a 3.7 million
words newspaper corpus. Except for the test how results could differ for larger corpora
described in section 4.5, where the MK I was combined with the BZK, the investigation
was based on the MN] on its own, for technical reasons and also because verbs occur
more often on average in the MK1 than in the BZK (cf. Breidt 1993).
</bodyText>
<subsectionHeader confidence="0.999689">
3.1 Statistical Method and Tools
</subsectionHeader>
<bodyText confidence="0.999741823529412">
MI is a function well suited for the statistical characterization of collocations because
it compares the joint probability p(u, I ,w2) that two words occur together within a
predefined distance with the independent probabilities p(u)i) and p(w2) that the two
words occur at all in the corpus (for a more detailed description see Church et al.
(1991:120) or Breidt (1993:18)):
Several methods are possible for the calculation of probabilities (cf. Gale and Church
1990); for our purposes we use the simplest one. where the frequency of occurrence
in the corpus is divided by the size N of the corpus, p(x) = f(x)/N. Distance will be
defined as a window-size in which bigrams are calculated.
MI does not give realistic figures for very low frequencies. If a relatively unfrequent
word occurs only once in a certain combination, the resulting very high MI value
suggests a. strong link between the words where it might well be simply by chance.
So a lower bound of at least 3 occurrences of a word pair is necessary to calculate
MI. The t-test used to check whether the difference between the probability for a.
collocational occurrence and the probability for an independent occurrence of the two
words is significant, is a standard significance test in statistics (e.g. Hatch and Farhady
1962). The statistical calculations were done as described in Church et at (1991), and
</bodyText>
<equation confidence="0.999043">
P(2 !1)
Ml(x , y) = log2
P(.7&amp;quot;)P(Y)
</equation>
<page confidence="0.75171">
76
</page>
<bodyText confidence="0.903228">
were performed together with KWIC queries and the creation of bigrams using tools
available at the &apos;Institut fiit Maschinelle Sprachverarbeitung&apos;, University of Stuttgart&apos;.
</bodyText>
<subsectionHeader confidence="0.999284">
3.2 The &apos;Standard&apos; Method
</subsectionHeader>
<bodyText confidence="0.997977611111111">
Verbs that can occur in SVes are in the centre of our study because they provide
examples for all three types of V-N collocations; besides, the chosen &apos;potential&apos; sup-
port verbs belong to the most frequent verbs in the corpus anyway. V-N collocations
were extracted for the following 16 verbs (no translations are given because they dif-
fer depending on the N argument): bleiben, bringen, erfahren, finden, geben, gehen,
gelangen, geraten, halten, kommen. nehmen, setzen, stehen, stellen, treten, ziehen.
Bigram tables of all words that occur within a certain distance of these verbs, to-
gether with their cooccurrence frequencies, form the basis for the calculation of MI.
Bigram calculations were restricted to words occurring within a 6-word window to the
left (cf. next. section), inclusive of the verb, a span which captures 95% of significant
collocations in English (Martin et al. 1983). We will refer to these with B16. For
combinations that occur at least 3 times, MI was calculated together with a t-score.
From these. candidates for V-N collocations were automatically extracted, sorted by
MI. All of these were checked by means of KWIC-listings and classified w.r.t, their col-
locational status by the author. The classification was in most cases very obvious. If a
combination potentially formed a collocation but was not used as such in the corpus it
was not counted; a couple of times, where some of the usages were indeed collocations
and others not, the decision was made in favour of the predominant case.
</bodyText>
<subsectionHeader confidence="0.997845">
3.3 Application for German Corpora: Some Problems
</subsectionHeader>
<bodyText confidence="0.999946352941177">
Some properties of the German language make the task of extracting V-N collocations
from German text corpora more difficult than for English corpora. A minor difference
concerns the strong inflection of German verbs. Whereas in English a verb lexeme
appears in 3 or 4 different forms plus one for the present participle, German verbs have
7 to 10 verb forms (without subjunctive forms) for one lexeme and additional 4 for
the present participle. This has to be considered for the evaluation of queries based on
single inflection forms, because in English more usages are covered with one verb form
than in German.
Another point concerns the variable word order in German (see Uszkoreit 1987)
which makes it more difficult, to locate the parts of a V-N collocation. In a main clause
(verb-second order), a noun preceding a. finite verb usually is the subject, but it can
also be a topicalized complement; in sentences where the main verb occurs at the end
(nonfinite verb or subordinate clause) the preceding noun is mostly a direct object or
other complement, or an adjunct. A noun to the right of a finite verb can be any of
subject, object or other argument. due to topicalization or scrambling. We restrict our
search to V-N combinations where the noun precedes the verb either directly or within
two to five words, because this at least definitely captures complements of main verbs
</bodyText>
<footnote confidence="0.6922205">
1We greatfully acknowledge that the work reported here would not have been possible without the
supplied tools and corpora.
</footnote>
<page confidence="0.997543">
77
</page>
<bodyText confidence="0.998353888888889">
in verb-final position. To find the correct argument, to the right of the verb is difficult
in an unparsecl corpus because of the variable number of intervening constituents.
As illustrated in the last paragraph the assumption that a &amp;quot;semantic agent 1...1
is principally used before the verb&amp;quot; and a &amp;quot;semantic object I...1 is used after it&amp;quot; as
described in Smadja (1991a:180) does not hold for German. Therefore, complicated
parsing is necessary to distinguish subject-verb from object-verb combinations. The
results of V-N extractions reflect this problem. In many if not in most of the uninter-
esting combinations extracted, the noun to the left of the verb is the subject rather
than a complement of the verb (cf. section 4.6).
</bodyText>
<sectionHeader confidence="0.930357" genericHeader="evaluation">
4 Evaluation of the Results
</sectionHeader>
<bodyText confidence="0.919649625">
Below, the top bigrams %vith kommen (come) are shown, and some of the nonsignificant
ones (t &lt; 1.65), to illustrate MI and t-scores. Bigrams with the infinitive form give best
results compared to other inflection forms, possibly because this form covers lst/3rd
pers. pl. present tense, the infinitive and the nonfinite main verb of complex tenses
(modals, conditional, future) at the same time. Also, the latter two always occur in
verb-final position.
N kommen Translation
(zur) Geltung k. show to advantage
</bodyText>
<listItem confidence="0.607021">
(in) Betracht kc to be considered
(in) Beriihrung k. come into contact
(zur) Anwendung k. to be used
(zu) Trinen k. come to tears
(zur) Ruhe k. get some peace
</listItem>
<table confidence="0.959842739130435">
(auf den) Gedanken k. get the idea
(in den) Himmel k. go to heaven
(zu) Hilfe k. come to aid
(zu) Wort k. get a chance to speak
Vernunft reason
(in) Frage k. to be possible
(zur) Welt k. to be born
Sie You
f(x,y) f(y) MI t-score V-N-Coll.
27 96 9.86 5.19
9 42 9.47 2.99
4 41 8.33 1.99
4 126 6.71 1.97
3 107 6.53 1.70
4 216 5.93 1.95
7 403 5.84 2.58
3 270 5.20 1.66
4 477 4.79 1.89
3 647 3.94 1.57
3 736 3.75 1.55
4 1054 3.65 1.77
4 1900 2.80 1.60
3 2414 2.04 1.17
</table>
<subsectionHeader confidence="0.928926">
4.1 Precision and Recall
</subsectionHeader>
<bodyText confidence="0.998828">
The question how much is extractable fully automatically can be answered by an eval-
uation of precision and &apos;recall&apos; of the described method as it, is done for memory tests.
Following Smadja (1991a) we define precision as the number of correctly found collo-
cations divided by the number of V-N combinations found at all. Recall reflects the
ratio of the number of correctly found collocations and the maximal number of colloca-
tions that could possibly have been found. The latter is slightly difficult to determine,
because in principle this means to know the total number of collocations occurring in
the whole corpus. Another possibility, to take all collocations that are mentioned in a
dictionary as the maximal number of valid collocations, had to be discarded: a com-
parison with Agricola (MO) or Drosdowski (1970) is not really possible because the
</bodyText>
<page confidence="0.995961">
78
</page>
<bodyText confidence="0.9998923">
collocations found in the corpus are not a subset of those mentioned in the dictionaries.
Only 22 of the 43 collocations found with the lemma bring- in the MK] (816) belong
to the 135 combinations mentioned in the lexical entry for bringen in Agricola (1970).
Of the remaining 21 in the NIK1, 9 can be found in the corresponding noun entries,
and 12 do not appear at all though they are &apos;significant&apos; collocations, e.g. Klarheit
bringer! (clarify). zur Entfaltung hr. (develop), zur 1Virkung hr. (bring the effect), in
Schwierigkeiten hr. (create difficulties), ins Gespra:ch hr. (bring into discussion). Thus,
we decided to use instead the number of collocations with the infinitive as determined
by the standard method (BI6) as the basis for recall comparisons, i.e. 100% recall is
set to this number.
</bodyText>
<subsectionHeader confidence="0.921442">
4.2 Results of the Standard Method
</subsectionHeader>
<bodyText confidence="0.9999715">
Frequencies for the infinitives of the 16 verbs range from 832 (kommen) to 117 (gelan-
gen). The number of V-N combinations varies from 46 (bringen) to 6 (erfahren, gelan-
gen, geraten, trete)* precision from 100% (geraten, ziehen) to 33% (erfahren). Average
figures are presented in table 1 below, labeled 1316 Inf. If non-significant combinations
are omitted with a t-test (BI6/t Inf), the average of collocations among the extracted
V-N combinations is only 95.8% of those found without a significance boundary, but
precision rises slightly. With a threshold of MI &gt; 6, precision would go up to 82.1%
with a still acceptable loss in recall of approximately 10%.
</bodyText>
<subsectionHeader confidence="0.999711">
4.3 Experiment 1: Variation of Window-Size
</subsectionHeader>
<bodyText confidence="0.999818">
To see whether the collocational nouns could be better located directly to the left of the
verb rather than within a couple of words, we reduced window-size to 3 words including
the verb (this allows one word in between, e.g. zu&apos; (to) in infinitival constructions).
As shown in table 1 for B13 Inf, precision rises about 10%, but with a recall of 72.1%,
because those collocations where other arguments or post modifiers occur between N
and V are no longer captured. Taking again only significant combinations (BI3/t
Inf) precision rises again slightly. This leads to the conclusion that for German, unless
syntactic relations can be determined, a smaller window is preferable to improve a
correct detection of preceding object arguments and to exclude unrelated nouns.
</bodyText>
<tableCaption confidence="0.999541">
Table 1: Average figures for varying window-size and lemmatizing
</tableCaption>
<table confidence="0.9996565">
Bigrams 0 V-N 0 Collocations Precision % Recall %
B16 Inc 21.5 13.5 66.3 100 (def.)
B16/t Inf 18.25 12.9 71.6 95.8
B13 Inf 12.4 9.5 81.2 72.1
B13/t Inf 11.5 9.1 83.1 70.0
B13 Lemma 29.9 16.1 59.8 114.7
</table>
<subsectionHeader confidence="0.993324">
4.4 Experiment 2: Simulating Lemmatizing
</subsectionHeader>
<bodyText confidence="0.999959666666667">
Because no lemmatizing program was available we used an additional program on top
of the bigram calculations for the inflected forms. In order to keep the amount of V-N
combinations within a magnitude that could still be checked manually for correctness,
</bodyText>
<page confidence="0.996574">
79
</page>
<bodyText confidence="0.999922866666667">
we restricted search to a 3-word window to the left. V-N combinations that occurred
less than two times with a single inflection form of the verb were sorted out. The
inflection forms for the infinitive (also 1st/3rd pers. pl.), 3rd pers. sg. present and past
tense, lst./3rd pers.. pl. past and past participle were added up; 1st. pers. sg. and 2nd
pers. sg./pl. were so rare that they could be ignored. The average results are again
presented in table 1 (BI3 lemma); the number of extracted collocations is maximal, but
precision is the lowest of all. Precision ranges from 33.3% (gehen) to 88.2% (setzen),
recall from 50% (erfahren) to 166.7% (setzen). Recall figures are above 100% because
the absolute number of collocations found is higher than for 316 Inf, the basis for
the recall calculations. Regarding lemmatization our study shows that one gets more
collocations, but at the expense of more uninteresting combinations as well. One
explanation for this is that 3rd pers. sg. present/past and lstI3rd pers. pl. past only
occur to the right of their noun argument in subordinate clauses, whereas 1st/3rd pers.
pl. present are identical with the nonfinite form which additionally occurs in verb-final
position in main clauses with a finite auxiliary or modal verb and in infinitive clauses.
</bodyText>
<subsectionHeader confidence="0.937038">
4.5 Experiment 3: Varying Corpus Size
</subsectionHeader>
<bodyText confidence="0.998550444444445">
For infinitive bringen and lexeme bring-, V-N combinations were also calculated with
1316 for a larger corpus consisting of the NIN1 and BZK together. For MK1 alone, 31 of
46 combinations are collocations, a precision of 67.4% (recall is set to 100%). With the
larger corpus the number of found V-N collocations is more than twice as big, with only
a slightly lower precision2. Thus, larger corpora would improve results considerably.
Results for the lexeme with the highest number of collocations at all (73) are along
the same lines; however almost every second V-N combination is no V-N collocation
in the sense defined in section 2, i.e. results are much better overall for the infinitive
separately. The complete data for bringen are listed below.
</bodyText>
<tableCaption confidence="0.9763">
Table 2: Variations for the verb bringen
</tableCaption>
<table confidence="0.999600777777778">
Bigrams f(V) V-N Coll. Precision % Recall %
BIG Inf 550 46 31 67.4 100 (def.)
BI6/t Inf 550 44 31 70.5 100
BIG MK1-1-BZE Inf. 1065 97 63 65.0 203
BI3 luf 550 33 28 84.9 90.3
B13/1 Inf 550 31 27 87.1 87.1
B16 Lemma 1508 74 43 58.0 138.7
BIG 1â– 11,Z1-1-BZE Lemma 3145 142 73 51.4 235.5
BI3 Lemma 1508 46 37 80.4 119.4
</table>
<subsectionHeader confidence="0.753368">
4.6 Experiment 4: Simulating Syntactic Tagging
</subsectionHeader>
<bodyText confidence="0.821557166666667">
In order to see how much the precision could possibly be improved by determining
syntactic relations as done by Smadja (1991a,b) for English, we conducted another test
with bringen, where we manually excluded those uninteresting extracted combinations
in which the nouns were in fact used in subject position of the verb. The results for
2The latest runs with the combined corpus showed that for the infinitives precision even rises
slightly on average (82.1%) while recall is almost doubled (134,9%), compared to BI3 Inf in table 1.
</bodyText>
<page confidence="0.99515">
80
</page>
<bodyText confidence="0.999638">
the two window-sizes, infinitive and lexeme, are shown in table 3. Precision would rise
up to 100% with still a good recall of S7.1% if one could consider syntactic relations for
the extraction of V-N collocations. The best recall of 43 collocations within 5 words
to the left of the lexeme would then still correspond to 78.2% precision as compared
to 58% if subjects cannot be detected. These results point in the same direction as
Sma.dja&apos;s who reports an improvement from 40 to 80% precision if s:vntactic relations
are considered, with a 94% recall of all collocations that had been found regardless
of syntactic relations. However, this cannot as easily be achieved in a large scale for
German due to the complicated parsing techniques necessary for the varying word
order.
</bodyText>
<tableCaption confidence="0.992856">
Table 3: Results for bringen if subject nouns are excluded manually
</tableCaption>
<table confidence="0.9985966">
Bigrarns V.N Coll. Precision % Recall %
B13/t Inf (no subj) 27 27 100 87.1
B16/1, la (no subj) 39 31 79.5 100 (def.)
BI3 Lemma (no subj) 90 37 92.5 119.4
B16 Lemma (no subj) 55 43 78.2 138.7
</table>
<sectionHeader confidence="0.894969" genericHeader="conclusions">
5 Conclusions and Outlook
</sectionHeader>
<figureCaption confidence="0.997733">
Figure 1: Results for bringen
</figureCaption>
<bodyText confidence="0.99960375">
The graphics in figure 1 visualize the results of the experiments for the verb bringen;
the left y-axis shows recall and precision in per cent, the one to the right the number
of counted V-N collocations. The left graph compares the results for the infinitive,
the right one those for the lexeme. From left to right are shown: 3-word window
</bodyText>
<figure confidence="0.987043333333333">
30 31 61 61 61+ 3L 31.(oS) 6L 6L+
Prec./Recall %
290
Coll. counts
200
150
</figure>
<page confidence="0.994332">
81
</page>
<bodyText confidence="0.999992444444444">
with t-threshold (3tI), 3-word window without t (31), 6-word window with t (GU)
and without (61), 6-word window for the enlarged corpus (61+). 31, stands for &apos;3-
word window, lexeme&apos;, 3L(oS) means the exclusion of subject nouns; 6L and 6L+ are
analogous to the infinitive version.
The result for `6I+ implies that larger corpora will improve recall without a serious
decline of precision compared to the same method used with the smaller corpus (61; see
also footnote 2). Whether the recall number should at the cost of a bad precision be
pushed even higher by calculating MI for lexemes (6L vs. 6L+) can be decided in view
of the application the data are extracted for. Once the number of V-N collocations
is generally big enough, higher significance and MI thresholds can be used in order
to improve precision again. MI sorts the extracted combinations in such a way that
the collocations are the better the higher the MI-score is (with a few exceptions which
often reflect highly significant, but linguistically uninteresting word combinations from
one of the texts; this could hopefully be avoided with a more balanced corpus).
In general, a trade-off has to be found between the number of extracted collocations
(recall) and the number of uninteresting items in between (precision), depending on
the application. The described approach seems to be a good method for corpora with
texts from restricted domains, where a special terminology is used which will thus show
up strongly against &apos;normal&apos; combinations.
Very high precision rates, which are an indispensible requirement for lexical acqui-
sition, can only realistically be envisaged for German with parsed corpora (3L(oS) has
the best recallâ€”precision ratio in figure 1); otherwise the main advantage lies in a better
lexicographical support, which should not be underestimated both for manually built
NLP lexica and for printed dictionaries. Lemmatizing does not seem to be always
useful, as a comparison of 61+ and 3L shows. Possibly the data are blurred because as
mentioned on p. 6 the various inflection forms are distributed differently in verb-final
and verb-second clauses, at least in the investigated corpus. Restricted lemmatizing
with infinitive (1st/3rd pers. pl.) and past participle for a search to the left, and with
3rd pers sg. pres./past and istOrd pers. pl. past for a search to the right (which is
problematic, though) promises to give more precise results, as long as search strategies
cannot take into account the syntactic structure of a sentence.
Work is currently in progress to calculate trigrams to check for prepositions in SVCs
or for specific (or no) determiners for phrasemes. This will give indications to distin-
guish SVCs and lexicalized, phraseological SVCs from other collocations. In addition,
we plan to consider the variation in span position of the noun within the searched
window in order to distinguish fixed phrasemes from flexible ones.
</bodyText>
<sectionHeader confidence="0.998199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.94877475">
Agricola, E., H. Garner, R.. Kamer (eds.) (1962/1970). Miner und Wendungen. Worterbuch
zum deutschen Sprachgebrauch. Leipzig: Verlag Enzyklopadie; MÃ¼nchen.
Barkema, H. (1989). Morphosyntactic flexibility: the other side of the idiomaticity coin. In:
Everaert, M., E. van der Linden (eds.). Proc. of the lst Tilburg Workshop on Idioms. 23-40.
</reference>
<page confidence="0.981539">
82
</page>
<reference confidence="0.998980842105263">
Breidt, E. (1993). Extraktiou von Verb-Nomen-Verbindungen aus dem Mannheimer Korpus
1. SIS-Report 03-93. University of Tiibingen.
Brundage, J., M. Kresse, U. SchwaII, A. Storrer (1992). Multiword lexemes: a monolin-
gual and contrastive typology for AIP and MT. IWBS-Report 232, September 1992. IBM
Germany, Scientific Centre Heidelberg.
Calzolari, N., R. Hindi (1990). Acquisition of lexical information from a large textual italian
corpus. 13th COLING 1990, Helsinki. 54-59.
Choueka, Y. (198S). Looking for needles in a haystack, or: locating interesting collocational
expressions in large textual databases. Proceedings of the NAO. 609-623.
Church, K. W., P. Hanks (1989). Word Association Norms, Mutual Information and Lexi-
cography. 27th ACL, Vancouver. 76-83.
Church, K. W., W. A. Gale, P. Hanks, D. M. Hindle (1991). Using statistics in lexical
analysis. In: Zernik, U. (ed.). Lexical acquisition: exploring on-line resources to build a
lexicon. Hillsdale, NJ.
Danlos, L. (1992). Support verb constructions. Linguistic properties, representation, trans-
lation. Journal of French Linguistic Study, Vol. 2, No. 1. CUP.
Drosdowski, G. et al. (eds.) (1970). sl Duden Stilworterbuch der deutschen Sprache: Die
Verwendung der Wailer int Satz. Orb completely revised and extended edition. Mannheim.
Fleischer, W. (1982). Phraseologie der deutsche]] Gegenwartssprache. Leipzig.
Gale, W., K. W. Church (1990). Whats wrong with adding one? IEEE Transactions on
Acoustics, Speech and Signal Processing.
Hatch, E., H. Farhady (1982). Research design and statistics for applied linguistics. Rowley.
Hausmann, F. J. (1989). Le dictionnaire de collocations. In: Hausmann, F. 3. et al. (eds.).
Dictionaries: an international handbook for lexicography. Part 1. HSK 5.1. 1010-1019.
Martin, W., B. Al, P. van Sterkenburg (1983). On the processing of a text corpus. In:
Hartmann, R. R. K. (ed.). Lexicography: principles and practice. London. 77-87.
v.Polenz, P. (1989). Funktionsverbgefiige im allgemeinen einsprachigen Worterbuch. In:
Hausmann, F. J. et al. (eds.). Dictionaries: an international handbook for lexicography.
Part I. IISK 5.1. 882-887.
Sinclair, J. M. (1966). Beginning the study of lexis. In: Bazell, C. E. et al. (eds.) (1966). in
memory of J. R. Firth. London. 410-430.
Smadja, F. A., K. R.. McKeown (1990). Automatically extracting and representing colloca-
tions for language generation. 28th ACL 1990. 252-259.
Smadja, F. A. (1991a). Macrocoding the lexicon with co-occurrence knowledge. In: Zernik,
U. (ed.). Lexical acquisition: exploring on-line resources to build a lexicon. Hillsdale, NJ.
Smadja, F. A. (1991b). From n-grams to collocations: an evaluation of Xtract. 29th ACL,
Berkeley, CA. 279-284.
Uszkoreit, H. (1987). Word order and constituent structure. CSLI Lecture Notes 8.
</reference>
<page confidence="0.999298">
83
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.568308">
<title confidence="0.9980435">Extraction of V-N-Collocations from Text Corpora: A Feasibility Study for German</title>
<author confidence="0.8183015">Elisabeth Breidt Seminar fur</author>
<affiliation confidence="0.993988">University of</affiliation>
<address confidence="0.908218">Kleine Wilhelmstr. 113, D-72074</address>
<email confidence="0.995325">breidttuarbuckle.sns.neuphilologie.uni-tuebingen.de</email>
<abstract confidence="0.998610933333333">The usefulness of a statistical approach suggested by Church and Hanks (1989) is evaluated for the extraction of verb-noun ( V-N) collocations from Gertext corpora. Some motivations for the extraction of V-N collocations corpora are given and a couple of differences concerning the German language are mentioned that have implications on the applicability of extraction methods developed for English. We present precision and recall results for V-N collocations with support verbs and discuss the consequences for further work on the extraction of collocations from German corpora. Depending on the goal to be achieved, emphasis can be put on a high recall for lexicographic purposes or on high precision for automatic lexical acquisition, in each case leading to a decrease of the corresponding other variable. Low recall can still be acceptif very large (i.e. 50 million words) are available or if corpora are used for special domains in addition to the data found in machine readable (collocation) dictionaries.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>E Agricola</author>
<author>H Garner</author>
<author>R</author>
</authors>
<booktitle>Miner und Wendungen. Worterbuch zum deutschen Sprachgebrauch.</booktitle>
<editor>Kamer (eds.) (1962/1970).</editor>
<publisher>Verlag Enzyklopadie; MÃ¼nchen.</publisher>
<location>Leipzig:</location>
<marker>Agricola, Garner, R, </marker>
<rawString>Agricola, E., H. Garner, R.. Kamer (eds.) (1962/1970). Miner und Wendungen. Worterbuch zum deutschen Sprachgebrauch. Leipzig: Verlag Enzyklopadie; MÃ¼nchen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Barkema</author>
</authors>
<title>Morphosyntactic flexibility: the other side of the idiomaticity coin.</title>
<date>1989</date>
<booktitle>Proc. of the lst Tilburg Workshop on Idioms.</booktitle>
<pages>23--40</pages>
<editor>In: Everaert, M., E. van der Linden (eds.).</editor>
<contexts>
<context position="4580" citStr="Barkema (1989" startWordPosition="699" endWordPosition="700">er in that they follow combinatory restrictions not explainable with syntactic and semantic principles (e.g. hammer a nail into sth. rather than &apos;beat a nail into sth.). For collocations that are based on a verb and a. noun (preferably an object argument, sometimes however the subject of an intransitive verb), three types of V-N combinations are distinguished for German in the literature: verbal phrasemes (idioms) (e.g. Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos 1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al. (1992:7) and Barkema (1989:24) point out, the differences between these three types are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to take a fancy), and iii) collocational combinations of support verbs with concrete or non-predicative nouns (e.g. to take a seat); we will refer to all these cases as V-</context>
</contexts>
<marker>Barkema, 1989</marker>
<rawString>Barkema, H. (1989). Morphosyntactic flexibility: the other side of the idiomaticity coin. In: Everaert, M., E. van der Linden (eds.). Proc. of the lst Tilburg Workshop on Idioms. 23-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Breidt</author>
</authors>
<title>Extraktiou von Verb-Nomen-Verbindungen aus dem Mannheimer Korpus 1. SIS-Report 03-93.</title>
<date>1993</date>
<institution>University of Tiibingen.</institution>
<contexts>
<context position="7386" citStr="Breidt 1993" startWordPosition="1144" endWordPosition="1145">r study, kindly supplied by the &apos;Institut fiir deutsche Sprache&apos; (41S), Mannheim: the 2.7 million words (Mannheimer Korpus (MEI) which contains approx. 73% fiction and scientific/philosophical literature and about 27% newspaper texts, and the &apos;Bonner Zeitungskorpus&apos; (BZK), a 3.7 million words newspaper corpus. Except for the test how results could differ for larger corpora described in section 4.5, where the MK I was combined with the BZK, the investigation was based on the MN] on its own, for technical reasons and also because verbs occur more often on average in the MK1 than in the BZK (cf. Breidt 1993). 3.1 Statistical Method and Tools MI is a function well suited for the statistical characterization of collocations because it compares the joint probability p(u, I ,w2) that two words occur together within a predefined distance with the independent probabilities p(u)i) and p(w2) that the two words occur at all in the corpus (for a more detailed description see Church et al. (1991:120) or Breidt (1993:18)): Several methods are possible for the calculation of probabilities (cf. Gale and Church 1990); for our purposes we use the simplest one. where the frequency of occurrence in the corpus is d</context>
</contexts>
<marker>Breidt, 1993</marker>
<rawString>Breidt, E. (1993). Extraktiou von Verb-Nomen-Verbindungen aus dem Mannheimer Korpus 1. SIS-Report 03-93. University of Tiibingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Brundage</author>
<author>M Kresse</author>
<author>U SchwaII</author>
<author>A Storrer</author>
</authors>
<title>Multiword lexemes: a monolingual and contrastive typology for AIP and MT.</title>
<date>1992</date>
<tech>IWBS-Report 232,</tech>
<institution>IBM Germany, Scientific Centre Heidelberg.</institution>
<contexts>
<context position="4412" citStr="Brundage et al. 1992" startWordPosition="672" endWordPosition="675"> Casual word combinations show a normal, free syntaginatic behaviour. In this paper, collocations shall refer only to word combinations that have a certain affinity to each other in that they follow combinatory restrictions not explainable with syntactic and semantic principles (e.g. hammer a nail into sth. rather than &apos;beat a nail into sth.). For collocations that are based on a verb and a. noun (preferably an object argument, sometimes however the subject of an intransitive verb), three types of V-N combinations are distinguished for German in the literature: verbal phrasemes (idioms) (e.g. Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos 1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al. (1992:7) and Barkema (1989:24) point out, the differences between these three types are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to </context>
</contexts>
<marker>Brundage, Kresse, SchwaII, Storrer, 1992</marker>
<rawString>Brundage, J., M. Kresse, U. SchwaII, A. Storrer (1992). Multiword lexemes: a monolingual and contrastive typology for AIP and MT. IWBS-Report 232, September 1992. IBM Germany, Scientific Centre Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Calzolari</author>
<author>R Hindi</author>
</authors>
<title>Acquisition of lexical information from a large textual italian corpus.</title>
<date>1990</date>
<booktitle>13th COLING</booktitle>
<pages>54--59</pages>
<location>Helsinki.</location>
<marker>Calzolari, Hindi, 1990</marker>
<rawString>Calzolari, N., R. Hindi (1990). Acquisition of lexical information from a large textual italian corpus. 13th COLING 1990, Helsinki. 54-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
</authors>
<title>Looking for needles in a haystack, or: locating interesting collocational expressions in large textual databases.</title>
<date></date>
<booktitle>Proceedings of the NAO.</booktitle>
<pages>609--623</pages>
<marker>Choueka, </marker>
<rawString>Choueka, Y. (198S). Looking for needles in a haystack, or: locating interesting collocational expressions in large textual databases. Proceedings of the NAO. 609-623.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<date>1989</date>
<booktitle>Word Association Norms, Mutual Information and Lexicography. 27th ACL,</booktitle>
<pages>76--83</pages>
<location>Vancouver.</location>
<contexts>
<context position="1728" citStr="Church and Hanks (1989)" startWordPosition="252" endWordPosition="255">eptable if very large corpora (i.e. 50 - 100 million words) are available or if corpora are used for special domains in addition to the data found in machine readable (collocation) dictionaries. 1 Introduction Collocations present an area that is important both for lexicography to improve their coverage in modern dictionaries as well as for lexical acquisition in computational linguistics, where the goal is to build either large reusable lexical databases (LDBs) or specific lexica for specialized N LP-applications. We have tested the statistical approach Mutual Information (MI), brought up by Church and Hanks (1989) for linguistics, for a (semi- )automatic extraction of verb-noun (V-N) collocations from untag,ged German text corpora. We try to answer the question how much can be done with an untagged corpus and what might be gained by lemmatizing, POS-tagging or even superficial parsing. Choueka (1988) describes how to automatically extract word combinations from English corpora as a preselection of collocation candidates to ease a lexicographer&apos;s search for collocations. He only uses quantitative selection criteria, no statistical ones, his main extraction criterion being frequency with a lower threshol</context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>Church, K. W., P. Hanks (1989). Word Association Norms, Mutual Information and Lexicography. 27th ACL, Vancouver. 76-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>W A Gale</author>
<author>P Hanks</author>
<author>D M Hindle</author>
</authors>
<title>Using statistics in lexical analysis.</title>
<date>1991</date>
<editor>In: Zernik, U. (ed.).</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="7770" citStr="Church et al. (1991" startWordPosition="1204" endWordPosition="1207">escribed in section 4.5, where the MK I was combined with the BZK, the investigation was based on the MN] on its own, for technical reasons and also because verbs occur more often on average in the MK1 than in the BZK (cf. Breidt 1993). 3.1 Statistical Method and Tools MI is a function well suited for the statistical characterization of collocations because it compares the joint probability p(u, I ,w2) that two words occur together within a predefined distance with the independent probabilities p(u)i) and p(w2) that the two words occur at all in the corpus (for a more detailed description see Church et al. (1991:120) or Breidt (1993:18)): Several methods are possible for the calculation of probabilities (cf. Gale and Church 1990); for our purposes we use the simplest one. where the frequency of occurrence in the corpus is divided by the size N of the corpus, p(x) = f(x)/N. Distance will be defined as a window-size in which bigrams are calculated. MI does not give realistic figures for very low frequencies. If a relatively unfrequent word occurs only once in a certain combination, the resulting very high MI value suggests a. strong link between the words where it might well be simply by chance. So a l</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>Church, K. W., W. A. Gale, P. Hanks, D. M. Hindle (1991). Using statistics in lexical analysis. In: Zernik, U. (ed.). Lexical acquisition: exploring on-line resources to build a lexicon. Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Danlos</author>
</authors>
<title>Support verb constructions. Linguistic properties, representation, translation.</title>
<date>1992</date>
<journal>Journal of French Linguistic Study,</journal>
<volume>2</volume>
<publisher>CUP.</publisher>
<contexts>
<context position="4478" citStr="Danlos 1992" startWordPosition="683" endWordPosition="684">is paper, collocations shall refer only to word combinations that have a certain affinity to each other in that they follow combinatory restrictions not explainable with syntactic and semantic principles (e.g. hammer a nail into sth. rather than &apos;beat a nail into sth.). For collocations that are based on a verb and a. noun (preferably an object argument, sometimes however the subject of an intransitive verb), three types of V-N combinations are distinguished for German in the literature: verbal phrasemes (idioms) (e.g. Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos 1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al. (1992:7) and Barkema (1989:24) point out, the differences between these three types are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to take a fancy), and iii) collocational combinations of support verb</context>
</contexts>
<marker>Danlos, 1992</marker>
<rawString>Danlos, L. (1992). Support verb constructions. Linguistic properties, representation, translation. Journal of French Linguistic Study, Vol. 2, No. 1. CUP.</rawString>
</citation>
<citation valid="true">
<title>sl Duden Stilworterbuch der deutschen Sprache: Die Verwendung der Wailer int Satz. Orb completely revised and extended edition.</title>
<date>1970</date>
<editor>Drosdowski, G. et al. (eds.)</editor>
<location>Mannheim.</location>
<contexts>
<context position="14851" citStr="(1970)" startWordPosition="2400" endWordPosition="2400">ision as the number of correctly found collocations divided by the number of V-N combinations found at all. Recall reflects the ratio of the number of correctly found collocations and the maximal number of collocations that could possibly have been found. The latter is slightly difficult to determine, because in principle this means to know the total number of collocations occurring in the whole corpus. Another possibility, to take all collocations that are mentioned in a dictionary as the maximal number of valid collocations, had to be discarded: a comparison with Agricola (MO) or Drosdowski (1970) is not really possible because the 78 collocations found in the corpus are not a subset of those mentioned in the dictionaries. Only 22 of the 43 collocations found with the lemma bring- in the MK] (816) belong to the 135 combinations mentioned in the lexical entry for bringen in Agricola (1970). Of the remaining 21 in the NIK1, 9 can be found in the corresponding noun entries, and 12 do not appear at all though they are &apos;significant&apos; collocations, e.g. Klarheit bringer! (clarify). zur Entfaltung hr. (develop), zur 1Virkung hr. (bring the effect), in Schwierigkeiten hr. (create difficulties),</context>
</contexts>
<marker>1970</marker>
<rawString>Drosdowski, G. et al. (eds.) (1970). sl Duden Stilworterbuch der deutschen Sprache: Die Verwendung der Wailer int Satz. Orb completely revised and extended edition. Mannheim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Fleischer</author>
</authors>
<title>Phraseologie der deutsche]] Gegenwartssprache.</title>
<date>1982</date>
<location>Leipzig.</location>
<contexts>
<context position="5365" citStr="Fleischer (1982" startWordPosition="824" endWordPosition="825">though our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to take a fancy), and iii) collocational combinations of support verbs with concrete or non-predicative nouns (e.g. to take a seat); we will refer to all these cases as V-N collocations. 2.2 Why V-N Collocations? Collocations are well suited for statistical corpora studies. The semantics of a collocation in the narrower sense according to Fleischer (1982:63f) is &amp;quot;given by the individual semantics of its components, its meaning differs however in an unpredictable way from the pure sum of its parts. A substantial cause for this unpredictable difference is the frequency of occurrence and the probability with which the occurrence of one component determines the occurrence of the other&apos; (our translation). The unpredictability of a collocation is thus partly caused by the high cooccurrence frequency of its components compared to the relative frequency of the single words. This holds even more 75 for SVCs and phrasernes due to their (partly) non-com</context>
</contexts>
<marker>Fleischer, 1982</marker>
<rawString>Fleischer, W. (1982). Phraseologie der deutsche]] Gegenwartssprache. Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K W Church</author>
</authors>
<title>Whats wrong with adding one?</title>
<date>1990</date>
<journal>IEEE Transactions on Acoustics, Speech and Signal Processing.</journal>
<contexts>
<context position="7890" citStr="Gale and Church 1990" startWordPosition="1221" endWordPosition="1224">for technical reasons and also because verbs occur more often on average in the MK1 than in the BZK (cf. Breidt 1993). 3.1 Statistical Method and Tools MI is a function well suited for the statistical characterization of collocations because it compares the joint probability p(u, I ,w2) that two words occur together within a predefined distance with the independent probabilities p(u)i) and p(w2) that the two words occur at all in the corpus (for a more detailed description see Church et al. (1991:120) or Breidt (1993:18)): Several methods are possible for the calculation of probabilities (cf. Gale and Church 1990); for our purposes we use the simplest one. where the frequency of occurrence in the corpus is divided by the size N of the corpus, p(x) = f(x)/N. Distance will be defined as a window-size in which bigrams are calculated. MI does not give realistic figures for very low frequencies. If a relatively unfrequent word occurs only once in a certain combination, the resulting very high MI value suggests a. strong link between the words where it might well be simply by chance. So a lower bound of at least 3 occurrences of a word pair is necessary to calculate MI. The t-test used to check whether the d</context>
</contexts>
<marker>Gale, Church, 1990</marker>
<rawString>Gale, W., K. W. Church (1990). Whats wrong with adding one? IEEE Transactions on Acoustics, Speech and Signal Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hatch</author>
<author>H Farhady</author>
</authors>
<title>Research design and statistics for applied linguistics.</title>
<date>1982</date>
<location>Rowley.</location>
<marker>Hatch, Farhady, 1982</marker>
<rawString>Hatch, E., H. Farhady (1982). Research design and statistics for applied linguistics. Rowley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Hausmann</author>
</authors>
<title>Le dictionnaire de collocations.</title>
<date>1989</date>
<booktitle>Dictionaries: an international handbook for lexicography. Part 1. HSK</booktitle>
<volume>5</volume>
<pages>1010--1019</pages>
<editor>In: Hausmann, F. 3. et al. (eds.).</editor>
<contexts>
<context position="4533" citStr="Hausmann 1989" startWordPosition="691" endWordPosition="692">nations that have a certain affinity to each other in that they follow combinatory restrictions not explainable with syntactic and semantic principles (e.g. hammer a nail into sth. rather than &apos;beat a nail into sth.). For collocations that are based on a verb and a. noun (preferably an object argument, sometimes however the subject of an intransitive verb), three types of V-N combinations are distinguished for German in the literature: verbal phrasemes (idioms) (e.g. Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos 1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al. (1992:7) and Barkema (1989:24) point out, the differences between these three types are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to take a fancy), and iii) collocational combinations of support verbs with concrete or non-predicative nouns (e.g. to take </context>
</contexts>
<marker>Hausmann, 1989</marker>
<rawString>Hausmann, F. J. (1989). Le dictionnaire de collocations. In: Hausmann, F. 3. et al. (eds.). Dictionaries: an international handbook for lexicography. Part 1. HSK 5.1. 1010-1019.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Martin</author>
<author>B Al</author>
<author>P van Sterkenburg</author>
</authors>
<title>On the processing of a text corpus.</title>
<date>1983</date>
<booktitle>Lexicography: principles and practice. London.</booktitle>
<pages>77--87</pages>
<editor>In: Hartmann, R. R. K. (ed.).</editor>
<marker>Martin, Al, van Sterkenburg, 1983</marker>
<rawString>Martin, W., B. Al, P. van Sterkenburg (1983). On the processing of a text corpus. In: Hartmann, R. R. K. (ed.). Lexicography: principles and practice. London. 77-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P v Polenz</author>
</authors>
<title>Funktionsverbgefiige im allgemeinen einsprachigen Worterbuch.</title>
<date>1989</date>
<journal>IISK</journal>
<volume>5</volume>
<pages>882--887</pages>
<editor>In: Hausmann, F. J. et al. (eds.).</editor>
<contexts>
<context position="4462" citStr="Polenz 1989" startWordPosition="680" endWordPosition="681">ehaviour. In this paper, collocations shall refer only to word combinations that have a certain affinity to each other in that they follow combinatory restrictions not explainable with syntactic and semantic principles (e.g. hammer a nail into sth. rather than &apos;beat a nail into sth.). For collocations that are based on a verb and a. noun (preferably an object argument, sometimes however the subject of an intransitive verb), three types of V-N combinations are distinguished for German in the literature: verbal phrasemes (idioms) (e.g. Brundage et al. 1992), support verb constructions (SVCs) (v.Polenz 1989 or Danlos 1992) and collocations in the narrower sense (Hausmann 1989). As Brundage et al. (1992:7) and Barkema (1989:24) point out, the differences between these three types are gradual and &amp;quot;it is hard to find criteria of good selectivity to distinguish collocations from phrasemes&amp;quot;. Although our main interest lies in SVCs we will in the following not distinguish between i) SVCs (e.g. to take into consideration), ii) lexicalized combinations with support verbs where the noun has lost its original meaning and which belong to phrasemes (e.g. to take a fancy), and iii) collocational combinations</context>
</contexts>
<marker>Polenz, 1989</marker>
<rawString>v.Polenz, P. (1989). Funktionsverbgefiige im allgemeinen einsprachigen Worterbuch. In: Hausmann, F. J. et al. (eds.). Dictionaries: an international handbook for lexicography. Part I. IISK 5.1. 882-887.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Sinclair</author>
</authors>
<title>Beginning the study of lexis. In:</title>
<date>1966</date>
<pages>410--430</pages>
<editor>Bazell, C. E. et al. (eds.)</editor>
<note>in memory of</note>
<marker>Sinclair, 1966</marker>
<rawString>Sinclair, J. M. (1966). Beginning the study of lexis. In: Bazell, C. E. et al. (eds.) (1966). in memory of J. R. Firth. London. 410-430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
<author>K R McKeown</author>
</authors>
<title>Automatically extracting and representing collocations for language generation. 28th ACL</title>
<date>1990</date>
<pages>252--259</pages>
<contexts>
<context position="2957" citStr="Smadja and McKeown (1990)" startWordPosition="445" endWordPosition="448"> at least one occurrence of the collocation in one million words. He mentions plans to define a &apos;My thanks go to the ldS that made the two corpora available for research purposes, to Angelika Storrer for her steady encouragement and many fruitful discussions, and to Mats Rooth and Matthias Heyn who introduced me to the corpora tools. I am also greatful to the anonymous reviewers for their helpful comments and constructive criticism. &apos;binding degree on how strong the words of a collocation attract each other, which would be similar in spirit to what is calculated with MI. The work described in Smadja and McKeown (1990) arid Smaclja (1991a.b) is along the same lines as ours, though he uses a different statistical calculation, a z-score, and tagged, lemmatized corpora. Some properties specific to German, however, lead to a type of problem that needs different treatment (section 3.3). Calzolari, Hindi (1990) use MI to extract compounds, fixed expressions and collocations from an Italian corpus, but to our knowledge have not evaluated their results so far. 2 Domain of Investigation 2.1 What Do We Mean by &apos;Collocation&apos;? Collocations in the sense of &apos;frequently cooccurring words&apos; can quite easily be extracted fro</context>
</contexts>
<marker>Smadja, McKeown, 1990</marker>
<rawString>Smadja, F. A., K. R.. McKeown (1990). Automatically extracting and representing collocations for language generation. 28th ACL 1990. 252-259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
</authors>
<title>Macrocoding the lexicon with co-occurrence knowledge.</title>
<date>1991</date>
<editor>In: Zernik, U. (ed.).</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="12486" citStr="Smadja (1991" startWordPosition="1983" endWordPosition="1984">erb either directly or within two to five words, because this at least definitely captures complements of main verbs 1We greatfully acknowledge that the work reported here would not have been possible without the supplied tools and corpora. 77 in verb-final position. To find the correct argument, to the right of the verb is difficult in an unparsecl corpus because of the variable number of intervening constituents. As illustrated in the last paragraph the assumption that a &amp;quot;semantic agent 1...1 is principally used before the verb&amp;quot; and a &amp;quot;semantic object I...1 is used after it&amp;quot; as described in Smadja (1991a:180) does not hold for German. Therefore, complicated parsing is necessary to distinguish subject-verb from object-verb combinations. The results of V-N extractions reflect this problem. In many if not in most of the uninteresting combinations extracted, the noun to the left of the verb is the subject rather than a complement of the verb (cf. section 4.6). 4 Evaluation of the Results Below, the top bigrams %vith kommen (come) are shown, and some of the nonsignificant ones (t &lt; 1.65), to illustrate MI and t-scores. Bigrams with the infinitive form give best results compared to other inflectio</context>
<context position="14228" citStr="Smadja (1991" startWordPosition="2298" endWordPosition="2299">Hilfe k. come to aid (zu) Wort k. get a chance to speak Vernunft reason (in) Frage k. to be possible (zur) Welt k. to be born Sie You f(x,y) f(y) MI t-score V-N-Coll. 27 96 9.86 5.19 9 42 9.47 2.99 4 41 8.33 1.99 4 126 6.71 1.97 3 107 6.53 1.70 4 216 5.93 1.95 7 403 5.84 2.58 3 270 5.20 1.66 4 477 4.79 1.89 3 647 3.94 1.57 3 736 3.75 1.55 4 1054 3.65 1.77 4 1900 2.80 1.60 3 2414 2.04 1.17 4.1 Precision and Recall The question how much is extractable fully automatically can be answered by an evaluation of precision and &apos;recall&apos; of the described method as it, is done for memory tests. Following Smadja (1991a) we define precision as the number of correctly found collocations divided by the number of V-N combinations found at all. Recall reflects the ratio of the number of correctly found collocations and the maximal number of collocations that could possibly have been found. The latter is slightly difficult to determine, because in principle this means to know the total number of collocations occurring in the whole corpus. Another possibility, to take all collocations that are mentioned in a dictionary as the maximal number of valid collocations, had to be discarded: a comparison with Agricola (M</context>
<context position="20386" citStr="Smadja (1991" startWordPosition="3322" endWordPosition="3323">erall for the infinitive separately. The complete data for bringen are listed below. Table 2: Variations for the verb bringen Bigrams f(V) V-N Coll. Precision % Recall % BIG Inf 550 46 31 67.4 100 (def.) BI6/t Inf 550 44 31 70.5 100 BIG MK1-1-BZE Inf. 1065 97 63 65.0 203 BI3 luf 550 33 28 84.9 90.3 B13/1 Inf 550 31 27 87.1 87.1 B16 Lemma 1508 74 43 58.0 138.7 BIG 1â– 11,Z1-1-BZE Lemma 3145 142 73 51.4 235.5 BI3 Lemma 1508 46 37 80.4 119.4 4.6 Experiment 4: Simulating Syntactic Tagging In order to see how much the precision could possibly be improved by determining syntactic relations as done by Smadja (1991a,b) for English, we conducted another test with bringen, where we manually excluded those uninteresting extracted combinations in which the nouns were in fact used in subject position of the verb. The results for 2The latest runs with the combined corpus showed that for the infinitives precision even rises slightly on average (82.1%) while recall is almost doubled (134,9%), compared to BI3 Inf in table 1. 80 the two window-sizes, infinitive and lexeme, are shown in table 3. Precision would rise up to 100% with still a good recall of S7.1% if one could consider syntactic relations for the extr</context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Smadja, F. A. (1991a). Macrocoding the lexicon with co-occurrence knowledge. In: Zernik, U. (ed.). Lexical acquisition: exploring on-line resources to build a lexicon. Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
</authors>
<title>From n-grams to collocations: an evaluation of Xtract.</title>
<date>1991</date>
<booktitle>29th ACL,</booktitle>
<pages>279--284</pages>
<location>Berkeley, CA.</location>
<contexts>
<context position="12486" citStr="Smadja (1991" startWordPosition="1983" endWordPosition="1984">erb either directly or within two to five words, because this at least definitely captures complements of main verbs 1We greatfully acknowledge that the work reported here would not have been possible without the supplied tools and corpora. 77 in verb-final position. To find the correct argument, to the right of the verb is difficult in an unparsecl corpus because of the variable number of intervening constituents. As illustrated in the last paragraph the assumption that a &amp;quot;semantic agent 1...1 is principally used before the verb&amp;quot; and a &amp;quot;semantic object I...1 is used after it&amp;quot; as described in Smadja (1991a:180) does not hold for German. Therefore, complicated parsing is necessary to distinguish subject-verb from object-verb combinations. The results of V-N extractions reflect this problem. In many if not in most of the uninteresting combinations extracted, the noun to the left of the verb is the subject rather than a complement of the verb (cf. section 4.6). 4 Evaluation of the Results Below, the top bigrams %vith kommen (come) are shown, and some of the nonsignificant ones (t &lt; 1.65), to illustrate MI and t-scores. Bigrams with the infinitive form give best results compared to other inflectio</context>
<context position="14228" citStr="Smadja (1991" startWordPosition="2298" endWordPosition="2299">Hilfe k. come to aid (zu) Wort k. get a chance to speak Vernunft reason (in) Frage k. to be possible (zur) Welt k. to be born Sie You f(x,y) f(y) MI t-score V-N-Coll. 27 96 9.86 5.19 9 42 9.47 2.99 4 41 8.33 1.99 4 126 6.71 1.97 3 107 6.53 1.70 4 216 5.93 1.95 7 403 5.84 2.58 3 270 5.20 1.66 4 477 4.79 1.89 3 647 3.94 1.57 3 736 3.75 1.55 4 1054 3.65 1.77 4 1900 2.80 1.60 3 2414 2.04 1.17 4.1 Precision and Recall The question how much is extractable fully automatically can be answered by an evaluation of precision and &apos;recall&apos; of the described method as it, is done for memory tests. Following Smadja (1991a) we define precision as the number of correctly found collocations divided by the number of V-N combinations found at all. Recall reflects the ratio of the number of correctly found collocations and the maximal number of collocations that could possibly have been found. The latter is slightly difficult to determine, because in principle this means to know the total number of collocations occurring in the whole corpus. Another possibility, to take all collocations that are mentioned in a dictionary as the maximal number of valid collocations, had to be discarded: a comparison with Agricola (M</context>
<context position="20386" citStr="Smadja (1991" startWordPosition="3322" endWordPosition="3323">erall for the infinitive separately. The complete data for bringen are listed below. Table 2: Variations for the verb bringen Bigrams f(V) V-N Coll. Precision % Recall % BIG Inf 550 46 31 67.4 100 (def.) BI6/t Inf 550 44 31 70.5 100 BIG MK1-1-BZE Inf. 1065 97 63 65.0 203 BI3 luf 550 33 28 84.9 90.3 B13/1 Inf 550 31 27 87.1 87.1 B16 Lemma 1508 74 43 58.0 138.7 BIG 1â– 11,Z1-1-BZE Lemma 3145 142 73 51.4 235.5 BI3 Lemma 1508 46 37 80.4 119.4 4.6 Experiment 4: Simulating Syntactic Tagging In order to see how much the precision could possibly be improved by determining syntactic relations as done by Smadja (1991a,b) for English, we conducted another test with bringen, where we manually excluded those uninteresting extracted combinations in which the nouns were in fact used in subject position of the verb. The results for 2The latest runs with the combined corpus showed that for the infinitives precision even rises slightly on average (82.1%) while recall is almost doubled (134,9%), compared to BI3 Inf in table 1. 80 the two window-sizes, infinitive and lexeme, are shown in table 3. Precision would rise up to 100% with still a good recall of S7.1% if one could consider syntactic relations for the extr</context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Smadja, F. A. (1991b). From n-grams to collocations: an evaluation of Xtract. 29th ACL, Berkeley, CA. 279-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Uszkoreit</author>
</authors>
<title>Word order and constituent structure.</title>
<date>1987</date>
<journal>CSLI Lecture Notes</journal>
<volume>8</volume>
<contexts>
<context position="11295" citStr="Uszkoreit 1987" startWordPosition="1782" endWordPosition="1783">cations from German text corpora more difficult than for English corpora. A minor difference concerns the strong inflection of German verbs. Whereas in English a verb lexeme appears in 3 or 4 different forms plus one for the present participle, German verbs have 7 to 10 verb forms (without subjunctive forms) for one lexeme and additional 4 for the present participle. This has to be considered for the evaluation of queries based on single inflection forms, because in English more usages are covered with one verb form than in German. Another point concerns the variable word order in German (see Uszkoreit 1987) which makes it more difficult, to locate the parts of a V-N collocation. In a main clause (verb-second order), a noun preceding a. finite verb usually is the subject, but it can also be a topicalized complement; in sentences where the main verb occurs at the end (nonfinite verb or subordinate clause) the preceding noun is mostly a direct object or other complement, or an adjunct. A noun to the right of a finite verb can be any of subject, object or other argument. due to topicalization or scrambling. We restrict our search to V-N combinations where the noun precedes the verb either directly o</context>
</contexts>
<marker>Uszkoreit, 1987</marker>
<rawString>Uszkoreit, H. (1987). Word order and constituent structure. CSLI Lecture Notes 8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>