<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025932">
<title confidence="0.9997865">
A Hybrid Approach for Functional Expression Identification
in a Japanese Reading Assistant
</title>
<author confidence="0.993612">
Gregory Hazelbeck
</author>
<affiliation confidence="0.979629">
Graduate School of
Science and Technology
Keio University
</affiliation>
<email confidence="0.997654">
gregh@nak.ics.keio.ac.jp
</email>
<sectionHeader confidence="0.993928" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998956818181818">
In this paper we present a hybrid approach
for identifying Japanese functional ex-
pressions and its application in a Japanese
reading assistant. We combine the re-
sults of machine learning and pattern-
based methods to identify several types
of functional expressions. We show that
by using our approach we can double the
coverage of previous approaches and still
maintain the high level of performance
necessary for our application.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999913045454546">
Functional expressions are one of the most im-
portant elements of Japanese grammar that any-
one studying the language must learn. Despite the
importance of functional expressions, many tools
that assist learners of Japanese with reading texts
only provide dictionary look-up of simple words.
However, the ability to quickly obtain informa-
tion about such grammar could not only improve
the learner’s comprehension of the text, but also
facilitate their learning process of new elements
of Japanese grammar. Thus, we have decided to
develop a Japanese reading assistant that is ca-
pable of providing explanations of functional ex-
pressions in addition to vocabulary.
Functional expressions in Japanese are com-
pound expressions that contain content and func-
tion words, and can have both compositional and
non-compositional meanings. For example, in Ta-
ble 1, sentences 1 and 2 contain the 6,:!&amp;5fes.9 (ni-
atari) compound expression. In sentence 1, this
expression has a functional, non-compositional
meaning of “when.” However, in sentence 2, the
</bodyText>
<author confidence="0.292813">
Hiroaki Saito
</author>
<affiliation confidence="0.382865">
Graduate School of
Science and Technology
Keio University
</affiliation>
<email confidence="0.754491">
hxs@ics.keio.ac.jp
</email>
<bodyText confidence="0.999958">
same expression has a compositional meaning that
results simply from using the post-particle 6,:! (ni)
and verb &amp;5fes.9 (a conjugated form of &amp;5fes.6
(ataru), meaning “to hit”) together. We refer to
this as the content usage of a functional expres-
sion. However, there are also functional expres-
sions where this type of content usage is very rare
(or even nonexistent). Sentence 3 shows an ex-
ample of the 4�V�hU4�9�-Ltlv (nakerebanari-
masen) functional expression which has a very
common functional meaning of “must or have to.”
Tsuchiya et al. (2006) have proposed a method
based on machine learning to identify functional
expressions. However, this method only covers
functional expressions which have balanced func-
tional vs. content usage ratios. In order to boost
coverage of current methods, we propose a hybrid
approach for functional expression identification
which uses a combination of the machine learning
method proposed by Tsuchiya et al. (2006) and
simple patterns. Coverage analysis and empirical
evaluations show that our method doubles the cov-
erage of previous approaches while still maintain-
ing a high level of performance.
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.998768">
2.1 Functional Expressions
</subsectionHeader>
<bodyText confidence="0.999878555555555">
Research on Japanese functional expressions has
included work on identification methods as well
as resources that aid identification. Matsuyoshi
et al. (2006) developed a hierarchical dictionary
of functional expressions called Tsutsuji. The top
level of the dictionary’s nine level hierarchy con-
tains the lexical form of 341 expressions. The sec-
ond level categorizes these expressions by mean-
ing. The remaining seven levels contain various
</bodyText>
<page confidence="0.981762">
81
</page>
<subsectionHeader confidence="0.4429815">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 81–84,
Beijing, August 2010
</subsectionHeader>
<bodyText confidence="0.595584625">
にあたり (niatari)
Functional アパートに入居するにあたり、隣近所に挨拶回りをするのは日本の習慣です。
It is a custom in Japan to greet your neighbors when you move into a new apartment.
Content ボールが顔面にあたり、歯が折れた。
The ball hit me in the face and broke my tooth.
なければなりません (nakerebanarimasen)
Functional 明日は学校に行かなければなりません。
I have to go to school tomorrow.
</bodyText>
<tableCaption confidence="0.981187">
Table 1. Examples of Japanese functional expressions.
</tableCaption>
<bodyText confidence="0.999969821428571">
surface forms for each expression where inser-
tion/deletion of particles and other conjugations
have been made. While this is the most compre-
hensive dictionary of Japanese functional expres-
sions, it can not be directly used for identifica-
tion because of the functional/content usage prob-
lem described in the previous section. Therefore,
identification methods like Tsuchiya et al. (2006)
which uses Support Vector Machines(SVM) have
been proposed to solve this problem. The data set
(Tsuchiya et al., 2005) used to train this method,
called MUST, contains annotated instances of 337
functional expressions. For each expression, a
maximum of 50 instances were collected from the
1995 Mainichi newspaper corpus.
Recent work by the same group of researchers
(Nagasaka et al., 2010) indicates that they have
continued to annotate additional functional ex-
pressions for the MUST data set. During this
process, they have observed that only around one
third of all functional expressions possess a suf-
ficient amount of functional and content usages
to be used with their machine learning method.
However, they have yet to propose any method
to cover the other two-thirds of functional expres-
sions. Our hybrid approach aims to improve cov-
erage by identifying functional expressions that
fall into this group.
</bodyText>
<sectionHeader confidence="0.99627" genericHeader="method">
3 Identification Method
</sectionHeader>
<bodyText confidence="0.999974">
Our hybrid approach combines the results from
two different methods of functional expression
identification. First, we will describe our imple-
mentation of a method that uses machine learning.
Then, we will describe our method of generating
patterns for functional expressions.
</bodyText>
<subsectionHeader confidence="0.998715">
3.1 Machine Learning
</subsectionHeader>
<bodyText confidence="0.999903666666667">
Our implementation of the method proposed by
Tsuchiya et al. (2006) only deviates slightly from
its original form. We developed our own SVM-
based text chunking system in Python while the
original paper uses a text chunker called Yamcha1.
We also use the MeCab2 morphological analyzer
with a dictionary called UniDic while the original
paper used ChaSen with the default dictionary.
When training the SVMs, the original method
uses three sets of labels: functional, content, and
other. This allows both functional and content us-
ages to be explicitly identified. However, in our
application, we only need to identify functional
usages so that the expressions’ correct definitions
can be displayed. Therefore, in our implementa-
tion we only use two sets of labels (functional and
other) and label all content usages as other. We
also decided to build a separate model for each
functional expression because it enables us to add
new training data and functional expressions with-
out having to retrain everything. Although this
does increase time complexity in the worse case,
in practice it does not have a big affect on perfor-
mance because only a small fraction of the total
number of models are being used for a given text.
Identification of functional expressions in a new
text is performed in the following steps:
</bodyText>
<listItem confidence="0.9974184">
1. Morphologically analyze the text with
MeCab and extract candidate functional
expressions from the morpheme sequence.
2. Select the model corresponding to each can-
didate functional expression.
</listItem>
<footnote confidence="0.9962825">
&apos;http://chasen.org/~taku/software/yamcha/
2http://mecab.sourceforge.net/
</footnote>
<page confidence="0.99152">
82
</page>
<figure confidence="0.980044428571428">
GeneratePatterns(C: list of candidates from Tsutsuji)
01 P = {}
02 for each candidate c in C:
03 S = sentences that contain c in the BCCWJ
04 for each sentence s in S:
05 Ms = morpheme sequence of s
06 Mc = ExtractCandMorph(c, Ms)
07 if Mc ≠ null n VerbChk(c, Mc, Ms, P):
08 Add Mc to P
09 break out of loop on line 4
10 end if
11 end for
12 end for
13 return P
</figure>
<figureCaption confidence="0.999965">
Figure 1. The GeneratePatterns algorithm.
</figureCaption>
<listItem confidence="0.9334775">
3. Use each model to conduct chunking. Label
any functional chunks as the model’s corre-
sponding functional expression.
4. Combine the results from each model. Re-
solve any overlapping chunks by the same
rules3 that Tsuchiya et al. (2006) use to re-
solve overlapping candidate functional ex-
pressions during feature generation.
</listItem>
<subsectionHeader confidence="0.995996">
3.2 Patterns
</subsectionHeader>
<bodyText confidence="0.947189739130435">
We generate simple patterns to identify functional
expressions with a high ratio of functional usage.
First, surveys are conducted of functional expres-
sions in Tsutsuji using the Balanced Corpus of
Contemporary Written Japanese (BCCWJ)4. As
of writing this paper, we have selected 36 func-
tional expressions from Tsutsuji’s top level as can-
didates for pattern generation. We also included
various surface forms of these expressions from
other levels of Tsutsuji resulting in a total of 1558
candidate functional expressions. The algorithm
used to generate patterns is shown in Figure 1.
The ExtractCandMorph function simply re-
turns the candidate c’s morpheme sequence. If
the candidate’s string does not match the bound-
aries of morphemes in M3 then null is returned.
The VerbChk function returns true if a candidate
is an auxiliary verb from Tsutsuji’s top level and
the morpheme immediately preceding it in M3 is a
verb. It returns true for lower level auxiliary verb
3Specifically, select the candidate that starts at the left-
most morpheme. If more than one candidate starts at the
same morpheme then select the longest candidate.
</bodyText>
<footnote confidence="0.944796">
4Balanced Corpus of Contemporary Written Japanese
Monitor Release Data (2009 Version).
</footnote>
<bodyText confidence="0.999604888888889">
candidates if the last morpheme in its morpheme
sequence is also in the morpheme sequence of its
top-level parent candidate from Tsutsuji. For any
candidate that is not an auxiliary verb, the func-
tion always returns true. We force candidates from
lower levels to satisfy an extra condition because
their lower frequency in the BCCWJ increases the
probability that a sentence with the wrong ex-
pression/usage will be selected. This algorithm
produces one pattern per functional expression.
Each pattern is composed of the expression’s mor-
pheme sequence. This is a list where each ele-
ment contains a morpheme’s surface form, part of
speech, and lexical form. Patterns for auxiliary
verbs also check if the previous morpheme is a
verb. Using this algorithm, we were able to gen-
erate 502 patterns with our 1558 candidate func-
tional expressions.
</bodyText>
<sectionHeader confidence="0.969474" genericHeader="method">
4 Coverage Analysis
</sectionHeader>
<bodyText confidence="0.999983035714286">
To investigate the improvement in coverage
achieved by our hybrid approach, we compared
the coverage of our approach with the coverage
of just the MUST data set. We define coverage
as the ratio of functional expressions contained in
both the Tsutsuji dictionary and BCCWJ that are
supported.
We first collected all of the functional expres-
sion surface forms contained in Tsutsuji. We ex-
cluded all of the single character surface forms
which are mostly simple particles. Next, we
recorded the frequency of each surface form’s
string in the BCCWJ. Overlapping of strings is
allowed as long as a string covers at least one
character that no other string does. Finally, we
recorded which surface forms were supported by
our hybrid approach and the MUST data set. Ta-
ble 3 shows our final results.
Our results show that MUST is only cover-
ing around 12% of Tsutsuji’s functional expres-
sions in the BCCWJ. The additional functional
expressions supported by our hybrid approach
helps boost this coverage to 24%. Improvement
in coverage is observed at every frequency inter-
val. This is especially advantageous for our ap-
plication because it allows us to display informa-
tion about many different common and uncom-
mon functional expressions.
</bodyText>
<page confidence="0.99811">
83
</page>
<table confidence="0.999418">
Corpus Usage Examples Total Examples Total Morphemes
Functional Content
Training (MUST) 1,767 1,463 3,230 114,699
Testing (1995 Mainichi Newspaper) 5,347 1,418 6,765 244,324
</table>
<tableCaption confidence="0.997804">
Table 2. Training and testing corpora details.
</tableCaption>
<table confidence="0.999931333333333">
Frequency Tsutsuji MUST Hybrid
Interval
&gt;5,000 199 44 (22%) 70 (35%)
5,000-1,001 244 70 (29%) 111 (45%)
1,000-501 134 37 (28%) 54 (40%)
500-101 519 124 (24%) 191 (37%)
100-51 269 53 (20%) 90 (33%)
50-26 327 54 (17%) 97 (30%)
25-11 467 46 (10%) 113 (24%)
10-2 1,180 55 (5%) 188 (16%)
1 723 11 (2%) 82 (11%)
Total 4,062 494 (12%) 996 (24%)
</table>
<tableCaption confidence="0.985649666666667">
Table 3. Functional expressions covered by each
resource. Percentage of Tsutsuji covered in each
frequency interval is given in parenthesis.
</tableCaption>
<table confidence="0.999036666666667">
Software (kernel) Precision Recall Fp = 1
Yamcha (polynomial) 0.928 0.936 0.932
Our chunker (linear) 0.931 0.935 0.933
</table>
<tableCaption confidence="0.9996">
Table 4. Experiment 1 results.
</tableCaption>
<sectionHeader confidence="0.995851" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999951833333334">
We evaluated the machine learning method on 54
of the most difficult to identify functional expres-
sions. These are the same expressions that were
used in Tsuchiya et al. (2006)’s evaluation. De-
tails of the training and testing data sets are shown
in Table 2. Results (Table 4) show that this method
performs well even on the most difficult functional
expressions. We also found that using a simple
linear kernel gave the best precision.
We evaluated the patterns generated from our
method by using them to identify functional ex-
pressions in randomly selected texts from the BC-
CWJ. After verifying 2000 instances of identified
functional expressions, we only found 6 instances
to be incorrect. However, since these 2000 in-
stances only cover 89 of the 502 expressions that
we support, we randomly selected two instances
of each remaining expression from the BCCWJ
and verified them. In the additional 750 instances
that were verified, only 10 instances were found
to be incorrect. Results of the second experi-
ment show that patterns generated for high fre-
quency functional expressions are providing espe-
cially good performance.
</bodyText>
<sectionHeader confidence="0.999492" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999044857142857">
In this paper we presented a hybrid approach for
identifying Japanese functional expressions and
its application in a Japanese reading assistant. We
showed that a combination of machine learning
and simple patterns can improve coverage while
still maintaining the high level of performance
necessary for our application.
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999982142857143">
We would like to thank Takehito Utsuro for allow-
ing us to use his annotated functional expression
data to evaluate our approach. We would also like
to thank all of the other people involved in cre-
ating the MUST data set. Finally, we would like
to thank the anonymous reviewers for all of their
helpful comments.
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994723">
Matsuyoshi, Suguru, Satoshi Sato, and Takehito Utsuro.
2006. Compilation of a Dictionary of Japanese Func-
tional Expressions with Hierarchical Organization. IC-
CPOL. pp. 395–402.
Nagasaka, Taiji, Takehito Utsuro, Suguru Matsuyoshi,
Masatoshi Tsuchiya. 2010. Analysis and Detection of
Japanese Functional Expressions based on a Hierarchical
Lexicon. Proceedings of the 16th Annual Meeting of the
Association for Natural Language Processing. pp. 970–
973. (in Japanese)
Tsuchiya, Masatoshi, Takao Shime, Toshihiro Takagi, Take-
hito Utsuro, Kiyotaka Uchimoto, Suguru Matsuyoshi,
Satoshi Sato, and Seiichi Nakagawa. 2006. Chunking
Japanese Compound Functional Expressions by Machine
Learning. Proceedings of the 2nd International Workshop
on Web as Corpus (EACL-2006). pp. 11–18.
Tsuchiya, Masatoshi, Takehito Utsuro, Suguru Matsuyoshi,
Satoshi Sato, and Seiichi Nakagawa. 2005. A Corpus
for Classifying Usages of Japanese Compound Functional
Expressions. PACLING. pp. 345–350.
</reference>
<page confidence="0.999241">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.129542">
<title confidence="0.999006">A Hybrid Approach for Functional Expression in a Japanese Reading Assistant</title>
<author confidence="0.968391">Gregory</author>
<affiliation confidence="0.9223225">Graduate School Science and</affiliation>
<email confidence="0.5127125">Keiogregh@nak.ics.keio.ac.jp</email>
<abstract confidence="0.999635083333333">In this paper we present a hybrid approach for identifying Japanese functional expressions and its application in a Japanese reading assistant. We combine the results of machine learning and patternbased methods to identify several types of functional expressions. We show that by using our approach we can double the coverage of previous approaches and still maintain the high level of performance necessary for our application.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Suguru Matsuyoshi</author>
<author>Satoshi Sato</author>
<author>Takehito Utsuro</author>
</authors>
<date>2006</date>
<booktitle>Compilation of a Dictionary of Japanese Functional Expressions with Hierarchical Organization. ICCPOL.</booktitle>
<pages>395--402</pages>
<contexts>
<context position="3114" citStr="Matsuyoshi et al. (2006)" startWordPosition="465" endWordPosition="468">tional vs. content usage ratios. In order to boost coverage of current methods, we propose a hybrid approach for functional expression identification which uses a combination of the machine learning method proposed by Tsuchiya et al. (2006) and simple patterns. Coverage analysis and empirical evaluations show that our method doubles the coverage of previous approaches while still maintaining a high level of performance. 2 Related Work 2.1 Functional Expressions Research on Japanese functional expressions has included work on identification methods as well as resources that aid identification. Matsuyoshi et al. (2006) developed a hierarchical dictionary of functional expressions called Tsutsuji. The top level of the dictionary’s nine level hierarchy contains the lexical form of 341 expressions. The second level categorizes these expressions by meaning. The remaining seven levels contain various 81 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 81–84, Beijing, August 2010 にあたり (niatari) Functional アパートに入居するにあたり、隣近所に挨拶回りをするのは日本の習慣です。 It is a custom in Japan to greet your neighbors when you move into a new apartment. Content ボールが顔面にあたり、歯が折れた。 The ball hit me in the fac</context>
</contexts>
<marker>Matsuyoshi, Sato, Utsuro, 2006</marker>
<rawString>Matsuyoshi, Suguru, Satoshi Sato, and Takehito Utsuro. 2006. Compilation of a Dictionary of Japanese Functional Expressions with Hierarchical Organization. ICCPOL. pp. 395–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taiji Nagasaka</author>
<author>Takehito Utsuro</author>
<author>Suguru Matsuyoshi</author>
<author>Masatoshi Tsuchiya</author>
</authors>
<title>Analysis and Detection of Japanese Functional Expressions based on a Hierarchical Lexicon.</title>
<date>2010</date>
<booktitle>Proceedings of the 16th Annual Meeting of the Association for Natural Language Processing.</booktitle>
<pages>970--973</pages>
<note>(in Japanese)</note>
<contexts>
<context position="4660" citStr="Nagasaka et al., 2010" startWordPosition="695" endWordPosition="698">ary of Japanese functional expressions, it can not be directly used for identification because of the functional/content usage problem described in the previous section. Therefore, identification methods like Tsuchiya et al. (2006) which uses Support Vector Machines(SVM) have been proposed to solve this problem. The data set (Tsuchiya et al., 2005) used to train this method, called MUST, contains annotated instances of 337 functional expressions. For each expression, a maximum of 50 instances were collected from the 1995 Mainichi newspaper corpus. Recent work by the same group of researchers (Nagasaka et al., 2010) indicates that they have continued to annotate additional functional expressions for the MUST data set. During this process, they have observed that only around one third of all functional expressions possess a sufficient amount of functional and content usages to be used with their machine learning method. However, they have yet to propose any method to cover the other two-thirds of functional expressions. Our hybrid approach aims to improve coverage by identifying functional expressions that fall into this group. 3 Identification Method Our hybrid approach combines the results from two diff</context>
</contexts>
<marker>Nagasaka, Utsuro, Matsuyoshi, Tsuchiya, 2010</marker>
<rawString>Nagasaka, Taiji, Takehito Utsuro, Suguru Matsuyoshi, Masatoshi Tsuchiya. 2010. Analysis and Detection of Japanese Functional Expressions based on a Hierarchical Lexicon. Proceedings of the 16th Annual Meeting of the Association for Natural Language Processing. pp. 970– 973. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masatoshi Tsuchiya</author>
</authors>
<title>Takao Shime, Toshihiro Takagi, Takehito Utsuro, Kiyotaka Uchimoto, Suguru Matsuyoshi, Satoshi Sato, and Seiichi Nakagawa.</title>
<date>2006</date>
<booktitle>Chunking Japanese Compound Functional Expressions by Machine Learning. Proceedings of the 2nd International Workshop on Web as Corpus (EACL-2006).</booktitle>
<pages>11--18</pages>
<marker>Tsuchiya, 2006</marker>
<rawString>Tsuchiya, Masatoshi, Takao Shime, Toshihiro Takagi, Takehito Utsuro, Kiyotaka Uchimoto, Suguru Matsuyoshi, Satoshi Sato, and Seiichi Nakagawa. 2006. Chunking Japanese Compound Functional Expressions by Machine Learning. Proceedings of the 2nd International Workshop on Web as Corpus (EACL-2006). pp. 11–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masatoshi Tsuchiya</author>
<author>Takehito Utsuro</author>
<author>Suguru Matsuyoshi</author>
<author>Satoshi Sato</author>
<author>Seiichi Nakagawa</author>
</authors>
<title>A Corpus for Classifying Usages of Japanese Compound Functional Expressions.</title>
<date>2005</date>
<pages>345--350</pages>
<publisher>PACLING.</publisher>
<contexts>
<context position="4388" citStr="Tsuchiya et al., 2005" startWordPosition="653" endWordPosition="656">Functional 明日は学校に行かなければなりません。 I have to go to school tomorrow. Table 1. Examples of Japanese functional expressions. surface forms for each expression where insertion/deletion of particles and other conjugations have been made. While this is the most comprehensive dictionary of Japanese functional expressions, it can not be directly used for identification because of the functional/content usage problem described in the previous section. Therefore, identification methods like Tsuchiya et al. (2006) which uses Support Vector Machines(SVM) have been proposed to solve this problem. The data set (Tsuchiya et al., 2005) used to train this method, called MUST, contains annotated instances of 337 functional expressions. For each expression, a maximum of 50 instances were collected from the 1995 Mainichi newspaper corpus. Recent work by the same group of researchers (Nagasaka et al., 2010) indicates that they have continued to annotate additional functional expressions for the MUST data set. During this process, they have observed that only around one third of all functional expressions possess a sufficient amount of functional and content usages to be used with their machine learning method. However, they have</context>
</contexts>
<marker>Tsuchiya, Utsuro, Matsuyoshi, Sato, Nakagawa, 2005</marker>
<rawString>Tsuchiya, Masatoshi, Takehito Utsuro, Suguru Matsuyoshi, Satoshi Sato, and Seiichi Nakagawa. 2005. A Corpus for Classifying Usages of Japanese Compound Functional Expressions. PACLING. pp. 345–350.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>