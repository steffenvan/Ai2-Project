<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000877">
<title confidence="0.823253">
UBC-UMB: Combining unsupervised and supervised systems for all-words
WSD
</title>
<author confidence="0.966853">
David Martinez,Timothy Baldwin
</author>
<affiliation confidence="0.970458">
LT Group, CSSE
University of Melbourne
</affiliation>
<address confidence="0.655581">
Victoria 3010 Australia
</address>
<email confidence="0.997751">
{davidm,tim}@csse.unimelb.edu.au
</email>
<author confidence="0.557901">
Eneko Agirre, Oier Lopez de Lacalle
</author>
<affiliation confidence="0.729030666666667">
IXA NLP Group
Univ. of the Basque Country
Donostia, Basque Country
</affiliation>
<email confidence="0.994734">
{e.agirre,jibloleo}@ehu.es
</email>
<sectionHeader confidence="0.998575" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908666666667">
This paper describes the joint submission
of two systems to the all-words WSD sub-
task of SemEval-2007 task 17. The main
goal of this work was to build a competitive
unsupervised system by combining hetero-
geneous algorithms. As a secondary goal,
we explored the integration of unsupervised
predictions into a supervised system by dif-
ferent means.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973925925926">
This paper describes the joint submission of two sys-
tems to the all-words WSD subtask of SemEval-
2007 task 17. The systems were developed by the
University of the Basque Country (UBC), and the
University of Melbourne (UMB). The main goal of
this work was to build a competitive unsupervised
system by combining heterogeneous algorithms. As
a secondary goal, we explored the integration of
this method into a supervised system by different
means. Thus, this paper describes both the unsu-
pervised system (UBC-UMB-1), and the combined
supervised system (UBC-UMB-2) submitted to the
all-words task.
Our motivation in building unsupervised systems
comes from the difficulty of creating hand-tagged
data for all words and all languages, which is col-
loquially known as the knowledge acquisition bot-
tleneck. There have also been promising results in
recent work on the combination of unsupervised ap-
proaches that suggest the gap with respect to super-
vised systems is narrowing (Brody et al., 2006).
The remainder of the paper is organized as fol-
lows. First we describe the disambiguation algo-
rithms in Section 2. Next, the development exper-
iments are presented in Section 3, and our final sub-
missions and results in Section 4. Finally, we sum-
marize our conclusions in Section 5.
</bodyText>
<sectionHeader confidence="0.991105" genericHeader="introduction">
2 Algorithms
</sectionHeader>
<bodyText confidence="0.999731">
In this section, we will describe the standalone algo-
rithms (three unsupervised and one supervised) and
the combination schemes we explored. The unsu-
pervised methods are based on different intuitions
for disambiguation (topical features, local context,
and WordNet relations), which is a desirable charac-
teristic for combining algorithms.
</bodyText>
<subsectionHeader confidence="0.97534">
2.1 Topic Signatures (TS)
</subsectionHeader>
<bodyText confidence="0.986973714285714">
Topic signatures (Agirre and de Lacalle, 2004) are
lists of words related to a particular sense. They can
be built from a variety of sources, and be used di-
rectly to perform WSD. Cuadros and Rigau (2006)
present a detailed evaluation of topic signatures built
from a variety of knowledge sources. In this work
we built those coming from the following:
</bodyText>
<listItem confidence="0.99872375">
• the relations in the Multilingual Central Repos-
itory (TS-MCR)
• the relations in the Extended WordNet (TS-
XWN)
</listItem>
<bodyText confidence="0.9995174">
In order to apply this resource for WSD, we sim-
ply measured the word-overlap between the target
context and each of the senses of the target word.
The sense with highest overlap is chosen as the cor-
rect sense.
</bodyText>
<page confidence="0.951349">
350
</page>
<bodyText confidence="0.8161">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 350–353,
Prague, June 2007. c�2007 Association for Computational Linguistics
</bodyText>
<subsectionHeader confidence="0.994156">
2.2 Relatives in Context (RIC)
</subsectionHeader>
<bodyText confidence="0.9999059">
This is an unsupervised method presented in Mar-
tinez et al. (2006). This algorithm makes use of
the WordNet relatives of the target word for disam-
biguation. The process is carried out in these steps:
(i) obtain a set of close relatives from WordNet for
each sense (the relatives can be polysemous); (ii) for
each test instance define all possible word sequences
that include the target word; (iii) for each word se-
quence, substitute the target word with each relative
and query a web search engine; (iv) rank queries ac-
cording to the following factors: length of the query,
distance of the relative to the target word, and num-
ber of hits; and (v) select the sense associated with
the highest ranked query.
The intuition behind this system is that we can
find related words that can be substituted for the tar-
get word in a given context, which are indicative of
its sense. The close relatives that can form more
common phrases from the target context determine
the target sense.
</bodyText>
<subsectionHeader confidence="0.997617">
2.3 Relative Number (RNB)
</subsectionHeader>
<bodyText confidence="0.999987285714286">
This heuristic has been motivated as a way of identi-
fying rare senses of a word. An important disadvan-
tage of unsupervised systems is that rare senses can
be over-represented in the models, while supervised
systems are able to discard them because they have
access to token-level word sense distributions.
This simple algorithm relies on the number of
close relatives found in WordNet for each sense of
the word. The senses are ranked according to the
number of synonyms, direct hypernyms, and di-
rect hyponyms they have in WordNet. The highest
ranked sense is taken to be the most important for the
target word, and all occurrences of the target word
are tagged with that sense.
</bodyText>
<subsectionHeader confidence="0.991615">
2.4 k-Nearest Neighbours (kNN)
</subsectionHeader>
<bodyText confidence="0.9999215">
As our supervised system, we relied on kNN. This is
a memory-based learning method where the neigh-
bours are the k most similar contexts, represented by
feature vectors (~cZ) of the test vector (~f). The sim-
ilarity among instances is measured by the cosine
of their vectors. The test instance is labeled with the
sense that obtains the maximum sum of the weighted
votes of the k most similar contexts. Each vote is
weighted depending on its (neighbour) position in
the ordered rank, with the closest being first. Equa-
tion 1 formalizes kNN, where CZ corresponds to the
sense label of the i-th closest neighbour.
</bodyText>
<figure confidence="0.7952472">
arg max ∑{ 1
Si k if CZ = 5�
z (1)
Z=1
0 otherwise
</figure>
<bodyText confidence="0.999143625">
The UBC group used a combination of kNN clas-
sifiers trained over a large set of features, and en-
hanced this method using Singular Value Decompo-
sition (SVD) for their supervised submission (UBC-
ALM) to the lexical-sample and all-words subtasks
(Agirre and Lopez de Lacalle, 2007). However, we
only used the basic implementation in this work, due
to time constraints.
</bodyText>
<subsectionHeader confidence="0.997575">
2.5 Combination of systems
</subsectionHeader>
<bodyText confidence="0.999948333333333">
We explored two approaches to combine the stan-
dalone systems. The first consisted simply of adding
up the normalized weights that each system would
give to each sense. We tested this voting approach
both for the unsupervised and supervised settings.
The second method could only be applied in com-
bination with the supervised kNN system. The
idea was to include the unsupervised predictions as
weighted features for the supervised system. We re-
fer to this method as “stacking”, and it has been pre-
viously used to integrate heterogeneous knowledge
sources for WSD (Stevenson and Wilks, 2001).
</bodyText>
<sectionHeader confidence="0.996364" genericHeader="method">
3 Development experiments
</sectionHeader>
<bodyText confidence="0.999893090909091">
We tested the single algorithms and their combina-
tion over both Semcor and the training distribution
of the SemEval-2007 lexical-sample subtask of task
17 (S07LS for short). The goal of these experiments
was to obtain an estimate of the expected perfor-
mance, and submit the most promising configura-
tion. We present first the tests on the unsupervised
setting, and then the supervised setting. It is im-
portant to note that the hand-tagged corpora was not
used to fine-tune the parameters of the unsupervised
algorithms.
</bodyText>
<subsectionHeader confidence="0.99774">
3.1 Unsupervised systems
</subsectionHeader>
<bodyText confidence="0.999917666666667">
For the first evaluation of our unsupervised systems,
we relied on Semcor, and tagged 43,063 instances
of the 329 word types occurring in SemEval-2007
</bodyText>
<page confidence="0.984152">
351
</page>
<table confidence="0.999763333333333">
System Recall
RNB 30.6
TS-MCR 57.5
TS-XWN 47.0
TS-MCR &amp; TS-XWN 57.3
RBN &amp; TS-MCR &amp; TS-XWN 53.6
</table>
<tableCaption confidence="0.883706">
Table 1: Evaluation of standalone and combined
unsupervised systems over 43,063 instances from
Semcor
</tableCaption>
<table confidence="0.7091532">
System Recall
TS-MCR 60.1
TS-XWN 54.3
TS-MCR &amp; TS-XWN 61.1
TS-MCR &amp; TS-XWN &amp; RIC* 61.2
</table>
<tableCaption confidence="0.887708333333333">
Table 2: Evaluation of standalone and combined
unsupervised systems over 8,518 instances from
S07LS training
</tableCaption>
<bodyText confidence="0.997886590909091">
all-words. Due to time constraints, we were not able
to test the RIC algorithm on this dataset. The re-
sults are shown in Table 1. We can see that the RNB
heuristic performs poorly, and that the best configu-
ration consists of applying the single TS-MCR algo-
rithm. From this experiment, we decided to remove
the RNB heuristic and focus on the topic signatures
and RIC.
We also used S07LS for extra experiments in
the unsupervised setting. From the training part of
the S07LS dataset, we extracted 8,518 instances of
words also occurring in SemEval-2007 all-words.
As S07LS used senses from OntoNotes, we relied
on the mapping provided by the task organisers to
link them to WordNet senses. We left RNB out of
this experiment due to its low performance in Sem-
cor, and regarding RIC, we only evaluated a sample
of 68 instances. Results are shown in Table 2. The
best scores are achieved when combining both sets
of topic signatures. The few cases that have been
disambiguated with RIC improve the overall perfor-
mance slightly.
</bodyText>
<subsectionHeader confidence="0.999246">
3.2 Combined system
</subsectionHeader>
<bodyText confidence="0.9999604">
We could not rely on Semcor in the supervised set-
ting (we used it for training), and therefore tried to
use as much data as possible from the training com-
ponent of S07LS, wherein all the instances avail-
able (22,281) were disambiguated. We tested first
</bodyText>
<subsectionHeader confidence="0.891333">
System Recall
</subsectionHeader>
<equation confidence="0.9062905">
kNN 87.4
kNN &amp; TS-MCR 86.8
kNN &amp; TS-XWN 86.4
kNN &amp; TS-MCR &amp; TS-XWN 86.0
</equation>
<tableCaption confidence="0.9380435">
Table 3: Evaluation of voting supervised systems in
22,281 instances from S07LS training
</tableCaption>
<subsectionHeader confidence="0.583738">
System Recall
</subsectionHeader>
<equation confidence="0.308643">
kNN 71.7
kNN &amp; TS-MCR &amp; TS-XWN 71.8
</equation>
<tableCaption confidence="0.841529">
Table 4: Evaluation of “stacking” the unsupervised
systems on kNN over 8,518 instances from S07LS
training
</tableCaption>
<bodyText confidence="0.999308733333333">
the voting combination by adding the normalized
weights from the output of each system. Due to
time constraints we only evaluated the combination
of kNN with TS-MCR and TS-XWN. Results are
shown in Table 3, where we can see that combin-
ing the unsupervised systems with voting hurts the
performance of the kNN method.
Finally, we applied the second combination ap-
proach, consisting of including the predictions of the
unsupervised systems as features for kNN (“stack-
ing”). We performed this experiment on the training
part of S07LS, but only for the 8,518 instances of
the words occurring on the all-words dataset. The
results of this experiment are given in Table 4. We
observed a slight improvement in this case.
</bodyText>
<sectionHeader confidence="0.982883" genericHeader="method">
4 Final systems
</sectionHeader>
<bodyText confidence="0.999952533333333">
For our final submissions, we chose the combination
“TS-MCR &amp; TS-XWN &amp; RIC” for the unsupervised
system (UBC-UMB-1), and the combination “kNN
&amp; TS-MCR &amp; TS-XWN” via “stacking” for our su-
pervised system (UBC-UMB-2). The results of all
the systems are given in Table 5.
We can see that our unsupervised system ranked
10th. Unfortunately, we do not know at the time of
writing which other systems are unsupervised, and
therefore are unable to compare to other unsuper-
vised systems.
Our “stacking” supervised system performs
slightly lower than the kNN supervised systems by
UBC-ALM (which ranks 7th), showing that our sys-
tem was not able to profit from information from
</bodyText>
<page confidence="0.993108">
352
</page>
<table confidence="0.999819133333333">
System Precision Recall
0.537 0.537
0.527 0.527
0.524 0.524
0.522 0.486
0.518 0.518
0.514 0.514
0.493 0.492
8. UBC-UMB-2 0.485 0.484
0.420 0.420
10. UBC-UMB-1 0.362 0.362
0.355 0.355
0.337 0.337
0.298 0.298
0.120 0.118
</table>
<tableCaption confidence="0.465098">
Table 5: Official results for all systems in task #17
of SemEval-2007. Our systems are shown in bold.
UBC-UMB-1 stands for TS-MCR &amp; TS-XWN &amp;
RIC, and UBC-UMB-2 for kNN &amp; TS-MCR &amp; TS-
XWN.
</tableCaption>
<table confidence="0.926135">
System Precision Recall
TS-MCR 36.7 36.5
TS-XWN 33.1 32.9
RIC 30.6 30.4
TS-MCR &amp; TS-XWN 37.5 37.3
TS-MCR &amp; TS-XWN &amp; RIC 36.2 36.2
</table>
<tableCaption confidence="0.988452">
Table 6: Our unsupervised systems in the SemEval-
2007 all words test data
</tableCaption>
<bodyText confidence="0.999820857142857">
the unsupervised systems. However, we cannot at-
tribute the decrease only to the unsupervised fea-
tures, as the kNN implementations were different
(UBC-ALM relied on SVD).
After the gold-standard data was released, we
were able to test the contribution of each of the un-
supervised systems in the ensemble, as well as two
additional combinations. The results are given in
Table 6. We can see that TS-MCR is the best per-
forming method, confirming our development ex-
periments (cf. Tables 1 and 2). In contrast, in-
cluding RIC decreased the performance by 0.7 per-
cent points, and had we used only TS-MCR and TS-
XWN our results would have been better.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999975666666666">
In this submission we combined heterogeneous un-
supervised algorithms to obtain competitive perfor-
mance without relying on training data. However,
due to time constraints, we were only able to submit
a preliminary system, and some of the unsupervised
methods were not properly developed and tested.
For future work we plan to properly test these
methods, and deploy other unsupervised algorithms.
We also plan to explore more sophisticated combina-
tion strategies, using meta-learning to try to predict
which features of each word make a certain WSD
system succeed (or fail).
</bodyText>
<sectionHeader confidence="0.997992" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.985213">
The first and second authors were supported by Aus-
tralian Research Council grant no. DP0663879. We
want to thank German Rigau from the University of
the Basque Country for kindly providing access to
the MCR.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999824">
Eneko Agirre and Oier Lopez de Lacalle. 2004. Pub-
licly available topic signatures for all WordNet nom-
inal senses. In Proceedings of the 4rd International
Conference on Language Resources and Evaluations
(LREC), pages 1123–6, Lisbon, Portugal.
Eneko Agirre and Oier Lopez de Lacalle. 2007. UBC-
ALM: Lexical-Sample and All-Words tasks. In
Proceedings of SemEval-2007 (forthcoming), Prague,
Czech Republic.
Samuel Brody, Roberto Navigli, and Mirella Lapata.
2006. Ensemble methods for unsupervised WSD. In
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th annual meet-
ing of the ACL, pages 97–104, Sydney, Australia.
Montse Cuadros and German Rigau. 2006. Quality as-
sessment of large scale knowledge resources. In Pro-
ceedings of the International Conference on Empirical
Methods in Natural Language Processing (EMNLP-
06), pages 534–41, Sydney, Australia.
David Martinez, Eneko Agirre, and Xinglong Wang.
2006. Word relatives in context for word sense dis-
ambiguation. In Proceedings of the 2006 Australasian
Language Technology Workshop, pages 42–50, Syd-
ney, Australia.
Mark Stevenson and Yorick Wilks. 2001. The interaction
of knowledge sources in word sense disambiguation.
Computational Linguistics, 27(3):321–49.
</reference>
<page confidence="0.999349">
353
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.486320">
<title confidence="0.998053">UBC-UMB: Combining unsupervised and supervised systems for all-words WSD</title>
<author confidence="0.999554">David Martinez</author>
<author confidence="0.999554">Timothy Baldwin</author>
<affiliation confidence="0.9900255">LT Group, CSSE University of Melbourne</affiliation>
<address confidence="0.964379">Victoria 3010 Australia</address>
<author confidence="0.761499">Eneko Agirre</author>
<author confidence="0.761499">Oier Lopez de_Lacalle</author>
<affiliation confidence="0.999473">IXA NLP Group Univ. of the Basque Country</affiliation>
<address confidence="0.687777">Donostia, Basque Country</address>
<abstract confidence="0.9963146">This paper describes the joint submission of two systems to the all-words WSD subtask of SemEval-2007 task 17. The main goal of this work was to build a competitive unsupervised system by combining heterogeneous algorithms. As a secondary goal, we explored the integration of unsupervised predictions into a supervised system by different means.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
</authors>
<title>Publicly available topic signatures for all WordNet nominal senses.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4rd International Conference on Language Resources and Evaluations (LREC),</booktitle>
<pages>1123--6</pages>
<location>Lisbon, Portugal.</location>
<marker>Agirre, de Lacalle, 2004</marker>
<rawString>Eneko Agirre and Oier Lopez de Lacalle. 2004. Publicly available topic signatures for all WordNet nominal senses. In Proceedings of the 4rd International Conference on Language Resources and Evaluations (LREC), pages 1123–6, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<title>Eneko Agirre and Oier Lopez de Lacalle.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval-2007 (forthcoming),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>2007</marker>
<rawString>Eneko Agirre and Oier Lopez de Lacalle. 2007. UBCALM: Lexical-Sample and All-Words tasks. In Proceedings of SemEval-2007 (forthcoming), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Ensemble methods for unsupervised WSD.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL,</booktitle>
<pages>97--104</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1688" citStr="Brody et al., 2006" startWordPosition="252" endWordPosition="255">the integration of this method into a supervised system by different means. Thus, this paper describes both the unsupervised system (UBC-UMB-1), and the combined supervised system (UBC-UMB-2) submitted to the all-words task. Our motivation in building unsupervised systems comes from the difficulty of creating hand-tagged data for all words and all languages, which is colloquially known as the knowledge acquisition bottleneck. There have also been promising results in recent work on the combination of unsupervised approaches that suggest the gap with respect to supervised systems is narrowing (Brody et al., 2006). The remainder of the paper is organized as follows. First we describe the disambiguation algorithms in Section 2. Next, the development experiments are presented in Section 3, and our final submissions and results in Section 4. Finally, we summarize our conclusions in Section 5. 2 Algorithms In this section, we will describe the standalone algorithms (three unsupervised and one supervised) and the combination schemes we explored. The unsupervised methods are based on different intuitions for disambiguation (topical features, local context, and WordNet relations), which is a desirable charact</context>
</contexts>
<marker>Brody, Navigli, Lapata, 2006</marker>
<rawString>Samuel Brody, Roberto Navigli, and Mirella Lapata. 2006. Ensemble methods for unsupervised WSD. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL, pages 97–104, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Montse Cuadros</author>
<author>German Rigau</author>
</authors>
<title>Quality assessment of large scale knowledge resources.</title>
<date>2006</date>
<booktitle>In Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP06),</booktitle>
<pages>534--41</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2551" citStr="Cuadros and Rigau (2006)" startWordPosition="392" endWordPosition="395">we summarize our conclusions in Section 5. 2 Algorithms In this section, we will describe the standalone algorithms (three unsupervised and one supervised) and the combination schemes we explored. The unsupervised methods are based on different intuitions for disambiguation (topical features, local context, and WordNet relations), which is a desirable characteristic for combining algorithms. 2.1 Topic Signatures (TS) Topic signatures (Agirre and de Lacalle, 2004) are lists of words related to a particular sense. They can be built from a variety of sources, and be used directly to perform WSD. Cuadros and Rigau (2006) present a detailed evaluation of topic signatures built from a variety of knowledge sources. In this work we built those coming from the following: • the relations in the Multilingual Central Repository (TS-MCR) • the relations in the Extended WordNet (TSXWN) In order to apply this resource for WSD, we simply measured the word-overlap between the target context and each of the senses of the target word. The sense with highest overlap is chosen as the correct sense. 350 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 350–353, Prague, June 2007. c�200</context>
</contexts>
<marker>Cuadros, Rigau, 2006</marker>
<rawString>Montse Cuadros and German Rigau. 2006. Quality assessment of large scale knowledge resources. In Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP06), pages 534–41, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Martinez</author>
<author>Eneko Agirre</author>
<author>Xinglong Wang</author>
</authors>
<title>Word relatives in context for word sense disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Australasian Language Technology Workshop,</booktitle>
<pages>42--50</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3292" citStr="Martinez et al. (2006)" startWordPosition="511" endWordPosition="515">se coming from the following: • the relations in the Multilingual Central Repository (TS-MCR) • the relations in the Extended WordNet (TSXWN) In order to apply this resource for WSD, we simply measured the word-overlap between the target context and each of the senses of the target word. The sense with highest overlap is chosen as the correct sense. 350 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 350–353, Prague, June 2007. c�2007 Association for Computational Linguistics 2.2 Relatives in Context (RIC) This is an unsupervised method presented in Martinez et al. (2006). This algorithm makes use of the WordNet relatives of the target word for disambiguation. The process is carried out in these steps: (i) obtain a set of close relatives from WordNet for each sense (the relatives can be polysemous); (ii) for each test instance define all possible word sequences that include the target word; (iii) for each word sequence, substitute the target word with each relative and query a web search engine; (iv) rank queries according to the following factors: length of the query, distance of the relative to the target word, and number of hits; and (v) select the sense as</context>
</contexts>
<marker>Martinez, Agirre, Wang, 2006</marker>
<rawString>David Martinez, Eneko Agirre, and Xinglong Wang. 2006. Word relatives in context for word sense disambiguation. In Proceedings of the 2006 Australasian Language Technology Workshop, pages 42–50, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Stevenson</author>
<author>Yorick Wilks</author>
</authors>
<title>The interaction of knowledge sources in word sense disambiguation.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="6582" citStr="Stevenson and Wilks, 2001" startWordPosition="1075" endWordPosition="1078">straints. 2.5 Combination of systems We explored two approaches to combine the standalone systems. The first consisted simply of adding up the normalized weights that each system would give to each sense. We tested this voting approach both for the unsupervised and supervised settings. The second method could only be applied in combination with the supervised kNN system. The idea was to include the unsupervised predictions as weighted features for the supervised system. We refer to this method as “stacking”, and it has been previously used to integrate heterogeneous knowledge sources for WSD (Stevenson and Wilks, 2001). 3 Development experiments We tested the single algorithms and their combination over both Semcor and the training distribution of the SemEval-2007 lexical-sample subtask of task 17 (S07LS for short). The goal of these experiments was to obtain an estimate of the expected performance, and submit the most promising configuration. We present first the tests on the unsupervised setting, and then the supervised setting. It is important to note that the hand-tagged corpora was not used to fine-tune the parameters of the unsupervised algorithms. 3.1 Unsupervised systems For the first evaluation of </context>
</contexts>
<marker>Stevenson, Wilks, 2001</marker>
<rawString>Mark Stevenson and Yorick Wilks. 2001. The interaction of knowledge sources in word sense disambiguation. Computational Linguistics, 27(3):321–49.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>