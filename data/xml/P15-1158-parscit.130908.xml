<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000601">
<title confidence="0.979198">
Why discourse affects speakers’ choice of referring expressions
</title>
<author confidence="0.986068">
Naho Orita
</author>
<affiliation confidence="0.989167">
Graduate School of Information Sciences
Tohoku University
</affiliation>
<email confidence="0.971591">
naho@ecei.tohoku.ac.jp
</email>
<author confidence="0.967778">
Naomi H. Feldman
</author>
<affiliation confidence="0.950515">
Linguistics and UMIACS
University of Maryland
</affiliation>
<email confidence="0.992544">
nhf@umd.edu
</email>
<author confidence="0.96859">
Eliana Vornov
</author>
<affiliation confidence="0.9911905">
Computer Science and Linguistics
University of Maryland
</affiliation>
<email confidence="0.985979">
evornov@umd.edu
</email>
<author confidence="0.996941">
Hal Daum´e III
</author>
<affiliation confidence="0.9978155">
Computer Science and UMIACS
University of Maryland
</affiliation>
<email confidence="0.996569">
hal@umiacs.umd.edu
</email>
<sectionHeader confidence="0.996644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982">
We propose a language production model
that uses dynamic discourse information
to account for speakers’ choices of refer-
ring expressions. Our model extends pre-
vious rational speech act models (Frank
and Goodman, 2012) to more naturally dis-
tributed linguistic data, instead of assuming
a controlled experimental setting. Simula-
tions show a close match between speakers’
utterances and model predictions, indicat-
ing that speakers’ behavior can be modeled
in a principled way by considering the prob-
abilities of referents in the discourse and
the information conveyed by each word.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999989607843138">
Discourse information plays an important role in
various aspects of linguistic processing, such as
predictions about upcoming words (Nieuwland and
Van Berkum, 2006) and scalar implicature process-
ing (Breheny et al., 2006). The relationship be-
tween discourse information and speakers’ choices
of referring expression is one of the most studied
problems. Speakers’ choices of referring expres-
sions have long been thought to depend on the
salience of entities in the discourse (Giv´on, 1983).
For example, speakers normally do not choose a
pronoun to refer to a new entity in the discourse,
but are more likely to use pronouns for referents
that have been referred to earlier in the discourse.
A number of grammatical, semantic, and distribu-
tional factors related to salience have been found to
influence choices of referring expressions (Arnold,
2008). While the relationship between discourse
salience and speakers’ choices of referring expres-
sions is well known, there is not yet a formal ac-
count of why this relationship exists.
In recent years, a number of formal models have
been proposed to capture inferences between speak-
ers and listeners in the context of Gricean prag-
matics (Grice, 1975; Frank and Goodman, 2012).
These models take a game theoretic approach in
which speakers optimize productions to convey in-
formation for listeners, and listeners infer meaning
based on speakers’ likely productions. These mod-
els have been argued to account for human commu-
nication (Jager, 2007; Frank and Goodman, 2012;
Bergen et al., 2012a; Smith et al., 2013), and stud-
ies report that they robustly predict various linguis-
tic phenomena in experimental settings (Goodman
and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et
al., 2014; Nordmeyer and Frank, 2014). However,
these models have not yet been applied to language
produced outside of the laboratory, nor have they
incorporated measures of discourse salience that
can be computed over corpora.
In this paper, we propose a probabilistic model
to explain speakers’ choices of referring expres-
sions based on discourse salience. Our model ex-
tends the rational speech act model from Frank
and Goodman (2012) to incorporate updates to lis-
teners’ beliefs as discourse proceeds. The model
predicts that a speaker’s choice of referring expres-
sions should depend directly on the amount of in-
formation that each word carries in the discourse.
Simulations probe the contribution of each model
component and show that the model can predict
</bodyText>
<page confidence="0.950845">
1639
</page>
<note confidence="0.976813333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1639–1649,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999817090909091">
speakers’ pronominalization in a corpus. These
results suggest that this model formalizes underly-
ing principles that account for speakers’ choices of
referring expressions.
The paper is organized as follows. Section 2
reviews relevant studies on choices of referring ex-
pressions. Section 3 describes the details of our
model. Section 4 describes the data, preprocessing
and annotation procedure. Section 5 presents simu-
lation results. Section 6 summarizes this study and
discusses implications and future directions.
</bodyText>
<sectionHeader confidence="0.998889" genericHeader="introduction">
2 Relevant Work
</sectionHeader>
<subsectionHeader confidence="0.872401">
2.1 Discourse salience
</subsectionHeader>
<bodyText confidence="0.999857852941177">
Speakers’ choices of referring expressions have
long been an object of study. Pronominalization
has been examined particularly often in both theo-
retical and experimental studies. Discourse theories
predict that speakers use pronouns when they think
that a referent is salient in the discourse (Giv´on,
1983; Ariel, 1990; Gundel et al., 1993; Grosz et
al., 1995), where salience of the referent is influ-
enced by various factors such as grammatical posi-
tion (Brennan, 1995), recency (Chafe, 1994), top-
icality (Arnold, 1998), competitors (Fukumura et
al., 2011), visual salience (Vogels et al., 2013b),
and so on.
Discourse theories have characterized the link
between referring expressions and discourse
salience by stipulating constructs such as a scale
of topicality (Giv´on, 1983), accessibility hierarchy
(Ariel, 1990), or implicational hierarchy (Gundel et
al., 1993). All of these assume fixed form-salience
correspondences in that a certain referring expres-
sion encodes a certain degree of salience. However,
it is not clear how this form-salience mapping holds
nor why it should be.
There is also a rich body of research that points
to the importance of production cost (Rohde et al.,
2012; Bergen et al., 2012b; Degen et al., 2013)
and listener models (Bard et al., 2004; Van der
Wege, 2009; Galati and Brennan, 2010; Fukumura
and van Gompel, 2012) in language production.
These studies suggest that only considering dis-
course salience of the referent may not precisely
capture speakers’ choices of referring expressions,
and it is necessary to examine discourse salience in
relation to these other factors.
</bodyText>
<subsectionHeader confidence="0.994743">
2.2 Formal models
</subsectionHeader>
<bodyText confidence="0.999919078947369">
Computational models relevant to speakers’
choices of referring expressions have been pro-
posed, but there is a gap between questions that
previous models have addressed and the questions
that we have raised above.
Gr¨uning and Kibrik (2005) and Khudyakova et
al. (2011) examine the significance of various fac-
tors that might influence choices of referring ex-
pressions by using machine learning models such
as neural networks, logistic regression and decision
trees. Although these models qualitatively show
some significant factors, they are data-driven rather
than being explanatory, and have not focused on
why and how these factors result in the observed
referring choices.
Formal models that go beyond identifying super-
ficial factors focus on only pronouns rather than
accounting for speakers’ word choices per se. For
example, Kehler et al. (2008) formalize a relation-
ship between pronoun comprehension and produc-
tion using Bayes’ rule to account for comprehen-
der’s semantic bias in experimental data. Rij et al.
(2013) use ACT-R (Anderson, 2007) to examine
the effects of working memory load in pronoun
interpretation. These models show how certain fac-
tors influence pronoun production/interpretation,
but it is not clear how these models would predict
speakers’ choices of referring expressions.
Relevant formal models in computational lin-
guistics include Centering theory (Grosz et al.,
1995; Poesio et al., 2004) and Referring Expres-
sion Generation (Krahmer and Van Deemter, 2012).
These models propose deterministic constraints
governing when pronouns are preferred in local dis-
course, but it is not clear how these would account
for speakers’ choices of referring expressions, nor
it is clear why there should be such deterministic
constraints.
</bodyText>
<subsectionHeader confidence="0.993393">
2.3 Uniform Information Density
</subsectionHeader>
<bodyText confidence="0.999647">
One potential formal explanation for the relation
between discourse salience and speakers’ choices
of referring expressions is the Uniform Informa-
tion Density hypothesis (UID) (Levy and Jaeger,
2007; Tily and Piantadosi, 2009; Jaeger, 2010).
UID states that speakers prefer to smooth the in-
formation density distribution of their utterances
over time to achieve optimal communication. This
theory predicts that speakers should use pronouns
instead of longer forms (e.g., the president) when a
</bodyText>
<page confidence="0.980825">
1640
</page>
<bodyText confidence="0.999948269230769">
referent is predictable in the context, whereas they
should use longer forms for unpredictable referents
that carry more information (Jaeger, 2010).
Tily and Piantadosi (2009) empirically exam-
ined the relationship between predictability of a
referent and choice of referring expressions. They
found that predictability is a significant predictor
of writers’ choices of referring expressions, in that
pronouns are used when a referent is predictable.
While these results appear to support UID, there
are several inconsistencies with previous UID ac-
counts. Information content of words has been
estimated using an n-gram language model (Levy
and Jaeger, 2007), a verb’s subcategorization fre-
quency (Jaeger, 2010), and so on, whereas here
the information content is that of referents with
respect to discourse salience. In addition, selecting
between a pronoun and a more specified referring
expression involves deciding how much informa-
tion to convey, whereas previous applications of
UID (Levy and Jaeger, 2007) have been concerned
with deciding between different ways of expressing
the same information content. We show in the next
section that we can derive predictions about refer-
ring expressions directly from a model of language
production.
</bodyText>
<subsectionHeader confidence="0.994728">
2.4 Summary
</subsectionHeader>
<bodyText confidence="0.999939222222222">
Previous linguistic studies have focused on identi-
fying factors that might influence choices of refer-
ring expressions. However, it is not clear from this
previous work how and why these factors result
in the observed patterns of referring expressions.
Where formal models relevant to this topic do exist,
they have not been built to explain why there is a
relation between discourse salience and speakers’
choices of referring expressions. Even UID, which
relates predictability to word length, is not set up
to account for the choice between words that vary
in their information content.
In the next section, we propose a speaker model
that formalizes the relation between discourse
salience and speakers’ choices of referring expres-
sions, considering production cost and speakers’
inference about listeners in a principled and ex-
planatory way.
</bodyText>
<sectionHeader confidence="0.999002" genericHeader="method">
3 Speaker model
</sectionHeader>
<subsectionHeader confidence="0.999938">
3.1 Rational speaker-listener model
</subsectionHeader>
<bodyText confidence="0.99920075">
We adopt the rational speaker-listener model from
Frank and Goodman (2012) and extend this model
to predict speakers’ choices of referring expres-
sions using discourse information.
The main idea of Frank and Goodman’s model
is that a rational pragmatic listener uses Bayesian
inference to infer the speaker’s intended referent
rs given the word w, their vocabulary (e.g., ‘blue’,
‘circle’), and shared context that consists of a set
of objects O (e.g., visual access to object referents)
as in (1), assuming that a speaker has chosen the
word informatively.
</bodyText>
<equation confidence="0.998968333333333">
PS(w|rs, O)P(rs)
P(rs|w, O) = (1)
Σr&apos;∈OP(w |r , O)P(r )
</equation>
<bodyText confidence="0.9745048">
While our work does not make use of this pragmatic
listener, it does build on the speaker model assumed
by the pragmatic listener. This speaker model (the
likelihood term in the listener model) is defined
using an exponentiated utility function as in (2).
</bodyText>
<equation confidence="0.961074">
PS(w|rs, O) a eαU(w;rs,O) (2)
</equation>
<bodyText confidence="0.992134875">
The utility U(w; rs, O) is defined as I(w; rs, O) −
D(w), where I(w; rs, O) represents informative-
ness of word w (quantified as surprisal) and D(w)
represents its speech cost. If a listener interprets
word w literally and cost D(w) is constant, the ex-
ponentiated utility function can be reduced to (3)
where |w |denotes the number of referents that the
word w can be used to refer to.
</bodyText>
<equation confidence="0.9908775">
PS(w |rs, O) a |1 (3)
w|
</equation>
<bodyText confidence="0.999977727272727">
Thus, the speaker model chooses a word based on
its specificity. We show in the next section that
this corresponds to a speaker who is optimizing
informativeness for a listener with uniform beliefs
about what will be referred to in the discourse. The
assumption of uniform discourse salience works
well in a simple language game where there are
a limited number of referents that have roughly
equal salience, but we show that a model that lacks
a sophisticated notion of discourse falls short in
more realistic settings.
</bodyText>
<subsectionHeader confidence="0.999813">
3.2 Incorporating discourse salience
</subsectionHeader>
<bodyText confidence="0.999956875">
To extend Frank and Goodman’s model to a natu-
ral linguistic situation, we assume that the speaker
estimates the listener’s interpretation of a word (or
referring expression) w based on discourse informa-
tion. We extend the speaker model from (3) by as-
suming that a speaker S chooses w to optimize a lis-
tener’s belief in speaker’s intended referent r rela-
tive to the speaker’s own speech cost Cw. This cost
</bodyText>
<page confidence="0.947484">
1641
</page>
<bodyText confidence="0.987563">
is another factor in the speaker model, roughly cor-
responding to utterance complexity such as word
length.1
</bodyText>
<equation confidence="0.978447666666667">
1
PS(w|r) ∝ PL(r|w) · (4)
Cw
</equation>
<bodyText confidence="0.999504375">
The term PL(r|w) in (4) represents informative-
ness of word w: the speaker chooses w that most
helps a listener L to infer referent r. The term Cw
in (4) is a cost function: the speaker chooses w that
is least costly to speak.
The speaker’s listener model, PL(r|w), infers
referent r that is referred to by word w according
to Bayes’ rule as in (5).
</bodyText>
<equation confidence="0.999388333333333">
P(w|r)P(r)
PL(r|w) = (5)
Σr,P(w|r0)P(r0)
</equation>
<bodyText confidence="0.999366821428571">
The first term in the numerator, P(w|r), is a word
probability: the listener in the speaker’s mind
guesses how likely the speaker would be to use w to
refer to r. The second term in the numerator, P(r),
is the discourse salience (or predictability) of refer-
ent r. The denominator Σr,P(w|r0)P(r0) is a sum
of potential referents r0 that could be referred to by
word w. The terms in this sum are non-zero only
for referents that are compatible with the meaning
of the word. If there are many potential referents
that could be referred to by word w, that word
would be more ambiguous thus less informative.
The whole of the right side in Equation (5) repre-
sents the speaker’s assumption about the listener:
given word w the listener would infer referent r
that is salient in a discourse and less ambiguously
referred to by word w.
If P(r) is uniform over referents and P(w|r) is
constant across words and referents, this listener
model reduces to 1
|w|. Thus, Frank and Goodman
(2012)’s speaker model in (3) is a special case of
our speaker model in (4) that assumes uniform
discourse salience and constant cost.
Our model predicts that the speaker’s probability
of choosing a word for a given referent should
depend on its cost relative to its information content.
To see this, we combine (4) and (5), yielding
</bodyText>
<equation confidence="0.957826666666667">
P (w|r)P (r) 1
PS(w|r) ∝ �r, P (w|r0)P (r0) · (6)
Cw
</equation>
<bodyText confidence="0.936906066666667">
Because the speaker is deciding what word to use
for an intended referent, and the term P(r) denotes
1Our speaker model corresponds to Frank and Goodman’s
exponentiated utility function (2), with α equal to one and
with their cost D(w) being the log of our cost C,,.
the probability of this referent, P(r) is constant in
the speaker model and does not affect the relative
probability of a speaker producing different words.
We further assume for simplicity that P(w|r) is
constant across words and referents. This means
that all referents have about the same number of
words that can be used to refer to them, and that
all words for a given referent are equally probable
for a naive listener. In this scenario, the speaker’s
probability of choosing a word is
</bodyText>
<equation confidence="0.973792">
1 1
PS(w|r) ∝ Er, P(r0) · (7)
Cw
</equation>
<bodyText confidence="0.999992466666667">
where the sum denotes the total discourse probabil-
ity of the referents referred to by that word.
The information content of an event is defined
as the negative log probability of that event. In this
scenario, the information conveyed by a word is the
logarithm of the first term in (7), − log Er, P(r0).
This means that in deciding which word to use,
the highest cost a speaker should be willing to pay
for a word should depend directly on that word’s
information content.
This relationship between cost and information
content allows us to derive the prediction tested by
Tily and Piantadosi (2009) that the use of referring
expressions should depend on the predictability
of a referent. For referents that are highly pre-
dictable from the discourse, different referring ex-
pressions (e.g., pronouns and proper names) will
have roughly equal information content, and speak-
ers should choose the referring expression that has
the lowest cost. In contrast, for less predictable ref-
erents, proper names will carry substantially more
information than pronouns, leading speakers to pay
a higher cost for the proper names. These are the
same predictions that have been discussed in the
context of UID, but here the predictions are derived
from a principled model of speakers who are try-
ing to provide information to listeners. The extent
to which our model can also capture other cases
that have been put forward as evidence for the UID
hypothesis remains a question for future research.
</bodyText>
<subsectionHeader confidence="0.999906">
3.3 Predicting behavior from corpora
</subsectionHeader>
<bodyText confidence="0.999977">
The model described in Section 3.2 is fully general,
applying to arbitrary word choices, discourse prob-
abilities, and cost fuctions. As an initial step, our
simulations focus on the choice between pronouns
and proper names. Our work tests the speaker
model from (4) directly, asking whether it can pre-
dict the referring expressions from corpora of writ-
</bodyText>
<page confidence="0.975042">
1642
</page>
<bodyText confidence="0.9998818">
ten and spoken language. Implementing the model
requires computing word probabilities P(w|r), dis-
course salience P(r), and word costs C,,,.
We simplify the word probability P(w|r) in the
speaker’s listener model as in (8):
</bodyText>
<equation confidence="0.998561333333333">
1
P(w|r) = (8)
V
</equation>
<bodyText confidence="0.998505529411765">
where the count V is the number of words that can
refer to referent r. We assume that V is constant
across all referents. Our reasoning is as follows.
There could be many ways to refer to a single entity.
For example, to refer to entity Barack Obama, we
could say ‘he’, ‘The U.S. president’, ‘Barack’, and
so on. We assume that there are the same number
of referring expressions for each entity and that
each referring expression is equally probable under
the listener’s likelihood model.
In our simulations, we assume that a speaker is
choosing between a proper name and a pronoun.
For example, we assume that an entity Barack
Obama has one and only one proper name ‘Barack
Obama’, and this entity is unambiguously associ-
ated with male and singular. Although we use an
example with two possible referring expressions,
as long as P(w|r) is constant across all referents
and words, it does not make a difference to the
computation in (5) how many competing words we
assume for each referent.
To estimate the salience of a referent, P(r), our
framework employs factors such as referent fre-
quency or recency. Although there are other impor-
tant factors such as topicality of the referent (Orita
et al., 2014) that are not incorporated in our sim-
ulations, this model sets up a framework to test
the role and interaction of various potential factors
suggested in the discourse literature.
Salience of the referent is computed differently
depending on its information status: old or new.
The following illustrates the speaker’s assumptions
about the listener’s discourse model:
For each referent r ∈ [1, Rd]:
</bodyText>
<listItem confidence="0.999075625">
1. If r = old, choose r in proportion to Nr (the
number of times referent r has been referred
to in the preceding discourse).
2. Otherwise, r = new with probability propor-
tional to α (a hyperparameter that controls
how likely the speaker is to refer to a new
referent).
3. If r = new, sample that new referent r from
</listItem>
<bodyText confidence="0.996303535714286">
the base distribution over entities with proba-
bility U·1 (count U· denotes a total number of
unseen entities that is estimated from a named
entity list (Bergsma and Lin, 2006)).
The above discourse model is frequency-based.
We can replace the term Nr for the old referent with
f(di,j) = e−di,j/a that captures recency, where the
recency function f(di,j) decays exponentially with
the distance between the current referent ri and the
same referent rj that has previously been referred
to. This framework for frequency and recency of
new and old referents exactly corresponds to pri-
ors in the Chinese Restaurant Process (Teh et al.,
2006) and the distance-dependent Chinese Restau-
rant Process (Blei and Frazier, 2011).
The denominator in (5) represents the sum of
potential referents that could be referred to by word
w. We assume that a pronoun can refer to a large
number of unseen referents if gender and number
match, but a proper name cannot. For example, ‘he’
could refer to all singular and male referents, but
‘Barack Obama’ can only refer to Barack Obama.
This assumption is reflected as a probability of
unseen referents for the pronoun as illustrated in
(10) below.
In our simulations, the speaker’s cost function
C,,, is estimated based on word length as in (9). We
assume that longer words are costly to produce.
</bodyText>
<equation confidence="0.993249">
C,,, = length(w) (9)
</equation>
<bodyText confidence="0.999827125">
Suppose that the speaker is considering using
‘he’ to refer to Barack Obama, which has been
referred to NO times in the preceding discourse,
and there is another singular and male entity, Joe
Biden, in the preceding discourse that has been
referred to NB times. In this situation, the model
computes the probability that the speaker uses ‘he’
to refer to Barack Obama as follows:
</bodyText>
<equation confidence="0.941533375">
PS(‘he’|Obama)
∝ PL(Obama|‘he’) · 1
C‘he’
= P(‘he’jObama)P(Obama)
Σr,P(‘he’jr1)P(r1) ·C‘he’
= V1 ·NO 1
(V1·NO)+( 1V·NB)+(v ·α· Usin U·
g&amp;masc) C‘he’
</equation>
<bodyText confidence="0.99990175">
where count Using&amp;masc in the denominator of the
last line denotes the number of unseen singular &amp;
male entities that could be referred to by ‘he’. We
estimate this number for each type of pronoun we
</bodyText>
<equation confidence="0.5787225">
1
(10)
</equation>
<page confidence="0.867753">
1643
</page>
<bodyText confidence="0.9863467">
evaluate (singular-female, singular-male, singular-
neuter, and plural) based on the named entity list
in Bergsma and Lin (2006). The term (1V · α ·
Using&amp;masc U· ) is the sum of probabilities of unseen
referents that could be referred to by the pronoun
‘he’. The unseen referents can be interpreted as a
penalty for the inexplicitness of pronouns. In the
case of proper names, the denominator is always
the same as the numerator, under the assumption
that each entity has one unique proper name.
</bodyText>
<sectionHeader confidence="0.999391" genericHeader="method">
4 Data
</sectionHeader>
<subsectionHeader confidence="0.997791">
4.1 Corpora
</subsectionHeader>
<bodyText confidence="0.99966865625">
Our model was run on both adult-directed speech
and child-directed speech. We chose to use the
SemEval-2010 Task 1 subset of OntoNotes (Re-
casens et al., 2011), a corpus of news text, as our
corpus of adult-directed speech. The Gleason et al.
(1984) subset of CHILDES (MacWhinney, 2000)
was chosen as our corpus of child-directed speech.
The model requires coreference chains, agree-
ment information, grammatical position, and part
of speech. These were extracted from each corpus,
either manually or automatically. The coreference
chains let us easily count how many times/how
recently each referent is mentioned in the dis-
course, which is necessary for computing discourse
salience. The agreement information (gender and
number of each referent) is required so that the
model can identify all possible competing refer-
ents for pronouns. For instance, Barack Obama
will be ruled out as a possible competitor for the
pronoun she. The grammatical position that each
proper name occupies2 determines the form of the
alternative pronoun that could be used there. For
example, the difference between he and him is the
grammatical position that each can appear in. The
part of speech is used to identify the form of the
referring expression (pronouns and proper names),
which is what our model aims to predict.3
OntoNotes includes information about corefer-
ence chains, part of speech, and grammatical de-
pendencies. Gleason CHILDES has parsed part of
speech and grammatical dependencies (Sagae et
al., 2010), but it does not have coreference chains.
</bodyText>
<footnote confidence="0.7809555">
2Dependency tags used were ‘SUBJ’, ‘OBJ’, and ‘PMOD’
in OntoNotes and ‘SBJ’ and ‘OBJ’ in CHILDES.
3The part of speech used to extract the target NPs were
‘PRP’ (pronoun), ‘NNP’ (proper name), and ‘NNPS’ (plu-
ral proper name) from OntoNotes and ‘pro’ (pronoun) and
‘n:prop’ (proper name) from CHILDES.
</footnote>
<bodyText confidence="0.9995334">
Neither corpus has agreement information. The fol-
lowing section describes manual annotations that
we have done for this study. Due to time constraints,
we annotated only a part of the CHILDES Gleason
corpus, 9 out of 70 scripts.
</bodyText>
<subsectionHeader confidence="0.8825435">
4.2 Annotation
4.2.1 Mention annotation
</subsectionHeader>
<bodyText confidence="0.999937916666667">
We considered only maximally spanning noun
phrases as mentions, ignoring nested NPs and
nested coreference chains. For the sentence “Both
Al Gore and George W. Bush have different ideas
on how to spend that extra money” from OntoNotes,
the extracted NPs are Both Al Gore and George W.
Bush and different ideas about how to spend that
extra money.
These maximally spanning NPs were automati-
cally extracted from the OntoNotes data, but were
manually annotated for the CHILDES data using
brat (Stenetorp et al., 2012) by two annotators.4
</bodyText>
<subsectionHeader confidence="0.674245">
4.2.2 Agreement annotation
</subsectionHeader>
<bodyText confidence="0.999970647058823">
Many mentions (46,246 out of 56,575 mentions in
OntoNotes and 10,141 out of 10,530 mentions in
CHILDES Gleason) were automatically annotated
using agreement information from the named entity
list in Bergsma and Lin (2006), leaving 10,329
to be manually annotated from OntoNotes (about
18%) and 389 from CHILDES (about 4%).5
The guidelines we followed for this manual
agreement annotation were largely based on pro-
noun replacement tests. NPs that referred to a sin-
gle man and could be replaced with he or him were
labeled ‘male singular’, NPs that could be replaced
by it, such as the comment, were labeled ‘neuter
singular’, and so on. NPs that could not be replaced
with a pronoun, such as about 30 years earnings
for the average peasant, who makes $145 a year,
were excluded from the analysis.
</bodyText>
<subsectionHeader confidence="0.806666">
4.2.3 Coreference annotation
</subsectionHeader>
<bodyText confidence="0.9999366">
We used the provided coreference chains for the
OntoNotes data, but for the CHILDES data, it was
necessary to do this manually using brat. The guide-
lines we followed for determining whether men-
tions coreferred came from the OntoNotes corefer-
</bodyText>
<footnote confidence="0.9958464">
4Interannotator agreement for the CHILDES mention an-
notation was: precision 0.97, recall 0.98, F-score 0.97 (for
two scripts).
5Interannotator agreement for the manual annotation of
agreement information was 97% (for 500 mentions).
</footnote>
<page confidence="0.991824">
1644
</page>
<figure confidence="0.888662">
ence guidelines (BBN Technologies, 2007).6 referent hyperparameter α and the decay parameter
for discourse recency salience were fixed at 0.1 and
5 Experiments 3.0, respectively.7
</figure>
<bodyText confidence="0.999927463414634">
Our experiments are designed to quantify the contri-
butions of the various components of the complete
model described in Section 3.2 that incorporates
discourse salience, cost, and unseen referents. We
contrast the complete model with three impover-
ished models that lack precisely one of these com-
ponents. The comparison model without discourse
uses a uniform discourse salience distribution. The
model without cost uses constant speech cost. The
model without good estimates of unseen referents
always assigns probability V1 · α · C· 1 to unseen
referents in the denominator of (5), regardless of
whether the word is a proper name or pronoun. In
other words, this model does not have good esti-
mates of unseen referents like the complete model
does.
We use the adult- and child-directed corpora to
examine to what extent each model captures speak-
ers’ referring expressions. We selected pronouns
and proper names in each corpus according to sev-
eral criteria. First, the referring expression had
to be in a coreference chain that had at least one
proper name, in order to facilitate computing the
cost of the proper name alternative. Second, pro-
nouns were only included if they were third person
pronouns in subject or object position, and index-
icals and reflexives were excluded. Finally, for
the CHILDES corpus, children’s utterances were
excluded.
After filtering pronouns and proper names ac-
cording to these criteria, 553 pronouns and 1,332
proper names (total 1,885 items) in the OntoNotes
corpus, and 165 pronouns and 149 proper names
(total 314 items) in the CHILDES Gleason corpus
remained for use in the analysis.
Each model chooses referring expressions given
information extracted from each corpus as de-
scribed in Section 4.1. For evaluation, we com-
puted accuracies (total, pronoun, and proper name)
and model log likelihood (summing log PS(w|r)
for the words in the corpus) for each model.
</bodyText>
<sectionHeader confidence="0.536694" genericHeader="evaluation">
5.1 Results
</sectionHeader>
<bodyText confidence="0.974538">
Table 1 summarizes the results of each model with
the OntoNotes and CHILDES datasets. The new
</bodyText>
<footnote confidence="0.985979666666667">
6Interannotator agreement for CHILDES coreference an-
notation was computed using B3 (Bagga and Baldwin, 1998):
precision: 0.99, recall: 1.00 (for one script).
</footnote>
<subsubsectionHeader confidence="0.594156">
5.1.1 News
</subsubsectionHeader>
<bodyText confidence="0.980229936170213">
Overall, the recency salience measure provides a
better fit than the frequency salience measure with
respect to accuracies, suggesting that recency bet-
ter captures speakers’ representations of discourse
salience that influence choices of referring expres-
sions. On the other hand, the models with fre-
quency discourse salience have higher model log
likelihood than the models with recency do. This
is because of the peakiness of the recency models.
Model log likelihood computed over pronouns and
proper names (complete model) were -1022.33 and
-222.76, respectively, with recency, and -491.81 and
-467.06 with frequency. The recency model tends
to return a higher probability for a proper name
than the frequency model does. Some pronouns
receive a very low probability for this reason, and
this lowers the model log likelihood.
The model without discourse and the model with-
out cost consistently failed to predict pronouns
(these models predicted all proper names). This
happens because in the model without discourse,
the information content of pronouns is extremely
low due to the large number of consistent unseen
referents. In the model without cost, pronouns are
disfavored because they always convey less infor-
mation than proper names. The log likelihoods of
these models were also below that of the complete
model. These results show that pronominalization
depends on subtle interaction between discourse
salience and speech cost. Neither of them is suf-
ficient to explain the distribution of pronouns and
nouns on its own.
The total accuracy of the model without good
estimates of unseen referents was the worst among
the four models, but this model did predict pro-
nouns to some extent. Because the number of
proper names is larger than the number of pronouns
in this dataset, the difference in total accuracies be-
tween the model without good estimates of unseen
referents and the models without discourse or cost
reflects this asymmetry. Comparison between the
complete model and the model without good esti-
mates of unseen referents also suggests that having
knowledge of unseen referents helps correctly pre-
7We chose the best parameter values based on multiple
runs, but results were qualitatively consistent across a range
of parameter values.
</bodyText>
<page confidence="0.945314">
1645
</page>
<table confidence="0.999876266666667">
Corpus Model Discourse Total accuracy Pronoun accuracy Proper name accuracy Log-lhood
complete recency 80.27% 59.49% 88.89% -1245.09
frequency 73.10% 62.74% 77.40% -958.87
-discourse NA 70.66% 0.00% 100.00% -6904.77
OntoNotes -cost recency 70.66% 0.00% 100.00% -1537.71
frequency 70.66% 0.00% 100.00% -1017.38
-unseen recency 64.14% 68.17% 62.46% -1567.51
frequency 56.98% 76.67% 48.80% -1351.58
complete recency 49.68% 11.52% 91.95% -968.64
frequency 46.18% 10.30% 85.91% -360.28
-discourse NA 47.45% 0.00% 100.00% -2159.22
CHILDES -cost recency 47.45% 0.00% 100.00% -1055.54
frequency 47.45% 0.00% 100.00% -392.72
-unseen recency 50.31% 13.94% 90.60% -961.54
frequency 48.41% 21.21% 78.52% -332.73
</table>
<tableCaption confidence="0.999858">
Table 1: Accuracies and model log-likelihood
</tableCaption>
<bodyText confidence="0.855869">
dict the use of proper names in the first mention of
a referent.
</bodyText>
<subsubsectionHeader confidence="0.91303">
5.1.2 Child-directed speech
</subsubsectionHeader>
<bodyText confidence="0.999983961538462">
Unlike the adult-directed news text, neither recency
nor frequency discourse salience provides a good
fit to the data. The low accuracies of pronouns and
the high accuracies of proper names in all models
indicate that the models are more likely to predict
proper names than pronouns. There are several
possible reasons for this. First, the CHILDES tran-
scripts involve long conversations in a natural set-
tings. Compared to the news, interlocutors are not
focusing on a specific topic, but rather they often
switch topics (e.g., a child interrupts her parents’
conversation about her father’s coworker to talk
about her eggs). This topic switching makes it dif-
ficult for the model to estimate discourse salience
using simple frequency or recency measures. Sec-
ond, interlocutors are a family and they share a
good deal of common knowledge/background (e.g.,
a mother said she as the first mention of her child’s
friend’s mother). The current model is not able
to incorporate this kind of background knowledge.
Third, many referents are visually available. The
current model is not able to use visual salience. In
general, these problems arise due to our impover-
ished estimates of salience, and we would expect a
more sophisticated discourse model that accurately
measured salience to show better performance.
</bodyText>
<subsectionHeader confidence="0.998668">
5.2 Summary
</subsectionHeader>
<bodyText confidence="0.999987875">
Experiments with the adult-directed news corpus
show a close match between speakers’ utterances
and model predictions. On the other hand, exper-
iments with child-directed speech show that the
models were more likely to predict proper names
where pronouns were used, suggesting that the esti-
mates of discourse salience using simple measures
were not sufficient to capture a conversation.
</bodyText>
<sectionHeader confidence="0.998917" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.9998105">
This paper proposes a language production model
that extends the rational speech act model from
Frank and Goodman (2012) to incorporate updates
to listeners’ beliefs as discourse proceeds. We show
that the predictions suggested from UID in this do-
main can be derived from our speaker model, pro-
viding an explanation from first principles for the
relation between discourse salience and speakers’
choices of referring expressions. Experiments with
an adult-directed news corpus show a close match
between speakers’ utterances and model predic-
tions, and experiments with child-directed speech
show a qualitatively similar pattern. This suggests
that speakers’ behavior can be modeled in a princi-
pled way by considering the probabilities of refer-
ents in the discourse and the information conveyed
by each word.
A controversial issue in language production is
to what extent speakers consider a listener’s dis-
course model (Fukumura and van Gompel, 2012).
By incorporating an explicit model of listeners, our
model provides a way to explore this question. For
example, the speaker’s listener model PL(rIw) in
(4) might differ between contexts and could also be
extended to sum over possible listener identity q in
mixed contexts, as in (11).
</bodyText>
<equation confidence="0.999059">
PL(rlw) = ΣQP(r|w, q)P(q) (11)
</equation>
<bodyText confidence="0.999774">
This provides a way to probe speakers’ sensitiv-
ity to differences in listener characteristics across
situations.
</bodyText>
<page confidence="0.972156">
1646
</page>
<bodyText confidence="0.999992595238095">
Although the simulations in this paper employed
simple measures for discourse salience (referent
frequency and recency), the discourse models used
by speakers are likely to be more complex. Stud-
ies show that semantic information that cannot be
captured with these simple measures, such as topi-
cality (Orita et al., 2014) and animacy (Vogels et
al., 2013a), affects speakers’ choices of referring
expressions. Future work will test to what extent
this latent discourse information could affect the
model predictions.
Our model predicts a tight coupling between the
probability of a referent being mentioned, p(r),
and the choice of referring expression. However,
these two quantities appear to be dissociated in
some cases. For example, Fukumura and Van Gom-
pel (2010) show that semantic bias (as a measure
of predictability) affects what to refer to (i.e., the
referent), but not how to refer (i.e., the referring
expression), while grammatical position does af-
fect how you refer. One way of dissociating the
probability of mention from the choice of referring
expression in our model would be through the likeli-
hood term, the word probability p(wIr). While we
have assumed this word probability to be constant
across words and referents, Kehler et al. (2008) use
grammatical position to define this probability and
show that their model captures experimental data.
Syntactic constraints (such as Binding principles)
also influence form choices, and this kind of knowl-
edge may also be reflected in the word probability.
Examining the role of the word probability p(wIr)
more closely would allow us to further explore
these issues.
Despite these limitations, our model provides
a principled explanation for speakers’ choices of
referring expressions. In future work we hope to
look at a broader range of referring expressions,
such as null pronouns and definite descriptions,
and to explore the extent to which our model can
be applied to other linguistic phenomena that rely
on discourse information.
</bodyText>
<sectionHeader confidence="0.998027" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999875">
We thank the UMD probabilistic modeling reading
group for helpful comments and discussion.
</bodyText>
<sectionHeader confidence="0.998466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.820670527272727">
John R Anderson. 2007. How can the human mind
occur in the physical universe? Oxford University
Press.
Mira Ariel. 1990. Accessing noun-phrase antecedents.
Routledge.
Jennifer Arnold. 1998. Reference form and discourse
patterns. Ph.D. thesis, Stanford University Stanford,
CA.
Jennifer Arnold. 2008. Reference produc-
tion: Production-internal and addressee-oriented
processes. Language and cognitive processes,
23(4):495–527.
Amit Bagga and Breck Baldwin. 1998. Algorithms
for scoring coreference chains. In The first interna-
tional conference on language resources and evalua-
tion workshop on linguistics coreference, volume 1,
pages 563–566.
Ellen Gurman Bard, Matthew P Aylett, J Trueswell,
and M Tanenhaus. 2004. Referential form, word du-
ration, and modeling the listener in spoken dialogue.
Approaches to studying world-situated language use:
Bridging the language-as-product and language-as-
action traditions, pages 173–191.
BBN Technologies. 2007. OntoNotes English co-
reference guidelines version 7.0.
Leon Bergen, Noah Goodman, and Roger Levy. 2012a.
That’s what she (could have) said: How alternative
utterances affect language use. In Proceedings of
the 34th Annual Conference of the Cognitive Science
Society.
Leon Bergen, Noah D Goodman, and Roger Levy.
2012b. That’s what she (could have) said: How
alternative utterances affect language use. In Pro-
ceedings of the thirty-fourth annual conference of
the cognitive science society.
Shane Bergsma and Dekang Lin. 2006. Bootstrapping
path-based pronoun resolution. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 33–40,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
David M Blei and Peter I Frazier. 2011. Distance de-
pendent Chinese restaurant processes. The Journal
of Machine Learning Research, 12:2461–2488.
Richard Breheny, Napoleon Katsos, and John Williams.
2006. Are generalised scalar implicatures generated
by default? an on-line investigation into the role of
context in generating pragmatic inferences. Cogni-
tion, 100(3):434–463.
Susan E Brennan. 1995. Centering attention in
discourse. Language and Cognitive Processes,
10(2):137–167.
Wallace Chafe. 1994. Discourse, consciousness, and
time. Discourse, 2(1).
</reference>
<page confidence="0.924622">
1647
</page>
<reference confidence="0.999682280373831">
Judith Degen, Michael Franke, and Gerhard J¨ager.
2013. Cost-based pragmatic inference about referen-
tial expressions. In Proceedings of the 35th Annual
Conference of the Cognitive Science Society, pages
376–381.
Michael Frank and Noah Goodman. 2012. Predicting
pragmatic reasoning in language games. Science,
336(6084):998–998.
Kumiko Fukumura and Roger PG Van Gompel. 2010.
Choosing anaphoric expressions: Do people take
into account likelihood of reference? Journal of
Memory and Language, 62(1):52–66.
Kumiko Fukumura and Roger PG van Gompel. 2012.
Producing pronouns and definite noun phrases: Do
speakers use the addressee’s discourse model? Cog-
nitive Science, 36(7):1289–1311.
Kumiko Fukumura, Roger PG Van Gompel, Trevor
Harley, and Martin J Pickering. 2011. How does
similarity-based interference affect the choice of re-
ferring expression? Journal of Memory and Lan-
guage, 65(3):331–344.
Alexia Galati and Susan E Brennan. 2010. Attenuat-
ing information in spoken communication: For the
speaker, or for the addressee? Journal of Memory
and Language, 62(1):35–51.
Talmy Giv´on. 1983. Topic continuity in discourse: A
quantitative cross-language study, volume 3. John
Benjamins Publishing.
Jean Berko Gleason, Rivka Y Perlmann, and Es-
ther Blank Greif. 1984. What’s the magic word:
Learning language through politeness routines. Dis-
course Processes, 7(4):493–502.
Noah D Goodman and Andreas Stuhlm¨uller. 2013.
Knowledge and implicature: Modeling language un-
derstanding as social cognition. Topics in Cognitive
Science.
H Paul Grice. 1975. Logic and conversation. Syntax
and semantics, 3:41–58.
Barbara J Grosz, Scott Weinstein, and Aravind K Joshi.
1995. Centering: A framework for modeling the lo-
cal coherence of discourse. Computational Linguis-
tics, 21(2):203–225.
Andr´e Gr¨uning and Andrej A Kibrik. 2005. Modeling
referential choice in discourse: A cognitive calcu-
lative approach and a neural network approach. In
Ruslan Mitkov, editor, Anaphora Processing: Lin-
guistic, Cognitive and Computational Modelling,
pages 163–198. John Benjamins.
Jeanette K Gundel, Nancy Hedberg, and Ron Zacharski.
1993. Cognitive status and the form of referring ex-
pressions in discourse. Language, pages 274–307.
Florian T Jaeger. 2010. Redundancy and reduc-
tion: Speakers manage syntactic information density.
Cognitive psychology, 61(1):23–62.
Gerhard Jager. 2007. Game dynamics connects seman-
tics and pragmatics. In Ahti-Veikko Pietarinen, edi-
tor, Game theory and linguistic meaning, pages 89–
102. Elsevier.
Justine T Kao, Jean Wu, Leon Bergen, and Noah D
Goodman. 2014. Nonliteral understanding of num-
ber words. Proceedings of the National Academy of
Sciences, 111(33):12002–12007.
Andrew Kehler, Laura Kertz, Hannah Rohde, and Jef-
frey L Elman. 2008. Coherence and coreference
revisited. Journal of Semantics, 25(1):1–44.
Mariya V Khudyakova, Grigory B Dobrov, Andrej A
Kibrik, and Natalia V Loukachevitch. 2011. Com-
putational modeling of referential choice: Major and
minor referential options. In Proceedings of the
CogSci 2011 Workshop on the Production of Refer-
ring Expressions. Boston (July 2011).
Emiel Krahmer and Kees Van Deemter. 2012. Compu-
tational generation of referring expressions: A sur-
vey. Computational Linguistics, 38(1):173–218.
Roger Levy and T. Florian Jaeger. 2007. Speakers op-
timize information density through syntactic reduc-
tion. In Proceedings of the 20th Conference on Neu-
ral Information Processing Systems (NIPS).
Brian MacWhinney. 2000. The CHILDES project:
Tools for analyzing talk.
Mante S Nieuwland and Jos JA Van Berkum. 2006.
When peanuts fall in love: N400 evidence for the
power of discourse. Journal of Cognitive Neuro-
science, 18(7):1098–1111.
Ann E Nordmeyer and Michael Frank. 2014. A
pragmatic account of the processing of negative sen-
tences. In Proceedings of the 36th Annual Confer-
ence of the Cognitive Science Society.
Naho Orita, Eliana Vornov, Naomi H Feldman, and Jor-
dan Boyd-Graber. 2014. Quantifying the role of
discourse topicality in speakers’ choices of referring
expressions. In Association for Computational Lin-
guistics, Workshop on Cognitive Modeling and Com-
putational Linguistics.
Massimo Poesio, Rosemary Stevenson, Barbara Di Eu-
genio, and Janet Hitzeman. 2004. Centering: A
parametric theory and its instantiations. Computa-
tional Linguistics, 30(3):309–363.
Marta Recasens, Lluis Marquez, Emili Sapena,
M. Ant`onia Mart´ı, and Mariona Taul´e. 2011.
SemEval-2010 task 1 OntoNotes English: Corefer-
ence resolution in multiple languages.
Jacolien Rij, Hedderik Rijn, and Petra Hendriks. 2013.
How WM load influences linguistic processing in
adults: A computational model of pronoun inter-
pretation in discourse. Topics in Cognitive Science,
5(3):564–580.
</reference>
<page confidence="0.811078">
1648
</page>
<reference confidence="0.996862476190476">
Hannah Rohde, Scott Seyfarth, Brady Clark, Gerhard
J¨ager, and Stefan Kaufmann. 2012. Communicat-
ing with cost-based implicature: A game-theoretic
approach to ambiguity. In The 16th Workshop on
the Semantics and Pragmatics of Dialogue, Paris,
September.
Kenji Sagae, Eric Davis, Alon Lavie, Brian MacWhin-
ney, and Shuly Wintner. 2010. Morphosyntactic an-
notation of CHILDES transcripts. Journal of Child
Language, 37(03):705–729.
Nathaniel J Smith, Noah Goodman, and Michael Frank.
2013. Learning and using language via recursive
pragmatic reasoning about other agents. In Ad-
vances in neural information processing systems,
pages 3039–3047.
Pontus Stenetorp, Sampo Pyysalo, Goran Topic,
Tomoko Ohta, Sophia Ananiadou, and Junichi Tsujii.
2012. brat: a web-based tool for NLP-assisted text
annotation. In Proceedings of the Demonstrations
Session at EACL 2012.
Yee Whye Teh, Michael I Jordan, Matthew J Beal, and
David M Blei. 2006. Hierarchical Dirichlet Pro-
cesses. Journal of the American Statistical Associ-
ation, 101.
Harry Tily and Steven Piantadosi. 2009. Refer effi-
ciently: Use less informative expressions for more
predictable meanings. In Proceedings of the work-
shop on the production of referring expressions:
Bridging the gap between computational and empir-
ical approaches to reference.
Mija Van der Wege. 2009. Lexical entrainment and
lexical differentiation in reference phrase choice.
Journal of Memory and Language, 60(4):448–463.
Jorrig Vogels, Emiel Krahmer, and Alfons Maes.
2013a. When a stone tries to climb up a slope: the
interplay between lexical and perceptual animacy in
referential choices. Frontiers in psychology, 4.
Jorrig Vogels, Emiel Krahmer, and Alfons Maes.
2013b. Who is where referred to how, and why? the
influence of visual saliency on referent accessibility
in spoken language production. Language and Cog-
nitive Processes, 28(9):1323–1349.
</reference>
<page confidence="0.995763">
1649
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.188527">
<title confidence="0.6869184">Why discourse affects speakers’ choice of referring expressions Naho Graduate School of Information Tohoku naho@ecei.tohoku.ac.jp</title>
<author confidence="0.992991">H Naomi</author>
<affiliation confidence="0.9720685">Linguistics and University of</affiliation>
<email confidence="0.99707">nhf@umd.edu</email>
<author confidence="0.533723">Eliana</author>
<affiliation confidence="0.9993725">Computer Science and University of</affiliation>
<email confidence="0.998621">evornov@umd.edu</email>
<author confidence="0.996969">Hal Daum´e</author>
<affiliation confidence="0.999574">Computer Science and University of</affiliation>
<email confidence="0.998708">hal@umiacs.umd.edu</email>
<abstract confidence="0.9971112">We propose a language production model that uses dynamic discourse information to account for speakers’ choices of referring expressions. Our model extends previous rational speech act models (Frank and Goodman, 2012) to more naturally distributed linguistic data, instead of assuming a controlled experimental setting. Simulations show a close match between speakers’ utterances and model predictions, indicating that speakers’ behavior can be modeled in a principled way by considering the probabilities of referents in the discourse and the information conveyed by each word.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John R Anderson</author>
</authors>
<title>How can the human mind occur in the physical universe?</title>
<date>2007</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6990" citStr="Anderson, 2007" startWordPosition="1058" endWordPosition="1059">egression and decision trees. Although these models qualitatively show some significant factors, they are data-driven rather than being explanatory, and have not focused on why and how these factors result in the observed referring choices. Formal models that go beyond identifying superficial factors focus on only pronouns rather than accounting for speakers’ word choices per se. For example, Kehler et al. (2008) formalize a relationship between pronoun comprehension and production using Bayes’ rule to account for comprehender’s semantic bias in experimental data. Rij et al. (2013) use ACT-R (Anderson, 2007) to examine the effects of working memory load in pronoun interpretation. These models show how certain factors influence pronoun production/interpretation, but it is not clear how these models would predict speakers’ choices of referring expressions. Relevant formal models in computational linguistics include Centering theory (Grosz et al., 1995; Poesio et al., 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how these would account for speaker</context>
</contexts>
<marker>Anderson, 2007</marker>
<rawString>John R Anderson. 2007. How can the human mind occur in the physical universe? Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mira Ariel</author>
</authors>
<title>Accessing noun-phrase antecedents.</title>
<date>1990</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="4625" citStr="Ariel, 1990" startWordPosition="692" endWordPosition="693">ng expressions. Section 3 describes the details of our model. Section 4 describes the data, preprocessing and annotation procedure. Section 5 presents simulation results. Section 6 summarizes this study and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience corresp</context>
</contexts>
<marker>Ariel, 1990</marker>
<rawString>Mira Ariel. 1990. Accessing noun-phrase antecedents. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Arnold</author>
</authors>
<title>Reference form and discourse patterns.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University</institution>
<location>Stanford, CA.</location>
<contexts>
<context position="4827" citStr="Arnold, 1998" startWordPosition="725" endWordPosition="726">dy and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of res</context>
</contexts>
<marker>Arnold, 1998</marker>
<rawString>Jennifer Arnold. 1998. Reference form and discourse patterns. Ph.D. thesis, Stanford University Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Arnold</author>
</authors>
<title>Reference production: Production-internal and addressee-oriented processes. Language and cognitive processes,</title>
<date>2008</date>
<pages>23--4</pages>
<contexts>
<context position="1854" citStr="Arnold, 2008" startWordPosition="270" endWordPosition="271">hip between discourse information and speakers’ choices of referring expression is one of the most studied problems. Speakers’ choices of referring expressions have long been thought to depend on the salience of entities in the discourse (Giv´on, 1983). For example, speakers normally do not choose a pronoun to refer to a new entity in the discourse, but are more likely to use pronouns for referents that have been referred to earlier in the discourse. A number of grammatical, semantic, and distributional factors related to salience have been found to influence choices of referring expressions (Arnold, 2008). While the relationship between discourse salience and speakers’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account</context>
</contexts>
<marker>Arnold, 2008</marker>
<rawString>Jennifer Arnold. 2008. Reference production: Production-internal and addressee-oriented processes. Language and cognitive processes, 23(4):495–527.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In The first international conference on language resources and evaluation workshop on linguistics coreference,</booktitle>
<volume>1</volume>
<pages>563--566</pages>
<contexts>
<context position="28239" citStr="Bagga and Baldwin, 1998" startWordPosition="4549" endWordPosition="4552">es corpus, and 165 pronouns and 149 proper names (total 314 items) in the CHILDES Gleason corpus remained for use in the analysis. Each model chooses referring expressions given information extracted from each corpus as described in Section 4.1. For evaluation, we computed accuracies (total, pronoun, and proper name) and model log likelihood (summing log PS(w|r) for the words in the corpus) for each model. 5.1 Results Table 1 summarizes the results of each model with the OntoNotes and CHILDES datasets. The new 6Interannotator agreement for CHILDES coreference annotation was computed using B3 (Bagga and Baldwin, 1998): precision: 0.99, recall: 1.00 (for one script). 5.1.1 News Overall, the recency salience measure provides a better fit than the frequency salience measure with respect to accuracies, suggesting that recency better captures speakers’ representations of discourse salience that influence choices of referring expressions. On the other hand, the models with frequency discourse salience have higher model log likelihood than the models with recency do. This is because of the peakiness of the recency models. Model log likelihood computed over pronouns and proper names (complete model) were -1022.33 </context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In The first international conference on language resources and evaluation workshop on linguistics coreference, volume 1, pages 563–566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Gurman Bard</author>
<author>Matthew P Aylett</author>
<author>J Trueswell</author>
<author>M Tanenhaus</author>
</authors>
<title>Referential form, word duration, and modeling the listener in spoken dialogue. Approaches to studying world-situated language use: Bridging the language-as-product and language-asaction traditions,</title>
<date>2004</date>
<pages>173--191</pages>
<contexts>
<context position="5583" citStr="Bard et al., 2004" startWordPosition="841" endWordPosition="844">tween referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012; Bergen et al., 2012b; Degen et al., 2013) and listener models (Bard et al., 2004; Van der Wege, 2009; Galati and Brennan, 2010; Fukumura and van Gompel, 2012) in language production. These studies suggest that only considering discourse salience of the referent may not precisely capture speakers’ choices of referring expressions, and it is necessary to examine discourse salience in relation to these other factors. 2.2 Formal models Computational models relevant to speakers’ choices of referring expressions have been proposed, but there is a gap between questions that previous models have addressed and the questions that we have raised above. Gr¨uning and Kibrik (2005) and</context>
</contexts>
<marker>Bard, Aylett, Trueswell, Tanenhaus, 2004</marker>
<rawString>Ellen Gurman Bard, Matthew P Aylett, J Trueswell, and M Tanenhaus. 2004. Referential form, word duration, and modeling the listener in spoken dialogue. Approaches to studying world-situated language use: Bridging the language-as-product and language-asaction traditions, pages 173–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BBN Technologies</author>
</authors>
<title>OntoNotes English coreference guidelines version 7.0.</title>
<date>2007</date>
<contexts>
<context position="25986" citStr="Technologies, 2007" startWordPosition="4192" endWordPosition="4193">verage peasant, who makes $145 a year, were excluded from the analysis. 4.2.3 Coreference annotation We used the provided coreference chains for the OntoNotes data, but for the CHILDES data, it was necessary to do this manually using brat. The guidelines we followed for determining whether mentions coreferred came from the OntoNotes corefer4Interannotator agreement for the CHILDES mention annotation was: precision 0.97, recall 0.98, F-score 0.97 (for two scripts). 5Interannotator agreement for the manual annotation of agreement information was 97% (for 500 mentions). 1644 ence guidelines (BBN Technologies, 2007).6 referent hyperparameter α and the decay parameter for discourse recency salience were fixed at 0.1 and 5 Experiments 3.0, respectively.7 Our experiments are designed to quantify the contributions of the various components of the complete model described in Section 3.2 that incorporates discourse salience, cost, and unseen referents. We contrast the complete model with three impoverished models that lack precisely one of these components. The comparison model without discourse uses a uniform discourse salience distribution. The model without cost uses constant speech cost. The model without </context>
</contexts>
<marker>Technologies, 2007</marker>
<rawString>BBN Technologies. 2007. OntoNotes English coreference guidelines version 7.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leon Bergen</author>
<author>Noah Goodman</author>
<author>Roger Levy</author>
</authors>
<title>That’s what she (could have) said: How alternative utterances affect language use.</title>
<date>2012</date>
<booktitle>In Proceedings of the 34th Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="2537" citStr="Bergen et al., 2012" startWordPosition="378" endWordPosition="381">’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model extends the rational speech act model from Fran</context>
<context position="5522" citStr="Bergen et al., 2012" startWordPosition="830" endWordPosition="833">), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012; Bergen et al., 2012b; Degen et al., 2013) and listener models (Bard et al., 2004; Van der Wege, 2009; Galati and Brennan, 2010; Fukumura and van Gompel, 2012) in language production. These studies suggest that only considering discourse salience of the referent may not precisely capture speakers’ choices of referring expressions, and it is necessary to examine discourse salience in relation to these other factors. 2.2 Formal models Computational models relevant to speakers’ choices of referring expressions have been proposed, but there is a gap between questions that previous models have addressed and the questi</context>
</contexts>
<marker>Bergen, Goodman, Levy, 2012</marker>
<rawString>Leon Bergen, Noah Goodman, and Roger Levy. 2012a. That’s what she (could have) said: How alternative utterances affect language use. In Proceedings of the 34th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leon Bergen</author>
<author>Noah D Goodman</author>
<author>Roger Levy</author>
</authors>
<title>That’s what she (could have) said: How alternative utterances affect language use.</title>
<date>2012</date>
<booktitle>In Proceedings of the thirty-fourth annual conference of the cognitive science society.</booktitle>
<contexts>
<context position="2537" citStr="Bergen et al., 2012" startWordPosition="378" endWordPosition="381">’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model extends the rational speech act model from Fran</context>
<context position="5522" citStr="Bergen et al., 2012" startWordPosition="830" endWordPosition="833">), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012; Bergen et al., 2012b; Degen et al., 2013) and listener models (Bard et al., 2004; Van der Wege, 2009; Galati and Brennan, 2010; Fukumura and van Gompel, 2012) in language production. These studies suggest that only considering discourse salience of the referent may not precisely capture speakers’ choices of referring expressions, and it is necessary to examine discourse salience in relation to these other factors. 2.2 Formal models Computational models relevant to speakers’ choices of referring expressions have been proposed, but there is a gap between questions that previous models have addressed and the questi</context>
</contexts>
<marker>Bergen, Goodman, Levy, 2012</marker>
<rawString>Leon Bergen, Noah D Goodman, and Roger Levy. 2012b. That’s what she (could have) said: How alternative utterances affect language use. In Proceedings of the thirty-fourth annual conference of the cognitive science society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
</authors>
<title>Bootstrapping path-based pronoun resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="19546" citStr="Bergsma and Lin, 2006" startWordPosition="3140" endWordPosition="3143"> or new. The following illustrates the speaker’s assumptions about the listener’s discourse model: For each referent r ∈ [1, Rd]: 1. If r = old, choose r in proportion to Nr (the number of times referent r has been referred to in the preceding discourse). 2. Otherwise, r = new with probability proportional to α (a hyperparameter that controls how likely the speaker is to refer to a new referent). 3. If r = new, sample that new referent r from the base distribution over entities with probability U·1 (count U· denotes a total number of unseen entities that is estimated from a named entity list (Bergsma and Lin, 2006)). The above discourse model is frequency-based. We can replace the term Nr for the old referent with f(di,j) = e−di,j/a that captures recency, where the recency function f(di,j) decays exponentially with the distance between the current referent ri and the same referent rj that has previously been referred to. This framework for frequency and recency of new and old referents exactly corresponds to priors in the Chinese Restaurant Process (Teh et al., 2006) and the distance-dependent Chinese Restaurant Process (Blei and Frazier, 2011). The denominator in (5) represents the sum of potential ref</context>
<context position="21583" citStr="Bergsma and Lin (2006)" startWordPosition="3478" endWordPosition="3481">red to NB times. In this situation, the model computes the probability that the speaker uses ‘he’ to refer to Barack Obama as follows: PS(‘he’|Obama) ∝ PL(Obama|‘he’) · 1 C‘he’ = P(‘he’jObama)P(Obama) Σr,P(‘he’jr1)P(r1) ·C‘he’ = V1 ·NO 1 (V1·NO)+( 1V·NB)+(v ·α· Usin U· g&amp;masc) C‘he’ where count Using&amp;masc in the denominator of the last line denotes the number of unseen singular &amp; male entities that could be referred to by ‘he’. We estimate this number for each type of pronoun we 1 (10) 1643 evaluate (singular-female, singular-male, singularneuter, and plural) based on the named entity list in Bergsma and Lin (2006). The term (1V · α · Using&amp;masc U· ) is the sum of probabilities of unseen referents that could be referred to by the pronoun ‘he’. The unseen referents can be interpreted as a penalty for the inexplicitness of pronouns. In the case of proper names, the denominator is always the same as the numerator, under the assumption that each entity has one unique proper name. 4 Data 4.1 Corpora Our model was run on both adult-directed speech and child-directed speech. We chose to use the SemEval-2010 Task 1 subset of OntoNotes (Recasens et al., 2011), a corpus of news text, as our corpus of adult-direct</context>
<context position="24864" citStr="Bergsma and Lin (2006)" startWordPosition="4009" endWordPosition="4012">ush have different ideas on how to spend that extra money” from OntoNotes, the extracted NPs are Both Al Gore and George W. Bush and different ideas about how to spend that extra money. These maximally spanning NPs were automatically extracted from the OntoNotes data, but were manually annotated for the CHILDES data using brat (Stenetorp et al., 2012) by two annotators.4 4.2.2 Agreement annotation Many mentions (46,246 out of 56,575 mentions in OntoNotes and 10,141 out of 10,530 mentions in CHILDES Gleason) were automatically annotated using agreement information from the named entity list in Bergsma and Lin (2006), leaving 10,329 to be manually annotated from OntoNotes (about 18%) and 389 from CHILDES (about 4%).5 The guidelines we followed for this manual agreement annotation were largely based on pronoun replacement tests. NPs that referred to a single man and could be replaced with he or him were labeled ‘male singular’, NPs that could be replaced by it, such as the comment, were labeled ‘neuter singular’, and so on. NPs that could not be replaced with a pronoun, such as about 30 years earnings for the average peasant, who makes $145 a year, were excluded from the analysis. 4.2.3 Coreference annotat</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 33–40, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Peter I Frazier</author>
</authors>
<title>Distance dependent Chinese restaurant processes.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2461</pages>
<contexts>
<context position="20086" citStr="Blei and Frazier, 2011" startWordPosition="3225" endWordPosition="3228"> unseen entities that is estimated from a named entity list (Bergsma and Lin, 2006)). The above discourse model is frequency-based. We can replace the term Nr for the old referent with f(di,j) = e−di,j/a that captures recency, where the recency function f(di,j) decays exponentially with the distance between the current referent ri and the same referent rj that has previously been referred to. This framework for frequency and recency of new and old referents exactly corresponds to priors in the Chinese Restaurant Process (Teh et al., 2006) and the distance-dependent Chinese Restaurant Process (Blei and Frazier, 2011). The denominator in (5) represents the sum of potential referents that could be referred to by word w. We assume that a pronoun can refer to a large number of unseen referents if gender and number match, but a proper name cannot. For example, ‘he’ could refer to all singular and male referents, but ‘Barack Obama’ can only refer to Barack Obama. This assumption is reflected as a probability of unseen referents for the pronoun as illustrated in (10) below. In our simulations, the speaker’s cost function C,,, is estimated based on word length as in (9). We assume that longer words are costly to </context>
</contexts>
<marker>Blei, Frazier, 2011</marker>
<rawString>David M Blei and Peter I Frazier. 2011. Distance dependent Chinese restaurant processes. The Journal of Machine Learning Research, 12:2461–2488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Breheny</author>
<author>Napoleon Katsos</author>
<author>John Williams</author>
</authors>
<title>Are generalised scalar implicatures generated by default? an on-line investigation into the role of context in generating pragmatic inferences.</title>
<date>2006</date>
<journal>Cognition,</journal>
<volume>100</volume>
<issue>3</issue>
<contexts>
<context position="1226" citStr="Breheny et al., 2006" startWordPosition="168" endWordPosition="171">rank and Goodman, 2012) to more naturally distributed linguistic data, instead of assuming a controlled experimental setting. Simulations show a close match between speakers’ utterances and model predictions, indicating that speakers’ behavior can be modeled in a principled way by considering the probabilities of referents in the discourse and the information conveyed by each word. 1 Introduction Discourse information plays an important role in various aspects of linguistic processing, such as predictions about upcoming words (Nieuwland and Van Berkum, 2006) and scalar implicature processing (Breheny et al., 2006). The relationship between discourse information and speakers’ choices of referring expression is one of the most studied problems. Speakers’ choices of referring expressions have long been thought to depend on the salience of entities in the discourse (Giv´on, 1983). For example, speakers normally do not choose a pronoun to refer to a new entity in the discourse, but are more likely to use pronouns for referents that have been referred to earlier in the discourse. A number of grammatical, semantic, and distributional factors related to salience have been found to influence choices of referrin</context>
</contexts>
<marker>Breheny, Katsos, Williams, 2006</marker>
<rawString>Richard Breheny, Napoleon Katsos, and John Williams. 2006. Are generalised scalar implicatures generated by default? an on-line investigation into the role of context in generating pragmatic inferences. Cognition, 100(3):434–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
</authors>
<title>Centering attention in discourse.</title>
<date>1995</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>10--2</pages>
<contexts>
<context position="4777" citStr="Brennan, 1995" startWordPosition="718" endWordPosition="719">s simulation results. Section 6 summarizes this study and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor </context>
</contexts>
<marker>Brennan, 1995</marker>
<rawString>Susan E Brennan. 1995. Centering attention in discourse. Language and Cognitive Processes, 10(2):137–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wallace Chafe</author>
</authors>
<title>Discourse, consciousness, and time.</title>
<date>1994</date>
<journal>Discourse,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="4800" citStr="Chafe, 1994" startWordPosition="721" endWordPosition="722">tion 6 summarizes this study and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There</context>
</contexts>
<marker>Chafe, 1994</marker>
<rawString>Wallace Chafe. 1994. Discourse, consciousness, and time. Discourse, 2(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Degen</author>
<author>Michael Franke</author>
<author>Gerhard J¨ager</author>
</authors>
<title>Cost-based pragmatic inference about referential expressions.</title>
<date>2013</date>
<booktitle>In Proceedings of the 35th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>376--381</pages>
<marker>Degen, Franke, J¨ager, 2013</marker>
<rawString>Judith Degen, Michael Franke, and Gerhard J¨ager. 2013. Cost-based pragmatic inference about referential expressions. In Proceedings of the 35th Annual Conference of the Cognitive Science Society, pages 376–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Frank</author>
<author>Noah Goodman</author>
</authors>
<title>Predicting pragmatic reasoning in language games.</title>
<date>2012</date>
<journal>Science,</journal>
<volume>336</volume>
<issue>6084</issue>
<contexts>
<context position="628" citStr="Frank and Goodman, 2012" startWordPosition="79" endWordPosition="82">discourse affects speakers’ choice of referring expressions Naho Orita Graduate School of Information Sciences Tohoku University naho@ecei.tohoku.ac.jp Naomi H. Feldman Linguistics and UMIACS University of Maryland nhf@umd.edu Eliana Vornov Computer Science and Linguistics University of Maryland evornov@umd.edu Hal Daum´e III Computer Science and UMIACS University of Maryland hal@umiacs.umd.edu Abstract We propose a language production model that uses dynamic discourse information to account for speakers’ choices of referring expressions. Our model extends previous rational speech act models (Frank and Goodman, 2012) to more naturally distributed linguistic data, instead of assuming a controlled experimental setting. Simulations show a close match between speakers’ utterances and model predictions, indicating that speakers’ behavior can be modeled in a principled way by considering the probabilities of referents in the discourse and the information conveyed by each word. 1 Introduction Discourse information plays an important role in various aspects of linguistic processing, such as predictions about upcoming words (Nieuwland and Van Berkum, 2006) and scalar implicature processing (Breheny et al., 2006). </context>
<context position="2225" citStr="Frank and Goodman, 2012" startWordPosition="329" endWordPosition="332">more likely to use pronouns for referents that have been referred to earlier in the discourse. A number of grammatical, semantic, and distributional factors related to salience have been found to influence choices of referring expressions (Arnold, 2008). While the relationship between discourse salience and speakers’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produ</context>
<context position="10454" citStr="Frank and Goodman (2012)" startWordPosition="1574" endWordPosition="1577">re is a relation between discourse salience and speakers’ choices of referring expressions. Even UID, which relates predictability to word length, is not set up to account for the choice between words that vary in their information content. In the next section, we propose a speaker model that formalizes the relation between discourse salience and speakers’ choices of referring expressions, considering production cost and speakers’ inference about listeners in a principled and explanatory way. 3 Speaker model 3.1 Rational speaker-listener model We adopt the rational speaker-listener model from Frank and Goodman (2012) and extend this model to predict speakers’ choices of referring expressions using discourse information. The main idea of Frank and Goodman’s model is that a rational pragmatic listener uses Bayesian inference to infer the speaker’s intended referent rs given the word w, their vocabulary (e.g., ‘blue’, ‘circle’), and shared context that consists of a set of objects O (e.g., visual access to object referents) as in (1), assuming that a speaker has chosen the word informatively. PS(w|rs, O)P(rs) P(rs|w, O) = (1) Σr&apos;∈OP(w |r , O)P(r ) While our work does not make use of this pragmatic listener, </context>
<context position="14165" citStr="Frank and Goodman (2012)" startWordPosition="2220" endWordPosition="2223">by word w. The terms in this sum are non-zero only for referents that are compatible with the meaning of the word. If there are many potential referents that could be referred to by word w, that word would be more ambiguous thus less informative. The whole of the right side in Equation (5) represents the speaker’s assumption about the listener: given word w the listener would infer referent r that is salient in a discourse and less ambiguously referred to by word w. If P(r) is uniform over referents and P(w|r) is constant across words and referents, this listener model reduces to 1 |w|. Thus, Frank and Goodman (2012)’s speaker model in (3) is a special case of our speaker model in (4) that assumes uniform discourse salience and constant cost. Our model predicts that the speaker’s probability of choosing a word for a given referent should depend on its cost relative to its information content. To see this, we combine (4) and (5), yielding P (w|r)P (r) 1 PS(w|r) ∝ �r, P (w|r0)P (r0) · (6) Cw Because the speaker is deciding what word to use for an intended referent, and the term P(r) denotes 1Our speaker model corresponds to Frank and Goodman’s exponentiated utility function (2), with α equal to one and with</context>
<context position="33233" citStr="Frank and Goodman (2012)" startWordPosition="5315" endWordPosition="5318"> sophisticated discourse model that accurately measured salience to show better performance. 5.2 Summary Experiments with the adult-directed news corpus show a close match between speakers’ utterances and model predictions. On the other hand, experiments with child-directed speech show that the models were more likely to predict proper names where pronouns were used, suggesting that the estimates of discourse salience using simple measures were not sufficient to capture a conversation. 6 Discussion This paper proposes a language production model that extends the rational speech act model from Frank and Goodman (2012) to incorporate updates to listeners’ beliefs as discourse proceeds. We show that the predictions suggested from UID in this domain can be derived from our speaker model, providing an explanation from first principles for the relation between discourse salience and speakers’ choices of referring expressions. Experiments with an adult-directed news corpus show a close match between speakers’ utterances and model predictions, and experiments with child-directed speech show a qualitatively similar pattern. This suggests that speakers’ behavior can be modeled in a principled way by considering the</context>
</contexts>
<marker>Frank, Goodman, 2012</marker>
<rawString>Michael Frank and Noah Goodman. 2012. Predicting pragmatic reasoning in language games. Science, 336(6084):998–998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Fukumura</author>
<author>Roger PG Van Gompel</author>
</authors>
<title>Choosing anaphoric expressions: Do people take into account likelihood of reference?</title>
<date>2010</date>
<journal>Journal of Memory and Language,</journal>
<volume>62</volume>
<issue>1</issue>
<marker>Fukumura, Van Gompel, 2010</marker>
<rawString>Kumiko Fukumura and Roger PG Van Gompel. 2010. Choosing anaphoric expressions: Do people take into account likelihood of reference? Journal of Memory and Language, 62(1):52–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Fukumura</author>
<author>Roger PG van Gompel</author>
</authors>
<title>Producing pronouns and definite noun phrases: Do speakers use the addressee’s discourse model?</title>
<date>2012</date>
<journal>Cognitive Science,</journal>
<volume>36</volume>
<issue>7</issue>
<marker>Fukumura, van Gompel, 2012</marker>
<rawString>Kumiko Fukumura and Roger PG van Gompel. 2012. Producing pronouns and definite noun phrases: Do speakers use the addressee’s discourse model? Cognitive Science, 36(7):1289–1311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Fukumura</author>
<author>Roger PG Van Gompel</author>
<author>Trevor Harley</author>
<author>Martin J Pickering</author>
</authors>
<title>How does similarity-based interference affect the choice of referring expression?</title>
<date>2011</date>
<journal>Journal of Memory and Language,</journal>
<volume>65</volume>
<issue>3</issue>
<marker>Fukumura, Van Gompel, Harley, Pickering, 2011</marker>
<rawString>Kumiko Fukumura, Roger PG Van Gompel, Trevor Harley, and Martin J Pickering. 2011. How does similarity-based interference affect the choice of referring expression? Journal of Memory and Language, 65(3):331–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexia Galati</author>
<author>Susan E Brennan</author>
</authors>
<title>Attenuating information in spoken communication: For the speaker, or for the addressee?</title>
<date>2010</date>
<journal>Journal of Memory and Language,</journal>
<volume>62</volume>
<issue>1</issue>
<contexts>
<context position="5629" citStr="Galati and Brennan, 2010" startWordPosition="849" endWordPosition="852">se salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012; Bergen et al., 2012b; Degen et al., 2013) and listener models (Bard et al., 2004; Van der Wege, 2009; Galati and Brennan, 2010; Fukumura and van Gompel, 2012) in language production. These studies suggest that only considering discourse salience of the referent may not precisely capture speakers’ choices of referring expressions, and it is necessary to examine discourse salience in relation to these other factors. 2.2 Formal models Computational models relevant to speakers’ choices of referring expressions have been proposed, but there is a gap between questions that previous models have addressed and the questions that we have raised above. Gr¨uning and Kibrik (2005) and Khudyakova et al. (2011) examine the signific</context>
</contexts>
<marker>Galati, Brennan, 2010</marker>
<rawString>Alexia Galati and Susan E Brennan. 2010. Attenuating information in spoken communication: For the speaker, or for the addressee? Journal of Memory and Language, 62(1):35–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Talmy Giv´on</author>
</authors>
<title>Topic continuity in discourse: A quantitative cross-language study, volume 3.</title>
<date>1983</date>
<publisher>John Benjamins Publishing.</publisher>
<marker>Giv´on, 1983</marker>
<rawString>Talmy Giv´on. 1983. Topic continuity in discourse: A quantitative cross-language study, volume 3. John Benjamins Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berko Gleason</author>
<author>Rivka Y Perlmann</author>
<author>Esther Blank Greif</author>
</authors>
<title>What’s the magic word: Learning language through politeness routines.</title>
<date>1984</date>
<booktitle>Discourse Processes,</booktitle>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="22219" citStr="Gleason et al. (1984)" startWordPosition="3591" endWordPosition="3594">· α · Using&amp;masc U· ) is the sum of probabilities of unseen referents that could be referred to by the pronoun ‘he’. The unseen referents can be interpreted as a penalty for the inexplicitness of pronouns. In the case of proper names, the denominator is always the same as the numerator, under the assumption that each entity has one unique proper name. 4 Data 4.1 Corpora Our model was run on both adult-directed speech and child-directed speech. We chose to use the SemEval-2010 Task 1 subset of OntoNotes (Recasens et al., 2011), a corpus of news text, as our corpus of adult-directed speech. The Gleason et al. (1984) subset of CHILDES (MacWhinney, 2000) was chosen as our corpus of child-directed speech. The model requires coreference chains, agreement information, grammatical position, and part of speech. These were extracted from each corpus, either manually or automatically. The coreference chains let us easily count how many times/how recently each referent is mentioned in the discourse, which is necessary for computing discourse salience. The agreement information (gender and number of each referent) is required so that the model can identify all possible competing referents for pronouns. For instance</context>
</contexts>
<marker>Gleason, Perlmann, Greif, 1984</marker>
<rawString>Jean Berko Gleason, Rivka Y Perlmann, and Esther Blank Greif. 1984. What’s the magic word: Learning language through politeness routines. Discourse Processes, 7(4):493–502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah D Goodman</author>
<author>Andreas Stuhlm¨uller</author>
</authors>
<title>Knowledge and implicature: Modeling language understanding as social cognition. Topics in Cognitive Science.</title>
<date>2013</date>
<marker>Goodman, Stuhlm¨uller, 2013</marker>
<rawString>Noah D Goodman and Andreas Stuhlm¨uller. 2013. Knowledge and implicature: Modeling language understanding as social cognition. Topics in Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Paul Grice</author>
</authors>
<title>Logic and conversation. Syntax and semantics,</title>
<date>1975</date>
<pages>3--41</pages>
<contexts>
<context position="2199" citStr="Grice, 1975" startWordPosition="327" endWordPosition="328">rse, but are more likely to use pronouns for referents that have been referred to earlier in the discourse. A number of grammatical, semantic, and distributional factors related to salience have been found to influence choices of referring expressions (Arnold, 2008). While the relationship between discourse salience and speakers’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>H Paul Grice. 1975. Logic and conversation. Syntax and semantics, 3:41–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Scott Weinstein</author>
<author>Aravind K Joshi</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="4667" citStr="Grosz et al., 1995" startWordPosition="698" endWordPosition="701">s the details of our model. Section 4 describes the data, preprocessing and annotation procedure. Section 5 presents simulation results. Section 6 summarizes this study and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expre</context>
<context position="7338" citStr="Grosz et al., 1995" startWordPosition="1106" endWordPosition="1109">ng for speakers’ word choices per se. For example, Kehler et al. (2008) formalize a relationship between pronoun comprehension and production using Bayes’ rule to account for comprehender’s semantic bias in experimental data. Rij et al. (2013) use ACT-R (Anderson, 2007) to examine the effects of working memory load in pronoun interpretation. These models show how certain factors influence pronoun production/interpretation, but it is not clear how these models would predict speakers’ choices of referring expressions. Relevant formal models in computational linguistics include Centering theory (Grosz et al., 1995; Poesio et al., 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how these would account for speakers’ choices of referring expressions, nor it is clear why there should be such deterministic constraints. 2.3 Uniform Information Density One potential formal explanation for the relation between discourse salience and speakers’ choices of referring expressions is the Uniform Information Density hypothesis (UID) (Levy and Jaeger, 2007; Tily and Pi</context>
</contexts>
<marker>Grosz, Weinstein, Joshi, 1995</marker>
<rawString>Barbara J Grosz, Scott Weinstein, and Aravind K Joshi. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e Gr¨uning</author>
<author>Andrej A Kibrik</author>
</authors>
<title>Modeling referential choice in discourse: A cognitive calculative approach and a neural network approach.</title>
<date>2005</date>
<booktitle>In Ruslan Mitkov, editor, Anaphora Processing: Linguistic, Cognitive and Computational Modelling,</booktitle>
<pages>163--198</pages>
<publisher>John Benjamins.</publisher>
<marker>Gr¨uning, Kibrik, 2005</marker>
<rawString>Andr´e Gr¨uning and Andrej A Kibrik. 2005. Modeling referential choice in discourse: A cognitive calculative approach and a neural network approach. In Ruslan Mitkov, editor, Anaphora Processing: Linguistic, Cognitive and Computational Modelling, pages 163–198. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeanette K Gundel</author>
<author>Nancy Hedberg</author>
<author>Ron Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse. Language,</title>
<date>1993</date>
<pages>274--307</pages>
<contexts>
<context position="4646" citStr="Gundel et al., 1993" startWordPosition="694" endWordPosition="697">s. Section 3 describes the details of our model. Section 4 describes the data, preprocessing and annotation procedure. Section 5 presents simulation results. Section 6 summarizes this study and discusses implications and future directions. 2 Relevant Work 2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a ce</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>Jeanette K Gundel, Nancy Hedberg, and Ron Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, pages 274–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian T Jaeger</author>
</authors>
<title>Redundancy and reduction: Speakers manage syntactic information density.</title>
<date>2010</date>
<booktitle>Cognitive psychology,</booktitle>
<pages>61--1</pages>
<contexts>
<context position="7967" citStr="Jaeger, 2010" startWordPosition="1200" endWordPosition="1201"> 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how these would account for speakers’ choices of referring expressions, nor it is clear why there should be such deterministic constraints. 2.3 Uniform Information Density One potential formal explanation for the relation between discourse salience and speakers’ choices of referring expressions is the Uniform Information Density hypothesis (UID) (Levy and Jaeger, 2007; Tily and Piantadosi, 2009; Jaeger, 2010). UID states that speakers prefer to smooth the information density distribution of their utterances over time to achieve optimal communication. This theory predicts that speakers should use pronouns instead of longer forms (e.g., the president) when a 1640 referent is predictable in the context, whereas they should use longer forms for unpredictable referents that carry more information (Jaeger, 2010). Tily and Piantadosi (2009) empirically examined the relationship between predictability of a referent and choice of referring expressions. They found that predictability is a significant predic</context>
</contexts>
<marker>Jaeger, 2010</marker>
<rawString>Florian T Jaeger. 2010. Redundancy and reduction: Speakers manage syntactic information density. Cognitive psychology, 61(1):23–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Jager</author>
</authors>
<title>Game dynamics connects semantics and pragmatics.</title>
<date>2007</date>
<booktitle>In Ahti-Veikko Pietarinen, editor, Game theory and linguistic meaning,</booktitle>
<pages>89--102</pages>
<publisher>Elsevier.</publisher>
<contexts>
<context position="2491" citStr="Jager, 2007" startWordPosition="372" endWordPosition="373">etween discourse salience and speakers’ choices of referring expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model e</context>
</contexts>
<marker>Jager, 2007</marker>
<rawString>Gerhard Jager. 2007. Game dynamics connects semantics and pragmatics. In Ahti-Veikko Pietarinen, editor, Game theory and linguistic meaning, pages 89– 102. Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine T Kao</author>
<author>Jean Wu</author>
<author>Leon Bergen</author>
<author>Noah D Goodman</author>
</authors>
<title>Nonliteral understanding of number words.</title>
<date>2014</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>111</volume>
<issue>33</issue>
<contexts>
<context position="2730" citStr="Kao et al., 2014" startWordPosition="409" endWordPosition="412">nces between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model extends the rational speech act model from Frank and Goodman (2012) to incorporate updates to listeners’ beliefs as discourse proceeds. The model predicts that a speaker’s choice of referring expressions should depend directly on the amount</context>
</contexts>
<marker>Kao, Wu, Bergen, Goodman, 2014</marker>
<rawString>Justine T Kao, Jean Wu, Leon Bergen, and Noah D Goodman. 2014. Nonliteral understanding of number words. Proceedings of the National Academy of Sciences, 111(33):12002–12007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Laura Kertz</author>
<author>Hannah Rohde</author>
<author>Jeffrey L Elman</author>
</authors>
<title>Coherence and coreference revisited.</title>
<date>2008</date>
<journal>Journal of Semantics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="6791" citStr="Kehler et al. (2008)" startWordPosition="1025" endWordPosition="1028">k (2005) and Khudyakova et al. (2011) examine the significance of various factors that might influence choices of referring expressions by using machine learning models such as neural networks, logistic regression and decision trees. Although these models qualitatively show some significant factors, they are data-driven rather than being explanatory, and have not focused on why and how these factors result in the observed referring choices. Formal models that go beyond identifying superficial factors focus on only pronouns rather than accounting for speakers’ word choices per se. For example, Kehler et al. (2008) formalize a relationship between pronoun comprehension and production using Bayes’ rule to account for comprehender’s semantic bias in experimental data. Rij et al. (2013) use ACT-R (Anderson, 2007) to examine the effects of working memory load in pronoun interpretation. These models show how certain factors influence pronoun production/interpretation, but it is not clear how these models would predict speakers’ choices of referring expressions. Relevant formal models in computational linguistics include Centering theory (Grosz et al., 1995; Poesio et al., 2004) and Referring Expression Gener</context>
<context position="35757" citStr="Kehler et al. (2008)" startWordPosition="5709" endWordPosition="5712">ng expression. However, these two quantities appear to be dissociated in some cases. For example, Fukumura and Van Gompel (2010) show that semantic bias (as a measure of predictability) affects what to refer to (i.e., the referent), but not how to refer (i.e., the referring expression), while grammatical position does affect how you refer. One way of dissociating the probability of mention from the choice of referring expression in our model would be through the likelihood term, the word probability p(wIr). While we have assumed this word probability to be constant across words and referents, Kehler et al. (2008) use grammatical position to define this probability and show that their model captures experimental data. Syntactic constraints (such as Binding principles) also influence form choices, and this kind of knowledge may also be reflected in the word probability. Examining the role of the word probability p(wIr) more closely would allow us to further explore these issues. Despite these limitations, our model provides a principled explanation for speakers’ choices of referring expressions. In future work we hope to look at a broader range of referring expressions, such as null pronouns and definit</context>
</contexts>
<marker>Kehler, Kertz, Rohde, Elman, 2008</marker>
<rawString>Andrew Kehler, Laura Kertz, Hannah Rohde, and Jeffrey L Elman. 2008. Coherence and coreference revisited. Journal of Semantics, 25(1):1–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariya V Khudyakova</author>
<author>Grigory B Dobrov</author>
<author>Andrej A Kibrik</author>
<author>Natalia V Loukachevitch</author>
</authors>
<title>Computational modeling of referential choice: Major and minor referential options.</title>
<date>2011</date>
<booktitle>In Proceedings of the CogSci 2011 Workshop on the Production of Referring Expressions.</booktitle>
<location>Boston</location>
<contexts>
<context position="6208" citStr="Khudyakova et al. (2011)" startWordPosition="937" endWordPosition="940"> Van der Wege, 2009; Galati and Brennan, 2010; Fukumura and van Gompel, 2012) in language production. These studies suggest that only considering discourse salience of the referent may not precisely capture speakers’ choices of referring expressions, and it is necessary to examine discourse salience in relation to these other factors. 2.2 Formal models Computational models relevant to speakers’ choices of referring expressions have been proposed, but there is a gap between questions that previous models have addressed and the questions that we have raised above. Gr¨uning and Kibrik (2005) and Khudyakova et al. (2011) examine the significance of various factors that might influence choices of referring expressions by using machine learning models such as neural networks, logistic regression and decision trees. Although these models qualitatively show some significant factors, they are data-driven rather than being explanatory, and have not focused on why and how these factors result in the observed referring choices. Formal models that go beyond identifying superficial factors focus on only pronouns rather than accounting for speakers’ word choices per se. For example, Kehler et al. (2008) formalize a rela</context>
</contexts>
<marker>Khudyakova, Dobrov, Kibrik, Loukachevitch, 2011</marker>
<rawString>Mariya V Khudyakova, Grigory B Dobrov, Andrej A Kibrik, and Natalia V Loukachevitch. 2011. Computational modeling of referential choice: Major and minor referential options. In Proceedings of the CogSci 2011 Workshop on the Production of Referring Expressions. Boston (July 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Kees Van Deemter</author>
</authors>
<title>Computational generation of referring expressions: A survey.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<marker>Krahmer, Van Deemter, 2012</marker>
<rawString>Emiel Krahmer and Kees Van Deemter. 2012. Computational generation of referring expressions: A survey. Computational Linguistics, 38(1):173–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>T Florian Jaeger</author>
</authors>
<title>Speakers optimize information density through syntactic reduction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th Conference on Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="7925" citStr="Levy and Jaeger, 2007" startWordPosition="1192" endWordPosition="1195">ntering theory (Grosz et al., 1995; Poesio et al., 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how these would account for speakers’ choices of referring expressions, nor it is clear why there should be such deterministic constraints. 2.3 Uniform Information Density One potential formal explanation for the relation between discourse salience and speakers’ choices of referring expressions is the Uniform Information Density hypothesis (UID) (Levy and Jaeger, 2007; Tily and Piantadosi, 2009; Jaeger, 2010). UID states that speakers prefer to smooth the information density distribution of their utterances over time to achieve optimal communication. This theory predicts that speakers should use pronouns instead of longer forms (e.g., the president) when a 1640 referent is predictable in the context, whereas they should use longer forms for unpredictable referents that carry more information (Jaeger, 2010). Tily and Piantadosi (2009) empirically examined the relationship between predictability of a referent and choice of referring expressions. They found t</context>
<context position="9235" citStr="Levy and Jaeger, 2007" startWordPosition="1386" endWordPosition="1389">ns, in that pronouns are used when a referent is predictable. While these results appear to support UID, there are several inconsistencies with previous UID accounts. Information content of words has been estimated using an n-gram language model (Levy and Jaeger, 2007), a verb’s subcategorization frequency (Jaeger, 2010), and so on, whereas here the information content is that of referents with respect to discourse salience. In addition, selecting between a pronoun and a more specified referring expression involves deciding how much information to convey, whereas previous applications of UID (Levy and Jaeger, 2007) have been concerned with deciding between different ways of expressing the same information content. We show in the next section that we can derive predictions about referring expressions directly from a model of language production. 2.4 Summary Previous linguistic studies have focused on identifying factors that might influence choices of referring expressions. However, it is not clear from this previous work how and why these factors result in the observed patterns of referring expressions. Where formal models relevant to this topic do exist, they have not been built to explain why there is</context>
</contexts>
<marker>Levy, Jaeger, 2007</marker>
<rawString>Roger Levy and T. Florian Jaeger. 2007. Speakers optimize information density through syntactic reduction. In Proceedings of the 20th Conference on Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES project: Tools for analyzing talk.</title>
<date>2000</date>
<contexts>
<context position="22256" citStr="MacWhinney, 2000" startWordPosition="3598" endWordPosition="3599">bilities of unseen referents that could be referred to by the pronoun ‘he’. The unseen referents can be interpreted as a penalty for the inexplicitness of pronouns. In the case of proper names, the denominator is always the same as the numerator, under the assumption that each entity has one unique proper name. 4 Data 4.1 Corpora Our model was run on both adult-directed speech and child-directed speech. We chose to use the SemEval-2010 Task 1 subset of OntoNotes (Recasens et al., 2011), a corpus of news text, as our corpus of adult-directed speech. The Gleason et al. (1984) subset of CHILDES (MacWhinney, 2000) was chosen as our corpus of child-directed speech. The model requires coreference chains, agreement information, grammatical position, and part of speech. These were extracted from each corpus, either manually or automatically. The coreference chains let us easily count how many times/how recently each referent is mentioned in the discourse, which is necessary for computing discourse salience. The agreement information (gender and number of each referent) is required so that the model can identify all possible competing referents for pronouns. For instance, Barack Obama will be ruled out as a</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. 2000. The CHILDES project: Tools for analyzing talk.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mante S Nieuwland</author>
<author>Jos JA Van Berkum</author>
</authors>
<title>When peanuts fall in love: N400 evidence for the power of discourse.</title>
<date>2006</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>18</volume>
<issue>7</issue>
<marker>Nieuwland, Van Berkum, 2006</marker>
<rawString>Mante S Nieuwland and Jos JA Van Berkum. 2006. When peanuts fall in love: N400 evidence for the power of discourse. Journal of Cognitive Neuroscience, 18(7):1098–1111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann E Nordmeyer</author>
<author>Michael Frank</author>
</authors>
<title>A pragmatic account of the processing of negative sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 36th Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="2758" citStr="Nordmeyer and Frank, 2014" startWordPosition="413" endWordPosition="416">ers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model extends the rational speech act model from Frank and Goodman (2012) to incorporate updates to listeners’ beliefs as discourse proceeds. The model predicts that a speaker’s choice of referring expressions should depend directly on the amount of information that each wo</context>
</contexts>
<marker>Nordmeyer, Frank, 2014</marker>
<rawString>Ann E Nordmeyer and Michael Frank. 2014. A pragmatic account of the processing of negative sentences. In Proceedings of the 36th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naho Orita</author>
<author>Eliana Vornov</author>
<author>Naomi H Feldman</author>
<author>Jordan Boyd-Graber</author>
</authors>
<title>Quantifying the role of discourse topicality in speakers’ choices of referring expressions.</title>
<date>2014</date>
<booktitle>In Association for Computational Linguistics, Workshop on Cognitive Modeling and Computational Linguistics.</booktitle>
<contexts>
<context position="18656" citStr="Orita et al., 2014" startWordPosition="2986" endWordPosition="2989">r example, we assume that an entity Barack Obama has one and only one proper name ‘Barack Obama’, and this entity is unambiguously associated with male and singular. Although we use an example with two possible referring expressions, as long as P(w|r) is constant across all referents and words, it does not make a difference to the computation in (5) how many competing words we assume for each referent. To estimate the salience of a referent, P(r), our framework employs factors such as referent frequency or recency. Although there are other important factors such as topicality of the referent (Orita et al., 2014) that are not incorporated in our simulations, this model sets up a framework to test the role and interaction of various potential factors suggested in the discourse literature. Salience of the referent is computed differently depending on its information status: old or new. The following illustrates the speaker’s assumptions about the listener’s discourse model: For each referent r ∈ [1, Rd]: 1. If r = old, choose r in proportion to Nr (the number of times referent r has been referred to in the preceding discourse). 2. Otherwise, r = new with probability proportional to α (a hyperparameter t</context>
<context position="34819" citStr="Orita et al., 2014" startWordPosition="5560" endWordPosition="5563">model PL(rIw) in (4) might differ between contexts and could also be extended to sum over possible listener identity q in mixed contexts, as in (11). PL(rlw) = ΣQP(r|w, q)P(q) (11) This provides a way to probe speakers’ sensitivity to differences in listener characteristics across situations. 1646 Although the simulations in this paper employed simple measures for discourse salience (referent frequency and recency), the discourse models used by speakers are likely to be more complex. Studies show that semantic information that cannot be captured with these simple measures, such as topicality (Orita et al., 2014) and animacy (Vogels et al., 2013a), affects speakers’ choices of referring expressions. Future work will test to what extent this latent discourse information could affect the model predictions. Our model predicts a tight coupling between the probability of a referent being mentioned, p(r), and the choice of referring expression. However, these two quantities appear to be dissociated in some cases. For example, Fukumura and Van Gompel (2010) show that semantic bias (as a measure of predictability) affects what to refer to (i.e., the referent), but not how to refer (i.e., the referring express</context>
</contexts>
<marker>Orita, Vornov, Feldman, Boyd-Graber, 2014</marker>
<rawString>Naho Orita, Eliana Vornov, Naomi H Feldman, and Jordan Boyd-Graber. 2014. Quantifying the role of discourse topicality in speakers’ choices of referring expressions. In Association for Computational Linguistics, Workshop on Cognitive Modeling and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Rosemary Stevenson</author>
<author>Barbara Di Eugenio</author>
<author>Janet Hitzeman</author>
</authors>
<title>Centering: A parametric theory and its instantiations.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<marker>Poesio, Stevenson, Di Eugenio, Hitzeman, 2004</marker>
<rawString>Massimo Poesio, Rosemary Stevenson, Barbara Di Eugenio, and Janet Hitzeman. 2004. Centering: A parametric theory and its instantiations. Computational Linguistics, 30(3):309–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Lluis Marquez</author>
<author>Emili Sapena</author>
<author>M Ant`onia Mart´ı</author>
<author>Mariona Taul´e</author>
</authors>
<date>2011</date>
<booktitle>SemEval-2010 task 1 OntoNotes English: Coreference resolution in multiple languages.</booktitle>
<marker>Recasens, Marquez, Sapena, Mart´ı, Taul´e, 2011</marker>
<rawString>Marta Recasens, Lluis Marquez, Emili Sapena, M. Ant`onia Mart´ı, and Mariona Taul´e. 2011. SemEval-2010 task 1 OntoNotes English: Coreference resolution in multiple languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacolien Rij</author>
<author>Hedderik Rijn</author>
<author>Petra Hendriks</author>
</authors>
<title>How WM load influences linguistic processing in adults: A computational model of pronoun interpretation in discourse.</title>
<date>2013</date>
<journal>Topics in Cognitive Science,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="6963" citStr="Rij et al. (2013)" startWordPosition="1052" endWordPosition="1055">s neural networks, logistic regression and decision trees. Although these models qualitatively show some significant factors, they are data-driven rather than being explanatory, and have not focused on why and how these factors result in the observed referring choices. Formal models that go beyond identifying superficial factors focus on only pronouns rather than accounting for speakers’ word choices per se. For example, Kehler et al. (2008) formalize a relationship between pronoun comprehension and production using Bayes’ rule to account for comprehender’s semantic bias in experimental data. Rij et al. (2013) use ACT-R (Anderson, 2007) to examine the effects of working memory load in pronoun interpretation. These models show how certain factors influence pronoun production/interpretation, but it is not clear how these models would predict speakers’ choices of referring expressions. Relevant formal models in computational linguistics include Centering theory (Grosz et al., 1995; Poesio et al., 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how thes</context>
</contexts>
<marker>Rij, Rijn, Hendriks, 2013</marker>
<rawString>Jacolien Rij, Hedderik Rijn, and Petra Hendriks. 2013. How WM load influences linguistic processing in adults: A computational model of pronoun interpretation in discourse. Topics in Cognitive Science, 5(3):564–580.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hannah Rohde</author>
<author>Scott Seyfarth</author>
<author>Brady Clark</author>
<author>Gerhard J¨ager</author>
<author>Stefan Kaufmann</author>
</authors>
<title>Communicating with cost-based implicature: A game-theoretic approach to ambiguity.</title>
<date>2012</date>
<booktitle>In The 16th Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<location>Paris,</location>
<marker>Rohde, Seyfarth, Clark, J¨ager, Kaufmann, 2012</marker>
<rawString>Hannah Rohde, Scott Seyfarth, Brady Clark, Gerhard J¨ager, and Stefan Kaufmann. 2012. Communicating with cost-based implicature: A game-theoretic approach to ambiguity. In The 16th Workshop on the Semantics and Pragmatics of Dialogue, Paris, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Eric Davis</author>
<author>Alon Lavie</author>
<author>Brian MacWhinney</author>
<author>Shuly Wintner</author>
</authors>
<title>Morphosyntactic annotation of CHILDES transcripts.</title>
<date>2010</date>
<journal>Journal of Child Language,</journal>
<volume>37</volume>
<issue>03</issue>
<contexts>
<context position="23469" citStr="Sagae et al., 2010" startWordPosition="3785" endWordPosition="3788">t as a possible competitor for the pronoun she. The grammatical position that each proper name occupies2 determines the form of the alternative pronoun that could be used there. For example, the difference between he and him is the grammatical position that each can appear in. The part of speech is used to identify the form of the referring expression (pronouns and proper names), which is what our model aims to predict.3 OntoNotes includes information about coreference chains, part of speech, and grammatical dependencies. Gleason CHILDES has parsed part of speech and grammatical dependencies (Sagae et al., 2010), but it does not have coreference chains. 2Dependency tags used were ‘SUBJ’, ‘OBJ’, and ‘PMOD’ in OntoNotes and ‘SBJ’ and ‘OBJ’ in CHILDES. 3The part of speech used to extract the target NPs were ‘PRP’ (pronoun), ‘NNP’ (proper name), and ‘NNPS’ (plural proper name) from OntoNotes and ‘pro’ (pronoun) and ‘n:prop’ (proper name) from CHILDES. Neither corpus has agreement information. The following section describes manual annotations that we have done for this study. Due to time constraints, we annotated only a part of the CHILDES Gleason corpus, 9 out of 70 scripts. 4.2 Annotation 4.2.1 Mention</context>
</contexts>
<marker>Sagae, Davis, Lavie, MacWhinney, Wintner, 2010</marker>
<rawString>Kenji Sagae, Eric Davis, Alon Lavie, Brian MacWhinney, and Shuly Wintner. 2010. Morphosyntactic annotation of CHILDES transcripts. Journal of Child Language, 37(03):705–729.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathaniel J Smith</author>
<author>Noah Goodman</author>
<author>Michael Frank</author>
</authors>
<title>Learning and using language via recursive pragmatic reasoning about other agents. In Advances in neural information processing systems,</title>
<date>2013</date>
<pages>3039--3047</pages>
<contexts>
<context position="2559" citStr="Smith et al., 2013" startWordPosition="382" endWordPosition="385"> expressions is well known, there is not yet a formal account of why this relationship exists. In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics (Grice, 1975; Frank and Goodman, 2012). These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers’ likely productions. These models have been argued to account for human communication (Jager, 2007; Frank and Goodman, 2012; Bergen et al., 2012a; Smith et al., 2013), and studies report that they robustly predict various linguistic phenomena in experimental settings (Goodman and Stuhlm¨uller, 2013; Degen et al., 2013; Kao et al., 2014; Nordmeyer and Frank, 2014). However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora. In this paper, we propose a probabilistic model to explain speakers’ choices of referring expressions based on discourse salience. Our model extends the rational speech act model from Frank and Goodman (2012) t</context>
</contexts>
<marker>Smith, Goodman, Frank, 2013</marker>
<rawString>Nathaniel J Smith, Noah Goodman, and Michael Frank. 2013. Learning and using language via recursive pragmatic reasoning about other agents. In Advances in neural information processing systems, pages 3039–3047.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
</authors>
<title>Sampo Pyysalo, Goran Topic, Tomoko Ohta, Sophia Ananiadou, and Junichi Tsujii.</title>
<date>2012</date>
<booktitle>In Proceedings of the Demonstrations Session at EACL</booktitle>
<marker>Stenetorp, 2012</marker>
<rawString>Pontus Stenetorp, Sampo Pyysalo, Goran Topic, Tomoko Ohta, Sophia Ananiadou, and Junichi Tsujii. 2012. brat: a web-based tool for NLP-assisted text annotation. In Proceedings of the Demonstrations Session at EACL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical Dirichlet Processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>101</volume>
<contexts>
<context position="20007" citStr="Teh et al., 2006" startWordPosition="3214" endWordPosition="3217">on over entities with probability U·1 (count U· denotes a total number of unseen entities that is estimated from a named entity list (Bergsma and Lin, 2006)). The above discourse model is frequency-based. We can replace the term Nr for the old referent with f(di,j) = e−di,j/a that captures recency, where the recency function f(di,j) decays exponentially with the distance between the current referent ri and the same referent rj that has previously been referred to. This framework for frequency and recency of new and old referents exactly corresponds to priors in the Chinese Restaurant Process (Teh et al., 2006) and the distance-dependent Chinese Restaurant Process (Blei and Frazier, 2011). The denominator in (5) represents the sum of potential referents that could be referred to by word w. We assume that a pronoun can refer to a large number of unseen referents if gender and number match, but a proper name cannot. For example, ‘he’ could refer to all singular and male referents, but ‘Barack Obama’ can only refer to Barack Obama. This assumption is reflected as a probability of unseen referents for the pronoun as illustrated in (10) below. In our simulations, the speaker’s cost function C,,, is estim</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Yee Whye Teh, Michael I Jordan, Matthew J Beal, and David M Blei. 2006. Hierarchical Dirichlet Processes. Journal of the American Statistical Association, 101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry Tily</author>
<author>Steven Piantadosi</author>
</authors>
<title>Refer efficiently: Use less informative expressions for more predictable meanings.</title>
<date>2009</date>
<booktitle>In Proceedings of the</booktitle>
<contexts>
<context position="7952" citStr="Tily and Piantadosi, 2009" startWordPosition="1196" endWordPosition="1199">t al., 1995; Poesio et al., 2004) and Referring Expression Generation (Krahmer and Van Deemter, 2012). These models propose deterministic constraints governing when pronouns are preferred in local discourse, but it is not clear how these would account for speakers’ choices of referring expressions, nor it is clear why there should be such deterministic constraints. 2.3 Uniform Information Density One potential formal explanation for the relation between discourse salience and speakers’ choices of referring expressions is the Uniform Information Density hypothesis (UID) (Levy and Jaeger, 2007; Tily and Piantadosi, 2009; Jaeger, 2010). UID states that speakers prefer to smooth the information density distribution of their utterances over time to achieve optimal communication. This theory predicts that speakers should use pronouns instead of longer forms (e.g., the president) when a 1640 referent is predictable in the context, whereas they should use longer forms for unpredictable referents that carry more information (Jaeger, 2010). Tily and Piantadosi (2009) empirically examined the relationship between predictability of a referent and choice of referring expressions. They found that predictability is a sig</context>
<context position="15937" citStr="Tily and Piantadosi (2009)" startWordPosition="2533" endWordPosition="2536">(w|r) ∝ Er, P(r0) · (7) Cw where the sum denotes the total discourse probability of the referents referred to by that word. The information content of an event is defined as the negative log probability of that event. In this scenario, the information conveyed by a word is the logarithm of the first term in (7), − log Er, P(r0). This means that in deciding which word to use, the highest cost a speaker should be willing to pay for a word should depend directly on that word’s information content. This relationship between cost and information content allows us to derive the prediction tested by Tily and Piantadosi (2009) that the use of referring expressions should depend on the predictability of a referent. For referents that are highly predictable from the discourse, different referring expressions (e.g., pronouns and proper names) will have roughly equal information content, and speakers should choose the referring expression that has the lowest cost. In contrast, for less predictable referents, proper names will carry substantially more information than pronouns, leading speakers to pay a higher cost for the proper names. These are the same predictions that have been discussed in the context of UID, but h</context>
</contexts>
<marker>Tily, Piantadosi, 2009</marker>
<rawString>Harry Tily and Steven Piantadosi. 2009. Refer efficiently: Use less informative expressions for more predictable meanings. In Proceedings of the workshop on the production of referring expressions: Bridging the gap between computational and empirical approaches to reference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mija Van der Wege</author>
</authors>
<title>Lexical entrainment and lexical differentiation in reference phrase choice.</title>
<date>2009</date>
<journal>Journal of Memory and Language,</journal>
<volume>60</volume>
<issue>4</issue>
<marker>Van der Wege, 2009</marker>
<rawString>Mija Van der Wege. 2009. Lexical entrainment and lexical differentiation in reference phrase choice. Journal of Memory and Language, 60(4):448–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorrig Vogels</author>
<author>Emiel Krahmer</author>
<author>Alfons Maes</author>
</authors>
<title>When a stone tries to climb up a slope: the interplay between lexical and perceptual animacy in referential choices. Frontiers</title>
<date>2013</date>
<note>in psychology, 4.</note>
<contexts>
<context position="4902" citStr="Vogels et al., 2013" startWordPosition="734" endWordPosition="737">2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012;</context>
<context position="34852" citStr="Vogels et al., 2013" startWordPosition="5566" endWordPosition="5569"> between contexts and could also be extended to sum over possible listener identity q in mixed contexts, as in (11). PL(rlw) = ΣQP(r|w, q)P(q) (11) This provides a way to probe speakers’ sensitivity to differences in listener characteristics across situations. 1646 Although the simulations in this paper employed simple measures for discourse salience (referent frequency and recency), the discourse models used by speakers are likely to be more complex. Studies show that semantic information that cannot be captured with these simple measures, such as topicality (Orita et al., 2014) and animacy (Vogels et al., 2013a), affects speakers’ choices of referring expressions. Future work will test to what extent this latent discourse information could affect the model predictions. Our model predicts a tight coupling between the probability of a referent being mentioned, p(r), and the choice of referring expression. However, these two quantities appear to be dissociated in some cases. For example, Fukumura and Van Gompel (2010) show that semantic bias (as a measure of predictability) affects what to refer to (i.e., the referent), but not how to refer (i.e., the referring expression), while grammatical position </context>
</contexts>
<marker>Vogels, Krahmer, Maes, 2013</marker>
<rawString>Jorrig Vogels, Emiel Krahmer, and Alfons Maes. 2013a. When a stone tries to climb up a slope: the interplay between lexical and perceptual animacy in referential choices. Frontiers in psychology, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorrig Vogels</author>
<author>Emiel Krahmer</author>
<author>Alfons Maes</author>
</authors>
<title>Who is where referred to how, and why? the influence of visual saliency on referent accessibility in spoken language production. Language and Cognitive Processes,</title>
<date>2013</date>
<contexts>
<context position="4902" citStr="Vogels et al., 2013" startWordPosition="734" endWordPosition="737">2.1 Discourse salience Speakers’ choices of referring expressions have long been an object of study. Pronominalization has been examined particularly often in both theoretical and experimental studies. Discourse theories predict that speakers use pronouns when they think that a referent is salient in the discourse (Giv´on, 1983; Ariel, 1990; Gundel et al., 1993; Grosz et al., 1995), where salience of the referent is influenced by various factors such as grammatical position (Brennan, 1995), recency (Chafe, 1994), topicality (Arnold, 1998), competitors (Fukumura et al., 2011), visual salience (Vogels et al., 2013b), and so on. Discourse theories have characterized the link between referring expressions and discourse salience by stipulating constructs such as a scale of topicality (Giv´on, 1983), accessibility hierarchy (Ariel, 1990), or implicational hierarchy (Gundel et al., 1993). All of these assume fixed form-salience correspondences in that a certain referring expression encodes a certain degree of salience. However, it is not clear how this form-salience mapping holds nor why it should be. There is also a rich body of research that points to the importance of production cost (Rohde et al., 2012;</context>
<context position="34852" citStr="Vogels et al., 2013" startWordPosition="5566" endWordPosition="5569"> between contexts and could also be extended to sum over possible listener identity q in mixed contexts, as in (11). PL(rlw) = ΣQP(r|w, q)P(q) (11) This provides a way to probe speakers’ sensitivity to differences in listener characteristics across situations. 1646 Although the simulations in this paper employed simple measures for discourse salience (referent frequency and recency), the discourse models used by speakers are likely to be more complex. Studies show that semantic information that cannot be captured with these simple measures, such as topicality (Orita et al., 2014) and animacy (Vogels et al., 2013a), affects speakers’ choices of referring expressions. Future work will test to what extent this latent discourse information could affect the model predictions. Our model predicts a tight coupling between the probability of a referent being mentioned, p(r), and the choice of referring expression. However, these two quantities appear to be dissociated in some cases. For example, Fukumura and Van Gompel (2010) show that semantic bias (as a measure of predictability) affects what to refer to (i.e., the referent), but not how to refer (i.e., the referring expression), while grammatical position </context>
</contexts>
<marker>Vogels, Krahmer, Maes, 2013</marker>
<rawString>Jorrig Vogels, Emiel Krahmer, and Alfons Maes. 2013b. Who is where referred to how, and why? the influence of visual saliency on referent accessibility in spoken language production. Language and Cognitive Processes, 28(9):1323–1349.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>