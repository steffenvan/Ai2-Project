<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000149">
<title confidence="0.997273">
Robust Domain Adaptation for Relation Extraction via Clustering
Consistency
</title>
<author confidence="0.980975">
Minh Luan Nguyen†∗, Ivor W. Tsang$, Kian Ming A. Chai§, and Hai Leong Chieu§
</author>
<affiliation confidence="0.967477">
†Institute for Infocomm Research, Singapore
$Centre for Quantum Computation &amp; Intelligent Systems, University of Technology, Sydney, Australia
§DSO National Laboratories, Singapore
</affiliation>
<email confidence="0.9277735">
mlnguyen@i2r.a-star.edu.sg, ivor.tsang@gmail.com
{ckianmin,chaileon}@dso.org.sg
</email>
<sectionHeader confidence="0.993847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989258064516">
We propose a two-phase framework to
adapt existing relation extraction classi-
fiers to extract relations for new target do-
mains. We address two challenges: neg-
ative transfer when knowledge in source
domains is used without considering the
differences in relation distributions; and
lack of adequate labeled samples for rarer
relations in the new domain, due to a
small labeled data set and imbalance rela-
tion distributions. Our framework lever-
ages on both labeled and unlabeled data
in the target domain. First, we determine
the relevance of each source domain to
the target domain for each relation type,
using the consistency between the clus-
tering given by the target domain labels
and the clustering given by the predic-
tors trained for the source domain. To
overcome the lack of labeled samples for
rarer relations, these clusterings operate
on both the labeled and unlabeled data in
the target domain. Second, we trade-off
between using relevance-weighted source-
domain predictors and the labeled target
data. Again, to overcome the imbalance
distribution, the source-domain predictors
operate on the unlabeled target data. Our
method outperforms numerous baselines
and a weakly-supervised relation extrac-
tion method on ACE 2004 and YAGO.
</bodyText>
<sectionHeader confidence="0.951017" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.6784285">
The World Wide Web contains information on
real-world entities, such as persons, locations and
</bodyText>
<note confidence="0.745618">
∗The work is done while Nguyen was a research staff in
Nanyang Technological University, Singapore.
</note>
<bodyText confidence="0.999988">
organizations, which are interconnected by vari-
ous semantic relations. Detecting these relations
between two entities is important for many tasks
on the Web, such as information retrieval (Salton
and McGill, 1986) and information extraction for
question answering (Etzioni et al., 2008). Recent
work on relation extraction has demonstrated that
supervised machine learning coupled with intelli-
gent feature engineering can provide state-of-the-
art performance (Jiang and Zhai, 2007b). How-
ever, most supervised learning algorithms require
adequate labeled data for every relation type to be
extracted. Due to the large number of relations
among entities, it may be costly to annotate a large
enough set of training data to cover each relation
type adequately in every new domain of interest.
Instead, it can be more cost-effective to adapt an
existing relation extraction system to the new do-
main using a small set of labeled data. This paper
considers relation adaptation, where a relation ex-
traction system trained on many source domains is
adapted to a new target domain.
There are at least three challenges when adapt-
ing a relation extraction system to a new domain.
First, the same semantic relation between two en-
tities can be expressed using different lexical or
syntactic patterns. For example, the acquisition of
company A by company B can be expressed with
“B bought over by A”, “A buys B” and “A pur-
chases B”. To extract a relation, we need to cap-
ture the different ways in which it can be expressed
across different open domains on the Web.
Second, the emphasis or interest on the different
relation types varies from domain to domain. For
example, in the organization domain, we may be
more interested in extracting relations such as lo-
catedIn (between a company and a location) and
founderOf (between a company and a person),
</bodyText>
<note confidence="0.811447666666667">
807
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 807–817,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999983706896552">
whereas in the person domain we may be more in-
terested in extracting relations such as liveIn (be-
tween a person and a location) and workAt (be-
tween a person and a company). Therefore, al-
though the two domains may have the same set
of relations, they probably have different marginal
distributions on the relations. This can produce a
negative transfer phenomenon (Rosenstein et al.,
2005), where using knowledge from other do-
mains degrades the performance on the target do-
main. Hence, when transferring knowledge from
multiple domains, it is overly optimistic to believe
that all source domains will contribute positively.
We call a source domain irrelevant when it has no
or negative contribution to the performance of the
target domain. One example is named entities ex-
traction adaptation, where naive transfer of infor-
mation from a mixed-case domain with capitaliza-
tion information (e.g., news-wire) to a single-case
domain (e.g., conversational speech transcripts)
will miss most names in the single-case domain
due to the absence of case information, which is
typically important in the mixed-case domain.
Third, the annotated instances for the target do-
main are typically much fewer than those for the
source domains. This is primarily due to the lack
of resources such as raw target domain documents,
time, and people with the expertise. Together with
imbalanced relation distributions inherent in the
domain, this can cause some rarer relations to con-
stitute only a very small proportion of the labeled
data set. This makes learning a relation classifier
for the target domain challenging.
To tackle these challenges, we propose a two-
phase Robust Domain Adaptation (RDA) frame-
work. In the first phase, Supervised Voting is used
to determine the relevance of each source domain
to each region in the target domain, using both la-
beled and unlabeled data in the target domain. By
using also unlabeled data, we alleviate the lack of
labeled samples for rarer relations due to imbal-
anced distributions in relation types.
The second phase uses the relevances deter-
mined the first phase to produce a reference pre-
dictor by weighing the source-domain predictors
for each target domain sample separately. The in-
tention is to alleviate the effect of mismatched dis-
tributions. The final predictor in the target domain
is trained on the labeled target domain data while
taking reference from the reference predictions on
the unlabeled target domain data. This ensures
reasonable predictive performance even when all
the source domains are irrelevant and augments
the rarer classes with examples in the unlabeled
data. We compare the proposed two-phase frame-
work with state-of-the-art domain adaptation base-
lines for the relation extraction task, and we find
that our method outperforms the baselines.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99988180952381">
Relation extraction is usually considered a classifi-
cation problem: determine if two given entities in
a sentence have a given relation. Kernel-based su-
pervised methods such as dependency tree kernels
(Culotta and Sorensen, 2004), subsequence ker-
nels (Bunescu and Mooney, 2006) and convolution
tree kernels (Qian et al., 2008) have been rather
successful in learning this task. However, purely
supervised relation extraction methods assume the
availability of sufficient labeled data, which may
be costly to obtain for new domains. We address
this by augmenting a small labeled data set with
other information in the domain adaptation setting.
Bootstrapping methods (Zhu et al., 2009;
Agichtein and Gravano, 2000; Xu et al., 2010;
Pasca et al., 2006; Riloff and Jones, 1999) to re-
lation extraction are attractive because they re-
quire fewer training instances than supervised ap-
proaches. Bootstrapping methods are either ini-
tialized with a few instances (often designated as
seeds) of the target relation (Zhu et al., 2009;
Agichtein and Gravano, 2000) or a few extraction
patterns (Xu et al., 2010). In subsequent itera-
tions, new extraction patterns are discovered, and
these are used to extract new instances. The qual-
ity of the extracted relations depends heavily on
the seeds (Kozareva and Hovy, 2010). Different
from bootstrapping, we not only use labeled tar-
get domain data as seeds, but also leverage on ex-
isting source-domain predictors to obtain a robust
relation extractor for the target domain.
Open Information Extraction (Open IE) (Et-
zioni et al., 2008; Banko et al., 2008; Mesquita
et al., 2013) is a domain-independent informa-
tion extraction paradigm to extract relation tu-
ples from collected corpus (Shinyama and Sekine,
2006) and Web (Etzioni et al., 2008; Banko et al.,
2008). Open IE systems are initialized with a few
domain-independent extraction patterns. To cre-
ate labeled data, the texts are dependency-parsed,
and the domain-independent patterns on the parses
form the basis for extractions. Recently, to reduce
</bodyText>
<page confidence="0.824662">
808
</page>
<bodyText confidence="0.999977930232558">
labeling effort for relation extraction, distant su-
pervision (Mintz et al., 2009; Takamatsu et al.,
2012; Min et al., 2013; Xu et al., 2013) has been
proposed. This is an unsupervised approach that
exploits textual features in large unlabeled cor-
pora. In contrast to Open IE, we tune the relation
patterns for a domain of interest, using labeled re-
lation instances in source and target domains and
unlabeled instances in the target domain.
Our work is also different from the multi-
schema matching in database integration (Doan
et al., 2003). Multi-schema matching finds rela-
tions between columns of schemas, which have
the same semantic. In addition, current weighted
schema matching methods do not address negative
transfer and imbalance class distribution.
Domain adaptation methods can be classi-
fied broadly into weakly-supervised adaptation
(Daume and Marcu, 2007; Blitzer et al., 2006;
Jiang and Zhai, 2007a; Jiang, 2009), and unsuper-
vised adaptation (Pan et al., 2010; Blitzer et al.,
2006; Plank and Moschitti, 2013). In the weakly-
supervised approach, we have plenty of labeled
data for the source domain and a few labeled in-
stances in the target domain; in the unsupervised
approach, the data for the target domain are not la-
beled. Among these studies, Plank and Moschitti’s
is the closest to ours because it adapts relation
extraction systems to new domains. Most other
works focused on adapting from old to new re-
lation types. Typical relation adaptation methods
first identify a set of common features in source
and target domains and then use those features as
pivots to map source domain features to the target
domain. These methods usually assume that each
source domain is relevant to the task on the target
domain. In addition, these methods do not handle
the imbalanced distribution of relation data explic-
itly. In this work, we study how to learn the target
prediction using only a few seed instances, while
dealing with negative transfer and imbalanced re-
lation distribution explicitly. These issues are sel-
dom explored in relation adaptation.
</bodyText>
<sectionHeader confidence="0.965231" genericHeader="method">
3 Problem Statement
</sectionHeader>
<bodyText confidence="0.999976">
This section defines the domain adaptation prob-
lem and describes our feature extraction scheme.
</bodyText>
<subsectionHeader confidence="0.9987">
3.1 Relation Extraction Domain Adaptation
</subsectionHeader>
<bodyText confidence="0.998889333333333">
Given two entities A and B in a sentence S, rela-
tion extraction is the task of selecting the relation
y between A and B from a fixed set of c relation
types, which includes the not-a-relation type. We
introduce a feature extraction χ that maps the triple
(A,B,S) to its feature vector x. Learning relation
extraction can then be abstracted to finding a func-
tion p such that p(χ(A,B,S)) = p(x) = y.
For adaptation, we have k source domains and
a target domain. We shall assume that all domains
have the same set of relation types. The target do-
main has a few labeled data Dl = {(xi,yi)}nl
</bodyText>
<equation confidence="0.736543666666667">
i=1 and
plenty of unlabeled data Du = { (xi) }n1&apos;+nu
n +1 , where
</equation>
<bodyText confidence="0.99882875">
nl and nu are the number of labeled and unla-
beled samples respectively, xi is the feature vec-
tor, yi is the corresponding label (if available). Let
n = nl + nu. For the sth source domain, we have
an adequate labeled data set Ds. We define domain
adaptation as the problem of learning a classifier
p for relation extraction in the target domain using
the data sets Dl, Du and Ds, s = 1,...,k.
</bodyText>
<subsectionHeader confidence="0.999282">
3.2 Relational Feature Representation
</subsectionHeader>
<bodyText confidence="0.9835541">
We consider relation extraction as a classifica-
tion problem, where each pair of entities A and
B within a sentence S is a candidate relation in-
stance. The contexts in which entities A and B co-
occur provide useful features to the relations be-
tween them. We use the term context to refer a
window of text in which two entities co-occur. A
context might not necessarily be a complete sen-
tence S. Retrieving contexts in which two entities
co-occur has been studied in previous works in-
vestigating the relations between entities.
Given a pair of entities (A,B) in S, the first step
is to express the relation between A and B with
some feature representation using a feature ex-
traction scheme χ. Lexical or syntactic patterns
have been successfully used in numerous natu-
ral language processing tasks, including relation
extraction. Jiang and Zhai (2007b) have shown
that selected lexical and syntactic patterns can give
good performance for relation extraction. Follow-
ing their work1, we also use lexical and syntactic
patterns extracted from the contexts to represent
the relations between entities. We extract features
from a sequence representation and a parse tree
representation of each relation instance. The de-
tails are as follows.
Entity Features Entity types and entity mention
types are very useful for relation extraction. We
1The source code for extracting entity features is provided
by the authors (Jiang and Zhai, 2007b).
</bodyText>
<page confidence="0.717607">
809
</page>
<bodyText confidence="0.99992512">
use a subgraph in the relation instance graph
(Jiang and Zhai, 2007b) that contains only the
node presenting the head word of the entity A, la-
beled with the entity type or entity mention types,
to describe a single entity attribute.
Sequence Features The sequence representation
preserves the order of the tokens as they occur in
the original sentence. Each node in the graph is a
token augmented with its relevant attributes.
Syntactic Features The syntactic parse tree of
the relation instance sentence can be augmented to
represent the relation instance. Each node is aug-
mented with relevant part-of-speech (POS) using
the Python Natural Language Processing Tool Kit.
Each node in the sequence or the parse tree
is augmented by an argument tag that indicates
whether the node corresponds to entity A, B, both,
or neither. The nodes that represent the argument
are also labeled with the entity type, subtype and
mention type. We trim the parse tree of a relation
instance so that it contains only the most essential
tree components based on constituent dependen-
cies (Qian et al., 2008). We also use unigram fea-
tures and bigram features from a relation instance
graph.
</bodyText>
<sectionHeader confidence="0.98563" genericHeader="method">
4 Robust Domain Adaptation
</sectionHeader>
<bodyText confidence="0.999968333333333">
In this section, we describe our two-phase ap-
proach, which comprises of a Supervised Voting
scheme and a combined classifier learning phase.
</bodyText>
<subsectionHeader confidence="0.998603">
4.1 Phase 1: Clustering Consistency via
Supervised Voting
</subsectionHeader>
<bodyText confidence="0.998820857142857">
In this section, we use the concept of clustering
consistency to determine the relevance of a source
domain to particular regions in the target domain.
Figure 1 illustrates this. There, both enclosing cir-
cles in the left and right figures denote the same
input space of the target domain. There are four
disjoint regions within the input space, located at
the left, right, top and bottom of the space. There
are four classes of labels: plus (+), cross (x), cir-
cle (o) and asterisk (∗). The labels in the left fig-
ure are given by a preliminary predictor in the tar-
get domain data, while the labels in the right fig-
ure are given by a predictor trained on the source
domain data. Comparing the figures, we see the
preliminary predictor and source domain predic-
tor are consistent for the bottom and right regions,
Target domain input Target domain input
space with transduc- space with labels from
tive learning using la- the predictor trained
beled and unlabeled on the source domain
target domain data. data set.
</bodyText>
<figureCaption confidence="0.714628">
Figure 1: Clustering consistency is used to deter-
</figureCaption>
<bodyText confidence="0.977409513513514">
mine the relevance of a source domain to a region
in the target domain data. The bottom and right
regions are more relevant than the top and left re-
gions. See text for explanation.
but are inconsistent for the top and left regions.
This suggests that the source domain is very rele-
vant for the bottom and right regions of the target
input space, but less so for the top and left regions.
To apply this idea to relation classification, we
have to (i) partition the target domain input space
into regions and (ii) assign preliminary labels for
all the examples. We approximate the target do-
main input space with all the samples from Dl and
Du. With data from both the labeled and unlabeled
data sets, we apply transductive inference or semi-
supervised learning (Zhou et al., 2003) to achieve
both (i) and (ii). By augmenting with unlabeled
data Du, we aim to alleviate the effect of imbal-
anced relation distribution, which causes a lack
of labeled samples for rarer classes in a small set
of labeled data. Briefly, the known labels in Dl
are propagated to the entire target input space by
encouraging label smoothness in neighborhoods.
The next three paragraphs give more details.
At present, we assume a similarity matrix W,
where Wij is the similarity between the ith and the
jth input samples in Dl U Du. Matrix W then de-
termines the neighborhoods. Let Λ be a diagonal
matrix where the (i,i)th entry is the sum of the
ith row of W. Let us also encode the the labeled
data Dl in an n-by-c matrix H, such that Hij = 1
if sample i is labeled with relation class j in Dl,
and Hij = 0 otherwise. Our objective is the c-
dimensional relation-class indicator vector Fi for
the ith sample, for every sample. This is achieved
810
via a regularization framework (Zhou et al., 2003): Phy Per Emp Agt Aff GPE Dis N/A
</bodyText>
<equation confidence="0.997156166666667">
{Fi�n i=1
min Fj X2
Wij ,1 /Λii Λjj
n � �
�Fi −
�IIFi −HiII2 .
</equation>
<bodyText confidence="0.9998314">
This trades off two criteria: the first term encour-
ages nearby samples (under distance metric W) to
have the same labels, while the second encourages
samples to take their labels from the labeled data.
The closed-form solution is
</bodyText>
<equation confidence="0.975233">
F* = (I − (1 +µ)−1L)−1H, (1)
</equation>
<bodyText confidence="0.994356892857143">
where L = Λ−1/2WΛ−1/2; and the n-by-c matrix
F* is the concatenation of the Fis.
Using vector F*
i , we now assign preliminary la-
bels to the samples. For a sample i, we transform
F*
i into probabilities p1i , p2i ,..., pci using softmax.
Our propagated label ji for sample i is then
The second clause is self-evident, but the first
needs further explanation. Because not-a-relation
is a background or default relation type in the re-
lation classification task, and because it has rather
high variation when manifested in natural lan-
guage, we have found it difficult to obtain a dis-
tance metric W that allows the not-a-relation sam-
ples to form clusters naturally using transductive
inference. Therefore, we introduce the first clause
to assign the not-a-relation label to a sample when
there is no strong evidence for any of the positive
relation types. The amount of evidence needed is
quantified by the parameter θ &gt; 1/c. In addition,
the second clause will also assign not-a-relation to
a sample if that probability is the highest.
Next, we partition the data in Dl U Du into c re-
gions, R1,R2,...,Rc, corresponding to the c rela-
tion types. The intuition is to use the true label in
Dl when available, or otherwise resort to using the
propagated label. That is,
</bodyText>
<equation confidence="0.8392315">
xi E � Ryi if xi E Dl,
Rji if xi E Du.
</equation>
<bodyText confidence="0.998428965517241">
We now have the necessary ingredients to quan-
tify the clustering consistency between a source
Figure 2: Heat map of the relevance scores ws,j
between the target domain Usenet (UN) with the
other domains on ACE 2004 data set. A lighter
shade means a higher score, or more relevant. N/A
refers to not-a-relation; for the other abbrevia-
tions, see the second paragraph in section 5.
domain and a region in the target domain. Intu-
itively, this is the agreement between the source-
domain predictor and the preliminary predictor
within the target domain. We use supervised vot-
ing in the following manner. For every source do-
main, say domain s, we first train a relation-type
predictor ps based on its training data Ds. Then,
for every region Rj, we compute the relevance
score ws,j = ∑xiERjQps(xi) = ji /|Rj|, where [• is
the Iverson bracket.
Figure 2 shows the heat map of the relevance
scores ws, j between the target domain Usenet
(UN) with the other domains in the ACE 2004 cor-
pus. We observe, for example, that the Broad-
cast News (BN) domain is more relevant in the
Personal-Social region of the target domain than
the Broadcast Conversation (BC) domain. These
relevance scores will be used in the next phase
of the framework to weigh the contributions of
source-domain predictors to the eventual target-
domain relation classifier.
</bodyText>
<subsectionHeader confidence="0.978474">
4.2 Phase 2: Target Classifier Learning
</subsectionHeader>
<bodyText confidence="0.999594142857143">
The second phase uses both the weighted predic-
tions from all sources and the target labeled data
Dl to learn a relation classifier. This ensures that
even when most of the source domains are irrele-
vant, the performance of our method is no worse
than using the target-domain labeled data alone.
The previous phase has computed the relevance
ws,j for source domain s in region Rj. We trans-
late this to the relevance weight us,i for an ex-
ample xi: if xi E Rj, then us,i = ws,j. At our dis-
posal from the previous phase are also k source-
domain predictors ps that have been trained on
Ds. Combining and weighing the predictions from
multiple sources, we obtain the reference predic-
</bodyText>
<figure confidence="0.864182428571429">
n
∑
i=1
+µ
�
not-a-relation if (maxj pji ) &lt; θ,
ji =
argmaxj pij otherwise. (2)
BC
BN
NW
CTS
WL
811
</figure>
<bodyText confidence="0.98914392">
tion ˆrji = ∑ks=1 us,i(2Qps(xi) = j� −1) for example
xi belonging to relation j, using the +1 encoding.
The relation classifier consists of c functions
f1,..., fc using the one-versus-rest decoding for
multi-class classification.2 Inspired by the Do-
main Adaptive Machine (Duan et al., 2009), we
combine the reference predictions and the labeled
data of the target domain to learn these functions:
where rji = 2Qyi = j� −1 is the +1 binary encod-
ing for the i labeled sample belonging to relation j.
Here, we have multiple objectives: the first term
controls the training error; the second regularizes
the complexity of the functions fjs in the Repro-
ducing Kernel Hilbert Space (RKHS) H; and the
third prefers the predicted labels of the unlabeled
data Dl to be close to the reference predictions.
The third term provides additional pseudo-training
samples for the rarer relation classes, if these are
available in Du. Parameters β and γ govern the
trade-offs between these objectives.
Let K(·,·) be the reproducing kernel for H. By
the Representer Theorem (Smola and Scholkopf,
1998), the solution for Eq. 3 is linear in K(xi,·):
fj(x) = ∑ni=1 αjiK(xi,x). Putting this into Eq. 3,
parameter vectors αj are (Belkin et al., 2006):
</bodyText>
<equation confidence="0.89519">
α*j = (JK +γ(nl +βnu)I)−1JRj. (4)
</equation>
<bodyText confidence="0.9995622">
Here, Rj is an (nl + nu)-vector, where Rji = rji if
sample i belongs to the labeled set, and Rji = ˆri j if
it belongs to the unlabeled set; and J is an (nl +
nu)-by-(nl +nu) diagonal matrix where the first nl
diagonal entries are ones and the rest are βs.
</bodyText>
<sectionHeader confidence="0.999414" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999583125">
We evaluate our algorithm on two corpora: Au-
tomatic Content Extraction (ACE) 2004 and
YAGO3. Table 1 provides some statistics on them.
ACE 2004 consists of six domains: Broad-
cast Conversations (BC), Broadcast News
(BN), Conversational Telephone Speech (CTS),
Newswire (NW), Usenet (UN) and Weblog
(WL). There are seven positive relation types:
</bodyText>
<footnote confidence="0.979154">
2For two-classes, though, only one function is needed.
3http://www.mpi-inf.mpg.de/yago-naga/yago/
</footnote>
<tableCaption confidence="0.997601">
Table 1: Statistics on ACE 2004 and YAGO
</tableCaption>
<table confidence="0.9378167">
Properties ACE 2004 YAGO
# relation types 7 20
# candidate relations 48,625 68,822
# gold relations 4,296 2,000
# mentions per entity pair 6 11
% mentions with +ve relations 8.8% 21%
Physical (Phy), Personal/Social (Per), Employ-
ment/Membership/Subsidiary (Emp), Agent-
Artifact (Agt), PER/ORG Affiliation (Aff), GPE
Affiliation (GPE) and Discourse (Dis).
</table>
<bodyText confidence="0.998883464285714">
YAGO is an open information extraction data
set. The relation types of YAGO are built from
Wikipedia and WordNet, while the labeled text for
YAGO is from Bollegala et al. (2011). It consists
of twenty relation types such as ceo company,
bornIn and isMarriedTo, and each of them is con-
sidered as a domain in this work. YAGO is dif-
ferent from ACE 2004 in two aspects: there is
less overlapping of topics, entity types and rela-
tion types between domains; and it has more rela-
tion mentions with 11 mentions per pair of entities
on the average.
We used Collins parser (Collins, 1999) to parse
the sentences. The constituent parse trees were
then transformed into dependency parse trees, us-
ing the head of each constituent (Jiang and Zhai,
2007b). The candidate relation instances were
generated by considering all pairs of entities that
occur in the same sentence. For the similarity ma-
trix W in section 4.1 and the kernel K(·,·) in sec-
tion 4.2, we used the composite kernel function
(Zhang et al., 2006), which is based on structured
features and entity-related features.
F1 is used to measure the performance of the al-
gorithms. This is the harmonic mean of precision
TP/(TP + FP) and recall TP/(TP + FN), where
TP, FP and FN are the numbers of correct, missing
and wrongly recognized relations.
</bodyText>
<subsectionHeader confidence="0.980835">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999965875">
For ACE 2004, we used each of the six domains
as the target domain and the remaining domains
as source domains. For YAGO, each relation type
in YAGO was considered as a domain. For each
domain in YAGO, we have a binary classifica-
tion task: whether the instance has the relation
corresponding to the domain. Five-fold cross-
validation was used to evaluate the performance.
</bodyText>
<figure confidence="0.959965538461538">
�
c nl
1
∑ ∑(fj(xi) − rji)2 +γI fjI2 H
nl
j (xi) − ˆrji I 2 , (3)
min
{fj}cj=1
j=1 i=1If n
β ∑
+ i=nl+1
2
812
</figure>
<bodyText confidence="0.99886525">
For every target domain, we divided all data into
5 subsets, and we used each subset for testing and
the other four subsets for training. In the training
set, we randomly removed most of the positive in-
stances of the target domain from the training set
except for 10% of the labeled data. This gave us
the weakly-supervised setting. This was repeated
five times with different training and test sets. We
report the average performance over the five runs.
In our experiments, we set µ = 0.8 in Eq. 1;
θ = 0.18 in Eq. 2; and γ = 0.1 and β = 0.3 in Eq. 3.
For each target domain, we used k ∈ {1,3,5} dif-
ferent source domains chosen randomly from the
remaining domains. Thus, the relevance of the
source domains to the target domain varies from
experiment to experiment.
</bodyText>
<subsectionHeader confidence="0.997592">
5.2 Baselines
</subsectionHeader>
<bodyText confidence="0.999790441860465">
We compare our framework with several other
methods, including state-of-the-art machine learn-
ing, relation extraction and common domain adap-
tation methods. These are described below.
In-domain multiclass classifier This is Support-
vector-machine (Fan et al., 2008, SVM) using
the one-versus-rest decoding without removing
positive labeled data (Jiang and Zhai, 2007b)
from the target domain. Its performance can be
regarded as an upper bound on the performance
of the cross-domain methods.
No-transfer classifier (NT) We only use the few
labeled instances of the target relation type to-
gether with the negative relation instances to
train a binary classifier.
Alternate no-transfer classifier (NT-U) We use
the union of the k source-domain labeled data
sets Dss and the small set of target-domain la-
beled data Dl to train a binary classifier. It is
then applied directly to predict on the unlabeled
target-domain data Du without any adaptation.
Laplacian SVM (L-SVM) This is a semi-
supervised learning method based on label
propagation (Melacci and Belkin, 2011).
Multi-task transfer (MTL) This is a learning
method for weakly-supervised relation extrac-
tion (Jiang, 2009).
Adaptive domain bootstrapping (DAB) This is
an instance-based domain adaptation method
for relation extraction (Xu et al., 2010).
Structural correspondence learning (SCL) We
use the feature-based domain adaptation ap-
proach by Blitzer et al. (2007). We apply SCL
on the Dss and Dl to train a model. The learned
model then makes predictions on Du.
Domain Adaptation Machine (DAM) We use
the framework of Duan et al. (2009), which is a
multiple-sources domain adaptation method.
For the kernel-based methods above, we use the
same composite kernel used in our method. The
source codes of L-SVM, MTL, SCL and DAM
were obtained from the authors. The others were
re-implemented.
</bodyText>
<subsectionHeader confidence="0.99831">
5.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999990083333334">
Tables 2, 3 and 4 present the results on ACE 2004
(corresponding to k = 1,3,5), and Tables 5 present
those on YAGO (corresponding to k = 5).
From Table 3 and Table 5, we see that the
proposed method has the best F1 among all the
other methods, except for the supervised upper
bound (In-domain). We first notice that NT-U
generally does not perform well, and sometimes
it performs worse than NT. The reason is that
NT-U aims to obtain a consensus among the do-
mains, and this will give a worse label than NT
when there are enough irrelevant sources to influ-
ence the classification decision wrongly. In fact,
one can roughly deduce that a target domain has
few relevant source domains by simply comparing
columns NT with columns NT-U in the tables: a
decrease in F1 from NT to NT-U suggests that the
source domains are mainly irrelevant. For exam-
ple, for domain BC in ACE 2004, we find that its
F1 decreases from NT to NT-U consistently in Ta-
bles 2, 3 and 4, which suggests that BN, NW, CTS,
UN and WL are generally irrelevant to it; and sim-
ilarly for domain CTS. We investigate this further
by examining the relevance scores ws,js, and we
find that the decreases in F1 from NT to NT-U hap-
pen when there are more regions in the target do-
main to which source-domains are irrelevant.
We find that MTL, DAB and SCL are better than
NT-U when the majority of source domains are
relevant. This shows that MTL, DAB and SCL are
able to make more effective use of relevant sources
than NT-U. Howevever, we find that their perfo-
mances are not stable: for example, MTL for tar-
get UN in Table 2. In contrast, we find the per-
formance of L-SVM and DAM to be more sta-
ble. The reason is their reduced vulnerability to
</bodyText>
<page confidence="0.951359">
813
</page>
<tableCaption confidence="0.981559">
Table 2: The F1 of different methods on ACE 2004 with k = 1 source domain. The best performance for
each target domain is in bold.
</tableCaption>
<table confidence="0.999764875">
Target In-domain NT NT-U L-SVM MTL DAB SCL DAM RDA
BC 55.74 30.00 20.31 32.42 32.74 32.12 30.41 33.07 35.43
BN 67.24 33.43 38.31 35.40 44.81 27.32 45.27 43.26 47.28
NW 68.32 41.48 39.35 41.50 42.28 43.27 44.16 41.69 45.41
CTS 72.92 36.60 29.90 36.15 45.06 37.50 44.68 39.40 44.27
UN 45.16 21.67 17.55 25.10 18.69 18.78 28.77 26.57 31.07
WL 46.46 28.53 23.84 29.90 26.13 24.78 23.71 27.01 30.80
Average 57.58 31.95 28.21 33.41 35.02 30.46 29.57 33.50 39.00
</table>
<tableCaption confidence="0.999104">
Table 3: The F1 of different methods on ACE 2004 with k = 3 source domains.
</tableCaption>
<table confidence="0.99976825">
Target In-domain NT NT-U L-SVM MTL DAB SCL DAM RDA
BC 55.74 30.00 24.55 32.42 35.26 34.12 37.83 36.08 39.43
BN 67.24 33.43 38.31 35.40 49.76 32.15 49.25 45.89 51.28
NW 68.32 41.48 43.35 42.50 43.28 43.71 44.16 44.01 46.41
CTS 72.92 36.60 30.25 36.15 45.06 37.50 44.68 42.51 49.27
UN 45.16 21.67 27.55 25.10 19.72 35.78 31.77 33.29 35.07
WL 46.46 28.53 30.72 30.90 33.21 32.81 26.37 32.46 35.11
Average 57.58 31.95 32.46 34.20 37.72 36.01 39.01 39.10 42.76
</table>
<tableCaption confidence="0.998968">
Table 4: The F1 of different methods on ACE 2004 with k = 5 source domains.
</tableCaption>
<table confidence="0.9994315">
Target In-domain NT NT-U L-SVM MTL DAB SCL DAM RDA
BC 55.74 30.00 27.32 33.07 37.76 35.08 40.38 38.70 42.90
BN 67.24 33.43 40.83 36.42 52.69 42.76. 50.47 48.23 53.40
NW 68.32 41.48 44.35 43.69 47.80 44.09 45.50 46.06 49.13
CTS 72.92 36.60 34.60 38.90 45.06 38.71 47.35 45.69 52.63
UN 45.16 21.67 29.34 26.34 35.47 35.44 33.21 34.13 36.02
WL 46.46 28.53 32.41 31.56 34.72 32.81 36.89 32.29 37.90
Average 57.58 31.95 34.80 35.0 42.25 38.15 42.30 40.84 45.33
</table>
<bodyText confidence="0.999223423076923">
negative transfer from irrelevant sources by rely-
ing on similarity of feature vectors between source
and target domains based on labeled and unlabeled
data. Further improvements can still be made, as
shown by the better performance of RDA over L-
SVM and DAM. This is achieved by further ad-
justing the relevances between source and target
domains according to regions in the target-domain
input space.
We analyzed histogram of the relation types to
order the domains according to the imbalance of
the class distributions. Using this, we observe
that MTL, DAB and SCL perform relatively badly
when the target-domain distribution is more im-
balanced. In constrast, L-SVM, DAM and RDA
are more robust.
Comparing with the baselines, RDA achieves
the best performance on almost all the experi-
ments. Using the two-phase framework, RDA
can successfully transfer useful knowledge even in
the pressence of irrelevant sources and imbalanced
distributions. For ACE 2004, the improvement in
F1 over the best baseline can be up to 4.0% and
is on average 3.6%. Similarly for YAGO, the im-
provement in F1 over the best baseline can be up
to 5.5% and is on average 4.3%.
</bodyText>
<subsectionHeader confidence="0.661819">
Impact of Number of Source Domains Tables
</subsectionHeader>
<bodyText confidence="0.999663">
2, 3, 4 and 6 also demonstrate that RDA improves
monotonically as the number of source domains
increases for both ACE 2004 and YAGO.
</bodyText>
<page confidence="0.881072">
814
</page>
<tableCaption confidence="0.999707">
Table 5: The F1 of different methods on YAGO with k = 5 source domains.
</tableCaption>
<table confidence="0.999501590909091">
Target In-domain NT NT-U L-SVM MTL DAB SCL DAM RDA
acquirer acquiree 58.74 32.12 33.19 43.16 45.28 39.08 44.19 45.07 51.15
actedIn 77.36 40.73 44.32 50.45 57.18 49.61 58.23 56.37 63.40
bornIn 68.32 42.39 40.35 44.38 49.80 48.36 50.67 48.12 56.93
ceo company 82.92 47.60 51.27 55.27 61.06 58.33 57.41 59.08 66.71
company headquarters 75.16 48.92 52.15 50.13 59.47 61.23 58.36 56.65 64.36
created 74.26 46.37 43.58 60.45 60.74 55.08 59.42 57.34 65.28
diedIn 81.45 42.78 47.37 57.37 62.69 57.16 65.28 60.44 71.15
directed 70.11 44.42 48.29 50.57 54.29 49.09 52.31 50.30 57.71
discovered 68.13 37.34 42.51 48.77 53.04 49.82 53.73 51.21 59.12
graduatedFrom 69.37 39.28 45.74 51.56 58.22 54.38 56.32 51.17 60.37
hasChild 74.56 49.14 50.98 56.07 64.82 53.41 62.38 61.12 66.83
hasWonPrize 69.41 38.75 45.72 53.47 57.38 52.76 58.29 54.03 63.13
isLeaderOf 79.18 46.31 52.66 58.88 63.49 60.27 63.75 61.51 70.27
isMarriedTo 73.33 47.85 48.16 52.31 56.39 50.73 55.35 52.10 62.58
livesIn 66.93 36.16 35.15 40.28 50.27 41.72 43.59 48.11 56.91
participatedIn 85.38 46.22 48.33 62.48 67.51 61.08 65.38 61.12 71.72
person birthplace 77.62 43.43 45.27 49.66 58.47 59.32 57.55 52.14 65.80
person field 68.32 36.25 37.93 47.69 54.22 50.46 50.47 48.89 59.47
politicianOf 79.10 39.17 42.25 53.38 64.56 62.11 60.74 58.82 68.12
worksAt 84.29 45.78 49.78 59.34 65.33 65.44 66.53 63.24 73.31
Average 74.20 42.55 45.25 52.28 58.21 53.97 56.80 54.84 63.72
</table>
<bodyText confidence="0.989083153846154">
Performance Gap From Tables 2 to 4, we ob-
serve that the smallest performance gap between
RDA and the in-domain settings is still high (about
12% with k = 5) on ACE 2004. This is because we
have used a lot less labeled instances in the target
domains: only 10% are used. However, the gaps
reduces when the number of source domains in-
creases. Comparing with the in-domain results in
Table 5 (which is constant with k), Table 6 also
shows a similar trend on YAGO. By exploiting the
labeled data in ten source domains in YAGO, our
RDA algorithm can reduce the gap between the
cross-domain and in-domain settings to 9%.
</bodyText>
<sectionHeader confidence="0.995637" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9996408">
In this paper, we have proposed a robust domain
adaptation (RDA) approach for the relation extrac-
tion problem where labeled data is scarce. Ex-
isting domain adaptation approaches suffer from
negative transfer and under imbalanced distribu-
tions. To overcome these, we have proposed a
two-phase approach to transfer only relevant in-
formation from multiple source domains, and thus
derive accurate and robust predictions on the un-
labeled target-domain data. Experimental results
</bodyText>
<tableCaption confidence="0.988806">
Table 6: Average F1 of RDA on YAGO
</tableCaption>
<table confidence="0.8846182">
# source domains F1
k = 1 53.81
k = 3 59.43
k = 5 63.72
k = 10 65.55
</table>
<bodyText confidence="0.999401111111111">
on ACE 2004 and YAGO have shown that the our
domain adaptation method achieves the best per-
formance on F1 measure compared with the other
baselines when only few labeled target instances
are used. Because of the practical importance of
domain adaptation for relation extraction due to
lack of labeled data in new domains, we hope our
study and findings will lead to further investiga-
tions into this problem.
</bodyText>
<sectionHeader confidence="0.997713" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999798">
This work is supported by DSO grant
DSOCL10021. We thank Jiang for provid-
ing the source code for feature extraction and
Bollegala for sharing his YAGO dataset.
</bodyText>
<page confidence="0.868716">
815
</page>
<sectionHeader confidence="0.995243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999651942857142">
Eugene Agichtein and Luis Gravano. 2000. Snow-
ball: Extracting relations from large plain-text col-
lections. In Proceedings of the fifth ACM conference
on Digital libraries, pages 85–94. ACM.
Michele Banko, Oren Etzioni, and Turing Center.
2008. The tradeoffs between open and traditional
relation extraction. Proceedings of ACL-08: HLT,
pages 28–36.
Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani.
2006. Manifold regularization: A geometric frame-
work for learning from labeled and unlabeled exam-
ples. The Journal of Machine Learning Research,
7:2399–2434.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language
Processing, pages 120–128. ACL.
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In ACL.
Danushka Bollegala, Yutaka Matsuo, and Mitsuru
Ishizuka. 2011. Relation adaptation: learning to
extract novel relations with minimum supervision.
In Proceedings of the Twenty-Second international
joint conference on Artificial Intelligence-Volume
Volume Three, pages 2205–2210. AAAI Press.
Razvan Bunescu and Raymond Mooney. 2006. Subse-
quence kernels for relation extraction. Advances in
neural information processing systems, 18:171–178.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the 42nd Annual Meeting on Association for Com-
putational Linguistics, pages 423–429. ACL.
Hal Daume and D Marcu. 2007. Frustratingly easy
domain adaptation. In Annual meeting-association
for computational linguistics, pages 256–263.
Anhai Doan, Pedro Domingos, and Alon Halevy.
2003. Learning to match the schemas of data
sources: A multistrategy approach. Machine Learn-
ing, 50(3):279–301.
Lixin Duan, Ivor W Tsang, Dong Xu, and Tat-Seng
Chua. 2009. Domain adaptation from multiple
sources via auxiliary classifiers. In Proceedings of
the 26th Annual ICML, pages 289–296. ACM.
Oren Etzioni, Michele Banko, Stephen Soderland, and
Daniel S Weld. 2008. Open information extrac-
tion from the web. Communications of the ACM,
51(12):68–74.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. The Journal of
Machine Learning Research, 9:1871–1874.
Jing Jiang and ChengXiang Zhai. 2007a. Instance
weighting for domain adaptation in nlp. In An-
nual Meeting-Association For Computational Lin-
guistics, pages 264–271.
Jing Jiang and ChengXiang Zhai. 2007b. A systematic
exploration of the feature space for relation extrac-
tion. In HLT-NAACL, pages 113–120.
Jing Jiang. 2009. Multi-task transfer learning for
weakly-supervised relation extraction. In Proceed-
ings of the 47th Annual Meeting of the ACL: Volume
2-Volume 2, pages 1012–1020.
Zornitsa Kozareva and Eduard Hovy. 2010. Not all
seeds are equal: Measuring the quality of text min-
ing seeds. In HLT: The 2010 Annual Conference of
the North American Chapter of the ACL, pages 618–
626. ACL.
Stefano Melacci and Mikhail Belkin. 2011. Laplacian
support vector machines trained in the primal. Jour-
nal of Machine Learning Research, 12:1149–1184.
Filipe Mesquita, Jordan Schmidek, and Denilson Bar-
bosa. 2013. Effectiveness and efficiency of open
relation extraction. In Proceedings of EMNLP-13,
volume 500, pages 447–457.
Bonan Min, Ralph Grishman, Li Wan, Chang Wang,
and David Gondek. 2013. Distant supervision for
relation extraction with an incomplete knowledge
base. In Proceedings of NAACL-HLT, pages 777–
782.
Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 2-Volume 2, pages 1003–1011. Association for
Computational Linguistics.
Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen. 2010. Cross-domain sen-
timent classification via spectral feature alignment.
In Proceedings of the 19th international conference
on World wide web, pages 751–760. ACM.
Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei
Lifchits, and Alpa Jain. 2006. Organizing and
searching the world wide web of facts - step one:
The one-million fact extraction challenge. In Pro-
ceedings of the 21st National Conference on Artifi-
cial Intelligence - Volume 2, AAAI’06, pages 1400–
1405. AAAI Press.
</reference>
<page confidence="0.644315">
816
</page>
<reference confidence="0.997512611940299">
Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics, pages 1498–1507.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaom-
ing Zhu, and Peide Qian. 2008. Exploiting con-
stituent dependencies for tree kernel-based semantic
relation extraction. In Proceedings of the 22nd Con-
ference on Computational Linguistics, pages 697–
704. ACL.
Ellen Riloff and Rosie Jones. 1999. Learning dic-
tionaries for information extraction by multi-level
bootstrapping. In Proceedings of the National Con-
ference on AI, pages 474–479.
Michael T Rosenstein, Zvika Marx, Leslie Pack Kael-
bling, and Thomas G Dietterich. 2005. To transfer
or not to transfer. In NIPS 2005 Workshop on Trans-
fer Learning, volume 898, pages –.
Gerard Salton and Michael J. McGill. 1986. Intro-
duction to Modern Information Retrieval. McGraw-
Hill, Inc., New York, NY, USA.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted rela-
tion discovery. In Proceedings of the HLT Confer-
ence of the North American Chapter of the ACL,
pages 304–311.
Alex J Smola and Bernhard Scholkopf. 1998. Learn-
ing with kernels. Citeseer.
Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge unifying wordnet and wikipedia. In Proceed-
ings of the 16th international conference on World
Wide Web, pages 697–706. ACM.
Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2012. Reducing wrong labels in distant supervi-
sion for relation extraction. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics: Long Papers-Volume 1, pages
721–729. Association for Computational Linguis-
tics.
Feiyu Xu, Hans Uszkoreit, Sebastian Krause, and Hong
Li. 2010. Boosting relation extraction with lim-
ited closed-world knowledge. In Proceedings of
the 23rd Conference on Computational Linguistics,
pages 1354–1362. ACL.
Wei Xu, Raphael Hoffmann Le Zhao, and Ralph Grish-
man. 2013. Filling knowledge base gaps for distant
supervision of relation extraction. In Proceedings of
EMNLP-13, pages 665–670.
Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both flat and structured features.
In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 825–832. Association for Computa-
tional Linguistics.
Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal,
Jason Weston, and Bernhard Sch¨olkopf. 2003.
Learning with local and global consistency. In
NIPS.
Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and
Ji-Rong Wen. 2009. Statsnowball: a statistical ap-
proach to extracting entity relationships. In Pro-
ceedings of the 18th international conference on
Worldwide web, pages 101–110. ACM.
</reference>
<page confidence="0.872324">
817
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287810">
<title confidence="0.961883">Robust Domain Adaptation for Relation Extraction via Clustering Consistency</title>
<author confidence="0.883962">Luan Ivor W Kian Ming A</author>
<author confidence="0.883962">Hai Leong</author>
<affiliation confidence="0.637599">for Infocomm Research, Singapore for Quantum Computation &amp; Intelligent Systems, University of Technology, Sydney, National Laboratories, Singapore</affiliation>
<email confidence="0.934328">mlnguyen@i2r.a-star.edu.sg,</email>
<abstract confidence="0.99657128125">We propose a two-phase framework to adapt existing relation extraction classifiers to extract relations for new target domains. We address two challenges: negative transfer when knowledge in source domains is used without considering the differences in relation distributions; and lack of adequate labeled samples for rarer relations in the new domain, due to a small labeled data set and imbalance relation distributions. Our framework leverages on both labeled and unlabeled data in the target domain. First, we determine the relevance of each source domain to the target domain for each relation type, using the consistency between the clustering given by the target domain labels and the clustering given by the predictors trained for the source domain. To overcome the lack of labeled samples for rarer relations, these clusterings operate on both the labeled and unlabeled data in the target domain. Second, we trade-off between using relevance-weighted sourcedomain predictors and the labeled target data. Again, to overcome the imbalance distribution, the source-domain predictors operate on the unlabeled target data. Our method outperforms numerous baselines and a weakly-supervised relation extraction method on ACE 2004 and YAGO.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: Extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the fifth ACM conference on Digital libraries,</booktitle>
<pages>85--94</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7436" citStr="Agichtein and Gravano, 2000" startWordPosition="1150" endWordPosition="1153">given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Differ</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting relations from large plain-text collections. In Proceedings of the fifth ACM conference on Digital libraries, pages 85–94. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
<author>Turing Center</author>
</authors>
<title>The tradeoffs between open and traditional relation extraction.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>28--36</pages>
<contexts>
<context position="8308" citStr="Banko et al., 2008" startWordPosition="1293" endWordPosition="1296">ated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has</context>
</contexts>
<marker>Banko, Etzioni, Center, 2008</marker>
<rawString>Michele Banko, Oren Etzioni, and Turing Center. 2008. The tradeoffs between open and traditional relation extraction. Proceedings of ACL-08: HLT, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Belkin</author>
<author>Partha Niyogi</author>
<author>Vikas Sindhwani</author>
</authors>
<title>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.</title>
<date>2006</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>7--2399</pages>
<contexts>
<context position="22755" citStr="Belkin et al., 2006" startWordPosition="3777" endWordPosition="3780">mplexity of the functions fjs in the Reproducing Kernel Hilbert Space (RKHS) H; and the third prefers the predicted labels of the unlabeled data Dl to be close to the reference predictions. The third term provides additional pseudo-training samples for the rarer relation classes, if these are available in Du. Parameters β and γ govern the trade-offs between these objectives. Let K(·,·) be the reproducing kernel for H. By the Representer Theorem (Smola and Scholkopf, 1998), the solution for Eq. 3 is linear in K(xi,·): fj(x) = ∑ni=1 αjiK(xi,x). Putting this into Eq. 3, parameter vectors αj are (Belkin et al., 2006): α*j = (JK +γ(nl +βnu)I)−1JRj. (4) Here, Rj is an (nl + nu)-vector, where Rji = rji if sample i belongs to the labeled set, and Rji = ˆri j if it belongs to the unlabeled set; and J is an (nl + nu)-by-(nl +nu) diagonal matrix where the first nl diagonal entries are ones and the rest are βs. 5 Experiments We evaluate our algorithm on two corpora: Automatic Content Extraction (ACE) 2004 and YAGO3. Table 1 provides some statistics on them. ACE 2004 consists of six domains: Broadcast Conversations (BC), Broadcast News (BN), Conversational Telephone Speech (CTS), Newswire (NW), Usenet (UN) and Web</context>
</contexts>
<marker>Belkin, Niyogi, Sindhwani, 2006</marker>
<rawString>Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani. 2006. Manifold regularization: A geometric framework for learning from labeled and unlabeled examples. The Journal of Machine Learning Research, 7:2399–2434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>120--128</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="9653" citStr="Blitzer et al., 2006" startWordPosition="1501" endWordPosition="1504">en IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 120–128. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="27896" citStr="Blitzer et al. (2007)" startWordPosition="4639" endWordPosition="4642">abeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM) This is a semisupervised learning method based on label propagation (Melacci and Belkin, 2011). Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extraction (Jiang, 2009). Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction (Xu et al., 2010). Structural correspondence learning (SCL) We use the feature-based domain adaptation approach by Blitzer et al. (2007). We apply SCL on the Dss and Dl to train a model. The learned model then makes predictions on Du. Domain Adaptation Machine (DAM) We use the framework of Duan et al. (2009), which is a multiple-sources domain adaptation method. For the kernel-based methods above, we use the same composite kernel used in our method. The source codes of L-SVM, MTL, SCL and DAM were obtained from the authors. The others were re-implemented. 5.3 Experimental Results Tables 2, 3 and 4 present the results on ACE 2004 (corresponding to k = 1,3,5), and Tables 5 present those on YAGO (corresponding to k = 5). From Tab</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>Yutaka Matsuo</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Relation adaptation: learning to extract novel relations with minimum supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three,</booktitle>
<pages>2205--2210</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="24075" citStr="Bollegala et al. (2011)" startWordPosition="3991" endWordPosition="3994"> needed. 3http://www.mpi-inf.mpg.de/yago-naga/yago/ Table 1: Statistics on ACE 2004 and YAGO Properties ACE 2004 YAGO # relation types 7 20 # candidate relations 48,625 68,822 # gold relations 4,296 2,000 # mentions per entity pair 6 11 % mentions with +ve relations 8.8% 21% Physical (Phy), Personal/Social (Per), Employment/Membership/Subsidiary (Emp), AgentArtifact (Agt), PER/ORG Affiliation (Aff), GPE Affiliation (GPE) and Discourse (Dis). YAGO is an open information extraction data set. The relation types of YAGO are built from Wikipedia and WordNet, while the labeled text for YAGO is from Bollegala et al. (2011). It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is considered as a domain in this work. YAGO is different from ACE 2004 in two aspects: there is less overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average. We used Collins parser (Collins, 1999) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent (Jiang and Zhai, 2007b). The candidate relation instances we</context>
</contexts>
<marker>Bollegala, Matsuo, Ishizuka, 2011</marker>
<rawString>Danushka Bollegala, Yutaka Matsuo, and Mitsuru Ishizuka. 2011. Relation adaptation: learning to extract novel relations with minimum supervision. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three, pages 2205–2210. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>Subsequence kernels for relation extraction. Advances in neural information processing systems,</title>
<date>2006</date>
<pages>18--171</pages>
<contexts>
<context position="7001" citStr="Bunescu and Mooney, 2006" startWordPosition="1084" endWordPosition="1087">reasonable predictive performance even when all the source domains are irrelevant and augments the rarer classes with examples in the unlabeled data. We compare the proposed two-phase framework with state-of-the-art domain adaptation baselines for the relation extraction task, and we find that our method outperforms the baselines. 2 Related Work Relation extraction is usually considered a classification problem: determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised ap</context>
</contexts>
<marker>Bunescu, Mooney, 2006</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2006. Subsequence kernels for relation extraction. Advances in neural information processing systems, 18:171–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="24476" citStr="Collins, 1999" startWordPosition="4066" endWordPosition="4067">iliation (GPE) and Discourse (Dis). YAGO is an open information extraction data set. The relation types of YAGO are built from Wikipedia and WordNet, while the labeled text for YAGO is from Bollegala et al. (2011). It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is considered as a domain in this work. YAGO is different from ACE 2004 in two aspects: there is less overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average. We used Collins parser (Collins, 1999) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent (Jiang and Zhai, 2007b). The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence. For the similarity matrix W in section 4.1 and the kernel K(·,·) in section 4.2, we used the composite kernel function (Zhang et al., 2006), which is based on structured features and entity-related features. F1 is used to measure the performance of the algorithms. This is the harmonic mean of precision TP/(TP + FP) a</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423--429</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="6953" citStr="Culotta and Sorensen, 2004" startWordPosition="1077" endWordPosition="1080">on the unlabeled target domain data. This ensures reasonable predictive performance even when all the source domains are irrelevant and augments the rarer classes with examples in the unlabeled data. We compare the proposed two-phase framework with state-of-the-art domain adaptation baselines for the relation extraction task, and we find that our method outperforms the baselines. 2 Related Work Relation extraction is usually considered a classification problem: determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they req</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 423–429. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
<author>D Marcu</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Annual meeting-association for computational linguistics,</booktitle>
<pages>256--263</pages>
<contexts>
<context position="9631" citStr="Daume and Marcu, 2007" startWordPosition="1497" endWordPosition="1500">pora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation me</context>
</contexts>
<marker>Daume, Marcu, 2007</marker>
<rawString>Hal Daume and D Marcu. 2007. Frustratingly easy domain adaptation. In Annual meeting-association for computational linguistics, pages 256–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anhai Doan</author>
<author>Pedro Domingos</author>
<author>Alon Halevy</author>
</authors>
<title>Learning to match the schemas of data sources: A multistrategy approach.</title>
<date>2003</date>
<booktitle>Machine Learning,</booktitle>
<volume>50</volume>
<issue>3</issue>
<contexts>
<context position="9304" citStr="Doan et al., 2003" startWordPosition="1452" endWordPosition="1455">atterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances </context>
</contexts>
<marker>Doan, Domingos, Halevy, 2003</marker>
<rawString>Anhai Doan, Pedro Domingos, and Alon Halevy. 2003. Learning to match the schemas of data sources: A multistrategy approach. Machine Learning, 50(3):279–301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lixin Duan</author>
<author>Ivor W Tsang</author>
<author>Dong Xu</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Domain adaptation from multiple sources via auxiliary classifiers.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual ICML,</booktitle>
<pages>289--296</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="21819" citStr="Duan et al., 2009" startWordPosition="3619" endWordPosition="3622"> xi E Rj, then us,i = ws,j. At our disposal from the previous phase are also k sourcedomain predictors ps that have been trained on Ds. Combining and weighing the predictions from multiple sources, we obtain the reference predicn ∑ i=1 +µ � not-a-relation if (maxj pji ) &lt; θ, ji = argmaxj pij otherwise. (2) BC BN NW CTS WL 811 tion ˆrji = ∑ks=1 us,i(2Qps(xi) = j� −1) for example xi belonging to relation j, using the +1 encoding. The relation classifier consists of c functions f1,..., fc using the one-versus-rest decoding for multi-class classification.2 Inspired by the Domain Adaptive Machine (Duan et al., 2009), we combine the reference predictions and the labeled data of the target domain to learn these functions: where rji = 2Qyi = j� −1 is the +1 binary encoding for the i labeled sample belonging to relation j. Here, we have multiple objectives: the first term controls the training error; the second regularizes the complexity of the functions fjs in the Reproducing Kernel Hilbert Space (RKHS) H; and the third prefers the predicted labels of the unlabeled data Dl to be close to the reference predictions. The third term provides additional pseudo-training samples for the rarer relation classes, if </context>
<context position="28069" citStr="Duan et al. (2009)" startWordPosition="4672" endWordPosition="4675"> a semisupervised learning method based on label propagation (Melacci and Belkin, 2011). Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extraction (Jiang, 2009). Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction (Xu et al., 2010). Structural correspondence learning (SCL) We use the feature-based domain adaptation approach by Blitzer et al. (2007). We apply SCL on the Dss and Dl to train a model. The learned model then makes predictions on Du. Domain Adaptation Machine (DAM) We use the framework of Duan et al. (2009), which is a multiple-sources domain adaptation method. For the kernel-based methods above, we use the same composite kernel used in our method. The source codes of L-SVM, MTL, SCL and DAM were obtained from the authors. The others were re-implemented. 5.3 Experimental Results Tables 2, 3 and 4 present the results on ACE 2004 (corresponding to k = 1,3,5), and Tables 5 present those on YAGO (corresponding to k = 5). From Table 3 and Table 5, we see that the proposed method has the best F1 among all the other methods, except for the supervised upper bound (In-domain). We first notice that NT-U g</context>
</contexts>
<marker>Duan, Tsang, Xu, Chua, 2009</marker>
<rawString>Lixin Duan, Ivor W Tsang, Dong Xu, and Tat-Seng Chua. 2009. Domain adaptation from multiple sources via auxiliary classifiers. In Proceedings of the 26th Annual ICML, pages 289–296. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michele Banko</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2008</date>
<journal>Communications of the ACM,</journal>
<volume>51</volume>
<issue>12</issue>
<contexts>
<context position="2161" citStr="Etzioni et al., 2008" startWordPosition="309" endWordPosition="312">get data. Our method outperforms numerous baselines and a weakly-supervised relation extraction method on ACE 2004 and YAGO. 1 Introduction The World Wide Web contains information on real-world entities, such as persons, locations and ∗The work is done while Nguyen was a research staff in Nanyang Technological University, Singapore. organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new</context>
<context position="8288" citStr="Etzioni et al., 2008" startWordPosition="1288" endWordPosition="1292">nstances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; </context>
</contexts>
<marker>Etzioni, Banko, Soderland, Weld, 2008</marker>
<rawString>Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld. 2008. Open information extraction from the web. Communications of the ACM, 51(12):68–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="26740" citStr="Fan et al., 2008" startWordPosition="4463" endWordPosition="4466">ormance over the five runs. In our experiments, we set µ = 0.8 in Eq. 1; θ = 0.18 in Eq. 2; and γ = 0.1 and β = 0.3 in Eq. 3. For each target domain, we used k ∈ {1,3,5} different source domains chosen randomly from the remaining domains. Thus, the relevance of the source domains to the target domain varies from experiment to experiment. 5.2 Baselines We compare our framework with several other methods, including state-of-the-art machine learning, relation extraction and common domain adaptation methods. These are described below. In-domain multiclass classifier This is Supportvector-machine (Fan et al., 2008, SVM) using the one-versus-rest decoding without removing positive labeled data (Jiang and Zhai, 2007b) from the target domain. Its performance can be regarded as an upper bound on the performance of the cross-domain methods. No-transfer classifier (NT) We only use the few labeled instances of the target relation type together with the negative relation instances to train a binary classifier. Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied d</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Instance weighting for domain adaptation in nlp.</title>
<date>2007</date>
<booktitle>In Annual Meeting-Association For Computational Linguistics,</booktitle>
<pages>264--271</pages>
<contexts>
<context position="2354" citStr="Jiang and Zhai, 2007" startWordPosition="335" endWordPosition="338">entities, such as persons, locations and ∗The work is done while Nguyen was a research staff in Nanyang Technological University, Singapore. organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new domain using a small set of labeled data. This paper considers relation adaptation, where a relation extraction system trained on many source domains is adapted to a new target domain. There a</context>
<context position="9675" citStr="Jiang and Zhai, 2007" startWordPosition="1505" endWordPosition="1508">ation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common feature</context>
<context position="12915" citStr="Jiang and Zhai (2007" startWordPosition="2067" endWordPosition="2070">he relations between them. We use the term context to refer a window of text in which two entities co-occur. A context might not necessarily be a complete sentence S. Retrieving contexts in which two entities co-occur has been studied in previous works investigating the relations between entities. Given a pair of entities (A,B) in S, the first step is to express the relation between A and B with some feature representation using a feature extraction scheme χ. Lexical or syntactic patterns have been successfully used in numerous natural language processing tasks, including relation extraction. Jiang and Zhai (2007b) have shown that selected lexical and syntactic patterns can give good performance for relation extraction. Following their work1, we also use lexical and syntactic patterns extracted from the contexts to represent the relations between entities. We extract features from a sequence representation and a parse tree representation of each relation instance. The details are as follows. Entity Features Entity types and entity mention types are very useful for relation extraction. We 1The source code for extracting entity features is provided by the authors (Jiang and Zhai, 2007b). 809 use a subgr</context>
<context position="24636" citStr="Jiang and Zhai, 2007" startWordPosition="4090" endWordPosition="4093">e the labeled text for YAGO is from Bollegala et al. (2011). It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is considered as a domain in this work. YAGO is different from ACE 2004 in two aspects: there is less overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average. We used Collins parser (Collins, 1999) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent (Jiang and Zhai, 2007b). The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence. For the similarity matrix W in section 4.1 and the kernel K(·,·) in section 4.2, we used the composite kernel function (Zhang et al., 2006), which is based on structured features and entity-related features. F1 is used to measure the performance of the algorithms. This is the harmonic mean of precision TP/(TP + FP) and recall TP/(TP + FN), where TP, FP and FN are the numbers of correct, missing and wrongly recognized relations. 5.1 Experimental Settings For ACE 2004, we use</context>
<context position="26842" citStr="Jiang and Zhai, 2007" startWordPosition="4477" endWordPosition="4480">= 0.1 and β = 0.3 in Eq. 3. For each target domain, we used k ∈ {1,3,5} different source domains chosen randomly from the remaining domains. Thus, the relevance of the source domains to the target domain varies from experiment to experiment. 5.2 Baselines We compare our framework with several other methods, including state-of-the-art machine learning, relation extraction and common domain adaptation methods. These are described below. In-domain multiclass classifier This is Supportvector-machine (Fan et al., 2008, SVM) using the one-versus-rest decoding without removing positive labeled data (Jiang and Zhai, 2007b) from the target domain. Its performance can be regarded as an upper bound on the performance of the cross-domain methods. No-transfer classifier (NT) We only use the few labeled instances of the target relation type together with the negative relation instances to train a binary classifier. Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007a. Instance weighting for domain adaptation in nlp. In Annual Meeting-Association For Computational Linguistics, pages 264–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A systematic exploration of the feature space for relation extraction. In</title>
<date>2007</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="2354" citStr="Jiang and Zhai, 2007" startWordPosition="335" endWordPosition="338">entities, such as persons, locations and ∗The work is done while Nguyen was a research staff in Nanyang Technological University, Singapore. organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new domain using a small set of labeled data. This paper considers relation adaptation, where a relation extraction system trained on many source domains is adapted to a new target domain. There a</context>
<context position="9675" citStr="Jiang and Zhai, 2007" startWordPosition="1505" endWordPosition="1508">ation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common feature</context>
<context position="12915" citStr="Jiang and Zhai (2007" startWordPosition="2067" endWordPosition="2070">he relations between them. We use the term context to refer a window of text in which two entities co-occur. A context might not necessarily be a complete sentence S. Retrieving contexts in which two entities co-occur has been studied in previous works investigating the relations between entities. Given a pair of entities (A,B) in S, the first step is to express the relation between A and B with some feature representation using a feature extraction scheme χ. Lexical or syntactic patterns have been successfully used in numerous natural language processing tasks, including relation extraction. Jiang and Zhai (2007b) have shown that selected lexical and syntactic patterns can give good performance for relation extraction. Following their work1, we also use lexical and syntactic patterns extracted from the contexts to represent the relations between entities. We extract features from a sequence representation and a parse tree representation of each relation instance. The details are as follows. Entity Features Entity types and entity mention types are very useful for relation extraction. We 1The source code for extracting entity features is provided by the authors (Jiang and Zhai, 2007b). 809 use a subgr</context>
<context position="24636" citStr="Jiang and Zhai, 2007" startWordPosition="4090" endWordPosition="4093">e the labeled text for YAGO is from Bollegala et al. (2011). It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is considered as a domain in this work. YAGO is different from ACE 2004 in two aspects: there is less overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average. We used Collins parser (Collins, 1999) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent (Jiang and Zhai, 2007b). The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence. For the similarity matrix W in section 4.1 and the kernel K(·,·) in section 4.2, we used the composite kernel function (Zhang et al., 2006), which is based on structured features and entity-related features. F1 is used to measure the performance of the algorithms. This is the harmonic mean of precision TP/(TP + FP) and recall TP/(TP + FN), where TP, FP and FN are the numbers of correct, missing and wrongly recognized relations. 5.1 Experimental Settings For ACE 2004, we use</context>
<context position="26842" citStr="Jiang and Zhai, 2007" startWordPosition="4477" endWordPosition="4480">= 0.1 and β = 0.3 in Eq. 3. For each target domain, we used k ∈ {1,3,5} different source domains chosen randomly from the remaining domains. Thus, the relevance of the source domains to the target domain varies from experiment to experiment. 5.2 Baselines We compare our framework with several other methods, including state-of-the-art machine learning, relation extraction and common domain adaptation methods. These are described below. In-domain multiclass classifier This is Supportvector-machine (Fan et al., 2008, SVM) using the one-versus-rest decoding without removing positive labeled data (Jiang and Zhai, 2007b) from the target domain. Its performance can be regarded as an upper bound on the performance of the cross-domain methods. No-transfer classifier (NT) We only use the few labeled instances of the target relation type together with the negative relation instances to train a binary classifier. Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007b. A systematic exploration of the feature space for relation extraction. In HLT-NAACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
</authors>
<title>Multi-task transfer learning for weakly-supervised relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL: Volume</booktitle>
<volume>2</volume>
<pages>1012--1020</pages>
<contexts>
<context position="9690" citStr="Jiang, 2009" startWordPosition="1509" endWordPosition="1510">main of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common features in source and</context>
<context position="27647" citStr="Jiang, 2009" startWordPosition="4606" endWordPosition="4607"> the target relation type together with the negative relation instances to train a binary classifier. Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM) This is a semisupervised learning method based on label propagation (Melacci and Belkin, 2011). Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extraction (Jiang, 2009). Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction (Xu et al., 2010). Structural correspondence learning (SCL) We use the feature-based domain adaptation approach by Blitzer et al. (2007). We apply SCL on the Dss and Dl to train a model. The learned model then makes predictions on Du. Domain Adaptation Machine (DAM) We use the framework of Duan et al. (2009), which is a multiple-sources domain adaptation method. For the kernel-based methods above, we use the same composite kernel used in our method. The source codes of L-SVM, MTL, S</context>
</contexts>
<marker>Jiang, 2009</marker>
<rawString>Jing Jiang. 2009. Multi-task transfer learning for weakly-supervised relation extraction. In Proceedings of the 47th Annual Meeting of the ACL: Volume 2-Volume 2, pages 1012–1020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard Hovy</author>
</authors>
<title>Not all seeds are equal: Measuring the quality of text mining seeds.</title>
<date>2010</date>
<booktitle>In HLT: The 2010 Annual Conference of the North American Chapter of the ACL,</booktitle>
<pages>618--626</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="8028" citStr="Kozareva and Hovy, 2010" startWordPosition="1247" endWordPosition="1250">009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard Hovy. 2010. Not all seeds are equal: Measuring the quality of text mining seeds. In HLT: The 2010 Annual Conference of the North American Chapter of the ACL, pages 618– 626. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Melacci</author>
<author>Mikhail Belkin</author>
</authors>
<title>Laplacian support vector machines trained in the primal.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--1149</pages>
<contexts>
<context position="27538" citStr="Melacci and Belkin, 2011" startWordPosition="4589" endWordPosition="4592">bound on the performance of the cross-domain methods. No-transfer classifier (NT) We only use the few labeled instances of the target relation type together with the negative relation instances to train a binary classifier. Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM) This is a semisupervised learning method based on label propagation (Melacci and Belkin, 2011). Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extraction (Jiang, 2009). Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction (Xu et al., 2010). Structural correspondence learning (SCL) We use the feature-based domain adaptation approach by Blitzer et al. (2007). We apply SCL on the Dss and Dl to train a model. The learned model then makes predictions on Du. Domain Adaptation Machine (DAM) We use the framework of Duan et al. (2009), which is a multiple-sources domain adaptation method. For the kerne</context>
</contexts>
<marker>Melacci, Belkin, 2011</marker>
<rawString>Stefano Melacci and Mikhail Belkin. 2011. Laplacian support vector machines trained in the primal. Journal of Machine Learning Research, 12:1149–1184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filipe Mesquita</author>
<author>Jordan Schmidek</author>
<author>Denilson Barbosa</author>
</authors>
<title>Effectiveness and efficiency of open relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP-13,</booktitle>
<volume>500</volume>
<pages>447--457</pages>
<contexts>
<context position="8332" citStr="Mesquita et al., 2013" startWordPosition="1297" endWordPosition="1300">e target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is </context>
</contexts>
<marker>Mesquita, Schmidek, Barbosa, 2013</marker>
<rawString>Filipe Mesquita, Jordan Schmidek, and Denilson Barbosa. 2013. Effectiveness and efficiency of open relation extraction. In Proceedings of EMNLP-13, volume 500, pages 447–457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonan Min</author>
<author>Ralph Grishman</author>
<author>Li Wan</author>
<author>Chang Wang</author>
<author>David Gondek</author>
</authors>
<title>Distant supervision for relation extraction with an incomplete knowledge base.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>777--782</pages>
<contexts>
<context position="8886" citStr="Min et al., 2013" startWordPosition="1382" endWordPosition="1385">zioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transf</context>
</contexts>
<marker>Min, Grishman, Wan, Wang, Gondek, 2013</marker>
<rawString>Bonan Min, Ralph Grishman, Li Wan, Chang Wang, and David Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In Proceedings of NAACL-HLT, pages 777– 782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8844" citStr="Mintz et al., 2009" startWordPosition="1374" endWordPosition="1377">n. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema match</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Jialin Pan</author>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Qiang Yang</author>
<author>Zheng Chen</author>
</authors>
<title>Cross-domain sentiment classification via spectral feature alignment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web,</booktitle>
<pages>751--760</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9737" citStr="Pan et al., 2010" startWordPosition="1515" endWordPosition="1518">stances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common features in source and target domains and then use those features as </context>
</contexts>
<marker>Pan, Ni, Sun, Yang, Chen, 2010</marker>
<rawString>Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen. 2010. Cross-domain sentiment classification via spectral feature alignment. In Proceedings of the 19th international conference on World wide web, pages 751–760. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Dekang Lin</author>
<author>Jeffrey Bigham</author>
<author>Andrei Lifchits</author>
<author>Alpa Jain</author>
</authors>
<title>Organizing and searching the world wide web of facts - step one: The one-million fact extraction challenge.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2, AAAI’06,</booktitle>
<pages>1400--1405</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="7473" citStr="Pasca et al., 2006" startWordPosition="1158" endWordPosition="1161">tion. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only u</context>
</contexts>
<marker>Pasca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, and Alpa Jain. 2006. Organizing and searching the world wide web of facts - step one: The one-million fact extraction challenge. In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2, AAAI’06, pages 1400– 1405. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Plank</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Embedding semantic similarity in tree kernels for domain adaptation of relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1498--1507</pages>
<contexts>
<context position="9787" citStr="Plank and Moschitti, 2013" startWordPosition="1523" endWordPosition="1526"> unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution. Domain adaptation methods can be classified broadly into weakly-supervised adaptation (Daume and Marcu, 2007; Blitzer et al., 2006; Jiang and Zhai, 2007a; Jiang, 2009), and unsupervised adaptation (Pan et al., 2010; Blitzer et al., 2006; Plank and Moschitti, 2013). In the weaklysupervised approach, we have plenty of labeled data for the source domain and a few labeled instances in the target domain; in the unsupervised approach, the data for the target domain are not labeled. Among these studies, Plank and Moschitti’s is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new relation types. Typical relation adaptation methods first identify a set of common features in source and target domains and then use those features as pivots to map source domain features to the target</context>
</contexts>
<marker>Plank, Moschitti, 2013</marker>
<rawString>Barbara Plank and Alessandro Moschitti. 2013. Embedding semantic similarity in tree kernels for domain adaptation of relation extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1498–1507.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longhua Qian</author>
<author>Guodong Zhou</author>
<author>Fang Kong</author>
<author>Qiaoming Zhu</author>
<author>Peide Qian</author>
</authors>
<title>Exploiting constituent dependencies for tree kernel-based semantic relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd Conference on Computational Linguistics,</booktitle>
<pages>697--704</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7050" citStr="Qian et al., 2008" startWordPosition="1092" endWordPosition="1095">ce domains are irrelevant and augments the rarer classes with examples in the unlabeled data. We compare the proposed two-phase framework with state-of-the-art domain adaptation baselines for the relation extraction task, and we find that our method outperforms the baselines. 2 Related Work Relation extraction is usually considered a classification problem: determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initia</context>
<context position="14591" citStr="Qian et al., 2008" startWordPosition="2338" endWordPosition="2341">e of the relation instance sentence can be augmented to represent the relation instance. Each node is augmented with relevant part-of-speech (POS) using the Python Natural Language Processing Tool Kit. Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node corresponds to entity A, B, both, or neither. The nodes that represent the argument are also labeled with the entity type, subtype and mention type. We trim the parse tree of a relation instance so that it contains only the most essential tree components based on constituent dependencies (Qian et al., 2008). We also use unigram features and bigram features from a relation instance graph. 4 Robust Domain Adaptation In this section, we describe our two-phase approach, which comprises of a Supervised Voting scheme and a combined classifier learning phase. 4.1 Phase 1: Clustering Consistency via Supervised Voting In this section, we use the concept of clustering consistency to determine the relevance of a source domain to particular regions in the target domain. Figure 1 illustrates this. There, both enclosing circles in the left and right figures denote the same input space of the target domain. Th</context>
</contexts>
<marker>Qian, Zhou, Kong, Zhu, Qian, 2008</marker>
<rawString>Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu, and Peide Qian. 2008. Exploiting constituent dependencies for tree kernel-based semantic relation extraction. In Proceedings of the 22nd Conference on Computational Linguistics, pages 697– 704. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the National Conference on AI,</booktitle>
<pages>474--479</pages>
<contexts>
<context position="7498" citStr="Riloff and Jones, 1999" startWordPosition="1162" endWordPosition="1165">upervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain </context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the National Conference on AI, pages 474–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael T Rosenstein</author>
<author>Zvika Marx</author>
<author>Leslie Pack Kaelbling</author>
<author>Thomas G Dietterich</author>
</authors>
<title>To transfer or not to transfer.</title>
<date>2005</date>
<booktitle>In NIPS 2005 Workshop on Transfer Learning,</booktitle>
<volume>898</volume>
<pages>pages –.</pages>
<contexts>
<context position="4300" citStr="Rosenstein et al., 2005" startWordPosition="660" endWordPosition="663">f (between a company and a person), 807 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 807–817, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics whereas in the person domain we may be more interested in extracting relations such as liveIn (between a person and a location) and workAt (between a person and a company). Therefore, although the two domains may have the same set of relations, they probably have different marginal distributions on the relations. This can produce a negative transfer phenomenon (Rosenstein et al., 2005), where using knowledge from other domains degrades the performance on the target domain. Hence, when transferring knowledge from multiple domains, it is overly optimistic to believe that all source domains will contribute positively. We call a source domain irrelevant when it has no or negative contribution to the performance of the target domain. One example is named entities extraction adaptation, where naive transfer of information from a mixed-case domain with capitalization information (e.g., news-wire) to a single-case domain (e.g., conversational speech transcripts) will miss most name</context>
</contexts>
<marker>Rosenstein, Marx, Kaelbling, Dietterich, 2005</marker>
<rawString>Michael T Rosenstein, Zvika Marx, Leslie Pack Kaelbling, and Thomas G Dietterich. 2005. To transfer or not to transfer. In NIPS 2005 Workshop on Transfer Learning, volume 898, pages –.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1986</date>
<publisher>McGrawHill, Inc.,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2088" citStr="Salton and McGill, 1986" startWordPosition="299" endWordPosition="302">ance distribution, the source-domain predictors operate on the unlabeled target data. Our method outperforms numerous baselines and a weakly-supervised relation extraction method on ACE 2004 and YAGO. 1 Introduction The World Wide Web contains information on real-world entities, such as persons, locations and ∗The work is done while Nguyen was a research staff in Nanyang Technological University, Singapore. organizations, which are interconnected by various semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval (Salton and McGill, 1986) and information extraction for question answering (Etzioni et al., 2008). Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelligent feature engineering can provide state-of-theart performance (Jiang and Zhai, 2007b). However, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more </context>
</contexts>
<marker>Salton, McGill, 1986</marker>
<rawString>Gerard Salton and Michael J. McGill. 1986. Introduction to Modern Information Retrieval. McGrawHill, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In Proceedings of the HLT Conference of the North American Chapter of the ACL,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="8465" citStr="Shinyama and Sekine, 2006" startWordPosition="1316" endWordPosition="1319">terations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstrapping, we not only use labeled target domain data as seeds, but also leverage on existing source-domain predictors to obtain a robust relation extractor for the target domain. Open Information Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patt</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of the HLT Conference of the North American Chapter of the ACL, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex J Smola</author>
<author>Bernhard Scholkopf</author>
</authors>
<title>Learning with kernels.</title>
<date>1998</date>
<publisher>Citeseer.</publisher>
<contexts>
<context position="22611" citStr="Smola and Scholkopf, 1998" startWordPosition="3751" endWordPosition="3754">i labeled sample belonging to relation j. Here, we have multiple objectives: the first term controls the training error; the second regularizes the complexity of the functions fjs in the Reproducing Kernel Hilbert Space (RKHS) H; and the third prefers the predicted labels of the unlabeled data Dl to be close to the reference predictions. The third term provides additional pseudo-training samples for the rarer relation classes, if these are available in Du. Parameters β and γ govern the trade-offs between these objectives. Let K(·,·) be the reproducing kernel for H. By the Representer Theorem (Smola and Scholkopf, 1998), the solution for Eq. 3 is linear in K(xi,·): fj(x) = ∑ni=1 αjiK(xi,x). Putting this into Eq. 3, parameter vectors αj are (Belkin et al., 2006): α*j = (JK +γ(nl +βnu)I)−1JRj. (4) Here, Rj is an (nl + nu)-vector, where Rji = rji if sample i belongs to the labeled set, and Rji = ˆri j if it belongs to the unlabeled set; and J is an (nl + nu)-by-(nl +nu) diagonal matrix where the first nl diagonal entries are ones and the rest are βs. 5 Experiments We evaluate our algorithm on two corpora: Automatic Content Extraction (ACE) 2004 and YAGO3. Table 1 provides some statistics on them. ACE 2004 consi</context>
</contexts>
<marker>Smola, Scholkopf, 1998</marker>
<rawString>Alex J Smola and Bernhard Scholkopf. 1998. Learning with kernels. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge unifying wordnet and wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<publisher>ACM.</publisher>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge unifying wordnet and wikipedia. In Proceedings of the 16th international conference on World Wide Web, pages 697–706. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shingo Takamatsu</author>
<author>Issei Sato</author>
<author>Hiroshi Nakagawa</author>
</authors>
<title>Reducing wrong labels in distant supervision for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>721--729</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8868" citStr="Takamatsu et al., 2012" startWordPosition="1378" endWordPosition="1381">Extraction (Open IE) (Etzioni et al., 2008; Banko et al., 2008; Mesquita et al., 2013) is a domain-independent information extraction paradigm to extract relation tuples from collected corpus (Shinyama and Sekine, 2006) and Web (Etzioni et al., 2008; Banko et al., 2008). Open IE systems are initialized with a few domain-independent extraction patterns. To create labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce 808 labeling effort for relation extraction, distant supervision (Mintz et al., 2009; Takamatsu et al., 2012; Min et al., 2013; Xu et al., 2013) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled corpora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled relation instances in source and target domains and unlabeled instances in the target domain. Our work is also different from the multischema matching in database integration (Doan et al., 2003). Multi-schema matching finds relations between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not addre</context>
</contexts>
<marker>Takamatsu, Sato, Nakagawa, 2012</marker>
<rawString>Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2012. Reducing wrong labels in distant supervision for relation extraction. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 721–729. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feiyu Xu</author>
<author>Hans Uszkoreit</author>
<author>Sebastian Krause</author>
<author>Hong Li</author>
</authors>
<title>Boosting relation extraction with limited closed-world knowledge.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd Conference on Computational Linguistics,</booktitle>
<pages>1354--1362</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7453" citStr="Xu et al., 2010" startWordPosition="1154" endWordPosition="1157">have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Kozareva and Hovy, 2010). Different from bootstra</context>
<context position="27777" citStr="Xu et al., 2010" startWordPosition="4622" endWordPosition="4625">assifier (NT-U) We use the union of the k source-domain labeled data sets Dss and the small set of target-domain labeled data Dl to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data Du without any adaptation. Laplacian SVM (L-SVM) This is a semisupervised learning method based on label propagation (Melacci and Belkin, 2011). Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extraction (Jiang, 2009). Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction (Xu et al., 2010). Structural correspondence learning (SCL) We use the feature-based domain adaptation approach by Blitzer et al. (2007). We apply SCL on the Dss and Dl to train a model. The learned model then makes predictions on Du. Domain Adaptation Machine (DAM) We use the framework of Duan et al. (2009), which is a multiple-sources domain adaptation method. For the kernel-based methods above, we use the same composite kernel used in our method. The source codes of L-SVM, MTL, SCL and DAM were obtained from the authors. The others were re-implemented. 5.3 Experimental Results Tables 2, 3 and 4 present the </context>
</contexts>
<marker>Xu, Uszkoreit, Krause, Li, 2010</marker>
<rawString>Feiyu Xu, Hans Uszkoreit, Sebastian Krause, and Hong Li. 2010. Boosting relation extraction with limited closed-world knowledge. In Proceedings of the 23rd Conference on Computational Linguistics, pages 1354–1362. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Xu</author>
<author>Raphael Hoffmann Le Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Filling knowledge base gaps for distant supervision of relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP-13,</booktitle>
<pages>665--670</pages>
<marker>Xu, Le Zhao, Grishman, 2013</marker>
<rawString>Wei Xu, Raphael Hoffmann Le Zhao, and Ralph Grishman. 2013. Filling knowledge base gaps for distant supervision of relation extraction. In Proceedings of EMNLP-13, pages 665–670.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>825--832</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="24897" citStr="Zhang et al., 2006" startWordPosition="4135" endWordPosition="4138">overlapping of topics, entity types and relation types between domains; and it has more relation mentions with 11 mentions per pair of entities on the average. We used Collins parser (Collins, 1999) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, using the head of each constituent (Jiang and Zhai, 2007b). The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence. For the similarity matrix W in section 4.1 and the kernel K(·,·) in section 4.2, we used the composite kernel function (Zhang et al., 2006), which is based on structured features and entity-related features. F1 is used to measure the performance of the algorithms. This is the harmonic mean of precision TP/(TP + FP) and recall TP/(TP + FN), where TP, FP and FN are the numbers of correct, missing and wrongly recognized relations. 5.1 Experimental Settings For ACE 2004, we used each of the six domains as the target domain and the remaining domains as source domains. For YAGO, each relation type in YAGO was considered as a domain. For each domain in YAGO, we have a binary classification task: whether the instance has the relation cor</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 825–832. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dengyong Zhou</author>
<author>Olivier Bousquet</author>
<author>Thomas Navin Lal</author>
<author>Jason Weston</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>Learning with local and global consistency.</title>
<date>2003</date>
<booktitle>In NIPS.</booktitle>
<marker>Zhou, Bousquet, Lal, Weston, Sch¨olkopf, 2003</marker>
<rawString>Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, and Bernhard Sch¨olkopf. 2003. Learning with local and global consistency. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Zaiqing Nie</author>
<author>Xiaojiang Liu</author>
<author>Bo Zhang</author>
<author>Ji-Rong Wen</author>
</authors>
<title>Statsnowball: a statistical approach to extracting entity relationships.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th international conference on Worldwide web,</booktitle>
<pages>101--110</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7407" citStr="Zhu et al., 2009" startWordPosition="1146" endWordPosition="1149"> determine if two given entities in a sentence have a given relation. Kernel-based supervised methods such as dependency tree kernels (Culotta and Sorensen, 2004), subsequence kernels (Bunescu and Mooney, 2006) and convolution tree kernels (Qian et al., 2008) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting. Bootstrapping methods (Zhu et al., 2009; Agichtein and Gravano, 2000; Xu et al., 2010; Pasca et al., 2006; Riloff and Jones, 1999) to relation extraction are attractive because they require fewer training instances than supervised approaches. Bootstrapping methods are either initialized with a few instances (often designated as seeds) of the target relation (Zhu et al., 2009; Agichtein and Gravano, 2000) or a few extraction patterns (Xu et al., 2010). In subsequent iterations, new extraction patterns are discovered, and these are used to extract new instances. The quality of the extracted relations depends heavily on the seeds (Koz</context>
</contexts>
<marker>Zhu, Nie, Liu, Zhang, Wen, 2009</marker>
<rawString>Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and Ji-Rong Wen. 2009. Statsnowball: a statistical approach to extracting entity relationships. In Proceedings of the 18th international conference on Worldwide web, pages 101–110. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>