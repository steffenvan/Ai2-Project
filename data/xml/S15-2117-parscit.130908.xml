<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003108">
<title confidence="0.997882">
ValenTo: Sentiment Analysis of Figurative Language Tweets
with Irony and Sarcasm∗
</title>
<author confidence="0.805077">
Delia Iraz´u Hern´andez Farias
</author>
<affiliation confidence="0.5405105">
Universitat Polit`ecnica de Val`encia
Pattern Recognition and Human Language Technology
</affiliation>
<email confidence="0.709897">
dhernandez1@dsic.upv.es
</email>
<author confidence="0.999227">
Emilio Sulis, Viviana Patti, Giancarlo Ruffo, Cristina Bosco
</author>
<affiliation confidence="0.879705">
University of Turin
Dipartimento di Informatica
</affiliation>
<email confidence="0.998025">
{sulis,patti,ruffo,bosco}@di.unito.it
</email>
<sectionHeader confidence="0.998592" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999796578947369">
This paper describes the system used by the
ValenTo team in the Task 11, Sentiment Anal-
ysis of Figurative Language in Twitter, at Se-
mEval 2015. Our system used a regression
model and additional external resources to as-
sign polarity values. A distinctive feature of
our approach is that we used not only word-
sentiment lexicons providing polarity anno-
tations, but also novel resources for dealing
with emotions and psycholinguistic informa-
tion. These are important aspects to tackle
in figurative language such as irony and sar-
casm, which were represented in the dataset.
The system also exploited novel and stan-
dard structural features of tweets. Considering
the different kinds of figurative language in
the dataset our submission obtained good re-
sults in recognizing sentiment polarity in both
ironic and sarcastic tweets.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99912552173913">
Figurative language, which is extensively exploited
in social media texts, is very challenging for both
traditional NLP techniques and sentiment analysis,
which has been defined as “the computational study
of opinions, sentiments and emotions expressed in
text” (Liu, 2010). There is a considerable amount
of works related to sentiment analysis and opinion
mining (Pang and Lee, 2008; Liu, 2010; Cambria
et al., 2013). In particular, the linguistic analysis
∗ The National Council for Science and Technology
(CONACyT-Mexico) has funded the research work of the first
author (218109/313683 grant).
of social media (microblogging like Twitter espe-
cially) has become a relevant topic of research in
different languages (Rosenthal et al., 2014; Basile
et al., 2014) and several frameworks for detecting
sentiments and opinions in social media have been
developed for different application purposes.
In a sentiment analysis setting, the presence in a
text of figurative language devices, such as for in-
stance irony, can work as an unexpected polarity re-
verser, by undermining the accuracy of the systems
(Bosco et al., 2013). Therefore, several efforts have
been recently devoted to detect and tackle figura-
tive language phenomena in social media, follow-
ing a variety of computational approaches, mostly
focussing on irony detection and sarcasm recogni-
tion (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al.,
2011; Riloff et al., 2013) as classification tasks.
Buschmeier et al. present an analysis of fea-
tures, previously applied in irony detection, in a
dataset from a product reviews corpus from Amazon
(Buschmeier et al., 2014). Veale and Hao present
a linguistic approach to separate ironic from non-
ironic expressions in figurative comparisons over a
corpus of web-harvested similes (Veale and Hao,
2010). Concerning Twitter, the problem of irony de-
tection is addressed in (Reyes et al., 2013), where
a set of textual features is used to recognize irony
at a linguistic level. In (Riloff et al., 2013) the fo-
cus is on identifying sarcastic tweets that express a
positive sentiment towards a negative situation. A
model to classify sarcastic tweets using a set of lex-
ical features is presented in (Barbieri et al., 2014).
Moreover, a recent analysis on the interplay between
sarcasm detection and sentiment analysis is in (May-
</bodyText>
<page confidence="0.983245">
694
</page>
<bodyText confidence="0.933872222222222">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 694–698,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
nard and Greenwood, 2014), where a set of rules has
been proposed to improve the performance of the
sentiment analysis in presence of sarcastic tweets.
In this paper we describe our participation to the
SemEval-2015 Task 11: Sentiment Analysis of Figu-
rative Language in Twitter (Ghosh et al., 2015). The
task concerned with classification of tweets contain-
ing different kinds of figurative language, in partic-
ular irony, sarcasm and metaphors. ValenTo system
used a linear regression model, exploiting novel and
standard structural and lexical features of tweets.
Considering the different kinds of figurative lan-
guage in the Semeval dataset - sarcasm, irony and
metaphors - our submission had good results in rec-
ognizing sentiment polarity in both ironic and sar-
castic tweets, than in the other cases.
</bodyText>
<sectionHeader confidence="0.970249" genericHeader="method">
2 Our System
</sectionHeader>
<bodyText confidence="0.999926666666667">
We propose a supervised approach that consists in
assigning a polarity value to tweets by using a lin-
ear regression model constructed from an annotated
dataset. In order to catch characteristics that allow
us to measure the polarity value in each tweet, we
considered a set of features described below.
</bodyText>
<subsectionHeader confidence="0.9912875">
2.1 Feature Description
2.1.1 Structural Features
</subsectionHeader>
<bodyText confidence="0.994382304347826">
Among the several structural characteristics of
tweets, in our study we consider: the length of
tweets in amount of words (lengthWords); the length
of a tweet as the number of characters that composes
the textual message (lengthChar); the frequency of
commas, semicolons, colons, exclamation and ques-
tion marks (punctuation marks); the frequency of
some Part of Speech categories as nouns, adverbs,
verbs and adjectives (POS); the frequency of upper-
case letters in each tweet upperFreq; the frequency
or presence of URL urlFreq; and the amount of
emoticons used in order to express some kind of
emotion, we consider both positive (emotPosFreq)
and negative ones (emotNegFreq).
We also consider some features that belongs to
tweets, like: the presence or absence of hashtags
(hashtagBinary) and mentions (mentionsBinary);
the amount of hashtags (hashtagFreq) and mentions
(mentionsFreq) in each tweet; and if the tweet is a
retweet (isRetweet). Finally, we decide to take into
account a feature (polReversal) in order to reverse
the polarity (positive to negative, and vice versa) if a
tweet includes the hashtag #sarcasm or #not.
</bodyText>
<subsectionHeader confidence="0.706677">
2.1.2 Lexical Resources
</subsectionHeader>
<bodyText confidence="0.998680470588235">
In order to take into account sentiments, emotions
and psycholinguistic features, and to count their fre-
quency, we use the following lexical resources:
AFINN: it is a dictionary of 2,477 English man-
ually labeled words collected by Nielsen (Nielsen,
2011). Polarity values varies from −5 up to +5 1.
ANEW: the Affective Norms for English Words
provides a set of emotional ratings for a large num-
ber of English words (Bradley and Lang, 1999).
Each word in is rated from 1 to 9 in terms of the three
dimensions of Valence, Arousal and Dominance.
DAL: the Dictionary of Affective Language devel-
oped by Whissell (Whissell, 2009) contains 8,742
English words rated in a three-point scale2. Each
word is rated into the dimensions of Pleasantness,
Activation and Imagery.
HL: Hu–Liu’s lexicon (Hu and Liu, 2004) in-
cludes about 6, 800 positive and negative words3.
GI: General Inquirer (Stone and Hunt, 1963) con-
tains categories and subcategories for content analy-
sis with dictionaries based on the Lasswell and Har-
vard IV-4 4.
SWN: SentiWordNet (Baccianella et al., 2010) is
a lexical resource for opinion mining and consists in
three sentiment scores: positive, negative and objec-
tive5. We take into account the first two categories.
SN: SenticNet is a semantic resource for concept-
level sentiment analysis (Cambria et al., 2012).
We take into account the values of each one of the
five dimensions (senticnetDimensions) provided by
the lexical resource: Pleasantness (Pl), Attention
(At), Sensitivity (Sn) and Aptitude (Ap) and Polar-
ity (Pol); and also the polarity value p obtained by
using the formula (senticnetFormula) below based
</bodyText>
<footnote confidence="0.978020666666667">
1https://github.com/abromberg/sentiment_
analysis/blob/master/AFINN/AFINN-111.txt
2ftp://perceptmx.com/wdalman.pdf
3http://www.cs.uic.edu/˜liub/FBS/
4http://www.wjh.harvard.edu/˜inquirer/
homecat.htm.We are mostly interested in the positive and
negative words.
5http://sentiwordnet.isti.cnr.it/
download.php
</footnote>
<page confidence="0.990118">
695
</page>
<bodyText confidence="0.422605">
on a combination of the first four dimensions:
</bodyText>
<equation confidence="0.9581495">
Pl(ci) + |At(ci) |− |Sn(ci) |+ Ap(ci)
3N
</equation>
<bodyText confidence="0.996940666666667">
where ci is an input concept, N the total number of
concepts which compose the tweet, and 3 a normal-
isation factor.
LIWC: Linguistic Inquiry and Word Counts dic-
tionary6 contains 127,149 words distributed in cate-
gories that can further be used to analyze psycho-
linguistic features in texts. We select two cate-
gories for positive and negative emotions: PosEmo
(12,878) entries and NegEmo (15,115 entries).
NRC: in the NRC word-emotion association lexi-
con (Mohammad and Turney, 2013) each word is la-
beled according to the Plutchik’s primary emotions.
</bodyText>
<sectionHeader confidence="0.999995" genericHeader="evaluation">
3 Results
</sectionHeader>
<subsectionHeader confidence="0.999827">
3.1 Task Description and Dataset
</subsectionHeader>
<bodyText confidence="0.9994395">
The goal of the Task 11 at SemEval 2015, is the fol-
lowing: given a set of tweets rich w.r.t. the pres-
ence of such figurative devices, to determine for each
message whether the user expressed positive, neg-
ative or neutral sentiment, and the sentiment de-
gree. To have a measure of the sentiment intensity
expressed in the message, it was proposed a fine-
grained 11-point sentiment polarity scale.
</bodyText>
<figureCaption confidence="0.9952255">
Figure 1: Frequency distribution of tweets by polarity in-
tensity.
</figureCaption>
<bodyText confidence="0.996885333333333">
Two measures evaluated the similarity of the par-
ticipant systems predictions to the manually anno-
tated gold standard: Cosine Similarity (CS) and
</bodyText>
<footnote confidence="0.883282">
6http://www.liwc.net
</footnote>
<tableCaption confidence="0.951996">
Table 1: Criteria for assigning classes.
</tableCaption>
<table confidence="0.999654333333333">
3c-approach 4c-approach
Original New Original New
pv&gt;0 pos pv &gt; 0 pos
pv&lt;0 neg -2.5 &gt; pv &lt;= 0 nsn
pv=0 neu -3.5 &gt; pv &lt;= -2.5 neg
pv &lt;= -3.5 vn
</table>
<bodyText confidence="0.987206">
Mean Squared Error (MSE). The corpus available
for training and trial consists of around 9, 000 figu-
rative tweets with sentiment scores ranging from −5
to +5. Because of the perishability of Twitter data,
some of them cannot be recovered by the published
list of tweet identifiers; finally, we could rely on a
corpus of 7,390 messages considering both training
and trial datasets. With respect to the polarity, the
whole distribution is positively skewed (Fig. 1). The
median value is very negative (−2.3) and the aver-
age of the tweets polarity is −2.
</bodyText>
<subsectionHeader confidence="0.99937">
3.2 ValenTo System
</subsectionHeader>
<bodyText confidence="0.99981047826087">
As a first step, we decided to address the problem
as a classification task. We experimented three ap-
proaches, each featured by a different amount of
considered classes; in the first one (3c-approach)
we used just three classes: positive (pos), nega-
tive (neg) and neutral (neu); in the second one (4c-
approach) we used four classes: positive, nega-
tive, not so negative (nsn) and very negative (vn);
and in the third one (11c-approach) we used the
original values included in the corpus, i.e. eleven
classes from −5 to +5. For the first two approaches
we changed the polarity values (pv) in each one of
the tweets contained in the dataset according to the
criteria summarized in Table 1. Based on polarity
value distribution shown in Fig. 1, we separated the
classes in different ranges that cover all the possi-
ble values. A small set of widely classification al-
gorithms was used: Naive Bayes (NB), Decision
Tree (DT) and Support Vector Machine (SVM)7. We
performed classification experiments using only the
training set (i.e. 6,928 tweets); a ten fold-cross-
validation criterium was applied. Table 2 presents
results obtained in F-measure terms.
</bodyText>
<footnote confidence="0.950208666666667">
7We used Weka toolkit’s version available at
http://www.cs.waikato.ac.nz/ml/weka/
downloading.html
</footnote>
<equation confidence="0.987872">
n
p=
i=1
</equation>
<page confidence="0.998706">
696
</page>
<tableCaption confidence="0.998934">
Table 2: Classification experiments: results.
</tableCaption>
<table confidence="0.998309">
Approach NB DT SVM
3c-approach 0.829 0.804 0.790
4c-approach 0.458 0.440 0.462
11c-approach 0.324 0.311 0.302
</table>
<bodyText confidence="0.993388771428571">
As expected, from our classification results, the
performance in terms of F-Measure drops while the
number of classes increase. We decided to apply a
different approach: Regression.
In order to build a regression model able to as-
sign polarity values, we decided to merge both train-
ing and trial datasets (fullTrainingSet composed by
7,390 tweets). We used the Linear Regression Algo-
rithm in Weka.
First, from the whole fullTrainingSet corpus we ran-
domly extracted a set for training, containing the
70% of the tweets, and a set for the test, with the re-
maining 30%, obtaining Subset-1. We repeated the
procedure two times more and we obtained Subset-2
and Subset-3.Second, we made up 11 different com-
binations of features ft-conf[1-11]. Each one con-
tains a subset of the features described in Sec. 2.1.
We built the features combination according to a
preliminary analysis with respect to frequency dis-
tribution. Then, we applied our regression model
for each Subset and ft-conf. In order to evaluate the
performance of our model, we used the script to ob-
tain the cosine similarity measure provided by the
organizers. Table 3 shows the results of these exper-
iments for what concerns ft-conf2 configuration, the
one we selected for constructing the final model sub-
mitted to SemEval-Task 11 (due to lack of space, not
have been included all results obtained). ft-conf2
contains the following features:
lengthChar, punctuation marks, POS, upperFreq,
urlFreq, emotPosFreq, emotNegFreq,
hashtagBinary, mentionsBinary, hashtagFreq,
mentionsFreq, isRetweet, polReversal, AFINN,
ANEW, DAL, HL,GI, SWN, senticnetDimensions,
senticnetFormula, LIWC, NRC
</bodyText>
<tableCaption confidence="0.999242">
Table 3: Regression experiments: results.
</tableCaption>
<subsectionHeader confidence="0.758223">
Features Subset-1 Subset-2 Subset-3
</subsectionHeader>
<bodyText confidence="0.994145">
ft-conf2 0.8218 0.8161 0.8199
In order to measure the relevance of each fea-
ture used in our model, we applied the RELIEF al-
gorithm8. The best ranked features are those re-
lated to emotional words (NRC) and polarity lexi-
cons (AFINN and HL).
</bodyText>
<subsectionHeader confidence="0.999587">
3.3 Official Results
</subsectionHeader>
<bodyText confidence="0.94454">
We ranked 6th out of 15 teams in the SemEval-2015
Task 11 (Ghosh et al., 2015)9. ValenTo achieved the
score of 0.634 using the CS measure, and a score of
2.999 using the MSE measure, while the best team
achieved the score of 0.758 for CS, and a score of
2.117 for MSE.
Our results in terms of irony and sarcasm seem to
be close to the best ones in each category (See Table
4).
</bodyText>
<tableCaption confidence="0.9544355">
Table 4: Official ValenTo and best results in each cate-
gory of figurative type.
</tableCaption>
<table confidence="0.999289">
Category CS Best MSE Best
ValenTo ValenTo
Overall 0.634 0.758 2.999 2.117
Sarcasm 0.895 0.904 1.004 0.934
Irony 0.901 0.918 0.777 0.671
Metaphor 0.393 0.655 4.730 3.155
Other 0.202 0.612 5.315 3.411
</table>
<sectionHeader confidence="0.997518" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999918076923077">
We described our participation at SemEval-2015
Task 11. A distinctive feature of our approach is
that we used not only word-sentiment lexicons but
also novel resources for dealing with emotions and
psycholinguistic information. Based on both fea-
tures analysis and evaluation results, we can draw
a first insight about the importance of using such
high-level information about affective value of the
words in a tweet to tackle with figurative language
such irony and sarcasm. As future work, the use
of additional features for addressing figurative lan-
guage under other perspectives (e.g. metaphor) will
be explored.
</bodyText>
<footnote confidence="0.882300666666667">
8ReliefFAttributeEval version included in Weka (Robnik-
Sikonja and Kononenko, 1997).
9http://alt.qcri.org/
semeval2015/task11/index.php?id=
task-results-and-initial-analysis-1,
Table1.
</footnote>
<page confidence="0.995301">
697
</page>
<sectionHeader confidence="0.993152" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998424126213591">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining. In
Proceedings of the Seventh International Conference
on Language Resources and Evaluation (LREC’10).
Francesco Barbieri, Horacio Saggion, and Francesco
Ronzano, 2014. Proceedings of the 5th Workshop on
Computational Approaches to Subjectivity, Sentiment
and Social Media Analysis, chapter Modelling Sar-
casm in Twitter, a Novel Approach, pages 50–58.
Valerio Basile, Andrea Bolioli, Malvina Nissim, Viviana
Patti, and Paolo Rosso. 2014. Overview of the Evalita
2014 SENTIment POLarity Classification Task. In
Proceedings of the 4th evaluation campaign of Nat-
ural Language Processing and Speech tools for Italian
(EVALITA’14), pages 50–57.
Cristina Bosco, Viviana Patti, and Andrea Bolioli. 2013.
Developing corpora for sentiment analysis: The case
of irony and senti-tut. IEEE Intelligent Systems,
28(2):55–63.
Margaret Bradley and Peter Lang. 1999. Affective norms
for english words (ANEW): Instruction manual and af-
fective ratings. Technical report, Citeseer.
Konstantin Buschmeier, Philipp Cimiano, and Roman
Klinger. 2014. An impact analysis of features in a
classification approach to irony detection in product
reviews. In Proceedings of the 5th Workshop on Com-
putational Approaches to Subjectivity, Sentiment and
Social Media Analysis, pages 42–49.
Erik Cambria, Catherine Havasi, and Amir Hussain.
2012. Senticnet 2: A semantic and affective resource
for opinion mining and sentiment analysis. In AAAI
FLAIRS Conference, pages 202–207.
Erick Cambria, B. Schuller, Yunqing Xia, and C. Havasi.
2013. New avenues in opinion mining and senti-
ment analysis. Intelligent Systems, IEEE, 28(2):15–
21, March.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Semi-supervised recognition of sarcastic sentences in
twitter and amazon. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning, CoNLL ’10, pages 107–116.
A. Ghosh, G. Li, T. Veale, P. Rosso, E. Shutova,
A. Reyes, and J. Barnden. 2015. Semeval-2015 task
11: Sentiment analysis of figurative language in twit-
ter. In Proc. Int. Workshop on Semantic Evaluation
(SemEval-2015), Co-located with NAACL and *SEM.
Roberto Gonz´alez-Ib´a˜nez, Smaranda Muresan, and Nina
Wacholder. 2011. Identifying sarcasm in twitter: A
closer look. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies: Short Papers - Vol-
ume 2, HLT ’11, pages 581–586.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, KDD ’04, pages
168–177.
Bing Liu. 2010. Sentiment analysis and subjectivity. In
Handbook of Natural Language Processing.
Diana Maynard and Mark Greenwood. 2014. Who
cares about sarcastic tweets? investigating the impact
of sarcasm on sentiment analysis. In Proceedings of
the Ninth International Conference on Language Re-
sources and Evaluation (LREC-2014).
Saif M. Mohammad and Peter D. Turney. 2013. Crowd-
sourcing a word–emotion association lexicon. Com-
putational Intelligence, 29(3):436–465.
Finn ˚Arup Nielsen. 2011. A new ANEW: evaluation of
a word list for sentiment analysis in microblogs.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(12):1–135.
Antonio Reyes, Paolo Rosso, and Tony Veale. 2013. A
multidimensional approach for detecting irony in twit-
ter. Language Resources and Evaluation, 47(1):239–
268.
Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra
De Silva, Nathan Gilbert, and Ruihong Huang. 2013.
Sarcasm as contrast between a positive sentiment and
negative situation. In Proceedings of the EMNLP:
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 704–714.
Marko Robnik-Sikonja and Igor Kononenko. 1997. An
adaptation of relief for attribute estimation in regres-
sion. In Fourteenth International Conference on Ma-
chine Learning, pages 296–304.
Sara Rosenthal, Alan Ritter, Preslav Nakov, and Veselin
Stoyanov. 2014. Semeval-2014 task 9: Sentiment
analysis in twitter. In Proceedings of the 8th Inter-
national Workshop on Semantic Evaluation (SemEval
2014), pages 73–80, August.
Philip J. Stone and Earl B. Hunt. 1963. A computer
approach to content analysis: Studies using the gen-
eral inquirer system. In Proceedings of the May 21-23,
1963, AFIPS ’63 (Spring), pages 241–256.
Tony Veale and Yanfen Hao. 2010. Detecting ironic in-
tent in creative comparisons. In ECAI, volume 215,
pages 765–770.
Cynthia Whissell. 2009. Using the revised dictionary
of affect in language to quantify the emotional under-
tones of samples of natural languages. In Psychologi-
cal Reports.
</reference>
<page confidence="0.99728">
698
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.449893">
<title confidence="0.955633">ValenTo: Sentiment Analysis of Figurative Language Tweets Irony and</title>
<author confidence="0.835888">Delia Iraz´u Hern´andez</author>
<affiliation confidence="0.816803">Universitat Polit`ecnica de</affiliation>
<title confidence="0.7427455">Pattern Recognition and Human Language dhernandez1@dsic.upv.es</title>
<author confidence="0.998851">Emilio Sulis</author>
<author confidence="0.998851">Viviana Patti</author>
<author confidence="0.998851">Giancarlo Ruffo</author>
<author confidence="0.998851">Cristina</author>
<affiliation confidence="0.961417">University of Dipartimento di</affiliation>
<abstract confidence="0.99924355">This paper describes the system used by the ValenTo team in the Task 11, Sentiment Analysis of Figurative Language in Twitter, at SemEval 2015. Our system used a regression model and additional external resources to assign polarity values. A distinctive feature of our approach is that we used not only wordsentiment lexicons providing polarity annotations, but also novel resources for dealing with emotions and psycholinguistic information. These are important aspects to tackle in figurative language such as irony and sarcasm, which were represented in the dataset. The system also exploited novel and standard structural features of tweets. Considering the different kinds of figurative language in the dataset our submission obtained good results in recognizing sentiment polarity in both ironic and sarcastic tweets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10).</booktitle>
<contexts>
<context position="7116" citStr="Baccianella et al., 2010" startWordPosition="1098" endWordPosition="1101">). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (Baccianella et al., 2010) is a lexical resource for opinion mining and consists in three sentiment scores: positive, negative and objective5. We take into account the first two categories. SN: SenticNet is a semantic resource for conceptlevel sentiment analysis (Cambria et al., 2012). We take into account the values of each one of the five dimensions (senticnetDimensions) provided by the lexical resource: Pleasantness (Pl), Attention (At), Sensitivity (Sn) and Aptitude (Ap) and Polarity (Pol); and also the polarity value p obtained by using the formula (senticnetFormula) below based 1https://github.com/abromberg/senti</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesco Barbieri</author>
<author>Horacio Saggion</author>
<author>Francesco Ronzano</author>
</authors>
<date>2014</date>
<booktitle>Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, chapter Modelling Sarcasm in Twitter, a Novel Approach,</booktitle>
<pages>50--58</pages>
<contexts>
<context position="3437" citStr="Barbieri et al., 2014" startWordPosition="518" endWordPosition="521">zon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in figurative comparisons over a corpus of web-harvested similes (Veale and Hao, 2010). Concerning Twitter, the problem of irony detection is addressed in (Reyes et al., 2013), where a set of textual features is used to recognize irony at a linguistic level. In (Riloff et al., 2013) the focus is on identifying sarcastic tweets that express a positive sentiment towards a negative situation. A model to classify sarcastic tweets using a set of lexical features is presented in (Barbieri et al., 2014). Moreover, a recent analysis on the interplay between sarcasm detection and sentiment analysis is in (May694 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 694–698, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics nard and Greenwood, 2014), where a set of rules has been proposed to improve the performance of the sentiment analysis in presence of sarcastic tweets. In this paper we describe our participation to the SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter (Ghosh et al., 2015). The tas</context>
</contexts>
<marker>Barbieri, Saggion, Ronzano, 2014</marker>
<rawString>Francesco Barbieri, Horacio Saggion, and Francesco Ronzano, 2014. Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, chapter Modelling Sarcasm in Twitter, a Novel Approach, pages 50–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valerio Basile</author>
<author>Andrea Bolioli</author>
<author>Malvina Nissim</author>
<author>Viviana Patti</author>
<author>Paolo Rosso</author>
</authors>
<title>Overview of the Evalita</title>
<date>2014</date>
<booktitle>In Proceedings of the 4th evaluation campaign of Natural Language Processing and Speech tools for Italian (EVALITA’14),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="1981" citStr="Basile et al., 2014" startWordPosition="285" endWordPosition="288">ent analysis, which has been defined as “the computational study of opinions, sentiments and emotions expressed in text” (Liu, 2010). There is a considerable amount of works related to sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2010; Cambria et al., 2013). In particular, the linguistic analysis ∗ The National Council for Science and Technology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, such as for instance irony, can work as an unexpected polarity reverser, by undermining the accuracy of the systems (Bosco et al., 2013). Therefore, several efforts have been recently devoted to detect and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov </context>
</contexts>
<marker>Basile, Bolioli, Nissim, Patti, Rosso, 2014</marker>
<rawString>Valerio Basile, Andrea Bolioli, Malvina Nissim, Viviana Patti, and Paolo Rosso. 2014. Overview of the Evalita 2014 SENTIment POLarity Classification Task. In Proceedings of the 4th evaluation campaign of Natural Language Processing and Speech tools for Italian (EVALITA’14), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Bosco</author>
<author>Viviana Patti</author>
<author>Andrea Bolioli</author>
</authors>
<title>Developing corpora for sentiment analysis: The case of irony and senti-tut.</title>
<date>2013</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="2339" citStr="Bosco et al., 2013" startWordPosition="342" endWordPosition="345">hnology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, such as for instance irony, can work as an unexpected polarity reverser, by undermining the accuracy of the systems (Bosco et al., 2013). Therefore, several efforts have been recently devoted to detect and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Riloff et al., 2013) as classification tasks. Buschmeier et al. present an analysis of features, previously applied in irony detection, in a dataset from a product reviews corpus from Amazon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in </context>
</contexts>
<marker>Bosco, Patti, Bolioli, 2013</marker>
<rawString>Cristina Bosco, Viviana Patti, and Andrea Bolioli. 2013. Developing corpora for sentiment analysis: The case of irony and senti-tut. IEEE Intelligent Systems, 28(2):55–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Bradley</author>
<author>Peter Lang</author>
</authors>
<title>Affective norms for english words (ANEW): Instruction manual and affective ratings.</title>
<date>1999</date>
<tech>Technical report, Citeseer.</tech>
<contexts>
<context position="6492" citStr="Bradley and Lang, 1999" startWordPosition="996" endWordPosition="999"> into account a feature (polReversal) in order to reverse the polarity (positive to negative, and vice versa) if a tweet includes the hashtag #sarcasm or #not. 2.1.2 Lexical Resources In order to take into account sentiments, emotions and psycholinguistic features, and to count their frequency, we use the following lexical resources: AFINN: it is a dictionary of 2,477 English manually labeled words collected by Nielsen (Nielsen, 2011). Polarity values varies from −5 up to +5 1. ANEW: the Affective Norms for English Words provides a set of emotional ratings for a large number of English words (Bradley and Lang, 1999). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (B</context>
</contexts>
<marker>Bradley, Lang, 1999</marker>
<rawString>Margaret Bradley and Peter Lang. 1999. Affective norms for english words (ANEW): Instruction manual and affective ratings. Technical report, Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Konstantin Buschmeier</author>
<author>Philipp Cimiano</author>
<author>Roman Klinger</author>
</authors>
<title>An impact analysis of features in a classification approach to irony detection in product reviews.</title>
<date>2014</date>
<booktitle>In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,</booktitle>
<pages>42--49</pages>
<contexts>
<context position="2844" citStr="Buschmeier et al., 2014" startWordPosition="419" endWordPosition="422">nce irony, can work as an unexpected polarity reverser, by undermining the accuracy of the systems (Bosco et al., 2013). Therefore, several efforts have been recently devoted to detect and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Riloff et al., 2013) as classification tasks. Buschmeier et al. present an analysis of features, previously applied in irony detection, in a dataset from a product reviews corpus from Amazon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in figurative comparisons over a corpus of web-harvested similes (Veale and Hao, 2010). Concerning Twitter, the problem of irony detection is addressed in (Reyes et al., 2013), where a set of textual features is used to recognize irony at a linguistic level. In (Riloff et al., 2013) the focus is on identifying sarcastic tweets that express a positive sentiment towards a negative situation. A model to classify sarcastic tweets using a set of lexical features is presented in (Barbieri et al., 2014). Moreo</context>
</contexts>
<marker>Buschmeier, Cimiano, Klinger, 2014</marker>
<rawString>Konstantin Buschmeier, Philipp Cimiano, and Roman Klinger. 2014. An impact analysis of features in a classification approach to irony detection in product reviews. In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 42–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Catherine Havasi</author>
<author>Amir Hussain</author>
</authors>
<title>Senticnet 2: A semantic and affective resource for opinion mining and sentiment analysis.</title>
<date>2012</date>
<booktitle>In AAAI FLAIRS Conference,</booktitle>
<pages>202--207</pages>
<contexts>
<context position="7375" citStr="Cambria et al., 2012" startWordPosition="1139" endWordPosition="1142">d into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (Baccianella et al., 2010) is a lexical resource for opinion mining and consists in three sentiment scores: positive, negative and objective5. We take into account the first two categories. SN: SenticNet is a semantic resource for conceptlevel sentiment analysis (Cambria et al., 2012). We take into account the values of each one of the five dimensions (senticnetDimensions) provided by the lexical resource: Pleasantness (Pl), Attention (At), Sensitivity (Sn) and Aptitude (Ap) and Polarity (Pol); and also the polarity value p obtained by using the formula (senticnetFormula) below based 1https://github.com/abromberg/sentiment_ analysis/blob/master/AFINN/AFINN-111.txt 2ftp://perceptmx.com/wdalman.pdf 3http://www.cs.uic.edu/˜liub/FBS/ 4http://www.wjh.harvard.edu/˜inquirer/ homecat.htm.We are mostly interested in the positive and negative words. 5http://sentiwordnet.isti.cnr.it/</context>
</contexts>
<marker>Cambria, Havasi, Hussain, 2012</marker>
<rawString>Erik Cambria, Catherine Havasi, and Amir Hussain. 2012. Senticnet 2: A semantic and affective resource for opinion mining and sentiment analysis. In AAAI FLAIRS Conference, pages 202–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erick Cambria</author>
<author>B Schuller</author>
<author>Yunqing Xia</author>
<author>C Havasi</author>
</authors>
<title>New avenues in opinion mining and sentiment analysis.</title>
<date>2013</date>
<journal>Intelligent Systems, IEEE,</journal>
<volume>28</volume>
<issue>2</issue>
<pages>21</pages>
<contexts>
<context position="1637" citStr="Cambria et al., 2013" startWordPosition="234" endWordPosition="237">of tweets. Considering the different kinds of figurative language in the dataset our submission obtained good results in recognizing sentiment polarity in both ironic and sarcastic tweets. 1 Introduction Figurative language, which is extensively exploited in social media texts, is very challenging for both traditional NLP techniques and sentiment analysis, which has been defined as “the computational study of opinions, sentiments and emotions expressed in text” (Liu, 2010). There is a considerable amount of works related to sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2010; Cambria et al., 2013). In particular, the linguistic analysis ∗ The National Council for Science and Technology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, such as for instance irony, can wo</context>
</contexts>
<marker>Cambria, Schuller, Xia, Havasi, 2013</marker>
<rawString>Erick Cambria, B. Schuller, Yunqing Xia, and C. Havasi. 2013. New avenues in opinion mining and sentiment analysis. Intelligent Systems, IEEE, 28(2):15– 21, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Semi-supervised recognition of sarcastic sentences in twitter and amazon.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL ’10,</booktitle>
<pages>107--116</pages>
<contexts>
<context position="2593" citStr="Davidov et al., 2010" startWordPosition="380" endWordPosition="383">., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, such as for instance irony, can work as an unexpected polarity reverser, by undermining the accuracy of the systems (Bosco et al., 2013). Therefore, several efforts have been recently devoted to detect and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Riloff et al., 2013) as classification tasks. Buschmeier et al. present an analysis of features, previously applied in irony detection, in a dataset from a product reviews corpus from Amazon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in figurative comparisons over a corpus of web-harvested similes (Veale and Hao, 2010). Concerning Twitter, the problem of irony detection is addressed in (Reyes et al., 2013), where a set of textual features is used to recognize irony at a linguistic level</context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Semi-supervised recognition of sarcastic sentences in twitter and amazon. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, CoNLL ’10, pages 107–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ghosh</author>
<author>G Li</author>
<author>T Veale</author>
<author>P Rosso</author>
<author>E Shutova</author>
<author>A Reyes</author>
<author>J Barnden</author>
</authors>
<title>Semeval-2015 task 11: Sentiment analysis of figurative language in twitter.</title>
<date>2015</date>
<booktitle>In Proc. Int. Workshop on Semantic Evaluation (SemEval-2015), Co-located with NAACL and *SEM.</booktitle>
<contexts>
<context position="4028" citStr="Ghosh et al., 2015" startWordPosition="607" endWordPosition="610">d in (Barbieri et al., 2014). Moreover, a recent analysis on the interplay between sarcasm detection and sentiment analysis is in (May694 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 694–698, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics nard and Greenwood, 2014), where a set of rules has been proposed to improve the performance of the sentiment analysis in presence of sarcastic tweets. In this paper we describe our participation to the SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter (Ghosh et al., 2015). The task concerned with classification of tweets containing different kinds of figurative language, in particular irony, sarcasm and metaphors. ValenTo system used a linear regression model, exploiting novel and standard structural and lexical features of tweets. Considering the different kinds of figurative language in the Semeval dataset - sarcasm, irony and metaphors - our submission had good results in recognizing sentiment polarity in both ironic and sarcastic tweets, than in the other cases. 2 Our System We propose a supervised approach that consists in assigning a polarity value to tw</context>
<context position="13553" citStr="Ghosh et al., 2015" startWordPosition="2097" endWordPosition="2100">rFreq, urlFreq, emotPosFreq, emotNegFreq, hashtagBinary, mentionsBinary, hashtagFreq, mentionsFreq, isRetweet, polReversal, AFINN, ANEW, DAL, HL,GI, SWN, senticnetDimensions, senticnetFormula, LIWC, NRC Table 3: Regression experiments: results. Features Subset-1 Subset-2 Subset-3 ft-conf2 0.8218 0.8161 0.8199 In order to measure the relevance of each feature used in our model, we applied the RELIEF algorithm8. The best ranked features are those related to emotional words (NRC) and polarity lexicons (AFINN and HL). 3.3 Official Results We ranked 6th out of 15 teams in the SemEval-2015 Task 11 (Ghosh et al., 2015)9. ValenTo achieved the score of 0.634 using the CS measure, and a score of 2.999 using the MSE measure, while the best team achieved the score of 0.758 for CS, and a score of 2.117 for MSE. Our results in terms of irony and sarcasm seem to be close to the best ones in each category (See Table 4). Table 4: Official ValenTo and best results in each category of figurative type. Category CS Best MSE Best ValenTo ValenTo Overall 0.634 0.758 2.999 2.117 Sarcasm 0.895 0.904 1.004 0.934 Irony 0.901 0.918 0.777 0.671 Metaphor 0.393 0.655 4.730 3.155 Other 0.202 0.612 5.315 3.411 4 Conclusions We descr</context>
</contexts>
<marker>Ghosh, Li, Veale, Rosso, Shutova, Reyes, Barnden, 2015</marker>
<rawString>A. Ghosh, G. Li, T. Veale, P. Rosso, E. Shutova, A. Reyes, and J. Barnden. 2015. Semeval-2015 task 11: Sentiment analysis of figurative language in twitter. In Proc. Int. Workshop on Semantic Evaluation (SemEval-2015), Co-located with NAACL and *SEM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Gonz´alez-Ib´a˜nez</author>
<author>Smaranda Muresan</author>
<author>Nina Wacholder</author>
</authors>
<title>Identifying sarcasm in twitter: A closer look.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11,</booktitle>
<pages>581--586</pages>
<marker>Gonz´alez-Ib´a˜nez, Muresan, Wacholder, 2011</marker>
<rawString>Roberto Gonz´alez-Ib´a˜nez, Smaranda Muresan, and Nina Wacholder. 2011. Identifying sarcasm in twitter: A closer look. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, HLT ’11, pages 581–586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="6856" citStr="Hu and Liu, 2004" startWordPosition="1056" endWordPosition="1059"> English manually labeled words collected by Nielsen (Nielsen, 2011). Polarity values varies from −5 up to +5 1. ANEW: the Affective Norms for English Words provides a set of emotional ratings for a large number of English words (Bradley and Lang, 1999). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (Baccianella et al., 2010) is a lexical resource for opinion mining and consists in three sentiment scores: positive, negative and objective5. We take into account the first two categories. SN: SenticNet is a semantic resource for conceptlevel sentiment analysis (Cambria et al., 2012). We take into account the values of each one of the five dimensions (senticnetDi</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’04, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and subjectivity.</title>
<date>2010</date>
<booktitle>In Handbook of Natural Language Processing.</booktitle>
<contexts>
<context position="1493" citStr="Liu, 2010" startWordPosition="212" endWordPosition="213">e such as irony and sarcasm, which were represented in the dataset. The system also exploited novel and standard structural features of tweets. Considering the different kinds of figurative language in the dataset our submission obtained good results in recognizing sentiment polarity in both ironic and sarcastic tweets. 1 Introduction Figurative language, which is extensively exploited in social media texts, is very challenging for both traditional NLP techniques and sentiment analysis, which has been defined as “the computational study of opinions, sentiments and emotions expressed in text” (Liu, 2010). There is a considerable amount of works related to sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2010; Cambria et al., 2013). In particular, the linguistic analysis ∗ The National Council for Science and Technology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different </context>
</contexts>
<marker>Liu, 2010</marker>
<rawString>Bing Liu. 2010. Sentiment analysis and subjectivity. In Handbook of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Maynard</author>
<author>Mark Greenwood</author>
</authors>
<title>Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014).</booktitle>
<marker>Maynard, Greenwood, 2014</marker>
<rawString>Diana Maynard and Mark Greenwood. 2014. Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word–emotion association lexicon.</title>
<date>2013</date>
<journal>Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="8561" citStr="Mohammad and Turney, 2013" startWordPosition="1297" endWordPosition="1300">words. 5http://sentiwordnet.isti.cnr.it/ download.php 695 on a combination of the first four dimensions: Pl(ci) + |At(ci) |− |Sn(ci) |+ Ap(ci) 3N where ci is an input concept, N the total number of concepts which compose the tweet, and 3 a normalisation factor. LIWC: Linguistic Inquiry and Word Counts dictionary6 contains 127,149 words distributed in categories that can further be used to analyze psycholinguistic features in texts. We select two categories for positive and negative emotions: PosEmo (12,878) entries and NegEmo (15,115 entries). NRC: in the NRC word-emotion association lexicon (Mohammad and Turney, 2013) each word is labeled according to the Plutchik’s primary emotions. 3 Results 3.1 Task Description and Dataset The goal of the Task 11 at SemEval 2015, is the following: given a set of tweets rich w.r.t. the presence of such figurative devices, to determine for each message whether the user expressed positive, negative or neutral sentiment, and the sentiment degree. To have a measure of the sentiment intensity expressed in the message, it was proposed a finegrained 11-point sentiment polarity scale. Figure 1: Frequency distribution of tweets by polarity intensity. Two measures evaluated the si</context>
</contexts>
<marker>Mohammad, Turney, 2013</marker>
<rawString>Saif M. Mohammad and Peter D. Turney. 2013. Crowdsourcing a word–emotion association lexicon. Computational Intelligence, 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Finn ˚Arup Nielsen</author>
</authors>
<title>A new ANEW: evaluation of a word list for sentiment analysis in microblogs.</title>
<date>2011</date>
<contexts>
<context position="6307" citStr="Nielsen, 2011" startWordPosition="964" endWordPosition="965">mentions (mentionsBinary); the amount of hashtags (hashtagFreq) and mentions (mentionsFreq) in each tweet; and if the tweet is a retweet (isRetweet). Finally, we decide to take into account a feature (polReversal) in order to reverse the polarity (positive to negative, and vice versa) if a tweet includes the hashtag #sarcasm or #not. 2.1.2 Lexical Resources In order to take into account sentiments, emotions and psycholinguistic features, and to count their frequency, we use the following lexical resources: AFINN: it is a dictionary of 2,477 English manually labeled words collected by Nielsen (Nielsen, 2011). Polarity values varies from −5 up to +5 1. ANEW: the Affective Norms for English Words provides a set of emotional ratings for a large number of English words (Bradley and Lang, 1999). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3</context>
</contexts>
<marker>Nielsen, 2011</marker>
<rawString>Finn ˚Arup Nielsen. 2011. A new ANEW: evaluation of a word list for sentiment analysis in microblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<volume>2</volume>
<issue>12</issue>
<contexts>
<context position="1603" citStr="Pang and Lee, 2008" startWordPosition="228" endWordPosition="231">d standard structural features of tweets. Considering the different kinds of figurative language in the dataset our submission obtained good results in recognizing sentiment polarity in both ironic and sarcastic tweets. 1 Introduction Figurative language, which is extensively exploited in social media texts, is very challenging for both traditional NLP techniques and sentiment analysis, which has been defined as “the computational study of opinions, sentiments and emotions expressed in text” (Liu, 2010). There is a considerable amount of works related to sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2010; Cambria et al., 2013). In particular, the linguistic analysis ∗ The National Council for Science and Technology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(12):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Reyes</author>
<author>Paolo Rosso</author>
<author>Tony Veale</author>
</authors>
<title>A multidimensional approach for detecting irony in twitter. Language Resources and Evaluation,</title>
<date>2013</date>
<volume>47</volume>
<issue>1</issue>
<pages>268</pages>
<contexts>
<context position="3111" citStr="Reyes et al., 2013" startWordPosition="461" endWordPosition="464">ational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Riloff et al., 2013) as classification tasks. Buschmeier et al. present an analysis of features, previously applied in irony detection, in a dataset from a product reviews corpus from Amazon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in figurative comparisons over a corpus of web-harvested similes (Veale and Hao, 2010). Concerning Twitter, the problem of irony detection is addressed in (Reyes et al., 2013), where a set of textual features is used to recognize irony at a linguistic level. In (Riloff et al., 2013) the focus is on identifying sarcastic tweets that express a positive sentiment towards a negative situation. A model to classify sarcastic tweets using a set of lexical features is presented in (Barbieri et al., 2014). Moreover, a recent analysis on the interplay between sarcasm detection and sentiment analysis is in (May694 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 694–698, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computa</context>
</contexts>
<marker>Reyes, Rosso, Veale, 2013</marker>
<rawString>Antonio Reyes, Paolo Rosso, and Tony Veale. 2013. A multidimensional approach for detecting irony in twitter. Language Resources and Evaluation, 47(1):239– 268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Ashequl Qadir</author>
<author>Prafulla Surve</author>
<author>Lalindra De Silva</author>
<author>Nathan Gilbert</author>
<author>Ruihong Huang</author>
</authors>
<title>Sarcasm as contrast between a positive sentiment and negative situation.</title>
<date>2013</date>
<booktitle>In Proceedings of the EMNLP: Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>704--714</pages>
<marker>Riloff, Qadir, Surve, De Silva, Gilbert, Huang, 2013</marker>
<rawString>Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Ruihong Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of the EMNLP: Conference on Empirical Methods in Natural Language Processing, pages 704–714.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marko Robnik-Sikonja</author>
<author>Igor Kononenko</author>
</authors>
<title>An adaptation of relief for attribute estimation in regression.</title>
<date>1997</date>
<booktitle>In Fourteenth International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<marker>Robnik-Sikonja, Kononenko, 1997</marker>
<rawString>Marko Robnik-Sikonja and Igor Kononenko. 1997. An adaptation of relief for attribute estimation in regression. In Fourteenth International Conference on Machine Learning, pages 296–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Alan Ritter</author>
<author>Preslav Nakov</author>
<author>Veselin Stoyanov</author>
</authors>
<title>Semeval-2014 task 9: Sentiment analysis in twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>73--80</pages>
<contexts>
<context position="1959" citStr="Rosenthal et al., 2014" startWordPosition="281" endWordPosition="284">LP techniques and sentiment analysis, which has been defined as “the computational study of opinions, sentiments and emotions expressed in text” (Liu, 2010). There is a considerable amount of works related to sentiment analysis and opinion mining (Pang and Lee, 2008; Liu, 2010; Cambria et al., 2013). In particular, the linguistic analysis ∗ The National Council for Science and Technology (CONACyT-Mexico) has funded the research work of the first author (218109/313683 grant). of social media (microblogging like Twitter especially) has become a relevant topic of research in different languages (Rosenthal et al., 2014; Basile et al., 2014) and several frameworks for detecting sentiments and opinions in social media have been developed for different application purposes. In a sentiment analysis setting, the presence in a text of figurative language devices, such as for instance irony, can work as an unexpected polarity reverser, by undermining the accuracy of the systems (Bosco et al., 2013). Therefore, several efforts have been recently devoted to detect and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm</context>
</contexts>
<marker>Rosenthal, Ritter, Nakov, Stoyanov, 2014</marker>
<rawString>Sara Rosenthal, Alan Ritter, Preslav Nakov, and Veselin Stoyanov. 2014. Semeval-2014 task 9: Sentiment analysis in twitter. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 73–80, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Stone</author>
<author>Earl B Hunt</author>
</authors>
<title>A computer approach to content analysis: Studies using the general inquirer system.</title>
<date>1963</date>
<journal>AFIPS</journal>
<booktitle>In Proceedings of the</booktitle>
<volume>63</volume>
<pages>241--256</pages>
<contexts>
<context position="6952" citStr="Stone and Hunt, 1963" startWordPosition="1072" endWordPosition="1075"> from −5 up to +5 1. ANEW: the Affective Norms for English Words provides a set of emotional ratings for a large number of English words (Bradley and Lang, 1999). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (Baccianella et al., 2010) is a lexical resource for opinion mining and consists in three sentiment scores: positive, negative and objective5. We take into account the first two categories. SN: SenticNet is a semantic resource for conceptlevel sentiment analysis (Cambria et al., 2012). We take into account the values of each one of the five dimensions (senticnetDimensions) provided by the lexical resource: Pleasantness (Pl), Attention (At), Sensitivity (Sn) </context>
</contexts>
<marker>Stone, Hunt, 1963</marker>
<rawString>Philip J. Stone and Earl B. Hunt. 1963. A computer approach to content analysis: Studies using the general inquirer system. In Proceedings of the May 21-23, 1963, AFIPS ’63 (Spring), pages 241–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Yanfen Hao</author>
</authors>
<title>Detecting ironic intent in creative comparisons.</title>
<date>2010</date>
<booktitle>In ECAI,</booktitle>
<volume>215</volume>
<pages>765--770</pages>
<contexts>
<context position="3022" citStr="Veale and Hao, 2010" startWordPosition="446" endWordPosition="449">ct and tackle figurative language phenomena in social media, following a variety of computational approaches, mostly focussing on irony detection and sarcasm recognition (Davidov et al., 2010; Gonz´alez-Ib´a˜nez et al., 2011; Riloff et al., 2013) as classification tasks. Buschmeier et al. present an analysis of features, previously applied in irony detection, in a dataset from a product reviews corpus from Amazon (Buschmeier et al., 2014). Veale and Hao present a linguistic approach to separate ironic from nonironic expressions in figurative comparisons over a corpus of web-harvested similes (Veale and Hao, 2010). Concerning Twitter, the problem of irony detection is addressed in (Reyes et al., 2013), where a set of textual features is used to recognize irony at a linguistic level. In (Riloff et al., 2013) the focus is on identifying sarcastic tweets that express a positive sentiment towards a negative situation. A model to classify sarcastic tweets using a set of lexical features is presented in (Barbieri et al., 2014). Moreover, a recent analysis on the interplay between sarcasm detection and sentiment analysis is in (May694 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEv</context>
</contexts>
<marker>Veale, Hao, 2010</marker>
<rawString>Tony Veale and Yanfen Hao. 2010. Detecting ironic intent in creative comparisons. In ECAI, volume 215, pages 765–770.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Whissell</author>
</authors>
<title>Using the revised dictionary of affect in language to quantify the emotional undertones of samples of natural languages. In Psychological Reports.</title>
<date>2009</date>
<contexts>
<context position="6676" citStr="Whissell, 2009" startWordPosition="1030" endWordPosition="1031"> to take into account sentiments, emotions and psycholinguistic features, and to count their frequency, we use the following lexical resources: AFINN: it is a dictionary of 2,477 English manually labeled words collected by Nielsen (Nielsen, 2011). Polarity values varies from −5 up to +5 1. ANEW: the Affective Norms for English Words provides a set of emotional ratings for a large number of English words (Bradley and Lang, 1999). Each word in is rated from 1 to 9 in terms of the three dimensions of Valence, Arousal and Dominance. DAL: the Dictionary of Affective Language developed by Whissell (Whissell, 2009) contains 8,742 English words rated in a three-point scale2. Each word is rated into the dimensions of Pleasantness, Activation and Imagery. HL: Hu–Liu’s lexicon (Hu and Liu, 2004) includes about 6, 800 positive and negative words3. GI: General Inquirer (Stone and Hunt, 1963) contains categories and subcategories for content analysis with dictionaries based on the Lasswell and Harvard IV-4 4. SWN: SentiWordNet (Baccianella et al., 2010) is a lexical resource for opinion mining and consists in three sentiment scores: positive, negative and objective5. We take into account the first two categori</context>
</contexts>
<marker>Whissell, 2009</marker>
<rawString>Cynthia Whissell. 2009. Using the revised dictionary of affect in language to quantify the emotional undertones of samples of natural languages. In Psychological Reports.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>