<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000825">
<title confidence="0.936284">
INRIASAC: Simple Hypernym Extraction Methods
</title>
<author confidence="0.835279">
Gregory Grefenstette
</author>
<affiliation confidence="0.523519">
Inria
</affiliation>
<address confidence="0.3689965">
1 rue Honoré d&apos;Estienne d&apos;Orves
91120 Palaiseau, France
</address>
<email confidence="0.894538">
Gregory.grefenstette@inria.fr
</email>
<sectionHeader confidence="0.978693" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999834421052632">
For information retrieval, it is useful to classi-
fy documents using a hierarchy of terms from
a domain. One problem is that, for many do-
mains, hierarchies of terms are not available.
The task 17 of SemEval 2015 addresses the
problem of structuring a set of terms from a
given domain into a taxonomy without manu-
al intervention. Here we present some simple
taxonomy structuring techniques, such as term
overlap and document and sentence co-
occurrence in large quantities of text (English
Wikipedia) to produce hypernym pairs for the
eight domain lists supplied by the task organ-
izers. Our submission ranked first in this 2015
benchmark, which suggests that overly com-
plicated methods might need to be adapted to
individual domains. We describe our generic
techniques and present an initial evaluation of
results.
</bodyText>
<sectionHeader confidence="0.99517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996816682926829">
This paper describes two simple hypernym extrac-
tion methods, given a list of domain terms and a
large amount of text divided into documents. Task
17 of the 2015 Semeval campaign (Bordea et al.,
2015) consists in structuring a flat list of pre-
identified domain terms into a list of hypernym
pairs. Task organizers provide two lists of terms
for each of four domains: equipment, food, chemi-
cal, science, one extracted from WordNet and one
from an unknown source. Participants in the task
were allowed to use any resource (except existing
taxonomies) to automatically transform the lists of
terms into lists of pairs of terms, the first term be-
ing a hyponym of the more general second term.
For example, if the words airship and blimp
were included in the lists of terms for a domain,
the system was expected to return lines such as:
blimp airship
The task organizers provided training data from
the domains of Artificial Intelligence, vehicles and
plants, different from the test domains. The train-
ing data consisted in term lists (for plants), and
term lists and lists of hypernyms (for AI and for
vehicles). We examined these files to get an under-
standing of the task but did not exploit them.
We used the English text of Wikipedia (download-
ed from http://dumps.wikimedia.org on August 13,
2014) as our only resource for discovering these
relations. We extracted only the text of each arti-
cle, ignoring titles, section headings, categories,
infoboxes, or other meta-information present in the
article. We recognized task terms in these articles
and gathered statistics on document and sentence
co-occurrence between domain terms, as well as
term frequency. To recognize hypernyms, we used
term inclusion (explained in section 3.1 below) and
co-occurrence statistics (see section 3.2) to decide
whether two terms were possibly in a hypernym
relation, and document frequency to chose which
term was the hypernym. Our submission ranked
first in the SemEval 2015 task 17 benchmark.
</bodyText>
<sectionHeader confidence="0.969681" genericHeader="method">
2 Domain Lists
</sectionHeader>
<bodyText confidence="0.978700684210526">
Participants were provided with the eight lists of
domain terms, each containing between 370 and
1555 terms. Some terms examples:
chemical: agarose, nickel sulfate heptahydrate, aminoglycan,
pinoquercetin, ...
equipment: storage equipment, strapping, traveling micro-
scope, minneapolis-moline, ...
food: sauce gribiche, botifarra, phitti, food colouring, bean,
limequat, kalach, ...
science: biological and physical, history of religions of east-
ern origins, linguistic anthropology, religion, semantics...
WN_chemical: abo antibodies, acaricide, acaroid resin, ac-
ceptor, acetal, acetaldehyde...
WN_equipment: acoustic modem, aerator, air search radar,
amplifier, anti submarine rocket, apishamore, apparatus, ...
WN_food: absinth, acidophilus milk, adobo, agar, aioli, alco-
hol, ale, alfalfa, allemande, allergy diet, ...
WN_science: abnormal psychology, acoustics, aerology, aer-
omechanics, aeronautics, ...
</bodyText>
<page confidence="0.512255">
911
</page>
<note confidence="0.724829">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 911–914,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.995528055555556">
Terms consisted of one to nine words. Some terms
were very short and ambiguous (only two or three
characters: ga, os, tu, ada, aji, ...) and some
very long (e.g., udp-n-acetyl-alpha-d-
muramoyl-l-alanyl-gamma-d-glutamyl-l-
lysyl-d-alanyl-d-alanine, korea advanced
institute of science and technology sat-
ellite 4). It is specified that the taxonomies pro-
duced during the task should be rooted on
chemical for the two chemical domain lists, on
equipment for the equipment lists, on food for
the food lists, and on science for the science lists,
even though the term chemical was absent from
the WN_chemical domain list. Participants were
allowed to add additional nodes, i.e. terms, in the
hierarchy as they consider appropriate. We did not
add any new terms, except for chemical in the
WN_chemical list.
</bodyText>
<subsectionHeader confidence="0.995959">
2.1 Preprocessing the resource
</subsectionHeader>
<bodyText confidence="0.999957529411765">
Our only resource for discovering hypernym rela-
tions was the English Wikipedia. Starting from the
wiki-latest-pages-articles.xml, we extracted all the
text between &lt;text&gt; markers, and marked off doc-
ument boundaries using &lt;title&gt; markers. No other
information (infoboxes, categories, etc.) was kept.
The text was then tokenized and output as one sen-
tence per line. The first English Wikipedia sen-
tence extracted looked like this: &apos; Anarchism &apos; is
a political philosophy that advocates stateless
societies often defined as self-governed volun-
tary institutions , but that several authors
have defined as more specific institutions
based on non-hierarchical free associations.
We applied Porter stemming (Willet, 2006) and
replaced stopwords (Buckley et al., 1995) by un-
derscores. The first sentence then becomes:
</bodyText>
<equation confidence="0.869625142857143">
anarch polit philosophi _ advoc
stateless societi defin self-govern
_ _
voluntari institut sever author
_ _
_
defin _ _ specif institut base _ non-
</equation>
<bodyText confidence="0.92529125">
hierarch free associ
We applied the same Porter stemming and stop-
word removal to the task-supplied domain terms.
So the science term list, for example, becomes
</bodyText>
<figure confidence="0.9314132">
0 electro-mechan system
1 biolog _ physic
2 histori _ religion _ eastern origin
3 linguist anthropolog
4 metaphys
</figure>
<bodyText confidence="0.99955975">
We retained both Porter-stemmed versions of the
Wikipedia sentences and domain terms as well as
the original unstemmed versions for the treatment
described below.
</bodyText>
<sectionHeader confidence="0.981504" genericHeader="method">
3 Extracting Hypernyms
</sectionHeader>
<bodyText confidence="0.9999436">
In order to extract hypernyms, we used the follow-
ing features: (i) presence of terms in the same sen-
tence, (ii) presence in the same document (iii) term
frequency (iv) document frequency, and (v) subse-
quences.
</bodyText>
<subsectionHeader confidence="0.986923">
3.1 Subterms
</subsectionHeader>
<bodyText confidence="0.98362628125">
In addition to domain lists supplied for the
Semeval task, we were supplied with training data.
One file in this training data, ontolearn_AX.taxo,
gives ground truth for the training file on-
tolearn_AX.terms, and contains:
source code &lt; code
theory of inheritance &lt; theory
From these validated examples, we concluded that
an ‘easy’ way to find hypernyms is to check
whether one term is a suffix of the other (e.g., com-
munications satellite as a type of satel-
lite),
atel-
1ite), or whether one term B is the prefix of
another term B A C where A is any two-letter
word (e.g. helmet of coţofeneşti as a type of
helmet; caterpillar d9 as a type of cater-
pillar). We chose two letters for the second term
to cover English prepositions such as of, in, by, ...
This heuristic was unexpectedly productive in the
chemical domain where many hypernym pairs
were similar to: ginsenoside mc as a type of
ginsenoside (see Table 1). But our prefix
matching using second words of length two missed
hypernyms such as fortimicin b as a type of
fortimicin or ginsenoside c-y as a type of
ginsenoside. Obviously chemical terms should
have their own heuristics for subterm matching.
Other examples of errors, false positives, caused
by these heuristics are licorice as a type of
rice or surface to air missile system as a
type of surface.
</bodyText>
<equation confidence="0.57239">
_ _ _
</equation>
<page confidence="0.356784">
912
</page>
<note confidence="0.7291355">
3.2 Sentence and Document Co-occurrence
Statistics
</note>
<bodyText confidence="0.996380176470588">
in the most documents for each term not found by
using the prefix or suffix heuristics.
For other domain terms (which could include the
hypernyms found by the suffix and prefix heuris-
tics), we use the statistics of document presence,
and of co-occurrence of terms in sentences to pre-
dict hypernym relations. Let Dporter(term) be the
document frequency of a Porter-stemmed term in
the stemmed version of Wikipedia. Since Wikipe-
dia article boundaries were stored, we considered
each Wikipedia article as a new document. Let
SentCoocporter(termi, termj) be the number of times
that the Porter-stemmed versions of termi and termj
appear in the same sentence in the stemmed Eng-
lish Wikipedia. Given two terms, termi and termj,
if termi is appears in more documents than termj,
then termi is a candidate hypernym for termj.
</bodyText>
<equation confidence="0.999950666666667">
CandHypenym(termi) = { termj :
SentCoocporter(termi, termj) &gt; 0 &amp;&amp;
Dporter(termj) &gt; Dporter(termi) }
</equation>
<bodyText confidence="0.99880975">
This heuristically derived set is meant to capture
the intuition that general terms are more widely
distributed than more specific terms (e.g., dog ap-
pears in more Wikipedia articles than poodle).
</bodyText>
<table confidence="0.999539181818182">
Domain suffix prefix cooc Total
hypernyms
produced
WN_chemical 750 10 3766 4001
WN_equipment 171 3 1338 1369
WN_food 616 25 4121 4238
WN_science 174 0 1070 1102
chemical 10780 91 19322 28443
equipment 241 17 1126 1168
food 471 33 4277 4363
science 193 17 1130 1164
</table>
<tableCaption confidence="0.966920666666667">
Table 1. Number of prefix and suffix hypernyms pro-
duced, compared to the total number of hypernyms re-
turned for each domain.
</tableCaption>
<bodyText confidence="0.993278666666667">
Next, we define the best hyperym candidate for
termi as being the term termk that appears in the
most documents (from Wikipedia in this case):
</bodyText>
<equation confidence="0.92930925">
BestHypernym(termi) = termk
such that
∀ termj ∈ CandHypernym(termi) :
Dporter(termk) ≥ Dporter(termj)
</equation>
<bodyText confidence="0.999930666666667">
Next, we remove this term termk from CandHyper-
nym(termi) and repeat the heuristic twice, retain-
ing, then, the three candidate hypernyms appearing
</bodyText>
<subsectionHeader confidence="0.774993">
3.2.1 Co-occurrence Example
</subsectionHeader>
<bodyText confidence="0.998390363636364">
Consider the following example. In the domain file
science.terms there is the term biblical stud-
ies. The Porter-stemmed version of this term
biblic studi appears in 887 documents. Con-
sidering all the other terms in science.terms, we
find that biblic studi appears 215 times in
the same sentence as the stemmed version of the-
ology (theologi), 111 times in the same sentenc-
es as stemmed history (histori), 50 times with
religion, 43 times with music, and 42 times with
science (scienc).
</bodyText>
<table confidence="0.83291175">
215 887 21977 biblic studi theologi
111 887 383927 biblic studi histori
50 887 64044 biblic studi religion
43 887 412791 biblic studi music
</table>
<bodyText confidence="0.999535333333333">
We decided to keep the top three for simplicity, so
this term contributed three bolded lines above to
our submitted science.taxo file.
</bodyText>
<subsectionHeader confidence="0.989014">
3.3 Other Attempts at Finding Relations
</subsectionHeader>
<bodyText confidence="0.999824894736842">
We tried a number of other methods to find hyper-
nyms, none of which gave results that looked good
from a cursory glance. We implemented a method
to recognize sentences containing Hearst patterns
(list from (Cimiano et al., 2005)) involving the
domain terms. For example, tape is in equipment,
and were able to find stemmed sentences of the
form A, B and other C É such as todai ,
sticki note , 3m #tape# @, and other@
#tape# ar exampl of psa ( pressure-sensit
adhes ) from which we should have been able to
extract relations such as 3m tape is a type of tape,
and sticky note is a type of tape. But we would
have had to the parse the sentence, and been will-
ing to add new terms (which was permitted by the
organizers) to the derived hypernym lists but we
did not want to make that processing investment
yet. We also tried to discover the basic vocabulary
(Kit, 2002) of each domain without success.
</bodyText>
<sectionHeader confidence="0.994503" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.994959666666667">
Each participant in Task 17 of SemEval 2015 was
allowed to submit one run for each of the 8 do-
mains (see Table 1 for the names of the domains,
</bodyText>
<page confidence="0.850283">
913
</page>
<bodyText confidence="0.9998989">
and the number of hypernym pairs we submitted.
Suffix and prefix subterms account for 10% to
36% of the hypernyms we produced. The
cooccurence technique produced the most hyper-
nym candidates). The task organizers evaluated the
submissions of the six participating teams, using
automated and manual methods, and published
their evaluation three weeks after the submission
deadline. Our team placed first in the official rank-
ing of the six teams.
</bodyText>
<table confidence="0.9996182">
Domain suffix prefix cooc union gold
to find
WN_chemical 377 5 574 644 1387
WN_equipment 119 0 168 184 485
WN_food 371 2 681 726 1533
WN_science 119 0 230 240 441
chemical 2019 9 715 2407 24817
equipment 184 1 286 305 615
food 279 1 807 822 1587
science 121 7 193 209 465
</table>
<tableCaption confidence="0.993439">
Table 2. Number of gold standard relations to find in
</tableCaption>
<bodyText confidence="0.9600878">
the last column. Columns 2, 3 and 4 are the number of
gold standard relations found by each technique. “un-
ion” is the union of columns 2, 3 and 4. Since the co-
occurrence technique can find relations that have been
found by the suffix and prefix techniques.
</bodyText>
<table confidence="0.9992556">
Domain suffix prefix cooc union gold
to find
WN_chemical 26% 0.3% 40% 46% 1387
WN_equipment 24% 0% 34% 38% 485
WN_food 23% 0.1% 43% 47% 1533
WN_science 26% 0% 51% 54% 441
chemical 8% 0.03% 3% 10% 24817
equipment 30% 0.02% 47% 50% 615
food 18% 0.06% 51% 52% 1587
science 26% 1.8% 42% 45% 465
</table>
<tableCaption confidence="0.9876735">
Table 3. Percentage of correct answers found by each
method.
</tableCaption>
<bodyText confidence="0.9999565">
The evaluation criteria, which were not published
before the submission, combined the presences of
cycles in the hypernyms submitted, the Fowlkes &amp;
Mallows measure of the overlap between the sub-
mitted hierarchy and the gold standard hierarchy,
the F-score ranking, the number of domains sub-
mitted (not all teams returned results for all do-
mains), and a manual precision ranking (for
hypernyms not present in the gold standard). The
gold standards used by the task organizers came
from published taxonomies, or from subtrees of
WordNet (prefixed as WN_ above). A quick eval-
uation of how well our simple hypernym extrac-
tion techniques fared on each gold standard is
shown in Table 2.
As Table 3 shows, most of the correct answers
found come from the sentence and document co-
occurrence method described in section 3.2.
</bodyText>
<sectionHeader confidence="0.998188" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99997125">
Even though training data was provided for this
taxonomy creation task, we did not exploit it in
this our first participation in Semeval. We imple-
mented some simple frequency-based co-
occurrence statistics, and substring inclusion heu-
ristics to propose a set of hypernyms. We did not
implement any graph algorithms (cycle detection,
branch deletion) that would be useful to build a
true hierarchy. Future plans involve examining and
eliminating cycles generated by this method. Since
we only used wikipedia as a resource, the method
depends on the given terms being present in Wik-
ipedia, which was not always the case, especially
in the chemical domain. In future work, we will
also examine using web documents, in lieu of or to
supplement Wikipedia.
</bodyText>
<sectionHeader confidence="0.987948" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.946170333333333">
This research is partially funded by a research grant from
INRIA, and the Paris-Saclay Institut de la Soci&amp;6 Num6rique
funded by the IDEX Paris-Saclay, ANR-11-IDEX-0003-02.
</bodyText>
<sectionHeader confidence="0.996089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999836619047619">
Georgeta Bordea, Paul Buitelaar, Stefano Faralli, and
Roberto Navigli. 2015. Semeval-2015 task 17: Tax-
onomy Extraction Evaluation. Proceedings of the 9th
International Workshop on Semantic Evaluation. As-
sociation for Computational Linguistics
Chris Buckley, Gerard Salton, James Allan, and Amit
Singhal. 1995. Automatic query expansion using
SMART: TREC3. Proceedings of the 3rd Text RE-
trieval Conference (TREC-3). NIST Special Publica-
tion 500–226. National Institute of Standards and
Technology (NIST), Gaithersburg, MD, pp: 69–80.
Philipp Cimiano, Aleksander Pivk, Lars Schmidt-
Thieme, and Steffen Staab. 2005. Learning taxo-
nomic relations from heterogeneous sources of evi-
dence. Ontology Learning from Text: Methods,
evaluation and applications. IoS Press.
Chunyu Kit. 2002. Corpus tools for retrieving and de-
riving termhood evidence. Proceedings of the 5th
East Asia Forum of Terminology, pp. 69-80.
Peter Willett. 2006. The Porter stemming algorithm:
then and now. Program 40(3): 219-223
</reference>
<page confidence="0.913459">
914
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.646927">
<title confidence="0.997853">INRIASAC: Simple Hypernym Extraction Methods</title>
<author confidence="0.97952">Gregory</author>
<address confidence="0.830023">1 rue Honoré d&apos;Estienne 91120 Palaiseau,</address>
<email confidence="0.954154">Gregory.grefenstette@inria.fr</email>
<abstract confidence="0.998941">For information retrieval, it is useful to classify documents using a hierarchy of terms from a domain. One problem is that, for many domains, hierarchies of terms are not available. The task 17 of SemEval 2015 addresses the problem of structuring a set of terms from a given domain into a taxonomy without manual intervention. Here we present some simple taxonomy structuring techniques, such as term overlap and document and sentence cooccurrence in large quantities of text (English Wikipedia) to produce hypernym pairs for the eight domain lists supplied by the task organizers. Our submission ranked first in this 2015 benchmark, which suggests that overly complicated methods might need to be adapted to individual domains. We describe our generic techniques and present an initial evaluation of results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Georgeta Bordea</author>
<author>Paul Buitelaar</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>Semeval-2015 task 17: Taxonomy Extraction Evaluation.</title>
<date>2015</date>
<booktitle>Proceedings of the 9th International Workshop on Semantic Evaluation. Association for Computational Linguistics</booktitle>
<contexts>
<context position="1192" citStr="Bordea et al., 2015" startWordPosition="184" endWordPosition="187">rlap and document and sentence cooccurrence in large quantities of text (English Wikipedia) to produce hypernym pairs for the eight domain lists supplied by the task organizers. Our submission ranked first in this 2015 benchmark, which suggests that overly complicated methods might need to be adapted to individual domains. We describe our generic techniques and present an initial evaluation of results. 1 Introduction This paper describes two simple hypernym extraction methods, given a list of domain terms and a large amount of text divided into documents. Task 17 of the 2015 Semeval campaign (Bordea et al., 2015) consists in structuring a flat list of preidentified domain terms into a list of hypernym pairs. Task organizers provide two lists of terms for each of four domains: equipment, food, chemical, science, one extracted from WordNet and one from an unknown source. Participants in the task were allowed to use any resource (except existing taxonomies) to automatically transform the lists of terms into lists of pairs of terms, the first term being a hyponym of the more general second term. For example, if the words airship and blimp were included in the lists of terms for a domain, the system was ex</context>
</contexts>
<marker>Bordea, Buitelaar, Faralli, Navigli, 2015</marker>
<rawString>Georgeta Bordea, Paul Buitelaar, Stefano Faralli, and Roberto Navigli. 2015. Semeval-2015 task 17: Taxonomy Extraction Evaluation. Proceedings of the 9th International Workshop on Semantic Evaluation. Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
<author>Gerard Salton</author>
<author>James Allan</author>
<author>Amit Singhal</author>
</authors>
<title>Automatic query expansion using SMART:</title>
<date>1995</date>
<booktitle>TREC3. Proceedings of the 3rd Text REtrieval Conference (TREC-3). NIST Special Publication 500–226. National Institute of Standards and Technology (NIST),</booktitle>
<pages>69--80</pages>
<location>Gaithersburg, MD,</location>
<contexts>
<context position="5669" citStr="Buckley et al., 1995" startWordPosition="852" endWordPosition="855">ted all the text between &lt;text&gt; markers, and marked off document boundaries using &lt;title&gt; markers. No other information (infoboxes, categories, etc.) was kept. The text was then tokenized and output as one sentence per line. The first English Wikipedia sentence extracted looked like this: &apos; Anarchism &apos; is a political philosophy that advocates stateless societies often defined as self-governed voluntary institutions , but that several authors have defined as more specific institutions based on non-hierarchical free associations. We applied Porter stemming (Willet, 2006) and replaced stopwords (Buckley et al., 1995) by underscores. The first sentence then becomes: anarch polit philosophi _ advoc stateless societi defin self-govern _ _ voluntari institut sever author _ _ _ defin _ _ specif institut base _ nonhierarch free associ We applied the same Porter stemming and stopword removal to the task-supplied domain terms. So the science term list, for example, becomes 0 electro-mechan system 1 biolog _ physic 2 histori _ religion _ eastern origin 3 linguist anthropolog 4 metaphys We retained both Porter-stemmed versions of the Wikipedia sentences and domain terms as well as the original unstemmed versions fo</context>
</contexts>
<marker>Buckley, Salton, Allan, Singhal, 1995</marker>
<rawString>Chris Buckley, Gerard Salton, James Allan, and Amit Singhal. 1995. Automatic query expansion using SMART: TREC3. Proceedings of the 3rd Text REtrieval Conference (TREC-3). NIST Special Publication 500–226. National Institute of Standards and Technology (NIST), Gaithersburg, MD, pp: 69–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Aleksander Pivk</author>
<author>Lars SchmidtThieme</author>
<author>Steffen Staab</author>
</authors>
<title>Learning taxonomic relations from heterogeneous sources of evidence. Ontology Learning from Text: Methods, evaluation and applications.</title>
<date>2005</date>
<publisher>IoS Press.</publisher>
<contexts>
<context position="10876" citStr="Cimiano et al., 2005" startWordPosition="1718" endWordPosition="1721">times with religion, 43 times with music, and 42 times with science (scienc). 215 887 21977 biblic studi theologi 111 887 383927 biblic studi histori 50 887 64044 biblic studi religion 43 887 412791 biblic studi music We decided to keep the top three for simplicity, so this term contributed three bolded lines above to our submitted science.taxo file. 3.3 Other Attempts at Finding Relations We tried a number of other methods to find hypernyms, none of which gave results that looked good from a cursory glance. We implemented a method to recognize sentences containing Hearst patterns (list from (Cimiano et al., 2005)) involving the domain terms. For example, tape is in equipment, and were able to find stemmed sentences of the form A, B and other C É such as todai , sticki note , 3m #tape# @, and other@ #tape# ar exampl of psa ( pressure-sensit adhes ) from which we should have been able to extract relations such as 3m tape is a type of tape, and sticky note is a type of tape. But we would have had to the parse the sentence, and been willing to add new terms (which was permitted by the organizers) to the derived hypernym lists but we did not want to make that processing investment yet. We also tried to dis</context>
</contexts>
<marker>Cimiano, Pivk, SchmidtThieme, Staab, 2005</marker>
<rawString>Philipp Cimiano, Aleksander Pivk, Lars SchmidtThieme, and Steffen Staab. 2005. Learning taxonomic relations from heterogeneous sources of evidence. Ontology Learning from Text: Methods, evaluation and applications. IoS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunyu Kit</author>
</authors>
<title>Corpus tools for retrieving and deriving termhood evidence.</title>
<date>2002</date>
<booktitle>Proceedings of the 5th East Asia Forum of Terminology,</booktitle>
<pages>69--80</pages>
<contexts>
<context position="11514" citStr="Kit, 2002" startWordPosition="1844" endWordPosition="1845">. For example, tape is in equipment, and were able to find stemmed sentences of the form A, B and other C É such as todai , sticki note , 3m #tape# @, and other@ #tape# ar exampl of psa ( pressure-sensit adhes ) from which we should have been able to extract relations such as 3m tape is a type of tape, and sticky note is a type of tape. But we would have had to the parse the sentence, and been willing to add new terms (which was permitted by the organizers) to the derived hypernym lists but we did not want to make that processing investment yet. We also tried to discover the basic vocabulary (Kit, 2002) of each domain without success. 4 Evaluation Each participant in Task 17 of SemEval 2015 was allowed to submit one run for each of the 8 domains (see Table 1 for the names of the domains, 913 and the number of hypernym pairs we submitted. Suffix and prefix subterms account for 10% to 36% of the hypernyms we produced. The cooccurence technique produced the most hypernym candidates). The task organizers evaluated the submissions of the six participating teams, using automated and manual methods, and published their evaluation three weeks after the submission deadline. Our team placed first in t</context>
</contexts>
<marker>Kit, 2002</marker>
<rawString>Chunyu Kit. 2002. Corpus tools for retrieving and deriving termhood evidence. Proceedings of the 5th East Asia Forum of Terminology, pp. 69-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Willett</author>
</authors>
<title>The Porter stemming algorithm: then and now.</title>
<date>2006</date>
<journal>Program</journal>
<volume>40</volume>
<issue>3</issue>
<pages>219--223</pages>
<marker>Willett, 2006</marker>
<rawString>Peter Willett. 2006. The Porter stemming algorithm: then and now. Program 40(3): 219-223</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>