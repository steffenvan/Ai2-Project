<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<figure confidence="0.70535025">
Abstract
A LOGICAL SEMANTICS
FOR NONMONOTONIC SORTS
Mark A. Young &amp; Bill Rounds
</figure>
<affiliation confidence="0.7734985">
Artificial Intelligence Laboratory
The University of Michigan
</affiliation>
<address confidence="0.78598">
1101 Beal Ave.
Ann Arbor, MI 48109
</address>
<email confidence="0.498238">
marky,roundsOengin.umich.edu
</email>
<bodyText confidence="0.999887653846154">
The original presentation of nonmonotonic sorts
provided only a description of their operation and
an informal description of their meaning. In this
paper, we present a logical basis for NSs and non-
monotonically sorted feature structures (NSFSs).
NSFSs are shown to be equivalent to default theo-
ries of default logic (Reiter 1980). In particular, we
show how nonmonotonic sort unification is equiv-
alent to finding the smallest default theory that
describes both NSFSs; and also how taking a solu-
tion for a NSFS is the same as finding an extension
for that theory.
Suppose we have a feature system, and we wish
to add default values in a well-defined way. We
might start with Kasper-Rounds logic, and use
Reiter&apos;s example to form it into a default logic.
Giving a node a default value would be equiv-
alent to saying &amp;quot;if it is consistent for this node
to have that value, then it does.&amp;quot; Then we
could use default theories to describe feature
structures. The particular feature structure
described would be the structure that supports
the extension of the default theory. This is, in
effect, what the theory of nonmonotonic sorts
gives you. This paper describes how that the-
ory derives from what is described above.
</bodyText>
<sectionHeader confidence="0.998364" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999681653846154">
There have been many suggestions for incorporat-
ing defaults into unification-based grammar for-
malisms (Bouma 1990; Bouma 1992; Carpenter
1991; Kaplan 1987; Russell ei al. 1992; Shieber
1986; Shieber 1987). Each of these proposes a
non-commutative, non-associative default unifica-
tion operation that combines one structure repre-
senting strict information with another represent-
ing default information. When presented with a
set of structures, the result depends on the order in
which the structures are combined. This runs very
much against the unification tradition, in which any
set has a unique most general satisfier (if a satisfier
exists at all).
A method that is free of these ordering effects
was presented in (Young 1992). The method of
nonmonotonic sorts (NSs) allows default labels to
be assigned at any time, and used only in the ab-
sence of conflicting information. NSs replace the
more traditional labels on feature structures to give
nonmonotonically sorted feature structures (NS-
FSs). These structures can be combined by an asso-
ciative and commutative unification operation. FSs
are rederived from NSFSs by taking a solution—an
operation defined in terms of information present
in the NSFS.
</bodyText>
<sectionHeader confidence="0.970488" genericHeader="method">
FEATURE SYSTEMS
</sectionHeader>
<bodyText confidence="0.7384875">
Unification-based grammar formalisms use formal
objects called feature structures to encode linguis-
tic information. We use a variant of the standard
definition. Each structure has a sort (drawn from
a finite set S), and a (possibly empty) set of at-
tributes (drawn from a finite set .F).
Definition 1 A feature structure is a tuple
(Q, r,S, 0) where
</bodyText>
<listItem confidence="0.992618833333333">
• Q is a finite set of nodes,
• r E Q is the root node,
• 6 : Qx..F --* Q is a partial feature value function
that gives the edges and their labels, and
• 0 : Q --4 S is a sorting function that gives the
labels of the nodes.
</listItem>
<bodyText confidence="0.974288153846154">
This structure must be connected.
It is not unusual to require that these structures
also be acyclic. For some systems 0 is defined only
for sink nodes (PATR-II, for example). Fig. 1 shows
a standard textual representation for a FS.
We sometimes want to refer to substructures of a
FS. If A is a feature structure as described above,
we write Alf for the feature structure rooted at
6(q, f). This feature structure is defined by Q&apos; C Q,
the set of nodes that can be reached from 6(r, f).
We will use the letter p (possibly subscripted) to
represent paths (that is, finite sequences from .7**).
We will also extend 6 to have paths in its second
</bodyText>
<page confidence="0.996297">
209
</page>
<figure confidence="0.939450076923077">
VERB template
&lt;past tense suffix&gt; default +te
&lt;past participle prefix&gt; isa ge+
&lt;past participle suffix&gt; default +t
spiel lex VERB
MIDDLE-VERB template VERB
&lt;past participle suffix&gt; isa +en
mahl lex MIDDLE-VERB
STRONG-VERB template MIDDLE-VERB
&lt;past tense suffix&gt; isa 0
zwing lex STRONG-VERB
&lt;past tense stem&gt; isa zwang
&lt;past participle stem&gt; isa zwung
</figure>
<figureCaption confidence="0.9909">
Figure 3: Example Lexicon with Defaults
</figureCaption>
<figure confidence="0.863171166666667">
&lt;subj agr person&gt; isa 3rd
&lt;subj agr number&gt; isa singular
&lt;subj agr&gt; &lt;pred agr&gt;
&lt;pred actor&gt; = &lt;subj&gt;
&lt;pred rep&gt; isa sleep
&lt;pred tense&gt; isa present
</figure>
<figureCaption confidence="0.8757365">
Figure 1: Textual Feature Structure: &amp;quot;Uther
sleeps.&amp;quot;
</figureCaption>
<figure confidence="0.999740857142857">
TRUE
FALSE
a where a E S
= P2 where each pi E
f:q5where f E and qEFML
A 0
0 V
</figure>
<figureCaption confidence="0.983091">
Figure 2: SFML: the domain of sorted logical for-
mulas.
</figureCaption>
<bodyText confidence="0.988693333333333">
position, with the notion of iterated application of
(5.
We will assume that there is a partial order,
defined on S. This ordering is such that the great-
est lower bound of any two sorts is unique, if it
exists. In other words, (S U {1}, --‹) is a meet-
semilattice (where 1 represents inconsistency or
failure). This allows us to define the most general
unifier of two sorts as their greatest lower bound,
which write as aAsb. We also assume that there is
a most general sort, T, called top. The structure
(5,-0 is called the sort hierarchy.
</bodyText>
<sectionHeader confidence="0.987416" genericHeader="method">
KASPER-ROUNDS LOGIC
</sectionHeader>
<bodyText confidence="0.934646">
(Kasper 1988) provides a logic for describing fea-
ture structures. Fig. 2 shows the domain of these
logical formulas. We use the standard notion of
satisfaction. Let A = (Q, r, 6, 0).
</bodyText>
<listItem confidence="0.996772142857143">
1. A k TRUE always;
2. A 1= FALSE never;
3. A k a &lt;==&gt; e(r) a;
4. A k P2 44=&apos; 6(r, pi) = (5(r, P2);
5. Ak f:0-.Alf is defined and All k
6. Ak0A0-4==&gt;AkOandAkik;
7. AHOVO-4=4iorA
</listItem>
<bodyText confidence="0.9972288">
Note that item 3 is different than Kasper&apos;s original
formulation. Kasper was working with a flat sort
hierarchy and a version of FSs that allowed sorts
only on sink nodes. The revised version allows for
order-sorted hierarchies and internal sorted nodes.
</bodyText>
<sectionHeader confidence="0.949882" genericHeader="method">
NONMONOTONIC SORTS
</sectionHeader>
<bodyText confidence="0.955936083333333">
Figure 3 shows a lexical inheritance hierarchy for
a subset of German verbs. The hierarchy specifies
strict (isa) and default (default) values for various
suffixes. If we ignore the difference between strict
and default values, we find that the information
specified for the past participle of mahl is inconsis-
tent. The MIDDLE-VERB template gives +en as
the suffix, while VERB gives +t. The declaration
of the latter as a default tells the system that it
should be dropped in favour of the former. The
method of nonmonotonic sorts formalizes this no-
tion of separating strict from default information.
Definition 2 A nonmonotonic sort is a pair (s, A)
where s E S, and A C S such that for each d E A,
d s.
The first element, s, represents the strict informa-
tion. The default sorts are gathered together in A.
We write H for the set of nonmonotonic sorts.
Given a pair of nonmonotonic sorts, we can unify
them to get a third NS that represents their com-
bined information.
Definition 3 The nonmonotonic sort unifier of
nonmonotonic sorts (s1, Ai) and (s2, A2) is the
nonmonotonic sort (s, A) where
</bodyText>
<listItem confidence="0.998847">
• s = s1A5s2, and
• A = IdAss I d E L U .6.2 A (dAss) sl.
</listItem>
<bodyText confidence="0.996598214285714">
The nonmonotonic sort unifier is undefined if
s1Ass2 is undefined. We write n1Ayn2 for the NS
unifier of n1 and n2.
The method strengthens consistent defaults while
eliminating redundant and inconsistent ones. It
should be clear from this definition that NS unifica-
tion is both commutative and associative. Thus we
may speak of the NS unifier of a set of NSs, with-
out regard to the order those NSs appear. Looking
back to our German verbs example, the past par-
ticiple suffix in VERB is (T, 1+4), while that of
MIDDLE-VERB is (+en, {}). The lexical entry for
mahl gets their nonmonotonic sort unifier, which is
(+en, {})• If +tAs+en had been defined, and equal
</bodyText>
<page confidence="0.988387">
210
</page>
<bodyText confidence="0.999308166666667">
to, say, +ten, then the NS unifier of (T, {-1-t}) and
(+en, {}) would have been (+en, {+ten}).
Once we have nonmonotonic sorts, we can create
nonmonotonically sorted feature structures (NS-
FSs) by replacing the function 0 :Q—Sby a
function Q : Q N. The nodes of the graph
are thus labeled by NSs instead of the usual sorts.
NSFSs may be unified by the same procedures as
before, only replacing sort unification at the nodes
with nonmonotonic sort unification. NSFS unifi-
cation, written with the symbol nN, is associative
and commutative.
NSFSs allow us to carry around default sorts, but
has so far given us no way to apply them. When
we are done collecting information, we will want
to return to the original system of FSs, using all
and only the applicable defaults. To do that, we
introduce the notions of explanation and solution.
</bodyText>
<construct confidence="0.995288">
Definition 4 A sort t is said to be explained by a
nonmonotonic sort (s, A) if there is aDCA such
that t = sAs(Asp)- If t is a maximally specific
explained sort, then t is called a solution of n.
</construct>
<bodyText confidence="0.945901389830509">
The solutions for (+en, {}) and (T, +t}) are +en
and +t respectively. The latter NS also explains T.
Note that, while D is maximal, it&apos;s not necessar-
ily the case that D = Z1. If we have mutually incon-
sistent defaults in A, then we will have more than
one maximal consistent set of defaults, and thus
more than one solution. On the other hand, strict
information can eliminate defaults during unifica-
tion. That means that a particular template can
inherit conflicting defaults and still have a unique
solution—provided that enough strict information
is given to disambiguate.
NSFS solutions are defined in much the same way
as NS solutions.
Definition 5 A FS (Q,r,(5,0) is said to be ex-
plained by a NSFS (Q,r,6,Q) if for each node
q E Q we have 12(q) explains 0(q). If A is a max-
imally specific explained FS, then A is called a so-
lution.
If we look again at our German verbs example, we
can see that the solution we get for mahl is the FS
that we want. The inconsistent default suffix +1
has been eliminated by the strict +en, and the sole
remaining default must be applied.
For the generic way we have defined feature
structures, a NSFS solution can be obtained sim-
ply by taking NS solutions at each node. More
restricted versions of FSs may require more care.
For instance, if sorts are not allowed on internal
nodes, then defining an attribute for a node will
eliminate any default sorts assigned to that node.
Another example where care must be taken is with
typed feature structures (Carpenter 1992). Here
the application of a default at one node can add
strict information at another (possibly making a
default at the other node inconsistent). The defini-
tion of NSFS solution handles both of these cases
(and others) by requiring that the solution be a
FS as the original system defines them. In both
of these cases, however, the work can be (at least
partially) delegated to the unification routine (in
the former by allowing labels with only defaults
to be removed when attributes are defined, and in
the latter by propagating type restrictions on strict
sorts).
What is done in other systems in one step has
been here broken into two steps—gathering infor-
mation and taking a solution. It is important that
the second step be carried out appropriately, since
it re-introduces the nonmonotonicity that we&apos;ve
taken out of the first step. For a lexicon, templates
exist in order to organize information about words.
Thus it is appropriate to take the solution of a lex-
ical entry (which corresponds to a word) but not of
a higher template (which does not). If the lexicon
were queried for the lexical entry for mahl, then, it
would collect the information from all appropriate
templates using NSFS unification, and return the
solution of that NSFS as the result.
</bodyText>
<sectionHeader confidence="0.971632" genericHeader="method">
DEFAULT LOGIC
</sectionHeader>
<bodyText confidence="0.999896166666666">
The semantics for nonmonotonic sorts is motivated
by default logic (Reiter 1980). What we want a
default sort to mean is: &amp;quot;if it is consistent for this
node to have that sort, then it does.&amp;quot; But where
Reiter based his DL on a first order language, we
want to base ours on Kasper-Rounds logic. This
will require some minor alterations to Reiter&apos;s for-
malism.
A default theory is a pair (D, W) where D is a
set of default inferences and W is a set of sentences
from the underlying logic. The default inferences
are triples, written in the form
</bodyText>
<equation confidence="0.866112">
:M 13
</equation>
<bodyText confidence="0.910315777777778">
Each of the greek letters here represents a wff from
the logic. The meaning of the default inference is
that if a is believed and it is consistent to assume
(3, then 7 can be believed.
Given a default theory (D, W), we are interested
in knowing what can we believe. Such a set of be-
liefs, called an extension, is a closure of W under
the usual rules of inference combined with the de-
fault rules of inference given in D. An extension
E is a minimal closed set containing W and such
that if a :M fl/7 is a default, and if a E E and #
consistent with E then 7 E E (that is, if we believe
a and 13 is consistent with what we believe, then
we also believe 7) .
Reiter can test a formula for consistency by test-
ing for the absence of its negation. Since Kasper-
Rounds logic does not have negation, we will not be
able to do that. Fortunately, we have do have our
</bodyText>
<page confidence="0.993378">
211
</page>
<bodyText confidence="0.998886210526316">
own natural notion of consistency—a set of formu-
las is consistent if it is satisfiable. Testing a set of
Kasper-Rounds formulas for consistency thus sim-
ply reduces to finding a satisfier for that set.
Formally, we encode our logic as an information
system (Scott 1982). An information system (IS)
is a triple (A, C,1-) where A is a countable set of
&amp;quot;atoms,&amp;quot; Cis a class of finite subsets of A, and F- is
a binary relation between subsets of A and elements
of A. A set X is said to be consistent if every finite
subset of X is an element of C. A set G is closed if
for every X C G such that X I- a, we have a E G.
Following the style used for information systems,
we will write G for the closure of G.
In our case, A is the wffs of SFML (except
FALSE), and C is the class of satisfiable sets. The
entailment relation encodes the semantics of the
particular unification system we are using. That
is, we have
</bodyText>
<equation confidence="0.952773333333333">
r FP if V F.F Ar F 13.
For instance,
P1 = P2, P2 = P3 FP1 = P3
</equation>
<bodyText confidence="0.868538">
represents the transitivity of path equations.
</bodyText>
<sectionHeader confidence="0.9804355" genericHeader="method">
DEFAULT KASPER-ROUNDS
LOGIC
</sectionHeader>
<bodyText confidence="0.928766333333333">
In the previous section we described the generic
form of default logic. We will not need the full
generality to describe default sorts. We will re-
strict our attention to closed precondition-free nor-
mal defaults. That is, all of our defaults will be of
the form:
</bodyText>
<equation confidence="0.9811285">
:M /3
i3
</equation>
<bodyText confidence="0.99674668">
We will write Dp as an abbreviation for this default
inference. Here stands for a generic wff from the
base language. Even this is more general than we
truly need, since we are really only interested in
default sorts. Nevertheless, we will prove things in
the more general form.
Note that our default inferences are closed and
normal. This means that we will always have an
extension and that the extension(s) will be consis-
tent if and only if W is consistent. These follow
from our equivalents of Reiter&apos;s theorem 3.1 and
corollaries 2.2 and 2.3.
Let&apos;s consider now how we would represent the
information in Fig. 3 in terms of Kasper-Rounds
default logic. The strict statements become normal
KR formulas in W. For instance, the information
for MIDDLE-VERBs (not counting the inheritance
information) is represented as follows:
({}, {past : participle : suffix : +en})
The information for VERB will clearly involve
some defaults. In particular, we have two paths
leading to default sorts. We interpret these state-
ments as saying that the path exists, and that it has
the value indicated by default. Thus we represent
the VERB template as:
</bodyText>
<equation confidence="0.9874812">
D = {Dpast:tense:suf fix:+te)
past.partscaple.suf f
W = {past : tense : suffix : T,
past : participle : suffix : T,
past : participle : prefix : ge+}
</equation>
<bodyText confidence="0.9875685">
Inheritance is done simply by pair-wise set union of
ancestors in the hierarchy. Since the entry for mahl
contains no local information, the full description
for it is simply the union of the two sets above.
</bodyText>
<equation confidence="0.9432525">
D = { Dpasi:tense:su f fix:+te
Dpost:participle:suf fix:+t})
W = {past : tense : suffix : T,
past : participle : suffix : T,
past : participle : prefix : ge+,
past : participle : suffix : +en}
</equation>
<bodyText confidence="0.99967125">
We can then find an extension for that default the-
ory and take the most general satisfier for that for-
mula. It is easy to see that the only extension for
mahl is the closure of:
</bodyText>
<construct confidence="0.889668666666667">
past : tense : suffix : +te,
past : participle : suffix : +en,
past : participle : prefix : ge+
</construct>
<bodyText confidence="0.999765666666667">
The default suffix +t is not applicable for the past
participle due to the presence of +en. The suffix
+te is applicable and so appears in the extension.
</bodyText>
<sectionHeader confidence="0.9933635" genericHeader="method">
DKRL AND NONMONOTONIC
SORTS
</sectionHeader>
<bodyText confidence="0.999564333333333">
In the previous section we defined how to get the
right answers from a system using default sorts. In
this section we will show that the method of non-
monotonic sorts gives us the same answers. First
we formalize the relation between NSFSs and de-
fault logic.
</bodyText>
<construct confidence="0.608141333333333">
Definition 6 Let V = (Q, r, 6, 12) be a nonrnono-
tonically sorted feature structure. The default the-
ory of D is
</construct>
<equation confidence="0.990166333333333">
DT(D) = ({Dp: I Q(6(r,p)) = (s, A) At E A},
{{Pi P2} I (5(r = 6(r, P2)}
U fp :s I C2(b(r,p)) = (s, A)})
</equation>
<bodyText confidence="0.998201666666667">
The default part of DT(D) encodes the default
sorts, while the strict part encodes the path equa-
tions and strict sorts.
</bodyText>
<construct confidence="0.871748333333333">
Theorem 1 The FS A is a solution for the NSFS
D if and only if {0 I A k of is an extension of
DT(D).
</construct>
<page confidence="0.998321">
212
</page>
<bodyText confidence="0.9070564">
Because we are dealing with closed normal default
theories, we can form extensions simply by taking
maximal consistent sets of defaults. This, of course,
is also how we form solutions, so the the solution
of a NSFS is an extension of its default theory.
We now need to show that NSFS unification be-
haves properly. That is, we must show that non-
monotonic sort unification doesn&apos;t create or destroy
extensions. We will write (D1, W1)=A (D2, W2) to
indicate that (D1, WO and (D2, W2) have the same
set of extensions. We will do this by combining a
number of intermediate results.
Theorem 2 Let (D, W) be a closed normal default
theory.
I. If a A [3 &lt;#. 7,
</bodyText>
<listItem confidence="0.8830785">
then (D,W U {cr A f3})--zA(D,W U {7}).
2. If W U{P} is inconsistent,
then (DU {Dp},W)=A(D,W).
3. 11W )3, then (D U {Dp},W)=A(D,W).
4. W}-c and ce A 7,
then (DU {Dp},W)=A(D U lay}, W).
</listItem>
<bodyText confidence="0.999581117647059">
The formulas a and 13 represent the (path pre-
fixed) sorts to be unified, and -y their (path pre-
fixed) greatest lower bound. The first part deals
with strict sort unification, and is a simple conse-
quence of the fact that (D, W) has the same exten-
sions as (D, W). The next two deal with inconsis-
tent and redundant default sorts. They are simi-
lar to theorems proved in (Delgrande and Jackson
1991): inconsistent defaults are never applicable;
while necessary ones are always applicable. The
last part allows for strengthening of default sorts.
It follows from the previous three. Together they
show that nonmonotonic unification preserves the
information present in the NSFSs being unified.
Theorem 3 Let D1 and D2 be NSFSs. Then
DT(DinND2)=--ADT(Di) U DT(D2) (using pair-
wise set union).
</bodyText>
<sectionHeader confidence="0.994206" genericHeader="discussions">
DISCUSSION
</sectionHeader>
<bodyText confidence="0.9997245">
Most treatments of default unification to date have
been presented very informally. (Bouma 1992)
and (Russell et al. 1992), however, provide very
thorough treatments of their respective methods.
Bouma&apos;s is more traditional in that it relies on
&amp;quot;subtracting&amp;quot; inconsistent information from the de-
fault side of the unification. The method given in
this paper is similar to Russell&apos;s method in that
it relies on consistency to decide whether default
information should be added.
Briefly, Bouma defines a default unification op-
eration AU!B = (A — B)U B, where A — B is de-
rived from A by eliminating any path that either
gets a label or shares a value in B. In the lexi-
con, each template has both &amp;quot;strict&amp;quot; and &amp;quot;default&amp;quot;
information. The default information is combined
</bodyText>
<figure confidence="0.998579714285714">
A template
&lt;f&gt; isa a
&lt;g&gt; default b
B template
&lt;f&gt; default c
&lt;g&gt; isa d
C lex A B
</figure>
<figureCaption confidence="0.99997">
Figure 4: Multiple Default Inheritance
</figureCaption>
<bodyText confidence="0.998194166666667">
with the inherited information by the usual unifica-
tion. This information is then combined (using U!)
with the strict information to derive the FS associ-
ated with the template. This FS is then inherited
by any children of the template.
Note that the division into &amp;quot;strict&amp;quot; and &amp;quot;default&amp;quot;
for Bouma is only local to the template. At the
next level in the hierarchy, what was strict becomes
default. Thus &amp;quot;defaultness&amp;quot; is not a property of the
information itself, as it is with NSs, but rather a
relation one piece of information has to another.
The method described in (Russell et al. 1992)
also divides templates into strict and default
parts&apos;. Here, though, the definitions of strict and
default are closer to our own. Each lexical entry
inherits from a list of templates, which are scanned
in order. Starting from the lexical entry, at each
template the strict information is added, and then
all consistent defaults are applied.
The list of templates that the lexical entry in-
herits from is generated by a topological sort of the
inheritance hierarchy. Thus the same set may give
two different results based on two different order-
ings. This approach to multiple inheritance allows
for conflicts between defaults to be resolved. Note,
however, that if template A gets scanned before
template B, then A must not contain any defaults
that conflict with the strict information in template
B. Otherwise we will get a unification failure, as
the default in A will already have been applied
when we reach B. With NSs, the strict informa-
tion will always override the default, regardless of
the order information is received.
The treatment of default information with NSs
allows strict and default information to be inherited
from multiple parents. Consider Fig. 4. Assuming
that the sorts do not combine at all, the resulting
FS for lexical entry C should be
f:al
Lg:d
The two methods mentioned above would fail to get
any answer for C: one default or the other would
</bodyText>
<footnote confidence="0.637143">
&apos;There may actually be multiple strict parts, which
are treated as disjuncts, but that is not pertinent to the
comparison.
</footnote>
<page confidence="0.998174">
213
</page>
<bodyText confidence="0.999993608695652">
be applied before the other template was even con-
sidered. In order to handle this example correctly,
they would have to state C&apos;s properties directly.
One advantage of both Bouma and Russell is
that exceptions to exceptions are allowed. With
nonmonotonic sorts as we have presented them
here, we would get conflicting defaults and thus
multiple answers. However, it is straight-forward
to add priorities to defaults. Each solution has a
unique set of defaults it uses, and so we can com-
pare the priorities of various solutions to choose the
most preferred one. The priority scheme can be any
partial order, though one that mirrored the lexical
inheritance hierarchy would be most natural.
Another advantage that both might claim is that
they deal with more than just default sorts. How-
ever, the theorems we proved above were proved
for generic wffs of Kasper-Rounds logic. Thus any
formula could be used as a default, and the only
question is how best to represent the information.
Nonmonotonic sorts are a concise and correct im-
plementation of the kind of default inheritance we
have defined here.
</bodyText>
<sectionHeader confidence="0.99419" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.988999408163266">
This paper has shown how the method of nonmono-
tonic sorts is grounded in the well-established the-
ories of Kasper-Rounds logic and Reiter&apos;s default
logic. This is, to our knowledge, the first attempt
to combine Reiter&apos;s theory with feature systems.
Most previous attempts to fuse defaults with fea-
ture structures have relied on procedural code—
a state of affairs that is highly inconsistent with
the declarative nature of feature systems. Meth-
ods that do not rely on procedures still suffer from
the necessity to specify what order information is
received in.
It seems to us that the major problem that has
plagued attempts to add defaults to feature systems
is the failure to recognize the difference in kind be-
tween strict and default information. The state-
ment that the present participle suffix for English
is `-l-ing&apos; is a very different sort of statement than
that the past participle suffix is `-Fed&apos; by default.
The former is unassailable information. The latter
merely describes a convention—that you should use
`-l-ed&apos; unless you&apos;re told otherwise. The method of
nonmonotonic sorts makes this important distinc-
tion between strict and default information. The
price of this method is in the need to find solu-
tions to NSFSs. But much of the cost of finding
solutions is dissipated through the unification pro-
cess (through the elimination of inconsistent and
redundant defaults). In a properly designed lexi-
con there will be only one solution, and that can
be found simply by unifying all the defaults present
(getting a unification failure here means that there
is more than one solution—a situation that should
indicates an error).
The semantics given for NSs can be extended in
a number of ways. In particular, it suggests a se-
mantics for one kind of default unification. It is
possible to say that two values are by default equal
by giving the formula D • . This would be useful
P1=P2
in our German verbs example to specify that the
past tense root is by default equal to the present
tense root. This would fill in roots for spiel and
mahl without confounding zwing. Another exten-
sion is to use a prioritized default logic to allow for
resolution of conflicts between defaults. The nat-
ural prioritization would be parallel to the lexicon
structure, but others could be imposed if they made
more sense in the context.
</bodyText>
<sectionHeader confidence="0.998426" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999165425">
Bouma, Gosse 1990. Defaults in unification gram-
mar. In Proceedings of the 1990 Conference of the
Association for Computational Linguistics. 165-
172.
Bouma, Gosse 1992. Feature structures and
nonmonotonicity. Computational Linguistics
18(2):183-203.
Carpenter, Bob 1991. Skeptical and credulous de-
fault unification with applications to templates
and inheritance. In Default Inheritance Within
Unification-Based Approaches to the Lexicon.
Carpenter, Bob 1992. The Logic of Typed Feature
Structures. Cambridge University Press.
Delgrande, James P and Jackson, W Ken 1991.
Default logic revisited. In Proceedings of the Sec-
ond International Conference on the Principles of
Knowledge Representation and Reasoning. 118-
127.
Kaplan, Ronald 1987. Three seductions of com-
putational linguistics. In Linguistic Theory and
Computer Applications. Academic Press, London.
149-188.
Kasper, Bob 1988. Feature Structures: A Logical
Theory with Applications to Language Analysis.
Ph.D. Dissertation, University of Michigan, Ann
Arbor.
Reiter, Ray 1980. A logic for default reasoning.
Artificial Intelligence 13:81-132.
Russell, Graham; Ballim, Afzal; Carroll, John;
and Warwick-Armstrong, Susan 1992. A practi-
cal approach to multiple default inheritance for
unification-based lexicons. Computational Lin-
guistics 18(3):311-337.
Scott, Dana 1982. Domains for Denotational Se-
mantics, volume 140 of Lecture Notes in Computer
Science.
Shieber, Stuart 1986. An Introduction to
Unification-Based Approaches to Grammar, vol-
ume 4 of CSLI Lecture Notes. University of
Chicago Press, Chicago.
</reference>
<page confidence="0.985271">
214
</page>
<reference confidence="0.989707">
Shieber, Stuart 1987. Separating linguistic anal-
yses from linguistic theories. In Linguistic The-
ory and Computer Applications. Academic Press,
London. 1-36.
Young, Mark 1992. Nonmonotonic sorts for fea-
ture structures. In National Conference on Arti-
ficial Intelligence, San Jose, California. 596-601.
</reference>
<page confidence="0.999141">
215
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898956">
<title confidence="0.986269">Abstract A LOGICAL SEMANTICS FOR NONMONOTONIC SORTS</title>
<author confidence="0.999983">Mark A Young</author>
<author confidence="0.999983">Bill Rounds</author>
<affiliation confidence="0.9999905">Artificial Intelligence Laboratory The University of Michigan</affiliation>
<address confidence="0.9980925">1101 Beal Ave. Ann Arbor, MI 48109</address>
<email confidence="0.989568">marky,roundsOengin.umich.edu</email>
<abstract confidence="0.997756384615385">The original presentation of nonmonotonic sorts provided only a description of their operation and an informal description of their meaning. In this paper, we present a logical basis for NSs and nonmonotonically sorted feature structures (NSFSs). NSFSs are shown to be equivalent to default theories of default logic (Reiter 1980). In particular, we show how nonmonotonic sort unification is equivalent to finding the smallest default theory that describes both NSFSs; and also how taking a solution for a NSFS is the same as finding an extension for that theory. Suppose we have a feature system, and we wish to add default values in a well-defined way. We might start with Kasper-Rounds logic, and use Reiter&apos;s example to form it into a default logic. Giving a node a default value would be equivalent to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
</authors>
<title>Defaults in unification grammar.</title>
<date>1990</date>
<booktitle>In Proceedings of the 1990 Conference of the Association for Computational Linguistics.</booktitle>
<pages>165--172</pages>
<contexts>
<context position="1544" citStr="Bouma 1990" startWordPosition="248" endWordPosition="249"> it into a default logic. Giving a node a default value would be equivalent to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented</context>
</contexts>
<marker>Bouma, 1990</marker>
<rawString>Bouma, Gosse 1990. Defaults in unification grammar. In Proceedings of the 1990 Conference of the Association for Computational Linguistics. 165-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
</authors>
<title>Feature structures and nonmonotonicity.</title>
<date>1992</date>
<journal>Computational Linguistics</journal>
<pages>18--2</pages>
<contexts>
<context position="1556" citStr="Bouma 1992" startWordPosition="250" endWordPosition="251">efault logic. Giving a node a default value would be equivalent to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1</context>
<context position="18716" citStr="Bouma 1992" startWordPosition="3354" endWordPosition="3355">ith inconsistent and redundant default sorts. They are similar to theorems proved in (Delgrande and Jackson 1991): inconsistent defaults are never applicable; while necessary ones are always applicable. The last part allows for strengthening of default sorts. It follows from the previous three. Together they show that nonmonotonic unification preserves the information present in the NSFSs being unified. Theorem 3 Let D1 and D2 be NSFSs. Then DT(DinND2)=--ADT(Di) U DT(D2) (using pairwise set union). DISCUSSION Most treatments of default unification to date have been presented very informally. (Bouma 1992) and (Russell et al. 1992), however, provide very thorough treatments of their respective methods. Bouma&apos;s is more traditional in that it relies on &amp;quot;subtracting&amp;quot; inconsistent information from the default side of the unification. The method given in this paper is similar to Russell&apos;s method in that it relies on consistency to decide whether default information should be added. Briefly, Bouma defines a default unification operation AU!B = (A — B)U B, where A — B is derived from A by eliminating any path that either gets a label or shares a value in B. In the lexicon, each template has both &amp;quot;stri</context>
</contexts>
<marker>Bouma, 1992</marker>
<rawString>Bouma, Gosse 1992. Feature structures and nonmonotonicity. Computational Linguistics 18(2):183-203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Skeptical and credulous default unification with applications to templates and inheritance. In Default Inheritance Within Unification-Based Approaches to the Lexicon.</title>
<date>1991</date>
<contexts>
<context position="1572" citStr="Carpenter 1991" startWordPosition="252" endWordPosition="253">. Giving a node a default value would be equivalent to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1992). The method</context>
</contexts>
<marker>Carpenter, 1991</marker>
<rawString>Carpenter, Bob 1991. Skeptical and credulous default unification with applications to templates and inheritance. In Default Inheritance Within Unification-Based Approaches to the Lexicon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures.</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10144" citStr="Carpenter 1992" startWordPosition="1775" endWordPosition="1776">n see that the solution we get for mahl is the FS that we want. The inconsistent default suffix +1 has been eliminated by the strict +en, and the sole remaining default must be applied. For the generic way we have defined feature structures, a NSFS solution can be obtained simply by taking NS solutions at each node. More restricted versions of FSs may require more care. For instance, if sorts are not allowed on internal nodes, then defining an attribute for a node will eliminate any default sorts assigned to that node. Another example where care must be taken is with typed feature structures (Carpenter 1992). Here the application of a default at one node can add strict information at another (possibly making a default at the other node inconsistent). The definition of NSFS solution handles both of these cases (and others) by requiring that the solution be a FS as the original system defines them. In both of these cases, however, the work can be (at least partially) delegated to the unification routine (in the former by allowing labels with only defaults to be removed when attributes are defined, and in the latter by propagating type restrictions on strict sorts). What is done in other systems in </context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Carpenter, Bob 1992. The Logic of Typed Feature Structures. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James P Delgrande</author>
<author>W Ken Jackson</author>
</authors>
<title>Default logic revisited.</title>
<date>1991</date>
<booktitle>In Proceedings of the Second International Conference on the Principles of Knowledge Representation and Reasoning.</booktitle>
<pages>118--127</pages>
<contexts>
<context position="18218" citStr="Delgrande and Jackson 1991" startWordPosition="3279" endWordPosition="3282">losed normal default theory. I. If a A [3 &lt;#. 7, then (D,W U {cr A f3})--zA(D,W U {7}). 2. If W U{P} is inconsistent, then (DU {Dp},W)=A(D,W). 3. 11W )3, then (D U {Dp},W)=A(D,W). 4. W}-c and ce A 7, then (DU {Dp},W)=A(D U lay}, W). The formulas a and 13 represent the (path prefixed) sorts to be unified, and -y their (path prefixed) greatest lower bound. The first part deals with strict sort unification, and is a simple consequence of the fact that (D, W) has the same extensions as (D, W). The next two deal with inconsistent and redundant default sorts. They are similar to theorems proved in (Delgrande and Jackson 1991): inconsistent defaults are never applicable; while necessary ones are always applicable. The last part allows for strengthening of default sorts. It follows from the previous three. Together they show that nonmonotonic unification preserves the information present in the NSFSs being unified. Theorem 3 Let D1 and D2 be NSFSs. Then DT(DinND2)=--ADT(Di) U DT(D2) (using pairwise set union). DISCUSSION Most treatments of default unification to date have been presented very informally. (Bouma 1992) and (Russell et al. 1992), however, provide very thorough treatments of their respective methods. Bou</context>
</contexts>
<marker>Delgrande, Jackson, 1991</marker>
<rawString>Delgrande, James P and Jackson, W Ken 1991. Default logic revisited. In Proceedings of the Second International Conference on the Principles of Knowledge Representation and Reasoning. 118-127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
</authors>
<title>Three seductions of computational linguistics.</title>
<date>1987</date>
<booktitle>In Linguistic Theory and Computer Applications.</booktitle>
<pages>149--188</pages>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="1585" citStr="Kaplan 1987" startWordPosition="254" endWordPosition="255">a default value would be equivalent to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1992). The method of nonmonoto</context>
</contexts>
<marker>Kaplan, 1987</marker>
<rawString>Kaplan, Ronald 1987. Three seductions of computational linguistics. In Linguistic Theory and Computer Applications. Academic Press, London. 149-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Kasper</author>
</authors>
<title>Feature Structures: A Logical Theory with Applications to Language Analysis.</title>
<date>1988</date>
<institution>University of Michigan,</institution>
<location>Ann Arbor.</location>
<note>Ph.D. Dissertation,</note>
<contexts>
<context position="5172" citStr="Kasper 1988" startWordPosition="877" endWordPosition="878">the domain of sorted logical formulas. position, with the notion of iterated application of (5. We will assume that there is a partial order, defined on S. This ordering is such that the greatest lower bound of any two sorts is unique, if it exists. In other words, (S U {1}, --‹) is a meetsemilattice (where 1 represents inconsistency or failure). This allows us to define the most general unifier of two sorts as their greatest lower bound, which write as aAsb. We also assume that there is a most general sort, T, called top. The structure (5,-0 is called the sort hierarchy. KASPER-ROUNDS LOGIC (Kasper 1988) provides a logic for describing feature structures. Fig. 2 shows the domain of these logical formulas. We use the standard notion of satisfaction. Let A = (Q, r, 6, 0). 1. A k TRUE always; 2. A 1= FALSE never; 3. A k a &lt;==&gt; e(r) a; 4. A k P2 44=&apos; 6(r, pi) = (5(r, P2); 5. Ak f:0-.Alf is defined and All k 6. Ak0A0-4==&gt;AkOandAkik; 7. AHOVO-4=4iorA Note that item 3 is different than Kasper&apos;s original formulation. Kasper was working with a flat sort hierarchy and a version of FSs that allowed sorts only on sink nodes. The revised version allows for order-sorted hierarchies and internal sorted node</context>
</contexts>
<marker>Kasper, 1988</marker>
<rawString>Kasper, Bob 1988. Feature Structures: A Logical Theory with Applications to Language Analysis. Ph.D. Dissertation, University of Michigan, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Reiter</author>
</authors>
<title>A logic for default reasoning.</title>
<date>1980</date>
<journal>Artificial Intelligence</journal>
<pages>13--81</pages>
<contexts>
<context position="11501" citStr="Reiter 1980" startWordPosition="2004" endWordPosition="2005">ropriately, since it re-introduces the nonmonotonicity that we&apos;ve taken out of the first step. For a lexicon, templates exist in order to organize information about words. Thus it is appropriate to take the solution of a lexical entry (which corresponds to a word) but not of a higher template (which does not). If the lexicon were queried for the lexical entry for mahl, then, it would collect the information from all appropriate templates using NSFS unification, and return the solution of that NSFS as the result. DEFAULT LOGIC The semantics for nonmonotonic sorts is motivated by default logic (Reiter 1980). What we want a default sort to mean is: &amp;quot;if it is consistent for this node to have that sort, then it does.&amp;quot; But where Reiter based his DL on a first order language, we want to base ours on Kasper-Rounds logic. This will require some minor alterations to Reiter&apos;s formalism. A default theory is a pair (D, W) where D is a set of default inferences and W is a set of sentences from the underlying logic. The default inferences are triples, written in the form :M 13 Each of the greek letters here represents a wff from the logic. The meaning of the default inference is that if a is believed and it </context>
</contexts>
<marker>Reiter, 1980</marker>
<rawString>Reiter, Ray 1980. A logic for default reasoning. Artificial Intelligence 13:81-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Russell</author>
<author>Afzal Ballim</author>
<author>John Carroll</author>
<author>Warwick-Armstrong</author>
</authors>
<title>A practical approach to multiple default inheritance for unification-based lexicons.</title>
<date>1992</date>
<journal>Computational Linguistics</journal>
<pages>18--3</pages>
<contexts>
<context position="18742" citStr="Russell et al. 1992" startWordPosition="3357" endWordPosition="3360">and redundant default sorts. They are similar to theorems proved in (Delgrande and Jackson 1991): inconsistent defaults are never applicable; while necessary ones are always applicable. The last part allows for strengthening of default sorts. It follows from the previous three. Together they show that nonmonotonic unification preserves the information present in the NSFSs being unified. Theorem 3 Let D1 and D2 be NSFSs. Then DT(DinND2)=--ADT(Di) U DT(D2) (using pairwise set union). DISCUSSION Most treatments of default unification to date have been presented very informally. (Bouma 1992) and (Russell et al. 1992), however, provide very thorough treatments of their respective methods. Bouma&apos;s is more traditional in that it relies on &amp;quot;subtracting&amp;quot; inconsistent information from the default side of the unification. The method given in this paper is similar to Russell&apos;s method in that it relies on consistency to decide whether default information should be added. Briefly, Bouma defines a default unification operation AU!B = (A — B)U B, where A — B is derived from A by eliminating any path that either gets a label or shares a value in B. In the lexicon, each template has both &amp;quot;strict&amp;quot; and &amp;quot;default&amp;quot; informat</context>
<context position="20090" citStr="Russell et al. 1992" startWordPosition="3593" endWordPosition="3596">4: Multiple Default Inheritance with the inherited information by the usual unification. This information is then combined (using U!) with the strict information to derive the FS associated with the template. This FS is then inherited by any children of the template. Note that the division into &amp;quot;strict&amp;quot; and &amp;quot;default&amp;quot; for Bouma is only local to the template. At the next level in the hierarchy, what was strict becomes default. Thus &amp;quot;defaultness&amp;quot; is not a property of the information itself, as it is with NSs, but rather a relation one piece of information has to another. The method described in (Russell et al. 1992) also divides templates into strict and default parts&apos;. Here, though, the definitions of strict and default are closer to our own. Each lexical entry inherits from a list of templates, which are scanned in order. Starting from the lexical entry, at each template the strict information is added, and then all consistent defaults are applied. The list of templates that the lexical entry inherits from is generated by a topological sort of the inheritance hierarchy. Thus the same set may give two different results based on two different orderings. This approach to multiple inheritance allows for co</context>
</contexts>
<marker>Russell, Ballim, Carroll, Warwick-Armstrong, 1992</marker>
<rawString>Russell, Graham; Ballim, Afzal; Carroll, John; and Warwick-Armstrong, Susan 1992. A practical approach to multiple default inheritance for unification-based lexicons. Computational Linguistics 18(3):311-337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Scott</author>
</authors>
<title>Domains for Denotational Semantics,</title>
<date>1982</date>
<journal>Lecture Notes in Computer Science.</journal>
<volume>140</volume>
<contexts>
<context position="13096" citStr="Scott 1982" startWordPosition="2314" endWordPosition="2315">if a E E and # consistent with E then 7 E E (that is, if we believe a and 13 is consistent with what we believe, then we also believe 7) . Reiter can test a formula for consistency by testing for the absence of its negation. Since KasperRounds logic does not have negation, we will not be able to do that. Fortunately, we have do have our 211 own natural notion of consistency—a set of formulas is consistent if it is satisfiable. Testing a set of Kasper-Rounds formulas for consistency thus simply reduces to finding a satisfier for that set. Formally, we encode our logic as an information system (Scott 1982). An information system (IS) is a triple (A, C,1-) where A is a countable set of &amp;quot;atoms,&amp;quot; Cis a class of finite subsets of A, and F- is a binary relation between subsets of A and elements of A. A set X is said to be consistent if every finite subset of X is an element of C. A set G is closed if for every X C G such that X I- a, we have a E G. Following the style used for information systems, we will write G for the closure of G. In our case, A is the wffs of SFML (except FALSE), and C is the class of satisfiable sets. The entailment relation encodes the semantics of the particular unification </context>
</contexts>
<marker>Scott, 1982</marker>
<rawString>Scott, Dana 1982. Domains for Denotational Semantics, volume 140 of Lecture Notes in Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar,</title>
<date>1986</date>
<volume>4</volume>
<institution>CSLI Lecture Notes. University of Chicago Press,</institution>
<location>Chicago.</location>
<contexts>
<context position="1620" citStr="Shieber 1986" startWordPosition="260" endWordPosition="261">t to saying &amp;quot;if it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1992). The method of nonmonotonic sorts (NSs) allows default labe</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart 1986. An Introduction to Unification-Based Approaches to Grammar, volume 4 of CSLI Lecture Notes. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>Separating linguistic analyses from linguistic theories.</title>
<date>1987</date>
<booktitle>In Linguistic Theory and Computer Applications.</booktitle>
<pages>1--36</pages>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="1635" citStr="Shieber 1987" startWordPosition="262" endWordPosition="263">f it is consistent for this node to have that value, then it does.&amp;quot; Then we could use default theories to describe feature structures. The particular feature structure described would be the structure that supports the extension of the default theory. This is, in effect, what the theory of nonmonotonic sorts gives you. This paper describes how that theory derives from what is described above. INTRODUCTION There have been many suggestions for incorporating defaults into unification-based grammar formalisms (Bouma 1990; Bouma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1992). The method of nonmonotonic sorts (NSs) allows default labels to be assign</context>
</contexts>
<marker>Shieber, 1987</marker>
<rawString>Shieber, Stuart 1987. Separating linguistic analyses from linguistic theories. In Linguistic Theory and Computer Applications. Academic Press, London. 1-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Young</author>
</authors>
<title>Nonmonotonic sorts for feature structures.</title>
<date>1992</date>
<booktitle>In National Conference on Artificial Intelligence,</booktitle>
<pages>596--601</pages>
<location>San Jose, California.</location>
<contexts>
<context position="2160" citStr="Young 1992" startWordPosition="344" endWordPosition="345">ma 1992; Carpenter 1991; Kaplan 1987; Russell ei al. 1992; Shieber 1986; Shieber 1987). Each of these proposes a non-commutative, non-associative default unification operation that combines one structure representing strict information with another representing default information. When presented with a set of structures, the result depends on the order in which the structures are combined. This runs very much against the unification tradition, in which any set has a unique most general satisfier (if a satisfier exists at all). A method that is free of these ordering effects was presented in (Young 1992). The method of nonmonotonic sorts (NSs) allows default labels to be assigned at any time, and used only in the absence of conflicting information. NSs replace the more traditional labels on feature structures to give nonmonotonically sorted feature structures (NSFSs). These structures can be combined by an associative and commutative unification operation. FSs are rederived from NSFSs by taking a solution—an operation defined in terms of information present in the NSFS. FEATURE SYSTEMS Unification-based grammar formalisms use formal objects called feature structures to encode linguistic infor</context>
</contexts>
<marker>Young, 1992</marker>
<rawString>Young, Mark 1992. Nonmonotonic sorts for feature structures. In National Conference on Artificial Intelligence, San Jose, California. 596-601.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>