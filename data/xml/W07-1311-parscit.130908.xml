<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002481">
<title confidence="0.993472">
Visualizing the evaluation of distance measures
</title>
<author confidence="0.997982">
Thomas Pilz
</author>
<affiliation confidence="0.999773">
University of Duisburg-Essen
Faculty of Engineering
Department of Computer Science
</affiliation>
<email confidence="0.950053">
pilz@inf.uni-due.de
</email>
<author confidence="0.969477">
Axel Philipsenburg
</author>
<affiliation confidence="0.652496333333333">
University of Duisburg-Essen
axel.philipsenburg@uni-
due.de
</affiliation>
<author confidence="0.962034">
Wolfram Luther
</author>
<affiliation confidence="0.999541">
University of Duisburg-Essen
Faculty of Engineering
Department of Computer Science
</affiliation>
<email confidence="0.981486">
luther@inf.uni-due.de
</email>
<sectionHeader confidence="0.998518" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999826769230769">
This paper describes the development and
use of an interface for visually evaluating
distance measures. The combination of
multidimensional scaling plots, histograms
and tables allows for different stages of
overview and detail. The interdisciplinary
project Rule-based search in text databases
with nonstandard orthography develops a
fuzzy full text search engine and uses dis-
tance measures for historical text document
retrieval. This engine should provide easier
text access for experts as well as interested
amateurs.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999612071428571">
In recent years interest in historical digitization
projects has markedly increased, bearing witness to
a growing desire to preserve cultural heritage
through new media. All over Europe projects are
arising digitizing not only monetary but also intel-
lectually valuable text documents. While more and
more documents are being digitized and often pro-
vided with well designed interfaces, they are not
necessarily easy to work with, especially for
nonlinguists. Spelling variants, faulty character
recognition (OCR) and typing errors hamper if not
circumvent sensible utilization of the data. One
such example is the archive of Jewish periodicals
in German language, Compact Memory
(www.compactmemory.de). Even though of great
cultural value and very well maintained, the opera-
tors of this project simply did not have the re-
sources required to postprocess or annotate their
automatically recognized text documents. A user
for example searching for the word “Fruchtbarkeit”
(=fertility) will not be able to find a certain peri-
odical from 1904 even though it clearly contains
the word. Worse, he will not even come to know
that this text was missed. Because the full text
aligned with the graphical representation of the
text contains recognition errors, only the search for
the misspelled word “Piuchtbaikeit” instead of
“Fruchtbarkeit” finds the correct page (cf. Figure
1). The same problem arises when dealing with
historical spelling variation. German texts prior to
1901 often contain historical spelling variants.
Numerous projects are dealing with similar prob-
lems of optical character recognition or spelling
variation.
To meet those problems linguistics and com-
puter science are closing ranks. Fuzzy full-text
search functions provide access to nonstandard text
databases. Since the amount of data on the one
hand and the divergence of users on the other in-
creases day by day, search methods are continu-
ously presented with new challenges. The project
RSNSR (Rule-based search in text databases with
</bodyText>
<figureCaption confidence="0.975768">
Figure 1. OCR errors prevent successful retrieval on digitized texts if misspelled variants are used for full
</figureCaption>
<bodyText confidence="0.451297">
text search.
</bodyText>
<page confidence="0.983675">
84
</page>
<note confidence="0.601695">
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 84–92,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999735714285714">
nonstandard orthography) seeks to improve the
retrieval of nonstandard texts. Such texts might
include historical documents, texts with re-
gional/dialectal or phonetic variation, typos or
OCR errors. The project’s funding by the Deutsche
Forschungsgemeinschaft (DFG [German Research
Foundation]) was recently extended by two years.
</bodyText>
<sectionHeader confidence="0.917042" genericHeader="method">
2 Comparing similarity measures
</sectionHeader>
<bodyText confidence="0.9999828">
One of the important issues in building a search
engine for nonstandard spellings is a reliable way
to allow the comparison of words, that is, to meas-
ure the similarity between the search expression
and the results provided. Given the abundance of
distance measures and edit-distances available,
methods are needed for efficiently comparing dif-
ferent similarity measures. In (Kempken et al.
2006) we evaluated 13 different measures with the
calculation of precision and recall to determine
which were most qualified to deal with historical
German spelling variants. We mainly used our own
database of historical spellings, manually collected
from the German text archives Bibliotheca Augus-
tana, documentArchiv.de and Digitales Archiv
Hessen-Darmstadt. Currently our database consists
of 12,687 modern-historical word pairs (that we
call evidences) originating between 1293 and 1919.
The algorithm that proved best for calculating
the edit costs between the modern and the histori-
cal spellings is called Stochastic distance (SM) and
was originally proposed in 1975 by Bahl and
Jelinek. In 1997 Ristad and Yianilos (Ristad et al,
1997) took it up again and extended the approach
to machine learning abilities. Due to the complex-
ity of language, apparently similar scopes can ob-
viously favor totally different mechanisms. The
Variant Detector VARD developed by Rayson et
al. to detect spelling variants in historical English
texts uses the standard Soundex algorithm with
convincing efficiency (Rayson et al, 2005). The
same algorithm yields an error rate 6.7 times
higher than the stochastic distance for the compari-
son of German spelling variants. Cases like these
suggest that finding one “most suitable” distance
measure for all data might not be possible. As soon
as the inherent structures change, another measure
can prove to be more efficient. Even though, with
the SM, we already found a suitable measure, its
dependency on the underlying training data forces
us to evaluate the training results: what is the size
of an optimal training set? Is the training set well
chosen? Does 14th-century data appropriately rep-
resent 13th-century spellings? Answers to these and
similar questions not only help to ensure better
retrieval but can also give an insight into phonetic
or graphematic changes of language. Since stan-
dard calculations of retrieval quality, as we did for
the 13 measures, require not only extensive work
but are also difficult to evaluate, we propose possi-
bilities for visual evaluation means to speed up and
ease this process. The prototype we developed is
but one example for those possibilities and is
meant to encourage scientists to benefit from vis-
ual information representation.
</bodyText>
<sectionHeader confidence="0.99196" genericHeader="method">
3 Development and functions of an inter-
active visual interface
</sectionHeader>
<bodyText confidence="0.999974266666667">
Since our project already deals with different
methods for calculating word distance, the defini-
tion of a generic interface was necessary. Priority
was given to the development of a slim and easily
accessible device that allows the connection of ar-
bitrary concepts of word distance. Our SM, a rule
based measure using regular expressions, Soundex
(Knuth, 1973), Jaro(-Winkler) (Jaro, 1995) and a
number of additional measures are already imple-
mented in our system. It was built in Java and is
embedded in our general environment for the proc-
essing of nonstandard spellings.
Information Visualization is a fairly new field of
research that is rapidly evolving. A well estab-
lished definition of information visualization is
“the use of computer-supported, interactive, visual
representations of abstract data to amplify cogni-
tion” (Card et al, 1999). While planning the proto-
type, we also kept Shneiderman’s paradigm in
mind: “Overview first, zoom and filter details on
demand” (Shneiderman, 1996). In dealing with
distance measures, our main task is to represent
word distance. We employed multidimensional
scaling (MDS) to display abstract distance in 2D
space (see below). Interactivity is gained with the
ability to select and remove spellings from the cal-
culations, lower or raise cutoff frequencies and
filters and even change replacement costs with in-
stantaneous effect (see below). This led to a user
interface separated into three main views:
</bodyText>
<listItem confidence="0.964123">
• The Histogram allows an overview of
thousands of data items. The selection of a
</listItem>
<page confidence="0.997459">
85
</page>
<bodyText confidence="0.928482">
certain portion of data triggers MDS and ta-
ble views.
</bodyText>
<listItem confidence="0.992069777777778">
• Multidimensional Scaling (MDS) func-
tions as a detail view. Such visualization is
used to display sets of several dozen to a
few hundred items.
• The Table View can display different lev-
els of detail. In (Kempken et al, 2007) we
presented a TreeMap approach, another way
to display details of single word derivations
as an add-on for table views.
</listItem>
<subsectionHeader confidence="0.996154">
3.1 Histograms
</subsectionHeader>
<bodyText confidence="0.999963666666667">
Histograms are a widely spread tool for display of
statistical distribution of values. In favor of Shnei-
derman’s paradigm, the histogram view represents
a combination of overview and zoom functionality.
This first stage allows for the reduction of the data
set from up to several thousand items down to
much more manageable sizes.
To get a first impression of how a spelling dis-
tance performs on a set of evidences, we calculate
the distance between a spelling variant and the en-
tries in a dictionary. It is ensured that the collection
also contains the standard spelling related to the
variant. The results are sorted in ascending order
by their distance from the spelling variant. After-
wards, the rank of the corresponding spellings is
determined. In the best case, the correct relation
will appear as the first entry in this list, that is, at
the smallest distance from the variant. Often, other
spellings appear “closer” to the variant and thus
have a higher rank, pushing the spelling we sought
for further down the list (cf. Figure 2).
By applying this procedure to a collection of
word pairs, we get a distribution of spelling ranks
over the set of evidences based on the spelling col-
</bodyText>
<figureCaption confidence="0.91892">
Figure 2. The standard spelling &amp;quot;liebe&amp;quot; corre-
sponding to variant &amp;quot;liebd&amp;quot; was pushed back
by &amp;quot;lieb&amp;quot; because deletion of &lt;d&gt; is cheaper
than the replacement of &lt;d&gt; with &lt;e&gt;.
</figureCaption>
<bodyText confidence="0.999989533333334">
lection. Good distance measures produce a histo-
gram with most of its largest bars close to the first
rank on the left. A good example is the evaluation
in section 5 (cf. Figure 5).
The histogram provides a good representation of
the overall performance of a spelling distance
given for a set of test data. The user will quickly
notice if a large number of spellings are found in
the acceptable ranking range, if there are notice-
able isolated outliers or if the values are spread
widely over the whole interval. In addition, histo-
grams can be useful as tools for comparing differ-
ent spelling distances. Usually multiple histograms
are viewed one after another or arranged next to
each other. While this might be enough to perceive
considerable differences in distributions, small-
scale variations may pass unnoticed. An easy solu-
tion to this problem is to arrange the different his-
tograms in a combined display area, where the
relevant subinterval bars are lined up next to one
another and made distinguishable by color or tex-
ture. Through this simple rearrangement, even
small changes become noticeable to the user.
Slight height differences between bars of the same
value interval can be noticed as can shifts in peaks
along the value range.
For more quantitative performance measurement
mean value and standard deviation are calculated
and presented in numerical form. A distance defi-
nition that performs well will have a low mean
value as more spellings are found with a good
ranking. However, a mean value that is not espe-
cially high or low by itself is usually not enough to
characterize a distribution. For this reason, it is
important to know the values’ spread around the
distribution’s mean value measured by the standard
deviation (SD). A distribution with only a few,
tightly packed value peaks provides a small SD
whereas a widely spread one will have a large SD.
A spelling distance that performs well can be rec-
ognized by a low mean value accompanied by a
low SD. Both key values can also be made visible
in a histogram by drawing markers in its back-
ground. In this way, even the key values are easy
to compare when comparing spelling distances.
</bodyText>
<subsectionHeader confidence="0.999817">
3.2 Multidimensional scaling
</subsectionHeader>
<bodyText confidence="0.999953">
The MDS view displays smaller subsets, thus al-
lowing further refinement while providing addi-
tional information detail.
</bodyText>
<page confidence="0.979961">
86
</page>
<bodyText confidence="0.999979372093023">
MDS is a class of statistical methods that has its
roots in psychological research. The main applica-
tion of such techniques is to assign the elements of
an item set to a spatial configuration in such a way
that it represents the elements’ relationships with
as little distortion as possible. In this context, MDS
can be used to arrange spellings in a two-
dimensional space according to their spelling dis-
tances from one another. Every available dimen-
sion reduces the need for distortion but increases
the difficulty to interpret. Two or three dimensions
are a good trade-off. This allows for an intuitive
display of distances and clusters of spelling vari-
ants. It also makes it possible to discover distance
anomalies. If this representation is provided with
filtering features, it can be used to select subsets of
elements quickly and comfortably. These subsets
can then be displayed in detailed information
views that would be too cluttered with greater
numbers of items.
The “distortion” is evaluated by comparing the
distances calculated by the spelling distances with
the configuration’s geometric distances (i.e. dis-
tances following geometric rules). A common cal-
culation for this distortion is the so-called “raw
stress” factor. Kruskal (Kruskal, 1964) defined raw
stress as the sum of distance errors over a configu-
ration. To calculate this error, we use the distance
matrix D, where each entry holds the calculated
distance δij between the spellings of the relevant
row and column. These values can be modified by
f(δij)=a δij to achieve a scaling more fit for visual
distances, thus reducing stress. Comparison with
geometric distances also requires this matrix to be
symmetric. Because spelling distances are not nec-
essarily symmetric (distance A – B differs from B
– A), we use the mean value of both distance direc-
tions to create symmetry, as Kruskal suggests. The
second part of the error calculation requires the
geometric distances dij between the spellings,
which is determined by i and j of the current con-
figuration X. The actual error is the difference be-
tween the two distances squared.
</bodyText>
<equation confidence="0.935683">
2
(δij)−dij (X) J
eij =�f
</equation>
<figureCaption confidence="0.9879445">
Figure 3. The user interface of the Metric Evaluation Tool showing the evaluation of six metrics
trained on different historical training sets, polygon selection in the MDS view and cut-off sliders.
</figureCaption>
<page confidence="0.993469">
87
</page>
<bodyText confidence="0.9998438">
Kruskal’s “raw stress” value is then determined
by summarizing the error over the elements of the
upper triangular matrix. The sum can be restricted
to this reduced element set due to the symmetric
nature of the matrix.
</bodyText>
<equation confidence="0.9622975">
∑ [ f δ ij d ij X
( ) ( )
−
( )
i j
&lt;
</equation>
<bodyText confidence="0.99977776">
In our Metric Evaluation Tool (MET) we used the
SMACOF algorithm (see below) to calculate a
stress-minimizing configuration. Finding such a
configuration is a numerical optimization problem.
Because a direct solution of such a problem is of-
ten not feasible, numerous iterative algorithms
have been developed to calculate an approximate
solution close enough to the direct solution, where
one actually exists. The SMACOF algorithm (scal-
ing by majorizing a complicated function) is such
an approach (De Leeuw, 1977). We start by ar-
ranging the items in a checkerboard grid configura-
tion. The algorithm then calculates the raw stress,
modifies the current configuration so that it yields
a lesser stress value by applying a Guttman Trans-
formation (Guttman, 1968) and then compares the
new configuration’s stress with the old one. This
step is repeated until the change in stress drops
below a set threshold or a maximum number of
iteration steps is exceeded.
The resulting configuration is usually not an op-
timal one. Optimal in this case would be a distor-
tionless representation with vanishing stress value.
Such a configuration is rarely, if ever, achieved in
MDS. There are three main reasons for this:
</bodyText>
<listItem confidence="0.73376325">
• Some calculated spelling distances can
conflict such that there is no spatial configu-
ration that represents the distances without
distortion. For example, a spelling may be
determined to be close to several other spell-
ings, which, however, are widely spread out.
This is due to the fact that spelling distances
do not always fulfill the triangle inequality.
• Although geometric distances, being
mathematical metrics, require the spelling
distances to be symmetric, the spelling dis-
tances calculated will not necessarily be so.
For instance, the distance between spellings
A and B could be different from that be-
tween spellings B and A.
• Even if an optimal configuration were to
</listItem>
<bodyText confidence="0.967664244897959">
exist, the iterative optimization process
might not actually find it. The algorithm
might terminate due to iteration limits or be-
cause of being “trapped” in a local mini-
mum.
This restriction on the MDS result, however, is
not severe enough to derogate its usage as a visu-
alization tool. Its task is not to reconstruct the cal-
culated distance perfectly but to uncover character-
istics of the spelling distances and spelling sets
used. These characteristics, such as clusters and
outliers, usually outweigh the distortions. Applied
to a set of spellings and their distance measure,
MDS generates a spatial configuration fit for a plot
view. The spellings’ positions in relation to one
another represent their similarity. Clusters of
closely related spellings and outliers are easy to
recognize and can be used as starting points for
detailed analyses of subsets.
An advantage of this type of visualization is that
it considers the calculated distances among all
spellings instead of only two. An initial compari-
son of the difference or similarity of multiple spell-
ings is possible at a single glance and without
switching between different views. Additional vis-
ual hints can improve the overview even further.
Certain spellings, such as the standard spelling or
the variant, can be made easily recognizable
through color or shape indications. The selection of
subsets is aided by zoom and filtering features ap-
plied to the plot view. Densely packed clusters can
be made less cluttered by changing the plot’s zoom
factor or by blending irrelevant items into the
background. Selecting the spellings by either click-
ing or encircling allows the subsets to be deter-
mined easily. The reduced item set can then be
used for a detail view, for example the display of
operations and distances like the tabular view. In
the MET, the components used to calculate a dis-
tance for a given subset can be viewed. In this way,
it is easy to understand, for example, why a certain
spelling is not as “close” to another spelling as ex-
pected.
This visualization approach is applicable to a
wide variety of spelling distances as long as they
provide a quantitative measurement of two spell-
ings. There are no assumptions made about the
distance value except that small values represent a
high degree of similarity.
</bodyText>
<equation confidence="0.9952915">
σr X
( )=
</equation>
<page confidence="0.996354">
88
</page>
<figureCaption confidence="0.9116725">
Figure 4. Table view of replacement costs mirroring deletion, insertion and replacement costs. These costs
can be manually adjusted to trigger an MDS view update.
</figureCaption>
<subsectionHeader confidence="0.99584">
3.3 Tabular views
</subsectionHeader>
<bodyText confidence="0.999978411764706">
After refining the selections from several thousand
down to a few items, a detailed display of relevant
information about the spellings and their calculated
distances is needed. At this stage the actual values
are more important than a visually comprehensible
display of relations.
Two different views in the MET use a tabular ar-
rangement of values. One represents the distance
matrix between a set of spellings, similar to the one
used to calculate the MDS solution. However, in
this case, the distances are not combined to a mean
value for both directions. At this point the differ-
ence between the two directions can be of interest
and should be visible. Standard spelling and spell-
ing variant are displayed in different colors so they
can be found more easily.
The second tabular view displays the distances
between the standard spelling and the ranked vari-
ants. To obtain a better understanding, the results
are split up into their components using a Leven-
shtein-based distance mirroring the replacement
costs that occurred when transforming one spelling
into the other. These components are displayed in
the rows according to their classification, while the
different spelling variants appear in the columns
(cf. Figure 4). By reordering the columns, the user
can move the spellings next to each other in order
to compare them more closely.
Another benefit of representing the values in this
way is that detailed modifications to the spelling
distance can be made interactively. Here, the re-
placement costs can be changed inside the table
itself, allowing an instant evaluation on what effect
such a change will have on the distance measure.
</bodyText>
<sectionHeader confidence="0.999702" genericHeader="method">
4 Interaction
</sectionHeader>
<bodyText confidence="0.999968916666667">
There are several ways to interact with the applica-
tion. Selection of data triggers an update of the
view(s) on the next level of detail: by selecting
columns of the histogram, the ranking table is acti-
vated; selecting spellings in the ranking table trig-
gers the MDS view where spellings can be selected
to be shown in the distance matrix and metric edi-
tor. While selections in the tabular views and the
histogram can easily be performed with a rectangu-
lar selection box, the MDS needed a more elabo-
rate way of selecting data. A polygonal form can
be drawn with the mouse that also allows inverted
selection (cf. Figure 3). Using two sliders or nu-
merical input, the upper and lower cut-off for se-
lection can be defined. For example, all spellings
with a distance higher than 2.5 to the search term
can be excluded (cf. right side of Figure 3). Zoom-
ing can be performed using the mouse wheel. In
the metric editor, showing the highest degree of
detail, the costs for the operations of deletion, in-
sertion and replacement can be adjusted. These
changes are instantly represented in the MDS view,
therefore allowing for the manual calibration of the
distance measures (cf. Figure 4).
</bodyText>
<sectionHeader confidence="0.958498" genericHeader="method">
5 Exemplary application of the interface
</sectionHeader>
<bodyText confidence="0.999922954545454">
To give an example of our MET, we will apply it
to a situation we have encountered more than once
in the last two years of our research: a set of his-
torical German text documents T from between
1500 and 1600 which contains nonstandard spell-
ings. As shown in (Kempken, 2006), the number of
spelling variants in old documents is monotoni-
cally nondecreasing with advancing age. T might
also contain errors originating from bad OCR or
obsolete characters. Nonetheless, we want to be
able to perform retrieval on the document. To
simulate a successful full-text search, we manually
collected all 1,165 spelling variants V in T and
aligned them with their equivalent standard spell-
ings S. We will call those word pairs evidences. S
is now merged into a contemporary dictionary—
the OpenOffice German dictionary, which contains
approximately 80,000 words. For a reliable evalua-
tion we need a high quality dictionary without ty-
pos or historical spellings. The OO-dictionary is
the best such wordlist available to us. Our algo-
rithm is able to process dictionaries of up to ~5
</bodyText>
<page confidence="0.999506">
89
</page>
<bodyText confidence="0.9851660625">
million words. Bigger dictionaries can be kept in a
database instead of the computer’s main memory.
We used the MET applied with six different dis-
tance measures to determine the one that works
best in finding all the standard spellings S “hidden”
in the dictionary related to the spelling variants V.
A normal search task in a historical database would
be to find a spelling variant by querying a standard
spelling. Because a coherent wordlist of historical
spellings was not available, to ensure a more reli-
able result, we performed the task the other way
around. This conforms to the way automatic anno-
tators like VARD work (see above).
Such experiments can be used not only to find
the best metric but also to answer general ques-
tions:
</bodyText>
<listItem confidence="0.994133888888889">
• Will an SM specifically trained on data
from the same time period as T work best or
will the extension of the time period lower
or raise the retrieval quality?
• Is there a level where a “saturation” of
training data is reached and the measures’
quality cannot be enhanced any further?
• Does the amount of necessary training data
vary with the time/location of T?
</listItem>
<bodyText confidence="0.999151869565217">
For our first experiment the six measures M1,
M2...M6 were trained by the same number of evi-
dences from 14th- to 19th-century German texts.
Prior to the training, the evidences had been dia-
chronically clustered (1300-1500, 1300-1700,
1300-1900, 1500-1700, 1500-1900, 1700-1900)
into sets, each containing 1,500 word pairs. In gen-
eral, performance is measured in precision (propor-
tion of retrieved and relevant documents to all
documents retrieved) and recall (proportion of re-
trieved and relevant documents to all relevant
documents). Since we ensured that for every his-
torical spelling there is a standard spelling, re-
trieved and relevant documents are equal and so
are precision and recall. We therefore use precision
at n (P@n). This measure is often used in cases
where instead of boolean retrieval a ranking of
documents is returned, for example in web-
retrieval. Precision at 10 is the precision that rele-
vant documents are retrieved within the 10 docu-
ments with the highest ranking. In standard settings
the MET is using n≤15.
The task of our prototype now was
</bodyText>
<listItem confidence="0.971629">
• to determine the metric most suitable for
the retrieval task, and
• to figure out deficiencies in the metrics to
further enhance their quality.
</listItem>
<table confidence="0.999451571428571">
DMV SD
1300–1500 1.37 3.174
1300–1700 1.384 3.222
1300–1900 1.261 2.983
1500–1700 1.375 3.1825
1500–1900 1.29 3.052
1700–1900 1.43 3.342
</table>
<tableCaption confidence="0.978442">
Table 1. Distribution mean value and standard de-
viation of the evaluated measures
</tableCaption>
<bodyText confidence="0.999809321428571">
Looking at P@1 the measures 1300-1500 (58.6%),
1300-1700 (58.7%), 1500-1700 (59.1%) and 1700-
1900 (59.4%) seem to be more or less equally effi-
cient. However, by looking at Table 1 we can see
that this assumption is not totally correct. The
measure trained on evidences from 1700 to 1900
holds a slightly higher distribution mean value and
standard deviation than the other two. Interestingly
the 1500-1700 measure is not the most efficient
one. 1300-1900 and 1500-1900 show better results
in P@1, DMV and SD. Even though the inclusion
of 1300-1500 evidences seems to be of minor sig-
nificance, the 1300-1900 measure is still slightly
better (60.5% P@1). Those results are – of course –
not significant because of the small dictionary we
used. We hope to acquire a bigger freely available
dictionary for more expressive results.
The ranking table is now able to show the actual
words that led to the result, therefore supporting
the expert in further interpretations. The MDS plot
and distance matrix let the user explore the words
at each rank interactively. Especially interesting
are, of course, those words that could not be found
within the top 15 ranks. The 1500-1900 and 1700-
1900 measures have some difficulties with elder
spellings (e.g. sammatin [=velvety]). It is also evi-
dent that many of the 3.9% of words &gt; P@10 share
certain characteristics:
</bodyText>
<page confidence="0.994797">
90
</page>
<figureCaption confidence="0.972347">
Figure 5. Histogram and DMV comparison of Jaro metric, standard bigram measure and SM 1300-1900.
</figureCaption>
<listItem confidence="0.9622391">
• a lot of words are short in length (e.g. vmb,
nit, het, eer). Even a single letter replace-
ment changes a high percentage of the
word’s recognizability
• some words consist of very frequent
graphemes, therefore increasing the space of
potential matches in standard spelling (e.g.
hendlen – enden, handeln, hehlen ...)
• some evidences feature high variability
(e.g. ewig – eehefig)
</listItem>
<bodyText confidence="0.9995423">
Those cases complicate successful retrieval.
Comparing the replacement costs in the metric
editor (cf. Figure 4) indicates where the SM needs
improvement. In our example we noticed that the
costs for the replacement of &lt;s&gt; with the German
ess-tset &lt;ß&gt; were a little too high, and therefore
spellings were not optimally retrieved. A slight
manual correction, a control in the MDS view and
a recalculation of the histogram showed improved
quality of the SM.
Further experiments suggested a “training satu-
ration” (see above) of about 4,000 variants. We
trained M1 on 1,500 evidences from 1300-1900,
M2 on 4,000, M3 on 6,000 and M4 on 12,000.
While M1 still shows a small drop in retrieval qual-
ity, the differences between M2 to M4 are almost
unnoticeable. We also performed a cross-language
evaluation between historical English and German
as we already did manually in (Archer et al, 2006).
Our prior results could be confirmed using the
MET.
For the comparison of truly different distance
measures, as we did in (Kempken, 2006), we used
the same data as above with our SM 1300-1900,
Jaro metric (Jaro, 1995) and a standard bigram
measure (cf. Figure 5). The histogram values of
p@&lt;4 for the SM (86.6%) are already 9.2% better
than Jaro (77.4%) and 9.9% better than the bigram
measure (76.7%). DMV and SD also show how
much better the SM performed (cf. Table 2).
</bodyText>
<table confidence="0.99795925">
DMV SD
SM 1300-1900 1.604 3.73
Jaro 2.731 5.124
Bigrams 2.533 4.754
</table>
<tableCaption confidence="0.9927065">
Table 2. DMV and SD comparison of SM, Jaro-
Winkler and bigram measure.
</tableCaption>
<sectionHeader confidence="0.99264" genericHeader="conclusions">
6 Conclusion and outlook
</sectionHeader>
<bodyText confidence="0.999971303030303">
While table views will probably not become obso-
lete any time soon, there are multiple ways to ease
and enhance the understanding of abstract data. It
has already been documented that users often pre-
fer visual data representations when dealing with
complex problems (Kempken, 2007).
In this paper we presented the prototype of our
Metric Evaluation Tool and showed that this soft-
ware is helpful in the evaluation of distance meas-
ures. The combination of overview, details and
interactivity eases the complex task of determining
quality problem-specific distance measures.
Because the MET is a prototype, there is room
for improvement. The graphical MDS display
could be extended in various ways to further im-
prove the configuration found. Displaying the nu-
merical distance values between spellings as a
tooltip or graphical overlay, group highlighting and
interactive insertion or removal of additional spell-
ing variants are just a few examples. The bar charts
of the histogram view could easily be extended
using pixel-matrix displays as proposed by (Hao et
al, 2007) to conveniently represent additional in-
formation like the distribution of distance ranges.
The MET is only one of the visualization tools
we are working on at the moment. No single appli-
cation will be able to satisfy all the many and vari-
ous needs that arise in the field of language re-
search. It is our goal to build applications that ac-
cess and reflect spelling variation in a more natural
and intuitive manner. To narrow the field of poten-
tially suitable distance measures, we are also work-
ing on automatic text classification. The Word-
</bodyText>
<page confidence="0.995519">
91
</page>
<bodyText confidence="0.999965">
Explorer, for instance, is an additional approach to
presenting details. Similar to the MDS view in ap-
pearance, it is used to further examine words’ pos-
sible spelling variants, the graphematic space of
solution (Neef, 2005). Based on the renowned Pre-
fuse-package for Java (prefuse.org), it provides
methods that support easy access and usability,
including fisheye, zoom and context menus.
</bodyText>
<sectionHeader confidence="0.999181" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998646">
We would like to thank the Deutsche For-
schungsgemeinschaft for supporting this research
and our anonymous reviewers whose detailed and
helpful reports have helped us to improve this pa-
per.
</bodyText>
<sectionHeader confidence="0.999677" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999933530612245">
Archer D, Ernst-Gerlach A, Pilz T, Rayson P (2006).
The Identification of Spelling Variants in English and
German Historical Texts: Manual or Automatic?.
Proceedings Digital Humanities 2006, July 5-9 2006,
Paris, France
Card S K, Mackinlay J D, Shneiderman B (1999). Read-
ings in Information Visualization; Using Vision to
think. Morgan Kaufman, Los Altos, California
De Leeuw J (1977). Applications of convex analysis to
multidimensional scaling
Guttman L (1968). A general nonmetric technique for
finding the smallest coordinate space for a configura-
tion of points, Psychometrika
Hao M C, Dayal U, Keim D, Schreck T (2007). A visual
analysis of multi-attribute data using pixel matrix
displays. Proceedings Visualization and Data Analy-
sis (EI 108), Jan 29-30 2007, San Jose, California
Jaro M A (1995) Probabilistic linkage of large public
health data file. In: Statistics in Medicine 14, pp.
491-498
Kempken S, Luther W, Pilz T (2006). Comparison of
distance measures for historical spelling variants.
Proceedings IFIP AI 2006, Sep 8-12 2006, Santiago,
Chile
Kempken S, Pilz T, Luther W (2007). Visualization of
rule productivity in deriving nonstandard spellings.
Proceedings Visualization and Data Analysis (EI
108), Jan 29-30 2007, San Jose, California
Knuth D (1973). The Art Of Computer Programming.
vol 3: Sorting and Searching, Addison-Wesley, pp.
391-392
Kruskal J B (1964). Multidimensional scaling by good-
ness-of-fit to a nonmetric hypothesis, Psychometrika,
29:1-27
Neef M (2005). Die Graphematik des Deutschen. Nie-
meyer, Tübingen, Germany
Rayson P, Archer D, Smith N (2005). VARD versus
Word: A comparison of the UCREL variant detector
and modern spell checkers on English historical cor-
pora. Proceedings of Corpus Linguistics 2005, July
14-17 2005, Birmingham, UK.
Ristad E; Yianilos P (1997). Learning string edit dis-
tance. Proceedings of the Fourteenth International
Conference, July 8-11 1997, San Francisco, Califor-
nia
Shneiderman B (1996). The eyes have it: A task by data
type taxonomy for information visualization. Pro-
ceedings Symposium of Visual Languages, Sep 3-6
1996, Boulder, Colorado
</reference>
<page confidence="0.99603">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.527813">
<title confidence="0.999903">Visualizing the evaluation of distance measures</title>
<author confidence="0.999984">Thomas Pilz</author>
<affiliation confidence="0.997673333333333">University of Duisburg-Essen Faculty of Engineering Department of Computer Science</affiliation>
<email confidence="0.948199">pilz@inf.uni-due.de</email>
<author confidence="0.997206">Axel Philipsenburg</author>
<affiliation confidence="0.992501">University of Duisburg-Essen</affiliation>
<email confidence="0.8169805">axel.philipsenburg@unidue.de</email>
<author confidence="0.984717">Wolfram Luther</author>
<affiliation confidence="0.997761">University of Duisburg-Essen Faculty of Engineering Department of Computer Science</affiliation>
<email confidence="0.985144">luther@inf.uni-due.de</email>
<abstract confidence="0.991894428571429">This paper describes the development and use of an interface for visually evaluating distance measures. The combination of multidimensional scaling plots, histograms and tables allows for different stages of overview and detail. The interdisciplinary project Rule-based search in text databases with nonstandard orthography develops a fuzzy full text search engine and uses distance measures for historical text document retrieval. This engine should provide easier text access for experts as well as interested amateurs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Archer</author>
<author>A Ernst-Gerlach</author>
<author>T Pilz</author>
<author>P Rayson</author>
</authors>
<title>The Identification of Spelling Variants in English and German Historical Texts: Manual or Automatic?.</title>
<date>2006</date>
<booktitle>Proceedings Digital Humanities</booktitle>
<location>Paris, France</location>
<contexts>
<context position="28158" citStr="Archer et al, 2006" startWordPosition="4571" endWordPosition="4574">o high, and therefore spellings were not optimally retrieved. A slight manual correction, a control in the MDS view and a recalculation of the histogram showed improved quality of the SM. Further experiments suggested a “training saturation” (see above) of about 4,000 variants. We trained M1 on 1,500 evidences from 1300-1900, M2 on 4,000, M3 on 6,000 and M4 on 12,000. While M1 still shows a small drop in retrieval quality, the differences between M2 to M4 are almost unnoticeable. We also performed a cross-language evaluation between historical English and German as we already did manually in (Archer et al, 2006). Our prior results could be confirmed using the MET. For the comparison of truly different distance measures, as we did in (Kempken, 2006), we used the same data as above with our SM 1300-1900, Jaro metric (Jaro, 1995) and a standard bigram measure (cf. Figure 5). The histogram values of p@&lt;4 for the SM (86.6%) are already 9.2% better than Jaro (77.4%) and 9.9% better than the bigram measure (76.7%). DMV and SD also show how much better the SM performed (cf. Table 2). DMV SD SM 1300-1900 1.604 3.73 Jaro 2.731 5.124 Bigrams 2.533 4.754 Table 2. DMV and SD comparison of SM, JaroWinkler and bigr</context>
</contexts>
<marker>Archer, Ernst-Gerlach, Pilz, Rayson, 2006</marker>
<rawString>Archer D, Ernst-Gerlach A, Pilz T, Rayson P (2006). The Identification of Spelling Variants in English and German Historical Texts: Manual or Automatic?. Proceedings Digital Humanities 2006, July 5-9 2006, Paris, France</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K Card</author>
<author>J D Mackinlay</author>
<author>B Shneiderman</author>
</authors>
<title>Readings in Information Visualization; Using Vision to think.</title>
<date>1999</date>
<publisher>Morgan</publisher>
<location>Kaufman, Los Altos, California</location>
<contexts>
<context position="7202" citStr="Card et al, 1999" startWordPosition="1075" endWordPosition="1078">e connection of arbitrary concepts of word distance. Our SM, a rule based measure using regular expressions, Soundex (Knuth, 1973), Jaro(-Winkler) (Jaro, 1995) and a number of additional measures are already implemented in our system. It was built in Java and is embedded in our general environment for the processing of nonstandard spellings. Information Visualization is a fairly new field of research that is rapidly evolving. A well established definition of information visualization is “the use of computer-supported, interactive, visual representations of abstract data to amplify cognition” (Card et al, 1999). While planning the prototype, we also kept Shneiderman’s paradigm in mind: “Overview first, zoom and filter details on demand” (Shneiderman, 1996). In dealing with distance measures, our main task is to represent word distance. We employed multidimensional scaling (MDS) to display abstract distance in 2D space (see below). Interactivity is gained with the ability to select and remove spellings from the calculations, lower or raise cutoff frequencies and filters and even change replacement costs with instantaneous effect (see below). This led to a user interface separated into three main view</context>
</contexts>
<marker>Card, Mackinlay, Shneiderman, 1999</marker>
<rawString>Card S K, Mackinlay J D, Shneiderman B (1999). Readings in Information Visualization; Using Vision to think. Morgan Kaufman, Los Altos, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>J De Leeuw</author>
</authors>
<title>Applications of convex analysis to multidimensional scaling</title>
<date>1977</date>
<marker>De Leeuw, 1977</marker>
<rawString>De Leeuw J (1977). Applications of convex analysis to multidimensional scaling</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Guttman</author>
</authors>
<title>A general nonmetric technique for finding the smallest coordinate space for a configuration of points,</title>
<date>1968</date>
<location>Psychometrika</location>
<contexts>
<context position="15331" citStr="Guttman, 1968" startWordPosition="2437" endWordPosition="2438">iguration is a numerical optimization problem. Because a direct solution of such a problem is often not feasible, numerous iterative algorithms have been developed to calculate an approximate solution close enough to the direct solution, where one actually exists. The SMACOF algorithm (scaling by majorizing a complicated function) is such an approach (De Leeuw, 1977). We start by arranging the items in a checkerboard grid configuration. The algorithm then calculates the raw stress, modifies the current configuration so that it yields a lesser stress value by applying a Guttman Transformation (Guttman, 1968) and then compares the new configuration’s stress with the old one. This step is repeated until the change in stress drops below a set threshold or a maximum number of iteration steps is exceeded. The resulting configuration is usually not an optimal one. Optimal in this case would be a distortionless representation with vanishing stress value. Such a configuration is rarely, if ever, achieved in MDS. There are three main reasons for this: • Some calculated spelling distances can conflict such that there is no spatial configuration that represents the distances without distortion. For example,</context>
</contexts>
<marker>Guttman, 1968</marker>
<rawString>Guttman L (1968). A general nonmetric technique for finding the smallest coordinate space for a configuration of points, Psychometrika</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Hao</author>
<author>U Dayal</author>
<author>D Keim</author>
<author>T Schreck</author>
</authors>
<title>A visual analysis of multi-attribute data using pixel matrix displays.</title>
<date>2007</date>
<booktitle>Proceedings Visualization and Data Analysis (EI 108),</booktitle>
<location>San Jose, California</location>
<contexts>
<context position="29862" citStr="Hao et al, 2007" startWordPosition="4853" endWordPosition="4856">f overview, details and interactivity eases the complex task of determining quality problem-specific distance measures. Because the MET is a prototype, there is room for improvement. The graphical MDS display could be extended in various ways to further improve the configuration found. Displaying the numerical distance values between spellings as a tooltip or graphical overlay, group highlighting and interactive insertion or removal of additional spelling variants are just a few examples. The bar charts of the histogram view could easily be extended using pixel-matrix displays as proposed by (Hao et al, 2007) to conveniently represent additional information like the distribution of distance ranges. The MET is only one of the visualization tools we are working on at the moment. No single application will be able to satisfy all the many and various needs that arise in the field of language research. It is our goal to build applications that access and reflect spelling variation in a more natural and intuitive manner. To narrow the field of potentially suitable distance measures, we are also working on automatic text classification. The Word91 Explorer, for instance, is an additional approach to pres</context>
</contexts>
<marker>Hao, Dayal, Keim, Schreck, 2007</marker>
<rawString>Hao M C, Dayal U, Keim D, Schreck T (2007). A visual analysis of multi-attribute data using pixel matrix displays. Proceedings Visualization and Data Analysis (EI 108), Jan 29-30 2007, San Jose, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jaro</author>
</authors>
<title>A</title>
<date>1995</date>
<booktitle>in Medicine 14,</booktitle>
<pages>491--498</pages>
<contexts>
<context position="6744" citStr="Jaro, 1995" startWordPosition="1005" endWordPosition="1006"> The prototype we developed is but one example for those possibilities and is meant to encourage scientists to benefit from visual information representation. 3 Development and functions of an interactive visual interface Since our project already deals with different methods for calculating word distance, the definition of a generic interface was necessary. Priority was given to the development of a slim and easily accessible device that allows the connection of arbitrary concepts of word distance. Our SM, a rule based measure using regular expressions, Soundex (Knuth, 1973), Jaro(-Winkler) (Jaro, 1995) and a number of additional measures are already implemented in our system. It was built in Java and is embedded in our general environment for the processing of nonstandard spellings. Information Visualization is a fairly new field of research that is rapidly evolving. A well established definition of information visualization is “the use of computer-supported, interactive, visual representations of abstract data to amplify cognition” (Card et al, 1999). While planning the prototype, we also kept Shneiderman’s paradigm in mind: “Overview first, zoom and filter details on demand” (Shneiderman,</context>
<context position="28377" citStr="Jaro, 1995" startWordPosition="4611" endWordPosition="4612">ng saturation” (see above) of about 4,000 variants. We trained M1 on 1,500 evidences from 1300-1900, M2 on 4,000, M3 on 6,000 and M4 on 12,000. While M1 still shows a small drop in retrieval quality, the differences between M2 to M4 are almost unnoticeable. We also performed a cross-language evaluation between historical English and German as we already did manually in (Archer et al, 2006). Our prior results could be confirmed using the MET. For the comparison of truly different distance measures, as we did in (Kempken, 2006), we used the same data as above with our SM 1300-1900, Jaro metric (Jaro, 1995) and a standard bigram measure (cf. Figure 5). The histogram values of p@&lt;4 for the SM (86.6%) are already 9.2% better than Jaro (77.4%) and 9.9% better than the bigram measure (76.7%). DMV and SD also show how much better the SM performed (cf. Table 2). DMV SD SM 1300-1900 1.604 3.73 Jaro 2.731 5.124 Bigrams 2.533 4.754 Table 2. DMV and SD comparison of SM, JaroWinkler and bigram measure. 6 Conclusion and outlook While table views will probably not become obsolete any time soon, there are multiple ways to ease and enhance the understanding of abstract data. It has already been documented that</context>
</contexts>
<marker>Jaro, 1995</marker>
<rawString>Jaro M A (1995) Probabilistic linkage of large public health data file. In: Statistics in Medicine 14, pp. 491-498</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kempken</author>
<author>W Luther</author>
<author>T Pilz</author>
</authors>
<title>Comparison of distance measures for historical spelling variants.</title>
<date>2006</date>
<booktitle>Proceedings IFIP AI</booktitle>
<location>Santiago, Chile</location>
<contexts>
<context position="3982" citStr="Kempken et al. 2006" startWordPosition="573" endWordPosition="576">ional/dialectal or phonetic variation, typos or OCR errors. The project’s funding by the Deutsche Forschungsgemeinschaft (DFG [German Research Foundation]) was recently extended by two years. 2 Comparing similarity measures One of the important issues in building a search engine for nonstandard spellings is a reliable way to allow the comparison of words, that is, to measure the similarity between the search expression and the results provided. Given the abundance of distance measures and edit-distances available, methods are needed for efficiently comparing different similarity measures. In (Kempken et al. 2006) we evaluated 13 different measures with the calculation of precision and recall to determine which were most qualified to deal with historical German spelling variants. We mainly used our own database of historical spellings, manually collected from the German text archives Bibliotheca Augustana, documentArchiv.de and Digitales Archiv Hessen-Darmstadt. Currently our database consists of 12,687 modern-historical word pairs (that we call evidences) originating between 1293 and 1919. The algorithm that proved best for calculating the edit costs between the modern and the historical spellings is </context>
</contexts>
<marker>Kempken, Luther, Pilz, 2006</marker>
<rawString>Kempken S, Luther W, Pilz T (2006). Comparison of distance measures for historical spelling variants. Proceedings IFIP AI 2006, Sep 8-12 2006, Santiago, Chile</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kempken</author>
<author>T Pilz</author>
<author>W Luther</author>
</authors>
<title>Visualization of rule productivity in deriving nonstandard spellings.</title>
<date>2007</date>
<booktitle>Proceedings Visualization and Data Analysis (EI 108),</booktitle>
<location>San Jose, California</location>
<contexts>
<context position="8170" citStr="Kempken et al, 2007" startWordPosition="1235" endWordPosition="1238">ed with the ability to select and remove spellings from the calculations, lower or raise cutoff frequencies and filters and even change replacement costs with instantaneous effect (see below). This led to a user interface separated into three main views: • The Histogram allows an overview of thousands of data items. The selection of a 85 certain portion of data triggers MDS and table views. • Multidimensional Scaling (MDS) functions as a detail view. Such visualization is used to display sets of several dozen to a few hundred items. • The Table View can display different levels of detail. In (Kempken et al, 2007) we presented a TreeMap approach, another way to display details of single word derivations as an add-on for table views. 3.1 Histograms Histograms are a widely spread tool for display of statistical distribution of values. In favor of Shneiderman’s paradigm, the histogram view represents a combination of overview and zoom functionality. This first stage allows for the reduction of the data set from up to several thousand items down to much more manageable sizes. To get a first impression of how a spelling distance performs on a set of evidences, we calculate the distance between a spelling va</context>
</contexts>
<marker>Kempken, Pilz, Luther, 2007</marker>
<rawString>Kempken S, Pilz T, Luther W (2007). Visualization of rule productivity in deriving nonstandard spellings. Proceedings Visualization and Data Analysis (EI 108), Jan 29-30 2007, San Jose, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Knuth</author>
</authors>
<title>The Art Of Computer Programming. vol 3: Sorting and Searching,</title>
<date>1973</date>
<pages>391--392</pages>
<publisher>Addison-Wesley,</publisher>
<contexts>
<context position="6715" citStr="Knuth, 1973" startWordPosition="1002" endWordPosition="1003">peed up and ease this process. The prototype we developed is but one example for those possibilities and is meant to encourage scientists to benefit from visual information representation. 3 Development and functions of an interactive visual interface Since our project already deals with different methods for calculating word distance, the definition of a generic interface was necessary. Priority was given to the development of a slim and easily accessible device that allows the connection of arbitrary concepts of word distance. Our SM, a rule based measure using regular expressions, Soundex (Knuth, 1973), Jaro(-Winkler) (Jaro, 1995) and a number of additional measures are already implemented in our system. It was built in Java and is embedded in our general environment for the processing of nonstandard spellings. Information Visualization is a fairly new field of research that is rapidly evolving. A well established definition of information visualization is “the use of computer-supported, interactive, visual representations of abstract data to amplify cognition” (Card et al, 1999). While planning the prototype, we also kept Shneiderman’s paradigm in mind: “Overview first, zoom and filter det</context>
</contexts>
<marker>Knuth, 1973</marker>
<rawString>Knuth D (1973). The Art Of Computer Programming. vol 3: Sorting and Searching, Addison-Wesley, pp. 391-392</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Kruskal</author>
</authors>
<title>Multidimensional scaling by goodness-of-fit to a nonmetric hypothesis, Psychometrika,</title>
<date>1964</date>
<pages>29--1</pages>
<contexts>
<context position="13238" citStr="Kruskal, 1964" startWordPosition="2082" endWordPosition="2083">lling variants. It also makes it possible to discover distance anomalies. If this representation is provided with filtering features, it can be used to select subsets of elements quickly and comfortably. These subsets can then be displayed in detailed information views that would be too cluttered with greater numbers of items. The “distortion” is evaluated by comparing the distances calculated by the spelling distances with the configuration’s geometric distances (i.e. distances following geometric rules). A common calculation for this distortion is the so-called “raw stress” factor. Kruskal (Kruskal, 1964) defined raw stress as the sum of distance errors over a configuration. To calculate this error, we use the distance matrix D, where each entry holds the calculated distance δij between the spellings of the relevant row and column. These values can be modified by f(δij)=a δij to achieve a scaling more fit for visual distances, thus reducing stress. Comparison with geometric distances also requires this matrix to be symmetric. Because spelling distances are not necessarily symmetric (distance A – B differs from B – A), we use the mean value of both distance directions to create symmetry, as Kru</context>
</contexts>
<marker>Kruskal, 1964</marker>
<rawString>Kruskal J B (1964). Multidimensional scaling by goodness-of-fit to a nonmetric hypothesis, Psychometrika, 29:1-27</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Neef</author>
</authors>
<title>Die Graphematik des Deutschen.</title>
<date>2005</date>
<location>Niemeyer, Tübingen, Germany</location>
<marker>Neef, 2005</marker>
<rawString>Neef M (2005). Die Graphematik des Deutschen. Niemeyer, Tübingen, Germany</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rayson</author>
<author>D Archer</author>
<author>N Smith</author>
</authors>
<title>VARD versus Word: A comparison of the UCREL variant detector and modern spell checkers on English historical corpora.</title>
<date>2005</date>
<booktitle>Proceedings of Corpus Linguistics</booktitle>
<location>Birmingham, UK.</location>
<contexts>
<context position="5097" citStr="Rayson et al, 2005" startWordPosition="740" endWordPosition="743">ithm that proved best for calculating the edit costs between the modern and the historical spellings is called Stochastic distance (SM) and was originally proposed in 1975 by Bahl and Jelinek. In 1997 Ristad and Yianilos (Ristad et al, 1997) took it up again and extended the approach to machine learning abilities. Due to the complexity of language, apparently similar scopes can obviously favor totally different mechanisms. The Variant Detector VARD developed by Rayson et al. to detect spelling variants in historical English texts uses the standard Soundex algorithm with convincing efficiency (Rayson et al, 2005). The same algorithm yields an error rate 6.7 times higher than the stochastic distance for the comparison of German spelling variants. Cases like these suggest that finding one “most suitable” distance measure for all data might not be possible. As soon as the inherent structures change, another measure can prove to be more efficient. Even though, with the SM, we already found a suitable measure, its dependency on the underlying training data forces us to evaluate the training results: what is the size of an optimal training set? Is the training set well chosen? Does 14th-century data appropr</context>
</contexts>
<marker>Rayson, Archer, Smith, 2005</marker>
<rawString>Rayson P, Archer D, Smith N (2005). VARD versus Word: A comparison of the UCREL variant detector and modern spell checkers on English historical corpora. Proceedings of Corpus Linguistics 2005, July 14-17 2005, Birmingham, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ristad</author>
<author>P Yianilos</author>
</authors>
<title>Learning string edit distance.</title>
<date>1997</date>
<booktitle>Proceedings of the Fourteenth International Conference,</booktitle>
<location>San Francisco, California</location>
<marker>Ristad, Yianilos, 1997</marker>
<rawString>Ristad E; Yianilos P (1997). Learning string edit distance. Proceedings of the Fourteenth International Conference, July 8-11 1997, San Francisco, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Shneiderman</author>
</authors>
<title>The eyes have it: A task by data type taxonomy for information visualization.</title>
<date>1996</date>
<booktitle>Proceedings Symposium of Visual Languages,</booktitle>
<location>Boulder, Colorado</location>
<contexts>
<context position="7350" citStr="Shneiderman, 1996" startWordPosition="1099" endWordPosition="1100">(Jaro, 1995) and a number of additional measures are already implemented in our system. It was built in Java and is embedded in our general environment for the processing of nonstandard spellings. Information Visualization is a fairly new field of research that is rapidly evolving. A well established definition of information visualization is “the use of computer-supported, interactive, visual representations of abstract data to amplify cognition” (Card et al, 1999). While planning the prototype, we also kept Shneiderman’s paradigm in mind: “Overview first, zoom and filter details on demand” (Shneiderman, 1996). In dealing with distance measures, our main task is to represent word distance. We employed multidimensional scaling (MDS) to display abstract distance in 2D space (see below). Interactivity is gained with the ability to select and remove spellings from the calculations, lower or raise cutoff frequencies and filters and even change replacement costs with instantaneous effect (see below). This led to a user interface separated into three main views: • The Histogram allows an overview of thousands of data items. The selection of a 85 certain portion of data triggers MDS and table views. • Mult</context>
</contexts>
<marker>Shneiderman, 1996</marker>
<rawString>Shneiderman B (1996). The eyes have it: A task by data type taxonomy for information visualization. Proceedings Symposium of Visual Languages, Sep 3-6 1996, Boulder, Colorado</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>