<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.983031">
Generating Quantifiers and Negation to Explain Homework Testing
</title>
<author confidence="0.988334">
Jason Perry and Chung-chieh Shan
</author>
<affiliation confidence="0.992885">
Rutgers University
Department of Computer Science
</affiliation>
<sectionHeader confidence="0.988043" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999304157894737">
We describe Prograder, a software package for
automatic checking of requirements for pro-
gramming homework assignments. Prograder
lets instructors specify requirements in natural
language as well as explains grading results to
students in natural language. It does so using
a grammar that generates as well as parses to
translate between a small fragment of English
and a first-order logical specification language
that can be executed directly in Python. This
execution embodies multiple semantics—both
to check the requirement and to search for ev-
idence that proves or disproves the require-
ment. Such a checker needs to interpret and
generate sentences containing quantifiers and
negation. To handle quantifier and negation
scope, we systematically simulate continua-
tion grammars using record structures in the
Grammatical Framework.
</bodyText>
<sectionHeader confidence="0.999125" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992394">
The typical programming assignment in a computer-
science course comes with not only a problem de-
scription but also correctness and stylistic require-
ments such as
(1) Every source file compiles and has comments,
and a text file mentions every source file and
every header file.
Although the requirements do not usually specify
exactly how the students’ work will be judged, they
make it much easier to grade and respond to the sub-
mitted work. Many requirements can be checked
57
automatically by computer, and often they are—
perhaps even right after each student uploads their
work so that the student can revise their work using
the immediate feedback.
This common workflow is wanting in two aspects.
First, the requirements are both specified to the stu-
dents in English and coded into a testing harness by
the course staff. Keeping the two versions is a hassle
that involves much boilerplate text as well as boil-
erplate code. Second, students rightfully demand
comprehensible explanations when their work is re-
jected by the requirement tester. It is tricky to code
up a tester that produces error messages neither too
terse nor too verbose, when one student might forget
to comment just one file and another might not know
the lexical syntax of comments at all.
A natural approach to improve this workflow,
then, is to specify the requirements in a formal lan-
guage and to implement an interpreter for the lan-
guage that produces explanations. Because many
instructors, like students, are averse to learning new
languages, we pursue the use of a controlled subset
of English as that formal language. In short, we aim
to produce a programming-assignment tester that
allows instructors to specify requirements for pro-
gramming assignments in natural language, checks
those requirements automatically by executing com-
mands on the submitted assignment files, and gen-
erates for the student a natural-language explanation
of the results. For example, in an introductory pro-
gramming class, a professor may write the specifi-
cation sentence (1). The system would then grade
all students’ programming assignments according to
these criteria, and return individualized explanations
</bodyText>
<note confidence="0.987889">
Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 57–65,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.969210882352941">
to students like
(2) Credit was lost because bar.c did not compile
and no text file mentioned the files foo.h and
baz.h.
As this example illustrates, the tester needs to in-
terpret and generate sentences with quantifiers and
negation. Although the interpretation of quantifiers
and negation is a traditional research area in com-
putational linguistics (VanLehn, 1978; Hobbs and
Shieber, 1987; Moran, 1988), their generation is
much less studied (Gailly, 1988). Even if our system
were to compose explanations entirely from the in-
put specification sentences and their negation, it can-
not negate a specification sentence merely by adding
or removing verbal auxiliaries: the negation of “a
source file defines main()” is not “a source file does
not define main()”.
</bodyText>
<subsectionHeader confidence="0.992139">
1.1 Contributions
</subsectionHeader>
<bodyText confidence="0.9999685">
We have built Prograder, a rudimentary program-
ming-assignment tester that correctly interprets and
generates a small fragment of English that includes
quantifiers and negation. This paper describes the
architecture of Prograder. Our implementation uses
a declarative grammar that simultaneously supports
interpretation and generation by relating English
phrase structure to type-logical semantics. This pa-
per details the new techniques we use in this gram-
mar to represent quantifier scope and De Morgan du-
ality in a tractable way.
Prograder also lets us investigate how to make a
computer program explain its own execution. The
concerns for a tester that must justify its output to
students are not merely grammatical, but involve the
semantics and pragmatics of summarization and jus-
tification. For example, when is it semantically cor-
rect to combine entities within an NP, as in “foo.h
and baz.h” above? When is an explanation prag-
matically enough for a student who has a right to
know why she lost credit on a programming assign-
ment? Which pieces of evidence must be stated and
which are better left out? We plan to study these
questions within type-logical semantics as well.
</bodyText>
<subsectionHeader confidence="0.998658">
1.2 Organization of This Paper
</subsectionHeader>
<bodyText confidence="0.998797111111111">
In Section 1, we have introduced the problem and
outlined the contributions of the research carried out
in building Prograder. In Section 2, we give a high-
level overview of the architecture of the system, in-
cluding the representation of natural-language syn-
tax and type-logical semantics, as well as the proce-
dure of operation. Section 3 describes Prograder’s
checking procedure and how it generates explana-
tions in tandem with the checking. In Section 4,
we begin to describe the details of the grammati-
cal framework that allows us to handle bidirectional
translation between English and the logical form.
Continuing in Section 5, we discuss the handling
of negation and quantifier scoping by means of a
record-based implementation of continuation gram-
mars. Section 6 reviews the architecture of the sys-
tem with additional implementation details, and Sec-
tion 7 concludes with future work.
</bodyText>
<sectionHeader confidence="0.97094" genericHeader="introduction">
2 System Overview
</sectionHeader>
<bodyText confidence="0.999957666666667">
We explain the architecture of our Prograder sys-
tem using a simplified example. Suppose that the
instructor specifies the requirement that
</bodyText>
<listItem confidence="0.876734">
(3) Every source file compiles.
</listItem>
<bodyText confidence="0.8716605">
Prograder begins by parsing this sentence into an ab-
stract syntax tree:
</bodyText>
<sectionHeader confidence="0.755129" genericHeader="method">
(4) ApplyS
</sectionHeader>
<subsectionHeader confidence="0.940578">
EverySourceFile Compiles
</subsectionHeader>
<bodyText confidence="0.9920035">
Interpreting this tree compositionally gives the
meaning of the sentence:
</bodyText>
<listItem confidence="0.865347">
(5) everysourcefile(lambda x:
compiles(x))
</listItem>
<bodyText confidence="0.998558272727273">
On one hand, this expression is a formula in pred-
icate logic. In general, each requirement specifi-
cation is a sentence, whose truth value is deter-
mined by checking a single student’s programming
assignment. We use the types of Montague gram-
mar (1974), which are the base type of entities e, the
base type of propositions t, and function types no-
tated by ✦. Our logical language is defined by a
domain-specific vocabulary of typed predicates and
entities (Hudak, 1996). Naturally, the files submit-
ted by the student are entities.
</bodyText>
<page confidence="0.996875">
58
</page>
<bodyText confidence="0.999778090909091">
For example, the unary predicates compiles and
hascomments have the type e ✦ t, and the bi-
nary predicate mentions has the type e ✦ e ✦ t.
These predicates in our vocabulary represent vari-
ous properties of submitted files that instructors may
want to check. Logical connectives are also part
of the vocabulary; for instance, and and or have
the type t ✦ t ✦ t, not_b has the type t ✦ t, and
everysourcefile has the type (e ✦ t) ✦ t. There-
fore, the expression (5) has the type t, as do the ex-
pressions
</bodyText>
<listItem confidence="0.931193666666667">
(6) compiles(&amp;quot;foo.c&amp;quot;)
(7) and(compiles(&amp;quot;foo.c&amp;quot;),
hascomments(&amp;quot;bar.c&amp;quot;))
</listItem>
<bodyText confidence="0.990387142857143">
On the other hand, the expressions (5–7) are exe-
cutable Python code. Prograder includes a library
of Python functions such as everysourcefile,
which iterates over the source files submitted, and
compiles, which invokes gcc. As each student sub-
mits their homework, we evaluate the expression (5)
to check the requirement (3). We use Python’s own
lambda abstraction and first-class functions to ex-
press quantified statements. For example, evaluating
(5) invokes gcc on each source file submitted.
Evaluation not only computes a Boolean value but
also yields a tree of evidence statements to justify
the result. At the root of the tree is either the re-
quirement (5) or its negation:
</bodyText>
<equation confidence="0.411078">
(8) asourcefile(lambda x:
not_b(compiles(x)))
</equation>
<bodyText confidence="0.9935266">
Each node’s children are the premises that together
justify the conclusion at that node. For example, if
every source file submitted by the student compiles
successfully except one, then (8) would be justified
by a sole child:
</bodyText>
<listItem confidence="0.9295092">
(9) not_b(compiles(&amp;quot;bar.c&amp;quot;))
Prograder then parses each evidence statement into
abstract syntax:
(10) ApplyS
ASourceFile Not_VP
</listItem>
<bodyText confidence="0.698091333333333">
Compiles
From these trees, Prograder finally renders each ev-
idence statement as an English clause:
</bodyText>
<listItem confidence="0.994499466666667">
(11) A source file does not compile because bar.c
does not compile.
To summarize, Prograder’s steps of operation are
as follows:
1. Parse the natural-language requirement state-
ment into a phrase-structure syntax tree.
2. Produce a logical semantic representation from
the syntax tree.
3. Execute the semantic representation to check
the requirement and produce a semantic repre-
sentation of each evidence statement.
4. Parse the evidence statements into phrase-
structure syntax trees.
5. Produce natural-language explanation from the
syntax trees.
</listItem>
<bodyText confidence="0.839445444444444">
From end to end, these steps operate on just three
levels of representation: the abstract syntax trees in
(4) and (10) can be spelled out either in natural lan-
guage (English) as in (3) and (11) or in predicate
logic (Python) as in (5–9). Thus, Prograder inter-
prets natural-language requirements and generates
natural-language explanations using the same exe-
cutable semantic representations. In fact, it uses the
same grammar, as described in Section 4.
</bodyText>
<sectionHeader confidence="0.920735" genericHeader="method">
3 Gathering Evidence while Testing Truth
</sectionHeader>
<bodyText confidence="0.999761357142857">
As sketched above, evaluating a proposition gives a
Boolean result along with a tree of evidence propo-
sitions that justify that result. That is, we represent
the type t in Python as an ordered pair, not just a
Boolean value. This is straightforward for primitive
first-order predicates. For example, the compiles
function, when invoked with the argument &amp;quot;foo.c&amp;quot;,
tries to compile foo.c, then either returns True
along with a trivial evidence tree containing just the
proposition compiles(&amp;quot;foo.c&amp;quot;), or returns False
along with a trivial evidence tree containing just
the proposition not_b(compiles(&amp;quot;foo.c&amp;quot;)). In
short, we hold whether a file compiles to be self-
evident.
</bodyText>
<figure confidence="0.608178666666667">
ApplyS
bar.c Not_VP
Compiles
</figure>
<page confidence="0.993821">
59
</page>
<bodyText confidence="0.998589">
The picture is more complex for logical connec-
tives, especially higher-order functions such as the
quantifier everysourcefile. Ideally, the falsity
of (3) should be justified by an explanation like
</bodyText>
<listItem confidence="0.660812">
(12) Not every source file compiles because foo.c
and bar.c do not compile.
</listItem>
<bodyText confidence="0.998258941176471">
Also, the explanation should be generated by com-
posing the implementations of everysourcefile
and of compiles, so that new quantifiers (“most
source files”) and predicates (“has comments”) can
be added as separate modules. For example, evaluat-
ing the proposition not_b(compiles(&amp;quot;foo.c&amp;quot;))
first evaluates compiles(&amp;quot;foo.c&amp;quot;) then negates
the Boolean while keeping the evidence the same.
Prograder currently justifies quantified proposi-
tions in the following compositional way. When
the higher-order function everysourcefile is in-
voked with the predicate argument p, it invokes p
on each source file submitted and collects the result-
ing Boolean-evidence pairs. If any of the Boolean
results is False, then the overall Boolean result is
of course also False. This result is justified by an
evidence tree whose root proposition is
</bodyText>
<equation confidence="0.396985">
(13) not_b(everysourcefile(p))
</equation>
<bodyText confidence="0.9176438">
and whose subtrees are the evidence trees for all the
False results. (After all, the primary mode of ex-
planation required in grading a programming assign-
ment is to say why credit has been subtracted.) Pro-
grader then produces the serviceable explanation
(14) Not every source file compiles because foo.c
does not compile and bar.c does not compile.
(We are working on simplifying this explanation
to (12).) This process generalizes immediately to
propositions with multiple quantifiers, such as
</bodyText>
<listItem confidence="0.972122714285714">
(15) Every text file mentions a source file.
everytextfile(lambda x:
asourcefile(lambda y:
mentions(y)(x)))
For example, Prograder might explain that
(16) Not every text file mentions a source file be-
cause README mentions no source file.
</listItem>
<bodyText confidence="0.990126904761905">
In sum, Prograder generates explanations in the
same process—the same sequence of function calls
and returns—as it computes Boolean values. In this
way, the checking process gains an additional inter-
pretation as a process of gathering evidence for the
explanation. The explanation itself is a tree structure
corresponding to the pattern of function calls in the
computation; in fact, it is a proof tree for the require-
ments specification statement (or its negation). Once
all the evidence has been gathered, a textual version
of the explanation can be generated by traversing the
tree and concatenating evidence statements, possi-
bly using summarization techniques to make the ex-
planation more concise.
We have so far glossed over how English sen-
tences, especially those with quantification and
negation such as (14) and (16), are parsed into and
generated from logical representations. The rest of
this paper describes our principled approach to this
problem, based on a consistent mapping between
syntactic categories and semantic types.
</bodyText>
<sectionHeader confidence="0.979509" genericHeader="method">
4 Using the Grammatical Framework
</sectionHeader>
<bodyText confidence="0.998459058823529">
We relate natural language (English) to logical se-
mantics (Python) using the Grammatical Framework
(GF) of Ranta (2004). GF is a mature system that al-
lows linguists and logicians to define grammars for
both natural and formal languages using a Haskell-
like syntax. Once defined, the grammars can be used
for parsing as well as generation (linearization) with
no further programming.
In GF, grammars are specified in two parts: an ab-
stract grammar and a concrete grammar. An abstract
grammar specifies the set of well-formed abstract
syntax trees, whereas a concrete grammar specifies
how to spell out abstract syntax as strings. For exam-
ple, an abstract grammar can admit the abstract syn-
tax tree in (4) by specifying that EverySourceFile
is an NP, Compiles is a VP, and ApplyS combines
an NP and a VP into an S:
</bodyText>
<listItem confidence="0.935926333333333">
fun EverySourceFile: NP;
fun Compiles: VP;
fun ApplyS: NP -&gt; VP -&gt; S;
</listItem>
<bodyText confidence="0.928481666666667">
A concrete grammar for English can then specify
that the linearization of EverySourceFile is a sin-
gular (Sg) string,
</bodyText>
<equation confidence="0.5412375">
lin EverySourceFile = {
s = &amp;quot;every source file&amp;quot;; n = Sg };
</equation>
<bodyText confidence="0.698885">
the linearization of Compiles is a pair of strings,
</bodyText>
<page confidence="0.779337">
60
</page>
<equation confidence="0.993104333333333">
lin Compiles = {
s = { Sg =&gt; &amp;quot;compiles&amp;quot;;
Pl =&gt; &amp;quot;compile&amp;quot; } };
</equation>
<bodyText confidence="0.998339">
and the linearization of ApplyS is a function that
combines these two linearizations into the string (3).
</bodyText>
<equation confidence="0.9943265">
lin ApplyS NP VP = {
s = NP.s ++ (VP.s ! NP.n) };
</equation>
<bodyText confidence="0.99908615">
Here ++ denotes string concatenation and ! denotes
table lookup.
Multiple concrete grammars can share the same
abstract grammar in GF, as in synchronous gram-
mars (Aho and Ullman, 1969) and abstract catego-
rial grammars (de Groote, 2002). This sharing is
meant to enable multilingual applications, in which
the same meaning representation defined by a sin-
gle abstract grammar can be rendered into various
natural languages by different concrete grammars.
This separation into abstract and concrete gram-
mars lets us use one concrete grammar to model En-
glish and another to model the Python syntax of Pro-
grader’s logical forms. For example, the lineariza-
tion of Compiles into Python is simply compiles,
which can be combined with &amp;quot;foo.c&amp;quot; by the lin-
earization of ApplyS to form compiles(&amp;quot;foo.c&amp;quot;).
The system can thus parse a natural-language spec-
ification into an abstract syntax tree using the first
concrete grammar, then produce the corresponding
semantic representation using the second concrete
grammar. Since each concrete grammar can be used
for both parsing and generation, the system can also
be run in the other direction, to parse the semantic
representations of an explanation, then generate that
explanation in natural language.
Since the linearization compiles(&amp;quot;foo.c&amp;quot;) in
Python is virtually isomorphic to its abstract syn-
tax tree, one may wonder why we bother with the
second concrete grammar at all. Why not just ex-
press the type-theoretical semantic structure in the
abstract syntax and relate it to English in a sin-
gle concrete grammar? The answer is that using
two concrete grammars lets us represent quantifier
meanings and scope preferences. Without the dis-
tinction between abstract syntax and logical seman-
tics, we would have to specify how to linearize
everysourcefile and asourcefile so that the
Python in (15) linearizes to the English. Moreover,
Prograder should disprefer the inverse-scope reading
</bodyText>
<listItem confidence="0.973121666666667">
(17) asourcefile(lambda y:
everytextfile(lambda x:
mentions(y)(x)))
</listItem>
<bodyText confidence="0.999845888888889">
for the same English sentence. We do not see a way
to achieve these goals given GF’s limited support for
higher-order abstract syntax. Instead, we keep our
grammars first-order and let our abstract grammar
express only the surface structure of English, where
quantifiers stay “in situ” just like proper names.
Below we describe how even a first-order concrete
grammar for semantic representations can represent
quantifier meanings and scope preferences.
</bodyText>
<sectionHeader confidence="0.97104" genericHeader="method">
5 Quantifier Scope, Negation and
Continuation Grammars
</sectionHeader>
<bodyText confidence="0.999953884615384">
Quantifier scoping has long been a key source of
difficulty in mapping natural language sentences to
logical forms. Scope ambiguities arise even in rela-
tively simple sentences such as (15), which any in-
structor might be expected to generate in specifying
programming assignment requirements. The scope
of negation is also problematic. An algorithm for
generating all possible quantifier scopings was de-
tailed by Hobbs and Shieber (1987). However, we
need a solution that prefers one highly likely default
scoping, that supports both interpretation and gener-
ation, and that is integrated with the type structure
of our semantic representation.
Compositional semantics based on continuations
(Barker, 2002) can represent preferred scoping of
quantifiers and negation without the semantic type-
shifting or syntactic underspecification (Hendriks,
1993; Steedman, 1996; Bos, 1995; Koller et al.,
2003) that typically complicates interpreting and
generating quantification. The rough idea is to gen-
eralize Montague’s PTQ (1974), so that every con-
stituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t:
not only does every NP denote the type (e ✦ t) ✦ t
instead of e, but every VP also denotes the type
((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example
(as in PTQ),
</bodyText>
<listItem confidence="0.99263525">
(18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;)
(19) “every text file” denotes
lambda c:
everytextfile(lambda x: c(x))
</listItem>
<page confidence="0.981127">
61
</page>
<bodyText confidence="0.431662">
Analogously (but unlike in PTQ),
</bodyText>
<listItem confidence="0.681543666666667">
(20) “compiles” denotes lambda c: c(compiles)
(21) “mentions a source file” denotes
lambda c:
</listItem>
<equation confidence="0.5283735">
asourcefile(lambda x:
c(mentions(x)))
</equation>
<bodyText confidence="0.926518333333333">
Recall from Section 4 that we model denotations as
the linearizations of abstract syntax trees. Therefore,
in GF, we want to specify linearizations like
</bodyText>
<equation confidence="0.989000714285714">
lin EverySourceFile =
lambda c:
everysourcefile(lambda x: c(x));
lin Compiles = lambda c: c(compiles);
to be combined by the linearization of ApplyS
lin ApplyS NP VP =
NP(lambda n: VP(lambda v: v(n)));
</equation>
<bodyText confidence="0.994441428571429">
into the expression (5).
In this last linearization, the innermost application
v(n) means to apply the VP’s predicate meaning
to the subject NP’s entity meaning. The surround-
ing NP(lambda n: VP(lambda v: ...)) lets a
quantificational subject take wide scope over the VP.
This general composition rule thus yields surface
scope to the exclusion of inverse scope. In particu-
lar, it equally well combines the denotations in (19)
and (21) into the expression (15), rather than (17).
In the present implementation of Prograder, the rules
all encode surface scope for the quantifiers. A simi-
lar linearization forms the VP denotation in (21) by
composing a transitive verb and its object NP:
</bodyText>
<equation confidence="0.8633795">
lin ApplyVP VT NP =
lambda c: NP(lambda n: c(VT(n)))
</equation>
<bodyText confidence="0.9998575">
The same machinery generalizes to handle posses-
sives, ditransitive verbs, relative clauses, and so on.
</bodyText>
<subsectionHeader confidence="0.999224">
5.1 Simulating higher-order functions
</subsectionHeader>
<bodyText confidence="0.999928421052632">
As shown above, denotations using continuations
are higher-order functions. However, linearization
in GF does not allow higher-order functions—in
fact, the only “functions” allowed in GF are record
or table structures indexed by a finite set of parame-
ters. To keep parsing tractable, GF only lets strings
be concatenated, not beta-reduced as lambda-terms;
the one extension that GF makes to the context-free
model is allowing argument suppression and repeti-
tion. In other words, GF cannot equate logical forms
by beta-equivalence. Therefore, we cannot just feed
the pseudocode above into GF to generate explana-
tions. This is an instance of the problem of logical-
form equivalence (Shieber, 1993).
Fortunately, because denotations using continua-
tions are always of a certain form (Danvy and Filin-
ski, 1992), we can simulate these higher-order func-
tions using first-order records. Specifically, we sim-
ulate a higher-order function of the form
</bodyText>
<listItem confidence="0.818127">
(22) lambda c: sl c(sm) sr
by the triple of strings
(23) { s_l = sl; s_m = sm; s_r = sr }
</listItem>
<bodyText confidence="0.9996838">
in GF. The middle string sm corresponds to the
“core” of the phrase, and the left and right strings
sl❀sr are those parts which may take scope over other
phrases. For example, following the pseudocode
above, we write
</bodyText>
<equation confidence="0.998828375">
lin EverySourceFile = {
s_l = &amp;quot;everysourcefile ( lambda x :&amp;quot;;
s_m = &amp;quot;x&amp;quot;;
s_r = )&amp;quot; };
lin Compiles = {
s_l = &amp;quot;&amp;quot;;
s_m = &amp;quot;compiles&amp;quot;;
s_r = &amp;quot;&amp;quot; };
</equation>
<bodyText confidence="0.99768375">
in our GF concrete grammar. Continuing to follow
the pseudocode above, we can also implement the
linearizations of ApplyS and ApplyVP to operate on
triples rather than the functions they simulate:
</bodyText>
<equation confidence="0.998205125">
lin ApplyS NP VP = {
s = NP.s_l ++ VP.s_l ++
VP.s_m ++ &amp;quot;(&amp;quot; ++ NP.s_m ++ &amp;quot;)&amp;quot; ++
VP.s_r ++ NP.s_r };
lin ApplyVP VT NP = {
s_l = NP.s_l;
s_m = VT.s ++ NP.s_m;
s_r = NP.s_r };
</equation>
<bodyText confidence="0.9995064">
Here the linearization of the transitive verb VT con-
sists of a single string s.
This simulation is reminiscent of Barker and
Shan’s “tower notation” (2008). In general, we
can simulate a n-level semantic tower by a tuple of
</bodyText>
<page confidence="0.998184">
62
</page>
<bodyText confidence="0.99349075">
2n - 1 strings. Overall, this simulation makes us
hopeful that linearization in GF can be extended to a
broad, useful class of higher-order expressions while
keeping parsing tractable.
</bodyText>
<subsectionHeader confidence="0.999886">
5.2 Maintaining De Morgan duals
</subsectionHeader>
<bodyText confidence="0.999977166666667">
Both to interpret requirements and to generate ex-
planations, our system needs to deal with negation
correctly. Whether in the form of a negative quanti-
fier such as “no source file” or a VP modifier such as
“don’t”, negation takes scope. (In the case of the de-
terminer “no”, the scope of negation is linked to the
containing NP.) We use continuations to account for
the scope of negation, as for all scope-taking.
When scope ambiguities arise, negation exhibits
the same preference for surface scope as other quan-
tifiers. For example, all of the sentences below pre-
fer the reading where the subject takes wide scope.
</bodyText>
<listItem confidence="0.993644333333333">
(24) A source file doesn’t compile.
(25) A text file mentions no source file.
(26) No text file mentions a source file.
</listItem>
<bodyText confidence="0.994434666666667">
The linearization of ApplyS shown above already
captures this preference; we just need to specify new
linearizations with not_b in them. The pseudocode
</bodyText>
<equation confidence="0.991419166666667">
lin NoSourceFile =
lambda c:
not_b(asourcefile(lambda x: c(x)));
lin Not_VP VP =
lambda c:
not_b(VP(lambda v: c(v)));
</equation>
<bodyText confidence="0.991796428571429">
captures the fact that the negation of “A source file
compiles” is not (24) but “No source file compiles”.
To generate natural-sounding negations of sen-
tences containing quantification, some simple logi-
cal equivalences are necessary. To take an extreme
example, suppose that Prograder needs to negate the
requirement specification
</bodyText>
<listItem confidence="0.962495">
(27) Every text file mentions no source file.
Strictly speaking, it would be correct to generate
(28) Not every text file mentions no source file.
</listItem>
<bodyText confidence="0.8924525">
However, it would be much more comprehensible
for Prograder to report instead
</bodyText>
<listItem confidence="0.454894">
(29) A text file mentions a source file.
</listItem>
<bodyText confidence="0.999971541666667">
One heuristic for preferring (29) over (28) is to use
as few negations as possible. But to apply this
heuristic, Prograder must first realize that (29) is a
correct negation of (27). In general, our concrete
grammar ought to equate formulas that are equiv-
alent by De Morgan’s laws. Unfortunately, GF can
no more equate formulas by De Morgan equivalence
than by beta-equivalence.
In lieu of equating formulas, we normalize them:
we use De Morgan’s laws to move negations log-
ically as far “inside” as possible. In other words,
we impose an invariant on our semantic represen-
tation, that not_b applies only to atomic formulas
(as in (8–9)). This invariant is easy to enforce in
our Python code for gathering evidence, because we
can rewrite each evidence statement after generating
it. It is trickier to enforce the invariant in our GF
concrete grammar for semantic representations, be-
cause (to keep parsing tractable) linearizations can
only be concatenated, never inspected and rewritten.
Therefore, our linearizations must maintain formu-
las alongside their De Morgan duals.
Specifically, we revise the simulation described in
the previous section as follows. The record
</bodyText>
<equation confidence="0.575933666666667">
(30) { spl = s✰l ; spm = s✰m; spr = s✰r ;
snl = s-l ; snm = sm; snr = sr ;
switched = False }
</equation>
<bodyText confidence="0.849002">
represents a higher-order function of the form
</bodyText>
<listItem confidence="0.766790333333333">
(31) lambda c: s✰l c(s✰m) s✰r
assuming that it is equivalent to
(32) lambda c: not_b(si not_b(c(sm)) sr )
</listItem>
<bodyText confidence="0.499002">
Dually, the record
</bodyText>
<equation confidence="0.469175666666667">
(33) { spl = s✰l ; spm = s✰m; spr = s✰r ;
snl = sl ; snm = sm; snr = sr ;
switched = True }
</equation>
<bodyText confidence="0.748418">
represents a higher-order function of the form
</bodyText>
<listItem confidence="0.905791666666667">
(34) lambda c: s✰l not_b(c(s✰m)) s✰r
assuming that it is equivalent to
(35) lambda c: not_b(si c(sm) sr )
</listItem>
<bodyText confidence="0.934779">
For example, given the linearizations
</bodyText>
<page confidence="0.979481">
63
</page>
<equation confidence="0.988069611111111">
lin NoSourceFile = {
spl = &amp;quot;everysourcefile ( lambda x :&amp;quot;;
spm = &amp;quot;x&amp;quot;; spr = &amp;quot;)&amp;quot;;
snl = &amp;quot;asourcefile ( lambda x :&amp;quot;;
snm = &amp;quot;x&amp;quot;; snr = &amp;quot;)&amp;quot;;
switched = True };
lin EverySourceFile = {
spl = &amp;quot;everysourcefile ( lambda y :&amp;quot;;
spm = &amp;quot;y&amp;quot;; spr = &amp;quot;)&amp;quot;;
snl = &amp;quot;asourcefile ( lambda y :&amp;quot;;
snm = &amp;quot;y&amp;quot;; snr = &amp;quot;)&amp;quot;;
switched = False };
lin ASourceFile = {
spl = &amp;quot;asourcefile ( lambda x :&amp;quot;;
spm = &amp;quot;x&amp;quot;; spr = &amp;quot;)&amp;quot;;
snl = &amp;quot;everysourcefile ( lambda x :&amp;quot;;
snm = &amp;quot;x&amp;quot;; snr = &amp;quot;)&amp;quot;;
switched = False };
</equation>
<bodyText confidence="0.9997001">
(and an alphabetic variant of ASourcefile), Pro-
grader uses the switched flags to deduce that one
way to negate “Every source file mentions no source
file” is “A source file mentions a source file”.
Our solution demonstrates that an existing gram-
matical software package can express continuation
grammars. While the record-based implementation
is somewhat unwieldy when encoded in the gram-
mar by hand, restricting ourselves to GF’s context-
free rewrite grammars also ensures efficient parsing.
</bodyText>
<sectionHeader confidence="0.978185" genericHeader="method">
6 Putting It All Together
</sectionHeader>
<bodyText confidence="0.936261225">
Currently, our English grammar supports declarative
sentences with a small vocabulary of transitive and
intransitive verbs (“exists”, “compiles”, “has com-
ments”, “mentions”), proper noun phrases referring
to specific source files, noun phrases representing
quantified nouns, and negations.
Given that the grammars correctly specify logi-
cal scoping and natural language syntax for parsing
and generation, the Python code that implements re-
quirement checking and evidence gathering is rela-
tively straightforward. As described above, the log-
ical form of the requirements specification is exe-
cutable Python, and their execution emits an evi-
dence statement in the same logical language for
each check performed, in a tree structure. Thus
the execution of the checking code is an evidence-
gathering or proof-search process. The evidence
statements are then translated to natural language by
means of the two GF grammars.
A Python “glue script” ties the Python and GF
components together and manages the dataflow of
the end-to-end system. This script provides a simple
scanner and symbol table to replace file names with
standardized placeholders from the grammar. The
variables used in lambda expressions also need to be
renamed in order to prevent conflicts.
Here is a sample output of the system as it cur-
rently runs:
./runPrograder.py &apos;every source file
compiles and every source file has
comments&apos;
******************************
RESULT: False, because:
some source files don&apos;t compile and
some source files don&apos;t have
comments:
&amp;quot;nowork2.c&amp;quot; doesn&apos;t compile
&amp;quot;nowork.c&amp;quot; doesn&apos;t compile
&amp;quot;nowork2.c&amp;quot; doesn&apos;t have comments
&amp;quot;nowork.c&amp;quot; doesn&apos;t have comments
</bodyText>
<sectionHeader confidence="0.99247" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999975454545455">
To our knowledge, Prograder incorporates the first
implementation of continuation-based semantics
within a grammatical framework that supports ef-
ficient parsing and generation. Consequently, our
declarative grammar uniformly expresses quantifier
meanings and scope preferences.
We want to see how far we can stretch a record-
based grammar system such as GF to handle quan-
tifiers and negation using continuations. In the end,
the boilerplate ingredients of our solution ought to
be automated, so as to combine the expressivity of
continuation-based semantics with the usability and
efficiency of GF. This will also make it easier to ex-
pand the range of natural-language constructs that
the system handles. Of course, this development
should be driven by feedback from actual instructors
using the system, which we also intend to obtain.
Our second area of future work is the summa-
rization of explanations. We plan to use Prograder
to investigate the semantics and pragmatics of sum-
marization, and to search for underlying principles
based on proofs and types.
</bodyText>
<page confidence="0.999166">
64
</page>
<sectionHeader confidence="0.995773" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999360651515152">
Alfred V. Aho and Jeffrey D. Ullman. 1969. Syn-
tax directed translations and the pushdown assembler.
Journal of Computer and System Sciences, 3(1):37–
56, February.
Chris Barker and Chung-chieh Shan. 2008. Donkey
anaphora is in-scope binding. Semantics and Prag-
matics, 1(1):1–46.
Chris Barker. 2002. Continuations and the na-
ture of quantification. Natural Language Semantics,
10(3):211–242.
Johan Bos. 1995. Predicate logic unplugged. In Paul
Dekker and Martin Stokhof, editors, Proceedings of
the 10th Amsterdam Colloquium, pages 133–142. In-
stitute for Logic, Language and Computation, Univer-
siteit van Amsterdam.
Olivier Danvy and Andrzej Filinski. 1992. Representing
control: A study of the CPS transformation. Math-
ematical Structures in Computer Science, 2(4):361–
391, December.
Philippe de Groote. 2002. Towards abstract catego-
rial grammars. In Proceedings of the 40th Annual
Meeting of the Association for Computational Linguis-
tics, pages 148–155, San Francisco, CA, July. Morgan
Kaufmann.
Pierre-Joseph Gailly. 1988. Expressing quantifier scope
in French generation. In COLING ’88: Proceedings of
the 12th International Conference on Computational
Linguistics, volume 1, pages 182–184.
Herman Hendriks. 1993. Studied Flexibility: Categories
and Types in Syntax and Semantics. Ph.D. thesis, In-
stitute for Logic, Language and Computation, Univer-
siteit van Amsterdam.
Jerry R. Hobbs and Stuart M. Shieber. 1987. An al-
gorithm for generating quantifier scopings. Compu-
tational Linguistics, 13(1–2):47–63.
Paul Hudak. 1996. Building domain-specific embedded
languages. ACM Computing Surveys, 28.
Alexander Koller, Joachim Niehren, and Stefan Thater.
2003. Bridging the gap between underspecification
formalisms: Hole semantics as dominance constraints.
In Proceedings of the 10th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 195–202, Somerset, NJ. Association for
Computational Linguistics.
Richard Montague. 1974. The proper treatment of
quantification in ordinary English. In Richmond H.
Thomason, editor, Formal Philosophy: Selected Pa-
pers of Richard Montague, pages 247–270. Yale Uni-
versity Press, New Haven.
Douglas B. Moran. 1988. Quantifier scoping in the
SRI core language engine. In Proceedings of the 26th
Annual Meeting of the Association for Computational
Linguistics, pages 33–40, Somerset, NJ. Association
for Computational Linguistics.
Aarne Ranta. 2004. Grammatical Framework: A type-
theoretical grammar formalism. Journal of Functional
Programming, 14(2):145–189.
Stuart M. Shieber. 1993. The problem of logical-form
equivalence. Computational Linguistics, 19(1):179–
190.
Mark J. Steedman. 1996. Surface Structure and Inter-
pretation. MIT Press, Cambridge.
Kurt A. VanLehn. 1978. Determining the scope of
English quantifiers. Master’s thesis, Department of
Electrical Engineering and Computer Science, Mas-
sachusetts Institute of Technology.
</reference>
<page confidence="0.999619">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.384923">
<title confidence="0.999567">Generating Quantifiers and Negation to Explain Homework Testing</title>
<author confidence="0.967482">Perry</author>
<affiliation confidence="0.993958">Rutgers University Department of Computer Science</affiliation>
<abstract confidence="0.96896225">We describe Prograder, a software package for automatic checking of requirements for programming homework assignments. Prograder lets instructors specify requirements in natural language as well as explains grading results to students in natural language. It does so using a grammar that generates as well as parses to translate between a small fragment of English and a first-order logical specification language that can be executed directly in Python. This execution embodies multiple semantics—both to check the requirement and to search for evidence that proves or disproves the requirement. Such a checker needs to interpret and generate sentences containing quantifiers and negation. To handle quantifier and negation scope, we systematically simulate continuation grammars using record structures in the Grammatical Framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Syntax directed translations and the pushdown assembler.</title>
<date>1969</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>56</pages>
<contexts>
<context position="15153" citStr="Aho and Ullman, 1969" startWordPosition="2390" endWordPosition="2393">rammar for English can then specify that the linearization of EverySourceFile is a singular (Sg) string, lin EverySourceFile = { s = &amp;quot;every source file&amp;quot;; n = Sg }; the linearization of Compiles is a pair of strings, 60 lin Compiles = { s = { Sg =&gt; &amp;quot;compiles&amp;quot;; Pl =&gt; &amp;quot;compile&amp;quot; } }; and the linearization of ApplyS is a function that combines these two linearizations into the string (3). lin ApplyS NP VP = { s = NP.s ++ (VP.s ! NP.n) }; Here ++ denotes string concatenation and ! denotes table lookup. Multiple concrete grammars can share the same abstract grammar in GF, as in synchronous grammars (Aho and Ullman, 1969) and abstract categorial grammars (de Groote, 2002). This sharing is meant to enable multilingual applications, in which the same meaning representation defined by a single abstract grammar can be rendered into various natural languages by different concrete grammars. This separation into abstract and concrete grammars lets us use one concrete grammar to model English and another to model the Python syntax of Prograder’s logical forms. For example, the linearization of Compiles into Python is simply compiles, which can be combined with &amp;quot;foo.c&amp;quot; by the linearization of ApplyS to form compiles(&amp;quot;f</context>
</contexts>
<marker>Aho, Ullman, 1969</marker>
<rawString>Alfred V. Aho and Jeffrey D. Ullman. 1969. Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3(1):37– 56, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Barker</author>
<author>Chung-chieh Shan</author>
</authors>
<title>Donkey anaphora is in-scope binding. Semantics and Pragmatics,</title>
<date>2008</date>
<marker>Barker, Shan, 2008</marker>
<rawString>Chris Barker and Chung-chieh Shan. 2008. Donkey anaphora is in-scope binding. Semantics and Pragmatics, 1(1):1–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Barker</author>
</authors>
<title>Continuations and the nature of quantification.</title>
<date>2002</date>
<journal>Natural Language Semantics,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="18171" citStr="Barker, 2002" startWordPosition="2850" endWordPosition="2851">tences to logical forms. Scope ambiguities arise even in relatively simple sentences such as (15), which any instructor might be expected to generate in specifying programming assignment requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every constituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t: not only does every NP denote the type (e ✦ t) ✦ t instead of e, but every VP also denotes the type ((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example (as in PTQ), (18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;) (19) “e</context>
</contexts>
<marker>Barker, 2002</marker>
<rawString>Chris Barker. 2002. Continuations and the nature of quantification. Natural Language Semantics, 10(3):211–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Predicate logic unplugged.</title>
<date>1995</date>
<booktitle>Proceedings of the 10th Amsterdam Colloquium,</booktitle>
<pages>133--142</pages>
<editor>In Paul Dekker and Martin Stokhof, editors,</editor>
<location>van Amsterdam.</location>
<contexts>
<context position="18340" citStr="Bos, 1995" startWordPosition="2872" endWordPosition="2873">ng assignment requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every constituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t: not only does every NP denote the type (e ✦ t) ✦ t instead of e, but every VP also denotes the type ((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example (as in PTQ), (18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;) (19) “every text file” denotes lambda c: everytextfile(lambda x: c(x)) 61 Analogously (but unlike in PTQ), (20) “compiles” denotes lambda c: c(compiles) (21) “mentions a source</context>
</contexts>
<marker>Bos, 1995</marker>
<rawString>Johan Bos. 1995. Predicate logic unplugged. In Paul Dekker and Martin Stokhof, editors, Proceedings of the 10th Amsterdam Colloquium, pages 133–142. Institute for Logic, Language and Computation, Universiteit van Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Danvy</author>
<author>Andrzej Filinski</author>
</authors>
<title>Representing control: A study of the CPS transformation.</title>
<date>1992</date>
<journal>Mathematical Structures in Computer Science,</journal>
<volume>2</volume>
<issue>4</issue>
<pages>391</pages>
<contexts>
<context position="21041" citStr="Danvy and Filinski, 1992" startWordPosition="3305" endWordPosition="3309">d in GF are record or table structures indexed by a finite set of parameters. To keep parsing tractable, GF only lets strings be concatenated, not beta-reduced as lambda-terms; the one extension that GF makes to the context-free model is allowing argument suppression and repetition. In other words, GF cannot equate logical forms by beta-equivalence. Therefore, we cannot just feed the pseudocode above into GF to generate explanations. This is an instance of the problem of logicalform equivalence (Shieber, 1993). Fortunately, because denotations using continuations are always of a certain form (Danvy and Filinski, 1992), we can simulate these higher-order functions using first-order records. Specifically, we simulate a higher-order function of the form (22) lambda c: sl c(sm) sr by the triple of strings (23) { s_l = sl; s_m = sm; s_r = sr } in GF. The middle string sm corresponds to the “core” of the phrase, and the left and right strings sl❀sr are those parts which may take scope over other phrases. For example, following the pseudocode above, we write lin EverySourceFile = { s_l = &amp;quot;everysourcefile ( lambda x :&amp;quot;; s_m = &amp;quot;x&amp;quot;; s_r = )&amp;quot; }; lin Compiles = { s_l = &amp;quot;&amp;quot;; s_m = &amp;quot;compiles&amp;quot;; s_r = &amp;quot;&amp;quot; }; in our GF concr</context>
</contexts>
<marker>Danvy, Filinski, 1992</marker>
<rawString>Olivier Danvy and Andrzej Filinski. 1992. Representing control: A study of the CPS transformation. Mathematical Structures in Computer Science, 2(4):361– 391, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe de Groote</author>
</authors>
<title>Towards abstract categorial grammars.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>148--155</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Francisco, CA,</location>
<marker>de Groote, 2002</marker>
<rawString>Philippe de Groote. 2002. Towards abstract categorial grammars. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 148–155, San Francisco, CA, July. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre-Joseph Gailly</author>
</authors>
<title>Expressing quantifier scope in French generation.</title>
<date>1988</date>
<booktitle>In COLING ’88: Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>182--184</pages>
<contexts>
<context position="3843" citStr="Gailly, 1988" startWordPosition="591" endWordPosition="592">ovative Use of NLP for Building Educational Applications, pages 57–65, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics to students like (2) Credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h. As this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation. Although the interpretation of quantifiers and negation is a traditional research area in computational linguistics (VanLehn, 1978; Hobbs and Shieber, 1987; Moran, 1988), their generation is much less studied (Gailly, 1988). Even if our system were to compose explanations entirely from the input specification sentences and their negation, it cannot negate a specification sentence merely by adding or removing verbal auxiliaries: the negation of “a source file defines main()” is not “a source file does not define main()”. 1.1 Contributions We have built Prograder, a rudimentary programming-assignment tester that correctly interprets and generates a small fragment of English that includes quantifiers and negation. This paper describes the architecture of Prograder. Our implementation uses a declarative grammar that</context>
</contexts>
<marker>Gailly, 1988</marker>
<rawString>Pierre-Joseph Gailly. 1988. Expressing quantifier scope in French generation. In COLING ’88: Proceedings of the 12th International Conference on Computational Linguistics, volume 1, pages 182–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herman Hendriks</author>
</authors>
<title>Studied Flexibility: Categories and Types in Syntax and Semantics.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Institute for Logic, Language and Computation, Universiteit van Amsterdam.</institution>
<contexts>
<context position="18313" citStr="Hendriks, 1993" startWordPosition="2868" endWordPosition="2869">generate in specifying programming assignment requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every constituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t: not only does every NP denote the type (e ✦ t) ✦ t instead of e, but every VP also denotes the type ((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example (as in PTQ), (18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;) (19) “every text file” denotes lambda c: everytextfile(lambda x: c(x)) 61 Analogously (but unlike in PTQ), (20) “compiles” denotes lambda c: c(compil</context>
</contexts>
<marker>Hendriks, 1993</marker>
<rawString>Herman Hendriks. 1993. Studied Flexibility: Categories and Types in Syntax and Semantics. Ph.D. thesis, Institute for Logic, Language and Computation, Universiteit van Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Stuart M Shieber</author>
</authors>
<title>An algorithm for generating quantifier scopings.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--1</pages>
<contexts>
<context position="3775" citStr="Hobbs and Shieber, 1987" startWordPosition="579" endWordPosition="582">idualized explanations Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 57–65, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics to students like (2) Credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h. As this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation. Although the interpretation of quantifiers and negation is a traditional research area in computational linguistics (VanLehn, 1978; Hobbs and Shieber, 1987; Moran, 1988), their generation is much less studied (Gailly, 1988). Even if our system were to compose explanations entirely from the input specification sentences and their negation, it cannot negate a specification sentence merely by adding or removing verbal auxiliaries: the negation of “a source file defines main()” is not “a source file does not define main()”. 1.1 Contributions We have built Prograder, a rudimentary programming-assignment tester that correctly interprets and generates a small fragment of English that includes quantifiers and negation. This paper describes the architect</context>
<context position="17903" citStr="Hobbs and Shieber (1987)" startWordPosition="2810" endWordPosition="2813">scribe how even a first-order concrete grammar for semantic representations can represent quantifier meanings and scope preferences. 5 Quantifier Scope, Negation and Continuation Grammars Quantifier scoping has long been a key source of difficulty in mapping natural language sentences to logical forms. Scope ambiguities arise even in relatively simple sentences such as (15), which any instructor might be expected to generate in specifying programming assignment requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every </context>
</contexts>
<marker>Hobbs, Shieber, 1987</marker>
<rawString>Jerry R. Hobbs and Stuart M. Shieber. 1987. An algorithm for generating quantifier scopings. Computational Linguistics, 13(1–2):47–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Hudak</author>
</authors>
<title>Building domain-specific embedded languages.</title>
<date>1996</date>
<journal>ACM Computing Surveys,</journal>
<volume>28</volume>
<contexts>
<context position="7146" citStr="Hudak, 1996" startWordPosition="1116" endWordPosition="1117">yS EverySourceFile Compiles Interpreting this tree compositionally gives the meaning of the sentence: (5) everysourcefile(lambda x: compiles(x)) On one hand, this expression is a formula in predicate logic. In general, each requirement specification is a sentence, whose truth value is determined by checking a single student’s programming assignment. We use the types of Montague grammar (1974), which are the base type of entities e, the base type of propositions t, and function types notated by ✦. Our logical language is defined by a domain-specific vocabulary of typed predicates and entities (Hudak, 1996). Naturally, the files submitted by the student are entities. 58 For example, the unary predicates compiles and hascomments have the type e ✦ t, and the binary predicate mentions has the type e ✦ e ✦ t. These predicates in our vocabulary represent various properties of submitted files that instructors may want to check. Logical connectives are also part of the vocabulary; for instance, and and or have the type t ✦ t ✦ t, not_b has the type t ✦ t, and everysourcefile has the type (e ✦ t) ✦ t. Therefore, the expression (5) has the type t, as do the expressions (6) compiles(&amp;quot;foo.c&amp;quot;) (7) and(compi</context>
</contexts>
<marker>Hudak, 1996</marker>
<rawString>Paul Hudak. 1996. Building domain-specific embedded languages. ACM Computing Surveys, 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Joachim Niehren</author>
<author>Stefan Thater</author>
</authors>
<title>Bridging the gap between underspecification formalisms: Hole semantics as dominance constraints.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>195--202</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Somerset, NJ.</location>
<contexts>
<context position="18362" citStr="Koller et al., 2003" startWordPosition="2874" endWordPosition="2877">nt requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every constituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t: not only does every NP denote the type (e ✦ t) ✦ t instead of e, but every VP also denotes the type ((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example (as in PTQ), (18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;) (19) “every text file” denotes lambda c: everytextfile(lambda x: c(x)) 61 Analogously (but unlike in PTQ), (20) “compiles” denotes lambda c: c(compiles) (21) “mentions a source file” denotes lambda </context>
</contexts>
<marker>Koller, Niehren, Thater, 2003</marker>
<rawString>Alexander Koller, Joachim Niehren, and Stefan Thater. 2003. Bridging the gap between underspecification formalisms: Hole semantics as dominance constraints. In Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics, pages 195–202, Somerset, NJ. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>The proper treatment of quantification in ordinary English. In</title>
<date>1974</date>
<booktitle>Formal Philosophy: Selected Papers of Richard Montague,</booktitle>
<pages>247--270</pages>
<editor>Richmond H. Thomason, editor,</editor>
<publisher>Yale University Press,</publisher>
<location>New Haven.</location>
<marker>Montague, 1974</marker>
<rawString>Richard Montague. 1974. The proper treatment of quantification in ordinary English. In Richmond H. Thomason, editor, Formal Philosophy: Selected Papers of Richard Montague, pages 247–270. Yale University Press, New Haven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas B Moran</author>
</authors>
<title>Quantifier scoping in the SRI core language engine.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Somerset, NJ.</location>
<contexts>
<context position="3789" citStr="Moran, 1988" startWordPosition="583" endWordPosition="584">oceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 57–65, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics to students like (2) Credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h. As this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation. Although the interpretation of quantifiers and negation is a traditional research area in computational linguistics (VanLehn, 1978; Hobbs and Shieber, 1987; Moran, 1988), their generation is much less studied (Gailly, 1988). Even if our system were to compose explanations entirely from the input specification sentences and their negation, it cannot negate a specification sentence merely by adding or removing verbal auxiliaries: the negation of “a source file defines main()” is not “a source file does not define main()”. 1.1 Contributions We have built Prograder, a rudimentary programming-assignment tester that correctly interprets and generates a small fragment of English that includes quantifiers and negation. This paper describes the architecture of Prograd</context>
</contexts>
<marker>Moran, 1988</marker>
<rawString>Douglas B. Moran. 1988. Quantifier scoping in the SRI core language engine. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 33–40, Somerset, NJ. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Grammatical Framework: A typetheoretical grammar formalism.</title>
<date>2004</date>
<journal>Journal of Functional Programming,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="13757" citStr="Ranta (2004)" startWordPosition="2141" endWordPosition="2142">tree and concatenating evidence statements, possibly using summarization techniques to make the explanation more concise. We have so far glossed over how English sentences, especially those with quantification and negation such as (14) and (16), are parsed into and generated from logical representations. The rest of this paper describes our principled approach to this problem, based on a consistent mapping between syntactic categories and semantic types. 4 Using the Grammatical Framework We relate natural language (English) to logical semantics (Python) using the Grammatical Framework (GF) of Ranta (2004). GF is a mature system that allows linguists and logicians to define grammars for both natural and formal languages using a Haskelllike syntax. Once defined, the grammars can be used for parsing as well as generation (linearization) with no further programming. In GF, grammars are specified in two parts: an abstract grammar and a concrete grammar. An abstract grammar specifies the set of well-formed abstract syntax trees, whereas a concrete grammar specifies how to spell out abstract syntax as strings. For example, an abstract grammar can admit the abstract syntax tree in (4) by specifying th</context>
</contexts>
<marker>Ranta, 2004</marker>
<rawString>Aarne Ranta. 2004. Grammatical Framework: A typetheoretical grammar formalism. Journal of Functional Programming, 14(2):145–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>The problem of logical-form equivalence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>190</pages>
<contexts>
<context position="20931" citStr="Shieber, 1993" startWordPosition="3291" endWordPosition="3292">ver, linearization in GF does not allow higher-order functions—in fact, the only “functions” allowed in GF are record or table structures indexed by a finite set of parameters. To keep parsing tractable, GF only lets strings be concatenated, not beta-reduced as lambda-terms; the one extension that GF makes to the context-free model is allowing argument suppression and repetition. In other words, GF cannot equate logical forms by beta-equivalence. Therefore, we cannot just feed the pseudocode above into GF to generate explanations. This is an instance of the problem of logicalform equivalence (Shieber, 1993). Fortunately, because denotations using continuations are always of a certain form (Danvy and Filinski, 1992), we can simulate these higher-order functions using first-order records. Specifically, we simulate a higher-order function of the form (22) lambda c: sl c(sm) sr by the triple of strings (23) { s_l = sl; s_m = sm; s_r = sr } in GF. The middle string sm corresponds to the “core” of the phrase, and the left and right strings sl❀sr are those parts which may take scope over other phrases. For example, following the pseudocode above, we write lin EverySourceFile = { s_l = &amp;quot;everysourcefile </context>
</contexts>
<marker>Shieber, 1993</marker>
<rawString>Stuart M. Shieber. 1993. The problem of logical-form equivalence. Computational Linguistics, 19(1):179– 190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark J Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="18329" citStr="Steedman, 1996" startWordPosition="2870" endWordPosition="2871">ifying programming assignment requirements. The scope of negation is also problematic. An algorithm for generating all possible quantifier scopings was detailed by Hobbs and Shieber (1987). However, we need a solution that prefers one highly likely default scoping, that supports both interpretation and generation, and that is integrated with the type structure of our semantic representation. Compositional semantics based on continuations (Barker, 2002) can represent preferred scoping of quantifiers and negation without the semantic typeshifting or syntactic underspecification (Hendriks, 1993; Steedman, 1996; Bos, 1995; Koller et al., 2003) that typically complicates interpreting and generating quantification. The rough idea is to generalize Montague’s PTQ (1974), so that every constituent’s semantic type has the form (✁ ✁ ✁ ✦ t) ✦ t: not only does every NP denote the type (e ✦ t) ✦ t instead of e, but every VP also denotes the type ((e ✦ t) ✦ t) ✦ t instead of e ✦ t. For example (as in PTQ), (18) “foo.c” denotes lambda c: c(&amp;quot;foo.c&amp;quot;) (19) “every text file” denotes lambda c: everytextfile(lambda x: c(x)) 61 Analogously (but unlike in PTQ), (20) “compiles” denotes lambda c: c(compiles) (21) “mentio</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Mark J. Steedman. 1996. Surface Structure and Interpretation. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt A VanLehn</author>
</authors>
<title>Determining the scope of English quantifiers.</title>
<date>1978</date>
<tech>Master’s thesis,</tech>
<institution>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology.</institution>
<contexts>
<context position="3750" citStr="VanLehn, 1978" startWordPosition="577" endWordPosition="578">nd return individualized explanations Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 57–65, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics to students like (2) Credit was lost because bar.c did not compile and no text file mentioned the files foo.h and baz.h. As this example illustrates, the tester needs to interpret and generate sentences with quantifiers and negation. Although the interpretation of quantifiers and negation is a traditional research area in computational linguistics (VanLehn, 1978; Hobbs and Shieber, 1987; Moran, 1988), their generation is much less studied (Gailly, 1988). Even if our system were to compose explanations entirely from the input specification sentences and their negation, it cannot negate a specification sentence merely by adding or removing verbal auxiliaries: the negation of “a source file defines main()” is not “a source file does not define main()”. 1.1 Contributions We have built Prograder, a rudimentary programming-assignment tester that correctly interprets and generates a small fragment of English that includes quantifiers and negation. This pape</context>
</contexts>
<marker>VanLehn, 1978</marker>
<rawString>Kurt A. VanLehn. 1978. Determining the scope of English quantifiers. Master’s thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>