<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992175">
Personal Health Information Leak Prevention in
Heterogeneous Texts
</title>
<author confidence="0.9808575">
Marina Sokolova&apos;, Khaled El Emam&apos;,&apos;, Sean Rose&apos;, Sadrul Chowdhury&apos;,
Emilio Neri&apos;, Elizabeth Jonker&apos;, Liam Peyton&apos;
</author>
<affiliation confidence="0.852295">
&apos;Electronic Health Information Lab
Children’s Hospital of Eastern Ontario
401 Smyth Rd., Ottawa, Canada, K1H 8L1
&apos; University of Ottawa
</affiliation>
<address confidence="0.901889">
800 King Edward, Ottawa, Canada, ON K1N 6N5
</address>
<email confidence="0.955936">
{msokolova, kelemam,srose,schowdhury,eneri,ejonker}@ehealthinformation.ca
lpeyton@site.uottawa.ca
</email>
<sectionHeader confidence="0.987623" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999714777777778">
We built a system which prevents leaks of per-
sonal health information inadvertently disclosed
in heterogeneous text data . The system works
with free-form texts. We empirically tested the
system on files gathered from peer-to-peer file ex-
change networks. This study presents our text
analysis apparatus. We discuss adaptation of
lexical sources used in medical, scientific, domain
for analysis of personal health information.
</bodyText>
<sectionHeader confidence="0.97838" genericHeader="keywords">
Keywords
</sectionHeader>
<keyword confidence="0.651538">
information leak prevention, personal health information
</keyword>
<sectionHeader confidence="0.997908" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999">
When electronic means became the prime instrument
for storage and exchange of personal health data, the
risks of inadvertent disclosure of personal health in-
formation (i.e., details of the individual’s health) had
increased. Inadvertently disclosed personal health in-
formation facilitates criminals to commit medical iden-
tity theft, i.e., allows an imposter to obtain care or
medications under someone else’s identity [10]. Fur-
thermore, PHI is an important source of identity theft
[14], and has been used by terrorist organizations to
target law enforcement personnel and intimidate wit-
nesses [21]. PHI security breaches had happened in
various domains. PHI has leaked from a Canadian
provincial government agency [6] and from health care
providers, through documents sent by employees and
medical students [18]. There are several examples of
the confirmed leaks on peer-to-peer file sharing net-
works: a chiropractor exposed his patient files on a
peer-to-peer network, including notes on treatments
and medications taken [20], a criminal obtained pass-
words for 117, 000 medical records through a file shar-
ing network [24]. In this work, we present a system
which detects personal health information (PHI) in
free-form heterogenous texts. It can be used to de-
tect the inadvertent disclosure of PHI, thus, benefit
information leak detection.
Texts which contain personal health information can
be written by doctors, nurses, medical students or pa-
tients and can be obtained from various sources within
the health care network. Hospitals provide patient
health records (e.g. speech assessment, discharge sum-
maries, nurse notes), patients write letters, notes, etc.
These texts can be found on the web, within peer-
to-peer file exchange networks, and on second-hand
disk drives [12, 25]. Within those texts, we seek the
information which refers to individual’s health: dis-
ease (pneumonia)&apos;, treatment procedures (X-rays), pre-
scribed drugs (aspirin), health care providers (the Ap-
ple Tree Medical Centre). Our system contributes to
information leak prevention, a growing content-based
part of data leak prevention.
There are several differences between our tool and
the previous work on PHI leak prevention. Our sys-
tem detects personally identifiable and health infor-
mation. Previous work focussed on detection and
de-identification of personally identifiable informa-
tion (.e.g,, person names, phone numbers, age-related
dates), but did not retrieve health information. Our
system processes data of unknown content, context
and structure. Whereas, previously the PHI leak pre-
vention systems operated within a closed domain of
hospital patient records, where the input data was
guaranteed to contain PHI. As we mentioned, these
systems were built to find and alter personally identi-
fiable information, e.g., name, age, phone.
In our case, the input files come with unknown con-
tent. Sometimes the file content excludes a possibility
of personal information, e.g., a young-adult vampire-
romance novel Twilight, a research presentation Statis-
tical Learning Theory, a song Quel Temps Fait Il A Paris.
</bodyText>
<footnote confidence="0.626584">
1 Hereinafter, this font signifies examples.
</footnote>
<page confidence="0.987727">
58
</page>
<bodyText confidence="0.986627647058823">
Workshop Adaptation of Language Resources and Technology to New Domains 2009 - Borovets, Bulgaria, pages 58–69
Sometimes, file contents may suggest holding personal
information and PHI, e.g., personal correspondence,
documents from lawyer or physician offices. In many
other cases, files fall between these two categories. We
discard files which we identify as being highly unlikely
to contain PHI and concentrate on the analysis of the
remaining files. In the remainder of the presentation,
we define personal health information, provide exam-
ples of texts containing PHI and discuss the extent
of confirmed inadvertent PHI leaks. We define pairs
of possible/impossible and probable/improbable PHI
containers. Our data and empirical results are pre-
sented after that. We follow with discussion of related
work and motives for the adaptation of medical knowl-
edge sources. At the end, we present plans for future
work and conclusions.
</bodyText>
<sectionHeader confidence="0.987363" genericHeader="method">
2 Background
</sectionHeader>
<bodyText confidence="0.996811857142857">
Our group works on prevention of inadvertent disclo-
sure of personal health information in heterogenous
text data. Personal health information (PHI) refers to
ailments, treatments and other health-specific details
of an individual. In Ontario, Canada, the Personal
Health Information Protection Act [1] defines PHI as
information that:
</bodyText>
<listItem confidence="0.977979333333333">
1. relates to the physical or mental health of the indi-
vidual, including information that consists of the
health history of the individual’s family
2. relates to the providing of health care to the indi-
vidual, including the identification of a person as
a provider of health care to the individual,
3. is a plan of service within the meaning of the
Long-Term Care Act for the individual
4. relates to payments or eligibility for health care,
or eligibility for coverage for health care, in re-
spect of the individual
5. relates to the donation by the individual of any
body part or bodily substance of the individual
or is derived from the testing or examination of
any such body part or bodily substance
6. is the individual’s health number
7. identifies an individual’s substitute decision-
maker.
</listItem>
<bodyText confidence="0.9868065">
It also states that “[identifying information] identifies
an individual or for which it is reasonably foreseeable
in the circumstances that it could be utilized, either
alone or with other information, to identify an indi-
vidual” [1]. Below we present samples of texts with
PHI:
</bodyText>
<note confidence="0.9587724">
[THE PATIENT] ADMITTED IN TRANSFER
FROM [HOSPITAL NAME] FOR MENTAL STATUS
CHANGES POST FALL AT HOME AND CONTIN-
UED HYPOTENSION AT CALVERT HOSPITAL
REQUIRING DOPAMINE;
</note>
<bodyText confidence="0.9552922">
[The person]’s heart attack happened on a sidewalk in
Midtown Manhattan last May. He was walking back
to work along Third Avenue with two colleagues after a
several-hundred-dollar sushi lunch. There was the distant
rumble of heartburn, the ominous tingle of perspiration.
</bodyText>
<construct confidence="0.986959833333333">
I, [John Doe], want to make the following statement
under Oath: On 02 May 2007, in duty hours between
1030 1100 hrs I was practicing drill exercises for our
next mobilization to [Place Name, Country]. In that
exercise trying to put someone under arrest the person
fell down on my left knee causing me a contusion.
</construct>
<bodyText confidence="0.999908142857143">
The act protects the confidentiality of PHI and the
privacy of individuals with respect to that informa-
tion, while facilitating the effective provision of health
care. Similar PHI protection acts have been enabled:
US has the Health Insurance Portability and Account-
ability Act, often known as HIPAA 2, EU – Directive
95/46/EC , or, Data Protection Directive 3, although
some details vary.
We divide PHI into two broad categories: personally
identifiable information (PII), e.g., name, birth data,
address, and health information (HI), e.g., diagnosis,
prescribed drugs. Table 1 lists some PII and HI sub-
categories and their examples. Further, in this paper,
we concentrate on the HI category.
</bodyText>
<figure confidence="0.380019538461538">
Personal information
Info categories Examples
Given names Serge, Jasmine
Locations London, Osaka
Addresses 401 Smyth Rd.,
Empire State Bldg.
Dates 02 May 2008, 05/14/07
Health information
Info categories Examples
Disease names Pneumonia, arthritis
Symptoms calcium deficiency
Drug names Aspirin, Fosamax
Health care providers CHEO, Dr. Joe Doe
</figure>
<tableCaption confidence="0.992001">
Table 1: PHI categories and their examples
</tableCaption>
<bodyText confidence="0.999259428571429">
Previously, second hand disk drives and peer-to-peer
file exchange networks (p2p networks) were searched
for the presence of texts with PHI [12, 25]. In [12], we
studied the extent of inadvertent PHI exposure on sec-
ond hand computer hard drives. We purchased func-
tional disk drives from various second-hand computer
equipment vendors, then examined sixty drives using
</bodyText>
<footnote confidence="0.995919666666667">
2 http://www.hhs.gov/ocr/privacy/index.html
3 http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=
-CELEX:31995L0046:EN:HTML
</footnote>
<page confidence="0.999425">
59
</page>
<bodyText confidence="0.999912357142857">
digital forensic tools. The focus was on drives with a
capacity range of 10 GB to 40 GB, which were used by
individual end users in desktop machines and servers.
The recovered data was examined manually by two
experts. PHI was found in 425 files gathered from
11(18%) disk drives. 5 disk drives contained PHI of
the computer owner, 6 disks – PHI of other people. In
[25], we suggested evaluation measures for automated
detection of PHI files. We semi-manually examined
859 files gathered from two p2p networks. 8(1%) files
contained PHI. Although the number of files was com-
paratively small, the personal health information con-
tained in these files potentially was exposed to millions
of on-lookers.
</bodyText>
<sectionHeader confidence="0.999367" genericHeader="method">
3 Methods
</sectionHeader>
<subsectionHeader confidence="0.995443">
3.1 Files as Personal Health Informa-
tion Containers
</subsectionHeader>
<bodyText confidence="0.9996985">
We consider that among heterogeneous files of un-
known content, some files can be possible containers
of personal information, whereas others cannot, i.e.
impossible containers. Only the possible containers
which contain personal information may become prob-
able sources of PHI leaks. The files become actual
PHI leaks if they additionally contain health informa-
tion. The impossible containers are improbable to leak
personal information, and consequently, improbable to
leak PHI. In other words,
</bodyText>
<equation confidence="0.998144">
DATA = POS + POS′ (1)
PHI C PROB C POS (2)
POS′ C PROB′ C PHI′ (3)
</equation>
<bodyText confidence="0.9999962">
where DATA denotes the data, POS is a set of possi-
ble containers, PROB – a set of probable containers,
PHI – a set of files with PHI. ′ marks the set comple-
ment. Based on the set relations 1–3 , we apply the
following rules of inference (f denotes a file):
</bodyText>
<equation confidence="0.9988125">
f E POS′ —* f E PROB′ —* f E PHI′ (4)
f E PHI —* f E PROB —* f E POS (5)
</equation>
<bodyText confidence="0.993206666666667">
To categorize files into POS or POS′, we recall that
personal information is information which identifies an
individual, either by itself or jointly with other infor-
mation (see Section 2). According to this definition,
two types of files immediately fall into the impossible
container category:
</bodyText>
<listItem confidence="0.9823505">
1. contents not concerned with individuals;
2. contents not able to identify individuals.
</listItem>
<bodyText confidence="0.997472043478261">
To find the first type, we look for files with con-
tent unrelated to individuals, e.g., fictions, songs . To
find the second type, we look for files whose content
is unreadable for end users, e.g viruses. All the other
files might or might not contain personal information,
and are put into the possible container category. From
those, only the files that are shown to contain personal
information are marked for further investigation, i.e.
health information detection.
Rules 4 – 5 are used in our text analysis system. The
system’s work cycle has three phases. On the first two
phases, it identifies impossible containers and removes
them from the set. On the third phase, it works with
the remaining files which we consider to be possible
containers. The utilized text analysis gradually deep-
ens:
shallow analysis the file titles and contents are
treated as streams of characters (phase 1);
partial content analysis for each file, a limited key-
word search is performed on a small portion of
text (phase 2);
deep content analysis texts are mined for syntactic
and semantic patterns (phase 3).
</bodyText>
<subsectionHeader confidence="0.99977">
3.2 Creating the Corpus
</subsectionHeader>
<bodyText confidence="0.999971457142857">
For our experiments, we used files gathered from
two peer-to-peer file sharing networks (p2p networks).
Peer-to-peer networks allow decentralized sharing of
computer resources, including those that provide the
infrastructure for direct, real-time communication and
collaboration between peer computers. The networks
are known for hosting files with PHI information.
The usage, together with the observed security
weakness, marks p2p network data as a possible source
of information leaks, including PHI leaks. This as-
sumption was confirmed by data management studies
[18].
To gather data, we obtained the project approval
from the Research Ethics Board of Children’s Hospital
of Eastern Ontario. The files were gathered from April
2008 till June 2009. The Gnutella and eD2K P2P net-
works were selected due to their prevalence and global
popularity.4 To automatically capture samples of p2p
files, we modified the publicly available ShAREAZA5
p2p client. The tool is a software package which al-
lows one to connect to multiple P2P networks simul-
taneously in order to search for and download files.
Modifications to this client included changes to the
search function as well as increased logging capabili-
ties. The search function was modified to automat-
ically search for any document file (Microsoft Word,
Raw Text, Rich Text, Excel, Powerpoint, PDF, Word-
pad, XML, etc) and automatically retrieve it. Auto-
matic searches were conducted by the code at fifteen
minute intervals. A semi-manual analysis of the first
data sample (859 files) showed the presence of PHI on
the two p2p networks [25]. In total, we have gath-
ered 2852 files. The data was sent for processing “as
is”, without preliminary pre-processing: we preserve
all the initial spelling, capitalization, grammar, etc.
</bodyText>
<footnote confidence="0.995689666666667">
4 http://www.kolabora.com/news/2004/01/09/popular p2p
tools and programs.htm, retrieved Aug 12, 2009
5 http://shareaza.sourceforge.net/?id=source
</footnote>
<page confidence="0.996544">
60
</page>
<table confidence="0.8938535">
Detection of publishable and educational text
Detection of non-personal text
</table>
<tableCaption confidence="0.969363">
Table 2: Categories and terms for partial content analysis
</tableCaption>
<table confidence="0.79808375">
Categories Examples
Categories Examples
Books ebook, ISBN, publisher
Periodic magazine, article, volume
Retail manual, readme, copyright
Book type dictionary, novel, cookbook
Genre biography, fiction, sci-fi, whodunit
Publishable abstract, acknowledgement, introduction
Education theses, assignment, course-work
Special (NA) Bible, dummies, Microsoft, software
Categories Examples
Categories Examples
Music album, ballad, song
Advertisement Mrs Tiggy Winkles, Tim Hortons
Fictionals Harry Porter, Scarlet O’Hara
Politics Al Gore, Winston Churchill
</table>
<subsectionHeader confidence="0.990632">
3.3 Empirical Text Processing
</subsectionHeader>
<bodyText confidence="0.999533714285714">
Shallow analysis On this step, we aimed to re-
move files which were the most unlikely candidates
to leak PHI. We assumed that any published text was
not leaking PHI: fictions described non-existing heros,
magazines and newspapers obtained person’s consent
on information disclosure, songs were not providing
enough details, etc. Corrupted files and non-text files
(images, music) were other candidates for a fast re-
moval. On this step, we applied string matching and
character-based N-gram modelling methods.
First, we processed only the file titles. The ti-
tles were compared with the Amazon.com database.
723(25.35%) files were removed after their titles were
found in the database, e.g. New York New York,
Abba The Winner Takes It All, abominable snowman
were discarded. However, if there was no exact title
matching, the file was passed for further processing.
On all of the following steps, we worked with whole
file data, i.e., body and title. Immediately after the
Amazon.com search, the files were passed through a
text extractor. 37(1.30%) non-text files ( images, mu-
sic, viruses) were removed. Then we applied a mod-
ified version of a publicly available language identi-
fier TextCat 6. For each file, the tool built character-
based N-grams. The N-grams were compared with
language models for 69 languages. The best-fitting
model provided the language text tag. On that step,
724(25.39%) non-English texts were discarded (e.g., 13
de octubre 20008, canserle ilgili bilgiler).
Partial content analysis The goal of this phase is
to identify and remove publishable, educational and
non-personal texts which cannot be identified by the
title string matching. #11 The Dragonfiend Pact 1,
Copy of VintagePatternBook are book files with “cam-
ouflaged” titles that passed through the string match-
ing method of the shallow filter; chriscolumbus is a stu-
dent assignment which could not be detected earlier.
To find such files, we define categories of terms char-
acteristic to publishable and educational texts. One
category represents local North American (NA) pref-
erences in the files; see the upper part of Table 2 for
examples.
</bodyText>
<footnote confidence="0.696382">
6 http://odur.let.rug.nl/ vannoord/TextCat/
</footnote>
<bodyText confidence="0.999903916666667">
We also look for texts with non-personal content.
Music texts, discussion of popular fictional characters,
current political events, and advertisements would be
unlikely candidates for leaking explicit, detailed PHI.
The lower part of Table 2 lists detection categories and
examples of terms.
In practice, we applied the key-word search to the
titles and the first 200 words of the body text. Many
detected texts were educational (assignments, reports,
theses), some represented small literary forms (essays,
poetry, self-published books). Manuals, tech reports,
articles were also detected on this step. As a result,
605(21.21%) publishable and non-personal texts were
filtered out.
Another task was to find and remove multiple copies
of the same file. For each pair of remaining files, we
compared their sizes, titles, and first and last sen-
tences. If all parameters were the same, we tagged two
files as duplicates and kept only one for further pro-
cessing.7 41(1.44%) files were removed on this step.
The remaining p2p files are deemed susceptible to in-
formation leaks, i.e., possible containers, and passed
to the deeper analysis stage; Figure 1 shows the pro-
portional distribution of the processed files.
</bodyText>
<figureCaption confidence="0.8787865">
Fig. 1: File content distribution found by shallow and
partial content analysis
</figureCaption>
<footnote confidence="0.3986755">
7 Here and everywhere, when appropriate, we used hashes and
compared hash values.
</footnote>
<page confidence="0.997628">
61
</page>
<bodyText confidence="0.985904797619048">
Deep content analysis 722(25.31%) files remained
after the shallow and partial content analysis phases.
Potentially, those files may have personal content,
thus, hold personal health information (i.e., possible
containers). In processing these files, we want to iden-
tify a set of probable containers first and then work
with this set only. For this, complete contents are an-
alyzed with a combination of syntactic, and semantic
methods. This phase uses external resources: dictio-
naries and knowledge sources.
The heterogeneity of the data makes it unrealistic to
expect such file commonalities as text structure, gram-
mar style, content word vocabulary, etc. We, instead,
rely on the definition of PHI which can be expressed
through a reasonably limited number of semantic cat-
egories, e.g., person and geographic names, disease
names and symptoms. Sets of syntactic rules are used
to identify references to individuals, locations and age-
identifiable events (birth, death). We parse sentences
to find preposition phrases, noun phrases and verb
phrases. Soft REGULAR EXPRESSIONS(RE) are used to
extract numeric-based categories, such as phone num-
ber, street number and unit, dates, and email.
In data management and privacy protection, geo-
graphic information is shown to be the single most
important category responsible for person identifica-
tion [16, 3]. We implement geographic information
extraction for the following categories:
country : all the UN-recognized countries and their
capitals on all the continents (France, Paris;
Liberia, Monrovia), and self-proclaimed entities
(Eritrea, Abkhazia) ;
place : in US: state name, state capital, the largest
city (Illinois, Springfield, Chicago); in Canada:
province, province capital, largest cities, tourist
attractions (Alberta, Edmonton, Calgary, Banff),
the same – for territories; in Europe, Latin Amer-
ica, Asia, Africa, Australia: Alpha, Beta and
Gamma world cities 8.
code : US’ ZIP code (Massachusetts 02163, NY
10027), Canada’s postal code (K1H 8L1);
street : for US and Canada – type (Avenue, Ch.,
Street, Beach), number (401 Smyth Rd.);
landmarks : Empire State Building, CN Tower, Ni-
agara Falls, etc.
From other named entities, we concentrate on
recognition of person names (John Smith), organiza-
tions (Nepean High School) and health care providers
(Ottawa General Hospital). We considered organiza-
tions to be geographic pointers, as they can tie an in-
dividual to a certain location. The Contact Us link on
the organization web site or a name part (Boston Uni-
versity) are strong indicators of a person’s geographic
affiliation. Hospital, doctor, and registered nurse in-
formation in the file makes it a strong candidate for a
8 http://en.wikipedia.org/wiki/Global city#GaWC Invento-
ry of World Cities
PHI leak. We combined a key word search and syn-
tactic patterns to find these named entities. We did
not apply look ups of health care providers, as no con-
firmed high quality sources are available
To reduce computationally expensive person name
look-up, we first searched for patterns of family rela-
tions (My daughter, an uncle of) and self-identification
(my name, sincerely). Other patterns are event-related
(was born, died in). Depending on the patterns, either
preceding or following capitalized words are stored in
the name list. Further, when the tool checks for a per-
son name, it will first check with the file dictionary.
The pattern search is augmented with an RE-based
search. The latter is combined with the person name
look up. We use three proprietary dictionaries: female
and male first names and last names. Our dictionaries
contain formal and informal name forms (William, Bill,
Billy) and non-Anglo-Saxon names (Meehai, Leila).
To be marked as probable containers, files should
contain a geographic identifier (e.g., street address,
place name, organization ) and two other identifiers,
e.g., first name and last name, first name and another
geographic identifier, last name and a phone number.
The 345(12.10%) probable containers were then passed
into the final phase of health information extraction
where 12 PHI files were found (Figure 2). We discuss
in detail PHI extraction in Section 3.4.
</bodyText>
<figureCaption confidence="0.519202">
Fig. 2: Gradual reduction in the number of analyzed
files
</figureCaption>
<page confidence="0.981219">
62
</page>
<subsectionHeader confidence="0.687004">
3.4 Health Information Extraction
3.4.1 Ontology structure
</subsectionHeader>
<bodyText confidence="0.998894322580645">
Our ontology building works as follows:
i to identify a small number of semantic categories
which correspond to the main categories of Health
Information;
ii work with each category separately, identifying
the information that should be analyzed;
iii apply Information Extraction methods to find the
information indicators in the existing sources.
At the initial step, we form three genetic semantic cat-
egories – disease, drugs, and symptoms – as was dis-
cussed in Section 2; see Table 1 for examples. For dis-
eases and drugs, we concentrate on extraction of their
names. The category contents were derived from Web-
ster’s New World Medical Dictionary [15], the Inter-
national Classification of Diseases (ICD9 codes)9, the
Medical Dictionary for Regulatory Activities (Med-
DRA)10 and Canadian Drug Product Database (Ac-
tive and Inactive) 11.
ICD9 codes [2] are used by health care professionals
to tag and classify morbidity data from inpatient and
outpatient records, physician offices, as well as most
of the National Center for Health Statistics (NCHS)12
and the Canada Institute for Health Information13 sur-
veys. The codes are divided into two sections: one con-
taining diseases and injuries (ICD9CM Disease and In-
jury), and another containing surgical, diagnostic, and
therapeutic procedures (ICD9CM Procedures). ICD9
provides the hierarchy of diseases where terms on every
level relate to the individual’s health. The following
sample presents the complete hierarchical snapshot for
cholera:
</bodyText>
<table confidence="0.497557875">
1 INFECTIOUS AND PARASITIC DISEASES (001-
139)
INTESTINAL INFECTIOUS DISEASES (001-009)
Excludes: helminthiases (120.0-129)
001 Cholera
001.0 Due to Vibrio cholerae
001.1 Due to Vibrio cholerae el tor
001.9 Cholera, unspecified
</table>
<bodyText confidence="0.995251">
This succinctness allows reduction in the source pro-
cessing and simplifies information extraction steps.
The Canadian Drug Product Database (CDPD)
contains product specific information on drugs ap-
proved for use in Canada. It includes human phar-
maceutical and biological drugs, veterinary drugs, and
</bodyText>
<footnote confidence="0.965597142857143">
9 http://www.cdc.gov/nchs/about/otheract/icd9/abticd9.htm
10 http://www.meddramsso.com/MSSOWeb/index.htm
11 http://www.hc-sc.gc.ca/dhp-mps/prodpharma/databasdon/
index-eng.php
12 http://www.cdc.gov/nchs/
13 http://secure.cihi.ca/cihiweb/dispPage.jsp?cw page=
home e
</footnote>
<bodyText confidence="0.999848185185185">
disinfectant products. Additionally, a database of pre-
viously available drugs is maintained. However, an av-
erage, non-expert individual may treat drugs as con-
sumer goods and refer to them in different ways. That
is why we expect that drug names can vary from a
generic, non-proprietary, name as Ibuprofen to a more
specific brand name as Advil.
To accommodate extraction of various drug names,
we sought information provided by Merck &amp; Co., an in-
ternational pharmaceutical company14. We obtained
a list of generic drug names and the trade names as-
sociated with them 15.
Patient symptoms such as chest pain or headache,
as well as mentioned procedures such as heart surgery,
also consist of health information, as they may allow
one to infer a specific medical, behavioural or psycho-
logical condition or ailment of another individual. To
identify patient symptoms, we use the MedDRA dic-
tionary which covers a wide range of terminology in-
cluding symptoms and signs (i.e. visible symptoms).
However, the listed above resources leave some gaps
in PHI detection. The most noticeable absentees are
acronyms (ICU) and providers (therapist, surgeon), but
also some condition names (blood pressure, tube fed).
To fill the gaps, we manually searched the Webster’s
medical dictionary. Figure 3 shows the structure of
our ontology.
</bodyText>
<figureCaption confidence="0.97213">
Fig. 3: The structure of the knowledge source
</figureCaption>
<subsubsectionHeader confidence="0.596057">
3.4.2 Terms and term units
</subsubsectionHeader>
<bodyText confidence="0.999705125">
We aimed to populate the ontology with PHI-related
single terms (diabetes) and term units (Felty’s syn-
drome). We first minimized the above mentioned re-
sources by removing un-related categories (e.g., animal
diseases, animal drugs). Then the remaining resource
texts were normalized : converted to lowercase, punc-
tuation marks and numbers were removed, and stop
words (of, when) were eliminated.
We consider that a term unit is a sequence of two
or more consecutive units words, that has characteris-
tics of a syntactic and semantic unit, i.e. collocation.
To identify collocations, we used a subset of 700,000
articles from the MEDLINE corpus 16, a repository
of medical documents. The normalized text was pro-
cessed by TExt::NSP17, a collocation extraction and
N-gram building tool. We looked for N-grams of
</bodyText>
<footnote confidence="0.9621864">
14 http://www.merck.com/
15 http://www.merck.com/mmpe/appendixes/ap2/ap2a.html
16 http://medline.cos.com/
17 http://search.cpan.org/ tpederse/Text-NSP-1.09/lib/
Text/NSP.pm
</footnote>
<page confidence="0.998941">
63
</page>
<bodyText confidence="0.999984875">
length 2 and 3. From these counts a log-likelihood sta-
tistical significance test was performed to determine if
a given textual unit qualifies either as an N-gram or
a collocation. We used the tool default settings. The
sets of trigrams and bigrams were then merged into
a single set of collocations which is used later in the
process.
Each of the IC9CM, CDPD, Merck, MedDRA, and
manually created datasets were then used to find and
extract PHI entities by applying the following proce-
dure: try to match collocations, and if a match is found
mark it as a PHI indicator; if a word is not matched
as part of a collocation, mark it as a single word PHI
indicator. However, this inclusiveness may reduce the
detection power of the terms. For example, cat and
magic would be extracted from the drug base entry:
</bodyText>
<sectionHeader confidence="0.617893" genericHeader="method">
CAT IV - SUNBURN PROTECTANTS, LEG MAGIC
</sectionHeader>
<bodyText confidence="0.999890533333333">
Thus, the list of HI indicators had to be filtered
and pruned to eliminate false HI indicators like these.
For filtering of these words, we used data obtained
from the British National Corpus (BNC)1S The BNC
is used to filter out terms that occur over 1800 times.
This threshold was chosen, as hospital occurs slightly
less than 1800 times. Additionally, we eliminated con-
tent words which appear among the top frequent 5000
words in the Brown corpus 19. No collocations were
filtered out by this process, which may in part cause
false PHI indicators to be included in the final list.
This process resulted in the ontology with 62004 en-
tities, including 25528 unigrams, 27641 two term col-
locations, and 8835 three term collocations. Figure 4
sketches the ontology building process.
</bodyText>
<figureCaption confidence="0.881819">
Fig. 4: Health Information ontology building. X de-
notes an external source
</figureCaption>
<subsubsectionHeader confidence="0.829372">
3.4.3 Text classification
</subsubsectionHeader>
<bodyText confidence="0.999074142857143">
After the ontology has been created, it can be used to
classify a text as PHI or not PHI. Based on the number
of trigrams T, bigrams B and unigrams U in the text,
identified as HI indicators, along with the length of
the document n, we classified the text as either PHI or
not PHI. We then could weight N-gram contributions
proportionally to the number of words N :
</bodyText>
<equation confidence="0.464974">
&gt; H —* PHI (6)
</equation>
<footnote confidence="0.7853005">
18 http://www.natcorp.ox.ac.uk/
19 http://www.edict.com.hk/textanalyser/
</footnote>
<bodyText confidence="0.998653636363636">
Texts were marked as PHI′ if their N-grams did not
satisfy Eq. 6 .
If we wanted to use the ontology structure, we would
augment the formula by including the term category
contributions. Each category is assigned a normalized
weight based upon its quality. We rate the quality of a
resource based upon the percentage of entities within
it that are not filtered out. So a category Ci of original
size (i.e., a number of initial terms) Si and filtered size
(i.e., a number of remaining terms) Fi has quality Qi
defined as:
</bodyText>
<equation confidence="0.966122666666667">
Fi
Qi = (7)
Si
</equation>
<bodyText confidence="0.99569">
We then compute the normalizing factor M and the
weight Wi, given to an entity from a given category:
</bodyText>
<equation confidence="0.999568">
Qi (8)
Qi
Wi = (9)
M
</equation>
<bodyText confidence="0.835546">
The weighted formula for text classification becomes:
</bodyText>
<equation confidence="0.858841">
&gt; H —* PHI (10)
</equation>
<bodyText confidence="0.998853909090909">
Empirical testing of several thousand documents al-
lowed us to determine a suitable threshold value of
0.04. Yet, the threshold H was chosen from a set of
empirical experiments such that it optimized the pre-
cision, while keeping the recall at 100%. Thus, the
chosen threshold value may be overly fit to the test
data. In the future, when more sample data becomes
available, experiments should be performed to try and
to determine what the optimal threshold value should
be. Figure 5 depicts the PHI text classification pro-
cess.
</bodyText>
<figureCaption confidence="0.943499">
Fig. 5: HI text classification
</figureCaption>
<sectionHeader confidence="0.990425" genericHeader="method">
4 Empirical Results
</sectionHeader>
<bodyText confidence="0.9993648">
Evaluation on screened positive examples
Evaluating the correct identification of PHI leaks
presents a certain methodological difficulty. The num-
ber of PHI files is negligible even if compared with
the number of probable containers. On the other
hand, all of the PHI files exhibit specific character-
istics: they contain personally identifiable and health
information. Hence, we can apply measures that eval-
uate a tool’s performance only on examples which sat-
isfy pre-determined criteria [23]. The other examples
</bodyText>
<equation confidence="0.994661666666667">
3T + 2B + U
n
M= 1 k
n 1
3Ti + 2Bi + Ui
Wi
n
k
1
</equation>
<page confidence="0.99378">
64
</page>
<bodyText confidence="0.99636275">
are ignored. The approach – evaluation on screened
positive examples – has been shown effective and ap-
propriate for PHI leak detection [25]. Table 3 presents
the confusion matrix:
</bodyText>
<equation confidence="0.766941">
Predicted
HI =1 HI =0
</equation>
<tableCaption confidence="0.989894">
Table 3: Confusion matrix for classification of screen
positive examples
</tableCaption>
<bodyText confidence="0.781668">
We compute True Detection Probability( TˆDP) and
False Referral Probability( FˆRP):
</bodyText>
<equation confidence="0.999205">
FˆRP = n+ + n� .
n+
PHI (12)
</equation>
<bodyText confidence="0.99993875">
TDP shows the proportion of files an algorithm
marked as having the PII and HI indicators and con-
taining PHI. FRP shows the proportion of files the
algorithm marked as having the PII and HI indicators
but not containing PHI.
To put the measures in perspective, we use the ideal
classification (Table 4) where all the predicted HI files
are indeed the PHI files and visa-verse:
</bodyText>
<equation confidence="0.981063">
Predicted
HI =1 HI =0
PHI=1
PHI=0
</equation>
<tableCaption confidence="0.9083115">
Table 4: Confusion matrix for the ideal classification
of screen positive examples
</tableCaption>
<bodyText confidence="0.984716">
Then, TˆDPi = n+
n++n� ,FˆRPi = 0. A method
is close to 1 and FˆRP – to 0.
The ontology application We tested our tool on
several sets of p2p files. Here we report typical results,
in terms of accuracy.
(a) 72 files were randomly obtained from a peer-to-
peer file sharing network. The set contained nine files
with health care information (parents’ notes, letters,
documents from a lawyer office). We used our HI on-
tology and manually examined all the labels output by
the system. Table 5 shows the results.
Here, TˆDPi = 11.11%. We obtained TˆDP =
= 1. We obtained FˆRP = 1.39%:
HI indicators were extracted from a summary of a teen
fiction which was not a PHI file.
</bodyText>
<table confidence="0.8990074">
PHI=1 HIo =1 HIo =0
PHI=0
8 ?
1 ?
n+ n�
</table>
<tableCaption confidence="0.987719">
Table 5: HI ontology: classification of the 72 files
</tableCaption>
<bodyText confidence="0.678256">
For per-term extraction accuracy, we obtained Re-
call = 100%, i.e., all health care indicators were cor-
rectly extracted. On the relevant, true PHI, eight
documents, we obtained Precision =100%, i.e. all ex-
tracted indicators were health care indicators indeed.
</bodyText>
<listItem confidence="0.760523">
(b) To test the proposed system a set of 76 texts
were used. This set was composed of 4 PHI texts and
72 non-PHI texts. Table 6 lists the results.
</listItem>
<equation confidence="0.894116333333333">
PHI=1 HIo =1 HIo =0
PHI=0
4 ?
2 ?
n+ n�
Table 6: HI ontology: classification of the 76 files
We obtained TˆDP = 5.26% = TˆDPi. Again,
TˆDP;
TˆDP = 1. We obtained FˆRP = 2.78%. Of the false
</equation>
<bodyText confidence="0.998958151515151">
PHI files, one was a resume of a healthcare worker,
and one was an unfilled health insurance form. In both
cases the falsely classified texts contained both PII and
HI, yet there was no link between the two. In the fu-
ture, a deeper analysis phase – perhaps, co-reference
resolution – of potential PHI texts could be done, po-
tentially increasing the precision of the method as a
whole.
Medical Subjects Heading application Medi-
cal Subjects Heading (MeSH), a controlled vocabu-
lary thesaurus, is produced by the National Library
of Medicine.20. Its hierarchical and categorized struc-
ture is often used in analysis of medical texts [7]. In
our case, however, MeSH would require a consider-
able adjustment before it can be used for PHI leak
detection. For example, the top hierarchical terms are
too general: Anatomy, Endocrine system (level 1) and
Bladder, Work Schedule Tolerance (level 3) do not con-
tribute much to the knowledge of a personal health sit-
uation. The bottom level terms might be informative
only to experts but not to the general population, e.g
Motor Cortex (level 8), Trypanosoma cruzi(level 11). In
both cases, the use of these terms could considerably
increase the number of false positives. On the other
hand, the un-predictability of the input data makes
it desirable for our tool to use terms belonging to all
the categories, perhaps mapping it to only one of the
assigned fields.
To support our claim, we used topical descriptors
(DC= 1) represented by the Main Heading field, with-
out selecting specific hierarchical level. We filtered out
the stop words and frequent content words. This left
21470 terms (Corneal Ulcer, Fibromyalgia). We applied
</bodyText>
<figure confidence="0.977814458333333">
20 http://www.nlm.nih.gov/mesh/
PHI=1
PHI=0
Actual
n+
PHI
?
n+
PHI
n+ n�
?
TˆDP = n+ PHI
(11)
n+ + n�
Actual
n+ ?
0 ?
n+ n�
TˆDP
TˆDP;
works better if
TˆDP
TˆDP;
11.11% , thus,
</figure>
<page confidence="0.999117">
65
</page>
<bodyText confidence="0.999307666666667">
them to classify a sample of 50 probable files. All of
the PHI files were detected, but the number of false
positive files was very high. 12 files were identified
as containing PHI, whereas the correct number was 4
files (Table 7). Publisher, technology are examples of
MeSH terms contributing to the file misclassification.
</bodyText>
<table confidence="0.9341664">
PHI=1 HIm =1 HIm =0
PHI=0
4 ?
8 ?
n+ n−
</table>
<tableCaption confidence="0.949099">
Table 7: MeSH: classification of the 50 files
In this case, TˆDP = 8.00% = TˆDPi,
</tableCaption>
<bodyText confidence="0.9991064">
On the other hand, FˆRP = 16.00% shows over-
inclusiveness of the test. A small number of examples,
however, does not allow for conclusive remarks. We
plan more experiments when new files will be gath-
ered.
</bodyText>
<sectionHeader confidence="0.999508" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99957921875">
Information Leak Prevention From a data man-
agement perspective, our problem belongs to informa-
tion leak prevention, a part of data leak prevention.
Intentional and un-intentional leaks of data have be-
come a major issue for businesses, end users, software
and network providers, etc. Many companies (Syman-
tec 21, Websense22, etc.) concentrate their efforts on
building tools able, ideally, to prevent or, at least,
minimize such leaks. These tools are based on orga-
nizational policies and identify, monitor, and protect
data at rest, in motion, and in use 23. Information
leak prevention is concerned with content analysis of
data. Information leak prevention tools are deployed
in banks, financial companies, government organiza-
tions [4]. While processing free-form text data, some
of the tools apply NLP methods to enforce safer data
management [4]. Many of those tools work on spe-
cific text structure and type. Our tool, on the other
hand, contributes to the solution of a specific task (i.e.,
prevention of PHI leaks) without constraining this so-
lution to predefined text structure or types.
The applied research community participates in
tool development for information leak prevention
[13, 19]. Microsoft Research developed a defensive
tool that looks for personally identifiable information
in one’s own documents. The tool processes digi-
tal documents, including metadata, and removes the
owner’s name, username,security ID, computer Net-
BIOS name, names of online, email, webmail servers,
etc. No NLP or TDM techniques are involved: all
documents are treated as flat byte streams. First,
the tool collects potentially sensitive information from
</bodyText>
<footnote confidence="0.9771665">
21 http://www.symantec.com/index.jsp
22 http://www.websense.com/content/home.aspx
23 http://media.techtarget.com/searchFinancialSecurity/
downloads/Understanding Selecting DLP Solution.pdf
</footnote>
<bodyText confidence="0.999008234042553">
the computer, then searches documents for its pres-
ence. The tool is semi-automated. User interven-
tion is required to reduce false positives, i.e., non-
sensitive information wrongly labelled as PII [5]. In
related efforts, academic groups mostly work on hospi-
tal record de-identification; more details follow in the
next paragraph. Few teams are actively involved in
health information leak prevention outside of the de-
identification of hospital records. In [8], the authors
propose a method which detects the inference of sensi-
tive information in documents. The method relies on
search engines to find the most frequent association
of topic-based terms. In [26], the author describes a
method which warns web site owners if posted per-
sonal information enables identity theft (e.g., date of
birth, address, name).
We, instead, focus on leak prevention techniques
able to detect information within heterogeneous texts.
De-identification of personally identifiable in-
formation So far, PHI detection attracted only lim-
ited attention from Text Data Mining and NLP com-
munities. Mainly, the work has been restricted to
preparation of hospital records for future use by other
researchers, i.e., the secondary use of health data.
In Europe and North America, the law requires re-
moval of personally identifiable information, data de-
identification, before permitting documents for sec-
ondary use [11]. The privacy protection requirements
made de-identification popular among NLP, Informa-
tion Extraction, and Machine Learning applications
implemented on hospital records and other PHI texts.
Typically, a de-identification method is designed for
one type of documents, e.g. discharge summaries
[27, 28]. De-identification consists of the detection
of patients’ personally identifiable information and its
subsequent transformation. De-identification tasks are
restricted to detection and transformation of PII, and
avoid the analysis of terminology concerning health
conditions of patients. The reported systems’ primary
methods are look-ups of person and geographic name
dictionaries. Their performance, thus, depends on
comparability of the dictionaries and the input data.
Table 8, adapted from [22], compares the performance
of a publicly available de-identifier STAT DE-id when it
uses customized dictionaries (the left part) and with-
out them (the right part). The results were obtained
on the de-identification of nurse notes.
</bodyText>
<table confidence="0.92990675">
Customized Non-customized
dictionaries dictionaries
Fscore Pr R Fscore Pr R
84.4 74.9 96.7 77.4 72.3 83.4
</table>
<tableCaption confidence="0.929491">
Table 8: Classification (%) of person names, health
care provider names, addresses, age-related dates.
</tableCaption>
<bodyText confidence="0.99779225">
Unfortunately, many publications do not report on
disambiguation results, e.g. person and geographic
names (Washington - surname, city, or state? Sofia
- name or city? Marina - name, street or area?), or
</bodyText>
<equation confidence="0.6431">
= 1.
TˆDP
TˆDP;
</equation>
<page confidence="0.901457">
66
</page>
<bodyText confidence="0.9999615">
person and trade marks (Tim Hortons - a coffee chain
or a person? Jo Malone – a private label or a person?).
Withholding of disambiguation accuracy makes it dif-
ficult to correctly assess the tool’s performance.
We, on other hand, focus on heterogeneous texts
whose content and context is not determined before
our system processes them.
Health care information extraction There are
few publications dedicated to health care information
analysis in free-form, unstructured texts. Presented
work often focuses on specific, rather narrow informa-
tion categories. In [17], the authors compare four com-
mercial tools which extract medication name, route,
dose (number-based), strength (number-based) , and
frequency (number-based) from discharge summaries
and family practice notes. In [29], the authors focus
on detection of obesity-related diagnostic information.
They used NLP methods to extract 16 obesity diag-
noses from dictated physician documentation. We, in-
stead, opt for detection of all the HI categories.
</bodyText>
<sectionHeader confidence="0.999751" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999085192307693">
In recent years, Text Data Mining and Natural Lan-
guage Processing communities have concentrated their
efforts on the analysis of medical, biomedical and bio-
informatics texts. With educational and research med-
ical publications rapidly increasing (for some types,
the increase fitting an exponential curve [9]), machine-
readable lexical and knowledge sources were built to
promote mining of medical texts: MedLine24, GENIA
corpus25, MeSH26, to name a few.
The services of medical and allied professionals are
offered through Health Care27, the industry which pro-
vides the prevention, treatment, and management of
illness and the preservation of mental and physical
well-being. Although medicine and health care are
closely related, the domains produce remarkably dif-
ferent text data. A bulk of texts containing medical
information comes from articles in medical journals,
magazines, professional blogs, research publications.
These are formally written, well-edited, knowledge-
rich texts. Texts containing PHI are mostly internal
reports, letters and various forms of personal commu-
nication. Often, they offer a description of the indi-
vidual’s health and lifestyle and related information
such as treatments they are receiving and drugs they
are taking. The texts are written without adherence
to requirements of formal editing. Sometimes they are
unedited, containing grammatical and lexical irregu-
larities. For example, hepatitis can be shortened as
hep, and future actions can be described as Assess/plan.
Recent publications show the increased demand for au-
tomated Health Care text processing; for example, see
the Journal of the American Medical Informatics As-
sociation 28. However, there are no readily available
lexical resources that cope well with Health Care text
characteristics. The existing medical resources may re-
quire adaptation. Their “as is” application may give
insufficient results in terms of effectiveness (missed rel-
evant information, whereas non-relevant information
captured) and efficiency (a long processing time and
extra computational resources ).
For example, the Medical Entities Dictionary
(MED)29 is an ontology containing approximately
60000 concepts, 208000 synonyms, and 84000 hierar-
chies. This powerful lexical and knowledge resource
is designed with medical research in mind, as opposed
to detection of personal health information which may
require a more concise knowledge base. We borrow
Figure 6 from the MED web site. 30 It shows the
term Plasma Glucose Test with its relationship to other
terms in the MED database. Solid lines connect it to
parents in the isa hierarchy, broken lines are nonhier-
archic semantic links.
</bodyText>
<figureCaption confidence="0.994963333333333">
Fig. 6: The term Plasma Glucose Test and relations
to other terms in the MED database (adapted from the
MED web site)
</figureCaption>
<bodyText confidence="0.999829421052631">
Consider a text which contains the term Plasma
Glucose Test. When referring to an individual, the
term indicates examination for diabetes. There are
two types of the test. Random Plasma Glucose Test
refers to a simple blood sugar test. No fasting or
glucose administration is required. Results are pro-
cessed within 24 to 48 hours or faster. Fasting Plasma
Glucose Test is more demanding: the patient should
avoid food or drink, except water, for at least 12 hours
prior to the procedure [15]. Both test types and the
generic term Plasma Glucose Test relate to the physical
health of a person, thus, are HI (see Section 2, point 1).
CHEM-7, metabolic panel testing31, is a more general
term which indicates 7 possible tests (glucose, serum
sodium, serum potassium, etc.). The term is HI, al-
though it is less revealing than Plasma Glucose Test.
Other terms, e.g., Bioactive Substance, Plasma,
Event, may or may not reveal HI, depending on the
context. Searching texts for all the sixteen terms in-
</bodyText>
<footnote confidence="0.9961347">
24 http://www.nlm.nih.gov/databases/databases medline.html
25 http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/home/wiki.cgi
26 http://www.nlm.nih.gov/mesh/
27 http://medical-dictionary.thefreedictionary.com/health
+care
28 http://www.jamia.org/
29 http://med.dmi.columbia.edu/
30 http://med.dmi.columbia.edu/struc.htm
31 http://www.nlm.nih.gov/medlineplus/ency/article/
003462.htm
</footnote>
<page confidence="0.999331">
67
</page>
<bodyText confidence="0.9997278">
creases the computing time by a factor of eight (the
near linear processing was confirmed in laboratory
testing). The extra time might not be a problem
for topic classification and text mining which process
published and otherwise legitimately dispensed docu-
ments. We, on the other hand, want to limit informa-
tion exposure to a reasonable minimum. The excessive
terms can also increase the probability of texts being
falsely tagged PHI.
We opted to build a HI lexical source from the
knowledge sources used by medical and allied pro-
fessionals in health care organizations. The two pri-
mary sources are the International Classification of
Diseases (ICD9 codes)32, and Canadian Drug Prod-
uct Database33.
</bodyText>
<sectionHeader confidence="0.991358" genericHeader="discussions">
7 Future Work and Conclusions
</sectionHeader>
<bodyText confidence="0.999980425">
The separation of possible and impossible containers
is a key factor of our tool performance. To insure high
accuracy, we want to implement a more diligent test-
ing of the file titles. In future, before being fed into the
Amazon.com search, the titles will be pre-screened to
find possible legal and health-related documents (Jane
Doe letter of assessment, My affidavit). We plan to use
stemming during this pre-screening. The sought after
key words belong to two groups: authorized and un-
authorized evidence (e.g., affidavit, permission, state-
ment) and health records (e.g., discharge, hospital, re-
ferral). We also plan to extend geographic informa-
tion analysis: (i) add more categories, e.g. popu-
lation hubs such as major airports (Heathrow, Pear-
son), international resorts (Varna, Saltsburg), etc.; (ii)
rank the found names according to their contribution
for person identification; for example, New York, pop.
&gt; 8, 300, 000, can be ranked lower than Ottawa, pop.
812, 000. In future, we want to reinforce person names
with statistical evidence of their use, e.g., a reverse
rank on the list of popular North American names.
These techniques should allow file ranking with respect
to a potential risk of information leaks. In this study,
we focus on contents seen by end users and do not col-
lect the hidden file metadata. We may want to investi-
gate the metadata impact on the scale of information
leaks.
By all means, we also plan to continue testing the
tool. A restricted number of PHI files can make our
tool prone to data over-fitting. Hence, we continue
to gather new data samples. Our future work may in-
clude analysis of the MeSH hierarchical levels, in order
to reduce the number of false positive examples. We
also want to use BNC to find frequent collocations, as
filtering these out from the PHI indicator dictionary
can, too, reduce the false positives. Other directions
of future work are related to detection of rare events
(e.g., a rare coma complication Lock-in). If found in
text, such event can correct identify a person. How-
ever, automated extraction of rarely supplied informa-
</bodyText>
<footnote confidence="0.887763333333333">
32 http://www.cdc.gov/nchs/about/otheract/icd9/abticd9.htm
33 http://www.hc-sc.gc.ca/dhp-mps/prodpharma/databasdon/
index-eng.php
</footnote>
<bodyText confidence="0.999721225806452">
tion is difficult and may require expanding our system
with a new element.
We have introduced a system which helps to pre-
vent leaks of personal health information. Our system
is able to work within the complex environment of pre-
viously unseen data types. It prevents the leakage of
PHI texts in heterogeneous input, i.e. files in which
context, content, and type vary unlimitedly. The un-
certain content of the files contrasts our data set with
homogenous data sets of known content; for example,
company employee files and hospital records, where
each file is pre-disposed to contain personal informa-
tion, or movie script archives, where scripts are a work
of fiction. To accommodate the uncertainty, we have
introduced a taxonomy of files related to the possibil-
ity and probability of the files leaking personal health
information.
On empirical evidence, we have shown that the med-
ical sources are well-suited to analyze formally written,
well-edited texts, often with an abundance of scientific
terms and relations. For our task, however, the sources
contain excessive information, making text analysis
too slow, inefficient and prone to false positive identifi-
cation. A series of experiments was performed on files
exchanged in peer-to-peer file sharing networks with
encouraging results.
Acknowledgements This work has been funded by
the Natural Sciences and Engineering Research Council of
Canada and the Ontario Centre of Excellence. We thank
Terry Copeck for his assistance with text extraction. We
thank anonymous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.997962" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999622130434783">
[1] Personal Health Information Protec-
tion Act. Legislation of Ontario, 2004.
http://www.e-laws.-gov.on.ca/html/statutes/
english/elaws statutes 04p03 e.htm, ac-
cessed Sept. 7, 2008.
[2] The International Classification of Diseases, 9th
revision, clinical modification, 2007. National
Centre for Health Statistics, Centres for Disease
Control and Prevention, US Government.
[3] Review of systems for extracting and anonymizing
geographic information. Technical report, Elec-
tronic Health Information Lab, CHEO, submitted
to GeoConnections, 2008.
[4] Understanding and selecting a data loss preven-
tion solution. Technical report, Securosis, L.L.C,
the SANS Institute, 2009.
[5] T. Aura, T. Kuhn, and M. Roe. Scanning elec-
tronic documents for personally identifiable infor-
mation. In Proceedings of the 2006 ACM Work-
shop on Privacy in the Electronic Society (WPES
06), pages 41–50, 2006.
[6] M. Baird. Personal files were accessible for more
than three weeks. The Western Star, 2008.
</reference>
<page confidence="0.988635">
68
</page>
<reference confidence="0.999421529411765">
http://www.thewesternstar.com/index.cfm?
sid-=104156&amp;sc=23, retrieved Feb 5, 2009.
[7] L. Bouma and M. de Rijke. Specificity helps text
classification. In Proceedings of European Con-
ference on Information Retrieval (ECIR 2006),
pages 539–542. Springer, 2006.
[8] R. Chow, P. Golle, and J. Staddon. Detecting pri-
vacy leaks using corpus-based association rules.
In Proceedings of the 14th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and
Data Mining (KDD), pages 893–901, 2008.
[9] J. DeShazo, D. LaVallie, and F. Wolfe. Publi-
cation trends in the medical informatics litera-
ture: 20 years of ‘medical informatics’ in mesh.
BMC Medical Informatics and Decision Making,
9(7):e13, 2009.
[10] P. Dixon. Medical identity theft:
The information crime that can kill
you. The World Privacy Forum, 2006.
http://www.worldprivacyforum.org/medicali
den-titytheft.html, retrieved June 7, 2009.
[11] B. Elger and A. Caplan. Consent and anonymiza-
tion in research involving biobanks. European
Molecular Biology Organization reports, 7(7):661–
666, 2006.
[12] K. E. Emam, E. Neri, and E. Jonker. An evalu-
ation of personal health information remnants in
second hand personal computer disk drives. Jour-
nal of Medical Internet Research, 9(3):e24, 2007.
[13] A. Evfimievski, R. Fagin, and D. Woodruff. Epis-
temic privacy. In Proceedings of the 27th ACM
Symposium on Principles of Database Systems
(PODS 2008), pages 171–180, 2008.
[14] J. Gayer. Policing privacy: Law en-
forcement’s response to identity theft.
CALPIRG Education Fund, 2003.
http://www.calpirg.org/home/reports/report
archives, retrieved June 7, 2009.
[15] F. Hecht and W. Shiel, editors. Webster’s New
World Medical Dictionary. Wiley Publishing, sec-
ond edition, 2003.
[16] T. Herzog, F. Scheuren, and W. Winkler. Data
Quality and Record Linkage Techniques. Springer,
2007.
[17] V. Jagannathan, C. Mullett, J. Arbogast,
K. Halbritter, D. Yellapragada, S. Regulapati,
and P. Bandaru. Assessment of commercial
NLP engines for medication information extrac-
tion from dictated clinical notes. International
Journal of Medical Informatics, 78(4):284 – 291,
2008.
[18] E. Johnson. Data hemorrhages in the health-care
sector. In Financial Cryptography and Data Se-
curity, 2009.
[19] R. Jones, R. Kumar, B. Pang, and A. Tomkins.
Vanity fair: privacy in querylog bundles. In Pro-
ceedings of the 17th ACM Conference on Infor-
mation and Knowledge Management (CIKM08),
pages 853–862, 2008.
[20] J. Long. No Tech Hacking: A Guide to Social En-
gineering, Dumpster Diving, and Shoulder Surf-
ing. Syngress Press, 2008.
[21] C. McGuigan and M. Browne. Hos-
pital leak linked to witness in lvf
case. Belfast Telegraph, 2007.
http://www.belfasttelegraph.co.uk/sunday-
life/news/hospital-leak-linked-to-witness
-in-lvf-case-13904797.html , retrieved June
7, 2009.
[22] I. Neamatullah, M. Douglass, L. Lehman, A. Reis-
ner, M. Villarroel, W. Long, P. Szolovits,
G. Moody, R. Mark, and G. Clifford. Au-
tomated de-identification of free-text medical
records. BMC Medical Informatics and Decision
Making, 8(32):e17, 2008.
[23] M. Pepe. The Statistical Evaluation of Medical
Tests for Classification and Prediction. Oxford
University Press, 2004.
[24] C. Preimesberger. Cyber-criminals use p2p
tools for identity theft, security analyst warns.
eWeek.com, 2006.
[25] M. Sokolova and K. El Emam. Evaluation of
learning from screened positive examples. In Pro-
ceedings of the 3rd workshop on Evaluation Meth-
ods for Machine Learning (EMML-ICML 2008),
2008.
[26] L. Sweeney. Protecting job seekers from iden-
tity theft. IEEE Internet Computing, 10(2):74–
78, 2006.
[27] O. Uzuner, Y. Luo, and P. Szolovits. Eval-
uating the state-of-the-art in automatic de-
indentification. Journal of the American Medical
Informatics Association, 14:550–563, 2007.
[28] O. Uzuner, T. Sibanda, Y. Luo, and P. Szolovits.
A de-identifier for medical discharge summaries.
Journal of Artificial Intelligence in Medicine,
42:13–35, 2008.
[29] H. Ware, C. Mullett, and V. Jagannathan. Nat-
ural Language Processing (NLP) Framework to
Assess Clinical Conditions. Journal of the Amer-
ican Medical Informatics Association : JAMIA,
16:585–589, 2009.
</reference>
<page confidence="0.999317">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.413480">
<title confidence="0.9996425">Personal Health Information Leak Prevention Heterogeneous Texts</title>
<author confidence="0.8565705">Khaled El_Sean Sadrul Elizabeth Liam</author>
<affiliation confidence="0.9756355">Health Information Children’s Hospital of Eastern</affiliation>
<address confidence="0.990383">401 Smyth Rd., Ottawa, Canada, K1H 8L1</address>
<affiliation confidence="0.713421">of Ottawa</affiliation>
<address confidence="0.970821">800 King Edward, Ottawa, Canada, ON K1N 6N5</address>
<abstract confidence="0.9999061">We built a system which prevents leaks of personal health information inadvertently disclosed in heterogeneous text data . The system works with free-form texts. We empirically tested the system on files gathered from peer-to-peer file exchange networks. This study presents our text analysis apparatus. We discuss adaptation of lexical sources used in medical, scientific, domain for analysis of personal health information.</abstract>
<keyword confidence="0.992025">Keywords</keyword>
<intro confidence="0.869347">information leak prevention, personal health information</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Personal Health Information Protection Act. Legislation of Ontario,</title>
<date>2004</date>
<note>http://www.e-laws.-gov.on.ca/html/statutes/ english/elaws statutes 04p03 e.htm, accessed</note>
<contexts>
<context position="5360" citStr="[1]" startWordPosition="784" endWordPosition="784">irs of possible/impossible and probable/improbable PHI containers. Our data and empirical results are presented after that. We follow with discussion of related work and motives for the adaptation of medical knowledge sources. At the end, we present plans for future work and conclusions. 2 Background Our group works on prevention of inadvertent disclosure of personal health information in heterogenous text data. Personal health information (PHI) refers to ailments, treatments and other health-specific details of an individual. In Ontario, Canada, the Personal Health Information Protection Act [1] defines PHI as information that: 1. relates to the physical or mental health of the individual, including information that consists of the health history of the individual’s family 2. relates to the providing of health care to the individual, including the identification of a person as a provider of health care to the individual, 3. is a plan of service within the meaning of the Long-Term Care Act for the individual 4. relates to payments or eligibility for health care, or eligibility for coverage for health care, in respect of the individual 5. relates to the donation by the individual of an</context>
</contexts>
<marker>[1]</marker>
<rawString>Personal Health Information Protection Act. Legislation of Ontario, 2004. http://www.e-laws.-gov.on.ca/html/statutes/ english/elaws statutes 04p03 e.htm, accessed Sept. 7, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>US Government Prevention</author>
</authors>
<title>The International Classification of Diseases, 9th revision, clinical modification,</title>
<date>2007</date>
<institution>National Centre for Health Statistics, Centres for Disease Control</institution>
<contexts>
<context position="23277" citStr="[2]" startWordPosition="3578" endWordPosition="3578">iii apply Information Extraction methods to find the information indicators in the existing sources. At the initial step, we form three genetic semantic categories – disease, drugs, and symptoms – as was discussed in Section 2; see Table 1 for examples. For diseases and drugs, we concentrate on extraction of their names. The category contents were derived from Webster’s New World Medical Dictionary [15], the International Classification of Diseases (ICD9 codes)9, the Medical Dictionary for Regulatory Activities (MedDRA)10 and Canadian Drug Product Database (Active and Inactive) 11. ICD9 codes [2] are used by health care professionals to tag and classify morbidity data from inpatient and outpatient records, physician offices, as well as most of the National Center for Health Statistics (NCHS)12 and the Canada Institute for Health Information13 surveys. The codes are divided into two sections: one containing diseases and injuries (ICD9CM Disease and Injury), and another containing surgical, diagnostic, and therapeutic procedures (ICD9CM Procedures). ICD9 provides the hierarchy of diseases where terms on every level relate to the individual’s health. The following sample presents the com</context>
</contexts>
<marker>[2]</marker>
<rawString>The International Classification of Diseases, 9th revision, clinical modification, 2007. National Centre for Health Statistics, Centres for Disease Control and Prevention, US Government.</rawString>
</citation>
<citation valid="true">
<title>Review of systems for extracting and anonymizing geographic information.</title>
<date>2008</date>
<booktitle>Electronic Health Information Lab, CHEO, submitted to GeoConnections,</booktitle>
<tech>Technical report,</tech>
<contexts>
<context position="19487" citStr="[16, 3]" startWordPosition="2987" endWordPosition="2988"> limited number of semantic categories, e.g., person and geographic names, disease names and symptoms. Sets of syntactic rules are used to identify references to individuals, locations and ageidentifiable events (birth, death). We parse sentences to find preposition phrases, noun phrases and verb phrases. Soft REGULAR EXPRESSIONS(RE) are used to extract numeric-based categories, such as phone number, street number and unit, dates, and email. In data management and privacy protection, geographic information is shown to be the single most important category responsible for person identification [16, 3]. We implement geographic information extraction for the following categories: country : all the UN-recognized countries and their capitals on all the continents (France, Paris; Liberia, Monrovia), and self-proclaimed entities (Eritrea, Abkhazia) ; place : in US: state name, state capital, the largest city (Illinois, Springfield, Chicago); in Canada: province, province capital, largest cities, tourist attractions (Alberta, Edmonton, Calgary, Banff), the same – for territories; in Europe, Latin America, Asia, Africa, Australia: Alpha, Beta and Gamma world cities 8. code : US’ ZIP code (Massachu</context>
</contexts>
<marker>[3]</marker>
<rawString>Review of systems for extracting and anonymizing geographic information. Technical report, Electronic Health Information Lab, CHEO, submitted to GeoConnections, 2008.</rawString>
</citation>
<citation valid="true">
<title>Understanding and selecting a data loss prevention solution.</title>
<date>2009</date>
<booktitle>Technical report, Securosis, L.L.C, the SANS Institute,</booktitle>
<contexts>
<context position="36624" citStr="[4]" startWordPosition="5782" endWordPosition="5782">k prevention. Intentional and un-intentional leaks of data have become a major issue for businesses, end users, software and network providers, etc. Many companies (Symantec 21, Websense22, etc.) concentrate their efforts on building tools able, ideally, to prevent or, at least, minimize such leaks. These tools are based on organizational policies and identify, monitor, and protect data at rest, in motion, and in use 23. Information leak prevention is concerned with content analysis of data. Information leak prevention tools are deployed in banks, financial companies, government organizations [4]. While processing free-form text data, some of the tools apply NLP methods to enforce safer data management [4]. Many of those tools work on specific text structure and type. Our tool, on the other hand, contributes to the solution of a specific task (i.e., prevention of PHI leaks) without constraining this solution to predefined text structure or types. The applied research community participates in tool development for information leak prevention [13, 19]. Microsoft Research developed a defensive tool that looks for personally identifiable information in one’s own documents. The tool proces</context>
</contexts>
<marker>[4]</marker>
<rawString>Understanding and selecting a data loss prevention solution. Technical report, Securosis, L.L.C, the SANS Institute, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Aura</author>
<author>T Kuhn</author>
<author>M Roe</author>
</authors>
<title>Scanning electronic documents for personally identifiable information.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 ACM Workshop on Privacy in the Electronic Society (WPES 06),</booktitle>
<pages>41--50</pages>
<contexts>
<context position="37927" citStr="[5]" startWordPosition="5962" endWordPosition="5962">ter NetBIOS name, names of online, email, webmail servers, etc. No NLP or TDM techniques are involved: all documents are treated as flat byte streams. First, the tool collects potentially sensitive information from 21 http://www.symantec.com/index.jsp 22 http://www.websense.com/content/home.aspx 23 http://media.techtarget.com/searchFinancialSecurity/ downloads/Understanding Selecting DLP Solution.pdf the computer, then searches documents for its presence. The tool is semi-automated. User intervention is required to reduce false positives, i.e., nonsensitive information wrongly labelled as PII [5]. In related efforts, academic groups mostly work on hospital record de-identification; more details follow in the next paragraph. Few teams are actively involved in health information leak prevention outside of the deidentification of hospital records. In [8], the authors propose a method which detects the inference of sensitive information in documents. The method relies on search engines to find the most frequent association of topic-based terms. In [26], the author describes a method which warns web site owners if posted personal information enables identity theft (e.g., date of birth, add</context>
</contexts>
<marker>[5]</marker>
<rawString>T. Aura, T. Kuhn, and M. Roe. Scanning electronic documents for personally identifiable information. In Proceedings of the 2006 ACM Workshop on Privacy in the Electronic Society (WPES 06), pages 41–50, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Baird</author>
</authors>
<title>Personal files were accessible for more than three weeks. The</title>
<date>2008</date>
<location>Western Star,</location>
<note>http://www.thewesternstar.com/index.cfm? sid-=104156&amp;sc=23, retrieved</note>
<contexts>
<context position="1693" citStr="[6]" startWordPosition="233" endWordPosition="233">advertent disclosure of personal health information (i.e., details of the individual’s health) had increased. Inadvertently disclosed personal health information facilitates criminals to commit medical identity theft, i.e., allows an imposter to obtain care or medications under someone else’s identity [10]. Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical records through a file sharing network [24]. In this work, we present a system which detects personal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit info</context>
</contexts>
<marker>[6]</marker>
<rawString>M. Baird. Personal files were accessible for more than three weeks. The Western Star, 2008. http://www.thewesternstar.com/index.cfm? sid-=104156&amp;sc=23, retrieved Feb 5, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bouma</author>
<author>M de Rijke</author>
</authors>
<title>Specificity helps text classification.</title>
<date>2006</date>
<booktitle>In Proceedings of European Conference on Information Retrieval (ECIR</booktitle>
<pages>539--542</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="34006" citStr="[7]" startWordPosition="5339" endWordPosition="5339">of a healthcare worker, and one was an unfilled health insurance form. In both cases the falsely classified texts contained both PII and HI, yet there was no link between the two. In the future, a deeper analysis phase – perhaps, co-reference resolution – of potential PHI texts could be done, potentially increasing the precision of the method as a whole. Medical Subjects Heading application Medical Subjects Heading (MeSH), a controlled vocabulary thesaurus, is produced by the National Library of Medicine.20. Its hierarchical and categorized structure is often used in analysis of medical texts [7]. In our case, however, MeSH would require a considerable adjustment before it can be used for PHI leak detection. For example, the top hierarchical terms are too general: Anatomy, Endocrine system (level 1) and Bladder, Work Schedule Tolerance (level 3) do not contribute much to the knowledge of a personal health situation. The bottom level terms might be informative only to experts but not to the general population, e.g Motor Cortex (level 8), Trypanosoma cruzi(level 11). In both cases, the use of these terms could considerably increase the number of false positives. On the other hand, the u</context>
</contexts>
<marker>[7]</marker>
<rawString>L. Bouma and M. de Rijke. Specificity helps text classification. In Proceedings of European Conference on Information Retrieval (ECIR 2006), pages 539–542. Springer, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Chow</author>
<author>P Golle</author>
<author>J Staddon</author>
</authors>
<title>Detecting privacy leaks using corpus-based association rules.</title>
<date>2008</date>
<booktitle>In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<pages>893--901</pages>
<contexts>
<context position="38187" citStr="[8]" startWordPosition="6001" endWordPosition="6001">//www.websense.com/content/home.aspx 23 http://media.techtarget.com/searchFinancialSecurity/ downloads/Understanding Selecting DLP Solution.pdf the computer, then searches documents for its presence. The tool is semi-automated. User intervention is required to reduce false positives, i.e., nonsensitive information wrongly labelled as PII [5]. In related efforts, academic groups mostly work on hospital record de-identification; more details follow in the next paragraph. Few teams are actively involved in health information leak prevention outside of the deidentification of hospital records. In [8], the authors propose a method which detects the inference of sensitive information in documents. The method relies on search engines to find the most frequent association of topic-based terms. In [26], the author describes a method which warns web site owners if posted personal information enables identity theft (e.g., date of birth, address, name). We, instead, focus on leak prevention techniques able to detect information within heterogeneous texts. De-identification of personally identifiable information So far, PHI detection attracted only limited attention from Text Data Mining and NLP c</context>
</contexts>
<marker>[8]</marker>
<rawString>R. Chow, P. Golle, and J. Staddon. Detecting privacy leaks using corpus-based association rules. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pages 893–901, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J DeShazo</author>
<author>D LaVallie</author>
<author>F Wolfe</author>
</authors>
<title>Publication trends in the medical informatics literature: 20 years of ‘medical informatics’ in mesh.</title>
<date>2009</date>
<journal>BMC Medical Informatics and Decision Making,</journal>
<volume>9</volume>
<issue>7</issue>
<contexts>
<context position="41908" citStr="[9]" startWordPosition="6548" endWordPosition="6548">om discharge summaries and family practice notes. In [29], the authors focus on detection of obesity-related diagnostic information. They used NLP methods to extract 16 obesity diagnoses from dictated physician documentation. We, instead, opt for detection of all the HI categories. 6 Discussion In recent years, Text Data Mining and Natural Language Processing communities have concentrated their efforts on the analysis of medical, biomedical and bioinformatics texts. With educational and research medical publications rapidly increasing (for some types, the increase fitting an exponential curve [9]), machinereadable lexical and knowledge sources were built to promote mining of medical texts: MedLine24, GENIA corpus25, MeSH26, to name a few. The services of medical and allied professionals are offered through Health Care27, the industry which provides the prevention, treatment, and management of illness and the preservation of mental and physical well-being. Although medicine and health care are closely related, the domains produce remarkably different text data. A bulk of texts containing medical information comes from articles in medical journals, magazines, professional blogs, researc</context>
</contexts>
<marker>[9]</marker>
<rawString>J. DeShazo, D. LaVallie, and F. Wolfe. Publication trends in the medical informatics literature: 20 years of ‘medical informatics’ in mesh. BMC Medical Informatics and Decision Making, 9(7):e13, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Dixon</author>
</authors>
<title>Medical identity theft: The information crime that can kill you. The World Privacy Forum,</title>
<date>2006</date>
<note>http://www.worldprivacyforum.org/medicali den-titytheft.html, retrieved</note>
<contexts>
<context position="1397" citStr="[10]" startWordPosition="187" endWordPosition="187"> of lexical sources used in medical, scientific, domain for analysis of personal health information. Keywords information leak prevention, personal health information 1 Introduction When electronic means became the prime instrument for storage and exchange of personal health data, the risks of inadvertent disclosure of personal health information (i.e., details of the individual’s health) had increased. Inadvertently disclosed personal health information facilitates criminals to commit medical identity theft, i.e., allows an imposter to obtain care or medications under someone else’s identity [10]. Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken</context>
</contexts>
<marker>[10]</marker>
<rawString>P. Dixon. Medical identity theft: The information crime that can kill you. The World Privacy Forum, 2006. http://www.worldprivacyforum.org/medicali den-titytheft.html, retrieved June 7, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Elger</author>
<author>A Caplan</author>
</authors>
<title>Consent and anonymization in research involving biobanks.</title>
<date>2006</date>
<journal>European Molecular Biology Organization reports,</journal>
<volume>7</volume>
<issue>7</issue>
<pages>666</pages>
<contexts>
<context position="39115" citStr="[11]" startWordPosition="6143" endWordPosition="6143">te of birth, address, name). We, instead, focus on leak prevention techniques able to detect information within heterogeneous texts. De-identification of personally identifiable information So far, PHI detection attracted only limited attention from Text Data Mining and NLP communities. Mainly, the work has been restricted to preparation of hospital records for future use by other researchers, i.e., the secondary use of health data. In Europe and North America, the law requires removal of personally identifiable information, data deidentification, before permitting documents for secondary use [11]. The privacy protection requirements made de-identification popular among NLP, Information Extraction, and Machine Learning applications implemented on hospital records and other PHI texts. Typically, a de-identification method is designed for one type of documents, e.g. discharge summaries [27, 28]. De-identification consists of the detection of patients’ personally identifiable information and its subsequent transformation. De-identification tasks are restricted to detection and transformation of PII, and avoid the analysis of terminology concerning health conditions of patients. The report</context>
</contexts>
<marker>[11]</marker>
<rawString>B. Elger and A. Caplan. Consent and anonymization in research involving biobanks. European Molecular Biology Organization reports, 7(7):661– 666, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K E Emam</author>
<author>E Neri</author>
<author>E Jonker</author>
</authors>
<title>An evaluation of personal health information remnants in second hand personal computer disk drives.</title>
<date>2007</date>
<journal>Journal of Medical Internet Research,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="2758" citStr="[12, 25]" startWordPosition="397" endWordPosition="398">rsonal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit information leak detection. Texts which contain personal health information can be written by doctors, nurses, medical students or patients and can be obtained from various sources within the health care network. Hospitals provide patient health records (e.g. speech assessment, discharge summaries, nurse notes), patients write letters, notes, etc. These texts can be found on the web, within peerto-peer file exchange networks, and on second-hand disk drives [12, 25]. Within those texts, we seek the information which refers to individual’s health: disease (pneumonia)&apos;, treatment procedures (X-rays), prescribed drugs (aspirin), health care providers (the Apple Tree Medical Centre). Our system contributes to information leak prevention, a growing content-based part of data leak prevention. There are several differences between our tool and the previous work on PHI leak prevention. Our system detects personally identifiable and health information. Previous work focussed on detection and de-identification of personally identifiable information (.e.g,, person </context>
<context position="8450" citStr="[12, 25]" startWordPosition="1277" endWordPosition="1278">eir examples. Further, in this paper, we concentrate on the HI category. Personal information Info categories Examples Given names Serge, Jasmine Locations London, Osaka Addresses 401 Smyth Rd., Empire State Bldg. Dates 02 May 2008, 05/14/07 Health information Info categories Examples Disease names Pneumonia, arthritis Symptoms calcium deficiency Drug names Aspirin, Fosamax Health care providers CHEO, Dr. Joe Doe Table 1: PHI categories and their examples Previously, second hand disk drives and peer-to-peer file exchange networks (p2p networks) were searched for the presence of texts with PHI [12, 25]. In [12], we studied the extent of inadvertent PHI exposure on second hand computer hard drives. We purchased functional disk drives from various second-hand computer equipment vendors, then examined sixty drives using 2 http://www.hhs.gov/ocr/privacy/index.html 3 http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri= -CELEX:31995L0046:EN:HTML 59 digital forensic tools. The focus was on drives with a capacity range of 10 GB to 40 GB, which were used by individual end users in desktop machines and servers. The recovered data was examined manually by two experts. PHI was found in 425 files gath</context>
</contexts>
<marker>[12]</marker>
<rawString>K. E. Emam, E. Neri, and E. Jonker. An evaluation of personal health information remnants in second hand personal computer disk drives. Journal of Medical Internet Research, 9(3):e24, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Evfimievski</author>
<author>R Fagin</author>
<author>D Woodruff</author>
</authors>
<title>Epistemic privacy.</title>
<date>2008</date>
<booktitle>In Proceedings of the 27th ACM Symposium on Principles of Database Systems (PODS</booktitle>
<pages>171--180</pages>
<contexts>
<context position="37086" citStr="[13, 19]" startWordPosition="5855" endWordPosition="5856">oncerned with content analysis of data. Information leak prevention tools are deployed in banks, financial companies, government organizations [4]. While processing free-form text data, some of the tools apply NLP methods to enforce safer data management [4]. Many of those tools work on specific text structure and type. Our tool, on the other hand, contributes to the solution of a specific task (i.e., prevention of PHI leaks) without constraining this solution to predefined text structure or types. The applied research community participates in tool development for information leak prevention [13, 19]. Microsoft Research developed a defensive tool that looks for personally identifiable information in one’s own documents. The tool processes digital documents, including metadata, and removes the owner’s name, username,security ID, computer NetBIOS name, names of online, email, webmail servers, etc. No NLP or TDM techniques are involved: all documents are treated as flat byte streams. First, the tool collects potentially sensitive information from 21 http://www.symantec.com/index.jsp 22 http://www.websense.com/content/home.aspx 23 http://media.techtarget.com/searchFinancialSecurity/ downloads</context>
</contexts>
<marker>[13]</marker>
<rawString>A. Evfimievski, R. Fagin, and D. Woodruff. Epistemic privacy. In Proceedings of the 27th ACM Symposium on Principles of Database Systems (PODS 2008), pages 171–180, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gayer</author>
</authors>
<title>Policing privacy: Law enforcement’s response to identity theft. CALPIRG Education Fund,</title>
<date>2003</date>
<note>http://www.calpirg.org/home/reports/report archives, retrieved</note>
<contexts>
<context position="1461" citStr="[14]" startWordPosition="198" endWordPosition="198">ysis of personal health information. Keywords information leak prevention, personal health information 1 Introduction When electronic means became the prime instrument for storage and exchange of personal health data, the risks of inadvertent disclosure of personal health information (i.e., details of the individual’s health) had increased. Inadvertently disclosed personal health information facilitates criminals to commit medical identity theft, i.e., allows an imposter to obtain care or medications under someone else’s identity [10]. Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical record</context>
</contexts>
<marker>[14]</marker>
<rawString>J. Gayer. Policing privacy: Law enforcement’s response to identity theft. CALPIRG Education Fund, 2003. http://www.calpirg.org/home/reports/report archives, retrieved June 7, 2009.</rawString>
</citation>
<citation valid="false">
<date>2003</date>
<editor>F. Hecht and W. Shiel, editors.</editor>
<publisher>Webster’s New World Medical Dictionary. Wiley Publishing,</publisher>
<note>second edition,</note>
<contexts>
<context position="23080" citStr="[15]" startWordPosition="3549" endWordPosition="3549">tify a small number of semantic categories which correspond to the main categories of Health Information; ii work with each category separately, identifying the information that should be analyzed; iii apply Information Extraction methods to find the information indicators in the existing sources. At the initial step, we form three genetic semantic categories – disease, drugs, and symptoms – as was discussed in Section 2; see Table 1 for examples. For diseases and drugs, we concentrate on extraction of their names. The category contents were derived from Webster’s New World Medical Dictionary [15], the International Classification of Diseases (ICD9 codes)9, the Medical Dictionary for Regulatory Activities (MedDRA)10 and Canadian Drug Product Database (Active and Inactive) 11. ICD9 codes [2] are used by health care professionals to tag and classify morbidity data from inpatient and outpatient records, physician offices, as well as most of the National Center for Health Statistics (NCHS)12 and the Canada Institute for Health Information13 surveys. The codes are divided into two sections: one containing diseases and injuries (ICD9CM Disease and Injury), and another containing surgical, di</context>
<context position="44868" citStr="[15]" startWordPosition="7001" endWordPosition="7001">6: The term Plasma Glucose Test and relations to other terms in the MED database (adapted from the MED web site) Consider a text which contains the term Plasma Glucose Test. When referring to an individual, the term indicates examination for diabetes. There are two types of the test. Random Plasma Glucose Test refers to a simple blood sugar test. No fasting or glucose administration is required. Results are processed within 24 to 48 hours or faster. Fasting Plasma Glucose Test is more demanding: the patient should avoid food or drink, except water, for at least 12 hours prior to the procedure [15]. Both test types and the generic term Plasma Glucose Test relate to the physical health of a person, thus, are HI (see Section 2, point 1). CHEM-7, metabolic panel testing31, is a more general term which indicates 7 possible tests (glucose, serum sodium, serum potassium, etc.). The term is HI, although it is less revealing than Plasma Glucose Test. Other terms, e.g., Bioactive Substance, Plasma, Event, may or may not reveal HI, depending on the context. Searching texts for all the sixteen terms in24 http://www.nlm.nih.gov/databases/databases medline.html 25 http://www-tsujii.is.s.u-tokyo.ac.j</context>
</contexts>
<marker>[15]</marker>
<rawString>F. Hecht and W. Shiel, editors. Webster’s New World Medical Dictionary. Wiley Publishing, second edition, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Herzog</author>
<author>F Scheuren</author>
<author>W Winkler</author>
</authors>
<title>Data Quality and Record Linkage Techniques.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<contexts>
<context position="19487" citStr="[16, 3]" startWordPosition="2987" endWordPosition="2988"> limited number of semantic categories, e.g., person and geographic names, disease names and symptoms. Sets of syntactic rules are used to identify references to individuals, locations and ageidentifiable events (birth, death). We parse sentences to find preposition phrases, noun phrases and verb phrases. Soft REGULAR EXPRESSIONS(RE) are used to extract numeric-based categories, such as phone number, street number and unit, dates, and email. In data management and privacy protection, geographic information is shown to be the single most important category responsible for person identification [16, 3]. We implement geographic information extraction for the following categories: country : all the UN-recognized countries and their capitals on all the continents (France, Paris; Liberia, Monrovia), and self-proclaimed entities (Eritrea, Abkhazia) ; place : in US: state name, state capital, the largest city (Illinois, Springfield, Chicago); in Canada: province, province capital, largest cities, tourist attractions (Alberta, Edmonton, Calgary, Banff), the same – for territories; in Europe, Latin America, Asia, Africa, Australia: Alpha, Beta and Gamma world cities 8. code : US’ ZIP code (Massachu</context>
</contexts>
<marker>[16]</marker>
<rawString>T. Herzog, F. Scheuren, and W. Winkler. Data Quality and Record Linkage Techniques. Springer, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Jagannathan</author>
<author>C Mullett</author>
<author>J Arbogast</author>
<author>K Halbritter</author>
<author>D Yellapragada</author>
<author>S Regulapati</author>
<author>P Bandaru</author>
</authors>
<title>Assessment of commercial NLP engines for medication information extraction from dictated clinical notes.</title>
<date>2008</date>
<journal>International Journal of Medical Informatics,</journal>
<volume>78</volume>
<issue>4</issue>
<contexts>
<context position="41145" citStr="[17]" startWordPosition="6438" endWordPosition="6438">reet or area?), or = 1. TˆDP TˆDP; 66 person and trade marks (Tim Hortons - a coffee chain or a person? Jo Malone – a private label or a person?). Withholding of disambiguation accuracy makes it difficult to correctly assess the tool’s performance. We, on other hand, focus on heterogeneous texts whose content and context is not determined before our system processes them. Health care information extraction There are few publications dedicated to health care information analysis in free-form, unstructured texts. Presented work often focuses on specific, rather narrow information categories. In [17], the authors compare four commercial tools which extract medication name, route, dose (number-based), strength (number-based) , and frequency (number-based) from discharge summaries and family practice notes. In [29], the authors focus on detection of obesity-related diagnostic information. They used NLP methods to extract 16 obesity diagnoses from dictated physician documentation. We, instead, opt for detection of all the HI categories. 6 Discussion In recent years, Text Data Mining and Natural Language Processing communities have concentrated their efforts on the analysis of medical, biomed</context>
</contexts>
<marker>[17]</marker>
<rawString>V. Jagannathan, C. Mullett, J. Arbogast, K. Halbritter, D. Yellapragada, S. Regulapati, and P. Bandaru. Assessment of commercial NLP engines for medication information extraction from dictated clinical notes. International Journal of Medical Informatics, 78(4):284 – 291, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Johnson</author>
</authors>
<title>Data hemorrhages in the health-care sector.</title>
<date>2009</date>
<booktitle>In Financial Cryptography and Data Security,</booktitle>
<contexts>
<context position="1787" citStr="[18]" startWordPosition="247" endWordPosition="247">) had increased. Inadvertently disclosed personal health information facilitates criminals to commit medical identity theft, i.e., allows an imposter to obtain care or medications under someone else’s identity [10]. Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical records through a file sharing network [24]. In this work, we present a system which detects personal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit information leak detection. Texts which contain personal health information can be written by doct</context>
<context position="12528" citStr="[18]" startWordPosition="1936" endWordPosition="1936">hase 3). 3.2 Creating the Corpus For our experiments, we used files gathered from two peer-to-peer file sharing networks (p2p networks). Peer-to-peer networks allow decentralized sharing of computer resources, including those that provide the infrastructure for direct, real-time communication and collaboration between peer computers. The networks are known for hosting files with PHI information. The usage, together with the observed security weakness, marks p2p network data as a possible source of information leaks, including PHI leaks. This assumption was confirmed by data management studies [18]. To gather data, we obtained the project approval from the Research Ethics Board of Children’s Hospital of Eastern Ontario. The files were gathered from April 2008 till June 2009. The Gnutella and eD2K P2P networks were selected due to their prevalence and global popularity.4 To automatically capture samples of p2p files, we modified the publicly available ShAREAZA5 p2p client. The tool is a software package which allows one to connect to multiple P2P networks simultaneously in order to search for and download files. Modifications to this client included changes to the search function as well</context>
</contexts>
<marker>[18]</marker>
<rawString>E. Johnson. Data hemorrhages in the health-care sector. In Financial Cryptography and Data Security, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jones</author>
<author>R Kumar</author>
<author>B Pang</author>
<author>A Tomkins</author>
</authors>
<title>Vanity fair: privacy in querylog bundles.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM08),</booktitle>
<pages>853--862</pages>
<contexts>
<context position="37086" citStr="[13, 19]" startWordPosition="5855" endWordPosition="5856">oncerned with content analysis of data. Information leak prevention tools are deployed in banks, financial companies, government organizations [4]. While processing free-form text data, some of the tools apply NLP methods to enforce safer data management [4]. Many of those tools work on specific text structure and type. Our tool, on the other hand, contributes to the solution of a specific task (i.e., prevention of PHI leaks) without constraining this solution to predefined text structure or types. The applied research community participates in tool development for information leak prevention [13, 19]. Microsoft Research developed a defensive tool that looks for personally identifiable information in one’s own documents. The tool processes digital documents, including metadata, and removes the owner’s name, username,security ID, computer NetBIOS name, names of online, email, webmail servers, etc. No NLP or TDM techniques are involved: all documents are treated as flat byte streams. First, the tool collects potentially sensitive information from 21 http://www.symantec.com/index.jsp 22 http://www.websense.com/content/home.aspx 23 http://media.techtarget.com/searchFinancialSecurity/ downloads</context>
</contexts>
<marker>[19]</marker>
<rawString>R. Jones, R. Kumar, B. Pang, and A. Tomkins. Vanity fair: privacy in querylog bundles. In Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM08), pages 853–862, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Long</author>
</authors>
<title>No Tech Hacking: A Guide to Social Engineering, Dumpster Diving, and Shoulder Surfing.</title>
<date>2008</date>
<publisher>Syngress Press,</publisher>
<contexts>
<context position="2002" citStr="[20]" startWordPosition="279" endWordPosition="279"> Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical records through a file sharing network [24]. In this work, we present a system which detects personal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit information leak detection. Texts which contain personal health information can be written by doctors, nurses, medical students or patients and can be obtained from various sources within the health care network. Hospitals provide patient health records (e.g. speech assessment, discharge summaries, nurse notes),</context>
</contexts>
<marker>[20]</marker>
<rawString>J. Long. No Tech Hacking: A Guide to Social Engineering, Dumpster Diving, and Shoulder Surfing. Syngress Press, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C McGuigan</author>
<author>M Browne</author>
</authors>
<title>Hospital leak linked to witness in lvf case.</title>
<date>2007</date>
<location>Belfast Telegraph,</location>
<note>http://www.belfasttelegraph.co.uk/sundaylife/news/hospital-leak-linked-to-witness -in-lvf-case-13904797.html , retrieved</note>
<contexts>
<context position="1573" citStr="[21]" startWordPosition="215" endWordPosition="215">ction When electronic means became the prime instrument for storage and exchange of personal health data, the risks of inadvertent disclosure of personal health information (i.e., details of the individual’s health) had increased. Inadvertently disclosed personal health information facilitates criminals to commit medical identity theft, i.e., allows an imposter to obtain care or medications under someone else’s identity [10]. Furthermore, PHI is an important source of identity theft [14], and has been used by terrorist organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical records through a file sharing network [24]. In this work, we present a system which detects personal health informati</context>
</contexts>
<marker>[21]</marker>
<rawString>C. McGuigan and M. Browne. Hospital leak linked to witness in lvf case. Belfast Telegraph, 2007. http://www.belfasttelegraph.co.uk/sundaylife/news/hospital-leak-linked-to-witness -in-lvf-case-13904797.html , retrieved June 7, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Neamatullah</author>
<author>M Douglass</author>
<author>L Lehman</author>
<author>A Reisner</author>
<author>M Villarroel</author>
<author>W Long</author>
<author>P Szolovits</author>
<author>G Moody</author>
<author>R Mark</author>
<author>G Clifford</author>
</authors>
<title>Automated de-identification of free-text medical records.</title>
<date>2008</date>
<journal>BMC Medical Informatics and Decision Making,</journal>
<volume>8</volume>
<issue>32</issue>
<contexts>
<context position="39916" citStr="[22]" startWordPosition="6249" endWordPosition="6249">lly, a de-identification method is designed for one type of documents, e.g. discharge summaries [27, 28]. De-identification consists of the detection of patients’ personally identifiable information and its subsequent transformation. De-identification tasks are restricted to detection and transformation of PII, and avoid the analysis of terminology concerning health conditions of patients. The reported systems’ primary methods are look-ups of person and geographic name dictionaries. Their performance, thus, depends on comparability of the dictionaries and the input data. Table 8, adapted from [22], compares the performance of a publicly available de-identifier STAT DE-id when it uses customized dictionaries (the left part) and without them (the right part). The results were obtained on the de-identification of nurse notes. Customized Non-customized dictionaries dictionaries Fscore Pr R Fscore Pr R 84.4 74.9 96.7 77.4 72.3 83.4 Table 8: Classification (%) of person names, health care provider names, addresses, age-related dates. Unfortunately, many publications do not report on disambiguation results, e.g. person and geographic names (Washington - surname, city, or state? Sofia - name o</context>
</contexts>
<marker>[22]</marker>
<rawString>I. Neamatullah, M. Douglass, L. Lehman, A. Reisner, M. Villarroel, W. Long, P. Szolovits, G. Moody, R. Mark, and G. Clifford. Automated de-identification of free-text medical records. BMC Medical Informatics and Decision Making, 8(32):e17, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pepe</author>
</authors>
<title>The Statistical Evaluation of Medical Tests for Classification and Prediction.</title>
<date>2004</date>
<publisher>Oxford University Press,</publisher>
<contexts>
<context position="31065" citStr="[23]" startWordPosition="4804" endWordPosition="4804">uld be. Figure 5 depicts the PHI text classification process. Fig. 5: HI text classification 4 Empirical Results Evaluation on screened positive examples Evaluating the correct identification of PHI leaks presents a certain methodological difficulty. The number of PHI files is negligible even if compared with the number of probable containers. On the other hand, all of the PHI files exhibit specific characteristics: they contain personally identifiable and health information. Hence, we can apply measures that evaluate a tool’s performance only on examples which satisfy pre-determined criteria [23]. The other examples 3T + 2B + U n M= 1 k n 1 3Ti + 2Bi + Ui Wi n k 1 64 are ignored. The approach – evaluation on screened positive examples – has been shown effective and appropriate for PHI leak detection [25]. Table 3 presents the confusion matrix: Predicted HI =1 HI =0 Table 3: Confusion matrix for classification of screen positive examples We compute True Detection Probability( TˆDP) and False Referral Probability( FˆRP): FˆRP = n+ + n� . n+ PHI (12) TDP shows the proportion of files an algorithm marked as having the PII and HI indicators and containing PHI. FRP shows the proportion of f</context>
</contexts>
<marker>[23]</marker>
<rawString>M. Pepe. The Statistical Evaluation of Medical Tests for Classification and Prediction. Oxford University Press, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Preimesberger</author>
</authors>
<title>Cyber-criminals use p2p tools for identity theft, security analyst warns. eWeek.com,</title>
<date>2006</date>
<contexts>
<context position="2098" citStr="[24]" startWordPosition="296" endWordPosition="296">organizations to target law enforcement personnel and intimidate witnesses [21]. PHI security breaches had happened in various domains. PHI has leaked from a Canadian provincial government agency [6] and from health care providers, through documents sent by employees and medical students [18]. There are several examples of the confirmed leaks on peer-to-peer file sharing networks: a chiropractor exposed his patient files on a peer-to-peer network, including notes on treatments and medications taken [20], a criminal obtained passwords for 117, 000 medical records through a file sharing network [24]. In this work, we present a system which detects personal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit information leak detection. Texts which contain personal health information can be written by doctors, nurses, medical students or patients and can be obtained from various sources within the health care network. Hospitals provide patient health records (e.g. speech assessment, discharge summaries, nurse notes), patients write letters, notes, etc. These texts can be found on the web, within peerto-peer fil</context>
</contexts>
<marker>[24]</marker>
<rawString>C. Preimesberger. Cyber-criminals use p2p tools for identity theft, security analyst warns. eWeek.com, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sokolova</author>
<author>K El</author>
</authors>
<title>Emam. Evaluation of learning from screened positive examples.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd workshop on Evaluation Methods for Machine Learning (EMML-ICML</booktitle>
<contexts>
<context position="2758" citStr="[12, 25]" startWordPosition="397" endWordPosition="398">rsonal health information (PHI) in free-form heterogenous texts. It can be used to detect the inadvertent disclosure of PHI, thus, benefit information leak detection. Texts which contain personal health information can be written by doctors, nurses, medical students or patients and can be obtained from various sources within the health care network. Hospitals provide patient health records (e.g. speech assessment, discharge summaries, nurse notes), patients write letters, notes, etc. These texts can be found on the web, within peerto-peer file exchange networks, and on second-hand disk drives [12, 25]. Within those texts, we seek the information which refers to individual’s health: disease (pneumonia)&apos;, treatment procedures (X-rays), prescribed drugs (aspirin), health care providers (the Apple Tree Medical Centre). Our system contributes to information leak prevention, a growing content-based part of data leak prevention. There are several differences between our tool and the previous work on PHI leak prevention. Our system detects personally identifiable and health information. Previous work focussed on detection and de-identification of personally identifiable information (.e.g,, person </context>
<context position="8450" citStr="[12, 25]" startWordPosition="1277" endWordPosition="1278">eir examples. Further, in this paper, we concentrate on the HI category. Personal information Info categories Examples Given names Serge, Jasmine Locations London, Osaka Addresses 401 Smyth Rd., Empire State Bldg. Dates 02 May 2008, 05/14/07 Health information Info categories Examples Disease names Pneumonia, arthritis Symptoms calcium deficiency Drug names Aspirin, Fosamax Health care providers CHEO, Dr. Joe Doe Table 1: PHI categories and their examples Previously, second hand disk drives and peer-to-peer file exchange networks (p2p networks) were searched for the presence of texts with PHI [12, 25]. In [12], we studied the extent of inadvertent PHI exposure on second hand computer hard drives. We purchased functional disk drives from various second-hand computer equipment vendors, then examined sixty drives using 2 http://www.hhs.gov/ocr/privacy/index.html 3 http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri= -CELEX:31995L0046:EN:HTML 59 digital forensic tools. The focus was on drives with a capacity range of 10 GB to 40 GB, which were used by individual end users in desktop machines and servers. The recovered data was examined manually by two experts. PHI was found in 425 files gath</context>
<context position="13545" citStr="[25]" startWordPosition="2102" endWordPosition="2102">which allows one to connect to multiple P2P networks simultaneously in order to search for and download files. Modifications to this client included changes to the search function as well as increased logging capabilities. The search function was modified to automatically search for any document file (Microsoft Word, Raw Text, Rich Text, Excel, Powerpoint, PDF, Wordpad, XML, etc) and automatically retrieve it. Automatic searches were conducted by the code at fifteen minute intervals. A semi-manual analysis of the first data sample (859 files) showed the presence of PHI on the two p2p networks [25]. In total, we have gathered 2852 files. The data was sent for processing “as is”, without preliminary pre-processing: we preserve all the initial spelling, capitalization, grammar, etc. 4 http://www.kolabora.com/news/2004/01/09/popular p2p tools and programs.htm, retrieved Aug 12, 2009 5 http://shareaza.sourceforge.net/?id=source 60 Detection of publishable and educational text Detection of non-personal text Table 2: Categories and terms for partial content analysis Categories Examples Categories Examples Books ebook, ISBN, publisher Periodic magazine, article, volume Retail manual, readme, c</context>
<context position="31277" citStr="[25]" startWordPosition="4851" endWordPosition="4851">s a certain methodological difficulty. The number of PHI files is negligible even if compared with the number of probable containers. On the other hand, all of the PHI files exhibit specific characteristics: they contain personally identifiable and health information. Hence, we can apply measures that evaluate a tool’s performance only on examples which satisfy pre-determined criteria [23]. The other examples 3T + 2B + U n M= 1 k n 1 3Ti + 2Bi + Ui Wi n k 1 64 are ignored. The approach – evaluation on screened positive examples – has been shown effective and appropriate for PHI leak detection [25]. Table 3 presents the confusion matrix: Predicted HI =1 HI =0 Table 3: Confusion matrix for classification of screen positive examples We compute True Detection Probability( TˆDP) and False Referral Probability( FˆRP): FˆRP = n+ + n� . n+ PHI (12) TDP shows the proportion of files an algorithm marked as having the PII and HI indicators and containing PHI. FRP shows the proportion of files the algorithm marked as having the PII and HI indicators but not containing PHI. To put the measures in perspective, we use the ideal classification (Table 4) where all the predicted HI files are indeed the </context>
</contexts>
<marker>[25]</marker>
<rawString>M. Sokolova and K. El Emam. Evaluation of learning from screened positive examples. In Proceedings of the 3rd workshop on Evaluation Methods for Machine Learning (EMML-ICML 2008), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Sweeney</author>
</authors>
<title>Protecting job seekers from identity theft.</title>
<date>2006</date>
<journal>IEEE Internet Computing,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="38388" citStr="[26]" startWordPosition="6033" endWordPosition="6033">The tool is semi-automated. User intervention is required to reduce false positives, i.e., nonsensitive information wrongly labelled as PII [5]. In related efforts, academic groups mostly work on hospital record de-identification; more details follow in the next paragraph. Few teams are actively involved in health information leak prevention outside of the deidentification of hospital records. In [8], the authors propose a method which detects the inference of sensitive information in documents. The method relies on search engines to find the most frequent association of topic-based terms. In [26], the author describes a method which warns web site owners if posted personal information enables identity theft (e.g., date of birth, address, name). We, instead, focus on leak prevention techniques able to detect information within heterogeneous texts. De-identification of personally identifiable information So far, PHI detection attracted only limited attention from Text Data Mining and NLP communities. Mainly, the work has been restricted to preparation of hospital records for future use by other researchers, i.e., the secondary use of health data. In Europe and North America, the law req</context>
</contexts>
<marker>[26]</marker>
<rawString>L. Sweeney. Protecting job seekers from identity theft. IEEE Internet Computing, 10(2):74– 78, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uzuner</author>
<author>Y Luo</author>
<author>P Szolovits</author>
</authors>
<title>Evaluating the state-of-the-art in automatic deindentification.</title>
<date>2007</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>14</volume>
<contexts>
<context position="39416" citStr="[27, 28]" startWordPosition="6182" endWordPosition="6183">he work has been restricted to preparation of hospital records for future use by other researchers, i.e., the secondary use of health data. In Europe and North America, the law requires removal of personally identifiable information, data deidentification, before permitting documents for secondary use [11]. The privacy protection requirements made de-identification popular among NLP, Information Extraction, and Machine Learning applications implemented on hospital records and other PHI texts. Typically, a de-identification method is designed for one type of documents, e.g. discharge summaries [27, 28]. De-identification consists of the detection of patients’ personally identifiable information and its subsequent transformation. De-identification tasks are restricted to detection and transformation of PII, and avoid the analysis of terminology concerning health conditions of patients. The reported systems’ primary methods are look-ups of person and geographic name dictionaries. Their performance, thus, depends on comparability of the dictionaries and the input data. Table 8, adapted from [22], compares the performance of a publicly available de-identifier STAT DE-id when it uses customized </context>
</contexts>
<marker>[27]</marker>
<rawString>O. Uzuner, Y. Luo, and P. Szolovits. Evaluating the state-of-the-art in automatic deindentification. Journal of the American Medical Informatics Association, 14:550–563, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uzuner</author>
<author>T Sibanda</author>
<author>Y Luo</author>
<author>P Szolovits</author>
</authors>
<title>A de-identifier for medical discharge summaries.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence in Medicine,</journal>
<volume>42</volume>
<contexts>
<context position="39416" citStr="[27, 28]" startWordPosition="6182" endWordPosition="6183">he work has been restricted to preparation of hospital records for future use by other researchers, i.e., the secondary use of health data. In Europe and North America, the law requires removal of personally identifiable information, data deidentification, before permitting documents for secondary use [11]. The privacy protection requirements made de-identification popular among NLP, Information Extraction, and Machine Learning applications implemented on hospital records and other PHI texts. Typically, a de-identification method is designed for one type of documents, e.g. discharge summaries [27, 28]. De-identification consists of the detection of patients’ personally identifiable information and its subsequent transformation. De-identification tasks are restricted to detection and transformation of PII, and avoid the analysis of terminology concerning health conditions of patients. The reported systems’ primary methods are look-ups of person and geographic name dictionaries. Their performance, thus, depends on comparability of the dictionaries and the input data. Table 8, adapted from [22], compares the performance of a publicly available de-identifier STAT DE-id when it uses customized </context>
</contexts>
<marker>[28]</marker>
<rawString>O. Uzuner, T. Sibanda, Y. Luo, and P. Szolovits. A de-identifier for medical discharge summaries. Journal of Artificial Intelligence in Medicine, 42:13–35, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ware</author>
<author>C Mullett</author>
<author>V Jagannathan</author>
</authors>
<title>Natural Language Processing (NLP) Framework to Assess Clinical Conditions.</title>
<date>2009</date>
<journal>Journal of the American Medical Informatics Association : JAMIA,</journal>
<volume>16</volume>
<contexts>
<context position="41362" citStr="[29]" startWordPosition="6467" endWordPosition="6467"> assess the tool’s performance. We, on other hand, focus on heterogeneous texts whose content and context is not determined before our system processes them. Health care information extraction There are few publications dedicated to health care information analysis in free-form, unstructured texts. Presented work often focuses on specific, rather narrow information categories. In [17], the authors compare four commercial tools which extract medication name, route, dose (number-based), strength (number-based) , and frequency (number-based) from discharge summaries and family practice notes. In [29], the authors focus on detection of obesity-related diagnostic information. They used NLP methods to extract 16 obesity diagnoses from dictated physician documentation. We, instead, opt for detection of all the HI categories. 6 Discussion In recent years, Text Data Mining and Natural Language Processing communities have concentrated their efforts on the analysis of medical, biomedical and bioinformatics texts. With educational and research medical publications rapidly increasing (for some types, the increase fitting an exponential curve [9]), machinereadable lexical and knowledge sources were </context>
</contexts>
<marker>[29]</marker>
<rawString>H. Ware, C. Mullett, and V. Jagannathan. Natural Language Processing (NLP) Framework to Assess Clinical Conditions. Journal of the American Medical Informatics Association : JAMIA, 16:585–589, 2009.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>