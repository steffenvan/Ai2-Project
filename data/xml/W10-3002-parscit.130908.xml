<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000694">
<title confidence="0.9987765">
A Cascade Method for Detecting Hedges and their Scope in Natural
Language Text
</title>
<author confidence="0.998198">
Buzhou Tang, Xiaolong Wang, Xuan Wang, Bo Yuan, Shixi Fan
</author>
<affiliation confidence="0.954294666666667">
Key Laboratory of Network Oriented Intelligent Computation
Harbin Institute of Technology Shenzhen Graduate School
Shenzhen, Guangdong, China
</affiliation>
<email confidence="0.991681">
{tangbuzhou,yuanbo.hitsz}@gmail.com
{wangxl,wangxuan,fanshixi}@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.997343" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959791666667">
Detecting hedges and their scope in nat-
ural language text is very important for
information inference. In this paper,
we present a system based on a cascade
method for the CoNLL-2010 shared task.
The system composes of two components:
one for detecting hedges and another one
for detecting their scope. For detecting
hedges, we build a cascade subsystem.
Firstly, a conditional random field (CRF)
model and a large margin-based model are
trained respectively. Then, we train an-
other CRF model using the result of the
first phase. For detecting the scope of
hedges, a CRF model is trained according
to the result of the first subtask. The ex-
periments show that our system achieves
86.36% F-measure on biological corpus
and 55.05% F-measure on Wikipedia cor-
pus for hedge detection, and 49.95% F-
measure on biological corpus for hedge
scope detection. Among them, 86.36%
is the best result on biological corpus for
hedge detection.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981775">
Hedge cues are very common in natural language
text. Vincze et al. (2008) report that 17.70% of
the sentences in the abstract section and 19.94% of
sentences in the full paper section contain hedges
on BioScope corpus. As Vincze et al. (2008)
suggest that information that falls in the scope
of hedges can not be presented as factual in-
formation. Detecting hedges and their scope in
natural language text is very important for in-
formation inference. Recently, relative research
has received considerable interest in the biomed-
ical NLP community, including detecting hedges
and their in-sentence scope in biomedical texts
(Morante and Daelemans, 2009). The CoNLL-
2010 has launched a shared task for exploiting the
hedge scope annotated in the BioScope (Vincze et
al., 2008) and publicly available Wikipedia (Gan-
ter and Strube, 2009) weasel annotations. The
shared task contains two subtasks (Farkas et al.,
2010): 1. learning to detect hedges in sentences on
BioScope and Wikipedia; 2. learning to detect the
in-sentence scope of these hedges on BioScope.
In this paper, we present a system based on a
cascade method for the CoNLL-2010 shared task.
The system composes of two components: one
for detecting hedges and another one for detect-
ing their scope. For detecting hedges, we build
a cascade subsystem. Firstly, conditional ran-
dom field (CRF) model and a large margin-based
model are trained respectively. Then, we train
another CRF model using the result of the first
phase. For detecting the scope of hedges, a CRF
model is trained according to the result of the first
subtask. The experiments show that our system
achieves 86.36% F-measure on biological corpus
and 55.05% F-measure on Wikipedia corpus for
hedge detection, and 49.95% F-measure on bio-
logical corpus for hedge scope detection. Among
them, 86.36% is the best result on biological cor-
pus for hedge detection.
</bodyText>
<sectionHeader confidence="0.977845" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999791571428571">
As there are two subtasks, we present a system
based on a cascade supervised machine learning
methods for the CoNLL-2010 shared task. The ar-
chitecture of our system is shown in Figure 1.
The system composes of two subsystems for
two subtasks respectively, and the first subsystem
is a two-layer cascaded classifier.
</bodyText>
<subsectionHeader confidence="0.996841">
2.1 Hedge Detection
</subsectionHeader>
<bodyText confidence="0.995206333333333">
The hedges are represented by indicating whether
a token is in a hedge and its position in the
CoNLL-2010 shared task. Three tags are used for
</bodyText>
<page confidence="0.992937">
13
</page>
<note confidence="0.7838145">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 13–17,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999919">
Figure 1: System architecture
</figureCaption>
<bodyText confidence="0.99994825">
this scheme, where O cue indicates a token out-
side of a hedge, B cue indicates a token at the
beginning of a hedge and I cue indicates a to-
ken inside of a hedge. In this subsystem, we do
preprocessing by GENIA Tagger (version 3.0.1)1
at first, which does lemma extraction, part-of-
speech (POS), chunking and named entity recog-
nition (NER) for feature extraction. For the out-
put of GENIA Tagger, we convert the first char
of a lemma into lower case and BIO chunk tag
into BIOS chunk tag, where S indicates a token
is a chunk, B indicates a token at the beginning
of a chunk, I indicates a token inside of a chunk,
and O indicates a token outside of a chunk. Then
a two-layer cascaded classifier is built for pre-
diction. There are a CRF classifier and a large
margin-based classifier in the first layer and a CRF
classifier in the second layer.
In the first layer, the following features are used
in our system:
</bodyText>
<listItem confidence="0.987118">
• Word and Word Shape of the lemma: we used
the similar scheme as shown in (Tsai et al.,
2005).
</listItem>
<footnote confidence="0.519164">
1http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/
</footnote>
<listItem confidence="0.887650210526316">
• Prefix and Suffix with length 3-5.
• Context of the lemma, POS and the chunk in
the window [-2,2].
• Combined features including LoCo, LiP0
and LiC0, where −1 G i G 1 L denotes the
lemma of a word, P denotes a POS and C
denotes a chunk tag.
• The type of a chunk; the lemma and POS se-
quences of it.
• Whether a token is a part of the pairs ”neither
... nor” and ”either ... or” as both tokens of a
pair are always labeled with the same tag.
• Whether a token can possibly be classified
into B cue, I cue or O cue; its lemma, POS
and chunk tag for each possible case: these
features are extracted according to a dictio-
nary extracted from training corpus, which
lists all possible hedge tag for each word in
the training corpus.
</listItem>
<bodyText confidence="0.821549">
In the second layer, we used some features
about the result of the last layer besides those men-
tioned above. They are listed as follow:
</bodyText>
<listItem confidence="0.996165833333333">
• The lemma and POS sequences of the hedge
predicted by each classifier.
• The times of a token classified into B cue,
I cue and O cue by the first two classifiers.
• Whether a token is the last token of the hedge
predicted by each classifier.
</listItem>
<subsectionHeader confidence="0.998523">
2.2 Hedge Scope Detection
</subsectionHeader>
<bodyText confidence="0.999991928571428">
We follow the way of Morante and Daelemans
(2009) to represent the scope of a hedge, where
F scope indicates a token at the beginning of a
scope sequence, L scope indicates a token at the
last of a scope sequence, and NONE indicates
others. In this phase, we do preprocessing by
GDep Tagger (version beta1)2 at first, which does
lemma extraction, part-of-speech (POS), chunk-
ing, named entity recognition (NER) and depen-
dency parse for feature extraction. For the out-
put of GDep Tagger, we deal with the lemma and
chunk tag using the same way mentioned in the
last section. Then, a CRF classifier is built for pre-
diction, which uses the following features:
</bodyText>
<footnote confidence="0.995001">
2http://www.cs.cmu.edu/ sagae/parser/gdep
</footnote>
<page confidence="0.996186">
14
</page>
<listItem confidence="0.981109208333333">
• Word.
• Context of the lemma, POS, the chunk, the
hedge and the dependency relation in the
window [-2,2].
• Combined features including L0C0,
L0H0, L0D0, LZP0, PZC0,PZH0, CZH0,
PZD0,CZD0, where −1 G i G 1 L denotes
the lemma of a word, P denotes a POS, C
denotes a chunk tag, H denotes a hedge tag
and D denotes a dependency relation tag.
• The type of a chunk; the lemma and POS se-
quences of it.
• The type of a hedge; the lemma, POS and
chunk sequences of it.
• The lemma, POS, chunk, hedge and depen-
dency relation sequences of 1st and 2nd de-
pendency relation edges; the lemma, POS,
chunk, hedge and dependency relation se-
quences of the path from a token to the root.
• Whether there are hedges in the 1st, 2nd de-
pendency relation edges or path from a token
to the root.
• The location of a token relative to the nega-
tion signal: previous the first hedge, in the
</listItem>
<bodyText confidence="0.9923005">
first hedge, between two hedge cues, in the
last hedge, post the last hedge.
At last, we provided a postprocessing system
for the output of the classifier to build the com-
plete sequence of tokens that constitute the scope.
We applied the following postprocessing:
</bodyText>
<listItem confidence="0.898608258064516">
• If a hedge is bracketed by a F scope and a
L scope, its scope is formed by the tokens be-
tween them.
• If a hedge is only bracketed by a F scope, and
there is no L scope in the sentence, we search
the first possible word from the end of the
sentence according to a dictionary, which ex-
tracted from the training corpus, and assign it
as L scope. The scope of the hedge is formed
by the tokens between them.
• If a hedge is only bracketed by a F scope, and
there are at least one L scope in the sentence,
we think the last L scope is the L scope of the
hedge, and its scope is formed by the tokens
between them.
• If a hedge is only bracketed by a L scope,
and there is no F scope in the sentence, we
search the first possible word from the begin-
ning of the sentence to the hedge according to
the dictionary, and assign it as F scope. The
scope of the hedge is formed by the tokens
between them.
• If a hedge is only bracketed by a L scope,
and there are at least one F scope in the sen-
tence, we search the first possible word from
the hedge to the beginning of the sentence ac-
cording to the dictionary, and think it as the
F scope of the hedge. The scope of the hedge
is formed by the tokens between them.
• If a hedge is bracketed by neither of them, we
remove it.
</listItem>
<sectionHeader confidence="0.996662" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.99990325">
Two annotated corpus: BioScope and Wikipedia
are supplied for the CoNLL-2010 shared task. The
BioScope corpus consists of two parts: biological
paper abstracts and biological full papers, and it
is used for two subtasks. The Wikipedia corpus is
only used for hedge detection. The detailed infor-
mation of these two corpora is shown in Table 1
and Table 2, respectively.
</bodyText>
<table confidence="0.995240714285714">
Abstracts Papers Test
#Documents 1273 9 15
#Sentences 11871 2670 5003
%Hedge sent. 17.70 19.44 15.75
#Hedges 2694 682 1043
#AvL. of sent. 30.43 27.95 31.30
#AvL. of scopes 17.27 14.17 17.51
</table>
<tableCaption confidence="0.865434">
Table 1: The detailed information of BioScope
corpus. ”AvL.” stands for average length.
</tableCaption>
<table confidence="0.999464">
Train Test
#Documents 2186 2737
#Sentences 11111 9634
%Hedge sentences 22.36 23.19
#Hedges 3133 3143
#AvL. of sentences 23.07 20.82
</table>
<tableCaption confidence="0.8676275">
Table 2: The detail information of Wikipedia cor-
pus. ”AvL.” stands for average length.
</tableCaption>
<bodyText confidence="0.817101">
In our experiments, CRF++-0.533 implemen-
</bodyText>
<footnote confidence="0.961693">
3http://crfpp.sourceforge.net/
</footnote>
<page confidence="0.99832">
15
</page>
<bodyText confidence="0.999922888888889">
tation is employed to CRF, and svm hmm 3.104
implementation is employed to the large margin
method. All parameters are default except C
(the trade-off between training error and margin,
C=8000, for selecting C, the training corpus is par-
titioned into three parts, two of them are used for
training and the left one is used as a development
dataset) in svm hmm. Both of them are state-of-
the-art toolkits for the sequence labeling problem.
</bodyText>
<subsectionHeader confidence="0.99891">
3.1 Hedge Detection
</subsectionHeader>
<bodyText confidence="0.983445555555555">
We first compare the performance of each single
classifier with the cascaded system on two corpora
in domain, respectively. Each model is trained by
whole corpus, and the performance of them was
evaluated by the official tool of the CoNLL-2010
shared task. There were two kinds of measure:
one for sentence-level performance and another
one for cue-match performance. Here, we only
focused on the first one, and the results shown in
</bodyText>
<tableCaption confidence="0.949703">
Table 3.
</tableCaption>
<table confidence="0.999888571428571">
Corpus System Prec. Recall F1
CRF 87.12 86.46 86.79
BioScope LM 85.24 87.72 86.46
CAS 85.03 87.72 86.36
CRF 86.10 35.77 50.54
Wikipedia LM 82.28 41.36 55.05
CAS 82.28 41.36 55.05
</table>
<tableCaption confidence="0.61589275">
Table 3: In-sentence performance of the hedge
detection subsystem for in-domain test. ”Prec.”
stands for precision, ”LM” stands for large mar-
gin, and ”CAS” stands for cascaded system.
</tableCaption>
<bodyText confidence="0.999819466666667">
From Table 3, we can see that the cascaded sys-
tem is not better than other two single classifiers
and the single CRF classifier achieves the best per-
formance with F-measure 86.79%. The reason for
selecting this cascaded system for our final sub-
mission is that the cascaded system achieved the
best performance on the two training corpus when
we partition each one into three parts: two of them
are used for training and the left one is used for
testing.
For cross-domain test, we train a cascaded clas-
sifier using BioScope+Wikipedia cropus. Table 4
shows the results.
As shown in Table 5, the performance of cross-
domain test is worse than that of in-domain test.
</bodyText>
<footnote confidence="0.9769285">
4http://www.cs.cornell.edu/People/tj/svm light/svm-
hmm.html
</footnote>
<table confidence="0.996517">
Corpus Precision Recall F1
BioScope 89.91 73.29 80.75
Wikipedia 81.56 40.20 53.85
</table>
<tableCaption confidence="0.670856666666667">
Table 4: Results of the hedge detection for cross-
domain test. ”LM” stands for large margin, and
”CAS” stands for cascaded system.
</tableCaption>
<subsectionHeader confidence="0.99982">
3.2 Hedge Scope Detection
</subsectionHeader>
<bodyText confidence="0.999813947368421">
For test the affect of postprocessing for hedge
scope detection, we test our system using two eval-
uation tools: one for scope tag and the other one
for sentence-level scope (the official tool). In or-
der to evaluate our system comprehensively, four
results are used for comparison. The ”gold” is the
performance using golden hedge tags for test, the
”CRF” is the performance using the hedge tags
prediction of single CRF for test, the ”LM” is the
performance using the hedge tag prediction of sin-
gle large margin for test, and ”CAS” is the per-
formance of using the hedge tag prediction of cas-
caded subsystem for test. The results of scope tag
and scope sentence-level are listed in Table 5 and
Table 6, respectively. Here, we should notice that
the result listed here is different with that submit-
ted to the CoNLL-2010 shared task because some
errors for feature extraction in the previous system
are revised here.
</bodyText>
<table confidence="0.999666846153846">
HD tag Precision Recall F1
F scope 92.06 78.83 84.94
gold L scope 80.56 68.67 74.14
NONE 99.68 99.86 99.77
F scope 78.83 66.89 72.37
CRF L scope 72.52 60.50 65.97
NONE 99.56 99.75 99.65
F scope 77.25 67.57 72.09
LM L scope 72.33 61.41 66.42
NONE 99.56 99.73 99.31
F scope 77.32 67.86 72.29
CAS L scope 72.00 61.29 66.22
NONE 99.57 99.73 99.65
</table>
<tableCaption confidence="0.991698">
Table 5: Results of the hedge scope tag. ”HD”
</tableCaption>
<bodyText confidence="0.913906333333333">
stands for hedge detection subsystem we used,
”LM” stands for large margin, and ”CAS” stands
for cascaded system.
As shown in Table 5, the performance of
L scope is much lower than that of F scope.
Therefore, the first problem we should solve is
</bodyText>
<page confidence="0.994915">
16
</page>
<table confidence="0.997844">
HD subsystem Precision Recall F1
gold 57.92 55.95 56.92
CRF 52.36 48.40 50.30
LM 51.06 48.89 49.95
CAS 50.96 48.98 49.95
</table>
<tableCaption confidence="0.8342775">
Table 6: Results of the hedge scope in-sentence.
”HD” stands for hedge detection subsystem we
used, ”LM” stands for large margin, and ”CAS”
stands for cascaded system.
</tableCaption>
<bodyText confidence="0.9997868">
how to improve the prediction performance of
L scope. Moreover, compared the performance
shown in Table 5 and 6, about 15% (F1 of L scope
in Table 5 - F1 in Table 6) scope labels are mis-
matched. An efficient postprocessing is needed to
do F-L scope pair match.
As ”CRF” hedge detection subsystem is bet-
ter than the other two subsystems, our system
achieves the best performance with F-measure
50.30% when using the ”CRF” subsystem.
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999946916666667">
This paper presents a cascaded system for the
CoNLL-2010 shared task, which contains two
subsystems: one for detecting hedges and an-
other one for detecting their scope. Although
the best performance of hedge detection subsys-
tem achieves F-measure 86.79%, the best per-
formance of the whole system only achieves F-
measure 50.30%. How to improve it, we think
some complex features such as context free gram-
mar may be effective for detecting hedge scope.
In addition, the postprocessing can be further im-
proved.
</bodyText>
<sectionHeader confidence="0.998964" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997657727272727">
We wish to thank the organizers of the CoNLL-
2010 shared task for preparing the datasets
and organizing the challenge shared tasks.
We also wish to thank all authors supply-
ing the toolkits used in this paper. This
research has been partially supported by the
National Natural Science Foundation of China
(No.60435020 and No.90612005), National 863
Program of China (No.2007AA01Z194) and the
Goal-oriented Lessons from the National 863 Pro-
gram of China (No.2006AA01Z197).
</bodyText>
<sectionHeader confidence="0.997875" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998886655172414">
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, Gy¨orgy Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their
Scope in Natural Language Text. In Proceedings of
the Fourteenth Conference on Computational Nat-
ural Language Learning (CoNLL-2010): Shared
Task, pages 1–12, Uppsala, Sweden, July. Associ-
ation for Computational Linguistics.
Viola Ganter and Michael Strube. 2009. Finding
hedges by chasing weasels: Hedge detection using
wikipedia tags and shallow linguistic features. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 173–176, Suntec, Singapore,
August. Association for Computational Linguistics.
Roser Morante and Walter Daelemans. 2009. Learning
the scope of hedge cues in biomedical texts. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 28–
36, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Tzong-Han Tsai, Chia-Wei Wu, and Wen-Lian Hsu.
2005. Using Maximum Entropy to Extract Biomed-
ical Named Entities without Dictionaries. In Sec-
ond International Joint Conference on Natural Lan-
guage Processing, pages 268–273.
Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas,
Gy¨orgy M´ora, and J´anos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9(Suppl 11):S9.
</reference>
<page confidence="0.999403">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.824772">
<title confidence="0.995333">A Cascade Method for Detecting Hedges and their Scope in Language Text</title>
<author confidence="0.985287">Buzhou Tang</author>
<author confidence="0.985287">Xiaolong Wang</author>
<author confidence="0.985287">Xuan Wang</author>
<author confidence="0.985287">Bo Yuan</author>
<author confidence="0.985287">Shixi</author>
<affiliation confidence="0.9595845">Key Laboratory of Network Oriented Intelligent Harbin Institute of Technology Shenzhen Graduate</affiliation>
<address confidence="0.940216">Shenzhen, Guangdong,</address>
<abstract confidence="0.99865276">hedges and their scope in ural language text is very important for information inference. In this we present a system based on a cascade method for the CoNLL-2010 shared task. The system composes of two components: one for detecting hedges and another one for detecting their scope. For detecting hedges, we build a cascade subsystem. Firstly, a conditional random field (CRF) model and a large margin-based model are trained respectively. Then, we train another CRF model using the result of the first phase. For detecting the scope of hedges, a CRF model is trained according to the result of the first subtask. The experiments show that our system achieves 86.36% F-measure on biological corpus and 55.05% F-measure on Wikipedia corpus for hedge detection, and 49.95% Fmeasure on biological corpus for hedge scope detection. Among them, 86.36% is the best result on biological corpus for hedge detection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, Gy¨orgy Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viola Ganter</author>
<author>Michael Strube</author>
</authors>
<title>Finding hedges by chasing weasels: Hedge detection using wikipedia tags and shallow linguistic features.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>173--176</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="2141" citStr="Ganter and Strube, 2009" startWordPosition="326" endWordPosition="330">cope corpus. As Vincze et al. (2008) suggest that information that falls in the scope of hedges can not be presented as factual information. Detecting hedges and their scope in natural language text is very important for information inference. Recently, relative research has received considerable interest in the biomedical NLP community, including detecting hedges and their in-sentence scope in biomedical texts (Morante and Daelemans, 2009). The CoNLL2010 has launched a shared task for exploiting the hedge scope annotated in the BioScope (Vincze et al., 2008) and publicly available Wikipedia (Ganter and Strube, 2009) weasel annotations. The shared task contains two subtasks (Farkas et al., 2010): 1. learning to detect hedges in sentences on BioScope and Wikipedia; 2. learning to detect the in-sentence scope of these hedges on BioScope. In this paper, we present a system based on a cascade method for the CoNLL-2010 shared task. The system composes of two components: one for detecting hedges and another one for detecting their scope. For detecting hedges, we build a cascade subsystem. Firstly, conditional random field (CRF) model and a large margin-based model are trained respectively. Then, we train anothe</context>
</contexts>
<marker>Ganter, Strube, 2009</marker>
<rawString>Viola Ganter and Michael Strube. 2009. Finding hedges by chasing weasels: Hedge detection using wikipedia tags and shallow linguistic features. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 173–176, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1961" citStr="Morante and Daelemans, 2009" startWordPosition="297" endWordPosition="300">mmon in natural language text. Vincze et al. (2008) report that 17.70% of the sentences in the abstract section and 19.94% of sentences in the full paper section contain hedges on BioScope corpus. As Vincze et al. (2008) suggest that information that falls in the scope of hedges can not be presented as factual information. Detecting hedges and their scope in natural language text is very important for information inference. Recently, relative research has received considerable interest in the biomedical NLP community, including detecting hedges and their in-sentence scope in biomedical texts (Morante and Daelemans, 2009). The CoNLL2010 has launched a shared task for exploiting the hedge scope annotated in the BioScope (Vincze et al., 2008) and publicly available Wikipedia (Ganter and Strube, 2009) weasel annotations. The shared task contains two subtasks (Farkas et al., 2010): 1. learning to detect hedges in sentences on BioScope and Wikipedia; 2. learning to detect the in-sentence scope of these hedges on BioScope. In this paper, we present a system based on a cascade method for the CoNLL-2010 shared task. The system composes of two components: one for detecting hedges and another one for detecting their sco</context>
<context position="6157" citStr="Morante and Daelemans (2009)" startWordPosition="1035" endWordPosition="1038">ssible case: these features are extracted according to a dictionary extracted from training corpus, which lists all possible hedge tag for each word in the training corpus. In the second layer, we used some features about the result of the last layer besides those mentioned above. They are listed as follow: • The lemma and POS sequences of the hedge predicted by each classifier. • The times of a token classified into B cue, I cue and O cue by the first two classifiers. • Whether a token is the last token of the hedge predicted by each classifier. 2.2 Hedge Scope Detection We follow the way of Morante and Daelemans (2009) to represent the scope of a hedge, where F scope indicates a token at the beginning of a scope sequence, L scope indicates a token at the last of a scope sequence, and NONE indicates others. In this phase, we do preprocessing by GDep Tagger (version beta1)2 at first, which does lemma extraction, part-of-speech (POS), chunking, named entity recognition (NER) and dependency parse for feature extraction. For the output of GDep Tagger, we deal with the lemma and chunk tag using the same way mentioned in the last section. Then, a CRF classifier is built for prediction, which uses the following fea</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the BioNLP 2009 Workshop, pages 28– 36, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tzong-Han Tsai</author>
<author>Chia-Wei Wu</author>
<author>Wen-Lian Hsu</author>
</authors>
<title>Using Maximum Entropy to Extract Biomedical Named Entities without Dictionaries.</title>
<date>2005</date>
<booktitle>In Second International Joint Conference on Natural Language Processing,</booktitle>
<pages>268--273</pages>
<contexts>
<context position="4919" citStr="Tsai et al., 2005" startWordPosition="801" endWordPosition="804"> Tagger, we convert the first char of a lemma into lower case and BIO chunk tag into BIOS chunk tag, where S indicates a token is a chunk, B indicates a token at the beginning of a chunk, I indicates a token inside of a chunk, and O indicates a token outside of a chunk. Then a two-layer cascaded classifier is built for prediction. There are a CRF classifier and a large margin-based classifier in the first layer and a CRF classifier in the second layer. In the first layer, the following features are used in our system: • Word and Word Shape of the lemma: we used the similar scheme as shown in (Tsai et al., 2005). 1http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/ • Prefix and Suffix with length 3-5. • Context of the lemma, POS and the chunk in the window [-2,2]. • Combined features including LoCo, LiP0 and LiC0, where −1 G i G 1 L denotes the lemma of a word, P denotes a POS and C denotes a chunk tag. • The type of a chunk; the lemma and POS sequences of it. • Whether a token is a part of the pairs ”neither ... nor” and ”either ... or” as both tokens of a pair are always labeled with the same tag. • Whether a token can possibly be classified into B cue, I cue or O cue; its lemma, POS and chunk tag f</context>
</contexts>
<marker>Tsai, Wu, Hsu, 2005</marker>
<rawString>Tzong-Han Tsai, Chia-Wei Wu, and Wen-Lian Hsu. 2005. Using Maximum Entropy to Extract Biomedical Named Entities without Dictionaries. In Second International Joint Conference on Natural Language Processing, pages 268–273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gy¨orgy Szarvas</author>
<author>Rich´ard Farkas</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<marker>Vincze, Szarvas, Farkas, M´ora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas, Gy¨orgy M´ora, and J´anos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>