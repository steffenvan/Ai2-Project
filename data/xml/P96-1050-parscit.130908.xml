<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.132607">
<title confidence="0.997623">
A Synopsis of Learning to Recognize Names Across Languages
</title>
<author confidence="0.98674">
Anthony F. Gallippi
</author>
<affiliation confidence="0.998869">
University of Southern California
</affiliation>
<address confidence="0.936890666666667">
University Park, EEB 234
Los Angeles, CA 90089
USA
</address>
<email confidence="0.998649">
gallippi@aludra.usc.edu
</email>
<sectionHeader confidence="0.993877" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999562454545455">
The development of natural language processing (NLP)
systems that perform machine translation (MT) and
information retrieval (IR) has highlighted the need for
the automatic recognition of proper names. While vari-
ous name recognizers have been developed, they suffer
from being too limited; some only recognize one name
class, and all are language specific. This work devel-
ops an approach to multilingual name recognition that
uses machine learning and a portable framework to
simplify the porting task by maximizing reuse and au-
tomation.
</bodyText>
<sectionHeader confidence="0.998802" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931043478261">
Proper names represent a unique challenge for MT and
IR systems. They are not found in dictionaries, are
very large in number, come and go every day, and ap-
pear in many alias forms. For these reasons, list based
matching schemes do not achieve desired performance
levels. Hand coded heuristics can be developed to
achieve high accuracy, however this approach lacks
portability. Much human effort is needed to port the
system to a new domain.
A desirable approach is one that maximizes reuse
and minimizes human effort. This paper presents an
approach to proper name recognition that uses machine
learning and a language independent framework.
Knowledge incorporated into the framework is based
on a set of measurable linguistic characteristics, or fea-
tures. Some of this knowledge is constant across lan-
guages. The rest can be generated automatically
through machine learning techniques.
Whether a phrase (or word) is a proper name, and
what type of proper name it is (company name, loca-
tion name, person name, date, other) depends on (1) the
internal structure of the phrase, and (2) the surrounding
context.
</bodyText>
<sectionHeader confidence="0.656193" genericHeader="method">
Internal: &amp;quot;Mr. Brandon&amp;quot;
</sectionHeader>
<bodyText confidence="0.889134809523809">
Context: &amp;quot;The new company. Safetek, will make
air bags.&amp;quot;
The person title &amp;quot;Mr.&amp;quot; reliably shows &amp;quot;Mr. Brandon&amp;quot; to
be a person name. &amp;quot;Safetek&amp;quot; can be recognized as a
company name by utilizing the preceding contextual
phrase and appositive &amp;quot;The new company,&amp;quot;.
The recognition task can be broken down into de-
limitation and classification. Delimitation is the de-
termination of the boundaries of the proper name,
while classification serves to provide a more specific
category.
Original: John Smith , chairman of Safetek, announced
his resignation yesterday.
Delimit: &lt;PN&gt; John Smith &lt;/PN&gt; , chairman of &lt;PN&gt;
Safetek &lt;/PN&gt; , announced his resignation
yesterday.
Classify: &lt;person&gt; John Smith &lt;/person&gt; , chairman of
&lt;company&gt; Safetek &lt;/company&gt; , announced
his resignation yesterday.
During the delimit step, proper name boundaries are
identified. Next, the delimited names are categorized.
</bodyText>
<sectionHeader confidence="0.953046" genericHeader="method">
2 Method
</sectionHeader>
<bodyText confidence="0.991033578947368">
The approach taken here is to utilize a data-driven
knowledge acquisition strategy based on decision trees
which uses contextual information. This differs from
other approaches (Farwell et al., 1994; Kitani &amp; Mita-
mura, 1994; McDonald, 1993; Rau, 1992) which
attempt to achieve this task by: (1) hand-coded heuris-
tics, (2) list-based matching schemes, (3) human-gen-
erated knowledge bases, and (4) combinations thereof.
Delimitation occurs through the application of
phrasal templates. These templates, built by hand, use
logical operators (AND, OR, etc.) to combine features
strongly associated with proper names, including:
proper noun, ampersand, hyphen, and comma. In addi-
tion, ambiguities with delimitation are handled by in-
cluding other predictive features within the templates.
To acquire the knowledge required for classifica-
tion, each word is tagged with all of its associated fea-
tures. Various types of features indicate the type of
name: parts of speech (POS), designators,
</bodyText>
<page confidence="0.994345">
357
</page>
<figureCaption confidence="0.999267">
Figure 1. Multilingual development system.
</figureCaption>
<figure confidence="0.997875909090909">
Attach
features
Decision
tree
Generate
tree
(English
feature set)--Pi.
Pre-lagged
train text
Transiala
(correct) e ct
Tokenize
Tag P05
Delimit
PNs
&amp; dates
Score d&apos;\
result
( New &gt;
features
Score
</figure>
<bodyText confidence="0.9987323125">
morphology, syntax, semantics, and more. Designators
are features which alone provide strong evidence for or
against a particular name type. Examples include
&amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot;
(location).
Features are derived through automated and manual
techniques. On-line lists can quickly provide useful
features such as cities, family names, nationalities, etc.
Proven POS taggers (Farwell et al., 1994; Brill, 1992;
Matsumoto et al., 1992) predetermine POS features.
Other features are derived through statistical measures
and hand analysis.
A decision tree is built (for each name class) from
the initial feature set using a recursive partitioning al-
gorithm (Quinlan, 1986; Breiman et al., 1984) that uses
the following function as its splitting criterion:
</bodyText>
<equation confidence="0.990881">
-p*log2(p) - (1-p)*log2(1-p) (1)
</equation>
<bodyText confidence="0.999876476190476">
where p represents the proportion of names within a
tree node belonging to the class for which the tree is
built. The feature which minimizes the weighted sum
of this function across both child nodes resulting from
a split is chosen. A multitree approach was chosen
over learning a single tree for all name classes because
it allows for the straightforward association of features
within the tree with specific name classes, and facili-
tates troubleshooting. Once built, the trees are all ap-
plied individually, and then the results are merged.
Trees typically contained 100 or more nodes.
In order to work with another language, the follow-
ing resources are needed: (1) pre-tagged training text
in the new language using same tags as before, (2) a
tokenizer for non-token languages, (3) a POS tagger
(plus translation of the tags to a standard POS conven-
tion), and (4) translation of designators and lexical
(list-based) features.
Figure 1 shows the working development system.
The starting point is training text which has been pre-
tagged with the locations of all proper names. The tok-
enizer separates punctuation from words. For non-to-
ken languages (no spaces between words), it also sepa-
rates contiguous characters into constituent words. The
POS tagger (Brill, 1992; Farwell et. al., 1994; Matsu-
moto et al, 1992) attaches parts of speech. The set of
derived features is attached. Names are delimited
using a set of POS based hand-coded templates. A de-
cision tree is built based on the existing feature set and
the specified level of context to be considered. The
generated tree is applied to test data and scored. Hand
analysis of results leads to the discovery of new fea-
tures. The new features are added to the tokenized
training text, and the process repeats.
Language-specific modules are highlighted with
bold borders. Feature translation occurs through the
utilization of: on-line resources, dictionaries, atlases,
bilingual speakers, etc. The remainder is constant
across languages: a language independent core, and an
optimally derived feature set for English. Parts of the
development system that are executed by hand appear
shaded. Everything else is automatic.
</bodyText>
<sectionHeader confidence="0.999111" genericHeader="evaluation">
3 Experiment
</sectionHeader>
<bodyText confidence="0.999944">
The system was first built for English and then ported
to Spanish and Japanese. For English, the training text
consisted of 50 messages obtained from the English
Joint Ventures (E.IV) domain MUC-5 corpus of the US
Advanced Research Projects Agency (ARPA). This
data was hand-tagged with the locations of companies,
persons, locations, dates, and &amp;quot;other&amp;quot;. The test set con-
sisted of 10 new messages from the same corpus.
Experimental results were obtained by applying the
generated trees to test texts. Proper names which are
voted into more than one class are handled by choosing
the highest priority class. Priorities are determined
based on the independent accuracy of each tree. The
metrics used were recall (R), precision (P), and an
averaging measure, P&amp;R, defined as:
</bodyText>
<equation confidence="0.73701">
P&amp;R = 2*P*R/(P+R) (2)
</equation>
<bodyText confidence="0.8464155">
Obtained results for English compare to the English re-
sults of Rau (1992) and McDonald (1993). The
</bodyText>
<page confidence="0.996755">
358
</page>
<bodyText confidence="0.99980140625">
weighted average of P&amp;R for companies, persons, lo-
cations, and dates is 94.0% (see Table 2).
The date grammar is rather small in comparison to
other name classes, hence the performance for dates
was perfect. Locations, by contrast, exhibited the low-
est performance. This can be attributed mainly to: (1)
locations are commonly associated with commas,
which can create ambiguities with delimitation, and (2)
locations made up a small percentage of all names in
the training set, which could have resulted in overfit-
ting of the built tree to the training data.
Three experiments were conducted for Spanish.
First, the English trees, generated from the feature set
optimized for English, are applied to the Spanish text
(E-E-S). In the second experiment, new Spanish-
specific trees are generated from the feature set
optimized for English and applied to the Spanish test
text (S-E-S). The third experiment proceeds like the
second, except that minor adjustments and additions
are made to the feature set with the goal of improving
performance (S-S-S).
The additional resources required for the first
Spanish experiment (E-E-S) are a Spanish POS tagger
(Farwell et aL, 1994) and also the translated feature set
(including POS) optimally derived for English. The
second and third Spanish experiments (S-E-S, S-S-S)
require in addition pre-tagged Spanish training text us-
ing the same tags as for English.
The additional features derived for S-S-S are shown
in Table 1 (FN/LN=given/farnily name, NNP=proper
noun, DE=&amp;quot;de&amp;quot;). Only a few new features allows for
significant performance improvement.
</bodyText>
<tableCaption confidence="0.999227">
Table 1. Spanish specific features for S-S-S.
</tableCaption>
<table confidence="0.988131428571429">
Type Feature Instances How many
List Companies &amp;quot;IBM&amp;quot;, &amp;quot;AT&amp;T&amp;quot;,... 100
Keyword &amp;quot;del&amp;quot; (OF THE) 1
Template Person &lt; FN DE LN &gt; 1
Person &lt; FN DE NNP &gt; 1
Date &lt; Num OF MM &gt; 1
Date &lt; Num OF MM OF Num &gt; 1
</table>
<bodyText confidence="0.99970625">
The same three experiments are being conducted
for Japanese. The first two, E-E-J and J-E-J, have been
completed; J-J-J is in progress. Table 2 summarizes
performance results and compares them to other work.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998897833333333">
The author would like to offer special thanks and grati-
tude to Eduard Hovy for all of his support, direction,
and encouragement from the onset of this work.
Thanks also to Kevin Knight for his early suggestions,
and to the Information Sciences Institute for use of
their facilities and resources.
</bodyText>
<tableCaption confidence="0.999008">
Table 2. Performance comparison to other work.
</tableCaption>
<table confidence="0.99960024">
System Language Class R P P&amp;R
Rau English Com NA 95 NA
PNF English Corn NA NA &amp;quot;Near
(McDonald) Pers 100%&amp;quot;
Loc
Date
Panglyzer Spanish NA NA 80 NA
MAJESTY Japanese Corn 84.3 81.4 82.8
Pers 93.1 98.6 95.8
Loc 92.6 96.8 94.7
MNR English Corn 97.6 91.6 94.5
(Gallippi) Pers 98.2 100 99.1
Loc 85.7 91.7 88.6
Date 100 100 100
(Avg) 94.0
MNR Spanish Corn 74.1 90.9 81.6
Pers 97.4 79.2 87.4
Loc 93.1 87.5 89.4
Date 100 100 100
(Avg) 89.2
MNR Japanese Corn 60.0 60.0 60.0
Pers 86.5 84.9 85.7
Loc 80.4 82.1 81.3
Date 90.0 94.7 92.3
(Avg) 83.1
</table>
<sectionHeader confidence="0.995978" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999796535714286">
Breiman, L., Friedman, J.H., Olshen, R.A., and Stone,
CJ. 1984. Classification and Regression Trees.
Wadsworth International Group.
Brill, E. 1992. A Simple Rule-Based Part of
Speech Tagger. In Proceedings of the Third
Conference on Applied Natural Language Processing,
ACL.
Farwell, D., Helmreich, S., Jin, W., Casper, M.,
Hargrave, J., Molina-Salgado, H., and Weng, F. 1994.
Panglyzer: Spanish Language Analysis System. In
Proceedings of the Conference of the Association of
Machine Translation in the Americas (ATMA).
Columbia, MD.
Kitani, T. and Mitamura, T. 1994. An Accurate
Morphological Analysis and Proper Name
Identification for Japanese Text Processing. In
Transactions of Information Processing Society of
Japan, Vol. 35, No. 3, pp. 404-413.
Matsumoto, Y., Kurohashi, S., Taegi, H. and
Nagao, M. 1992. JUMAN Users&apos; Manual Version 0.8,
Nagao Laboratory, Kyoto University.
McDonald, D. 1993. Internal and External
Evidence in the Identification and Semantic
Categorization of Proper Names. In Proceedings of the
SINGLEX workshop on &amp;quot;Acquisition of Lexical
Knowledge from Text&amp;quot;, pp. 32-43.
Quinlan, J.R. 1986. Induction of Decision Trees.
In Machine Learning, pp. 81-106.
</reference>
<page confidence="0.999076">
359
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.718241">
<title confidence="0.999889">A Synopsis of Learning to Recognize Names Across Languages</title>
<author confidence="0.999948">Anthony F Gallippi</author>
<affiliation confidence="0.999938">University of Southern California</affiliation>
<address confidence="0.997197">University Park, EEB 234 Los Angeles, CA 90089 USA</address>
<email confidence="0.999875">gallippi@aludra.usc.edu</email>
<abstract confidence="0.976887833333333">The development of natural language processing (NLP) systems that perform machine translation (MT) and information retrieval (IR) has highlighted the need for the automatic recognition of proper names. While various name recognizers have been developed, they suffer from being too limited; some only recognize one name class, and all are language specific. This work develops an approach to multilingual name recognition that uses machine learning and a portable framework to simplify the porting task by maximizing reuse and automation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Breiman</author>
<author>J H Friedman</author>
<author>R A Olshen</author>
<author>CJ Stone</author>
</authors>
<title>Classification and Regression Trees.</title>
<date>1984</date>
<publisher>Wadsworth International Group.</publisher>
<contexts>
<context position="4715" citStr="Breiman et al., 1984" startWordPosition="711" endWordPosition="714"> evidence for or against a particular name type. Examples include &amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot; (location). Features are derived through automated and manual techniques. On-line lists can quickly provide useful features such as cities, family names, nationalities, etc. Proven POS taggers (Farwell et al., 1994; Brill, 1992; Matsumoto et al., 1992) predetermine POS features. Other features are derived through statistical measures and hand analysis. A decision tree is built (for each name class) from the initial feature set using a recursive partitioning algorithm (Quinlan, 1986; Breiman et al., 1984) that uses the following function as its splitting criterion: -p*log2(p) - (1-p)*log2(1-p) (1) where p represents the proportion of names within a tree node belonging to the class for which the tree is built. The feature which minimizes the weighted sum of this function across both child nodes resulting from a split is chosen. A multitree approach was chosen over learning a single tree for all name classes because it allows for the straightforward association of features within the tree with specific name classes, and facilitates troubleshooting. Once built, the trees are all applied individua</context>
</contexts>
<marker>Breiman, Friedman, Olshen, Stone, 1984</marker>
<rawString>Breiman, L., Friedman, J.H., Olshen, R.A., and Stone, CJ. 1984. Classification and Regression Trees. Wadsworth International Group.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A Simple Rule-Based Part of Speech Tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing,</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="4433" citStr="Brill, 1992" startWordPosition="670" endWordPosition="671"> Decision tree Generate tree (English feature set)--Pi. Pre-lagged train text Transiala (correct) e ct Tokenize Tag P05 Delimit PNs &amp; dates Score d&apos;\ result ( New &gt; features Score morphology, syntax, semantics, and more. Designators are features which alone provide strong evidence for or against a particular name type. Examples include &amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot; (location). Features are derived through automated and manual techniques. On-line lists can quickly provide useful features such as cities, family names, nationalities, etc. Proven POS taggers (Farwell et al., 1994; Brill, 1992; Matsumoto et al., 1992) predetermine POS features. Other features are derived through statistical measures and hand analysis. A decision tree is built (for each name class) from the initial feature set using a recursive partitioning algorithm (Quinlan, 1986; Breiman et al., 1984) that uses the following function as its splitting criterion: -p*log2(p) - (1-p)*log2(1-p) (1) where p represents the proportion of names within a tree node belonging to the class for which the tree is built. The feature which minimizes the weighted sum of this function across both child nodes resulting from a split </context>
<context position="6077" citStr="Brill, 1992" startWordPosition="933" endWordPosition="934">needed: (1) pre-tagged training text in the new language using same tags as before, (2) a tokenizer for non-token languages, (3) a POS tagger (plus translation of the tags to a standard POS convention), and (4) translation of designators and lexical (list-based) features. Figure 1 shows the working development system. The starting point is training text which has been pretagged with the locations of all proper names. The tokenizer separates punctuation from words. For non-token languages (no spaces between words), it also separates contiguous characters into constituent words. The POS tagger (Brill, 1992; Farwell et. al., 1994; Matsumoto et al, 1992) attaches parts of speech. The set of derived features is attached. Names are delimited using a set of POS based hand-coded templates. A decision tree is built based on the existing feature set and the specified level of context to be considered. The generated tree is applied to test data and scored. Hand analysis of results leads to the discovery of new features. The new features are added to the tokenized training text, and the process repeats. Language-specific modules are highlighted with bold borders. Feature translation occurs through the ut</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, E. 1992. A Simple Rule-Based Part of Speech Tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Farwell</author>
<author>S Helmreich</author>
<author>W Jin</author>
<author>M Casper</author>
<author>J Hargrave</author>
<author>H Molina-Salgado</author>
<author>F Weng</author>
</authors>
<title>Panglyzer: Spanish Language Analysis System.</title>
<date>1994</date>
<booktitle>In Proceedings of the Conference of the Association of Machine Translation in the Americas (ATMA).</booktitle>
<location>Columbia, MD.</location>
<contexts>
<context position="2975" citStr="Farwell et al., 1994" startWordPosition="454" endWordPosition="457">Original: John Smith , chairman of Safetek, announced his resignation yesterday. Delimit: &lt;PN&gt; John Smith &lt;/PN&gt; , chairman of &lt;PN&gt; Safetek &lt;/PN&gt; , announced his resignation yesterday. Classify: &lt;person&gt; John Smith &lt;/person&gt; , chairman of &lt;company&gt; Safetek &lt;/company&gt; , announced his resignation yesterday. During the delimit step, proper name boundaries are identified. Next, the delimited names are categorized. 2 Method The approach taken here is to utilize a data-driven knowledge acquisition strategy based on decision trees which uses contextual information. This differs from other approaches (Farwell et al., 1994; Kitani &amp; Mitamura, 1994; McDonald, 1993; Rau, 1992) which attempt to achieve this task by: (1) hand-coded heuristics, (2) list-based matching schemes, (3) human-generated knowledge bases, and (4) combinations thereof. Delimitation occurs through the application of phrasal templates. These templates, built by hand, use logical operators (AND, OR, etc.) to combine features strongly associated with proper names, including: proper noun, ampersand, hyphen, and comma. In addition, ambiguities with delimitation are handled by including other predictive features within the templates. To acquire the </context>
<context position="4420" citStr="Farwell et al., 1994" startWordPosition="666" endWordPosition="669">ystem. Attach features Decision tree Generate tree (English feature set)--Pi. Pre-lagged train text Transiala (correct) e ct Tokenize Tag P05 Delimit PNs &amp; dates Score d&apos;\ result ( New &gt; features Score morphology, syntax, semantics, and more. Designators are features which alone provide strong evidence for or against a particular name type. Examples include &amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot; (location). Features are derived through automated and manual techniques. On-line lists can quickly provide useful features such as cities, family names, nationalities, etc. Proven POS taggers (Farwell et al., 1994; Brill, 1992; Matsumoto et al., 1992) predetermine POS features. Other features are derived through statistical measures and hand analysis. A decision tree is built (for each name class) from the initial feature set using a recursive partitioning algorithm (Quinlan, 1986; Breiman et al., 1984) that uses the following function as its splitting criterion: -p*log2(p) - (1-p)*log2(1-p) (1) where p represents the proportion of names within a tree node belonging to the class for which the tree is built. The feature which minimizes the weighted sum of this function across both child nodes resulting </context>
</contexts>
<marker>Farwell, Helmreich, Jin, Casper, Hargrave, Molina-Salgado, Weng, 1994</marker>
<rawString>Farwell, D., Helmreich, S., Jin, W., Casper, M., Hargrave, J., Molina-Salgado, H., and Weng, F. 1994. Panglyzer: Spanish Language Analysis System. In Proceedings of the Conference of the Association of Machine Translation in the Americas (ATMA). Columbia, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kitani</author>
<author>T Mitamura</author>
</authors>
<title>An Accurate Morphological Analysis and Proper Name Identification for Japanese Text Processing.</title>
<date>1994</date>
<journal>In Transactions of Information Processing Society of Japan,</journal>
<volume>35</volume>
<pages>404--413</pages>
<contexts>
<context position="3000" citStr="Kitani &amp; Mitamura, 1994" startWordPosition="458" endWordPosition="462"> chairman of Safetek, announced his resignation yesterday. Delimit: &lt;PN&gt; John Smith &lt;/PN&gt; , chairman of &lt;PN&gt; Safetek &lt;/PN&gt; , announced his resignation yesterday. Classify: &lt;person&gt; John Smith &lt;/person&gt; , chairman of &lt;company&gt; Safetek &lt;/company&gt; , announced his resignation yesterday. During the delimit step, proper name boundaries are identified. Next, the delimited names are categorized. 2 Method The approach taken here is to utilize a data-driven knowledge acquisition strategy based on decision trees which uses contextual information. This differs from other approaches (Farwell et al., 1994; Kitani &amp; Mitamura, 1994; McDonald, 1993; Rau, 1992) which attempt to achieve this task by: (1) hand-coded heuristics, (2) list-based matching schemes, (3) human-generated knowledge bases, and (4) combinations thereof. Delimitation occurs through the application of phrasal templates. These templates, built by hand, use logical operators (AND, OR, etc.) to combine features strongly associated with proper names, including: proper noun, ampersand, hyphen, and comma. In addition, ambiguities with delimitation are handled by including other predictive features within the templates. To acquire the knowledge required for cl</context>
</contexts>
<marker>Kitani, Mitamura, 1994</marker>
<rawString>Kitani, T. and Mitamura, T. 1994. An Accurate Morphological Analysis and Proper Name Identification for Japanese Text Processing. In Transactions of Information Processing Society of Japan, Vol. 35, No. 3, pp. 404-413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>S Kurohashi</author>
<author>H Taegi</author>
<author>M Nagao</author>
</authors>
<date>1992</date>
<journal>JUMAN Users&apos; Manual Version</journal>
<volume>0</volume>
<institution>Nagao Laboratory, Kyoto University.</institution>
<contexts>
<context position="4458" citStr="Matsumoto et al., 1992" startWordPosition="672" endWordPosition="675">e Generate tree (English feature set)--Pi. Pre-lagged train text Transiala (correct) e ct Tokenize Tag P05 Delimit PNs &amp; dates Score d&apos;\ result ( New &gt; features Score morphology, syntax, semantics, and more. Designators are features which alone provide strong evidence for or against a particular name type. Examples include &amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot; (location). Features are derived through automated and manual techniques. On-line lists can quickly provide useful features such as cities, family names, nationalities, etc. Proven POS taggers (Farwell et al., 1994; Brill, 1992; Matsumoto et al., 1992) predetermine POS features. Other features are derived through statistical measures and hand analysis. A decision tree is built (for each name class) from the initial feature set using a recursive partitioning algorithm (Quinlan, 1986; Breiman et al., 1984) that uses the following function as its splitting criterion: -p*log2(p) - (1-p)*log2(1-p) (1) where p represents the proportion of names within a tree node belonging to the class for which the tree is built. The feature which minimizes the weighted sum of this function across both child nodes resulting from a split is chosen. A multitree ap</context>
<context position="6124" citStr="Matsumoto et al, 1992" startWordPosition="939" endWordPosition="943"> in the new language using same tags as before, (2) a tokenizer for non-token languages, (3) a POS tagger (plus translation of the tags to a standard POS convention), and (4) translation of designators and lexical (list-based) features. Figure 1 shows the working development system. The starting point is training text which has been pretagged with the locations of all proper names. The tokenizer separates punctuation from words. For non-token languages (no spaces between words), it also separates contiguous characters into constituent words. The POS tagger (Brill, 1992; Farwell et. al., 1994; Matsumoto et al, 1992) attaches parts of speech. The set of derived features is attached. Names are delimited using a set of POS based hand-coded templates. A decision tree is built based on the existing feature set and the specified level of context to be considered. The generated tree is applied to test data and scored. Hand analysis of results leads to the discovery of new features. The new features are added to the tokenized training text, and the process repeats. Language-specific modules are highlighted with bold borders. Feature translation occurs through the utilization of: on-line resources, dictionaries, </context>
</contexts>
<marker>Matsumoto, Kurohashi, Taegi, Nagao, 1992</marker>
<rawString>Matsumoto, Y., Kurohashi, S., Taegi, H. and Nagao, M. 1992. JUMAN Users&apos; Manual Version 0.8, Nagao Laboratory, Kyoto University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McDonald</author>
</authors>
<title>Internal and External Evidence in the Identification and Semantic Categorization of Proper Names.</title>
<date>1993</date>
<booktitle>In Proceedings of the SINGLEX workshop on &amp;quot;Acquisition of Lexical Knowledge from Text&amp;quot;,</booktitle>
<pages>32--43</pages>
<contexts>
<context position="3016" citStr="McDonald, 1993" startWordPosition="463" endWordPosition="464">ounced his resignation yesterday. Delimit: &lt;PN&gt; John Smith &lt;/PN&gt; , chairman of &lt;PN&gt; Safetek &lt;/PN&gt; , announced his resignation yesterday. Classify: &lt;person&gt; John Smith &lt;/person&gt; , chairman of &lt;company&gt; Safetek &lt;/company&gt; , announced his resignation yesterday. During the delimit step, proper name boundaries are identified. Next, the delimited names are categorized. 2 Method The approach taken here is to utilize a data-driven knowledge acquisition strategy based on decision trees which uses contextual information. This differs from other approaches (Farwell et al., 1994; Kitani &amp; Mitamura, 1994; McDonald, 1993; Rau, 1992) which attempt to achieve this task by: (1) hand-coded heuristics, (2) list-based matching schemes, (3) human-generated knowledge bases, and (4) combinations thereof. Delimitation occurs through the application of phrasal templates. These templates, built by hand, use logical operators (AND, OR, etc.) to combine features strongly associated with proper names, including: proper noun, ampersand, hyphen, and comma. In addition, ambiguities with delimitation are handled by including other predictive features within the templates. To acquire the knowledge required for classification, ea</context>
<context position="7885" citStr="McDonald (1993)" startWordPosition="1222" endWordPosition="1223">d-tagged with the locations of companies, persons, locations, dates, and &amp;quot;other&amp;quot;. The test set consisted of 10 new messages from the same corpus. Experimental results were obtained by applying the generated trees to test texts. Proper names which are voted into more than one class are handled by choosing the highest priority class. Priorities are determined based on the independent accuracy of each tree. The metrics used were recall (R), precision (P), and an averaging measure, P&amp;R, defined as: P&amp;R = 2*P*R/(P+R) (2) Obtained results for English compare to the English results of Rau (1992) and McDonald (1993). The 358 weighted average of P&amp;R for companies, persons, locations, and dates is 94.0% (see Table 2). The date grammar is rather small in comparison to other name classes, hence the performance for dates was perfect. Locations, by contrast, exhibited the lowest performance. This can be attributed mainly to: (1) locations are commonly associated with commas, which can create ambiguities with delimitation, and (2) locations made up a small percentage of all names in the training set, which could have resulted in overfitting of the built tree to the training data. Three experiments were conducte</context>
</contexts>
<marker>McDonald, 1993</marker>
<rawString>McDonald, D. 1993. Internal and External Evidence in the Identification and Semantic Categorization of Proper Names. In Proceedings of the SINGLEX workshop on &amp;quot;Acquisition of Lexical Knowledge from Text&amp;quot;, pp. 32-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>Induction of Decision Trees.</title>
<date>1986</date>
<booktitle>In Machine Learning,</booktitle>
<pages>81--106</pages>
<contexts>
<context position="4692" citStr="Quinlan, 1986" startWordPosition="709" endWordPosition="710"> provide strong evidence for or against a particular name type. Examples include &amp;quot;Co.&amp;quot; (company), &amp;quot;Dr.&amp;quot; (person), and &amp;quot;County&amp;quot; (location). Features are derived through automated and manual techniques. On-line lists can quickly provide useful features such as cities, family names, nationalities, etc. Proven POS taggers (Farwell et al., 1994; Brill, 1992; Matsumoto et al., 1992) predetermine POS features. Other features are derived through statistical measures and hand analysis. A decision tree is built (for each name class) from the initial feature set using a recursive partitioning algorithm (Quinlan, 1986; Breiman et al., 1984) that uses the following function as its splitting criterion: -p*log2(p) - (1-p)*log2(1-p) (1) where p represents the proportion of names within a tree node belonging to the class for which the tree is built. The feature which minimizes the weighted sum of this function across both child nodes resulting from a split is chosen. A multitree approach was chosen over learning a single tree for all name classes because it allows for the straightforward association of features within the tree with specific name classes, and facilitates troubleshooting. Once built, the trees ar</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>Quinlan, J.R. 1986. Induction of Decision Trees. In Machine Learning, pp. 81-106.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>