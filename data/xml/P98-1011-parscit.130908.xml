<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000466">
<title confidence="0.987413">
Evaluating a Focus-Based Approach to Anaphora Resolution*
</title>
<author confidence="0.99708">
Saliha Azzam, Kevin Humphreys and Robert Gaizauskas
</author>
<affiliation confidence="0.995061">
fs.azzam,k.humphreys,r.gaizauskaslOdcs.shef.ac.uk
Department of Computer Science, University of Sheffield
</affiliation>
<address confidence="0.786983">
Regent Court, Portobello Road
Sheffield Si 4DP UK
</address>
<sectionHeader confidence="0.929775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999854538461539">
We present an approach to anaphora resolution
based on a focusing algorithm, and implemented
within an existing MUC (Message Understand-
ing Conference) Information Extraction system,
allowing quantitative evaluation against a sub-
stantial corpus of annotated real-world texts.
Extensions to the basic focusing mechanism can
be easily tested, resulting in refinements to the
mechanism and resolution rules. Results show
that the focusing algorithm is highly sensitive
to the quality of syntactic-semantic analyses,
when compared to a simpler heuristic-based ap-
proach.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996342066666667">
Anaphora resolution is still present as a signi-
ficant linguistic problem, both theoretically and
practically, and interest has recently been re-
newed with the introduction of a quantitative
evaluation regime as part of the Message Under-
standing Conference (MUC) evaluations of In-
formation Extraction (IE) systems (Grishman
and Sundheim, 1996). This has made it pos-
sible to evaluate different (implementable) the-
oretical approaches against sizable corpora of
real-world texts, rather than the small collec-
tions of artificial examples typically discussed
in the literature.
This paper describes an evaluation of a focus-
based approach to pronoun resolution (not ana-
phora in general), based on an extension of
Sidner&apos;s algorithm (Sidner, 1981) proposed in
(Azzam, 1996), with further refinements from
development on real-world texts. The approach
This work was carried out in the context of the EU
AVENTINUS project (Thumair, 1996), which aims to
develop a multilingual IE system for drug enforcement,
and including a language-independent coreference mech-
anism (Azzam et al., 1998).
is implemented within the general coreference
mechanism provided by the LaSIE (Large Scale
Information Extraction) system (Gaizauskas et
al., 1995) and (Humphreys et al., 1998), Shef-
field University&apos;s entry in the MUC-6 and 7
evaluations.
</bodyText>
<sectionHeader confidence="0.981241" genericHeader="method">
2 Focus in Anaphora Resolution
</sectionHeader>
<bodyText confidence="0.999890103448276">
The term focus, along with its many relations
such as theme, topic, center, etc., reflects an in-
tuitive notion that utterances in discourse are
usually &apos;about&apos; something. This notion has been
put to use in accounts of numerous linguistic
phenomena, but it has rarely been given a firm
enough definition to allow its use to be evalu-
ated. For anaphora resolution, however, stem-
ming from Sidner&apos;s work, focus has been given
an algorithmic definition and a set of rules for its
application. Sidner&apos;s approach is based on the
claim that anaphora generally refer to the cur-
rent discourse focus, and so modelling changes
in focus through a discourse will allow the iden-
tification of antecedents.
The algorithm makes use of several focus re-
gisters to represent the current state of a dis-
course: CF, the current focus; AFL, the altern-
ate focus list, containing other candidate foci;
and FS, the focus stack. A parallel structure to
the CF, AF the actor focus, is also set to deal
with agentive pronouns. The algorithm updates
these registers after each sentence, confirming or
rejecting the current focus. A set of Interpret-
ation Rules (IRs) applies whenever an anaphor
is encountered, proposing potential antecedents
from the registers, from which one is chosen us-
ing other criteria: syntactic, semantic, inferen-
tial, etc.
</bodyText>
<page confidence="0.997196">
74
</page>
<subsectionHeader confidence="0.998845">
2.1 Evaluating Focus-Based Approaches
</subsectionHeader>
<bodyText confidence="0.999334090909091">
Sidner&apos;s algorithmic account, although not ex-
haustively specified, has lead to the implement-
ation of focus-based approaches to anaphora
resolution in several systems, e.g. PIE (Lin,
1995). However, evaluation of the approach has
mainly consisted of manual analyses of small
sets of problematic cases mentioned in the liter-
ature. Precise evaluation over sizable corpora of
real-world texts has only recently become pos-
sible, through the resources provided as part of
the MUC evaluations.
</bodyText>
<sectionHeader confidence="0.983773" genericHeader="method">
3 Coreference in LaSIE
</sectionHeader>
<bodyText confidence="0.999967361702128">
The LaSIE system (Gaizauskas et al., 1995)
and (Humphreys et al., 1998), has been de-
signed as a general purpose IE system which
can conform to the MUC task specifications for
named entity identification, coreference resolu-
tion, IE template element and relation identific-
ation, and the construction of scenario-specific
IE templates. The system is basically a pipeline
architecture consisting of tokenisation, sentence
splitting, part-of-speech tagging, morphological
stemming, list lookup, parsing with semantic in-
terpretation, proper name matching, and dis-
course interpretation. The latter stage con-
structs a discourse model, based on a predefined
domain model, using the, often partial, se-
mantic analyses supplied by the parser.
The domain model represents a hierarchy of
domain-relevant concept nodes, together with
associated properties. It is expressed in the XI
formalism (Gaizauskas, 1995) which provides a
basic inheritance mechanism for property values
and the ability to represent multiple classificat-
ory dimensions in the hierarchy. Instances of
concepts mentioned in a text are added to the
domain model, populating it to become a text-,
or discourse-, specific model.
Coreference resolution is carried out by at-
tempting to merge each newly added instance,
including pronouns, with instances already
present in the model. The basic mechanism
is to examine, for each new-old pair of in-
stances: semantic type consistency/similarity
in the concept hierarchy; attribute value con-
sistency/similarity, and a set of heuristic rules,
some specific to pronouns, which can act to rule
out a proposed merge. These rules can refer
to various lexical, syntactic, semantic, and po-
sitional information about instances. The in-
tegration of the focus-based approach replaces
the heuristic rules for pronouns, and represents
the use of LaSIE as an evaluation platform for
more theoretically motivated algorithms. It is
possible to extend the approach to include def-
inite NPs but, at present, the existing rules are
retained for non-pronominal anaphora in the
MUC coreference task: proper names, definite
noun phrases and bare nouns.
</bodyText>
<sectionHeader confidence="0.8167235" genericHeader="method">
4 Implementing Focus-Based
Pronoun Resolution in LaSIE
</sectionHeader>
<bodyText confidence="0.999988277777778">
Our implementation makes use of the algorithm
proposed in (Azzam, 1996), where elementary
events (EEs, effectively simple clauses) are used
as basic processing units, rather than sentences.
Updating the focus registers and the application
of interpretation rules (IRs) for pronoun resolu-
tion then takes place after each EE, permitting
intrasentential references.1 In addition, an ini-
tial &apos;expected focus&apos; is determined based on the
first EE in a text, providing a potential ante-
cedent for any pronoun within the first EE.
Development of the algorithm using real-
world texts resulted in various further refine-
ments to the algorithm, in both the IRs and the
rules for updating the focus registers. The fol-
lowing sections describe the two rules sets sep-
arately, though they are highly interrelated in
both development and processing.
</bodyText>
<subsectionHeader confidence="0.999509">
4.1 Updating the Focus
</subsectionHeader>
<bodyText confidence="0.996020578947368">
The algorithm includes two new focus registers,
in addition to those mentioned in section 2:
AFS, the actor focus stack, used to record pre-
vious AF (actor focus) values and so allow a
separate set of IRs for agent pronouns (animate
verb subjects); and Intra-AFL, the intrasenten-
tial alternate focus list, used to record candidate
foci from the current EE only.
In the space available here, the algorithm
is best described through an example showing
the use of the registers. This example is taken
from a New York Times article in the MUC-7
training corpus on aircraft crashes:
lAn important limitation of Sidner&apos;s algorithm, noted
in (Azzam, 1996), is that the focus registers are only
updated after each sentence. Thus antecedents proposed
for an anaphor in the current sentence will always be
from the previous sentence or before and intrasentential
references are impossible.
</bodyText>
<page confidence="0.994603">
75
</page>
<bodyText confidence="0.9681015">
State Police said witnesses told them the pro-
peller was not turning as the plane descended
quickly toward the highway in Wareham near
Exit 2. It hit a tree.
</bodyText>
<listItem confidence="0.582576">
EE-1: State Police said tell_event
</listItem>
<bodyText confidence="0.917614125">
An &apos;expected focus&apos; algorithm applies to
initialise the registers as follows:
CF (current focus) = tell_event
AF (actor focus) = State Police
Intra-AFL remains empty because EE-1
contains no other candidate foci. No other
registers are affected by the expected focus.
No pronouns occur in EE-1 and so no IRs apply.
</bodyText>
<equation confidence="0.4734015">
EE-2: witnesses told them
The Intra-AFL is first initialised with all
(non-pronominal) candidate foci in the EE:
Intra-AFL = witnesses
</equation>
<bodyText confidence="0.995472722222222">
The IRs are then applied to the first pronoun,
them, and, in this case, propose the current AF,
State Police, as the antecedent. The Intra-AFL
is immediately updated to add the antecedent:
Intra-AFL = State Police, witnesses
EE-2 has a pronoun in &apos;thematic&apos; position,
&apos;theme&apos; being either the object of a transitive
verb, or the subject of an intransitive or the
copula (following (Gruber, 1976)). Its ante-
cedent therefore becomes the new CF, with the
previous value moving to the FS. EE-2 has an
&apos;agent&apos;, where this is an animate verb subject
(again as in (Gruber, 1976)), and this becomes
the new AF. Because the old AF is now the
CF, it is not added to the AFS as it would
be otherwise. After each EE the Intra-AFL is
added to the current AFL, excluding the CF.
The state after EE-2 is then:
</bodyText>
<equation confidence="0.793998333333333">
CF = State Police AF = witnesses
FS = tell_event AFL = witnesses
EE-3: the propeller was not turning
</equation>
<bodyText confidence="0.9642905">
The Intra-AFL is reinitialised with candidate
foci from this EE:
</bodyText>
<equation confidence="0.857689">
Intra-AFL = propeller
</equation>
<bodyText confidence="0.9998622">
No pronouns occur in EE-3 and so no IRs
apply. The &apos;theme&apos;, propeller here because
of the copula, becomes the new CF and the
old one is added to the FS. The AF remains
unchanged as the current EE lacks an agent:
</bodyText>
<equation confidence="0.8871668">
CF = propeller
AF = witnesses
FS = State Police, tell_event
AFL = propeller, witnesses
EE-4: the plane descended
Intra-AFL = the plane
CF = the plane (theme)
AF = witnesses (unchanged)
FS = propeller, State Police, tell_event
AFL = the plane, propeller, witnesses
</equation>
<bodyText confidence="0.892411">
In the current algorithm the AFL is reset at
this point, because EE-4 ends the sentence.
</bodyText>
<equation confidence="0.832671142857143">
EE-5: it hit a tree
Intra-AFL = a tree
The IRs resolve the pronoun it with the CF:
CF = the plane (unchanged)
AF = witnesses (unchanged)
FS = propeller, State Police, tell_event
AFL = a tree
</equation>
<subsectionHeader confidence="0.91931">
4.2 Interpretation Rules
</subsectionHeader>
<bodyText confidence="0.998559947368421">
Pronouns are divided into three classes, each
with a distinct set of IRs proposing antecedents:
Personal pronouns acting as agents (an-
imate subjects): (e.g. he in Shotz said he
knew the pilots) AF proposed initially, then an-
imate members of AFL.
Non-agent pronouns: (e.g. them in EE-2
above and it in EE-5) CF proposed initially,
then members of the AFL and FS.
Possessive, reciprocal and reflexive pro-
nouns (PRRs): (e.g. their in the brothers
had left and were on their way home) Ante-
cedents proposed from the Intra-AFL, allowing
intra-EE references.
Antecedents proposed by the IRs are accep-
ted or rejected based on their semantic type and
feature compatibility, using the semantic and
attribute value similarity scores of LaSIE&apos;s ex-
isting coreference mechanism.
</bodyText>
<sectionHeader confidence="0.660919" genericHeader="method">
5 Evaluation with the MUC Corpora
</sectionHeader>
<bodyText confidence="0.9998619">
As part of MUC (Grishman and Sundheim,
1996), coreference resolution was evaluated as
a sub-task of information extraction, which in-
volved negotiating a definition of coreference re-
lations that could be reliably evaluated. The fi-
nal definition included only &apos;identity&apos; relations
between text strings: proper nouns, common
nouns and pronouns. Other possible corefer-
ence relations, such as &apos;part-whole&apos;, and non-
text strings (zero anaphora) were excluded.
</bodyText>
<page confidence="0.964657">
76
</page>
<bodyText confidence="0.999907157894737">
The definition was used to manually annot-
ate several corpora of newswire texts, using
SGML markup to indicate relations between
text strings. Automatically annotated texts,
produced by systems using the same markup
scheme, were then compared with the manually
annotated versions, using scoring software made
available to MUC participants, based on (Vilain
et al., 1995).
The scoring software calculates the stand-
ard Information Retrieval metrics of &apos;recall&apos; and
`precision&apos;,2 together with an overall f -measure.
The following section presents the results ob-
tained using the corpora and scorer provided
for MUC-7 training (60 texts, average 581 words
per text, 19 words per sentence) and evaluation
(20 texts, average 605 words per text, 20 words
per sentence), the latter provided for the formal
MUC-7 run and kept blind during development.
</bodyText>
<sectionHeader confidence="0.999783" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.998066666666667">
The MUC scorer does not distinguish between
different classes of anaphora (pronouns, definite
noun phrases, bare nouns, and proper nouns),
but baseline figures can be established by run-
ning the LaSIE system with no attempt made
to resolve any pronouns:
</bodyText>
<table confidence="0.611371">
Corpus Recall Precision f
Training: 42.4% 73.67. 52.6%
Evaluation: 44.77. 73.9% 55.7%
</table>
<bodyText confidence="0.741371333333333">
LaSIE with the simple pronoun resolution
heuristics of the non-focus-based mechanism
achieves the following:
</bodyText>
<table confidence="0.807001666666667">
Corpus Recall Precision
Training: 58.2% 71.37. 64.17.
Evaluation: 56.0% 70 . 2% 62.3%
</table>
<bodyText confidence="0.9458515">
showing that more than three quarters of the
estimated 20% of pronoun coreferences in the
corpora are correctly resolved with only a minor
loss of precision.
LaSIE with the focus-based algorithm
achieves the following:
</bodyText>
<footnote confidence="0.998012">
2Recall is a measure of how many correct (i.e. manu-
ally annotated) coreferences a system found, and preci-
sion is a measure of how many coreferences that the sys-
tem proposed were actually correct. For example, with
100 manually annotated coreference relations in a corpus
and a system that proposes 75, of which 50 are correct,
recall is then 50/100 or 50% and precision is 50/75 or
66.7%.
</footnote>
<table confidence="0.974963666666667">
Corpus Recall Precision
Training: 55.4% 70.3% 61.97.
Evaluation: 53.3% 69.7% 60.4%
</table>
<bodyText confidence="0.99992355319149">
which, while demonstrating that the focus-
based algorithm is applicable to real-world text,
does question whether the more complex al-
gorithm has any real advantage over LaSIE&apos;s
original simple approach.
The lower performance of the focus-based al-
gorithm is mainly due to an increased reliance
on the accuracy and completeness of the gram-
matical structure identified by the parser. For
example, the resolution of a pronoun will be
skipped altogether if its role as a verb argu-
ment is missed by the parser. Partial parses
will also affect the identification of EE bound-
aries, on which the focus update rules depend.
For example, if the parser fails to attach a pre-
positional phrase containing an antecedent, it
will then be missed from the focus registers and
so the IRs (see (Azzam, 1995)). The simple
LaSIE approach, however, will be unaffected in
this case.
Recall is also lost due to the more restricted
proposal of candidate antecedents in the focus-
based approach. The simple LaSIE approach
proposes antecedents from each preceding para-
graph until one is accepted, while the focus-
based approach suggests a single fixed set.
From a theoretical point of view, many
interesting issues appear with a large set of
examples, discussed here only briefly because
of lack of space. Firstly, the fundamental
assumption of the focus-based approach, that
the focus is favoured as an antecedent, does
not always apply. For example:
In June, a few weeks before the crash of
TWA Flight 800, leaders of several Middle
Eastern terrorist organizations met in Te-
heran to plan terrorist acts. Among them
was the PFL of Palestine, an organization that
has been linked to airplane bombings in the past.
Here, the pronoun them corefers with organiz-
ations rather than the focus leaders. Additional
information will be required to override the fun-
damental assumption.
Another significant question is when sentence
focus changes. In our algorithm, focus changes
when there is no reference (pronominal or
otherwise) to the current focus in the current
</bodyText>
<page confidence="0.994983">
77
</page>
<bodyText confidence="0.999598461538462">
EE. In the example used in section 4.1, this
causes the focus at the end of the first sentence
to be that of the last EE in that sentence,
thus allowing the pronoun it in the subsequent
sentence to be correctly resolved with the plane.
However in the example below, the focus of
the first EE (the writ) is the antecedent of the
pronoun it in the subsequent sentence, rather
than the focus from the last EE (the ...flight):
The writ is for &amp;quot;damages&amp;quot; of seven pas-
sengers who died when the Airbus A310 flight
crashed. It claims the deaths were caused by
negligence.
Updating focus after the complete sentence,
rather than each EE, would propose the cor-
rect antecedent in this case. However neither
strategy has a significant overall advantage in
our evaluations on the MUC corpora.
Another important factor is the priorities of
the Interpretation Rules. For example, when a
personal pronoun can corefer with both CF and
AF, IRs select the CF first in our algorithm.
However, this priority is not fixed, being based
only on the corpora used so far, which raises the
possibility of automatically acquiring IR prior-
ities through training on other corpora.
</bodyText>
<sectionHeader confidence="0.99564" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999935">
A focus-based approach to pronoun resolution
has been implemented within the LaSIE IE sys-
tem and evaluated on real-world texts. The res-
ults show no significant preformance increase
over a simpler heuristic-based approach. The
main limitation of the focus-based approach is
its reliance on a robust syntactic/semantic ana-
lysis to find the focus on which all the IRs
depend. Examining performance on the real-
world data also raises questions about the the-
oretical assumptions of focus-based approaches,
in particular whether focus is always a favoured
antecedent, or whether this depends, to some
extent, on discourse style.
Analysing the differences in the results of the
focus- and non-focus-based approaches, does
show that the focus-based rules are commonly
required when the simple syntactic and se-
mantic rules propose a set of equivalent ante-
cedents and can only select, say, the closest ar-
bitrarily. A combined approach is therefore sug-
gested, but whether this would be more effect-
ive than further refining the resolution rules of
the focus-based approach, or improving parse
results and adding more detailed semantic con-
straints, remains an open question.
</bodyText>
<sectionHeader confidence="0.99228" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999933681818182">
S. Azzam, K. Humphreys, and R. Gaizauskas.
1998. Coreference resolution in a multilin-
gual information extraction system. In Pro-
ceedings of the First Language Resources and
Evaluation Conference (LREC). Linguistic
Coreference Workshop.
S. Azzam. 1995. Anaphors, PPs and Disam-
biguation Process for conceptual analysis. In
Proceedings of 14th LICA]:
S. Azzam. 1996. Resolving anaphors in embed-
ded sentences. In Proceedings of 34th ACL.
R. Gaizauskas, T. Wakao, K Humphreys,
H. Cunningham, and Y. Wilks. 1995. De-
scription of the LaSIE system. In Pro-
ceedings of MUC-6, pages 207-220. Morgan
Kaufmann.
R. Gaizauskas. 1995. XI: A Knowledge
Representation Language Based on Cross-
Classification and Inheritance. Technical Re-
port CS-95-24, University of Sheffield.
R. Grishman and B. Sundheim. 1996. Mes-
sage Understanding Conference - 6: A brief
history. In Proceedings of 16th IJCAI, pages
466-471.
J.S. Gruber. 1976. Lexical structures in syntax
and semantics. North-Holland.
K. Humphreys, R. Gaizauskas, S. Azzam,
C. Huyck, B. Mitchell, H. Cunningham, and
Y. Wilks. 1998. Description of the LaSIE-II
system. In Proceedings of MUC-7. Forthcom-
ing.
D. Lin. 1995. Description of the PIE System. In
Proceedings of MUC-6, pages 113-126. Mor-
gan Kaufmann.
C. Sidner. 1981. Focusing for interpretation
of pronouns. American Journal of Computa-
tional Linguistics, 7:217-231.
G. Thurmair. 1996. AVENTINUS System Ar-
chitecture. AVENTINUS project report LE1-
2238.
M. Vilain, J. Burger, J. Aberdeen, D. Connolly,
and L. Hirschman. 1995. A model-theoretic
coreference scoring scheme. In Proceedings of
MUC-6, pages 45-52. Morgan Kaufmann.
</reference>
<page confidence="0.998827">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.411271">
<title confidence="0.998497">Evaluating a Focus-Based Approach to Anaphora Resolution*</title>
<author confidence="0.783251">Kevin Humphreys Gaizauskas Azzam</author>
<email confidence="0.993602">fs.azzam,k.humphreys,r.gaizauskaslOdcs.shef.ac.uk</email>
<affiliation confidence="0.994884">Department of Computer Science, University of Sheffield</affiliation>
<address confidence="0.882748">Regent Court, Portobello Road Sheffield Si 4DP UK</address>
<abstract confidence="0.976455928571428">We present an approach to anaphora resolution based on a focusing algorithm, and implemented within an existing MUC (Message Understanding Conference) Information Extraction system, allowing quantitative evaluation against a substantial corpus of annotated real-world texts. Extensions to the basic focusing mechanism can be easily tested, resulting in refinements to the mechanism and resolution rules. Results show that the focusing algorithm is highly sensitive to the quality of syntactic-semantic analyses, when compared to a simpler heuristic-based approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Azzam</author>
<author>K Humphreys</author>
<author>R Gaizauskas</author>
</authors>
<title>Coreference resolution in a multilingual information extraction system.</title>
<date>1998</date>
<booktitle>In Proceedings of the First Language Resources and Evaluation Conference (LREC). Linguistic Coreference Workshop.</booktitle>
<contexts>
<context position="1931" citStr="Azzam et al., 1998" startWordPosition="269" endWordPosition="272">real-world texts, rather than the small collections of artificial examples typically discussed in the literature. This paper describes an evaluation of a focusbased approach to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to develop a multilingual IE system for drug enforcement, and including a language-independent coreference mechanism (Azzam et al., 1998). is implemented within the general coreference mechanism provided by the LaSIE (Large Scale Information Extraction) system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), Sheffield University&apos;s entry in the MUC-6 and 7 evaluations. 2 Focus in Anaphora Resolution The term focus, along with its many relations such as theme, topic, center, etc., reflects an intuitive notion that utterances in discourse are usually &apos;about&apos; something. This notion has been put to use in accounts of numerous linguistic phenomena, but it has rarely been given a firm enough definition to allow its use to be ev</context>
</contexts>
<marker>Azzam, Humphreys, Gaizauskas, 1998</marker>
<rawString>S. Azzam, K. Humphreys, and R. Gaizauskas. 1998. Coreference resolution in a multilingual information extraction system. In Proceedings of the First Language Resources and Evaluation Conference (LREC). Linguistic Coreference Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Azzam</author>
</authors>
<title>Anaphors, PPs and Disambiguation Process for conceptual analysis.</title>
<date>1995</date>
<booktitle>In Proceedings of 14th LICA]:</booktitle>
<contexts>
<context position="14509" citStr="Azzam, 1995" startWordPosition="2286" endWordPosition="2287">s original simple approach. The lower performance of the focus-based algorithm is mainly due to an increased reliance on the accuracy and completeness of the grammatical structure identified by the parser. For example, the resolution of a pronoun will be skipped altogether if its role as a verb argument is missed by the parser. Partial parses will also affect the identification of EE boundaries, on which the focus update rules depend. For example, if the parser fails to attach a prepositional phrase containing an antecedent, it will then be missed from the focus registers and so the IRs (see (Azzam, 1995)). The simple LaSIE approach, however, will be unaffected in this case. Recall is also lost due to the more restricted proposal of candidate antecedents in the focusbased approach. The simple LaSIE approach proposes antecedents from each preceding paragraph until one is accepted, while the focusbased approach suggests a single fixed set. From a theoretical point of view, many interesting issues appear with a large set of examples, discussed here only briefly because of lack of space. Firstly, the fundamental assumption of the focus-based approach, that the focus is favoured as an antecedent, d</context>
</contexts>
<marker>Azzam, 1995</marker>
<rawString>S. Azzam. 1995. Anaphors, PPs and Disambiguation Process for conceptual analysis. In Proceedings of 14th LICA]:</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Azzam</author>
</authors>
<title>Resolving anaphors in embedded sentences.</title>
<date>1996</date>
<booktitle>In Proceedings of 34th ACL.</booktitle>
<contexts>
<context position="1619" citStr="Azzam, 1996" startWordPosition="224" endWordPosition="225">h the introduction of a quantitative evaluation regime as part of the Message Understanding Conference (MUC) evaluations of Information Extraction (IE) systems (Grishman and Sundheim, 1996). This has made it possible to evaluate different (implementable) theoretical approaches against sizable corpora of real-world texts, rather than the small collections of artificial examples typically discussed in the literature. This paper describes an evaluation of a focusbased approach to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to develop a multilingual IE system for drug enforcement, and including a language-independent coreference mechanism (Azzam et al., 1998). is implemented within the general coreference mechanism provided by the LaSIE (Large Scale Information Extraction) system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), Sheffield University&apos;s entry in the MUC-6 and 7 evaluations. 2 Focus in Anaphora Resolution The term focus, </context>
<context position="6321" citStr="Azzam, 1996" startWordPosition="946" endWordPosition="947">s lexical, syntactic, semantic, and positional information about instances. The integration of the focus-based approach replaces the heuristic rules for pronouns, and represents the use of LaSIE as an evaluation platform for more theoretically motivated algorithms. It is possible to extend the approach to include definite NPs but, at present, the existing rules are retained for non-pronominal anaphora in the MUC coreference task: proper names, definite noun phrases and bare nouns. 4 Implementing Focus-Based Pronoun Resolution in LaSIE Our implementation makes use of the algorithm proposed in (Azzam, 1996), where elementary events (EEs, effectively simple clauses) are used as basic processing units, rather than sentences. Updating the focus registers and the application of interpretation rules (IRs) for pronoun resolution then takes place after each EE, permitting intrasentential references.1 In addition, an initial &apos;expected focus&apos; is determined based on the first EE in a text, providing a potential antecedent for any pronoun within the first EE. Development of the algorithm using realworld texts resulted in various further refinements to the algorithm, in both the IRs and the rules for updati</context>
<context position="7750" citStr="Azzam, 1996" startWordPosition="1177" endWordPosition="1178">s registers, in addition to those mentioned in section 2: AFS, the actor focus stack, used to record previous AF (actor focus) values and so allow a separate set of IRs for agent pronouns (animate verb subjects); and Intra-AFL, the intrasentential alternate focus list, used to record candidate foci from the current EE only. In the space available here, the algorithm is best described through an example showing the use of the registers. This example is taken from a New York Times article in the MUC-7 training corpus on aircraft crashes: lAn important limitation of Sidner&apos;s algorithm, noted in (Azzam, 1996), is that the focus registers are only updated after each sentence. Thus antecedents proposed for an anaphor in the current sentence will always be from the previous sentence or before and intrasentential references are impossible. 75 State Police said witnesses told them the propeller was not turning as the plane descended quickly toward the highway in Wareham near Exit 2. It hit a tree. EE-1: State Police said tell_event An &apos;expected focus&apos; algorithm applies to initialise the registers as follows: CF (current focus) = tell_event AF (actor focus) = State Police Intra-AFL remains empty because</context>
</contexts>
<marker>Azzam, 1996</marker>
<rawString>S. Azzam. 1996. Resolving anaphors in embedded sentences. In Proceedings of 34th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>T Wakao</author>
<author>K Humphreys</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>Description of the LaSIE system.</title>
<date>1995</date>
<booktitle>In Proceedings of MUC-6,</booktitle>
<pages>207--220</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="2080" citStr="Gaizauskas et al., 1995" startWordPosition="289" endWordPosition="292">tion of a focusbased approach to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to develop a multilingual IE system for drug enforcement, and including a language-independent coreference mechanism (Azzam et al., 1998). is implemented within the general coreference mechanism provided by the LaSIE (Large Scale Information Extraction) system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), Sheffield University&apos;s entry in the MUC-6 and 7 evaluations. 2 Focus in Anaphora Resolution The term focus, along with its many relations such as theme, topic, center, etc., reflects an intuitive notion that utterances in discourse are usually &apos;about&apos; something. This notion has been put to use in accounts of numerous linguistic phenomena, but it has rarely been given a firm enough definition to allow its use to be evaluated. For anaphora resolution, however, stemming from Sidner&apos;s work, focus has been given an algorithmic definition and a set of rules for its app</context>
<context position="4111" citStr="Gaizauskas et al., 1995" startWordPosition="615" endWordPosition="618">c, semantic, inferential, etc. 74 2.1 Evaluating Focus-Based Approaches Sidner&apos;s algorithmic account, although not exhaustively specified, has lead to the implementation of focus-based approaches to anaphora resolution in several systems, e.g. PIE (Lin, 1995). However, evaluation of the approach has mainly consisted of manual analyses of small sets of problematic cases mentioned in the literature. Precise evaluation over sizable corpora of real-world texts has only recently become possible, through the resources provided as part of the MUC evaluations. 3 Coreference in LaSIE The LaSIE system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), has been designed as a general purpose IE system which can conform to the MUC task specifications for named entity identification, coreference resolution, IE template element and relation identification, and the construction of scenario-specific IE templates. The system is basically a pipeline architecture consisting of tokenisation, sentence splitting, part-of-speech tagging, morphological stemming, list lookup, parsing with semantic interpretation, proper name matching, and discourse interpretation. The latter stage constructs a discourse model, based on a pred</context>
</contexts>
<marker>Gaizauskas, Wakao, Humphreys, Cunningham, Wilks, 1995</marker>
<rawString>R. Gaizauskas, T. Wakao, K Humphreys, H. Cunningham, and Y. Wilks. 1995. Description of the LaSIE system. In Proceedings of MUC-6, pages 207-220. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
</authors>
<title>XI: A Knowledge Representation Language Based on CrossClassification and Inheritance.</title>
<date>1995</date>
<tech>Technical Report CS-95-24,</tech>
<institution>University of Sheffield.</institution>
<contexts>
<context position="4965" citStr="Gaizauskas, 1995" startWordPosition="739" endWordPosition="740">d the construction of scenario-specific IE templates. The system is basically a pipeline architecture consisting of tokenisation, sentence splitting, part-of-speech tagging, morphological stemming, list lookup, parsing with semantic interpretation, proper name matching, and discourse interpretation. The latter stage constructs a discourse model, based on a predefined domain model, using the, often partial, semantic analyses supplied by the parser. The domain model represents a hierarchy of domain-relevant concept nodes, together with associated properties. It is expressed in the XI formalism (Gaizauskas, 1995) which provides a basic inheritance mechanism for property values and the ability to represent multiple classificatory dimensions in the hierarchy. Instances of concepts mentioned in a text are added to the domain model, populating it to become a text-, or discourse-, specific model. Coreference resolution is carried out by attempting to merge each newly added instance, including pronouns, with instances already present in the model. The basic mechanism is to examine, for each new-old pair of instances: semantic type consistency/similarity in the concept hierarchy; attribute value consistency/</context>
</contexts>
<marker>Gaizauskas, 1995</marker>
<rawString>R. Gaizauskas. 1995. XI: A Knowledge Representation Language Based on CrossClassification and Inheritance. Technical Report CS-95-24, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>B Sundheim</author>
</authors>
<title>Message Understanding Conference - 6: A brief history.</title>
<date>1996</date>
<booktitle>In Proceedings of 16th IJCAI,</booktitle>
<pages>466--471</pages>
<contexts>
<context position="1196" citStr="Grishman and Sundheim, 1996" startWordPosition="158" endWordPosition="161">basic focusing mechanism can be easily tested, resulting in refinements to the mechanism and resolution rules. Results show that the focusing algorithm is highly sensitive to the quality of syntactic-semantic analyses, when compared to a simpler heuristic-based approach. 1 Introduction Anaphora resolution is still present as a significant linguistic problem, both theoretically and practically, and interest has recently been renewed with the introduction of a quantitative evaluation regime as part of the Message Understanding Conference (MUC) evaluations of Information Extraction (IE) systems (Grishman and Sundheim, 1996). This has made it possible to evaluate different (implementable) theoretical approaches against sizable corpora of real-world texts, rather than the small collections of artificial examples typically discussed in the literature. This paper describes an evaluation of a focusbased approach to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to</context>
<context position="11234" citStr="Grishman and Sundheim, 1996" startWordPosition="1770" endWordPosition="1773">, then animate members of AFL. Non-agent pronouns: (e.g. them in EE-2 above and it in EE-5) CF proposed initially, then members of the AFL and FS. Possessive, reciprocal and reflexive pronouns (PRRs): (e.g. their in the brothers had left and were on their way home) Antecedents proposed from the Intra-AFL, allowing intra-EE references. Antecedents proposed by the IRs are accepted or rejected based on their semantic type and feature compatibility, using the semantic and attribute value similarity scores of LaSIE&apos;s existing coreference mechanism. 5 Evaluation with the MUC Corpora As part of MUC (Grishman and Sundheim, 1996), coreference resolution was evaluated as a sub-task of information extraction, which involved negotiating a definition of coreference relations that could be reliably evaluated. The final definition included only &apos;identity&apos; relations between text strings: proper nouns, common nouns and pronouns. Other possible coreference relations, such as &apos;part-whole&apos;, and nontext strings (zero anaphora) were excluded. 76 The definition was used to manually annotate several corpora of newswire texts, using SGML markup to indicate relations between text strings. Automatically annotated texts, produced by sys</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>R. Grishman and B. Sundheim. 1996. Message Understanding Conference - 6: A brief history. In Proceedings of 16th IJCAI, pages 466-471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Gruber</author>
</authors>
<title>Lexical structures in syntax and semantics.</title>
<date>1976</date>
<publisher>North-Holland.</publisher>
<contexts>
<context position="9022" citStr="Gruber, 1976" startWordPosition="1383" endWordPosition="1384">are affected by the expected focus. No pronouns occur in EE-1 and so no IRs apply. EE-2: witnesses told them The Intra-AFL is first initialised with all (non-pronominal) candidate foci in the EE: Intra-AFL = witnesses The IRs are then applied to the first pronoun, them, and, in this case, propose the current AF, State Police, as the antecedent. The Intra-AFL is immediately updated to add the antecedent: Intra-AFL = State Police, witnesses EE-2 has a pronoun in &apos;thematic&apos; position, &apos;theme&apos; being either the object of a transitive verb, or the subject of an intransitive or the copula (following (Gruber, 1976)). Its antecedent therefore becomes the new CF, with the previous value moving to the FS. EE-2 has an &apos;agent&apos;, where this is an animate verb subject (again as in (Gruber, 1976)), and this becomes the new AF. Because the old AF is now the CF, it is not added to the AFS as it would be otherwise. After each EE the Intra-AFL is added to the current AFL, excluding the CF. The state after EE-2 is then: CF = State Police AF = witnesses FS = tell_event AFL = witnesses EE-3: the propeller was not turning The Intra-AFL is reinitialised with candidate foci from this EE: Intra-AFL = propeller No pronouns </context>
</contexts>
<marker>Gruber, 1976</marker>
<rawString>J.S. Gruber. 1976. Lexical structures in syntax and semantics. North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Humphreys</author>
<author>R Gaizauskas</author>
<author>S Azzam</author>
<author>C Huyck</author>
<author>B Mitchell</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>Description of the LaSIE-II system.</title>
<date>1998</date>
<booktitle>In Proceedings of MUC-7. Forthcoming.</booktitle>
<contexts>
<context position="2109" citStr="Humphreys et al., 1998" startWordPosition="294" endWordPosition="297">to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to develop a multilingual IE system for drug enforcement, and including a language-independent coreference mechanism (Azzam et al., 1998). is implemented within the general coreference mechanism provided by the LaSIE (Large Scale Information Extraction) system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), Sheffield University&apos;s entry in the MUC-6 and 7 evaluations. 2 Focus in Anaphora Resolution The term focus, along with its many relations such as theme, topic, center, etc., reflects an intuitive notion that utterances in discourse are usually &apos;about&apos; something. This notion has been put to use in accounts of numerous linguistic phenomena, but it has rarely been given a firm enough definition to allow its use to be evaluated. For anaphora resolution, however, stemming from Sidner&apos;s work, focus has been given an algorithmic definition and a set of rules for its application. Sidner&apos;s approach i</context>
<context position="4140" citStr="Humphreys et al., 1998" startWordPosition="620" endWordPosition="623"> 74 2.1 Evaluating Focus-Based Approaches Sidner&apos;s algorithmic account, although not exhaustively specified, has lead to the implementation of focus-based approaches to anaphora resolution in several systems, e.g. PIE (Lin, 1995). However, evaluation of the approach has mainly consisted of manual analyses of small sets of problematic cases mentioned in the literature. Precise evaluation over sizable corpora of real-world texts has only recently become possible, through the resources provided as part of the MUC evaluations. 3 Coreference in LaSIE The LaSIE system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), has been designed as a general purpose IE system which can conform to the MUC task specifications for named entity identification, coreference resolution, IE template element and relation identification, and the construction of scenario-specific IE templates. The system is basically a pipeline architecture consisting of tokenisation, sentence splitting, part-of-speech tagging, morphological stemming, list lookup, parsing with semantic interpretation, proper name matching, and discourse interpretation. The latter stage constructs a discourse model, based on a predefined domain model, using th</context>
</contexts>
<marker>Humphreys, Gaizauskas, Azzam, Huyck, Mitchell, Cunningham, Wilks, 1998</marker>
<rawString>K. Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell, H. Cunningham, and Y. Wilks. 1998. Description of the LaSIE-II system. In Proceedings of MUC-7. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Description of the PIE System. In</title>
<date>1995</date>
<booktitle>Proceedings of MUC-6,</booktitle>
<pages>113--126</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3746" citStr="Lin, 1995" startWordPosition="560" endWordPosition="561"> the actor focus, is also set to deal with agentive pronouns. The algorithm updates these registers after each sentence, confirming or rejecting the current focus. A set of Interpretation Rules (IRs) applies whenever an anaphor is encountered, proposing potential antecedents from the registers, from which one is chosen using other criteria: syntactic, semantic, inferential, etc. 74 2.1 Evaluating Focus-Based Approaches Sidner&apos;s algorithmic account, although not exhaustively specified, has lead to the implementation of focus-based approaches to anaphora resolution in several systems, e.g. PIE (Lin, 1995). However, evaluation of the approach has mainly consisted of manual analyses of small sets of problematic cases mentioned in the literature. Precise evaluation over sizable corpora of real-world texts has only recently become possible, through the resources provided as part of the MUC evaluations. 3 Coreference in LaSIE The LaSIE system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), has been designed as a general purpose IE system which can conform to the MUC task specifications for named entity identification, coreference resolution, IE template element and relation identification, </context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>D. Lin. 1995. Description of the PIE System. In Proceedings of MUC-6, pages 113-126. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sidner</author>
</authors>
<title>Focusing for interpretation of pronouns.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>7--217</pages>
<contexts>
<context position="1593" citStr="Sidner, 1981" startWordPosition="220" endWordPosition="221">s recently been renewed with the introduction of a quantitative evaluation regime as part of the Message Understanding Conference (MUC) evaluations of Information Extraction (IE) systems (Grishman and Sundheim, 1996). This has made it possible to evaluate different (implementable) theoretical approaches against sizable corpora of real-world texts, rather than the small collections of artificial examples typically discussed in the literature. This paper describes an evaluation of a focusbased approach to pronoun resolution (not anaphora in general), based on an extension of Sidner&apos;s algorithm (Sidner, 1981) proposed in (Azzam, 1996), with further refinements from development on real-world texts. The approach This work was carried out in the context of the EU AVENTINUS project (Thumair, 1996), which aims to develop a multilingual IE system for drug enforcement, and including a language-independent coreference mechanism (Azzam et al., 1998). is implemented within the general coreference mechanism provided by the LaSIE (Large Scale Information Extraction) system (Gaizauskas et al., 1995) and (Humphreys et al., 1998), Sheffield University&apos;s entry in the MUC-6 and 7 evaluations. 2 Focus in Anaphora R</context>
</contexts>
<marker>Sidner, 1981</marker>
<rawString>C. Sidner. 1981. Focusing for interpretation of pronouns. American Journal of Computational Linguistics, 7:217-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Thurmair</author>
</authors>
<date>1996</date>
<booktitle>AVENTINUS System Architecture. AVENTINUS project report</booktitle>
<pages>1--2238</pages>
<marker>Thurmair, 1996</marker>
<rawString>G. Thurmair. 1996. AVENTINUS System Architecture. AVENTINUS project report LE1-2238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>J Burger</author>
<author>J Aberdeen</author>
<author>D Connolly</author>
<author>L Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of MUC-6,</booktitle>
<pages>45--52</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="12015" citStr="Vilain et al., 1995" startWordPosition="1884" endWordPosition="1887">liably evaluated. The final definition included only &apos;identity&apos; relations between text strings: proper nouns, common nouns and pronouns. Other possible coreference relations, such as &apos;part-whole&apos;, and nontext strings (zero anaphora) were excluded. 76 The definition was used to manually annotate several corpora of newswire texts, using SGML markup to indicate relations between text strings. Automatically annotated texts, produced by systems using the same markup scheme, were then compared with the manually annotated versions, using scoring software made available to MUC participants, based on (Vilain et al., 1995). The scoring software calculates the standard Information Retrieval metrics of &apos;recall&apos; and `precision&apos;,2 together with an overall f -measure. The following section presents the results obtained using the corpora and scorer provided for MUC-7 training (60 texts, average 581 words per text, 19 words per sentence) and evaluation (20 texts, average 605 words per text, 20 words per sentence), the latter provided for the formal MUC-7 run and kept blind during development. 6 Results The MUC scorer does not distinguish between different classes of anaphora (pronouns, definite noun phrases, bare noun</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and L. Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of MUC-6, pages 45-52. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>