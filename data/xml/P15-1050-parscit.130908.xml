<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.981773">
Entity Retrieval via Entity Factoid Hierarchy∗
</title>
<author confidence="0.944268">
Chunliang Lu, Wai Lam, Yi Liao
</author>
<affiliation confidence="0.971522">
Key Laboratory of High Confidence Software Technologies
Ministry of Education (CUHK Sub-Lab)
Department of Systems Engineering and Engineering Management
The Chinese University of Hong Kong
</affiliation>
<email confidence="0.998603">
{cllu,wlam,yliao}@se.cuhk.edu.hk
</email>
<sectionHeader confidence="0.994795" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99991875">
We propose that entity queries are gener-
ated via a two-step process: users first se-
lect entity facts that can distinguish tar-
get entities from the others; and then
choose words to describe each selected
fact. Based on this query generation
paradigm, we propose a new entity rep-
resentation model named as entity fac-
toid hierarchy. An entity factoid hierar-
chy is a tree structure composed of fac-
toid nodes. A factoid node describes one
or more facts about the entity in different
information granularities. The entity fac-
toid hierarchy is constructed via a factor
graph model, and the inference on the fac-
tor graph is achieved by a modified variant
of Multiple-try Metropolis algorithm. En-
tity retrieval is performed by decompos-
ing entity queries and computing the query
likelihood on the entity factoid hierarchy.
Using an array of benchmark datasets, we
demonstrate that our proposed framework
significantly improves the retrieval perfor-
mance over existing models.
</bodyText>
<sectionHeader confidence="0.998884" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.942677181818182">
Entity retrieval, which aims at returning specific
entities to directly answer a user’s query, has
drawn much attention these years. Various entity
retrieval tasks have been proposed, such as TREC
Entity (Balog et al., 2012; Wang et al., 2011) and
INEX-LD (Wang et al., 2012; Wang and Kang,
2012). Many existing entity retrieval models fol-
low the document retrieval assumption: when is-
suing queries, users choose the words that may
∗ The work described in this paper is substantially sup-
ported by grants from the Research Grant Council of the
Hong Kong Special Administrative Region, China (Project
Codes: 413510 and 14203414) and the Direct Grant of the
Faculty of Engineering, CUHK (Project Code: 4055034).
appear in the “entity pseudo-document”. Based
on the assumption, these models construct in-
ternal entity representations by combining vari-
ous entity descriptions, and use these representa-
tions to compute the rank of the candidate enti-
ties for a given entity query. These models in-
clude fielded versions of BM25 and Mixture of
Language Models (Neumayer et al., 2012), Entity
Language Model (Raghavan et al., 2004), Hierar-
chical Expert Model (Petkova and Croft, 2006),
Structured Positional Entity Language Model (Lu
et al., 2013).
However, a closer examination of entity queries
reveals that most of them are not simple uniform
word samples from the “entity pseudo-document”.
Instead, they can be decomposed into multiple
parts, where each part describes a fact about target
entities. For example, the query “National capitals
situated on islands” describes two facts regarding
a target entity: it is a national capital; it is lo-
cated on an island. Compared to the assumption
in document retrieval models, where query terms
are assumed to be generated from a single docu-
ment, these query terms can be regarded to be in-
dependently generated from two underlying docu-
ments. According to this observation, we propose
that an entity query is generated via a two-step
process: users first select facts that can distinguish
target entities from the others; and then choose
words that describe the selected facts. Based on
the proposed query generation paradigm, we de-
sign a new entity retrieval framework. On one
hand, an entity is modeled to have multiple in-
ternal representations, each regarding one or more
closely related facts. On the other hand, an entity
query is decomposed into one or more subqueries,
each describing a fact about target entities. In this
way, entity retrieval can be performed by combin-
ing the probabilities of subqueries being satisfied
for each candidate entity.
One of the central components of our proposed
</bodyText>
<page confidence="0.963255">
514
</page>
<note confidence="0.988839333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 514–523,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999352">
Figure 1: An example of entity factoid hierarchy containing two factoids about Barack Obama
</figureCaption>
<figure confidence="0.728989375">
E
born×3, 1961×2, august×1, hawaii×1, honolulu×1
D
C
born×2, 1961×2, august×1
he was born in Honolulu Hawaii
A B
he was born in 1961 he was born in August 1961
</figure>
<bodyText confidence="0.96369488">
retrieval framework is a novel entity representa-
tion known as entity factoid hierarchy. An entity
factoid hierarchy is a tree structure composed of
factoid nodes, which is automatically constructed
b in Hnlulu Hii born in
from a collection of entity descriptions. We abuse
the term “factoid” to denote a single piece of infor-
mation regarding an entity. A factoid node in
born in 1961 born Agust 1961 b
hierarchy describes one or more factoids. Factoid
(a
nodes in different levels capture the information of
different levels of detail (referred to as information
granularities hereafter), where lower level nodes
contain more detailed information and higher level
nodes abstract the details away. The entity factoid
hierarchy is constructed via a factor graph model,
and the inference on the factor graph is achieved
by a modified variant of Multiple-try Metropolis
algorithm. Each factoid node is indexed sepa-
rately as a pseudo-document. During retrieval, the
query likelihood for a candidate entity are com-
puted by transversing the factoid hierarchy. Com-
pared to exiting entity retrieval models, our pro-
posed framework exhibits two advantages:
</bodyText>
<listItem confidence="0.959501555555555">
• By organizing entity descriptions in a hier-
archical structure, detailed entity information
is preserved and we can return finer confi-
dence value. Suppose that the entity “Barack
Obama” is only described by one sentence:
“born in 1961”. Traditional entity models,
which model an entity as a pseudo-document,
would return high confidence value for the
query “who is born in 1961”. However, as
we add more and more sentences to describe
“Barack Obama”, the confidence value re-
turned for the query decreases due to the
longer entity pseudo-document. This result is
not desirable for entity retrieval, since adding
more descriptions about other facts should
not affect the confidence of existing facts.
Our factoid hierarchy avoids this problem by
preserving all the entity descriptions in a hi-
</listItem>
<bodyText confidence="0.8119924">
erarchical structure. When performing re-
trieval, entity factoid hierarchy can be tra-
versed to locate the best supporting descrip-
tion for the query.
wii br 1961
</bodyText>
<listItem confidence="0.979380727272727">
• By separating entity facts in different factoid
nodes, our model preventnambiguityorcaused
by mixing terms describing different facts.
Suppose “Barack Obama” is described by
two sentences: “Barack Obama is a presi-
dent of United States” and “Barack Obama
is a graduate of Harvard Law School”, and
our query is “Who is a president of Har-
vard Law School”. A traditional docu-
ment retrieval model with a bag-of-word en-
tity pseudo-document would return “Barack
</listItem>
<bodyText confidence="0.94386975">
Obama” with high confidence, since all the
query terms appear in the entity descriptions.
But obviously, this result is not correct. In
our factoid hierarchy, these two facts are sep-
arated in lower level factoid nodes. While
higher level nodes are still mixed with terms
from child nodes, they are penalized to avoid
giving high confidence value.
</bodyText>
<sectionHeader confidence="0.990994" genericHeader="method">
2 Factoid Hierarchy
</sectionHeader>
<subsectionHeader confidence="0.999359">
2.1 Hierarchy Representation
</subsectionHeader>
<bodyText confidence="0.961540785714286">
As mentioned in the previous section, all the infor-
mation regarding an entity is organized in a partic-
ular factoid hierarchy. We denote the term “fac-
toid” as a single piece of information regarding an
entity, such as the birth date of Barack Obama.
A factoid node in the hierarchy describes one or
more factoids. Each factoid node is associated
with a bag-of-words vector to represent the fac-
toid description. Factoid nodes in different depth
encode information in different granularities.
An example of an entity factoid hierarchy, re-
garding two factoids (birth date and birth place)
about Barack Obama, is given in Figure 1. The
the
</bodyText>
<page confidence="0.985322">
515
</page>
<bodyText confidence="0.999973111111111">
example hierarchy is constructed from three sen-
tences about Barack Obama: he was born in 1961;
he was born in August 1961; he was born in Hon-
olulu Hawaii. These three sentences correspond
to the leaf nodes A, B, and C respectively in Fig-
ure 1. In general, a leaf node in the factoid hi-
erarchy comes directly from a sentence or a RDF
triple describing the entity. Since it is extracted
either from human written texts or from manu-
ally crafted structured databases, a leaf node repre-
sents the most exact representation regarding one
or more factoids. During the construction of the
hierarchy, intermediate nodes are formed as par-
ents for nodes that contain closely related factoids.
The factoid description for an intermediate node is
the sum of bag-of-words vectors of its child nodes.
In this way, intermediate nodes capture the words
that are used more frequently with higher weights
to describe the underlying factoids in a more gen-
eral form. As we merge more nodes and move
up in the hierarchy, intermediate nodes become
blended with more different factoids. Node D in
Figure 1 is an intermediate factoid node, as a par-
ent node for nodes A and B both describing the
birth date. The root node in an entity factoid hi-
erarchy summarizes all the descriptions regarding
an entity, which is similar to the “entity pseudo-
document” used in some existing entity retrieval
models. Each entity factoid hierarchy has only one
root node. For example, node E in Figure 1 is the
root node, and it contains words from all the three
sentences.
Note that the depth of a leaf node varies with
the number of descriptions associated with the fac-
toids. Some factoids may be associated with lots
of detailed information and are expressed in many
sentences, while others are only expressed in one
or two sentences. For example, the factoid that
Obama is elected president in 2008 may be de-
scribed in many sentences and in different con-
texts; while the factoid that Obama is born in
Kapiolani Maternity &amp; Gynecological Hospital is
only mentioned in a few sentences. In this case,
factoid nodes associated with more details may
have deeper hierarchical structure.
</bodyText>
<subsectionHeader confidence="0.997343">
2.2 Factor Graph Model
</subsectionHeader>
<bodyText confidence="0.999989735294118">
To construct the entity factoid hierarchy, we make
use of a hierarchical discriminative factor graph
model. A similar factor graph model has been pro-
posed to solve the coreference resolution in (Singh
et al., 2011; Wick et al., 2012). Here we design a
factor graph model corresponding to the entity fac-
toid hierarchy, together with new factor types and
inference mechanism.
Generally speaking, a factor graph is composed
of two parts: a set of random variables and a set of
factors that model the dependencies between ran-
dom variables. An example of the factor graph
construction corresponding to the factoid hierar-
chy involved in Figure 1 is given in Figure 2. In
our factor graph approach, each factoid is repre-
sented as a random variable fz, corresponding to a
rounded square node in Figure 2. The pairwise bi-
nary decision variable yzj, denotes whether a fac-
toid fz is a child of another factoid fj correspond-
ing to a circle node in Figure 2. The set of fac-
toids F plus the set of decision variables y are the
random variables in our factor graph model. To
model the dependency between factoids, we con-
sider two types of factors. Ψp is the set of factors
that consider the compatibility between two fac-
toid nodes, i.e., to indicate whether two nodes have
parent-child relationship. Ψu is the set of factors
that measure the compatibility of the factoid node
itself. Such factor is used to check whether a new
intermediate node should be created. Factors are
represented as square nodes in Figure 2. Given a
factor graph model m, our target is to find the best
assignments for the decision variable y that maxi-
mizes the objective function in Equation (1).
</bodyText>
<equation confidence="0.556061">
P(y, F|m) = � Ψp(f, fp)Ψu(f) (1)
f∈F
</equation>
<subsectionHeader confidence="0.994502">
2.3 Factors Design
</subsectionHeader>
<bodyText confidence="0.999951764705882">
The pairwise factors Ψp and unit-wise factors Ψu
compute the compatibility scores among factoid
nodes. Each factor type is associated with a weight
w to indicate the importance of the factor during
inference. For the notation, the bag-of-words rep-
resentation for a factoid node is denoted as d. We
use superscripts p and c to denote the variables of
parent nodes and child nodes. To capture the in-
terrelations between factoid nodes, the following
factors are used in our factor graph model.
Bag-of-words similarity To check whether two
factoid nodes refer to the same fact, we compare
the similarity between their bag-of-words descrip-
tions. We choose Kullback-Leibler divergence
(KL divergence) as the similarity measure. By
definition, the KL divergence of Q from P, de-
noted DKL(P IQ), is a measure of the informa-
</bodyText>
<page confidence="0.98458">
516
</page>
<figure confidence="0.9997536">
born 1961
august
born in Honolulu Hawaii
born in August 1961
born in 1961
born in Honolulu Hawaii
born 1961
august
born in August 1961
(b)
born in 1961
(c)
born in Honolulu Hawaii
born in 1961 born in August 1961
(a)
</figure>
<figureCaption confidence="0.870703">
Figure 2: Generation of an factoid hierarchy via factor graph inference. Factoid nodes are initialized as
singletons in (a). During one step of sampling in (b), two factoid nodes are selected and one proposal is
to add a common parent. If we accept the proposal, we end up with the factoid hierarchy in (c).
</figureCaption>
<bodyText confidence="0.9743908">
tion lost when Q is used to approximate P. It is
a non-symmetric measure and fits in our problem
nicely, i.e., measuring whether a parent node is a
more abstract representation of its child node. The
compatibility score is computed as:
</bodyText>
<equation confidence="0.9930255">
− w1 · DKL(dp||dq)
p
dip log do / , (2)
di
</equation>
<bodyText confidence="0.9999825">
where dpi is the smoothed term frequency of the
factoid description for the parent node; dci is for
the child node; w1 is a global weighting parame-
ter among different factors. In fact, we have also
explored other popular text similarity metrics sum-
marized in (Huang, 2008), and find that KL diver-
gence performs the best.
Entropy penalty We penalize the entropy of the
factoid description to encourage a smaller vocab-
ulary of words describing the underlying factoids:
</bodyText>
<equation confidence="0.9983975">
H(d) (3)
log  ||d ||0,
</equation>
<bodyText confidence="0.999022222222222">
where H(d) denotes the Shannon entropy for
the bag-of-words representation of the factoid de-
scription d; ||d||0 is the number of unique terms in
the factoid description.
Structure penalty The depth of a factoid node
indicates the level of information granularity.
However, we also need to control the depth of the
factoid hierarchy. A factoid node should not have
too many levels. We define the depth penalty as:
</bodyText>
<equation confidence="0.942712">
−w3 · |nd − ||d||0 s|, (4)
</equation>
<bodyText confidence="0.9999754">
where nd is the depth of a factoid node and s is
the parameter that controls the average depth of
factoid nodes per term. In this way, we can con-
trol the average depth of factoid nodes in the entity
factoid hierarchy.
</bodyText>
<subsectionHeader confidence="0.85628">
2.4 Inference
</subsectionHeader>
<bodyText confidence="0.999820833333333">
Exact inference is impossible for our factor graph
model due to the large state space. Here we adopt a
modified variant of Multiple-try Metropolis algo-
rithm to conduct maximum probability estimation
for inference, following the work in (Wick et al.,
2013). At each sampling step, multiple changes
to the current setting are proposed. The accep-
tance probability for a given proposal is equal to
the likelihood ratio of the proposed hypothesis to
the current hypothesis. In our case, we initialize
the MCMC procedure to the singleton configura-
tion, where each entity description, such as a sen-
tence or a RDF triple, forms its own factoid hierar-
chy initially. At each sampling step, we randomly
select two nodes and propose several alternative
local modifications. If fi and fj are not connected,
i.e., sharing no common child nodes, the following
changes are proposed:
</bodyText>
<listItem confidence="0.9891835">
• Add factoid fi as the parent of fj, if fj has
no parent node;
• Remove fj from its current parent, if fj has a
parent;
• Create a new common parent for fi and fj, if
both fi and fj have no parent.
</listItem>
<bodyText confidence="0.954889">
Otherwise, if fi and fj are in the same cluster, the
following changes are proposed:
</bodyText>
<listItem confidence="0.956382666666667">
• Remove fj from its current parent;
• Move fj’s children to fj’s parent and delete
fj, if fj is an intermediate node.
</listItem>
<bodyText confidence="0.999816428571429">
A sampling step of the inference process is il-
lustrated in Figure 2. Initially, all the decision vari-
ables y are set to zero. That is, each factoid node
is regarded as forming its own factoid hierarchy,
as illustrated in Figure 2(a). During the inference,
local modifications are proposed to the current fac-
tor graph hypothesis. For example, in Figure 2(b),
</bodyText>
<equation confidence="0.9898755">
m
= − w1 ·
i=1
−w2 ·
</equation>
<page confidence="0.958672">
517
</page>
<bodyText confidence="0.999936">
the two factoid nodes at the bottom are selected
and proposed to add a new intermediate factoid as
their common parent. If we accept the proposal,
we get an intermediate factoid hierarchy as illus-
trated in Figure 2(c).
The sampling process is iterated until no pro-
posal has been accepted in a certain number of
successive steps, or a maximum number of steps
has been reached. Each entity factoid hierarchy is
inferred separately, allowing us to parallelize the
inference across multiple machines.
</bodyText>
<sectionHeader confidence="0.991715" genericHeader="method">
3 Entity Retrieval
</sectionHeader>
<subsectionHeader confidence="0.835529">
3.1 Retrieval Model
</subsectionHeader>
<bodyText confidence="0.999665619047619">
After we preprocess available information sources
and construct the entity factoid hierarchy, we are
ready to answer entity queries. Our retrieval
model is based on the query likelihood model. Us-
ing Bayes’ rule, the probability that an entity e is
a target entity for a query q can be written as:
The probability of the query p(q) is the same for
all entities and can be ignored. Furthermore, we
assume that the prior probability of an entity being
a target entity is uniform. Thus, p(e) can also be
ignored. The task is to rank an entity e in response
to a query q by estimating the query generation
probability p(q|e).
To compute p(q|e), recall that our two-step
query generation process assumes that users gen-
erate queries by first selecting facts and then
choosing query words for each fact. Based on the
query generation process, we first decompose the
query q into m subqueries qi (discussed in Sec-
tion 3.2). Then the probability p(q|e) can be com-
puted as:
</bodyText>
<equation confidence="0.9978428">
p(qi|e) (6)
n p(qi|fk)p(fk|e) (7)
k=1
maxp(qi|fk). (8)
k
</equation>
<bodyText confidence="0.999671636363636">
Equation (6) decomposes the query into sub-
queries, assuming that all the subqueries are inde-
pendent. Equation (7) iterates through all the fac-
toid nodes fk in the factoid hierarchy of an entity
e. Equation (8) simplifies the computation by as-
suming that the underlying factoid generating sub-
query qi is the factoid fk with the highest query
generation probability.
To compute p(qi|fk), the probability of the fac-
toid fk generating the subquery qi, we use the
multinomial unigram language model:
</bodyText>
<equation confidence="0.980252">
p(qi|fk) = e(fk) rl p(tji|fk), (9)
j
</equation>
<bodyText confidence="0.993088">
where tji is the term j in the subquery qi. e(fk)
is the penalty term for factoids containing many
children:
</bodyText>
<equation confidence="0.997497">
1
e(fk) = w c(fk), (10)
</equation>
<bodyText confidence="0.999969777777778">
where c(fk) is the number of child nodes for
fk. To understand why we add this penalty term,
consider a query “who is born in 2008”. Sup-
pose “Barack Obama” is described by two sen-
tences: “born in 1961” and “elected president in
2008”. When computing p(qi|fk) for the root
node, although it contains both the terms “born”
and “2008”, it should be penalized since the terms
come from two different child nodes.
</bodyText>
<subsectionHeader confidence="0.999931">
3.2 Query analysis
</subsectionHeader>
<bodyText confidence="0.9999967">
As mentioned earlier, we decompose the original
query q into multiple factoid subqueries qi. For
long queries issued in a verbose sentence, such
as “which presidents were born in 1945”, depen-
dency parsing is performed (Klein and Manning,
2003) and the resulting dependency tree is used to
split the original query. For short queries issued
in keywords, such as “vietnam war movies”, we
decompose it based on possible key concepts ex-
pressed in the query. Usually a short query only
contains a single entity, which is used to segment
the original query into subqueries.
Furthermore, stop structures in verbose queries
is removed, following the method proposed in
(Huston and Croft, 2010). Here a stop structure
is defined as a phrase which provides no informa-
tion regarding the information needs, such as “tell
me the”. We also inject target entity type informa-
tion by replacing the leading “who ” as “person”,
and “where” as “place” for all the queries.
</bodyText>
<subsectionHeader confidence="0.904752">
3.3 Retrieval Process
</subsectionHeader>
<bodyText confidence="0.999904666666667">
For the purpose of retrieval, each node in the
entity factoid hierarchy is regarded as a pseudo-
document describing one or more factoids about
</bodyText>
<equation confidence="0.9991161">
p(e|q) = p(q|e)p(e) (5)
p(q
)
p(q|e) = m
i=1
= m
i=1
m
N
i=1
</equation>
<page confidence="0.960647">
518
</page>
<bodyText confidence="0.999890583333333">
the entity, and is indexed as a bag-of-words doc-
ument during the preprocessing. The retrieval is
performed in a two-step process. First, for each in-
dividual subquery, we retrieve top 1000 candidate
entities by performing retrieval on all root nodes.
This gives us an initial pool of candidate entities
by merging the returned entities for subqueries.
After that, for each candidate entity, we traverse
its factoid hierarchy and compute the query gen-
eration probability p(q|e) using Equations (8) and
(9). Top ranked entities are returned as retrieval
results.
</bodyText>
<sectionHeader confidence="0.999538" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.705551">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999409375">
We perform entity retrieval experiments using the
DBpedia-Entity dataset used in (Balog and Neu-
mayer, 2013). The dataset is a mixture of multiple
entity retrieval datasets, covering entity queries of
various styles such as keyword queries like “viet-
nam war movies” and verbose queries like “What
is the capital of Canada”. Some query statistics are
shown in Table 2.
</bodyText>
<table confidence="0.999589">
Query set #query avg(lql) avg(#rel)
INEX-XER 55 5.5 29.7
TREC Entity 17 6.7 12.9
SemSearch ES 130 2.7 8.6
SemSearch LS 43 5.4 12.5
QALD-2 140 7.9 41.2
INEX-LD 100 4.8 36.8
Total 485 5.3 26.7
</table>
<tableCaption confidence="0.99861">
Table 2: DBpedia-Entity dataset statistics
</tableCaption>
<bodyText confidence="0.9999297">
The data corpus we use are DBpedia 3.9 and
the corresponding English Wikipedia data dump
on April 4, 2013. It should be noted that the origi-
nal DBpedia-Entity benchmark only uses DBpedia
for entity modeling (Balog and Neumayer, 2013).
In our experiments, we also conducted another set
of experiments which include full-text Wikipedia
articles as additional entity descriptions, to eval-
uate the capacity of different models on handling
free texts as information sources.
</bodyText>
<subsectionHeader confidence="0.818445">
4.2 Comparison models and variants of our
model
</subsectionHeader>
<bodyText confidence="0.957729346153846">
For comparison, we have implemented the follow-
ing two existing models:
• BM25. BM25 is a popular document re-
trieval method and also used to perform en-
tity retrieval (Balog and Neumayer, 2013).
All the descriptions about an entity are ag-
gregated into an entity pseudo-document. We
use ki = 1.2, b = 0.8 for the model parame-
ter, similar to the original papers.
• MLM-tc. The Mixture of Language Model
represents an entity as a document with
multiple fields, where each field is given
a different weight for generating the query
terms. MLM is often adopted to do entity
retrieval (Neumayer et al., 2012). Here we
adopt the MLM-tc model used in (Balog and
Neumayer, 2013), where two fields are con-
sidered: title and content fields (described in
Section 4.3). The parameters used are 0.8 for
the title field and 0.2 for the content field.
Note that both MLM-tc and BM25 are also
compared in (Balog and Neumayer, 2013), and
have shown the best MAP performances among all
the compared models.
For our models, the following two variants are
implemented and compared.
</bodyText>
<listItem confidence="0.666252571428571">
• Factoid Retrieval Model with Hierarchy
(FRMwH). Our full model uses entity fac-
toid graph as entity representation. Each fac-
toid node is indexed as a bag-of-words docu-
ment. The retrieval model described in Sec-
tion 3 is employed.
• Factoid Retrieval Model (FRM). This
</listItem>
<bodyText confidence="0.8153498">
model does not use entity factoid hierarchy
as entity representation. Instead, K-Means
clustering algorithm is used to cluster the sen-
tences into text clusters. Each text cluster is
then indexed as a document. Compared to the
FRMwH model, an entity only has a flat clus-
ter of factoid descriptions. The same retrieval
model is used.
All the four models use the same query prepro-
cessing techniques.
</bodyText>
<subsectionHeader confidence="0.994337">
4.3 Setup
</subsectionHeader>
<bodyText confidence="0.999816888888889">
The entity descriptions come from texts in
Wikipedia articles and structured information
from DBpedia. For DBpedia information, we con-
sider top 1000 most frequent predicates as fields.
We convert RDF predicates to free text by break-
ing the camelcase predicate name to terms, for ex-
ample “birthPlace” is converted to “birth place”.
For Wikipedia texts, we first remove all markup
text such as images, categories. Infoboxes are also
</bodyText>
<page confidence="0.990037">
519
</page>
<figure confidence="0.997268930232558">
Model INEX-XER TREC Entity SemSearch ES SemSearch LS QALD-2 INEX-LD Total
MAP P@10 MAP P@10 MAP P@10 MAP P@10 MAP P@10 MAP P@10 MAP P@10
Experiments with only DBpedia information
BM25
.1890 .2706
.1257 .1571
.2732 .2426
.2050 .2286
.2211 .1976
.1104 .2158
.1806 .1901
MLM-tc
.1439 .2176
.1138 .1143
.2962 .2641
.1755 .1976
.1789 .1598
.1093 .2144
.1720 .1792
FRM
✿✿✿ ✿✿✿
.2186 .2186
.1548 .1548
✿✿✿✿
.2430 .2430
.2088 .2088
✿✿✿ ✿✿✿✿
.2462 .2462
.1178 .1178
✿✿✿ ✿✿✿
.1854 .1965
FRMwH
.2260 .2260
.1742.1742
.2270 .2270
.1642 .1642
.2286 .2286
.1358 .1358
.1905 .2004
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿✿
✿✿✿
✿✿✿ ✿✿✿
Experiments with both DBpedia and Wikipedia information
BM25
.1313 .1887
.1374 .1667
.2916 .2526
.1867 .1833
.1552 .1253
.1698 .2680
.1848 .1821
MLM-tc
.0777 .0981
.0942 .0875
.2794 .2398
.1071 .1071
.1024 .0771
.1501 .2370
.1515 .1452
FRM
.1922 .1922
.1601 .1601
.2279 .2279
.1729 .1729
.1965 .1965
.1793 .1793 .1934 .1998
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿✿
✿✿✿ ✿✿✿✿
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿✿ ✿✿✿ ✿✿✿
.2092 .2130
FRMwH
.2634 .2634
.1770 .1770
.2267 .2267
.1910 .1910
.2491 .2491
.1554 .1554
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿✿
✿✿✿ ✿✿✿✿
✿✿✿ ✿✿✿
✿✿✿ ✿✿✿
</figure>
<tableCaption confidence="0.983975">
Table 1: Retrieval performance for various models
</tableCaption>
<bodyText confidence="0.99994156">
removed since the information is already well cap-
tured in DBpedia. Each Wikipedia article is then
segmented to a list of sentences, which are consid-
ered as factoid descriptions regarding the entity.
For the BM25 model, all the descriptions about
an entity are aggregated into an entity pseudo-
document. For the MLMtc model, the title field
is constructed by combining DBpedia properties
whose property names are ending with “title”,
“name” or “label”, such as “fullName” (Neumayer
et al., 2012), and the content field is the same
as the entity pseudo-document used in the BM25
model.
The inference algorithm for the entity factoid
hierarchy is implemented based on the factorie
package (McCallum et al., 2009). The parame-
ters used in the inference are manually tuned on
a small set of entities. The retrieval algorithms,
including BM25 and Language Modeling, are im-
plemented based on Apache Lucene1. For lan-
guage models, Bayesian smoothing with Dirich-
let priors is used, with parameter µ = 2000. For
FRM, to cluster the entity descriptions, we use
the K-Means clustering algorithm implemented in
Carrot22.
</bodyText>
<subsectionHeader confidence="0.935596">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.9999904">
We report two standard retrieval measures: mean
average precision (MAP) and precision at 10
(P@10). Top 100 ranked entities are evaluated for
each query. Two set of experiments are conducted:
experiments with only DBpedia information; ex-
periments with both DBpedia and Wikipedia in-
formation. The experiment result is shown in Ta-
ble 1. To conduct the statistical significance anal-
ysis, we use two-tailed paired t-test at the 0.05
level. The symbols underline and✿✿✿✿✿ wave✿✿✿✿✿✿✿✿✿ underline
</bodyText>
<footnote confidence="0.999889">
1Apache Lucene: http://lucene.apache.org/
2Carrot2: http://www.carrot2.org/
</footnote>
<bodyText confidence="0.999338655172414">
are used to indicate significant improvement of
our model compared with the BM25 and MLM-
tc models respectively.
The first set of rows in Table 1 show the per-
formance of four models using only DBpedia in-
formation. Both of our models have better overall
performance. On datasets with verbose queries,
such as INEX-XER and TREC Entity, both our
models outperform the baseline models. One rea-
son is that our retrieval model relies on the as-
sumption that verbose queries can be decomposed
into multiple subqueries. The second set of rows
show the performance of four models using both
DBpedia and Wikipedia information. After adding
the additional information from Wikipedia arti-
cles, MLM-tc attains much worse performance,
while BM25 performs roughly the same. One
possible reason is that Wikipedia articles con-
tain much irrelevant information regarding enti-
ties, and these two existing models cannot eas-
ily make use of additional information. In con-
trast, with Wikipedia full-text available, both of
our proposed models achieve obviously better per-
formances.
Our full model, FRMwH, has shown consis-
tently better overall performance compared with
the FRM model. It demonstrates that it is worth-
while to employ our proposed entity hierarchical
structure for entity representation.
</bodyText>
<subsectionHeader confidence="0.998271">
4.5 Analysis
</subsectionHeader>
<bodyText confidence="0.99998925">
For the retrieval performance, we also perform a
topic-level analysis between our model FRMwH
and the baseline model BM25, shown in Fig-
ure 3. The X-axis represents individual query
topics, ordered by average precision difference
(shown on the Y-axis). Positive Y value indi-
cates that FRMwH performs better than the BM25
model for the query. From the figure, most of
</bodyText>
<page confidence="0.976804">
520
</page>
<figure confidence="0.99951096">
0.8
0.4
−0.4
−0.8
−0.4
−0.8
0.8
0.4
−0.4
−0.8
0.8
0.4
−0.4
−0.8
0.8
0.4
−0.4
−0.8
0.8
0.4
−0.4
−0.8
0.8
0.4
(a) (b) (c) (d) (e) (f)
</figure>
<figureCaption confidence="0.9977285">
Figure 3: Topic-level differences between FRMwH and BM25. Positive values mean FRMwH is better.
(a) INEX-XER; (b) TREC Entity; (c) SemSearch ES; (d) SemSearch LS; (e) QALD-2; (f) INEX-LD.
</figureCaption>
<bodyText confidence="0.999484272727273">
queries are affected by using FRMwH model. On
the datasets with verbose queries, such as INEX-
XER and TREC Entity, we can see most of the
query are improved. FRMwH performs slightly
worse for datasets like SemSearch ES which is
mostly composed of keyword queries. For the
queries that show little or no performance differ-
ences, manual inspection shows that both models
fail to find any relevant results, due to the lack of
supporting descriptions in Wikipedia and DBpe-
dia.
</bodyText>
<sectionHeader confidence="0.999955" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99997005">
Besides the entity retrieval models reviewed in
Section 1, there are models that do not maintain
an explicit entity representation. Instead, they
compute the entity relevance score based on the
co-occurance between entities and query terms
in the documents directly. Most of these mod-
els are originally proposed for expertise retrieval,
where the appearance of a person name indicates
the association with the expertise mentioned in
the same document. Typical models include vot-
ing model (Macdonald and Ounis, 2006), graph
model (Serdyukov et al., 2008), etc. However, it
is not easy to generalize these models for open do-
main entity retrieval.
Entity models are also used in other fields be-
sides entity retrieval. For example, entity topic
models are used to perform entity prediction, clas-
sification of entity pairs, construction of entity-
entity network (Newman et al., 2006), as well as
entity linking (Han and Sun, 2012). These models
are not suitable for our retrieval framework.
The decomposing of entity queries into fac-
toid queries is related to query segmentation.
Query segmentation has been used by search en-
gines to support inverse lookup of words and
phrases (Risvik et al., 2003; Bergsma and Wang,
2007). Our use of query decomposition is quite
different compared to query segmentation. Be-
sides query segmentation, query decomposition
has also been used to facilitate the acquisition and
optimization of high-order contextual term associ-
ations (Song et al., 2012).
Our work is also related to the information ex-
traction and knowledge representation field since
our framework involves extraction and aggrega-
tion of knowledge from free texts. However, most
existing approaches takes two extreme ways: ei-
ther extract relations based on pre-defined ontol-
ogy, such as DBpedia (Lehmann et al., 2014); or
cluster relation without referring to some ontol-
ogy, such as OpenIE (Etzioni et al., 2011). Though
our main goal is not on constructing a complete
knowledge base, we do leverage both existing
knowledge bases as well as free text data.
Semantic search also targets on returning an-
swers directly (Pound et al., 2010; Blanco et al.,
2011; Tonon et al., 2012; Kahng and Lee, 2012).
However, they are mainly based on structured
linked data, as well as structured query language
like SPARQL. While this is an effective approach
if we have a powerful thorough knowledge base,
in practice many facts cannot be effectively repre-
sented as linked data. Only a small set of relations
(thousands in DBpedia) have been defined in the
ontology, such as “birthPlace”. Furthermore, even
if we can define a formal representation of human
knowledge, retrieve them effectively is still a prob-
lem due to the difficulty of transforming the hu-
man query into a structured query on a knowledge
base.
</bodyText>
<sectionHeader confidence="0.999542" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999984714285714">
We propose that an entity query is generated in a
two-step process: users first select the facts that
can distinguish target entities from the others; then
choose words to express those facts. Following
this motivation, we propose a retrieval framework
by decomposing the original query into factoid
queries. We also propose to construct an entity
</bodyText>
<page confidence="0.991906">
521
</page>
<bodyText confidence="0.999987833333333">
factoid hierarchy as the entity model for the pur-
pose of entity retrieval. Our entity factoid hier-
archy can integrate information of different gran-
ularities from both free text and structured data.
Extensive experiments demonstrate the effective-
ness of our framework.
</bodyText>
<sectionHeader confidence="0.99762" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999622265306122">
Krisztian Balog and Robert Neumayer. 2013. A test
collection for entity search in DBpedia. In Proceed-
ings of the 36th International ACM SIGIR confer-
ence on Research and Development in Information
Retrieval, pages 737–740.
K. Balog, P. Serdyukov, and A. P. de Vries. 2012.
Overview of the TREC 2011 entity track. In Pro-
ceedings of the Twentieth Text REtrieval Conference.
Shane Bergsma and Qin Iris Wang. 2007. Learning
noun phrase query segmentation. In Proc. EMNLP-
CoNLL, pages 819–826.
Roi Blanco, Harry Halpin, Daniel M. Herzig, Pe-
ter Mika, Jeffrey Pound, and Henry S. Thompson.
2011. Entity search evaluation over structured web
data. In Proceedings of the 1st International Work-
shop on Entity-Oriented Search, EOS ’11.
Oren Etzioni, Anthony Fader, Janara Christensen,
Stephen Soderland, and Mausam Mausam. 2011.
Open information extraction: The second genera-
tion. In Proceedings of the Twenty-Second Inter-
national Joint Conference on Artificial Intelligence,
pages 3–10.
Xianpei Han and Le Sun. 2012. An entity-topic model
for entity linking. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, EMNLP-CoNLL ’12, pages 105–
115.
Anna Huang. 2008. Similarity measures for text doc-
ument clustering. In Proceedings of the Sixth New
Zealand Computer Science Research Student Con-
ference, pages 49–56.
Samuel Huston and W. Bruce Croft. 2010. Evaluating
verbose query processing techniques. In Proceed-
ings of the 33rd International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 291–298.
Minsuk Kahng and Sang-goo Lee. 2012. Exploiting
paths for entity search in rdf graphs. In Proceedings
of the 35th international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ’12, pages 1027–1028.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 423–
430.
Jens Lehmann, Robert Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N. Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, S¨oren Auer, and Christian Bizer. 2014. DB-
pedia - a large-scale, multilingual knowledge base
extracted from wikipedia. Semantic Web Journal,
6(2):167–195.
Chunliang Lu, Lidong Bing, and Wai Lam. 2013.
Structured positional entity language model for en-
terprise entity retrieval. In Proceedings of the 22Nd
ACMInternational Conference on Conference on In-
formation &amp; Knowledge Management, CIKM ’13,
pages 129–138.
Craig Macdonald and Iadh Ounis. 2006. Voting
for candidates: adapting data fusion techniques for
an expert search task. In Proceedings of the 15th
ACM International Conference on Information and
Knowledge Management, pages 387–396.
Andrew McCallum, Karl Schultz, and Sameer Singh.
2009. FACTORIE: Probabilistic programming via
imperatively defined factor graphs. In Neural In-
formation Processing Systems (NIPS), pages 1249–
1257.
Robert Neumayer, Krisztian Balog, and Kjetil Nrvg.
2012. When simple is (more than) good enough:
Effective semantic search with (almost) no seman-
tics. In Advances in Information Retrieval, pages
540–543.
David Newman, Chaitanya Chemudugunta, and
Padhraic Smyth. 2006. Statistical entity-topic mod-
els. In Proceedings of the 12th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and
Data Mining, pages 680–686.
D. Petkova and W.B. Croft. 2006. Hierarchical lan-
guage models for expert finding in enterprise cor-
pora. In Tools with Artificial Intelligence, 2006.
ICTAI ’06. 18th IEEE International Conference on,
pages 599–608, Nov.
Jeffrey Pound, Peter Mika, and Hugo Zaragoza. 2010.
Ad-hoc object retrieval in the web of data. In Pro-
ceedings of the 19th international conference on
World wide web, WWW ’10, pages 771–780.
Hema Raghavan, James Allan, and Andrew Mccallum.
2004. An exploration of entity models, collective
classification and relation description. In Proceed-
ings of KDD Workshop on Link Analysis and Group
Detection, pages 1–10.
K. M. Risvik, T. Mikolajewski, and P. Boros. 2003.
Query segmentation for web search. In Proceedings
of the Twelfth International World Wide Web Con-
ference (Poster session).
</reference>
<page confidence="0.971113">
522
</page>
<reference confidence="0.9997923125">
Pavel Serdyukov, Henning Rode, and Djoerd Hiemstra.
2008. Modeling multi-step relevance propagation
for expert finding. In Proceeding of the 17th ACM
Conference on Information and Knowledge Mining,
pages 1133–1142.
Sameer Singh, Amarnag Subramanya, Fernando
Pereira, and Andrew McCallum. 2011. Large-scale
cross-document coreference using distributed infer-
ence and hierarchical models. In Proceedings of the
49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 793–803.
Dawei Song, Qiang Huang, Peter Bruza, and Ray-
mond Lau. 2012. An aspect query language model
based on query decomposition and high-order con-
textual term associations. Comput. Intell., 28(1):1–
23, February.
Alberto Tonon, Gianluca Demartini, and Philippe
Cudr´e-Mauroux. 2012. Combining inverted indices
and structured search for ad-hoc object retrieval. In
Proceedings of the 35th international ACM SIGIR
conference on Research and development in infor-
mation retrieval, SIGIR ’12, pages 125–134.
Qiuyue Wang and Jinglin Kang. 2012. Inte-
grated retrieval over structured and unstructured
data. In Pamela Forner, Jussi Karlgren, and Christa
Womser-Hacker, editors, CLEF (Online Working
Notes/Labs/Workshop), pages 42–44.
Zhanyi Wang, Wenlong Lv, Heng Li, Wenyuan Zhou,
Li Zhang, Xiao Mo, Liaoming Zhou, Weiran Xu,
Guang Chen, and Jun Guo. 2011. PRIS at TREC
2011 entity track: Related entity finding and entity
list completion. In TREC.
Qiuyue Wang, Jaap Kamps, Georgina Ramirez Camps,
Maarten Marx, Anne Schuth, Martin Theobald,
Sairam Gurajada, and Arunav Mishra. 2012.
Overview of the inex 2012 linked data track. In
CLEF (Online Working Notes/Labs/Workshop).
Michael Wick, Sameer Singh, and Andrew McCallum.
2012. A discriminative hierarchical model for fast
coreference at large scale. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics, pages 379–388.
Michael Wick, Sameer Singh, Harshal Pandya, and An-
drew McCallum. 2013. A joint model for discover-
ing and linking entities. In CIKM 2013 Workshop
on Automated Knowledge Base Construction, pages
67–72.
</reference>
<page confidence="0.998927">
523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.774282">
<title confidence="0.983228">Retrieval via Entity Factoid</title>
<author confidence="0.986225">Chunliang Lu</author>
<author confidence="0.986225">Wai Lam</author>
<author confidence="0.986225">Yi</author>
<affiliation confidence="0.940579">Key Laboratory of High Confidence Software Ministry of Education (CUHK Department of Systems Engineering and Engineering The Chinese University of Hong</affiliation>
<abstract confidence="0.99956308">We propose that entity queries are generated via a two-step process: users first select entity facts that can distinguish target entities from the others; and then choose words to describe each selected fact. Based on this query generation paradigm, we propose a new entity representation model named as entity factoid hierarchy. An entity factoid hierarchy is a tree structure composed of factoid nodes. A factoid node describes one or more facts about the entity in different information granularities. The entity factoid hierarchy is constructed via a factor graph model, and the inference on the factor graph is achieved by a modified variant of Multiple-try Metropolis algorithm. Entity retrieval is performed by decomposing entity queries and computing the query likelihood on the entity factoid hierarchy. Using an array of benchmark datasets, we demonstrate that our proposed framework significantly improves the retrieval performance over existing models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Krisztian Balog</author>
<author>Robert Neumayer</author>
</authors>
<title>A test collection for entity search in DBpedia.</title>
<date>2013</date>
<booktitle>In Proceedings of the 36th International ACM SIGIR conference on Research and Development in Information Retrieval,</booktitle>
<pages>737--740</pages>
<contexts>
<context position="20872" citStr="Balog and Neumayer, 2013" startWordPosition="3484" endWordPosition="3488">processing. The retrieval is performed in a two-step process. First, for each individual subquery, we retrieve top 1000 candidate entities by performing retrieval on all root nodes. This gives us an initial pool of candidate entities by merging the returned entities for subqueries. After that, for each candidate entity, we traverse its factoid hierarchy and compute the query generation probability p(q|e) using Equations (8) and (9). Top ranked entities are returned as retrieval results. 4 Experiments 4.1 Dataset We perform entity retrieval experiments using the DBpedia-Entity dataset used in (Balog and Neumayer, 2013). The dataset is a mixture of multiple entity retrieval datasets, covering entity queries of various styles such as keyword queries like “vietnam war movies” and verbose queries like “What is the capital of Canada”. Some query statistics are shown in Table 2. Query set #query avg(lql) avg(#rel) INEX-XER 55 5.5 29.7 TREC Entity 17 6.7 12.9 SemSearch ES 130 2.7 8.6 SemSearch LS 43 5.4 12.5 QALD-2 140 7.9 41.2 INEX-LD 100 4.8 36.8 Total 485 5.3 26.7 Table 2: DBpedia-Entity dataset statistics The data corpus we use are DBpedia 3.9 and the corresponding English Wikipedia data dump on April 4, 2013.</context>
<context position="22551" citStr="Balog and Neumayer, 2013" startWordPosition="3767" endWordPosition="3770">llowing two existing models: • BM25. BM25 is a popular document retrieval method and also used to perform entity retrieval (Balog and Neumayer, 2013). All the descriptions about an entity are aggregated into an entity pseudo-document. We use ki = 1.2, b = 0.8 for the model parameter, similar to the original papers. • MLM-tc. The Mixture of Language Model represents an entity as a document with multiple fields, where each field is given a different weight for generating the query terms. MLM is often adopted to do entity retrieval (Neumayer et al., 2012). Here we adopt the MLM-tc model used in (Balog and Neumayer, 2013), where two fields are considered: title and content fields (described in Section 4.3). The parameters used are 0.8 for the title field and 0.2 for the content field. Note that both MLM-tc and BM25 are also compared in (Balog and Neumayer, 2013), and have shown the best MAP performances among all the compared models. For our models, the following two variants are implemented and compared. • Factoid Retrieval Model with Hierarchy (FRMwH). Our full model uses entity factoid graph as entity representation. Each factoid node is indexed as a bag-of-words document. The retrieval model described in S</context>
</contexts>
<marker>Balog, Neumayer, 2013</marker>
<rawString>Krisztian Balog and Robert Neumayer. 2013. A test collection for entity search in DBpedia. In Proceedings of the 36th International ACM SIGIR conference on Research and Development in Information Retrieval, pages 737–740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Balog</author>
<author>P Serdyukov</author>
<author>A P de Vries</author>
</authors>
<title>entity track.</title>
<date>2012</date>
<journal>Overview of the TREC</journal>
<booktitle>In Proceedings of the Twentieth Text REtrieval Conference.</booktitle>
<marker>Balog, Serdyukov, de Vries, 2012</marker>
<rawString>K. Balog, P. Serdyukov, and A. P. de Vries. 2012. Overview of the TREC 2011 entity track. In Proceedings of the Twentieth Text REtrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Qin Iris Wang</author>
</authors>
<title>Learning noun phrase query segmentation.</title>
<date>2007</date>
<booktitle>In Proc. EMNLPCoNLL,</booktitle>
<pages>819--826</pages>
<contexts>
<context position="30580" citStr="Bergsma and Wang, 2007" startWordPosition="5077" endWordPosition="5080">ize these models for open domain entity retrieval. Entity models are also used in other fields besides entity retrieval. For example, entity topic models are used to perform entity prediction, classification of entity pairs, construction of entityentity network (Newman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by search engines to support inverse lookup of words and phrases (Risvik et al., 2003; Bergsma and Wang, 2007). Our use of query decomposition is quite different compared to query segmentation. Besides query segmentation, query decomposition has also been used to facilitate the acquisition and optimization of high-order contextual term associations (Song et al., 2012). Our work is also related to the information extraction and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or clust</context>
</contexts>
<marker>Bergsma, Wang, 2007</marker>
<rawString>Shane Bergsma and Qin Iris Wang. 2007. Learning noun phrase query segmentation. In Proc. EMNLPCoNLL, pages 819–826.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Blanco</author>
<author>Harry Halpin</author>
<author>Daniel M Herzig</author>
<author>Peter Mika</author>
<author>Jeffrey Pound</author>
<author>Henry S Thompson</author>
</authors>
<title>Entity search evaluation over structured web data.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st International Workshop on Entity-Oriented Search, EOS ’11.</booktitle>
<contexts>
<context position="31509" citStr="Blanco et al., 2011" startWordPosition="5224" endWordPosition="5227">action and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or cluster relation without referring to some ontology, such as OpenIE (Etzioni et al., 2011). Though our main goal is not on constructing a complete knowledge base, we do leverage both existing knowledge bases as well as free text data. Semantic search also targets on returning answers directly (Pound et al., 2010; Blanco et al., 2011; Tonon et al., 2012; Kahng and Lee, 2012). However, they are mainly based on structured linked data, as well as structured query language like SPARQL. While this is an effective approach if we have a powerful thorough knowledge base, in practice many facts cannot be effectively represented as linked data. Only a small set of relations (thousands in DBpedia) have been defined in the ontology, such as “birthPlace”. Furthermore, even if we can define a formal representation of human knowledge, retrieve them effectively is still a problem due to the difficulty of transforming the human query into</context>
</contexts>
<marker>Blanco, Halpin, Herzig, Mika, Pound, Thompson, 2011</marker>
<rawString>Roi Blanco, Harry Halpin, Daniel M. Herzig, Peter Mika, Jeffrey Pound, and Henry S. Thompson. 2011. Entity search evaluation over structured web data. In Proceedings of the 1st International Workshop on Entity-Oriented Search, EOS ’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Anthony Fader</author>
<author>Janara Christensen</author>
<author>Stephen Soderland</author>
<author>Mausam Mausam</author>
</authors>
<title>Open information extraction: The second generation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence,</booktitle>
<pages>3--10</pages>
<contexts>
<context position="31265" citStr="Etzioni et al., 2011" startWordPosition="5182" endWordPosition="5185">query segmentation. Besides query segmentation, query decomposition has also been used to facilitate the acquisition and optimization of high-order contextual term associations (Song et al., 2012). Our work is also related to the information extraction and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or cluster relation without referring to some ontology, such as OpenIE (Etzioni et al., 2011). Though our main goal is not on constructing a complete knowledge base, we do leverage both existing knowledge bases as well as free text data. Semantic search also targets on returning answers directly (Pound et al., 2010; Blanco et al., 2011; Tonon et al., 2012; Kahng and Lee, 2012). However, they are mainly based on structured linked data, as well as structured query language like SPARQL. While this is an effective approach if we have a powerful thorough knowledge base, in practice many facts cannot be effectively represented as linked data. Only a small set of relations (thousands in DBpe</context>
</contexts>
<marker>Etzioni, Fader, Christensen, Soderland, Mausam, 2011</marker>
<rawString>Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam Mausam. 2011. Open information extraction: The second generation. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, pages 3–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
</authors>
<title>An entity-topic model for entity linking.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>105--115</pages>
<marker>Han, Le Sun, 2012</marker>
<rawString>Xianpei Han and Le Sun. 2012. An entity-topic model for entity linking. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 105– 115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Huang</author>
</authors>
<title>Similarity measures for text document clustering.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth New Zealand Computer Science Research Student Conference,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="13806" citStr="Huang, 2008" startWordPosition="2273" endWordPosition="2274">t the proposal, we end up with the factoid hierarchy in (c). tion lost when Q is used to approximate P. It is a non-symmetric measure and fits in our problem nicely, i.e., measuring whether a parent node is a more abstract representation of its child node. The compatibility score is computed as: − w1 · DKL(dp||dq) p dip log do / , (2) di where dpi is the smoothed term frequency of the factoid description for the parent node; dci is for the child node; w1 is a global weighting parameter among different factors. In fact, we have also explored other popular text similarity metrics summarized in (Huang, 2008), and find that KL divergence performs the best. Entropy penalty We penalize the entropy of the factoid description to encourage a smaller vocabulary of words describing the underlying factoids: H(d) (3) log ||d ||0, where H(d) denotes the Shannon entropy for the bag-of-words representation of the factoid description d; ||d||0 is the number of unique terms in the factoid description. Structure penalty The depth of a factoid node indicates the level of information granularity. However, we also need to control the depth of the factoid hierarchy. A factoid node should not have too many levels. We</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Anna Huang. 2008. Similarity measures for text document clustering. In Proceedings of the Sixth New Zealand Computer Science Research Student Conference, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Huston</author>
<author>W Bruce Croft</author>
</authors>
<title>Evaluating verbose query processing techniques.</title>
<date>2010</date>
<booktitle>In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>291--298</pages>
<contexts>
<context position="19682" citStr="Huston and Croft, 2010" startWordPosition="3286" endWordPosition="3289">ultiple factoid subqueries qi. For long queries issued in a verbose sentence, such as “which presidents were born in 1945”, dependency parsing is performed (Klein and Manning, 2003) and the resulting dependency tree is used to split the original query. For short queries issued in keywords, such as “vietnam war movies”, we decompose it based on possible key concepts expressed in the query. Usually a short query only contains a single entity, which is used to segment the original query into subqueries. Furthermore, stop structures in verbose queries is removed, following the method proposed in (Huston and Croft, 2010). Here a stop structure is defined as a phrase which provides no information regarding the information needs, such as “tell me the”. We also inject target entity type information by replacing the leading “who ” as “person”, and “where” as “place” for all the queries. 3.3 Retrieval Process For the purpose of retrieval, each node in the entity factoid hierarchy is regarded as a pseudodocument describing one or more factoids about p(e|q) = p(q|e)p(e) (5) p(q ) p(q|e) = m i=1 = m i=1 m N i=1 518 the entity, and is indexed as a bag-of-words document during the preprocessing. The retrieval is perfor</context>
</contexts>
<marker>Huston, Croft, 2010</marker>
<rawString>Samuel Huston and W. Bruce Croft. 2010. Evaluating verbose query processing techniques. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 291–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minsuk Kahng</author>
<author>Sang-goo Lee</author>
</authors>
<title>Exploiting paths for entity search in rdf graphs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12,</booktitle>
<pages>1027--1028</pages>
<contexts>
<context position="31551" citStr="Kahng and Lee, 2012" startWordPosition="5232" endWordPosition="5235"> since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or cluster relation without referring to some ontology, such as OpenIE (Etzioni et al., 2011). Though our main goal is not on constructing a complete knowledge base, we do leverage both existing knowledge bases as well as free text data. Semantic search also targets on returning answers directly (Pound et al., 2010; Blanco et al., 2011; Tonon et al., 2012; Kahng and Lee, 2012). However, they are mainly based on structured linked data, as well as structured query language like SPARQL. While this is an effective approach if we have a powerful thorough knowledge base, in practice many facts cannot be effectively represented as linked data. Only a small set of relations (thousands in DBpedia) have been defined in the ontology, such as “birthPlace”. Furthermore, even if we can define a formal representation of human knowledge, retrieve them effectively is still a problem due to the difficulty of transforming the human query into a structured query on a knowledge base. 6</context>
</contexts>
<marker>Kahng, Lee, 2012</marker>
<rawString>Minsuk Kahng and Sang-goo Lee. 2012. Exploiting paths for entity search in rdf graphs. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12, pages 1027–1028.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="19240" citStr="Klein and Manning, 2003" startWordPosition="3214" endWordPosition="3217">. To understand why we add this penalty term, consider a query “who is born in 2008”. Suppose “Barack Obama” is described by two sentences: “born in 1961” and “elected president in 2008”. When computing p(qi|fk) for the root node, although it contains both the terms “born” and “2008”, it should be penalized since the terms come from two different child nodes. 3.2 Query analysis As mentioned earlier, we decompose the original query q into multiple factoid subqueries qi. For long queries issued in a verbose sentence, such as “which presidents were born in 1945”, dependency parsing is performed (Klein and Manning, 2003) and the resulting dependency tree is used to split the original query. For short queries issued in keywords, such as “vietnam war movies”, we decompose it based on possible key concepts expressed in the query. Usually a short query only contains a single entity, which is used to segment the original query into subqueries. Furthermore, stop structures in verbose queries is removed, following the method proposed in (Huston and Croft, 2010). Here a stop structure is defined as a phrase which provides no information regarding the information needs, such as “tell me the”. We also inject target ent</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423– 430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Lehmann</author>
<author>Robert Isele</author>
<author>Max Jakob</author>
<author>Anja Jentzsch</author>
<author>Dimitris Kontokostas</author>
<author>Pablo N Mendes</author>
<author>Sebastian Hellmann</author>
<author>Mohamed Morsey</author>
<author>Patrick van Kleef</author>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
</authors>
<title>DBpedia - a large-scale, multilingual knowledge base extracted from wikipedia.</title>
<date>2014</date>
<journal>Semantic Web Journal,</journal>
<volume>6</volume>
<issue>2</issue>
<marker>Lehmann, Isele, Jakob, Jentzsch, Kontokostas, Mendes, Hellmann, Morsey, van Kleef, Auer, Bizer, 2014</marker>
<rawString>Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N. Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van Kleef, S¨oren Auer, and Christian Bizer. 2014. DBpedia - a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web Journal, 6(2):167–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunliang Lu</author>
<author>Lidong Bing</author>
<author>Wai Lam</author>
</authors>
<title>Structured positional entity language model for enterprise entity retrieval.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd ACMInternational Conference on Conference on Information &amp; Knowledge Management, CIKM ’13,</booktitle>
<pages>129--138</pages>
<contexts>
<context position="2526" citStr="Lu et al., 2013" startWordPosition="389" endWordPosition="392">03414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representations to compute the rank of the candidate entities for a given entity query. These models include fielded versions of BM25 and Mixture of Language Models (Neumayer et al., 2012), Entity Language Model (Raghavan et al., 2004), Hierarchical Expert Model (Petkova and Croft, 2006), Structured Positional Entity Language Model (Lu et al., 2013). However, a closer examination of entity queries reveals that most of them are not simple uniform word samples from the “entity pseudo-document”. Instead, they can be decomposed into multiple parts, where each part describes a fact about target entities. For example, the query “National capitals situated on islands” describes two facts regarding a target entity: it is a national capital; it is located on an island. Compared to the assumption in document retrieval models, where query terms are assumed to be generated from a single document, these query terms can be regarded to be independently</context>
</contexts>
<marker>Lu, Bing, Lam, 2013</marker>
<rawString>Chunliang Lu, Lidong Bing, and Wai Lam. 2013. Structured positional entity language model for enterprise entity retrieval. In Proceedings of the 22Nd ACMInternational Conference on Conference on Information &amp; Knowledge Management, CIKM ’13, pages 129–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig Macdonald</author>
<author>Iadh Ounis</author>
</authors>
<title>Voting for candidates: adapting data fusion techniques for an expert search task.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>387--396</pages>
<contexts>
<context position="29878" citStr="Macdonald and Ounis, 2006" startWordPosition="4961" endWordPosition="4964">find any relevant results, due to the lack of supporting descriptions in Wikipedia and DBpedia. 5 Related Work Besides the entity retrieval models reviewed in Section 1, there are models that do not maintain an explicit entity representation. Instead, they compute the entity relevance score based on the co-occurance between entities and query terms in the documents directly. Most of these models are originally proposed for expertise retrieval, where the appearance of a person name indicates the association with the expertise mentioned in the same document. Typical models include voting model (Macdonald and Ounis, 2006), graph model (Serdyukov et al., 2008), etc. However, it is not easy to generalize these models for open domain entity retrieval. Entity models are also used in other fields besides entity retrieval. For example, entity topic models are used to perform entity prediction, classification of entity pairs, construction of entityentity network (Newman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by searc</context>
</contexts>
<marker>Macdonald, Ounis, 2006</marker>
<rawString>Craig Macdonald and Iadh Ounis. 2006. Voting for candidates: adapting data fusion techniques for an expert search task. In Proceedings of the 15th ACM International Conference on Information and Knowledge Management, pages 387–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Karl Schultz</author>
<author>Sameer Singh</author>
</authors>
<title>FACTORIE: Probabilistic programming via imperatively defined factor graphs.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS),</booktitle>
<pages>1249--1257</pages>
<contexts>
<context position="25921" citStr="McCallum et al., 2009" startWordPosition="4330" endWordPosition="4333">cle is then segmented to a list of sentences, which are considered as factoid descriptions regarding the entity. For the BM25 model, all the descriptions about an entity are aggregated into an entity pseudodocument. For the MLMtc model, the title field is constructed by combining DBpedia properties whose property names are ending with “title”, “name” or “label”, such as “fullName” (Neumayer et al., 2012), and the content field is the same as the entity pseudo-document used in the BM25 model. The inference algorithm for the entity factoid hierarchy is implemented based on the factorie package (McCallum et al., 2009). The parameters used in the inference are manually tuned on a small set of entities. The retrieval algorithms, including BM25 and Language Modeling, are implemented based on Apache Lucene1. For language models, Bayesian smoothing with Dirichlet priors is used, with parameter µ = 2000. For FRM, to cluster the entity descriptions, we use the K-Means clustering algorithm implemented in Carrot22. 4.4 Results We report two standard retrieval measures: mean average precision (MAP) and precision at 10 (P@10). Top 100 ranked entities are evaluated for each query. Two set of experiments are conducted:</context>
</contexts>
<marker>McCallum, Schultz, Singh, 2009</marker>
<rawString>Andrew McCallum, Karl Schultz, and Sameer Singh. 2009. FACTORIE: Probabilistic programming via imperatively defined factor graphs. In Neural Information Processing Systems (NIPS), pages 1249– 1257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Neumayer</author>
<author>Krisztian Balog</author>
<author>Kjetil Nrvg</author>
</authors>
<title>When simple is (more than) good enough: Effective semantic search with (almost) no semantics.</title>
<date>2012</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>540--543</pages>
<contexts>
<context position="2363" citStr="Neumayer et al., 2012" startWordPosition="365" endWordPosition="368">d in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representations to compute the rank of the candidate entities for a given entity query. These models include fielded versions of BM25 and Mixture of Language Models (Neumayer et al., 2012), Entity Language Model (Raghavan et al., 2004), Hierarchical Expert Model (Petkova and Croft, 2006), Structured Positional Entity Language Model (Lu et al., 2013). However, a closer examination of entity queries reveals that most of them are not simple uniform word samples from the “entity pseudo-document”. Instead, they can be decomposed into multiple parts, where each part describes a fact about target entities. For example, the query “National capitals situated on islands” describes two facts regarding a target entity: it is a national capital; it is located on an island. Compared to the a</context>
<context position="22484" citStr="Neumayer et al., 2012" startWordPosition="3755" endWordPosition="3758">variants of our model For comparison, we have implemented the following two existing models: • BM25. BM25 is a popular document retrieval method and also used to perform entity retrieval (Balog and Neumayer, 2013). All the descriptions about an entity are aggregated into an entity pseudo-document. We use ki = 1.2, b = 0.8 for the model parameter, similar to the original papers. • MLM-tc. The Mixture of Language Model represents an entity as a document with multiple fields, where each field is given a different weight for generating the query terms. MLM is often adopted to do entity retrieval (Neumayer et al., 2012). Here we adopt the MLM-tc model used in (Balog and Neumayer, 2013), where two fields are considered: title and content fields (described in Section 4.3). The parameters used are 0.8 for the title field and 0.2 for the content field. Note that both MLM-tc and BM25 are also compared in (Balog and Neumayer, 2013), and have shown the best MAP performances among all the compared models. For our models, the following two variants are implemented and compared. • Factoid Retrieval Model with Hierarchy (FRMwH). Our full model uses entity factoid graph as entity representation. Each factoid node is ind</context>
<context position="25706" citStr="Neumayer et al., 2012" startWordPosition="4295" endWordPosition="4298"> .1910 .1910 .2491 .2491 .1554 .1554 ✿✿✿ ✿✿✿ ✿✿✿ ✿✿✿✿ ✿✿✿ ✿✿✿✿ ✿✿✿ ✿✿✿ ✿✿✿ ✿✿✿ Table 1: Retrieval performance for various models removed since the information is already well captured in DBpedia. Each Wikipedia article is then segmented to a list of sentences, which are considered as factoid descriptions regarding the entity. For the BM25 model, all the descriptions about an entity are aggregated into an entity pseudodocument. For the MLMtc model, the title field is constructed by combining DBpedia properties whose property names are ending with “title”, “name” or “label”, such as “fullName” (Neumayer et al., 2012), and the content field is the same as the entity pseudo-document used in the BM25 model. The inference algorithm for the entity factoid hierarchy is implemented based on the factorie package (McCallum et al., 2009). The parameters used in the inference are manually tuned on a small set of entities. The retrieval algorithms, including BM25 and Language Modeling, are implemented based on Apache Lucene1. For language models, Bayesian smoothing with Dirichlet priors is used, with parameter µ = 2000. For FRM, to cluster the entity descriptions, we use the K-Means clustering algorithm implemented i</context>
</contexts>
<marker>Neumayer, Balog, Nrvg, 2012</marker>
<rawString>Robert Neumayer, Krisztian Balog, and Kjetil Nrvg. 2012. When simple is (more than) good enough: Effective semantic search with (almost) no semantics. In Advances in Information Retrieval, pages 540–543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Chaitanya Chemudugunta</author>
<author>Padhraic Smyth</author>
</authors>
<title>Statistical entity-topic models.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>680--686</pages>
<contexts>
<context position="30240" citStr="Newman et al., 2006" startWordPosition="5020" endWordPosition="5023">directly. Most of these models are originally proposed for expertise retrieval, where the appearance of a person name indicates the association with the expertise mentioned in the same document. Typical models include voting model (Macdonald and Ounis, 2006), graph model (Serdyukov et al., 2008), etc. However, it is not easy to generalize these models for open domain entity retrieval. Entity models are also used in other fields besides entity retrieval. For example, entity topic models are used to perform entity prediction, classification of entity pairs, construction of entityentity network (Newman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by search engines to support inverse lookup of words and phrases (Risvik et al., 2003; Bergsma and Wang, 2007). Our use of query decomposition is quite different compared to query segmentation. Besides query segmentation, query decomposition has also been used to facilitate the acquisition and optimization of high-order contextual term associations (Song et al., 2012)</context>
</contexts>
<marker>Newman, Chemudugunta, Smyth, 2006</marker>
<rawString>David Newman, Chaitanya Chemudugunta, and Padhraic Smyth. 2006. Statistical entity-topic models. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 680–686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Petkova</author>
<author>W B Croft</author>
</authors>
<title>Hierarchical language models for expert finding in enterprise corpora.</title>
<date>2006</date>
<booktitle>In Tools with Artificial Intelligence,</booktitle>
<pages>599--608</pages>
<contexts>
<context position="2463" citStr="Petkova and Croft, 2006" startWordPosition="380" endWordPosition="383">ong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representations to compute the rank of the candidate entities for a given entity query. These models include fielded versions of BM25 and Mixture of Language Models (Neumayer et al., 2012), Entity Language Model (Raghavan et al., 2004), Hierarchical Expert Model (Petkova and Croft, 2006), Structured Positional Entity Language Model (Lu et al., 2013). However, a closer examination of entity queries reveals that most of them are not simple uniform word samples from the “entity pseudo-document”. Instead, they can be decomposed into multiple parts, where each part describes a fact about target entities. For example, the query “National capitals situated on islands” describes two facts regarding a target entity: it is a national capital; it is located on an island. Compared to the assumption in document retrieval models, where query terms are assumed to be generated from a single </context>
</contexts>
<marker>Petkova, Croft, 2006</marker>
<rawString>D. Petkova and W.B. Croft. 2006. Hierarchical language models for expert finding in enterprise corpora. In Tools with Artificial Intelligence, 2006. ICTAI ’06. 18th IEEE International Conference on, pages 599–608, Nov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pound</author>
<author>Peter Mika</author>
<author>Hugo Zaragoza</author>
</authors>
<title>Ad-hoc object retrieval in the web of data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web, WWW ’10,</booktitle>
<pages>771--780</pages>
<contexts>
<context position="31488" citStr="Pound et al., 2010" startWordPosition="5220" endWordPosition="5223">the information extraction and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or cluster relation without referring to some ontology, such as OpenIE (Etzioni et al., 2011). Though our main goal is not on constructing a complete knowledge base, we do leverage both existing knowledge bases as well as free text data. Semantic search also targets on returning answers directly (Pound et al., 2010; Blanco et al., 2011; Tonon et al., 2012; Kahng and Lee, 2012). However, they are mainly based on structured linked data, as well as structured query language like SPARQL. While this is an effective approach if we have a powerful thorough knowledge base, in practice many facts cannot be effectively represented as linked data. Only a small set of relations (thousands in DBpedia) have been defined in the ontology, such as “birthPlace”. Furthermore, even if we can define a formal representation of human knowledge, retrieve them effectively is still a problem due to the difficulty of transforming</context>
</contexts>
<marker>Pound, Mika, Zaragoza, 2010</marker>
<rawString>Jeffrey Pound, Peter Mika, and Hugo Zaragoza. 2010. Ad-hoc object retrieval in the web of data. In Proceedings of the 19th international conference on World wide web, WWW ’10, pages 771–780.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hema Raghavan</author>
<author>James Allan</author>
<author>Andrew Mccallum</author>
</authors>
<title>An exploration of entity models, collective classification and relation description.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD Workshop on Link Analysis and Group Detection,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="2410" citStr="Raghavan et al., 2004" startWordPosition="372" endWordPosition="375">rants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representations to compute the rank of the candidate entities for a given entity query. These models include fielded versions of BM25 and Mixture of Language Models (Neumayer et al., 2012), Entity Language Model (Raghavan et al., 2004), Hierarchical Expert Model (Petkova and Croft, 2006), Structured Positional Entity Language Model (Lu et al., 2013). However, a closer examination of entity queries reveals that most of them are not simple uniform word samples from the “entity pseudo-document”. Instead, they can be decomposed into multiple parts, where each part describes a fact about target entities. For example, the query “National capitals situated on islands” describes two facts regarding a target entity: it is a national capital; it is located on an island. Compared to the assumption in document retrieval models, where q</context>
</contexts>
<marker>Raghavan, Allan, Mccallum, 2004</marker>
<rawString>Hema Raghavan, James Allan, and Andrew Mccallum. 2004. An exploration of entity models, collective classification and relation description. In Proceedings of KDD Workshop on Link Analysis and Group Detection, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K M Risvik</author>
<author>T Mikolajewski</author>
<author>P Boros</author>
</authors>
<title>Query segmentation for web search.</title>
<date>2003</date>
<booktitle>In Proceedings of the Twelfth International World Wide Web Conference (Poster session).</booktitle>
<contexts>
<context position="30555" citStr="Risvik et al., 2003" startWordPosition="5073" endWordPosition="5076">s not easy to generalize these models for open domain entity retrieval. Entity models are also used in other fields besides entity retrieval. For example, entity topic models are used to perform entity prediction, classification of entity pairs, construction of entityentity network (Newman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by search engines to support inverse lookup of words and phrases (Risvik et al., 2003; Bergsma and Wang, 2007). Our use of query decomposition is quite different compared to query segmentation. Besides query segmentation, query decomposition has also been used to facilitate the acquisition and optimization of high-order contextual term associations (Song et al., 2012). Our work is also related to the information extraction and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehman</context>
</contexts>
<marker>Risvik, Mikolajewski, Boros, 2003</marker>
<rawString>K. M. Risvik, T. Mikolajewski, and P. Boros. 2003. Query segmentation for web search. In Proceedings of the Twelfth International World Wide Web Conference (Poster session).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Serdyukov</author>
<author>Henning Rode</author>
<author>Djoerd Hiemstra</author>
</authors>
<title>Modeling multi-step relevance propagation for expert finding.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th ACM Conference on Information and Knowledge Mining,</booktitle>
<pages>1133--1142</pages>
<contexts>
<context position="29916" citStr="Serdyukov et al., 2008" startWordPosition="4967" endWordPosition="4970">k of supporting descriptions in Wikipedia and DBpedia. 5 Related Work Besides the entity retrieval models reviewed in Section 1, there are models that do not maintain an explicit entity representation. Instead, they compute the entity relevance score based on the co-occurance between entities and query terms in the documents directly. Most of these models are originally proposed for expertise retrieval, where the appearance of a person name indicates the association with the expertise mentioned in the same document. Typical models include voting model (Macdonald and Ounis, 2006), graph model (Serdyukov et al., 2008), etc. However, it is not easy to generalize these models for open domain entity retrieval. Entity models are also used in other fields besides entity retrieval. For example, entity topic models are used to perform entity prediction, classification of entity pairs, construction of entityentity network (Newman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by search engines to support inverse lookup of</context>
</contexts>
<marker>Serdyukov, Rode, Hiemstra, 2008</marker>
<rawString>Pavel Serdyukov, Henning Rode, and Djoerd Hiemstra. 2008. Modeling multi-step relevance propagation for expert finding. In Proceeding of the 17th ACM Conference on Information and Knowledge Mining, pages 1133–1142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>Andrew McCallum</author>
</authors>
<title>Large-scale cross-document coreference using distributed inference and hierarchical models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>793--803</pages>
<contexts>
<context position="10411" citStr="Singh et al., 2011" startWordPosition="1676" endWordPosition="1679">expressed in one or two sentences. For example, the factoid that Obama is elected president in 2008 may be described in many sentences and in different contexts; while the factoid that Obama is born in Kapiolani Maternity &amp; Gynecological Hospital is only mentioned in a few sentences. In this case, factoid nodes associated with more details may have deeper hierarchical structure. 2.2 Factor Graph Model To construct the entity factoid hierarchy, we make use of a hierarchical discriminative factor graph model. A similar factor graph model has been proposed to solve the coreference resolution in (Singh et al., 2011; Wick et al., 2012). Here we design a factor graph model corresponding to the entity factoid hierarchy, together with new factor types and inference mechanism. Generally speaking, a factor graph is composed of two parts: a set of random variables and a set of factors that model the dependencies between random variables. An example of the factor graph construction corresponding to the factoid hierarchy involved in Figure 1 is given in Figure 2. In our factor graph approach, each factoid is represented as a random variable fz, corresponding to a rounded square node in Figure 2. The pairwise bin</context>
</contexts>
<marker>Singh, Subramanya, Pereira, McCallum, 2011</marker>
<rawString>Sameer Singh, Amarnag Subramanya, Fernando Pereira, and Andrew McCallum. 2011. Large-scale cross-document coreference using distributed inference and hierarchical models. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 793–803.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dawei Song</author>
<author>Qiang Huang</author>
<author>Peter Bruza</author>
<author>Raymond Lau</author>
</authors>
<title>An aspect query language model based on query decomposition and high-order contextual term associations.</title>
<date>2012</date>
<journal>Comput. Intell.,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>23</pages>
<contexts>
<context position="30840" citStr="Song et al., 2012" startWordPosition="5115" endWordPosition="5118">wman et al., 2006), as well as entity linking (Han and Sun, 2012). These models are not suitable for our retrieval framework. The decomposing of entity queries into factoid queries is related to query segmentation. Query segmentation has been used by search engines to support inverse lookup of words and phrases (Risvik et al., 2003; Bergsma and Wang, 2007). Our use of query decomposition is quite different compared to query segmentation. Besides query segmentation, query decomposition has also been used to facilitate the acquisition and optimization of high-order contextual term associations (Song et al., 2012). Our work is also related to the information extraction and knowledge representation field since our framework involves extraction and aggregation of knowledge from free texts. However, most existing approaches takes two extreme ways: either extract relations based on pre-defined ontology, such as DBpedia (Lehmann et al., 2014); or cluster relation without referring to some ontology, such as OpenIE (Etzioni et al., 2011). Though our main goal is not on constructing a complete knowledge base, we do leverage both existing knowledge bases as well as free text data. Semantic search also targets o</context>
</contexts>
<marker>Song, Huang, Bruza, Lau, 2012</marker>
<rawString>Dawei Song, Qiang Huang, Peter Bruza, and Raymond Lau. 2012. An aspect query language model based on query decomposition and high-order contextual term associations. Comput. Intell., 28(1):1– 23, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alberto Tonon</author>
<author>Gianluca Demartini</author>
<author>Philippe Cudr´e-Mauroux</author>
</authors>
<title>Combining inverted indices and structured search for ad-hoc object retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12,</booktitle>
<pages>125--134</pages>
<marker>Tonon, Demartini, Cudr´e-Mauroux, 2012</marker>
<rawString>Alberto Tonon, Gianluca Demartini, and Philippe Cudr´e-Mauroux. 2012. Combining inverted indices and structured search for ad-hoc object retrieval. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12, pages 125–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiuyue Wang</author>
<author>Jinglin Kang</author>
</authors>
<title>Integrated retrieval over structured and unstructured data.</title>
<date>2012</date>
<pages>42--44</pages>
<editor>In Pamela Forner, Jussi Karlgren, and Christa Womser-Hacker, editors, CLEF (Online</editor>
<contexts>
<context position="1586" citStr="Wang and Kang, 2012" startWordPosition="242" endWordPosition="245">le-try Metropolis algorithm. Entity retrieval is performed by decomposing entity queries and computing the query likelihood on the entity factoid hierarchy. Using an array of benchmark datasets, we demonstrate that our proposed framework significantly improves the retrieval performance over existing models. 1 Introduction Entity retrieval, which aims at returning specific entities to directly answer a user’s query, has drawn much attention these years. Various entity retrieval tasks have been proposed, such as TREC Entity (Balog et al., 2012; Wang et al., 2011) and INEX-LD (Wang et al., 2012; Wang and Kang, 2012). Many existing entity retrieval models follow the document retrieval assumption: when issuing queries, users choose the words that may ∗ The work described in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representat</context>
</contexts>
<marker>Wang, Kang, 2012</marker>
<rawString>Qiuyue Wang and Jinglin Kang. 2012. Integrated retrieval over structured and unstructured data. In Pamela Forner, Jussi Karlgren, and Christa Womser-Hacker, editors, CLEF (Online Working Notes/Labs/Workshop), pages 42–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhanyi Wang</author>
<author>Wenlong Lv</author>
<author>Heng Li</author>
<author>Wenyuan Zhou</author>
<author>Li Zhang</author>
<author>Xiao Mo</author>
<author>Liaoming Zhou</author>
<author>Weiran Xu</author>
<author>Guang Chen</author>
<author>Jun Guo</author>
</authors>
<title>entity track: Related entity finding and entity list completion.</title>
<date>2011</date>
<journal>PRIS at TREC</journal>
<booktitle>In TREC.</booktitle>
<contexts>
<context position="1533" citStr="Wang et al., 2011" startWordPosition="232" endWordPosition="235">r graph is achieved by a modified variant of Multiple-try Metropolis algorithm. Entity retrieval is performed by decomposing entity queries and computing the query likelihood on the entity factoid hierarchy. Using an array of benchmark datasets, we demonstrate that our proposed framework significantly improves the retrieval performance over existing models. 1 Introduction Entity retrieval, which aims at returning specific entities to directly answer a user’s query, has drawn much attention these years. Various entity retrieval tasks have been proposed, such as TREC Entity (Balog et al., 2012; Wang et al., 2011) and INEX-LD (Wang et al., 2012; Wang and Kang, 2012). Many existing entity retrieval models follow the document retrieval assumption: when issuing queries, users choose the words that may ∗ The work described in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining v</context>
</contexts>
<marker>Wang, Lv, Li, Zhou, Zhang, Mo, Zhou, Xu, Chen, Guo, 2011</marker>
<rawString>Zhanyi Wang, Wenlong Lv, Heng Li, Wenyuan Zhou, Li Zhang, Xiao Mo, Liaoming Zhou, Weiran Xu, Guang Chen, and Jun Guo. 2011. PRIS at TREC 2011 entity track: Related entity finding and entity list completion. In TREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiuyue Wang</author>
<author>Jaap Kamps</author>
<author>Georgina Ramirez Camps</author>
<author>Maarten Marx</author>
<author>Anne Schuth</author>
<author>Martin Theobald</author>
<author>Sairam Gurajada</author>
<author>Arunav Mishra</author>
</authors>
<title>Overview of the inex 2012 linked data track.</title>
<date>2012</date>
<booktitle>In CLEF (Online Working Notes/Labs/Workshop).</booktitle>
<contexts>
<context position="1564" citStr="Wang et al., 2012" startWordPosition="238" endWordPosition="241">d variant of Multiple-try Metropolis algorithm. Entity retrieval is performed by decomposing entity queries and computing the query likelihood on the entity factoid hierarchy. Using an array of benchmark datasets, we demonstrate that our proposed framework significantly improves the retrieval performance over existing models. 1 Introduction Entity retrieval, which aims at returning specific entities to directly answer a user’s query, has drawn much attention these years. Various entity retrieval tasks have been proposed, such as TREC Entity (Balog et al., 2012; Wang et al., 2011) and INEX-LD (Wang et al., 2012; Wang and Kang, 2012). Many existing entity retrieval models follow the document retrieval assumption: when issuing queries, users choose the words that may ∗ The work described in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK (Project Code: 4055034). appear in the “entity pseudo-document”. Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and</context>
</contexts>
<marker>Wang, Kamps, Camps, Marx, Schuth, Theobald, Gurajada, Mishra, 2012</marker>
<rawString>Qiuyue Wang, Jaap Kamps, Georgina Ramirez Camps, Maarten Marx, Anne Schuth, Martin Theobald, Sairam Gurajada, and Arunav Mishra. 2012. Overview of the inex 2012 linked data track. In CLEF (Online Working Notes/Labs/Workshop).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wick</author>
<author>Sameer Singh</author>
<author>Andrew McCallum</author>
</authors>
<title>A discriminative hierarchical model for fast coreference at large scale.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>379--388</pages>
<contexts>
<context position="10431" citStr="Wick et al., 2012" startWordPosition="1680" endWordPosition="1683">two sentences. For example, the factoid that Obama is elected president in 2008 may be described in many sentences and in different contexts; while the factoid that Obama is born in Kapiolani Maternity &amp; Gynecological Hospital is only mentioned in a few sentences. In this case, factoid nodes associated with more details may have deeper hierarchical structure. 2.2 Factor Graph Model To construct the entity factoid hierarchy, we make use of a hierarchical discriminative factor graph model. A similar factor graph model has been proposed to solve the coreference resolution in (Singh et al., 2011; Wick et al., 2012). Here we design a factor graph model corresponding to the entity factoid hierarchy, together with new factor types and inference mechanism. Generally speaking, a factor graph is composed of two parts: a set of random variables and a set of factors that model the dependencies between random variables. An example of the factor graph construction corresponding to the factoid hierarchy involved in Figure 1 is given in Figure 2. In our factor graph approach, each factoid is represented as a random variable fz, corresponding to a rounded square node in Figure 2. The pairwise binary decision variabl</context>
</contexts>
<marker>Wick, Singh, McCallum, 2012</marker>
<rawString>Michael Wick, Sameer Singh, and Andrew McCallum. 2012. A discriminative hierarchical model for fast coreference at large scale. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 379–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wick</author>
<author>Sameer Singh</author>
<author>Harshal Pandya</author>
<author>Andrew McCallum</author>
</authors>
<title>A joint model for discovering and linking entities.</title>
<date>2013</date>
<booktitle>In CIKM 2013 Workshop on Automated Knowledge Base Construction,</booktitle>
<pages>67--72</pages>
<contexts>
<context position="14950" citStr="Wick et al., 2013" startWordPosition="2467" endWordPosition="2470"> the factoid hierarchy. A factoid node should not have too many levels. We define the depth penalty as: −w3 · |nd − ||d||0 s|, (4) where nd is the depth of a factoid node and s is the parameter that controls the average depth of factoid nodes per term. In this way, we can control the average depth of factoid nodes in the entity factoid hierarchy. 2.4 Inference Exact inference is impossible for our factor graph model due to the large state space. Here we adopt a modified variant of Multiple-try Metropolis algorithm to conduct maximum probability estimation for inference, following the work in (Wick et al., 2013). At each sampling step, multiple changes to the current setting are proposed. The acceptance probability for a given proposal is equal to the likelihood ratio of the proposed hypothesis to the current hypothesis. In our case, we initialize the MCMC procedure to the singleton configuration, where each entity description, such as a sentence or a RDF triple, forms its own factoid hierarchy initially. At each sampling step, we randomly select two nodes and propose several alternative local modifications. If fi and fj are not connected, i.e., sharing no common child nodes, the following changes ar</context>
</contexts>
<marker>Wick, Singh, Pandya, McCallum, 2013</marker>
<rawString>Michael Wick, Sameer Singh, Harshal Pandya, and Andrew McCallum. 2013. A joint model for discovering and linking entities. In CIKM 2013 Workshop on Automated Knowledge Base Construction, pages 67–72.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>