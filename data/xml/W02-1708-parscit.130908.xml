<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.939106">
Annotating the Semantic Web Using Natural Language
</title>
<author confidence="0.883494">
Boris Katz Jimmy Lin
</author>
<note confidence="0.501185">
MIT Artificial Intelligence Laboratory
200 Technology Square
Cambridge, MA 02139, USA
</note>
<bodyText confidence="0.381518">
{boris , j immylin}@ai .mit . edu
</bodyText>
<sectionHeader confidence="0.887997" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999812277777778">
Because the ultimate purpose of the Semantic Web
is to help users better locate, organize, and process
content, we believe that it should be grounded in the
information access method humans are most com-
fortable with natural language. However, the Re-
source Description Framework (RDF), the founda-
tion of the Semantic Web, was designed to be eas-
ily processed by computers, not humans. To render
RDF more friendly to humans, we propose to aug-
ment it with natural language annotations, or meta-
data written in everyday language. We argue that
natural language annotations, parsed into computer-
readable representations, are not only intuitive and
effective, but can also accelerate the pace with which
the Semantic Web is being adopted. We believe that
our technology can facilitate a happy marriage be-
tween natural language technology and the Semantic
Web vision.
</bodyText>
<sectionHeader confidence="0.996303" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963703703704">
The vision of the Semantic Web (Berners-Lee et
al., 2001) is to convert existing Web information
into a more machine-readable form, with the goal
of making the Web more effective for users. This
goal grew out of the recognition that a wealth of
information readily exists today in electronic form:
however, since this information lacks any machine-
understandable semantics, it cannot be easily pro-
cessed by computer systems.
Fundamentally, Semantic Web research is at-
tempting to address the problem of information ac-
cess: building systems that help users locate, collate,
compare, and cross-reference content. As such, we
believe that the Semantic Web should be motivated
by and grounded in the method of information access
most comfortable to users natural language. Nat-
ural language is intuitive, easy to use and rapidly
deployable, and requires no specialized training. In
our vision, the Semantic Web will be equally acces-
sible by computers using specialized languages and
interchange formats, and humans using natural lan-
guage. The scenario of being able to ask a computer
&amp;quot;when was the president of Taiwan born,&amp;quot; or &amp;quot;Find
me the cheapest vacation package in the Bahamas
this month&amp;quot; and getting back &amp;quot;just the right infor-
mation&amp;quot; is very appealing.
Because the first step to building the Seman-
tic Web is to transform existing sources (stored
as HTML pages, in legacy databases, etc.) into a
machine-understandable form (i.e., XML/RDF), it
is sometimes at odds with a human-based natural
language view of the world. Although the gen-
eral framework of the Semantic Web includes pro-
visions for natural language technology, the actual
deployment of such technology remains largely un-
explored. In an effort to exploit the synergistic op-
portunities between the Semantic Web and natural
language techniques, we propose three mechanisms
for seamlessly integrating natural language tech-
nology into the Resource Description Framework.
The first involves augmenting RDF property defi-
nitions. The second involves creating information
access schemata to bridge the gap between language
and RDF. The third mechanism proposes further
extensions that attempt to mirror human question
answering behavior in the form of natural language
query plans.&amp;quot; All these mechanisms are based on
the concept of natural language annotations, a tech-
nique which we have pioneered in the last decade.
This technology has already been successfully used
in START. the first question answering system avail-
able on the World Wide Web, and we believe that it
provides a simple mechanism to marry natural lan-
guage technology and the Semantic Web.
</bodyText>
<sectionHeader confidence="0.950266" genericHeader="introduction">
2 Natural Language Annotations
</sectionHeader>
<bodyText confidence="0.938846545454546">
Use of metadata is a common technique for render-
ing information fragments more tenable to process-
ing by computer systems. Using natural language
itself as metadata presents several additional advan-
tages: it preserves human readability, allows for easy
querying, and encourages non-expert users to en-
gage in metadata creation. To this end, we have b &apos;b
de-
veloped natural language annotations (Katz, 1997),
which are machine-parsable sentences and phrases
that describe the content of various information seg-
ments. These annotations serve as metadata to de-
scribe the kinds of questions that a particular piece
of knowledge is capable of answering.
To illustrate how this technology works, consider
the following paragraph about Joseph Brodsky:
&amp;quot;For an all-embracing authorship, imbued
with clarity of thought and poetic intensity,&amp;quot;
Joseph Brodsky was awarded the 1987 Nobel
Prize in Literature.
This paragraph may be annotated with the follow-
ing:
</bodyText>
<table confidence="0.853163">
Joseph Brodsky was awarded the Nobel Prize
for Literature in 1987.
1987 Nobel Prize for Literature
</table>
<bodyText confidence="0.995816743589743">
A question answering system would parse these
two annotations and store the parsed structures
(e.g., ternary expressions (Katz, 1988)) with point-
ers back to the original information segment. To
answer a question, the user query, parsed into the
same type of structures, would be compared against
the annotations stored in the knowledge base. Be-
cause this match would occur at the level of parsed
representations, linguistically sophisticated machin-
ery such as synonymy/hyponymy relations, ontolo-
gies, and structural transformation rules (e.g., &amp;quot;S-
Rules&amp;quot; (Katz, 1997; Katz and Levin, 1988)) could
be brought to bear on the matching process. If a
match were found, the segment corresponding to
the annotation would be returned to the user as
the answer. Because sophisticated natural language
processing could be invoked in matching questions
with annotations, precision far beyond that of stan-
dard keyword-based information retrieval techniques
could be achieved. In addition, a linguistically-based
system allows for variations in user queries, e.g., al-
ternate formulations, active/passive voice, nominal-
izations, etc. To give a more concrete example, the
annotations above would allow a question answering
system to answer the following questions (see Fig-
ure 1 for an example):
What prize did Brodsky receive in 1987?
Who was awarded the Nobel Prize for Litera-
ture in 1987?
Tell me about the winner of the 1987 Nobel
Prize for Literature.
Who was the Nobel Prize for Literature given
to in 1987?
An important feature of the annotation concept
is that any information segment can be annotated:
not only text, but also images, multimedia, database
queries, and even procedures.
We have implemented the above technology in
START&apos; (Katz, 1988; Katz, 1997), the first question
</bodyText>
<page confidence="0.304023">
lhttp://www.ai.mit.edu/projects/infolab
</page>
<table confidence="0.986089333333333">
0 Netscape:START&apos;s reply M
B
START&apos;s reply il
===&gt; Who won the Nobel Prize for Literature in 1987?
Pr
The Nobel Prize in
li Literature 1987 &apos;el Ii*&amp;quot;
..
for an all-embracing authorship, imbued A
with clarity of thought and poetic intensity&amp;quot; &apos;Al
Joseph Brodsky
USA
b.1940
Source Nobel e-Museuin d.1996
-..., &apos;.&apos; C4 •e.-...1::&apos;
</table>
<figureCaption confidence="0.998762">
Figure 1: START answering the question &amp;quot;Who won
the Nobel Prize for Literature in 1987?&amp;quot;
Figure 2: START answering the question &amp;quot;Who wrote
</figureCaption>
<bodyText confidence="0.977703625">
the screenplay for Good Will Hunting?&amp;quot; by extract-
ing information from the Internet Movie Database
and generating an appropriate response.
answering system available on the World Wide Web.
Since it came online in December 1993, START has
engaged in exchanges with hundreds of thousands of
users all over the world, supplying them with use-
ful knowledge. Currently, our system can answer
millions of natural language questions about places
(e.g., cities, countries, lakes; coordinates, weather,
maps, demographics, political and economic sys-
tems), movies (e.g., titles, actors, directors), peo-
ple (e.g., birth dates, biographies), dictionary defi-
nitions, and much, much more.
In order to give START uniform access to
semistructured resources on the Web, we have
created Omnibase (Katz et al., 2002), a virtual
database that integrates numerous heterogeneous
Web sources under a single query interface. To
actually answer user questions, however, the gap
between natural language questions and structured
Omnibase queries must be bridged. Natural lan-
guage annotations serve as the enabling technology
that allows the integration of START and Omni-
</bodyText>
<figure confidence="0.677495">
Netscape: START&apos;s reply
START&apos;s reply
===&gt; Who wrote the screenplay for Good Will Hunting?
The script for Good Will Hunting (1997) was written by
Matt Damon and Ben Affleck.
Source: The Internet Movie Database
a=w-I -Ar,94a ••,:eJ
</figure>
<bodyText confidence="0.98055725">
&lt;rdfs:Class ID=&amp;quot;Country&amp;quot;› In 1997, we proposed to attach natural language
&lt;rdfs:comment&gt;A Country in the annotations to everything available on the Web
CIA Factbook&lt;/rdfs:comment&gt; (Katz, 1997). Furthermore, we described a dis-
&lt;/rdfs:Class&gt; tributed mechanism for knowledge gathering:
&lt;rdf:Property ID=&amp;quot;population&amp;quot;› By allowing thousands of people to build
&lt;rdfs:domain rdf:resource=&amp;quot;#Country&amp;quot;/&gt; up knowledge about knowledge, we will
&lt;rdfs:range rdf:resource=&amp;quot;xsd:string&amp;quot;/&gt; create a knowledge base of an interesting
&lt;nl:ann text=&amp;quot;Many people live in ?s&amp;quot;/&gt; form. The Web will continue to be built out
&lt;nl:ann text=&amp;quot;population of ?s&amp;quot;/&gt; of &amp;quot;opaque&amp;quot; information segments: text,
&lt;nl:gen text=&amp;quot;The population of ?s is ?o&amp;quot;/&gt; maps, charts, audio, video, etc.; but at-
&lt;/rdf:Property&gt; tached to each of these will be natural lan-
guage annotations that facilitate retrieval.
By giving humans access to relevant in-
formation that humans can further inter-
pret and understand, we will transform the
Web into an intelligent, high performance
knowledge base.
Figure 3: Augmenting an ontology about the CIA
World Factbook with natural language annotations.
base. Since annotations can describe arbitrary frag-
ments of knowledge, there is no reason why they
can&apos;t be employed to describe Omnibase queries.
In fact, annotations can be parameterized, that is,
they can contain symbols representative of an en-
tire class of objects. For example, the annotation &amp;quot;a
person wrote the screenplay for imdb-movie&amp;quot; can
be attached to an Omnibase query that retrieves
the writers for various movies from the Internet
Movie Database (IMDb).2 The symbol imdb-movie
serves as a placeholder for any one of the hundreds
of thousands of movies that IMDb contains infor-
mation about; when the annotation matches the
user question, the actual movie name is instanti-
ated and passed along to Omnibase After Omni-
base fetches the correct answer. START performs ad-
ditional postprocessing, e.g., natural language gen-
eration, to present the answer (see Figure 2).
3 Towards Human-friendly RDF
The Resource Description Framework (RDF) (Las-
sila and Swick, 1999; Brickley and Guha, 2002), the
standardized Semantic Web language for describing
metadata, was meant for consumption by comput-
ers, not humans. Given this philosophy, how can we
be sure that we&apos;re creating useful metadata? How
can we be sure that our ontologies mirror the way
users organize and think about content? Since the
final beneficiary of the Semantic Web should be the
average user, we advocate a human-centered organi-
zation of metadata3 grounded in natural language.
The Semantic Web provides many of the mech-
anisms required to realize this dream. In this pa-
per, we describe three concrete proposals for leverag-
ing Semantic Web research to accomplish our vision:
First, we propose to embed natural language anno-
tations directly in RDF property definitions to facil-
itate language-based querying. Second, we propose
the use of information access schemata, an extension
of the schemata currently being used by START, to
capture patterns of user requests. Third, we propose
even more &amp;quot;natural&amp;quot; (but somewhat less powerful)
information access schemata that would allow ordi-
nary users to become skillful knowledge engineers.
3.1 Simple Properties
The foundation of the Semantic Web rests on RDF
statements, which are essentially triples denoting ob-
jects, properties, and values. An alternative and of-
ten used description of RDF statements is in terms
of &amp;quot;subject,&amp;quot; &amp;quot;relation,&amp;quot; and &amp;quot;object,&amp;quot; revealing a
grammatical basis for RDF constructs. In fact, the
RDF triples are very similar, both in spirit and in
form, to our ternary expression representation of
natural language (Katz and Winston, 1982; Katz,
1988). We propose to make this connection more
explicit by augmenting rdf :Property definitions with
natural language annotations.
Figure 3 illustrates our proposal, using a fragment
of an ontology representing the CIA World Fact-
book.4 Intuitively, the population property is a re-
lation connecting a country to its population value.
Natural language annotations express this connec-
tion concretely in natural language sentences and
phrases, via the nl : ann property. For example, the
phrase &amp;quot;population of ?s&amp;quot; is linked to every RDF
statement involving the population property; ?s is
shorthand for indicating the subject (domain) of the
2http: !!www. imdb . com/
31t is true that many parts of the Semantic Web will never
have any contact with humans, and may be created only for
the benefit of software agents, e.g., inventory management
systems communicating with warehouses. For these applica-
tions, natural language may not be necessary. Nevertheless, a
large fraction of the Semantic Web involves end users, where
we believe natural language forms the best information access
medium.
4http://www.cia.gov/cia/publications/factbook/
relation. From this, a natural language-aware soft-
ware agent could answer the following English ques-
tions without forcing the user to learn and use pre-
cisely defined ontological terms:
How many people live in Kiribati?
What is the population of the Bahamas?
Tell me Guam&apos;s population.
In addition, the nl: gen property specifies a natural
language rendition of the knowledge. allowing soft-
ware agents to present meaningful. natural sounding
responses to users.
By &amp;quot;hooking&amp;quot; natural language annotations di-
rectly into RDF property definitions, we can not
only ensure that our ontologies &amp;quot;make sense&amp;quot; to a
user. but also provide natural language question an-
swering and generation capabilities with minimal ad-
ditional knowledge engineering overhead.
</bodyText>
<subsectionHeader confidence="0.944042">
3.2 Information Access Schemata
</subsectionHeader>
<bodyText confidence="0.996216545454546">
Despite the simplicity of adding natural language
annotations to RDF properties directly. there is a
significant restriction to the types of questions that
this technique can answer, namely, only one RDF
statement can be queried at once. We propose to
overcome this limitation by creating schemata that
capture similar patterns of information access. For
example, consider this &amp;quot;family&amp;quot; of questions:
What is the country in Africa with the largest
area?
Tell me what Asian country has the highest
population density.
What country in Europe has the lowest infant
mortality rate?
What is the most populated South American
country?
We propose to capture this &amp;quot;pattern&amp;quot; of informa-
tion requests in an information access schema, shown
in Figure 4. Here, natural language annotations are
employed to describe a pattern of RDF statements.5
More formally, an information access schema is a
quadruple:
</bodyText>
<listItem confidence="0.4850073">
• Annotations: natural language sentences (ei-
ther declarative or interrogative) or phrases
that describe the types of user questions this
schema can answer. These sentences and
phrases can contain special symbols that stand
in for whole classes of lexical items. e.g..
$country might stand in for any country in the
CIA World Factbook. This allows annotations
to be parameterized for greater knowledge cov-
erage.
</listItem>
<footnote confidence="0.9623295">
5Because annotations would be processed by linguistically-
sophisticated systems, different adjectives such as &amp;quot;highest&amp;quot;
and &amp;quot;largest&amp;quot; could be uniformly mapped onto the maximum
operation.
</footnote>
<figure confidence="0.925740578947368">
&lt;nl:InformationAccessSchema&gt;
&lt;nl:ann&gt;what country in $region has the
largest $attribute&lt;/n1:ann&gt;
&lt;nl:pattern&gt;?x a :Country&lt;/n1:pattern&gt;
&lt;nl:pattern&gt;?x map(Sattribute) ?val&lt;/n1:pattern&gt;
&lt;nl:pattern&gt;?x :location Sregion&lt;/n1:pattern&gt;
&lt;nl:action&gt;display(boundto(?x, max(?val)))
qui:action&gt;
&lt;nl:mapping&gt;
&lt;nl:hash variable=&amp;quot;Sattribute&amp;quot;&gt;
&lt;nl:map value=&amp;quot;population&amp;quot;›
:population
&lt;/n1:map&gt;
&lt;nl:map value=&amp;quot;area&amp;quot;›
area
&lt;/n1:map&gt;
qui:hash&gt;
qui:mapping&gt;
&lt;/n1:InformationAccessSchema&gt;
</figure>
<figureCaption confidence="0.9893805">
Figure 4: An information access schema for superla-
tives (for simplicity, only one annotation is shown.)
</figureCaption>
<listItem confidence="0.85925404">
• Pattern: a declarative pattern of RDF triples
(expressed in N3 (Berners-Lee. 2000) for sake
of brevity) that references a pre-existing ontol-
ogy. The patterns can contain the same special
symbols used in the annotations, as well as in-
troduce new unbound variables. Usually, the
pattern is written in such a way that when it is
satisfied, particular variables would be bound
to the answer.
• Action: a set of operators to further process
variables bound during the pattern matching
process. The actions could be as simple as dis-
playing the output, but allows for more complex
operations, e.g.. aggregation (count, average,
max, min. etc.). comparison (&lt;, &gt;, etc.). In order
to present users with natural sounding answers,
natural language generation may be involved.
• Mapping: an optional hash for specifying
the bindings between special symbols used in
the natural language annotations and RDF re-
sources. For example. the RDF property :area
might be lexicalized as &amp;quot;land area.&amp;quot; &amp;quot;area.&amp;quot; or
&amp;quot;size&amp;quot;; The mapping provides the mechanism for
handling this disjunction between lexical and
ontological terms.
</listItem>
<bodyText confidence="0.993533">
The schema, in Figure 4 could provide answers
to questions that involve region-specific superlative
comparison of countries in the world. The pattern
binds to the value of the particular attribute for
countries within the queried geographic region. and
the action specifies an aggregate operation (max-
imum) over the values bound within the pattern.
The country corresponding to that maximum value
is returned as the answer.6 The mapping provides
a, translation from (lexicalized) language attributes
to RDF properties. Note that information access
schemata, are written with respect to a, particular
pre-existing ontology; for this example. we assume
than an appropriate ontology has been established
(i.e„ :Country is defined as a, class, and :location is
defined as a, property).
In our vision of the Semantic Web, information ac-
cess schemata, grounded in natural language would
co-exist alongside RDF metadatkL These schemata,
could be distributed (e.g, embedded directly into
Web pages) or centralized; either way. a, software
agent would compile these schemata, into a, question
answering system capable of providing natural lan-
guageinformation access to users.
&apos;
Figure 5 provides another example of an informa-
tion access schema, that could allow a, linguistically
aware software agent to answer the following ques-
tions:
Is Canada&apos;s coastline longer than Russia&apos;s
coastline?
Which country has the larger population, Ger-
many or Japan?
Is Nigeria&apos;s population bigger than that of
South Africa?
Once again, a stylized language annotation de-
scribes an RDF knowledge fragment that contains
the answer. A specific sequence of commands ex-
tracts the information and returns it to the user.
</bodyText>
<subsectionHeader confidence="0.999796">
3.3 Going Further
</subsectionHeader>
<bodyText confidence="0.999945307692308">
Consider the question &amp;quot;what is the distance from
Japan to South Korea?&amp;quot; A reasonable answer would
be to compute the distance between their respec-
tive capitals. A person faced with this question
might first find the capitals of the two countries,
and then compute (or look up) the distance between
those cities. People generally have no difficulty de-
scribing in natural language a &amp;quot;plan&amp;quot; for answering
questions that require multiple operations from dif-
ferent sources. Could humans &amp;quot;teach&amp;quot; such plans
to a computer directly? Currently, the answer is
no, because existing mechanisms of knowledge ac-
quisition require familiarity with precise ontologies,
</bodyText>
<figure confidence="0.99649295">
&lt;nl:InformationAccessSchema&gt;
&lt;nl:ann4country-l&apos;s $att is larger
than $country-2&apos;s $att&lt;/n1:ann&gt;
&lt;nl:pattern&gt;?x a :Country&lt;/n1:pattern&gt;
&lt;nl:pattern&gt;?x map($att) ?val-1&lt;/n1:pattern&gt;
&lt;nl:pattern&gt;?y a :Country&lt;/n1:pattern&gt;
&lt;nl:pattern&gt;?y map($att) ?val-2&lt;/n1:pattern&gt;
&lt;nl:action&gt;display(gt(?val-1,?val-2))
qui:action&gt;
&lt;nl:mapping&gt;
&lt;nl:hash variable=&amp;quot;$attribute&amp;quot;&gt;
&lt;nl:map value=&amp;quot;population&amp;quot;›
:population
qui:map&gt;
&lt;nl:map value=&amp;quot;area&amp;quot;›
area
qui:map&gt;
qui:hash&gt;
qui:mapping&gt;
&lt;/n1:InformationAccessSchema&gt;
</figure>
<figureCaption confidence="0.969491">
Figure 5: An information access schema for compar-
isons
</figureCaption>
<figure confidence="0.9805083125">
&lt;nl:InformationPlanningSchema&gt;
&lt;nl:ann&gt;distance between $countryl
and $country2&lt;/ann&gt;
&lt;nl:plan&gt;
&lt;rdf:Seq&gt;
&lt;rdf:li&gt;what is the capital of $countryl
:= ?capitall&lt;/rdf:li&gt;
&lt;rdf:li&gt;what is the capital of $country2
:= ?capital2&lt;/rdf:li&gt;
&lt;rdf:li&gt;what is the distance between
?capitall and ?capital2
:= ?distance&lt;/rdf:li&gt;
&lt;/rdf:Seq&gt;
qui:plan&gt;
&lt;nl:action&gt;display(?distance)&lt;/n1:action&gt;
&lt;/n1:InformationPlanningSchema&gt;
</figure>
<figureCaption confidence="0.67824325">
6Although the answer in this schema is simply the country
name, it could be couched in a natural language generated
sentence for better presentation to the user.
Figure 6: An information planning schema,
</figureCaption>
<bodyText confidence="0.978276964285714">
something that cannot be realistically expected for
all users. Despite having plenty of common sense,
most users cannot become effective knowledge engi-
neers. We propose to utilize natural language anno-
tations to a,ddress this difficulty in imparting knowl-
edge to computers.
We think that &amp;quot;information planning schemata,&amp;quot;
an extension of the information access schemata,
technology described in the previous section, can
dramatically simplify the task of knowledge engi-
neering. An example of our proposal is shown in
Figure 6. Instead of writing RDF patterns, which
would require knowledge of domain-specific ontolo-
gies, we could use natural language itself to describe
the process of answering a question. The answer
plan (n1 :plan) reflects the user&apos;s thought process ex-
pressed in natural language: first find the capitals
of the countries, and then find the distance between
those cities.
The above example could answer the following
questions:
How far is the United States from Russia?
What&apos;s the distance between Germany and
England?
This method of specifying schemata essentially
serves to capture the intuitive thought patterns of
a human, and allows ordinary users to &amp;quot;teach&amp;quot; a,
computer knowledge using natural language.
</bodyText>
<subsectionHeader confidence="0.979216">
3.4 Integrating the Three Methods
</subsectionHeader>
<bodyText confidence="0.992486689655172">
The three proposed methods for integrating natural
language and RDF can be used together to afford
greater flexibility. Annotating RDF properties is a,
low-cost (from a knowledge engineering perspective)
way of providing natural language access to RDF
statements. Information access schemata, while
being more complex and requiring knowledge of
domain-specific ontologies, give experienced knowl-
edge engineers fine-grained tools for manipulating
RDF and controlling the output. Finally, informa-
tion planning schemata allow users to describe, in
natural language itself, how they would go about an-
swering a particular class of questions. These three
methods can combine to provide the foundation for
question answering on the Semantic Web.
Ultimately, the actual details of natural language
annotations should be hidden from the user behind
GUI authoring tools, so that he or she need not come
into direct contact with XML or RDF. Additionally,
an authoring tool could pre-parse the natural lan-
guage annotations and store those representations
(essentially triples themselves) alongside the a,nnota,-
tions.7 With both natural language and parsed rep-
resentations at their disposal, software agents would
71ATithout an authoring tool, such a scheme would not be
feasible because we cannot expect humans to manually gener-
ate parse structures. Note also that keeping natural language
have even greater flexibility in manipulating meta-
data.
</bodyText>
<sectionHeader confidence="0.893996" genericHeader="method">
4 Deploying the Semantic Web
</sectionHeader>
<bodyText confidence="0.984313714285714">
We believe that natural language annotations are
not only an intuitive and helpful extension to the
Semantic Web, but will assist in the deployment and
adoption of the Semantic Web itself. The primary
barrier to its creation is a classic chicken-and-egg
problem: people will not spend extra time marking
up their data unless they perceive a value for their
efforts, and meta,data, will not be useful until a &amp;quot;crit-
ical mass&amp;quot; has been achieved. Although researchers
have been focusing on technology to reduce barri-
ers to entry (via authoring tools, for example), such
initiative may not be sufficient to overcome the hur-
dles. As Hendler (Hendler, 2001) remarks, lower-
ing markup cost isn&apos;t enough; for many users, the
benefits of the Semantic Web should come for free.
Semantic markup should be a by-product of normal
computer use and there is no process of meta,data,
creation that is easier and more intuitive than the
use of natural language. By divorcing the major-
ity of users from the need to understand formal on-
tologies and a precisely defined vocabulary, we can
dramatically lower barrier-of-entry, easing the tra,n-
sition into the Semantic Web vision.
Our technology of information access schemata,
provides an annotation system suitable for different
levels of user experience. Novices to the Semantic
Web merely have to rationally elucidate the process
by which they come up with the answer to a particu-
lar set of questions, and then describe that plan in a,
form of stylized language. For more advanced users,
the ability to access RDF directly allows finer-tuned
control, greater flexibility, and more concise descrip-
tions.8
Ultimately, let us not forget that the purpose of
the Semantic Web is to benefit humans, not com-
puters. The original idea was that instead of wait-
ing for computers to become smart enough to solve
all the problems of understanding human language,
we should focus on the slightly less difficult prob-
lem of making human data more understandable to
computers. To this end, the foundations of the Se-
mantic Web are grounded in language. However, to
achieve interoperability and to facilitate interaction
between software agents, we&apos;ve had to sacrifice a lot
of human understandability precise ontologies and
formally defined semantics are foreign concepts to
the average user. By reintroducing natural language
annotations makes it possible for them to be re-analyzed later
as more powerful parsers become available.
</bodyText>
<footnote confidence="0.86780325">
8For example, expert users may be able to write schemata.
that parameterize across RDF properties (the equivalent of
verbs in natural language). This may be unnatural for novice
users, because it corresponds to higher order logics.
</footnote>
<bodyText confidence="0.999611333333333">
annotations and rendering the connection to human
language explicit, we can achieve a satisfying middle
ground between computer and human needs.
</bodyText>
<sectionHeader confidence="0.889159" genericHeader="method">
5 Patterns of Information Requests
</sectionHeader>
<bodyText confidence="0.999989676470588">
We have argued that natural language annotations
are a useful and flexible extension to the Semantic
Web. But &amp;quot;is it enough?&amp;quot; Specifically, can informa-
tion access schemata achieve broad enough knowl-
edge coverage to be useful? We believe the answer
is yes.
Natural language annotations can serve as more
than metadata; they can capture generalized pat-
terns of information access. As shown in the pre-
vious sections, our annotations can be parameter-
ized to encompass entire classes of questions. A
schema about the CIA Factbook in which the prop-
erties and countries are parameterized can answer
tens of thousands of potential questions. The cost of
writing schemata is not proportional to the number
of class instances, but rather the complexity of the
class itself. A single schema for the Internet Movie
Database, for example, could grant the user natu-
ral language access to over three hundred thousand
titles!
It is our experience that people ask the same types
of questions frequently. Analysis of the questions
from the TREC-9 (Voorhees and Tice, 2000) and
TREC-2001 (Voorhees, 2001) QA Track, a standard-
ized test set for question answering, reveals a ques-
tion distribution that qualitatively obeys Zipf&apos;s law:
a few high frequency query types account for a large
portion of all questions (Lin, 2002). Furthermore,
questions can often be modeled as database queries
(Katz et al., 2002) to simplify access. From these
observations, we can conclude that although infor-
mation access schemata require human effort, they
are nevertheless an effective way of achieving broad
knowledge coverage at reasonable costs.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="method">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999974">
We have described three concrete proposals for mak-
ing the Semantic Web friendly to computers and hu-
mans alike. All the pieces for the implementation of
our ideas already exist. START, our natural language
question answering system, has demonstrated for
nearly a decade that natural language annotations
are both useful and effective. Currently, schemat a,
in START can contain actual content (e.g., text and
images), procedures (e.g., to access the system clock
to tell time), or Omnibase queries (to access hetero-
geneous data from the Web). Generalizing this tech-
nology to the information access schemata we&apos;ve pro-
posed in Section 3.1 is a relatively straightforward
task.
Furthermore, all the machinery necessary to per-
form complex queries over RDF stores has already
been developed by other researchers. For example,
the RDF Query Language (RQL) (Karvounarakis et
al., 2002) provides a SQL-like query language for
accessing large amounts of RDF triples. More con-
cretely, the types of questions handled by annota-
tions in Figure 3 would ultimately translated in a,
declarative query like:
</bodyText>
<sectionHeader confidence="0.976302666666667" genericHeader="method">
SELECT Y
FROM {X}popnlation{y}
WHERE X = &apos;Taiwan&apos;
</sectionHeader>
<bodyText confidence="0.999993228571429">
In fact, RQL provides a rich set of comparison and
aggregation operators necessary to perform complex
queries, just like a standard RDBMS.
We are currently collaborating with the Haystack
Project (Adar et al., 1999; Huynh et al., 2002), part
of MIT&apos;s Project Oxygen,9 to implement the ideas
proposed here. Haystack is a personalized informa-
tion repository built on RDF, and we plan to use it
as a testbed for exploring the interactions between
natural language technology and the Semantic Web.
In addition to deploying these proposed technolo-
gies, we are also resegrchino. advanced methods for
decomposing complex natural language queries into
a series of simpler ones. For example, a question
like &amp;quot;When was the president of Russia born,&amp;quot; could
be broken down into two information seeking steps:
first, find out who the president of Russia is, and
then find out his or her birthdate. We could write
annotations that capture this reasoning directly, but
this would require far too many annotations to ac-
commodate every possible combination of proper-
ties. Instead, we would like to be able to perform
this question decomposition automatically, guided
by whatever ontologies are available; for example, we
would know that the president of a country is a per-
son, and that a person has a birthdate. With a little
bit of search, perhaps we could draw this connection
without manual intervention. Note, however, that
there are limitations to this approach; the example
givenFigure in Fio 6 cannot be broken down automat-
ically,
in this manner because it implicitly captures
the heuristic &amp;quot;since one cannot directly calculate the
distance between two countries, a reasonable answer
is to calculate the distance between their capitals.&amp;quot;
</bodyText>
<sectionHeader confidence="0.997665" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999868375">
Just like the development of the Semantic Web it-
self, early efforts to integrate natural language tech-
nology with the Semantic Web will no doubt be slow
and incremental. However, we believe that the three
mechanisms we&apos;ve proposed are a step in the right
direction. The final goal is truly alluring: an enor-
mous network of knowledge easily accessible by ma-
chines and humans alike.
</bodyText>
<footnote confidence="0.885273">
9http://oxygen.lcs.mit.edu/
</footnote>
<sectionHeader confidence="0.948805" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.998923625">
Thanks to Sue Feishin, David Huynh, Greg Marton,
Dennis Quan, and Vineet Sinha for their comments
on earlier drafts of this paper. We would also like
to thank two anonymous reviewers for their helpful
comments This research is funded by DARPA un-
der contract number F30602-00-1-0545 and admin-
istered by the Air Force Research Laboratory. Ad-
ditional funding is provided by the Oxygen Project.
</bodyText>
<sectionHeader confidence="0.998441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999218513888889">
Eytan Adar, David Karger, and Lynn Andrea Stein.
1999. Haystack: Per-user information environ-
ments. In Proceedings of the 1999 Conference on
Information and Knowledge Management.
Tim Berners-Lee, James Bendier, and Ora Lassila.
2001. The Semantic Web. Scientific American.
284(5):34-43.
Tim Berners-Lee. 2000. Primer: Getting into RDF
and Semantic Web using N3.
Dan Brickley and R.V. Guha. 2002. RDF vocabu-
lary description language 1.0: RDF Schema. W3C
Working Draft, World Wide Web Consortium,
April.
James Bendier. 2001. Agents and the Semantic
Web. IEEE Intelligent Systems. 16(2):30-37.
David Huynh, David Karger, and Dennis Quan.
2002. Haystack: A platform for creating, orga-
nizing and visualizing information using RDF.
In Proceedings of the Eleventh, World Wide Web
Conference Semantic Web Workshop.
Greg Karvounarakis, Sofia Alexaki, Vassilis
Christophides, Dimitris Plexousakis, and Michel
Scholl. 2002. RQL: A declarative query lan-
guage for RDF. In Proceedings of the Eleventh,
International World Wide Web Conference
(WWW2002).
Boris Katz and Beth Levin. 1988. Exploiting lexi-
cal regularities in designing natural language sys-
tems. In Proceedings of the 12th International
Conference on Computational Linguistics (COL-
INC &apos;88).
Boris Katz and Patrick H. Winston. 1982. Parsing
and generating English using commutative trans-
formations. Al Memo 677, MIT Artificial Intelli-
gence Laboratory.
Boris Katz, Jimmy Lin, and Sue Feishin 2001.
Gathering knowledge for a question answering sys-
tem from heterogeneous information sources. In
Proceedings of the ACL 2000 Workshop on Hu-
man Language Technology and Knowledge Man-
agement.
Boris Katz, Sue Feishin, Deniz Yuret, Ali Ibrahim,
Jimmy Lin, Gregory Marton, Alton Jerome Mc-
Farland, and Bans Temelkuran. 2002. Omnibase.
Uniform access to heterogeneous data as a com-
ponent of a natural language question answering
system. In Proceedings of the 7th International
Workshop on Applications of Natural Language to
Information Systems (NLDB 2002).
Boris Katz. 1988. Using English for indexing and
retrieving. In Proceedings of the 1st RIAO Con-
ference on User-Oriented Content-Based Text and
Image Handling (RIAO &apos;88).
Boris Katz. 1997. Annotating the World Wide Web
using natural language. In Proceedings of the 5th
RIAO Conference on Computer Assisted Informa-
tion Searching on the Internet (RIAO &apos;97).
Ora Lassila and Ralph R. Swick. 1999. Resource
Description Framework (RDF) model and syn-
tax specification. W3C Recommendation, World
Wide Web Consortium, February.
Jimmy J. Lin. 2002. The Web as a resource for ques-
tion answering: Perspectives and challenges. In
Proceedings of the Third International Conference
on Language Resources and Evaluation.
Ellen M. Voorhees and Dawn M. Tice. 2000.
Overview of the TREC-9 question answering
track. In Proceedings of the Ninth Text REtrieval
Conference (TREC-9).
Ellen M. Voorhees. 2001. Overview of the TREC
2001 question answering track. In Proceedings of
the 2001 Text REtrieval Conference (TREC 200).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.307747">
<title confidence="0.999953">Annotating the Semantic Web Using Natural Language</title>
<author confidence="0.999985">Boris Katz Jimmy Lin</author>
<affiliation confidence="0.980117">MIT Artificial Intelligence</affiliation>
<address confidence="0.978118">200 Technology Cambridge, MA 02139,</address>
<email confidence="0.567406">boris@ai.mit.edu</email>
<email confidence="0.567406">jimmylin@ai.mit.edu</email>
<abstract confidence="0.976282421052632">Because the ultimate purpose of the Semantic Web is to help users better locate, organize, and process content, we believe that it should be grounded in the access method humans are most comwith natural language. However, the source Description Framework (RDF), the foundation of the Semantic Web, was designed to be easily processed by computers, not humans. To render RDF more friendly to humans, we propose to augment it with natural language annotations, or metadata written in everyday language. We argue that natural language annotations, parsed into computerreadable representations, are not only intuitive and effective, but can also accelerate the pace with which the Semantic Web is being adopted. We believe that our technology can facilitate a happy marriage between natural language technology and the Semantic Web vision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eytan Adar</author>
<author>David Karger</author>
<author>Lynn Andrea Stein</author>
</authors>
<title>Haystack: Per-user information environments.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Conference on Information and Knowledge Management.</booktitle>
<contexts>
<context position="29294" citStr="Adar et al., 1999" startWordPosition="4417" endWordPosition="4420">ries over RDF stores has already been developed by other researchers. For example, the RDF Query Language (RQL) (Karvounarakis et al., 2002) provides a SQL-like query language for accessing large amounts of RDF triples. More concretely, the types of questions handled by annotations in Figure 3 would ultimately translated in a, declarative query like: SELECT Y FROM {X}popnlation{y} WHERE X = &apos;Taiwan&apos; In fact, RQL provides a rich set of comparison and aggregation operators necessary to perform complex queries, just like a standard RDBMS. We are currently collaborating with the Haystack Project (Adar et al., 1999; Huynh et al., 2002), part of MIT&apos;s Project Oxygen,9 to implement the ideas proposed here. Haystack is a personalized information repository built on RDF, and we plan to use it as a testbed for exploring the interactions between natural language technology and the Semantic Web. In addition to deploying these proposed technologies, we are also resegrchino. advanced methods for decomposing complex natural language queries into a series of simpler ones. For example, a question like &amp;quot;When was the president of Russia born,&amp;quot; could be broken down into two information seeking steps: first, find out w</context>
</contexts>
<marker>Adar, Karger, Stein, 1999</marker>
<rawString>Eytan Adar, David Karger, and Lynn Andrea Stein. 1999. Haystack: Per-user information environments. In Proceedings of the 1999 Conference on Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Berners-Lee</author>
<author>James Bendier</author>
<author>Ora Lassila</author>
</authors>
<title>The Semantic Web. Scientific American.</title>
<date>2001</date>
<pages>284--5</pages>
<contexts>
<context position="1132" citStr="Berners-Lee et al., 2001" startWordPosition="176" endWordPosition="179"> Semantic Web, was designed to be easily processed by computers, not humans. To render RDF more friendly to humans, we propose to augment it with natural language annotations, or metadata written in everyday language. We argue that natural language annotations, parsed into computerreadable representations, are not only intuitive and effective, but can also accelerate the pace with which the Semantic Web is being adopted. We believe that our technology can facilitate a happy marriage between natural language technology and the Semantic Web vision. 1 Introduction The vision of the Semantic Web (Berners-Lee et al., 2001) is to convert existing Web information into a more machine-readable form, with the goal of making the Web more effective for users. This goal grew out of the recognition that a wealth of information readily exists today in electronic form: however, since this information lacks any machineunderstandable semantics, it cannot be easily processed by computer systems. Fundamentally, Semantic Web research is attempting to address the problem of information access: building systems that help users locate, collate, compare, and cross-reference content. As such, we believe that the Semantic Web should</context>
</contexts>
<marker>Berners-Lee, Bendier, Lassila, 2001</marker>
<rawString>Tim Berners-Lee, James Bendier, and Ora Lassila. 2001. The Semantic Web. Scientific American. 284(5):34-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Berners-Lee</author>
</authors>
<title>Primer: Getting into RDF and Semantic Web using N3.</title>
<date>2000</date>
<marker>Berners-Lee, 2000</marker>
<rawString>Tim Berners-Lee. 2000. Primer: Getting into RDF and Semantic Web using N3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Brickley</author>
<author>R V Guha</author>
</authors>
<title>RDF vocabulary description language 1.0: RDF Schema. W3C Working Draft, World Wide Web Consortium,</title>
<date>2002</date>
<contexts>
<context position="10541" citStr="Brickley and Guha, 2002" startWordPosition="1615" endWordPosition="1618">se query that retrieves the writers for various movies from the Internet Movie Database (IMDb).2 The symbol imdb-movie serves as a placeholder for any one of the hundreds of thousands of movies that IMDb contains information about; when the annotation matches the user question, the actual movie name is instantiated and passed along to Omnibase After Omnibase fetches the correct answer. START performs additional postprocessing, e.g., natural language generation, to present the answer (see Figure 2). 3 Towards Human-friendly RDF The Resource Description Framework (RDF) (Lassila and Swick, 1999; Brickley and Guha, 2002), the standardized Semantic Web language for describing metadata, was meant for consumption by computers, not humans. Given this philosophy, how can we be sure that we&apos;re creating useful metadata? How can we be sure that our ontologies mirror the way users organize and think about content? Since the final beneficiary of the Semantic Web should be the average user, we advocate a human-centered organization of metadata3 grounded in natural language. The Semantic Web provides many of the mechanisms required to realize this dream. In this paper, we describe three concrete proposals for leveraging </context>
</contexts>
<marker>Brickley, Guha, 2002</marker>
<rawString>Dan Brickley and R.V. Guha. 2002. RDF vocabulary description language 1.0: RDF Schema. W3C Working Draft, World Wide Web Consortium, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Bendier</author>
</authors>
<title>Agents and the Semantic Web.</title>
<date>2001</date>
<journal>IEEE Intelligent Systems.</journal>
<pages>16--2</pages>
<marker>Bendier, 2001</marker>
<rawString>James Bendier. 2001. Agents and the Semantic Web. IEEE Intelligent Systems. 16(2):30-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Huynh</author>
<author>David Karger</author>
<author>Dennis Quan</author>
</authors>
<title>Haystack: A platform for creating, organizing and visualizing information using RDF.</title>
<date>2002</date>
<booktitle>In Proceedings of the Eleventh, World Wide Web Conference Semantic Web Workshop.</booktitle>
<contexts>
<context position="29315" citStr="Huynh et al., 2002" startWordPosition="4421" endWordPosition="4424">s has already been developed by other researchers. For example, the RDF Query Language (RQL) (Karvounarakis et al., 2002) provides a SQL-like query language for accessing large amounts of RDF triples. More concretely, the types of questions handled by annotations in Figure 3 would ultimately translated in a, declarative query like: SELECT Y FROM {X}popnlation{y} WHERE X = &apos;Taiwan&apos; In fact, RQL provides a rich set of comparison and aggregation operators necessary to perform complex queries, just like a standard RDBMS. We are currently collaborating with the Haystack Project (Adar et al., 1999; Huynh et al., 2002), part of MIT&apos;s Project Oxygen,9 to implement the ideas proposed here. Haystack is a personalized information repository built on RDF, and we plan to use it as a testbed for exploring the interactions between natural language technology and the Semantic Web. In addition to deploying these proposed technologies, we are also resegrchino. advanced methods for decomposing complex natural language queries into a series of simpler ones. For example, a question like &amp;quot;When was the president of Russia born,&amp;quot; could be broken down into two information seeking steps: first, find out who the president of R</context>
</contexts>
<marker>Huynh, Karger, Quan, 2002</marker>
<rawString>David Huynh, David Karger, and Dennis Quan. 2002. Haystack: A platform for creating, organizing and visualizing information using RDF. In Proceedings of the Eleventh, World Wide Web Conference Semantic Web Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Karvounarakis</author>
<author>Sofia Alexaki</author>
<author>Vassilis Christophides</author>
<author>Dimitris Plexousakis</author>
<author>Michel Scholl</author>
</authors>
<title>RQL: A declarative query language for RDF.</title>
<date>2002</date>
<booktitle>In Proceedings of the Eleventh, International World Wide Web Conference (WWW2002).</booktitle>
<contexts>
<context position="28817" citStr="Karvounarakis et al., 2002" startWordPosition="4341" endWordPosition="4344">or nearly a decade that natural language annotations are both useful and effective. Currently, schemat a, in START can contain actual content (e.g., text and images), procedures (e.g., to access the system clock to tell time), or Omnibase queries (to access heterogeneous data from the Web). Generalizing this technology to the information access schemata we&apos;ve proposed in Section 3.1 is a relatively straightforward task. Furthermore, all the machinery necessary to perform complex queries over RDF stores has already been developed by other researchers. For example, the RDF Query Language (RQL) (Karvounarakis et al., 2002) provides a SQL-like query language for accessing large amounts of RDF triples. More concretely, the types of questions handled by annotations in Figure 3 would ultimately translated in a, declarative query like: SELECT Y FROM {X}popnlation{y} WHERE X = &apos;Taiwan&apos; In fact, RQL provides a rich set of comparison and aggregation operators necessary to perform complex queries, just like a standard RDBMS. We are currently collaborating with the Haystack Project (Adar et al., 1999; Huynh et al., 2002), part of MIT&apos;s Project Oxygen,9 to implement the ideas proposed here. Haystack is a personalized info</context>
</contexts>
<marker>Karvounarakis, Alexaki, Christophides, Plexousakis, Scholl, 2002</marker>
<rawString>Greg Karvounarakis, Sofia Alexaki, Vassilis Christophides, Dimitris Plexousakis, and Michel Scholl. 2002. RQL: A declarative query language for RDF. In Proceedings of the Eleventh, International World Wide Web Conference (WWW2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Beth Levin</author>
</authors>
<title>Exploiting lexical regularities in designing natural language systems.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLINC &apos;88).</booktitle>
<contexts>
<context position="5347" citStr="Katz and Levin, 1988" startWordPosition="828" endWordPosition="831">. 1987 Nobel Prize for Literature A question answering system would parse these two annotations and store the parsed structures (e.g., ternary expressions (Katz, 1988)) with pointers back to the original information segment. To answer a question, the user query, parsed into the same type of structures, would be compared against the annotations stored in the knowledge base. Because this match would occur at the level of parsed representations, linguistically sophisticated machinery such as synonymy/hyponymy relations, ontologies, and structural transformation rules (e.g., &amp;quot;SRules&amp;quot; (Katz, 1997; Katz and Levin, 1988)) could be brought to bear on the matching process. If a match were found, the segment corresponding to the annotation would be returned to the user as the answer. Because sophisticated natural language processing could be invoked in matching questions with annotations, precision far beyond that of standard keyword-based information retrieval techniques could be achieved. In addition, a linguistically-based system allows for variations in user queries, e.g., alternate formulations, active/passive voice, nominalizations, etc. To give a more concrete example, the annotations above would allow a </context>
</contexts>
<marker>Katz, Levin, 1988</marker>
<rawString>Boris Katz and Beth Levin. 1988. Exploiting lexical regularities in designing natural language systems. In Proceedings of the 12th International Conference on Computational Linguistics (COLINC &apos;88).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Patrick H Winston</author>
</authors>
<title>Parsing and generating English using commutative transformations.</title>
<date>1982</date>
<journal>Al Memo 677, MIT Artificial Intelligence Laboratory.</journal>
<contexts>
<context position="12116" citStr="Katz and Winston, 1982" startWordPosition="1862" endWordPosition="1865">e even more &amp;quot;natural&amp;quot; (but somewhat less powerful) information access schemata that would allow ordinary users to become skillful knowledge engineers. 3.1 Simple Properties The foundation of the Semantic Web rests on RDF statements, which are essentially triples denoting objects, properties, and values. An alternative and often used description of RDF statements is in terms of &amp;quot;subject,&amp;quot; &amp;quot;relation,&amp;quot; and &amp;quot;object,&amp;quot; revealing a grammatical basis for RDF constructs. In fact, the RDF triples are very similar, both in spirit and in form, to our ternary expression representation of natural language (Katz and Winston, 1982; Katz, 1988). We propose to make this connection more explicit by augmenting rdf :Property definitions with natural language annotations. Figure 3 illustrates our proposal, using a fragment of an ontology representing the CIA World Factbook.4 Intuitively, the population property is a relation connecting a country to its population value. Natural language annotations express this connection concretely in natural language sentences and phrases, via the nl : ann property. For example, the phrase &amp;quot;population of ?s&amp;quot; is linked to every RDF statement involving the population property; ?s is shorthan</context>
</contexts>
<marker>Katz, Winston, 1982</marker>
<rawString>Boris Katz and Patrick H. Winston. 1982. Parsing and generating English using commutative transformations. Al Memo 677, MIT Artificial Intelligence Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
<author>Sue Feishin</author>
</authors>
<title>Gathering knowledge for a question answering system from heterogeneous information sources.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL 2000 Workshop on Human Language Technology and Knowledge Management.</booktitle>
<marker>Katz, Lin, Feishin, 2001</marker>
<rawString>Boris Katz, Jimmy Lin, and Sue Feishin 2001. Gathering knowledge for a question answering system from heterogeneous information sources. In Proceedings of the ACL 2000 Workshop on Human Language Technology and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Sue Feishin</author>
<author>Deniz Yuret</author>
<author>Ali Ibrahim</author>
<author>Jimmy Lin</author>
<author>Gregory Marton</author>
<author>Alton Jerome McFarland</author>
<author>Bans Temelkuran</author>
</authors>
<title>Omnibase. Uniform access to heterogeneous data as a component of a natural language question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Workshop on Applications of Natural Language to Information Systems (NLDB</booktitle>
<contexts>
<context position="7831" citStr="Katz et al., 2002" startWordPosition="1213" endWordPosition="1216"> Wide Web. Since it came online in December 1993, START has engaged in exchanges with hundreds of thousands of users all over the world, supplying them with useful knowledge. Currently, our system can answer millions of natural language questions about places (e.g., cities, countries, lakes; coordinates, weather, maps, demographics, political and economic systems), movies (e.g., titles, actors, directors), people (e.g., birth dates, biographies), dictionary definitions, and much, much more. In order to give START uniform access to semistructured resources on the Web, we have created Omnibase (Katz et al., 2002), a virtual database that integrates numerous heterogeneous Web sources under a single query interface. To actually answer user questions, however, the gap between natural language questions and structured Omnibase queries must be bridged. Natural language annotations serve as the enabling technology that allows the integration of START and OmniNetscape: START&apos;s reply START&apos;s reply ===&gt; Who wrote the screenplay for Good Will Hunting? The script for Good Will Hunting (1997) was written by Matt Damon and Ben Affleck. Source: The Internet Movie Database a=w-I -Ar,94a ••,:eJ &lt;rdfs:Class ID=&amp;quot;Countr</context>
<context position="27702" citStr="Katz et al., 2002" startWordPosition="4169" endWordPosition="4172">gle schema for the Internet Movie Database, for example, could grant the user natural language access to over three hundred thousand titles! It is our experience that people ask the same types of questions frequently. Analysis of the questions from the TREC-9 (Voorhees and Tice, 2000) and TREC-2001 (Voorhees, 2001) QA Track, a standardized test set for question answering, reveals a question distribution that qualitatively obeys Zipf&apos;s law: a few high frequency query types account for a large portion of all questions (Lin, 2002). Furthermore, questions can often be modeled as database queries (Katz et al., 2002) to simplify access. From these observations, we can conclude that although information access schemata require human effort, they are nevertheless an effective way of achieving broad knowledge coverage at reasonable costs. 6 Future Work We have described three concrete proposals for making the Semantic Web friendly to computers and humans alike. All the pieces for the implementation of our ideas already exist. START, our natural language question answering system, has demonstrated for nearly a decade that natural language annotations are both useful and effective. Currently, schemat a, in STA</context>
</contexts>
<marker>Katz, Feishin, Yuret, Ibrahim, Lin, Marton, McFarland, Temelkuran, 2002</marker>
<rawString>Boris Katz, Sue Feishin, Deniz Yuret, Ali Ibrahim, Jimmy Lin, Gregory Marton, Alton Jerome McFarland, and Bans Temelkuran. 2002. Omnibase. Uniform access to heterogeneous data as a component of a natural language question answering system. In Proceedings of the 7th International Workshop on Applications of Natural Language to Information Systems (NLDB 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
</authors>
<title>Using English for indexing and retrieving.</title>
<date>1988</date>
<booktitle>In Proceedings of the 1st RIAO Conference on User-Oriented Content-Based Text and Image Handling (RIAO &apos;88).</booktitle>
<contexts>
<context position="4893" citStr="Katz, 1988" startWordPosition="761" endWordPosition="762">inds of questions that a particular piece of knowledge is capable of answering. To illustrate how this technology works, consider the following paragraph about Joseph Brodsky: &amp;quot;For an all-embracing authorship, imbued with clarity of thought and poetic intensity,&amp;quot; Joseph Brodsky was awarded the 1987 Nobel Prize in Literature. This paragraph may be annotated with the following: Joseph Brodsky was awarded the Nobel Prize for Literature in 1987. 1987 Nobel Prize for Literature A question answering system would parse these two annotations and store the parsed structures (e.g., ternary expressions (Katz, 1988)) with pointers back to the original information segment. To answer a question, the user query, parsed into the same type of structures, would be compared against the annotations stored in the knowledge base. Because this match would occur at the level of parsed representations, linguistically sophisticated machinery such as synonymy/hyponymy relations, ontologies, and structural transformation rules (e.g., &amp;quot;SRules&amp;quot; (Katz, 1997; Katz and Levin, 1988)) could be brought to bear on the matching process. If a match were found, the segment corresponding to the annotation would be returned to the us</context>
<context position="6498" citStr="Katz, 1988" startWordPosition="1011" endWordPosition="1012">more concrete example, the annotations above would allow a question answering system to answer the following questions (see Figure 1 for an example): What prize did Brodsky receive in 1987? Who was awarded the Nobel Prize for Literature in 1987? Tell me about the winner of the 1987 Nobel Prize for Literature. Who was the Nobel Prize for Literature given to in 1987? An important feature of the annotation concept is that any information segment can be annotated: not only text, but also images, multimedia, database queries, and even procedures. We have implemented the above technology in START&apos; (Katz, 1988; Katz, 1997), the first question lhttp://www.ai.mit.edu/projects/infolab 0 Netscape:START&apos;s reply M B START&apos;s reply il ===&gt; Who won the Nobel Prize for Literature in 1987? Pr The Nobel Prize in li Literature 1987 &apos;el Ii*&amp;quot; .. for an all-embracing authorship, imbued A with clarity of thought and poetic intensity&amp;quot; &apos;Al Joseph Brodsky USA b.1940 Source Nobel e-Museuin d.1996 -..., &apos;.&apos; C4 •e.-...1::&apos; Figure 1: START answering the question &amp;quot;Who won the Nobel Prize for Literature in 1987?&amp;quot; Figure 2: START answering the question &amp;quot;Who wrote the screenplay for Good Will Hunting?&amp;quot; by extracting informati</context>
<context position="12129" citStr="Katz, 1988" startWordPosition="1866" endWordPosition="1867">ut somewhat less powerful) information access schemata that would allow ordinary users to become skillful knowledge engineers. 3.1 Simple Properties The foundation of the Semantic Web rests on RDF statements, which are essentially triples denoting objects, properties, and values. An alternative and often used description of RDF statements is in terms of &amp;quot;subject,&amp;quot; &amp;quot;relation,&amp;quot; and &amp;quot;object,&amp;quot; revealing a grammatical basis for RDF constructs. In fact, the RDF triples are very similar, both in spirit and in form, to our ternary expression representation of natural language (Katz and Winston, 1982; Katz, 1988). We propose to make this connection more explicit by augmenting rdf :Property definitions with natural language annotations. Figure 3 illustrates our proposal, using a fragment of an ontology representing the CIA World Factbook.4 Intuitively, the population property is a relation connecting a country to its population value. Natural language annotations express this connection concretely in natural language sentences and phrases, via the nl : ann property. For example, the phrase &amp;quot;population of ?s&amp;quot; is linked to every RDF statement involving the population property; ?s is shorthand for indicat</context>
</contexts>
<marker>Katz, 1988</marker>
<rawString>Boris Katz. 1988. Using English for indexing and retrieving. In Proceedings of the 1st RIAO Conference on User-Oriented Content-Based Text and Image Handling (RIAO &apos;88).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
</authors>
<title>Annotating the World Wide Web using natural language.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th RIAO Conference on Computer Assisted Information Searching on the Internet (RIAO &apos;97).</booktitle>
<contexts>
<context position="4119" citStr="Katz, 1997" startWordPosition="645" endWordPosition="646">e first question answering system available on the World Wide Web, and we believe that it provides a simple mechanism to marry natural language technology and the Semantic Web. 2 Natural Language Annotations Use of metadata is a common technique for rendering information fragments more tenable to processing by computer systems. Using natural language itself as metadata presents several additional advantages: it preserves human readability, allows for easy querying, and encourages non-expert users to engage in metadata creation. To this end, we have b &apos;b developed natural language annotations (Katz, 1997), which are machine-parsable sentences and phrases that describe the content of various information segments. These annotations serve as metadata to describe the kinds of questions that a particular piece of knowledge is capable of answering. To illustrate how this technology works, consider the following paragraph about Joseph Brodsky: &amp;quot;For an all-embracing authorship, imbued with clarity of thought and poetic intensity,&amp;quot; Joseph Brodsky was awarded the 1987 Nobel Prize in Literature. This paragraph may be annotated with the following: Joseph Brodsky was awarded the Nobel Prize for Literature </context>
<context position="6511" citStr="Katz, 1997" startWordPosition="1013" endWordPosition="1014">e example, the annotations above would allow a question answering system to answer the following questions (see Figure 1 for an example): What prize did Brodsky receive in 1987? Who was awarded the Nobel Prize for Literature in 1987? Tell me about the winner of the 1987 Nobel Prize for Literature. Who was the Nobel Prize for Literature given to in 1987? An important feature of the annotation concept is that any information segment can be annotated: not only text, but also images, multimedia, database queries, and even procedures. We have implemented the above technology in START&apos; (Katz, 1988; Katz, 1997), the first question lhttp://www.ai.mit.edu/projects/infolab 0 Netscape:START&apos;s reply M B START&apos;s reply il ===&gt; Who won the Nobel Prize for Literature in 1987? Pr The Nobel Prize in li Literature 1987 &apos;el Ii*&amp;quot; .. for an all-embracing authorship, imbued A with clarity of thought and poetic intensity&amp;quot; &apos;Al Joseph Brodsky USA b.1940 Source Nobel e-Museuin d.1996 -..., &apos;.&apos; C4 •e.-...1::&apos; Figure 1: START answering the question &amp;quot;Who won the Nobel Prize for Literature in 1987?&amp;quot; Figure 2: START answering the question &amp;quot;Who wrote the screenplay for Good Will Hunting?&amp;quot; by extracting information from the I</context>
<context position="8601" citStr="Katz, 1997" startWordPosition="1327" endWordPosition="1328">ween natural language questions and structured Omnibase queries must be bridged. Natural language annotations serve as the enabling technology that allows the integration of START and OmniNetscape: START&apos;s reply START&apos;s reply ===&gt; Who wrote the screenplay for Good Will Hunting? The script for Good Will Hunting (1997) was written by Matt Damon and Ben Affleck. Source: The Internet Movie Database a=w-I -Ar,94a ••,:eJ &lt;rdfs:Class ID=&amp;quot;Country&amp;quot;› In 1997, we proposed to attach natural language &lt;rdfs:comment&gt;A Country in the annotations to everything available on the Web CIA Factbook&lt;/rdfs:comment&gt; (Katz, 1997). Furthermore, we described a dis&lt;/rdfs:Class&gt; tributed mechanism for knowledge gathering: &lt;rdf:Property ID=&amp;quot;population&amp;quot;› By allowing thousands of people to build &lt;rdfs:domain rdf:resource=&amp;quot;#Country&amp;quot;/&gt; up knowledge about knowledge, we will &lt;rdfs:range rdf:resource=&amp;quot;xsd:string&amp;quot;/&gt; create a knowledge base of an interesting &lt;nl:ann text=&amp;quot;Many people live in ?s&amp;quot;/&gt; form. The Web will continue to be built out &lt;nl:ann text=&amp;quot;population of ?s&amp;quot;/&gt; of &amp;quot;opaque&amp;quot; information segments: text, &lt;nl:gen text=&amp;quot;The population of ?s is ?o&amp;quot;/&gt; maps, charts, audio, video, etc.; but at&lt;/rdf:Property&gt; tached to each of th</context>
</contexts>
<marker>Katz, 1997</marker>
<rawString>Boris Katz. 1997. Annotating the World Wide Web using natural language. In Proceedings of the 5th RIAO Conference on Computer Assisted Information Searching on the Internet (RIAO &apos;97).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ora Lassila</author>
<author>Ralph R Swick</author>
</authors>
<title>Resource Description Framework (RDF) model and syntax specification. W3C Recommendation, World Wide Web Consortium,</title>
<date>1999</date>
<contexts>
<context position="10515" citStr="Lassila and Swick, 1999" startWordPosition="1610" endWordPosition="1614"> be attached to an Omnibase query that retrieves the writers for various movies from the Internet Movie Database (IMDb).2 The symbol imdb-movie serves as a placeholder for any one of the hundreds of thousands of movies that IMDb contains information about; when the annotation matches the user question, the actual movie name is instantiated and passed along to Omnibase After Omnibase fetches the correct answer. START performs additional postprocessing, e.g., natural language generation, to present the answer (see Figure 2). 3 Towards Human-friendly RDF The Resource Description Framework (RDF) (Lassila and Swick, 1999; Brickley and Guha, 2002), the standardized Semantic Web language for describing metadata, was meant for consumption by computers, not humans. Given this philosophy, how can we be sure that we&apos;re creating useful metadata? How can we be sure that our ontologies mirror the way users organize and think about content? Since the final beneficiary of the Semantic Web should be the average user, we advocate a human-centered organization of metadata3 grounded in natural language. The Semantic Web provides many of the mechanisms required to realize this dream. In this paper, we describe three concrete</context>
</contexts>
<marker>Lassila, Swick, 1999</marker>
<rawString>Ora Lassila and Ralph R. Swick. 1999. Resource Description Framework (RDF) model and syntax specification. W3C Recommendation, World Wide Web Consortium, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jimmy J Lin</author>
</authors>
<title>The Web as a resource for question answering: Perspectives and challenges.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="27617" citStr="Lin, 2002" startWordPosition="4158" endWordPosition="4159">mber of class instances, but rather the complexity of the class itself. A single schema for the Internet Movie Database, for example, could grant the user natural language access to over three hundred thousand titles! It is our experience that people ask the same types of questions frequently. Analysis of the questions from the TREC-9 (Voorhees and Tice, 2000) and TREC-2001 (Voorhees, 2001) QA Track, a standardized test set for question answering, reveals a question distribution that qualitatively obeys Zipf&apos;s law: a few high frequency query types account for a large portion of all questions (Lin, 2002). Furthermore, questions can often be modeled as database queries (Katz et al., 2002) to simplify access. From these observations, we can conclude that although information access schemata require human effort, they are nevertheless an effective way of achieving broad knowledge coverage at reasonable costs. 6 Future Work We have described three concrete proposals for making the Semantic Web friendly to computers and humans alike. All the pieces for the implementation of our ideas already exist. START, our natural language question answering system, has demonstrated for nearly a decade that nat</context>
</contexts>
<marker>Lin, 2002</marker>
<rawString>Jimmy J. Lin. 2002. The Web as a resource for question answering: Perspectives and challenges. In Proceedings of the Third International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
<author>Dawn M Tice</author>
</authors>
<title>Overview of the TREC-9 question answering track.</title>
<date>2000</date>
<booktitle>In Proceedings of the Ninth Text REtrieval Conference (TREC-9).</booktitle>
<contexts>
<context position="27369" citStr="Voorhees and Tice, 2000" startWordPosition="4116" endWordPosition="4119">can be parameterized to encompass entire classes of questions. A schema about the CIA Factbook in which the properties and countries are parameterized can answer tens of thousands of potential questions. The cost of writing schemata is not proportional to the number of class instances, but rather the complexity of the class itself. A single schema for the Internet Movie Database, for example, could grant the user natural language access to over three hundred thousand titles! It is our experience that people ask the same types of questions frequently. Analysis of the questions from the TREC-9 (Voorhees and Tice, 2000) and TREC-2001 (Voorhees, 2001) QA Track, a standardized test set for question answering, reveals a question distribution that qualitatively obeys Zipf&apos;s law: a few high frequency query types account for a large portion of all questions (Lin, 2002). Furthermore, questions can often be modeled as database queries (Katz et al., 2002) to simplify access. From these observations, we can conclude that although information access schemata require human effort, they are nevertheless an effective way of achieving broad knowledge coverage at reasonable costs. 6 Future Work We have described three concr</context>
</contexts>
<marker>Voorhees, Tice, 2000</marker>
<rawString>Ellen M. Voorhees and Dawn M. Tice. 2000. Overview of the TREC-9 question answering track. In Proceedings of the Ninth Text REtrieval Conference (TREC-9).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Overview of the TREC</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Text REtrieval Conference (TREC 200).</booktitle>
<contexts>
<context position="27400" citStr="Voorhees, 2001" startWordPosition="4122" endWordPosition="4123"> classes of questions. A schema about the CIA Factbook in which the properties and countries are parameterized can answer tens of thousands of potential questions. The cost of writing schemata is not proportional to the number of class instances, but rather the complexity of the class itself. A single schema for the Internet Movie Database, for example, could grant the user natural language access to over three hundred thousand titles! It is our experience that people ask the same types of questions frequently. Analysis of the questions from the TREC-9 (Voorhees and Tice, 2000) and TREC-2001 (Voorhees, 2001) QA Track, a standardized test set for question answering, reveals a question distribution that qualitatively obeys Zipf&apos;s law: a few high frequency query types account for a large portion of all questions (Lin, 2002). Furthermore, questions can often be modeled as database queries (Katz et al., 2002) to simplify access. From these observations, we can conclude that although information access schemata require human effort, they are nevertheless an effective way of achieving broad knowledge coverage at reasonable costs. 6 Future Work We have described three concrete proposals for making the Se</context>
</contexts>
<marker>Voorhees, 2001</marker>
<rawString>Ellen M. Voorhees. 2001. Overview of the TREC 2001 question answering track. In Proceedings of the 2001 Text REtrieval Conference (TREC 200).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>