<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000055">
<title confidence="0.798568">
Automatic Extraction of Systematic Polysemy Using Tree-cut
</title>
<author confidence="0.952171">
Noriko Tomuro
</author>
<affiliation confidence="0.9665335">
DePaul University
School of Computer Science, Telecommunications and Information Systems
</affiliation>
<address confidence="0.750502">
243 S. Wabash Ave.
Chicago, IL 60604
</address>
<email confidence="0.911433">
tomuroncs.depaul.edu
</email>
<sectionHeader confidence="0.992504" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998927166666667">
This paper describes an automatic method for
extracting systematic polysemy from a hierar-
chically organized semantic lexicon (WordNet).
Systematic polysemy is a set of word senses
that are related in systematic and predictable
ways. Our method uses a modification of a tree
generalization technique used in (Li and Abe,
1998), and generates a tree-cut, which is a list
of clusters that partition a tree. We compare
the systematic relations extracted by our auto-
matic method to manually extracted WordNet
cousins.
</bodyText>
<sectionHeader confidence="0.998418" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997176826086957">
In recent years, several on-line broad-coverage
semantic lexicons became available, including
LDOCE (Procter, 1978), WordNet (Miller,
1990) and HECTOR (Kilgaxriff, 1998a).
These lexicons have been used as a domain-
independent semantic resource as well as an
evaluation criteria in various Natural Language
Processing (NLP) tasks, such as Information
Retrieval (IR), Information Extraction (IE) and
Word Sense Disambiguation (WSD).
However, those lexicons are rather complex.
For instance, WordNet (version 1.6) contains a
total of over 120,000 words and 170,000 word
senses, which are grouped into around 100,000
synsets (synonym sets). In addition to the size,
word entries in those lexicon are often polyse-
mous. For instance, 20% of the words in Word-
net have more than one sense, and the average
number of senses of those polysemous words is
around 3. Also, the distinction between word
senses tends to be ambiguous and arbitrary.
For example, the following 6 senses are listed
in WordNet for the noun &amp;quot;door&amp;quot;:
</bodyText>
<listItem confidence="0.999849375">
1. door - a swinging or sliding barrier
2. door - the space in a wall
3. door - anything providing a means of
access (or escape)
4. door - a swinging or sliding barrier that
will close off access into a car
5. door - a house that is entered via a door
6. door - a room that is entered via a door
</listItem>
<bodyText confidence="0.999688517241379">
Because of the high degree of ambiguity, using
such complex semantic lexicons brings some se-
rious problems to the performance of NLP sys-
tems. The first, obvious problem is the com-
putational intractability: increased processing
time needed to disambiguate multiple possibili-
ties will necessarily slow down the system. An-
other problem, which has been receiving atten-
tion in the past few years, is the inaccuracy:
when there is more than one sense applicable in
a given context, different systems (or human in-
dividuals) may select different senses as the cor-
rect sense, Indeed, recent studies in WSD show
that, when sense definitions are fine-grained,
similar senses become indistinguishable to hu-
man annotators and often cause disagreement
on the correct tag (Ng et al., 1999; Veronis,
1998; Kilgarriff, 1998b). Also in IR and IE
tasks, difference in the correct sense assignment
will surely degrade recall and precision of the
systems. Thus, it is apparent that, in order for
a lexicon to be useful as an evaluation criteria
for NLP systems, it must represent word senses
at the level of granularity that captures human
intuition.
In Lexical Semantics, several approaches have
been proposed which organize a lexicon based
on systematic polysemy:1 a set of word senses
that are related in systematic and predictable
</bodyText>
<footnote confidence="0.929587">
ISysternatic polysemy (in the sense we use in this
paper) is also referred to as regular polysemy (Apresjan,
1973) or logical polyserny (Pustejovsky, 1995).
</footnote>
<page confidence="0.991863">
20
</page>
<bodyText confidence="0.998447386363636">
ways (e.g. ANIMAL and MEAT meanings of the
word &amp;quot;chicken&amp;quot; ).2 In particular, (Buitelaar,
1997, 1998) identified systematic relations that
exist between abstract semantic concepts in
the WordNet noun hierarchy, and defined a
set of underspecified semantic classes that rep-
resent the relations. Then he extracted all
polysemous nouns in WordNet according to
those underspecified classes and built a lexicon
called CORELEX. For example, a CORELEX
class AQU (which represents a relation between
ARTIFACT and QUANTITY) contains words such
as &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;.
Using the abstract semantic classes and orga-
nizing a lexicon based on systematic polysemy
addresses the two problems mentioned above in
the following ways. For the first problem, using
the abstract classes can reduce the size of the
lexicon by combining several related senses into
one sense; thus computation becomes more effi-
cient. For the second problem, systematic poly-
semy does reflect our general intuitions on word
meanings. Although the distinction between
systematic vs. non-systematic relations (or re-
lated vs. unrelated meanings) is sometimes un-
clear, systematicity of the related senses among
words is quite intuitive and has been well stud-
ied in Lexical Semantics (for example, (Apres-
jan, 1973; Cruse, 1986; Nunberg, 1995; Copes-
take and Briscoe, 1995)).
However, there is one critical issue still to
be addressed: the level of granularity at which
the abstract classes are defined. The prob-
lem is that, when the granularity of the ab-
stract classes is too coarse, systematic rela-
tions defined at that level may not hold uni-
formly at more fine-grained levels (Vossen et
al., 1999). For instance, the CORELEX class
AQU mentioned above also contains a word
&amp;quot;dose&amp;quot; .3 Here, the relation between the senses
of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;,
&amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as
CONTAINER-CONTAINERFUL relation. We argue
that human intuitions can distinguish meanings
</bodyText>
<footnote confidence="0.977850125">
2Note that systematic polysemy should be contrasted
with homonymy which refers to words which have more
than one unrelated sense (e.g. FINANCIALINSTITUTION
and SLOPING_LAND meanings of the word &amp;quot;bank&amp;quot;).
&apos;Senses of &amp;quot;dose&amp;quot; in WordNet are: (1) a measured
portion of medicine taken at any one time, and (2)
the quantity of an active agent (substance or radiation)
taken in or absorbed at any one time.
</footnote>
<figure confidence="0.90246825">
ARTIFACT
AIRCRAFT TOY
/IN
airplane helicopter ball k&apos;te puzzle
</figure>
<figureCaption confidence="0.999888">
Figure 1: An example thesaurus tree
</figureCaption>
<bodyText confidence="0.999887533333333">
at this level, where differences between the sys-
tematic relations are rather clear, and therefore
lexicons that encode word senses at this level of
granularity have advantages over fine-grained as
well as coarse-grained lexicons in various NLP
tasks.
Another issue we like to address is the ways
for extracting systematic polysemy. Most of-
ten, this procedure is done manually. For ex-
ample, the current version of WordNet (1.6)
encodes the similarity between word senses (or
synsets) by a relation called cousin. But those
cousin relations were identified manually by the
WordNet lexicographers. A similar effort was
also made in the EuroWordnet project (Vossen
et at., 1999). However, manually inspecting a
large, complex lexicon is very time-consuming
and often prone to inconsistencies.
In this paper, we propose a method which au-
tomatically extracts systematic polysemy from
a hierarchically organized semantic lexicon
(WordNet). Our method uses a modification of
a tree generalization technique used in (Li and
Abe, 1998), and generates a tree-cut, which is a
list of clusters that partition a tree. Then, we
compare the systematic relations extracted by
our automatic method to the WordNet cousins.
Preliminary results show that our method dis-
covered most of the WordNet cousins as well as
some more interesting relations.
</bodyText>
<sectionHeader confidence="0.358906" genericHeader="method">
2 Tree Generalization using Tree-cut
and MDL
</sectionHeader>
<bodyText confidence="0.9998304">
Before we present our method, we first give a
brief summary of the tree-cut technique which
we adopted from (Li and Abe, 1998). This tech-
nique is used to acquire generalized case frame
patterns from a corpus using a thesaurus tree.
</bodyText>
<subsectionHeader confidence="0.662478">
2.1 Tree-cut Models
</subsectionHeader>
<bodyText confidence="0.998826">
A thesaurus tree is a hierarchically organized
lexicon where leaf nodes encode lexical data
</bodyText>
<page confidence="0.994686">
21
</page>
<bodyText confidence="0.999952892857143">
(i.e., words) and internal nodes represent ab-
stract semantic classes. A tree-cut is a partition
of a thesaurus tree. It is a list of internal/leaf
nodes in the tree, and each node represents a
set of all leaf nodes in a subtree rooted by the
node. Such set is also considered as a clus-
ter.4 Clusters in a tree-cut exhaustively cover
all leaf nodes of the tree, and they are mutu-
ally disjoint. For example, for a thesaurus tree
in Figure 1, there are 5 tree-cuts: [airplane, he-
licopter, ball, kite, puzzle], [AIRCRAFT, ball,
kite, puzzle], [airplane, helicopter, TOY], [AIR-
CRAFT, TOY] and [ARTIFACT]. Thus, a tree-
cut corresponds to one of the levels of abstrac-
tion in the tree.
Using a thesaurus tree and the idea of tree-
cut, the problem of acquiring generalized case
frame patters (for a fixed verb) from a corpus
is to select the best tree-cut that accounts for
both observed and unobserved case frame in-
stances. In (Li and Abe, 1998), this generaliza-
tion problem is viewed as a problem of select-
ing the best model for a tree-cut that estimates
the true probability distribution, given a sample
corpus data.
Formally, a tree-cut model M is a pair consist-
ing of a tree-cut F and a probability parameter
vector () of the same length,
</bodyText>
<equation confidence="0.545683">
m , (r, 6) (1)
</equation>
<bodyText confidence="0.988041">
where r and e are:
</bodyText>
<equation confidence="0.835882">
r = [C1, Cid, = [P(C1), ..) P(C)] (2)
</equation>
<bodyText confidence="0.976943961538462">
where C (1 &lt; i &lt; k) is a cluster in the tree-
cut, P(Ci) is the probability of a cluster
and ak_i P(Ci) = 1. For example, suppose
a corpus contained 10 instances of verb-object
relation for the verb &amp;quot;fly&amp;quot;, and the frequency
of object noun n, denoted f (n), are as follows:
I (airplane) = 5, f(helicopter) = 3, f (ball) =
0, f (kite) = 2, f (puzzle) = 0. Then, the set of
tree-cut models for the thesaurus tree shown in
Figure 1 includes ([airplane, helicopter, TOY],
[0.5, 0.3, 0.2]) and ([AIRCRAFT, TOY], [0.8,
0.2]).
Note that P(C) is the probability of cluster
C = {n1, ..,nm} as a whole. It is essentially the
sum of all (true) probabilities of the member
4A leaf node is also a cluster whose cardinality is 1.
words, that is, P(C) = P(ni). Here, com-
pared to knowing all P(ni) (where 1 &lt;j &lt;m)
individually, knowing one P(C) can only facil-
itate an estimate of uniform probability distri-
bution among members as the best guess, that
is, P(nj) =11--).:}3 for all j. Therefore, in general,
when clusters C1..C, are merged and general-
ized to C according to the thesaurus tree, the
estimation of a probability model becomes less
accurate.
</bodyText>
<subsectionHeader confidence="0.997074">
2.2 The MDL Principle
</subsectionHeader>
<bodyText confidence="0.999288545454545">
To select the best tree-cut model, (Li and Abe,
1998) uses the Minimal Description Length
(MDL) principle (Rissanen, 1978). The MDL is
a principle of data compression in Information
Theory which states that, for a given dataset,
the best model is the one which requires the
minimum length (often measured in bits) to en-
code the model (the model description length)
and the data (the data description length). For
the problem of case frame generalization, the
MDL principle fits very well in that it captures
the trade-off between the simplicity of a model,
which is measured by the number of clusters in
a tree-cut, and the goodness of fit to the data,
which is measured by the estimation accuracy
of the probability distribution.
The calculation of the description length for
a tree-cut model is as follows. Given a the-
saurus tree T and a sample S consisting of
the case frame instances, the total description
length L(M, S) for a tree-cut model M 0)
is
</bodyText>
<equation confidence="0.902623">
L(M, 5) = L(r) + goir) + L(sir,e) (3)
</equation>
<bodyText confidence="0.9965705">
where L(r) is the model description length,
MOW) is the parameter description length (ex-
plained shortly), and L(sir,e) is the data de-
scription length. Note that L(P) L(eir) es-
sentially corresponds to the usual notion of the
model description length.
Each length in L(M, 5) is calculated as fol-
lows.5 The model description length L(r) is
</bodyText>
<equation confidence="0.999776">
L(r) = log2IGI (4)
</equation>
<bodyText confidence="0.92096">
where G is the set of all cuts in T, and IG1 de-
notes the size of G. This value is a constant for
•5For justification and detailed explanation of these
formulas, see (Li and Abe, 1998).
</bodyText>
<page confidence="0.984806">
22
</page>
<bodyText confidence="0.999570857142857">
all models, thus it is omitted in the calculation
of the total length.
The parameter description length L(IF) in-
dicates the complexity of the model. It is the
length required to encode the probability dis-
tribution of the clusters in the tree-cut F. It is
calculated as
</bodyText>
<equation confidence="0.9084685">
Row) _k x /og21,51 (5)
2
</equation>
<bodyText confidence="0.9110108">
where k is the length of 0, and ISI is the size of
S.
Finally, the data description length L(sir, e)
is the length required to encode the whole sam-
ple data. It is calculated as
</bodyText>
<equation confidence="0.980837">
L(sir, e) E lo92P(n) (6)
</equation>
<bodyText confidence="0.7081375">
nEs
where, for each n G C and each C E r,
</bodyText>
<equation confidence="0.974279">
P (n)
</equation>
<bodyText confidence="0.984580214285714">
and
Is&apos;
Note here that, in (7), the probability of C is di-
vided evenly among all n in C. This way, words
that are not observed in the sample receive a
non-zero probability, and the data sparseness
problem is avoided.
Then, the best model is the one which re-
quires the minimum total description length.
Figure 2 shows the MDL lengths for all five
tree-cut models that can be produced for the
thesaurus tree in Figure I. The best model is
the one with the tree-cut [AIRCRAFT, ball, kite,
puzzle) indicated by a thick curve in the figure.
</bodyText>
<sectionHeader confidence="0.964272" genericHeader="method">
3 Clustering Systematic Polysemy
</sectionHeader>
<subsectionHeader confidence="0.983933">
3.1 Generalization Technique
</subsectionHeader>
<bodyText confidence="0.999858377777778">
Using the generalization technique in (Li and
Abe, 1998) described in the previous section,
we wish to extract systematic polysemy au-
tomatically from WordNet. Our assumption
is that, if a semantic concept is systemati-
cally related to another concept, words that
have one sense under one concept (sub)tree are
likely to have another sense under the other
concept (sub)tree. To give an example, Fig-
ure 3 shows parts of WordNet noun trees for
ARTIFACT and MEASURE, where subtrees under
CONTAINER and CONTAINERFUL respectively con-
tain &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&apos;. Note a
dashed line in the figure indicates an indirect
link for more than one level.
Based on this assumption, it seems system-
atic polysemy in the two trees can be extracted
straight-forwardly by clustering each tree ac-
cording to polysemy as a feature, and by match-
ing of clusters taken from each tree.6 To this
end, the notion of tree-cut and the MDL prin-
ciple seem to comprise an excellent tool.
However, we must be careful in adopting Li
and Abe&apos;s technique directly: since the problem
which their technique was applied to is funda-
mentally different from ours, some procedures
used in their problem may not have any inter-
pretation in our problem. Although both prob-
lems are essentially a tree generalization prob-
lem, their problem estimates the true probabil-
ity distribution from a random sample of exam-
ples (a corpus), whereas our problem does not
have any additional data to estimate, since all
data (a lexicon) is already known. This differ-
ence raises the following issue. In the calcu-
lation of the data description length in equa-
tion (6), each word in a cluster, observed or un-
observed, is assigned an estimated probability,
which is a uniform fraction of the probability
of the cluster. This procedure does not have
interpretation if it is applied to our problem.
Instead, we use the distribution of feature fre-
quency proportion of the clusters, and calculate
the data description length by the following for-
mula:
</bodyText>
<equation confidence="0.998556">
f(C1) x log2P(Ci) (9)
</equation>
<bodyText confidence="0.9997495">
where r = [ci, cd, 0 = [P(C1), -,P(Cic)1•
This corresponds to the length required to en-
code all words in a cluster, for all clusters
in a tree-cut, assuming Huffman&apos;s algorithm
(Huffman, 1952) assigned a codeword of length
—log2P(Ci) to each cluster C, (whose propor-
</bodyText>
<footnote confidence="0.939696">
6We could also combine two (or possibly more) trees
into one tree and apply clustering over that tree once.
In this paper, we describe clustering of two trees for ex-
ample purpose.
</footnote>
<equation confidence="0.996664333333333">
f (C)
P(C) =
L(sir, =-
</equation>
<page confidence="0.994628">
23
</page>
<table confidence="0.709373875">
ARTIFACT
F L(eir) L(sir,e) L(M,S)
[A] 1.66 11.60 13.26
[AC,TOY1 3.32 14.34 17.66
[ap,heli,TOY] 4.98 14.44 19.42
[AC,ball,kite,puz]- 5.64 4.96 11.60
[ap,hel,hall,kite,puz] 8.31 5.06 13.37
airplane helicopter ball kite puzzle
</table>
<figureCaption confidence="0.997373">
Figure 2: The MDL lengths and the final tree-cut
</figureCaption>
<figure confidence="0.997941571428571">
ARTIFACT
*N.
CONTAINER MEDICINE
I
bottle bucket spoon
VESSEL spoon dose
bottle bucket
</figure>
<figureCaption confidence="0.997517">
Figure 3: Parts of WordNet trees ARTIFACT and MEASURE
</figureCaption>
<figure confidence="0.9839405">
dose CONTAINERFUL
MEASURE
.0. .4.
04. *4,4.
</figure>
<bodyText confidence="0.780819333333333">
tion is P(Ci) =
All other notions and formulas are applicable
to our problem without modification.
</bodyText>
<subsectionHeader confidence="0.999582">
3.2 Clustering Method
</subsectionHeader>
<bodyText confidence="0.996489962264151">
Our clustering method uses the the modified
generalization technique described in the last
section to generate tree-cuts. But before we ap-
ply the method, we must transform the data in
Wordnet. This is because WordNet differs from
a theaurus tree in two ways: it is a graph rather
than a tree, and internal nodes as well as leaf
nodes carry data. First, we eliminate multiple
inheritance by separating shared subtrees. Sec-
ond, we bring down every internal node to a
leaf level by creating a new duplicate node and
adding it as a child of the old node (thus making
the old node an internal node).
After trees are transformed, our method ex-
tracts systematic polysemy by the following
three steps. In the first step, all leaf nodes of
the two trees are marked with either 1 or 0 (1
if a node/word appears in both trees, or 0 oth-
erwise).
In the second step, the generalization tech-
nique is applied to each tree, and two tree-cuts
are obtained. To search for the best tree-cut,
instead of computing the description length for
all possible tree-cuts in a tree, a greedy dy-
namic programming algorithm is used. This
algorithm, called Find-MDL in (Li and Abe,
1998), finds the best tree-cut for a tree by recur-
sively finding the best tree-cuts for all of its sub-
trees and merging them from bottom up. This
algorithm is quite efficient, since it is basically a
depth-first search with minor overhead for com-
puting the description length.
Finally in the third step, clusters from the two
tree-cuts are matched up, and the pairs which
have substantial overlap are selected as system-
atic polysemy.
Figure 4 shows parts of the final tree-cuts
for ARTIFACT and MEASURE obtained by our
method.7 In both trees, most of the clusters in
the tree-cuts are from nodes at depth 1 (count-
ing the root as depth 0). That is because the
tree-cut technique used in our method is sensi-
tive to the structure of the tree. More specifi-
cally, the MDL principle inherently penalizes a
complex tree-cut by assigning a long parame-
ter length. Therefore, unless the entropy of the
feature distribution is large enough to make the
data length overshadow the parameter length,
simpler tree-cuts partitioned at abstract levels
are preferred. This situation tends to happen
often when the tree is bushy and the total fea-
ture frequency is low. This was precisely the
case with ARTIFACT and MEASURE, where both
</bodyText>
<footnote confidence="0.981838">
7In the figure, bold letters indicate words which are
polysemous in the two tree.
</footnote>
<page confidence="0.998221">
24
</page>
<figure confidence="0.998598659090909">
ARTIFACT
0.1
base
STRUCTURE
building
foot
IMPLEMENT DEVICE CONTAINER
foot VESSEL spoon
UTENSIL ROD
knot
INSTRUMEN-
TALITY
ZN
DRUG
MEDICINE
N
inhalant dose
TABLEWARE
1
spoon dish plate
ARTICLE
0.02
mixer porcelain bottle bucket
yard
MEASURE
INDEFINITE
QUANTITY
CONTAINERFUL dose load
VIN
0.12
TIME
PERIOD
morning I flash sixties
quarter
0.36
DEFINITE
QUANTITY
bit block
ounce
LINEAR
UNIT
LINEAR
MEASURE
bottle bucket spoon mile knot yard foot
</figure>
<figureCaption confidence="0.999979">
Figure 4: Parts of the final tree-cuts for ARTIFACT and MEASURE
</figureCaption>
<bodyText confidence="0.999805">
trees were quite bushy, and only 4% and 14% of
the words were polysemous in the two categories
respectively.
</bodyText>
<sectionHeader confidence="0.993763" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999899571428571">
To test our method, we chose 5 combinations
from WordNet noun Top categories (which we
call top relation classes), and extracted clus-
ter pairs which have more than 3 overlapping
words. Then we evaluated those pairs in two
aspects: related vs. unrelated relations, and
automatic vs. manual clusters.
</bodyText>
<subsectionHeader confidence="0.808064">
4.1 Related vs. Unrelated Clusters
</subsectionHeader>
<bodyText confidence="0.999981029411765">
Of the cluster pairs we extracted automatically,
not all are systematically related; some are un-
related, homonymous relations. They are essen-
tially false positives for our purposes. Table 1
shows the number of related and unrelated re-
lations in the extracted cluster pairs.
Although the results vary among category
combinations, the ratio of the related pairs is
rather low: less than 60% on average. There are
several reasons for this. First, there are some
pairs whose relations are spurious. For exam-
ple, in ARTIFACT-GROUP class, a pair [LUMBER,
SOCIAL_GROUP] was extracted. Words which
are common in the two clusters are &amp;quot;picket&amp;quot;,
&amp;quot;board&amp;quot; and &amp;quot;stock&amp;quot;. This relation is obviously
homonymous.
Second, some clusters obtained by tree-cut
are rather abstract, so that pairing two ab-
stract clusters results in an unrelated pair. For
example, in ARTIFACT-MEASURE class, a pair
[INSTRUMENTALITY, LINEAR_UNIT] was selected.
Words which are common in the two clus-
ters include &amp;quot;yard&amp;quot;, &amp;quot;foot&amp;quot; and &amp;quot;knot&amp;quot; (see
the previous Figure 4). Here, the concept
INSTRUMENTALITY is very general (at depth
1), and it also contains many (polysemous)
words. So, matching this cluster with an-
other abstract cluster is likely to yield a pair
which has just enough overlapping words but
whose relation is not systematic. In the case
of [INSTRUMENTALITY, LINEAR_UNIT], the situ-
ation is even worse, because the concept of
LINEAR_UNIT in MEASURE represents a collection
of terms that were chosen arbitrarily in the his-
</bodyText>
<page confidence="0.999082">
25
</page>
<tableCaption confidence="0.999865">
Table 1: Related vs. Unrelated Relations
</tableCaption>
<table confidence="0.99844525">
Top relation class Related Unrelated Total &apos; % of
related
ACTION-LOCATION 10 1 11 90.9
ARTIFACT-GROUP 18 9 27 66.7
ARTIFACT-MEASURE 7 19 26 26.9
ARTIFACT-SUBSTANCE 19 12 31 61.3
COMMUNICATION-PERSON 12 11 23 52,2
Total 66 52 118 55.9
</table>
<bodyText confidence="0.70517">
tory of the English language.
</bodyText>
<subsectionHeader confidence="0.987508">
4.2 Automatic vs. Manual Clusters
</subsectionHeader>
<bodyText confidence="0.982348466666667">
To compare the cluster pairs our method ex-
tracted automatically to manually extracted
clusters, we use WordNet cousins. A cousin
relation is relatively new in WordNet, and the
coverage is still incomplete. However, it gives
us a good measure to see whether our auto-
matic method discovered systematic relations
that correspond to human intuitions.
A cousin relation in WordNet is defined be-
tween two synsets (currently in the noun trees
only), and it indicates that senses of a word that
appear in both of the (sub)trees rooted by those
synsets are related.8 The cousins were manually
extracted by the WordNet lexicographers. Ta-
ble 2 shows the number of cousins listed for each
top relation class and the number of cousins our
automatic method recovered (in the &apos;Auto&apos; col-
umn). As you see, the total recall ratio is over
80% (27/33.=-.. .82).
In the right three columns of Table 2, we also
show the breakdown of the recovered cousins,
whether each recovered one was an exact match,
or it was more general or specific than the cor-
responding WordNet cousin. From this, we
can see that more than half of the recovered
cousins were more general than the WordNet
cousins. That is partly because some WordNet
cousins have only one or two common words.
For example, a WordNet cousin [PAINTING,
COLORING_MATERIAL1 in ARTIFACT-SUBSTANCE
has only one common word &amp;quot;watercolor&amp;quot;. Such
8Actually, cousin is one of the three relations which
indicate the grouping of related senses of a word. Others
are sister and twin. In this paper, we use cousin to refer
to all relations listed in &amp;quot;cousin.tps&amp;quot; file (available in a
WordNet distribution).
a minor relation tends to be lost in our tree gen-
eralization procedure. However, the main rea-
son is the difficulty mentioned earlier in the pa-
per: the problem of applying the tree-cut tech-
nique to a bushy tree when the data is sparse.
In addition to the WordNet cousins, our auto-
matic extraction method discovered several in-
teresting relations. Table 3 shows some exam-
ples.
</bodyText>
<sectionHeader confidence="0.993065" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999958263157895">
In this paper, we proposed an automatic
method for extracting systematic polysemy
from WordNet. As we reported, preliminary re-
sults show that our method identified almost
all WordNet cousins as well as some new ones.
One difficulty is that applying the generaliza-
tion technique using the MDL principle to the
bushy WordNet trees seems to yield a tree-cut
at rather abstract level.
For future work, we plan to compare the
systematic relations extracted by our automatic
method to corpus data. In particular, we like
to test whether our method extracts the same
groups of senses which human annotators
disagreed (Ng et al., 1999). We also like to test
whether our method agrees with the finding
that multiple senses which occur in a discourse
are often systematically polysemous (Krovetz,
1998).
</bodyText>
<sectionHeader confidence="0.998625" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984504">
Apresjan, J. (1973). Regular Polysemy. Lin-
guistics, (142).
Buitelaar, P. (1997). A Lexicon for Underspec-
ffied Semantic Tagging. In Proceedings of the
ACL SIGLEX Workshop on Tagging Text
</reference>
<page confidence="0.999316">
26
</page>
<tableCaption confidence="0.995885">
Table 2: Automatic Clusters vs. WordNet Cousins
</tableCaption>
<table confidence="0.998994714285714">
Top relation class WN cousin Auto Exact Gen Spec
ACTION-LOCATION 2 1 0 1 0
ARTIFACT-GROUP 6 6 1 5 0
ARTIFACT-MEASURE 1 1 0 1 0
ARTIFACT-SUBSTANCE 15 13 3 9 1
COMMUNICATION-PERSON 9 6 5 1 0
Total 33 27 9 17 1
</table>
<tableCaption confidence="0.998376">
Table 3: Examples of Automatically Extracted Systematic Polysemy
</tableCaption>
<reference confidence="0.968525180327869">
Top relation class Relation Common Words
ACTION-LOCATION [ACTION, POINT] &amp;quot;drop&amp;quot;, &amp;quot;circle&amp;quot;, &amp;quot;intersection&amp;quot;, &amp;quot;dig&amp;quot;,
&amp;quot;crossing&amp;quot;, &amp;quot;bull&apos;s eye&amp;quot;
ARTIFACT-GROUP STRUCTURE, PEOPLE] &amp;quot;house&amp;quot;, &amp;quot;convent&amp;quot;, &amp;quot;market&amp;quot;, &amp;quot;center&amp;quot;
ARTIFACT-SUBSTANCE FABRIC, CHEMICAL_COMPCIUND] &amp;quot;acetate&amp;quot;, &amp;quot;nylon&amp;quot;, &amp;quot;acrylic&amp;quot;, &amp;quot;polyester&amp;quot;
COMMUNICATION-PERSON VOICE, SINGER] &amp;quot;soprano&amp;quot;, &amp;quot;alto&amp;quot;, &amp;quot;tenor&amp;quot;, &amp;quot;baritone&apos;
- WRITING, RELIGIOUS_PERSON] &amp;quot;John&amp;quot;, &amp;quot;Matthew&amp;quot;, &amp;quot;Jonah&amp;quot;, &amp;quot;Joshua&amp;quot;,
&amp;quot;Jeremiah&amp;quot;
with Lexical Semantics, Washington, D.C.,
pp. 25-33.
Buitelaar, P. (1998). CORELEX: Systematic
Polysemy and Underspecification. Ph.D. dis-
sertation, Department of Computer Science,
Brandeis University.
Copestake, A. and Briscoe, T. (1995). Semi-
productive Polysemy and Sense Extension.
Journal of Semantics, 12.
Cruse, D. (1986). Lexical Semantics, Cam-
bridge University Press.
Huffman, D. A. (1952). A Model for the Con-
struction of Minimum Redundancy Codes.
In Proceedings of the IRE, 40.
Kilgarriff, A. (1998a). SENSEVAL: An Exer-
cise in Evaluating Word Sense Disambigua-
tion Programs. In Proceedings of the LREC
Kilgarriff, A. (1998b). Inter-tagger Agree-
ment. In Advanced Papers of the SENSE-
VAL Workshop, Sussex, UK.
Krovetz, R. (1998). More than One Sense Per
Discourse. In Advanced Papers of the SEN-
SEVAL Workshop, Sussex, UK.
Li, H. and Abe, N. (1998). Generalizing Case
Frames Using a Thesaurus and the MDL
Principle, Computational Linguistics, 24(2),
pp. 217-244
Miller, G. (eds.) (1990). WORDNET: An On-
line Lexical Database. International Journal
of Lexicography, 3 (4).
Ng, WT., Lim, C. and Foo, S. (1999). A
Case Study on Inter-Annotator Agreement
for Word Sense Disambiguation. In Proceed-
ings of the ACL SIGLEX Workshop on Stan-
dardizing Lexical Resources, College Park,
MD.
Nunberg, G. (1995). Transfers of Meaning.
Journal of Semantics, 12.
Procter, P. (1978). Longman dictionary of
Contemporary English, Longman Group.
Pustejovsky, J. (1995). The Generative Lexi-
con, The MIT Press.
Rissanen, J. (1978). Modeling by Shortest
Data Description. Automatic, 14,
Veronis, J. (1998). A Study of Polysemy Judge-
ments and Inter-annotator Agreement. In
Advanced Papers of the SENSE VAL Work-
shop, Sussex, UK.
Vossen, P., Peters, W. and Gonzalo, J. (1999).
Towards a Universal Index of Meaning. In
Proceedings of the ACL SIGLEX Workshop
on Standardizing Lexical Resources, College
Park, MD.
</reference>
<page confidence="0.998805">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000112">
<title confidence="0.8607255">Automatic Extraction of Systematic Polysemy Using Tree-cut Noriko</title>
<author confidence="0.880315">DePaul</author>
<affiliation confidence="0.999092">School of Computer Science, Telecommunications and Information</affiliation>
<address confidence="0.962173">243 S. Wabash Chicago, IL</address>
<email confidence="0.99905">tomuroncs.depaul.edu</email>
<abstract confidence="0.992702140000001">paper describes an for polysemy a hierarchically organized semantic lexicon (WordNet). Systematic polysemy is a set of word senses that are related in systematic and predictable ways. Our method uses a modification of a tree generalization technique used in (Li and Abe, and generates a is a list of clusters that partition a tree. We compare the systematic relations extracted by our automatic method to manually extracted WordNet cousins. In recent years, several on-line broad-coverage semantic lexicons became available, including LDOCE (Procter, 1978), WordNet (Miller, 1990) and HECTOR (Kilgaxriff, 1998a). These lexicons have been used as a domainindependent semantic resource as well as an evaluation criteria in various Natural Language Processing (NLP) tasks, such as Information Retrieval (IR), Information Extraction (IE) and Word Sense Disambiguation (WSD). However, those lexicons are rather complex. For instance, WordNet (version 1.6) contains a total of over 120,000 words and 170,000 word senses, which are grouped into around 100,000 sets). In addition to the size, word entries in those lexicon are often polysemous. For instance, 20% of the words in Wordhave more than one the average number of senses of those polysemous words is around 3. Also, the distinction between word senses tends to be ambiguous and arbitrary. the following 6 senses listed in WordNet for the noun &amp;quot;door&amp;quot;: 1. door a swinging or sliding barrier 2. door the space in a wall 3. door anything providing a means of access (or escape) 4. door a swinging or sliding barrier that will close off access into a car 5. door a house that is entered via a door 6. door a room that is entered via a door Because of the high degree of ambiguity, using such complex semantic lexicons brings some serious problems to the performance of NLP sys- The first, obvious problem is the computational intractability: increased processing needed disambiguate multiple possibiliwill necessarily slow down the Another problem, which has been receiving attention in the past few years, is the inaccuracy: when there is more than one sense applicable in a given context, different systems (or human individuals) may select different senses as the correct sense, Indeed, recent studies in WSD show that, when sense definitions are fine-grained, similar senses become indistinguishable to human annotators and often cause disagreement the correct tag (Ng al., Veronis, Kilgarriff, 1998b). Also in IR and difference in the sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria NLP it must represent senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based a set of word senses that are related in systematic and predictable polysemy (in the sense we use in this is also referred to as regular polyserny 1995). 20 (e.g. of the &amp;quot;chicken&amp;quot; In particular, (Buitelaar, 1997, 1998) identified systematic relations that exist between abstract semantic concepts in the WordNet noun hierarchy, and defined a of semantic classes repthe relations. he extracted all nouns WordNet according to those underspecified classes and built a lexicon called CORELEX. For example, a CORELEX class AQU (which represents a relation between words such as &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;. Using the abstract semantic classes and organizing a lexicon based on systematic polysemy addresses the two problems mentioned above in the following ways. For the first problem, using the abstract classes can reduce the size of the lexicon by combining several related senses into one sense; thus computation becomes more efficient. For the second problem, systematic polysemy does reflect our general intuitions on word meanings. Although the distinction between systematic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniat more fine-grained levels (Vossen al., 1999). For instance, the CORELEX class above also contains a word Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as CONTAINER-CONTAINERFUL relation. We argue that human intuitions can distinguish meanings that systematic polysemy should be contrasted refers to words which have more one unrelated sense (e.g. SLOPING_LAND meanings word &amp;quot;bank&amp;quot;). of &amp;quot;dose&amp;quot; in WordNet are: measured portion of medicine taken at any one time, and (2) the quantity of an active agent (substance or radiation) in or absorbed at any one ARTIFACT AIRCRAFT TOY airplane helicopter ball k&apos;te Figure 1: An example thesaurus tree at this level, where differences between the systematic relations are rather clear, and therefore lexicons that encode word senses at this level of granularity have advantages over fine-grained as well as coarse-grained lexicons in various NLP tasks. Another issue we like to address is the ways for extracting systematic polysemy. Most often, this procedure is done manually. For example, the current version of WordNet (1.6) encodes the similarity between word senses (or by a relation called those cousin relations were identified manually by the WordNet lexicographers. A similar effort was also made in the EuroWordnet project (Vossen However, manually inspecting a large, complex lexicon is very time-consuming and often prone to inconsistencies. In this paper, we propose a method which automatically extracts systematic polysemy from a hierarchically organized semantic lexicon (WordNet). Our method uses a modification of a tree generalization technique used in (Li and 1998), and generates a is a of clusters that partition a tree. compare the systematic relations extracted by our automatic method to the WordNet cousins. Preliminary results show that our method discovered most of the WordNet cousins as well as some more interesting relations. 2 Tree Generalization using Tree-cut and MDL we present we first give a brief summary of the tree-cut technique which we adopted from (Li and Abe, 1998). This technique is used to acquire generalized case frame corpus using a thesaurus tree. Models tree a hierarchically organized where nodes encode lexical data 21 (i.e., words) and internal nodes represent absemantic classes. A is partition of a thesaurus tree. It is a list of internal/leaf nodes in the tree, and each node represents a set of all leaf nodes in a subtree rooted by the Such set is also considered as a clus- Clusters in a tree-cut exhaustively cover all leaf nodes of the tree, and they are mutually disjoint. For example, for a thesaurus tree in Figure 1, there are 5 tree-cuts: [airplane, helicopter, ball, kite, puzzle], [AIRCRAFT, ball, kite, puzzle], [airplane, helicopter, TOY], [AIR- CRAFT, TOY] and [ARTIFACT]. Thus, a treecut corresponds to one of the levels of abstraction in the tree. Using a thesaurus tree and the idea of treecut, the problem of acquiring generalized case frame patters (for a fixed verb) from a corpus is to select the best tree-cut that accounts for both observed and unobserved case frame instances. In (Li and Abe, 1998), this generalization problem is viewed as a problem of selecting the best model for a tree-cut that estimates the true probability distribution, given a sample corpus data. a model M a pair consisting of a tree-cut F and a probability parameter vector () of the same length, (r, 6) (1) e are: = [C1, [P(C1), ..) P(C)] C &lt; &lt; a cluster in the treethe probability of a cluster P(Ci) = For example, suppose a corpus contained 10 instances of verb-object relation for the verb &amp;quot;fly&amp;quot;, and the frequency of object noun n, denoted f (n), are as follows: (airplane) = = (ball) = f (kite) = = Then, the set of tree-cut models for the thesaurus tree shown in Figure 1 includes ([airplane, helicopter, TOY], [0.5, 0.3, 0.2]) and ([AIRCRAFT, TOY], [0.8, 0.2]). that the probability of cluster ..,nm} as whole. It is essentially the sum of all (true) probabilities of the member leaf node is also a cluster whose cardinality is 1. that is, comto knowing all 1 &lt;j knowing one only facilitate an estimate of uniform probability distribution among members as the best guess, that for all in general, clusters are merged and generalto to the thesaurus tree, the estimation of a probability model becomes less accurate. 2.2 The MDL Principle To select the best tree-cut model, (Li and Abe, uses the Description Length (Rissanen, 1978). The MDL is a principle of data compression in Information which states that, for a given the best model is the one which requires the minimum length (often measured in bits) to enthe model (the description length) the data (the description length). the problem of case frame generalization, the MDL principle fits very well in that it captures the trade-off between the simplicity of a model, which is measured by the number of clusters in tree-cut, and of fit to the data, which is measured by the estimation accuracy of the probability distribution. The calculation of the description length for model is as follows. Given a thetree a sample of the case frame instances, the total description S) a tree-cut model is 5) = + goir) + L(sir,e) the model description length, MOW) is the parameter description length (exshortly), and is the data delength. Note that L(P) L(eir) essentially corresponds to the usual notion of the model description length. length in 5) calculated as fol- The model description length = the set of in IG1 dethe size of is constant for • and detailed explanation of these formulas, see (Li and Abe, 1998). 22 all models, thus it is omitted in the calculation of the total length. The parameter description length L(IF) indicates the complexity of the model. It is the length required to encode the probability disof the clusters in the tree-cut It calculated as (5) 2 where k is the length of 0, and ISI is the size of S. the data description length e) is the length required to encode the whole sample data. It is calculated as nEs for each n each (n) and Is&apos; here that, in (7), the probability of dievenly among all n in way, words that are not observed in the sample receive a non-zero probability, and the data sparseness problem is avoided. Then, the best model is the one which requires the minimum total description length. Figure 2 shows the MDL lengths for all five tree-cut models that can be produced for the thesaurus tree in Figure I. The best model is the one with the tree-cut [AIRCRAFT, ball, kite, indicated by a thick curve in 3 Clustering Systematic Polysemy 3.1 Generalization Technique Using the generalization technique in (Li and Abe, 1998) described in the previous section, we wish to extract systematic polysemy automatically from WordNet. Our assumption is that, if a semantic concept is systematically related to another concept, words that have one sense under one concept (sub)tree are likely to have another sense under the other concept (sub)tree. To give an example, Fig- 3 shows parts of WordNet noun trees and MEASURE, subtrees under con- &amp;quot;bucket&amp;quot; and &amp;quot;spoon&apos;. Note a dashed line in the figure indicates an indirect link for more than one level. on this assumption, it systemin the two trees can be extracted straight-forwardly by clustering each tree according to polysemy as a feature, and by matchof clusters taken from each To this end, the notion of tree-cut and the MDL principle seem to comprise an excellent tool. However, we must be careful in adopting Li and Abe&apos;s technique directly: since the problem which their technique was applied to is fundamentally different from ours, some procedures in problem may have any interpretation in our problem. Although both problems are essentially a tree generalization problem, their problem estimates the true probability distribution from a random sample of examples (a corpus), whereas our problem does not have any additional data to estimate, since all data (a lexicon) is already known. This difference raises the following issue. In the calculation of the data description length in equation (6), each word in a cluster, observed or unobserved, is assigned an estimated probability, which is a uniform fraction of the probability of the cluster. This procedure does not have interpretation if it is applied to our problem. Instead, we use the distribution of feature frequency proportion of the clusters, and calculate the data description length by the following formula: x = cd, 0 = -,P(Cic)1• This corresponds to the length required to encode all words in a cluster, for all clusters in a tree-cut, assuming Huffman&apos;s algorithm (Huffman, 1952) assigned a codeword of length each cluster C, (whose proporcould also combine two (or possibly more) trees into one tree and apply clustering over that tree once. paper, we describe clustering of two trees for exf (C) P(C) = 23 ARTIFACT F L(eir) L(sir,e) L(M,S) [A] 1.66 11.60 13.26 [AC,TOY1 3.32 14.34 17.66 [ap,heli,TOY] 4.98 14.44 19.42 [AC,ball,kite,puz]- 5.64 4.96 11.60 [ap,hel,hall,kite,puz] 8.31 5.06 13.37 airplane helicopter ball kite puzzle Figure 2: The MDL lengths and the final tree-cut ARTIFACT *N. CONTAINER MEDICINE I bottle bucket spoon VESSEL spoon dose bottle bucket 3: Parts of WordNet trees MEASURE is = All other notions and formulas are applicable to our problem without modification. 3.2 Clustering Method Our clustering method uses the the modified generalization technique described in the last section to generate tree-cuts. But before we apply the method, we must transform the data in Wordnet. This is because WordNet differs from a theaurus tree in two ways: it is a graph rather than a tree, and internal nodes as well as leaf nodes carry data. First, we eliminate multiple inheritance by separating shared subtrees. Second, we bring down every internal node to a leaf level by creating a new duplicate node and adding it as a child of the old node (thus making the old node an internal node). After trees are transformed, our method extracts systematic polysemy by the following three steps. In the first step, all leaf nodes of two trees are marked with either 0 if a node/word appears in both trees, or 0 otherwise). In the second step, the generalization technique is applied to each tree, and two tree-cuts are obtained. To search for the best tree-cut, instead of computing the description length for all possible tree-cuts in a tree, a greedy dynamic programming algorithm is used. This called (Li and Abe, 1998), finds the best tree-cut for a tree by recurfinding the all of its submerging them from bottom up. This algorithm is quite efficient, since it is basically a depth-first search with minor overhead for computing the description length. Finally in the third step, clusters from the two tree-cuts are matched up, and the pairs which substantial overlap are selected systematic polysemy. Figure 4 shows parts of the final tree-cuts by our In both trees, most of the clusters in the tree-cuts are from nodes at depth 1 (counting the root as depth 0). That is because the tree-cut technique used in our method is sensitive to the structure of the tree. More specifically, the MDL principle inherently penalizes a complex tree-cut by assigning a long parameter length. Therefore, unless the entropy of the feature distribution is large enough to make the data length overshadow the parameter length, simpler tree-cuts partitioned at abstract levels are preferred. This situation tends to happen often when the tree is bushy and the total feature frequency is low. This was precisely the with MEASURE, where both the figure, bold letters indicate words which are polysemous in the two tree. 24 ARTIFACT 0.1 base STRUCTURE building foot IMPLEMENT DEVICE CONTAINER foot VESSEL spoon UTENSIL ROD knot INSTRUMEN- TALITY ZN MEDICINE N inhalant dose TABLEWARE 1 plate ARTICLE 0.02 mixer porcelain bottle bucket yard MEASURE QUANTITY load 0.12 TIME PERIOD morning I flash sixties quarter 0.36 DEFINITE QUANTITY bit block ounce LINEAR UNIT LINEAR MEASURE bucket spoon yard foot Figure 4: Parts of the final tree-cuts for ARTIFACT and MEASURE were quite bushy, and only 14% of the words were polysemous in the two categories respectively. To test our method, we chose 5 combinations from WordNet noun Top categories (which we relation classes), extracted cluster pairs which have more than 3 overlapping words. Then we evaluated those pairs in two aspects: related vs. unrelated relations, and automatic vs. manual clusters. Related Unrelated Of the cluster pairs we extracted automatically, not all are systematically related; some are unrelated, homonymous relations. They are essentially false positives for our purposes. Table 1 shows the number of related and unrelated relations in the extracted cluster pairs. Although the results vary among category combinations, the ratio of the related pairs is low: less than average. There are several reasons for this. First, there are some pairs whose relations are spurious. For example, in ARTIFACT-GROUP class, a pair [LUMBER, was extracted. Words common the two clusters are &amp;quot;picket&amp;quot;, &amp;quot;board&amp;quot; and &amp;quot;stock&amp;quot;. This relation is obviously homonymous. Second, some clusters obtained by tree-cut are rather abstract, so that pairing two abstract clusters results in an unrelated pair. For example, in ARTIFACT-MEASURE class, a pair LINEAR_UNIT] Words which are common in the two clusters include &amp;quot;yard&amp;quot;, &amp;quot;foot&amp;quot; and &amp;quot;knot&amp;quot; (see the previous Figure 4). Here, the concept INSTRUMENTALITY is very general (at depth 1), and it also contains many (polysemous) words. So, matching this cluster with another abstract cluster is likely to yield a pair which has just enough overlapping words but whose relation is not systematic. In the case LINEAR_UNIT], situation is even worse, because the concept of in a collection terms that were chosen arbitrarily in the his- 25 Table 1: Related vs. Unrelated Relations Top relation class Related Unrelated Total &apos; % of related ACTION-LOCATION 10 1 11 90.9 ARTIFACT-GROUP 27 66.7 ARTIFACT-MEASURE 7 19 26 26.9 ARTIFACT-SUBSTANCE 31 61.3 COMMUNICATION-PERSON 23 52,2 Total 66 52 118 55.9 tory of the English language. 4.2 Automatic vs. Manual Clusters To compare the cluster pairs our method extracted automatically to manually extracted we use WordNet cousin relation is relatively new in WordNet, and the coverage is still incomplete. However, it gives a measure to see whether our automatic method discovered systematic relations that correspond to human intuitions. A cousin relation in WordNet is defined between two synsets (currently in the noun trees only), and it indicates that senses of a word that appear in both of the (sub)trees rooted by those are The cousins were manually extracted by the WordNet lexicographers. Table 2 shows the number of cousins listed for each top relation class and the number of cousins our automatic method recovered (in the &apos;Auto&apos; column). As you see, the total recall ratio is over 80% (27/33.=-.. .82). In the right three columns of Table 2, we also show the breakdown of the recovered cousins, whether each recovered one was an exact match, or it was more general or specific than the corresponding WordNet cousin. From this, we can see that more than half of the recovered cousins were more general than the WordNet cousins. That is partly because some WordNet cousins have only one or two common words. a WordNet cousin has only one common word &amp;quot;watercolor&amp;quot;. Such cousin is one of the three relations which indicate the grouping of related senses of a word. Others this paper, we use cousin to refer to all relations listed in &amp;quot;cousin.tps&amp;quot; file (available in a WordNet distribution). a minor relation tends to be lost in our tree generalization procedure. However, the main reason is the difficulty mentioned earlier in the paper: the problem of applying the tree-cut technique to a bushy tree when the data is sparse. In addition to the WordNet cousins, our automatic extraction method discovered several inrelations. Table 3 shows examples. 5 Conclusions and Future Work In this paper, we proposed an automatic method for extracting systematic polysemy from WordNet. As we reported, preliminary results show that our method identified almost all WordNet cousins as well as some new ones. One difficulty is that applying the generalization technique using the MDL principle to the bushy WordNet trees seems to yield a tree-cut at rather abstract level. For future work, we plan to compare the systematic relations extracted by our automatic method to corpus data. In particular, we like to test whether our method extracts the same groups of senses which human annotators (Ng 1999). We also like to test whether our method agrees with the finding that multiple senses which occur in a discourse are often systematically polysemous (Krovetz, 1998).</abstract>
<title confidence="0.584329">References</title>
<author confidence="0.535665">Lin-</author>
<note confidence="0.797107638888889">Buitelaar, P. (1997). A Lexicon for Underspec- Semantic Tagging. In of the ACL SIGLEX Workshop on Tagging Text 26 Table 2: Automatic Clusters vs. WordNet Cousins Top relation class WN cousin Auto Exact Gen Spec ACTION-LOCATION 2 1 0 1 0 ARTIFACT-GROUP 6 6 1 5 0 ARTIFACT-MEASURE 1 1 0 1 0 ARTIFACT-SUBSTANCE 15 13 3 9 1 COMMUNICATION-PERSON 9 6 5 1 0 Total 33 27 9 17 1 Table 3: Examples of Automatically Extracted Systematic Polysemy Top relation class Relation Common Words [ACTION, POINT] &amp;quot;drop&amp;quot;, &amp;quot;circle&amp;quot;, &amp;quot;intersection&amp;quot;, &amp;quot;dig&amp;quot;, &amp;quot;crossing&amp;quot;, &amp;quot;bull&apos;s eye&amp;quot; STRUCTURE, PEOPLE] &amp;quot;house&amp;quot;, &amp;quot;convent&amp;quot;, &amp;quot;market&amp;quot;, &amp;quot;center&amp;quot; FABRIC, CHEMICAL_COMPCIUND] &amp;quot;acetate&amp;quot;, &amp;quot;nylon&amp;quot;, &amp;quot;acrylic&amp;quot;, &amp;quot;polyester&amp;quot; VOICE, SINGER] &amp;quot;soprano&amp;quot;, &amp;quot;alto&amp;quot;, &amp;quot;tenor&amp;quot;, &amp;quot;baritone&apos; RELIGIOUS_PERSON] &amp;quot;John&amp;quot;, &amp;quot;Matthew&amp;quot;, &amp;quot;Jonah&amp;quot;, &amp;quot;Joshua&amp;quot;, &amp;quot;Jeremiah&amp;quot; Lexical Semantics, D.C., pp. 25-33. Buitelaar, P. (1998). CORELEX: Systematic Polysemy and Underspecification. Ph.D. disof Computer Brandeis University. Copestake, A. and Briscoe, T. (1995). Semiproductive Polysemy and Sense Extension. of Semantics, D. (1986). Semantics, Cambridge University Press. Huffman, D. A. (1952). A Model for the Construction of Minimum Redundancy Codes. of the IRE, Kilgarriff, A. (1998a). SENSEVAL: An Exercise in Evaluating Word Sense Disambigua- Programs. In of the LREC A. (1998b). In Papers of the SENSE- Workshop, UK. Krovetz, R. (1998). More than One Sense Per In Papers of the SEN- Workshop, UK. Li, H. and Abe, N. (1998). Generalizing Case Frames Using a Thesaurus and the MDL Linguistics, Miller, G. (eds.) (1990). WORDNET: An On- Lexical Database. Journal Lexicography, (4). Ng, WT., Lim, C. and Foo, S. (1999). A Study on Agreement Word Sense Disambiguation. In Proceedings of the ACL SIGLEX Workshop on Stan- Lexical Resources, Park, MD. Nunberg, G. (1995). Transfers of Meaning. of Semantics, P. (1978). dictionary of English, Group. J. (1995). Lexi- MIT Press. Rissanen, J. (1978). Modeling by Shortest Description. Veronis, J. (1998). A Study of Polysemy Judgements and Inter-annotator Agreement. In Advanced Papers of the SENSE VAL Work- UK. Vossen, P., Peters, W. and Gonzalo, J. (1999). Towards a Universal Index of Meaning. In Proceedings of the ACL SIGLEX Workshop Standardizing Lexical Resources, Park, MD. 27</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Apresjan</author>
</authors>
<title>Regular Polysemy. Linguistics,</title>
<date>1973</date>
<contexts>
<context position="3492" citStr="Apresjan, 1973" startWordPosition="559" endWordPosition="560">o in IR and IE tasks, difference in the correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred to as regular polysemy (Apresjan, 1973) or logical polyserny (Pustejovsky, 1995). 20 ways (e.g. ANIMAL and MEAT meanings of the word &amp;quot;chicken&amp;quot; ).2 In particular, (Buitelaar, 1997, 1998) identified systematic relations that exist between abstract semantic concepts in the WordNet noun hierarchy, and defined a set of underspecified semantic classes that represent the relations. Then he extracted all polysemous nouns in WordNet according to those underspecified classes and built a lexicon called CORELEX. For example, a CORELEX class AQU (which represents a relation between ARTIFACT and QUANTITY) contains words such as &amp;quot;bottle&amp;quot;, &amp;quot;bucket</context>
<context position="4813" citStr="Apresjan, 1973" startWordPosition="758" endWordPosition="760">dresses the two problems mentioned above in the following ways. For the first problem, using the abstract classes can reduce the size of the lexicon by combining several related senses into one sense; thus computation becomes more efficient. For the second problem, systematic polysemy does reflect our general intuitions on word meanings. Although the distinction between systematic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniformly at more fine-grained levels (Vossen et al., 1999). For instance, the CORELEX class AQU mentioned above also contains a word &amp;quot;dose&amp;quot; .3 Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as </context>
</contexts>
<marker>Apresjan, 1973</marker>
<rawString>Apresjan, J. (1973). Regular Polysemy. Linguistics, (142).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
</authors>
<title>A Lexicon for Underspecffied Semantic Tagging.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Tagging Text Top relation class Relation Common Words ACTION-LOCATION [ACTION, POINT]</booktitle>
<pages>25--33</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="3631" citStr="Buitelaar, 1997" startWordPosition="580" endWordPosition="581">ent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred to as regular polysemy (Apresjan, 1973) or logical polyserny (Pustejovsky, 1995). 20 ways (e.g. ANIMAL and MEAT meanings of the word &amp;quot;chicken&amp;quot; ).2 In particular, (Buitelaar, 1997, 1998) identified systematic relations that exist between abstract semantic concepts in the WordNet noun hierarchy, and defined a set of underspecified semantic classes that represent the relations. Then he extracted all polysemous nouns in WordNet according to those underspecified classes and built a lexicon called CORELEX. For example, a CORELEX class AQU (which represents a relation between ARTIFACT and QUANTITY) contains words such as &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;. Using the abstract semantic classes and organizing a lexicon based on systematic polysemy addresses the two problems mention</context>
</contexts>
<marker>Buitelaar, 1997</marker>
<rawString>Buitelaar, P. (1997). A Lexicon for Underspecffied Semantic Tagging. In Proceedings of the ACL SIGLEX Workshop on Tagging Text Top relation class Relation Common Words ACTION-LOCATION [ACTION, POINT] &amp;quot;drop&amp;quot;, &amp;quot;circle&amp;quot;, &amp;quot;intersection&amp;quot;, &amp;quot;dig&amp;quot;, &amp;quot;crossing&amp;quot;, &amp;quot;bull&apos;s eye&amp;quot; ARTIFACT-GROUP STRUCTURE, PEOPLE] with Lexical Semantics, Washington, D.C., pp. 25-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
</authors>
<title>CORELEX: Systematic Polysemy and Underspecification.</title>
<date>1998</date>
<tech>Ph.D. dissertation,</tech>
<institution>Department of Computer Science, Brandeis University.</institution>
<marker>Buitelaar, 1998</marker>
<rawString>Buitelaar, P. (1998). CORELEX: Systematic Polysemy and Underspecification. Ph.D. dissertation, Department of Computer Science, Brandeis University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>T Briscoe</author>
</authors>
<title>Semiproductive Polysemy and Sense Extension.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<contexts>
<context position="4871" citStr="Copestake and Briscoe, 1995" startWordPosition="765" endWordPosition="769">the following ways. For the first problem, using the abstract classes can reduce the size of the lexicon by combining several related senses into one sense; thus computation becomes more efficient. For the second problem, systematic polysemy does reflect our general intuitions on word meanings. Although the distinction between systematic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniformly at more fine-grained levels (Vossen et al., 1999). For instance, the CORELEX class AQU mentioned above also contains a word &amp;quot;dose&amp;quot; .3 Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as CONTAINER-CONTAINERFUL relation. We argue that human intui</context>
</contexts>
<marker>Copestake, Briscoe, 1995</marker>
<rawString>Copestake, A. and Briscoe, T. (1995). Semiproductive Polysemy and Sense Extension. Journal of Semantics, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>Lexical Semantics,</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4826" citStr="Cruse, 1986" startWordPosition="761" endWordPosition="762">problems mentioned above in the following ways. For the first problem, using the abstract classes can reduce the size of the lexicon by combining several related senses into one sense; thus computation becomes more efficient. For the second problem, systematic polysemy does reflect our general intuitions on word meanings. Although the distinction between systematic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniformly at more fine-grained levels (Vossen et al., 1999). For instance, the CORELEX class AQU mentioned above also contains a word &amp;quot;dose&amp;quot; .3 Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as CONTAINER-CON</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>Cruse, D. (1986). Lexical Semantics, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Huffman</author>
</authors>
<title>A Model for the Construction of Minimum Redundancy Codes.</title>
<date>1952</date>
<booktitle>In Proceedings of the IRE,</booktitle>
<pages>40</pages>
<contexts>
<context position="15058" citStr="Huffman, 1952" startWordPosition="2531" endWordPosition="2532">length in equation (6), each word in a cluster, observed or unobserved, is assigned an estimated probability, which is a uniform fraction of the probability of the cluster. This procedure does not have interpretation if it is applied to our problem. Instead, we use the distribution of feature frequency proportion of the clusters, and calculate the data description length by the following formula: f(C1) x log2P(Ci) (9) where r = [ci, cd, 0 = [P(C1), -,P(Cic)1• This corresponds to the length required to encode all words in a cluster, for all clusters in a tree-cut, assuming Huffman&apos;s algorithm (Huffman, 1952) assigned a codeword of length —log2P(Ci) to each cluster C, (whose propor6We could also combine two (or possibly more) trees into one tree and apply clustering over that tree once. In this paper, we describe clustering of two trees for example purpose. f (C) P(C) = L(sir, =- 23 ARTIFACT F L(eir) L(sir,e) L(M,S) [A] 1.66 11.60 13.26 [AC,TOY1 3.32 14.34 17.66 [ap,heli,TOY] 4.98 14.44 19.42 [AC,ball,kite,puz]- 5.64 4.96 11.60 [ap,hel,hall,kite,puz] 8.31 5.06 13.37 airplane helicopter ball kite puzzle Figure 2: The MDL lengths and the final tree-cut ARTIFACT *N. CONTAINER MEDICINE I bottle bucket</context>
</contexts>
<marker>Huffman, 1952</marker>
<rawString>Huffman, D. A. (1952). A Model for the Construction of Minimum Redundancy Codes. In Proceedings of the IRE, 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>SENSEVAL: An Exercise in Evaluating Word Sense Disambiguation Programs.</title>
<date>1998</date>
<booktitle>In Proceedings of the LREC</booktitle>
<contexts>
<context position="2870" citStr="Kilgarriff, 1998" startWordPosition="457" endWordPosition="458">intractability: increased processing time needed to disambiguate multiple possibilities will necessarily slow down the system. Another problem, which has been receiving attention in the past few years, is the inaccuracy: when there is more than one sense applicable in a given context, different systems (or human individuals) may select different senses as the correct sense, Indeed, recent studies in WSD show that, when sense definitions are fine-grained, similar senses become indistinguishable to human annotators and often cause disagreement on the correct tag (Ng et al., 1999; Veronis, 1998; Kilgarriff, 1998b). Also in IR and IE tasks, difference in the correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred to as regular pol</context>
</contexts>
<marker>Kilgarriff, 1998</marker>
<rawString>Kilgarriff, A. (1998a). SENSEVAL: An Exercise in Evaluating Word Sense Disambiguation Programs. In Proceedings of the LREC</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Inter-tagger Agreement.</title>
<date>1998</date>
<booktitle>In Advanced Papers of the SENSEVAL Workshop,</booktitle>
<location>Sussex, UK.</location>
<contexts>
<context position="2870" citStr="Kilgarriff, 1998" startWordPosition="457" endWordPosition="458">intractability: increased processing time needed to disambiguate multiple possibilities will necessarily slow down the system. Another problem, which has been receiving attention in the past few years, is the inaccuracy: when there is more than one sense applicable in a given context, different systems (or human individuals) may select different senses as the correct sense, Indeed, recent studies in WSD show that, when sense definitions are fine-grained, similar senses become indistinguishable to human annotators and often cause disagreement on the correct tag (Ng et al., 1999; Veronis, 1998; Kilgarriff, 1998b). Also in IR and IE tasks, difference in the correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred to as regular pol</context>
</contexts>
<marker>Kilgarriff, 1998</marker>
<rawString>Kilgarriff, A. (1998b). Inter-tagger Agreement. In Advanced Papers of the SENSEVAL Workshop, Sussex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Krovetz</author>
</authors>
<title>More than One Sense Per Discourse.</title>
<date>1998</date>
<booktitle>In Advanced Papers of the SENSEVAL Workshop,</booktitle>
<location>Sussex, UK.</location>
<marker>Krovetz, 1998</marker>
<rawString>Krovetz, R. (1998). More than One Sense Per Discourse. In Advanced Papers of the SENSEVAL Workshop, Sussex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>N Abe</author>
</authors>
<title>Generalizing Case Frames Using a Thesaurus and the MDL Principle,</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<pages>217--244</pages>
<contexts>
<context position="7024" citStr="Li and Abe, 1998" startWordPosition="1106" endWordPosition="1109">n of WordNet (1.6) encodes the similarity between word senses (or synsets) by a relation called cousin. But those cousin relations were identified manually by the WordNet lexicographers. A similar effort was also made in the EuroWordnet project (Vossen et at., 1999). However, manually inspecting a large, complex lexicon is very time-consuming and often prone to inconsistencies. In this paper, we propose a method which automatically extracts systematic polysemy from a hierarchically organized semantic lexicon (WordNet). Our method uses a modification of a tree generalization technique used in (Li and Abe, 1998), and generates a tree-cut, which is a list of clusters that partition a tree. Then, we compare the systematic relations extracted by our automatic method to the WordNet cousins. Preliminary results show that our method discovered most of the WordNet cousins as well as some more interesting relations. 2 Tree Generalization using Tree-cut and MDL Before we present our method, we first give a brief summary of the tree-cut technique which we adopted from (Li and Abe, 1998). This technique is used to acquire generalized case frame patterns from a corpus using a thesaurus tree. 2.1 Tree-cut Models </context>
<context position="8654" citStr="Li and Abe, 1998" startWordPosition="1388" endWordPosition="1391">ustively cover all leaf nodes of the tree, and they are mutually disjoint. For example, for a thesaurus tree in Figure 1, there are 5 tree-cuts: [airplane, helicopter, ball, kite, puzzle], [AIRCRAFT, ball, kite, puzzle], [airplane, helicopter, TOY], [AIRCRAFT, TOY] and [ARTIFACT]. Thus, a treecut corresponds to one of the levels of abstraction in the tree. Using a thesaurus tree and the idea of treecut, the problem of acquiring generalized case frame patters (for a fixed verb) from a corpus is to select the best tree-cut that accounts for both observed and unobserved case frame instances. In (Li and Abe, 1998), this generalization problem is viewed as a problem of selecting the best model for a tree-cut that estimates the true probability distribution, given a sample corpus data. Formally, a tree-cut model M is a pair consisting of a tree-cut F and a probability parameter vector () of the same length, m , (r, 6) (1) where r and e are: r = [C1, Cid, = [P(C1), ..) P(C)] (2) where C (1 &lt; i &lt; k) is a cluster in the treecut, P(Ci) is the probability of a cluster and ak_i P(Ci) = 1. For example, suppose a corpus contained 10 instances of verb-object relation for the verb &amp;quot;fly&amp;quot;, and the frequency of objec</context>
<context position="10233" citStr="Li and Abe, 1998" startWordPosition="1683" endWordPosition="1686"> is essentially the sum of all (true) probabilities of the member 4A leaf node is also a cluster whose cardinality is 1. words, that is, P(C) = P(ni). Here, compared to knowing all P(ni) (where 1 &lt;j &lt;m) individually, knowing one P(C) can only facilitate an estimate of uniform probability distribution among members as the best guess, that is, P(nj) =11--).:}3 for all j. Therefore, in general, when clusters C1..C, are merged and generalized to C according to the thesaurus tree, the estimation of a probability model becomes less accurate. 2.2 The MDL Principle To select the best tree-cut model, (Li and Abe, 1998) uses the Minimal Description Length (MDL) principle (Rissanen, 1978). The MDL is a principle of data compression in Information Theory which states that, for a given dataset, the best model is the one which requires the minimum length (often measured in bits) to encode the model (the model description length) and the data (the data description length). For the problem of case frame generalization, the MDL principle fits very well in that it captures the trade-off between the simplicity of a model, which is measured by the number of clusters in a tree-cut, and the goodness of fit to the data, </context>
<context position="11712" citStr="Li and Abe, 1998" startWordPosition="1944" endWordPosition="1947">th L(M, S) for a tree-cut model M 0) is L(M, 5) = L(r) + goir) + L(sir,e) (3) where L(r) is the model description length, MOW) is the parameter description length (explained shortly), and L(sir,e) is the data description length. Note that L(P) L(eir) essentially corresponds to the usual notion of the model description length. Each length in L(M, 5) is calculated as follows.5 The model description length L(r) is L(r) = log2IGI (4) where G is the set of all cuts in T, and IG1 denotes the size of G. This value is a constant for •5For justification and detailed explanation of these formulas, see (Li and Abe, 1998). 22 all models, thus it is omitted in the calculation of the total length. The parameter description length L(IF) indicates the complexity of the model. It is the length required to encode the probability distribution of the clusters in the tree-cut F. It is calculated as Row) _k x /og21,51 (5) 2 where k is the length of 0, and ISI is the size of S. Finally, the data description length L(sir, e) is the length required to encode the whole sample data. It is calculated as L(sir, e) E lo92P(n) (6) nEs where, for each n G C and each C E r, P (n) and Is&apos; Note here that, in (7), the probability of </context>
<context position="17071" citStr="Li and Abe, 1998" startWordPosition="2872" endWordPosition="2875">he old node (thus making the old node an internal node). After trees are transformed, our method extracts systematic polysemy by the following three steps. In the first step, all leaf nodes of the two trees are marked with either 1 or 0 (1 if a node/word appears in both trees, or 0 otherwise). In the second step, the generalization technique is applied to each tree, and two tree-cuts are obtained. To search for the best tree-cut, instead of computing the description length for all possible tree-cuts in a tree, a greedy dynamic programming algorithm is used. This algorithm, called Find-MDL in (Li and Abe, 1998), finds the best tree-cut for a tree by recursively finding the best tree-cuts for all of its subtrees and merging them from bottom up. This algorithm is quite efficient, since it is basically a depth-first search with minor overhead for computing the description length. Finally in the third step, clusters from the two tree-cuts are matched up, and the pairs which have substantial overlap are selected as systematic polysemy. Figure 4 shows parts of the final tree-cuts for ARTIFACT and MEASURE obtained by our method.7 In both trees, most of the clusters in the tree-cuts are from nodes at depth </context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Li, H. and Abe, N. (1998). Generalizing Case Frames Using a Thesaurus and the MDL Principle, Computational Linguistics, 24(2), pp. 217-244</rawString>
</citation>
<citation valid="true">
<title>WORDNET: An Online Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<editor>Miller, G. (eds.)</editor>
<marker>1990</marker>
<rawString>Miller, G. (eds.) (1990). WORDNET: An Online Lexical Database. International Journal of Lexicography, 3 (4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>WT Ng</author>
<author>C Lim</author>
<author>S Foo</author>
</authors>
<title>A Case Study on Inter-Annotator Agreement for Word Sense Disambiguation.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources,</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="2837" citStr="Ng et al., 1999" startWordPosition="451" endWordPosition="454">us problem is the computational intractability: increased processing time needed to disambiguate multiple possibilities will necessarily slow down the system. Another problem, which has been receiving attention in the past few years, is the inaccuracy: when there is more than one sense applicable in a given context, different systems (or human individuals) may select different senses as the correct sense, Indeed, recent studies in WSD show that, when sense definitions are fine-grained, similar senses become indistinguishable to human annotators and often cause disagreement on the correct tag (Ng et al., 1999; Veronis, 1998; Kilgarriff, 1998b). Also in IR and IE tasks, difference in the correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) i</context>
</contexts>
<marker>Ng, Lim, Foo, 1999</marker>
<rawString>Ng, WT., Lim, C. and Foo, S. (1999). A Case Study on Inter-Annotator Agreement for Word Sense Disambiguation. In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nunberg</author>
</authors>
<title>Transfers of Meaning.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<contexts>
<context position="4841" citStr="Nunberg, 1995" startWordPosition="763" endWordPosition="764">ioned above in the following ways. For the first problem, using the abstract classes can reduce the size of the lexicon by combining several related senses into one sense; thus computation becomes more efficient. For the second problem, systematic polysemy does reflect our general intuitions on word meanings. Although the distinction between systematic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniformly at more fine-grained levels (Vossen et al., 1999). For instance, the CORELEX class AQU mentioned above also contains a word &amp;quot;dose&amp;quot; .3 Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as CONTAINER-CONTAINERFUL relat</context>
</contexts>
<marker>Nunberg, 1995</marker>
<rawString>Nunberg, G. (1995). Transfers of Meaning. Journal of Semantics, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Procter</author>
</authors>
<title>Longman dictionary of Contemporary English,</title>
<date>1978</date>
<publisher>Longman Group.</publisher>
<contexts>
<context position="872" citStr="Procter, 1978" startWordPosition="122" endWordPosition="123">atic method for extracting systematic polysemy from a hierarchically organized semantic lexicon (WordNet). Systematic polysemy is a set of word senses that are related in systematic and predictable ways. Our method uses a modification of a tree generalization technique used in (Li and Abe, 1998), and generates a tree-cut, which is a list of clusters that partition a tree. We compare the systematic relations extracted by our automatic method to manually extracted WordNet cousins. 1 Introduction In recent years, several on-line broad-coverage semantic lexicons became available, including LDOCE (Procter, 1978), WordNet (Miller, 1990) and HECTOR (Kilgaxriff, 1998a). These lexicons have been used as a domainindependent semantic resource as well as an evaluation criteria in various Natural Language Processing (NLP) tasks, such as Information Retrieval (IR), Information Extraction (IE) and Word Sense Disambiguation (WSD). However, those lexicons are rather complex. For instance, WordNet (version 1.6) contains a total of over 120,000 words and 170,000 word senses, which are grouped into around 100,000 synsets (synonym sets). In addition to the size, word entries in those lexicon are often polysemous. Fo</context>
</contexts>
<marker>Procter, 1978</marker>
<rawString>Procter, P. (1978). Longman dictionary of Contemporary English, Longman Group.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The Generative Lexicon,</title>
<date>1995</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="3533" citStr="Pustejovsky, 1995" startWordPosition="564" endWordPosition="565">e correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred to as regular polysemy (Apresjan, 1973) or logical polyserny (Pustejovsky, 1995). 20 ways (e.g. ANIMAL and MEAT meanings of the word &amp;quot;chicken&amp;quot; ).2 In particular, (Buitelaar, 1997, 1998) identified systematic relations that exist between abstract semantic concepts in the WordNet noun hierarchy, and defined a set of underspecified semantic classes that represent the relations. Then he extracted all polysemous nouns in WordNet according to those underspecified classes and built a lexicon called CORELEX. For example, a CORELEX class AQU (which represents a relation between ARTIFACT and QUANTITY) contains words such as &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;. Using the abstract semanti</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>Pustejovsky, J. (1995). The Generative Lexicon, The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rissanen</author>
</authors>
<title>Modeling by Shortest Data Description.</title>
<date>1978</date>
<journal>Automatic,</journal>
<volume>14</volume>
<contexts>
<context position="10302" citStr="Rissanen, 1978" startWordPosition="1694" endWordPosition="1695">af node is also a cluster whose cardinality is 1. words, that is, P(C) = P(ni). Here, compared to knowing all P(ni) (where 1 &lt;j &lt;m) individually, knowing one P(C) can only facilitate an estimate of uniform probability distribution among members as the best guess, that is, P(nj) =11--).:}3 for all j. Therefore, in general, when clusters C1..C, are merged and generalized to C according to the thesaurus tree, the estimation of a probability model becomes less accurate. 2.2 The MDL Principle To select the best tree-cut model, (Li and Abe, 1998) uses the Minimal Description Length (MDL) principle (Rissanen, 1978). The MDL is a principle of data compression in Information Theory which states that, for a given dataset, the best model is the one which requires the minimum length (often measured in bits) to encode the model (the model description length) and the data (the data description length). For the problem of case frame generalization, the MDL principle fits very well in that it captures the trade-off between the simplicity of a model, which is measured by the number of clusters in a tree-cut, and the goodness of fit to the data, which is measured by the estimation accuracy of the probability distr</context>
</contexts>
<marker>Rissanen, 1978</marker>
<rawString>Rissanen, J. (1978). Modeling by Shortest Data Description. Automatic, 14,</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Veronis</author>
</authors>
<title>A Study of Polysemy Judgements and Inter-annotator Agreement.</title>
<date>1998</date>
<booktitle>In Advanced Papers of the SENSE VAL Workshop,</booktitle>
<location>Sussex, UK.</location>
<contexts>
<context position="2852" citStr="Veronis, 1998" startWordPosition="455" endWordPosition="456"> computational intractability: increased processing time needed to disambiguate multiple possibilities will necessarily slow down the system. Another problem, which has been receiving attention in the past few years, is the inaccuracy: when there is more than one sense applicable in a given context, different systems (or human individuals) may select different senses as the correct sense, Indeed, recent studies in WSD show that, when sense definitions are fine-grained, similar senses become indistinguishable to human annotators and often cause disagreement on the correct tag (Ng et al., 1999; Veronis, 1998; Kilgarriff, 1998b). Also in IR and IE tasks, difference in the correct sense assignment will surely degrade recall and precision of the systems. Thus, it is apparent that, in order for a lexicon to be useful as an evaluation criteria for NLP systems, it must represent word senses at the level of granularity that captures human intuition. In Lexical Semantics, several approaches have been proposed which organize a lexicon based on systematic polysemy:1 a set of word senses that are related in systematic and predictable ISysternatic polysemy (in the sense we use in this paper) is also referred</context>
</contexts>
<marker>Veronis, 1998</marker>
<rawString>Veronis, J. (1998). A Study of Polysemy Judgements and Inter-annotator Agreement. In Advanced Papers of the SENSE VAL Workshop, Sussex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
<author>W Peters</author>
<author>J Gonzalo</author>
</authors>
<title>Towards a Universal Index of Meaning.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources,</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="5198" citStr="Vossen et al., 1999" startWordPosition="823" endWordPosition="826">atic vs. non-systematic relations (or related vs. unrelated meanings) is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example, (Apresjan, 1973; Cruse, 1986; Nunberg, 1995; Copestake and Briscoe, 1995)). However, there is one critical issue still to be addressed: the level of granularity at which the abstract classes are defined. The problem is that, when the granularity of the abstract classes is too coarse, systematic relations defined at that level may not hold uniformly at more fine-grained levels (Vossen et al., 1999). For instance, the CORELEX class AQU mentioned above also contains a word &amp;quot;dose&amp;quot; .3 Here, the relation between the senses of &amp;quot;dose&amp;quot; is different from that of &amp;quot;bottle&amp;quot;, &amp;quot;bucket&amp;quot; and &amp;quot;spoon&amp;quot;, which can be labeled as CONTAINER-CONTAINERFUL relation. We argue that human intuitions can distinguish meanings 2Note that systematic polysemy should be contrasted with homonymy which refers to words which have more than one unrelated sense (e.g. FINANCIALINSTITUTION and SLOPING_LAND meanings of the word &amp;quot;bank&amp;quot;). &apos;Senses of &amp;quot;dose&amp;quot; in WordNet are: (1) a measured portion of medicine taken at any one time, a</context>
</contexts>
<marker>Vossen, Peters, Gonzalo, 1999</marker>
<rawString>Vossen, P., Peters, W. and Gonzalo, J. (1999). Towards a Universal Index of Meaning. In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources, College Park, MD.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>