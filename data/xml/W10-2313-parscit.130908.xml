<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007253">
<title confidence="0.996247">
Distinguishing between Positive and Negative Opinions with Complex
Network Features
</title>
<author confidence="0.7411345">
Diego R. Amancio, Renato Fabbri, Osvaldo N. Oliveira Jr.,
Maria G. V. Nunes and Luciano da F. Costa
</author>
<affiliation confidence="0.979219">
University of S˜ao Paulo, S˜ao Carlos, S˜ao Paulo, Brazil
</affiliation>
<email confidence="0.951648">
diego.amancio@usp.br, renato.fabbri@gmail.com, chu@ifsc.usp.br,
gracan@icmc.usp.br, ldfcosta@gmail.com
</email>
<sectionHeader confidence="0.997346" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971681818182">
Topological and dynamic features of com-
plex networks have proven to be suitable
for capturing text characteristics in recent
years, with various applications in natu-
ral language processing. In this article we
show that texts with positive and negative
opinions can be distinguished from each
other when represented as complex net-
works. The distinction was possible by
obtaining several metrics of the networks,
including the in-degree, out-degree, short-
est paths, clustering coefficient, between-
ness and global efficiency. For visu-
alization, the obtained multidimensional
dataset was projected into a 2-dimensional
space with the canonical variable analysis.
The distinction was quantified using ma-
chine learning algorithms, which allowed
an recall of 70% in the automatic dis-
crimination for the negative opinions, even
without attempts to optimize the pattern
recognition process.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977714285715">
The use of statistical methods is well estab-
lished for a number of natural language pro-
cessing tasks (Manning and Schuetze, 2007), in
some cases combined with a deep linguistic treat-
ment in hybrid approaches. Representing text as
graphs (Antiqueira et al., 2007), in particular, has
become popular with the advent of complex net-
works (CN) (Newman, 2003; Albert and Barabasi,
2002), especially after it was shown that large
pieces of text generate scale-free networks (Ferrer
i Cancho and Sole, 2001; Barabasi, 2009). This
scale-free nature of such networks is probably the
main reason why complex networks concepts are
capable of capturing features of text, even in the
absence of any linguistic treatment. Significantly,
the scale-free property has also allowed CN to be
applied in diverse fields (Costa et al., 2008), from
neuroscience (Sporns, 2002) to physics (Gfeller,
2007), from linguistics (Dorogovtsev and Mendes,
2001) to computer science (Moura et al., 2003), to
mention a few areas. Other frequently observed
unifying principles that natural networks exhibit
are short paths between any two nodes and high
clustering coefficients (i.e. the so-called small-
world property), correlations in node degrees, and
a large number of cycles or specific motifs.
The topology and the dynamics of CN can be
exploited in natural language processing, which
has led to several contributions in the literature.
For instance, metrics of CN have been used to as-
sess the quality of written essays by high school
students (Antiqueira et al., 2007). Furthermore,
degrees, shortest paths and other metrics of CN
were used to produce strategies for automatic sum-
marization (Antiqueira et al., 2009), whose results
are among the best for methods that only employ
statistics. The quality of machine translation sys-
tems can be examined using local mappings of lo-
cal measures (Amancio et al., 2008). Other re-
lated applications include lexical resources anal-
ysis (Sigman and Cecchi, 2002), human-induced
words association (Costa, 2004), language evolu-
tion (Dorogovtsev and Mendes, 2002), and author-
ship recognition (Antiqueira et al., 2006).
In this paper, we model texts as complex net-
works with each word being represented by a
node and co-occurrences of words defining the
edges (see next section). Unlike traditional meth-
ods of text mining and sentiment detection of re-
views (Tang et al., 2009; Pennebaker et al., 2003),
the method described here only takes into account
the relationships between concepts, regardless of
the semantics related to each word. Specifically,
we analyze the topology of the networks in order
to distinguish between texts with positive and neg-
ative opinions. Using a corpus of 290 pieces of
</bodyText>
<page confidence="0.989476">
83
</page>
<note confidence="0.636981">
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 83–87,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.981852">
Before pre-processing After pre-processing
The projection of the projection
network data into two network data two
dimensions is crucial dimension be crucial
for big networks big network
</bodyText>
<tableCaption confidence="0.72938">
Table 1: Adjacency list obtained from the sentence
“The projection of the network data into two di-
mensions is crucial for big networks”.
</tableCaption>
<bodyText confidence="0.989426666666667">
text with half of positive opinions, we show that
the network features allows one to achieve a rea-
sonable distinction.
</bodyText>
<sectionHeader confidence="0.999601" genericHeader="introduction">
2 Methodology
</sectionHeader>
<subsectionHeader confidence="0.999417">
2.1 Representing texts as complex networks
</subsectionHeader>
<bodyText confidence="0.999937457142857">
Texts are modeled as complex networks here by
considering each word (concept) as a node and es-
tablishing links by co-occurrence of words, disre-
garding the punctuation. In selecting the nodes,
the stopwords were removed and the remaining
words were lemmatized to combine words with
the same canonical form but different inflections
into a single node. Additionally, the texts were
labeled using the MXPost part-of-speech Tag-
ger based on the Ratnaparki’s model (Ratnaparki,
1996), which helps to resolve problems of am-
biguity. This is useful because the words with
the same canonical form and same meaning are
grouped into a single node, while words that have
the same canonical form but distinct meanings
generate distinct nodes. This pre-processing is
done by accessing a computational lexicon, where
each word has an associated rule for the genera-
tion of the canonical form. For illustrative means,
Table 1 shows the pre-processed form of the sen-
tence “The projection of the network data into two
dimensions is crucial for big networks” and Figure
1 shows the network obtained for the same sen-
tence.
Several CN metrics have been used to analyze
textual characteristics, the most common of which
are out-degree (ko,t), in-degree (kin), cluster co-
efficient (C) and shortest paths (l). Here we also
use the betweenness (o) and the global efficiency
(η). The out-degree corresponds to the number
of edges emanating from a given node, where
the weight of each link between any two nodes
may also be considered, being referred to as out-
strength. Analogously, the node’s in-degree is de-
fined as the number of edges arriving at a given
</bodyText>
<figureCaption confidence="0.995662333333333">
Figure 1: Network obtained from the sentence
“The projection of the network data into two di-
mensions is crucial for big networks”.
</figureCaption>
<bodyText confidence="0.99883225">
node. The network’s kont and kin are evaluated
by calculating the average among all the nodes,
note that such global measures kont and kin are
always equal. Regarding the adjacency matrix to
represent the network, for a given node i, its kont
and kin are calculated by eqs 1 and 2, where N
represents the number of distinct words in the pre-
processed text:
</bodyText>
<equation confidence="0.9982812">
kont(i) = ∑N Wji (1)
j=1
N
kin(i) = ∑ Wij (2)
j=1
</equation>
<bodyText confidence="0.999868857142857">
The cluster coefficient (C) is defined as follows.
Let S be the set formed by nodes receiving edges
of a given node i, and N, is the cardinality of this
set. If the nodes of this set form a completely con-
nected set, then there are N,(N,-1) edges in this
sub graph. However, if there are only B edges,
then the coefficient is given by eq. (3):
</bodyText>
<equation confidence="0.997456333333333">
B
C(i) = (3)
N,(N, − 1)
</equation>
<bodyText confidence="0.997782111111111">
If N, is less than 1, then C is defined as zero.
Note that this measure quantifies how the nodes
connected to a specific node are linked to each
other, with its value varying between zero and one.
The shortest paths are calculated from all pairs
of nodes within the network. Let dij be the min-
imum distance between any two words i and j in
the network. The shortest path length l of a node i
is given in equation 4.
</bodyText>
<page confidence="0.878415">
84
</page>
<equation confidence="0.943596">
_ 1
l(i) N − 1 Y-
</equation>
<bodyText confidence="0.999870818181818">
Another measure often used in network analy-
sis is the global efficiency (η), which is defined in
equation 5, and may be interpreted as the speed
with which information is exchanged between any
two nodes, since a short distance dij contributes
more significantly than a long distance. Note that
the formula below prevents divergence; therefore,
it is especially useful for networks with two or
more components. The inverse of η, named har-
monic mean of geodesic distances, has also been
used to characterize complex networks.
</bodyText>
<equation confidence="0.930019">
σ(i, v, j) (6)
σ(i, j)
</equation>
<subsectionHeader confidence="0.983454">
2.2 Corpus
</subsectionHeader>
<bodyText confidence="0.9995038">
The corpus used in the experiments was ob-
tained from the Brazilian newspaper Folha de S˜ao
Paulo1, from which we selected 290 articles over a
10-year period from a special section where a pos-
itive opinion is confronted with a negative opinion
about a given topic. For this study, we selected
the 145 longest texts with positive opinion and the
145 longest text with negative opinions2, in order
to have meaningful statistical data for the CN anal-
ysis.
</bodyText>
<subsectionHeader confidence="0.989747">
2.3 Machine Learning Methods
</subsectionHeader>
<bodyText confidence="0.99873825">
In order to discriminate the topological features
from distinct networks we first applied a technique
for reducing the dimension of the dataset, the
canonical variable analysis (McLachlan, 2004).
</bodyText>
<footnote confidence="0.999356">
1http://www.folha.com.br
2The average size of the selected corpus is 600 words.
</footnote>
<bodyText confidence="0.999716181818182">
The projection of network data into a lower di-
mension is crucial for visualization, in addition
to avoids the so-called “curse of dimensional-
ity” (Bishop, 2006). To calculate the axes points
for projecting the data, a criterion must be es-
tablished with which the distances between data
points are defined. Let S be the overall disper-
sion of the measurements, as shown in equation 7,
where ζ is the number of instances (ζ = 290), →−xc is
the set of metrics for a particular instance and ⟨−→x ⟩
is the average of all →−xc.
</bodyText>
<equation confidence="0.9786145">
(−→ xc− ⟨−→ )(−→ )T (7)
x ⟩ xc − ⟨−→ x ⟩
</equation>
<bodyText confidence="0.998808181818182">
Considering that two classes (C1 = positive
opinions and C2 = negative opinions) are used, the
scatter matrix Si is obtained for each class Ci, ac-
cording to equation 8, where ⟨−→x ⟩i is the analo-
gous of ⟨−→x ⟩ when only the instances belonging to
class Ci is taken into account.
The intraclass matrix, i.e. the matrix that gives
the dispersion inside C1 and C2, is defined as in
equation 9. Additionally, we define the interclass
matrix, i.e. the matrix that provides the dispersion
between C1 and C2, as shown in equation 10.
</bodyText>
<equation confidence="0.9995175">
Sintra = S1 + S2 (9)
Sinter = S − Sintra (10)
</equation>
<bodyText confidence="0.9852214">
The principal axes for the projection are then
obtained by computing the eigenvector associ-
ated with the largest eigenvalues of the ma-
trix A (McLachlan, 2004) defined in equation
11. Since the data were projected in a two-
dimensional space, the two principal axes were se-
lected, corresponding to the two largest eigenval-
ues.
While l and η use the length of shortest paths,
the betweenness uses the number of shortest paths.
Formally, the betweenness centrality for a given
vertex v is given in equation 6, where the numera-
tor represents the number of shortest paths passing
through the vertices i, v and j and the denomina-
tor represents the number of shortest paths pass-
ing through the vertices i and j. In other words,
if there are many shortest paths passing through a
given node, this node will receive a high between-
ness centrality.
A = S−1 intraSinter (11)
Finally, to quantify the efficiency of separa-
tion with the projection using canonical variable
analysis, we implemented three machine learn-
ing algorithms (decision tree, using the C4.5 algo-
rithm (Quinlan, 1993); rules of decision, using the
</bodyText>
<equation confidence="0.998594333333333">
1 ∑ 1
N(N−
1) i̸=j dij (5)
η=
dij (4)
ϱ(v) = ∑ ∑
i j
S = ∑ ζ
c=1
∑Si = (−→ )(−→
cECi xc − ⟨−→ )T (8)
x ⟩i xc − ⟨−→ x ⟩i
</equation>
<page confidence="0.991809">
85
</page>
<bodyText confidence="0.9966545">
RIP algorithm (Cohen, 1995), and Naive Bayes
algorithm (John and Langley, 1995)) and eval-
uated the accuracy rate using the 10-fold-cross-
validation (Kohavi, 1995).
</bodyText>
<sectionHeader confidence="0.999592" genericHeader="related work">
3 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999895205882353">
The metrics out-degree (kout), in-degree (kin),
shortest paths (l), cluster coefficient (C), between-
ness (ϱ) and global efficiency (q) were computed
for each of the 145 texts for positive and nega-
tive opinions, as described in the Methodology.
The mean values and the standard deviations of
these metrics were used as attributes for each text.
This generated a dataset described in 10 attributes,
since the average kin is equal to the average kout
and the standard deviation of q is not defined (in
other words, it is always zero). Figure 2 shows the
projection of the dataset obtained with canonical
variable analysis, illustrating that texts with dif-
ferent opinions can be distinguished to a certain
extent. That is to say, the topological features of
networks representing positive opinion tend to dif-
fer from those of texts with negative opinion.
The efficiency of this methodology for charac-
terizing different opinions can be quantified using
machine learning algorithms to process the data
from the projection. The results are illustrated in
Table 2. Again, the distinction between classes is
reasonably good, since the accuracy rate reached
62%. Indeed, this rate seems to be a good result,
since the baseline method3 tested showed an ac-
curacy rate of 53%. One also should highlight
the coverage found for the class of negative re-
views by using the C4.5 algorithm, for which a
value of 82% (result not shown in the Table 2) was
obtained. This means that if an opinion is nega-
tive, the probability of being classified as negative
is only 18%. Thus, our method seems especially
useful when a negative view should be classified
correctly.
</bodyText>
<table confidence="0.98943875">
Method Correctly classified
C4.5 58%
Rip 60%
Naive Bayes 62%
</table>
<tableCaption confidence="0.970476">
Table 2: Percentage of correctly classified in-
stances.
</tableCaption>
<footnote confidence="0.975723">
3The baseline method used as attributes the frequency of
each word in each text. Then, the algorithm C4.5 was run
with the same parameters used for the methodology based on
complex networks.
</footnote>
<table confidence="0.225519333333333">
PROJECTION OF POSITIVE AND
NEGATIVE OBSERVATIONS
FIRST PRINCIPAL AXIS
</table>
<figureCaption confidence="0.9748695">
Figure 2: Projection obtained by using the method
of canonical variables. A reasonable distinction
could be achieved between positive and negative
opinions.
</figureCaption>
<sectionHeader confidence="0.964173" genericHeader="conclusions">
4 Conclusion and Further Work
</sectionHeader>
<bodyText confidence="0.999890652173913">
The topological features of complex networks
generated with texts appear to be efficient in dis-
tinguishing between attitudes, as indicated here
where texts conveying positive opinions could be
distinguished from those of negative opinions.
The metrics of the CN combined with a projec-
tion technique allowed a reasonable separation of
the two types of text, and this was confirmed with
machine learning algorithms. An 62% accuracy
was achieved (the baseline reached 53%), even
though there was no attempt to optimize the met-
rics or the methods of analysis. These promis-
ing results are motivation to evaluate other types
of subtleties in texts, including emotional states,
which is presently being performed in our group.
Acknowledgements: Luciano da F. Costa
is grateful to FAPESP (05/00587-5) and CNPq
(301303/06-1 and 573583/2008-0) for the finan-
cial support. Diego R. Amancio is grateful to
FAPESP sponsorship (proc. 09/02941-1) and Re-
nato Fabbri is grateful to CAPES sponsorship. We
also thank Dr. Oto Araujo Vale very much for sup-
plying the corpus.
</bodyText>
<figure confidence="0.996113363636363">
-0.120 -0.110 -0.100 -0.090
SECOND PRINCIPALAXIS
-0.150
-0.155
-0.160
-0.165
-0.170
-0.175
-0.180
POSITIVE
NEGATIVE
</figure>
<page confidence="0.983785">
86
</page>
<sectionHeader confidence="0.99521" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99974524137931">
C. D. Manning and H. Schuetze. 1999. Foundations of
Statistical Natural Language Processing. The MIT
Press, First Edition.
L. Antiqueira, M. G. V. Nunes, O. N. Oliveira Jr. and L.
da F. Costa. 2007. Strong correlations between text
quality and complex networks features. Physica A,
373:811–820.
M. E. J. Newman. 2003. The Structure and Function
of Complex Networks. SIAM Review, 45:167–256.
R. Z. Albert and A.L. Barabasi. 2002. Statistical Me-
chanics of Complex Networks. Rev. Modern Phys.,
74:47–97.
R. Ferrer i Cancho and R. V. Sole. 2001. The small
world of human language. Proceedings of the Royal
Society of London B, 268:2261.
A.L. Barabasi. 2009. Scale-Free Networks: a decade
and beyond. Science, 24 325 5939 412–413.
L. F. da Costa, O. N. Oliveira Jr., G. Travieso, F.
A. Rodrigues, P. R. Villas Boas, L. Antiqueira, M.
P. Viana, L. E. C. da Rocha. 2008. Analyzing
and Modeling Real-World Phenomena with Com-
plex Networks: A Survey of Applications. arXiv
0711.3199.
O. Sporns. 2002. Network analysis, complexity, and
brain function. Complexity, 8(1):56–60.
D. Gfeller, P. LosRios, A. Caflisch and F. Rao. 2007.
Complex network analysis of free-energy land-
scapes. Proceedings of the National Academy of
Science USA, 104 (6):1817–1822
S. N. Dorogovtsev and J. F. F.Mendes. 2001. Lan-
guage as an evolving word web. Proceedings of the
Royal Society of London B, 268:2603.
A. P. S. de Moura, Y. C. Lai and A. E. Motter. 2003.
Signatures of small-world and scale-free properties
in large computer programs. Physical Review E,
68(1):017102.
L. Antiqueira, O. N. Oliveira Jr., L. da F. Costa and
M. G. V. Nunes. 2009. A Complex Network Ap-
proach to Text Summarization. Information Sci-
ences, 179:(5) 584–599.
M. Sigman and G.A. Cecchi. 2002. Global Organi-
zation of the Wordnet Lexicon. Proceedings of the
National Academy of Sciences, 99:1742–1747.
L. F. Costa. 2004. What’s in a name ? International
Journal of Modern Physics C, 15:371–379.
S. N. Dorogovtsev and J. F. F. Mendes. 2002. Evo-
lution of networks. Advances in Physics, 51:1079–
1187.
L. Antiqueira, T. A. S. Pardo, M. G. V. Nunes, O. N.
Oliveira Jr. and L. F. Costa. 2006. Some issues on
complex networks for author characterization. Pro-
ceeedings of the Workshop in Information and Hu-
man Language Technology.
H. Tang, S. Tan and X. Cheng. 2009. A survey on
sentiment detection of reviews. Expert Systems with
Applications, 36:7 10760–10773.
J. W. Pennebaker, M. R. Mehl and K. G. Niederhoffer.
2003. Psychological aspects of natural language.
use: our words, our selves. Annual review of psy-
chology, 54 547-77.
D. R. Amancio, L. Antiqueira, T. A. S. Pardo, L.
F. Costa, O. N. Oliveira Jr. and M. G. V. Nunes.
2008. Complex networks analysis of manual and
machine translations. International Journal of Mod-
ern Physics C, 19(4):583-598.
A. Ratnaparki. 1996. A Maximum Entropy Part-Of-
Speech Tagger. Proceedings of the Empirical Meth-
ods in Natural Language Processing Conference,
University of Pennsylvania.
G. J. McLachlan. 2004. Discriminant Analysis and
Statistical Pattern Recognition. Wiley.
C. M. Bishop. 2006. Pattern Recognition and Machine
Learning. Springer-Verlag New York.
R. Quinlan. 1993. C4.5: Programs for Machine Learn-
ing. Morgan Kaufmann Publishers.
W. W. Cohen. 1995. Fast Effective Rule Induction.
12 International converence on Machine Learning,
115–223.
G. H. John and P. Langley. 1995. Estimating Continu-
ous Distribution in Bayesian Classifiers. 11 Confer-
ence on Uncertainty in Artificial Intelligence, 338–
345.
R. Kohavi. 1995. A study of cross-validation and boot-
strap for accuracy estimation and model selection.
Proceedings of the Fourteenth International Joint
Conference on Artificial Intelligence 2, 12:1137-
1143.
</reference>
<page confidence="0.99947">
87
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.633765">
<title confidence="0.999792">Distinguishing between Positive and Negative Opinions with Network Features</title>
<author confidence="0.853499333333333">Diego R Amancio</author>
<author confidence="0.853499333333333">Renato Fabbri</author>
<author confidence="0.853499333333333">Osvaldo N Oliveira Maria G V Nunes</author>
<author confidence="0.853499333333333">Luciano da F of Paulo</author>
<author confidence="0.853499333333333">Paulo Carlos</author>
<email confidence="0.971044">diego.amancio@usp.br,renato.fabbri@gmail.com,gracan@icmc.usp.br,ldfcosta@gmail.com</email>
<abstract confidence="0.999551565217392">Topological and dynamic features of complex networks have proven to be suitable for capturing text characteristics in recent years, with various applications in natural language processing. In this article we show that texts with positive and negative opinions can be distinguished from each other when represented as complex networks. The distinction was possible by obtaining several metrics of the networks, including the in-degree, out-degree, shortest paths, clustering coefficient, betweenness and global efficiency. For visualization, the obtained multidimensional dataset was projected into a 2-dimensional space with the canonical variable analysis. The distinction was quantified using machine learning algorithms, which allowed an recall of 70% in the automatic discrimination for the negative opinions, even without attempts to optimize the pattern recognition process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schuetze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>First Edition.</location>
<marker>Manning, Schuetze, 1999</marker>
<rawString>C. D. Manning and H. Schuetze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, First Edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L da F Costa</author>
</authors>
<title>Strong correlations between text quality and complex networks features.</title>
<date>2007</date>
<pages>373--811</pages>
<publisher>Physica A,</publisher>
<marker>Costa, 2007</marker>
<rawString>L. Antiqueira, M. G. V. Nunes, O. N. Oliveira Jr. and L. da F. Costa. 2007. Strong correlations between text quality and complex networks features. Physica A, 373:811–820.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E J Newman</author>
</authors>
<title>The Structure and Function of Complex Networks.</title>
<date>2003</date>
<journal>SIAM Review,</journal>
<pages>45--167</pages>
<contexts>
<context position="1603" citStr="Newman, 2003" startWordPosition="229" endWordPosition="230">al variable analysis. The distinction was quantified using machine learning algorithms, which allowed an recall of 70% in the automatic discrimination for the negative opinions, even without attempts to optimize the pattern recognition process. 1 Introduction The use of statistical methods is well established for a number of natural language processing tasks (Manning and Schuetze, 2007), in some cases combined with a deep linguistic treatment in hybrid approaches. Representing text as graphs (Antiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Mo</context>
</contexts>
<marker>Newman, 2003</marker>
<rawString>M. E. J. Newman. 2003. The Structure and Function of Complex Networks. SIAM Review, 45:167–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Z Albert</author>
<author>A L Barabasi</author>
</authors>
<date>2002</date>
<journal>Statistical Mechanics of Complex Networks. Rev. Modern Phys.,</journal>
<pages>74--47</pages>
<contexts>
<context position="1631" citStr="Albert and Barabasi, 2002" startWordPosition="231" endWordPosition="234">alysis. The distinction was quantified using machine learning algorithms, which allowed an recall of 70% in the automatic discrimination for the negative opinions, even without attempts to optimize the pattern recognition process. 1 Introduction The use of statistical methods is well established for a number of natural language processing tasks (Manning and Schuetze, 2007), in some cases combined with a deep linguistic treatment in hybrid approaches. Representing text as graphs (Antiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mentio</context>
</contexts>
<marker>Albert, Barabasi, 2002</marker>
<rawString>R. Z. Albert and A.L. Barabasi. 2002. Statistical Mechanics of Complex Networks. Rev. Modern Phys., 74:47–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ferrer i Cancho</author>
<author>R V Sole</author>
</authors>
<title>The small world of human language.</title>
<date>2001</date>
<journal>Proceedings of the Royal Society of London B,</journal>
<pages>268--2261</pages>
<contexts>
<context position="1749" citStr="Cancho and Sole, 2001" startWordPosition="250" endWordPosition="253">iscrimination for the negative opinions, even without attempts to optimize the pattern recognition process. 1 Introduction The use of statistical methods is well established for a number of natural language processing tasks (Manning and Schuetze, 2007), in some cases combined with a deep linguistic treatment in hybrid approaches. Representing text as graphs (Antiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mention a few areas. Other frequently observed unifying principles that natural networks exhibit are short paths between any</context>
</contexts>
<marker>Cancho, Sole, 2001</marker>
<rawString>R. Ferrer i Cancho and R. V. Sole. 2001. The small world of human language. Proceedings of the Royal Society of London B, 268:2261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Barabasi</author>
</authors>
<title>Scale-Free Networks: a decade and beyond.</title>
<date>2009</date>
<journal>Science,</journal>
<volume>24</volume>
<pages>412--413</pages>
<contexts>
<context position="1766" citStr="Barabasi, 2009" startWordPosition="254" endWordPosition="255">egative opinions, even without attempts to optimize the pattern recognition process. 1 Introduction The use of statistical methods is well established for a number of natural language processing tasks (Manning and Schuetze, 2007), in some cases combined with a deep linguistic treatment in hybrid approaches. Representing text as graphs (Antiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mention a few areas. Other frequently observed unifying principles that natural networks exhibit are short paths between any two nodes and hi</context>
</contexts>
<marker>Barabasi, 2009</marker>
<rawString>A.L. Barabasi. 2009. Scale-Free Networks: a decade and beyond. Science, 24 325 5939 412–413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F da Costa</author>
<author>O N Oliveira Jr</author>
<author>G Travieso</author>
<author>F A Rodrigues</author>
<author>P R Villas Boas</author>
<author>L Antiqueira</author>
<author>M P Viana</author>
<author>L E C da Rocha</author>
</authors>
<title>Analyzing and Modeling Real-World Phenomena with Complex Networks: A Survey of Applications.</title>
<date>2008</date>
<pages>0711--3199</pages>
<contexts>
<context position="2069" citStr="Costa et al., 2008" startWordPosition="300" endWordPosition="303">proaches. Representing text as graphs (Antiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mention a few areas. Other frequently observed unifying principles that natural networks exhibit are short paths between any two nodes and high clustering coefficients (i.e. the so-called smallworld property), correlations in node degrees, and a large number of cycles or specific motifs. The topology and the dynamics of CN can be exploited in natural language processing, which has led to several contributions in the literature. For instance</context>
</contexts>
<marker>Costa, Jr, Travieso, Rodrigues, Boas, Antiqueira, Viana, Rocha, 2008</marker>
<rawString>L. F. da Costa, O. N. Oliveira Jr., G. Travieso, F. A. Rodrigues, P. R. Villas Boas, L. Antiqueira, M. P. Viana, L. E. C. da Rocha. 2008. Analyzing and Modeling Real-World Phenomena with Complex Networks: A Survey of Applications. arXiv 0711.3199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Sporns</author>
</authors>
<title>Network analysis, complexity, and brain function.</title>
<date>2002</date>
<journal>Complexity,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="2103" citStr="Sporns, 2002" startWordPosition="306" endWordPosition="307">ntiqueira et al., 2007), in particular, has become popular with the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mention a few areas. Other frequently observed unifying principles that natural networks exhibit are short paths between any two nodes and high clustering coefficients (i.e. the so-called smallworld property), correlations in node degrees, and a large number of cycles or specific motifs. The topology and the dynamics of CN can be exploited in natural language processing, which has led to several contributions in the literature. For instance, metrics of CN have been used to </context>
</contexts>
<marker>Sporns, 2002</marker>
<rawString>O. Sporns. 2002. Network analysis, complexity, and brain function. Complexity, 8(1):56–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gfeller</author>
<author>P LosRios</author>
<author>A Caflisch</author>
<author>F Rao</author>
</authors>
<title>Complex network analysis of free-energy landscapes.</title>
<date>2007</date>
<booktitle>Proceedings of the National Academy of Science USA,</booktitle>
<volume>104</volume>
<pages>6--1817</pages>
<marker>Gfeller, LosRios, Caflisch, Rao, 2007</marker>
<rawString>D. Gfeller, P. LosRios, A. Caflisch and F. Rao. 2007. Complex network analysis of free-energy landscapes. Proceedings of the National Academy of Science USA, 104 (6):1817–1822</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Dorogovtsev</author>
<author>J F F Mendes</author>
</authors>
<title>Language as an evolving word web.</title>
<date>2001</date>
<journal>Proceedings of the Royal Society of London B,</journal>
<pages>268--2603</pages>
<contexts>
<context position="2179" citStr="Dorogovtsev and Mendes, 2001" startWordPosition="314" endWordPosition="317">ith the advent of complex networks (CN) (Newman, 2003; Albert and Barabasi, 2002), especially after it was shown that large pieces of text generate scale-free networks (Ferrer i Cancho and Sole, 2001; Barabasi, 2009). This scale-free nature of such networks is probably the main reason why complex networks concepts are capable of capturing features of text, even in the absence of any linguistic treatment. Significantly, the scale-free property has also allowed CN to be applied in diverse fields (Costa et al., 2008), from neuroscience (Sporns, 2002) to physics (Gfeller, 2007), from linguistics (Dorogovtsev and Mendes, 2001) to computer science (Moura et al., 2003), to mention a few areas. Other frequently observed unifying principles that natural networks exhibit are short paths between any two nodes and high clustering coefficients (i.e. the so-called smallworld property), correlations in node degrees, and a large number of cycles or specific motifs. The topology and the dynamics of CN can be exploited in natural language processing, which has led to several contributions in the literature. For instance, metrics of CN have been used to assess the quality of written essays by high school students (Antiqueira et </context>
</contexts>
<marker>Dorogovtsev, Mendes, 2001</marker>
<rawString>S. N. Dorogovtsev and J. F. F.Mendes. 2001. Language as an evolving word web. Proceedings of the Royal Society of London B, 268:2603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P S de Moura</author>
<author>Y C Lai</author>
<author>A E Motter</author>
</authors>
<title>Signatures of small-world and scale-free properties in large computer programs. Physical Review E,</title>
<date>2003</date>
<marker>de Moura, Lai, Motter, 2003</marker>
<rawString>A. P. S. de Moura, Y. C. Lai and A. E. Motter. 2003. Signatures of small-world and scale-free properties in large computer programs. Physical Review E, 68(1):017102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Antiqueira</author>
<author>O N Oliveira Jr</author>
<author>L da F Costa</author>
<author>M G V Nunes</author>
</authors>
<title>A Complex Network Approach to Text Summarization. Information Sciences,</title>
<date>2009</date>
<volume>179</volume>
<pages>584--599</pages>
<contexts>
<context position="2937" citStr="Antiqueira et al., 2009" startWordPosition="434" endWordPosition="437"> exhibit are short paths between any two nodes and high clustering coefficients (i.e. the so-called smallworld property), correlations in node degrees, and a large number of cycles or specific motifs. The topology and the dynamics of CN can be exploited in natural language processing, which has led to several contributions in the literature. For instance, metrics of CN have been used to assess the quality of written essays by high school students (Antiqueira et al., 2007). Furthermore, degrees, shortest paths and other metrics of CN were used to produce strategies for automatic summarization (Antiqueira et al., 2009), whose results are among the best for methods that only employ statistics. The quality of machine translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). U</context>
</contexts>
<marker>Antiqueira, Jr, Costa, Nunes, 2009</marker>
<rawString>L. Antiqueira, O. N. Oliveira Jr., L. da F. Costa and M. G. V. Nunes. 2009. A Complex Network Approach to Text Summarization. Information Sciences, 179:(5) 584–599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sigman</author>
<author>G A Cecchi</author>
</authors>
<title>Global Organization of the Wordnet Lexicon.</title>
<date>2002</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<pages>99--1742</pages>
<contexts>
<context position="3222" citStr="Sigman and Cecchi, 2002" startWordPosition="480" endWordPosition="483"> which has led to several contributions in the literature. For instance, metrics of CN have been used to assess the quality of written essays by high school students (Antiqueira et al., 2007). Furthermore, degrees, shortest paths and other metrics of CN were used to produce strategies for automatic summarization (Antiqueira et al., 2009), whose results are among the best for methods that only employ statistics. The quality of machine translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). Unlike traditional methods of text mining and sentiment detection of reviews (Tang et al., 2009; Pennebaker et al., 2003), the method described here only takes into account the relationships between concepts, regardless of the semantics related to each word. Specifically, we analyze th</context>
</contexts>
<marker>Sigman, Cecchi, 2002</marker>
<rawString>M. Sigman and G.A. Cecchi. 2002. Global Organization of the Wordnet Lexicon. Proceedings of the National Academy of Sciences, 99:1742–1747.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Costa</author>
</authors>
<title>What’s in a name ?</title>
<date>2004</date>
<journal>International Journal of Modern Physics C,</journal>
<pages>15--371</pages>
<contexts>
<context position="3269" citStr="Costa, 2004" startWordPosition="487" endWordPosition="488">For instance, metrics of CN have been used to assess the quality of written essays by high school students (Antiqueira et al., 2007). Furthermore, degrees, shortest paths and other metrics of CN were used to produce strategies for automatic summarization (Antiqueira et al., 2009), whose results are among the best for methods that only employ statistics. The quality of machine translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). Unlike traditional methods of text mining and sentiment detection of reviews (Tang et al., 2009; Pennebaker et al., 2003), the method described here only takes into account the relationships between concepts, regardless of the semantics related to each word. Specifically, we analyze the topology of the networks in order to distingu</context>
</contexts>
<marker>Costa, 2004</marker>
<rawString>L. F. Costa. 2004. What’s in a name ? International Journal of Modern Physics C, 15:371–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Dorogovtsev</author>
<author>J F F Mendes</author>
</authors>
<title>Evolution of networks.</title>
<date>2002</date>
<journal>Advances in Physics,</journal>
<volume>51</volume>
<pages>1187</pages>
<contexts>
<context position="3320" citStr="Dorogovtsev and Mendes, 2002" startWordPosition="492" endWordPosition="495">een used to assess the quality of written essays by high school students (Antiqueira et al., 2007). Furthermore, degrees, shortest paths and other metrics of CN were used to produce strategies for automatic summarization (Antiqueira et al., 2009), whose results are among the best for methods that only employ statistics. The quality of machine translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). Unlike traditional methods of text mining and sentiment detection of reviews (Tang et al., 2009; Pennebaker et al., 2003), the method described here only takes into account the relationships between concepts, regardless of the semantics related to each word. Specifically, we analyze the topology of the networks in order to distinguish between texts with positive and negative opinio</context>
</contexts>
<marker>Dorogovtsev, Mendes, 2002</marker>
<rawString>S. N. Dorogovtsev and J. F. F. Mendes. 2002. Evolution of networks. Advances in Physics, 51:1079– 1187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Costa</author>
</authors>
<date>2006</date>
<booktitle>Some issues on complex networks for author characterization. Proceeedings of the Workshop in Information and Human Language Technology.</booktitle>
<marker>Costa, 2006</marker>
<rawString>L. Antiqueira, T. A. S. Pardo, M. G. V. Nunes, O. N. Oliveira Jr. and L. F. Costa. 2006. Some issues on complex networks for author characterization. Proceeedings of the Workshop in Information and Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tang</author>
<author>S Tan</author>
<author>X Cheng</author>
</authors>
<title>A survey on sentiment detection of reviews. Expert Systems with Applications,</title>
<date>2009</date>
<volume>36</volume>
<pages>10760--10773</pages>
<contexts>
<context position="3631" citStr="Tang et al., 2009" startWordPosition="545" endWordPosition="548">he quality of machine translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). Unlike traditional methods of text mining and sentiment detection of reviews (Tang et al., 2009; Pennebaker et al., 2003), the method described here only takes into account the relationships between concepts, regardless of the semantics related to each word. Specifically, we analyze the topology of the networks in order to distinguish between texts with positive and negative opinions. Using a corpus of 290 pieces of 83 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 83–87, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics Before pre-processing After pre-processing The projection of the projection netw</context>
</contexts>
<marker>Tang, Tan, Cheng, 2009</marker>
<rawString>H. Tang, S. Tan and X. Cheng. 2009. A survey on sentiment detection of reviews. Expert Systems with Applications, 36:7 10760–10773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Pennebaker</author>
<author>M R Mehl</author>
<author>K G Niederhoffer</author>
</authors>
<title>Psychological aspects of natural language. use: our words, our selves. Annual review of psychology,</title>
<date>2003</date>
<volume>54</volume>
<pages>547--77</pages>
<contexts>
<context position="3657" citStr="Pennebaker et al., 2003" startWordPosition="549" endWordPosition="552">ne translation systems can be examined using local mappings of local measures (Amancio et al., 2008). Other related applications include lexical resources analysis (Sigman and Cecchi, 2002), human-induced words association (Costa, 2004), language evolution (Dorogovtsev and Mendes, 2002), and authorship recognition (Antiqueira et al., 2006). In this paper, we model texts as complex networks with each word being represented by a node and co-occurrences of words defining the edges (see next section). Unlike traditional methods of text mining and sentiment detection of reviews (Tang et al., 2009; Pennebaker et al., 2003), the method described here only takes into account the relationships between concepts, regardless of the semantics related to each word. Specifically, we analyze the topology of the networks in order to distinguish between texts with positive and negative opinions. Using a corpus of 290 pieces of 83 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 83–87, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics Before pre-processing After pre-processing The projection of the projection network data into two network </context>
</contexts>
<marker>Pennebaker, Mehl, Niederhoffer, 2003</marker>
<rawString>J. W. Pennebaker, M. R. Mehl and K. G. Niederhoffer. 2003. Psychological aspects of natural language. use: our words, our selves. Annual review of psychology, 54 547-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G V Nunes</author>
</authors>
<title>Complex networks analysis of manual and machine translations.</title>
<date>2008</date>
<journal>International Journal of Modern Physics C,</journal>
<pages>19--4</pages>
<marker>Nunes, 2008</marker>
<rawString>D. R. Amancio, L. Antiqueira, T. A. S. Pardo, L. F. Costa, O. N. Oliveira Jr. and M. G. V. Nunes. 2008. Complex networks analysis of manual and machine translations. International Journal of Modern Physics C, 19(4):583-598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparki</author>
</authors>
<title>A Maximum Entropy Part-OfSpeech Tagger.</title>
<date>1996</date>
<booktitle>Proceedings of the Empirical Methods in Natural Language Processing Conference,</booktitle>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="5128" citStr="Ratnaparki, 1996" startWordPosition="777" endWordPosition="778"> we show that the network features allows one to achieve a reasonable distinction. 2 Methodology 2.1 Representing texts as complex networks Texts are modeled as complex networks here by considering each word (concept) as a node and establishing links by co-occurrence of words, disregarding the punctuation. In selecting the nodes, the stopwords were removed and the remaining words were lemmatized to combine words with the same canonical form but different inflections into a single node. Additionally, the texts were labeled using the MXPost part-of-speech Tagger based on the Ratnaparki’s model (Ratnaparki, 1996), which helps to resolve problems of ambiguity. This is useful because the words with the same canonical form and same meaning are grouped into a single node, while words that have the same canonical form but distinct meanings generate distinct nodes. This pre-processing is done by accessing a computational lexicon, where each word has an associated rule for the generation of the canonical form. For illustrative means, Table 1 shows the pre-processed form of the sentence “The projection of the network data into two dimensions is crucial for big networks” and Figure 1 shows the network obtained</context>
</contexts>
<marker>Ratnaparki, 1996</marker>
<rawString>A. Ratnaparki. 1996. A Maximum Entropy Part-OfSpeech Tagger. Proceedings of the Empirical Methods in Natural Language Processing Conference, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J McLachlan</author>
</authors>
<title>Discriminant Analysis and Statistical Pattern Recognition.</title>
<date>2004</date>
<booktitle>Pattern Recognition and Machine Learning.</booktitle>
<publisher>Springer-Verlag</publisher>
<location>New York.</location>
<contexts>
<context position="8852" citStr="McLachlan, 2004" startWordPosition="1437" endWordPosition="1438">azilian newspaper Folha de S˜ao Paulo1, from which we selected 290 articles over a 10-year period from a special section where a positive opinion is confronted with a negative opinion about a given topic. For this study, we selected the 145 longest texts with positive opinion and the 145 longest text with negative opinions2, in order to have meaningful statistical data for the CN analysis. 2.3 Machine Learning Methods In order to discriminate the topological features from distinct networks we first applied a technique for reducing the dimension of the dataset, the canonical variable analysis (McLachlan, 2004). 1http://www.folha.com.br 2The average size of the selected corpus is 600 words. The projection of network data into a lower dimension is crucial for visualization, in addition to avoids the so-called “curse of dimensionality” (Bishop, 2006). To calculate the axes points for projecting the data, a criterion must be established with which the distances between data points are defined. Let S be the overall dispersion of the measurements, as shown in equation 7, where ζ is the number of instances (ζ = 290), →−xc is the set of metrics for a particular instance and ⟨−→x ⟩ is the average of all →−x</context>
<context position="10227" citStr="McLachlan, 2004" startWordPosition="1687" endWordPosition="1688"> obtained for each class Ci, according to equation 8, where ⟨−→x ⟩i is the analogous of ⟨−→x ⟩ when only the instances belonging to class Ci is taken into account. The intraclass matrix, i.e. the matrix that gives the dispersion inside C1 and C2, is defined as in equation 9. Additionally, we define the interclass matrix, i.e. the matrix that provides the dispersion between C1 and C2, as shown in equation 10. Sintra = S1 + S2 (9) Sinter = S − Sintra (10) The principal axes for the projection are then obtained by computing the eigenvector associated with the largest eigenvalues of the matrix A (McLachlan, 2004) defined in equation 11. Since the data were projected in a twodimensional space, the two principal axes were selected, corresponding to the two largest eigenvalues. While l and η use the length of shortest paths, the betweenness uses the number of shortest paths. Formally, the betweenness centrality for a given vertex v is given in equation 6, where the numerator represents the number of shortest paths passing through the vertices i, v and j and the denominator represents the number of shortest paths passing through the vertices i and j. In other words, if there are many shortest paths passin</context>
</contexts>
<marker>McLachlan, 2004</marker>
<rawString>G. J. McLachlan. 2004. Discriminant Analysis and Statistical Pattern Recognition. Wiley. C. M. Bishop. 2006. Pattern Recognition and Machine Learning. Springer-Verlag New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="11140" citStr="Quinlan, 1993" startWordPosition="1842" endWordPosition="1843">ty for a given vertex v is given in equation 6, where the numerator represents the number of shortest paths passing through the vertices i, v and j and the denominator represents the number of shortest paths passing through the vertices i and j. In other words, if there are many shortest paths passing through a given node, this node will receive a high betweenness centrality. A = S−1 intraSinter (11) Finally, to quantify the efficiency of separation with the projection using canonical variable analysis, we implemented three machine learning algorithms (decision tree, using the C4.5 algorithm (Quinlan, 1993); rules of decision, using the 1 ∑ 1 N(N− 1) i̸=j dij (5) η= dij (4) ϱ(v) = ∑ ∑ i j S = ∑ ζ c=1 ∑Si = (−→ )(−→ cECi xc − ⟨−→ )T (8) x ⟩i xc − ⟨−→ x ⟩i 85 RIP algorithm (Cohen, 1995), and Naive Bayes algorithm (John and Langley, 1995)) and evaluated the accuracy rate using the 10-fold-crossvalidation (Kohavi, 1995). 3 Results and Discussion The metrics out-degree (kout), in-degree (kin), shortest paths (l), cluster coefficient (C), betweenness (ϱ) and global efficiency (q) were computed for each of the 145 texts for positive and negative opinions, as described in the Methodology. The mean value</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>R. Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W W Cohen</author>
</authors>
<title>Fast Effective Rule Induction.</title>
<date>1995</date>
<booktitle>12 International converence on Machine Learning,</booktitle>
<pages>115--223</pages>
<contexts>
<context position="11321" citStr="Cohen, 1995" startWordPosition="1891" endWordPosition="1892">number of shortest paths passing through the vertices i and j. In other words, if there are many shortest paths passing through a given node, this node will receive a high betweenness centrality. A = S−1 intraSinter (11) Finally, to quantify the efficiency of separation with the projection using canonical variable analysis, we implemented three machine learning algorithms (decision tree, using the C4.5 algorithm (Quinlan, 1993); rules of decision, using the 1 ∑ 1 N(N− 1) i̸=j dij (5) η= dij (4) ϱ(v) = ∑ ∑ i j S = ∑ ζ c=1 ∑Si = (−→ )(−→ cECi xc − ⟨−→ )T (8) x ⟩i xc − ⟨−→ x ⟩i 85 RIP algorithm (Cohen, 1995), and Naive Bayes algorithm (John and Langley, 1995)) and evaluated the accuracy rate using the 10-fold-crossvalidation (Kohavi, 1995). 3 Results and Discussion The metrics out-degree (kout), in-degree (kin), shortest paths (l), cluster coefficient (C), betweenness (ϱ) and global efficiency (q) were computed for each of the 145 texts for positive and negative opinions, as described in the Methodology. The mean values and the standard deviations of these metrics were used as attributes for each text. This generated a dataset described in 10 attributes, since the average kin is equal to the aver</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>W. W. Cohen. 1995. Fast Effective Rule Induction. 12 International converence on Machine Learning, 115–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H John</author>
<author>P Langley</author>
</authors>
<date>1995</date>
<booktitle>Estimating Continuous Distribution in Bayesian Classifiers. 11 Conference on Uncertainty in Artificial Intelligence,</booktitle>
<volume>338</volume>
<pages>345</pages>
<contexts>
<context position="11373" citStr="John and Langley, 1995" startWordPosition="1897" endWordPosition="1900">the vertices i and j. In other words, if there are many shortest paths passing through a given node, this node will receive a high betweenness centrality. A = S−1 intraSinter (11) Finally, to quantify the efficiency of separation with the projection using canonical variable analysis, we implemented three machine learning algorithms (decision tree, using the C4.5 algorithm (Quinlan, 1993); rules of decision, using the 1 ∑ 1 N(N− 1) i̸=j dij (5) η= dij (4) ϱ(v) = ∑ ∑ i j S = ∑ ζ c=1 ∑Si = (−→ )(−→ cECi xc − ⟨−→ )T (8) x ⟩i xc − ⟨−→ x ⟩i 85 RIP algorithm (Cohen, 1995), and Naive Bayes algorithm (John and Langley, 1995)) and evaluated the accuracy rate using the 10-fold-crossvalidation (Kohavi, 1995). 3 Results and Discussion The metrics out-degree (kout), in-degree (kin), shortest paths (l), cluster coefficient (C), betweenness (ϱ) and global efficiency (q) were computed for each of the 145 texts for positive and negative opinions, as described in the Methodology. The mean values and the standard deviations of these metrics were used as attributes for each text. This generated a dataset described in 10 attributes, since the average kin is equal to the average kout and the standard deviation of q is not defi</context>
</contexts>
<marker>John, Langley, 1995</marker>
<rawString>G. H. John and P. Langley. 1995. Estimating Continuous Distribution in Bayesian Classifiers. 11 Conference on Uncertainty in Artificial Intelligence, 338– 345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kohavi</author>
</authors>
<title>A study of cross-validation and bootstrap for accuracy estimation and model selection.</title>
<date>1995</date>
<booktitle>Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence</booktitle>
<volume>2</volume>
<pages>12--1137</pages>
<contexts>
<context position="11455" citStr="Kohavi, 1995" startWordPosition="1911" endWordPosition="1912">en node, this node will receive a high betweenness centrality. A = S−1 intraSinter (11) Finally, to quantify the efficiency of separation with the projection using canonical variable analysis, we implemented three machine learning algorithms (decision tree, using the C4.5 algorithm (Quinlan, 1993); rules of decision, using the 1 ∑ 1 N(N− 1) i̸=j dij (5) η= dij (4) ϱ(v) = ∑ ∑ i j S = ∑ ζ c=1 ∑Si = (−→ )(−→ cECi xc − ⟨−→ )T (8) x ⟩i xc − ⟨−→ x ⟩i 85 RIP algorithm (Cohen, 1995), and Naive Bayes algorithm (John and Langley, 1995)) and evaluated the accuracy rate using the 10-fold-crossvalidation (Kohavi, 1995). 3 Results and Discussion The metrics out-degree (kout), in-degree (kin), shortest paths (l), cluster coefficient (C), betweenness (ϱ) and global efficiency (q) were computed for each of the 145 texts for positive and negative opinions, as described in the Methodology. The mean values and the standard deviations of these metrics were used as attributes for each text. This generated a dataset described in 10 attributes, since the average kin is equal to the average kout and the standard deviation of q is not defined (in other words, it is always zero). Figure 2 shows the projection of the data</context>
</contexts>
<marker>Kohavi, 1995</marker>
<rawString>R. Kohavi. 1995. A study of cross-validation and bootstrap for accuracy estimation and model selection. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence 2, 12:1137-1143.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>