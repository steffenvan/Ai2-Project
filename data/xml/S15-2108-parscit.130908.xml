<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.998893">
SeNTU: Sentiment Analysis of Tweets by Combining a Rule-based Classifier
with Supervised Learning
</title>
<author confidence="0.994231">
Prerna Chikersal, Soujanya Poria, and Erik Cambria
</author>
<affiliation confidence="0.990021">
School of Computer Engineering
Nanyang Technological University
</affiliation>
<address confidence="0.965625">
Singapore - 639798
</address>
<email confidence="0.999228">
{prerna1,sporia,cambria}@ntu.edu.sg
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999286875">
We describe a Twitter sentiment analysis sys-
tem developed by combining a rule-based
classifier with supervised learning. We sub-
mitted our results for the message-level sub-
task in SemEval 2015 Task 10, and achieved
a F1-score of 57.06%. The rule-based classi-
fier is based on rules that are dependent on the
occurrences of emoticons and opinion words
in tweets. Whereas, the Support Vector Ma-
chine (SVM) is trained on semantic, depen-
dency, and sentiment lexicon based features.
The tweets are classified as positive, negative
or unknown by the rule-based classifier, and as
positive, negative or neutral by the SVM. The
results we obtained show that rules can help
refine the SVM’s predictions.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.970161424242424">
Our opinions and the opinions of others play a
very important role in our decision-making process
and even influence our behaviour. In recent times,
an increasing number of people have taken to ex-
pressing their opinions on a wide variety of topics
on microblogging websites such as Twitter. Be-
ing able to analyse this data and extract opinions
about a number of topics, can help us make informed
choices and predictions regarding those topics. Due
to this, sentiment analysis of tweets is gaining im-
portance across a number of domains such as e-
commerce (Wang and Cardie, 2014), politics (Tu-
masjan et al., 2010; Johnson et al., 2012; Wang et
1We average the positive and negative F-measures to get the
F-score, which is the evaluation metric for this task.
al., 2012), health and psychology (Cambria et al.,
2010; Harman, ; Harman, ), multimodality (Poria et
al., 2015), crowd validation (Cambria et al., 2010),
and even intelligence and surveillance (Jansen et al.,
2009).
SemEval 2015 Task 10 (Rosenthal et al., 2015)
is an international shared-task competition that aims
to promote research in sentiment analysis of tweets
by providing annotated tweets for training, devel-
opment and testing. We created a sentiment anal-
ysis system to participate in the message-level task
of this competition. The objective of the system is
to label the sentiment of each tweet as “positive”,
“negative” or “neutral”.
In this paper, we describe our sentiment analysis
system, which is a combined classifier created by in-
tegrating a rule-based classification layer with a sup-
port vector machine.
</bodyText>
<sectionHeader confidence="0.989085" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.597015">
Our Sentiment Analysis System consists of two clas-
</subsectionHeader>
<bodyText confidence="0.999340307692308">
sifiers – (i) Rule-based and (ii) Supervised, inte-
grated together. This section describes both these
classifiers and how we combine them.
During pre-processing, all the @&lt;username&gt;
references are changes to @USER and all the URLs
are changed to http://URL.com. Then, we use the
CMU Twitter Tokeniser and POS Tagger (Gim-
pel et al., 2011) to tokenise the tweets and give
a parts-of-speech tag to each token. We use the
POS tags to remove all emoticons from the pre-
processed tweets. Pre-processed tweets with emoti-
cons are given as input to the rule-based classi-
fier, whereas the support vector machine takes pre-
</bodyText>
<page confidence="0.979293">
647
</page>
<bodyText confidence="0.487186">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 647–651,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
processed tweets without emoticons as an input.
</bodyText>
<subsectionHeader confidence="0.990613">
2.1 Supervised Learning
</subsectionHeader>
<bodyText confidence="0.999870846153846">
For the supervised classifier, we cast the sentiment
analysis problem as a multi-class classification prob-
lem, where each tweet has to be labeled as “pos-
itive”, “negative” or “neutral”. We train a Sup-
port Vector Machine (SVM) (Cortes and Vapnik,
1995) on the tweets provided for training. For all
our experiments, we use a linear kernel and L1-
regularisation. The C parameter is chosen by cross-
validation. As mentioned above, emoticons have al-
ready been removed from tweets given as input to
the SVM.
Each tweet is represented as a feature vector, con-
taining the following features:
</bodyText>
<listItem confidence="0.8495759375">
• Word N-grams: Frequencies of contiguous
sequences of 1, 2 or 3 tokens. The TF-IDF
weighting scheme is applied.
• Character N-grams: Frequencies of contigu-
ous sequences of 1, 2 or 3 characters inside
each word’s boundary. The TF-IDF weighting
scheme is applied.
• POS Tags: Using CMU Twitter Tagger (Gim-
pel et al., 2011) output, for each tweet we com-
pute – (i) countAdj (number of adjectives), (ii)
countAdv (number of adverbs), (iii) countNoun
(number of nouns, proper nouns, and proper
nouns+possessives), (iv) countVerb (number of
verbs), and (v) countIntj (number of interjec-
tions). The sum of these five counts, gives us
the totalPos. The POS features are: [countAdj
</listItem>
<equation confidence="0.671048">
totalPos ,
countIntj
totalPos ].
</equation>
<listItem confidence="0.9667727">
• @USER: A boolean feature that is set to 1 if
the tweet contains a @&lt;username&gt; reference.
• Hashtag: A boolean feature that is set to 1 if
the tweet contains a hashtag.
• URL: A boolean feature that is set to 1 if the
tweet contains a URL.
• Discourse: A boolean feature that is set to 1 if
the tweet contains a “discourse marker”. Ex-
amples of discourse markers would be a “RT”
followed by a username to indicate that the
</listItem>
<bodyText confidence="0.9962525">
tweet is a re-tweet, news article headline fol-
lowed by “...” followed by a URL to the news
article, etc. Basically, this feature indicates
whether or not the tweet is a part of a discourse.
</bodyText>
<listItem confidence="0.7825504">
• Sentiment140 Lexicon: The Sentiment140
Lexicon (Mohammad et al., 2013) contains un-
igrams and bigrams along with their polarity
scores in the range of −5.00 to +5.00. Con-
sidering all uni/bi-grams with polarity less than
−1.0 to be negative and with polarity greater
than +1.0 to be positive, we count the number
of negative (negativesCount) and the number
of positive (positivesCount) uni/bi-gram occur-
rences in every tweet. For each tweet,
</listItem>
<bodyText confidence="0.892806181818182">
– the polarityMeasure is based on the pos-
itivesCount and negativesCount, and cal-
culated using Algorithm 1.
– the maximum polarity value (maxPolari-
tyValue) is the most positive or most nega-
tive polarity value of all polar uni/bi-gram
occurrences in the tweet.
Both these features are normalised to values be-
tween −1 and +1.
if positivesCount &gt; negativesCount then
if negativesCount ! = 0 then
</bodyText>
<equation confidence="0.902996076923077">
polarityMeasure = positivesCount
negativesCount
else
polarityMeasure = positivesCount
end if
else if negativesCount &gt; positivesCount then
if positivesCount ! = 0 then
polarityMeasure = −1 x negativesCount
positivesCount
else
polarityMeasure = −1x negativesCount
end if
end if
</equation>
<bodyText confidence="0.746797363636364">
• Bing Liu Lexicon: The Bing Liu lexicon (Liu
et al., 2005) is a list of positive and nega-
tive words. We count the number of posi-
tive (positivesCount) and negative words (neg-
ativesCount) in each tweet, and calculate po-
larityMeasure using Algorithm 1. The polari-
tyMeasure is appended to the feature vector.
countAdv countNoun countVerb
totalPos , totalPos , totalPos ,
Algorithm 1 Calculating polarityMeasure based on
positivesCount and negativesCount
</bodyText>
<page confidence="0.984723">
648
</page>
<listItem confidence="0.975708870967742">
• NRC Emotion Lexicon: The NRC Emotion
Lexicon (Mohammad and Turney, 2013) con-
tains a list of positive and negative words. The
polarityMeasure is calculated using the method
used for the Bing Liu Lexicon.
• NRC Hashtag Lexicon: The NRC Hashtag
Lexicon (Mohammad et al., 2013) contains un-
igrams and bigrams along with their polarity
scores in the range of −5.00 to +5.00. Using
the method used for the Sentiment140 Lexicon,
we calculate polarityMeasure and maxPolarity-
Value, and append them to the feature vector.
• SentiWordNet: SentiWordNet (Esuli and Se-
bastiani, 2006) assigns to each synset of Word-
Net (Fellbaum, 2010) 3 scores: positivity, neg-
ativity, objectivity. A word whose positivity
score is greater than negativity and objectiv-
ity is positive, while a word whose negativity
score is greater than positivity and objectivity
is negative. For each tweet, we calculate po-
larityMeasure and maxPolarityValue using the
method used for the Bing Liu Lexicon.
• SenticNet: SenticNet (Cambria et al., 2014)
contains polarity scores of single and multi-
word phrases. We count the number of positive
and negative words/phrases in each tweet, and
calculate polarityMeasure using the method
used for the Sentiment140 Lexicon.
• Negation: The Stanford Dependency
Parser (De Marneffe et al., 2006) is used
to find negation in tweets. Negation is not a
</listItem>
<bodyText confidence="0.8481094">
feature on its own. Rather, it affects the word
n-grams and the lexicons related features. The
negated word is appended with a “ NEG” in
all n-grams, while the polarity of all negated
words is inverted in the lexicon features.
</bodyText>
<subsectionHeader confidence="0.985428">
2.2 Rule-based Classifier
</subsectionHeader>
<bodyText confidence="0.9996346">
For the rule-based classifier, we cast the problem
as a multi-class classification problem, where each
tweet is to be labeled as “positive”, “negative”
or “unknown”. This is an unsupervised classifier,
which applies the following rules for predictions:
</bodyText>
<listItem confidence="0.9966145">
• Emoticon-related Rules: If a tweet contains
only positive emoticons and no negative emoti-
</listItem>
<bodyText confidence="0.9927679">
cons, it is classified as positive. If a tweet con-
tains only negative emoticons and no positive
emoticons, it is classified as negative. If a tweet
contains no emoticons, we apply the sentiment
lexicon-related rules. The following emoticons
are considered to be positive: :) , (: , ;) ,
:-) , (-: , :D , :-D , :P , :-P . While, the
following emoticons are considered to be neg-
ative::(,):,;(,:-(,)-:,D:,
D-:,:’(,:’-(,)’:,)-’:.
</bodyText>
<listItem confidence="0.820951">
• Sentiment Lexicon-related Rules: The Bing
</listItem>
<bodyText confidence="0.962952545454545">
Liu lexicon, the NRC Emotion lexicon, and
SentiWordNet are used as resources for posi-
tive and negative opinion words. If a tweet con-
tains more than two positive words, and no
negation or negative words from either of the
lexicons, it is classified as positive. If a tweet
contains more than two negative words, and
no negation or positive words from either of the
lexicons, it is classified as negative. If none of
the above rules apply, the tweet is classified as
unknown.
</bodyText>
<subsectionHeader confidence="0.99953">
2.3 Combining the Classifiers
</subsectionHeader>
<bodyText confidence="0.999992875">
After developing the rule-based classifier and train-
ing the SVM, we combine the them to refine the
SVM’s predictions. Since, our goal is to maximise
positive and negative precision and recall, we use
the rule-based classifier to correct or verify the “neu-
tral” SVM predictions. So, for every tweet labeled
as neutral by the SVM, we consider the predictions
of the rule-based layer as the final labels.
</bodyText>
<sectionHeader confidence="0.998496" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.9999655">
We trained a Support Vector Machine (SVM) on
9418 tweets allowed to be used for training pur-
poses. The results we submitted to SemEval
2015 were yielded by using all SVM features and
emoticon-related rules. The sentiment lexicon-
related rules were implemented later, and thus could
not be used for the official submission. Table 2
shows the official test results for SemEval 2015.
</bodyText>
<page confidence="0.998281">
649
</page>
<table confidence="0.999794133333334">
Features P Positive F P Negative F P Neutral F Fpn
R R R
All Features 0.824 0.629 0.713 0.612 0.607 0.610 0.679 0.831 0.748 0.662
w/o N-grams 0.671 0.597 0.632 0.430 0.574 0.491 0.645 0.637 0.641 0.562
w/o POS Tags 0.814 0.611 0.698 0.633 0.589 0.610 0.669 0.839 0.744 0.654
w/o @User, 0.821 0.616 0.704 0.602 0.607 0.605 0.672 0.826 0.741 0.654
Hashtag, URL,
Discourse
w/o Sentiment140 0.814 0.616 0.701 0.602 0.599 0.600 0.676 0.830 0.745 0.651
w/o Bing Liu 0.821 0.621 0.707 0.616 0.603 0.610 0.676 0.833 0.746 0.658
w/o NRC Emo- 0.816 0.619 0.705 0.609 0.597 0.603 0.676 0.832 0.746 0.654
tion + Hashtag
w/o SentiWordNet 0.821 0.624 0.709 0.610 0.597 0.603 0.674 0.830 0.744 0.656
w/o SenticNet 0.820 0.615 0.703 0.610 0.597 0.603 0.674 0.837 0.747 0.653
w/o Negation 0.811 0.610 0.701 0.598 0.601 0.593 0.674 0.824 0.744 0.647
</table>
<tableCaption confidence="0.977809">
Table 1: Feature ablation study for the SVM classifier. Each row shows the precision, recall, and F-score for the
positive, negative, and neutral classes respectively, followed by the average positive and negative F-score, which is the
chosen evaluation metric. All values in the table are between 0 and 1, and are rounded off to 3 decimal places.
</tableCaption>
<table confidence="0.999790428571428">
Dataset Our Score Best Score
Twitter 2015 57.06 64.84
LiveJournal 2014 68.70 75.34
Twitter 2014 66.85 74.42
Twitter 2013 63.50 72.80
SMS 2013 60.53 68.49
Twitter 2014 Sarcasm 45.18 57.50
</table>
<tableCaption confidence="0.9829255">
Table 2: Average positive and negative F-scores for sys-
tem with all SVM features and only emoticon rules.
</tableCaption>
<bodyText confidence="0.981388416666667">
Table 1 reports the results of a feature abla-
tion study carried out by testing the SVM classi-
fier on 3204 development tweets (from SemEval
2013) not included in the training data. These are
cross-validation results obtained using the hold-out
method.This study helps us understand the impor-
tance of different features. From the table, we can
see that the word and character n-grams features are
the most useful, followed by negation and then the
rest. All sentiment lexicon related features appear to
have similar importance, but we get the best F-score
when we append them all to the feature vector.
</bodyText>
<table confidence="0.998169">
Features Fpn Classification Rate (%)
All Features 66.2 71.5
All Features and Rules 66.7 72.3
</table>
<tableCaption confidence="0.9646815">
Table 3: Comparison between the results obtained using
SVM alone, and using SVM with a rule-based layer.
</tableCaption>
<bodyText confidence="0.998838111111111">
Since, using all the previously described features
gives the best SVM predictions, we add the rule-
based classification layer to a SVM trained on all
features. Table 3 compares the results obtained us-
ing the SVM alone with the results obtained using
SVM along with all the rules (emoticon and lexicon-
based) specified in section 2.2. We observe that the
F-score further increases by around half a unit and
the classification rate2 increases by around 0.8.
</bodyText>
<sectionHeader confidence="0.996879" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999962384615385">
In this paper, we described a sentiment analysis sys-
tem developed by combining a SVM with a rule-
based classification layer. Even though we do not
get the best scores, we find that a rule-based clas-
sification layer can indeed refine the SVM’s predic-
tions. We also devise creative twitter-specific, nega-
tion and lexicon-related features for the SVM, and
demonstrate how they improve the sentiment analy-
sis system. In future, we aim to use enriched senti-
ment and emotion lists like the ones used by (Poria et
al., 2012). We would also like to experiment with re-
fining the SVM’s predictions using more rules based
on complex semantics.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9982255">
We wish to acknowledge the funding for this project
from Nanyang Technological University under the
Undergraduate Research Experience on CAmpus
(URECA) programme.
</bodyText>
<footnote confidence="0.736643">
2Classification rate = number of tweets classified correctly
total number of tweets
</footnote>
<page confidence="0.997253">
650
</page>
<sectionHeader confidence="0.996209" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999870987804878">
Erik Cambria, Amir Hussain, Catherine Havasi, Chris
Eckl, and James Munro. 2010. Towards crowd val-
idation of the uk national health service. WebSci10,
pages 1–5.
Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal.
2014. Senticnet 3: a common and common-sense
knowledge base for cognition-driven sentiment anal-
ysis. In Twenty-eighth AAAI conference on artificial
intelligence, pages 1515–1521.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine learning, 20(3):273–297.
Marie-Catherine De Marneffe, Bill MacCartney, Christo-
pher D Manning, et al. 2006. Generating typed de-
pendency parses from phrase structure parses. In Pro-
ceedings of LREC, volume 6, pages 449–454.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiword-
net: A publicly available lexical resource for opinion
mining. In Proceedings of LREC, volume 6, pages
417–422.
Christiane Fellbaum. 2010. Wordnet: An electronic
lexical database. 1998. WordNet is available from
http://www. cogsci. princeton. edu/wn.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael
Heilman, Dani Yogatama, Jeffrey Flanigan, and
Noah A Smith. 2011. Part-of-speech tagging for twit-
ter: Annotation, features, and experiments. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies: short papers-Volume 2, pages 42–47.
Glen Coppersmith Mark Dredze Craig Harman. Quanti-
fying mental health signals in twitter.
Bernard J Jansen, Mimi Zhang, Kate Sobel, and Abdur
Chowdury. 2009. Twitter power: Tweets as electronic
word of mouth. Journal of theAmerican society for in-
formation science and technology, 60(11):2169–2188.
Christopher Johnson, Parul Shukla, and Shilpa Shukla.
2012. On classifying the political sentiment of tweets.
cs. utexas. edu.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opinions
on the web. In Proceedings of the 14th international
conference on World Wide Web, pages 342–351.
Saif M Mohammad and Peter D Turney. 2013. Crowd-
sourcing a word–emotion association lexicon. Com-
putational Intelligence, 29(3):436–465.
Saif Mohammad, Svetlana Kiritchenko, and Xiaodan
Zhu. 2013. Nrc-canada: Building the state-of-the-
art in sentiment analysis of tweets. In Proceedings of
the seventh international workshop on Semantic Eval-
uation Exercises (SemEval-2013), Atlanta, Georgia,
USA, June.
Soujanya Poria, Alexander Gelbukh, Erik Cambria,
Peipei Yang, Amir Hussain, and Tariq Durrani. 2012.
Merging senticnet and wordnet-affect emotion lists for
sentiment analysis. In Signal Processing (ICSP), 2012
IEEE 11th International Conference on, volume 2,
pages 1251–1255.
Soujanya Poria, Erik Cambria, Amir Hussain, and
Guang-Bin Huang. 2015. Towards an intelligent
framework for multimodal affective data analysis.
Neural Networks, 63:104–116.
Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko,
Saif M Mohammad, Alan Ritter, and Veselin Stoy-
anov. 2015. Semeval-2015 task 10: Sentiment analy-
sis in twitter. In Proceedings of the 9th International
Workshop on Semantic Evaluation, SemEval ’2015,
Denver, Colorado, June.
Andranik Tumasjan, Timm Oliver Sprenger, Philipp G
Sandner, and Isabell M Welpe. 2010. Predicting elec-
tions with twitter: What 140 characters reveal about
political sentiment. ICWSM, 10:178–185.
Lu Wang and Claire Cardie. 2014. A piece of my mind:
A sentiment analysis approach for online dispute de-
tection. In Proceedings of the 52nd Annual Meeting
of the Association for Computational Linguistics, vol-
ume 2, pages 693–699.
Hao Wang, Dogan Can, Abe Kazemzadeh, Franc¸ois Bar,
and Shrikanth Narayanan. 2012. A system for real-
time twitter sentiment analysis of 2012 us presidential
election cycle. In Proceedings of the ACL 2012 System
Demonstrations, pages 115–120.
</reference>
<page confidence="0.998526">
651
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.468823">
<title confidence="0.999261">SeNTU: Sentiment Analysis of Tweets by Combining a Rule-based Classifier with Supervised Learning</title>
<author confidence="0.980184">Prerna Chikersal</author>
<author confidence="0.980184">Soujanya Poria</author>
<author confidence="0.980184">Erik</author>
<affiliation confidence="0.814691333333333">School of Computer Nanyang Technological Singapore -</affiliation>
<abstract confidence="0.999742117647059">We describe a Twitter sentiment analysis system developed by combining a rule-based classifier with supervised learning. We submitted our results for the message-level subtask in SemEval 2015 Task 10, and achieved of 57.06%. The rule-based classifier is based on rules that are dependent on the occurrences of emoticons and opinion words in tweets. Whereas, the Support Vector Machine (SVM) is trained on semantic, dependency, and sentiment lexicon based features. tweets are classified as the rule-based classifier, and as the SVM. The results we obtained show that rules can help refine the SVM’s predictions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Amir Hussain</author>
<author>Catherine Havasi</author>
<author>Chris Eckl</author>
<author>James Munro</author>
</authors>
<title>Towards crowd validation of the uk national health service.</title>
<date>2010</date>
<booktitle>WebSci10,</booktitle>
<pages>1--5</pages>
<contexts>
<context position="1796" citStr="Cambria et al., 2010" startWordPosition="280" endWordPosition="283">to expressing their opinions on a wide variety of topics on microblogging websites such as Twitter. Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a sentiment analysis system to participate in the message-level task of this competition. The objective of the system is to label the sentiment of each tweet as “positive”, “negative” or “neutral”. In this </context>
</contexts>
<marker>Cambria, Hussain, Havasi, Eckl, Munro, 2010</marker>
<rawString>Erik Cambria, Amir Hussain, Catherine Havasi, Chris Eckl, and James Munro. 2010. Towards crowd validation of the uk national health service. WebSci10, pages 1–5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Daniel Olsher</author>
<author>Dheeraj Rajagopal</author>
</authors>
<title>Senticnet 3: a common and common-sense knowledge base for cognition-driven sentiment analysis.</title>
<date>2014</date>
<booktitle>In Twenty-eighth AAAI conference on artificial intelligence,</booktitle>
<pages>1515--1521</pages>
<contexts>
<context position="7978" citStr="Cambria et al., 2014" startWordPosition="1279" endWordPosition="1282">od used for the Sentiment140 Lexicon, we calculate polarityMeasure and maxPolarityValue, and append them to the feature vector. • SentiWordNet: SentiWordNet (Esuli and Sebastiani, 2006) assigns to each synset of WordNet (Fellbaum, 2010) 3 scores: positivity, negativity, objectivity. A word whose positivity score is greater than negativity and objectivity is positive, while a word whose negativity score is greater than positivity and objectivity is negative. For each tweet, we calculate polarityMeasure and maxPolarityValue using the method used for the Bing Liu Lexicon. • SenticNet: SenticNet (Cambria et al., 2014) contains polarity scores of single and multiword phrases. We count the number of positive and negative words/phrases in each tweet, and calculate polarityMeasure using the method used for the Sentiment140 Lexicon. • Negation: The Stanford Dependency Parser (De Marneffe et al., 2006) is used to find negation in tweets. Negation is not a feature on its own. Rather, it affects the word n-grams and the lexicons related features. The negated word is appended with a “ NEG” in all n-grams, while the polarity of all negated words is inverted in the lexicon features. 2.2 Rule-based Classifier For the </context>
</contexts>
<marker>Cambria, Olsher, Rajagopal, 2014</marker>
<rawString>Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal. 2014. Senticnet 3: a common and common-sense knowledge base for cognition-driven sentiment analysis. In Twenty-eighth AAAI conference on artificial intelligence, pages 1515–1521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<booktitle>Machine learning,</booktitle>
<pages>20--3</pages>
<contexts>
<context position="3755" citStr="Cortes and Vapnik, 1995" startWordPosition="586" endWordPosition="589">weets with emoticons are given as input to the rule-based classifier, whereas the support vector machine takes pre647 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 647–651, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics processed tweets without emoticons as an input. 2.1 Supervised Learning For the supervised classifier, we cast the sentiment analysis problem as a multi-class classification problem, where each tweet has to be labeled as “positive”, “negative” or “neutral”. We train a Support Vector Machine (SVM) (Cortes and Vapnik, 1995) on the tweets provided for training. For all our experiments, we use a linear kernel and L1- regularisation. The C parameter is chosen by crossvalidation. As mentioned above, emoticons have already been removed from tweets given as input to the SVM. Each tweet is represented as a feature vector, containing the following features: • Word N-grams: Frequencies of contiguous sequences of 1, 2 or 3 tokens. The TF-IDF weighting scheme is applied. • Character N-grams: Frequencies of contiguous sequences of 1, 2 or 3 characters inside each word’s boundary. The TF-IDF weighting scheme is applied. • PO</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Machine learning, 20(3):273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="7542" citStr="Esuli and Sebastiani, 2006" startWordPosition="1210" endWordPosition="1214">tyMeasure based on positivesCount and negativesCount 648 • NRC Emotion Lexicon: The NRC Emotion Lexicon (Mohammad and Turney, 2013) contains a list of positive and negative words. The polarityMeasure is calculated using the method used for the Bing Liu Lexicon. • NRC Hashtag Lexicon: The NRC Hashtag Lexicon (Mohammad et al., 2013) contains unigrams and bigrams along with their polarity scores in the range of −5.00 to +5.00. Using the method used for the Sentiment140 Lexicon, we calculate polarityMeasure and maxPolarityValue, and append them to the feature vector. • SentiWordNet: SentiWordNet (Esuli and Sebastiani, 2006) assigns to each synset of WordNet (Fellbaum, 2010) 3 scores: positivity, negativity, objectivity. A word whose positivity score is greater than negativity and objectivity is positive, while a word whose negativity score is greater than positivity and objectivity is negative. For each tweet, we calculate polarityMeasure and maxPolarityValue using the method used for the Bing Liu Lexicon. • SenticNet: SenticNet (Cambria et al., 2014) contains polarity scores of single and multiword phrases. We count the number of positive and negative words/phrases in each tweet, and calculate polarityMeasure u</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>Wordnet: An electronic lexical database.</title>
<date>2010</date>
<note>WordNet is available from http://www. cogsci. princeton. edu/wn.</note>
<contexts>
<context position="7593" citStr="Fellbaum, 2010" startWordPosition="1222" endWordPosition="1223">Emotion Lexicon: The NRC Emotion Lexicon (Mohammad and Turney, 2013) contains a list of positive and negative words. The polarityMeasure is calculated using the method used for the Bing Liu Lexicon. • NRC Hashtag Lexicon: The NRC Hashtag Lexicon (Mohammad et al., 2013) contains unigrams and bigrams along with their polarity scores in the range of −5.00 to +5.00. Using the method used for the Sentiment140 Lexicon, we calculate polarityMeasure and maxPolarityValue, and append them to the feature vector. • SentiWordNet: SentiWordNet (Esuli and Sebastiani, 2006) assigns to each synset of WordNet (Fellbaum, 2010) 3 scores: positivity, negativity, objectivity. A word whose positivity score is greater than negativity and objectivity is positive, while a word whose negativity score is greater than positivity and objectivity is negative. For each tweet, we calculate polarityMeasure and maxPolarityValue using the method used for the Bing Liu Lexicon. • SenticNet: SenticNet (Cambria et al., 2014) contains polarity scores of single and multiword phrases. We count the number of positive and negative words/phrases in each tweet, and calculate polarityMeasure using the method used for the Sentiment140 Lexicon. </context>
</contexts>
<marker>Fellbaum, 2010</marker>
<rawString>Christiane Fellbaum. 2010. Wordnet: An electronic lexical database. 1998. WordNet is available from http://www. cogsci. princeton. edu/wn.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 42–47.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Glen Coppersmith</author>
</authors>
<title>Mark Dredze Craig Harman. Quantifying mental health signals in twitter.</title>
<marker>Coppersmith, </marker>
<rawString>Glen Coppersmith Mark Dredze Craig Harman. Quantifying mental health signals in twitter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard J Jansen</author>
<author>Mimi Zhang</author>
<author>Kate Sobel</author>
<author>Abdur Chowdury</author>
</authors>
<title>Twitter power: Tweets as electronic word of mouth. Journal of theAmerican society for information science and technology,</title>
<date>2009</date>
<pages>60--11</pages>
<contexts>
<context position="1956" citStr="Jansen et al., 2009" startWordPosition="304" endWordPosition="307"> number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a sentiment analysis system to participate in the message-level task of this competition. The objective of the system is to label the sentiment of each tweet as “positive”, “negative” or “neutral”. In this paper, we describe our sentiment analysis system, which is a combined classifier created by integrating a rule-based classification layer with a support vector </context>
</contexts>
<marker>Jansen, Zhang, Sobel, Chowdury, 2009</marker>
<rawString>Bernard J Jansen, Mimi Zhang, Kate Sobel, and Abdur Chowdury. 2009. Twitter power: Tweets as electronic word of mouth. Journal of theAmerican society for information science and technology, 60(11):2169–2188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Johnson</author>
<author>Parul Shukla</author>
<author>Shilpa Shukla</author>
</authors>
<title>On classifying the political sentiment of tweets.</title>
<date>2012</date>
<note>cs. utexas. edu.</note>
<contexts>
<context position="1616" citStr="Johnson et al., 2012" startWordPosition="250" endWordPosition="253">s and the opinions of others play a very important role in our decision-making process and even influence our behaviour. In recent times, an increasing number of people have taken to expressing their opinions on a wide variety of topics on microblogging websites such as Twitter. Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a sentiment analysis syste</context>
</contexts>
<marker>Johnson, Shukla, Shukla, 2012</marker>
<rawString>Christopher Johnson, Parul Shukla, and Shilpa Shukla. 2012. On classifying the political sentiment of tweets. cs. utexas. edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th international conference on World Wide Web,</booktitle>
<pages>342--351</pages>
<contexts>
<context position="6576" citStr="Liu et al., 2005" startWordPosition="1059" endWordPosition="1062">he maximum polarity value (maxPolarityValue) is the most positive or most negative polarity value of all polar uni/bi-gram occurrences in the tweet. Both these features are normalised to values between −1 and +1. if positivesCount &gt; negativesCount then if negativesCount ! = 0 then polarityMeasure = positivesCount negativesCount else polarityMeasure = positivesCount end if else if negativesCount &gt; positivesCount then if positivesCount ! = 0 then polarityMeasure = −1 x negativesCount positivesCount else polarityMeasure = −1x negativesCount end if end if • Bing Liu Lexicon: The Bing Liu lexicon (Liu et al., 2005) is a list of positive and negative words. We count the number of positive (positivesCount) and negative words (negativesCount) in each tweet, and calculate polarityMeasure using Algorithm 1. The polarityMeasure is appended to the feature vector. countAdv countNoun countVerb totalPos , totalPos , totalPos , Algorithm 1 Calculating polarityMeasure based on positivesCount and negativesCount 648 • NRC Emotion Lexicon: The NRC Emotion Lexicon (Mohammad and Turney, 2013) contains a list of positive and negative words. The polarityMeasure is calculated using the method used for the Bing Liu Lexicon.</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In Proceedings of the 14th international conference on World Wide Web, pages 342–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word–emotion association lexicon.</title>
<date>2013</date>
<journal>Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="7046" citStr="Mohammad and Turney, 2013" startWordPosition="1131" endWordPosition="1134">ure = −1 x negativesCount positivesCount else polarityMeasure = −1x negativesCount end if end if • Bing Liu Lexicon: The Bing Liu lexicon (Liu et al., 2005) is a list of positive and negative words. We count the number of positive (positivesCount) and negative words (negativesCount) in each tweet, and calculate polarityMeasure using Algorithm 1. The polarityMeasure is appended to the feature vector. countAdv countNoun countVerb totalPos , totalPos , totalPos , Algorithm 1 Calculating polarityMeasure based on positivesCount and negativesCount 648 • NRC Emotion Lexicon: The NRC Emotion Lexicon (Mohammad and Turney, 2013) contains a list of positive and negative words. The polarityMeasure is calculated using the method used for the Bing Liu Lexicon. • NRC Hashtag Lexicon: The NRC Hashtag Lexicon (Mohammad et al., 2013) contains unigrams and bigrams along with their polarity scores in the range of −5.00 to +5.00. Using the method used for the Sentiment140 Lexicon, we calculate polarityMeasure and maxPolarityValue, and append them to the feature vector. • SentiWordNet: SentiWordNet (Esuli and Sebastiani, 2006) assigns to each synset of WordNet (Fellbaum, 2010) 3 scores: positivity, negativity, objectivity. A wor</context>
</contexts>
<marker>Mohammad, Turney, 2013</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2013. Crowdsourcing a word–emotion association lexicon. Computational Intelligence, 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the state-of-theart in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>In Proceedings of the seventh international workshop on Semantic Evaluation Exercises (SemEval-2013),</booktitle>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="5479" citStr="Mohammad et al., 2013" startWordPosition="885" endWordPosition="888">ns a @&lt;username&gt; reference. • Hashtag: A boolean feature that is set to 1 if the tweet contains a hashtag. • URL: A boolean feature that is set to 1 if the tweet contains a URL. • Discourse: A boolean feature that is set to 1 if the tweet contains a “discourse marker”. Examples of discourse markers would be a “RT” followed by a username to indicate that the tweet is a re-tweet, news article headline followed by “...” followed by a URL to the news article, etc. Basically, this feature indicates whether or not the tweet is a part of a discourse. • Sentiment140 Lexicon: The Sentiment140 Lexicon (Mohammad et al., 2013) contains unigrams and bigrams along with their polarity scores in the range of −5.00 to +5.00. Considering all uni/bi-grams with polarity less than −1.0 to be negative and with polarity greater than +1.0 to be positive, we count the number of negative (negativesCount) and the number of positive (positivesCount) uni/bi-gram occurrences in every tweet. For each tweet, – the polarityMeasure is based on the positivesCount and negativesCount, and calculated using Algorithm 1. – the maximum polarity value (maxPolarityValue) is the most positive or most negative polarity value of all polar uni/bi-gr</context>
<context position="7247" citStr="Mohammad et al., 2013" startWordPosition="1165" endWordPosition="1168">nt the number of positive (positivesCount) and negative words (negativesCount) in each tweet, and calculate polarityMeasure using Algorithm 1. The polarityMeasure is appended to the feature vector. countAdv countNoun countVerb totalPos , totalPos , totalPos , Algorithm 1 Calculating polarityMeasure based on positivesCount and negativesCount 648 • NRC Emotion Lexicon: The NRC Emotion Lexicon (Mohammad and Turney, 2013) contains a list of positive and negative words. The polarityMeasure is calculated using the method used for the Bing Liu Lexicon. • NRC Hashtag Lexicon: The NRC Hashtag Lexicon (Mohammad et al., 2013) contains unigrams and bigrams along with their polarity scores in the range of −5.00 to +5.00. Using the method used for the Sentiment140 Lexicon, we calculate polarityMeasure and maxPolarityValue, and append them to the feature vector. • SentiWordNet: SentiWordNet (Esuli and Sebastiani, 2006) assigns to each synset of WordNet (Fellbaum, 2010) 3 scores: positivity, negativity, objectivity. A word whose positivity score is greater than negativity and objectivity is positive, while a word whose negativity score is greater than positivity and objectivity is negative. For each tweet, we calculate</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. Nrc-canada: Building the state-of-theart in sentiment analysis of tweets. In Proceedings of the seventh international workshop on Semantic Evaluation Exercises (SemEval-2013), Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soujanya Poria</author>
<author>Alexander Gelbukh</author>
<author>Erik Cambria</author>
<author>Peipei Yang</author>
<author>Amir Hussain</author>
<author>Tariq Durrani</author>
</authors>
<title>Merging senticnet and wordnet-affect emotion lists for sentiment analysis.</title>
<date>2012</date>
<booktitle>In Signal Processing (ICSP), 2012 IEEE 11th International Conference on,</booktitle>
<volume>2</volume>
<pages>1251--1255</pages>
<marker>Poria, Gelbukh, Cambria, Yang, Hussain, Durrani, 2012</marker>
<rawString>Soujanya Poria, Alexander Gelbukh, Erik Cambria, Peipei Yang, Amir Hussain, and Tariq Durrani. 2012. Merging senticnet and wordnet-affect emotion lists for sentiment analysis. In Signal Processing (ICSP), 2012 IEEE 11th International Conference on, volume 2, pages 1251–1255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soujanya Poria</author>
<author>Erik Cambria</author>
<author>Amir Hussain</author>
<author>Guang-Bin Huang</author>
</authors>
<title>Towards an intelligent framework for multimodal affective data analysis.</title>
<date>2015</date>
<journal>Neural Networks,</journal>
<pages>63--104</pages>
<contexts>
<context position="1853" citStr="Poria et al., 2015" startWordPosition="289" endWordPosition="292">n microblogging websites such as Twitter. Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a sentiment analysis system to participate in the message-level task of this competition. The objective of the system is to label the sentiment of each tweet as “positive”, “negative” or “neutral”. In this paper, we describe our sentiment analysis system, which i</context>
</contexts>
<marker>Poria, Cambria, Hussain, Huang, 2015</marker>
<rawString>Soujanya Poria, Erik Cambria, Amir Hussain, and Guang-Bin Huang. 2015. Towards an intelligent framework for multimodal affective data analysis. Neural Networks, 63:104–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Svetlana Kiritchenko</author>
<author>Saif M Mohammad</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<title>Semeval-2015 task 10: Sentiment analysis in twitter.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="2003" citStr="Rosenthal et al., 2015" startWordPosition="312" endWordPosition="315"> choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a sentiment analysis system to participate in the message-level task of this competition. The objective of the system is to label the sentiment of each tweet as “positive”, “negative” or “neutral”. In this paper, we describe our sentiment analysis system, which is a combined classifier created by integrating a rule-based classification layer with a support vector machine. 2 System Description Our Sentiment Ana</context>
</contexts>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2015</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko, Saif M Mohammad, Alan Ritter, and Veselin Stoyanov. 2015. Semeval-2015 task 10: Sentiment analysis in twitter. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andranik Tumasjan</author>
<author>Timm Oliver Sprenger</author>
<author>Philipp G Sandner</author>
<author>Isabell M Welpe</author>
</authors>
<title>Predicting elections with twitter: What 140 characters reveal about political sentiment.</title>
<date>2010</date>
<journal>ICWSM,</journal>
<pages>10--178</pages>
<contexts>
<context position="1594" citStr="Tumasjan et al., 2010" startWordPosition="245" endWordPosition="249">ntroduction Our opinions and the opinions of others play a very important role in our decision-making process and even influence our behaviour. In recent times, an increasing number of people have taken to expressing their opinions on a wide variety of topics on microblogging websites such as Twitter. Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, development and testing. We created a se</context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Andranik Tumasjan, Timm Oliver Sprenger, Philipp G Sandner, and Isabell M Welpe. 2010. Predicting elections with twitter: What 140 characters reveal about political sentiment. ICWSM, 10:178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Wang</author>
<author>Claire Cardie</author>
</authors>
<title>A piece of my mind: A sentiment analysis approach for online dispute detection.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>693--699</pages>
<contexts>
<context position="1561" citStr="Wang and Cardie, 2014" startWordPosition="240" endWordPosition="243"> refine the SVM’s predictions. 1 Introduction Our opinions and the opinions of others play a very important role in our decision-making process and even influence our behaviour. In recent times, an increasing number of people have taken to expressing their opinions on a wide variety of topics on microblogging websites such as Twitter. Being able to analyse this data and extract opinions about a number of topics, can help us make informed choices and predictions regarding those topics. Due to this, sentiment analysis of tweets is gaining importance across a number of domains such as ecommerce (Wang and Cardie, 2014), politics (Tumasjan et al., 2010; Johnson et al., 2012; Wang et 1We average the positive and negative F-measures to get the F-score, which is the evaluation metric for this task. al., 2012), health and psychology (Cambria et al., 2010; Harman, ; Harman, ), multimodality (Poria et al., 2015), crowd validation (Cambria et al., 2010), and even intelligence and surveillance (Jansen et al., 2009). SemEval 2015 Task 10 (Rosenthal et al., 2015) is an international shared-task competition that aims to promote research in sentiment analysis of tweets by providing annotated tweets for training, develop</context>
</contexts>
<marker>Wang, Cardie, 2014</marker>
<rawString>Lu Wang and Claire Cardie. 2014. A piece of my mind: A sentiment analysis approach for online dispute detection. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 2, pages 693–699.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Wang</author>
<author>Dogan Can</author>
<author>Abe Kazemzadeh</author>
<author>Franc¸ois Bar</author>
<author>Shrikanth Narayanan</author>
</authors>
<title>A system for realtime twitter sentiment analysis of 2012 us presidential election cycle.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations,</booktitle>
<pages>115--120</pages>
<marker>Wang, Can, Kazemzadeh, Bar, Narayanan, 2012</marker>
<rawString>Hao Wang, Dogan Can, Abe Kazemzadeh, Franc¸ois Bar, and Shrikanth Narayanan. 2012. A system for realtime twitter sentiment analysis of 2012 us presidential election cycle. In Proceedings of the ACL 2012 System Demonstrations, pages 115–120.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>