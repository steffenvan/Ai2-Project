<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.999032">
A Systematic Analysis of Translation Model Search Spaces
</title>
<author confidence="0.999246">
Michael Auli, Adam Lopez, Hieu Hoang and Philipp Koehn
</author>
<affiliation confidence="0.999255">
University of Edinburgh
</affiliation>
<address confidence="0.983519666666667">
10 Crichton Street
Edinburgh, EH8 9AB
United Kingdom
</address>
<email confidence="0.994841">
m.auli@sms.ed.ac.uk, alopez@inf.ed.ac.uk, h.hoang@sms.ed.ac.uk, pkoehn@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.993731" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999877615384615">
Translation systems are complex, and
most metrics do little to pinpoint causes of
error or isolate system differences. We use
a simple technique to discover induction
errors, which occur when good transla-
tions are absent from model search spaces.
Our results show that a common prun-
ing heuristic drastically increases induc-
tion error, and also strongly suggest that
the search spaces of phrase-based and hi-
erarchical phrase-based models are highly
overlapping despite the well known struc-
tural differences.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999808086956522">
Most empirical work in translation analyzes mod-
els and algorithms using BLEU (Papineni et al.,
2002) and related metrics. Though such met-
rics are useful as sanity checks in iterative sys-
tem development, they are less useful as analyti-
cal tools. The performance of a translation system
depends on the complex interaction of several dif-
ferent components. Since metrics assess only out-
put, they fail to inform us about the consequences
of these interactions, and thus provide no insight
into the errors made by a system, or into the de-
sign tradeoffs of competing systems.
In this work, we show that it is possible to ob-
tain such insights by analyzing translation sys-
tem components in isolation. We focus on model
search spaces (§2), posing a very simple question:
Given a model and a sentence pair, does the search
space contain the sentence pair? Applying this
method to the analysis and comparison of French-
English translation using both phrase-based and
hierarchical phrase-based systems yields surpris-
ing results, which we analyze quantitatively and
qualitatively.
</bodyText>
<listItem confidence="0.943981">
• First, we analyze the induction error of a
</listItem>
<bodyText confidence="0.996600833333333">
model, a measure on the completeness of the
search space. We find that low weight phrase
translations typically discarded by heuristic
pruning nearly triples the number of refer-
ence sentences that can be exactly recon-
structed by either model (§3).
</bodyText>
<listItem confidence="0.977892714285714">
• Second, we find that the high-probability re-
gions in the search spaces of phrase-based
and hierarchical systems are nearly identical
(§4). This means that reported differences be-
tween the models are due to their rankings of
competing hypotheses, rather than structural
differences of the derivations they produce.
</listItem>
<sectionHeader confidence="0.57074" genericHeader="method">
2 Models, Search Spaces, and Errors
</sectionHeader>
<bodyText confidence="0.99994496">
A translation model consists of two distinct ele-
ments: an unweighted ruleset, and a parameteri-
zation (Lopez, 2008a; 2009). A ruleset licenses
the steps by which a source string f1...fI may be
rewritten as a target string e1...eJ. A parameter-
ization defines a weight function over every se-
quence of rule applications.
In a phrase-based model, the ruleset is simply
the unweighted phrase table, where each phrase
pair fi...fi,/ej...ej, states that phrase fi...fi, in
the source can be rewritten as ej...ej, in the tar-
get. The model operates by iteratively apply-
ing rewrites to the source sentence until each
source word has been consumed by exactly one
rule. There are two additional heuristic rules:
The distortion limit dl constrains distances over
which phrases can be reordered, and the transla-
tion option limit tol constrains the number of tar-
get phrases that may be considered for any given
source phrase. Together, these rules completely
determine the finite set of all possible target sen-
tences for a given source sentence. We call this set
of target sentences the model search space.
The parameterization of the model includes all
information needed to score any particular se-
</bodyText>
<note confidence="0.937859">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 224–232,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998141">
224
</page>
<bodyText confidence="0.999963954545455">
quence of rule applications. In our phrase-based
model, it typically includes phrase translation
probabilities, lexical translation probabilities, lan-
guage model probabilities, word counts, and co-
efficients on the linear combination of these. The
combination of large rulesets and complex param-
eterizations typically makes search intractable, re-
quiring the use of approximate search. It is im-
portant to note that, regardless of the parameteri-
zation or search used, the set of all possible output
sentences is still a function of only the ruleset.
Germann et al. (2004) identify two types of
translation system error: model error and search
error.1 Model error occurs when the optimal
path through the search space leads to an incorrect
translation. Search error occurs when the approxi-
mate search technique causes the decoder to select
a translation other than the optimum.
Given the decomposition outlined above, it
seems clear that model error depends on param-
eterization, while search error depends on approx-
imate search. However, there is no error type that
clearly depends on the ruleset (Table 1). We there-
fore identify a new type of error on the ruleset: in-
duction error. Induction error occurs when the
search space does not contain the correct target
sentence at all, and is thus a more fundamental
defect than model error. This is difficult to mea-
sure, since there could be many correct transla-
tions and there is no way to see whether they are
all absent from the search space.2 However, if we
assume that a given reference sentence is ground
truth, then as a proxy we can simply ask whether
or not the model search space contains the refer-
ence. This assumption is of course too strong, but
over a sufficiently large test set, it should correlate
with metrics which depend on the reference, since
under most metrics, exactly reproducing the ref-
erence results in a perfect score. More loosely, it
should correlate with translation accuracy—even
if there are many good translations, a model which
is systematically unable to produce any reference
sentences from a sufficiently large test sample is
almost certainly deficient in some way.
</bodyText>
<subsectionHeader confidence="0.497695">
Phrase Probability p(e|f)
</subsectionHeader>
<sectionHeader confidence="0.963929" genericHeader="method">
3 Does Ruleset Pruning Matter?
</sectionHeader>
<bodyText confidence="0.995742">
The heuristic translation option limit tol controls
the number of translation rules considered per
</bodyText>
<footnote confidence="0.99575925">
1They also identify variants within these types.
2It can also be gamed by using a model that can generate
any English word from any French word. However, this is
not a problem for the real models we investigate here.
</footnote>
<bodyText confidence="0.619785666666667">
ruleset induction error
parameterization model error
search search error
</bodyText>
<tableCaption confidence="0.9876375">
Table 1: Translation system components and their
associated error types.
</tableCaption>
<figure confidence="0.996045166666667">
0.8
0.6
0.4
0.2
0100 101 102 103
Translation Options
</figure>
<figureCaption confidence="0.910053">
Figure 1: Distribution p(f|e) of the English trans-
lation options for the French word probl`eme.
</figureCaption>
<bodyText confidence="0.99495671875">
source span. It plays a major role in keeping the
search space manageable. Ignoring reordering, the
complexity of the search in a phrase-based model
is O(n&amp;quot;&apos;), where n is the number of French spans.
Therefore tol has a major effect on efficiency.
Tight pruning with tol is often assumed without
question to be a worthwhile tradeoff. However,
we wish to examine this assumption more closely.
Consider the French word probl`eme. It has 288
different translation options in the phrase table
of our French-English phrase-based system. The
phrase translation probability p(elf) over these
options is a familiar Zipf distribution (Figure 1).
The most likely candidate translation for the word
is problem with a probability of 0.71, followed by
issue with a much smaller probability of 0.12. Fur-
ther down, we find challenge at rank 25, obsta-
cle at 44 and dilemma at rank 105. Depending on
the context, these might be perfectly good transla-
tions. However, with a typical tol of 20, most of
these options are not considered during decoding.
Table 2 shows that 93.8% of rules are available
during decoding with the standard tol setting and
only about 0.1% of French spans of the entire rule-
set have more than 20 translation options. It seems
as if already most of the information is available
when using the default limit. However, a tol of
20 can clearly exclude good translations as illus-
trated by our example. Therefore we hypothesize
the following: Increasing the translation option
limit gives the decoder a larger vocabulary which
in turn will decrease the induction error. We sup-
</bodyText>
<page confidence="0.998458">
225
</page>
<table confidence="0.946956375">
tol Ruleset Size French Spans
20 93.8 99.9
50 96.8 100.0
100 98.3 100.0
200 99.2 100.0
400 99.7 100.0
800 99.9 100.0
All 100.0 100.0
</table>
<tableCaption confidence="0.948834">
Table 2: Ruleset size expressed as percentage of
available rules when varying the limit of transla-
tion options tol per English span and percentage
of French spans with up to tol translations.
</tableCaption>
<bodyText confidence="0.854716">
port this hypothesis experimentally in §5.4.
</bodyText>
<sectionHeader confidence="0.893743" genericHeader="method">
4 How Similar are Model Search Spaces?
</sectionHeader>
<bodyText confidence="0.950282">
Most work on hierarchical phrase-based transla-
tion focuses quite intently on its structural differ-
ences from phrase-based translation.
</bodyText>
<listItem confidence="0.953589666666667">
• A hierarchical model can translate discon-
tiguous groups of words as a unit. A phrase-
based model cannot. Lopez (2008b) gives in-
direct experimental evidence that this differ-
ence affects performance.
• A standard phrase-based model can reorder
phrases arbitrarily within the distortion limit,
while the hierarchical model requires some
lexical evidence for movement, resorting to
monotone translation otherwise.
• While both models can indirectly model
word deletion in the context of phrases, the
hierarchical model can delete words using
non-local context due to its use of discontigu-
ous phrases.
</listItem>
<bodyText confidence="0.999981571428571">
The underlying assumption in most discussions
of these models is that these differences in their
generative stories are responsible for differences
in performance. We believe that this assumption
should be investigated empirically.
In an interesting analysis of phrase-based and
hierarchical translation, Zollmann et al. (2008)
forced a phrase-based system to produce the trans-
lations generated by a hierarchical system. Unfor-
tunately, their analysis is incomplete; they do not
perform the analysis in both directions. In §5.5 we
extend their work by requiring each system to gen-
erate the 1-best output of the other. This allows us
to see how their search spaces differ.
</bodyText>
<sectionHeader confidence="0.997833" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99997425">
We analyse rulesets in isolation, removing the in-
fluence of the parametrization and heuristics as
much as possible for each system as follows: First,
we disabled beam search to avoid pruning based
on parametrization weights. Second, we require
our decoders to generate the reference via disal-
lowing reference-incompatible hypothesis or chart
entries. This leaves only some search restrictions
such as the distortion limit for the phrase-based
system for which we controlled, or the maximum
number of source words involved in a rule appli-
cation for the hierarchical system.
</bodyText>
<subsectionHeader confidence="0.984121">
5.1 Experimental Systems
</subsectionHeader>
<bodyText confidence="0.9999914375">
Our phrase-based system is Moses (Koehn et al.,
2007). We set its stack size to 105, disabled the
beam threshold, and varied the translation option
limit tol. Forced translation was implemented by
Schwartz (2008) who ensures that hypothesis are
a prefix of the reference to be generated.
Our hierarchical system is Hiero (Chiang,
2007), modified to construct rules from a small
sample of occurrences of each source phrase in
training as described by Lopez (2008b). The
search parameters restricting the number of rules
or chart entries as well as the minimum threshold
were set to very high values (1050) to prevent prun-
ing. Forced translation was implemented by dis-
carding rules and chart entries which do not match
the reference.
</bodyText>
<subsectionHeader confidence="0.997693">
5.2 Experimental Data
</subsectionHeader>
<bodyText confidence="0.999992166666667">
We conducted experiments in French-English
translation, attempting to make the experimental
conditions for both systems as equal as possible.
Each system was trained on French-English Eu-
roparl (Koehn, 2005), version 3 (40M words). The
corpus was aligned with GIZA++ (Och and Ney,
2003) and symmetrized with the grow-diag-final-
and heuristic (Koehn et al., 2003). A trigram
language model with modified Kneser-Ney dis-
counting and interpolation was used as produced
by the SRILM toolkit (Stolcke, 2002). Systems
were optimized on the WMT08 French-English
development data (2000 sentences) using mini-
mum error rate training (Och, 2003) and tested
on the WMT08 test data (2000 sentences). Rules
based on unaligned words at the edges of foreign
and source spans were not allowed unless other-
wise stated, this is denoted as the tightness con-
</bodyText>
<page confidence="0.993457">
226
</page>
<figure confidence="0.449152">
Translation Option Limit
</figure>
<figureCaption confidence="0.975006666666667">
Figure 2: Coverage for phrase-based reference
aligned translation on test data when varying the
translation option and the distortion limits (dl).
</figureCaption>
<bodyText confidence="0.999234111111111">
straint. Ayan and Dorr (2006) showed that under
certain conditions, this constraint could have sig-
nificant impact on system performance. The max-
imum phrase lengths for both the hierarchical and
phrase-based system were set to 7. The distortion
limit (dl) for the phrase-based system was set to
6 unless otherwise mentioned. All other settings
were left at their default values as described by
Chiang (2007) and Koehn et al. (2007).
</bodyText>
<subsectionHeader confidence="0.992552">
5.3 Metric: Reference Reachability
</subsectionHeader>
<bodyText confidence="0.999394">
We measure system performance in terms of ref-
erence reachability, which is the inverse of in-
duction error: A system is required to be able to
exactly reproduce the reference, otherwise we re-
gard the result as an error.
</bodyText>
<subsectionHeader confidence="0.999891">
5.4 Analysis of Ruleset Pruning
</subsectionHeader>
<bodyText confidence="0.9999662">
In §3 we outlined the hypothesis that increas-
ing the number of English translation options per
French span can increase performance. Here we
present results for both phrase-based and hierar-
chical systems to support this claim.
</bodyText>
<subsectionHeader confidence="0.766802">
5.4.1 Quantitative Results
</subsectionHeader>
<bodyText confidence="0.999219625">
Figure 2 shows the experimental results when
forcing our phrase-based system to generate un-
seen test data. We observe more than 30% in-
crease in reachability from tol = 20 to tol = 50
for all dl &gt; 6 which supports our hypothesis that
increasing tol by a small multiple can have a sig-
nificant impact on performance. With no limit on
tol, reachability nearly triples.
</bodyText>
<table confidence="0.999681647058824">
French Spans Number of Translations
des 3006
les 2464
la 1582
de 1557
en 1428
de la 1332
fait 1308
une 1303
a` 1291
le 1273
d’ 1271
faire 1263
l’ 1111
c’ est 1109
a` la 1053
, 1035
</table>
<tableCaption confidence="0.981658">
Table 3: French spans with more than 1000 trans-
lation options.
</tableCaption>
<bodyText confidence="0.997494033333333">
Notably, the increase stems from the small frac-
tion of French spans (0.1%) which have more than
20 translation options (Table 2). There are only
16 French spans (Table 3) which have more than
1000 translation options, however, utilising these
can still achieve an increase in reachability of up
to 5%. The list shown in Table 3 includes common
articles, interpuncutation, conjunctions, preposi-
tions but also verbs which have unreliable align-
ment points and therefore a very long tail of low
probability translation options. Yet, the largest in-
crease does not stem from using such unreliable
translation options, but rather when increasing tol
by a relatively small amount.
The increases we see in reachability are pro-
portional to the size of the ruleset: The high-
est increases in ruleset size can be seen between
tol = 20 and tol = 200 (Table 2), similarly, reach-
ability performance has then the largest increase.
For higher tol settings both the increases of ruleset
size and reachability are smaller.
Figure 3 plots the average number of words per
sentence for the reachable sentences. The average
sentence length increases by up to six words when
using all translation options. The black line repre-
sents the average number of words per sentence of
the reference set. This shows that longer and more
complex sentences can be generated when using
more translation options.
Similarly, for our hierarchical system (see Fig-
</bodyText>
<figure confidence="0.983851727272727">
dl=6
dl=7
dl=8
dl=9
dl=10
dl=11
dl=12
dl=13
dl=14
dl=15
dl=16
15
50 100 200 400 800 All
10
20
35
30
Reachability (%)
25
20
227
Translation Option Limit
</figure>
<figureCaption confidence="0.84702425">
Figure 3: Average number of words per sen-
tence for the reachable test data translations of the
phrase-based system (as shown in Figure 2).
Figure 4: Coverage for hierarchical reference
aligned translation on test data when varying the
number of matching French samples (sl) drawn
from the training data. The baseline setting is
sl = 300.
</figureCaption>
<bodyText confidence="0.999978181818182">
ure 4) we find that reachability can be more than
doubled when drawing a richer ruleset sample than
in the baseline setting. Those results are not di-
rectly comparable to the phrase-based system due
to the slightly different nature of the parameters
which were varied: In the phrase-based case we
have tol different English spans per French span.
In the hierarchical system it is very likely to have
duplicate French spans in the sample drawn from
training data. Yet, the trend is the same and thus
supports our claim.
</bodyText>
<subsectionHeader confidence="0.523325">
5.4.2 Qualitative Results
</subsectionHeader>
<bodyText confidence="0.999967225806452">
We were interested how the performance increase
could be achieved and therefore looked into which
kind of translation options were involved when a
translation was generable with a higher tol setting.
One possibility is that the long tail of translation
options includes all kinds of English spans that
match some part of the reference but are simply
an artifact of unreliable alignment points.
We looked at the first twenty translations pro-
duced by our phrase-based system under dl = 10
which could not be generated with tol = 20 but
with tol = 50. The aim was to find out which
translation options made it possible to reach the
reference under tol = 50.
We found that nearly half (9) involved transla-
tion options which used a common or less com-
mon translation of the foreign span. The first four
translations in Table 4 are examples for that. When
allowing unaligned words at the rule edges it turns
out that even 13 out of 20 translations are based on
sound translation options.
The remaining sentences involved translation
options which were an artifact of unreliable align-
ment points. An example rule is la / their, which
erroneously translates a common determiner into
an equally common adjective. The last translation
in Figure 4 involves such a translation option.
This analysis demonstrates that the performance
increase between tol = 20 to tol = 50 is to a
considerable extent based on translation options
which are meaningful.
</bodyText>
<subsectionHeader confidence="0.999582">
5.5 Analysis of Mutual Reachability
</subsectionHeader>
<bodyText confidence="0.99985595">
The aim of this analysis was to find out by how
much the high-probability search spaces of the
phrase-based and hierarchical models differ. The
necessary data was obtained via forcing each sys-
tem to produce the 1-best translation of the other
system denoted as the unconstrained translation.
This unconstrained translation used the standard
setting for the number of translation options.
We controlled for the way unaligned words
were handled during rule extraction: The phrase-
based system allowed unaligned words at the
edges of phrases while the hierarchical system did
not. We varied this condition for the phrase-based
system. The distortion limit of the phrase-based
system was set to 10. This is equal to the maxi-
mum span a rule can be applied within the hierar-
chical system.
We carried out the same experiment for
German-English and English-German translation
which serve as examples for translating into a mor-
</bodyText>
<figure confidence="0.996205432432433">
Average Number of Words per Sentence
28
26
24
22
20
32
30
18
16
dl=6
dl=7
dl=8
dl=9
dl=10
dl=11
dl=12
dl=13
dl=14
dl=15
dl=16
Reference
50 100 200 400 800 All
1
4
20
40
35
30
25
20
15
10
5
25 50 100 200 400 800 1600 3200 6400 12800 Inf
Sample Limit (SL)
Reachability (%)
</figure>
<page confidence="0.985621">
228
</page>
<bodyText confidence="0.978783363636364">
S: je voterai en faveur du projet de r`eglement .
O: i will vote to approve the draft regulation.
i shall be voting in favour of the draft regulation.
O: ... il npeut y avoir de d´elai transitoire en mati`ere de respect des r`egles d´emocratiques .
... there can be no transitional period for complying with democratic rules .
... there can be no transitional period in the field of democratic rules .
O: je souhaite aux n´egociateurs la poursuite du succ`es de leur travail dans ce domaine important.
i wish the negotiators continued success with their work in this important area.
i wish the negotiators the continuation of the success of their work on this important area .
O: mais commencons par les points positifs .
but let us begin with the good news .
but let us begin with the positive points .
R: ... partage la plupart des conclusions que tire le rapporteur .
O: ... share the majority of conclusions that he draws.
... share most of the conclusions that is the rapporteur .
Table 4: Example translations which could be generated with tol = 50 but not with tol = 20. For each
translation the source (S), reference (R) and the unconstrained output (O) are shown. Bold phrases mark
translation options which were not available under tol = 20.
phologically simpler and more complex language
respectively. The test and training sets for these
languages are similarly sized and are from the
WMT08 shared task.
</bodyText>
<subsectionHeader confidence="0.949581">
5.5.1 Quantitative Results
</subsectionHeader>
<bodyText confidence="0.99985268">
Table 5 shows the mutual reachability perfor-
mance for our phrase-based and hierarchical sys-
tem. The hierarchical system can generate almost
all of the 1-best phrase-based translations, partic-
ularly when unaligned words at rule edges are dis-
allowed which is the most equal condition we ex-
perimented with. The phrase-based reachability
for English-German using tight rulesets is remark-
ably low. We found that this is because the hi-
erarchical model allows unaligned words around
gaps under the tight constraint. This makes it very
hard for the phrase-based system to reach the hi-
erarchical translation. However, the phrase-based
system can overcome this problem when the tight-
ness constraint is loosened (last row in Table 5).
Table 6 shows the translation performance mea-
sured in BLEU for both systems for normal un-
constrained translation. It can be seen that the dif-
ference is rather marginal which is in line with our
reachability results.
We were interested why certain translations of
one system were not reachable by the other sys-
tem. The following two subsections describe
our analysis of these translations for the French-
English language pair.
</bodyText>
<table confidence="0.9996364">
Translation Direction fr-en de-en en-de
Ht —* Pt 99.40 97.65 98.50
Ht Pnt 95.95 93.95 94.30
Pt Ht 93.75 92.30 82.95
Pnt Ht 97.55 97.55 96.30
</table>
<tableCaption confidence="0.896042">
Table 5: Mutual reachability performance for
</tableCaption>
<bodyText confidence="0.968918166666667">
French-English (fr-en), German-English (de-en)
and Enlgish-German (en-de). P —* H denotes how
many hierarchical (H) high scoring outputs can be
reached by the phrase-based (P) system. The sub-
scripts nt (non-tight) and t (tight) denote the use
of rules with unaligned words or not.
</bodyText>
<subsectionHeader confidence="0.994819">
5.5.2 Qualitative Analysis of Unreachable
Hierarchical Translations
</subsectionHeader>
<bodyText confidence="0.999662">
We analysed the first twenty translations within
the set of unreachable hierarchical translations
when disallowing unaligned words at rule edges to
find out why the phrase-based system fails to reach
them. Two aspects were considered in this anal-
ysis: First, the successful hierarchical derivation
and second, the relevant part of the phrase-based
ruleset which was involved in the failed forced
translation i.e. how much of the input and the ref-
erence could be covered by the raw phrase-pairs
available to the phrase-based system.
Within the examined subset, the majority of
sentences (14) involved hierarchical rules which
could not be replicated by the phrase-based sys-
</bodyText>
<page confidence="0.995922">
229
</page>
<table confidence="0.9994308">
System fr-en de-en en-de
Phrase-based 31.96 26.94 19.96
Hierarchical 31.62 27.18 20.20
Difference absolute 0.34 0.24 0.24
Difference (%) 1.06 0.90 1.20
</table>
<tableCaption confidence="0.830906">
Table 6: Performance for phrase-based and hier-
archical systems in BLEU for French-English (fr-
</tableCaption>
<bodyText confidence="0.982565658536585">
en), German-English (de-en) and English-German
(en-de).
tem. We described this as the first structural dif-
ference in §4. Almost all of these translations
(12 out of 14) could not be generated because
of the third structural difference which involved
rule that omits the translation of a word within
the French span. An example is the rule X —*
estX1 ordinaireX2 /isX1 X2 which omits a trans-
lation for the French word ordinaire in the English
span. For this particular subset the capability of
the hierarchical system to capture long-distance
reorderings did not make the difference, but rather
the ability to drop words within a translation rule.
The phrase-based system cannot learn many
rules which omit the translation of words because
we disallowed unaligned words at phrase edges.
The hierarchical system has the same restriction,
but the constraint does not prohibit rules which
have unaligned words within the rule. This allows
the hierarchical system to learn rules such as the
one presented above. The phrase-based system
can learn similar knowledge, although less gen-
eral, if it is allowed to have unaligned words at
the phrase edges. In fact, without this constraint
13 out of the 20 analysed rules can be generated
by the phrase-based system.
Figure 5 shows a seemingly simple hierarchi-
cal translation which fails to be constructed by the
phrase-based system: The second rule application
involves both the reordering of the translation of
postaux and the omittance of a translation for con-
currence. This translation could be easily captured
by a phrase-pair, however, it requires that the train-
ing data contains exactly such an example which
was not the case. The closest rule the phrase-based
rulestore contains is des services postaux / postal
services which fails since it does not cover all of
the input. This is an example for when the gen-
eralisation of the hierarchical model is superior to
the phrase-based approach.
</bodyText>
<subsectionHeader confidence="0.671956">
5.5.3 Qualitative Analysis of Unreachable
Phrase-based Translations
</subsectionHeader>
<bodyText confidence="0.999988485714286">
The size of the set of unreachable phrase-based
translations is only 0.6% or 12 sentences. This
means that almost all of the 1-best outputs of the
phrase-based translations can be reached by the hi-
erarchical system. Similarly to above, we analysed
which words of the input as well as which words
of the phrase-based translation can be covered by
the available hierarchical translation rules.
We found that all of the translations were not
generable because of the second structural differ-
ence we identified in §4. The hierarchical rule-
set did not contain a rule with the necessary lex-
ical evidence to perform the same reordering as
the phrase-based model. Figure 6 shows a phrase-
based translation which could not be reached by
the hierarchical system because a rule of the form
X —* ´electoralesX1 /X1 electoral would be re-
quired to move the translation of ´electorales (elec-
toral) just before the translation of r´eunions (meet-
ings). Inspection of the hierarchical ruleset reveals
that such a rule is not available and so the transla-
tion cannot be generated.
The small size of the set of unreachable phrase-
based translations shows that the lexically in-
formed reordering mechanism of the hierarchical
model is not a large obstacle in generating most of
the phrase-based outputs.
In summary, each system can reproduce nearly
all of the highest-scoring outputs of the other sys-
tem. This shows that the 1-best regions of both
systems are nearly identical despite the differ-
ences discussed in §4. This means that differences
in observed system performance are probably at-
tributable to the degree of model error and search
error in each system.
</bodyText>
<sectionHeader confidence="0.999679" genericHeader="method">
6 Related Work and Open Questions
</sectionHeader>
<bodyText confidence="0.999655666666667">
Zhang et al. (2008) and Wellington et al. (2006)
answer the question: what is the minimal gram-
mar that can be induced to completely describe a
training set? We look at the related question of
what a heuristically induced ruleset can translate
in an unseen test set, considering both phrase- and
grammar-based models. We also extend the work
of Zollmann et al. (2008) on Chinese-English, per-
forming the analysis in both directions and provid-
ing a detailed qualitative explanation.
Our focus has been on the induction error of
models, a previously unstudied cause of transla-
</bodyText>
<page confidence="0.985653">
230
</page>
<table confidence="0.995894888888889">
Source: concurrence des services postaux
Reference: competition between postal services
Hierarchical: postal services
Deviation:
( [0-4: @S -&gt; @X&amp;quot;1  |@X&amp;quot;1 ]
( [0-4: @X -&gt; concurrence @X&amp;quot;1 postaux  |postal @X&amp;quot;1 ]
postal
( [1-3: @X -&gt; des services  |services ] services
) ) )
</table>
<figureCaption confidence="0.833216666666667">
Figure 5: Derivation of a hierarchical translation which cannot be generated by the phrase-based system,
in the format of Zollmann et al. (2008). The parse tree contains the outputs (shaded) at its leaves in infix
order and each non-leaf node denotes a rule, in the form: [ Source-span: LHS —*RHS ].
</figureCaption>
<bodyText confidence="0.629581166666667">
Source: ceux qui me disaient cela faisaient par exemple r`ef`erence a` certaines des
r´eunions ´electorales auxquelles ils avaient assist´e .
Phrase-based: those who said to me that were for example refer to some of which
they had been electoral meetings .
Reference: they referred to some of the election meetings , for example , that
they had gone to .
</bodyText>
<figureCaption confidence="0.845976">
Figure 6: Phrase-based translation which cannot be reached by the hierarchical system because no rule to
perform the necessary reordering is available. Marked sections are source and reference spans involved
in the largest possible partial hierarchical derivation.
</figureCaption>
<bodyText confidence="0.999914444444444">
tion errors. Although the results described here
are striking, our exact match criterion for reach-
ability is surely too strict—for example, we re-
port an error if even a single comma is missing.
One solution is to use a more tolerant criterion
such as WER and measure the amount of devia-
tion from the reference. We could also maximize
BLEU with respect to the reference as in Dreyer et
al. (2007), but it is less interpretable.
</bodyText>
<sectionHeader confidence="0.98789" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999979194444444">
Sparse distributions are common in natural lan-
guage processing, and machine translation is no
exception. We showed that utilizing more of the
entire distribution can dramatically improve the
coverage of translation models, and possibly their
accuracy. Accounting for sparsity explicitly has
achieved significant improvements in other areas
such as in part of speech tagging (Goldwater and
Griffiths, 2007). Considering the entire tail is chal-
lenging, since the search space grows exponen-
tially with the number of translation options. A
first step might be to use features that facilitate
more variety in the top 20 translation options. A
more elaborate aim is to look into alternatives to
maximum likelihood hood estimation such as in
Blunsom and Osborne (2008).
Additionally, our expressiveness analysis shows
clearly that the 1-best region of hierarchical and
phrase-based models is nearly identical. Dis-
counting cases in which systems handle unaligned
words differently, we observe an overlap of be-
tween 96% and 99% across three language pairs.
This implies that the main difference between the
models is in their parameterization, rather than in
the structural differences in the types of transla-
tions they can produce. Our results also suggest
that the search spaces of both models are highly
overlapping: The results for the 1-best region al-
low the conjecture that also other parts of the
search space are behaving similarly since it ap-
pears rather unlikely that spaces are nearly disjoint
with only the 1-best region being nearly identical.
In future work we aim to use n-best lists or lattices
to more precisely measure search space overlap.
We also aim to analyse the effects of the model
and search errors for these systems.
</bodyText>
<sectionHeader confidence="0.997514" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999918">
This research was supported by the Euromatrix
Project funded by the European Commission (6th
Framework Programme). The experiments were
conducted using the resources provided by the
Edinburgh Compute and Data Facility (ECDF).
Many thanks to the three anonymous reviewers for
very helpful comments on earlier drafts.
</bodyText>
<page confidence="0.996074">
231
</page>
<sectionHeader confidence="0.995813" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999958106060606">
N. F. Ayan and B. Dorr. 2006. Going beyond AER:
An extensive analysis of word alignments and their
impact on MT. In Proc. ofACL-COLING, pages 9–
16, Jul.
P. Blunsom and M. Osborne. 2008. Probabilistic infer-
ence for machine translation. In Proc. ofEMNLP.
D. Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
M. Dreyer, K. B. Hall, and S. P. Khudanpur. 2007.
Comparing reordering constraints for SMT using ef-
ficient BLEU oracle computation. In Proc. of Work-
shop on Syntax and Structure in Statistical Transla-
tion, pages 103–110, Apr.
U. Germann, M. Jahr, K. Knight, D. Marcu, and K. Ya-
mada. 2004. Fast and optimal decoding for machine
translation. Artificial Intelligence, 154(1–2):127–
143, Apr.
S. Goldwater and T. Griffiths. 2007. A fully Bayesian
approach to unsupervised part-of-speech tagging. In
Proc. of ACL, pages 744–751, Prague, Czech Re-
public, June.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of HLT-NAACL,
pages 48–54, Morristown, NJ, USA.
P. Koehn, H. Hoang, A. B. Mayne, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proc. of ACL
Demonstration Session, pages 177–180, Jun.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT Summit.
A. Lopez. 2008a. Statistical machine translation.
ACM Computing Surveys, 40(3).
A. Lopez. 2008b. Tera-scale translation models via
pattern matching. In Proc. of COLING, pages 505–
512, Aug.
A. Lopez. 2009. Translation as weighted deduction.
In Proc. of EACL.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
F. J. Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. of ACL, pages
160–167, Morristown, NJ, USA.
K. Papineni, S. Roukos, T. Ward, and W. jing Zhu.
2002. BLEU: A method for automatic evaluation
of machine translation. In Proc. ofACL, pages 311–
318.
L. Schwartz. 2008. Multi-source translation methods.
In Proc. ofAMTA, October.
A. Stolcke. 2002. SRILM – an extensible language
modeling toolkit. In Proc. Int. Conf. Spoken Lan-
guage Processing (ICSLP 2002).
B. Wellington, S. Waxmonsky, and I. D. Melamed.
2006. Empirical lower bounds on the complexity
of translational equivalence. In Proc. ofACL, pages
977–984, Morristown, NJ, USA.
H. Zhang, D. Gildea, and D. Chiang. 2008. Extracting
synchronous grammar rules from word-level align-
ments in linear time. In Proc. of COLING, pages
1081–1088, Manchester, UK.
A. Zollmann, A. Venugopal, F. Och, and J. Ponte.
2008. A systematic comparison of phrase-based, hi-
erarchical and syntax-augmented statistical MT. In
Proc. of COLING.
</reference>
<page confidence="0.99518">
232
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.191835">
<title confidence="0.999303">A Systematic Analysis of Translation Model Search Spaces</title>
<author confidence="0.973053">Adam Lopez Auli</author>
<author confidence="0.973053">Hieu Hoang</author>
<affiliation confidence="0.99204">University of</affiliation>
<address confidence="0.7115225">10 Crichton Edinburgh, EH8</address>
<note confidence="0.691121">United</note>
<email confidence="0.844369">m.auli@sms.ed.ac.uk,alopez@inf.ed.ac.uk,h.hoang@sms.ed.ac.uk,pkoehn@inf.ed.ac.uk</email>
<abstract confidence="0.993058857142857">Translation systems are complex, and most metrics do little to pinpoint causes of error or isolate system differences. We use a simple technique to discover induction errors, which occur when good translations are absent from model search spaces. Our results show that a common pruning heuristic drastically increases induction error, and also strongly suggest that the search spaces of phrase-based and hierarchical phrase-based models are highly overlapping despite the well known structural differences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N F Ayan</author>
<author>B Dorr</author>
</authors>
<title>Going beyond AER: An extensive analysis of word alignments and their impact on MT.</title>
<date>2006</date>
<booktitle>In Proc. ofACL-COLING,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="12491" citStr="Ayan and Dorr (2006)" startWordPosition="1979" endWordPosition="1982">ting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl). straint. Ayan and Dorr (2006) showed that under certain conditions, this constraint could have significant impact on system performance. The maximum phrase lengths for both the hierarchical and phrase-based system were set to 7. The distortion limit (dl) for the phrase-based system was set to 6 unless otherwise mentioned. All other settings were left at their default values as described by Chiang (2007) and Koehn et al. (2007). 5.3 Metric: Reference Reachability We measure system performance in terms of reference reachability, which is the inverse of induction error: A system is required to be able to exactly reproduce th</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>N. F. Ayan and B. Dorr. 2006. Going beyond AER: An extensive analysis of word alignments and their impact on MT. In Proc. ofACL-COLING, pages 9– 16, Jul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>M Osborne</author>
</authors>
<title>Probabilistic inference for machine translation. In</title>
<date>2008</date>
<booktitle>Proc. ofEMNLP.</booktitle>
<contexts>
<context position="29873" citStr="Blunsom and Osborne (2008)" startWordPosition="4862" endWordPosition="4865">of the entire distribution can dramatically improve the coverage of translation models, and possibly their accuracy. Accounting for sparsity explicitly has achieved significant improvements in other areas such as in part of speech tagging (Goldwater and Griffiths, 2007). Considering the entire tail is challenging, since the search space grows exponentially with the number of translation options. A first step might be to use features that facilitate more variety in the top 20 translation options. A more elaborate aim is to look into alternatives to maximum likelihood hood estimation such as in Blunsom and Osborne (2008). Additionally, our expressiveness analysis shows clearly that the 1-best region of hierarchical and phrase-based models is nearly identical. Discounting cases in which systems handle unaligned words differently, we observe an overlap of between 96% and 99% across three language pairs. This implies that the main difference between the models is in their parameterization, rather than in the structural differences in the types of translations they can produce. Our results also suggest that the search spaces of both models are highly overlapping: The results for the 1-best region allow the conjec</context>
</contexts>
<marker>Blunsom, Osborne, 2008</marker>
<rawString>P. Blunsom and M. Osborne. 2008. Probabilistic inference for machine translation. In Proc. ofEMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="11033" citStr="Chiang, 2007" startWordPosition="1752" endWordPosition="1753">e hypothesis or chart entries. This leaves only some search restrictions such as the distortion limit for the phrase-based system for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system. 5.1 Experimental Systems Our phrase-based system is Moses (Koehn et al., 2007). We set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol. Forced translation was implemented by Schwartz (2008) who ensures that hypothesis are a prefix of the reference to be generated. Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-Engli</context>
<context position="12868" citStr="Chiang (2007)" startWordPosition="2041" endWordPosition="2042">is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl). straint. Ayan and Dorr (2006) showed that under certain conditions, this constraint could have significant impact on system performance. The maximum phrase lengths for both the hierarchical and phrase-based system were set to 7. The distortion limit (dl) for the phrase-based system was set to 6 unless otherwise mentioned. All other settings were left at their default values as described by Chiang (2007) and Koehn et al. (2007). 5.3 Metric: Reference Reachability We measure system performance in terms of reference reachability, which is the inverse of induction error: A system is required to be able to exactly reproduce the reference, otherwise we regard the result as an error. 5.4 Analysis of Ruleset Pruning In §3 we outlined the hypothesis that increasing the number of English translation options per French span can increase performance. Here we present results for both phrase-based and hierarchical systems to support this claim. 5.4.1 Quantitative Results Figure 2 shows the experimental re</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
<author>K B Hall</author>
<author>S P Khudanpur</author>
</authors>
<title>Comparing reordering constraints for SMT using efficient BLEU oracle computation.</title>
<date>2007</date>
<booktitle>In Proc. of Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>103--110</pages>
<contexts>
<context position="29051" citStr="Dreyer et al. (2007)" startWordPosition="4735" endWordPosition="4738"> cannot be reached by the hierarchical system because no rule to perform the necessary reordering is available. Marked sections are source and reference spans involved in the largest possible partial hierarchical derivation. tion errors. Although the results described here are striking, our exact match criterion for reachability is surely too strict—for example, we report an error if even a single comma is missing. One solution is to use a more tolerant criterion such as WER and measure the amount of deviation from the reference. We could also maximize BLEU with respect to the reference as in Dreyer et al. (2007), but it is less interpretable. 7 Conclusion and Future Work Sparse distributions are common in natural language processing, and machine translation is no exception. We showed that utilizing more of the entire distribution can dramatically improve the coverage of translation models, and possibly their accuracy. Accounting for sparsity explicitly has achieved significant improvements in other areas such as in part of speech tagging (Goldwater and Griffiths, 2007). Considering the entire tail is challenging, since the search space grows exponentially with the number of translation options. A fir</context>
</contexts>
<marker>Dreyer, Hall, Khudanpur, 2007</marker>
<rawString>M. Dreyer, K. B. Hall, and S. P. Khudanpur. 2007. Comparing reordering constraints for SMT using efficient BLEU oracle computation. In Proc. of Workshop on Syntax and Structure in Statistical Translation, pages 103–110, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Germann</author>
<author>M Jahr</author>
<author>K Knight</author>
<author>D Marcu</author>
<author>K Yamada</author>
</authors>
<title>Fast and optimal decoding for machine translation.</title>
<date>2004</date>
<journal>Artificial Intelligence,</journal>
<volume>154</volume>
<issue>1</issue>
<pages>143</pages>
<contexts>
<context position="4447" citStr="Germann et al. (2004)" startWordPosition="689" endWordPosition="692">c�2009 Association for Computational Linguistics 224 quence of rule applications. In our phrase-based model, it typically includes phrase translation probabilities, lexical translation probabilities, language model probabilities, word counts, and coefficients on the linear combination of these. The combination of large rulesets and complex parameterizations typically makes search intractable, requiring the use of approximate search. It is important to note that, regardless of the parameterization or search used, the set of all possible output sentences is still a function of only the ruleset. Germann et al. (2004) identify two types of translation system error: model error and search error.1 Model error occurs when the optimal path through the search space leads to an incorrect translation. Search error occurs when the approximate search technique causes the decoder to select a translation other than the optimum. Given the decomposition outlined above, it seems clear that model error depends on parameterization, while search error depends on approximate search. However, there is no error type that clearly depends on the ruleset (Table 1). We therefore identify a new type of error on the ruleset: induct</context>
</contexts>
<marker>Germann, Jahr, Knight, Marcu, Yamada, 2004</marker>
<rawString>U. Germann, M. Jahr, K. Knight, D. Marcu, and K. Yamada. 2004. Fast and optimal decoding for machine translation. Artificial Intelligence, 154(1–2):127– 143, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>T Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>744--751</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="29517" citStr="Goldwater and Griffiths, 2007" startWordPosition="4803" endWordPosition="4806">t criterion such as WER and measure the amount of deviation from the reference. We could also maximize BLEU with respect to the reference as in Dreyer et al. (2007), but it is less interpretable. 7 Conclusion and Future Work Sparse distributions are common in natural language processing, and machine translation is no exception. We showed that utilizing more of the entire distribution can dramatically improve the coverage of translation models, and possibly their accuracy. Accounting for sparsity explicitly has achieved significant improvements in other areas such as in part of speech tagging (Goldwater and Griffiths, 2007). Considering the entire tail is challenging, since the search space grows exponentially with the number of translation options. A first step might be to use features that facilitate more variety in the top 20 translation options. A more elaborate aim is to look into alternatives to maximum likelihood hood estimation such as in Blunsom and Osborne (2008). Additionally, our expressiveness analysis shows clearly that the 1-best region of hierarchical and phrase-based models is nearly identical. Discounting cases in which systems handle unaligned words differently, we observe an overlap of betwee</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>S. Goldwater and T. Griffiths. 2007. A fully Bayesian approach to unsupervised part-of-speech tagging. In Proc. of ACL, pages 744–751, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. of HLT-NAACL,</booktitle>
<pages>48--54</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="11812" citStr="Koehn et al., 2003" startWordPosition="1873" endWordPosition="1876">ing the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the t</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proc. of HLT-NAACL, pages 48–54, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A B Mayne</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL Demonstration Session,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="10751" citStr="Koehn et al., 2007" startWordPosition="1705" endWordPosition="1708">, removing the influence of the parametrization and heuristics as much as possible for each system as follows: First, we disabled beam search to avoid pruning based on parametrization weights. Second, we require our decoders to generate the reference via disallowing reference-incompatible hypothesis or chart entries. This leaves only some search restrictions such as the distortion limit for the phrase-based system for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system. 5.1 Experimental Systems Our phrase-based system is Moses (Koehn et al., 2007). We set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol. Forced translation was implemented by Schwartz (2008) who ensures that hypothesis are a prefix of the reference to be generated. Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was imple</context>
<context position="12892" citStr="Koehn et al. (2007)" startWordPosition="2044" endWordPosition="2047">tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl). straint. Ayan and Dorr (2006) showed that under certain conditions, this constraint could have significant impact on system performance. The maximum phrase lengths for both the hierarchical and phrase-based system were set to 7. The distortion limit (dl) for the phrase-based system was set to 6 unless otherwise mentioned. All other settings were left at their default values as described by Chiang (2007) and Koehn et al. (2007). 5.3 Metric: Reference Reachability We measure system performance in terms of reference reachability, which is the inverse of induction error: A system is required to be able to exactly reproduce the reference, otherwise we regard the result as an error. 5.4 Analysis of Ruleset Pruning In §3 we outlined the hypothesis that increasing the number of English translation options per French span can increase performance. Here we present results for both phrase-based and hierarchical systems to support this claim. 5.4.1 Quantitative Results Figure 2 shows the experimental results when forcing our p</context>
</contexts>
<marker>Koehn, Hoang, Mayne, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. B. Mayne, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. of ACL Demonstration Session, pages 177–180, Jun.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="11658" citStr="Koehn, 2005" startWordPosition="1850" endWordPosition="1851"> construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Computing Surveys,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="2628" citStr="Lopez, 2008" startWordPosition="405" endWordPosition="406">typically discarded by heuristic pruning nearly triples the number of reference sentences that can be exactly reconstructed by either model (§3). • Second, we find that the high-probability regions in the search spaces of phrase-based and hierarchical systems are nearly identical (§4). This means that reported differences between the models are due to their rankings of competing hypotheses, rather than structural differences of the derivations they produce. 2 Models, Search Spaces, and Errors A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization (Lopez, 2008a; 2009). A ruleset licenses the steps by which a source string f1...fI may be rewritten as a target string e1...eJ. A parameterization defines a weight function over every sequence of rule applications. In a phrase-based model, the ruleset is simply the unweighted phrase table, where each phrase pair fi...fi,/ej...ej, states that phrase fi...fi, in the source can be rewritten as ej...ej, in the target. The model operates by iteratively applying rewrites to the source sentence until each source word has been consumed by exactly one rule. There are two additional heuristic rules: The distortion</context>
<context position="8934" citStr="Lopez (2008" startWordPosition="1432" endWordPosition="1433"> 100.0 100 98.3 100.0 200 99.2 100.0 400 99.7 100.0 800 99.9 100.0 All 100.0 100.0 Table 2: Ruleset size expressed as percentage of available rules when varying the limit of translation options tol per English span and percentage of French spans with up to tol translations. port this hypothesis experimentally in §5.4. 4 How Similar are Model Search Spaces? Most work on hierarchical phrase-based translation focuses quite intently on its structural differences from phrase-based translation. • A hierarchical model can translate discontiguous groups of words as a unit. A phrasebased model cannot. Lopez (2008b) gives indirect experimental evidence that this difference affects performance. • A standard phrase-based model can reorder phrases arbitrarily within the distortion limit, while the hierarchical model requires some lexical evidence for movement, resorting to monotone translation otherwise. • While both models can indirectly model word deletion in the context of phrases, the hierarchical model can delete words using non-local context due to its use of discontiguous phrases. The underlying assumption in most discussions of these models is that these differences in their generative stories are</context>
<context position="11159" citStr="Lopez (2008" startWordPosition="1773" endWordPosition="1774">m for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system. 5.1 Experimental Systems Our phrase-based system is Moses (Koehn et al., 2007). We set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol. Forced translation was implemented by Schwartz (2008) who ensures that hypothesis are a prefix of the reference to be generated. Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>A. Lopez. 2008a. Statistical machine translation. ACM Computing Surveys, 40(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Tera-scale translation models via pattern matching.</title>
<date>2008</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>505--512</pages>
<contexts>
<context position="2628" citStr="Lopez, 2008" startWordPosition="405" endWordPosition="406">typically discarded by heuristic pruning nearly triples the number of reference sentences that can be exactly reconstructed by either model (§3). • Second, we find that the high-probability regions in the search spaces of phrase-based and hierarchical systems are nearly identical (§4). This means that reported differences between the models are due to their rankings of competing hypotheses, rather than structural differences of the derivations they produce. 2 Models, Search Spaces, and Errors A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization (Lopez, 2008a; 2009). A ruleset licenses the steps by which a source string f1...fI may be rewritten as a target string e1...eJ. A parameterization defines a weight function over every sequence of rule applications. In a phrase-based model, the ruleset is simply the unweighted phrase table, where each phrase pair fi...fi,/ej...ej, states that phrase fi...fi, in the source can be rewritten as ej...ej, in the target. The model operates by iteratively applying rewrites to the source sentence until each source word has been consumed by exactly one rule. There are two additional heuristic rules: The distortion</context>
<context position="8934" citStr="Lopez (2008" startWordPosition="1432" endWordPosition="1433"> 100.0 100 98.3 100.0 200 99.2 100.0 400 99.7 100.0 800 99.9 100.0 All 100.0 100.0 Table 2: Ruleset size expressed as percentage of available rules when varying the limit of translation options tol per English span and percentage of French spans with up to tol translations. port this hypothesis experimentally in §5.4. 4 How Similar are Model Search Spaces? Most work on hierarchical phrase-based translation focuses quite intently on its structural differences from phrase-based translation. • A hierarchical model can translate discontiguous groups of words as a unit. A phrasebased model cannot. Lopez (2008b) gives indirect experimental evidence that this difference affects performance. • A standard phrase-based model can reorder phrases arbitrarily within the distortion limit, while the hierarchical model requires some lexical evidence for movement, resorting to monotone translation otherwise. • While both models can indirectly model word deletion in the context of phrases, the hierarchical model can delete words using non-local context due to its use of discontiguous phrases. The underlying assumption in most discussions of these models is that these differences in their generative stories are</context>
<context position="11159" citStr="Lopez (2008" startWordPosition="1773" endWordPosition="1774">m for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system. 5.1 Experimental Systems Our phrase-based system is Moses (Koehn et al., 2007). We set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol. Forced translation was implemented by Schwartz (2008) who ensures that hypothesis are a prefix of the reference to be generated. Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>A. Lopez. 2008b. Tera-scale translation models via pattern matching. In Proc. of COLING, pages 505– 512, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Translation as weighted deduction.</title>
<date>2009</date>
<booktitle>In Proc. of EACL.</booktitle>
<marker>Lopez, 2009</marker>
<rawString>A. Lopez. 2009. Translation as weighted deduction. In Proc. of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11737" citStr="Och and Ney, 2003" startWordPosition="1862" endWordPosition="1865"> in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>160--167</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="12083" citStr="Och, 2003" startWordPosition="1915" endWordPosition="1916">nts in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl). straint. Ayan and Dorr (2006) showed that under certain conditions, this constraint could have significant impact on system performance. The maximum phrase lengths for both the hierarchical and phrase-based system were se</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of ACL, pages 160–167, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W jing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ofACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="904" citStr="Papineni et al., 2002" startWordPosition="125" endWordPosition="128">Translation systems are complex, and most metrics do little to pinpoint causes of error or isolate system differences. We use a simple technique to discover induction errors, which occur when good translations are absent from model search spaces. Our results show that a common pruning heuristic drastically increases induction error, and also strongly suggest that the search spaces of phrase-based and hierarchical phrase-based models are highly overlapping despite the well known structural differences. 1 Introduction Most empirical work in translation analyzes models and algorithms using BLEU (Papineni et al., 2002) and related metrics. Though such metrics are useful as sanity checks in iterative system development, they are less useful as analytical tools. The performance of a translation system depends on the complex interaction of several different components. Since metrics assess only output, they fail to inform us about the consequences of these interactions, and thus provide no insight into the errors made by a system, or into the design tradeoffs of competing systems. In this work, we show that it is possible to obtain such insights by analyzing translation system components in isolation. We focus</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. jing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proc. ofACL, pages 311– 318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Schwartz</author>
</authors>
<title>Multi-source translation methods.</title>
<date>2008</date>
<booktitle>In Proc. ofAMTA,</booktitle>
<contexts>
<context position="10910" citStr="Schwartz (2008)" startWordPosition="1732" endWordPosition="1733">d on parametrization weights. Second, we require our decoders to generate the reference via disallowing reference-incompatible hypothesis or chart entries. This leaves only some search restrictions such as the distortion limit for the phrase-based system for which we controlled, or the maximum number of source words involved in a rule application for the hierarchical system. 5.1 Experimental Systems Our phrase-based system is Moses (Koehn et al., 2007). We set its stack size to 105, disabled the beam threshold, and varied the translation option limit tol. Forced translation was implemented by Schwartz (2008) who ensures that hypothesis are a prefix of the reference to be generated. Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b). The search parameters restricting the number of rules or chart entries as well as the minimum threshold were set to very high values (1050) to prevent pruning. Forced translation was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, at</context>
</contexts>
<marker>Schwartz, 2008</marker>
<rawString>L. Schwartz. 2008. Multi-source translation methods. In Proc. ofAMTA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. Int. Conf. Spoken Language Processing (ICSLP</booktitle>
<contexts>
<context position="11951" citStr="Stolcke, 2002" startWordPosition="1896" endWordPosition="1897">tion was implemented by discarding rules and chart entries which do not match the reference. 5.2 Experimental Data We conducted experiments in French-English translation, attempting to make the experimental conditions for both systems as equal as possible. Each system was trained on French-English Europarl (Koehn, 2005), version 3 (40M words). The corpus was aligned with GIZA++ (Och and Ney, 2003) and symmetrized with the grow-diag-finaland heuristic (Koehn et al., 2003). A trigram language model with modified Kneser-Ney discounting and interpolation was used as produced by the SRILM toolkit (Stolcke, 2002). Systems were optimized on the WMT08 French-English development data (2000 sentences) using minimum error rate training (Och, 2003) and tested on the WMT08 test data (2000 sentences). Rules based on unaligned words at the edges of foreign and source spans were not allowed unless otherwise stated, this is denoted as the tightness con226 Translation Option Limit Figure 2: Coverage for phrase-based reference aligned translation on test data when varying the translation option and the distortion limits (dl). straint. Ayan and Dorr (2006) showed that under certain conditions, this constraint could</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proc. Int. Conf. Spoken Language Processing (ICSLP 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wellington</author>
<author>S Waxmonsky</author>
<author>I D Melamed</author>
</authors>
<title>Empirical lower bounds on the complexity of translational equivalence.</title>
<date>2006</date>
<booktitle>In Proc. ofACL,</booktitle>
<pages>977--984</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="26937" citStr="Wellington et al. (2006)" startWordPosition="4385" endWordPosition="4388">le phrasebased translations shows that the lexically informed reordering mechanism of the hierarchical model is not a large obstacle in generating most of the phrase-based outputs. In summary, each system can reproduce nearly all of the highest-scoring outputs of the other system. This shows that the 1-best regions of both systems are nearly identical despite the differences discussed in §4. This means that differences in observed system performance are probably attributable to the degree of model error and search error in each system. 6 Related Work and Open Questions Zhang et al. (2008) and Wellington et al. (2006) answer the question: what is the minimal grammar that can be induced to completely describe a training set? We look at the related question of what a heuristically induced ruleset can translate in an unseen test set, considering both phrase- and grammar-based models. We also extend the work of Zollmann et al. (2008) on Chinese-English, performing the analysis in both directions and providing a detailed qualitative explanation. Our focus has been on the induction error of models, a previously unstudied cause of transla230 Source: concurrence des services postaux Reference: competition between </context>
</contexts>
<marker>Wellington, Waxmonsky, Melamed, 2006</marker>
<rawString>B. Wellington, S. Waxmonsky, and I. D. Melamed. 2006. Empirical lower bounds on the complexity of translational equivalence. In Proc. ofACL, pages 977–984, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>D Gildea</author>
<author>D Chiang</author>
</authors>
<title>Extracting synchronous grammar rules from word-level alignments in linear time.</title>
<date>2008</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>1081--1088</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="26908" citStr="Zhang et al. (2008)" startWordPosition="4380" endWordPosition="4383"> of the set of unreachable phrasebased translations shows that the lexically informed reordering mechanism of the hierarchical model is not a large obstacle in generating most of the phrase-based outputs. In summary, each system can reproduce nearly all of the highest-scoring outputs of the other system. This shows that the 1-best regions of both systems are nearly identical despite the differences discussed in §4. This means that differences in observed system performance are probably attributable to the degree of model error and search error in each system. 6 Related Work and Open Questions Zhang et al. (2008) and Wellington et al. (2006) answer the question: what is the minimal grammar that can be induced to completely describe a training set? We look at the related question of what a heuristically induced ruleset can translate in an unseen test set, considering both phrase- and grammar-based models. We also extend the work of Zollmann et al. (2008) on Chinese-English, performing the analysis in both directions and providing a detailed qualitative explanation. Our focus has been on the induction error of models, a previously unstudied cause of transla230 Source: concurrence des services postaux Re</context>
</contexts>
<marker>Zhang, Gildea, Chiang, 2008</marker>
<rawString>H. Zhang, D. Gildea, and D. Chiang. 2008. Extracting synchronous grammar rules from word-level alignments in linear time. In Proc. of COLING, pages 1081–1088, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zollmann</author>
<author>A Venugopal</author>
<author>F Och</author>
<author>J Ponte</author>
</authors>
<title>A systematic comparison of phrase-based, hierarchical and syntax-augmented statistical MT.</title>
<date>2008</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="9742" citStr="Zollmann et al. (2008)" startWordPosition="1545" endWordPosition="1548">ierarchical model requires some lexical evidence for movement, resorting to monotone translation otherwise. • While both models can indirectly model word deletion in the context of phrases, the hierarchical model can delete words using non-local context due to its use of discontiguous phrases. The underlying assumption in most discussions of these models is that these differences in their generative stories are responsible for differences in performance. We believe that this assumption should be investigated empirically. In an interesting analysis of phrase-based and hierarchical translation, Zollmann et al. (2008) forced a phrase-based system to produce the translations generated by a hierarchical system. Unfortunately, their analysis is incomplete; they do not perform the analysis in both directions. In §5.5 we extend their work by requiring each system to generate the 1-best output of the other. This allows us to see how their search spaces differ. 5 Experiments We analyse rulesets in isolation, removing the influence of the parametrization and heuristics as much as possible for each system as follows: First, we disabled beam search to avoid pruning based on parametrization weights. Second, we requir</context>
<context position="27255" citStr="Zollmann et al. (2008)" startWordPosition="4439" endWordPosition="4442">both systems are nearly identical despite the differences discussed in §4. This means that differences in observed system performance are probably attributable to the degree of model error and search error in each system. 6 Related Work and Open Questions Zhang et al. (2008) and Wellington et al. (2006) answer the question: what is the minimal grammar that can be induced to completely describe a training set? We look at the related question of what a heuristically induced ruleset can translate in an unseen test set, considering both phrase- and grammar-based models. We also extend the work of Zollmann et al. (2008) on Chinese-English, performing the analysis in both directions and providing a detailed qualitative explanation. Our focus has been on the induction error of models, a previously unstudied cause of transla230 Source: concurrence des services postaux Reference: competition between postal services Hierarchical: postal services Deviation: ( [0-4: @S -&gt; @X&amp;quot;1 |@X&amp;quot;1 ] ( [0-4: @X -&gt; concurrence @X&amp;quot;1 postaux |postal @X&amp;quot;1 ] postal ( [1-3: @X -&gt; des services |services ] services ) ) ) Figure 5: Derivation of a hierarchical translation which cannot be generated by the phrase-based system, in the format </context>
</contexts>
<marker>Zollmann, Venugopal, Och, Ponte, 2008</marker>
<rawString>A. Zollmann, A. Venugopal, F. Och, and J. Ponte. 2008. A systematic comparison of phrase-based, hierarchical and syntax-augmented statistical MT. In Proc. of COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>