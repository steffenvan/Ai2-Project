<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.075319">
<title confidence="0.993511">
Generation of Referring Expression with an Individual Imprint
</title>
<author confidence="0.971971">
Bernd Bohnet
</author>
<affiliation confidence="0.948629">
International Computer Science Institute
</affiliation>
<address confidence="0.637828">
1947 Center Street, CA 94704 Berkeley
</address>
<email confidence="0.999197">
bohnet@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.993906" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999931277777778">
A major outcome of the last Shared Tasks
for Referring Expressions Generation was
that each human prefers distinct proper-
ties, syntax and lexical units for building
referring expressions. One of the reasons
for this seems to be that entities might
be identified faster since the conversation
partner has already some knowledge about
how his conversation partner builds refer-
ring expressions. Therefore, artificial re-
ferring expressions should provide such
individual preferences as well so that they
become human like. With this contribu-
tion to the shared task, we follow this idea
again. For the development set, we got a
very good DICE score of 0.88 for the fur-
niture domain and of 0.79 for the people
domain.
</bodyText>
<sectionHeader confidence="0.998037" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966466666667">
We expect that the test set does not provide the
information to which human a referring expres-
sion belongs. Therefore, we implemented a fall
back strategy in order to get still acceptable DICE
scores. In such cases, we select among all sets the
set of referring expressions which is most similar
to all others. We compute the similarity between
two sets as the average DICE score between all re-
ferring expression of two sets. The basis for our
algorithm is an extended full brevity implementa-
tion, cf. (Bohnet and Dale, 2005). IS-FP uses also
the nearest neighbor technique like the IS-FBN al-
gorithm that was introduced by Bohnet (2007).
With the nearest neighbor technique, IS-FP se-
lects the expressions which are most similar to
the referring expressions of the same human and
a human that builds referring expressions similar
or in the case that the human is unknown it uses
the most similar one to all others referring expres-
sions. The similarity is computed as the average of
all DICE scores between all combinations of the
available trails for two humans. From the result
of the nearest neighbor evaluation, FP selects the
shortest and if still more than one expressions re-
main then it computes the similarity among them
and chooses the most typical and finally, if still al-
ternatives remain, it selects one with the attributes
having the highest frequency. Table 1 shows the
results for IS-FP trained on the training set and ap-
plied to the development set.
</bodyText>
<table confidence="0.99473575">
Set Dice MASI Accuracy.
Furniture 0.880 0.691 51.25%
People 0.794 0.558 36.8%
Total 0.837 0.625 44%
</table>
<tableCaption confidence="0.997248">
Table 1: Results for the IS-FP algorithm
</tableCaption>
<sectionHeader confidence="0.9452885" genericHeader="method">
2 IS-GT: Realization with Graph
Transducers
</sectionHeader>
<bodyText confidence="0.999848363636363">
We build the input dependency tree for the text
generator due to the statistical information that we
collect from the training data for each person. This
procedure is consistent with our referring expres-
sion generator IS-FP that reproduces the individ-
ual imprint in a referring expression for the target
person. We start with the realization of the refer-
ring expressions from a surface syntactic depen-
dency tree, cf. (Mel’ˇcuk, 1988). For the realiza-
tion of the text, we use the Text Generator and Lin-
guistic Environment MATE.
</bodyText>
<note confidence="0.482606">
Proceedings of the 12th European Workshop on Natural Language Generation, pages 185–186,
Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.999149">
185
</page>
<sectionHeader confidence="0.989216" genericHeader="method">
3 The Referring Expression Models
</sectionHeader>
<bodyText confidence="0.99473025">
An algorithm learns a Referring Expression Model
for each person that contributed referring expres-
sion to the corpus. The model contains the follow-
ing information:
</bodyText>
<listItem confidence="0.80352875">
(1) The lexicalization for the values of a attribute
such as couch for the value sofa, man for
value person, etc.
(2) The preferred usage of determiners for the
type that can be definite (the), indefinite (a),
no article.
(3) The syntactic preferences such as the top left
chair, the chair at the bottom to the left, etc.
</listItem>
<bodyText confidence="0.9999895">
The information about the determiner and the
lexicalization is collected from the annotated word
string and the word string itself. We collect the
most frequent usage for each person in the corpus.
In order to collect the preferred syntax, we anno-
tated the word strings with syntactic dependency
trees. Each of the dependency tress contains ad-
ditional attributes, which describe the information
content of a branch outgoing from the root as well
as the possible value of the attribute at the nodes
which carry the information. The learning pro-
gram cuts the syntactic tree at edges starting at the
root node and stores the branches in the referring
expression model for the person.
</bodyText>
<sectionHeader confidence="0.9965" genericHeader="method">
4 Realization
</sectionHeader>
<bodyText confidence="0.999897125">
For the realization, we use a handcrafted grammar
that generates out of the dependency trees topo-
logic graphs. The main task of the grammar is to
determine the word order. The system was devel-
oped only by using the training data without any
consideration of the development data. We used
as guide for the optimization cross validation of
training data.
</bodyText>
<sectionHeader confidence="0.814894" genericHeader="method">
5 IS-FP-GT: The Combination of
Attribute Selection and Realization
</sectionHeader>
<bodyText confidence="0.999837">
For the combination of the both methods, we com-
bine the two procedure in a pipeline architecture.
Table 2 shows the results.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99906025">
The IS-FP algorithm reproduces the imprint of hu-
man referring expressions. When the test set con-
tains the reference to the human then the scores are
exceptional high.
</bodyText>
<table confidence="0.976063">
Set Accuracy String ED Mean SED Blue 3
Furniture 15 % 3,8625 0.3826 0.3684
People 4,41 % 4,764 0.4817 0.2263
Total 9,71 4,313 0.4321 0.297
</table>
<tableCaption confidence="0.984587">
Table 2: Results for the TUNA-REG Task
</tableCaption>
<sectionHeader confidence="0.995387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999463545454546">
B. Bohnet and R. Dale. 2005. Viewing referring
expression generation as search. In IJCAI, pages
1004–1009.
B. Bohnet. 2007. IS-FBN, IS-FBS, IS-IAC: The Adap-
tation of Two Classic Algorithms for the Generation
of Referring Expressions in order to Produce Ex-
pressions like Humans Do. In MT Summit XI, UC-
NLG+MT, pages 84–86.
I.A. Mel’ˇcuk. 1988. Dependency Syntax: Theory and
Practice. State University of New York Press, Al-
bany.
</reference>
<page confidence="0.998784">
186
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.873926">
<title confidence="0.988489">Generation of Referring Expression with an Individual Imprint</title>
<author confidence="0.941195">Bernd</author>
<affiliation confidence="0.998625">International Computer Science</affiliation>
<address confidence="0.999877">1947 Center Street, CA 94704</address>
<email confidence="0.999454">bohnet@icsi.berkeley.edu</email>
<abstract confidence="0.996204368421053">A major outcome of the last Shared Tasks for Referring Expressions Generation was that each human prefers distinct properties, syntax and lexical units for building referring expressions. One of the reasons for this seems to be that entities might be identified faster since the conversation partner has already some knowledge about how his conversation partner builds referring expressions. Therefore, artificial referring expressions should provide such individual preferences as well so that they become human like. With this contribution to the shared task, we follow this idea again. For the development set, we got a very good DICE score of 0.88 for the furniture domain and of 0.79 for the people domain.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>R Dale</author>
</authors>
<title>Viewing referring expression generation as search.</title>
<date>2005</date>
<booktitle>In IJCAI,</booktitle>
<pages>1004--1009</pages>
<contexts>
<context position="1440" citStr="Bohnet and Dale, 2005" startWordPosition="227" endWordPosition="230">od DICE score of 0.88 for the furniture domain and of 0.79 for the people domain. 1 Introduction We expect that the test set does not provide the information to which human a referring expression belongs. Therefore, we implemented a fall back strategy in order to get still acceptable DICE scores. In such cases, we select among all sets the set of referring expressions which is most similar to all others. We compute the similarity between two sets as the average DICE score between all referring expression of two sets. The basis for our algorithm is an extended full brevity implementation, cf. (Bohnet and Dale, 2005). IS-FP uses also the nearest neighbor technique like the IS-FBN algorithm that was introduced by Bohnet (2007). With the nearest neighbor technique, IS-FP selects the expressions which are most similar to the referring expressions of the same human and a human that builds referring expressions similar or in the case that the human is unknown it uses the most similar one to all others referring expressions. The similarity is computed as the average of all DICE scores between all combinations of the available trails for two humans. From the result of the nearest neighbor evaluation, FP selects </context>
</contexts>
<marker>Bohnet, Dale, 2005</marker>
<rawString>B. Bohnet and R. Dale. 2005. Viewing referring expression generation as search. In IJCAI, pages 1004–1009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bohnet</author>
</authors>
<title>IS-FBN, IS-FBS, IS-IAC: The Adaptation of Two Classic Algorithms for the Generation of Referring Expressions in order to Produce Expressions like Humans Do.</title>
<date>2007</date>
<booktitle>In MT Summit XI, UCNLG+MT,</booktitle>
<pages>84--86</pages>
<contexts>
<context position="1551" citStr="Bohnet (2007)" startWordPosition="247" endWordPosition="248"> set does not provide the information to which human a referring expression belongs. Therefore, we implemented a fall back strategy in order to get still acceptable DICE scores. In such cases, we select among all sets the set of referring expressions which is most similar to all others. We compute the similarity between two sets as the average DICE score between all referring expression of two sets. The basis for our algorithm is an extended full brevity implementation, cf. (Bohnet and Dale, 2005). IS-FP uses also the nearest neighbor technique like the IS-FBN algorithm that was introduced by Bohnet (2007). With the nearest neighbor technique, IS-FP selects the expressions which are most similar to the referring expressions of the same human and a human that builds referring expressions similar or in the case that the human is unknown it uses the most similar one to all others referring expressions. The similarity is computed as the average of all DICE scores between all combinations of the available trails for two humans. From the result of the nearest neighbor evaluation, FP selects the shortest and if still more than one expressions remain then it computes the similarity among them and choos</context>
</contexts>
<marker>Bohnet, 2007</marker>
<rawString>B. Bohnet. 2007. IS-FBN, IS-FBS, IS-IAC: The Adaptation of Two Classic Algorithms for the Generation of Referring Expressions in order to Produce Expressions like Humans Do. In MT Summit XI, UCNLG+MT, pages 84–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>Albany.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>I.A. Mel’ˇcuk. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, Albany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>