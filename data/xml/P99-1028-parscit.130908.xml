<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.9974185">
Resolving Translation Ambiguity and Target Polysemy
in Cross-Language Information Retrieval
</title>
<author confidence="0.975679">
Hsin-Hsi Chen, Guo-Wei Bian and Wen-Cheng Lin
</author>
<affiliation confidence="0.940551">
Department of Computer Science and Information Engineering
National Taiwan University
Taipei, TAIWAN, R.O.C.
</affiliation>
<email confidence="0.997171">
E-mail: hh_chen@csie.ntu.edu.tw, {gwbian, denislin}@n1g2.csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.997396" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999635916666667">
This paper deals with translation ambiguity and
target polysemy problems together. Two
monolingual balanced corpora are employed to
learn word co-occurrence for translation
ambiguity resolution, and augmented translation
restrictions for• target polysemy resolution.
Experiments show that the model achieves
62.92% of monolingual information retrieval, and
is 40.80% addition to the select-all model.
Combining the target polysemy resolution, the
retrieval performance is about 10.11% increase to
the model resolving translation ambiguity only.
</bodyText>
<sectionHeader confidence="0.998773" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999847233333333">
Cross language information retrieval (CUR)
(Oard and DOIT, 1996; Oard, 1997) deals with the
use of queries in one language to access
documents in another. Due to the differences
between source and target languages, query
translation is usually employed to unify the
language in queries and documents. In query
translation, translation ambiguity is a basic
problem to be resolved. A word in a source
query may have more than one sense. Word
sense disambiguation identifies the correct sense
of each source word, and lexical selection
translates it into the corresponding target word.
The above procedure is similar to lexical choice
operation in a traditional machine translation (MT)
system. However, there is a significant
difference between the applications of MT and
CLIR. In MT, readers interpret the translated
results. If the target word has more than one
sense, readers can disambiguate its meaning
automatically. Comparatively, the translated
result is sent to a monolingual information
retrieval system in CLIR. The target polysemy
adds extraneous senses and affects the retrieval
performance.
Some different approaches have been proposed
for query translation. Dictionary-based approach
exploits machine-readable dictionaries and
selection strategies like select all (Hull and
Grefenstette, 1996; Davis, 1997), randomly select
N (Ballesteros and Croft, 1996; Kwok 1997) and
select best N (Hayashi, Kikui and Susaki, 1997;
Davis 1997). Corpus-based approaches exploit
sentence-aligned corpora (Davis and Dunning,
1996) and document-aligned corpora (Sheridan
and Ballerini, 1996). These two approaches are
complementary. Dictionary provides translation
candidates, and corpus provides context to fit user
intention. Coverage of dictionaries, alignment
performance and domain shift of corpus are major
problems of these two approaches. Hybrid
approaches (Ballesteros and Croft, 1998; Bian and
Chen, 1998; Davis 1997) integrate both lexical
and corpus knowledge.
All the above approaches deal with the
translation ambiguity problem in query translation.
Few touch on translation ambiguity and target
polysemy together. This paper will study the
multiplication effects of translation ambiguity and
target polysemy in cross-language information
retrieval systems, and propose a new translation
method to resolve these problems. Section 2
shows the effects of translation ambiguity and
target polysemy in Chinese-English and English-
Chinese information retrievals. Section 3
presents several models to revolve translation
ambiguity and target polysemy problems.
Section 4 demonstrates the experimental results,
and compares the performances of the proposed
models. Section 5 concludes the remarks.
</bodyText>
<sectionHeader confidence="0.948332" genericHeader="method">
2. Effects of Ambiguities
</sectionHeader>
<bodyText confidence="0.959433857142857">
Translation ambiguity and target polysemy are
two major problems in CDR. Translation
ambiguity results from the source language, and
target polysemy occurs in target language. Take
Chinese-English information retrieval (CEIR) and
English-Chinese information retrieval (ECIR) as
examples. The former uses Chinese queries to
</bodyText>
<page confidence="0.999326">
215
</page>
<tableCaption confidence="0.99916">
Table 1. Statistics of Chinese and English Thesaurus
</tableCaption>
<table confidence="0.514941666666667">
Total Words Average # of Senses Average # of Senses for Top 1000 Words
English Thesaurus 29,380 1.687 3.527
Chinese Thesaurus 53,780 1.397 1.504
</table>
<bodyText confidence="0.970952607142857">
retrieve English documents, while the later
employs English queries to retrieve Chinese
documents. To explore the difficulties in the
query translation of different languages, we gather
the sense statistics of English and Chinese words.
Table 1 shows the degree of word sense ambiguity
(in terms of number of senses) in English and in
Chinese, respectively. A Chinese thesaurus, i.e.,
.4,19 1 W (tong2yi4ci2ci2lin2), (Mei, et al.,
1982) and an English thesaurus, i.e., Roget&apos;s
thesaurus, are used to count the statistics of the
senses of words. On the average, an English
word has 1.687 senses, and a Chinese word has
1.397 senses. If the top 1000 high frequent
words are considered, the English words have
3.527 senses, and the bi-character Chinese words
only have 1.504 senses. In summary, Chinese
word is comparatively unambiguous, so that
translation ambiguity is not serious but target
polysemy is serious in CEIR. In contrast, an
English word is usually ambiguous. The
translation disambiguation is important in ECIR.
Consider an example in CEIR. The Chinese
word &amp;quot;0.4-1-&amp;quot; (yin2hang2) is unambiguous, but its
English translation &amp;quot;bank&amp;quot; has 9 senses (Longman,
1978). When the Chinese word &amp;quot; &amp;quot;
(yin2hang2) is issued, it is translated into the
English counterpart &amp;quot;bank&amp;quot; by dictionary lookup
without difficulty, and then &amp;quot;bank&amp;quot; is sent to an IR
system. The IR system will retrieve documents
that contain this word. Because &amp;quot;bank&amp;quot; is not
disambiguated, irrelevant documents will be
reported. On the contrary, when &amp;quot;bank&amp;quot; is
submitted to an ECIR system, we must
disambiguate its meaning at first. If we can find
that its correct translation is &amp;quot;ig.4-1-&amp;quot; (yin2hang2),
the subsequent operation is very simple. That is,
&amp;quot;4414-5-&amp;quot; (yin2hang2) is sent into an IR system, and
then documents containing &amp;quot;4-1-&amp;quot; (yin2hang2)
will be presented. In this example, translation
disambiguation should be done rather than target
polysemy resolution.
The above examples do not mean translation
disambiguation is not required in CEIR. Some
Chinese words may have more than one sense.
For example, &amp;quot;ittb&amp;quot; (yun4dong4) has the
following meanings (Lai and Lin, 1987): (1) sport,
(2) exercise, (3) movement, (4) motion, (5)
campaign, and (6) lobby. Each corresponding
English word may have more than one sense.
For example, &amp;quot;exercise&amp;quot; may mean a question or
set of questions to be answered by a pupil for
practice; the use of a power or right; and so on.
The multiplication effects of translation ambiguity
and target polysemy make query translation
harder.
</bodyText>
<sectionHeader confidence="0.8193755" genericHeader="method">
3. Translation Ambiguity and Polysemy
Resolution Models
</sectionHeader>
<bodyText confidence="0.99977590625">
In the recent works, Ballesteros and Croft
(1998), and Bian and Chen (1998) employ
dictionaries and co-occurrence statistics trained
from target language documents to deal with
translation ambiguity. We will follow our
previous work (Bian and Chen, 1998), which
combines the dictionary-based and corpus-based
approaches for CEIR. A bilingual dictionary
provides the translation equivalents of each query
term, and the word co-occurrence information
trained from a target language text collection is
used to disambiguate the translation. This
method considers the content around the
translation equivalents to decide the best target
word. The translation of a query term can be
disambiguated using the co-occurrence of the
translation equivalents of this term and other
terms. We adopt mutual information (Church, et
al., 1989) to measure the strength. This
disambiguation method performs good
translations even when the multi-term phrases are
not found in the bilingual dictionary, or the
phrases are not identified in the source language.
Before discussion, we take Chinese-English
information retrieval as an example to explain our
methods. Consider the Chinese query &amp;quot;ip..4-1--&amp;quot;
(yin2hang2) to an English collection again. The
ambiguity grows from none (source side) to 9
senses (target side) during query translation.
How to incorporate the knowledge from source
side to target side is an important issue. To
avoid the problem of target polysemy in query
</bodyText>
<page confidence="0.998118">
216
</page>
<bodyText confidence="0.997550928571428">
translation, we have to restrict the use of a target
word by augmenting some other words that
usually co-occur with it. That is, we have to
make a context for the target word. In our
method, the contextual information is derived
from the source word.
We collect the frequently accompanying nouns
and verbs for each word in a Chinese corpus.
Those words that co-occur with a given word
within a window are selected. The word
association strength of a word and its
accompanying words is measured by mutual
information. For each word C in a Chinese
query, we augment it with a sequence of Chinese
words trained in the above way. Let these words
be CW,, CW2, ..., and CW.. Assume the
corresponding English translations of C, CW1,
CW2, ..., and CW„, are E, EW1, EW2, ..., and EW„„
respectively. EW,, EW2, ..., and EWn, form an
augmented translation restriction of E for C. In
other words, the list (E, EW,, EW2, EW„,) is
called an augmented translation result for C.
EW„ EW2, ..., and EWm are a pseudo English
context produced from Chinese side. Consider
the Chinese word &amp;quot;itt.tt&amp;quot; (yin2hang2). Some
strongly co-related Chinese words in ROCLING
balanced corpus (Huang, et al., 1995) are: &amp;quot;ROC
(tielxian4), &amp;quot;4k &amp;quot; (ling3chul), 4&apos;7&amp;quot; (1i3ang2),
&amp;quot;4&apos; Pt&amp;quot; (yal hui4), 3t,&amp;quot; (hui4dui4), etc. Thus
the augmented translation restriction of &amp;quot;bank&amp;quot; is
(rebate, show out, Lyons, negotiate, transfer, ...).
Unfortunately, the query translation is not so
simple. A word C in a query Q may be
ambiguous. Besides, the accompanying words
CW, (1 i 5_ m) trained from Chinese corpus may
be translated into more than one English word.
An augmented translation restriction may add
erroneous patterns when a word in a restriction
has more than one sense. Thus we devise several
models to discuss the effects of augmented
restrictions. Figure 1 shows the different models
and the model refinement procedure. A Chinese
query may go through translation ambiguity
resolution module (left-to-right), target polysemy
resolution module (top-down), or both (i.e., these
two modules are integrated at the right corner).
In the following, we will show how each module
is operated independently, and how the two
modules are combined.
For a Chinese query which is composed of n
words C„ C2, ..., Cn, find the corresponding
English translation equivalents in a Chinese-
English bilingual dictionary. To discuss the
propagation errors from translation ambiguity
resolution part in the experiments, we consider the
following two alternatives:
</bodyText>
<listItem confidence="0.466521">
(a) select all (do-nothing)
</listItem>
<bodyText confidence="0.981988">
The strategy does nothing on the translation
disambiguation. All the English translation
equivalents for the n Chinese words are selected,
and are submitted to a monolingual information
retrieval system.
(b) co-occurrence model (Co-Model)
We adopt the strategy discussed previously
for translation disambiguation (Bian and Chen,
1998). This method considers the content
around the English translation equivalents to
decide the best target equivalent.
For target polysemy resolution part in Figure 1,
we also consider two alternatives. In the first
alternative (called A model), we augment
restrictions to all the words no matter whether
they are ambiguous or not. In the second
alternative (called U model), we neglect those Cs
that have more than one English translation.
Assume Cam, Co(2), C (p n) have only one
English translation. The restrictions are
augmented to Caw, Cam, ..., Co(p) only. We apply
the above corpus-based method to find the
restriction for each English word selected by the
translation ambiguity resolution model. Recall
that the restrictions are derived from Chinese
corpus. The accompanying words trained from
Chinese corpus may be translated into more than
one English word. Here, the translation
ambiguity may occur when translating the
restrictions. Three alternatives are considered.
In Ul (or Al) model, the terms without ambiguity,
i.e., Chinese and English words are one-to-one
correspondent in a Chinese-English bilingual
dictionary, are added. In UT (or AT) model, the
terms with the same parts of speech (POSes) are
added. That is, POS is used to select English
word. In UTT (or ATT) model, we use mutual
information to select top 10 accompanying terms
of a Chinese query word, and POS is used to
obtain the augmented translation restriction.
</bodyText>
<page confidence="0.979174">
217
</page>
<figure confidence="0.956861142857143">
Select All
(baseline)
English Query
Ei I, En), (E21, Ea), ..., (Eni. , Ent.)
•
•
Chinese Query
</figure>
<table confidence="0.818035107142857">
CI, C2, Cn
Translation Ambiguity Resolution
Co Model •
(Co-occurrence model)
English Query
Ei, E2, ..., En
Target Polysemy Resolution
Translated
English Restriction
{EMI, },
(EW2i, ENV2k,), ,
(EWnt, EWnk.)
Argumented
English Query
Ei, (EWij)
A Model
___•1Chinese Query
CI, C2, ...,Cn
Al Model
(Unique Translation)
Chinese Restriction
• (CW11. CW1.,), AT Model
(POS Tag Matched)
ICW2i, CW2=,),
(CWnt, CWnm.)
An&apos; Model
10 &amp; POS Tag Matche471
(Top
</table>
<figure confidence="0.989836592592593">
U Model
•
AIH
ATH
--0, A
•
UI
ER-Al
ER-AT
ER-ATT
Chinese Query
(1) Only one English Translation:
C5()
(2) More than one English Translation:
C51.11, C a(,+2), — ,
Chinese Restriction
{CW WI&apos; • CW (I)m
1CW , CW (2)m,), ,
(CW a (0,
UI Model ER-U1
(POS Tag Matched) ER-UT
Top 10 &amp; POS Tag MatchecliSt
UTT Model ER-UTT
UT H•
UTT
(Unique Translation)
UT Model
</figure>
<figureCaption confidence="0.999987">
Figure 1. Models for Translation Ambiguity and Target Polysemy Resolution
</figureCaption>
<bodyText confidence="0.999412545454545">
In the above treatment, a word C, in a query Q
is translated into (E,, EW&amp;quot;, EW,2, EW,„„). E,
is selected by Co-Model, and EW&amp;quot;, EW12,
EW,,n, are augmented by different target polysemy
resolution models. Intuitively, E,, EW&amp;quot;, EW12,
should have different weights. E, is
assigned a higher weight, and the words EW&amp;quot;,
EW12, E, in the restriction are assigned lower
weights. They are determined by the following
formula, where n is number of words in Q and mk
is the number of words in a restriction for Ek.
</bodyText>
<equation confidence="0.998092">
weight(E1) — 1
weight(EW,i) —
(n +1)*Emk
k=1
</equation>
<bodyText confidence="0.998457555555556">
Thus six new models, i.e., A 1 W, ATW, ATTW,
U1W, UTW and UTTW, are derived. Finally,
we apply Co-model again to disambiguate the
pseudo contexts and devise six new models
(A1WCO, ATWCO, ATTWCO, U1WCO,
UTWCO, and UTTWCO). In these six models,
only one restriction word will be selected from the
words EW&amp;quot;, EW12, EW,„„ via disambiguation
with other restrictions.
</bodyText>
<sectionHeader confidence="0.992779" genericHeader="evaluation">
4. Experimental Results
</sectionHeader>
<bodyText confidence="0.999953235294118">
To evaluate the above models, we employ
TREC-6 text collection, TREC topics 301-350
(Harman, 1997), and Smart information retrieval
system (Salton and Buckley, 1988). The text
collection contains 556,077 documents, and is
about 2.2G bytes. Because the goal is to
evaluate the performance of Chinese-English
information retrieval on different models, we
translate the 50 English queries into Chinese by
human. The topic 332 is considered as an
example in the following. The original English
version and the human-translated Chinese version
are shown. A TREC topic is composed of
several fields. Tags &lt;num&gt;, &lt;title&gt;, &lt;des&gt;, and
&lt;narr&gt; denote topic number, title, description, and
narrative fields. Narrative provides a complete
description of document relevance for the
</bodyText>
<equation confidence="0.3566105">
n+1
1
</equation>
<page confidence="0.997029">
218
</page>
<bodyText confidence="0.9979126">
shows the augmented translation results using
different models. Here, both translation
ambiguity and target polysemy are resolved.
The following lists the selected restrictions in Al
model.
</bodyText>
<equation confidence="0.8146278">
ig (evasion): V, _N (N: poundage), 41:1.43f,_N (N:
scot), (V: stay)
)4(income): Frc.O_N (N: quota)
ig.,(tax): ita_V (N: evasion), fifIhrift_N (N:surtax), .2.
(N: surplus), *I4jLN (N: sales tax)
</equation>
<bodyText confidence="0.90176572">
Augmented translation restrictions (poundage,
scot, stay), (quota), and (evasion, surtax, surplus,
sales tax) are added to &amp;quot;evasion&amp;quot;, &amp;quot;income&amp;quot;, and
&amp;quot;tax&amp;quot;, respectively. From Longman dictionary,
we know there are 3 senses, 1 sense, and 2 senses
for &amp;quot;evasion&amp;quot;, &amp;quot;income&amp;quot;, and &amp;quot;tax&amp;quot;, respectively.
Augmented restrictions are used to deal with
target polysemy problem. Compared with Al
model, only &amp;quot;evasion&amp;quot; is augmented with a
translation restriction in Ul model. This is
because &amp;quot; AA&amp;quot; (tao2luo4) has only one
translation and &amp;quot;iq-1-V-&amp;quot; (suo3de2) and &amp;quot;ft&amp;quot; (sui4)
have more than one translation. Similarly, the
augmented translation restrictions are omitted in
the other U-models. Now we consider AT
model. The Chinese restrictions, which have the
matching POSes, are listed below:
AA (evasion):
IAA _N (N: poundage), 4i1.43LN (N: scot), itth._V (V:
stay), (N: droit, duty, geld, tax), U1 _N (N:
custom, douane, tariff), it.4_V (V: avoid, elude,
wangle, welch, welsh; N: avoidance, elusion, evasion,
evasiveness, miss, runaround, shirk, skulk), it k_V
(V: contravene, infract, infringe; N: contravention,
infraction, infringement, sin, violation)
</bodyText>
<equation confidence="0.9033045">
M-f4- (income):
if_V (V: impose; N: division), iffjf,_V (V: assess, put,
tax; N: imposition, taxation), At1 A_N (N: Swiss,
Switzer), Atz - A- _V (V: minus, subtract), FA.N (N:
</equation>
<bodyText confidence="0.824226636363636">
quota), (N: commonwealth, folk, land, nation,
nationality, son, subject)
(tax):
(N: surtax), 1.4*_N (N: surplus), *VI,
_N (N: sales tax), F.-*.y (V: abase, alight, debase,
descend), A_N (N: altitude, loftiness, tallness; ADJ:
high; ADV: loftily), 4-_V (V: comprise, comprize,
embrace, encompass), 4-_V (V: compete, emulate, vie;
N: conflict, contention, duel, strife)
assessors. In our experiments, only the fields of
title and description are used to generate queries.
</bodyText>
<figure confidence="0.689207304347826">
&lt;top&gt;
&lt;num&gt; Number: 332
&lt;title&gt; Income Tax Evasion
&lt;desc&gt; Description:
This query is looking for investigations that have
targeted evaders of U.S. income tax.
&lt;narr&gt; Narrative:
A relevant document would mention investigations
either in the U.S. or abroad of people suspected of evading
U.S. income tax laws. Of particular interest are
investigations involving revenue from illegal activities, as
a strategy to bring known or suspected criminals to justice.
&lt;/top&gt;
&lt;top&gt;
&lt;num&gt; Number: 332
&lt;C-title&gt;
itiA0144.4it °
&lt;C-desc&gt; Description:
itti-A141i&apos;114-&apos;4XitAtti-01111-11
&lt;C-narr&gt; Narrative:
411114Sc-41-itgi/ *AMIN A,141,1-A-4
J4111 otAA i_t_c ***it *A-41thosoc.A.ewlit.
&lt;/top&gt;
</figure>
<bodyText confidence="0.999740958333334">
Totally, there are 1,017 words (557 distinct
words) in the title and description fields of the 50
translated TREC topics. Among these, 401
words have unique translations and 616 words
have multiple translation equivalents in our
Chinese-English bilingual dictionary. Table 2
shows the degree of word sense ambiguity in
English and in Chinese, respectively. On the
average, an English query term has 2.976 senses,
and a Chinese query term has 1.828 senses only.
In our experiments, LOB corpus is employed to
train the co-occurrence statistics for translation
ambiguity resolution, and ROCLING balanced
corpus (Huang, et al., 1995) is employed to train
the restrictions for target polysemy resolution.
The mutual information tables are trained using a
window size 3 for adjacent words.
Table 3 shows the query translation of TREC
topic 332. For the sake of space, only title field
is shown. In Table 3(a), the first two rows list
the original English query and the Chinese query.
Rows 3 and 4 demonstrate the English translation
by select-all model and co-occurrence model by
resolving translation ambiguity only. Table 3(b)
</bodyText>
<tableCaption confidence="0.999442">
Table 2. Statistics of TREC Topics 301-350
</tableCaption>
<table confidence="0.989930333333333">
# of Distinct Words Average # of Senses
Original English Topics 500 (370 words found in our dictionary) 2.976
Human-translated Chinese Topics 557 (389 words found in our dictionary) 1.828
</table>
<page confidence="0.975473">
219
</page>
<tableCaption confidence="0.772889">
Table 3. Query Translation of Title Field of TREC Topic 332
a Resolving Translation AmbiguityOnl
</tableCaption>
<table confidence="0.995178904761905">
original English query income tax evasion
Chinese translation by human A A (tao2luo4) ill* (suo3de2) if. (sui4)
by select all model (evasion), (earning, finance, income, taking), (droit, duty, geld, tax)
by co-occurrence model evasion, income, tax
b Resolving both Translation Ambiguityand Target Polysemy
_ (evasion, poundage, scot, stay), (income, quota),
by Al model (tax, evasion, surtax, surplus, sales tax)
by Ul model (evasion, poundage, scot, stay), (income), (tax)
by AT model (evasion; poundage; scot; stay; droit, duty, geld, tax; custom, douane, tariff; avoid, elude, wangle,
welch, welsh; contravene, infract, infringe), (income; impose; assess, put, tax; Swiss, Switzer; minus,
subtract; quota; commonwealth, folk, land, nation, nationality, son, subject),
(tax; surtax; surplus; sales tax; abase, alight, debase, descend; altitude, loftiness, tallness; comprise,
comprize, embrace, encompass; compete, emulate, vie)
by UT model (evasion; poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff, avoid, elude, wangle, welch,
welsh, contravene, infract, infringe), (income), (tax)
by ATT model (evasion, poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff), (income), (tax)
by UTT model (evasion, poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff), (income), (tax)
by ATWCO model (evasion, tax), (income, land), (tax, surtax)
by UTWCO model (evasion, poundage), (income), (tax)
by ATTWCO model (evasion, tax), (income), (tax)
by UTTWCO model (evasion, poundage), (income), (tax)
</table>
<bodyText confidence="0.998880120689655">
Those English words whose POSes are the
same as the corresponding Chinese restrictions are
selected as augmented translation restriction.
For example, the translation of &amp;quot;its 4&amp;quot;_V (tao2bi4)
has two possible POSes, i.e., V and N, so only
&amp;quot;avoid&amp;quot;, &amp;quot;elude&amp;quot;, &amp;quot;wangle&amp;quot;, &amp;quot;welch&amp;quot;, and &amp;quot;welsh&amp;quot;
are chosen. The other terms are added in the
similar way. Recall that we use mutual
information to select the top 10 accompanying
terms of a Chinese query term in ATT model.
The 5th row shows that the augmented translation
restrictions for &amp;quot; (suo3de2) and &amp;quot;ft&amp;quot; (sui4)
are removed because their top 10 Chinese
accompanying terms do not have English
translations of the same POSes. Finally, we
consider ATWCO model. The words &amp;quot;tax&amp;quot;,
&amp;quot;land&amp;quot;, and &amp;quot;surtax&amp;quot; are selected from the three
lists in 3rd row of Table 3(b) respectively, by using
word co-occurrences.
Figure 2 shows the number of relevant
documents on the top 1000 retrieved documents
for Topics 332 and 337. The performances are
stable in all of the +weight (W) models and the
enhanced CO restriction (WCO) models, even
there are different number of words in translation
restrictions. Especially, the enhanced CO
restriction models add at most one translated
restriction word for each query term. They can
achieve the similar performance to those models
that add more translated restriction words.
Surprisingly, the augmented translation results
may perform better than the monolingual retrieval.
Topic 337 in Figure 2 is an example.
Table 4 shows the overall performance of 18
different models for 50 topics. Eleven-point
average precision on the top 1000 retrieved
documents is adopted to measure the performance
of all the experiments. The monolingual
information retrieval, i.e., the original English
queries to English text collection, is regarded as a
baseline model. The performance is 0.1459
under the specified environment. The select-all
model, i.e., all the translation equivalents are
passed without disambiguation, has 0.0652
average precision. About 44.69% of the
performance of the monolingual information
retrieval is achieved. When co-occurrence
model is employed to resolve translation
ambiguity, 0.0831 average precision (56.96% of
monolingual information retrieval) is reported.
Compared to do-nothing model, the performance
is 27.45% increase.
Now we consider the treatment of translation
ambiguity and target polysemy together.
Augmented restrictions are formed in Al, AT,
ATT, UI, UT and UTT models, however, their
performances are worse than Co-model
(translation disambiguation only). The major
</bodyText>
<page confidence="0.995141">
220
</page>
<figureCaption confidence="0.999672">
Figure 2. The Retrieved Performances of Topics 332 and 337
</figureCaption>
<figure confidence="0.9955902">
4 of relevant documents are retrieved
90
80
70
60
50
30
20
10
0
</figure>
<tableCaption confidence="0.998361">
Table 4. Performance of Different Models (11-point Average Precision)
</tableCaption>
<table confidence="0.998588">
Monolingual Resolving Resolving
IR Translation Ambiguity Translation Ambiguity and Target Polyserny
Select English Unambiguous Wards All Words
All Co Model
Ul UT UTT Al AT ATT
0.1459 0.0652 0.0831 0.0797 0.0574 0.0709 0.0674 0.0419 0.0660
(44.69%) (56.96%) (54.63%) (39.34%) (48.59%) (46.20%) (28.72%) (45.24%)
I
-I- Weight + Weight
U1W UTW UTTW Al W ATW ATTW
0.0916 0.0915 0.0914 0.0914 0.0913 0.0914
(62.78%) (62.71%) (62.65%) (62.65%) (62.58%) (62.65%)
+ Weight, English Co Model for + Weight English Co Model for
Restriction Translation Restriction Translation
U 1 W CO UT W C 0 UTTWCO Al W CO AT W CO ATTWCO
0.0918 0.0917 0.0915 0.0917 0.0917 0.0915
(62.92%) (62.85%) (62.71%) (62.85%) (62.85%) (62.71%)
</table>
<bodyText confidence="0.999944921052632">
reason is the restrictions may introduce errors.
That can be found from the fact that models Ul,
UT, and UTT are better than Al, AT, and ATT.
Because the translation of restriction from source
language (Chinese) to target language (English)
has the translation ambiguity problem, the models
(U1 and Al) introduce the unambiguous
restriction terms and perform better than other
models. Controlled augmentation shows higher
performance than uncontrolled augmentation.
When different weights are assigned to the
original English translation and the augmented
restrictions, all the models are improved
significantly. The performances of A1W, ATW,
ATTW, U1W, UTW, and UTTW are about
10.11% addition to the model for translation
disambiguation only. Of these models, the
performance change from model AT to model
ATW is drastic, i.e., from 0.0419 (28.72%) to
0.0913 (62.58%). It tells us the original English
translation plays a major role, but the augmented
restriction still has a significant effect on the
performance.
We know that restriction for each English
translation presents a pseudo English context.
Thus we apply the co-occurrence model again on
the pseudo English contexts. The performances
are increased a little. These models add at most
one translated restriction word for each query
term, but their performances are better than those
models that adding more translated restriction
words. It tells us that a good translated
restriction word for each query term is enough for
resolving target polysemy problem. U1WCO,
which is the best in these experiments, gains
62.92% of monolingual information retrieval, and
40.80% increase to the do-nothing model (select-
all).
</bodyText>
<page confidence="0.996934">
221
</page>
<sectionHeader confidence="0.987521" genericHeader="conclusions">
5. Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999996216216217">
This paper deals with translation ambiguity and
target polysemy at the same time. We utilize
two monolingual balanced corpora to learn useful
statistical data, i.e., word co-occurrence for
translation ambiguity resolution, and translation
restrictions for target polysemy resolution.
Aligned bilingual corpus or special domain corpus
is not required in this design. Experiments show
that resolving both translation ambiguity and
target polysemy gains about 10.11% performance
addition to the method for translation
disambiguation in cross-language information
retrieval. We also analyze the two factors: word
sense ambiguity in source language (translation
ambiguity), and word sense ambiguity in target
language (target polysemy). The statistics of
word sense ambiguities have shown that target
polysemy resolution is critical in Chinese-English
information retrieval.
This treatment is very suitable to translate very
short query on Web. The queries on Web are
1.5-2 words on the average (Pinkerton, 1994;
Fitzpatrick and Dent, 1997). Because the major
components of queries are nouns, at least one
word of a short query of length 1.5-2 words is
noun. Besides, most of the Chinese nouns are
unambiguous, so that translation ambiguity is not
serious comparatively, but target polysemy is
critical in Chinese-English Web retrieval. The
translation restrictions, which introduce pseudo
contexts, are helpful for target polysemy
resolution. The applications of this method to
cross-language Internet searching, the
applicability of this method to other language
pairs, and the effects of human-computer
interaction on resolving translation ambiguity and
target polysemy will be studied in the future.
</bodyText>
<sectionHeader confidence="0.99928" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999659171875">
Ballesteros, L. and Croft, W.B. (1996) &amp;quot;Dictionary-based
Methods for Cross-Lingual Information Retrieval.&amp;quot;
Proceedings of the 7th International DEXA Conference on
Database and Expert Systems Applications, 791-801.
Ballesteros, L. and Croft, W.B. (1998) &amp;quot;Resolving Ambiguity
for Cross-Language Retrieval.&amp;quot; Proceedings of 21&amp;quot; ACM
SIGIR, 64-71.
Bian, G.W. and Chen, H.H. (1998) &amp;quot;Integrating Query
Translation and Document Translation in a Cross-
Language Information Retrieval System.&amp;quot; Machine
Translation and Information Soup, Lecture Notes in
Computer Science, No. 1529, Spring-Verlag, 250-265.
Church, K. et al. (1989) &amp;quot;Parsing, Word Associations and
Typical Predicate-Argument Relations.&amp;quot; Proceedings of
International Workshop on Parsing Technologies, 389-
398.
Davis, M.W. (1997) &amp;quot;New Experiments in Cross-Language
Text Retrieval at NMSU&apos;s Computing Research Lab.&amp;quot;
Proceedings of TREC 5, 39-1-39-19.
Davis, M.W. and Dunning, T. (1996) &amp;quot;A TREC Evaluation of
Query Translation Methods for Multi-lingual Text
Retrieval.&amp;quot; Proceedings of TREC-4, 1996.
Fitzpatrick, L. and Dent, M. (1997) &amp;quot;Automatic Feedback
Using Past Queries: Social Searching. &amp;quot; Proceedings of
20&apos;&apos;&apos; ACM SIGIR, 306-313.
Harman, D.K. (1997) TREC-6 Proceedings, Gaithersburg,
Maryland.
Hayashi, Y., Kikui, G. and Susaki, S. (1997) &amp;quot;TITAN: A
Cross-linguistic Search Engine for the WWW.&amp;quot; Working
Notes of AAAI-97 Spring Symposiums on Cross-Language
Text and Speech Retrieval, 58-65.
Huang, C.R., et al. (1995) &amp;quot;Introduction to Academia Sinica
Balanced Corpus. &amp;quot; Proceedings of ROCLING VIII,
Taiwan, 81-99.
Hull, D.A. and Grefenstette, G. (1996) &amp;quot;Querying Across
Languages: A Dictionary-based Approach to Multilingual
Information Retrieval.&amp;quot; Proceedings of the 19th ACM
SIGIR, 49-57.
Kowk, K.L. (1997) &amp;quot;Evaluation of an English-Chinese Cross-
Lingual Retrieval Experiment.&amp;quot; Working Notes of AAAI-97
Spring Symposiums on Cross-Language Text and Speech
Retrieval, 110-114.
Lai, M. and Lin, T.Y. (1987) The New Lin Yutang Chinese-
English Dictionary. Panorama Press Ltd, Hong Kong.
Longman (1978) Longman Dictionary of Contemporary
English. Longman Group Limited.
Mei, J.; et al. (1982) tong2yi4ci2ci2lin2. Shanghai
Dictionary Press.
Oard, D.W. (1997) &amp;quot;Alternative Approaches for Cross-
Language Text Retrieval.&amp;quot; Working Notes of AAAI-97
Spring Symposiums on Cross-Language Text and Speech
Retrieval, 131-139.
Oard, D.W. and Dorr, B.J. (1996) A Survey of Multilingual
Text Retrieval. Technical Report UMIACS-TR-96-19,
University of Maryland, Institute for Advanced Computer
Studies. http://www.ee.umd.edu/medlab/filter/papers/mlir.ps.
Pinkerton, B. (1994) &amp;quot;Finding What People Want:
Experiences with the WebCrawler.&amp;quot; Proceedings of WWW.
Salton, G. and Buckley, C. (1988) &amp;quot;Term Weighting
Approaches in Automatic Text Retrieval.&amp;quot; Information
Processing and Management, Vol. 5, No. 24, 513-523.
Sheridan, P. and Ballerini, J.P. (1996) &amp;quot;Experiments in
Multilingual Information Retrieval Using the SPIDER
System.&amp;quot; Proceedings of the 19th ACM SIGIR, 58-65.
</reference>
<page confidence="0.99797">
222
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.907820">
<title confidence="0.998913">Resolving Translation Ambiguity and Target Polysemy in Cross-Language Information Retrieval</title>
<author confidence="0.99506">Hsin-Hsi Chen</author>
<author confidence="0.99506">Guo-Wei Bian</author>
<author confidence="0.99506">Wen-Cheng Lin</author>
<affiliation confidence="0.99975">Department of Computer Science and Information Engineering National Taiwan University</affiliation>
<address confidence="0.99897">Taipei, TAIWAN, R.O.C.</address>
<email confidence="0.977038">E-mail:hh_chen@csie.ntu.edu.tw,{gwbian,denislin}@n1g2.csie.ntu.edu.tw</email>
<abstract confidence="0.991924538461538">This paper deals with translation ambiguity and target polysemy problems together. Two monolingual balanced corpora are employed to learn word co-occurrence for translation ambiguity resolution, and augmented translation restrictions for• target polysemy resolution. Experiments show that the model achieves 62.92% of monolingual information retrieval, and is 40.80% addition to the select-all model. Combining the target polysemy resolution, the retrieval performance is about 10.11% increase to the model resolving translation ambiguity only.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Dictionary-based Methods for Cross-Lingual Information Retrieval.&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the 7th International DEXA Conference on Database and Expert Systems Applications,</booktitle>
<pages>791--801</pages>
<contexts>
<context position="2257" citStr="Ballesteros and Croft, 1996" startWordPosition="305" endWordPosition="308">en the applications of MT and CLIR. In MT, readers interpret the translated results. If the target word has more than one sense, readers can disambiguate its meaning automatically. Comparatively, the translated result is sent to a monolingual information retrieval system in CLIR. The target polysemy adds extraneous senses and affects the retrieval performance. Some different approaches have been proposed for query translation. Dictionary-based approach exploits machine-readable dictionaries and selection strategies like select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1997) integrate both lexical and corpus knowledge</context>
</contexts>
<marker>Ballesteros, Croft, 1996</marker>
<rawString>Ballesteros, L. and Croft, W.B. (1996) &amp;quot;Dictionary-based Methods for Cross-Lingual Information Retrieval.&amp;quot; Proceedings of the 7th International DEXA Conference on Database and Expert Systems Applications, 791-801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Resolving Ambiguity for Cross-Language Retrieval.&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of 21&amp;quot; ACM SIGIR,</booktitle>
<pages>64--71</pages>
<contexts>
<context position="2779" citStr="Ballesteros and Croft, 1998" startWordPosition="374" endWordPosition="377">ike select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1997) integrate both lexical and corpus knowledge. All the above approaches deal with the translation ambiguity problem in query translation. Few touch on translation ambiguity and target polysemy together. This paper will study the multiplication effects of translation ambiguity and target polysemy in cross-language information retrieval systems, and propose a new translation method to resolve these problems. Section 2 shows the effects of translation ambiguity and target polysemy in Chinese-English and EnglishChinese information retrievals. Section 3 presents sev</context>
<context position="6781" citStr="Ballesteros and Croft (1998)" startWordPosition="981" endWordPosition="984">EIR. Some Chinese words may have more than one sense. For example, &amp;quot;ittb&amp;quot; (yun4dong4) has the following meanings (Lai and Lin, 1987): (1) sport, (2) exercise, (3) movement, (4) motion, (5) campaign, and (6) lobby. Each corresponding English word may have more than one sense. For example, &amp;quot;exercise&amp;quot; may mean a question or set of questions to be answered by a pupil for practice; the use of a power or right; and so on. The multiplication effects of translation ambiguity and target polysemy make query translation harder. 3. Translation Ambiguity and Polysemy Resolution Models In the recent works, Ballesteros and Croft (1998), and Bian and Chen (1998) employ dictionaries and co-occurrence statistics trained from target language documents to deal with translation ambiguity. We will follow our previous work (Bian and Chen, 1998), which combines the dictionary-based and corpus-based approaches for CEIR. A bilingual dictionary provides the translation equivalents of each query term, and the word co-occurrence information trained from a target language text collection is used to disambiguate the translation. This method considers the content around the translation equivalents to decide the best target word. The transla</context>
</contexts>
<marker>Ballesteros, Croft, 1998</marker>
<rawString>Ballesteros, L. and Croft, W.B. (1998) &amp;quot;Resolving Ambiguity for Cross-Language Retrieval.&amp;quot; Proceedings of 21&amp;quot; ACM SIGIR, 64-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G W Bian</author>
<author>H H Chen</author>
</authors>
<title>Integrating Query Translation and Document Translation in a CrossLanguage Information Retrieval System.&amp;quot; Machine Translation and Information Soup,</title>
<date>1998</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>1529</volume>
<pages>250--265</pages>
<contexts>
<context position="2800" citStr="Bian and Chen, 1998" startWordPosition="378" endWordPosition="381">enstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1997) integrate both lexical and corpus knowledge. All the above approaches deal with the translation ambiguity problem in query translation. Few touch on translation ambiguity and target polysemy together. This paper will study the multiplication effects of translation ambiguity and target polysemy in cross-language information retrieval systems, and propose a new translation method to resolve these problems. Section 2 shows the effects of translation ambiguity and target polysemy in Chinese-English and EnglishChinese information retrievals. Section 3 presents several models to revolv</context>
<context position="6807" citStr="Bian and Chen (1998)" startWordPosition="986" endWordPosition="989">ore than one sense. For example, &amp;quot;ittb&amp;quot; (yun4dong4) has the following meanings (Lai and Lin, 1987): (1) sport, (2) exercise, (3) movement, (4) motion, (5) campaign, and (6) lobby. Each corresponding English word may have more than one sense. For example, &amp;quot;exercise&amp;quot; may mean a question or set of questions to be answered by a pupil for practice; the use of a power or right; and so on. The multiplication effects of translation ambiguity and target polysemy make query translation harder. 3. Translation Ambiguity and Polysemy Resolution Models In the recent works, Ballesteros and Croft (1998), and Bian and Chen (1998) employ dictionaries and co-occurrence statistics trained from target language documents to deal with translation ambiguity. We will follow our previous work (Bian and Chen, 1998), which combines the dictionary-based and corpus-based approaches for CEIR. A bilingual dictionary provides the translation equivalents of each query term, and the word co-occurrence information trained from a target language text collection is used to disambiguate the translation. This method considers the content around the translation equivalents to decide the best target word. The translation of a query term can b</context>
<context position="11053" citStr="Bian and Chen, 1998" startWordPosition="1649" endWordPosition="1652">rds C„ C2, ..., Cn, find the corresponding English translation equivalents in a ChineseEnglish bilingual dictionary. To discuss the propagation errors from translation ambiguity resolution part in the experiments, we consider the following two alternatives: (a) select all (do-nothing) The strategy does nothing on the translation disambiguation. All the English translation equivalents for the n Chinese words are selected, and are submitted to a monolingual information retrieval system. (b) co-occurrence model (Co-Model) We adopt the strategy discussed previously for translation disambiguation (Bian and Chen, 1998). This method considers the content around the English translation equivalents to decide the best target equivalent. For target polysemy resolution part in Figure 1, we also consider two alternatives. In the first alternative (called A model), we augment restrictions to all the words no matter whether they are ambiguous or not. In the second alternative (called U model), we neglect those Cs that have more than one English translation. Assume Cam, Co(2), C (p n) have only one English translation. The restrictions are augmented to Caw, Cam, ..., Co(p) only. We apply the above corpus-based method</context>
</contexts>
<marker>Bian, Chen, 1998</marker>
<rawString>Bian, G.W. and Chen, H.H. (1998) &amp;quot;Integrating Query Translation and Document Translation in a CrossLanguage Information Retrieval System.&amp;quot; Machine Translation and Information Soup, Lecture Notes in Computer Science, No. 1529, Spring-Verlag, 250-265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>Parsing, Word Associations and Typical Predicate-Argument Relations.&amp;quot;</title>
<date>1989</date>
<booktitle>Proceedings of International Workshop on Parsing Technologies,</booktitle>
<pages>389--398</pages>
<marker>Church, 1989</marker>
<rawString>Church, K. et al. (1989) &amp;quot;Parsing, Word Associations and Typical Predicate-Argument Relations.&amp;quot; Proceedings of International Workshop on Parsing Technologies, 389-398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Davis</author>
</authors>
<title>New Experiments in Cross-Language Text Retrieval at NMSU&apos;s Computing Research Lab.&amp;quot;</title>
<date>1997</date>
<journal>Proceedings of TREC</journal>
<volume>5</volume>
<pages>39--1</pages>
<contexts>
<context position="2209" citStr="Davis, 1997" startWordPosition="300" endWordPosition="301">is a significant difference between the applications of MT and CLIR. In MT, readers interpret the translated results. If the target word has more than one sense, readers can disambiguate its meaning automatically. Comparatively, the translated result is sent to a monolingual information retrieval system in CLIR. The target polysemy adds extraneous senses and affects the retrieval performance. Some different approaches have been proposed for query translation. Dictionary-based approach exploits machine-readable dictionaries and selection strategies like select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1</context>
</contexts>
<marker>Davis, 1997</marker>
<rawString>Davis, M.W. (1997) &amp;quot;New Experiments in Cross-Language Text Retrieval at NMSU&apos;s Computing Research Lab.&amp;quot; Proceedings of TREC 5, 39-1-39-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Davis</author>
<author>T Dunning</author>
</authors>
<title>A TREC Evaluation of Query Translation Methods for Multi-lingual Text Retrieval.&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of TREC-4,</booktitle>
<contexts>
<context position="2417" citStr="Davis and Dunning, 1996" startWordPosition="327" endWordPosition="330">ng automatically. Comparatively, the translated result is sent to a monolingual information retrieval system in CLIR. The target polysemy adds extraneous senses and affects the retrieval performance. Some different approaches have been proposed for query translation. Dictionary-based approach exploits machine-readable dictionaries and selection strategies like select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1997) integrate both lexical and corpus knowledge. All the above approaches deal with the translation ambiguity problem in query translation. Few touch on translation ambiguity and target polysemy together. Th</context>
</contexts>
<marker>Davis, Dunning, 1996</marker>
<rawString>Davis, M.W. and Dunning, T. (1996) &amp;quot;A TREC Evaluation of Query Translation Methods for Multi-lingual Text Retrieval.&amp;quot; Proceedings of TREC-4, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Fitzpatrick</author>
<author>M Dent</author>
</authors>
<title>Automatic Feedback Using Past Queries: Social Searching. &amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of 20&apos;&apos;&apos; ACM SIGIR,</booktitle>
<pages>306--313</pages>
<contexts>
<context position="27226" citStr="Fitzpatrick and Dent, 1997" startWordPosition="4106" endWordPosition="4109">lation ambiguity and target polysemy gains about 10.11% performance addition to the method for translation disambiguation in cross-language information retrieval. We also analyze the two factors: word sense ambiguity in source language (translation ambiguity), and word sense ambiguity in target language (target polysemy). The statistics of word sense ambiguities have shown that target polysemy resolution is critical in Chinese-English information retrieval. This treatment is very suitable to translate very short query on Web. The queries on Web are 1.5-2 words on the average (Pinkerton, 1994; Fitzpatrick and Dent, 1997). Because the major components of queries are nouns, at least one word of a short query of length 1.5-2 words is noun. Besides, most of the Chinese nouns are unambiguous, so that translation ambiguity is not serious comparatively, but target polysemy is critical in Chinese-English Web retrieval. The translation restrictions, which introduce pseudo contexts, are helpful for target polysemy resolution. The applications of this method to cross-language Internet searching, the applicability of this method to other language pairs, and the effects of human-computer interaction on resolving translati</context>
</contexts>
<marker>Fitzpatrick, Dent, 1997</marker>
<rawString>Fitzpatrick, L. and Dent, M. (1997) &amp;quot;Automatic Feedback Using Past Queries: Social Searching. &amp;quot; Proceedings of 20&apos;&apos;&apos; ACM SIGIR, 306-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Harman</author>
</authors>
<date>1997</date>
<booktitle>TREC-6 Proceedings,</booktitle>
<location>Gaithersburg, Maryland.</location>
<contexts>
<context position="14500" citStr="Harman, 1997" startWordPosition="2221" endWordPosition="2222">re n is number of words in Q and mk is the number of words in a restriction for Ek. weight(E1) — 1 weight(EW,i) — (n +1)*Emk k=1 Thus six new models, i.e., A 1 W, ATW, ATTW, U1W, UTW and UTTW, are derived. Finally, we apply Co-model again to disambiguate the pseudo contexts and devise six new models (A1WCO, ATWCO, ATTWCO, U1WCO, UTWCO, and UTTWCO). In these six models, only one restriction word will be selected from the words EW&amp;quot;, EW12, EW,„„ via disambiguation with other restrictions. 4. Experimental Results To evaluate the above models, we employ TREC-6 text collection, TREC topics 301-350 (Harman, 1997), and Smart information retrieval system (Salton and Buckley, 1988). The text collection contains 556,077 documents, and is about 2.2G bytes. Because the goal is to evaluate the performance of Chinese-English information retrieval on different models, we translate the 50 English queries into Chinese by human. The topic 332 is considered as an example in the following. The original English version and the human-translated Chinese version are shown. A TREC topic is composed of several fields. Tags &lt;num&gt;, &lt;title&gt;, &lt;des&gt;, and &lt;narr&gt; denote topic number, title, description, and narrative fields. Na</context>
</contexts>
<marker>Harman, 1997</marker>
<rawString>Harman, D.K. (1997) TREC-6 Proceedings, Gaithersburg, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hayashi</author>
<author>G Kikui</author>
<author>S Susaki</author>
</authors>
<title>TITAN: A Cross-linguistic Search Engine for the WWW.&amp;quot; Working Notes of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval,</title>
<date>1997</date>
<pages>58--65</pages>
<marker>Hayashi, Kikui, Susaki, 1997</marker>
<rawString>Hayashi, Y., Kikui, G. and Susaki, S. (1997) &amp;quot;TITAN: A Cross-linguistic Search Engine for the WWW.&amp;quot; Working Notes of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval, 58-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Huang</author>
</authors>
<title>Introduction to Academia Sinica Balanced Corpus. &amp;quot;</title>
<date>1995</date>
<booktitle>Proceedings of ROCLING VIII, Taiwan,</booktitle>
<pages>81--99</pages>
<marker>Huang, 1995</marker>
<rawString>Huang, C.R., et al. (1995) &amp;quot;Introduction to Academia Sinica Balanced Corpus. &amp;quot; Proceedings of ROCLING VIII, Taiwan, 81-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Hull</author>
<author>G Grefenstette</author>
</authors>
<title>Querying Across Languages: A Dictionary-based Approach to Multilingual Information Retrieval.&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the 19th ACM SIGIR,</booktitle>
<pages>49--57</pages>
<contexts>
<context position="2195" citStr="Hull and Grefenstette, 1996" startWordPosition="296" endWordPosition="299"> (MT) system. However, there is a significant difference between the applications of MT and CLIR. In MT, readers interpret the translated results. If the target word has more than one sense, readers can disambiguate its meaning automatically. Comparatively, the translated result is sent to a monolingual information retrieval system in CLIR. The target polysemy adds extraneous senses and affects the retrieval performance. Some different approaches have been proposed for query translation. Dictionary-based approach exploits machine-readable dictionaries and selection strategies like select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen,</context>
</contexts>
<marker>Hull, Grefenstette, 1996</marker>
<rawString>Hull, D.A. and Grefenstette, G. (1996) &amp;quot;Querying Across Languages: A Dictionary-based Approach to Multilingual Information Retrieval.&amp;quot; Proceedings of the 19th ACM SIGIR, 49-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K L Kowk</author>
</authors>
<title>Evaluation of an English-Chinese CrossLingual Retrieval Experiment.&amp;quot; Working Notes</title>
<date>1997</date>
<booktitle>of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval,</booktitle>
<pages>110--114</pages>
<marker>Kowk, 1997</marker>
<rawString>Kowk, K.L. (1997) &amp;quot;Evaluation of an English-Chinese CrossLingual Retrieval Experiment.&amp;quot; Working Notes of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval, 110-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lai</author>
<author>T Y Lin</author>
</authors>
<title>The New Lin Yutang ChineseEnglish Dictionary.</title>
<date>1987</date>
<publisher>Panorama Press Ltd,</publisher>
<location>Hong Kong. Longman</location>
<contexts>
<context position="6285" citStr="Lai and Lin, 1987" startWordPosition="901" endWordPosition="904">submitted to an ECIR system, we must disambiguate its meaning at first. If we can find that its correct translation is &amp;quot;ig.4-1-&amp;quot; (yin2hang2), the subsequent operation is very simple. That is, &amp;quot;4414-5-&amp;quot; (yin2hang2) is sent into an IR system, and then documents containing &amp;quot;4-1-&amp;quot; (yin2hang2) will be presented. In this example, translation disambiguation should be done rather than target polysemy resolution. The above examples do not mean translation disambiguation is not required in CEIR. Some Chinese words may have more than one sense. For example, &amp;quot;ittb&amp;quot; (yun4dong4) has the following meanings (Lai and Lin, 1987): (1) sport, (2) exercise, (3) movement, (4) motion, (5) campaign, and (6) lobby. Each corresponding English word may have more than one sense. For example, &amp;quot;exercise&amp;quot; may mean a question or set of questions to be answered by a pupil for practice; the use of a power or right; and so on. The multiplication effects of translation ambiguity and target polysemy make query translation harder. 3. Translation Ambiguity and Polysemy Resolution Models In the recent works, Ballesteros and Croft (1998), and Bian and Chen (1998) employ dictionaries and co-occurrence statistics trained from target language</context>
</contexts>
<marker>Lai, Lin, 1987</marker>
<rawString>Lai, M. and Lin, T.Y. (1987) The New Lin Yutang ChineseEnglish Dictionary. Panorama Press Ltd, Hong Kong. Longman (1978) Longman Dictionary of Contemporary English. Longman Group Limited.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mei</author>
</authors>
<date>1982</date>
<pages>2--4</pages>
<publisher>Shanghai Dictionary Press.</publisher>
<marker>Mei, 1982</marker>
<rawString>Mei, J.; et al. (1982) tong2yi4ci2ci2lin2. Shanghai Dictionary Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
</authors>
<title>Alternative Approaches for CrossLanguage Text Retrieval.&amp;quot;</title>
<date>1997</date>
<booktitle>Working Notes of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval,</booktitle>
<pages>131--139</pages>
<contexts>
<context position="966" citStr="Oard, 1997" startWordPosition="117" endWordPosition="118">slation ambiguity and target polysemy problems together. Two monolingual balanced corpora are employed to learn word co-occurrence for translation ambiguity resolution, and augmented translation restrictions for• target polysemy resolution. Experiments show that the model achieves 62.92% of monolingual information retrieval, and is 40.80% addition to the select-all model. Combining the target polysemy resolution, the retrieval performance is about 10.11% increase to the model resolving translation ambiguity only. 1. Introduction Cross language information retrieval (CUR) (Oard and DOIT, 1996; Oard, 1997) deals with the use of queries in one language to access documents in another. Due to the differences between source and target languages, query translation is usually employed to unify the language in queries and documents. In query translation, translation ambiguity is a basic problem to be resolved. A word in a source query may have more than one sense. Word sense disambiguation identifies the correct sense of each source word, and lexical selection translates it into the corresponding target word. The above procedure is similar to lexical choice operation in a traditional machine translati</context>
</contexts>
<marker>Oard, 1997</marker>
<rawString>Oard, D.W. (1997) &amp;quot;Alternative Approaches for CrossLanguage Text Retrieval.&amp;quot; Working Notes of AAAI-97 Spring Symposiums on Cross-Language Text and Speech Retrieval, 131-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
<author>B J Dorr</author>
</authors>
<title>A Survey of Multilingual Text Retrieval.</title>
<date>1996</date>
<tech>Technical Report UMIACS-TR-96-19,</tech>
<institution>University of Maryland, Institute for Advanced Computer Studies.</institution>
<note>http://www.ee.umd.edu/medlab/filter/papers/mlir.ps.</note>
<marker>Oard, Dorr, 1996</marker>
<rawString>Oard, D.W. and Dorr, B.J. (1996) A Survey of Multilingual Text Retrieval. Technical Report UMIACS-TR-96-19, University of Maryland, Institute for Advanced Computer Studies. http://www.ee.umd.edu/medlab/filter/papers/mlir.ps.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pinkerton</author>
</authors>
<title>Finding What People Want: Experiences with the WebCrawler.&amp;quot;</title>
<date>1994</date>
<booktitle>Proceedings of WWW.</booktitle>
<contexts>
<context position="27197" citStr="Pinkerton, 1994" startWordPosition="4104" endWordPosition="4105">olving both translation ambiguity and target polysemy gains about 10.11% performance addition to the method for translation disambiguation in cross-language information retrieval. We also analyze the two factors: word sense ambiguity in source language (translation ambiguity), and word sense ambiguity in target language (target polysemy). The statistics of word sense ambiguities have shown that target polysemy resolution is critical in Chinese-English information retrieval. This treatment is very suitable to translate very short query on Web. The queries on Web are 1.5-2 words on the average (Pinkerton, 1994; Fitzpatrick and Dent, 1997). Because the major components of queries are nouns, at least one word of a short query of length 1.5-2 words is noun. Besides, most of the Chinese nouns are unambiguous, so that translation ambiguity is not serious comparatively, but target polysemy is critical in Chinese-English Web retrieval. The translation restrictions, which introduce pseudo contexts, are helpful for target polysemy resolution. The applications of this method to cross-language Internet searching, the applicability of this method to other language pairs, and the effects of human-computer inter</context>
</contexts>
<marker>Pinkerton, 1994</marker>
<rawString>Pinkerton, B. (1994) &amp;quot;Finding What People Want: Experiences with the WebCrawler.&amp;quot; Proceedings of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<title>Term Weighting Approaches in Automatic Text Retrieval.&amp;quot;</title>
<date>1988</date>
<journal>Information Processing and Management,</journal>
<volume>5</volume>
<pages>513--523</pages>
<contexts>
<context position="14567" citStr="Salton and Buckley, 1988" startWordPosition="2228" endWordPosition="2231">rds in a restriction for Ek. weight(E1) — 1 weight(EW,i) — (n +1)*Emk k=1 Thus six new models, i.e., A 1 W, ATW, ATTW, U1W, UTW and UTTW, are derived. Finally, we apply Co-model again to disambiguate the pseudo contexts and devise six new models (A1WCO, ATWCO, ATTWCO, U1WCO, UTWCO, and UTTWCO). In these six models, only one restriction word will be selected from the words EW&amp;quot;, EW12, EW,„„ via disambiguation with other restrictions. 4. Experimental Results To evaluate the above models, we employ TREC-6 text collection, TREC topics 301-350 (Harman, 1997), and Smart information retrieval system (Salton and Buckley, 1988). The text collection contains 556,077 documents, and is about 2.2G bytes. Because the goal is to evaluate the performance of Chinese-English information retrieval on different models, we translate the 50 English queries into Chinese by human. The topic 332 is considered as an example in the following. The original English version and the human-translated Chinese version are shown. A TREC topic is composed of several fields. Tags &lt;num&gt;, &lt;title&gt;, &lt;des&gt;, and &lt;narr&gt; denote topic number, title, description, and narrative fields. Narrative provides a complete description of document relevance for t</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Salton, G. and Buckley, C. (1988) &amp;quot;Term Weighting Approaches in Automatic Text Retrieval.&amp;quot; Information Processing and Management, Vol. 5, No. 24, 513-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sheridan</author>
<author>J P Ballerini</author>
</authors>
<title>Experiments in Multilingual Information Retrieval Using the SPIDER System.&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of the 19th ACM SIGIR,</booktitle>
<pages>58--65</pages>
<contexts>
<context position="2477" citStr="Sheridan and Ballerini, 1996" startWordPosition="334" endWordPosition="337">is sent to a monolingual information retrieval system in CLIR. The target polysemy adds extraneous senses and affects the retrieval performance. Some different approaches have been proposed for query translation. Dictionary-based approach exploits machine-readable dictionaries and selection strategies like select all (Hull and Grefenstette, 1996; Davis, 1997), randomly select N (Ballesteros and Croft, 1996; Kwok 1997) and select best N (Hayashi, Kikui and Susaki, 1997; Davis 1997). Corpus-based approaches exploit sentence-aligned corpora (Davis and Dunning, 1996) and document-aligned corpora (Sheridan and Ballerini, 1996). These two approaches are complementary. Dictionary provides translation candidates, and corpus provides context to fit user intention. Coverage of dictionaries, alignment performance and domain shift of corpus are major problems of these two approaches. Hybrid approaches (Ballesteros and Croft, 1998; Bian and Chen, 1998; Davis 1997) integrate both lexical and corpus knowledge. All the above approaches deal with the translation ambiguity problem in query translation. Few touch on translation ambiguity and target polysemy together. This paper will study the multiplication effects of translatio</context>
</contexts>
<marker>Sheridan, Ballerini, 1996</marker>
<rawString>Sheridan, P. and Ballerini, J.P. (1996) &amp;quot;Experiments in Multilingual Information Retrieval Using the SPIDER System.&amp;quot; Proceedings of the 19th ACM SIGIR, 58-65.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>