<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017633">
<title confidence="0.9995225">
Answer Sequence Learning with Neural Networks for Answer Selection in
Community Question Answering
</title>
<author confidence="0.997647">
Xiaoqiang Zhou Baotian Hu Qingcai Chen∗ Buzhou Tang Xiaolong Wang
</author>
<affiliation confidence="0.997477">
Intelligent Computing Research Center
Harbin Institute of Technology, Shenzhen Graduate School
</affiliation>
<email confidence="0.991044">
{xiaoqiang.jeseph,baotianchina,qingcai.chen,tangbuzhou}@gmail.com
wangxl@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.993805" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998091875">
In this paper, the answer selection problem
in community question answering (CQA)
is regarded as an answer sequence label-
ing task, and a novel approach is proposed
based on the recurrent architecture for this
problem. Our approach applies convo-
lution neural networks (CNNs) to learn-
ing the joint representation of question-
answer pair firstly, and then uses the joint
representation as input of the long short-
term memory (LSTM) to learn the answer
sequence of a question for labeling the
matching quality of each answer. Experi-
ments conducted on the SemEval 2015 C-
QA dataset shows the effectiveness of our
approach.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99983275">
Answer selection in community question answer-
ing (CQA), which recognizes high-quality re-
sponses to obtain useful question-answer pairs,
is greatly valuable for knowledge base construc-
tion and information retrieval systems. To rec-
ognize matching answers for a question, typi-
cal approaches model semantic matching between
question and answer by exploring various fea-
tures (Wang et al., 2009a; Shah and Pomerantz,
2010). Some studies exploit syntactic tree struc-
tures (Wang et al., 2009b; Moschitti et al., 2007) to
measure the semantic matching between question
and answer. However, these approaches require
high-quality data and various external resources
which may be quite difficult to obtain. To take
advantage of a large quantity of raw data, deep
learning based approaches (Wang et al., 2010; Hu
et al., 2013) are proposed to learn the distribut-
ed representation of question-answer pair directly.
One disadvantage of these approaches lies in that
</bodyText>
<note confidence="0.98477425">
∗* Corresponding author
Q Hi. anyone can suggest a good tailor shop (preferably
Philippine nationality) in Qatar? i heard there&apos;s one over at Al
Saad. just not sure the details... thanks!
a1 There are a lot of tailor shops, it depends on what you want!
a2 Sterling Tailors in Barwa Village, it is run by indians and sri
lankans but service is good. I&apos;ve seen some filipinos who are
taking orders from them. Just Check it out...
a3 thanks. will def check &apos;em out...
a4 Oh my...they now sell Filipinos? Is there anything they don&apos;t
sell? Well, apart from Guitar Hero...
a5 there&apos;s always a place for improvement. lol,.
</note>
<figureCaption confidence="0.827047">
Figure 1: An Example of the Answer Sequence for
a Question. The dashed arrows depict the relation-
ships of the answers in the sequence.
</figureCaption>
<bodyText confidence="0.99491652">
semantic correlations embedded in the answer se-
quence of a question are ignored, while they are
very important for answer selection. Figure 1 is a
example to show the relationship of answers in the
sequence for a given question. Intuitively, other
answers of the question are beneficial to judge the
quality of the current answer.
Recently, recurrent neural network (RNN),
especially Long Short-Term Memory (LST-
M) (Hochreiter et al., 2001), has been proved su-
periority in various tasks (Sutskever et al., 2014;
Srivastava et al., 2015) and it models long term
and short term information of the sequence. And
also, there are some works on using convolution-
al neural networks (CNNs) to learn the represen-
tations of sentence or short text, which achieve
state-of-the-art performance on sentiment classi-
fication (Kim, 2014) and short text matching (Hu
et al., 2014).
In this paper, we address the answer selection
problem as a sequence labeling task, which iden-
tifies the matching quality of each answer in the
answer sequence of a question. Firstly, CNNs are
used to learn the joint representation of question
answer (QA) pair. Then the learnt joint repre-
</bodyText>
<page confidence="0.946461">
713
</page>
<bodyText confidence="0.8719266">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 713–718,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
sentations are used as inputs of LSTM to predic-
t the quality (e.g., Good, Bad and Potential) of
each answer in the answer sequence. Experiments
conducted on the CQA dataset of the answer se-
lection task in SemEval-20151 show that the pro-
posed approach outperforms other state-of-the-art
approaches.
</bodyText>
<sectionHeader confidence="0.997916" genericHeader="related work">
2 Related Work
</sectionHeader>
<figure confidence="0.972974333333333">
question answer-sequence
LSTM
CNNs
</figure>
<figureCaption confidence="0.999965">
Figure 2: The architecture of R-CNN
</figureCaption>
<bodyText confidence="0.999973210526316">
Prior studies on answer selection generally treat-
ed this challenge as a classification problem via
employing machine learning methods, which re-
ly on exploring various features to represent QA
pair. Huang et al. (2007) integrated textual fea-
tures with structural features of forum threads to
represent the candidate QA pairs, and used sup-
port vector machine (SVM) to classify the can-
didate pairs. Beyond typical features, Shah and
Pomerantz (2010) trained a logistic regression (L-
R) classifier with user metadata to predict the qual-
ity of answers in CQA. Ding et al. (2008) pro-
posed an approach based on conditional random
fields (CRF), which can capture contextual fea-
tures from the answer sequence for the semantic
matching between question and answer. Addition-
ally, the translation-based language model was al-
so used for QA matching by transferring the an-
swer to the corresponding question (Jeon et al.,
2005; Xue et al., 2008; Zhou et al., 2011). The
translation-based methods suffer from the infor-
mal words or phrases in Q&amp;A archives, and per-
form less applicability in new domains.
In contrast to symbolic representation, Wang
et al. (2010) proposed a deep belief nets (DBN)
based semantic relevance model to learn the dis-
tributed representation of QA pair. Recently, the
convolutional neural networks (CNNs) based sen-
tence representation models have achieved suc-
cesses in neural language processing (NLP) tasks.
Yu et al. (2014) proposed a convolutional sentence
model to identify answer contents of a question
from Q&amp;A archives via means of distributed rep-
resentations. The work in Hu et al. (2014) demon-
strated that 2-dimensional convolutional sentence
models can represent the hierarchical structures of
sentences and capture rich matching patterns be-
tween two language objects.
</bodyText>
<footnote confidence="0.94814">
1http://alt.qcri.org/semeval2015/task3/
</footnote>
<sectionHeader confidence="0.989571" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999983315789474">
We consider the answer selection problem in CQA
as a sequence labeling task. To label the matching
quality of each answer for a given question, our
approach models the semantic links between suc-
cessive answers, as well as the semantic relevance
between question and answer. Figure 2 summa-
rizes the recurrent architecture of our model (R-
CNN). The motivation of R-CNN is to learn the
useful context to improve the performance of an-
swer selection. The answer sequence is modeled
to enrich semantic features.
At each step, our approach uses the pre-trained
word embeddings to encode the sentences of QA
pair, which then is used as the input vectors of
the model. Based on the joint representation of
QA pair learned from CNNs, the LSTM is applied
in our model for answer sequence learning, which
makes a prediction to each answer of the question
with softmax function.
</bodyText>
<subsectionHeader confidence="0.999765">
3.1 Convolutional Neural Networks for QA
Joint Learning
</subsectionHeader>
<bodyText confidence="0.9999905625">
Given a question-answer pair at the step t, we use
convolutional neural networks (CNNs) to learn the
joint representation pt for the pair. Figure 3 illus-
trates the process of QA joint learning, which in-
cludes two stages: summarizing the meaning of
the question and an answer, and generating the
joint representation of QA pair.
To obtain high-level sentence representations of
the question and answer, we set 3 hidden layers
in two convolutional sentence models respective-
ly. The output of each hidden layer is made up of a
set of 2-dimensional arrays called feature map pa-
rameters (wm, bm). Each feature map is the out-
come of one convolutional or pooling filter. Each
pooling layer is followed an activation function Q.
The output of the mth hidden layer is computed as
</bodyText>
<page confidence="0.986699">
714
</page>
<figure confidence="0.917879">
Joint Representation
</figure>
<figureCaption confidence="0.997562">
Figure 3: CNNs for QA joint learning
</figureCaption>
<equation confidence="0.9646185">
Eq. 1:
Hm = σ(pool(wmHm−1 + bm)) (1)
</equation>
<bodyText confidence="0.996580444444444">
Here, H0 is one real-value matrix after sentence
semantic encoding by concatenating the word vec-
tors with sliding windows. It is the input of deep
convolution and pooling, which is similar to that
of traditional image input.
Finally, we combine the two sentence models
by adding an additional layer Ht on the top. The
learned joint representation pt for QA pair is for-
malized as Eq. 2:
</bodyText>
<equation confidence="0.9913">
pt = σ(wtHt + bt) (2)
</equation>
<bodyText confidence="0.999909333333333">
where σ is an activation function, and the input
vector is constructed by concatenating the sen-
tence representations of question and answer.
</bodyText>
<subsectionHeader confidence="0.974753">
3.2 LSTM for Answer Sequence Learning
</subsectionHeader>
<bodyText confidence="0.999961941176471">
Based on the joint representation of QA pair, the
LSTM unit of our model performs answer se-
quence learning to model semantic links between
continuous answers. Unlike the traditional recur-
rent unit, the LSTM unit modulates the memory
at each time step, instead of overwriting the states.
The key component of LSTM unit is the memo-
ry cell ct which has a state over time, and the L-
STM unit decides to modify and add the memory
in the cell via the sigmoidal gates: input gate it,
forget gate ft and output gate ot. The implemen-
tation of the LSTM unit in our study is close the
one discussed by Graves (2013). Given the joint
representation pt at time t, the memory cell ct is
updated by the input gate’s activation it and the
forget gate’s activation ft. The updating equation
is given by Eq. 3:
</bodyText>
<equation confidence="0.949893">
ct = ftct−1+ittanh(Wxcpt+Whcht−1+bc) (3)
</equation>
<table confidence="0.9995148">
Data #question #answer length
training 2600 16541 6.36
development 300 1645 5.48
test 329 1976 6.00
all 3229 21062 6.00
</table>
<tableCaption confidence="0.999868">
Table 1: Statistics of experimental dataset
</tableCaption>
<bodyText confidence="0.999418">
The LSTM unit keeps to update the context by
discarding the useless context in forget gate ft and
adding new content from input gate it. The ex-
tents to modulate context for these two gates are
computed as Eq. 4 and Eq. 5:
</bodyText>
<equation confidence="0.999752">
it = σ(Wxipt + Whih(t−1) + Wcict−1 + bi) (4)
ft = σ(Wxfpt + Whfht−1 + Wcfct−1 + bf) (5)
</equation>
<bodyText confidence="0.616934">
With the updated cell state ct, the final output
from LSTM unit ht is computed as Eq 6 and Eq 7:
</bodyText>
<equation confidence="0.999367">
ot = σ(Wxopt + Whoht−1 + Wcoct + bo) (6)
ht = ottanh(ct) (7)
</equation>
<bodyText confidence="0.999837727272727">
Note that (W∗, b∗) is the parameters of LSTM
unit, in which Wcf, Wci , and Wco are diagonal
matrices.
According to the output ht at each time step,
our approach estimates the conditional probability
of the answer sequence over answer classes, it is
given by Eq. 8:
Here, (y1, ..., yT) is the corresponding label se-
quence for the input sequence (p1, ..., pt−1), and
the class distribution p(yt|c, y1, ..., .yt−1) is repre-
sented by a softmax function.
</bodyText>
<sectionHeader confidence="0.999942" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996658">
4.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.97422775">
Experimental Dataset: We conduct experiments
on the public dataset of the answer selection chal-
lenge in SemEval 2015. This dataset consists of
three subsets: training, development, and test sets,
</bodyText>
<figure confidence="0.644550090909091">
question
answer
conv&amp;pooling
Encoding
É
É
P(y1, ..., yT |c, p1, ..., pt−1) =
T
H p(yt|c, y1, ..., yt−1)
t=1
(8)
</figure>
<page confidence="0.985459">
715
</page>
<bodyText confidence="0.996691549019608">
and contains 3,229 questions with 21,062 answer-
s. The answers falls into three classes: Good, Bad,
and Potential, accounting for 51%, 39%, and 10%
respectively. The statistics of the dataset are sum-
marized in Table 1, where #question/answer de-
notes the number of questions/answers, and length
stands for the average number of answers for a
question.
Competitor Methods: We compare our approach
against the following competitor methods:
SVM (Huang et al., 2007): An SVM-based
method with bag-of-words (textual features), non-
textual features, and features based on topic model
(i.e., latent Dirichlet allocation, LDA).
CRF (Ding et al., 2008): A CRF-based method
using the same features as the SVM approach.
DBN (Wang et al., 2010): Taking bag-of-words
representation, the method applies deep belief net-
s to learning the distributed representation of QA
pair, and predicts the class of answers using a lo-
gistic regression classifier on the top layer.
mDBN (Hu et al., 2013): In contrast to DBN,
multimodal DBN learns the joint representations
of textual features and non-textual features rather
than bag-of-words.
CNN: Using word embedding, the CNNs based
model in Hu et al. (2014) is used to learn the rep-
resentations of questions and answers, and a logis-
tic regression classifier is used to predict the class
of answers.
Evaluation Metrics: The evaluation metric-
s include Macro − precision(P), Macro −
recall(R), Macro − F1(F1), and F1 scores of
the individual classes. According to the evalua-
tion results on the development set, all the hyper-
parameters are optimized on the training set.
Model Architecture and Training Details: The
CNNs of our model for QA joint representation
learning have 3 hidden layers for modeling ques-
tion and answer sentence respectively, in which
each layer has 100 feature maps for convolution
and pooling operators. The window sizes of con-
volution for each layer are [1 x 1, 2 x 2, 2 x 2], the
window sizes of pooling are [2 x 2, 2 x 2,1 x 1].
For the LSTM unit, the size of input gate is set
to 200, the sizes of forget gate, output gate, and
memory cell are all set to 360.
Stochastic gradient descent (SGD) algorithm vi-
a back-propagation through time is used to train
the model. To prevent serious overfitting, early
stopping and dropout (Hinton et al., 2012) are used
</bodyText>
<table confidence="0.999684428571429">
Methods P R F1
SVM 50.10 54.43 52.14
CRF 53.89 54.26 53.40
DBN 55.22 53.80 54.07
mDBN 56.11 53.95 54.29
CNN 55.33 54.73 54.42
R-CNN 56.41 56.16 56.14
</table>
<tableCaption confidence="0.997641">
Table 2: Macro-averaged results(%)
</tableCaption>
<bodyText confidence="0.9997322">
during the training procedure. The learning rate
A is initialized to be 0.01 and is updated dynam-
ically according to the gradient descent using the
ADADELTA method (Zeiler, 2012). The activa-
tion functions (σ, γ) in our model adopt the rec-
tified linear unit (ReLU) (Dahl et al., 2013). In
addition, the word embeddings for encoding sen-
tences are pre-trained with the unsupervised neu-
ral language model (Mikolov et al., 2013) on the
Qatar Living data2.
</bodyText>
<subsectionHeader confidence="0.781131">
4.2 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.999968222222222">
Table 2 summarizes the Macro-averaged results.
The F1 scores of the individual classes are present-
ed in Table 3.
It is clear to see that the proposed R-CNN ap-
proach outperforms the competitor methods over
the Macro-averaged metrics as expected from Ta-
ble 2. The main reason lies in that R-CNN takes
advantages of the semantic correlations between
successive answers by LSTM, in addition to the
semantic relationships between question and an-
swer. The joint representation of QA pair learnt
by CNNs also captures richer matching patterns
between question and answer than other methods.
It is notable that the methods based on deep
learning perform more powerful than SVM and
CRF, especially for complicate answers (e.g., Po-
tential answers). In contrast, SVM and CRF using
a large amount of features perform better for the
answers that have obvious tendency (e.g., Good
and Bad answers). The main reason is that the
distributed representation learnt from deep learn-
ing architecture is able to capture the semantic re-
lationships between question and answer. On the
other hand, the feature-engineers in both SVM and
CRF suffer from noisy information of CQA and
the feature sparse problem for short questions and
answers.
</bodyText>
<footnote confidence="0.9125385">
2http://alt.qcri.org/semeval2015/task3/index.php?id=data-
and-tools
</footnote>
<page confidence="0.989202">
716
</page>
<table confidence="0.998426285714286">
Methods Good Bad Potential
SVM 79.78 76.65 0.00
CRF 79.32 75.50 5.38
DBN 76.99 71.33 13.89
mDBN 77.74 70.39 14.74
CNN 76.45 74.77 12.05
R-CNN 77.31 75.88 15.22
</table>
<tableCaption confidence="0.999774">
Table 3: F1 scores for the individual classes(%)
</tableCaption>
<bodyText confidence="0.999613707317074">
Compared to DBN and mDBN, CNN and R-
CNN show their superiority in modeling QA pair.
The convolutional sentence models, used in CN-
N and R-CNN, can learn the hierarchical struc-
ture of language object by deep convolution and
pooling operators. In addition, both R-CNN and
CNN encode the sentence into one tensor, which
makes sure the representation contains more se-
mantic features than the bag-of-words representa-
tion in DBN and mDBN.
The improvement achieved by R-CNN over C-
NN demonstrates that answer sequence learning is
able to improve the performance of the answer se-
lection in CQA. Because modeling the answer se-
quence can enjoy the advantage of the shared rep-
resentation between successive answers, and com-
plement the classification features with the learn-
t useful context from previous answers. Further-
more, memory cell and gates in LSTM unit modify
the valuable context to pass onwards by updating
the state of RNN during the learning procedure.
The main improvement of R-CNN against with
the competitor methods comes from the Potential
answers, which are much less than other two type
of answers. It demonstrates that R-CNN is able to
process the unbalance data. In fact, the Potential
answers are most difficult to identify among the
three types of answers as Potential is an intermedi-
ate category (M`arquez et al., 2015). Nevertheless,
R-CNN achieves the highest F1 score of 15.22%
on Potential answers. In CQA, Q&amp;A archives usu-
ally form one multi-parties conversation when the
asker gives feedbacks (e.g., “ok” and “please”) to
users responses, indicating that the answers of one
question are sematic related. Thus, it is easy to un-
derstand that R-CNN performs better performance
than competitor methods, especially on the recal-
l. The reason is that R-CNN can model semantic
correlations between successive answers to learn
the context and the long range dependencies in the
answer sequence.
</bodyText>
<sectionHeader confidence="0.995156" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999771347826087">
In this paper, we propose an answer sequence
learning model R-CNN for the answer selection
task by integrating LSTM unit and CNNs. Based
on the recurrent architecture of our model, our ap-
proach is able to model the semantic link between
successive answers, in addition to the semantic rel-
evance between question and answer. Experimen-
tal results demonstrate that our approach can learn
the useful context from the answer sequence to im-
prove the performance of answer selection in C-
QA.
In the future, we plan to explore the method-
s on training the unbalance data to improve the
overall performances of our approach. Based on
this work, more research can be conducted on
topic recognition and semantic roles labeling for
human-human conversations in real-world.
Acknowledgments: This work was support-
ed in part by National 863 Program of China
(2015AA015405), NSFCs (National Natural Sci-
ence Foundation of China) (61402128, 61473101,
61173075 and 61272383). We thank the anony-
mous reviewers for their insightful comments.
</bodyText>
<sectionHeader confidence="0.998003" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99666064">
George E. Dahl, Tara N. Sainath, and Geoffrey E. Hin-
ton. 2013. Improving deep neural networks for lvc-
sr using rectified linear units and dropout. In ICAS-
SP, pages 8609–8613. IEEE.
Shilin Ding, Gao Cong, Chin yew Lin, and Xiaoyan
Zhu. 2008. Using conditional random fields to ex-
tract contexts and answers of questions from online
forums. In In Proceedings of ACL-08: HLT.
Alex Graves. 2013. Generating sequences with recur-
rent neural networks. CoRR, abs/1308.0850.
Geoffrey E. Hinton, Nitish Srivastava, Alex
Krizhevsky, Ilya Sutskever, and Ruslan Salakhut-
dinov. 2012. Improving neural networks by
preventing co-adaptation of feature detectors.
CoRR, abs/1207.0580.
Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and
J¨urgen Schmidhuber. 2001. Gradient flow in recur-
rent nets: the difficulty of learning long-term depen-
dencies.
Haifeng Hu, Bingquan Liu, Baoxun Wang, Ming Li-
u, and Xiaolong Wang. 2013. Multimodal dbn for
predicting high-quality answers in cqa portals. In
Proceedings of the 51st Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:
Short Papers), Sofia, Bulgaria, August.
</reference>
<page confidence="0.986227">
717
</page>
<reference confidence="0.999805797468354">
Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai
Chen. 2014. Convolutional neural network archi-
tectures for matching natural language sentences. In
Advances in Neural Information Processing Systems
27, pages 2042–2050.
Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Ex-
tracting chatbot knowledge from online discussion
forums. In Proceedings of the 20th International
Joint Conference on Artifical Intelligence, IJCAI’07,
pages 423–428.
Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005.
Finding similar questions in large question and an-
swer archives. In Proceedings of the 14th ACM In-
ternational Conference on Information and Knowl-
edge Management, CIKM ’05, pages 84–90.
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. CoRR, abs/1408.5882.
Llu´ıs M`arquez, James Glass, Walid Magdy, Alessan-
dro Moschitti, Preslav Nakov, and Bilal Randeree.
2015. Semeval-2015 task 3: Answer selection in
community question answering. In Proceedings of
the 9th International Workshop on Semantic Evalu-
ation (SemEval-2015).
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. CoRR, abs/1301.3781.
Alessandro Moschitti, Silvia Quarteroni, Roberto
Basili, and Suresh Manandhar. 2007. Exploiting
syntactic and shallow semantic kernels for question
answer classification. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics, pages 776–783.
Chirag Shah and Jefferey Pomerantz. 2010. Evaluat-
ing and predicting answer quality in community qa.
In Proceedings of the 33rd International ACM SI-
GIR Conference on Research and Development in
Information Retrieval, SIGIR ’10, pages 411–418.
Nitish Srivastava, Elman Mansimov, and Ruslan
Salakhutdinov. 2015. Unsupervised learning of
video representations using lstms. CoRR, ab-
s/1502.04681.
Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural network-
s. CoRR, abs/1409.3215.
Baoxun Wang, Bingquan Liu, Chengjie Sun, Xiaolong
Wang, and Lin Sun. 2009a. Extracting chinese
question-answer pairs from online forums. In IEEE
International Conference on Systems, Man, and Cy-
bernetics (SMC), pages 1159–1164.
Kai Wang, Zhaoyan Ming, and Tat-Seng Chua. 2009b.
A syntactic tree matching approach to finding sim-
ilar questions in community-based qa services. In
Proceedings of the 32Nd International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ’09, pages 187–194.
Baoxun Wang, Xiaolong Wang, Chengjie Sun,
Bingquan Liu, and Lin Sun. 2010. Modeling se-
mantic relevance for question-answer pairs in web
social communities. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics, ACL ’10, pages 1230–1238.
Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008.
Retrieval models for question and answer archives.
In Proceedings of the 31st Annual International
ACM SIGIR Conference on Research and Devel-
opment in Information Retrieval, SIGIR ’08, pages
475–482.
Lei Yu, Karl Moritz Hermann, Phil Blunsom, and
Stephen Pulman. 2014. Deep learning for answer
sentence selection. CoRR, abs/1412.1632.
Matthew D. Zeiler. 2012. ADADELTA: an adaptive
learning rate method. CoRR, abs/1212.5701.
Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu.
2011. Phrase-based translation model for question
retrieval in community question answer archives. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages
653–662.
</reference>
<page confidence="0.995012">
718
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.830510">
<title confidence="0.992094">Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering</title>
<author confidence="0.997392">Zhou Baotian Hu Qingcai Buzhou Tang Xiaolong Wang</author>
<affiliation confidence="0.9961495">Intelligent Computing Research Harbin Institute of Technology, Shenzhen Graduate</affiliation>
<email confidence="0.931514">wangxl@insun.hit.edu.cn</email>
<abstract confidence="0.992877882352941">In this paper, the answer selection problem in community question answering (CQA) is regarded as an answer sequence labeling task, and a novel approach is proposed based on the recurrent architecture for this problem. Our approach applies convolution neural networks (CNNs) to learning the joint representation of questionanswer pair firstly, and then uses the joint representation as input of the long shortterm memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 C- QA dataset shows the effectiveness of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George E Dahl</author>
<author>Tara N Sainath</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>Improving deep neural networks for lvcsr using rectified linear units and dropout.</title>
<date>2013</date>
<booktitle>In ICASSP,</booktitle>
<pages>8609--8613</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="13756" citStr="Dahl et al., 2013" startWordPosition="2265" endWordPosition="2268">a back-propagation through time is used to train the model. To prevent serious overfitting, early stopping and dropout (Hinton et al., 2012) are used Methods P R F1 SVM 50.10 54.43 52.14 CRF 53.89 54.26 53.40 DBN 55.22 53.80 54.07 mDBN 56.11 53.95 54.29 CNN 55.33 54.73 54.42 R-CNN 56.41 56.16 56.14 Table 2: Macro-averaged results(%) during the training procedure. The learning rate A is initialized to be 0.01 and is updated dynamically according to the gradient descent using the ADADELTA method (Zeiler, 2012). The activation functions (σ, γ) in our model adopt the rectified linear unit (ReLU) (Dahl et al., 2013). In addition, the word embeddings for encoding sentences are pre-trained with the unsupervised neural language model (Mikolov et al., 2013) on the Qatar Living data2. 4.2 Results and Analysis Table 2 summarizes the Macro-averaged results. The F1 scores of the individual classes are presented in Table 3. It is clear to see that the proposed R-CNN approach outperforms the competitor methods over the Macro-averaged metrics as expected from Table 2. The main reason lies in that R-CNN takes advantages of the semantic correlations between successive answers by LSTM, in addition to the semantic rela</context>
</contexts>
<marker>Dahl, Sainath, Hinton, 2013</marker>
<rawString>George E. Dahl, Tara N. Sainath, and Geoffrey E. Hinton. 2013. Improving deep neural networks for lvcsr using rectified linear units and dropout. In ICASSP, pages 8609–8613. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin yew Lin</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Using conditional random fields to extract contexts and answers of questions from online forums. In</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT.</booktitle>
<contexts>
<context position="5080" citStr="Ding et al. (2008)" startWordPosition="792" endWordPosition="795">LSTM CNNs Figure 2: The architecture of R-CNN Prior studies on answer selection generally treated this challenge as a classification problem via employing machine learning methods, which rely on exploring various features to represent QA pair. Huang et al. (2007) integrated textual features with structural features of forum threads to represent the candidate QA pairs, and used support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets</context>
<context position="11626" citStr="Ding et al., 2008" startWordPosition="1898" endWordPosition="1901">stions with 21,062 answers. The answers falls into three classes: Good, Bad, and Potential, accounting for 51%, 39%, and 10% respectively. The statistics of the dataset are summarized in Table 1, where #question/answer denotes the number of questions/answers, and length stands for the average number of answers for a question. Competitor Methods: We compare our approach against the following competitor methods: SVM (Huang et al., 2007): An SVM-based method with bag-of-words (textual features), nontextual features, and features based on topic model (i.e., latent Dirichlet allocation, LDA). CRF (Ding et al., 2008): A CRF-based method using the same features as the SVM approach. DBN (Wang et al., 2010): Taking bag-of-words representation, the method applies deep belief nets to learning the distributed representation of QA pair, and predicts the class of answers using a logistic regression classifier on the top layer. mDBN (Hu et al., 2013): In contrast to DBN, multimodal DBN learns the joint representations of textual features and non-textual features rather than bag-of-words. CNN: Using word embedding, the CNNs based model in Hu et al. (2014) is used to learn the representations of questions and answer</context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin yew Lin, and Xiaoyan Zhu. 2008. Using conditional random fields to extract contexts and answers of questions from online forums. In In Proceedings of ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Graves</author>
</authors>
<title>Generating sequences with recurrent neural networks.</title>
<date>2013</date>
<tech>CoRR, abs/1308.0850.</tech>
<contexts>
<context position="9327" citStr="Graves (2013)" startWordPosition="1503" endWordPosition="1504"> Learning Based on the joint representation of QA pair, the LSTM unit of our model performs answer sequence learning to model semantic links between continuous answers. Unlike the traditional recurrent unit, the LSTM unit modulates the memory at each time step, instead of overwriting the states. The key component of LSTM unit is the memory cell ct which has a state over time, and the LSTM unit decides to modify and add the memory in the cell via the sigmoidal gates: input gate it, forget gate ft and output gate ot. The implementation of the LSTM unit in our study is close the one discussed by Graves (2013). Given the joint representation pt at time t, the memory cell ct is updated by the input gate’s activation it and the forget gate’s activation ft. The updating equation is given by Eq. 3: ct = ftct−1+ittanh(Wxcpt+Whcht−1+bc) (3) Data #question #answer length training 2600 16541 6.36 development 300 1645 5.48 test 329 1976 6.00 all 3229 21062 6.00 Table 1: Statistics of experimental dataset The LSTM unit keeps to update the context by discarding the useless context in forget gate ft and adding new content from input gate it. The extents to modulate context for these two gates are computed as E</context>
</contexts>
<marker>Graves, 2013</marker>
<rawString>Alex Graves. 2013. Generating sequences with recurrent neural networks. CoRR, abs/1308.0850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey E Hinton</author>
<author>Nitish Srivastava</author>
</authors>
<title>Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.</title>
<date>2012</date>
<location>CoRR, abs/1207.0580.</location>
<marker>Hinton, Srivastava, 2012</marker>
<rawString>Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2012. Improving neural networks by preventing co-adaptation of feature detectors. CoRR, abs/1207.0580.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sepp Hochreiter</author>
<author>Yoshua Bengio</author>
<author>Paolo Frasconi</author>
<author>J¨urgen Schmidhuber</author>
</authors>
<title>Gradient flow in recurrent nets: the difficulty of learning long-term dependencies.</title>
<date>2001</date>
<contexts>
<context position="3131" citStr="Hochreiter et al., 2001" startWordPosition="483" endWordPosition="486"> a5 there&apos;s always a place for improvement. lol,. Figure 1: An Example of the Answer Sequence for a Question. The dashed arrows depict the relationships of the answers in the sequence. semantic correlations embedded in the answer sequence of a question are ignored, while they are very important for answer selection. Figure 1 is a example to show the relationship of answers in the sequence for a given question. Intuitively, other answers of the question are beneficial to judge the quality of the current answer. Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LSTM) (Hochreiter et al., 2001), has been proved superiority in various tasks (Sutskever et al., 2014; Srivastava et al., 2015) and it models long term and short term information of the sequence. And also, there are some works on using convolutional neural networks (CNNs) to learn the representations of sentence or short text, which achieve state-of-the-art performance on sentiment classification (Kim, 2014) and short text matching (Hu et al., 2014). In this paper, we address the answer selection problem as a sequence labeling task, which identifies the matching quality of each answer in the answer sequence of a question. F</context>
</contexts>
<marker>Hochreiter, Bengio, Frasconi, Schmidhuber, 2001</marker>
<rawString>Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J¨urgen Schmidhuber. 2001. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haifeng Hu</author>
<author>Bingquan Liu</author>
<author>Baoxun Wang</author>
<author>Ming Liu</author>
<author>Xiaolong Wang</author>
</authors>
<title>Multimodal dbn for predicting high-quality answers in cqa portals.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1802" citStr="Hu et al., 2013" startWordPosition="260" endWordPosition="263">mation retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone can suggest a good tailor shop (preferably Philippine nationality) in Qatar? i heard there&apos;s one over at Al Saad. just not sure the details... thanks! a1 There are a lot of tailor shops, it depends on what you want! a2 Sterling Tailors in Barwa Village, it is run by indians and sri lankans but service is good. I&apos;ve seen some filipinos who are taking orders from them. Just Check it out... a3 thanks. will def check &apos;em out.</context>
<context position="11957" citStr="Hu et al., 2013" startWordPosition="1953" endWordPosition="1956">titor Methods: We compare our approach against the following competitor methods: SVM (Huang et al., 2007): An SVM-based method with bag-of-words (textual features), nontextual features, and features based on topic model (i.e., latent Dirichlet allocation, LDA). CRF (Ding et al., 2008): A CRF-based method using the same features as the SVM approach. DBN (Wang et al., 2010): Taking bag-of-words representation, the method applies deep belief nets to learning the distributed representation of QA pair, and predicts the class of answers using a logistic regression classifier on the top layer. mDBN (Hu et al., 2013): In contrast to DBN, multimodal DBN learns the joint representations of textual features and non-textual features rather than bag-of-words. CNN: Using word embedding, the CNNs based model in Hu et al. (2014) is used to learn the representations of questions and answers, and a logistic regression classifier is used to predict the class of answers. Evaluation Metrics: The evaluation metrics include Macro − precision(P), Macro − recall(R), Macro − F1(F1), and F1 scores of the individual classes. According to the evaluation results on the development set, all the hyperparameters are optimized on </context>
</contexts>
<marker>Hu, Liu, Wang, Liu, Wang, 2013</marker>
<rawString>Haifeng Hu, Bingquan Liu, Baoxun Wang, Ming Liu, and Xiaolong Wang. 2013. Multimodal dbn for predicting high-quality answers in cqa portals. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baotian Hu</author>
<author>Zhengdong Lu</author>
<author>Hang Li</author>
<author>Qingcai Chen</author>
</authors>
<title>Convolutional neural network architectures for matching natural language sentences.</title>
<date>2014</date>
<booktitle>In Advances in Neural Information Processing Systems 27,</booktitle>
<pages>2042--2050</pages>
<contexts>
<context position="3553" citStr="Hu et al., 2014" startWordPosition="552" endWordPosition="555">er answers of the question are beneficial to judge the quality of the current answer. Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LSTM) (Hochreiter et al., 2001), has been proved superiority in various tasks (Sutskever et al., 2014; Srivastava et al., 2015) and it models long term and short term information of the sequence. And also, there are some works on using convolutional neural networks (CNNs) to learn the representations of sentence or short text, which achieve state-of-the-art performance on sentiment classification (Kim, 2014) and short text matching (Hu et al., 2014). In this paper, we address the answer selection problem as a sequence labeling task, which identifies the matching quality of each answer in the answer sequence of a question. Firstly, CNNs are used to learn the joint representation of question answer (QA) pair. Then the learnt joint repre713 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 713–718, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics sentations are used as inputs</context>
<context position="6112" citStr="Hu et al. (2014)" startWordPosition="957" endWordPosition="960">rom the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A archives via means of distributed representations. The work in Hu et al. (2014) demonstrated that 2-dimensional convolutional sentence models can represent the hierarchical structures of sentences and capture rich matching patterns between two language objects. 1http://alt.qcri.org/semeval2015/task3/ 3 Approach We consider the answer selection problem in CQA as a sequence labeling task. To label the matching quality of each answer for a given question, our approach models the semantic links between successive answers, as well as the semantic relevance between question and answer. Figure 2 summarizes the recurrent architecture of our model (RCNN). The motivation of R-CNN </context>
<context position="12165" citStr="Hu et al. (2014)" startWordPosition="1985" endWordPosition="1988">topic model (i.e., latent Dirichlet allocation, LDA). CRF (Ding et al., 2008): A CRF-based method using the same features as the SVM approach. DBN (Wang et al., 2010): Taking bag-of-words representation, the method applies deep belief nets to learning the distributed representation of QA pair, and predicts the class of answers using a logistic regression classifier on the top layer. mDBN (Hu et al., 2013): In contrast to DBN, multimodal DBN learns the joint representations of textual features and non-textual features rather than bag-of-words. CNN: Using word embedding, the CNNs based model in Hu et al. (2014) is used to learn the representations of questions and answers, and a logistic regression classifier is used to predict the class of answers. Evaluation Metrics: The evaluation metrics include Macro − precision(P), Macro − recall(R), Macro − F1(F1), and F1 scores of the individual classes. According to the evaluation results on the development set, all the hyperparameters are optimized on the training set. Model Architecture and Training Details: The CNNs of our model for QA joint representation learning have 3 hidden layers for modeling question and answer sentence respectively, in which each</context>
</contexts>
<marker>Hu, Lu, Li, Chen, 2014</marker>
<rawString>Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. In Advances in Neural Information Processing Systems 27, pages 2042–2050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jizhou Huang</author>
<author>Ming Zhou</author>
<author>Dan Yang</author>
</authors>
<title>Extracting chatbot knowledge from online discussion forums.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI’07,</booktitle>
<pages>423--428</pages>
<contexts>
<context position="4725" citStr="Huang et al. (2007)" startWordPosition="733" endWordPosition="736">ional Linguistics sentations are used as inputs of LSTM to predict the quality (e.g., Good, Bad and Potential) of each answer in the answer sequence. Experiments conducted on the CQA dataset of the answer selection task in SemEval-20151 show that the proposed approach outperforms other state-of-the-art approaches. 2 Related Work question answer-sequence LSTM CNNs Figure 2: The architecture of R-CNN Prior studies on answer selection generally treated this challenge as a classification problem via employing machine learning methods, which rely on exploring various features to represent QA pair. Huang et al. (2007) integrated textual features with structural features of forum threads to represent the candidate QA pairs, and used support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also use</context>
<context position="11446" citStr="Huang et al., 2007" startWordPosition="1872" endWordPosition="1875">ets: training, development, and test sets, question answer conv&amp;pooling Encoding É É P(y1, ..., yT |c, p1, ..., pt−1) = T H p(yt|c, y1, ..., yt−1) t=1 (8) 715 and contains 3,229 questions with 21,062 answers. The answers falls into three classes: Good, Bad, and Potential, accounting for 51%, 39%, and 10% respectively. The statistics of the dataset are summarized in Table 1, where #question/answer denotes the number of questions/answers, and length stands for the average number of answers for a question. Competitor Methods: We compare our approach against the following competitor methods: SVM (Huang et al., 2007): An SVM-based method with bag-of-words (textual features), nontextual features, and features based on topic model (i.e., latent Dirichlet allocation, LDA). CRF (Ding et al., 2008): A CRF-based method using the same features as the SVM approach. DBN (Wang et al., 2010): Taking bag-of-words representation, the method applies deep belief nets to learning the distributed representation of QA pair, and predicts the class of answers using a logistic regression classifier on the top layer. mDBN (Hu et al., 2013): In contrast to DBN, multimodal DBN learns the joint representations of textual features</context>
</contexts>
<marker>Huang, Zhou, Yang, 2007</marker>
<rawString>Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Extracting chatbot knowledge from online discussion forums. In Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI’07, pages 423–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
<author>Joon Ho Lee</author>
</authors>
<title>Finding similar questions in large question and answer archives.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM ’05,</booktitle>
<pages>84--90</pages>
<contexts>
<context position="5418" citStr="Jeon et al., 2005" startWordPosition="846" endWordPosition="849">present the candidate QA pairs, and used support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a que</context>
</contexts>
<marker>Jeon, Croft, Lee, 2005</marker>
<rawString>Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005. Finding similar questions in large question and answer archives. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM ’05, pages 84–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification.</title>
<date>2014</date>
<location>CoRR, abs/1408.5882.</location>
<contexts>
<context position="3511" citStr="Kim, 2014" startWordPosition="546" endWordPosition="547">r a given question. Intuitively, other answers of the question are beneficial to judge the quality of the current answer. Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LSTM) (Hochreiter et al., 2001), has been proved superiority in various tasks (Sutskever et al., 2014; Srivastava et al., 2015) and it models long term and short term information of the sequence. And also, there are some works on using convolutional neural networks (CNNs) to learn the representations of sentence or short text, which achieve state-of-the-art performance on sentiment classification (Kim, 2014) and short text matching (Hu et al., 2014). In this paper, we address the answer selection problem as a sequence labeling task, which identifies the matching quality of each answer in the answer sequence of a question. Firstly, CNNs are used to learn the joint representation of question answer (QA) pair. Then the learnt joint repre713 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 713–718, Beijing, China, July 26-31, 2015. c�2015 Association for Computational</context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. CoRR, abs/1408.5882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs M`arquez</author>
<author>James Glass</author>
<author>Walid Magdy</author>
<author>Alessandro Moschitti</author>
<author>Preslav Nakov</author>
<author>Bilal Randeree</author>
</authors>
<title>Semeval-2015 task 3: Answer selection in community question answering.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015).</booktitle>
<marker>M`arquez, Glass, Magdy, Moschitti, Nakov, Randeree, 2015</marker>
<rawString>Llu´ıs M`arquez, James Glass, Walid Magdy, Alessandro Moschitti, Preslav Nakov, and Bilal Randeree. 2015. Semeval-2015 task 3: Answer selection in community question answering. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<location>CoRR, abs/1301.3781.</location>
<contexts>
<context position="13896" citStr="Mikolov et al., 2013" startWordPosition="2287" endWordPosition="2290">12) are used Methods P R F1 SVM 50.10 54.43 52.14 CRF 53.89 54.26 53.40 DBN 55.22 53.80 54.07 mDBN 56.11 53.95 54.29 CNN 55.33 54.73 54.42 R-CNN 56.41 56.16 56.14 Table 2: Macro-averaged results(%) during the training procedure. The learning rate A is initialized to be 0.01 and is updated dynamically according to the gradient descent using the ADADELTA method (Zeiler, 2012). The activation functions (σ, γ) in our model adopt the rectified linear unit (ReLU) (Dahl et al., 2013). In addition, the word embeddings for encoding sentences are pre-trained with the unsupervised neural language model (Mikolov et al., 2013) on the Qatar Living data2. 4.2 Results and Analysis Table 2 summarizes the Macro-averaged results. The F1 scores of the individual classes are presented in Table 3. It is clear to see that the proposed R-CNN approach outperforms the competitor methods over the Macro-averaged metrics as expected from Table 2. The main reason lies in that R-CNN takes advantages of the semantic correlations between successive answers by LSTM, in addition to the semantic relationships between question and answer. The joint representation of QA pair learnt by CNNs also captures richer matching patterns between que</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question answer classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>776--783</pages>
<contexts>
<context position="1498" citStr="Moschitti et al., 2007" startWordPosition="212" endWordPosition="215">er. Experiments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach. 1 Introduction Answer selection in community question answering (CQA), which recognizes high-quality responses to obtain useful question-answer pairs, is greatly valuable for knowledge base construction and information retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone can suggest a good tailor shop (preferably Philippine nationality) in Qatar? i heard there&apos;s one over at Al Saad. just no</context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting syntactic and shallow semantic kernels for question answer classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 776–783.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chirag Shah</author>
<author>Jefferey Pomerantz</author>
</authors>
<title>Evaluating and predicting answer quality in community qa.</title>
<date>2010</date>
<booktitle>In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’10,</booktitle>
<pages>411--418</pages>
<contexts>
<context position="1405" citStr="Shah and Pomerantz, 2010" startWordPosition="197" endWordPosition="200">LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach. 1 Introduction Answer selection in community question answering (CQA), which recognizes high-quality responses to obtain useful question-answer pairs, is greatly valuable for knowledge base construction and information retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone can suggest a good tailor sh</context>
<context position="4954" citStr="Shah and Pomerantz (2010)" startWordPosition="769" endWordPosition="772">SemEval-20151 show that the proposed approach outperforms other state-of-the-art approaches. 2 Related Work question answer-sequence LSTM CNNs Figure 2: The architecture of R-CNN Prior studies on answer selection generally treated this challenge as a classification problem via employing machine learning methods, which rely on exploring various features to represent QA pair. Huang et al. (2007) integrated textual features with structural features of forum threads to represent the candidate QA pairs, and used support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and per</context>
</contexts>
<marker>Shah, Pomerantz, 2010</marker>
<rawString>Chirag Shah and Jefferey Pomerantz. 2010. Evaluating and predicting answer quality in community qa. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’10, pages 411–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitish Srivastava</author>
<author>Elman Mansimov</author>
<author>Ruslan Salakhutdinov</author>
</authors>
<title>Unsupervised learning of video representations using lstms.</title>
<date>2015</date>
<location>CoRR, abs/1502.04681.</location>
<contexts>
<context position="3227" citStr="Srivastava et al., 2015" startWordPosition="499" endWordPosition="502">r a Question. The dashed arrows depict the relationships of the answers in the sequence. semantic correlations embedded in the answer sequence of a question are ignored, while they are very important for answer selection. Figure 1 is a example to show the relationship of answers in the sequence for a given question. Intuitively, other answers of the question are beneficial to judge the quality of the current answer. Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LSTM) (Hochreiter et al., 2001), has been proved superiority in various tasks (Sutskever et al., 2014; Srivastava et al., 2015) and it models long term and short term information of the sequence. And also, there are some works on using convolutional neural networks (CNNs) to learn the representations of sentence or short text, which achieve state-of-the-art performance on sentiment classification (Kim, 2014) and short text matching (Hu et al., 2014). In this paper, we address the answer selection problem as a sequence labeling task, which identifies the matching quality of each answer in the answer sequence of a question. Firstly, CNNs are used to learn the joint representation of question answer (QA) pair. Then the l</context>
</contexts>
<marker>Srivastava, Mansimov, Salakhutdinov, 2015</marker>
<rawString>Nitish Srivastava, Elman Mansimov, and Ruslan Salakhutdinov. 2015. Unsupervised learning of video representations using lstms. CoRR, abs/1502.04681.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Sutskever</author>
<author>Oriol Vinyals</author>
<author>Quoc V Le</author>
</authors>
<title>Sequence to sequence learning with neural networks.</title>
<date>2014</date>
<tech>CoRR, abs/1409.3215.</tech>
<contexts>
<context position="3201" citStr="Sutskever et al., 2014" startWordPosition="495" endWordPosition="498">f the Answer Sequence for a Question. The dashed arrows depict the relationships of the answers in the sequence. semantic correlations embedded in the answer sequence of a question are ignored, while they are very important for answer selection. Figure 1 is a example to show the relationship of answers in the sequence for a given question. Intuitively, other answers of the question are beneficial to judge the quality of the current answer. Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LSTM) (Hochreiter et al., 2001), has been proved superiority in various tasks (Sutskever et al., 2014; Srivastava et al., 2015) and it models long term and short term information of the sequence. And also, there are some works on using convolutional neural networks (CNNs) to learn the representations of sentence or short text, which achieve state-of-the-art performance on sentiment classification (Kim, 2014) and short text matching (Hu et al., 2014). In this paper, we address the answer selection problem as a sequence labeling task, which identifies the matching quality of each answer in the answer sequence of a question. Firstly, CNNs are used to learn the joint representation of question an</context>
</contexts>
<marker>Sutskever, Vinyals, Le, 2014</marker>
<rawString>Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. CoRR, abs/1409.3215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baoxun Wang</author>
<author>Bingquan Liu</author>
<author>Chengjie Sun</author>
<author>Xiaolong Wang</author>
<author>Lin Sun</author>
</authors>
<title>Extracting chinese question-answer pairs from online forums.</title>
<date>2009</date>
<booktitle>In IEEE International Conference on Systems, Man, and Cybernetics (SMC),</booktitle>
<pages>1159--1164</pages>
<contexts>
<context position="1377" citStr="Wang et al., 2009" startWordPosition="193" endWordPosition="196">g shortterm memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach. 1 Introduction Answer selection in community question answering (CQA), which recognizes high-quality responses to obtain useful question-answer pairs, is greatly valuable for knowledge base construction and information retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone </context>
</contexts>
<marker>Wang, Liu, Sun, Wang, Sun, 2009</marker>
<rawString>Baoxun Wang, Bingquan Liu, Chengjie Sun, Xiaolong Wang, and Lin Sun. 2009a. Extracting chinese question-answer pairs from online forums. In IEEE International Conference on Systems, Man, and Cybernetics (SMC), pages 1159–1164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Wang</author>
<author>Zhaoyan Ming</author>
<author>Tat-Seng Chua</author>
</authors>
<title>A syntactic tree matching approach to finding similar questions in community-based qa services.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="1377" citStr="Wang et al., 2009" startWordPosition="193" endWordPosition="196">g shortterm memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach. 1 Introduction Answer selection in community question answering (CQA), which recognizes high-quality responses to obtain useful question-answer pairs, is greatly valuable for knowledge base construction and information retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone </context>
</contexts>
<marker>Wang, Ming, Chua, 2009</marker>
<rawString>Kai Wang, Zhaoyan Ming, and Tat-Seng Chua. 2009b. A syntactic tree matching approach to finding similar questions in community-based qa services. In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09, pages 187–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baoxun Wang</author>
<author>Xiaolong Wang</author>
<author>Chengjie Sun</author>
<author>Bingquan Liu</author>
<author>Lin Sun</author>
</authors>
<title>Modeling semantic relevance for question-answer pairs in web social communities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1230--1238</pages>
<contexts>
<context position="1784" citStr="Wang et al., 2010" startWordPosition="256" endWordPosition="259">struction and information retrieval systems. To recognize matching answers for a question, typical approaches model semantic matching between question and answer by exploring various features (Wang et al., 2009a; Shah and Pomerantz, 2010). Some studies exploit syntactic tree structures (Wang et al., 2009b; Moschitti et al., 2007) to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches (Wang et al., 2010; Hu et al., 2013) are proposed to learn the distributed representation of question-answer pair directly. One disadvantage of these approaches lies in that ∗* Corresponding author Q Hi. anyone can suggest a good tailor shop (preferably Philippine nationality) in Qatar? i heard there&apos;s one over at Al Saad. just not sure the details... thanks! a1 There are a lot of tailor shops, it depends on what you want! a2 Sterling Tailors in Barwa Village, it is run by indians and sri lankans but service is good. I&apos;ve seen some filipinos who are taking orders from them. Just Check it out... a3 thanks. will </context>
<context position="5652" citStr="Wang et al. (2010)" startWordPosition="885" endWordPosition="888"> quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A archives via means of distributed representations. The work in Hu et al. (2014) demonstrated that 2-dimensional convolutional sentence models can represent the hierarchical structures of sentences and capture rich match</context>
<context position="11715" citStr="Wang et al., 2010" startWordPosition="1914" endWordPosition="1917">l, accounting for 51%, 39%, and 10% respectively. The statistics of the dataset are summarized in Table 1, where #question/answer denotes the number of questions/answers, and length stands for the average number of answers for a question. Competitor Methods: We compare our approach against the following competitor methods: SVM (Huang et al., 2007): An SVM-based method with bag-of-words (textual features), nontextual features, and features based on topic model (i.e., latent Dirichlet allocation, LDA). CRF (Ding et al., 2008): A CRF-based method using the same features as the SVM approach. DBN (Wang et al., 2010): Taking bag-of-words representation, the method applies deep belief nets to learning the distributed representation of QA pair, and predicts the class of answers using a logistic regression classifier on the top layer. mDBN (Hu et al., 2013): In contrast to DBN, multimodal DBN learns the joint representations of textual features and non-textual features rather than bag-of-words. CNN: Using word embedding, the CNNs based model in Hu et al. (2014) is used to learn the representations of questions and answers, and a logistic regression classifier is used to predict the class of answers. Evaluati</context>
</contexts>
<marker>Wang, Wang, Sun, Liu, Sun, 2010</marker>
<rawString>Baoxun Wang, Xiaolong Wang, Chengjie Sun, Bingquan Liu, and Lin Sun. 2010. Modeling semantic relevance for question-answer pairs in web social communities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1230–1238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaobing Xue</author>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
</authors>
<title>Retrieval models for question and answer archives.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’08,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="5436" citStr="Xue et al., 2008" startWordPosition="850" endWordPosition="853">te QA pairs, and used support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A arc</context>
</contexts>
<marker>Xue, Jeon, Croft, 2008</marker>
<rawString>Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008. Retrieval models for question and answer archives. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’08, pages 475–482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Yu</author>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
<author>Stephen Pulman</author>
</authors>
<title>Deep learning for answer sentence selection.</title>
<date>2014</date>
<location>CoRR, abs/1412.1632.</location>
<contexts>
<context position="5941" citStr="Yu et al. (2014)" startWordPosition="929" endWordPosition="932">d for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A archives via means of distributed representations. The work in Hu et al. (2014) demonstrated that 2-dimensional convolutional sentence models can represent the hierarchical structures of sentences and capture rich matching patterns between two language objects. 1http://alt.qcri.org/semeval2015/task3/ 3 Approach We consider the answer selection problem in CQA as a sequence labeling task. To label the matching quality of each answer for a given question, our approach models the semantic links between succ</context>
</contexts>
<marker>Yu, Hermann, Blunsom, Pulman, 2014</marker>
<rawString>Lei Yu, Karl Moritz Hermann, Phil Blunsom, and Stephen Pulman. 2014. Deep learning for answer sentence selection. CoRR, abs/1412.1632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Zeiler</author>
</authors>
<title>ADADELTA: an adaptive learning rate method.</title>
<date>2012</date>
<location>CoRR, abs/1212.5701.</location>
<contexts>
<context position="13651" citStr="Zeiler, 2012" startWordPosition="2247" endWordPosition="2248">ate, output gate, and memory cell are all set to 360. Stochastic gradient descent (SGD) algorithm via back-propagation through time is used to train the model. To prevent serious overfitting, early stopping and dropout (Hinton et al., 2012) are used Methods P R F1 SVM 50.10 54.43 52.14 CRF 53.89 54.26 53.40 DBN 55.22 53.80 54.07 mDBN 56.11 53.95 54.29 CNN 55.33 54.73 54.42 R-CNN 56.41 56.16 56.14 Table 2: Macro-averaged results(%) during the training procedure. The learning rate A is initialized to be 0.01 and is updated dynamically according to the gradient descent using the ADADELTA method (Zeiler, 2012). The activation functions (σ, γ) in our model adopt the rectified linear unit (ReLU) (Dahl et al., 2013). In addition, the word embeddings for encoding sentences are pre-trained with the unsupervised neural language model (Mikolov et al., 2013) on the Qatar Living data2. 4.2 Results and Analysis Table 2 summarizes the Macro-averaged results. The F1 scores of the individual classes are presented in Table 3. It is clear to see that the proposed R-CNN approach outperforms the competitor methods over the Macro-averaged metrics as expected from Table 2. The main reason lies in that R-CNN takes adv</context>
</contexts>
<marker>Zeiler, 2012</marker>
<rawString>Matthew D. Zeiler. 2012. ADADELTA: an adaptive learning rate method. CoRR, abs/1212.5701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangyou Zhou</author>
<author>Li Cai</author>
<author>Jun Zhao</author>
<author>Kang Liu</author>
</authors>
<title>Phrase-based translation model for question retrieval in community question answer archives.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>653--662</pages>
<contexts>
<context position="5456" citStr="Zhou et al., 2011" startWordPosition="854" endWordPosition="857">sed support vector machine (SVM) to classify the candidate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (LR) classifier with user metadata to predict the quality of answers in CQA. Ding et al. (2008) proposed an approach based on conditional random fields (CRF), which can capture contextual features from the answer sequence for the semantic matching between question and answer. Additionally, the translation-based language model was also used for QA matching by transferring the answer to the corresponding question (Jeon et al., 2005; Xue et al., 2008; Zhou et al., 2011). The translation-based methods suffer from the informal words or phrases in Q&amp;A archives, and perform less applicability in new domains. In contrast to symbolic representation, Wang et al. (2010) proposed a deep belief nets (DBN) based semantic relevance model to learn the distributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sentence representation models have achieved successes in neural language processing (NLP) tasks. Yu et al. (2014) proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A archives via means of d</context>
</contexts>
<marker>Zhou, Cai, Zhao, Liu, 2011</marker>
<rawString>Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu. 2011. Phrase-based translation model for question retrieval in community question answer archives. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 653–662.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>