<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000250">
<note confidence="0.7828566">
ON THE EXISTENCE OF PRIMITIVE MEANING UNITS
Sharon C. Salveter
Computer Science Department
SUNY Stony Brook
Stony Brook, N.Y. 11794
</note>
<sectionHeader confidence="0.834028" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999834923076923">
Knowledge representation schemes are either based on
a set of primitives or not. The decision of whether
or not to have a primitive-based scheme is crucial
since it affects the knowledge that is stored and how
that knowledge may be processed. We suggest that a
knowledge representation scheme may not initially have
primitives, but may evolve into a primitive-based
scheme by inferring a set of primitive meaning units
based on previous experience. We describe a program
that infers its own primitive set and discuss how the
inferred primitives may affect the organization of
existing information and the subsequent incorporation
of new information.
</bodyText>
<listItem confidence="0.533769">
1. DECIDING HOW TO REPRESENT KNOWLEDGE
</listItem>
<bodyText confidence="0.999925090909091">
A crucial decision in the design of a knowledge repre-
sentation is whether to base it on primitives. A prim-
itive-based scheme postulates a pre-defined set of mean-
ing structures, combination rules and procedures. The
primitives may combine according to the rules into more
complex representational structures, the procedures
interpret what those structures mean. A primitive-free
scheme, on the other hand, does not build complex struc-
tures from standard building blocks; instead, informa-
tion is gathered from any available source, such as
input and information in previously built meaning
structures.
A hybrid approach postulates a small set of pre-defined
meaning units that may be used if applicable and con-
venient, but is not limited to those units. Such a
representation scheme is not truly primitive-based
since the word &amp;quot;primitive&amp;quot; implies a complete set of
pre-defined meaning units that are the only ones avail-
able for construction. However, we will call this hy-
brid approach a primitive-based scheme, since it does
postulate some pre-defined meaning units that are used
in the same manner as primitives.
</bodyText>
<sectionHeader confidence="0.840095" genericHeader="method">
2. WHAT IS A PRIMITIVE?
</sectionHeader>
<bodyText confidence="0.999391333333333">
All representation systems must have primitives of some
sort, and we can see different types of primitives at
different levels. Some primitives are purely structural
and have little inherent associated semantics. That is,
the primitives are at such a low level that there are
no semantics pre-defined for the primitives other than
how they may combine. We call these primitives struc-
tural primitives. On the other hand, semantic primi-
tives have both structural and semantic components.
The structures are defined on a higher level and come
with pre-attached procedures (their semantics) that
indicate what they &amp;quot;mean,&amp;quot; that is, how they are to be
meaningfully processed. What makes primitives semantic
is this association of procedures with structures, since
the procedures operating on the structures give them
meaning. In a primitive-based scheme, we design both
a set of structures and their semantics to describe a
specific environment.
There are two problems with pre-defining primitives.
First, the choice of primitives may be structurally
inadequate. That is, they may limit what can be repre-
sented. For example, if we have a set of rectilinear
primitives, it is difficult to represent objects in a
sphere world. The second problem may arise even if we
have a structurally adequate set of primitives. In this
case the primitives may be defined on too low a level
to be useful. For example, we may define atoms as our
primitives and specify how atoms interact as their
semantics. Now we may adequately describe a rubber ball
structurally, but we will have great difficulty describ-
ing the action of a rolling ball. We would like a set
of semantic primitives at a level both structurally and
semantically appropriate to the world we are describing.
</bodyText>
<listItem confidence="0.758916">
3. INFERRING AN APPROPRIATE PRIMITIVE SET
</listItem>
<bodyText confidence="0.9999612">
Schank [19721 has proposed a powerful primitive-based
knowledge representation scheme called conceptual
dependency. Several natural language understanding
programs have been written that use conceptual depend-
ency as their underlying method of knowledge represen-
tation. These programs are among the most successful
at natural language understanding. Although Schenk
does not claim that his primitives constitute the only
possible set, he does claim that some set of primitives
is necessary in a general knowledge representation
scheme.
Our claim is that any advanced, sophisticated or rich
memory is likely to be decomposable into primitives,
since they seem to be a reasonable and efficient method
for storing knowledge. However, this set of after-the-
fact primitives need not be pre-defined or innate to
a representation scheme; the primitives may be learned
and therefore vary depending on early experiences.
We really have two problems: inferring from early
experiences a set of structural primitives at an appro-
priate descriptive level and learning the semantics to
associate with these structural primitives. In this
paper we shall only address the first problem. Even
though we will not address the semantics attachment
task, we will describe a method that yields the minimal
structural units with which we will want to associate
semantics. We feel that since the inferred structural
primitives will be appropriate for describing a par-
ticular environment, they will have appropriate seman-
tics and that unlike pre-defined primitives, these
learned primitives are guaranteed to be at the appro-
priate level for a given descriptive task. Identify-
ing the structural primitives is the first step (prob-
ably a parallel step) in identifying semantic primi-
tives, which are composed of structural units and
associated procedures that give the structures meaning.
This thesis developed while investigating learning
strategies. Moran [Salveter 19791 is a program that
learns frame-like structures that represent verb mean-
ings. We chose a simple representative frame-like
knowledge representation for Moran to learn. We chose
a primitive-free scheme in order not to determine the
level of detail at which the world must be described.
As Moran learned, its knowledge base, the verb world,
evolved from nothing to a rich interconnection of frame
structures that represent various senses of different
root verbs. When the verb world was &amp;quot;rich enough&amp;quot; (a
heuristic decision), Moran detected substructures,
which we call building blocks, that were frequently
used in the representations of many verb senses across
root verb boundaries. These building blocks can be
used as after-the-fact primitives. The knowledge
representation scheme thus evolves from a primitive-
free state to a hybrid state. Importantly, the build-
ing blocks are at the level of description appropriate
</bodyText>
<page confidence="0.995637">
13
</page>
<bodyText confidence="0.999935714285714">
to how the world was described to Moran. Now Moraa may
reorganize the interconnected frames that maks up the
verb world with respect to the building blocks. This
reorganization results in a uniform identification of the
commonalities and differences of the various meanings
of different root verbs. As ;earning continues the new
knowledge incorporated into the verb world will also be
stored, as much as possible, with respect to the build-
ing blocks; when processing subsequent input, Moran
first tries to use a combination of the building blocks
to represent the meaning of each new situation it
encounters.
A set of building blocks, once inferred, need not be
fixed forever; the search for more building blocks may
continue as the knowledge base becomes richer. A
different, &amp;quot;better,&amp;quot; set of building blocks may be in-
ferred later from the richer knowledge and all knowledge
reorganized with respect to them. If we can assume that
initial inputs are representative of future inputs,
subsequent processing will approach that of primitive-
based systems.
</bodyText>
<sectionHeader confidence="0.84824" genericHeader="method">
4. AN OVERVIEW OF MORAN
</sectionHeader>
<bodyText confidence="0.980727476190476">
Moran is able to &amp;quot;view&amp;quot; a world that is a room; the
room contains people and objects. Moran has pre-defined
knowledge of the contents of the room. For example, it
knows that lamps, tables and Chairs are all types of
furniture, Figaro is a male, Ristin is a female, Ristin
and Figaro are human. As input to a learning trial,
Moran is presented with:
3) a parsed sentence that describes the action that
occured in the two-snapshot sequence.
The learning task is to associate a frame-like structure,
called a Conceptual Meaning Structure (CMS), with each
root verb it encounters. A CMS is a directed acyclic
graph that represents the types of entities that partic-
ipate in an action and the changes the entities undergo
during the action.
The CMSs are organized so that the similarities among
various senses of a given root verb are explicitly rep-
resented by sharing nodes in a graph. A CMS is organ-
ized into two parts: an arguments graph and an effects
graph. The arguments graph stores cases and case slot
restrictions, the effects graph stores a description of
what happens to the entities described in the arguments
graph when an action &amp;quot;takes place.&amp;quot;
A simplified example of a possible CMS for the verb
&amp;quot;throw&amp;quot; is shown in Figure 1. Sense 1, composed of argu-
ment and effect nodes labelled A, W and X can represent
&amp;quot;Mary throws the ball.&amp;quot; It show that during sense 1 of
the action &amp;quot;throw,&amp;quot; a human agent remains at a location
while a physical object changes location from where the
Agent is to another location. The Agent changes from
being in a state of physical contact with the Object to
not being in physical contact with it. Sense 2 is com-
posed of nodes labelled A, B, W and Y; it might repre-
sent &amp;quot;Figaro throws the ball to Zistin.&amp;quot; Sense 3, com-
posed of nodes labelled A, B, C, W, X and Z, could rep-
&apos;resent &amp;quot;Sharon threw the terminal at Raphael.&amp;quot;
1) a snapshot of the room just before an action Moran infers a CMS for each root verb it encounters.
occurs, Although similarities among different senses of the
same root verb are recognized, similarities are not
2) a snapshot of the room just after the action is recognized across CMS boundaries; true synonyms might
completed and have identical graphs, but Moran would have no knowledge
arguments
</bodyText>
<figure confidence="0.97678955">
1,2,3
PREP
INDOBJ
Prespositi
Human
A:
C3
Location
Human
Physobj
Location
Location
2,3
3
AGENT
OBJECT
Cl
C2
effects
1,2,3
</figure>
<table confidence="0.6883136">
1,3 NV 2
AGENT PHYSCONT OBJECT ---&gt; null Y: INDOBJ Al&apos; C2 ---&gt; INDOBJ AT C2
AGENT PHYSCONT OBJECT ---&gt; INDOBJ PHYSCONT OBJECT
3
INDOBJ AT C3 ---&gt; INDOBJ Al&apos; C3
</table>
<figureCaption confidence="0.97533">
Figure 1.
</figureCaption>
<figure confidence="0.909248666666667">
AGENT AT Cl ---&gt; AGENT AT Cl
OBJECT AT Cl ---&gt; OBJECT AT C2
W:
</figure>
<page confidence="0.996074">
14
</page>
<bodyText confidence="0.9637525">
of the similarity. Similarities among verbs that are
close in meaning, but not synonyms, are not represented;
the fact that &amp;quot;move&amp;quot; and &amp;quot;throw&amp;quot; are related is not ob-
vious to Moran.
5. PRELIMINARY RESULTS
A primitive meaning unit, or building block, should be
useful for describing a large number of different mean-
ings. Moran attempts to identify those structures that
have been useful descriptors. At a certain point in the
learning process, currently arbitrarily chosen by the
human trainer, Moran looks for building blocks that have
been used to describe a number of different root verbs.
This search for building blocks crosses CMS boundaries
and occurs only when memory is rich enough for some
global decisions to be made.
Moran was presented with twenty senses of four root
verbs: move, throw, carry and buy. Moran chose the
following effects as building blocks:
</bodyText>
<figure confidence="0.723925363636364">
1) Agent (human) AT Casel (location)
Agent (human) AT Casel (location)
* a human agent remains at a location *
2) Agent (human) AT Casel (location)
Agent (human) AT Case2 (location)
* a human agent changes location *
3) Object (physicalobj) AT Casel (location)
Object (physicalobj) AT Case2 (location)
* a physical object changes location *
4) Agent (human) PHYSICALCONTACT Object (physicalobj)
Agent (human) PHYSICALCONTACT Object (physicalobj)
</figure>
<bodyText confidence="0.995921722222222">
* a human agent remains in physical contact
with a physical object *
Since Moran has only been presented with a small number
of verbs of movement, it is not surprising that the
building blocks it chooses describe Agents and Objects
moving about the environment and their interaction with
each other. A possible criticism is that the chosen
building blocks are artifacts of the particular descrip-
tions that were given to Moran. We feel this is an
advantage rather than a drawback, since Moran must as-
sume that the world is described to it on a level that
will be appropriate for subsequent processing.
In Schank&apos;s conceptual dependency scheme, verbs of move-
ment are often described with PTRANS and PROPEL. It is
interesting that some of the building blocks Moran in-
ferred seem to be subparts of the structures of ?TRANS
and PROPEL. For example, the conceptual dependency for
&amp;quot;X throw Z at Y&amp;quot; is:
</bodyText>
<equation confidence="0.747630333333333">
L Y
X(.---.=) PROPEL 4â€”c= Z
X
</equation>
<bodyText confidence="0.984068538461539">
where X and Y are humans and Z is a physical object. We
see the object, Z, changing from the location of X to
that of Y. Thus, the conceptual dependency subpart:
z
appears to be approximated by building block #3 where
the Object changes location. Moran would recognize
that the location change is from the location of the
Agent to the location of the indirect object by the
interaction of building block #3 with other building
blocks and effects that participate in the action
description.
Similarly, the conceptual dependency for &amp;quot;X move Z to
W&amp;quot; is:
</bodyText>
<equation confidence="0.6737785">
w
x PTRANS z
Hir
lo c (W)
</equation>
<bodyText confidence="0.97207625">
where X and Z have the same restrictions as above and
W is a location. Again we see an object changing loca-
tion; a common acct.:tante in movement and a building
block Moran identified.
</bodyText>
<sectionHeader confidence="0.539848" genericHeader="method">
6. &apos; CONCLUDING REMARKS
</sectionHeader>
<bodyText confidence="0.999940333333333">
We are currently modifying Moran so that the identified
building blocks are used to process subsequent input.
That is, as new situations are encountered, Moran will
try to describe them as much as possible in terms of
the building blocks. It will be interesting to see
how these descriptions differ from the ones Moran would
have constructed if the building blocks had not been
available. We shall also investigate how the existence
of the building blocks affects processing time.
As a cognitive model, inferred primitives may account
for the effects of &amp;quot;bad teaching,&amp;quot; that is, an unfor-
tunate sequence of examples of a new concept. If ex-
amples are so disparate that few building blocks exist,
or so unrepresentative that the derived building blocks
are useless for future inputs, then the after-the-fact
primitives will impede efficient representation. The
knowledge organization will not tie together what we
have experienced in the past or predict that we will
experience in the future. Although the learning pro-
gram could infer more useful building blocks at a later
time, that process is expensive, time-consuming and may
be unable to replace information lost because of poor
building blocks chosen earlier. In general, however,
we must assume that our world is described at a level
appropriate to how we must process it. If that is the
case, then inferring a set of primitives is an advanta-
geous strategy.
</bodyText>
<sectionHeader confidence="0.72898" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.544523">
(Salveter 1979] Inferring conceptual graphs. Cognitive
Science, 1979, 3, 141-166.
[Schenk 1972] Conceptual Dependency: a theory of
natural language understanding. Cognitive
Psychology, 1972, 3, 552-631.
</reference>
<page confidence="0.997342">
15
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.003854">
<title confidence="0.997667">ON THE EXISTENCE OF PRIMITIVE MEANING UNITS</title>
<author confidence="0.999979">Sharon C Salveter</author>
<affiliation confidence="0.988527">Computer Science Department SUNY Stony Brook</affiliation>
<address confidence="0.981198">Stony Brook, N.Y. 11794</address>
<abstract confidence="0.998083663212435">Knowledge representation schemes are either based on a set of primitives or not. The decision of whether or not to have a primitive-based scheme is crucial since it affects the knowledge that is stored and how that knowledge may be processed. We suggest that a knowledge representation scheme may not initially have primitives, but may evolve into a primitive-based scheme by inferring a set of primitive meaning units based on previous experience. We describe a program that infers its own primitive set and discuss how the inferred primitives may affect the organization of existing information and the subsequent incorporation of new information. 1. DECIDING HOW TO REPRESENT KNOWLEDGE A crucial decision in the design of a knowledge representation is whether to base it on primitives. A primitive-based scheme postulates a pre-defined set of meaning structures, combination rules and procedures. The primitives may combine according to the rules into more complex representational structures, the procedures what those structures A scheme, on the other hand, does not build complex structures from standard building blocks; instead, information is gathered from any available source, such as input and information in previously built meaning structures. A hybrid approach postulates a small set of pre-defined meaning units that may be used if applicable and convenient, but is not limited to those units. Such a representation scheme is not truly primitive-based &amp;quot;primitive&amp;quot; implies a complete pre-defined meaning units that are the only ones available for construction. However, we will call this hybrid approach a primitive-based scheme, since it does postulate some pre-defined meaning units that are used in the same manner as primitives. 2. WHAT IS A PRIMITIVE? All representation systems must have primitives of some sort, and we can see different types of primitives at different levels. Some primitives are purely structural and have little inherent associated semantics. That is, the primitives are at such a low level that there are no semantics pre-defined for the primitives other than how they may combine. We call these primitives structural primitives. On the other hand, semantic primitives have both structural and semantic components. The structures are defined on a higher level and come with pre-attached procedures (their semantics) that indicate what they &amp;quot;mean,&amp;quot; that is, how they are to be meaningfully processed. What makes primitives semantic association of procedures with structures, since the procedures operating on the structures give them meaning. In a primitive-based scheme, we design both a set of structures and their semantics to describe a specific environment. There are two problems with pre-defining primitives. First, the choice of primitives may be structurally inadequate. That is, they may limit what can be represented. For example, if we have a set of rectilinear primitives, it is difficult to represent objects in a The second problem may arise even if we have a structurally adequate set of primitives. In this case the primitives may be defined on too low a level be useful. For we may define atoms as our primitives and specify how atoms interact as their Now we may adequately describe ball structurally, but we will have great difficulty describing the action of a rolling ball. We would like a set semantic primitives at a level both structurally semantically appropriate to the world we are describing. 3. INFERRING AN APPROPRIATE PRIMITIVE SET Schank [19721 has proposed a powerful primitive-based knowledge representation scheme called conceptual dependency. Several natural language understanding programs have been written that use conceptual dependency as their underlying method of knowledge representation. These programs are among the most successful natural language understanding. Although does not claim that his primitives constitute the only possible set, he does claim that some set of primitives is necessary in a general knowledge representation scheme. Our claim is that any advanced, sophisticated or rich memory is likely to be decomposable into primitives, since they seem to be a reasonable and efficient method for storing knowledge. However, this set of after-thefact primitives need not be pre-defined or innate to a representation scheme; the primitives may be learned and therefore vary depending on early experiences. We really have two problems: inferring from early experiences a set of structural primitives at an appropriate descriptive level and learning the semantics to associate with these structural primitives. In this we only address the first Even though we will not address the semantics attachment task, we will describe a method that yields the minimal structural units with which we will want to associate We feel that since the structural primitives will be appropriate for describing a particular environment, they will have appropriate semantics and that unlike pre-defined primitives, these learned primitives are guaranteed to be at the appropriate level for a given descriptive task. Identifying the structural primitives is the first step (probably a parallel step) in identifying semantic primitives, which are composed of structural units and associated procedures that give the structures meaning. This thesis developed while investigating learning Moran 19791 is program that learns frame-like structures that represent verb meanings. We chose a simple representative frame-like representation for Moran to learn. We scheme in order not to determine the level of detail at which the world must be described. learned, its knowledge the verb world, evolved from nothing to a rich interconnection of frame structures that represent various senses of different verbs. When the verb world &amp;quot;rich enough&amp;quot; (a decision), Moran substructures, which we call building blocks, that were frequently used in the representations of many verb senses across root verb boundaries. These building blocks can be used as after-the-fact primitives. The knowledge representation scheme thus evolves from a primitivefree state to a hybrid state. Importantly, the building blocks are at the level of description appropriate 13 to how the world was described to Moran. Now Moraa may reorganize the interconnected frames that maks up the verb world with respect to the building blocks. This reorganization results in a uniform identification of the commonalities and differences of the various meanings of different root verbs. As ;earning continues the new knowledge incorporated into the verb world will also be stored, as much as possible, with respect to the building blocks; when processing subsequent input, Moran first tries to use a combination of the building blocks to represent the meaning of each new situation it encounters. A set of building blocks, once inferred, need not be fixed forever; the search for more building blocks may continue as the knowledge base becomes richer. A different, &amp;quot;better,&amp;quot; set of building blocks may be inferred later from the richer knowledge and all knowledge reorganized with respect to them. If we can assume that initial inputs are representative of future inputs, subsequent processing will approach that of primitivebased systems. OVERVIEW OF MORAN Moran is able to &amp;quot;view&amp;quot; a world that is a room; the room contains people and objects. Moran has pre-defined of the contents of the room. For example, knows that lamps, tables and Chairs are all types of furniture, Figaro is a male, Ristin is a female, Ristin and Figaro are human. As input to a learning trial, Moran is presented with: 3) a parsed sentence that describes the action that occured in the two-snapshot sequence. The learning task is to associate a frame-like structure, called a Conceptual Meaning Structure (CMS), with each root verb it encounters. A CMS is a directed acyclic graph that represents the types of entities that participate in an action and the changes the entities undergo during the action. The CMSs are organized so that the similarities among various senses of a given root verb are explicitly represented by sharing nodes in a graph. A CMS is organized into two parts: an arguments graph and an effects graph. The arguments graph stores cases and case slot restrictions, the effects graph stores a description of what happens to the entities described in the arguments graph when an action &amp;quot;takes place.&amp;quot; A simplified example of a possible CMS for the verb in Figure 1. Sense 1, composed of argument and effect nodes labelled A, W and X can represent &amp;quot;Mary throws the ball.&amp;quot; It show that during sense 1 of the action &amp;quot;throw,&amp;quot; a human agent remains at a location while a physical object changes location from where the Agent is to another location. The Agent changes from being in a state of physical contact with the Object to not being in physical contact with it. Sense 2 is composed of nodes labelled A, B, W and Y; it might represent &amp;quot;Figaro throws the ball to Zistin.&amp;quot; Sense 3, composed of nodes labelled A, B, C, W, X and Z, could rep- &apos;resent &amp;quot;Sharon threw the terminal at Raphael.&amp;quot; 1) a snapshot of the room just before an action Moran infers a CMS for each root verb it encounters. occurs, Although similarities among different senses of the same root verb are recognized, similarities are not 2) a snapshot of the room just after the action is recognized across CMS boundaries; true synonyms might completed and have identical graphs, but Moran would have no knowledge arguments 1,2,3</abstract>
<title confidence="0.690870666666667">PREP INDOBJ Prespositi</title>
<author confidence="0.589259">Human</author>
<note confidence="0.716547">A: C3</note>
<title confidence="0.9334694">Location Human Physobj Location Location</title>
<note confidence="0.846463352941176">2,3 3 AGENT OBJECT Cl C2 effects 1,2,3 1,3 AGENT PHYSCONT OBJECT ---&gt; null Y: INDOBJ Al&apos; C2 ---&gt; INDOBJ AT C2 AGENT PHYSCONT OBJECT ---&gt; INDOBJ PHYSCONT OBJECT 3 INDOBJ AT C3 ---&gt; INDOBJ Al&apos; C3 Figure 1. AGENT AT Cl ---&gt; AGENT AT Cl OBJECT AT Cl ---&gt; OBJECT AT C2 14</note>
<abstract confidence="0.996758319587629">of the similarity. Similarities among verbs that are close in meaning, but not synonyms, are not represented; the fact that &amp;quot;move&amp;quot; and &amp;quot;throw&amp;quot; are related is not obvious to Moran. RESULTS A primitive meaning unit, or building block, should be useful for describing a large number of different meanings. Moran attempts to identify those structures that have been useful descriptors. At a certain point in the learning process, currently arbitrarily chosen by the human trainer, Moran looks for building blocks that have been used to describe a number of different root verbs. This search for building blocks crosses CMS boundaries and occurs only when memory is rich enough for some global decisions to be made. Moran was presented with twenty senses of four root verbs: move, throw, carry and buy. Moran chose the following effects as building blocks: 1) Agent (human) AT Casel (location) Agent (human) AT Casel (location) * a human agent remains at a location * 2) Agent (human) AT Casel (location) Agent (human) AT Case2 (location) * a human agent changes location * 3) Object (physicalobj) AT Casel (location) Object (physicalobj) AT Case2 (location) * a physical object changes location * 4) Agent (human) PHYSICALCONTACT Object (physicalobj) Agent (human) PHYSICALCONTACT Object (physicalobj) * a human agent remains in physical contact with a physical object * Since Moran has only been presented with a small number of verbs of movement, it is not surprising that the building blocks it chooses describe Agents and Objects moving about the environment and their interaction with other. criticism is that the chosen building blocks are artifacts of the particular descripthat were to Moran. We this is an rather a drawback, since Moran must asthe world is described to it on a level that will be appropriate for subsequent processing. In Schank&apos;s conceptual dependency scheme, verbs of movement are often described with PTRANS and PROPEL. It is interesting that some of the building blocks Moran inferred seem to be subparts of the structures of ?TRANS and PROPEL. For example, the conceptual dependency for &amp;quot;X throw Z at Y&amp;quot; is: Z X where X and Y are humans and Z is a physical object. We see the object, Z, changing from the location of X to that of Y. Thus, the conceptual dependency subpart: z appears to be approximated by building block #3 where changes location. Moran would recognize that the location change is from the location of the Agent to the location of the indirect object by the interaction of building block #3 with other building blocks and effects that participate in the action description. Similarly, the conceptual dependency for &amp;quot;X move Z to W&amp;quot; is: w Hir c where X and Z have the same restrictions as above and W is a location. Again we see an object changing location; a common acct.:tante in movement and a building block Moran identified. &apos; REMARKS We are currently modifying Moran so that the identified building blocks are used to process subsequent input. as new situations are encountered, Moran will try to describe them as much as possible in terms of the building blocks. It will be interesting to see how these descriptions differ from the ones Moran would have constructed if the building blocks had not been also investigate how the existence of the building blocks affects processing time. As a cognitive model, inferred primitives may account for the effects of &amp;quot;bad teaching,&amp;quot; that is, an unfortunate sequence of examples of a new concept. If examples are so disparate that few building blocks exist, or so unrepresentative that the derived building blocks are useless for future inputs, then the after-the-fact primitives will impede efficient representation. The knowledge organization will not tie together what we have experienced in the past or predict that we will experience in the future. Although the learning program could infer more useful building blocks at a later that process is expensive, and be unable to replace information lost because of poor building blocks chosen earlier. In general, however, we must assume that our world is described at a level appropriate to how we must process it. If that is the case, then inferring a set of primitives is an advantageous strategy.</abstract>
<note confidence="0.8427645">REFERENCES 1979] Inferring conceptual graphs. Science,1979, 3, 141-166. [Schenk 1972] Conceptual Dependency: a theory of language understanding. Psychology,1972, 3, 552-631.</note>
<intro confidence="0.51585">15</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Inferring conceptual graphs. Cognitive Science,</title>
<date>1979</date>
<volume>3</volume>
<pages>141--166</pages>
<marker>1979</marker>
<rawString> (Salveter 1979] Inferring conceptual graphs. Cognitive Science, 1979, 3, 141-166.</rawString>
</citation>
<citation valid="true">
<title>Conceptual Dependency: a theory of natural language understanding. Cognitive Psychology,</title>
<date>1972</date>
<volume>3</volume>
<pages>552--631</pages>
<marker>[Schenk 1972]</marker>
<rawString>Conceptual Dependency: a theory of natural language understanding. Cognitive Psychology, 1972, 3, 552-631.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>