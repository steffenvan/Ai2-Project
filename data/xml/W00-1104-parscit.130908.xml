<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.986263">
Semantic Indexing using WordNet Senses
</title>
<author confidence="0.987392">
Rada Mihalcea and Dan Moldovan
</author>
<affiliation confidence="0.871521">
Department of Computer Science and Engineering
Southern Methodist University
</affiliation>
<address confidence="0.684126">
Dallas, Texas, 75275-0122
</address>
<email confidence="0.768873">
{rada, moldovan}Â©seas.smu.edu
</email>
<sectionHeader confidence="0.992579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9988838">
We describe in this paper a boolean
Information Retrieval system that
adds word semantics to the classic
word based indexing. Two of the
main tasks of our system, namely
the indexing and retrieval compo-
nents, are using a combined word-
based and sense-based approach.
The key to our system is a methodol-
ogy for building semantic represen-
tations of open text, at word and col-
location level. This new technique,
called semantic indexing, shows im-
proved effectiveness over the classic
word based indexing techniques.
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999745696428572">
The main problem with the traditional
boolean word-based approach to Information
Retrieval (IR) is that it usually returns too
many results or wrong results to be useful.
Keywords have often multiple lexical func-
tionalities (i.e. can have various parts of
speech) or have several semantic senses. Also,
relevant information can be missed by not
specifying the exact keywords.
The solution is to include more information
in the documents to be indexed, such as to
enable a system to retrieve documents based
on the words, regarded as lexical strings, or
based on the semantic meaning of the words.
With this idea in mind, we designed an
IR system which performs a combined word-
based and sense-based indexing and retrieval.
The inputs to IR systems consist of a ques-
tion/query and a set of documents from which
the information has to be retrieved. We add
lexical and semantic information to both the
query and the documents, during a prepro-
cessing phase in which the input question
and the texts are disambiguated. The disam-
biguation process relies on contextual infor-
mation, and identify the meaning of the words
based on WordNet 1 (Fellbaum, 1998) senses.
As described in the fourth section, we have
opted for a disambiguation algorithm which
is semi-complete (it disambiguates about 55%
of the nouns and verbs), but is highly precise
(over 92% accuracy), instead of using a com-
plete but less precise disambiguation. A part
of speech tag is also appended to each word.
After adding these lexical and semantic tags
to the words, the documents are ready to be
indexed: the index is created using the words
as lexical strings (to ensure a word-based re-
trieval), and the semantic tags (for the sense-
based retrieval).
Once the index is created, an input query is
answered using the document retrieval com-
ponent of our system. First, the query is fully
disambiguated; then, it is adapted to a spe-
cific format which incorporates semantic in-
formation, as found in the index, and uses
the AND and OR operators implemented in
the retrieval module.
Hence, using semantic indexing, we try to
solve the two main problems of the IR systems
described earlier. (1) relevant information is
not missed by not specifying the exact key-
words; with the new tags added to the words,
we also retrieve words which are semantically
related to the input keywords; (2) using the
sense-based component of our retrieval sys-
</bodyText>
<footnote confidence="0.902919">
1WordNet 1.6 is used in our system.
</footnote>
<page confidence="0.997933">
35
</page>
<bodyText confidence="0.97297228">
tem, the number of results returned from a
search can be reduced, by specifying exactly
the lexical functionality and/or the meaning
of an input keyword.
The system was tested using the Cran-
field standard test collection. This collec-
tion consists of 1400 documents, SGML for-
mated, from the aerodynamics field. From
the 225 questions associated with this data
set, we have randomly selected 50 questions
and build for each of them three types of
queries: (1) a query that uses only keywords
selected from the question, stemmed using the
WordNet stemmer2; (2) a query that uses the
keywords from the question and the synsets
3 for these keywords and (3) a query that
uses the keywords from the question, the
synsets for these keywords and the synsets for
the keywords hypernyms. All these types of
queries have been run against the semantic
index described in this paper. Comparative
results indicate the performance benefits of a
retrieval system that uses a combined word-
based and synset-based indexing and retrieval
over the classic word based indexing.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9973535">
There are three main approaches reported
in the literature regarding the incorpora-
tion of semantic information into IR systems:
(1)conceptual indexing, (2) query expansion
and (3) semantic indexing. The former is
based on ontological taxonomies, while the
last two make use of Word Sense Disambigua-
tion algorithms
</bodyText>
<subsectionHeader confidence="0.995715">
2.1 Conceptual indexing
</subsectionHeader>
<bodyText confidence="0.996705857142857">
The usage of concepts for document index-
ing is a relatively new trend within the IR
field. Concept matching is a technique that
has been used in limited domains, like the le-
gal field were conceptual indexing has been
applied by (Stein, 1997). The FERRET sys-
tem (Mauldin, 1991) is another example of
</bodyText>
<footnote confidence="0.997220166666667">
2WordNet stemmer = words are stemmed based on
WordNet definitions (using the morphs&amp; function)
3The words in WordNet are organized in synonym
sets, called synsets. A synset is associated with a par-
ticular sense of a word, and thus we use sense-based
and synset-based interchangeably.
</footnote>
<bodyText confidence="0.997761290322581">
how concept identification can improve IR
systems.
To our knowledge, the most intensive work
in this direction was performed by Woods
(Woods, 1997), at Sun Microsystems Labo-
ratories. He creates some custom built onto-
logical taxonomies based on subsumtion and
morphology for the purpose of indexing and
retrieving documents. Comparing the per-
formance of the system that uses conceptual
indexing, with the performance obtained us-
ing classical retrieval techniques, resulted in
an increased performance and recall. He de-
fines also a new measure, called success rate
which indicates if a question has an answer
in the top ten documents returned by a re-
trieval system. The success rate obtained in
the case of conceptual indexing was 60%, re-
spect to a maximum of 45% obtained using
other retrieval systems. This is a significant
improvement and shows that semantics can
have a strong impact on the effectiveness of
IR systems.
The experiments described in (Woods,
1997) refer to small collections of text, as
for example the Unix manual pages (about
10MB of text). But, as shown in (Ambroziak,
1997), this is not a limitation; conceptual in-
dexing can be successfully applied to much
larger text collections, and even used in Web
browsing.
</bodyText>
<subsectionHeader confidence="0.999843">
2.2 Query Expansion
</subsectionHeader>
<bodyText confidence="0.998337625">
Query expansion has been proved to have
positive effects in retrieving relevant informa-
tion (Lu and Keefer, 1994). The purpose of
query extension can be either to broaden the
set of documents retrieved or to increase the
retrieval precision. In the former case, the
query is expanded with terms similar with
the words from the original query, while in
the second case the expansion procedure adds
completely new terms.
There are two main techniques used in ex-
panding an original query. The first one con-
siders the use of Machine Readable Dictio-
nary; (Moldovan and Mihalcea, 2000) and
(Voorhees, 1994) are making use of WordNet
to enlarge the query such as it includes words
</bodyText>
<page confidence="0.996819">
36
</page>
<bodyText confidence="0.9999021">
which are semantically related to the concepts
from the original query. The basic semantic
relation used in their systems is the synonymy
relation. This technique requires the disam-
biguation of the words in the input query and
it was reported that this method can be useful
if the sense disambiguation is highly accurate.
The other technique for query expansion is
to use relevance feedback, as used in SMART
(Buckley et al., 1994).
</bodyText>
<subsectionHeader confidence="0.999587">
2.3 Semantic indexing
</subsectionHeader>
<bodyText confidence="0.999982372093024">
The usage of word senses in the process of
document indexing is a pretty much debated
field of discussions. The basic idea is to in-
dex word meanings, rather than words taken
as lexical strings. A survey of the efforts of
incorporating WSD into IR is presented in
(Sanderson, 2000). Experiments performed
by different researchers led to various, some-
time contradicting results. Nevertheless, the
conclusion which can be drawn from all these
experiments is that a highly accurate Word
Sense Disambiguation algorithm is needed in
order to obtain an increase in the performance
of IR systems.
Ellen Voorhees (Voorhees, 1998) (Voorhees,
1999) tried to resolve word ambiguity in the
collection of documents, as well as in the
query, and then she compared the results ob-
tained with the performance of a standard
run. Even if she used different weighting
schemes, the overall results have shown a
degradation in IR effectiveness when word
meanings were used for indexing. Still, as she
pointed out, the precision of the WSD tech-
nique has a dramatic influence on these re-
sults. She states that a better WSD can lead
to an increase in IR performance.
A rather &amp;quot;artificial&amp;quot; experiment in the same
direction of semantic indexing is provided in
(Sanderson, 1994). He uses pseudo-words
to test the utility of disambiguation in IR.
A pseudo-word is an artificially created am-
biguous word, like for example &amp;quot;banana-door&amp;quot;
(pseudo-words have been introduced for the
first time in (Yarowsky, 1993), as means of
testing WSD accuracy without the costs as-
sociated with the acquisition of sense tagged
corpora). Different levels of ambiguity were
introduced in the set of documents prior to in-
dexing. The conclusion drawn was that WSD
has little impact on IR performance, to the
point that only a WSD algorithm with over
90% precision could help IR systems.
The reasons for the results obtained by
Sanderson have been discussed in (Schutze
and Pedersen, 1995). They argue that the
usage of pseudo-words does not always pro-
vide an accurate measure of the effect of WSD
over IR performance. It is shown that in the
case of pseudo-words, high-frequency word
types have the majority of senses of a pseudo-
word, i.e. the word ambiguity is not realisti-
cally modeled. More than this, (Schutze and
Pedersen, 1995) performed experiments which
have shown that semantics can actually help
retrieval performance. They reported an in-
crease in precision of up to 7% when sense
based indexing is used alone, and up to 14%
for a combined word based and sense based
indexing.
One of the largest studies regarding the
applicability of word semantics to IR is re-
ported by Krovetz (Krovetz and Croft, 1993),
(Krovetz, 1997). When talking about word
ambiguity, he collapses both the morpholog-
ical and semantic aspects of ambiguity, and
refers them as polysemy and homonymy. He
shows that word senses should be used in ad-
dition to word based indexing, rather than
indexing on word senses alone, basically be-
cause of the uncertainty involved in sense dis-
ambiguation. He had extensively studied the
effect of lexical ambiguity over IR; the ex-
periments described provide a clear indication
that word meanings can improve the perfor-
mance of a retrieval system.
(Gonzalo et al., 1998) performed experi-
ments in sense based indexing: they used the
SMART retrieval system and a manually dis-
ambiguated collection (Semcor). It turned
out that indexing by synsets can increase re-
call up to 29% respect to word based indexing.
Part of their experiments was the simulation
of a WSD algorithm with error rates of 5%,
10%, 20%, 30% and 60%: they found that er-
ror rates of up to 10% do not substantially af-
</bodyText>
<page confidence="0.996537">
37
</page>
<bodyText confidence="0.999796615384615">
fect precision, and a system with WSD errors
below 30% still perform better than a stan-
dard run. The results of their experiments
are encouraging, and proved that an accurate
WSD algorithm can significantly help IR sys-
tems.
We propose here a system which tries
to combine the benefits of word-based and
synset-based indexing. Both words and
synsets are indexed in the input text, and the
retrieval is then performed using either one or
both these sources of information. The key to
our system is a WSD method for open text.
</bodyText>
<sectionHeader confidence="0.985723" genericHeader="method">
3 System Architecture
</sectionHeader>
<bodyText confidence="0.994312">
There are three main modules used by this
system:
</bodyText>
<listItem confidence="0.625048">
1. Word Sense Disambiguation (WSD)
</listItem>
<bodyText confidence="0.992709363636364">
module, which performs a semi-complete
but precise disambiguation of the words
in the documents. Besides semantic in-
formation, this module also adds part of
speech tags to each word and stems the
word using the WordNet stemming algo-
rithm. Every document in the input set
of documents is processed with this mod-
ule. The output is a new document in
which each word is replaced with the new
format
</bodyText>
<subsectionHeader confidence="0.493677">
PosiSternIPOSIOffset
</subsectionHeader>
<bodyText confidence="0.887855">
where: Pos is the position of the word
in the text; Stem is the stemmed form of
the word; POS is the part of speech and
Offset is the offset of the WordNet synset
in which this word occurs.
In the case when no sense is assigned by
the WSD module or if the word cannot
be found in WordNet, the last field is left
empty.
2. Indexing module, which indexes the
documents, after they are processed by
the WSD module. From the new for-
mat of a word, as returned by the WSD
function, the Stem and, separately, the
OffsetIPOS are added to the index. This
enables the retrieval of the words, re-
garded as lexical strings, or the retrieval
of the synset of the words (this actually
means the retrieval of the given sense of
the word and its synonyms).
</bodyText>
<listItem confidence="0.585473">
3. Retrieval module, which retrieves doc-
</listItem>
<bodyText confidence="0.985696">
uments, based on an input query. As
we are using a combined word-based and
synset-based indexing, we can retrieve
documents containing either (1) the in-
put keywords, (2) the input keywords
with an assigned sense or (3) synonyms
of the input keywords.
</bodyText>
<sectionHeader confidence="0.987641" genericHeader="method">
4 Word Sense Disambiguation
</sectionHeader>
<bodyText confidence="0.875018666666667">
As stated earlier, the WSD is performed for
both the query and the documents from which
we have to retrieve information.
The WSD algorithm used for this purpose
is an iterative algorithm; it was for the first
time presented in (Mihalcea and Moldovan,
2000). It determines, in a given text, a set of
nouns and verbs which can be disambiguated
with high precision. The semantic tagging is
performed using the senses defined in Word-
Net.
In this section, we present the various
methods used to identify the correct sense of a
word. Then, we describe the main algorithm
in which these procedures are invoked in an
iterative manner.
PROCEDURE 1. This procedure identifies the
proper nouns in the text, and marked them
as having sense #1.
Example. &amp;quot;Hudson&amp;quot; is identified as a
proper noun and marked with sense #1.
PROCEDURE 2. Identify the words having
only one sense in WordNet (monosemous
words). Mark them with sense #1.
Example. The noun subcommittee has one
sense defined in WordNet. Thus, it is a
monosemous word and can be marked as hav-
ing sense #1.
PROCEDURE 3. For a given word Wi, at po-
sition i in the text, form two pairs, one with
the word before Wi (pair W1_1-W1) and the
other one with the word after Wi (pair Wi-
W2+1). Determiners or conjunctions cannot
</bodyText>
<page confidence="0.997281">
38
</page>
<bodyText confidence="0.998664653061225">
be part of these pairs. Then, we extract all
the occurrences of these pairs found within
the semantic tagged corpus formed with the
179 texts from SemCor(Miller et al., 1993). If,
in all the occurrences, the word Wi has only
one sense #k, and the number of occurrences
of this sense is larger than 3, then mark the
word Wi as having sense #k.
Example. Consider the word approval in
the text fragment &amp;quot; committee approval
of &amp;quot; . The pairs formed are &amp;quot; committee
approval&amp;quot; and &amp;quot;approval of &amp;quot; . No oc-
currences of the first pair are found in the
corpus. Instead, there are four occurrences of
the second pair, and in all these occurrences
the sense of approval is sense #1. Thus,
approval is marked with sense #1.
PROCEDURE 4. For a given noun N in the
text, determine the noun-context of each of
its senses. This noun-context is actually a list
of nouns which can occur within the context
of a given sense i of the noun N. In order to
form the noun-context for every sense N, we
are determining all the concepts in the hyper-
nym synsets of Ni. Also, using SemCor, we
determine all the nouns which occur within a
window of 10 words respect to N.
All of these nouns, determined using Word-
Net and SemCor, constitute the noun-context
of N. We can now calculate the number of
common words between this noun-context and
the original text in which the noun N is found.
Applying this procedure to all the senses of
the noun N will provide us with an ordering
over its possible senses. We pick up the sense
i for the noun N which: (1) is in the top of
this ordering and (2) has the distance to the
next sense in this ordering larger than a given
threshold.
Example. The word diameter, as it appears
in the document 1340 from the Cranfield col-
lection, has two senses. The common words
found between the noun-contexts of its senses
and the text are: for diameter#1: { property,
hole, ratio } and for diameter#2: { form}.
For this text, the threshold was set to 1, and
thus we pick diameter#1 as the correct sense
(there is a difference larger than 1 between
the number of nouns in the two sets).
PROCEDURE 5. Find words which are se-
mantically connected to the already disam-
biguated words for which the connection dis-
tance is 0. The distance is computed based
on the WordNet hierarchy; two words are se-
mantically connected at a distance of 0 if they
belong to the same synset.
Example. Consider these two words ap-
pearing in the text to be disambiguated:
authorize and clear. The verb authorize
is a monosemous word, and thus it is disam-
biguated with procedure 2. One of the senses
of the verb clear, namely sense #4, appears
in the same synset with authorize#1, and
thus clear is marked as having sense #4.
PROCEDURE 6. Find words which are seman-
tically connected, and for which the connec-
tion distance is 0. This procedure is weaker
than procedure 5: none of the words con-
sidered by this procedure are already disam-
biguated. We have to consider all the senses
of both words in order to determine whether
or not the distance between them is 0, and
this makes this procedure computationally in-
tensive.
Example. For the words measure and bill,
both of them ambiguous, this procedure tries
to find two possible senses for these words,
which are at a distance of 0, i.e. they be-
long to the same synset. The senses found
are measure#4 and bill#1, and thus the two
words are marked with their corresponding
senses.
PROCEDURE 7. Find words which are se-
mantically connected to the already disam-
biguated words, and for which the connection
distance is maximum 1. Again, the distance
is computed based on the WordNet hierar-
chy; two words are semantically connected at
a maximum distance of 1 if they are synonyms
or they belong to a hypernymy/hyponymy re-
lation.
Example. Consider the nouns subcommittee
and committee. The first one is disam-
biguated with procedure 2, and thus it is
marked with sense #1. The word committee
with its sense #1 is semantically linked with
the word subcommittee by a hypernymy re-
lation. Hence, we semantically tag this word
</bodyText>
<page confidence="0.997298">
39
</page>
<bodyText confidence="0.9977634">
with sense #1.
PROCEDURE 8. Find words which are se-
mantically connected between them, and for
which the connection distance is maximum 1.
This procedure is similar with procedure 6:
both words are ambiguous, and thus all their
senses have to be considered in the process of
finding the distance between them.
Example. The words gift and donation
are both ambiguous. This procedure finds
gift with sense #1 as being the hypernym
of donation, also with sense #1. Therefore,
both words are disambiguated and marked
with their assigned senses.
The procedures presented above are applied
iteratively. This allows us to identify a set of
nouns and verbs which can be disambiguated
with high precision. About 55% of the nouns
and verbs are disambiguated with over 92%
accuracy.
</bodyText>
<sectionHeader confidence="0.557878" genericHeader="method">
Algorithm
</sectionHeader>
<bodyText confidence="0.999294464285714">
Step 1. Pre-process the text. This implies
tokenization and part-of-speech tagging. The
part-of-speech tagging task is performed with
high accuracy using an improved version of
Brill&apos;s tagger (Brill, 1992). At this step, we
also identify the complex nominals, based on
WordNet definitions. For example, the word
sequence pipeline companies&apos;&apos; is found
in WordNet and thus it is identified as a single
concept. There is also a list of words which
we do not attempt to disambiguate. These
words are marked with a special flag to in-
dicate that they should not be considered in
the disambiguation process. So far, this list
consists of three verbs: be, have, do.
Step 2. Initialize the Set of Disambiguated
Words (SDW) with the empty set SDW={}.
Initialize the Set of Ambiguous Words (SAW)
with the set formed by all the nouns and verbs
in the input text.
Step 3. Apply procedure 1. The named en-
tities identified here are removed from SAW
and added to SDW.
Step 4. Apply procedure 2. The monosemous
words found here are removed from SAW and
added to SDW.
Step 5. Apply procedure 3. This step allows
us to disambiguate words based on their oc-
currence in the semantically tagged corpus.
The words whose sense is identified with this
procedure are removed from SAW and added
to SDW.
Step 6. Apply procedure 4. This will identify
a set of nouns which can be disambiguated
based on their noun-contexts.
Step 7. Apply procedure 5. This procedure
tries to identify a synonymy relation between
the words from SAW and SDW. The words
disambiguated are removed from SAW and
added to SDW.
Step 8. Apply procedure 6. This step is dif-
ferent from the previous one, as the synonymy
relation is sought among words in SAW (no
SDW words involved). The words disam-
biguated are removed from SAW and added
to SDW.
Step 9. Apply procedure 7. This step tries
to identify words from SAW which are linked
at a distance of maximum 1 with the words
from SDW. Remove the words disambiguated
from SAW and add them to SDW.
Step 10. Apply procedure 8. This procedure
finds words from SAW connected at a distance
of maximum 1. As in step 8, no words from
SDW are involved. The words disambiguated
are removed from SAW and added to SDW.
</bodyText>
<sectionHeader confidence="0.902516" genericHeader="method">
Results
</sectionHeader>
<bodyText confidence="0.9999873">
To determine the accuracy and the recall
of the disambiguation method presented here,
we have performed tests on 6 randomly se-
lected files from SemCor. The following files
have been used: br-a01, br-a02, br-k01, br-
k18, br-m02, br-r05. Each of these files was
split into smaller files with a maximum of 15
lines each. This size limit is based on our
observation that small contexts reduce the
applicability of procedures 5-8, while large
contexts become a source of errors. Thus,
we have created a benchmark with 52 texts,
on which we have tested the disambiguation
method.
In table 1, we present the results obtained
for these 52 texts. The first column indicates
the file for which the results are presented.
The average number of nouns and verbs con-
sidered by the disambiguation algorithm for
each of these files is shown in the second col-
</bodyText>
<page confidence="0.999437">
40
</page>
<tableCaption confidence="0.99851">
Table 1: Results for the WSD algorithm applied on 52 texts
</tableCaption>
<table confidence="0.9997829">
File No. Proc.1+2 Proc.3 Proc.4 Proc.5+6 Proc.7+8
words
No. Acc. No. Acc. No. Acc. No. Acc. No. Acc.
br-a01 132 40 100% 43 99.7% 58.5 94.6% 63.8 92.7% 73.2 89.3%
br-a02 135 49 100% 52.5 98.5% 68.6 94% 75.2 92.4% 81.2 91.4%
br-k01 68.1 17.2 100% 23.3 99.7% 38.1 97.4% 40.3 97.4% 41.8 96.4%
br-k18 60.4 18.1 100% 20.7 99.1% 26.6 96.9% 27.8 95.3% 29.8 93.2%
br-m02 63 17.3 100% 20.3 98.1% 26.1 95% 26.8 94.9% 30.1 93.9%
br-r05 72.5 14.3 100% 16.6 98.1% 27 93.2% 30.2 91.5% 34.2 89.1%
AVERAGE 88.5 25.9 100% 29.4 98.8% 40.8 95.2% 44 94% 48.4 92.2%
</table>
<bodyText confidence="0.99931996969697">
umn. In columns 3 and 4, there are presented
the average number of words disambiguated
with procedures 1 and 2, and the accuracy
obtained with these procedures. Column 5
and 6 present the average number of words
disambiguated and the accuracy obtained af-
ter applying procedure 3 (cumulative results).
The cumulative results obtained after apply-
ing procedures 3, 4 and 5, 6 and 7, are shown
in columns 7 and 8, 9 and 10, respectively
columns 10 and 11.
The novelty of this method consists of the
fact that the disambiguation process is done
in an iterative manner. Several procedures,
described above, are applied such as to build
a set of words which are disambiguated with
high accuracy: 55% of the nouns and verbs
are disambiguated with a precision of 92.22%.
The most important improvements which
are expected to be achieved on the WSD prob-
lem are precision and speed. In the case of
our approach to WSD, we can also talk about
the need for an increased recall, meaning that
we want to obtain a larger number of words
which can be disambiguated in the input text.
The precision of more than 92% obtained
during our experiments is very high, consid-
ering the fact that WordNet, which is the dic-
tionary used for sense identification, is very
fine grained and sometime the senses are very
close to each other. The accuracy obtained is
close to the precision achieved by humans in
sense disambiguation.
</bodyText>
<sectionHeader confidence="0.988966" genericHeader="method">
5 Indexing and Retrieval
</sectionHeader>
<bodyText confidence="0.999902536585366">
The indexing process takes a group of docu-
ment files and produces a new index. Such
things as unique document identifiers, proper
SGML tags, and other artificial constructs are
ignored. In the current version of the system,
we are using only the AND and OR boolean
operators. Future versions will consider the
implementation of the NOT and NEAR oper-
ators.
The information obtained from the WSD
module is used by the main indexing process,
where the word stem and location are indexed
along with the WordNet synset (if present).
Collocations are indexed at each location that
a member of the collocation occurs.
All elements of the document are indexed.
This includes, but is not limited to, dates,
numbers, document identifiers, the stemmed
words, collocations, WordNet synsets (if
available), and even those terms which other
indexers consider stop words. The only items
currently excluded from the index are punc-
tuation marks which are not part of a word
or collocation.
The benefit of this form of indexing is that
documents may be retrieved using stemmed
words, or using synset offsets. Using synset
offset values has the added benefit of retriev-
ing documents which do not contain the orig-
inal stemmed word, but do contain synonyms
of the original word.
The retrieval process is limited to the use of
the Boolean operators AND and OR. There
is an auxiliary front end to the retrieval en-
gine which allows the user to enter a textual
query, such as, &amp;quot;What financial institutions
are found along the banks of the Nile?&amp;quot; The
auxiliary front end will then use the WSD to
disambiguate the query and build a Boolean
query for the standard retrieval engine.
For the preceding example, the auxil-
</bodyText>
<page confidence="0.99867">
41
</page>
<bodyText confidence="0.999561818181818">
iary front end would build the query: (fi-
nanciaLinstitution OR 6003131INN) AND
(bank OR 68002231NN) AND (Nile OR
6826174INN) where the numbers in the pre-
vious query represent the offsets of the synsets
in which the words with their determined
meaning occur.
Once a list of documents meeting the query
requirements has been determined, the com-
plete text of each matching document is re-
trieved and presented to the user.
</bodyText>
<sectionHeader confidence="0.885635" genericHeader="method">
6 An Example
</sectionHeader>
<bodyText confidence="0.999167740740741">
Consider, for example, the following ques-
tion: &amp;quot;Has anyone investigated the effect of
surface mass transfer on hypersonic viscous
interactions?&amp;quot;. The question processing in-
volves part of speech tagging, stemming and
word sense disambiguation.
The question be-
comes: &amp;quot;Has anyone investigatelV11535831
the effectINN17766144 of surfacelN1â 13447223
massINIVI3923435 transferIN1V1132095
on hypersonicIJJ viscousIJJ interactioniNM
7840572&amp;quot;.
The selection of the keywords is not an
easy task, and it is performed using the set
of 8 heuristics presented in (Moldovan et al.,
1999). Because of space limitations, we are
not going to detail here the heuristics and the
algorithm used for keywords selection. The
main idea is that an initial number of key-
words is determined using a subset of these
heuristics. If no documents are retrieved,
more keywords are added, respectively a too
large number of documents will imply that
some of the keywords are dropped in the re-
versed order in which they have been entered.
For each question, three types of query are
formed, using the AND and OR operators.
</bodyText>
<listItem confidence="0.722175">
1. QwNste-m. Keywords from the question,
</listItem>
<bodyText confidence="0.937751363636364">
stemmed based on WordNet, concate-
nated with the AND operator.
2- QWNOf f set- Keywords from the ques-
tion, stemmed based on WordNet, con-
catenated using the OR operator with
the associated synset offset, and con-
catenated with the AND operator among
them.
3- QWNHyperOf f set-
Keywords from the
question, stemmed based on WordNet,
concatenated using the OR operator with
the associated synset offset and with the
offset of the hypernym synset, and con-
catenated with the AND operator among
them.
All these types of queries are run against
the semantic index created based on words
and synset offsets. We denote these runs with
RwNStem, RWNOf fset and RWNHyperOf fset-
The three query formats, for the given ques-
tion, are presented below:
</bodyText>
<listItem confidence="0.735764916666667">
QwNstem. effect AND surface AND mass
AND flow AND interaction
QWNO f f set- (effect OR 7766/44{N/V) AND
(surface OR 3447223IN1V) AND (mass OR
39234351N1V) AND (transfer OR 132095INN)
AND (interaction OR 7840572(N1V)
QWNHyperOf pet (effect OR 7766/44INN OR
2046/INN) AND (surface OR
3447223INN OR 119371N1V) AND (mass OR
39234351NN OR 3912591IN1V) AND (transfer
OR 1320951NN OR 130470IN1V) AND (inter-
action OR 7840572INN OR 77709571NN)
</listItem>
<bodyText confidence="0.999012307692308">
Using the first type of query, 7 documents
were found out of which 1 was considered
to be relevant. With the second and third
types of query, we obtained 11, respectively
17 documents, out of which 4 were found rel-
evant, and actually contained the answer to
the question.
(sample answer) ... the present report gives an ac-
count of the development of an approximate theory to
the problem of hypersonic strong viscous interaction
on a flat plate with mass-transfer at the plate surface.
the disturbance flow region is divided into inviscid and
viscous flow regions .... (cranfield0305).
</bodyText>
<sectionHeader confidence="0.999977" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.999359333333333">
The system was tested on the Cranfield col-
lection, including 1400 documents, SGML
formated4. From the 225 questions provided
</bodyText>
<footnote confidence="0.9985745">
4Demo available online at
http://pdp13.seas.smu.edu/ rada/sem.ind./
</footnote>
<page confidence="0.998869">
42
</page>
<bodyText confidence="0.99979125">
with this collection, we randomly selected 50
questions and used them to create a bench-
mark against which we have performed the
three runs described in the previous sections:
</bodyText>
<subsubsectionHeader confidence="0.28512">
RwNStem, RW NO f fset and RwNHyperOf f set-
</subsubsectionHeader>
<bodyText confidence="0.9409418">
For each of these questions, the system
forms three types of queries, as described
above. Below, we present 10 of these ques-
tions and show the results obtained in Table
2.
</bodyText>
<reference confidence="0.995287590909091">
1. Has anyone investigated the effect of surface mass trans-
fer on hypersonic viscous interactions?
2. What is the combined effect of surface heat and mass
transfer on hypersonic flow?
3. What are the existing solutions for hypersonic viscous in-
teractions over an insulated flat plate?
4. What controls leading-edge attachment at transonic ve-
locities?
5. What are wind-tunnel corrections for a two-dimensional
aerofoil mounted off-centre in a tunnel?
6. What is the present state of the theory of quasi-conical
flows?
7. References on the methods available for accurately esti-
mating aerodynamic heat transfer to conical bodies for both
laminar and turbulent flow.
8. What parameters can seriously influence natural transi-
tion from laminar to turbulent flow on a model in a wind
tunnel?
9. Can a satisfactory experimental technique be devel-
oped for measuring oscillatory derivatives on slender sting-
mounted models in supersonic wind tunnels?
10. Recent data on shock-induced boundary-layer separation.
</reference>
<bodyText confidence="0.999667">
Three measures are used in the evaluation
of the system performance: (1) precision, de-
fined as the number of relevant documents re-
trieved over the total number of documents
retrieved; (2) recall, defined as the number
of relevant documents retrieved over the total
number of relevant documents found in the
collection and (3) F-measure, which combines
both the precision and recall into a single for-
mula:
</bodyText>
<equation confidence="0.763176">
(132 + 1.0) * P * R
(02 * I)) R
</equation>
<bodyText confidence="0.99996502631579">
where P is the precision, R is the recall and
)3 is the relative importance given to recall
over precision. In our case, we consider both
precision and recall of equal importance, and
thus the factor )3 in our evaluation is 1.
The tests over the entire set of 50 questions
led to 0.22 precision and 0.25 recall when the
WordNet stemmer is used, 0.23 precision and
0.29 recall when using a combined word-based
and synset-based indexing. The usage of hy-
pemym synsets led to a recall of 0.32 and a
precision of 0.21.
The relative gain of the combined word-
based and synset-based indexing respect to
the basic word-based indexing was 16% in-
crease in recall and 4% increase in precision.
When using the hypernym synsets, there is a
28% increase in recall, with a 9% decrease in
precision.
The conclusion of these experiments is that
indexing by synsets, in addition to the clas-
sic word-based indexing, can actually improve
IR effectiveness. More than that, this is the
first time to our knowledge when a WSD algo-
rithm for open text was actually used to au-
tomatically disambiguate a collection of texts
prior to indexing, with a disambiguation ac-
curacy high enough to actually increase the
recall and precision of an IR system.
An issue which can be raised here is the ef-
ficiency of such a system: we have introduced
a WSD stage into the classic IR process and it
is well known that WSD algorithms are usu-
ally computationally intensive; on the other
side, the disambiguation of a text collection
is a process which can be highly parallelized,
and thus this does not constitute a problem
anymore.
</bodyText>
<sectionHeader confidence="0.999033" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.990405846153846">
The full understanding of text is still an elu-
sive goal. Short of that, semantic indexing
offers an improvement over current IR tech-
niques. The key to semantic indexing is fast
WSD of large collections of documents.
In this paper we offer a WSD method for
open domains that is fast and accurate. Since
only 55% of the words can be disambiguated
so far, we use a hybrid indexing approach that
combines word-based and sense-based index-
ing. The senses in WordNet are fine grain and
the WSD method has to cope with this. The
Fmeasure
</bodyText>
<page confidence="0.999847">
43
</page>
<tableCaption confidence="0.961115">
Table 2: Results for 10 questions run against the three indices created on the Cranfield collection. The bottom
line shows the results for the entire set of questions.
</tableCaption>
<table confidence="0.999701666666666">
Question Query type
number
RWNStem RWNOJ feet RWNNyperOf fact
rec all precision f-measure recall precision f-measure recall precision f-measure
1 0.08 0.14 0.05 0.31 0.36 0.17 0.31 0.24 0.14
2 0.06 0.17 0.04 0.25 0.44 0.16 0.25 0.31 0.14
3 0.47 0.70 0.28 0.47 0.70 0.28 0.53 0.67 0.30
4 0.25 0.60 0.18 0.25 0.60 0.18 0.25 0.60 0.18
5 0.33 0.50 0.20 1.00 0.25 0.20 1.00 0.19 0.16
6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
7 0.17 0.17 0.09 0.17 0.17 0.09 0.17 0.17 0.09
8 0.20 0.11 0.07 0.20 0.11 0.07 0.20 0.11 0.07
9 0.67 0.50 0.29 0.67 0.50 0.29 1.00 0.38 0.28
10 0.29 0.07 0.06 0.29 0.07 0.06 0.29 0.06 0.05
Avo/50 0.25 0.22 0.09 0.29 0.23 0.11 0.32 0.21 0.10
</table>
<bodyText confidence="0.999743357142857">
WSD algorithm presented here is new for the
NLP community and proves to be well suited
for a task such as semantic indexing.
The continuously increasing amount of in-
formation available today requires more and
more sophisticated IR te bniques, and seman-
tic indexing is one of the new trends when try-
ing to improve IR effectiveness. With seman-
tic indexing, the search may be expanded to
other forms of semantically related concepts
as done by Woods (Woods, 1997). Finally,
semantic indexing can have an impact on the
semantic Web technology that is under con-
sideration (Hellman, 1999).
</bodyText>
<sectionHeader confidence="0.998967" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998853358490566">
J. Ambroziak. 1997. Conceptually assisted Web
browsing. In Sixth International World Wide
Web conference, Santa Clara, CA. full paper
available online at http://www.scope.gmd.de/
info/www6/posters/ 702/guide2.html.
E. Brill. 1992. A simple rule-based part of speech
tagger. In Proceedings of the 3rd Conference on
Applied Natural Language Processing, Trento,
Italy.
C. Buckley, G. Salton, J. Allan, and A. Singhal.
1994. Automatic query expansion using smart:
Trec 3. In Proceedings of the Text REtrieval
Conference (TREC-3), pages 69-81.
C. Fellbaum. 1998. WordNet, An Electronic Lex-
ical Database. The MIT Press.
J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigar-
ran. 1998. Indexing with WordNet synsets
can improve text retrieval. In Proceedings
of COLING-ACL &apos;98 Workshop on Usage of
WordNet in Natural Language Processing Sys-
tems, Montreal, Canada, August.
R. Hellman. 1999. A semantic approach adds
meaning to the Web. Computer, pages 13-16.
R. Krovetz and W.B. Croft. 1993. Lexical ambi-
guity and information retrieval. ACM Transac-
tions on Information Systems, 10(2):115-141.
R. Krovetz. 1997. Homonymy and polysemy in in-
formation retrieval. In Proceedings of the 35th
Annual Meeting of the Association for Compu-
tational Linguistics (ACL-97), pages 72-79.
X.A. Lu and R.B. Keefer. 1994. Query expan-
sion/reduction and its impact on retrieval ef-
fectiveness. In The Text REtrieval Conference
(TREC-3), pages 231-240.
M.L. Mauldin. 1991. Retrieval performance
in FERRET: a conceptual information re-
trieval system. In Proceedings of the 14th
International ACM-SIGIR Conference on Re-
search and Development in Information Re-
trieval, pages 347-355, Chicago, IL, October.
R. Mihalcea and D.I. Moldovan. 2000. An iter-
ative approach to word sense disambiguation.
In Proceedings of FLAIRS-2000, pages 219-223,
Orlando, FL, May.
G. Miller, C. Leacock, T. Randee, and R. Bunker.
1993. A semantic concordance. In Proceedings
of the 3rd DARPA Workshop on Human Lan-
guage Technology, pages 303-308, Plainsboro,
New Jersey.
D Moldovan and R. Mihalcea. 2000. Using Word-
Net and lexical operators to improve Internet
searches. IEEE Internet Computing, 4(1):34-
43.
</reference>
<page confidence="0.980547">
44
</page>
<reference confidence="0.99953088372093">
D. Moldovan, S. Harabagiu, M. Pasca, It. Mihal-
cea, R. Goodrum, R. Girju, and V. Rus. 1999.
LASSO: A tool for surfing the answer net. In
Proceedings of the Text Retrieval Conference
(TREC-8), November.
M. Sanderson. 1994. Word sense disambiguation
and information retrieval. In Proceedings of the
17th Annual International ACM-SIGIR Con-
ference on Research and Development in In-
formation Retrieval, pages 142-151, Springer-
Verlag.
M. Sanderson. 2000. Retrieving with good sense.
Information Retrieval, 2(1):49-69.
H. Schutze and J. Pedersen. 1995. Information re-
trieval based on word senses. In Proceedings of
the 4th Annual Symposium on Document Anal-
ysis and Information Retrieval, pages 161-175.
J.A. Stein. 1997. Alternative methods of index-
ing legal material: Development of a conceptual
index. In Proceedings of the Conference &amp;quot;Law
Via the Internet 97&amp;quot;, Sydney, Australia.
E.M. Voorhees. 1994. Query expansion using
lexical-semantic relations. In Proceedings of the
17th Annual International ACM SIGIR, Con-
ference on Research and Development in Infor-
mation Retrieval, pages 61-69, Dublin, Ireland.
E.M. Voorhees. 1998. Using WordNet for text
retrieval. In WordNet, An Electronic Lexical
Database, pages 285-303. The MIT Press.
E.M. Voorhees. 1999. Natural language pro-
cessing and information retrieval. In Infor-
mation Extraction: towards scalable, adaptable
systems. Lecture notes in Artificial Intelligence,
#1714, pages 32-48.
W.A. Woods. 1997. Conceptual indexing: A
better way to organize knowledge. Techni-
cal Report SMLI TR-97-61, Sun Microsys-
tems Laboratories, April. available online
at: http://www.sun.com/ research/techrep/
1997/abstract-61.html.
D. Yarowsky. 1993. One sense per collocation.
In Proceedings of the ARPA Human Language
Technology Workshop.
</reference>
<page confidence="0.999377">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.775880">
<title confidence="0.999908">Semantic Indexing using WordNet Senses</title>
<author confidence="0.996892">Rada Mihalcea</author>
<author confidence="0.996892">Dan</author>
<affiliation confidence="0.9822005">Department of Computer Science and Southern Methodist</affiliation>
<address confidence="0.794358">Dallas, Texas,</address>
<email confidence="0.999897">radaÂ©seas.smu.edu</email>
<email confidence="0.999897">moldovanÂ©seas.smu.edu</email>
<abstract confidence="0.9994261875">We describe in this paper a boolean Information Retrieval system that adds word semantics to the classic word based indexing. Two of the main tasks of our system, namely the indexing and retrieval components, are using a combined wordbased and sense-based approach. The key to our system is a methodology for building semantic representations of open text, at word and collocation level. This new technique, indexing, improved effectiveness over the classic word based indexing techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>1. Has anyone investigated the effect of surface mass transfer on hypersonic viscous interactions? 2. What is the combined effect of surface heat and mass transfer on hypersonic flow? 3. What are the existing solutions for hypersonic viscous interactions over an insulated flat plate? 4. What controls leading-edge attachment at transonic velocities?</title>
<marker></marker>
<rawString>1. Has anyone investigated the effect of surface mass transfer on hypersonic viscous interactions? 2. What is the combined effect of surface heat and mass transfer on hypersonic flow? 3. What are the existing solutions for hypersonic viscous interactions over an insulated flat plate? 4. What controls leading-edge attachment at transonic velocities?</rawString>
</citation>
<citation valid="false">
<title>What are wind-tunnel corrections for a two-dimensional aerofoil mounted off-centre in a tunnel? 6. What is the present state of the theory of quasi-conical flows?</title>
<marker></marker>
<rawString>5. What are wind-tunnel corrections for a two-dimensional aerofoil mounted off-centre in a tunnel? 6. What is the present state of the theory of quasi-conical flows?</rawString>
</citation>
<citation valid="false">
<title>References on the methods available for accurately estimating aerodynamic heat transfer to conical bodies for both laminar and turbulent flow.</title>
<marker></marker>
<rawString>7. References on the methods available for accurately estimating aerodynamic heat transfer to conical bodies for both laminar and turbulent flow.</rawString>
</citation>
<citation valid="false">
<title>What parameters can seriously influence natural transition from laminar to turbulent flow on a model in a wind tunnel?</title>
<marker></marker>
<rawString>8. What parameters can seriously influence natural transition from laminar to turbulent flow on a model in a wind tunnel?</rawString>
</citation>
<citation valid="false">
<title>Can a satisfactory experimental technique be developed for measuring oscillatory derivatives on slender stingmounted models in supersonic wind tunnels? 10. Recent data on shock-induced boundary-layer separation.</title>
<marker></marker>
<rawString>9. Can a satisfactory experimental technique be developed for measuring oscillatory derivatives on slender stingmounted models in supersonic wind tunnels? 10. Recent data on shock-induced boundary-layer separation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ambroziak</author>
</authors>
<title>Conceptually assisted Web browsing.</title>
<date>1997</date>
<booktitle>In Sixth International World Wide Web conference,</booktitle>
<location>Santa Clara, CA.</location>
<note>full paper available online at http://www.scope.gmd.de/ info/www6/posters/ 702/guide2.html.</note>
<contexts>
<context position="6256" citStr="Ambroziak, 1997" startWordPosition="1023" endWordPosition="1024">increased performance and recall. He defines also a new measure, called success rate which indicates if a question has an answer in the top ten documents returned by a retrieval system. The success rate obtained in the case of conceptual indexing was 60%, respect to a maximum of 45% obtained using other retrieval systems. This is a significant improvement and shows that semantics can have a strong impact on the effectiveness of IR systems. The experiments described in (Woods, 1997) refer to small collections of text, as for example the Unix manual pages (about 10MB of text). But, as shown in (Ambroziak, 1997), this is not a limitation; conceptual indexing can be successfully applied to much larger text collections, and even used in Web browsing. 2.2 Query Expansion Query expansion has been proved to have positive effects in retrieving relevant information (Lu and Keefer, 1994). The purpose of query extension can be either to broaden the set of documents retrieved or to increase the retrieval precision. In the former case, the query is expanded with terms similar with the words from the original query, while in the second case the expansion procedure adds completely new terms. There are two main te</context>
</contexts>
<marker>Ambroziak, 1997</marker>
<rawString>J. Ambroziak. 1997. Conceptually assisted Web browsing. In Sixth International World Wide Web conference, Santa Clara, CA. full paper available online at http://www.scope.gmd.de/ info/www6/posters/ 702/guide2.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="19581" citStr="Brill, 1992" startWordPosition="3333" endWordPosition="3334">cedure finds gift with sense #1 as being the hypernym of donation, also with sense #1. Therefore, both words are disambiguated and marked with their assigned senses. The procedures presented above are applied iteratively. This allows us to identify a set of nouns and verbs which can be disambiguated with high precision. About 55% of the nouns and verbs are disambiguated with over 92% accuracy. Algorithm Step 1. Pre-process the text. This implies tokenization and part-of-speech tagging. The part-of-speech tagging task is performed with high accuracy using an improved version of Brill&apos;s tagger (Brill, 1992). At this step, we also identify the complex nominals, based on WordNet definitions. For example, the word sequence pipeline companies&apos;&apos; is found in WordNet and thus it is identified as a single concept. There is also a list of words which we do not attempt to disambiguate. These words are marked with a special flag to indicate that they should not be considered in the disambiguation process. So far, this list consists of three verbs: be, have, do. Step 2. Initialize the Set of Disambiguated Words (SDW) with the empty set SDW={}. Initialize the Set of Ambiguous Words (SAW) with the set formed </context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>E. Brill. 1992. A simple rule-based part of speech tagger. In Proceedings of the 3rd Conference on Applied Natural Language Processing, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Buckley</author>
<author>G Salton</author>
<author>J Allan</author>
<author>A Singhal</author>
</authors>
<title>Automatic query expansion using smart: Trec 3.</title>
<date>1994</date>
<booktitle>In Proceedings of the Text REtrieval Conference (TREC-3),</booktitle>
<pages>69--81</pages>
<contexts>
<context position="7524" citStr="Buckley et al., 1994" startWordPosition="1234" endWordPosition="1237">he first one considers the use of Machine Readable Dictionary; (Moldovan and Mihalcea, 2000) and (Voorhees, 1994) are making use of WordNet to enlarge the query such as it includes words 36 which are semantically related to the concepts from the original query. The basic semantic relation used in their systems is the synonymy relation. This technique requires the disambiguation of the words in the input query and it was reported that this method can be useful if the sense disambiguation is highly accurate. The other technique for query expansion is to use relevance feedback, as used in SMART (Buckley et al., 1994). 2.3 Semantic indexing The usage of word senses in the process of document indexing is a pretty much debated field of discussions. The basic idea is to index word meanings, rather than words taken as lexical strings. A survey of the efforts of incorporating WSD into IR is presented in (Sanderson, 2000). Experiments performed by different researchers led to various, sometime contradicting results. Nevertheless, the conclusion which can be drawn from all these experiments is that a highly accurate Word Sense Disambiguation algorithm is needed in order to obtain an increase in the performance of</context>
</contexts>
<marker>Buckley, Salton, Allan, Singhal, 1994</marker>
<rawString>C. Buckley, G. Salton, J. Allan, and A. Singhal. 1994. Automatic query expansion using smart: Trec 3. In Proceedings of the Text REtrieval Conference (TREC-3), pages 69-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet, An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="1886" citStr="Fellbaum, 1998" startWordPosition="300" endWordPosition="301"> lexical strings, or based on the semantic meaning of the words. With this idea in mind, we designed an IR system which performs a combined wordbased and sense-based indexing and retrieval. The inputs to IR systems consist of a question/query and a set of documents from which the information has to be retrieved. We add lexical and semantic information to both the query and the documents, during a preprocessing phase in which the input question and the texts are disambiguated. The disambiguation process relies on contextual information, and identify the meaning of the words based on WordNet 1 (Fellbaum, 1998) senses. As described in the fourth section, we have opted for a disambiguation algorithm which is semi-complete (it disambiguates about 55% of the nouns and verbs), but is highly precise (over 92% accuracy), instead of using a complete but less precise disambiguation. A part of speech tag is also appended to each word. After adding these lexical and semantic tags to the words, the documents are ready to be indexed: the index is created using the words as lexical strings (to ensure a word-based retrieval), and the semantic tags (for the sensebased retrieval). Once the index is created, an inpu</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet, An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejo</author>
<author>I Chugur</author>
<author>J Cigarran</author>
</authors>
<title>Indexing with WordNet synsets can improve text retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL &apos;98 Workshop on Usage of WordNet in Natural Language Processing Systems,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="10781" citStr="Gonzalo et al., 1998" startWordPosition="1774" endWordPosition="1777">R is reported by Krovetz (Krovetz and Croft, 1993), (Krovetz, 1997). When talking about word ambiguity, he collapses both the morphological and semantic aspects of ambiguity, and refers them as polysemy and homonymy. He shows that word senses should be used in addition to word based indexing, rather than indexing on word senses alone, basically because of the uncertainty involved in sense disambiguation. He had extensively studied the effect of lexical ambiguity over IR; the experiments described provide a clear indication that word meanings can improve the performance of a retrieval system. (Gonzalo et al., 1998) performed experiments in sense based indexing: they used the SMART retrieval system and a manually disambiguated collection (Semcor). It turned out that indexing by synsets can increase recall up to 29% respect to word based indexing. Part of their experiments was the simulation of a WSD algorithm with error rates of 5%, 10%, 20%, 30% and 60%: they found that error rates of up to 10% do not substantially af37 fect precision, and a system with WSD errors below 30% still perform better than a standard run. The results of their experiments are encouraging, and proved that an accurate WSD algorit</context>
</contexts>
<marker>Gonzalo, Verdejo, Chugur, Cigarran, 1998</marker>
<rawString>J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigarran. 1998. Indexing with WordNet synsets can improve text retrieval. In Proceedings of COLING-ACL &apos;98 Workshop on Usage of WordNet in Natural Language Processing Systems, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hellman</author>
</authors>
<title>A semantic approach adds meaning to the Web. Computer,</title>
<date>1999</date>
<pages>13--16</pages>
<marker>Hellman, 1999</marker>
<rawString>R. Hellman. 1999. A semantic approach adds meaning to the Web. Computer, pages 13-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Krovetz</author>
<author>W B Croft</author>
</authors>
<title>Lexical ambiguity and information retrieval.</title>
<date>1993</date>
<journal>ACM Transactions on Information Systems,</journal>
<pages>10--2</pages>
<contexts>
<context position="10210" citStr="Krovetz and Croft, 1993" startWordPosition="1681" endWordPosition="1684">of WSD over IR performance. It is shown that in the case of pseudo-words, high-frequency word types have the majority of senses of a pseudoword, i.e. the word ambiguity is not realistically modeled. More than this, (Schutze and Pedersen, 1995) performed experiments which have shown that semantics can actually help retrieval performance. They reported an increase in precision of up to 7% when sense based indexing is used alone, and up to 14% for a combined word based and sense based indexing. One of the largest studies regarding the applicability of word semantics to IR is reported by Krovetz (Krovetz and Croft, 1993), (Krovetz, 1997). When talking about word ambiguity, he collapses both the morphological and semantic aspects of ambiguity, and refers them as polysemy and homonymy. He shows that word senses should be used in addition to word based indexing, rather than indexing on word senses alone, basically because of the uncertainty involved in sense disambiguation. He had extensively studied the effect of lexical ambiguity over IR; the experiments described provide a clear indication that word meanings can improve the performance of a retrieval system. (Gonzalo et al., 1998) performed experiments in sen</context>
</contexts>
<marker>Krovetz, Croft, 1993</marker>
<rawString>R. Krovetz and W.B. Croft. 1993. Lexical ambiguity and information retrieval. ACM Transactions on Information Systems, 10(2):115-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Krovetz</author>
</authors>
<title>Homonymy and polysemy in information retrieval.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL-97),</booktitle>
<pages>72--79</pages>
<contexts>
<context position="10227" citStr="Krovetz, 1997" startWordPosition="1685" endWordPosition="1686"> It is shown that in the case of pseudo-words, high-frequency word types have the majority of senses of a pseudoword, i.e. the word ambiguity is not realistically modeled. More than this, (Schutze and Pedersen, 1995) performed experiments which have shown that semantics can actually help retrieval performance. They reported an increase in precision of up to 7% when sense based indexing is used alone, and up to 14% for a combined word based and sense based indexing. One of the largest studies regarding the applicability of word semantics to IR is reported by Krovetz (Krovetz and Croft, 1993), (Krovetz, 1997). When talking about word ambiguity, he collapses both the morphological and semantic aspects of ambiguity, and refers them as polysemy and homonymy. He shows that word senses should be used in addition to word based indexing, rather than indexing on word senses alone, basically because of the uncertainty involved in sense disambiguation. He had extensively studied the effect of lexical ambiguity over IR; the experiments described provide a clear indication that word meanings can improve the performance of a retrieval system. (Gonzalo et al., 1998) performed experiments in sense based indexing</context>
</contexts>
<marker>Krovetz, 1997</marker>
<rawString>R. Krovetz. 1997. Homonymy and polysemy in information retrieval. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL-97), pages 72-79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X A Lu</author>
<author>R B Keefer</author>
</authors>
<title>Query expansion/reduction and its impact on retrieval effectiveness.</title>
<date>1994</date>
<booktitle>In The Text REtrieval Conference (TREC-3),</booktitle>
<pages>231--240</pages>
<contexts>
<context position="6529" citStr="Lu and Keefer, 1994" startWordPosition="1065" endWordPosition="1068">maximum of 45% obtained using other retrieval systems. This is a significant improvement and shows that semantics can have a strong impact on the effectiveness of IR systems. The experiments described in (Woods, 1997) refer to small collections of text, as for example the Unix manual pages (about 10MB of text). But, as shown in (Ambroziak, 1997), this is not a limitation; conceptual indexing can be successfully applied to much larger text collections, and even used in Web browsing. 2.2 Query Expansion Query expansion has been proved to have positive effects in retrieving relevant information (Lu and Keefer, 1994). The purpose of query extension can be either to broaden the set of documents retrieved or to increase the retrieval precision. In the former case, the query is expanded with terms similar with the words from the original query, while in the second case the expansion procedure adds completely new terms. There are two main techniques used in expanding an original query. The first one considers the use of Machine Readable Dictionary; (Moldovan and Mihalcea, 2000) and (Voorhees, 1994) are making use of WordNet to enlarge the query such as it includes words 36 which are semantically related to th</context>
</contexts>
<marker>Lu, Keefer, 1994</marker>
<rawString>X.A. Lu and R.B. Keefer. 1994. Query expansion/reduction and its impact on retrieval effectiveness. In The Text REtrieval Conference (TREC-3), pages 231-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Mauldin</author>
</authors>
<title>Retrieval performance in FERRET: a conceptual information retrieval system.</title>
<date>1991</date>
<booktitle>In Proceedings of the 14th International ACM-SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>347--355</pages>
<location>Chicago, IL,</location>
<contexts>
<context position="4855" citStr="Mauldin, 1991" startWordPosition="796" endWordPosition="797">There are three main approaches reported in the literature regarding the incorporation of semantic information into IR systems: (1)conceptual indexing, (2) query expansion and (3) semantic indexing. The former is based on ontological taxonomies, while the last two make use of Word Sense Disambiguation algorithms 2.1 Conceptual indexing The usage of concepts for document indexing is a relatively new trend within the IR field. Concept matching is a technique that has been used in limited domains, like the legal field were conceptual indexing has been applied by (Stein, 1997). The FERRET system (Mauldin, 1991) is another example of 2WordNet stemmer = words are stemmed based on WordNet definitions (using the morphs&amp; function) 3The words in WordNet are organized in synonym sets, called synsets. A synset is associated with a particular sense of a word, and thus we use sense-based and synset-based interchangeably. how concept identification can improve IR systems. To our knowledge, the most intensive work in this direction was performed by Woods (Woods, 1997), at Sun Microsystems Laboratories. He creates some custom built ontological taxonomies based on subsumtion and morphology for the purpose of inde</context>
</contexts>
<marker>Mauldin, 1991</marker>
<rawString>M.L. Mauldin. 1991. Retrieval performance in FERRET: a conceptual information retrieval system. In Proceedings of the 14th International ACM-SIGIR Conference on Research and Development in Information Retrieval, pages 347-355, Chicago, IL, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D I Moldovan</author>
</authors>
<title>An iterative approach to word sense disambiguation.</title>
<date>2000</date>
<booktitle>In Proceedings of FLAIRS-2000,</booktitle>
<pages>219--223</pages>
<location>Orlando, FL,</location>
<contexts>
<context position="13557" citStr="Mihalcea and Moldovan, 2000" startWordPosition="2265" endWordPosition="2268">al of the given sense of the word and its synonyms). 3. Retrieval module, which retrieves documents, based on an input query. As we are using a combined word-based and synset-based indexing, we can retrieve documents containing either (1) the input keywords, (2) the input keywords with an assigned sense or (3) synonyms of the input keywords. 4 Word Sense Disambiguation As stated earlier, the WSD is performed for both the query and the documents from which we have to retrieve information. The WSD algorithm used for this purpose is an iterative algorithm; it was for the first time presented in (Mihalcea and Moldovan, 2000). It determines, in a given text, a set of nouns and verbs which can be disambiguated with high precision. The semantic tagging is performed using the senses defined in WordNet. In this section, we present the various methods used to identify the correct sense of a word. Then, we describe the main algorithm in which these procedures are invoked in an iterative manner. PROCEDURE 1. This procedure identifies the proper nouns in the text, and marked them as having sense #1. Example. &amp;quot;Hudson&amp;quot; is identified as a proper noun and marked with sense #1. PROCEDURE 2. Identify the words having only one s</context>
</contexts>
<marker>Mihalcea, Moldovan, 2000</marker>
<rawString>R. Mihalcea and D.I. Moldovan. 2000. An iterative approach to word sense disambiguation. In Proceedings of FLAIRS-2000, pages 219-223, Orlando, FL, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>C Leacock</author>
<author>T Randee</author>
<author>R Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the 3rd DARPA Workshop on Human Language Technology,</booktitle>
<pages>303--308</pages>
<location>Plainsboro, New Jersey.</location>
<contexts>
<context position="14739" citStr="Miller et al., 1993" startWordPosition="2475" endWordPosition="2478">. Identify the words having only one sense in WordNet (monosemous words). Mark them with sense #1. Example. The noun subcommittee has one sense defined in WordNet. Thus, it is a monosemous word and can be marked as having sense #1. PROCEDURE 3. For a given word Wi, at position i in the text, form two pairs, one with the word before Wi (pair W1_1-W1) and the other one with the word after Wi (pair WiW2+1). Determiners or conjunctions cannot 38 be part of these pairs. Then, we extract all the occurrences of these pairs found within the semantic tagged corpus formed with the 179 texts from SemCor(Miller et al., 1993). If, in all the occurrences, the word Wi has only one sense #k, and the number of occurrences of this sense is larger than 3, then mark the word Wi as having sense #k. Example. Consider the word approval in the text fragment &amp;quot; committee approval of &amp;quot; . The pairs formed are &amp;quot; committee approval&amp;quot; and &amp;quot;approval of &amp;quot; . No occurrences of the first pair are found in the corpus. Instead, there are four occurrences of the second pair, and in all these occurrences the sense of approval is sense #1. Thus, approval is marked with sense #1. PROCEDURE 4. For a given noun N in the text, determine the noun-</context>
</contexts>
<marker>Miller, Leacock, Randee, Bunker, 1993</marker>
<rawString>G. Miller, C. Leacock, T. Randee, and R. Bunker. 1993. A semantic concordance. In Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303-308, Plainsboro, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>R Mihalcea</author>
</authors>
<title>Using WordNet and lexical operators to improve Internet searches.</title>
<date>2000</date>
<journal>IEEE Internet Computing,</journal>
<pages>4--1</pages>
<contexts>
<context position="6995" citStr="Moldovan and Mihalcea, 2000" startWordPosition="1144" endWordPosition="1147">d even used in Web browsing. 2.2 Query Expansion Query expansion has been proved to have positive effects in retrieving relevant information (Lu and Keefer, 1994). The purpose of query extension can be either to broaden the set of documents retrieved or to increase the retrieval precision. In the former case, the query is expanded with terms similar with the words from the original query, while in the second case the expansion procedure adds completely new terms. There are two main techniques used in expanding an original query. The first one considers the use of Machine Readable Dictionary; (Moldovan and Mihalcea, 2000) and (Voorhees, 1994) are making use of WordNet to enlarge the query such as it includes words 36 which are semantically related to the concepts from the original query. The basic semantic relation used in their systems is the synonymy relation. This technique requires the disambiguation of the words in the input query and it was reported that this method can be useful if the sense disambiguation is highly accurate. The other technique for query expansion is to use relevance feedback, as used in SMART (Buckley et al., 1994). 2.3 Semantic indexing The usage of word senses in the process of docu</context>
</contexts>
<marker>Moldovan, Mihalcea, 2000</marker>
<rawString>D Moldovan and R. Mihalcea. 2000. Using WordNet and lexical operators to improve Internet searches. IEEE Internet Computing, 4(1):34-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Goodrum Mihalcea</author>
<author>R Girju</author>
<author>V Rus</author>
</authors>
<title>LASSO: A tool for surfing the answer net.</title>
<date>1999</date>
<booktitle>In Proceedings of the Text Retrieval Conference (TREC-8),</booktitle>
<marker>Mihalcea, Girju, Rus, 1999</marker>
<rawString>D. Moldovan, S. Harabagiu, M. Pasca, It. Mihalcea, R. Goodrum, R. Girju, and V. Rus. 1999. LASSO: A tool for surfing the answer net. In Proceedings of the Text Retrieval Conference (TREC-8), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sanderson</author>
</authors>
<title>Word sense disambiguation and information retrieval.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>142--151</pages>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="8797" citStr="Sanderson, 1994" startWordPosition="1446" endWordPosition="1447">999) tried to resolve word ambiguity in the collection of documents, as well as in the query, and then she compared the results obtained with the performance of a standard run. Even if she used different weighting schemes, the overall results have shown a degradation in IR effectiveness when word meanings were used for indexing. Still, as she pointed out, the precision of the WSD technique has a dramatic influence on these results. She states that a better WSD can lead to an increase in IR performance. A rather &amp;quot;artificial&amp;quot; experiment in the same direction of semantic indexing is provided in (Sanderson, 1994). He uses pseudo-words to test the utility of disambiguation in IR. A pseudo-word is an artificially created ambiguous word, like for example &amp;quot;banana-door&amp;quot; (pseudo-words have been introduced for the first time in (Yarowsky, 1993), as means of testing WSD accuracy without the costs associated with the acquisition of sense tagged corpora). Different levels of ambiguity were introduced in the set of documents prior to indexing. The conclusion drawn was that WSD has little impact on IR performance, to the point that only a WSD algorithm with over 90% precision could help IR systems. The reasons fo</context>
</contexts>
<marker>Sanderson, 1994</marker>
<rawString>M. Sanderson. 1994. Word sense disambiguation and information retrieval. In Proceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, pages 142-151, SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sanderson</author>
</authors>
<title>Retrieving with good sense.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<pages>2--1</pages>
<contexts>
<context position="7828" citStr="Sanderson, 2000" startWordPosition="1289" endWordPosition="1290">ms is the synonymy relation. This technique requires the disambiguation of the words in the input query and it was reported that this method can be useful if the sense disambiguation is highly accurate. The other technique for query expansion is to use relevance feedback, as used in SMART (Buckley et al., 1994). 2.3 Semantic indexing The usage of word senses in the process of document indexing is a pretty much debated field of discussions. The basic idea is to index word meanings, rather than words taken as lexical strings. A survey of the efforts of incorporating WSD into IR is presented in (Sanderson, 2000). Experiments performed by different researchers led to various, sometime contradicting results. Nevertheless, the conclusion which can be drawn from all these experiments is that a highly accurate Word Sense Disambiguation algorithm is needed in order to obtain an increase in the performance of IR systems. Ellen Voorhees (Voorhees, 1998) (Voorhees, 1999) tried to resolve word ambiguity in the collection of documents, as well as in the query, and then she compared the results obtained with the performance of a standard run. Even if she used different weighting schemes, the overall results have</context>
</contexts>
<marker>Sanderson, 2000</marker>
<rawString>M. Sanderson. 2000. Retrieving with good sense. Information Retrieval, 2(1):49-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schutze</author>
<author>J Pedersen</author>
</authors>
<title>Information retrieval based on word senses.</title>
<date>1995</date>
<booktitle>In Proceedings of the 4th Annual Symposium on Document Analysis and Information Retrieval,</booktitle>
<pages>161--175</pages>
<contexts>
<context position="9484" citStr="Schutze and Pedersen, 1995" startWordPosition="1556" endWordPosition="1559"> in IR. A pseudo-word is an artificially created ambiguous word, like for example &amp;quot;banana-door&amp;quot; (pseudo-words have been introduced for the first time in (Yarowsky, 1993), as means of testing WSD accuracy without the costs associated with the acquisition of sense tagged corpora). Different levels of ambiguity were introduced in the set of documents prior to indexing. The conclusion drawn was that WSD has little impact on IR performance, to the point that only a WSD algorithm with over 90% precision could help IR systems. The reasons for the results obtained by Sanderson have been discussed in (Schutze and Pedersen, 1995). They argue that the usage of pseudo-words does not always provide an accurate measure of the effect of WSD over IR performance. It is shown that in the case of pseudo-words, high-frequency word types have the majority of senses of a pseudoword, i.e. the word ambiguity is not realistically modeled. More than this, (Schutze and Pedersen, 1995) performed experiments which have shown that semantics can actually help retrieval performance. They reported an increase in precision of up to 7% when sense based indexing is used alone, and up to 14% for a combined word based and sense based indexing. O</context>
</contexts>
<marker>Schutze, Pedersen, 1995</marker>
<rawString>H. Schutze and J. Pedersen. 1995. Information retrieval based on word senses. In Proceedings of the 4th Annual Symposium on Document Analysis and Information Retrieval, pages 161-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Stein</author>
</authors>
<title>Alternative methods of indexing legal material: Development of a conceptual index.</title>
<date>1997</date>
<booktitle>In Proceedings of the Conference</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="4820" citStr="Stein, 1997" startWordPosition="790" endWordPosition="791">d based indexing. 2 Related Work There are three main approaches reported in the literature regarding the incorporation of semantic information into IR systems: (1)conceptual indexing, (2) query expansion and (3) semantic indexing. The former is based on ontological taxonomies, while the last two make use of Word Sense Disambiguation algorithms 2.1 Conceptual indexing The usage of concepts for document indexing is a relatively new trend within the IR field. Concept matching is a technique that has been used in limited domains, like the legal field were conceptual indexing has been applied by (Stein, 1997). The FERRET system (Mauldin, 1991) is another example of 2WordNet stemmer = words are stemmed based on WordNet definitions (using the morphs&amp; function) 3The words in WordNet are organized in synonym sets, called synsets. A synset is associated with a particular sense of a word, and thus we use sense-based and synset-based interchangeably. how concept identification can improve IR systems. To our knowledge, the most intensive work in this direction was performed by Woods (Woods, 1997), at Sun Microsystems Laboratories. He creates some custom built ontological taxonomies based on subsumtion and</context>
</contexts>
<marker>Stein, 1997</marker>
<rawString>J.A. Stein. 1997. Alternative methods of indexing legal material: Development of a conceptual index. In Proceedings of the Conference &amp;quot;Law Via the Internet 97&amp;quot;, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Query expansion using lexical-semantic relations.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th Annual International ACM SIGIR, Conference on Research and Development in Information Retrieval,</booktitle>
<pages>61--69</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="7016" citStr="Voorhees, 1994" startWordPosition="1149" endWordPosition="1150">uery Expansion Query expansion has been proved to have positive effects in retrieving relevant information (Lu and Keefer, 1994). The purpose of query extension can be either to broaden the set of documents retrieved or to increase the retrieval precision. In the former case, the query is expanded with terms similar with the words from the original query, while in the second case the expansion procedure adds completely new terms. There are two main techniques used in expanding an original query. The first one considers the use of Machine Readable Dictionary; (Moldovan and Mihalcea, 2000) and (Voorhees, 1994) are making use of WordNet to enlarge the query such as it includes words 36 which are semantically related to the concepts from the original query. The basic semantic relation used in their systems is the synonymy relation. This technique requires the disambiguation of the words in the input query and it was reported that this method can be useful if the sense disambiguation is highly accurate. The other technique for query expansion is to use relevance feedback, as used in SMART (Buckley et al., 1994). 2.3 Semantic indexing The usage of word senses in the process of document indexing is a pr</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>E.M. Voorhees. 1994. Query expansion using lexical-semantic relations. In Proceedings of the 17th Annual International ACM SIGIR, Conference on Research and Development in Information Retrieval, pages 61-69, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Using WordNet for text retrieval.</title>
<date>1998</date>
<booktitle>In WordNet, An Electronic Lexical Database,</booktitle>
<pages>285--303</pages>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="8168" citStr="Voorhees, 1998" startWordPosition="1339" endWordPosition="1340">sage of word senses in the process of document indexing is a pretty much debated field of discussions. The basic idea is to index word meanings, rather than words taken as lexical strings. A survey of the efforts of incorporating WSD into IR is presented in (Sanderson, 2000). Experiments performed by different researchers led to various, sometime contradicting results. Nevertheless, the conclusion which can be drawn from all these experiments is that a highly accurate Word Sense Disambiguation algorithm is needed in order to obtain an increase in the performance of IR systems. Ellen Voorhees (Voorhees, 1998) (Voorhees, 1999) tried to resolve word ambiguity in the collection of documents, as well as in the query, and then she compared the results obtained with the performance of a standard run. Even if she used different weighting schemes, the overall results have shown a degradation in IR effectiveness when word meanings were used for indexing. Still, as she pointed out, the precision of the WSD technique has a dramatic influence on these results. She states that a better WSD can lead to an increase in IR performance. A rather &amp;quot;artificial&amp;quot; experiment in the same direction of semantic indexing is </context>
</contexts>
<marker>Voorhees, 1998</marker>
<rawString>E.M. Voorhees. 1998. Using WordNet for text retrieval. In WordNet, An Electronic Lexical Database, pages 285-303. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Natural language processing and information retrieval. In Information Extraction: towards scalable, adaptable systems.</title>
<date>1999</date>
<journal>Lecture notes in Artificial Intelligence,</journal>
<volume>1714</volume>
<pages>32--48</pages>
<contexts>
<context position="8185" citStr="Voorhees, 1999" startWordPosition="1341" endWordPosition="1342">es in the process of document indexing is a pretty much debated field of discussions. The basic idea is to index word meanings, rather than words taken as lexical strings. A survey of the efforts of incorporating WSD into IR is presented in (Sanderson, 2000). Experiments performed by different researchers led to various, sometime contradicting results. Nevertheless, the conclusion which can be drawn from all these experiments is that a highly accurate Word Sense Disambiguation algorithm is needed in order to obtain an increase in the performance of IR systems. Ellen Voorhees (Voorhees, 1998) (Voorhees, 1999) tried to resolve word ambiguity in the collection of documents, as well as in the query, and then she compared the results obtained with the performance of a standard run. Even if she used different weighting schemes, the overall results have shown a degradation in IR effectiveness when word meanings were used for indexing. Still, as she pointed out, the precision of the WSD technique has a dramatic influence on these results. She states that a better WSD can lead to an increase in IR performance. A rather &amp;quot;artificial&amp;quot; experiment in the same direction of semantic indexing is provided in (Sand</context>
</contexts>
<marker>Voorhees, 1999</marker>
<rawString>E.M. Voorhees. 1999. Natural language processing and information retrieval. In Information Extraction: towards scalable, adaptable systems. Lecture notes in Artificial Intelligence, #1714, pages 32-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Conceptual indexing: A better way to organize knowledge.</title>
<date>1997</date>
<tech>Technical Report SMLI TR-97-61,</tech>
<institution>Sun Microsystems Laboratories,</institution>
<note>available online at: http://www.sun.com/ research/techrep/ 1997/abstract-61.html.</note>
<contexts>
<context position="5309" citStr="Woods, 1997" startWordPosition="868" endWordPosition="869">ique that has been used in limited domains, like the legal field were conceptual indexing has been applied by (Stein, 1997). The FERRET system (Mauldin, 1991) is another example of 2WordNet stemmer = words are stemmed based on WordNet definitions (using the morphs&amp; function) 3The words in WordNet are organized in synonym sets, called synsets. A synset is associated with a particular sense of a word, and thus we use sense-based and synset-based interchangeably. how concept identification can improve IR systems. To our knowledge, the most intensive work in this direction was performed by Woods (Woods, 1997), at Sun Microsystems Laboratories. He creates some custom built ontological taxonomies based on subsumtion and morphology for the purpose of indexing and retrieving documents. Comparing the performance of the system that uses conceptual indexing, with the performance obtained using classical retrieval techniques, resulted in an increased performance and recall. He defines also a new measure, called success rate which indicates if a question has an answer in the top ten documents returned by a retrieval system. The success rate obtained in the case of conceptual indexing was 60%, respect to a </context>
</contexts>
<marker>Woods, 1997</marker>
<rawString>W.A. Woods. 1997. Conceptual indexing: A better way to organize knowledge. Technical Report SMLI TR-97-61, Sun Microsystems Laboratories, April. available online at: http://www.sun.com/ research/techrep/ 1997/abstract-61.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>One sense per collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="9026" citStr="Yarowsky, 1993" startWordPosition="1481" endWordPosition="1482">rall results have shown a degradation in IR effectiveness when word meanings were used for indexing. Still, as she pointed out, the precision of the WSD technique has a dramatic influence on these results. She states that a better WSD can lead to an increase in IR performance. A rather &amp;quot;artificial&amp;quot; experiment in the same direction of semantic indexing is provided in (Sanderson, 1994). He uses pseudo-words to test the utility of disambiguation in IR. A pseudo-word is an artificially created ambiguous word, like for example &amp;quot;banana-door&amp;quot; (pseudo-words have been introduced for the first time in (Yarowsky, 1993), as means of testing WSD accuracy without the costs associated with the acquisition of sense tagged corpora). Different levels of ambiguity were introduced in the set of documents prior to indexing. The conclusion drawn was that WSD has little impact on IR performance, to the point that only a WSD algorithm with over 90% precision could help IR systems. The reasons for the results obtained by Sanderson have been discussed in (Schutze and Pedersen, 1995). They argue that the usage of pseudo-words does not always provide an accurate measure of the effect of WSD over IR performance. It is shown </context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>D. Yarowsky. 1993. One sense per collocation. In Proceedings of the ARPA Human Language Technology Workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>