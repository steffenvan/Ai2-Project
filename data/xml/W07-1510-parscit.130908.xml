<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.378451">
<title confidence="0.974807">
Querying multimodal annotation: A concordancer for GeM
</title>
<author confidence="0.994641">
Martin Thomas
</author>
<affiliation confidence="0.9975095">
Centre for Translation Studies
University of Leeds
</affiliation>
<address confidence="0.935337">
UK, LS2 9JT
</address>
<email confidence="0.998979">
m.thomas@leeds.ac.uk
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997125">
This paper presents a multimodal corpus of
comparable pack messages and the concor-
dancer that has been built to query it. The
design of the corpus and its annotation is
introduced. This is followed by a descrip-
tion of the concordancer’s interface, imple-
mentation and concordance display. Finally,
some ideas for future work are outlined.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999865428571429">
This paper introduces a multimodal concordancer1
that has been developed to investigate variation be-
tween messages on fast-moving consumer goods
packaging from China, Taiwan and the UK. The
need to develop such a concordancer arises from the
fact that these pack messages are themselves mul-
timodal. While they communicate through what
Twyman (1985) calls the visual channel, messages
are realized using a combination of three modes
(verbal, schematic, pictorial). Moreover, the verbal
components of visual messages are modulated and
segmented through typography (Waller, 1987).
It is assumed that this multimodality will have
complex implications for cross-linguistic variation
within the genre of pack messages. The specific na-
ture of these implications is not yet known, but vari-
ation in the construal of textual meaning and cohe-
sion would seem to offer a good starting point for
investigation. However, using purely linguistic an-
notation and a monomodal concordancer to analyze
such material could reveal only part of the picture.
</bodyText>
<footnote confidence="0.98398">
1http://corpus.leeds.ac.uk/-martin/
</footnote>
<page confidence="0.995207">
57
</page>
<bodyText confidence="0.998508">
An existing annotation scheme, developed by the
Genre and Multimodality (GeM) project2, is well-
suited to my needs. In addition to information about
their verbal and visual realization, the scheme pro-
vides a mechanism for encoding the rhetorical rela-
tions between message components.
However, existing tools for multimodal analysis
do not support simultaneous investigation of verbal,
visual and rhetorical phenomena. While Baldry’s
(2004) multimodal concordancer supports multilay-
ered analysis of video data, his approach does not
support the segmentation of still visual layouts, let
alone consideration of specific typographical real-
izations. From an altogether different perspective,
the database developed as part of the Typographic
Design for Children3 project does allow access to
such typographic information, but does not relate
this directly to the linguistic realization of messages.
Their multimodal realization makes pack mes-
sages a rich testing ground for the new concordancer
and Chinese and English offer great potential for
looking at multimodal cross-linguistic variation. Ty-
pographic resources are constrained by the writing
system of a given language: Chinese offers variety
in reading directions and a consistent footprint for
each character; English offers a range of case dis-
tinctions and a predictable reading direction.
</bodyText>
<sectionHeader confidence="0.824989" genericHeader="method">
2 Corpus design
</sectionHeader>
<bodyText confidence="0.996837666666667">
I take each pack as a text: through the messages
by which it is realized, it ‘functions as a unity with
respect to its environment’ (Halliday and Hasan,
</bodyText>
<footnote confidence="0.999825">
2http://www.purl.org/net/gem/
3http://www.kidstype.org/
</footnote>
<bodyText confidence="0.9767970625">
Proceedings of the Linguistic Annotation Workshop, pages 57–60,
Prague, June 2007. c�2007 Association for Computational Linguistics
1976). In the corpus, each text constitutes a record.
Each record consists of a set of files. These include
the transcribed and annotated pack messages, and
photographs of each pack face. In the future, pack
metadata will be added to describe the product cat-
egory to which the pack belongs, the product name,
brand owner, variety and so on. I will also record
the location and date of purchase of each sample.
This will support query constraints at the level of
the record (e.g. packs of a certain size) and will fa-
cilitate comparisons across time as well as across lo-
cales, or markets.
Packs are represented in the corpus in an un-
opened state. As far as possible, every message
on each face of the pack which is visible in this
state is recorded. There are good reasons for this.
Sinclair (1991) makes the point that the differences
across specific parts of a text may constitute regu-
larity within a genre. In the context of investigation
into cross-linguistic variation within a single genre,
this observation seems particularly apt.
The selection of packs for inclusion in the corpus
will be made in cooperation with an industrial part-
ner. Packs will be selected from product categories
in which the partner is active, or seeks to participate,
in all three locales. A combination of popular local
brands as well as locally established global brands
will be selected. Thus the packs will be comparable
commercially as well as in terms of the communica-
tive functions that they perform.
</bodyText>
<sectionHeader confidence="0.956893" genericHeader="method">
3 Corpus annotation
</sectionHeader>
<bodyText confidence="0.999964642857143">
The GeM scheme is described comprehensively by
Henschel (2003). It implements stand-off annota-
tion in four XML layers. The base layer segments
the document. The resulting base units are cross-
referenced by layers which describe layout, rhetori-
cal structure and navigation.
Within the layout layer, there are three main sec-
tions: layout segmentation (each layout unit con-
tains one or more base units), realization informa-
tion and a description of the layout structure of the
document. These components allow a comprehen-
sive picture of the typographic realization of the
messages to be built, from details such as font fam-
ily and colour to information about the composition
of each pack and the location, spacing and framing
of chunks of layout units.
Rhetorical relations between annotated units are
expressed in terms of Rhetorical Structure Theory
(Mann and Thompson, 1987). In the GeM imple-
mentation, RST has been extended to accommodate
the graphical elements found in multimodal texts.
RST annotation provides a way to identify patterns
in the construction of messages and to make com-
parisons across the corpus. It might be that more
RST relations of a specific type, e.g. elaboration,
are found in messages from a particular locale. Such
observations might support or contest claims, such
as that packs from developing markets convention-
ally carry more information about how to use the
product. In combination with the layout layer it will
also be possible to look for patterns in the choice of
semiotic mode used to realize messages involving
specific types of relation, such as evidence.
In sum, the aim of the annotation is not to support
low-level lexicogrammatical analysis, but rather to
facilitate the uncovering of patterns in the linguistic
and typographical realization of pack messages and
to relate these to semantic values expressed in terms
of RST relations. Such patterns may reflect local de-
sign conventions and language-dependent strategies
for ensuring textual cohesion.
So far annotation has begun with several UK and
Taiwan packs. All annotation has been performed
manually and has proved costly in terms of time. In
future it is hoped that at least some annotations may
be generated through the conversion of digital copies
of designs obtained directly from brand owners.
The pilot annotations have identified a number of
ways in which the GeM scheme will need to be ex-
tended to accommodate the genre of pack messages
and important aspects of Chinese typography: the
lists of colours and font families enumerated in the
DTD are not sufficiently extensive or delicate and
there is no mechanism in the layout annotation layer
to record the orientation and reading direction of
text.
</bodyText>
<sectionHeader confidence="0.992487" genericHeader="method">
4 The prototype concordancer
</sectionHeader>
<subsectionHeader confidence="0.999713">
4.1 Design aims and system overview
</subsectionHeader>
<bodyText confidence="0.999315">
The concordancer is an established tool for linguis-
tic analysis. Concordance lines, which show in-
stances of a key word in their immediate contexts,
</bodyText>
<page confidence="0.998908">
58
</page>
<figureCaption confidence="0.999921">
Figure 1: Multimodal concordancer interface
</figureCaption>
<bodyText confidence="0.999926620689655">
have proved useful in uncovering patterns of usage
and variation that may not be apparent either from
reading individual texts or from consulting reference
resources, such as dictionaries and grammars.
My aim was to develop a similar tool to support
multimodal analysis. Such a tool should be able
to combine questions relating to the verbal compo-
nents of messages with those relating to the typo-
graphic resources through which they are realized. It
should do this in such a way that queries can easily
be built and modified. To this end, a user interface is
needed. Finally, the concordancer should be usable
without the need for local installation of specialist
client software.
In order to meet these requirements, I adopted
a web-based client-server model. The user inter-
face is shown in Figure 1. The concordancer is
implemented in Perl as a CGI script. XPath ex-
pressions are used to identify matches from among
the XML-annotated packs and to handle cross-
references across annotation layers.
Using the concordancer interface to build a query
is a process of moving from the general to the spe-
cific. By default, all constraints are relaxed: submit-
ting a query with these selections will return every
annotated message in the corpus. More usefully, se-
lections can be made to constrain the set of records
searched and the linguistic, typographic, and picto-
rial realization properties of messages to match.
</bodyText>
<subsectionHeader confidence="0.997896">
4.2 Search criteria
</subsectionHeader>
<bodyText confidence="0.999930142857143">
The search criteria are grouped into high- and low-
level selections. I will introduce the high-level se-
lections first.
Locale and category selections control the set of
records to be processed.
Given the notion of generic regularity in the dif-
ferences between different parts of texts, it seemed
sensible to allow queries to be constrained by pack
face. Looking at the front of a shampoo bottle might
be seen as akin to looking at the abstract of an aca-
demic paper. This is a step towards implementing
more specific constraints about the on-pack position
of messages. The pack face constraint, as with most
of the remaining selections, is implemented in an
XPath expression. The remaining high-level selec-
tions constrain the type of encoded element to in-
clude in the search.
The first group of low-level selections relate to
specific font properties.
The colours used to realize messages are de-
scribed in the corpus using hexadecimal RGB
triplets. While this affords precision in annotation, it
also means that some calculation is required to sup-
port searching. The current approach is to take any
colour selected by the user from the menu and calcu-
late the distance between this and the RGB value for
each candidate match. If this distance falls within
the tolerance specified by the user, the colour is con-
sidered to match. Thus a search for green may match
RGB values representing various hues.
Finally, all matching layout units are cross-
referenced with the base units that they realize. If the
user specified a pattern to match (a string or regular
expression), this is tested against the string value of
the base unit.
</bodyText>
<subsectionHeader confidence="0.999804">
4.3 Concordance display
</subsectionHeader>
<bodyText confidence="0.9986385">
The final options on the interface control the dis-
play of the resulting concordance. In the pilot an-
notations, an English gloss for each Chinese pack
message is recorded as an XML comment. These
glosses may be reproduced in the concordance. The
other display options control whether to display the
base unit preceding and/or following the match.
Figure 2 shows the results of a query generated
from the selections shown in Figure 1. This is a
search for verbal messages on the front of packs
which are realized in a large font. Unsurprisingly,
in each case, this returns the product name which is
conventionally salient.
Details about the search query are given above the
</bodyText>
<page confidence="0.998305">
59
</page>
<figureCaption confidence="0.999596">
Figure 2: Multimodal concordance example
</figureCaption>
<bodyText confidence="0.999904964285714">
concordance. Depending on the specific query, this
may include selections for locale and product cat-
egory, the XPath expression which identifies candi-
date layout realization units, the colour selection and
the search string or regular expression.
Information relating to each match is then dis-
played. As in a traditional concordancer, matches
are presented together with the context in which they
are found. Optionally, this context includes the pre-
ceding and following base units. Moreover, the no-
tion of context is extended to include the visual en-
vironment in which each match is found. The colour
used on-pack to realize the matching message is re-
used in the presentation of the match. A thumbnail
image of the pack face on which the match is found
is also presented, as is information about the typo-
graphic realization of the match, taken from the lay-
out annotation. Links are provided to high resolu-
tion photographs and to each annotation layer for the
pack from which the match is retrieved.
The display of the thumbnail is a step towards
a more specific indication of the position of each
match on the pack. In the future, I hope to use in-
formation from the layout annotation to generate a
visual representation of the layout chunk in which
each match is found.
The number of matches found is given below the
concordance.
</bodyText>
<sectionHeader confidence="0.996068" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.99998244">
The prototype concordancer is rather slow: it takes
just under a minute to process and print every unit
in the pilot corpus and the time taken will increase
as more packs are added. But it works. It has also
been tested with files taken from the original GeM
corpus. Once they have been renamed, following
the conventions used by the concordancer, the legacy
files integrate seamlessly into the new corpus.
As noted above, there is scope for further devel-
opment in a number of areas. The pilot corpus needs
to be populated with more packs. The GeM annota-
tion scheme requires modification in certain details.
It might also be useful to add an annotation layer to
record translations of the string values of base units
rather than using XML comments for this.
As for the concordancer, support for queries based
on the rhetorical relations between message compo-
nents is the next major step. Other planned function-
ality includes the generation of typographically real-
ized layout chunks which contain query matches and
the calculation of collocation statistics which may be
compared across sets of records.
Finally, more work is needed to see whether the
concordancer is useful for the kind of analytical
work it has been developed to support.
</bodyText>
<sectionHeader confidence="0.999116" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999843954545455">
Anthony P. Baldry. 2004. Phase and transition, type and
instance: patterns in media texts seen through a multi-
modal concordancer. In Kay O’Halloran, editor, Mul-
timodal discourse analysis: Systemic-functional per-
spectives. Continuum, London.
M.A.K. Halliday and Ruqaiya Hasan. 1976. Cohesion in
English. Longman, London.
Renate Henschel, 2003. GeM Annotation Manual Ver-
sion 2. GeM Project.
William Mann and Sandra Annear Thompson. 1987.
Rhetorical structure theory: A theory of text organiza-
tion. Technical report, Information Sciences Institute,
Los Angeles.
John Sinclair. 1991. Corpus, concordance, collocation.
Oxford University Press, Oxford.
Michael Twyman. 1985. Using pictorial language:
A discussion of the dimensions of the problem. In
Thomas Walker and Robert Duffy, editors, Designing
Usable Texts, chapter 11. Academic Press, Orlando,
Florida.
Robert Waller. 1987. The Typographic Contribution to
Language. Ph.D. thesis, University of Reading.
</reference>
<page confidence="0.998413">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.895606">
<title confidence="0.999758">Querying multimodal annotation: A concordancer for GeM</title>
<author confidence="0.9787">Martin</author>
<affiliation confidence="0.998892">Centre for Translation University of</affiliation>
<address confidence="0.941868">UK, LS2</address>
<email confidence="0.998064">m.thomas@leeds.ac.uk</email>
<abstract confidence="0.997021888888889">This paper presents a multimodal corpus of comparable pack messages and the concordancer that has been built to query it. The design of the corpus and its annotation is introduced. This is followed by a description of the concordancer’s interface, implementation and concordance display. Finally, some ideas for future work are outlined.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anthony P Baldry</author>
</authors>
<title>Phase and transition, type and instance: patterns in media texts seen through a multimodal concordancer.</title>
<date>2004</date>
<booktitle>Multimodal discourse analysis: Systemic-functional perspectives. Continuum,</booktitle>
<editor>In Kay O’Halloran, editor,</editor>
<location>London.</location>
<marker>Baldry, 2004</marker>
<rawString>Anthony P. Baldry. 2004. Phase and transition, type and instance: patterns in media texts seen through a multimodal concordancer. In Kay O’Halloran, editor, Multimodal discourse analysis: Systemic-functional perspectives. Continuum, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>Ruqaiya Hasan</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English. Longman,</booktitle>
<location>London.</location>
<marker>Halliday, Hasan, 1976</marker>
<rawString>M.A.K. Halliday and Ruqaiya Hasan. 1976. Cohesion in English. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renate Henschel</author>
</authors>
<date>2003</date>
<journal>GeM Annotation Manual Version</journal>
<tech>GeM Project.</tech>
<volume>2</volume>
<contexts>
<context position="4858" citStr="Henschel (2003)" startWordPosition="745" endWordPosition="746">guistic variation within a single genre, this observation seems particularly apt. The selection of packs for inclusion in the corpus will be made in cooperation with an industrial partner. Packs will be selected from product categories in which the partner is active, or seeks to participate, in all three locales. A combination of popular local brands as well as locally established global brands will be selected. Thus the packs will be comparable commercially as well as in terms of the communicative functions that they perform. 3 Corpus annotation The GeM scheme is described comprehensively by Henschel (2003). It implements stand-off annotation in four XML layers. The base layer segments the document. The resulting base units are crossreferenced by layers which describe layout, rhetorical structure and navigation. Within the layout layer, there are three main sections: layout segmentation (each layout unit contains one or more base units), realization information and a description of the layout structure of the document. These components allow a comprehensive picture of the typographic realization of the messages to be built, from details such as font family and colour to information about the com</context>
</contexts>
<marker>Henschel, 2003</marker>
<rawString>Renate Henschel, 2003. GeM Annotation Manual Version 2. GeM Project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
<author>Sandra Annear Thompson</author>
</authors>
<title>Rhetorical structure theory: A theory of text organization.</title>
<date>1987</date>
<tech>Technical report,</tech>
<institution>Information Sciences Institute,</institution>
<location>Los Angeles.</location>
<contexts>
<context position="5669" citStr="Mann and Thompson, 1987" startWordPosition="872" endWordPosition="875">ucture and navigation. Within the layout layer, there are three main sections: layout segmentation (each layout unit contains one or more base units), realization information and a description of the layout structure of the document. These components allow a comprehensive picture of the typographic realization of the messages to be built, from details such as font family and colour to information about the composition of each pack and the location, spacing and framing of chunks of layout units. Rhetorical relations between annotated units are expressed in terms of Rhetorical Structure Theory (Mann and Thompson, 1987). In the GeM implementation, RST has been extended to accommodate the graphical elements found in multimodal texts. RST annotation provides a way to identify patterns in the construction of messages and to make comparisons across the corpus. It might be that more RST relations of a specific type, e.g. elaboration, are found in messages from a particular locale. Such observations might support or contest claims, such as that packs from developing markets conventionally carry more information about how to use the product. In combination with the layout layer it will also be possible to look for </context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>William Mann and Sandra Annear Thompson. 1987. Rhetorical structure theory: A theory of text organization. Technical report, Information Sciences Institute, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Sinclair</author>
</authors>
<title>Corpus, concordance, collocation.</title>
<date>1991</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="4085" citStr="Sinclair (1991)" startWordPosition="621" endWordPosition="622"> face. In the future, pack metadata will be added to describe the product category to which the pack belongs, the product name, brand owner, variety and so on. I will also record the location and date of purchase of each sample. This will support query constraints at the level of the record (e.g. packs of a certain size) and will facilitate comparisons across time as well as across locales, or markets. Packs are represented in the corpus in an unopened state. As far as possible, every message on each face of the pack which is visible in this state is recorded. There are good reasons for this. Sinclair (1991) makes the point that the differences across specific parts of a text may constitute regularity within a genre. In the context of investigation into cross-linguistic variation within a single genre, this observation seems particularly apt. The selection of packs for inclusion in the corpus will be made in cooperation with an industrial partner. Packs will be selected from product categories in which the partner is active, or seeks to participate, in all three locales. A combination of popular local brands as well as locally established global brands will be selected. Thus the packs will be com</context>
</contexts>
<marker>Sinclair, 1991</marker>
<rawString>John Sinclair. 1991. Corpus, concordance, collocation. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Twyman</author>
</authors>
<title>Using pictorial language: A discussion of the dimensions of the problem.</title>
<date>1985</date>
<booktitle>Designing Usable Texts, chapter 11.</booktitle>
<editor>In Thomas Walker and Robert Duffy, editors,</editor>
<publisher>Academic Press,</publisher>
<location>Orlando, Florida.</location>
<contexts>
<context position="863" citStr="Twyman (1985)" startWordPosition="129" endWordPosition="130"> that has been built to query it. The design of the corpus and its annotation is introduced. This is followed by a description of the concordancer’s interface, implementation and concordance display. Finally, some ideas for future work are outlined. 1 Introduction This paper introduces a multimodal concordancer1 that has been developed to investigate variation between messages on fast-moving consumer goods packaging from China, Taiwan and the UK. The need to develop such a concordancer arises from the fact that these pack messages are themselves multimodal. While they communicate through what Twyman (1985) calls the visual channel, messages are realized using a combination of three modes (verbal, schematic, pictorial). Moreover, the verbal components of visual messages are modulated and segmented through typography (Waller, 1987). It is assumed that this multimodality will have complex implications for cross-linguistic variation within the genre of pack messages. The specific nature of these implications is not yet known, but variation in the construal of textual meaning and cohesion would seem to offer a good starting point for investigation. However, using purely linguistic annotation and a m</context>
</contexts>
<marker>Twyman, 1985</marker>
<rawString>Michael Twyman. 1985. Using pictorial language: A discussion of the dimensions of the problem. In Thomas Walker and Robert Duffy, editors, Designing Usable Texts, chapter 11. Academic Press, Orlando, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Waller</author>
</authors>
<title>The Typographic Contribution to Language.</title>
<date>1987</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Reading.</institution>
<contexts>
<context position="1091" citStr="Waller, 1987" startWordPosition="160" endWordPosition="161">re work are outlined. 1 Introduction This paper introduces a multimodal concordancer1 that has been developed to investigate variation between messages on fast-moving consumer goods packaging from China, Taiwan and the UK. The need to develop such a concordancer arises from the fact that these pack messages are themselves multimodal. While they communicate through what Twyman (1985) calls the visual channel, messages are realized using a combination of three modes (verbal, schematic, pictorial). Moreover, the verbal components of visual messages are modulated and segmented through typography (Waller, 1987). It is assumed that this multimodality will have complex implications for cross-linguistic variation within the genre of pack messages. The specific nature of these implications is not yet known, but variation in the construal of textual meaning and cohesion would seem to offer a good starting point for investigation. However, using purely linguistic annotation and a monomodal concordancer to analyze such material could reveal only part of the picture. 1http://corpus.leeds.ac.uk/-martin/ 57 An existing annotation scheme, developed by the Genre and Multimodality (GeM) project2, is wellsuited t</context>
</contexts>
<marker>Waller, 1987</marker>
<rawString>Robert Waller. 1987. The Typographic Contribution to Language. Ph.D. thesis, University of Reading.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>