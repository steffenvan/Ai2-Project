<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000444">
<title confidence="0.9981325">
Joint Case Argument Identification for
Japanese Predicate Argument Structure Analysis
</title>
<author confidence="0.996973">
Hiroki Ouchi Hiroyuki Shindo Kevin Duh Yuji Matsumoto
</author>
<affiliation confidence="0.852238333333333">
Graduate School of Information and Science
Nara Institute of Science and Technology
8916-5, Takayama, Ikoma, Nara, 630-0192, Japan
</affiliation>
<email confidence="0.892336">
{ ouchi.hiroki.nt6, shindo, kevinduh, matsu }@is.naist.jp
</email>
<figureCaption confidence="0.994727">
Figure 1: An example of Japanese PAS. The En-
</figureCaption>
<bodyText confidence="0.997131259259259">
glish translation is “Because ϕi caught a cold, Ii
skipped school.”. The upper edges are dependency
relations, and the under edges are case arguments.
“NOM” and “ACC” represents the nominative and
accusative arguments, respectively. “ϕi” is a zero-
pronoun, referring to the antecedent “watashii”.
The case role label “NOM” and “ACC” respec-
tively represents the nominative and accusative
roles, and ϕi represents a zero-pronoun. There
are two predicates “hiita (caught)” and “yasunda
(skipped)”. For the predicate “yasunda (skipped)”,
“watashii-wa (Ii)” is the “skipper”, and “gakko-wo
(school)” is the “entity skipped”. It is easy to iden-
tify these arguments, since syntactic dependency
between an argument and its predicate is a strong
clue. On the other hand, the nominative argument
of the predicate “hiita (caught)” is “watashii-wa
(Ii)”, and this identification is more difficult be-
cause of the lack of the direct syntactic depen-
dency with “hiita (caught)”. The original nomina-
tive argument appears as a zero-pronoun, so that
we have to explore the antecedent, an element re-
ferred to by a zero-pronoun, as the argument. As
the example sentence shows, we cannot use ef-
fective syntactic information for identifying such
arguments. This type of arguments is known as
implicit arguments, a very problematic language
</bodyText>
<page confidence="0.720473">
961
</page>
<sectionHeader confidence="0.80105" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999754157894737">
Existing methods for Japanese predicate
argument structure (PAS) analysis identify
case arguments of each predicate without
considering interactions between the tar-
get PAS and others in a sentence. How-
ever, the argument structures of the pred-
icates in a sentence are semantically re-
lated to each other. This paper proposes
new methods for Japanese PAS analysis
to jointly identify case arguments of all
predicates in a sentence by (1) modeling
multiple PAS interactions with a bipar-
tite graph and (2) approximately search-
ing optimal PAS combinations. Perform-
ing experiments on the NAIST Text Cor-
pus, we demonstrate that our joint analysis
methods substantially outperform a strong
baseline and are comparable to previous
work.
</bodyText>
<sectionHeader confidence="0.981542" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991713454545455">
Predicate argument structure (PAS) analysis is a
shallow semantic parsing task that identifies ba-
sic semantic units of a sentence, such as who does
what to whom, which is similar to semantic role
labeling (SRL)&apos;.
In Japanese PAS analysis, one of the most prob-
lematic issues is that arguments are often omitted
in the surface form, resulting in so-called zero-
pronouns. Consider the sentence of Figure 1.
&apos;We use “PAS analysis” in this paper following previous
work on Japanese PAS analysis.
</bodyText>
<note confidence="0.940902">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 961–970,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999714960784314">
phenomenon for PAS analysis (Gerber and Chai,
2010; Laparra and Rigau, 2013).
Previous work on Japanese PAS analysis at-
tempted to solve this problem by identifying argu-
ments per predicate without considering interac-
tions between multiple predicates and arguments
(Taira et al., 2008; Imamura et al., 2009). How-
ever, implicit arguments are likely to be shared
by semantically-related predicates. In the above
example (Figure 1), the implicit argument of the
predicate “hiita (caught)” is shared by the other
predicate “yasunda (skipped)” as its nominative
argument “watashii (Ii)”.
Based on this intuition, we propose methods to
jointly identify optimal case arguments of all pred-
icates in a sentence taking their interactions into
account. We represent the interactions as a bipar-
tite graph that covers all predicates and candidate
arguments in a sentence, and factorize the whole
relation into the second-order relations. This in-
teraction modeling results in a hard combinatorial
problem because it is required to select the optimal
PAS combination from all possible PAS combina-
tions in a sentence. To solve this issue, we extend
the randomized hill-climbing algorithm (Zhang et
al., 2014) to search all possible PAS in the space
of bipartite graphs.
We perform experiments on the NAIST Text
Corpus (Iida et al., 2007), a standard bench-
mark for Japanese PAS analysis. Experimental
results show that compared with a strong base-
line, our methods achieve an improvement of
1.0-1.2 points in F-measure for total case argu-
ment identification, and especially improve per-
formance for implicit argument identification by
2.0-2.5 points. In addition, although we exploit no
external resources, we get comparable results to
previous work exploiting large-scale external re-
sources (Taira et al., 2008; Imamura et al., 2009;
Sasano and Kurohashi, 2011). These results sug-
gest that there is potential for more improvement
by adding external resources.
The main contributions of this work are: (1) We
present new methods to jointly identify case ar-
guments of all predicates in a sentence. (2) We
propose global feature templates that capture inter-
actions over multiple PAS. (3) Performing experi-
ments on the NAIST Text Corpus, we demonstrate
our methods are superior to a strong baseline and
comparable to the methods of representative pre-
vious work.
</bodyText>
<sectionHeader confidence="0.980009" genericHeader="method">
2 Japanese Predicate Argument
</sectionHeader>
<subsectionHeader confidence="0.8070275">
Structure Analysis
2.1 Task Overview
</subsectionHeader>
<bodyText confidence="0.999865310344827">
In Japanese PAS analysis, we identify arguments
taking part in the three major case roles, nomina-
tive (NOM), accusative (ACC) and dative (DAT)
cases, for each predicate. Case arguments can be
divided into three categories according to the posi-
tions relative to their predicates (Hayashibe et al.,
2011):
Dep: The arguments that have direct syntactic de-
pendency with the predicate.
Zero: The implicit arguments whose antecedents
appear in the same sentence and have no di-
rect syntactic dependency with the predicate.
Inter-Zero: The implicit arguments whose an-
tecedents do not appear in the same sentence.
For example, in Figure 1, the accusative argu-
ment “gakko-wo (school)” of the predicate “ya-
sunda (skipped)” is regarded as Dep, and the
nominative argument “watashii-wa (I)” (the an-
tecedent of zero-pronoun “ϕi”) of the predicate
“hiita (caught)” is Zero.
In this paper, we focus on the analysis for intra-
sentential arguments (Dep and Zero). In order to
identify inter-sentential arguments (Inter-Zero), it
is required to search a much broader space, such
as the whole document, resulting in a much harder
analysis than intra-sentential arguments.2 There-
fore, we believe that quite different approaches are
necessary to realize an inter-sentential PAS analy-
sis with high accuracy, and leave it for future work.
</bodyText>
<subsectionHeader confidence="0.750256">
2.2 Related Work
</subsectionHeader>
<bodyText confidence="0.9983685">
For Japanese PAS analysis research, the NAIST
Text Corpus has been used as a standard bench-
mark (Iida et al., 2007). One of the representa-
tive researches using the NAIST Text Corpus is
Imamura et al. (2009). They built three distinct
models corresponding to the three case roles by
extracting features defined on each pair of a predi-
cate and a candidate argument. Using each model,
they select the best candidate argument for each
case per predicate. Their models are based on
maximum entropy model and can easily incorpo-
rate various features, resulting in high accuracy.
</bodyText>
<footnote confidence="0.994808333333333">
2Around 10-20% in F measure has been achieved in pre-
vious work (Taira et al., 2008; Imamura et al., 2009; Sasano
and Kurohashi, 2011).
</footnote>
<page confidence="0.985917">
962
</page>
<figureCaption confidence="0.985315">
Figure 2: Intuitive image of a predicate-argument
graph. This graph is factorized into the local and
global features. The different line color/style indi-
cate different cases.
</figureCaption>
<bodyText confidence="0.999935153846154">
While in Imamura et al. (2009) one case ar-
gument is identified at a time per predicate, the
method proposed by Sasano and Kurohashi (2011)
simultaneously determines all the three case argu-
ments per predicate by exploiting large-scale case
frames obtained from large raw texts. They fo-
cus on identification of implicit arguments (Zero
and Inter-Zero), and achieves comparable results
to Imamura et al. (2009).
In these approaches, case arguments were iden-
tified per predicate without considering interac-
tions between multiple predicates and candidate
arguments in a sentence. In the semantic role la-
beling (SRL) task, Yang and Zong (2014) pointed
out that information of different predicates and
their candidate arguments could help each other
for identifying arguments taking part in semantic
roles. They exploited a reranking method to cap-
ture the interactions between multiple predicates
and candidate arguments, and jointly determine ar-
gument structures of all predicates in a sentence
(Yang and Zong, 2014). In this paper, we propose
new joint analysis methods for identifying case ar-
guments of all predicates in a sentence capturing
interactions between multiple predicates and can-
didate arguments.
</bodyText>
<sectionHeader confidence="0.987348" genericHeader="method">
3 Graph-Based Joint Models
</sectionHeader>
<subsectionHeader confidence="0.996691">
3.1 A Predicate-Argument Graph
</subsectionHeader>
<bodyText confidence="0.999935954545455">
We define predicate argument relations by exploit-
ing a bipartite graph, illustrated in Figure 2. The
nodes of the graph consist of two disjoint sets: the
left one is a set of candidate arguments and the
right one is a set of predicates. In this paper, we
call it a predicate-argument (PA) graph.
Each predicate node has three distinct edges
corresponding to nominative (NOM), accusative
(ACC), and dative (DAT) cases. Each edge with
a case role label joins a candidate argument node
with a predicate node, which represents a case ar-
gument of a predicate. For instance, in Figure 2
a1 is the nominative argument of p1, and a3 is the
accusative argument of p2.
Formally, a PA graph is a bipartite graph
(A, P, E), where A is the node set consisting of
candidate arguments, P the node set consisting of
predicates, and E the set of edges subject to that
there is exactly one edge e with a case role label c
outgoing from each of the predicate nodes p to a
candidate argument node a. A PA graph is defined
as follows:
</bodyText>
<equation confidence="0.99537975">
A = {a1, ..., an, an+1 = NULL}
P = {p1, ..., p.1
E = {(a, p, c) I deg(p, c) = 1,
baEA,bpEP,bcECI
</equation>
<bodyText confidence="0.999873823529412">
where deg(p, c) is the number of edges with a case
role c outgoing from p, and C is the case role label
set. We add a dummy node an+1, which is defined
for the cases where the predicate requires no case
argument or the required case argument does not
appear in the sentence. An edge e E E is repre-
sented by a tuple (a, p, c), indicating the edge with
a case role c joining a candidate argument node a
and a predicate node p. An admissible PA graph
satisfies the constraint deg(p, c) = 1, representing
that each predicate node p has only one edge with
a case role c.
To identify the whole PAS for a sentence x, we
predict the PA graph with an edge set correspond-
ing to the correct PAS from the admissible PA
graph set G(x) based on a score associated with
a PA graph y as follows:
</bodyText>
<equation confidence="0.997774">
y� = argmax Score(x, y)
yEG(x)
</equation>
<bodyText confidence="0.996869909090909">
A scoring function Score(x, y) receives a sen-
tence x and a candidate graph y as its input, and
returns a scalar value.
In this paper, we propose two scoring functions
as analysis models based on different assumptions:
(1) Per-Case Joint Model assumes the interac-
tion between multiple predicates (predicate inter-
action) and the independence between case roles,
and (2) All-Cases Joint Model assumes the in-
teraction between case roles (case interaction) as
well as the predicate interaction.
</bodyText>
<page confidence="0.901121">
963
</page>
<subsectionHeader confidence="0.997386">
3.2 Per-Case Joint Model
</subsectionHeader>
<bodyText confidence="0.999875142857143">
Per-Case Joint Model assumes that different case
roles are independent from each other. However,
for each case, interactions between multiple pred-
icates are considered jointly.
We define the score of a PA graph y to be the
sum of the scores for each case role c of the set of
the case roles C:
</bodyText>
<equation confidence="0.987887">
∑Scoreper(x, y) = Scorec(x, y) (1)
cEC
</equation>
<bodyText confidence="0.997507666666667">
The scores for each case role are defined as the dot
products between a weight vector θc and a feature
vector ϕc(x, E(y, c)):
</bodyText>
<equation confidence="0.955919">
Scorec(x, y) = θc · ϕc(x, E(y, c)) (2)
</equation>
<bodyText confidence="0.999987714285714">
where E(y, c) is the edge set associated with a
case role c in the candidate graph y, and the feature
vector is defined on the edge set.
The edge set E(y, c) in the equation (2) is uti-
lized for the two types of features, the local fea-
tures and global features, inspired by (Huang,
2008), defined as follows:
</bodyText>
<equation confidence="0.994877333333333">
θc · ϕc(x, E(y, c)) =
∑ θc ϕl(x, e) + θc ϕg(x, E(y, c)) (3)
eEE(y,c)
</equation>
<bodyText confidence="0.999298947368421">
where ϕl(x, e) denotes the local feature vector,
and ϕg(x, E(y, c)) the global feature vector. The
local feature vector ϕl(x, e) is defined on each
edge e in the edge set E(y, c) and a sentence x,
which captures a predicate-argument pair. Con-
sider the example of Figure 2. For Per-Case Joint
Model, we use edges, ea1p1, ea1p2, and ea2p3, as
local features to compute the score of the edge set
with the nominative case.
In addition, the global feature vector
ϕg(x, E(y, c)) is defined on the edge set
E(y, c), and enables the model to utilize lin-
guistically richer information over multiple
predicate-argument pairs. In this paper, we
exploit second-order relations, similar to the
second-order edge factorization of dependency
trees (McDonald and Pereira, 2006). We make a
set of edge pairs Epair by combining two edges
ei, ej in the edge set E(y, c), as follows:
</bodyText>
<equation confidence="0.616655">
Epair = { {ei, ej}  |∀ei, ej ∈ E(y, c), ei ≠ ej }
</equation>
<bodyText confidence="0.979683333333333">
For instance, in the PA graph in Figure 2, to com-
pute the score of the nominative arguments, we
make three edge pairs:
</bodyText>
<equation confidence="0.634293">
{{ea1p1, ea1p2}, {ea1p1, ea2p3}, {ea1p2, ea2p3}}
</equation>
<bodyText confidence="0.999901555555556">
Then, features are extracted from these edge pairs
and utilized for the score computation. For the
accusative and dative cases, their scores are com-
puted in the same manner. Then, we obtain the
resulting score of the PA graph by summing up
the scores of the local and global features. If we
do not consider the global features, the model re-
duces to a per-case local model similar to previous
work (Imamura et al., 2009).
</bodyText>
<subsectionHeader confidence="0.985439">
3.3 All-Cases Joint Model
</subsectionHeader>
<bodyText confidence="0.999946916666667">
While Per-Case Joint Model assumes the predi-
cate interaction with the independence between
case roles, All-Cases Joint Model assumes the
case interaction together with the predicate inter-
action. Our graph-based formulation is very flex-
ible and easily enables the extension of Per-Case
Joint Model to All-Cases Joint Model. Therefore,
we extend Per-Case Joint Model to All-Cases Joint
Model to capture the interactions between predi-
cates and all case arguments in a sentence.
We define the score of a PA graph y based on
the local and global features as follows:
</bodyText>
<equation confidence="0.993152666666667">
Scoreall(x, y) =
∑ θ · ϕl(x, e) + θ · ϕg(x, E(y)) (4)
eEE(y)
</equation>
<bodyText confidence="0.999556571428571">
where E(y) is the edge set associated with all the
case roles on the candidate graph y, ϕl(x, e) is the
local feature vector defined on each edge e in the
edge set E(y), and ϕg(x, E(y)) is the global fea-
ture vector defined on the edge set E(y).
Consider the PA graph in Figure 2. The local
features are extracted from each edge:
</bodyText>
<equation confidence="0.987863666666667">
Nominative: ea1p1, ea1p2, ea2p3
Accusative : ea2p1, ea3p2, ea3p3
Dative : ea3p1, ea4p2, ea4p3
</equation>
<bodyText confidence="0.9999397">
For the global features, we make a set of edge
pairs Epair by combining two edges ei, ej in the
edge set E(y), like Per-Case Joint Model. How-
ever, in the All-Cases Joint Model, the global fea-
tures may involve different cases (i.e. mixing
edges with different case roles). For the PA graph
in Figure 2, we make the edge pairs {ea1p1, ea2p1},
{ea3p1, ea1p2}, {ea3p2, ea4p3}, and so on. From
these edge pairs, we extract information as global
features to compute a graph score.
</bodyText>
<page confidence="0.983908">
964
</page>
<table confidence="0.99975675">
Structure Name Description
Diff-Arg PAIR ( pi.rf o pj.rf o pi.vo o pj.vo ),
( ai.ax o ai.rp o pi.ax o pi.vo ), ( aj.ax o aj.rp o pj.ax o pj.vo )
TRIANGLE ( ai.ax o ai.ax o ai.rp o aj.rp o pi.ax o pi.vo ),
( ai.ax o aj.ax o ai.rp o aj.rp o pj.ax o pj.vo ),
QUAD ( ai.ax o aj.ax o ai.rp o aj.rp o pi.vo o pj.vo )
( ai.ax o aj.ax o pi.ax o pj.ax o ai.rp o aj.rp o pi.vo o pj.vo )
( ai.ax o aj.ax o pi.rf o pj.rf o ai.rp o ai.rp o pi.vo o pi.vo )
Co-Arg BI-PREDS ( ai.rp o pi.rf o pj.rf ),
( ai.ax o ai.rp o pi.rf o pj.rf )
DEP-REL ( ai.ax o ai.rp o pi.ax o pj.ax o pi.vo o pj.vo o (x, y).dep )
if x depends on y for x,y in (pi,pj), (ai,pi), (ai,pj), (pi,ai), (pj,ai)
</table>
<tableCaption confidence="0.998315">
Table 1: Global feature templates. pi, pj is a predicate, ai is the argument connected with pi, and
</tableCaption>
<bodyText confidence="0.918260333333333">
aj is the argument connected with pj. Feature conjunction is indicated by o; ax=auxiliary, rp=relative
position, vo=voice, rf=regular form, dep=dependency. All the features are conjoined with the relative
position and the case role labels of the two predicates.
</bodyText>
<sectionHeader confidence="0.998652" genericHeader="method">
4 Global Features
</sectionHeader>
<bodyText confidence="0.9999495">
Features are extracted based on feature tem-
plates, which are functions that draw information
from the given entity. For instance, one feature
template ϕ100 = a.ax o p.vo is a conjunction of
two atomic features a.ax and p.vo, representing an
auxiliary word attached to a candidate argument
(a.ax) and the voice of a predicate (p.vo). We
design several feature templates for characterizing
each specific PA graph. Consider the PA graph
constructed from the sentence in Figure 1, and a
candidate argument “kaze-wo (a cold)” and a pred-
icate “hiita (caught)” are connected with an edge.
To characterize the graph, we draw some linguis-
tic information associated with the edge. Since the
auxiliary word attached to the candidate argument
is “wo” and the voice of the predicate is “active”,
the above feature template ϕ100 will generate a
feature instance as follows.
</bodyText>
<equation confidence="0.921075">
(a.ax = wo) o (p.vo = active)
</equation>
<bodyText confidence="0.999954769230769">
Such features are utilized for the local and global
features in the joint models.
We propose the global feature templates that
capture multiple PAS interactions based on the
Diff-Arg and Co-Arg structures, depicted in the
right part of Figure 1. The Diff-Arg structure rep-
resents that the two predicates have different can-
didate arguments, and the Co-Arg structure repre-
sents that the two predicates share the same can-
didate argument. Based on these structures, we
define the global feature templates that receive a
pair of edges in a PA graph as input and return a
feature vector, shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.941593">
4.1 Diff-Arg Features
</subsectionHeader>
<bodyText confidence="0.99998496">
The feature templates based on the Diff-Arg struc-
ture are three types: PAIR (a pair of predicate-
argument relation), TRIANGLE (a predicate and
its two arguments relation), and QUAD (two
predicate-argument relations).
PAIR These feature templates denote where the
target argument is located relative to another argu-
ment and the two predicates in the Diff-Arg struc-
ture. We combine the relative position information
(rp) with the auxiliary words (ax) and the voice of
the two predicates (vo).
TRIANGLE This type of feature templates cap-
tures the interactions between three elements: two
candidate arguments and a predicate. Like the
PAIR feature templates, we encode the relative po-
sition information of two candidate arguments and
a predicate with the auxiliary words and voice.
QUAD When we judge if a candidate argu-
ment takes part in a case role of a predicate, it
would be beneficial to grasp information of an-
other predicate-argument pair. The QUAD fea-
ture templates capture the mutual relation between
four elements: two candidate arguments and pred-
icates. We encode the relative position informa-
tion, the auxiliary words, and the voice.
</bodyText>
<subsectionHeader confidence="0.967256">
4.2 Co-Arg Features
</subsectionHeader>
<bodyText confidence="0.96031375">
To identify predicates that take implicit (Zero) ar-
guments, we set two feature types, BI-PREDS and
DEP-REL, based on the Co-Arg structure.
BI-PREDS For identifying an implicit argu-
</bodyText>
<page confidence="0.963604">
965
</page>
<bodyText confidence="0.994768333333333">
Input: the set of cases to be analyzed C,
parameter θ,, sentence x
Output: a locally optimal PA graph y�
</bodyText>
<listItem confidence="0.989097090909091">
1: Sample a PA graph y(0) from G(x)
2: t +— 0
3: for each case c E C do
4: repeat
5: Y, +— NeighborG(y(t), c) U y(t)
6: y(t+1) +— argmax θ, · ϕ,(x, E(y, c))
yEY�
7: t +— t + 1
8: until y(t) = y(t+1)
9: end for
10: return y� +— y(t)
</listItem>
<figureCaption confidence="0.997412">
Figure 3: Hill-Climbing for Per-Case Joint Model
</figureCaption>
<bodyText confidence="0.976252333333333">
Input: the set of cases to be analyzed C,
parameter θ, sentence x
Output: a locally optimal PA graph y�
</bodyText>
<listItem confidence="0.997707222222222">
1: Sample a PA graph y(0) from G(x)
2: t +— 0
3: repeat
4: Y +— NeighborG(y(t)) U y(t)
5: y(t+1) +— argmax θ · ϕ(x, E(y))
yEY
6: t +— t + 1
7: until y(t) = y(t+1)
8: return y� +— y(t)
</listItem>
<figureCaption confidence="0.993674">
Figure 4: Hill-Climbing for All-Cases Joint Model
</figureCaption>
<bodyText confidence="0.9979565">
ment of a predicate, information of another
semantically-related predicate in the sentence
could be effective. We utilize bi-grams of the reg-
ular forms (rf) of the two predicates in the Co-Arg
structure to capture the predicates that are likely to
share the same argument in the sentence.
DEP-REL We set five distinct feature templates
to capture dependency relations (dep) between the
shared argument and the two predicates. If two
elements have a direct dependency relation, we
encode its dependency relation with the auxiliary
words and the voice.
</bodyText>
<sectionHeader confidence="0.998439" genericHeader="method">
5 Inference and Training
</sectionHeader>
<subsectionHeader confidence="0.454988">
5.1 Inference for the Joint Models
</subsectionHeader>
<bodyText confidence="0.999937108695652">
Global features make the inference of finding the
maximum scoring PA graph more difficult. For
searching the graph with the highest score, we pro-
pose two greedy search algorithms by extending
the randomized hill-climbing algorithm proposed
in (Zhang et al., 2014), which has been shown to
achieve the state-of-the-art performance in depen-
dency parsing.
Figure 3 describes the pseudo code of our pro-
posed algorithm for Per-Case Joint Model. Firstly,
we set an initial PA graph y(0) sampled uniformly
from the set of admissible PA graphs G(x) (line 1
in Figure 3). Then, the union Y, is constructed
from the set of neighboring graphs with a case
NeighborG(y(t), c), which is a set of admissible
graphs obtained by changing one edge with the
case c in y(t), and the current graph y(t) (line 5).
The current graph y(t) is updated to a higher scor-
ing graph y(t+1) selected from the union Y, (line
6). The algorithm continues until no more score
improvement is possible by changing an edge with
the case c in y(t) (line 8). This repetition is exe-
cuted for other case roles in the same manner. As
a result, we can get a locally optimal graph y.
Figure 4 describes the pseudo code of the algo-
rithm for All-Cases Joint Model. The large part of
the algorithm is the same as that for Per-Case Joint
Model. The difference is that the union Y consists
of the current graph y(t) and the neighboring graph
set obtained by changing one edge in y(t) regard-
less of case roles (line 4 in Figure 4), and that the
iteration process for each case role (line 3 in Fig-
ure 3) is removed. The algorithm also continues
until no more score improvement is possible by
changing an edge in y(t), resulting in a locally op-
timal graph y.
Following Zhang et al. (2014), for a given sen-
tence x, we repeatedly run these algorithms with
K consecutive restarts. Each run starts with initial
graphs randomly sampled from the set of admis-
sible PA graphs G(x), so that we obtain K local
optimal graphs by K restarts. Then the highest
scoring one of K graphs is selected for the sen-
tence x as the result. Each run of the algorithms is
independent from each other, so that multiple runs
are easily executable in parallel.
</bodyText>
<subsectionHeader confidence="0.998294">
5.2 Training
</subsectionHeader>
<bodyText confidence="0.9998368">
Given a training data set D = {(x, y)}Z� , the
weight vectors θ (θ,) in the scoring functions of
the joint models are estimated by using machine
learning techniques. We adopt averaged percep-
tron (Collins, 2002) with a max-margin technique:
</bodyText>
<page confidence="0.92791">
966
</page>
<equation confidence="0.9028635">
Vi E {1, ..., N}, y E G(xi),
Score(xi, yi) &gt; Score(xi, y) + Ilyi − yIl1 − ξi
</equation>
<bodyText confidence="0.9966292">
where ξi &gt; 0 is the slack variable and Ilyi − yIl1 is
the Hamming distance between the gold PA graph
yi and a candidate PA graph y of the admissible
PA graphs G(xi). Following Zhang et al. (2014),
we select the highest scoring graph y� as follows:
</bodyText>
<table confidence="0.9996966">
feature Dep Zero Total
PC Joint local 84.59 42.55 77.89
+ global 85.51 44.54 78.85
AC Joint local 84.17 41.33 77.43
+ global 85.92 44.45 79.17
</table>
<tableCaption confidence="0.808354">
Table 2: Global vs Local features on the develop-
ment sets in F-measures. “PC Joint” denotes the
Per-Case Joint Model, and “AC Joint” denotes the
All-Cases Joint Model.
</tableCaption>
<equation confidence="0.96603225">
TRAIN: y� = argmax {Score(xi, y)+Ilyi−yIl1}
yEG(2i)
TEST: y� = argmax {Score(x, y)}
yEG(x)
</equation>
<bodyText confidence="0.9979985">
Using the weight vector tuned by the training, we
perform analysis on a sentence x in the test set.
</bodyText>
<sectionHeader confidence="0.999731" genericHeader="evaluation">
6 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999339">
6.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.981170414634146">
Data Set We evaluate our proposed methods on
the NAIST Text Corpus 1.5, which consists of
40,000 sentences of Japanese newspaper text (Iida
et al., 2007). While previous work has adopted
the version 1.4 beta, we adopt the latest version.
The major difference between version 1.4 beta and
1.5 is revision of dative case (corresponding to
Japanese case particle “ni”). In 1.4 beta, most of
adjunct usages of “ni” are mixed up with the argu-
ment usages of “ni”, making the identification of
dative cases seemingly easy. Therefore, our results
are not directly comparable with previous work.
We adopt standard train/dev/test split (Taira et
al., 2008) as follows:
Train Articles: Jan 1-11, Editorials: Jan-Aug
Dev Articles: Jan 12-13, Editorials: Sept
Test Articles: Jan 14-17, Editorials: Oct-Dec
We exclude inter-sentential arguments (Inter-
Zero) in our experiments. Our features make use
of the annotated POS tags, phrase boundaries, and
dependency relations annotated in the NAIST Text
Corpus. We do not use any external resources.
Baseline We adopt the pointwise method (using
only local features) proposed by Imamura et al.
(2009) as the baseline. They built three distinct
models corresponding to the three case roles. By
using each model, they estimate the likelihood that
each candidate argument plays a case role of the
target predicate as a score, and independently se-
lect the highest scoring one per predicate.
Features The baseline utilizes the Baseline Fea-
tures used in Imamura et al. (2009) and Grammat-
ical features used in Hayashibe et al. (2009), as
the “Local Features”. In addition, the joint models
utilize the “Global Features” in Table 1.
Implementation Details For our joint models
with hill-climbing, we report the average per-
formance across ten independent runs with 10
restarts, which almost reaches convergence 3. We
train the baseline and our joint models for 20 iter-
ations with averaged perceptron.
</bodyText>
<subsectionHeader confidence="0.837239">
6.2 Results
Local Features vs Global Features
</subsectionHeader>
<bodyText confidence="0.9752528">
Table 2 shows the effectiveness of the global fea-
tures on the development sets. We incrementally
add the global features to the both models that uti-
lize only the local features. The results show that
the global features improve the performance by
about 1.0 point in F-measures in total. For and
are particularly beneficial to the implicit (Zero)
argument identification (an improvement of 1.99
points in Per-Case Joint Model and 3.12 points in
All-Cases Joint Model).
</bodyText>
<subsectionHeader confidence="0.902813">
Pointwise Methods vs Joint Methods
</subsectionHeader>
<bodyText confidence="0.999981909090909">
Table 3 presents the F-measures of the baseline
and our joint methods on the test set of the NAIST
Text Corpus. We used the bootstrap resampling
method as the significance test. In most of the met-
rics, our proposed joint methods outperform the
baseline pointwise method. Note that since Per-
Case Joint Model yields better results compared
with the baseline, capturing the predicate inter-
action is beneficial to Japanese PAS analysis. In
addition, the joint methods achieve a considerable
improvement of 2.0-2.5 points in F-measure for
</bodyText>
<footnote confidence="0.963184">
3Performance did not change when increasing the number
of restarts
</footnote>
<page confidence="0.958972">
967
</page>
<table confidence="0.999811153846154">
Case Type # of Args. Baseline PC Joint AC Joint
NOM Dep 14055 86.50 87.54 † 88.13 † t
Zero 4935 45.56 47.62 48.11
Total 18990 77.31 78.39 † 79.03 † t
ACC Dep 9473 92.84 * 93.09 † * 92.74
Zero 833 21.38 22.73 24.43
Total 10306 88.86 * 89.00 † * 88.47
DAT Dep 2518 30.97 34.29 † 38.39 † t
Zero 239 0.83 0.83 4.80
Total 2757 29.02 32.20 † 36.35 † t
ALL Dep 26046 85.06 85.79 † 86.07 † t
Zero 6007 41.65 43.60 44.09
Total 32053 78.15 78.91 † 79.23 † t
</table>
<tableCaption confidence="0.994925333333333">
Table 3: F-measures of the three methods in the test sets. The bold values denote the highest F-measures
among all the three methods. Statistical significance with p &lt; 0.05 is marked with † compared with
Baseline, t compared with PC Joint, and * compared with AC Joint.
</tableCaption>
<table confidence="0.999846142857143">
Dep Zero
NOM ACC DAT NOM ACC DAT
TA08 75.53 88.20 89.51 30.15 11.41 3.66
IM09 87.0 93.9 80.8 50.0 30.8 0.0
S&amp;K11 - - - 39.5 17.5 8.9
PC Joint 87.54 93.09 34.19 47.62 22.73 0.83
AC Joint 88.13 92.74 38.39 48.11 24.44 4.80
</table>
<tableCaption confidence="0.99669">
Table 4: Comparison with previous work using the NAIST Text Corpus in F-measure. TA08 is Taira et
</tableCaption>
<bodyText confidence="0.990190888888889">
al. (2008), IM09 is Imamura et al. (2009), and S&amp;K11 is Sasano &amp; Kurohashi (2011). Their results are
not directly comparable to ours since they use external resources and the NAIST Text Corpus 1.4 beta.
the implicit arguments (Zero), one of the problem-
atic issues in Japanese PAS analysis.
Comparing the joint methods, each of our two
joint methods is effective for a different case role.
Per-Case Joint Model is better at the ACC case,
and All-Cases Joint Model is better at the NOM
and DAT cases. One of the possible explanations is
that the distribution of ACC cases is different from
NOM cases. While the ratio of Dep and Zero argu-
ments for ACC cases is 90:10, the ratio for NOM
cases is 75:25. This might have some negative
effects on the ACC case identification with All-
Cases Joint Model. However, in total, All-Cases
Joint Model achieves significantly better results.
This suggests that capturing case interactions im-
proves performance of Japanese PAS analysis.
</bodyText>
<subsectionHeader confidence="0.630314">
Existing Methods vs Joint Methods
</subsectionHeader>
<bodyText confidence="0.999748541666667">
To compare our proposed methods with previous
work, we pick the three pieces of representative
previous work exploiting the NAIST Text Cor-
pus: Taira et al. (2008) (TA08), Imamura et al.
(2009) (IM09), and Sasano and Kurohashi (2011)
(S&amp;K11). Sasano and Kurohashi (2011) focus on
the analysis for the Zero and Inter-Zero arguments,
and do not report the results on the Dep arguments.
With respect to the Dep arguments, the All-Cases
Joint Model achieves the best result for the NOM
cases, Imamura et al. (2009) the best for the ACC
cases, and Taira et al. (2008) the best for the DAT
cases. In terms of the Zero arguments, Imamura
et al. (2009) is the best for the NOM and ACC
cases, and Sasano and Kurohashi (2011) the best
for the DAT cases. Our joint methods achieve high
performance comparable to Imamura et al. (2009).
However, because they used additional exter-
nal resources and a different version of the NAIST
Text Corpus, the results of previous work are not
directly comparable to ours. Our research direc-
tion and contributions are orthogonal to theirs, and
adding their external resources could potentially
leads to much better results.
</bodyText>
<page confidence="0.994153">
968
</page>
<sectionHeader confidence="0.999098" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999995833333334">
We have presented joint methods for Japanese PAS
analysis, which model interactions between mul-
tiple predicates and arguments using a bipartite
graph and greedily search the optimal PAS combi-
nation in a sentence. Experimental results shows
that capturing the predicate interaction and case
interaction is effective for Japanese PAS analy-
sis. In particular, implicit (Zero) argument identi-
fication, one of the problematic issues in Japanese
PAS analysis, is improved by taking such interac-
tions into account. Since this framework is appli-
cable to the argument classification in SRL, apply-
ing our methods to that task is an interesting line
of the future research. In addition, the final results
of our joint methods are comparable to represen-
tative existing methods despite using no external
resources. For future work, we plan to incorporate
external resources for our joint methods.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999719">
We are grateful to the anonymous reviewers. This
work is partially supported by a JSPS KAKENHI
Grant Number 26730121 and 15K16053.
</bodyText>
<sectionHeader confidence="0.998387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999553370370371">
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages 1–
8, Philadelphia, July. Association for Computational
Linguistics.
Matthew Gerber and Joyce Chai. 2010. Beyond nom-
bank: A study of implicit arguments for nominal
predicates. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 1583–1592, Uppsala, Sweden, July. As-
sociation for Computational Linguistics.
Yuta Hayashibe, Mamoru Komachi, and Yuji Mat-
sumoto. 2011. Japanese predicate argument struc-
ture analysis exploiting argument position and type.
In Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 201–209,
Chiang Mai, Thailand, November. Asian Federation
of Natural Language Processing.
Liang Huang. 2008. Forest reranking: Discrimina-
tive parsing with non-local features. In Proceedings
of 46th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 586–594, Columbus, Ohio, June. Asso-
ciation for Computational Linguistics.
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji
Matsumoto. 2007. Annotating a japanese text cor-
pus with predicate-argument and coreference rela-
tions. In Proceedings of the Linguistic Annotation
Workshop, pages 132–139, Prague, Czech Republic,
June. Association for Computational Linguistics.
Kenji Imamura, Kuniko Saito, and Tomoko Izumi.
2009. Discriminative approach to predicate-
argument structure analysis with zero-anaphora res-
olution. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the Association for Com-
putational Linguistics and 4th International Joint
Conference on Natural Language Processing, pages
85–88, Suntec, Singapore, August. Association for
Computational Linguistics.
Egoitz Laparra and German Rigau. 2013. Impar: A
deterministic algorithm for implicit semantic role la-
belling. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 1180–1189, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
Ryan McDonald and Fernando Pereira. 2006. Online
learning of approximate dependency parsing algo-
rithms. In Proceedings of the 11th conference on
European Chapter of the Association for Compu-
tational Linguistics (EACL), pages 81–88, Trento,
Italy, April. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.986697">
969
</page>
<reference confidence="0.998891444444445">
Ryohei Sasano and Sadao Kurohashi. 2011. A dis-
criminative approach to japanese zero anaphora res-
olution with large-scale lexicalized case frames. In
Proceedings of 5th International Joint Conference
on Natural Language Processing, pages 758–766,
Chiang Mai, Thailand, November. Asian Federation
of Natural Language Processing.
Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata.
2008. A japanese predicate argument structure anal-
ysis using decision lists. In Proceedings of the 2008
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 523–532, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
Haitong Yang and Chengqing Zong. 2014. Multi-
predicate semantic role labeling. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 363–
373, Doha, Qatar, October. Association for Compu-
tational Linguistics.
Yuan Zhang, Tao Lei, Regina Barzilay, and Tommi
Jaakkola. 2014. Greed is good if randomized: New
inference for dependency parsing. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1013–
1024, Doha, Qatar, October. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.997778">
970
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.584366">
<title confidence="0.9984625">Joint Case Argument Identification Japanese Predicate Argument Structure Analysis</title>
<author confidence="0.9963">Hiroki Ouchi Hiroyuki Shindo Kevin Duh Yuji</author>
<affiliation confidence="0.9992825">Graduate School of Information and Nara Institute of Science and</affiliation>
<address confidence="0.987109">8916-5, Takayama, Ikoma, Nara, 630-0192,</address>
<email confidence="0.902137">shindo,kevinduh,matsu</email>
<abstract confidence="0.992208387755102">Figure 1: An example of Japanese PAS. The Entranslation is “Because a cold, skipped school.”. The upper edges are dependency relations, and the under edges are case arguments. and represents the nominative and arguments, respectively. is a zeroreferring to the case role label and respectively represents the nominative and accusative and a zero-pronoun. There are two predicates “hiita (caught)” and “yasunda (skipped)”. For the predicate “yasunda (skipped)”, is the “skipper”, and (school)” is the “entity skipped”. It is easy to identify these arguments, since syntactic dependency between an argument and its predicate is a strong clue. On the other hand, the nominative argument the predicate “hiita (caught)” is and this identification is more difficult because of the lack of the direct syntactic dependency with “hiita (caught)”. The original nominative argument appears as a zero-pronoun, so that have to explore the an element referred to by a zero-pronoun, as the argument. As the example sentence shows, we cannot use effective syntactic information for identifying such arguments. This type of arguments is known as a very problematic language 961 Abstract Existing methods for Japanese predicate argument structure (PAS) analysis identify case arguments of each predicate without considering interactions between the target PAS and others in a sentence. However, the argument structures of the predicates in a sentence are semantically related to each other. This paper proposes new methods for Japanese PAS analysis to jointly identify case arguments of all predicates in a sentence by (1) modeling multiple PAS interactions with a bipartite graph and (2) approximately searching optimal PAS combinations. Performing experiments on the NAIST Text Corpus, we demonstrate that our joint analysis methods substantially outperform a strong baseline and are comparable to previous work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia,</location>
<contexts>
<context position="23087" citStr="Collins, 2002" startWordPosition="3934" endWordPosition="3935">rithms with K consecutive restarts. Each run starts with initial graphs randomly sampled from the set of admissible PA graphs G(x), so that we obtain K local optimal graphs by K restarts. Then the highest scoring one of K graphs is selected for the sentence x as the result. Each run of the algorithms is independent from each other, so that multiple runs are easily executable in parallel. 5.2 Training Given a training data set D = {(x, y)}Z� , the weight vectors θ (θ,) in the scoring functions of the joint models are estimated by using machine learning techniques. We adopt averaged perceptron (Collins, 2002) with a max-margin technique: 966 Vi E {1, ..., N}, y E G(xi), Score(xi, yi) &gt; Score(xi, y) + Ilyi − yIl1 − ξi where ξi &gt; 0 is the slack variable and Ilyi − yIl1 is the Hamming distance between the gold PA graph yi and a candidate PA graph y of the admissible PA graphs G(xi). Following Zhang et al. (2014), we select the highest scoring graph y� as follows: feature Dep Zero Total PC Joint local 84.59 42.55 77.89 + global 85.51 44.54 78.85 AC Joint local 84.17 41.33 77.43 + global 85.92 44.45 79.17 Table 2: Global vs Local features on the development sets in F-measures. “PC Joint” denotes the Pe</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1– 8, Philadelphia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Gerber</author>
<author>Joyce Chai</author>
</authors>
<title>Beyond nombank: A study of implicit arguments for nominal predicates.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1583--1592</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="3245" citStr="Gerber and Chai, 2010" startWordPosition="490" endWordPosition="493">o semantic role labeling (SRL)&apos;. In Japanese PAS analysis, one of the most problematic issues is that arguments are often omitted in the surface form, resulting in so-called zeropronouns. Consider the sentence of Figure 1. &apos;We use “PAS analysis” in this paper following previous work on Japanese PAS analysis. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 961–970, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics phenomenon for PAS analysis (Gerber and Chai, 2010; Laparra and Rigau, 2013). Previous work on Japanese PAS analysis attempted to solve this problem by identifying arguments per predicate without considering interactions between multiple predicates and arguments (Taira et al., 2008; Imamura et al., 2009). However, implicit arguments are likely to be shared by semantically-related predicates. In the above example (Figure 1), the implicit argument of the predicate “hiita (caught)” is shared by the other predicate “yasunda (skipped)” as its nominative argument “watashii (Ii)”. Based on this intuition, we propose methods to jointly identify optim</context>
</contexts>
<marker>Gerber, Chai, 2010</marker>
<rawString>Matthew Gerber and Joyce Chai. 2010. Beyond nombank: A study of implicit arguments for nominal predicates. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1583–1592, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuta Hayashibe</author>
<author>Mamoru Komachi</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese predicate argument structure analysis exploiting argument position and type.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>201--209</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="5902" citStr="Hayashibe et al., 2011" startWordPosition="904" endWordPosition="907">ropose global feature templates that capture interactions over multiple PAS. (3) Performing experiments on the NAIST Text Corpus, we demonstrate our methods are superior to a strong baseline and comparable to the methods of representative previous work. 2 Japanese Predicate Argument Structure Analysis 2.1 Task Overview In Japanese PAS analysis, we identify arguments taking part in the three major case roles, nominative (NOM), accusative (ACC) and dative (DAT) cases, for each predicate. Case arguments can be divided into three categories according to the positions relative to their predicates (Hayashibe et al., 2011): Dep: The arguments that have direct syntactic dependency with the predicate. Zero: The implicit arguments whose antecedents appear in the same sentence and have no direct syntactic dependency with the predicate. Inter-Zero: The implicit arguments whose antecedents do not appear in the same sentence. For example, in Figure 1, the accusative argument “gakko-wo (school)” of the predicate “yasunda (skipped)” is regarded as Dep, and the nominative argument “watashii-wa (I)” (the antecedent of zero-pronoun “ϕi”) of the predicate “hiita (caught)” is Zero. In this paper, we focus on the analysis for</context>
</contexts>
<marker>Hayashibe, Komachi, Matsumoto, 2011</marker>
<rawString>Yuta Hayashibe, Mamoru Komachi, and Yuji Matsumoto. 2011. Japanese predicate argument structure analysis exploiting argument position and type. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 201–209, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>586--594</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="12304" citStr="Huang, 2008" startWordPosition="2011" endWordPosition="2012">tly. We define the score of a PA graph y to be the sum of the scores for each case role c of the set of the case roles C: ∑Scoreper(x, y) = Scorec(x, y) (1) cEC The scores for each case role are defined as the dot products between a weight vector θc and a feature vector ϕc(x, E(y, c)): Scorec(x, y) = θc · ϕc(x, E(y, c)) (2) where E(y, c) is the edge set associated with a case role c in the candidate graph y, and the feature vector is defined on the edge set. The edge set E(y, c) in the equation (2) is utilized for the two types of features, the local features and global features, inspired by (Huang, 2008), defined as follows: θc · ϕc(x, E(y, c)) = ∑ θc ϕl(x, e) + θc ϕg(x, E(y, c)) (3) eEE(y,c) where ϕl(x, e) denotes the local feature vector, and ϕg(x, E(y, c)) the global feature vector. The local feature vector ϕl(x, e) is defined on each edge e in the edge set E(y, c) and a sentence x, which captures a predicate-argument pair. Consider the example of Figure 2. For Per-Case Joint Model, we use edges, ea1p1, ea1p2, and ea2p3, as local features to compute the score of the edge set with the nominative case. In addition, the global feature vector ϕg(x, E(y, c)) is defined on the edge set E(y, c), </context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 586–594, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating a japanese text corpus with predicate-argument and coreference relations.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop,</booktitle>
<pages>132--139</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="4514" citStr="Iida et al., 2007" startWordPosition="688" endWordPosition="691">aking their interactions into account. We represent the interactions as a bipartite graph that covers all predicates and candidate arguments in a sentence, and factorize the whole relation into the second-order relations. This interaction modeling results in a hard combinatorial problem because it is required to select the optimal PAS combination from all possible PAS combinations in a sentence. To solve this issue, we extend the randomized hill-climbing algorithm (Zhang et al., 2014) to search all possible PAS in the space of bipartite graphs. We perform experiments on the NAIST Text Corpus (Iida et al., 2007), a standard benchmark for Japanese PAS analysis. Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points. In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). These results suggest that there is potential for more improvement by adding</context>
<context position="7046" citStr="Iida et al., 2007" startWordPosition="1086" endWordPosition="1089">cate “hiita (caught)” is Zero. In this paper, we focus on the analysis for intrasentential arguments (Dep and Zero). In order to identify inter-sentential arguments (Inter-Zero), it is required to search a much broader space, such as the whole document, resulting in a much harder analysis than intra-sentential arguments.2 Therefore, we believe that quite different approaches are necessary to realize an inter-sentential PAS analysis with high accuracy, and leave it for future work. 2.2 Related Work For Japanese PAS analysis research, the NAIST Text Corpus has been used as a standard benchmark (Iida et al., 2007). One of the representative researches using the NAIST Text Corpus is Imamura et al. (2009). They built three distinct models corresponding to the three case roles by extracting features defined on each pair of a predicate and a candidate argument. Using each model, they select the best candidate argument for each case per predicate. Their models are based on maximum entropy model and can easily incorporate various features, resulting in high accuracy. 2Around 10-20% in F measure has been achieved in previous work (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). 962 Figu</context>
<context position="24140" citStr="Iida et al., 2007" startWordPosition="4122" endWordPosition="4125"> 78.85 AC Joint local 84.17 41.33 77.43 + global 85.92 44.45 79.17 Table 2: Global vs Local features on the development sets in F-measures. “PC Joint” denotes the Per-Case Joint Model, and “AC Joint” denotes the All-Cases Joint Model. TRAIN: y� = argmax {Score(xi, y)+Ilyi−yIl1} yEG(2i) TEST: y� = argmax {Score(x, y)} yEG(x) Using the weight vector tuned by the training, we perform analysis on a sentence x in the test set. 6 Experiment 6.1 Experimental Settings Data Set We evaluate our proposed methods on the NAIST Text Corpus 1.5, which consists of 40,000 sentences of Japanese newspaper text (Iida et al., 2007). While previous work has adopted the version 1.4 beta, we adopt the latest version. The major difference between version 1.4 beta and 1.5 is revision of dative case (corresponding to Japanese case particle “ni”). In 1.4 beta, most of adjunct usages of “ni” are mixed up with the argument usages of “ni”, making the identification of dative cases seemingly easy. Therefore, our results are not directly comparable with previous work. We adopt standard train/dev/test split (Taira et al., 2008) as follows: Train Articles: Jan 1-11, Editorials: Jan-Aug Dev Articles: Jan 12-13, Editorials: Sept Test A</context>
</contexts>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007. Annotating a japanese text corpus with predicate-argument and coreference relations. In Proceedings of the Linguistic Annotation Workshop, pages 132–139, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kenji Imamura</author>
<author>Kuniko Saito</author>
<author>Tomoko Izumi</author>
</authors>
<title>Discriminative approach to predicateargument structure analysis with zero-anaphora resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and 4th International Joint Conference on Natural Language Processing,</booktitle>
<pages>85--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="3500" citStr="Imamura et al., 2009" startWordPosition="529" endWordPosition="532">aper following previous work on Japanese PAS analysis. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 961–970, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics phenomenon for PAS analysis (Gerber and Chai, 2010; Laparra and Rigau, 2013). Previous work on Japanese PAS analysis attempted to solve this problem by identifying arguments per predicate without considering interactions between multiple predicates and arguments (Taira et al., 2008; Imamura et al., 2009). However, implicit arguments are likely to be shared by semantically-related predicates. In the above example (Figure 1), the implicit argument of the predicate “hiita (caught)” is shared by the other predicate “yasunda (skipped)” as its nominative argument “watashii (Ii)”. Based on this intuition, we propose methods to jointly identify optimal case arguments of all predicates in a sentence taking their interactions into account. We represent the interactions as a bipartite graph that covers all predicates and candidate arguments in a sentence, and factorize the whole relation into the second</context>
<context position="5007" citStr="Imamura et al., 2009" startWordPosition="762" endWordPosition="765">o search all possible PAS in the space of bipartite graphs. We perform experiments on the NAIST Text Corpus (Iida et al., 2007), a standard benchmark for Japanese PAS analysis. Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points. In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). These results suggest that there is potential for more improvement by adding external resources. The main contributions of this work are: (1) We present new methods to jointly identify case arguments of all predicates in a sentence. (2) We propose global feature templates that capture interactions over multiple PAS. (3) Performing experiments on the NAIST Text Corpus, we demonstrate our methods are superior to a strong baseline and comparable to the methods of representative previous work. 2 Japanese Predicate Argument Structure Analysis 2.1 Task Overview In Japa</context>
<context position="7137" citStr="Imamura et al. (2009)" startWordPosition="1102" endWordPosition="1105">al arguments (Dep and Zero). In order to identify inter-sentential arguments (Inter-Zero), it is required to search a much broader space, such as the whole document, resulting in a much harder analysis than intra-sentential arguments.2 Therefore, we believe that quite different approaches are necessary to realize an inter-sentential PAS analysis with high accuracy, and leave it for future work. 2.2 Related Work For Japanese PAS analysis research, the NAIST Text Corpus has been used as a standard benchmark (Iida et al., 2007). One of the representative researches using the NAIST Text Corpus is Imamura et al. (2009). They built three distinct models corresponding to the three case roles by extracting features defined on each pair of a predicate and a candidate argument. Using each model, they select the best candidate argument for each case per predicate. Their models are based on maximum entropy model and can easily incorporate various features, resulting in high accuracy. 2Around 10-20% in F measure has been achieved in previous work (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). 962 Figure 2: Intuitive image of a predicate-argument graph. This graph is factorized into the loca</context>
<context position="13896" citStr="Imamura et al., 2009" startWordPosition="2296" endWordPosition="2299">j} |∀ei, ej ∈ E(y, c), ei ≠ ej } For instance, in the PA graph in Figure 2, to compute the score of the nominative arguments, we make three edge pairs: {{ea1p1, ea1p2}, {ea1p1, ea2p3}, {ea1p2, ea2p3}} Then, features are extracted from these edge pairs and utilized for the score computation. For the accusative and dative cases, their scores are computed in the same manner. Then, we obtain the resulting score of the PA graph by summing up the scores of the local and global features. If we do not consider the global features, the model reduces to a per-case local model similar to previous work (Imamura et al., 2009). 3.3 All-Cases Joint Model While Per-Case Joint Model assumes the predicate interaction with the independence between case roles, All-Cases Joint Model assumes the case interaction together with the predicate interaction. Our graph-based formulation is very flexible and easily enables the extension of Per-Case Joint Model to All-Cases Joint Model. Therefore, we extend Per-Case Joint Model to All-Cases Joint Model to capture the interactions between predicates and all case arguments in a sentence. We define the score of a PA graph y based on the local and global features as follows: Scoreall(x</context>
<context position="25117" citStr="Imamura et al. (2009)" startWordPosition="4274" endWordPosition="4277"> easy. Therefore, our results are not directly comparable with previous work. We adopt standard train/dev/test split (Taira et al., 2008) as follows: Train Articles: Jan 1-11, Editorials: Jan-Aug Dev Articles: Jan 12-13, Editorials: Sept Test Articles: Jan 14-17, Editorials: Oct-Dec We exclude inter-sentential arguments (InterZero) in our experiments. Our features make use of the annotated POS tags, phrase boundaries, and dependency relations annotated in the NAIST Text Corpus. We do not use any external resources. Baseline We adopt the pointwise method (using only local features) proposed by Imamura et al. (2009) as the baseline. They built three distinct models corresponding to the three case roles. By using each model, they estimate the likelihood that each candidate argument plays a case role of the target predicate as a score, and independently select the highest scoring one per predicate. Features The baseline utilizes the Baseline Features used in Imamura et al. (2009) and Grammatical features used in Hayashibe et al. (2009), as the “Local Features”. In addition, the joint models utilize the “Global Features” in Table 1. Implementation Details For our joint models with hill-climbing, we report t</context>
<context position="28141" citStr="Imamura et al. (2009)" startWordPosition="4802" endWordPosition="4805">F-measures of the three methods in the test sets. The bold values denote the highest F-measures among all the three methods. Statistical significance with p &lt; 0.05 is marked with † compared with Baseline, t compared with PC Joint, and * compared with AC Joint. Dep Zero NOM ACC DAT NOM ACC DAT TA08 75.53 88.20 89.51 30.15 11.41 3.66 IM09 87.0 93.9 80.8 50.0 30.8 0.0 S&amp;K11 - - - 39.5 17.5 8.9 PC Joint 87.54 93.09 34.19 47.62 22.73 0.83 AC Joint 88.13 92.74 38.39 48.11 24.44 4.80 Table 4: Comparison with previous work using the NAIST Text Corpus in F-measure. TA08 is Taira et al. (2008), IM09 is Imamura et al. (2009), and S&amp;K11 is Sasano &amp; Kurohashi (2011). Their results are not directly comparable to ours since they use external resources and the NAIST Text Corpus 1.4 beta. the implicit arguments (Zero), one of the problematic issues in Japanese PAS analysis. Comparing the joint methods, each of our two joint methods is effective for a different case role. Per-Case Joint Model is better at the ACC case, and All-Cases Joint Model is better at the NOM and DAT cases. One of the possible explanations is that the distribution of ACC cases is different from NOM cases. While the ratio of Dep and Zero arguments </context>
<context position="29612" citStr="Imamura et al. (2009)" startWordPosition="5048" endWordPosition="5051">at capturing case interactions improves performance of Japanese PAS analysis. Existing Methods vs Joint Methods To compare our proposed methods with previous work, we pick the three pieces of representative previous work exploiting the NAIST Text Corpus: Taira et al. (2008) (TA08), Imamura et al. (2009) (IM09), and Sasano and Kurohashi (2011) (S&amp;K11). Sasano and Kurohashi (2011) focus on the analysis for the Zero and Inter-Zero arguments, and do not report the results on the Dep arguments. With respect to the Dep arguments, the All-Cases Joint Model achieves the best result for the NOM cases, Imamura et al. (2009) the best for the ACC cases, and Taira et al. (2008) the best for the DAT cases. In terms of the Zero arguments, Imamura et al. (2009) is the best for the NOM and ACC cases, and Sasano and Kurohashi (2011) the best for the DAT cases. Our joint methods achieve high performance comparable to Imamura et al. (2009). However, because they used additional external resources and a different version of the NAIST Text Corpus, the results of previous work are not directly comparable to ours. Our research direction and contributions are orthogonal to theirs, and adding their external resources could pote</context>
</contexts>
<marker>Imamura, Saito, Izumi, 2009</marker>
<rawString>Kenji Imamura, Kuniko Saito, and Tomoko Izumi. 2009. Discriminative approach to predicateargument structure analysis with zero-anaphora resolution. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and 4th International Joint Conference on Natural Language Processing, pages 85–88, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Egoitz Laparra</author>
<author>German Rigau</author>
</authors>
<title>Impar: A deterministic algorithm for implicit semantic role labelling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1180--1189</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="3271" citStr="Laparra and Rigau, 2013" startWordPosition="494" endWordPosition="497">g (SRL)&apos;. In Japanese PAS analysis, one of the most problematic issues is that arguments are often omitted in the surface form, resulting in so-called zeropronouns. Consider the sentence of Figure 1. &apos;We use “PAS analysis” in this paper following previous work on Japanese PAS analysis. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 961–970, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics phenomenon for PAS analysis (Gerber and Chai, 2010; Laparra and Rigau, 2013). Previous work on Japanese PAS analysis attempted to solve this problem by identifying arguments per predicate without considering interactions between multiple predicates and arguments (Taira et al., 2008; Imamura et al., 2009). However, implicit arguments are likely to be shared by semantically-related predicates. In the above example (Figure 1), the implicit argument of the predicate “hiita (caught)” is shared by the other predicate “yasunda (skipped)” as its nominative argument “watashii (Ii)”. Based on this intuition, we propose methods to jointly identify optimal case arguments of all p</context>
</contexts>
<marker>Laparra, Rigau, 2013</marker>
<rawString>Egoitz Laparra and German Rigau. 2013. Impar: A deterministic algorithm for implicit semantic role labelling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1180–1189, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th conference on European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>81--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Trento, Italy,</location>
<contexts>
<context position="13156" citStr="McDonald and Pereira, 2006" startWordPosition="2156" endWordPosition="2159">fined on each edge e in the edge set E(y, c) and a sentence x, which captures a predicate-argument pair. Consider the example of Figure 2. For Per-Case Joint Model, we use edges, ea1p1, ea1p2, and ea2p3, as local features to compute the score of the edge set with the nominative case. In addition, the global feature vector ϕg(x, E(y, c)) is defined on the edge set E(y, c), and enables the model to utilize linguistically richer information over multiple predicate-argument pairs. In this paper, we exploit second-order relations, similar to the second-order edge factorization of dependency trees (McDonald and Pereira, 2006). We make a set of edge pairs Epair by combining two edges ei, ej in the edge set E(y, c), as follows: Epair = { {ei, ej} |∀ei, ej ∈ E(y, c), ei ≠ ej } For instance, in the PA graph in Figure 2, to compute the score of the nominative arguments, we make three edge pairs: {{ea1p1, ea1p2}, {ea1p1, ea2p3}, {ea1p2, ea2p3}} Then, features are extracted from these edge pairs and utilized for the score computation. For the accusative and dative cases, their scores are computed in the same manner. Then, we obtain the resulting score of the PA graph by summing up the scores of the local and global feat</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of the 11th conference on European Chapter of the Association for Computational Linguistics (EACL), pages 81–88, Trento, Italy, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryohei Sasano</author>
<author>Sadao Kurohashi</author>
</authors>
<title>A discriminative approach to japanese zero anaphora resolution with large-scale lexicalized case frames.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>758--766</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="5036" citStr="Sasano and Kurohashi, 2011" startWordPosition="766" endWordPosition="769">PAS in the space of bipartite graphs. We perform experiments on the NAIST Text Corpus (Iida et al., 2007), a standard benchmark for Japanese PAS analysis. Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points. In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). These results suggest that there is potential for more improvement by adding external resources. The main contributions of this work are: (1) We present new methods to jointly identify case arguments of all predicates in a sentence. (2) We propose global feature templates that capture interactions over multiple PAS. (3) Performing experiments on the NAIST Text Corpus, we demonstrate our methods are superior to a strong baseline and comparable to the methods of representative previous work. 2 Japanese Predicate Argument Structure Analysis 2.1 Task Overview In Japanese PAS analysis, we identif</context>
<context position="7636" citStr="Sasano and Kurohashi, 2011" startWordPosition="1185" endWordPosition="1188">tandard benchmark (Iida et al., 2007). One of the representative researches using the NAIST Text Corpus is Imamura et al. (2009). They built three distinct models corresponding to the three case roles by extracting features defined on each pair of a predicate and a candidate argument. Using each model, they select the best candidate argument for each case per predicate. Their models are based on maximum entropy model and can easily incorporate various features, resulting in high accuracy. 2Around 10-20% in F measure has been achieved in previous work (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). 962 Figure 2: Intuitive image of a predicate-argument graph. This graph is factorized into the local and global features. The different line color/style indicate different cases. While in Imamura et al. (2009) one case argument is identified at a time per predicate, the method proposed by Sasano and Kurohashi (2011) simultaneously determines all the three case arguments per predicate by exploiting large-scale case frames obtained from large raw texts. They focus on identification of implicit arguments (Zero and Inter-Zero), and achieves comparable results to Imamura et al. (2009). In these a</context>
<context position="29335" citStr="Sasano and Kurohashi (2011)" startWordPosition="5001" endWordPosition="5004"> ratio of Dep and Zero arguments for ACC cases is 90:10, the ratio for NOM cases is 75:25. This might have some negative effects on the ACC case identification with AllCases Joint Model. However, in total, All-Cases Joint Model achieves significantly better results. This suggests that capturing case interactions improves performance of Japanese PAS analysis. Existing Methods vs Joint Methods To compare our proposed methods with previous work, we pick the three pieces of representative previous work exploiting the NAIST Text Corpus: Taira et al. (2008) (TA08), Imamura et al. (2009) (IM09), and Sasano and Kurohashi (2011) (S&amp;K11). Sasano and Kurohashi (2011) focus on the analysis for the Zero and Inter-Zero arguments, and do not report the results on the Dep arguments. With respect to the Dep arguments, the All-Cases Joint Model achieves the best result for the NOM cases, Imamura et al. (2009) the best for the ACC cases, and Taira et al. (2008) the best for the DAT cases. In terms of the Zero arguments, Imamura et al. (2009) is the best for the NOM and ACC cases, and Sasano and Kurohashi (2011) the best for the DAT cases. Our joint methods achieve high performance comparable to Imamura et al. (2009). However, </context>
<context position="28181" citStr="Sasano &amp; Kurohashi (2011)" startWordPosition="4809" endWordPosition="4812">he test sets. The bold values denote the highest F-measures among all the three methods. Statistical significance with p &lt; 0.05 is marked with † compared with Baseline, t compared with PC Joint, and * compared with AC Joint. Dep Zero NOM ACC DAT NOM ACC DAT TA08 75.53 88.20 89.51 30.15 11.41 3.66 IM09 87.0 93.9 80.8 50.0 30.8 0.0 S&amp;K11 - - - 39.5 17.5 8.9 PC Joint 87.54 93.09 34.19 47.62 22.73 0.83 AC Joint 88.13 92.74 38.39 48.11 24.44 4.80 Table 4: Comparison with previous work using the NAIST Text Corpus in F-measure. TA08 is Taira et al. (2008), IM09 is Imamura et al. (2009), and S&amp;K11 is Sasano &amp; Kurohashi (2011). Their results are not directly comparable to ours since they use external resources and the NAIST Text Corpus 1.4 beta. the implicit arguments (Zero), one of the problematic issues in Japanese PAS analysis. Comparing the joint methods, each of our two joint methods is effective for a different case role. Per-Case Joint Model is better at the ACC case, and All-Cases Joint Model is better at the NOM and DAT cases. One of the possible explanations is that the distribution of ACC cases is different from NOM cases. While the ratio of Dep and Zero arguments for ACC cases is 90:10, the ratio for NO</context>
</contexts>
<marker>Sasano, Kurohashi, 2011</marker>
<rawString>Ryohei Sasano and Sadao Kurohashi. 2011. A discriminative approach to japanese zero anaphora resolution with large-scale lexicalized case frames. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 758–766, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hirotoshi Taira</author>
<author>Sanae Fujita</author>
<author>Masaaki Nagata</author>
</authors>
<title>A japanese predicate argument structure analysis using decision lists.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>523--532</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="3477" citStr="Taira et al., 2008" startWordPosition="525" endWordPosition="528"> analysis” in this paper following previous work on Japanese PAS analysis. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 961–970, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics phenomenon for PAS analysis (Gerber and Chai, 2010; Laparra and Rigau, 2013). Previous work on Japanese PAS analysis attempted to solve this problem by identifying arguments per predicate without considering interactions between multiple predicates and arguments (Taira et al., 2008; Imamura et al., 2009). However, implicit arguments are likely to be shared by semantically-related predicates. In the above example (Figure 1), the implicit argument of the predicate “hiita (caught)” is shared by the other predicate “yasunda (skipped)” as its nominative argument “watashii (Ii)”. Based on this intuition, we propose methods to jointly identify optimal case arguments of all predicates in a sentence taking their interactions into account. We represent the interactions as a bipartite graph that covers all predicates and candidate arguments in a sentence, and factorize the whole r</context>
<context position="4985" citStr="Taira et al., 2008" startWordPosition="758" endWordPosition="761">hang et al., 2014) to search all possible PAS in the space of bipartite graphs. We perform experiments on the NAIST Text Corpus (Iida et al., 2007), a standard benchmark for Japanese PAS analysis. Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points. In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). These results suggest that there is potential for more improvement by adding external resources. The main contributions of this work are: (1) We present new methods to jointly identify case arguments of all predicates in a sentence. (2) We propose global feature templates that capture interactions over multiple PAS. (3) Performing experiments on the NAIST Text Corpus, we demonstrate our methods are superior to a strong baseline and comparable to the methods of representative previous work. 2 Japanese Predicate Argument Structure Analysis 2.1</context>
<context position="7585" citStr="Taira et al., 2008" startWordPosition="1177" endWordPosition="1180">the NAIST Text Corpus has been used as a standard benchmark (Iida et al., 2007). One of the representative researches using the NAIST Text Corpus is Imamura et al. (2009). They built three distinct models corresponding to the three case roles by extracting features defined on each pair of a predicate and a candidate argument. Using each model, they select the best candidate argument for each case per predicate. Their models are based on maximum entropy model and can easily incorporate various features, resulting in high accuracy. 2Around 10-20% in F measure has been achieved in previous work (Taira et al., 2008; Imamura et al., 2009; Sasano and Kurohashi, 2011). 962 Figure 2: Intuitive image of a predicate-argument graph. This graph is factorized into the local and global features. The different line color/style indicate different cases. While in Imamura et al. (2009) one case argument is identified at a time per predicate, the method proposed by Sasano and Kurohashi (2011) simultaneously determines all the three case arguments per predicate by exploiting large-scale case frames obtained from large raw texts. They focus on identification of implicit arguments (Zero and Inter-Zero), and achieves comp</context>
<context position="24633" citStr="Taira et al., 2008" startWordPosition="4202" endWordPosition="4205">oposed methods on the NAIST Text Corpus 1.5, which consists of 40,000 sentences of Japanese newspaper text (Iida et al., 2007). While previous work has adopted the version 1.4 beta, we adopt the latest version. The major difference between version 1.4 beta and 1.5 is revision of dative case (corresponding to Japanese case particle “ni”). In 1.4 beta, most of adjunct usages of “ni” are mixed up with the argument usages of “ni”, making the identification of dative cases seemingly easy. Therefore, our results are not directly comparable with previous work. We adopt standard train/dev/test split (Taira et al., 2008) as follows: Train Articles: Jan 1-11, Editorials: Jan-Aug Dev Articles: Jan 12-13, Editorials: Sept Test Articles: Jan 14-17, Editorials: Oct-Dec We exclude inter-sentential arguments (InterZero) in our experiments. Our features make use of the annotated POS tags, phrase boundaries, and dependency relations annotated in the NAIST Text Corpus. We do not use any external resources. Baseline We adopt the pointwise method (using only local features) proposed by Imamura et al. (2009) as the baseline. They built three distinct models corresponding to the three case roles. By using each model, they </context>
<context position="28110" citStr="Taira et al. (2008)" startWordPosition="4796" endWordPosition="4799">5 78.91 † 79.23 † t Table 3: F-measures of the three methods in the test sets. The bold values denote the highest F-measures among all the three methods. Statistical significance with p &lt; 0.05 is marked with † compared with Baseline, t compared with PC Joint, and * compared with AC Joint. Dep Zero NOM ACC DAT NOM ACC DAT TA08 75.53 88.20 89.51 30.15 11.41 3.66 IM09 87.0 93.9 80.8 50.0 30.8 0.0 S&amp;K11 - - - 39.5 17.5 8.9 PC Joint 87.54 93.09 34.19 47.62 22.73 0.83 AC Joint 88.13 92.74 38.39 48.11 24.44 4.80 Table 4: Comparison with previous work using the NAIST Text Corpus in F-measure. TA08 is Taira et al. (2008), IM09 is Imamura et al. (2009), and S&amp;K11 is Sasano &amp; Kurohashi (2011). Their results are not directly comparable to ours since they use external resources and the NAIST Text Corpus 1.4 beta. the implicit arguments (Zero), one of the problematic issues in Japanese PAS analysis. Comparing the joint methods, each of our two joint methods is effective for a different case role. Per-Case Joint Model is better at the ACC case, and All-Cases Joint Model is better at the NOM and DAT cases. One of the possible explanations is that the distribution of ACC cases is different from NOM cases. While the r</context>
<context position="29664" citStr="Taira et al. (2008)" startWordPosition="5059" endWordPosition="5062"> Japanese PAS analysis. Existing Methods vs Joint Methods To compare our proposed methods with previous work, we pick the three pieces of representative previous work exploiting the NAIST Text Corpus: Taira et al. (2008) (TA08), Imamura et al. (2009) (IM09), and Sasano and Kurohashi (2011) (S&amp;K11). Sasano and Kurohashi (2011) focus on the analysis for the Zero and Inter-Zero arguments, and do not report the results on the Dep arguments. With respect to the Dep arguments, the All-Cases Joint Model achieves the best result for the NOM cases, Imamura et al. (2009) the best for the ACC cases, and Taira et al. (2008) the best for the DAT cases. In terms of the Zero arguments, Imamura et al. (2009) is the best for the NOM and ACC cases, and Sasano and Kurohashi (2011) the best for the DAT cases. Our joint methods achieve high performance comparable to Imamura et al. (2009). However, because they used additional external resources and a different version of the NAIST Text Corpus, the results of previous work are not directly comparable to ours. Our research direction and contributions are orthogonal to theirs, and adding their external resources could potentially leads to much better results. 968 7 Conclusi</context>
</contexts>
<marker>Taira, Fujita, Nagata, 2008</marker>
<rawString>Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata. 2008. A japanese predicate argument structure analysis using decision lists. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 523–532, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitong Yang</author>
<author>Chengqing Zong</author>
</authors>
<title>Multipredicate semantic role labeling.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>363--373</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<contexts>
<context position="8454" citStr="Yang and Zong (2014)" startWordPosition="1312" endWordPosition="1315">et al. (2009) one case argument is identified at a time per predicate, the method proposed by Sasano and Kurohashi (2011) simultaneously determines all the three case arguments per predicate by exploiting large-scale case frames obtained from large raw texts. They focus on identification of implicit arguments (Zero and Inter-Zero), and achieves comparable results to Imamura et al. (2009). In these approaches, case arguments were identified per predicate without considering interactions between multiple predicates and candidate arguments in a sentence. In the semantic role labeling (SRL) task, Yang and Zong (2014) pointed out that information of different predicates and their candidate arguments could help each other for identifying arguments taking part in semantic roles. They exploited a reranking method to capture the interactions between multiple predicates and candidate arguments, and jointly determine argument structures of all predicates in a sentence (Yang and Zong, 2014). In this paper, we propose new joint analysis methods for identifying case arguments of all predicates in a sentence capturing interactions between multiple predicates and candidate arguments. 3 Graph-Based Joint Models 3.1 A </context>
</contexts>
<marker>Yang, Zong, 2014</marker>
<rawString>Haitong Yang and Chengqing Zong. 2014. Multipredicate semantic role labeling. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 363– 373, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Zhang</author>
<author>Tao Lei</author>
<author>Regina Barzilay</author>
<author>Tommi Jaakkola</author>
</authors>
<title>Greed is good if randomized: New inference for dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1013--1024</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<contexts>
<context position="4385" citStr="Zhang et al., 2014" startWordPosition="665" endWordPosition="668">ii (Ii)”. Based on this intuition, we propose methods to jointly identify optimal case arguments of all predicates in a sentence taking their interactions into account. We represent the interactions as a bipartite graph that covers all predicates and candidate arguments in a sentence, and factorize the whole relation into the second-order relations. This interaction modeling results in a hard combinatorial problem because it is required to select the optimal PAS combination from all possible PAS combinations in a sentence. To solve this issue, we extend the randomized hill-climbing algorithm (Zhang et al., 2014) to search all possible PAS in the space of bipartite graphs. We perform experiments on the NAIST Text Corpus (Iida et al., 2007), a standard benchmark for Japanese PAS analysis. Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points. In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources (Taira et al., 2008</context>
<context position="20948" citStr="Zhang et al., 2014" startWordPosition="3543" endWordPosition="3546">he same argument in the sentence. DEP-REL We set five distinct feature templates to capture dependency relations (dep) between the shared argument and the two predicates. If two elements have a direct dependency relation, we encode its dependency relation with the auxiliary words and the voice. 5 Inference and Training 5.1 Inference for the Joint Models Global features make the inference of finding the maximum scoring PA graph more difficult. For searching the graph with the highest score, we propose two greedy search algorithms by extending the randomized hill-climbing algorithm proposed in (Zhang et al., 2014), which has been shown to achieve the state-of-the-art performance in dependency parsing. Figure 3 describes the pseudo code of our proposed algorithm for Per-Case Joint Model. Firstly, we set an initial PA graph y(0) sampled uniformly from the set of admissible PA graphs G(x) (line 1 in Figure 3). Then, the union Y, is constructed from the set of neighboring graphs with a case NeighborG(y(t), c), which is a set of admissible graphs obtained by changing one edge with the case c in y(t), and the current graph y(t) (line 5). The current graph y(t) is updated to a higher scoring graph y(t+1) sele</context>
<context position="22419" citStr="Zhang et al. (2014)" startWordPosition="3813" endWordPosition="3816">cally optimal graph y. Figure 4 describes the pseudo code of the algorithm for All-Cases Joint Model. The large part of the algorithm is the same as that for Per-Case Joint Model. The difference is that the union Y consists of the current graph y(t) and the neighboring graph set obtained by changing one edge in y(t) regardless of case roles (line 4 in Figure 4), and that the iteration process for each case role (line 3 in Figure 3) is removed. The algorithm also continues until no more score improvement is possible by changing an edge in y(t), resulting in a locally optimal graph y. Following Zhang et al. (2014), for a given sentence x, we repeatedly run these algorithms with K consecutive restarts. Each run starts with initial graphs randomly sampled from the set of admissible PA graphs G(x), so that we obtain K local optimal graphs by K restarts. Then the highest scoring one of K graphs is selected for the sentence x as the result. Each run of the algorithms is independent from each other, so that multiple runs are easily executable in parallel. 5.2 Training Given a training data set D = {(x, y)}Z� , the weight vectors θ (θ,) in the scoring functions of the joint models are estimated by using machi</context>
</contexts>
<marker>Zhang, Lei, Barzilay, Jaakkola, 2014</marker>
<rawString>Yuan Zhang, Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2014. Greed is good if randomized: New inference for dependency parsing. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1013– 1024, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>