<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.730154">
TOWARDS THE AUTOMATIC IDENTIFICATION OF ADJECTIVAL
SCALES: CLUSTERING ADJECTIVES ACCORDING TO MEANING
</title>
<author confidence="0.841018">
Vasileios Hatzivassiloglou
Kathleen R. McKeown
</author>
<affiliation confidence="0.899382666666667">
Department of Computer Science
450 Computer Science Building
Columbia University
</affiliation>
<address confidence="0.994365">
New York, N.Y. 10027
</address>
<email confidence="0.9905295">
Internet: vh@cs.columbia.edu
kathy@cs.columbia.edu
</email>
<sectionHeader confidence="0.998355" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9953462">
In this paper we present a method to group adjectives
according to their meaning, as a first step towards the
automatic identification of adjectival scales. We discuss the
properties of adjectival scales and of groups of semantically
related adjectives and how they imply sources of linguistic
knowledge in text corpora. We describe how our system
exploits this linguistic knowledge to compute a measure of
similarity between two adjectives, using statistical tech-
niques and without having access to any semantic infor-
mation about the adjectives. We also show how a clustering
algorithm can use these similarities to produce the groups
of adjectives, and we present results produced by our sys-
tem for a sample set of adjectives. We conclude by present-
ing evaluation methods for the task at hand, and analyzing
the significance of the results obtained.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="keywords">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99998203125">
As natural language processing systems become
more oriented towards solving real-world problems
like machine translation or spoken language under-
standing in a limited domain, their need for access to
vast amounts of knowledge increases. While a model
of the general rules of the language at various levels
(morphological, syntactic, etc.) can be hand-encoded,
knowledge which pertains to each specific word is
harder to encode manually, if only because of the size
of the lexicon. Most systems currently rely on human
linguists or lexicographers who compile lexicon
entries by hand. This approach requires significant
amounts of time and effort for expanding the
system&apos;s lexicon. Furthermore, if the compiled infor-
mation depends in any way on the domain of the
application, the acquisition of lexical knowledge
must be repeated whenever the system is transported
to another domain. For systems which need access to
large lexicons, some form of at least partial automa-
tion of the lexical knowledge acquisition phase is
needed.
One type of lexical knowledge which is useful for
many natural language (NL) tasks is the semantic re-
latedness between words of the same or different syn-
tactic categories. Semantic relatedness subsumes
hyponymy, synonymy, and antonymy-
incompatibility. Special forms of relatedness are
represented in the lexical entries of the WordNet lex-
ical database (Miller et al., 1990). Paradigmatic
semantic relations in WordNet have been used for
diverse NL problems, including disambiguation of
syntactic structure (Resnik, 1993) and semi-
automatic construction of a large-scale ontology for
machine translation (Knight, 1993).
In this paper, we focus on a particular case of
semantic relatedness: relatedness between adjectives
which describe the same property. We describe a
technique for automatically grouping adjectives ac-
cording to their meaning based on a given text cor-
pus, so that all adjectives placed in one group
describe different values of the same property. Our
method is based on statistical techniques, augmented
with linguistic information derived from the corpus,
and is completely domain independent. It
demonstrates how high-level semantic knowledge
can be computed from large amounts of low-level
knowledge (essentially plain text, part-of-speech
rules, and optionally syntactic relations).
The problem of identifying semantically related
words has received considerable attention, both in
computational linguistics (e.g. in connection with
thesaurus or dictionary construction (Sparck-Jones,
1986)) and in psychology (Osgood et al., 1957).
However, only recently has work been done on the
automatic computation of such relationships from
text, quantifying similarity between words and
clustering them ( (Brown et al., 1992), (Pereira et al.,
1993)). In comparison, our work emphasizes the use
of shallow linguistic knowledge in addition to a
statistical model and is original in the use of negative
knowledge to constrain the search space. Further-
more, we use a flexible architecture which will allow
us to easily incorporate additional knowledge sources
for computing similarity.
</bodyText>
<page confidence="0.995509">
172
</page>
<bodyText confidence="0.999933461538461">
While our current system does not distinguish be-
tween scalar and non-scalar adjectives, it is a first
step in the automatic identification of adjectival
scales, since the scales can be subsequently ordered
and the non-scalar adjectives filtered on the basis of
independent tests, done in part automatically and in
part by hand in a post-editing phase. The result is a
semi-automated system for the compilation of adjec-
tival scales.
In the following sections, we first provide back-
ground on scales, then describe our algorithm in
detail, present the results obtained, and finally
provide a formal evaluation of the results.
</bodyText>
<sectionHeader confidence="0.999227" genericHeader="introduction">
2. BACKGROUND
</sectionHeader>
<bodyText confidence="0.999845340909091">
A linguistic scale is a set of words, of the same
grammatical category, which can be ordered by their
semantic strength or degree of informativeness
(Levinson, 1983). For example, lukewarm, warm,
and hot fall along a single adjectival scale since they
indicate a variation in the intensity of temperature of
the modified noun (at least when used in their non-
metaphorical senses; metaphorical usage of scalar
words normally also follows the order of the scale by
analogy). Scales are not limited to adjectives; for ex-
ample, (may, should, must) and (sometimes, often,
always) (Horn, 1972) are linguistic scales consisting
of auxiliary verbs expressing obligation and of ad-
verbs expressing frequency respectively.
In the case of adjectives, the above definition is
commonly relaxed to replace the total order among
the elements of the scale by a partial one, so that the
elements of the scale may be partitioned into two
groups (sub-scales), within each of which the order is
total. The two sub-groups correspond to positive and
negative degrees of the common property that the
scale describes. For example, the set of adjectives
(cold, lukewarm, warm, hot) are normally considered
part of one scale, even though no direct ordering of
semantic strength exists between cold and hot.
Linguistic scales are known to possess interesting
properties, derived from conventional logical entail-
ment on the linear ordering of their elements and
from Gricean scalar implicature (Levinson, 1983).
Despite these properties and their potential usefulness
in both understanding and generating natural lan-
guage text, dictionary entries are largely incomplete
for adjectives in this regard. Yet, if systems are to use
the information encoded in adjectival scales for
generation or interpretation (e.g. for selecting an ad-
jective with a particular degree of semantic strength
(Elhadad, 1991, Elhadad, 1993), or for handling
negation), they must have access to the sets of words
comprising a scale.
Linguists have presented various tests for accept-
ing or rejecting a particular scalar relationship be-
tween any two adjectives. For example, Horn (1969)
proposed a test using the phrase &amp;quot;x even y&amp;quot; for two
elements x and y of a totally ordered scale. More
</bodyText>
<figure confidence="0.910060166666667">
SIMILARITY SIMILARITY • • • SIMILARITY
MODULE 1 MODULE 2 MODULE n
COMBINE
SIMILARITIES
CLUSTER
WORDS
</figure>
<figureCaption confidence="0.999943">
Figure 1: System architecture.
</figureCaption>
<bodyText confidence="0.999858428571429">
refined tests locate the position of an adjective in a
scale relative to the neutral element or to the ex-
tremes of the scale (Bolinger, 1977). The common
problem with these methods is that they are designed
to be applied by a human who incorporates the two
adjectives in specific sentential frames (e.g. &amp;quot;X is
warm, even hot&amp;quot;) and assesses the semantic validity
of the resulting sentences. Such tests cannot be used
computationally to identify scales in a domain, since
the specific sentences do not occur frequently enough
in a corpus to produce an adequate description of the
adjectival scales in the domain (Smadja, 1991). As
scales vary across domains, the task of compiling
such information is compounded.
</bodyText>
<sectionHeader confidence="0.997405" genericHeader="method">
3. ALGORITHM
</sectionHeader>
<bodyText confidence="0.999967888888889">
Our algorithm, whose overall architecture is
depicted in Figure 1, operates in four stages. First, we
extract linguistic data from the parsed corpus in the
form of syntactically related word pairs, or, more
generally, sequences of syntactically related words;
this co-occurrence information is processed by a mor-
phology component and tabulated. In the second
stage, the various types of co-occurrence relations
which have been identified in the text are forwarded
</bodyText>
<figure confidence="0.5785775">
EXTRACT WORD
PATTERNS
</figure>
<page confidence="0.997207">
173
</page>
<bodyText confidence="0.999864">
to a set of independent similarity modules, which
operate in parallel. Each similarity module uses some
linguistic criterion to judge the similarity or dis-
similarity between any two adjectives, producing a
real number between 0 and 1; a module may also
refrain from making any judgement. The third stage
combines the opinions of the various similarity
modules in a single dissimilarity measure for any pair
of adjectives. Finally, the fourth stage clusters the
adjectives into groups according to the dissimilarity
measure, so that adjectives with a high degree of
pairwise similarity fall in the same cluster (and, con-
sequently, adjectives with a low degree of similarity
fall in different clusters).
The algorithm currently uses two similarity
modules based on two sources of linguistic data: data
that help establish that two adjectives are related, and
data that indicate that two adjectives are unrelated.
First, we extract adjective-noun pairs that occur in a
modification relation in order to identify the distribu-
tion of nouns an adjective modifies and, ultimately,
determine which adjectives it is related to. This is
based on the expectation that adjectives describing
the same property tend to modify approximately the
same set of nouns. For example, temperature is nor-
mally defined for physical objects and we can expect
to find that adjectives conveying different values of
temperature will all modify physical objects. There-
fore, our algorithm finds the distribution of nouns
that each adjective modifies and categorizes adjec-
tives as similar if they have similar distributions.
Second, we use adjective-adjective pairs occur-
ring as pre-modifiers within the same NP as a strong
indication that the two adjectives do not belong in the
same group. There are three cases:
</bodyText>
<listItem confidence="0.915452111111111">
1. If both adjectives modify the head noun
and the two adjectives are antithetical,
the NP would be self-contradictory, as
in the scalar sequence hot cold or the
non-scalar red black.
2. For non-antithetical scalar adjectives
which both modify the head noun, the
NP would violate the Gricean maxim of
Manner (Levinson, 1983) since the
same information is conveyed by the
strongest of the two adjectives (e.g. hot
warm).
3. Finally, if one adjective modifies the
other, the modifying adjective has to
qualify the modified one in a different
dimension. For example, in light blue
shirt, blue is a value of the property
color, while light indicates the shadel.
</listItem>
<bodyText confidence="0.990221090909091">
The use of multiple types of linguistic data, in
Note that sequences such as blue-green are usually hyphenated
and thus better considered as a compound.
addition to statistical measures, is a unique property
of our work and significantly improves the accuracy
of our results. One other published model for group-
ing semantically related words (Brown et al., 1992),
is based on a statistical model of bigrams and
trigrams and produces word groups using no linguis-
tic knowledge, but no evaluation of the results is
reported.
</bodyText>
<subsectionHeader confidence="0.997768">
3.1. Stage One: Extracting Word Pairs
</subsectionHeader>
<bodyText confidence="0.999996394736842">
During the first stage, the system extracts
adjective-noun and adjective-adjective pairs from the
corpus. To determine the syntactic category of each
word, and identify the NP boundaries and the syntac-
tic relations among the words, we used the Fidditch
parser (Hindle, 1989). For each NP, we then deter-
mine its minimal NP, that part of an NP consisting of
the head noun and its adjectival pre-modifiers2. We
match a set of regular expressions, consisting of syn-
tactic categories and representing the different forms
a minimal NP can take, against the NPs. From the
minimal NP, we produce the different pairs of adjec-
tives and nouns, assuming that all adjectives modify
the head noun3. This assumption is rarely invalid,
because a minimal NP with multiple adjectives all
modifying the head noun is far more common than a
minimal NP with multiple adjectives where one of
them modifies another. Furthermore, minimal NPs
with multiple adjectives are relatively rare in the first
place; most minimal NPs consist simply of a noun or
an adjective and a noun.
The resulting adjective-adjective and adjective-
noun pairs are filtered by a morphology component,
which removes pairs that contain erroneous infor-
mation (such as mistyped words, proper names, and
closed-class words which may be mistakenly classi-
fied as adjectives (e.g. possessive pronouns)). This
component also reduces the number of different pairs
without losing information by transforming words to
an equivalent, base form (e.g. plural nouns are con-
verted to singular) so that the expected and actual
frequencies of each pair are higher. Stage one then
produces as output a simple list of adjective-adjective
pairs that occurred within the same minimal NP and a
table with the observed frequencies of every
adjective-noun combination. Each row in the table
contains the frequencies of modified nouns for a
given adjective.
</bodyText>
<footnote confidence="0.7798775">
2This part of an NP has been used by many researchers (e.g.
(Hobbs et al., 1993) who call it a noun group), mostly because of
the relative ease with which it can be identified.
3We take into account possessives however and correct the
result, so that the minimal NP (the) tall man&apos;s wife will correctly
produce the pair (tall, man) instead of (tall, wife).
</footnote>
<page confidence="0.992892">
174
</page>
<subsectionHeader confidence="0.9957535">
3.2. Stage Two: Computing Similarities
Between Adjectives
</subsectionHeader>
<bodyText confidence="0.999385108108108">
This stage currently employs two similarity
modules, each of which processes a part of the output
of stage one and produces a measure of similarity for
each possible pair of adjectives.
The first module processes the adjective-noun
frequency table; for each possible pair in the table we
compare the two distributions of nouns. We use a
robust non-parametric method to compute the
similarity between the modified noun distributions
for any two adjectives, namely Kendall&apos;s coef-
ficient (Kendall, 1938) for two random variables with
paired observations. In our case, the two random
variables are the two adjectives we are comparing,
and each paired observation is their frequency of co-
occurrence with a given noun. Kendall&apos;s T coef-
ficient compares the two variables by repeatedly
comparing two pairs of their corresponding obser-
vations. Formally, if (Xi,Yi) and (XJ,Yi) are two
pairs of observations for the adjectives X&apos; and Y on
the nouns i and j respectively, we call these pairs
concordant if Xi&gt;XJ. and Y.&gt;Y. or if X&lt;X. and
Y t &lt;11, otherwise these pairs are discordant. We dis-
card ties, that is pairs of observations where Xi=Xf or
Y/.YJ.&apos; For example, Table 1 shows the frequencies
observed for the co-occurrences of the nouns
coordination and market and the adjectives global
and international in the test corpus which is
described in Section 4. From the table we observe
that for i=coordination, j=market, X=global, and
Y=intemational, we have Xi=16 &lt; 24=Xi and
Y1=19 &lt;33=Y so this particular pair of paired&apos; obser-
vations is concordant and contributes positively to the
similarity between global and international.
In general, if the distributions for the two adjec-
tives are similar, we expect a large number of concor-
dances, and a small number of discordances.
Kendall&apos;s T is defined as
</bodyText>
<subsubsectionHeader confidence="0.485969">
Pc—Pd
</subsubsectionHeader>
<bodyText confidence="0.996186166666667">
where pc and pd are the probabilities of observing a
concordance or discordance respectively. T ranges
from -1 to +1, with +1 indicating complete concor-
dance, -1 complete discordance, and 0 no correlation
between X and Y.
An unbiased estimator oft is the statistic
</bodyText>
<equation confidence="0.949605">
T= C—Q
n\
</equation>
<bodyText confidence="0.999666571428571">
where n is the number of paired observations in the
sample and C and Q are the numbers of observed
concordances and discordances respectively (Wayne,
1990). We compute T for each pair of adjectives, ad-
justing for possible ties in the values of each variable,
so that our statistic remains an unbiased estimator of
T. We determine concordances and discordances by
</bodyText>
<table confidence="0.962605">
global international
coordination 16 19
market 24 33
</table>
<tableCaption confidence="0.999605">
Table 1: Example adjective-noun frequencies.
</tableCaption>
<bodyText confidence="0.999943872340426">
sorting the pairs of observations (noun frequencies)
on one of the variables (adjectives), and computing
how many of the (3) pairs of paired observations
agree or disagree with the expected order on the other
adjective. We normalize the result to the range 0 to 1
using a simple linear transformation.
The second similarity module utilizes the
knowledge offered by the observed adjective-
adjective pairs. We know that the adjectives which
appear in any such pair cannot be part of the same
group, so the module produces zero similarity for all
such pairs. The module does not output any similarity
value for pairs of adjectives which have not been ob-
served together in the same minimal NP.
The two modules produce results of a sig-
nificantly different character. The adjective-noun
module always outputs a similarity value for any pair
of adjectives, but these values tend to be around the
middle of the range of possible values; rarely will the
pattern of similarity or dissimilarity be strong enough
to produce a value which has a large deviation from
0.5. This compression of the range of the similarity
values can be attributed to the existence of many ties
and many adjective-noun pairs with low frequencies,
as would be expected by Zipf s law (Zipf, 1949).
However, the expected number of concordances and
discordances which can be attributed to chance will
be the same (a random pair can produce a concor-
dance or discordance with probability 0.5 for each),
so the effect of chance fluctuations on T is not very
significant. Furthermore, the robustness of the
method guarantees that it will not be significantly
influenced by any outliers (this is true for all rank
based methods). Therefore, although we cannot have
complete confidence in a statistical estimate like T,
we expect the module to produce useful estimates of
similarity.
On the other hand, the adjective-adjective module
produces similarity values with absolute certainty,
since once two adjectives have been seen in the same
NP even once, we can deduce that they do not belong
in the same group. However, this negative knowledge
is computed only for a few of the possible pairs of
adjectives, and it cannot be propagated to more pairs
as dissimilarity is not a transitive relation. As a result
we can make some inferences with very high con-
fidence, but we cannot make very many of them.
</bodyText>
<page confidence="0.992521">
175
</page>
<subsectionHeader confidence="0.995886">
3.3. Stage Three: Combining The
Similarity Estimates
</subsectionHeader>
<bodyText confidence="0.96391924590164">
In stage three we combine the values produced by
the various similarity modules in stage two using a
pre-specified algorithm. The output of this stage is a
single table of dissimilarity values (as required by the
next stage) having one entry for each adjective pair.
Currently we have only the two similarity modules
described in the previous subsection, so we employ
the following simple algorithm:
for any pair of adjectives (x,y) do
if the adjective-adjective module has no opinion
on (x,y) then
dissimilarity = 1 - (the similarity reported by the
adjective-noun module)
else
dissimilarity = some constant
As can be easily seen, the algorithm has complete
confidence in the results of the adjective-adjective
module whenever that module has an opinion; when
it does not, the algorithm uses the similarity value
produced by the adjective-noun module, after a
simple linear transformation is applied to convert it to
a dissimilarity. The choice of the constant k reflects
how undesirable it is to place in the same group two
adjectives which have been observed in the same
minimal NP. Since we consider the results of the
adjective-adjective module more reliable than the
adjective-noun module, we use a high value for k,
k=10; this practically guarantees that a suggestion by
the adjective-adjective module will be respected by
the clustering algorithm unless the evidence for the
contrary is overwhelming.
Note that by placing complete confidence in the
output of the adjective-adjective module, the algo-
rithm of stage three is sensitive to small errors that
this module may perform. An incorrect suggestion
would make possibly related adjectives be kept
separate. However, this problem looks more severe
than it really is. An erroneous opinion produced by
that module must correspond to a violation of one of
the three linguistic principles listed at the start of this
section; such violations do not occur in carefully
written English (as is our test corpus of Associated
Press news reports). In fact, during the analysis of the
corpus for our test set of adjectives we found no er-
roneously identified pairs of adjectives; however, if
the system is used with a less well written, or even
spoken, corpus, the complete confidence in the
adjective-adjective module may need to be reduced.
This can be accomplished by taking into account the
frequency of an adjective-adjective pair, and making
our confidence an increasing function of this fre-
quency.
When new similarity modules, such as the ones
discussed in Section 6, are added to the system, the
above algorithm will be inadequate for combining
their suggestions. We plan to extend the algorithm to
compute an extended weighted average of the
similarities and/or dissimilarities produced by these
modules, and add a separate training component
which will determine the appropriate value for the
weight of each module.
</bodyText>
<subsectionHeader confidence="0.830421">
3.4. Stage Four: Clustering The
Adjectives
</subsectionHeader>
<bodyText confidence="0.999996206896552">
In stage four we form groups of adjectives (a par-
tition) according to the combined dissimilarity values
computed in the previous stage. We want to find a
partition which is optimal, in the sense that adjectives
with high dissimilarity are placed in different groups.
We use a non-hierarchical clustering algorithm, since
such algorithms are in general stronger than hierar-
chical methods (Kaufman and Rousseeuw, 1990).
The number of clusters produced is an input
parameter. The algorithm uses the exchange method
(Spath, 1985) since the more commonly used K-
means method (Kaufman and Rousseeuw, 1990) is
not applicable; the K-means method, like all centroid
methods, requires the measure d between the clus-
tered objects to be a distance; this means, among
other conditions, that for any three objects x, y, and z
the triangle inequality applies. However, this in-
equality does not necessarily hold for our dis-
similarity measure. If the adjectives x and y were ob-
served in the same minimal NP, their dissimilarity is
quite large. If neither z and x nor z and y were found
in the same minimal NP, then it is quite possible that
the sum of their dissimilarities could be less than the
dissimilarity between x and y.
The algorithm tries to produce a partition of the
set of adjectives as close as possible to the optimal
one. This is accomplished by minimizing an
objective function (Ico which scores a partition P. The
objective function we use is
</bodyText>
<equation confidence="0.995672">
( = [ d(x,y)]
CE P ICIx,yE C
</equation>
<bodyText confidence="0.999853222222222">
The algorithm starts by producing a random par-
tition of the adjectives, computing its 0:1) value and
then for each adjective computing the improvement
in (1) for every cluster where it can be moved; the
adjective is moved to the cluster that yields the best
improvement of (13 if there is such a cluster and the
next adjective is considered. This procedure is
repeated until no more moves lead to an improve-
ment of O.
This is a hill-climbing method and therefore is
guaranteed to converge, but it may lead to a local
minimum of (1), inferior to the global minimum that
corresponds to the optimal solution. To alleviate this
problem, the partitioning algorithm is called
repeatedly with different random starting partitions
and the best solution in these runs is kept. As with
many practical optimization problems, computing the
optimal solution is NP-complete (Brucker, 1978).
</bodyText>
<page confidence="0.992928">
176
</page>
<table confidence="0.985066636363636">
antitrust new
big old
economic political
financial potential
foreign real
global serious
international severe
legal staggering
little technical
major unexpected
mechanical
</table>
<figureCaption confidence="0.993145">
Figure 2: Adjectives to be grouped.
</figureCaption>
<bodyText confidence="0.999968785714286">
Note that if the problem&apos;s search space had been rela-
tively small, then we could have computed the op-
timal partition by enumerating all possible solutions
and keeping the best one. However, again as with
many other practical optimization problems, the
search space turns out to be intractably large. The
number of possible partitions of n objects to m non-
empty subsets with mtt is equal to the correspond-
ing Stirling number of the second kind (Knuth,
1973), and this number grows exponentially with n
for all but trivial values of m. For example, for our
test set of adjectives presented in the next section, we
have n=21 and m=9; the corresponding number of
possible partitions is roughly 1.23 x 1014.
</bodyText>
<sectionHeader confidence="0.999617" genericHeader="method">
4. RESULTS
</sectionHeader>
<bodyText confidence="0.999992107142857">
We tested our system on a 8.2 million word cor-
pus of stock market reports from the Associated Press
news wire. A subset of 21 of the adjectives in the
corpus (Figure 2) was selected for practical reasons
(mainly for keeping the evaluation task tractable).
We selected adjectives that have one modified noun
in common (problem) to ensure some semantic re-
latedness, and we included only adjectives that oc-
curred frequently so that our similarity measure
would be meaningful.
The partition produced by the system for 9
clusters appears in Figure 3. Before presenting a for-
mal evaluation of the results, we note that this par-
tition contains interesting data. First, the results con-
tain two clusters of gradable adjectives which fall in
the same scale. Groups 5 and 8 contain adjectives
that indicate the size, or scope, of a problem; by aug-
menting the system with tests to identify when an
adjective is gradable, we could separate out these two
groups from other potential scales, and perhaps con-
sider combining them. Second, groups 1 and 6 clearly
identify separate sets of non-gradable adjectives. The
first contains adjectives that describe the geographi-
cal scope of the problem. Although at first sight we
would classify these adjectives as non-scalar, we ob-
served that the phrase international, even global,
problem is acceptable while the phrase *global, even
international, problem is not. These patterns seem to
</bodyText>
<listItem confidence="0.9977684">
1. foreign global international
2. old
3. potential
4. new real unexpected
5. little staggering
6. economic financial mechanical political
technical
7. antitrust
8. big major serious severe
9. legal
</listItem>
<figureCaption confidence="0.99773">
Figure 3: Partition found for 9 clusters.
</figureCaption>
<bodyText confidence="0.9933408">
suggest at least some degree of scalability. On the
other hand, group 6 contains non-scalar relational ad-
jectives that specify the nature of the problem. It is
interesting to note here that the clustering algorithm
discourages long groups, with the expected number
</bodyText>
<page confidence="0.836074">
21
</page>
<bodyText confidence="0.999841181818182">
of adjectives per cluster being -§- ---- 2.33; nevertheless,
the evidence for the adjectives in group 6 is strong
enough to allow the creation of a group with more
than twice the expected number of members. Finally,
note that even in group 4 which is the weakest group
produced, there is a positive semantic correlation be-
tween the adjectives new and unexpected. To sum-
marize, the system seems to be able to identify many
of the existent semantic relationships among the ad-
jectives, while its mistakes are limited to creating
singleton groups containing adjectives that are related
to other adjectives in the test set (e.g., missing the
semantic associations between new-old and
potential-real) and &amp;quot;recognizing&amp;quot; a non-significant
relationship between real and new-unexpected in
group 4.
We produced good results with a relatively small
corpus of 8.2 million words4, out of which only
34,359 total / 3,073 distinct adjective-noun pairs in-
volving 1,509 distinct nouns were relevant to our test
set of 21 adjectives (Figure 2). The accuracy of the
results can be improved if a larger, homogeneous cor-
pus is used to provide the raw data. Also, we can
increase the size of the adjective-noun and adjective-
adjective data that we are using if we introduce more
syntactic patterns in stage one to extract more com-
plex cases of pairs. Furthermore, some of the associa-
tions between adjectives that the system reports ap-
pear to be more stable than others; these associations
remain in the same group when we vary the number
of clusters in the partition. We have noticed that ad-
jectives with a higher degree of semantic content
(e.g. international or severe) appear to form more
</bodyText>
<footnote confidence="0.9677965">
4Corpora up to 366 million words have been used for similar
classification tasks.
</footnote>
<page confidence="0.980282">
177
</page>
<note confidence="0.876512">
Answer should be Yes Answer should be No
The system says Yes a b
The system says No c d
</note>
<tableCaption confidence="0.998678">
Table 2: Contingency table model for evaluation.
</tableCaption>
<bodyText confidence="0.95875775">
stable associations than relatively semantically empty
adjectives (e.g. little or real). This observation can be
used to filter out adjectives which are too general to
be meaningfully clustered in groups.
</bodyText>
<sectionHeader confidence="0.999768" genericHeader="evaluation">
5. EVALUATION
</sectionHeader>
<bodyText confidence="0.9999955">
To evaluate the performance of our system we
compared its output to a model solution for the
problem designed by humans. Nine human judges
were presented with the set of adjectives to be par-
titioned, a description of the domain, and a simple
example. They were told that clusters should not
overlap but they could select any number of clusters
(the judges used from 6 to 11 clusters, with an
average of 8.565 and a sample standard deviation of
1.74). Note that this evaluation method differs sig-
nificantly from the alternative method of asking the
humans to directly estimate the goodness of the
system&apos;s results (e.g. (Matsukawa, 1993)). It requires
an explicit construction of a model from the human
judge and places the burden of the comparison be-
tween the model and the system&apos;s output on the sys-
tem instead of the judge. It has been repeatedly
demonstrated that in complex evaluation tasks
humans can easily find arguments to support ob-
served data, leading to biased results and to an infla-
tion of the evaluation scores.
To score our results, we converted the com-
parison of two partitions to a series of yes-no ques-
tions, each of which has a correct answer (as dictated
by the model) and an answer assigned by the system.
For each pair of adjectives, we asked if they fell in
the same cluster (&amp;quot;yes&amp;quot;) or not (&amp;quot;no&amp;quot;). Since human
judges did not always agree, we used fractional
values for the correctness of each answer instead of 0
(&amp;quot;incorrect&amp;quot;) and 1 (&amp;quot;correct&amp;quot;). We defined the cor-
rectness of each answer as the relative frequency of
the association between the two adjectives among the
human models and the incorrectness of each answer
as 1 - correctness; in this way, associations receive a
correctness value proportional to their popularity
among the human judges. For example, in the sample
set of adjectives discussed in the previous section, the
association (foreign, international) received a cor-
rectness value of 1, since all the humans placed these
two adjectives in the same group, while the associa-
tion (legal, severe) received a correctness value of 0.
The pair (economic, political) on the other hand
</bodyText>
<footnote confidence="0.913271666666667">
5This is the reason that we presented the partition with 9
clusters, as this is the closest integer to the average number of
clusters used by the humans.
</footnote>
<bodyText confidence="0.954854666666667">
received a correctness value of 0.67, since two thirds
of the judges placed the two adjectives in the same
group. Once correctness and incorrectness values
have been defined, we can generalize measures such
as &amp;quot;the number of correct associations retrieved by
the system&amp;quot; by using summation of those values in-
stead of counting. Then the contingency table model
(Swets, 1969), widely used in Information Retrieval
and Psychology, is applicable. Referring to the clas-
sification of the yes-no answers in Table 2, the fol-
lowing measures are defined:
a
</bodyText>
<listItem confidence="0.995445">
• Recall = a+c 100%
a
• Precision = a+b• 100%
• Fallout = -1 100%
</listItem>
<bodyText confidence="0.985257103448276">
7—
i.d
In other words, recall is the percentage of correct
&amp;quot;yes&amp;quot; answers that the system found among the
model &amp;quot;yes&amp;quot; answers, precision is the percentage of
correct &amp;quot;yes&amp;quot; answers among the total of &amp;quot;yes&amp;quot;
answers that the system reported, and fallout is the
percentage of incorrect &amp;quot;yes&amp;quot; answers relative to the
total number of &amp;quot;no&amp;quot; answers6. Note that in our
generalized contingency table model, the symbols a,
b, c, and d do not represent numbers of observed
associations but rather sums of correctness or incor-
rectness values. These sums use correctness values
for the quantities in the first column of Table 2 and
incorrectness values for the quantities in the second
column of Table 2. Furthermore, the summation is
performed over all pairs reported or not reported by
the system for quantities in the first or second row of
Table 2 respectively. Consequently, the information
theoretic measures represent the generalized counter-
parts of their original definitions. In the case of per-
fect agreement between the models, or of only one
model, the generalized measures reduce to their
original definitions.
We also compute a combined measure for recall
and precision, the F-measure (Van Rijsbergen, 1979),
which always takes a value between the values of
recall and precision, and is higher when recall and
precision are closer; it is defined as
</bodyText>
<equation confidence="0.51587">
F — (132+1)x Precision x Recall
</equation>
<footnote confidence="0.969236666666667">
6Another measure used in information retrieval,
overgeneration, is in our case always equal to (100 - precision)%.
132x Precision +Recall
</footnote>
<page confidence="0.975992">
178
</page>
<table confidence="0.9997286">
Recall Precision Fallout F-measure (13.1)
7 clusters 50.78% 43.56% 7.48% 46.89%
8 clusters 37.31% 38.10% 6.89% 37.70%
9 clusters 49.74% 46.38% 6.54% 48.00%
10 clusters 35.23% 41.98% 5.54% 38.31%
</table>
<tableCaption confidence="0.999886">
Table 3: Evaluation results.
</tableCaption>
<bodyText confidence="0.997155333333333">
where 3 is the weight of recall relative to precision;
we use 13.1.0, which corresponds to equal weighting
of the two measures.
The results of applying our evaluation method to
the system output (Figure 3) are shown in Table 3,
which also includes the scores obtained for several
other sub-optimal choices of the number of clusters.
We have made these observations related to the
evaluation mechanism:
</bodyText>
<listItem confidence="0.644381117647059">
1. Recall is inversely related to fallout and
precision. Decreasing the number of
clusters generally increases the recall
and fallout and simultaneously
decreases precision.
2. We have found fallout to be a better
measure overall than precision, since, in
addition to its decision-theoretic ad-
vantages (Swets, 1969), it appears to be
more consistent across evaluations of
partitions with different numbers of
clusters. This has also been reported by
other researchers in different evaluation
problems (Lewis and Tong, 1992).
3. The problem of assessing the meaning
of the evaluation scores in an absolute
sense is a non-trivial one. For example,
</listItem>
<bodyText confidence="0.996995018867925">
there has been increasing concern that
the scoring methods used for evaluating
the goodness of parsers are producing
values which seem extremely good (in
the &gt;90% range), while in fact the parse
trees produced are not so satisfactory;
the blame for this inflation of the scores
can be assigned to an inadequate com-
parison technique, which essentially
considers a tree fragment correct when
it is a part of (although not exactly
matching) the corresponding fragment
in the model. For other tasks, such as
part-of-speech assignment to free text,
the comparison techniques are sound,
but very high levels of performance
(e.g. 90%) can be obtained by a zero-
parameter model which operates at ran-
dom; clearly this makes the assessment
of the significance of an improvement
over the base line of the random algo-
rithm much harder.
As a consequence of point (3) made above, we
need to understand the significance of the scores
produced by our evaluation methods (for example,
the limits of their ranges) before trying to interpret
them. There are theoretical principles which indicate
that the evaluation metrics will produce lower values
much more easily than higher ones. Because of the
multiple models used, perfect scores are not attain-
able. Also, because each pair of adjectives in a cluster
is considered an observed association, the relation-
ship between the number of associations produced by
a cluster and the number of adjectives in the cluster is
not linear (a cluster with k adjectives will produce
() k 0(k2) associations). This leads to lower values
2/
of recall, since moving a single adjective out of a
cluster with k elements in the model will cause the
system to miss k-1 associations. As an example of
this phenomenon, consider the hypothetical (single)
model and partition of Figure 4; while the partition
differs from the model only in that the first cluster
has been split into two, the recall score abruptly falls
to 50%.
In order to provide empirical evidence in addition
to the theoretical discussion above, and be able to
estimate an upper bound on the values of the evalua-
tion metrics, we evaluated each human model against
all the other human models, using the same evalua-
tion method which was used for the system; the
results ranged from 38 to 72% for recall, 1 to 12% for
fallout, 38 to 81% for precision, and, covering a
</bodyText>
<figure confidence="0.8456856">
Model: Partition:
1.ABCDE 1. A B C
2. F G 2. D E
3. H I 3. F G
4. H I
</figure>
<figureCaption confidence="0.845884666666667">
Figure 4: A hypothetical model where a small
perturbation leads to a recall score
of 50%.
</figureCaption>
<table confidence="0.9368265">
1 9
Recall Precision Fallout F-measure (3.1)
Without negative knowledge 33.16% 32.32% 7.90% 32.74%
With both modules 49.74% 46.38% 6.54% 48.00%
</table>
<tableCaption confidence="0.999923">
Table 4: Comparison of the system&apos;s performance (9 clusters) with and without the negative knowledge module.
</tableCaption>
<bodyText confidence="0.989314542372881">
remarkably short range, 49 to 59% for F-measure7,
indicating that the performance of the system is not
far behind human performance.
In order to provide a lower bound for the evalua-
tion metrics and thus show that the system&apos;s scores
are not close to the scores of the human judges
simply by chance, we performed a Monte Carlo
analysis (Rubinstein, 1981) for the evaluation
metrics, by repeatedly creating random partitions of
the sample adjectives and evaluating the results. Then
we estimated a smoothed probability density function
for each metric from the resulting histograms; the
results obtained are shown in Figure 5 for F-measure
and fallout using 9 clusters. We observed that the
system&apos;s performance (indicated by a square in the
diagrams) was significantly better than what we
would expect under the null hypothesis of random
performance; the probability of getting a better par-
tition than the system&apos;s is extremely small for all
metrics (no occurrence in 20,000 trials) except for
fallout, for which a random system may be better
4.9% of the time. The estimated density functions
also show that the metrics are severely constrained by
the structure imposed by the clustering as they tend to
peak at some point and then fall rapidly.
Finally, we performed another study to quantify
the impact of using negative knowledge obtained
from adjective-adjective pairs. We ran our system in
a mode where the suggestions of the adjective-
adjective module were ignored (i.e. stage three
simply passed to the output the similarities computed
by the adjective-noun module, after converting them
to dissimilarities), and evaluated the results produced.
The values of the metrics for the partition with 9
clusters appear in Table 4, alongside the correspond-
ing values produced when the system uses both
modules. When both modules are used, we can see a
significant improvement of about 15 points, which is
a 43% to 50% improvement for all metrics (except
for fallout where the improvement is about 17%).
This represents a definite improvement even though
for our test set of 21 adjectives (Figure 2) we ob-
served in our corpus only 41 distinct adjective-
adjective pairs, out of a possible (221)=210 pairs. Al-
7Thus indicating that human models which fared well on the
precision metric tended to perform badly on recall, and vice versa;
remember that the values of the metrics are related to the number
of clusters used, and that the human judges were allowed to select
the number of clusters they considered most appropriate; con-
sequently, the models with high recall/low precision are the ones
with a small number of clusters, while the opposite pattern of
scores characterizes the models with a large number of clusters.
though the observed pairs represent only 19.52% of
the possible pairs, their importance is considerable.
Note that the sparsity of the adjective-adjective
pairs does not allow us to perform a comparable
study for the partition produced using the adjective-
adjective module alone, since such a partition would
be largely determined by chance.
</bodyText>
<sectionHeader confidence="0.9999715" genericHeader="conclusions">
6. CONCLUSIONS AND
FUTURE WORK
</sectionHeader>
<bodyText confidence="0.9997735">
We have described a system for extracting groups
of semantically related adjectives from large text cor-
pora, with a flexible architecture which allows for
multiple knowledge sources influencing similarity to
</bodyText>
<figure confidence="0.97848425">
10 20 30
F-measure (9 c13310,3)
10 IS 20
Feloul d,03.3)
</figure>
<figureCaption confidence="0.9957645">
Figure 5: Estimated probability densities for
F-measure and fallout with 9 clusters.
</figureCaption>
<page confidence="0.986615">
180
</page>
<bodyText confidence="0.999996736842106">
be easily incorporated into the system. Our evalua-
tion reveals that it has significantly high performance
levels, comparable to humans, using only a relatively
small amount of input data; in addition, it shows the
usefulness of negative knowledge, an original feature
of our approach. The system&apos;s results can be filtered
to produce scalar adjectives that are applicable in any
given domain. Furthermore, while we have
demonstrated the algorithm on adjectives, it can be
directly applied to other word classes once sources of
linguistic information for judging their similarity
have been identified.
Our immediate plans are to incorporate more
similarity modules into stage two of the system and
add a training component to stage three so that the
relative weights of the various modules can be es-
timated. We have identified several additional
sources of linguistic knowledge which look promis-
ing, namely pairs of adjectives separated by connec-
tives and adverb-adjective pairs. We also plan to ex-
tend the adjective-noun module to cover adjectives in
predicative positions, in addition to our current use of
attributive adjectives. These extensions not only will
provide us with a better way of exploiting the infor-
mation in the corpus but may also help us categorize
the adjectives as relational or attributive (Levi, 1978);
such a categorization may be useful in classifying
them as either scalar or non-scalar. For determining
whether a group of adjectives is scalar, we also plan
to use the gradability of the adjectives as observed in
the corpus. In addition, we are exploring tests for
determining whether two adjectives are antonymous,
essentially in the opposite direction of the work by
Justeson and Katz (1991) , and tests for comparing
the relative semantic strength of two adjectives.
Furthermore, we plan to consider alternative
evaluation methods and test our system on a much
larger set of adjectives. That was not done for the
current evaluation because of the difficulty for
humans of constructing large models. We are con-
sidering an evaluation method which would use a
thesaurus to judge similarity, as well as a supplemen-
tary method based on mathematical properties of the
clustering. Neither of these methods would access
any human models. The mathematical method, which
uses cluster silhouettes and the silhouette coefficient
(Kaufman and Rousseeuw, 1990), can also be used to
automatically determine the proper number of
clusters, one of the hardest problems in cluster
analysis. We also plan a formal study to evaluate the
appropriateness of the clustering method used, by
computing and evaluating the results when a hierar-
chical algorithm is employed instead in stage four.
Eventually, we plan to evaluate the system&apos;s output
by using it to augment adjective entries in a lexicon
and test the augmented lexicon in an application such
as language generation.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.99997375">
This work was supported jointly by DARPA and
ONR under contract N00014-894-1782, by NSF
GER-90-24069, and by New York State Center for
Advanced Technology Contract NYSSTF-
CAT(91)-053. We wish to thank Diane Litman and
Donald Hindle for providing us with access to the
Fidditch parser at AT&amp;T Bell Labs, and Karen
Kulcich and Frank Smadja for providing us with ac-
cess to the Associated Press news wire corpus.
Finally, we thank Rebecca Passonneau and the
anonymous reviewers for providing us with useful
comments on earlier versions of the paper.
</bodyText>
<sectionHeader confidence="0.999907" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999045076923077">
Bolinger, D. (1977). Neutrality, Norm, and Bias.
Bloomington, IN: Indiana University Linguistics
Club.
Brown P., Della Pietra V., deSouza P., Lai J., and Mercer
R. (1992). Class-based n-gram Models of Natural
Language. Computational Linguistics, 18:4, 467-479.
Brucker, P. (1978). On the complexity of clustering
problems. In Henn, R., Korte, B., and Oletti,
W. (Eds.), Lecture Notes in Economics and Math-
ematical Systems. Optimierung und Operations
Research. Berlin: Springer. Quoted in (Garey and
Johnson, 1979).
Elhadad, Michael. (1991). Generating Adjectives to Ex-
press the Speaker&apos;s Argumentative Intent.
Proceedings of 9th National Conference on Artificial
Intelligence (AAA&apos; 91). Anaheim.
Elhadad, Michael. (1993). Using Argumentation to Control
Lexical Choice: A Unification-Based
Implementation. Doctoral dissertation, Computer
Science Department, Columbia University.
Garey, M.R., and Johnson, D.S. (1979). Computers and
Intractability: A Guide to the Theory of
NP-Completeness. W.H. Freeman.
Hindle, D. M. (1989). Acquiring Disambiguation Rules
from Text. Proceedings of the 27th meeting of the
Association for Computational Linguistics. Van-
couver, B.C..
Hobbs J.R., Appelt D., Bear J., Israel D., Kameyama M.,
and Tyson M. (1993). FAsTus: A System for Extract-
ing Information from Text. Proceedings of the
ARPA Workshop on Human Language Technology.
ARPA Information Science and Technology Office.
Horn, L. (1969). A Presuppositional Analysis of Only and
Even. Papers from the Fifth Regional Meeting.
Chicago Linguistics Society.
Horn, L.R. (1972). On the Semantic Properties of the
Logical Operators in English. Bloomington, IN: In-
diana University Linguistics Club.
Justeson, J.S. and Katz, S.M. (1991). Co-occurences of
</reference>
<page confidence="0.980278">
181
</page>
<reference confidence="0.999570115942029">
Antonymous Adjectives and Their Contexts.
Computational Linguistics, 17:1, 1-19.
Kaufman, L. and Rousseeuw, P.J. (1990). Wiley Series in
Probability and Mathematical Statistics. Finding
Groups in Data: An Introduction to Cluster Analysis.
New York: Wiley.
Kendall, M.G. (1938). A New Measure of Rank Correla-
tion. Biometrika, 30, 81-93.
Knight, Kevin. (1993). Building a Large Ontology for
Machine Translation. Proceedings of the ARPA
Workshop on Human Language Technology. ARPA
Information Science and Technology Office.
Knuth, D.E. (1973). The Art of Computer Programming.
Vol. 1: Fundamental Algorithms (2nd ed.). Reading,
Mass.: Addison-Wesley.
Levi, Judith N. (1978). The Syntax and Semantics of Com-
plex Nominals. New York: Academic Press.
Levinson, S.C. (1983). Pragmatics. Cambridge, England:
Cambridge University Press.
Lewis, D. and Tong, R. (1992). Text Filtering in MUC-3
and MUC-4. Proceedings of the Fourth Message
Understanding Conference (MUC-4). DARPA
Software and Intelligent Systems Technology Office.
Matsukawa, Tomoyoshi. (1993). Hypothesizing Word As-
sociation From Untagged Text. Proceedings of the
ARPA Workshop on Human Language Technology.
ARPA Information Science and Technology Office.
Miller, G.A. (ed.). (1990). WordNet: An On-Line Lexical
Database. International Journal of Lexicography
(special issue), 3:4, 235-312.
Osgood, C.E., Suci, G.S. and Tannenbaum, P.H. (1957).
The measurement of meaning. Urbana, Illinois:
University of Illinois Press.
Pereira F., Tishby N., and Lee L. (1993). Distributional
Clustering of English Words. Proceedings of the
31st Conference of the ACL. Columbus, Ohio: As-
sociation for Computational Linguistics.
Resnik, Philip. (1993). Semantic Classes and Syntactic
Ambiguity. Proceedings of the ARPA Workshop on
Human Language Technology. ARPA Information
Science and Technology Office.
Rubinstein, R.Y. (1981). Wiley Series in Probability and
Mathematical Statistics. Simulation and the Monte
Carlo method. New York: Wiley.
Smadja, F. (1991). Retrieving Collocational Knowledge
from Textual Corpora. An Application: Language
Generation. Doctoral dissertation, Department of
Computer Science, Columbia University.
Sparck-Jones, Karen. (1986). Synonymy and Semantic
Classification. Edinburgh, Great Britain: Edinburgh
University Press. Based on the author&apos;s Ph.D. thesis,
University of Cambridge, 1964.
Spath, Helmuth. (1985). Ellis Norwood Series in Com-
puters and their Applications. Cluster Dissection
and Analysis: Theory, FORTRAN Programs,
Examples. Chichester, West Sussex, England: Ellis
Horwood.
Swets, J.A. (January 1969). Effectiveness of Information
Retrieval Methods. American Documentation, 20,
72-89.
Van Rijsbergen, C.J. (1979). Information Retrieval (2nd
ed.). London: Butterwoths.
Wayne, D.W. (1990). The Duxbury Advanced Series in
Statistics and Decision Sciences. Applied Non-
parametric Statistics (2nd ed.). Boston: PWS-
KENT Publishing Company.
Zipf, G.K. (1949). Human Behavior and the Principle of
Least Effort: An Introduction to Human Ecology.
Reading, Mass.: Addison-Wesley,
</reference>
<page confidence="0.998012">
182
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.601359">
<title confidence="0.904887333333333">TOWARDS THE AUTOMATIC IDENTIFICATION OF ADJECTIVAL SCALES: CLUSTERING ADJECTIVES ACCORDING TO MEANING Vasileios Hatzivassiloglou</title>
<author confidence="0.999994">Kathleen R McKeown</author>
<affiliation confidence="0.999886">Department of Computer Science</affiliation>
<address confidence="0.878753">450 Computer Science Building</address>
<affiliation confidence="0.996428">Columbia University</affiliation>
<address confidence="0.99969">New York, N.Y. 10027</address>
<email confidence="0.9882485">Internet:vh@cs.columbia.edukathy@cs.columbia.edu</email>
<abstract confidence="0.9986648125">In this paper we present a method to group adjectives according to their meaning, as a first step towards the automatic identification of adjectival scales. We discuss the properties of adjectival scales and of groups of semantically related adjectives and how they imply sources of linguistic knowledge in text corpora. We describe how our system exploits this linguistic knowledge to compute a measure of similarity between two adjectives, using statistical techniques and without having access to any semantic information about the adjectives. We also show how a clustering algorithm can use these similarities to produce the groups of adjectives, and we present results produced by our system for a sample set of adjectives. We conclude by presenting evaluation methods for the task at hand, and analyzing the significance of the results obtained.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bolinger</author>
</authors>
<title>Neutrality, Norm, and Bias.</title>
<date>1977</date>
<institution>Indiana University Linguistics Club.</institution>
<location>Bloomington, IN:</location>
<contexts>
<context position="7444" citStr="Bolinger, 1977" startWordPosition="1134" endWordPosition="1135"> for handling negation), they must have access to the sets of words comprising a scale. Linguists have presented various tests for accepting or rejecting a particular scalar relationship between any two adjectives. For example, Horn (1969) proposed a test using the phrase &amp;quot;x even y&amp;quot; for two elements x and y of a totally ordered scale. More SIMILARITY SIMILARITY • • • SIMILARITY MODULE 1 MODULE 2 MODULE n COMBINE SIMILARITIES CLUSTER WORDS Figure 1: System architecture. refined tests locate the position of an adjective in a scale relative to the neutral element or to the extremes of the scale (Bolinger, 1977). The common problem with these methods is that they are designed to be applied by a human who incorporates the two adjectives in specific sentential frames (e.g. &amp;quot;X is warm, even hot&amp;quot;) and assesses the semantic validity of the resulting sentences. Such tests cannot be used computationally to identify scales in a domain, since the specific sentences do not occur frequently enough in a corpus to produce an adequate description of the adjectival scales in the domain (Smadja, 1991). As scales vary across domains, the task of compiling such information is compounded. 3. ALGORITHM Our algorithm, wh</context>
</contexts>
<marker>Bolinger, 1977</marker>
<rawString>Bolinger, D. (1977). Neutrality, Norm, and Bias. Bloomington, IN: Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>Della Pietra V</author>
<author>P deSouza</author>
<author>J Lai</author>
<author>R Mercer</author>
</authors>
<title>Class-based n-gram Models of Natural Language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<pages>467--479</pages>
<contexts>
<context position="3941" citStr="Brown et al., 1992" startWordPosition="576" endWordPosition="579">onstrates how high-level semantic knowledge can be computed from large amounts of low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations). The problem of identifying semantically related words has received considerable attention, both in computational linguistics (e.g. in connection with thesaurus or dictionary construction (Sparck-Jones, 1986)) and in psychology (Osgood et al., 1957). However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them ( (Brown et al., 1992), (Pereira et al., 1993)). In comparison, our work emphasizes the use of shallow linguistic knowledge in addition to a statistical model and is original in the use of negative knowledge to constrain the search space. Furthermore, we use a flexible architecture which will allow us to easily incorporate additional knowledge sources for computing similarity. 172 While our current system does not distinguish between scalar and non-scalar adjectives, it is a first step in the automatic identification of adjectival scales, since the scales can be subsequently ordered and the non-scalar adjectives fi</context>
<context position="11320" citStr="Brown et al., 1992" startWordPosition="1746" endWordPosition="1749">s (e.g. hot warm). 3. Finally, if one adjective modifies the other, the modifying adjective has to qualify the modified one in a different dimension. For example, in light blue shirt, blue is a value of the property color, while light indicates the shadel. The use of multiple types of linguistic data, in Note that sequences such as blue-green are usually hyphenated and thus better considered as a compound. addition to statistical measures, is a unique property of our work and significantly improves the accuracy of our results. One other published model for grouping semantically related words (Brown et al., 1992), is based on a statistical model of bigrams and trigrams and produces word groups using no linguistic knowledge, but no evaluation of the results is reported. 3.1. Stage One: Extracting Word Pairs During the first stage, the system extracts adjective-noun and adjective-adjective pairs from the corpus. To determine the syntactic category of each word, and identify the NP boundaries and the syntactic relations among the words, we used the Fidditch parser (Hindle, 1989). For each NP, we then determine its minimal NP, that part of an NP consisting of the head noun and its adjectival pre-modifiers</context>
</contexts>
<marker>Brown, V, deSouza, Lai, Mercer, 1992</marker>
<rawString>Brown P., Della Pietra V., deSouza P., Lai J., and Mercer R. (1992). Class-based n-gram Models of Natural Language. Computational Linguistics, 18:4, 467-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brucker</author>
</authors>
<title>On the complexity of clustering problems. In</title>
<date>1978</date>
<booktitle>Lecture Notes in Economics and Mathematical Systems. Optimierung und Operations Research.</booktitle>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<note>Quoted in</note>
<contexts>
<context position="24030" citStr="Brucker, 1978" startWordPosition="3834" endWordPosition="3835">rovement of (13 if there is such a cluster and the next adjective is considered. This procedure is repeated until no more moves lead to an improvement of O. This is a hill-climbing method and therefore is guaranteed to converge, but it may lead to a local minimum of (1), inferior to the global minimum that corresponds to the optimal solution. To alleviate this problem, the partitioning algorithm is called repeatedly with different random starting partitions and the best solution in these runs is kept. As with many practical optimization problems, computing the optimal solution is NP-complete (Brucker, 1978). 176 antitrust new big old economic political financial potential foreign real global serious international severe legal staggering little technical major unexpected mechanical Figure 2: Adjectives to be grouped. Note that if the problem&apos;s search space had been relatively small, then we could have computed the optimal partition by enumerating all possible solutions and keeping the best one. However, again as with many other practical optimization problems, the search space turns out to be intractably large. The number of possible partitions of n objects to m nonempty subsets with mtt is equal</context>
</contexts>
<marker>Brucker, 1978</marker>
<rawString>Brucker, P. (1978). On the complexity of clustering problems. In Henn, R., Korte, B., and Oletti, W. (Eds.), Lecture Notes in Economics and Mathematical Systems. Optimierung und Operations Research. Berlin: Springer. Quoted in (Garey and Johnson, 1979).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
</authors>
<title>Generating Adjectives to Express the Speaker&apos;s Argumentative Intent.</title>
<date>1991</date>
<booktitle>Proceedings of 9th National Conference on Artificial Intelligence (AAA&apos; 91).</booktitle>
<location>Anaheim.</location>
<contexts>
<context position="6809" citStr="Elhadad, 1991" startWordPosition="1026" endWordPosition="1027"> between cold and hot. Linguistic scales are known to possess interesting properties, derived from conventional logical entailment on the linear ordering of their elements and from Gricean scalar implicature (Levinson, 1983). Despite these properties and their potential usefulness in both understanding and generating natural language text, dictionary entries are largely incomplete for adjectives in this regard. Yet, if systems are to use the information encoded in adjectival scales for generation or interpretation (e.g. for selecting an adjective with a particular degree of semantic strength (Elhadad, 1991, Elhadad, 1993), or for handling negation), they must have access to the sets of words comprising a scale. Linguists have presented various tests for accepting or rejecting a particular scalar relationship between any two adjectives. For example, Horn (1969) proposed a test using the phrase &amp;quot;x even y&amp;quot; for two elements x and y of a totally ordered scale. More SIMILARITY SIMILARITY • • • SIMILARITY MODULE 1 MODULE 2 MODULE n COMBINE SIMILARITIES CLUSTER WORDS Figure 1: System architecture. refined tests locate the position of an adjective in a scale relative to the neutral element or to the ext</context>
</contexts>
<marker>Elhadad, 1991</marker>
<rawString>Elhadad, Michael. (1991). Generating Adjectives to Express the Speaker&apos;s Argumentative Intent. Proceedings of 9th National Conference on Artificial Intelligence (AAA&apos; 91). Anaheim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
</authors>
<title>Using Argumentation to Control Lexical Choice: A Unification-Based Implementation. Doctoral dissertation,</title>
<date>1993</date>
<institution>Computer Science Department, Columbia University.</institution>
<contexts>
<context position="6825" citStr="Elhadad, 1993" startWordPosition="1028" endWordPosition="1029">nd hot. Linguistic scales are known to possess interesting properties, derived from conventional logical entailment on the linear ordering of their elements and from Gricean scalar implicature (Levinson, 1983). Despite these properties and their potential usefulness in both understanding and generating natural language text, dictionary entries are largely incomplete for adjectives in this regard. Yet, if systems are to use the information encoded in adjectival scales for generation or interpretation (e.g. for selecting an adjective with a particular degree of semantic strength (Elhadad, 1991, Elhadad, 1993), or for handling negation), they must have access to the sets of words comprising a scale. Linguists have presented various tests for accepting or rejecting a particular scalar relationship between any two adjectives. For example, Horn (1969) proposed a test using the phrase &amp;quot;x even y&amp;quot; for two elements x and y of a totally ordered scale. More SIMILARITY SIMILARITY • • • SIMILARITY MODULE 1 MODULE 2 MODULE n COMBINE SIMILARITIES CLUSTER WORDS Figure 1: System architecture. refined tests locate the position of an adjective in a scale relative to the neutral element or to the extremes of the sca</context>
</contexts>
<marker>Elhadad, 1993</marker>
<rawString>Elhadad, Michael. (1993). Using Argumentation to Control Lexical Choice: A Unification-Based Implementation. Doctoral dissertation, Computer Science Department, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Garey</author>
<author>D S Johnson</author>
</authors>
<title>Computers and Intractability: A Guide to the Theory of NP-Completeness.</title>
<date>1979</date>
<publisher>W.H. Freeman.</publisher>
<marker>Garey, Johnson, 1979</marker>
<rawString>Garey, M.R., and Johnson, D.S. (1979). Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. Freeman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Hindle</author>
</authors>
<title>Acquiring Disambiguation Rules from Text.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th meeting of the Association for Computational Linguistics.</booktitle>
<location>Vancouver, B.C..</location>
<contexts>
<context position="11792" citStr="Hindle, 1989" startWordPosition="1823" endWordPosition="1824">nd significantly improves the accuracy of our results. One other published model for grouping semantically related words (Brown et al., 1992), is based on a statistical model of bigrams and trigrams and produces word groups using no linguistic knowledge, but no evaluation of the results is reported. 3.1. Stage One: Extracting Word Pairs During the first stage, the system extracts adjective-noun and adjective-adjective pairs from the corpus. To determine the syntactic category of each word, and identify the NP boundaries and the syntactic relations among the words, we used the Fidditch parser (Hindle, 1989). For each NP, we then determine its minimal NP, that part of an NP consisting of the head noun and its adjectival pre-modifiers2. We match a set of regular expressions, consisting of syntactic categories and representing the different forms a minimal NP can take, against the NPs. From the minimal NP, we produce the different pairs of adjectives and nouns, assuming that all adjectives modify the head noun3. This assumption is rarely invalid, because a minimal NP with multiple adjectives all modifying the head noun is far more common than a minimal NP with multiple adjectives where one of them </context>
</contexts>
<marker>Hindle, 1989</marker>
<rawString>Hindle, D. M. (1989). Acquiring Disambiguation Rules from Text. Proceedings of the 27th meeting of the Association for Computational Linguistics. Vancouver, B.C..</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
<author>D Appelt</author>
<author>J Bear</author>
<author>D Israel</author>
<author>M Kameyama</author>
<author>M Tyson</author>
</authors>
<title>FAsTus: A System for Extracting Information from Text.</title>
<date>1993</date>
<booktitle>Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</booktitle>
<contexts>
<context position="13478" citStr="Hobbs et al., 1993" startWordPosition="2095" endWordPosition="2098">)). This component also reduces the number of different pairs without losing information by transforming words to an equivalent, base form (e.g. plural nouns are converted to singular) so that the expected and actual frequencies of each pair are higher. Stage one then produces as output a simple list of adjective-adjective pairs that occurred within the same minimal NP and a table with the observed frequencies of every adjective-noun combination. Each row in the table contains the frequencies of modified nouns for a given adjective. 2This part of an NP has been used by many researchers (e.g. (Hobbs et al., 1993) who call it a noun group), mostly because of the relative ease with which it can be identified. 3We take into account possessives however and correct the result, so that the minimal NP (the) tall man&apos;s wife will correctly produce the pair (tall, man) instead of (tall, wife). 174 3.2. Stage Two: Computing Similarities Between Adjectives This stage currently employs two similarity modules, each of which processes a part of the output of stage one and produces a measure of similarity for each possible pair of adjectives. The first module processes the adjective-noun frequency table; for each pos</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Israel, Kameyama, Tyson, 1993</marker>
<rawString>Hobbs J.R., Appelt D., Bear J., Israel D., Kameyama M., and Tyson M. (1993). FAsTus: A System for Extracting Information from Text. Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Horn</author>
</authors>
<title>A Presuppositional Analysis of Only and Even. Papers from the Fifth Regional Meeting. Chicago Linguistics Society.</title>
<date>1969</date>
<contexts>
<context position="7068" citStr="Horn (1969)" startWordPosition="1067" endWordPosition="1068">potential usefulness in both understanding and generating natural language text, dictionary entries are largely incomplete for adjectives in this regard. Yet, if systems are to use the information encoded in adjectival scales for generation or interpretation (e.g. for selecting an adjective with a particular degree of semantic strength (Elhadad, 1991, Elhadad, 1993), or for handling negation), they must have access to the sets of words comprising a scale. Linguists have presented various tests for accepting or rejecting a particular scalar relationship between any two adjectives. For example, Horn (1969) proposed a test using the phrase &amp;quot;x even y&amp;quot; for two elements x and y of a totally ordered scale. More SIMILARITY SIMILARITY • • • SIMILARITY MODULE 1 MODULE 2 MODULE n COMBINE SIMILARITIES CLUSTER WORDS Figure 1: System architecture. refined tests locate the position of an adjective in a scale relative to the neutral element or to the extremes of the scale (Bolinger, 1977). The common problem with these methods is that they are designed to be applied by a human who incorporates the two adjectives in specific sentential frames (e.g. &amp;quot;X is warm, even hot&amp;quot;) and assesses the semantic validity of </context>
</contexts>
<marker>Horn, 1969</marker>
<rawString>Horn, L. (1969). A Presuppositional Analysis of Only and Even. Papers from the Fifth Regional Meeting. Chicago Linguistics Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Horn</author>
</authors>
<date>1972</date>
<booktitle>On the Semantic Properties of the Logical Operators in English.</booktitle>
<institution>Indiana University Linguistics Club.</institution>
<location>Bloomington, IN:</location>
<contexts>
<context position="5526" citStr="Horn, 1972" startWordPosition="830" endWordPosition="831">e results. 2. BACKGROUND A linguistic scale is a set of words, of the same grammatical category, which can be ordered by their semantic strength or degree of informativeness (Levinson, 1983). For example, lukewarm, warm, and hot fall along a single adjectival scale since they indicate a variation in the intensity of temperature of the modified noun (at least when used in their nonmetaphorical senses; metaphorical usage of scalar words normally also follows the order of the scale by analogy). Scales are not limited to adjectives; for example, (may, should, must) and (sometimes, often, always) (Horn, 1972) are linguistic scales consisting of auxiliary verbs expressing obligation and of adverbs expressing frequency respectively. In the case of adjectives, the above definition is commonly relaxed to replace the total order among the elements of the scale by a partial one, so that the elements of the scale may be partitioned into two groups (sub-scales), within each of which the order is total. The two sub-groups correspond to positive and negative degrees of the common property that the scale describes. For example, the set of adjectives (cold, lukewarm, warm, hot) are normally considered part of</context>
</contexts>
<marker>Horn, 1972</marker>
<rawString>Horn, L.R. (1972). On the Semantic Properties of the Logical Operators in English. Bloomington, IN: Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Justeson</author>
<author>S M Katz</author>
</authors>
<date>1991</date>
<journal>Co-occurences of Antonymous Adjectives and Their Contexts. Computational Linguistics,</journal>
<volume>17</volume>
<pages>1--19</pages>
<contexts>
<context position="42588" citStr="Justeson and Katz (1991)" startWordPosition="6883" endWordPosition="6886">rent use of attributive adjectives. These extensions not only will provide us with a better way of exploiting the information in the corpus but may also help us categorize the adjectives as relational or attributive (Levi, 1978); such a categorization may be useful in classifying them as either scalar or non-scalar. For determining whether a group of adjectives is scalar, we also plan to use the gradability of the adjectives as observed in the corpus. In addition, we are exploring tests for determining whether two adjectives are antonymous, essentially in the opposite direction of the work by Justeson and Katz (1991) , and tests for comparing the relative semantic strength of two adjectives. Furthermore, we plan to consider alternative evaluation methods and test our system on a much larger set of adjectives. That was not done for the current evaluation because of the difficulty for humans of constructing large models. We are considering an evaluation method which would use a thesaurus to judge similarity, as well as a supplementary method based on mathematical properties of the clustering. Neither of these methods would access any human models. The mathematical method, which uses cluster silhouettes and </context>
</contexts>
<marker>Justeson, Katz, 1991</marker>
<rawString>Justeson, J.S. and Katz, S.M. (1991). Co-occurences of Antonymous Adjectives and Their Contexts. Computational Linguistics, 17:1, 1-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kaufman</author>
<author>P J Rousseeuw</author>
</authors>
<title>Wiley Series in Probability and Mathematical Statistics. Finding Groups in Data: An Introduction to Cluster Analysis.</title>
<date>1990</date>
<publisher>Wiley.</publisher>
<location>New York:</location>
<contexts>
<context position="22100" citStr="Kaufman and Rousseeuw, 1990" startWordPosition="3500" endWordPosition="3503">rities and/or dissimilarities produced by these modules, and add a separate training component which will determine the appropriate value for the weight of each module. 3.4. Stage Four: Clustering The Adjectives In stage four we form groups of adjectives (a partition) according to the combined dissimilarity values computed in the previous stage. We want to find a partition which is optimal, in the sense that adjectives with high dissimilarity are placed in different groups. We use a non-hierarchical clustering algorithm, since such algorithms are in general stronger than hierarchical methods (Kaufman and Rousseeuw, 1990). The number of clusters produced is an input parameter. The algorithm uses the exchange method (Spath, 1985) since the more commonly used Kmeans method (Kaufman and Rousseeuw, 1990) is not applicable; the K-means method, like all centroid methods, requires the measure d between the clustered objects to be a distance; this means, among other conditions, that for any three objects x, y, and z the triangle inequality applies. However, this inequality does not necessarily hold for our dissimilarity measure. If the adjectives x and y were observed in the same minimal NP, their dissimilarity is qui</context>
<context position="43244" citStr="Kaufman and Rousseeuw, 1990" startWordPosition="6985" endWordPosition="6988">he relative semantic strength of two adjectives. Furthermore, we plan to consider alternative evaluation methods and test our system on a much larger set of adjectives. That was not done for the current evaluation because of the difficulty for humans of constructing large models. We are considering an evaluation method which would use a thesaurus to judge similarity, as well as a supplementary method based on mathematical properties of the clustering. Neither of these methods would access any human models. The mathematical method, which uses cluster silhouettes and the silhouette coefficient (Kaufman and Rousseeuw, 1990), can also be used to automatically determine the proper number of clusters, one of the hardest problems in cluster analysis. We also plan a formal study to evaluate the appropriateness of the clustering method used, by computing and evaluating the results when a hierarchical algorithm is employed instead in stage four. Eventually, we plan to evaluate the system&apos;s output by using it to augment adjective entries in a lexicon and test the augmented lexicon in an application such as language generation. ACKNOWLEDGEMENTS This work was supported jointly by DARPA and ONR under contract N00014-894-17</context>
</contexts>
<marker>Kaufman, Rousseeuw, 1990</marker>
<rawString>Kaufman, L. and Rousseeuw, P.J. (1990). Wiley Series in Probability and Mathematical Statistics. Finding Groups in Data: An Introduction to Cluster Analysis. New York: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Kendall</author>
</authors>
<title>A New Measure of Rank Correlation.</title>
<date>1938</date>
<journal>Biometrika,</journal>
<volume>30</volume>
<pages>81--93</pages>
<contexts>
<context position="14317" citStr="Kendall, 1938" startWordPosition="2231" endWordPosition="2232">oduce the pair (tall, man) instead of (tall, wife). 174 3.2. Stage Two: Computing Similarities Between Adjectives This stage currently employs two similarity modules, each of which processes a part of the output of stage one and produces a measure of similarity for each possible pair of adjectives. The first module processes the adjective-noun frequency table; for each possible pair in the table we compare the two distributions of nouns. We use a robust non-parametric method to compute the similarity between the modified noun distributions for any two adjectives, namely Kendall&apos;s coefficient (Kendall, 1938) for two random variables with paired observations. In our case, the two random variables are the two adjectives we are comparing, and each paired observation is their frequency of cooccurrence with a given noun. Kendall&apos;s T coefficient compares the two variables by repeatedly comparing two pairs of their corresponding observations. Formally, if (Xi,Yi) and (XJ,Yi) are two pairs of observations for the adjectives X&apos; and Y on the nouns i and j respectively, we call these pairs concordant if Xi&gt;XJ. and Y.&gt;Y. or if X&lt;X. and Y t &lt;11, otherwise these pairs are discordant. We discard ties, that is p</context>
</contexts>
<marker>Kendall, 1938</marker>
<rawString>Kendall, M.G. (1938). A New Measure of Rank Correlation. Biometrika, 30, 81-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Building a Large Ontology for Machine Translation.</title>
<date>1993</date>
<booktitle>Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</booktitle>
<contexts>
<context position="2821" citStr="Knight, 1993" startWordPosition="419" endWordPosition="420">e type of lexical knowledge which is useful for many natural language (NL) tasks is the semantic relatedness between words of the same or different syntactic categories. Semantic relatedness subsumes hyponymy, synonymy, and antonymyincompatibility. Special forms of relatedness are represented in the lexical entries of the WordNet lexical database (Miller et al., 1990). Paradigmatic semantic relations in WordNet have been used for diverse NL problems, including disambiguation of syntactic structure (Resnik, 1993) and semiautomatic construction of a large-scale ontology for machine translation (Knight, 1993). In this paper, we focus on a particular case of semantic relatedness: relatedness between adjectives which describe the same property. We describe a technique for automatically grouping adjectives according to their meaning based on a given text corpus, so that all adjectives placed in one group describe different values of the same property. Our method is based on statistical techniques, augmented with linguistic information derived from the corpus, and is completely domain independent. It demonstrates how high-level semantic knowledge can be computed from large amounts of low-level knowled</context>
</contexts>
<marker>Knight, 1993</marker>
<rawString>Knight, Kevin. (1993). Building a Large Ontology for Machine Translation. Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<date>1973</date>
<booktitle>The Art of Computer Programming.</booktitle>
<volume>1</volume>
<publisher>Addison-Wesley.</publisher>
<location>Reading, Mass.:</location>
<contexts>
<context position="24700" citStr="Knuth, 1973" startWordPosition="3940" endWordPosition="3941">otential foreign real global serious international severe legal staggering little technical major unexpected mechanical Figure 2: Adjectives to be grouped. Note that if the problem&apos;s search space had been relatively small, then we could have computed the optimal partition by enumerating all possible solutions and keeping the best one. However, again as with many other practical optimization problems, the search space turns out to be intractably large. The number of possible partitions of n objects to m nonempty subsets with mtt is equal to the corresponding Stirling number of the second kind (Knuth, 1973), and this number grows exponentially with n for all but trivial values of m. For example, for our test set of adjectives presented in the next section, we have n=21 and m=9; the corresponding number of possible partitions is roughly 1.23 x 1014. 4. RESULTS We tested our system on a 8.2 million word corpus of stock market reports from the Associated Press news wire. A subset of 21 of the adjectives in the corpus (Figure 2) was selected for practical reasons (mainly for keeping the evaluation task tractable). We selected adjectives that have one modified noun in common (problem) to ensure some </context>
</contexts>
<marker>Knuth, 1973</marker>
<rawString>Knuth, D.E. (1973). The Art of Computer Programming. Vol. 1: Fundamental Algorithms (2nd ed.). Reading, Mass.: Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith N Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="42192" citStr="Levi, 1978" startWordPosition="6821" endWordPosition="6822">omponent to stage three so that the relative weights of the various modules can be estimated. We have identified several additional sources of linguistic knowledge which look promising, namely pairs of adjectives separated by connectives and adverb-adjective pairs. We also plan to extend the adjective-noun module to cover adjectives in predicative positions, in addition to our current use of attributive adjectives. These extensions not only will provide us with a better way of exploiting the information in the corpus but may also help us categorize the adjectives as relational or attributive (Levi, 1978); such a categorization may be useful in classifying them as either scalar or non-scalar. For determining whether a group of adjectives is scalar, we also plan to use the gradability of the adjectives as observed in the corpus. In addition, we are exploring tests for determining whether two adjectives are antonymous, essentially in the opposite direction of the work by Justeson and Katz (1991) , and tests for comparing the relative semantic strength of two adjectives. Furthermore, we plan to consider alternative evaluation methods and test our system on a much larger set of adjectives. That wa</context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Levi, Judith N. (1978). The Syntax and Semantics of Complex Nominals. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Levinson</author>
</authors>
<date>1983</date>
<publisher>Cambridge University Press.</publisher>
<location>Pragmatics. Cambridge, England:</location>
<contexts>
<context position="5105" citStr="Levinson, 1983" startWordPosition="762" endWordPosition="763">bsequently ordered and the non-scalar adjectives filtered on the basis of independent tests, done in part automatically and in part by hand in a post-editing phase. The result is a semi-automated system for the compilation of adjectival scales. In the following sections, we first provide background on scales, then describe our algorithm in detail, present the results obtained, and finally provide a formal evaluation of the results. 2. BACKGROUND A linguistic scale is a set of words, of the same grammatical category, which can be ordered by their semantic strength or degree of informativeness (Levinson, 1983). For example, lukewarm, warm, and hot fall along a single adjectival scale since they indicate a variation in the intensity of temperature of the modified noun (at least when used in their nonmetaphorical senses; metaphorical usage of scalar words normally also follows the order of the scale by analogy). Scales are not limited to adjectives; for example, (may, should, must) and (sometimes, often, always) (Horn, 1972) are linguistic scales consisting of auxiliary verbs expressing obligation and of adverbs expressing frequency respectively. In the case of adjectives, the above definition is com</context>
<context position="6420" citStr="Levinson, 1983" startWordPosition="969" endWordPosition="970">he elements of the scale may be partitioned into two groups (sub-scales), within each of which the order is total. The two sub-groups correspond to positive and negative degrees of the common property that the scale describes. For example, the set of adjectives (cold, lukewarm, warm, hot) are normally considered part of one scale, even though no direct ordering of semantic strength exists between cold and hot. Linguistic scales are known to possess interesting properties, derived from conventional logical entailment on the linear ordering of their elements and from Gricean scalar implicature (Levinson, 1983). Despite these properties and their potential usefulness in both understanding and generating natural language text, dictionary entries are largely incomplete for adjectives in this regard. Yet, if systems are to use the information encoded in adjectival scales for generation or interpretation (e.g. for selecting an adjective with a particular degree of semantic strength (Elhadad, 1991, Elhadad, 1993), or for handling negation), they must have access to the sets of words comprising a scale. Linguists have presented various tests for accepting or rejecting a particular scalar relationship betw</context>
<context position="10624" citStr="Levinson, 1983" startWordPosition="1634" endWordPosition="1635">at each adjective modifies and categorizes adjectives as similar if they have similar distributions. Second, we use adjective-adjective pairs occurring as pre-modifiers within the same NP as a strong indication that the two adjectives do not belong in the same group. There are three cases: 1. If both adjectives modify the head noun and the two adjectives are antithetical, the NP would be self-contradictory, as in the scalar sequence hot cold or the non-scalar red black. 2. For non-antithetical scalar adjectives which both modify the head noun, the NP would violate the Gricean maxim of Manner (Levinson, 1983) since the same information is conveyed by the strongest of the two adjectives (e.g. hot warm). 3. Finally, if one adjective modifies the other, the modifying adjective has to qualify the modified one in a different dimension. For example, in light blue shirt, blue is a value of the property color, while light indicates the shadel. The use of multiple types of linguistic data, in Note that sequences such as blue-green are usually hyphenated and thus better considered as a compound. addition to statistical measures, is a unique property of our work and significantly improves the accuracy of our</context>
</contexts>
<marker>Levinson, 1983</marker>
<rawString>Levinson, S.C. (1983). Pragmatics. Cambridge, England: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
<author>R Tong</author>
</authors>
<title>Text Filtering</title>
<date>1992</date>
<booktitle>in MUC-3 and MUC-4. Proceedings of the Fourth Message Understanding Conference (MUC-4). DARPA Software and Intelligent Systems Technology Office.</booktitle>
<contexts>
<context position="34550" citStr="Lewis and Tong, 1992" startWordPosition="5564" endWordPosition="5567">s of the number of clusters. We have made these observations related to the evaluation mechanism: 1. Recall is inversely related to fallout and precision. Decreasing the number of clusters generally increases the recall and fallout and simultaneously decreases precision. 2. We have found fallout to be a better measure overall than precision, since, in addition to its decision-theoretic advantages (Swets, 1969), it appears to be more consistent across evaluations of partitions with different numbers of clusters. This has also been reported by other researchers in different evaluation problems (Lewis and Tong, 1992). 3. The problem of assessing the meaning of the evaluation scores in an absolute sense is a non-trivial one. For example, there has been increasing concern that the scoring methods used for evaluating the goodness of parsers are producing values which seem extremely good (in the &gt;90% range), while in fact the parse trees produced are not so satisfactory; the blame for this inflation of the scores can be assigned to an inadequate comparison technique, which essentially considers a tree fragment correct when it is a part of (although not exactly matching) the corresponding fragment in the model</context>
</contexts>
<marker>Lewis, Tong, 1992</marker>
<rawString>Lewis, D. and Tong, R. (1992). Text Filtering in MUC-3 and MUC-4. Proceedings of the Fourth Message Understanding Conference (MUC-4). DARPA Software and Intelligent Systems Technology Office.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoyoshi Matsukawa</author>
</authors>
<title>Hypothesizing Word Association From Untagged Text.</title>
<date>1993</date>
<booktitle>Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</booktitle>
<contexts>
<context position="29629" citStr="Matsukawa, 1993" startWordPosition="4757" endWordPosition="4758">ormance of our system we compared its output to a model solution for the problem designed by humans. Nine human judges were presented with the set of adjectives to be partitioned, a description of the domain, and a simple example. They were told that clusters should not overlap but they could select any number of clusters (the judges used from 6 to 11 clusters, with an average of 8.565 and a sample standard deviation of 1.74). Note that this evaluation method differs significantly from the alternative method of asking the humans to directly estimate the goodness of the system&apos;s results (e.g. (Matsukawa, 1993)). It requires an explicit construction of a model from the human judge and places the burden of the comparison between the model and the system&apos;s output on the system instead of the judge. It has been repeatedly demonstrated that in complex evaluation tasks humans can easily find arguments to support observed data, leading to biased results and to an inflation of the evaluation scores. To score our results, we converted the comparison of two partitions to a series of yes-no questions, each of which has a correct answer (as dictated by the model) and an answer assigned by the system. For each </context>
</contexts>
<marker>Matsukawa, 1993</marker>
<rawString>Matsukawa, Tomoyoshi. (1993). Hypothesizing Word Association From Untagged Text. Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: An On-Line Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography (special issue),</journal>
<volume>3</volume>
<pages>235--312</pages>
<marker>Miller, 1990</marker>
<rawString>Miller, G.A. (ed.). (1990). WordNet: An On-Line Lexical Database. International Journal of Lexicography (special issue), 3:4, 235-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C E Osgood</author>
<author>G S Suci</author>
<author>P H Tannenbaum</author>
</authors>
<title>The measurement of meaning.</title>
<date>1957</date>
<publisher>University of Illinois Press.</publisher>
<location>Urbana, Illinois:</location>
<contexts>
<context position="3756" citStr="Osgood et al., 1957" startWordPosition="548" endWordPosition="551">nt values of the same property. Our method is based on statistical techniques, augmented with linguistic information derived from the corpus, and is completely domain independent. It demonstrates how high-level semantic knowledge can be computed from large amounts of low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations). The problem of identifying semantically related words has received considerable attention, both in computational linguistics (e.g. in connection with thesaurus or dictionary construction (Sparck-Jones, 1986)) and in psychology (Osgood et al., 1957). However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them ( (Brown et al., 1992), (Pereira et al., 1993)). In comparison, our work emphasizes the use of shallow linguistic knowledge in addition to a statistical model and is original in the use of negative knowledge to constrain the search space. Furthermore, we use a flexible architecture which will allow us to easily incorporate additional knowledge sources for computing similarity. 172 While our current system does not distinguish between</context>
</contexts>
<marker>Osgood, Suci, Tannenbaum, 1957</marker>
<rawString>Osgood, C.E., Suci, G.S. and Tannenbaum, P.H. (1957). The measurement of meaning. Urbana, Illinois: University of Illinois Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>N Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional Clustering of English Words.</title>
<date>1993</date>
<booktitle>Proceedings of the 31st Conference of the ACL.</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio:</location>
<contexts>
<context position="3965" citStr="Pereira et al., 1993" startWordPosition="580" endWordPosition="583">el semantic knowledge can be computed from large amounts of low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations). The problem of identifying semantically related words has received considerable attention, both in computational linguistics (e.g. in connection with thesaurus or dictionary construction (Sparck-Jones, 1986)) and in psychology (Osgood et al., 1957). However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them ( (Brown et al., 1992), (Pereira et al., 1993)). In comparison, our work emphasizes the use of shallow linguistic knowledge in addition to a statistical model and is original in the use of negative knowledge to constrain the search space. Furthermore, we use a flexible architecture which will allow us to easily incorporate additional knowledge sources for computing similarity. 172 While our current system does not distinguish between scalar and non-scalar adjectives, it is a first step in the automatic identification of adjectival scales, since the scales can be subsequently ordered and the non-scalar adjectives filtered on the basis of i</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira F., Tishby N., and Lee L. (1993). Distributional Clustering of English Words. Proceedings of the 31st Conference of the ACL. Columbus, Ohio: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic Classes and Syntactic Ambiguity.</title>
<date>1993</date>
<booktitle>Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</booktitle>
<contexts>
<context position="2725" citStr="Resnik, 1993" startWordPosition="406" endWordPosition="407">ome form of at least partial automation of the lexical knowledge acquisition phase is needed. One type of lexical knowledge which is useful for many natural language (NL) tasks is the semantic relatedness between words of the same or different syntactic categories. Semantic relatedness subsumes hyponymy, synonymy, and antonymyincompatibility. Special forms of relatedness are represented in the lexical entries of the WordNet lexical database (Miller et al., 1990). Paradigmatic semantic relations in WordNet have been used for diverse NL problems, including disambiguation of syntactic structure (Resnik, 1993) and semiautomatic construction of a large-scale ontology for machine translation (Knight, 1993). In this paper, we focus on a particular case of semantic relatedness: relatedness between adjectives which describe the same property. We describe a technique for automatically grouping adjectives according to their meaning based on a given text corpus, so that all adjectives placed in one group describe different values of the same property. Our method is based on statistical techniques, augmented with linguistic information derived from the corpus, and is completely domain independent. It demons</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Resnik, Philip. (1993). Semantic Classes and Syntactic Ambiguity. Proceedings of the ARPA Workshop on Human Language Technology. ARPA Information Science and Technology Office.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Y Rubinstein</author>
</authors>
<date>1981</date>
<booktitle>Wiley Series in Probability and Mathematical Statistics. Simulation and the Monte Carlo method.</booktitle>
<publisher>Wiley.</publisher>
<location>New York:</location>
<contexts>
<context position="37781" citStr="Rubinstein, 1981" startWordPosition="6119" endWordPosition="6120">re of 50%. 1 9 Recall Precision Fallout F-measure (3.1) Without negative knowledge 33.16% 32.32% 7.90% 32.74% With both modules 49.74% 46.38% 6.54% 48.00% Table 4: Comparison of the system&apos;s performance (9 clusters) with and without the negative knowledge module. remarkably short range, 49 to 59% for F-measure7, indicating that the performance of the system is not far behind human performance. In order to provide a lower bound for the evaluation metrics and thus show that the system&apos;s scores are not close to the scores of the human judges simply by chance, we performed a Monte Carlo analysis (Rubinstein, 1981) for the evaluation metrics, by repeatedly creating random partitions of the sample adjectives and evaluating the results. Then we estimated a smoothed probability density function for each metric from the resulting histograms; the results obtained are shown in Figure 5 for F-measure and fallout using 9 clusters. We observed that the system&apos;s performance (indicated by a square in the diagrams) was significantly better than what we would expect under the null hypothesis of random performance; the probability of getting a better partition than the system&apos;s is extremely small for all metrics (no </context>
</contexts>
<marker>Rubinstein, 1981</marker>
<rawString>Rubinstein, R.Y. (1981). Wiley Series in Probability and Mathematical Statistics. Simulation and the Monte Carlo method. New York: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving Collocational Knowledge from Textual Corpora. An Application: Language Generation.</title>
<date>1991</date>
<institution>Department of Computer Science, Columbia University.</institution>
<note>Doctoral dissertation,</note>
<contexts>
<context position="7927" citStr="Smadja, 1991" startWordPosition="1213" endWordPosition="1214">ts locate the position of an adjective in a scale relative to the neutral element or to the extremes of the scale (Bolinger, 1977). The common problem with these methods is that they are designed to be applied by a human who incorporates the two adjectives in specific sentential frames (e.g. &amp;quot;X is warm, even hot&amp;quot;) and assesses the semantic validity of the resulting sentences. Such tests cannot be used computationally to identify scales in a domain, since the specific sentences do not occur frequently enough in a corpus to produce an adequate description of the adjectival scales in the domain (Smadja, 1991). As scales vary across domains, the task of compiling such information is compounded. 3. ALGORITHM Our algorithm, whose overall architecture is depicted in Figure 1, operates in four stages. First, we extract linguistic data from the parsed corpus in the form of syntactically related word pairs, or, more generally, sequences of syntactically related words; this co-occurrence information is processed by a morphology component and tabulated. In the second stage, the various types of co-occurrence relations which have been identified in the text are forwarded EXTRACT WORD PATTERNS 173 to a set o</context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Smadja, F. (1991). Retrieving Collocational Knowledge from Textual Corpora. An Application: Language Generation. Doctoral dissertation, Department of Computer Science, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sparck-Jones</author>
</authors>
<title>Synonymy and Semantic Classification. Edinburgh, Great Britain: Edinburgh University Press. Based on the author&apos;s Ph.D. thesis,</title>
<date>1986</date>
<institution>University of Cambridge,</institution>
<contexts>
<context position="3715" citStr="Sparck-Jones, 1986" startWordPosition="543" endWordPosition="544">ves placed in one group describe different values of the same property. Our method is based on statistical techniques, augmented with linguistic information derived from the corpus, and is completely domain independent. It demonstrates how high-level semantic knowledge can be computed from large amounts of low-level knowledge (essentially plain text, part-of-speech rules, and optionally syntactic relations). The problem of identifying semantically related words has received considerable attention, both in computational linguistics (e.g. in connection with thesaurus or dictionary construction (Sparck-Jones, 1986)) and in psychology (Osgood et al., 1957). However, only recently has work been done on the automatic computation of such relationships from text, quantifying similarity between words and clustering them ( (Brown et al., 1992), (Pereira et al., 1993)). In comparison, our work emphasizes the use of shallow linguistic knowledge in addition to a statistical model and is original in the use of negative knowledge to constrain the search space. Furthermore, we use a flexible architecture which will allow us to easily incorporate additional knowledge sources for computing similarity. 172 While our cu</context>
</contexts>
<marker>Sparck-Jones, 1986</marker>
<rawString>Sparck-Jones, Karen. (1986). Synonymy and Semantic Classification. Edinburgh, Great Britain: Edinburgh University Press. Based on the author&apos;s Ph.D. thesis, University of Cambridge, 1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmuth Spath</author>
</authors>
<title>Ellis Norwood Series in Computers and their Applications. Cluster Dissection and Analysis: Theory, FORTRAN Programs, Examples.</title>
<date>1985</date>
<publisher>Ellis Horwood.</publisher>
<location>Chichester, West Sussex, England:</location>
<contexts>
<context position="22209" citStr="Spath, 1985" startWordPosition="3519" endWordPosition="3520">priate value for the weight of each module. 3.4. Stage Four: Clustering The Adjectives In stage four we form groups of adjectives (a partition) according to the combined dissimilarity values computed in the previous stage. We want to find a partition which is optimal, in the sense that adjectives with high dissimilarity are placed in different groups. We use a non-hierarchical clustering algorithm, since such algorithms are in general stronger than hierarchical methods (Kaufman and Rousseeuw, 1990). The number of clusters produced is an input parameter. The algorithm uses the exchange method (Spath, 1985) since the more commonly used Kmeans method (Kaufman and Rousseeuw, 1990) is not applicable; the K-means method, like all centroid methods, requires the measure d between the clustered objects to be a distance; this means, among other conditions, that for any three objects x, y, and z the triangle inequality applies. However, this inequality does not necessarily hold for our dissimilarity measure. If the adjectives x and y were observed in the same minimal NP, their dissimilarity is quite large. If neither z and x nor z and y were found in the same minimal NP, then it is quite possible that th</context>
</contexts>
<marker>Spath, 1985</marker>
<rawString>Spath, Helmuth. (1985). Ellis Norwood Series in Computers and their Applications. Cluster Dissection and Analysis: Theory, FORTRAN Programs, Examples. Chichester, West Sussex, England: Ellis Horwood.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Swets</author>
</authors>
<date>1969</date>
<journal>Effectiveness of Information Retrieval Methods. American Documentation,</journal>
<volume>20</volume>
<pages>72--89</pages>
<contexts>
<context position="31640" citStr="Swets, 1969" startWordPosition="5098" endWordPosition="5099"> received a correctness value of 0. The pair (economic, political) on the other hand 5This is the reason that we presented the partition with 9 clusters, as this is the closest integer to the average number of clusters used by the humans. received a correctness value of 0.67, since two thirds of the judges placed the two adjectives in the same group. Once correctness and incorrectness values have been defined, we can generalize measures such as &amp;quot;the number of correct associations retrieved by the system&amp;quot; by using summation of those values instead of counting. Then the contingency table model (Swets, 1969), widely used in Information Retrieval and Psychology, is applicable. Referring to the classification of the yes-no answers in Table 2, the following measures are defined: a • Recall = a+c 100% a • Precision = a+b• 100% • Fallout = -1 100% 7— i.d In other words, recall is the percentage of correct &amp;quot;yes&amp;quot; answers that the system found among the model &amp;quot;yes&amp;quot; answers, precision is the percentage of correct &amp;quot;yes&amp;quot; answers among the total of &amp;quot;yes&amp;quot; answers that the system reported, and fallout is the percentage of incorrect &amp;quot;yes&amp;quot; answers relative to the total number of &amp;quot;no&amp;quot; answers6. Note that in our g</context>
<context position="34342" citStr="Swets, 1969" startWordPosition="5535" endWordPosition="5536">g of the two measures. The results of applying our evaluation method to the system output (Figure 3) are shown in Table 3, which also includes the scores obtained for several other sub-optimal choices of the number of clusters. We have made these observations related to the evaluation mechanism: 1. Recall is inversely related to fallout and precision. Decreasing the number of clusters generally increases the recall and fallout and simultaneously decreases precision. 2. We have found fallout to be a better measure overall than precision, since, in addition to its decision-theoretic advantages (Swets, 1969), it appears to be more consistent across evaluations of partitions with different numbers of clusters. This has also been reported by other researchers in different evaluation problems (Lewis and Tong, 1992). 3. The problem of assessing the meaning of the evaluation scores in an absolute sense is a non-trivial one. For example, there has been increasing concern that the scoring methods used for evaluating the goodness of parsers are producing values which seem extremely good (in the &gt;90% range), while in fact the parse trees produced are not so satisfactory; the blame for this inflation of th</context>
</contexts>
<marker>Swets, 1969</marker>
<rawString>Swets, J.A. (January 1969). Effectiveness of Information Retrieval Methods. American Documentation, 20, 72-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Van Rijsbergen</author>
</authors>
<date>1979</date>
<booktitle>Information Retrieval (2nd ed.).</booktitle>
<location>London: Butterwoths.</location>
<marker>Van Rijsbergen, 1979</marker>
<rawString>Van Rijsbergen, C.J. (1979). Information Retrieval (2nd ed.). London: Butterwoths.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Wayne</author>
</authors>
<date>1990</date>
<booktitle>The Duxbury Advanced Series in Statistics and Decision Sciences. Applied Nonparametric Statistics (2nd ed.).</booktitle>
<publisher>PWSKENT Publishing Company.</publisher>
<location>Boston:</location>
<contexts>
<context position="16048" citStr="Wayne, 1990" startWordPosition="2519" endWordPosition="2520">l. In general, if the distributions for the two adjectives are similar, we expect a large number of concordances, and a small number of discordances. Kendall&apos;s T is defined as Pc—Pd where pc and pd are the probabilities of observing a concordance or discordance respectively. T ranges from -1 to +1, with +1 indicating complete concordance, -1 complete discordance, and 0 no correlation between X and Y. An unbiased estimator oft is the statistic T= C—Q n\ where n is the number of paired observations in the sample and C and Q are the numbers of observed concordances and discordances respectively (Wayne, 1990). We compute T for each pair of adjectives, adjusting for possible ties in the values of each variable, so that our statistic remains an unbiased estimator of T. We determine concordances and discordances by global international coordination 16 19 market 24 33 Table 1: Example adjective-noun frequencies. sorting the pairs of observations (noun frequencies) on one of the variables (adjectives), and computing how many of the (3) pairs of paired observations agree or disagree with the expected order on the other adjective. We normalize the result to the range 0 to 1 using a simple linear transfor</context>
</contexts>
<marker>Wayne, 1990</marker>
<rawString>Wayne, D.W. (1990). The Duxbury Advanced Series in Statistics and Decision Sciences. Applied Nonparametric Statistics (2nd ed.). Boston: PWSKENT Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology.</title>
<date>1949</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Mass.:</location>
<contexts>
<context position="17613" citStr="Zipf, 1949" startWordPosition="2779" endWordPosition="2780">bserved together in the same minimal NP. The two modules produce results of a significantly different character. The adjective-noun module always outputs a similarity value for any pair of adjectives, but these values tend to be around the middle of the range of possible values; rarely will the pattern of similarity or dissimilarity be strong enough to produce a value which has a large deviation from 0.5. This compression of the range of the similarity values can be attributed to the existence of many ties and many adjective-noun pairs with low frequencies, as would be expected by Zipf s law (Zipf, 1949). However, the expected number of concordances and discordances which can be attributed to chance will be the same (a random pair can produce a concordance or discordance with probability 0.5 for each), so the effect of chance fluctuations on T is not very significant. Furthermore, the robustness of the method guarantees that it will not be significantly influenced by any outliers (this is true for all rank based methods). Therefore, although we cannot have complete confidence in a statistical estimate like T, we expect the module to produce useful estimates of similarity. On the other hand, t</context>
</contexts>
<marker>Zipf, 1949</marker>
<rawString>Zipf, G.K. (1949). Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology. Reading, Mass.: Addison-Wesley,</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>