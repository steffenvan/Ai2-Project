<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.994953">
Monolingual Distributional Similarity for Text-to-Text Generation
</title>
<author confidence="0.9979">
Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch
</author>
<affiliation confidence="0.84900425">
Center for Language and Speech Processing
Human Language Technology Center of Excellence
Johns Hopkins University
Baltimore, MD 21218, USA
</affiliation>
<sectionHeader confidence="0.95789" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999370923076923">
Previous work on paraphrase extraction and
application has relied on either parallel
datasets, or on distributional similarity met-
rics over large text corpora. Our approach
combines these two orthogonal sources of in-
formation and directly integrates them into
our paraphrasing system’s log-linear model.
We compare different distributional similar-
ity feature-sets and show significant improve-
ments in grammaticality and meaning reten-
tion on the example text-to-text generation
task of sentence compression, achieving state-
of-the-art quality.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999828212121212">
A wide variety of applications in natural language
processing can be cast in terms of text-to-text gen-
eration. Given input in the form of natural lan-
guage, a text-to-text generation system produces
natural language output that is subject to a set of
constraints. Compression systems, for instance, pro-
duce shorter sentences. Paraphrases, i.e. differ-
ing textual realizations of the same meaning, are a
crucial components of text-to-text generation sys-
tems, and have been successfully applied to tasks
such as multi-document summarization (Barzilay et
al., 1999; Barzilay, 2003), query expansion (An-
ick and Tipirneni, 1999; Riezler et al., 2007), ques-
tion answering (McKeown, 1979; Ravichandran and
Hovy, 2002), sentence compression (Cohn and La-
pata, 2008; Zhao et al., 2009), and simplification
(Wubben et al., 2012).
Paraphrase collections for text-to-text generation
have been extracted from a variety of different cor-
pora. Several approaches rely on bilingual paral-
lel data (Bannard and Callison-Burch, 2005; Zhao
et al., 2008; Callison-Burch, 2008; Ganitkevitch et
al., 2011), while others leverage distributional meth-
ods on monolingual text corpora (Lin and Pantel,
2001; Bhagat and Ravichandran, 2008). So far, how-
ever, only preliminary studies have been undertaken
to combine the information from these two sources
(Chan et al., 2011).
In this paper, we describe an extension of Gan-
itkevitch et al. (2011)’s bilingual data-based ap-
proach. We augment the bilingually-sourced para-
phrases using features based on monolingual distri-
butional similarity. More specifically:
</bodyText>
<listItem confidence="0.905495857142857">
• We show that using monolingual distributional
similarity features improves paraphrase quality
beyond what we can achieve with features esti-
mated from bilingual data.
• We define distributional similarity for para-
phrase patterns that contain constituent-level
gaps, e.g.
</listItem>
<bodyText confidence="0.919010666666667">
sim(one JJ instance of NP, a JJ case of NP).
This generalizes over distributional similarity
for contiguous phrases.
</bodyText>
<listItem confidence="0.799781111111111">
• We compare different types of monolingual
distributional information and show that they
can be used to achieve significant improve-
ments in grammaticality.
• Finally, we compare our method to several
strong baselines on the text-to-text generation
task of sentence compression. Our method
shows state-of-the-art results, beating a purely
bilingually sourced paraphrasing system.
</listItem>
<page confidence="0.975199">
256
</page>
<note confidence="0.9888755">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 256–264,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.8250375">
Figure 1: Pivot-based paraphrase extraction for con-
tiguous phrases. Two phrases translating to the same
phrase in the foreign language are assumed to be
paraphrases of one another.
</figureCaption>
<sectionHeader confidence="0.975013" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999748">
Approaches to paraphrase extraction differ based on
their underlying data source. In Section 2.1 we out-
line pivot-based paraphrase extraction from bilin-
gual data, while the contextual features used to de-
termine closeness in meaning in monolingual ap-
proaches is described in Section 2.2.
</bodyText>
<subsectionHeader confidence="0.988614">
2.1 Paraphrase Extraction via Pivoting
</subsectionHeader>
<bodyText confidence="0.9983824">
Following Ganitkevitch et al. (2011), we formulate
our paraphrases as a syntactically annotated syn-
chronous context-free grammar (SCFG) (Aho and
Ullman, 1972; Chiang, 2005). An SCFG rule has
the form:
</bodyText>
<equation confidence="0.978284">
r = C —* (f, e, —, ~ϕ),
</equation>
<bodyText confidence="0.998935538461538">
where the left-hand side of the rule, C, is a nonter-
minal and the right-hand sides f and e are strings
of terminal and nonterminal symbols. There is a
one-to-one correspondency between the nontermi-
nals in f and e: each nonterminal symbol in f has
to also appear in e. The function — captures this bi-
jective mapping between the nonterminals. Drawing
on machine translation terminology, we refer to f as
the source and e as the target side of the rule.
Each rule is annotated with a feature vector of fea-
ture functions ϕ~ = {ϕ1...ϕN} that, using a corre-
sponding weight vector ~λ, are combined in a log-
linear model to compute the cost of applying r:
</bodyText>
<figureCaption confidence="0.787026">
Figure 2: Extraction of syntactic paraphrases via the
pivoting approach: We aggregate over different sur-
face realizations, matching the lexicalized portions
of the rule and generalizing over the nonterminals.
</figureCaption>
<bodyText confidence="0.999941666666667">
To extract paraphrases we follow the intuition that
two English strings e1 and e2 that translate to the
same foreign string f can be assumed to have the
same meaning, as illustrated in Figure 1.1
First, we use standard machine translation meth-
ods to extract a foreign-to-English translation gram-
mar from a bilingual parallel corpus (Koehn, 2010).
Then, for each pair of translation rules where the
left-hand side C and foreign string f match:
</bodyText>
<equation confidence="0.9988345">
r1 = C —* (f, e1, —1, ~ϕ1)
r2 = C —* (f, e2, —2, ~ϕ2),
we pivot over f to create a paraphrase rule rp:
rp = C —* (e1, e2, —p, ~ϕp),
</equation>
<bodyText confidence="0.9874922">
with a combined nonterminal correspondency func-
tion —p. Note that the common source side f im-
plies that e1 and e2 share the same set of nonterminal
symbols.
The paraphrase feature vector ~ϕp is computed
from the translation feature vectors ~ϕ1 and ~ϕ2 by
following the pivoting idea. For instance, we esti-
mate the conditional paraphrase probability p(e2|e1)
by marginalizing over all shared foreign-language
translations f:
</bodyText>
<equation confidence="0.6845745">
Ep(e2|e1) = p(e2, f|e1) (2)
f
</equation>
<figure confidence="0.985392729166667">
...
...
their
would
in the long term
plans
...
PlŠne
... ihre
wŸrden
langfristigen
...
aufzugeben
...
seine
ohne
giving up his
langfristigen
long-term
...
PlŠne
plans
...
without
...
. . .
NP
NN &apos;s NP
in the long term
EU
&apos;s
intentions
in the long term
IBM goals
&apos;s
in the long term
langfristigen PlŠne
der EU
..
IBM &apos;s
lŠngerfristige Ziele
the long-term plans
of Europe
the long-term ambitions of
IBM
the long-term
NP of NN
NP
</figure>
<equation confidence="0.8026355">
cost(r) = � N λi log ϕi. (1) E= p(e2|f, e1)p(f|e1) (3)
i=1 f
</equation>
<bodyText confidence="0.994025">
A wide variety of feature functions can be formu-
lated. We detail the feature-set used in our experi-
ments in Section 4.
</bodyText>
<equation confidence="0.675116">
p(e2|f)p(f|e1). (4)
1See Yao et al. (2012) for an analysis of this assumption.
E�
f
</equation>
<page confidence="0.982317">
257
</page>
<figureCaption confidence="0.92929225">
Figure 3: An example of a synchronous paraphras-
tic derivation, here a sentence compression. Shaded
words are deleted in the indicated rule applications.
Figure 2 illustrates syntax-constrained pivoting and
</figureCaption>
<bodyText confidence="0.959914615384615">
feature aggregation over multiple foreign language
translations for a paraphrase pattern.
After the SCFG has been extracted, it can be used
within standard machine translation machinery, such
as the Joshua decoder (Ganitkevitch et al., 2012).
Figure 3 shows an example for a synchronous para-
phrastic derivation produced as a result of applying
our paraphrase grammar in the decoding process.
The approach outlined relies on aligned bilingual
texts to identify phrases and patterns that are equiva-
lent in meaning. When extracting paraphrases from
monolingual text, we have to rely on an entirely dif-
ferent set of semantic cues and features.
</bodyText>
<subsectionHeader confidence="0.998532">
2.2 Monolingual Distributional Similarity
</subsectionHeader>
<bodyText confidence="0.999913166666667">
Methods based on monolingual text corpora mea-
sure the similarity of phrases based on contextual
features. To describe a phrase e, we define a set of
features that capture the context of an occurrence of
e in our corpus. Writing the context vector for the
i-th occurrence of e as c�e,i, we can aggregate over
all occurrences of e, resulting in a distributional sig-
nature for e, c�e = Ei c�e,i. Following the intuition
that phrases with similar meanings occur in similar
contexts, we can then quantify the goodness of e&apos; as
a paraphrase of e by computing the cosine similarity
between their distributional signatures:
</bodyText>
<equation confidence="0.477348">
sim(e, e&apos;) =
</equation>
<bodyText confidence="0.999848545454545">
A wide variety of features have been used to de-
scribe the distributional context of a phrase. Rich,
linguistically informed feature-sets that rely on de-
pendency and constituency parses, part-of-speech
tags, or lemmatization have been proposed in widely
known work such as by Church and Hanks (1991)
and Lin and Pantel (2001). For instance, a phrase
is described by the various syntactic relations it has
with lexical items in its context, such as: “for what
verbs do we see with the phrase as the subject?”, or
“what adjectives modify the phrase?”.
However, when moving to vast text collections or
collapsed representations of large text corpora, lin-
guistic annotations can become impractically expen-
sive to produce. A straightforward and widely used
solution is to fall back onto lexical n-gram features,
e.g. “what words or bigrams have we seen to the left
of this phrase?” A substantial body of work has fo-
cussed on using this type of feature-set for a variety
of purposes in NLP (Lapata and Keller, 2005; Bha-
gat and Ravichandran, 2008; Lin et al., 2010; Van
Durme and Lall, 2010).
</bodyText>
<subsectionHeader confidence="0.997961">
2.3 Other Related Work
</subsectionHeader>
<bodyText confidence="0.99991875">
Recently, Chan et al. (2011) presented an initial in-
vestigation into combining phrasal paraphrases ob-
tained through bilingual pivoting with monolingual
distributional information. Their work investigated
a reranking approach and evaluated their method via
a substitution task, showing that the two sources of
information are complementary and can yield im-
provements in paraphrase quality when combined.
</bodyText>
<sectionHeader confidence="0.99142" genericHeader="method">
3 Incorporating Distributional Similarity
</sectionHeader>
<bodyText confidence="0.9999338">
In order to incorporate distributional similarity in-
formation into the paraphrasing system, we need
to calculate similarity scores for the paraphrastic
SCFG rules in our grammar. For rules with purely
lexical right-hand sides e1 and e2 this is a simple
task, and the similarity score sim(e1, e2) can be di-
rectly included in the rule’s feature vector cp. How-
ever, if e1 and e2 are long, their occurrences become
sparse and their similarity can no longer be reliably
estimated. In our case, the right-hand sides of our
rules often contain gaps and computing a similarity
score is less straightforward.
Figure 4 shows an example of such a discontin-
uous rule and illustrates our solution: we decom-
pose the discontinuous patterns that make up the
</bodyText>
<figure confidence="0.947332052631579">
twelve cartoons insulting the prophet mohammad
the prophet mohammad
cartoons that are offensive to
CD NNS JJ DT NNP
NP
DT+NNP
NP
VP
NP
12
of the
CD NNS JJ DT NNP
NP
NP
VP
DT+NNP
NP
c�e · c�e1
|c�e||c�e1|&apos;
</figure>
<page confidence="0.774189">
258
</page>
<bodyText confidence="0.945549842105263">
Figure 4: Scoring a rule by extracting and scoring
contiguous phrases consistent with the alignment.
The overall score of the rule is determined by av-
eraging across all pairs of contiguous subphrases.
right-hand sides of a rule r into pairs of contiguous
phrases P(r) = {(e, e&apos;)}, for which we can look
up distributional signatures and compute similarity
scores. This decomposition into phrases is non-
trivial, since our sentential paraphrase rules often
involve significant reordering or structural changes.
To avoid comparing unrelated phrase pairs, we re-
quire P(r) to be consistent with a token alignment
a. The alignment is defined analogously to word
alignments in machine translation, and computed by
treating the source and target sides of our paraphrase
rules as a parallel corpus.
We define the overall similarity score of the rule
to be the average of the similarity scores of all ex-
tracted phrase pairs:
</bodyText>
<equation confidence="0.8123715">
sim (r, a) = |P1 (a)  |sim (e, e&apos;).
(e,e )EP(a)
</equation>
<bodyText confidence="0.999964863636364">
Since the distributional signatures for long, rare
phrases may be computed from only a handful of
occurrences, we additionally query for the shorter
sub-phrases that are more likely to have been ob-
served often enough to have reliable signatures and
thus similarity estimates.
Our definition of the similarity of two discon-
tinuous phrases substantially differs from others in
the literature. This difference is due to a differ-
ence in motivation. Lin and Pantel (2001), for in-
stance, seek to find new paraphrase pairs by compar-
ing their arguments. In this work, however, we try
to add orthogonal information to existing paraphrase
pairs. Both our definition of pattern similarity and
our feature-set (see Section 4.3) are therefore geared
towards comparing the substitutability and context
similarity of a pair of paraphrases.
Our two similarity scores are incorporated into
the paraphraser as additional rule features in cp,
simngram and simsyn, respectively. We estimate the
corresponding weights along with the other AZ as de-
tailed in Section 4.
</bodyText>
<sectionHeader confidence="0.99984" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.998143">
4.1 Task: Sentence Compression
</subsectionHeader>
<bodyText confidence="0.99997475">
To evaluate our method on a real text-to-text appli-
cation, we use the sentence compression task. To
tune the parameters of our paraphrase system for
sentence compression, we need an appropriate cor-
pus of reference compressions. Since our model is
designed to compress by paraphrasing rather than
deletion, the commonly used deletion-based com-
pression data sets like the Ziff-Davis corpus are not
suitable. We thus use the dataset introduced in our
previous work (Ganitkevitch et al., 2011).
Beginning with 9570 tuples of parallel English–
English sentences obtained from multiple reference
translations for machine translation evaluation, we
construct a parallel compression corpus by select-
ing the longest reference in each tuple as the source
sentence and the shortest reference as the target sen-
tence. We further retain only those sentence pairs
where the compression ratio cr falls in the range
0.5 &lt; cr &lt; 0.8. From these, we select 936 sen-
tences for the development set, as well as 560 sen-
tences for a test set that we use to gauge the perfor-
mance of our system.
We contrast our distributional similarity-informed
paraphrase system with a pivoting-only baseline, as
well as an implementation of Clarke and Lapata
(2008)’s state-of-the-art compression model which
uses a series of constraints in an integer linear pro-
gramming (ILP) solver.
</bodyText>
<subsectionHeader confidence="0.938827">
4.2 Baseline Paraphrase Grammar
</subsectionHeader>
<bodyText confidence="0.999721">
We extract our paraphrase grammar from the
French–English portion of the Europarl corpus (ver-
sion 5) (Koehn, 2005). The Berkeley aligner (Liang
et al., 2006) and the Berkeley parser (Petrov and
Klein, 2007) are used to align the bitext and parse
the English side, respectively. The paraphrase gram-
mar is produced using the Hadoop-based Thrax
</bodyText>
<figure confidence="0.990293295081967">
⌘ sim ⇣of⌘
the long-term
in the long term
sim(r) = 1 sim ⇣
NN
long
term
NP
NN
the
&apos;s NP in the
long-term
NP of
259
holding on to
VP
the
PP
long-term investment
det
amod
NP
dep-det-R-investment
lex-R-investment
pos-L-IN-TO
pos-L-TO
lex-L-on-to
pos-R-NN
lex-L-to
dep-amod-R-investment
syn-gov-NP syn-miss-L-NN
dep-det-R-NN dep-amod-R-NN
⇣
VBG
IN TO DT
JJ NN
st s t ⇣the long-term⌘ _
Left Right
25
achieve
64
43
confirmed
revise
the long-term
investment 10
L-achieve = 25
R-plans = 97
si g,. ⇣the long-term⌘ _
L-revise = 43
⇣
R-goals = 23
R-investment = 10
L-confirmed = 64
the long-term
the long-term
goals 23
the long-term
plans 97
the long-term
the long-term
</figure>
<figureCaption confidence="0.997516">
Figure 5: An example of the n-gram feature extrac-
</figureCaption>
<bodyText confidence="0.927789357142857">
tion on an n-gram corpus. Here, “the long-term” is
seen preceded by “revise” (43 times) and followed
by “plans” (97 times). The corresponding left- and
right-side features are added to the phrase signature
with the counts of the n-grams that gave rise to them.
grammar extractor’s paraphrase mode (Ganitkevitch
et al., 2012). The syntactic nonterminal labels we
allowed in the grammar were limited to constituent
labels and CCG-style slashed categories. Paraphrase
grammars extracted via pivoting tend to grow very
large. To keep the grammar size manageable, we
pruned away all paraphrase rules whose phrasal
paraphrase probabilities p(e1|e2) or p(e2|e1) were
smaller than 0.001.
We extend the feature-set used in Ganitkevitch et
al. (2011) with a number of features that aim to bet-
ter describe a rule’s compressive power: on top of
the word count features wcountsrc and wcounttgt
and the word count difference feature wcountdiff ,
we add character based count and difference features
ccountsrc, ccounttgt, and ccountdiff , as well as log-
compression ratio features wordcr = log wcounttgt
wcountsrc
and the analogously defined charcr = log ccounttgt
ccountsrc .
For model tuning and decoding we used the
Joshua machine translation system (Ganitkevitch et
al., 2012). The model weights are estimated using an
implementation of the PRO tuning algorithm (Hop-
kins and May, 2011), with PR´ECIS as our objective
function (Ganitkevitch et al., 2011). The language
model used in our paraphraser and the Clarke and
Lapata (2008) baseline system is a Kneser-Ney dis-
counted 5-gram model estimated on the Gigaword
corpus using the SRILM toolkit (Stolcke, 2002).
Figure 6: An example of the syntactic feature-
set. The phrase “the long-term” is annotated with
position-aware lexical and part-of-speech n-gram
features (e.g. “on to” on the left, and “investment”
and “NN” to its right), labeled dependency links
(e.g. amod − investment) and features derived
from the phrase’s CCG label NP/NN.
</bodyText>
<subsectionHeader confidence="0.995529">
4.3 Distributional Similarity Model
</subsectionHeader>
<bodyText confidence="0.999893166666667">
To investigate the impact of the feature-set used to
construct distributional signatures, we contrast two
approaches: a high-coverage collection of distribu-
tional signatures with a relatively simple feature-set,
and a much smaller set of signatures with a rich, syn-
tactically informed feature-set.
</bodyText>
<sectionHeader confidence="0.660236" genericHeader="method">
4.3.1 n-gram Model
</sectionHeader>
<bodyText confidence="0.999953333333333">
The high-coverage model (from here on: n-gram
model) is drawn from a web-scale n-gram corpus
(Brants and Franz, 2006; Lin et al., 2010). We ex-
tract signatures for phrases up to a length of 4. For
each phrase p we look at n-grams of the form wp
and pv, where w and v are single words. We then
extract the corresponding features wleft and vright.
The feature count is set to the count of the n-gram,
reflecting the frequency with which p was preceded
or followed, respectively, by w and v in the data the
n-gram corpus is based on. Figure 5 illustrates this
feature extraction approach. The resulting collection
comprises distributional signatures for the 200 mil-
lion most frequent 1-to-4-grams in the n-gram cor-
pus.
</bodyText>
<page confidence="0.990102">
260
</page>
<sectionHeader confidence="0.487604" genericHeader="method">
4.3.2 Syntactic Model
</sectionHeader>
<bodyText confidence="0.999986">
For the syntactically informed signature model
(from here on: syntax model), we use the
constituency and dependency parses provided in
the Annotated Gigaword corpus (Napoles et al.,
2012). We limit ourselves to the Los Angeles
Times/Washington Post portion of the corpus and
extract phrases up to a length of 4. The following
feature set is used to compute distributional signa-
tures for the extracted phrases:
</bodyText>
<listItem confidence="0.9826409">
• Position-aware lexical and part-of-speech uni-
gram and bigram features, drawn from a three-
word window to the right and left of the phrase.
• Features based on dependencies for both links
into and out of the phrase, labeled with the cor-
responding lexical item and POS. If the phrase
corresponds to a complete subtree in the con-
stituency parse we additionally include lexical
and POS features for its head word.
• Syntactic features for any constituents govern-
</listItem>
<bodyText confidence="0.853371625">
ing the phrase, as well as for CCG-style slashed
constituent labels for the phrase. The latter are
split in governing constituent and missing con-
stituent (with directionality).
Figure 6 illustrates the syntax model’s feature ex-
traction for an example phrase occurrence. Using
this method we extract distributional signatures for
over 12 million 1-to-4-gram phrases.
</bodyText>
<subsectionHeader confidence="0.942518">
4.3.3 Locality Sensitive Hashing
</subsectionHeader>
<bodyText confidence="0.999978111111111">
Collecting distributional signatures for a large
number of phrases quickly leads to unmanageably
large datasets. Storing the syntax model’s 12 mil-
lion signatures in a compressed readable format,
for instance, requires over 20GB of disk space.
Like Ravichandran et al. (2005) and Bhagat and
Ravichandran (2008), we rely on locality sensitive
hashing (LSH) to make the use of these large collec-
tions practical.
In order to avoid explicitly computing the fea-
ture vectors, which can be memory intensive for fre-
quent phrases, we chose the online LSH variant de-
scribed by Van Durme and Lall (2010), as imple-
mented in the Jerboa toolkit (Van Durme, 2012).
This method, based on the earlier work of Indyk and
Motwani (1998) and Charikar (2002), approximates
the cosine similarity between two feature vectors
based on the Hamming distance in a dimensionality-
reduced bitwise representation. Two feature vec-
tors u, v each of dimension d are first projected
through a dxb random matrix populated with draws
from N(0,1). We then convert the resulting b-
dimensional vectors into bit-vectors by setting each
bit of the signature conditioned on whether the cor-
responding projected value is less than 0. Now,
given the bit signatures h(u) and h(v), we can ap-
proximate the cosine similarity of u and v as:
</bodyText>
<equation confidence="0.9866695">
(D(h(u), h(v)) l
sim (u, v) = cos l b �J ,
</equation>
<bodyText confidence="0.9998235">
where d(·, ·) is the Hamming distance. In our ex-
periments we use 256-bit signatures. This reduces
the memory requirements for the syntax model to
around 600MB.
</bodyText>
<sectionHeader confidence="0.974402" genericHeader="evaluation">
5 Evaluation Results
</sectionHeader>
<bodyText confidence="0.999823461538462">
To rate the quality of our output, we solicit human
judgments of the compressions along two five-point
scales: grammaticality and meaning preservation.
Judges are instructed to decide how much the mean-
ing from a reference translation is retained in the
compressed sentence, with a score of 5 indicating
that all of the important information is present, and
1 being that the compression does not retain any of
the original meaning. Similarly, a grammar score
of 5 indicates perfect grammaticality, while a score
of 1 is assigned to sentences that are entirely un-
grammatical. We ran our evaluation on Mechani-
cal Turk, where a total of 126 judges provided 3 re-
dundant judgments for each system output. To pro-
vide additional quality control, our HITs were aug-
mented with both positive and negative control com-
pressions. For the positive control we used the refer-
ence compressions from our test set. Negative con-
trol was provided by adding a compression model
based on random word deletions to the mix.
In Table 1 we compare our distributional
similarity-augmented systems to the plain pivoting-
based baseline and the ILP approach. The compres-
sion ratios of the paraphrasing systems are tuned to
match the average compression ratio seen on the de-
velopment and test set. The ILP system is config-
</bodyText>
<page confidence="0.993406">
261
</page>
<bodyText confidence="0.999988162162162">
ured to loosely match this ratio, as to not overly con-
strain its search space. Our results indicate that the
paraphrase approach significantly outperforms ILP
on meaning retention. However, the baseline sys-
tem shows notable weaknesses in grammaticality.
Adding the n-gram distributional similarity model
to the paraphraser recovers some of the difference in
grammaticality while simultaneously yielding some
gain in the compressions’ meaning retention. Mov-
ing to distributional similarity estimated on the syn-
tactic feature-set yields additional improvement, de-
spite the model’s lower coverage.
It is known that human evaluation scores correlate
linearly with the compression ratio produced by a
sentence compression system (Napoles et al., 2011).
Thus, to ensure fairness in our comparisons, we pro-
duce a pairwise comparison breakdown that only
takes into account compressions of almost identical
length.2 Figure 7 shows the results of this analysis,
detailing the number of wins and ties in the human
judgements.
We note that the gains in meaning retention over
both the baseline and the ILP system are still present
in the pairwise breakdown. The gains over the
paraphrasing baseline, as well as the improvement
in meaning over ILP are statistically significant at
p &lt; 0.05 (using the sign test).
We can observe that there is substantial overlap
between the baseline paraphraser and the n-gram
model, while the syntax model appears to yield no-
ticeably different output far more often.
Table 2 shows two example sentences drawn from
our test set and the compressions produced by the
different systems. It can be seen that both the
paraphrase-based and ILP systems produce good
quality results, with the paraphrase system retaining
the meaning of the source sentence more accurately.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999930333333333">
We presented a method to incorporate monolingual
distributional similarity into linguistically informed
paraphrases extracted from bilingual parallel data.
Having extended the notion of similarity to dis-
contiguous pattern with multi-word gaps, we inves-
tigated the effect of using feature-sets of varying
</bodyText>
<footnote confidence="0.9413265">
2We require the compressions to be within ±10% length of
one another.
</footnote>
<figureCaption confidence="0.989791">
Figure 7: A pairwise breakdown of the human judg-
</figureCaption>
<bodyText confidence="0.8636885">
ments comparing the systems. Dark grey regions
show the number of times the two systems were tied,
and light grey shows how many times one system
was judged to be better than the other.
</bodyText>
<table confidence="0.996199142857143">
CR Meaning Grammar
Reference 0.80 4.80 4.54
ILP 0.74 3.44 3.41
PP 0.78 3.53 2.98
PP + n-gram 0.80 3.65 3.16
PP + syntax 0.79 3.70 3.26
Random Deletions 0.78 2.91 2.53
</table>
<tableCaption confidence="0.965456">
Table 1: Results of the human evaluation on longer
compressions: pairwise compression rates (CR),
meaning and grammaticality scores. Bold indicates
a statistically significance difference at p &lt; 0.05.
</tableCaption>
<bodyText confidence="0.998941125">
complexity to compute distributional similarity for
our paraphrase collection. We conclude that, com-
pared to a simple large-scale model, a rich, syntax-
based feature-set, even with significantly lower cov-
erage, noticeably improves output quality in a text-
to-text generation task. Our syntactic method sig-
nificantly improves grammaticality and meaning re-
tention over a strong paraphrastic baseline, and of-
fers substantial gains in meaning retention over a
deletion-based state-of-the-art system.
Acknowledgements This research was supported
in part by the NSF under grant IIS-0713448 and
in part by the EuroMatrixPlus project funded by
the European Commission (7th Framework Pro-
gramme). Opinions, interpretations, and conclu-
sions are the authors’ alone.
</bodyText>
<figure confidence="0.997545533333334">
Syntax :: ILP Syntax :: n−gram n−gram :: PP
Score 300
250
200
150
100
50
0
300
250
200
150
100
50
0
</figure>
<page confidence="0.981009">
262
</page>
<table confidence="0.990474538461538">
Source should these political developments have an impact on sports ?
Reference should these political events affect sports ?
Syntax should these events have an impact on sports ?
n-gram these political developments impact on sports ?
PP should these events impact on sports ?
ILP political developments have an impact
Source now we have to think and make a decision about our direction and choose only one way.
thanks.
Reference we should ponder it and decide our path and follow it , thanks .
Syntax now we think and decide on our way and choose one way. thanks.
n-gram now we have and decide on our way and choose one way. thanks.
PP now we have and decide on our way and choose one way. thanks.
ILP we have to think and make a decision and choose way thanks
</table>
<tableCaption confidence="0.994317">
Table 2: Example compressions produced by our systems and the baselines Table 1 for three input sentences
from our test data.
</tableCaption>
<sectionHeader confidence="0.992186" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9982275">
Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling. Prentice Hall.
Peter G. Anick and Suresh Tipirneni. 1999. The para-
phrase search assistant: terminological feedback for
iterative information seeking. In Proceedings of SI-
GIR.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL.
Regina Barzilay, Kathleen R. McKeown, and Michael
Elhadad. 1999. Information fusion in the context
of multi-document summarization. In Proceedings of
ACL.
Regina Barzilay. 2003. Information Fusion for Mutli-
document Summarization: Paraphrasing and Genera-
tion. Ph.D. thesis, Columbia University, New York.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of ACL/HLT.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
version 1.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. In Pro-
ceedings of EMNLP.
Tsz Ping Chan, Chris Callison-Burch, and Benjamin Van
Durme. 2011. Reranking bilingually extracted para-
phrases using monolingual distributional similarity. In
EMNLP Workshop on GEMS.
Moses Charikar. 2002. Similarity estimation techniques
from rounding algorithms. In Proceedings of STOC.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL.
Kenneth Church and Patrick Hanks. 1991. Word asso-
ciation norms, mutual information and lexicography.
Computational Linguistics, 6(1):22–29.
James Clarke and Mirella Lapata. 2008. Global infer-
ence for sentence compression: An integer linear pro-
gramming approach. Journal of Artificial Intelligence
Research, 31:273–381.
Trevor Cohn and Mirella Lapata. 2008. Sentence com-
pression beyond word deletion. In Proceedings of the
COLING.
Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel corpora
for text-to-text generation. In Proceedings of EMNLP.
Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post,
</reference>
<page confidence="0.981953">
263
</page>
<reference confidence="0.999881746478874">
and Chris Callison-Burch. 2012. Joshua 4.0: Packing,
PRO, and paraphrases. In Proceedings of WMT12.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of EMNLP.
Piotr Indyk and Rajeev Motwani. 1998. Approximate
nearest neighbors: towards removing the curse of di-
mensionality. In Proceedings of STOC.
Philipp Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In MT summit, volume 5.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Mirella Lapata and Frank Keller. 2005. Web-based mod-
els for natural language processing. ACM Transac-
tions on Speech and Language Processing, 2(1).
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of HLT/NAACL.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules from text. Natural Language Engineering.
Dekang Lin, Kenneth Church, Heng Ji, Satoshi Sekine,
David Yarowsky, Shane Bergsma, Kailash Patil, Emily
Pitler, Rachel Lathbury, Vikram Rao, Kapil Dalwani,
and Sushant Narsale. 2010. New tools for web-scale
n-grams. In Proceedings of LREC.
Kathleen R. McKeown. 1979. Paraphrasing using given
and new information in a question-answer system. In
Proceedings of ACL.
Courtney Napoles, Chris Callison-Burch, Juri Ganitke-
vitch, and Benjamin Van Durme. 2011. Paraphrastic
sentence compression with a character-based metric:
Tightening without deletion. Workshop on Monolin-
gual Text-To-Text Generation.
Courtney Napoles, Matt Gormley, and Benjamin Van
Durme. 2012. Annotated gigaword. In Proceedings
of AKBC-WEKEX 2012.
Slav Petrov and Dan Klein. 2007. Improved infer-
ence for unlexicalized parsing. In Proceedings of
HLT/NAACL.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
sufrace text patterns for a question answering system.
In Proceedings of ACL.
Deepak Ravichandran, Patrick Pantel, and Eduard Hovy.
2005. Randomized Algorithms and NLP: Using Lo-
cality Sensitive Hash Functions for High Speed Noun
Clustering. In Proceedings of ACL.
Stefan Riezler, Alexander Vasserman, Ioannis Tsochan-
taridis, Vibhu Mittal, and Yi Liu. 2007. Statistical
machine translation for query expansion in answer re-
trieval. In Proceedings of ACL.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceeding of the International
Conference on Spoken Language Processing.
Benjamin Van Durme and Ashwin Lall. 2010. Online
generation of locality sensitive hash signatures. In
Proceedings of ACL, Short Papers.
Benjamin Van Durme. 2012. Jerboa: A toolkit for
randomized and streaming algorithms. Technical Re-
port 7, Human Language Technology Center of Excel-
lence, Johns Hopkins University.
Sander Wubben, Antal van den Bosch, and Emiel Krah-
mer. 2012. Sentence simplification by monolingual
machine translation. In Proceedings of ACL.
Xuchen Yao, Benjamin Van Durme, and Chris Callison-
Burch. 2012. Expectations of word sense in parallel
corpora. In Proceedings of HLT/NAACL.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008. Pivot approach for extracting paraphrase pat-
terns from bilingual corpora. In Proceedings of
ACL/HLT.
Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009.
Application-driven statistical paraphrase generation.
In Proceedings of ACL.
</reference>
<page confidence="0.998215">
264
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.679825">
<title confidence="0.997903">Monolingual Distributional Similarity for Text-to-Text Generation</title>
<author confidence="0.998131">Benjamin Van_Durme Ganitkevitch</author>
<affiliation confidence="0.902814333333333">Center for Language and Speech Human Language Technology Center of Johns Hopkins</affiliation>
<address confidence="0.999396">Baltimore, MD 21218, USA</address>
<abstract confidence="0.995908857142857">Previous work on paraphrase extraction and application has relied on either parallel datasets, or on distributional similarity metrics over large text corpora. Our approach combines these two orthogonal sources of information and directly integrates them into our paraphrasing system’s log-linear model. We compare different distributional similarity feature-sets and show significant improvements in grammaticality and meaning retention on the example text-to-text generation task of sentence compression, achieving stateof-the-art quality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling.</booktitle>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="4028" citStr="Aho and Ullman, 1972" startWordPosition="572" endWordPosition="575">s phrases. Two phrases translating to the same phrase in the foreign language are assumed to be paraphrases of one another. 2 Background Approaches to paraphrase extraction differ based on their underlying data source. In Section 2.1 we outline pivot-based paraphrase extraction from bilingual data, while the contextual features used to determine closeness in meaning in monolingual approaches is described in Section 2.2. 2.1 Paraphrase Extraction via Pivoting Following Ganitkevitch et al. (2011), we formulate our paraphrases as a syntactically annotated synchronous context-free grammar (SCFG) (Aho and Ullman, 1972; Chiang, 2005). An SCFG rule has the form: r = C —* (f, e, —, ~ϕ), where the left-hand side of the rule, C, is a nonterminal and the right-hand sides f and e are strings of terminal and nonterminal symbols. There is a one-to-one correspondency between the nonterminals in f and e: each nonterminal symbol in f has to also appear in e. The function — captures this bijective mapping between the nonterminals. Drawing on machine translation terminology, we refer to f as the source and e as the target side of the rule. Each rule is annotated with a feature vector of feature functions ϕ~ = {ϕ1...ϕN} </context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter G Anick</author>
<author>Suresh Tipirneni</author>
</authors>
<title>The paraphrase search assistant: terminological feedback for iterative information seeking.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<contexts>
<context position="1455" citStr="Anick and Tipirneni, 1999" startWordPosition="199" endWordPosition="203">tion A wide variety of applications in natural language processing can be cast in terms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, howe</context>
</contexts>
<marker>Anick, Tipirneni, 1999</marker>
<rawString>Peter G. Anick and Suresh Tipirneni. 1999. The paraphrase search assistant: terminological feedback for iterative information seeking. In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1844" citStr="Bannard and Callison-Burch, 2005" startWordPosition="257" endWordPosition="260">the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an extension of Ganitkevitch et al. (2011)’s bilingual data-based approach. We augment the bilingually-sourced paraphrases using features based on monolingual distributional similarity. More specifically: • We show that using monolingual di</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
<author>Michael Elhadad</author>
</authors>
<title>Information fusion in the context of multi-document summarization.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1394" citStr="Barzilay et al., 1999" startWordPosition="191" endWordPosition="194">ompression, achieving stateof-the-art quality. 1 Introduction A wide variety of applications in natural language processing can be cast in terms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin a</context>
</contexts>
<marker>Barzilay, McKeown, Elhadad, 1999</marker>
<rawString>Regina Barzilay, Kathleen R. McKeown, and Michael Elhadad. 1999. Information fusion in the context of multi-document summarization. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
</authors>
<title>Information Fusion for Mutlidocument Summarization: Paraphrasing and Generation.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University,</institution>
<location>New York.</location>
<contexts>
<context position="1411" citStr="Barzilay, 2003" startWordPosition="195" endWordPosition="196">tateof-the-art quality. 1 Introduction A wide variety of applications in natural language processing can be cast in terms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; </context>
</contexts>
<marker>Barzilay, 2003</marker>
<rawString>Regina Barzilay. 2003. Information Fusion for Mutlidocument Summarization: Paraphrasing and Generation. Ph.D. thesis, Columbia University, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL/HLT.</booktitle>
<contexts>
<context position="2041" citStr="Bhagat and Ravichandran, 2008" startWordPosition="285" endWordPosition="288">, query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an extension of Ganitkevitch et al. (2011)’s bilingual data-based approach. We augment the bilingually-sourced paraphrases using features based on monolingual distributional similarity. More specifically: • We show that using monolingual distributional similarity features improves paraphrase quality beyond what we can achieve with features estimated from bilingual data. • We define distributional similarity for paraphrase patterns th</context>
<context position="9231" citStr="Bhagat and Ravichandran, 2008" startWordPosition="1461" endWordPosition="1465">lexical items in its context, such as: “for what verbs do we see with the phrase as the subject?”, or “what adjectives modify the phrase?”. However, when moving to vast text collections or collapsed representations of large text corpora, linguistic annotations can become impractically expensive to produce. A straightforward and widely used solution is to fall back onto lexical n-gram features, e.g. “what words or bigrams have we seen to the left of this phrase?” A substantial body of work has focussed on using this type of feature-set for a variety of purposes in NLP (Lapata and Keller, 2005; Bhagat and Ravichandran, 2008; Lin et al., 2010; Van Durme and Lall, 2010). 2.3 Other Related Work Recently, Chan et al. (2011) presented an initial investigation into combining phrasal paraphrases obtained through bilingual pivoting with monolingual distributional information. Their work investigated a reranking approach and evaluated their method via a substitution task, showing that the two sources of information are complementary and can yield improvements in paraphrase quality when combined. 3 Incorporating Distributional Similarity In order to incorporate distributional similarity information into the paraphrasing s</context>
<context position="19830" citStr="Bhagat and Ravichandran (2008)" startWordPosition="3161" endWordPosition="3164">rase. The latter are split in governing constituent and missing constituent (with directionality). Figure 6 illustrates the syntax model’s feature extraction for an example phrase occurrence. Using this method we extract distributional signatures for over 12 million 1-to-4-gram phrases. 4.3.3 Locality Sensitive Hashing Collecting distributional signatures for a large number of phrases quickly leads to unmanageably large datasets. Storing the syntax model’s 12 million signatures in a compressed readable format, for instance, requires over 20GB of disk space. Like Ravichandran et al. (2005) and Bhagat and Ravichandran (2008), we rely on locality sensitive hashing (LSH) to make the use of these large collections practical. In order to avoid explicitly computing the feature vectors, which can be memory intensive for frequent phrases, we chose the online LSH variant described by Van Durme and Lall (2010), as implemented in the Jerboa toolkit (Van Durme, 2012). This method, based on the earlier work of Indyk and Motwani (1998) and Charikar (2002), approximates the cosine similarity between two feature vectors based on the Hamming distance in a dimensionalityreduced bitwise representation. Two feature vectors u, v eac</context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of ACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram version 1.</title>
<date>2006</date>
<contexts>
<context position="17628" citStr="Brants and Franz, 2006" startWordPosition="2803" endWordPosition="2806">left, and “investment” and “NN” to its right), labeled dependency links (e.g. amod − investment) and features derived from the phrase’s CCG label NP/NN. 4.3 Distributional Similarity Model To investigate the impact of the feature-set used to construct distributional signatures, we contrast two approaches: a high-coverage collection of distributional signatures with a relatively simple feature-set, and a much smaller set of signatures with a rich, syntactically informed feature-set. 4.3.1 n-gram Model The high-coverage model (from here on: n-gram model) is drawn from a web-scale n-gram corpus (Brants and Franz, 2006; Lin et al., 2010). We extract signatures for phrases up to a length of 4. For each phrase p we look at n-grams of the form wp and pv, where w and v are single words. We then extract the corresponding features wleft and vright. The feature count is set to the count of the n-gram, reflecting the frequency with which p was preceded or followed, respectively, by w and v in the data the n-gram corpus is based on. Figure 5 illustrates this feature extraction approach. The resulting collection comprises distributional signatures for the 200 million most frequent 1-to-4-grams in the n-gram corpus. 2</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram version 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1885" citStr="Callison-Burch, 2008" startWordPosition="265" endWordPosition="266">-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an extension of Ganitkevitch et al. (2011)’s bilingual data-based approach. We augment the bilingually-sourced paraphrases using features based on monolingual distributional similarity. More specifically: • We show that using monolingual distributional similarity features improves</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsz Ping Chan</author>
<author>Chris Callison-Burch</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Reranking bilingually extracted paraphrases using monolingual distributional similarity.</title>
<date>2011</date>
<booktitle>In EMNLP Workshop on GEMS.</booktitle>
<marker>Chan, Callison-Burch, Van Durme, 2011</marker>
<rawString>Tsz Ping Chan, Chris Callison-Burch, and Benjamin Van Durme. 2011. Reranking bilingually extracted paraphrases using monolingual distributional similarity. In EMNLP Workshop on GEMS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moses Charikar</author>
</authors>
<title>Similarity estimation techniques from rounding algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of STOC.</booktitle>
<contexts>
<context position="20256" citStr="Charikar (2002)" startWordPosition="3238" endWordPosition="3239"> the syntax model’s 12 million signatures in a compressed readable format, for instance, requires over 20GB of disk space. Like Ravichandran et al. (2005) and Bhagat and Ravichandran (2008), we rely on locality sensitive hashing (LSH) to make the use of these large collections practical. In order to avoid explicitly computing the feature vectors, which can be memory intensive for frequent phrases, we chose the online LSH variant described by Van Durme and Lall (2010), as implemented in the Jerboa toolkit (Van Durme, 2012). This method, based on the earlier work of Indyk and Motwani (1998) and Charikar (2002), approximates the cosine similarity between two feature vectors based on the Hamming distance in a dimensionalityreduced bitwise representation. Two feature vectors u, v each of dimension d are first projected through a dxb random matrix populated with draws from N(0,1). We then convert the resulting bdimensional vectors into bit-vectors by setting each bit of the signature conditioned on whether the corresponding projected value is less than 0. Now, given the bit signatures h(u) and h(v), we can approximate the cosine similarity of u and v as: (D(h(u), h(v)) l sim (u, v) = cos l b �J , where</context>
</contexts>
<marker>Charikar, 2002</marker>
<rawString>Moses Charikar. 2002. Similarity estimation techniques from rounding algorithms. In Proceedings of STOC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="4043" citStr="Chiang, 2005" startWordPosition="576" endWordPosition="577"> translating to the same phrase in the foreign language are assumed to be paraphrases of one another. 2 Background Approaches to paraphrase extraction differ based on their underlying data source. In Section 2.1 we outline pivot-based paraphrase extraction from bilingual data, while the contextual features used to determine closeness in meaning in monolingual approaches is described in Section 2.2. 2.1 Paraphrase Extraction via Pivoting Following Ganitkevitch et al. (2011), we formulate our paraphrases as a syntactically annotated synchronous context-free grammar (SCFG) (Aho and Ullman, 1972; Chiang, 2005). An SCFG rule has the form: r = C —* (f, e, —, ~ϕ), where the left-hand side of the rule, C, is a nonterminal and the right-hand sides f and e are strings of terminal and nonterminal symbols. There is a one-to-one correspondency between the nonterminals in f and e: each nonterminal symbol in f has to also appear in e. The function — captures this bijective mapping between the nonterminals. Drawing on machine translation terminology, we refer to f as the source and e as the target side of the rule. Each rule is annotated with a feature vector of feature functions ϕ~ = {ϕ1...ϕN} that, using a c</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="8491" citStr="Church and Hanks (1991)" startWordPosition="1336" endWordPosition="1339">ver all occurrences of e, resulting in a distributional signature for e, c�e = Ei c�e,i. Following the intuition that phrases with similar meanings occur in similar contexts, we can then quantify the goodness of e&apos; as a paraphrase of e by computing the cosine similarity between their distributional signatures: sim(e, e&apos;) = A wide variety of features have been used to describe the distributional context of a phrase. Rich, linguistically informed feature-sets that rely on dependency and constituency parses, part-of-speech tags, or lemmatization have been proposed in widely known work such as by Church and Hanks (1991) and Lin and Pantel (2001). For instance, a phrase is described by the various syntactic relations it has with lexical items in its context, such as: “for what verbs do we see with the phrase as the subject?”, or “what adjectives modify the phrase?”. However, when moving to vast text collections or collapsed representations of large text corpora, linguistic annotations can become impractically expensive to produce. A straightforward and widely used solution is to fall back onto lexical n-gram features, e.g. “what words or bigrams have we seen to the left of this phrase?” A substantial body of </context>
</contexts>
<marker>Church, Hanks, 1991</marker>
<rawString>Kenneth Church and Patrick Hanks. 1991. Word association norms, mutual information and lexicography. Computational Linguistics, 6(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>31--273</pages>
<contexts>
<context position="13981" citStr="Clarke and Lapata (2008)" startWordPosition="2227" endWordPosition="2230">ns for machine translation evaluation, we construct a parallel compression corpus by selecting the longest reference in each tuple as the source sentence and the shortest reference as the target sentence. We further retain only those sentence pairs where the compression ratio cr falls in the range 0.5 &lt; cr &lt; 0.8. From these, we select 936 sentences for the development set, as well as 560 sentences for a test set that we use to gauge the performance of our system. We contrast our distributional similarity-informed paraphrase system with a pivoting-only baseline, as well as an implementation of Clarke and Lapata (2008)’s state-of-the-art compression model which uses a series of constraints in an integer linear programming (ILP) solver. 4.2 Baseline Paraphrase Grammar We extract our paraphrase grammar from the French–English portion of the Europarl corpus (version 5) (Koehn, 2005). The Berkeley aligner (Liang et al., 2006) and the Berkeley parser (Petrov and Klein, 2007) are used to align the bitext and parse the English side, respectively. The paraphrase grammar is produced using the Hadoop-based Thrax ⌘ sim ⇣of⌘ the long-term in the long term sim(r) = 1 sim ⇣ NN long term NP NN the &apos;s NP in the long-term N</context>
<context position="16701" citStr="Clarke and Lapata (2008)" startWordPosition="2664" endWordPosition="2667">count difference feature wcountdiff , we add character based count and difference features ccountsrc, ccounttgt, and ccountdiff , as well as logcompression ratio features wordcr = log wcounttgt wcountsrc and the analogously defined charcr = log ccounttgt ccountsrc . For model tuning and decoding we used the Joshua machine translation system (Ganitkevitch et al., 2012). The model weights are estimated using an implementation of the PRO tuning algorithm (Hopkins and May, 2011), with PR´ECIS as our objective function (Ganitkevitch et al., 2011). The language model used in our paraphraser and the Clarke and Lapata (2008) baseline system is a Kneser-Ney discounted 5-gram model estimated on the Gigaword corpus using the SRILM toolkit (Stolcke, 2002). Figure 6: An example of the syntactic featureset. The phrase “the long-term” is annotated with position-aware lexical and part-of-speech n-gram features (e.g. “on to” on the left, and “investment” and “NN” to its right), labeled dependency links (e.g. amod − investment) and features derived from the phrase’s CCG label NP/NN. 4.3 Distributional Similarity Model To investigate the impact of the feature-set used to construct distributional signatures, we contrast two </context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31:273–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression beyond word deletion.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLING.</booktitle>
<contexts>
<context position="1588" citStr="Cohn and Lapata, 2008" startWordPosition="219" endWordPosition="223">rm of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this pap</context>
</contexts>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2008. Sentence compression beyond word deletion. In Proceedings of the COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Chris Callison-Burch</author>
<author>Courtney Napoles</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Ganitkevitch, Callison-Burch, Napoles, Van Durme, 2011</marker>
<rawString>Juri Ganitkevitch, Chris Callison-Burch, Courtney Napoles, and Benjamin Van Durme. 2011. Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Yuan Cao</author>
<author>Jonathan Weese</author>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Joshua 4.0: Packing, PRO, and paraphrases.</title>
<date>2012</date>
<booktitle>In Proceedings of WMT12.</booktitle>
<contexts>
<context position="7123" citStr="Ganitkevitch et al., 2012" startWordPosition="1113" endWordPosition="1116">nctions can be formulated. We detail the feature-set used in our experiments in Section 4. p(e2|f)p(f|e1). (4) 1See Yao et al. (2012) for an analysis of this assumption. E� f 257 Figure 3: An example of a synchronous paraphrastic derivation, here a sentence compression. Shaded words are deleted in the indicated rule applications. Figure 2 illustrates syntax-constrained pivoting and feature aggregation over multiple foreign language translations for a paraphrase pattern. After the SCFG has been extracted, it can be used within standard machine translation machinery, such as the Joshua decoder (Ganitkevitch et al., 2012). Figure 3 shows an example for a synchronous paraphrastic derivation produced as a result of applying our paraphrase grammar in the decoding process. The approach outlined relies on aligned bilingual texts to identify phrases and patterns that are equivalent in meaning. When extracting paraphrases from monolingual text, we have to rely on an entirely different set of semantic cues and features. 2.2 Monolingual Distributional Similarity Methods based on monolingual text corpora measure the similarity of phrases based on contextual features. To describe a phrase e, we define a set of features t</context>
<context position="15507" citStr="Ganitkevitch et al., 2012" startWordPosition="2478" endWordPosition="2481">43 confirmed revise the long-term investment 10 L-achieve = 25 R-plans = 97 si g,. ⇣the long-term⌘ _ L-revise = 43 ⇣ R-goals = 23 R-investment = 10 L-confirmed = 64 the long-term the long-term goals 23 the long-term plans 97 the long-term the long-term Figure 5: An example of the n-gram feature extraction on an n-gram corpus. Here, “the long-term” is seen preceded by “revise” (43 times) and followed by “plans” (97 times). The corresponding left- and right-side features are added to the phrase signature with the counts of the n-grams that gave rise to them. grammar extractor’s paraphrase mode (Ganitkevitch et al., 2012). The syntactic nonterminal labels we allowed in the grammar were limited to constituent labels and CCG-style slashed categories. Paraphrase grammars extracted via pivoting tend to grow very large. To keep the grammar size manageable, we pruned away all paraphrase rules whose phrasal paraphrase probabilities p(e1|e2) or p(e2|e1) were smaller than 0.001. We extend the feature-set used in Ganitkevitch et al. (2011) with a number of features that aim to better describe a rule’s compressive power: on top of the word count features wcountsrc and wcounttgt and the word count difference feature wcoun</context>
</contexts>
<marker>Ganitkevitch, Cao, Weese, Post, Callison-Burch, 2012</marker>
<rawString>Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, and Chris Callison-Burch. 2012. Joshua 4.0: Packing, PRO, and paraphrases. In Proceedings of WMT12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Jonathan May</author>
</authors>
<title>Tuning as ranking.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="16556" citStr="Hopkins and May, 2011" startWordPosition="2640" endWordPosition="2644">ber of features that aim to better describe a rule’s compressive power: on top of the word count features wcountsrc and wcounttgt and the word count difference feature wcountdiff , we add character based count and difference features ccountsrc, ccounttgt, and ccountdiff , as well as logcompression ratio features wordcr = log wcounttgt wcountsrc and the analogously defined charcr = log ccounttgt ccountsrc . For model tuning and decoding we used the Joshua machine translation system (Ganitkevitch et al., 2012). The model weights are estimated using an implementation of the PRO tuning algorithm (Hopkins and May, 2011), with PR´ECIS as our objective function (Ganitkevitch et al., 2011). The language model used in our paraphraser and the Clarke and Lapata (2008) baseline system is a Kneser-Ney discounted 5-gram model estimated on the Gigaword corpus using the SRILM toolkit (Stolcke, 2002). Figure 6: An example of the syntactic featureset. The phrase “the long-term” is annotated with position-aware lexical and part-of-speech n-gram features (e.g. “on to” on the left, and “investment” and “NN” to its right), labeled dependency links (e.g. amod − investment) and features derived from the phrase’s CCG label NP/N</context>
</contexts>
<marker>Hopkins, May, 2011</marker>
<rawString>Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piotr Indyk</author>
<author>Rajeev Motwani</author>
</authors>
<title>Approximate nearest neighbors: towards removing the curse of dimensionality.</title>
<date>1998</date>
<booktitle>In Proceedings of STOC.</booktitle>
<contexts>
<context position="20236" citStr="Indyk and Motwani (1998)" startWordPosition="3233" endWordPosition="3236">eably large datasets. Storing the syntax model’s 12 million signatures in a compressed readable format, for instance, requires over 20GB of disk space. Like Ravichandran et al. (2005) and Bhagat and Ravichandran (2008), we rely on locality sensitive hashing (LSH) to make the use of these large collections practical. In order to avoid explicitly computing the feature vectors, which can be memory intensive for frequent phrases, we chose the online LSH variant described by Van Durme and Lall (2010), as implemented in the Jerboa toolkit (Van Durme, 2012). This method, based on the earlier work of Indyk and Motwani (1998) and Charikar (2002), approximates the cosine similarity between two feature vectors based on the Hamming distance in a dimensionalityreduced bitwise representation. Two feature vectors u, v each of dimension d are first projected through a dxb random matrix populated with draws from N(0,1). We then convert the resulting bdimensional vectors into bit-vectors by setting each bit of the signature conditioned on whether the corresponding projected value is less than 0. Now, given the bit signatures h(u) and h(v), we can approximate the cosine similarity of u and v as: (D(h(u), h(v)) l sim (u, v) </context>
</contexts>
<marker>Indyk, Motwani, 1998</marker>
<rawString>Piotr Indyk and Rajeev Motwani. 1998. Approximate nearest neighbors: towards removing the curse of dimensionality. In Proceedings of STOC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT summit,</booktitle>
<volume>5</volume>
<contexts>
<context position="14247" citStr="Koehn, 2005" startWordPosition="2268" endWordPosition="2269">r falls in the range 0.5 &lt; cr &lt; 0.8. From these, we select 936 sentences for the development set, as well as 560 sentences for a test set that we use to gauge the performance of our system. We contrast our distributional similarity-informed paraphrase system with a pivoting-only baseline, as well as an implementation of Clarke and Lapata (2008)’s state-of-the-art compression model which uses a series of constraints in an integer linear programming (ILP) solver. 4.2 Baseline Paraphrase Grammar We extract our paraphrase grammar from the French–English portion of the Europarl corpus (version 5) (Koehn, 2005). The Berkeley aligner (Liang et al., 2006) and the Berkeley parser (Petrov and Klein, 2007) are used to align the bitext and parse the English side, respectively. The paraphrase grammar is produced using the Hadoop-based Thrax ⌘ sim ⇣of⌘ the long-term in the long term sim(r) = 1 sim ⇣ NN long term NP NN the &apos;s NP in the long-term NP of 259 holding on to VP the PP long-term investment det amod NP dep-det-R-investment lex-R-investment pos-L-IN-TO pos-L-TO lex-L-on-to pos-R-NN lex-L-to dep-amod-R-investment syn-gov-NP syn-miss-L-NN dep-det-R-NN dep-amod-R-NN ⇣ VBG IN TO DT JJ NN st s t ⇣the long</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT summit, volume 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5297" citStr="Koehn, 2010" startWordPosition="795" endWordPosition="796">d in a loglinear model to compute the cost of applying r: Figure 2: Extraction of syntactic paraphrases via the pivoting approach: We aggregate over different surface realizations, matching the lexicalized portions of the rule and generalizing over the nonterminals. To extract paraphrases we follow the intuition that two English strings e1 and e2 that translate to the same foreign string f can be assumed to have the same meaning, as illustrated in Figure 1.1 First, we use standard machine translation methods to extract a foreign-to-English translation grammar from a bilingual parallel corpus (Koehn, 2010). Then, for each pair of translation rules where the left-hand side C and foreign string f match: r1 = C —* (f, e1, —1, ~ϕ1) r2 = C —* (f, e2, —2, ~ϕ2), we pivot over f to create a paraphrase rule rp: rp = C —* (e1, e2, —p, ~ϕp), with a combined nonterminal correspondency function —p. Note that the common source side f implies that e1 and e2 share the same set of nonterminal symbols. The paraphrase feature vector ~ϕp is computed from the translation feature vectors ~ϕ1 and ~ϕ2 by following the pivoting idea. For instance, we estimate the conditional paraphrase probability p(e2|e1) by marginali</context>
</contexts>
<marker>Koehn, 2010</marker>
<rawString>Philipp Koehn. 2010. Statistical Machine Translation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Frank Keller</author>
</authors>
<title>Web-based models for natural language processing.</title>
<date>2005</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="9200" citStr="Lapata and Keller, 2005" startWordPosition="1457" endWordPosition="1460">ic relations it has with lexical items in its context, such as: “for what verbs do we see with the phrase as the subject?”, or “what adjectives modify the phrase?”. However, when moving to vast text collections or collapsed representations of large text corpora, linguistic annotations can become impractically expensive to produce. A straightforward and widely used solution is to fall back onto lexical n-gram features, e.g. “what words or bigrams have we seen to the left of this phrase?” A substantial body of work has focussed on using this type of feature-set for a variety of purposes in NLP (Lapata and Keller, 2005; Bhagat and Ravichandran, 2008; Lin et al., 2010; Van Durme and Lall, 2010). 2.3 Other Related Work Recently, Chan et al. (2011) presented an initial investigation into combining phrasal paraphrases obtained through bilingual pivoting with monolingual distributional information. Their work investigated a reranking approach and evaluated their method via a substitution task, showing that the two sources of information are complementary and can yield improvements in paraphrase quality when combined. 3 Incorporating Distributional Similarity In order to incorporate distributional similarity info</context>
</contexts>
<marker>Lapata, Keller, 2005</marker>
<rawString>Mirella Lapata and Frank Keller. 2005. Web-based models for natural language processing. ACM Transactions on Speech and Language Processing, 2(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="14290" citStr="Liang et al., 2006" startWordPosition="2273" endWordPosition="2276"> From these, we select 936 sentences for the development set, as well as 560 sentences for a test set that we use to gauge the performance of our system. We contrast our distributional similarity-informed paraphrase system with a pivoting-only baseline, as well as an implementation of Clarke and Lapata (2008)’s state-of-the-art compression model which uses a series of constraints in an integer linear programming (ILP) solver. 4.2 Baseline Paraphrase Grammar We extract our paraphrase grammar from the French–English portion of the Europarl corpus (version 5) (Koehn, 2005). The Berkeley aligner (Liang et al., 2006) and the Berkeley parser (Petrov and Klein, 2007) are used to align the bitext and parse the English side, respectively. The paraphrase grammar is produced using the Hadoop-based Thrax ⌘ sim ⇣of⌘ the long-term in the long term sim(r) = 1 sim ⇣ NN long term NP NN the &apos;s NP in the long-term NP of 259 holding on to VP the PP long-term investment det amod NP dep-det-R-investment lex-R-investment pos-L-IN-TO pos-L-TO lex-L-on-to pos-R-NN lex-L-to dep-amod-R-investment syn-gov-NP syn-miss-L-NN dep-det-R-NN dep-amod-R-NN ⇣ VBG IN TO DT JJ NN st s t ⇣the long-term⌘ _ Left Right 25 achieve 64 43 confir</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules from text. Natural Language Engineering.</title>
<date>2001</date>
<contexts>
<context position="2009" citStr="Lin and Pantel, 2001" startWordPosition="281" endWordPosition="284"> 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an extension of Ganitkevitch et al. (2011)’s bilingual data-based approach. We augment the bilingually-sourced paraphrases using features based on monolingual distributional similarity. More specifically: • We show that using monolingual distributional similarity features improves paraphrase quality beyond what we can achieve with features estimated from bilingual data. • We define distributional simil</context>
<context position="8517" citStr="Lin and Pantel (2001)" startWordPosition="1341" endWordPosition="1344">sulting in a distributional signature for e, c�e = Ei c�e,i. Following the intuition that phrases with similar meanings occur in similar contexts, we can then quantify the goodness of e&apos; as a paraphrase of e by computing the cosine similarity between their distributional signatures: sim(e, e&apos;) = A wide variety of features have been used to describe the distributional context of a phrase. Rich, linguistically informed feature-sets that rely on dependency and constituency parses, part-of-speech tags, or lemmatization have been proposed in widely known work such as by Church and Hanks (1991) and Lin and Pantel (2001). For instance, a phrase is described by the various syntactic relations it has with lexical items in its context, such as: “for what verbs do we see with the phrase as the subject?”, or “what adjectives modify the phrase?”. However, when moving to vast text collections or collapsed representations of large text corpora, linguistic annotations can become impractically expensive to produce. A straightforward and widely used solution is to fall back onto lexical n-gram features, e.g. “what words or bigrams have we seen to the left of this phrase?” A substantial body of work has focussed on using</context>
<context position="12124" citStr="Lin and Pantel (2001)" startWordPosition="1933" endWordPosition="1936">rall similarity score of the rule to be the average of the similarity scores of all extracted phrase pairs: sim (r, a) = |P1 (a) |sim (e, e&apos;). (e,e )EP(a) Since the distributional signatures for long, rare phrases may be computed from only a handful of occurrences, we additionally query for the shorter sub-phrases that are more likely to have been observed often enough to have reliable signatures and thus similarity estimates. Our definition of the similarity of two discontinuous phrases substantially differs from others in the literature. This difference is due to a difference in motivation. Lin and Pantel (2001), for instance, seek to find new paraphrase pairs by comparing their arguments. In this work, however, we try to add orthogonal information to existing paraphrase pairs. Both our definition of pattern similarity and our feature-set (see Section 4.3) are therefore geared towards comparing the substitutability and context similarity of a pair of paraphrases. Our two similarity scores are incorporated into the paraphraser as additional rule features in cp, simngram and simsyn, respectively. We estimate the corresponding weights along with the other AZ as detailed in Section 4. 4 Experimental Setu</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules from text. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Kenneth Church</author>
<author>Heng Ji</author>
<author>Satoshi Sekine</author>
<author>David Yarowsky</author>
<author>Shane Bergsma</author>
</authors>
<title>New tools for web-scale n-grams.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC.</booktitle>
<institution>Kailash Patil, Emily Pitler, Rachel Lathbury, Vikram Rao, Kapil Dalwani, and Sushant</institution>
<contexts>
<context position="9249" citStr="Lin et al., 2010" startWordPosition="1466" endWordPosition="1469">uch as: “for what verbs do we see with the phrase as the subject?”, or “what adjectives modify the phrase?”. However, when moving to vast text collections or collapsed representations of large text corpora, linguistic annotations can become impractically expensive to produce. A straightforward and widely used solution is to fall back onto lexical n-gram features, e.g. “what words or bigrams have we seen to the left of this phrase?” A substantial body of work has focussed on using this type of feature-set for a variety of purposes in NLP (Lapata and Keller, 2005; Bhagat and Ravichandran, 2008; Lin et al., 2010; Van Durme and Lall, 2010). 2.3 Other Related Work Recently, Chan et al. (2011) presented an initial investigation into combining phrasal paraphrases obtained through bilingual pivoting with monolingual distributional information. Their work investigated a reranking approach and evaluated their method via a substitution task, showing that the two sources of information are complementary and can yield improvements in paraphrase quality when combined. 3 Incorporating Distributional Similarity In order to incorporate distributional similarity information into the paraphrasing system, we need to </context>
<context position="17647" citStr="Lin et al., 2010" startWordPosition="2807" endWordPosition="2810">nd “NN” to its right), labeled dependency links (e.g. amod − investment) and features derived from the phrase’s CCG label NP/NN. 4.3 Distributional Similarity Model To investigate the impact of the feature-set used to construct distributional signatures, we contrast two approaches: a high-coverage collection of distributional signatures with a relatively simple feature-set, and a much smaller set of signatures with a rich, syntactically informed feature-set. 4.3.1 n-gram Model The high-coverage model (from here on: n-gram model) is drawn from a web-scale n-gram corpus (Brants and Franz, 2006; Lin et al., 2010). We extract signatures for phrases up to a length of 4. For each phrase p we look at n-grams of the form wp and pv, where w and v are single words. We then extract the corresponding features wleft and vright. The feature count is set to the count of the n-gram, reflecting the frequency with which p was preceded or followed, respectively, by w and v in the data the n-gram corpus is based on. Figure 5 illustrates this feature extraction approach. The resulting collection comprises distributional signatures for the 200 million most frequent 1-to-4-grams in the n-gram corpus. 260 4.3.2 Syntactic </context>
</contexts>
<marker>Lin, Church, Ji, Sekine, Yarowsky, Bergsma, 2010</marker>
<rawString>Dekang Lin, Kenneth Church, Heng Ji, Satoshi Sekine, David Yarowsky, Shane Bergsma, Kailash Patil, Emily Pitler, Rachel Lathbury, Vikram Rao, Kapil Dalwani, and Sushant Narsale. 2010. New tools for web-scale n-grams. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Paraphrasing using given and new information in a question-answer system.</title>
<date>1979</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1513" citStr="McKeown, 1979" startWordPosition="211" endWordPosition="212"> be cast in terms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to comb</context>
</contexts>
<marker>McKeown, 1979</marker>
<rawString>Kathleen R. McKeown. 1979. Paraphrasing using given and new information in a question-answer system. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Napoles</author>
<author>Chris Callison-Burch</author>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Paraphrastic sentence compression with a character-based metric: Tightening without deletion. Workshop on Monolingual Text-To-Text Generation.</title>
<date>2011</date>
<marker>Napoles, Callison-Burch, Ganitkevitch, Van Durme, 2011</marker>
<rawString>Courtney Napoles, Chris Callison-Burch, Juri Ganitkevitch, and Benjamin Van Durme. 2011. Paraphrastic sentence compression with a character-based metric: Tightening without deletion. Workshop on Monolingual Text-To-Text Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Napoles</author>
<author>Matt Gormley</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Annotated gigaword.</title>
<date>2012</date>
<booktitle>In Proceedings of AKBC-WEKEX</booktitle>
<marker>Napoles, Gormley, Van Durme, 2012</marker>
<rawString>Courtney Napoles, Matt Gormley, and Benjamin Van Durme. 2012. Annotated gigaword. In Proceedings of AKBC-WEKEX 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="14339" citStr="Petrov and Klein, 2007" startWordPosition="2281" endWordPosition="2284">development set, as well as 560 sentences for a test set that we use to gauge the performance of our system. We contrast our distributional similarity-informed paraphrase system with a pivoting-only baseline, as well as an implementation of Clarke and Lapata (2008)’s state-of-the-art compression model which uses a series of constraints in an integer linear programming (ILP) solver. 4.2 Baseline Paraphrase Grammar We extract our paraphrase grammar from the French–English portion of the Europarl corpus (version 5) (Koehn, 2005). The Berkeley aligner (Liang et al., 2006) and the Berkeley parser (Petrov and Klein, 2007) are used to align the bitext and parse the English side, respectively. The paraphrase grammar is produced using the Hadoop-based Thrax ⌘ sim ⇣of⌘ the long-term in the long term sim(r) = 1 sim ⇣ NN long term NP NN the &apos;s NP in the long-term NP of 259 holding on to VP the PP long-term investment det amod NP dep-det-R-investment lex-R-investment pos-L-IN-TO pos-L-TO lex-L-on-to pos-R-NN lex-L-to dep-amod-R-investment syn-gov-NP syn-miss-L-NN dep-det-R-NN dep-amod-R-NN ⇣ VBG IN TO DT JJ NN st s t ⇣the long-term⌘ _ Left Right 25 achieve 64 43 confirmed revise the long-term investment 10 L-achieve </context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning sufrace text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1543" citStr="Ravichandran and Hovy, 2002" startWordPosition="213" endWordPosition="216">ms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning sufrace text patterns for a question answering system. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Patrick Pantel</author>
<author>Eduard Hovy</author>
</authors>
<title>Randomized Algorithms and NLP: Using Locality Sensitive Hash Functions for High Speed Noun Clustering.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="19795" citStr="Ravichandran et al. (2005)" startWordPosition="3156" endWordPosition="3159">d constituent labels for the phrase. The latter are split in governing constituent and missing constituent (with directionality). Figure 6 illustrates the syntax model’s feature extraction for an example phrase occurrence. Using this method we extract distributional signatures for over 12 million 1-to-4-gram phrases. 4.3.3 Locality Sensitive Hashing Collecting distributional signatures for a large number of phrases quickly leads to unmanageably large datasets. Storing the syntax model’s 12 million signatures in a compressed readable format, for instance, requires over 20GB of disk space. Like Ravichandran et al. (2005) and Bhagat and Ravichandran (2008), we rely on locality sensitive hashing (LSH) to make the use of these large collections practical. In order to avoid explicitly computing the feature vectors, which can be memory intensive for frequent phrases, we chose the online LSH variant described by Van Durme and Lall (2010), as implemented in the Jerboa toolkit (Van Durme, 2012). This method, based on the earlier work of Indyk and Motwani (1998) and Charikar (2002), approximates the cosine similarity between two feature vectors based on the Hamming distance in a dimensionalityreduced bitwise represent</context>
</contexts>
<marker>Ravichandran, Pantel, Hovy, 2005</marker>
<rawString>Deepak Ravichandran, Patrick Pantel, and Eduard Hovy. 2005. Randomized Algorithms and NLP: Using Locality Sensitive Hash Functions for High Speed Noun Clustering. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Alexander Vasserman</author>
<author>Ioannis Tsochantaridis</author>
<author>Vibhu Mittal</author>
<author>Yi Liu</author>
</authors>
<title>Statistical machine translation for query expansion in answer retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1478" citStr="Riezler et al., 2007" startWordPosition="204" endWordPosition="207">ications in natural language processing can be cast in terms of text-to-text generation. Given input in the form of natural language, a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary s</context>
</contexts>
<marker>Riezler, Vasserman, Tsochantaridis, Mittal, Liu, 2007</marker>
<rawString>Stefan Riezler, Alexander Vasserman, Ioannis Tsochantaridis, Vibhu Mittal, and Yi Liu. 2007. Statistical machine translation for query expansion in answer retrieval. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceeding of the International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="16830" citStr="Stolcke, 2002" startWordPosition="2686" endWordPosition="2687">s logcompression ratio features wordcr = log wcounttgt wcountsrc and the analogously defined charcr = log ccounttgt ccountsrc . For model tuning and decoding we used the Joshua machine translation system (Ganitkevitch et al., 2012). The model weights are estimated using an implementation of the PRO tuning algorithm (Hopkins and May, 2011), with PR´ECIS as our objective function (Ganitkevitch et al., 2011). The language model used in our paraphraser and the Clarke and Lapata (2008) baseline system is a Kneser-Ney discounted 5-gram model estimated on the Gigaword corpus using the SRILM toolkit (Stolcke, 2002). Figure 6: An example of the syntactic featureset. The phrase “the long-term” is annotated with position-aware lexical and part-of-speech n-gram features (e.g. “on to” on the left, and “investment” and “NN” to its right), labeled dependency links (e.g. amod − investment) and features derived from the phrase’s CCG label NP/NN. 4.3 Distributional Similarity Model To investigate the impact of the feature-set used to construct distributional signatures, we contrast two approaches: a high-coverage collection of distributional signatures with a relatively simple feature-set, and a much smaller set </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceeding of the International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Van Durme</author>
<author>Ashwin Lall</author>
</authors>
<title>Online generation of locality sensitive hash signatures.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL, Short Papers.</booktitle>
<marker>Van Durme, Lall, 2010</marker>
<rawString>Benjamin Van Durme and Ashwin Lall. 2010. Online generation of locality sensitive hash signatures. In Proceedings of ACL, Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Van Durme</author>
</authors>
<title>Jerboa: A toolkit for randomized and streaming algorithms.</title>
<date>2012</date>
<tech>Technical Report 7,</tech>
<institution>Human Language Technology Center of Excellence, Johns Hopkins University.</institution>
<marker>Van Durme, 2012</marker>
<rawString>Benjamin Van Durme. 2012. Jerboa: A toolkit for randomized and streaming algorithms. Technical Report 7, Human Language Technology Center of Excellence, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sander Wubben</author>
<author>Antal van den Bosch</author>
<author>Emiel Krahmer</author>
</authors>
<title>Sentence simplification by monolingual machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Wubben, van den Bosch, Krahmer, 2012</marker>
<rawString>Sander Wubben, Antal van den Bosch, and Emiel Krahmer. 2012. Sentence simplification by monolingual machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuchen Yao</author>
<author>Benjamin Van Durme</author>
<author>Chris CallisonBurch</author>
</authors>
<title>Expectations of word sense in parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<marker>Yao, Van Durme, CallisonBurch, 2012</marker>
<rawString>Xuchen Yao, Benjamin Van Durme, and Chris CallisonBurch. 2012. Expectations of word sense in parallel corpora. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot approach for extracting paraphrase patterns from bilingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL/HLT.</booktitle>
<contexts>
<context position="1863" citStr="Zhao et al., 2008" startWordPosition="261" endWordPosition="264">mponents of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an extension of Ganitkevitch et al. (2011)’s bilingual data-based approach. We augment the bilingually-sourced paraphrases using features based on monolingual distributional similarity. More specifically: • We show that using monolingual distributional simila</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008. Pivot approach for extracting paraphrase patterns from bilingual corpora. In Proceedings of ACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Application-driven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1608" citStr="Zhao et al., 2009" startWordPosition="224" endWordPosition="227"> a text-to-text generation system produces natural language output that is subject to a set of constraints. Compression systems, for instance, produce shorter sentences. Paraphrases, i.e. differing textual realizations of the same meaning, are a crucial components of text-to-text generation systems, and have been successfully applied to tasks such as multi-document summarization (Barzilay et al., 1999; Barzilay, 2003), query expansion (Anick and Tipirneni, 1999; Riezler et al., 2007), question answering (McKeown, 1979; Ravichandran and Hovy, 2002), sentence compression (Cohn and Lapata, 2008; Zhao et al., 2009), and simplification (Wubben et al., 2012). Paraphrase collections for text-to-text generation have been extracted from a variety of different corpora. Several approaches rely on bilingual parallel data (Bannard and Callison-Burch, 2005; Zhao et al., 2008; Callison-Burch, 2008; Ganitkevitch et al., 2011), while others leverage distributional methods on monolingual text corpora (Lin and Pantel, 2001; Bhagat and Ravichandran, 2008). So far, however, only preliminary studies have been undertaken to combine the information from these two sources (Chan et al., 2011). In this paper, we describe an e</context>
</contexts>
<marker>Zhao, Lan, Liu, Li, 2009</marker>
<rawString>Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven statistical paraphrase generation. In Proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>