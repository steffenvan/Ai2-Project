<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000219">
<title confidence="0.9993885">
A Situated Context Model for
Resolution and Generation of Referring Expressions
</title>
<author confidence="0.970074">
Hendrik Zender and Geert-Jan M. Kruijff and Ivana Kruijff-Korbayov´a
</author>
<affiliation confidence="0.950184">
Language Technology Lab, German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.645486">
Saarbr¨ucken, Germany
</address>
<email confidence="0.995776">
{zender, gj, ivana.kruijff}@dfki.de
</email>
<sectionHeader confidence="0.993832" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999927315789474">
The background for this paper is the aim
to build robotic assistants that can “natu-
rally” interact with humans. One prereq-
uisite for this is that the robot can cor-
rectly identify objects or places a user
refers to, and produce comprehensible ref-
erences itself. As robots typically act
in environments that are larger than what
is immediately perceivable, the problem
arises how to identify the appropriate con-
text, against which to resolve or produce
a referring expression (RE). Existing al-
gorithms for generating REs generally by-
pass this problem by assuming a given
context. In this paper, we explicitly ad-
dress this problem, proposing a method for
context determination in large-scale space.
We show how it can be applied both for re-
solving and producing REs.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999947166666667">
The past years have seen an extraordinary increase
in research on robotic assistants that help users
perform daily chores. Autonomous vacuum clean-
ers have already found their way into people’s
homes, but it will still take a while before fully
conversational robot “gophers” will assist people
in more demanding everyday tasks. Imagine a
robot that can deliver objects, and give directions
to visitors on a university campus. This robot must
be able to verbalize its knowledge in a way that is
understandable by humans.
A conversational robot will inevitably face sit-
uations in which it needs to refer to an entity (an
object, a locality, or even an event) that is located
somewhere outside the current scene, as Figure 1
illustrates. There are conceivably many ways in
which a robot might refer to things in the world,
but many such expressions are unsuitable in most
</bodyText>
<figureCaption confidence="0.99735">
Figure 1: Situated dialogue with a service robot
</figureCaption>
<bodyText confidence="0.7680185">
human-robot dialogues. Consider the following
set of examples:
</bodyText>
<listItem confidence="0.9968225">
1. “position P = (45.56, −3.92,10.45)”
2. “Peter’s office no. 200 at the end of the cor-
ridor on the third floor of the Acme Corp.
building 3 in the Acme Corp. complex, 47
Evergreen Terrace, Calisota, Earth, (...)”
3. “the area”
</listItem>
<bodyText confidence="0.998520142857143">
These REs are valid descriptions of their respec-
tive referents. Still they fail to achieve their com-
municative goal, which is to specify the right
amount of information that the hearer needs to
uniquely identify the referent. The next REs might
serve as more appropriate variants of the previous
examples (in certain contexts!):
</bodyText>
<listItem confidence="0.996827">
1. “the IT help desk”
2. “Peter’s office”
3. “the large hall on the first floor”
</listItem>
<bodyText confidence="0.987572666666667">
The first example highlights a requirement on the
knowledge representation to which an algorithm
for generating referring expressions (GRE) has ac-
cess. Although the robot needs a robot-centric rep-
resentation of its surrounding space that allows it
to safely perform actions and navigate its world,
it should use human-centric qualitative descrip-
tions when talking about things in the world. We
Where is hh
Where is the
T Help desk
IT help desk?
</bodyText>
<equation confidence="0.84861125">
It is t
t is at
&lt;45.56, -3.92, 10.45&gt;
It is on the 1st
It s on thefloor in building
1st floor in
ding
3B.
</equation>
<bodyText confidence="0.4058">
Proceedings of the 12th European Workshop on Natural Language Generation, pages 126–129,
Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.997646">
126
</page>
<bodyText confidence="0.999915264705882">
do not address this issue here, but refer the inter-
ested reader to our recent work on multi-layered
spatial maps for robots, bridging the gap between
robot-centric and human-centric spatial represen-
tations (Zender et al., 2008).
The other examples point out another impor-
tant consideration: how much information does the
human need to single out the intended referent
among the possible entities that the robot could be
referring to? According to the seminal work on
GRE by Dale and Reiter (1995), one needs to dis-
tinguish whether the intended referent is already
in the hearer’s focus of attention or not. This focus
of attention can consist of a local visual scene (vi-
sual context) or a shared workspace (spatial con-
text), but also contains recently mentioned entities
(dialogue context). If the referent is already part
of the current context, the GRE task merely con-
sists of singling it out among the other members
of the context, which act as distractors. In this
case the generated RE contains discriminatory in-
formation, e.g. “the red ball” if several kinds of ob-
jects with different colors are in the context. If, on
the other hand, the referent is not in the hearer’s fo-
cus of attention, an RE needs to contain what Dale
and Reiter call navigational, or attention-directing
information. The example they give is “the black
power supply in the equipment rack,” where “the
equipment rack” is supposed to direct the hearers
attention to the rack and its contents.
In the following we propose an approach for
context determination and extension that allows a
mobile robot to produce and interpret REs to enti-
ties outside the current visual context.
</bodyText>
<sectionHeader confidence="0.95203" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999970621212122">
Most GRE approaches are applied to very lim-
ited, visual scenes – so-called small-scale space.
The domain of such systems is usually a small vi-
sual scene, e.g. a number of objects, such as cups
and tables, located in the same room), or other
closed-context scenarios (Dale and Reiter, 1995;
Horacek, 1997; Krahmer and Theune, 2002). Re-
cently, Kelleher and Kruijff (2006) have presented
an incremental GRE algorithm for situated di-
alogue with a robot about a table-top setting,
i.e. also about small-scale space. In all these cases,
the context set is assumed to be identical to the
visual scene that is shared between the interlocu-
tors. The intended referent is thus already in the
hearer’s focus of attention.
In contrast, robots typically act in large-scale
space, i.e. space “larger than what can be per-
ceived at once” (Kuipers, 1977). They need the
ability to understand and produce references to
things that are beyond the current visual and spa-
tial context. In any situated dialogue that involves
entities beyond the current focus of attention, the
task of extending the context becomes key.
Paraboni et al. (2007) present an algorithm for
context determination in hierarchically ordered
domains, e.g. a university campus or a document
structure. Their approach is mainly targeted at
producing textual references to entities in written
documents (e.g. figures, tables in book chapters).
Consequently they do not address the challenges
that arise in physically and perceptually situated
dialogues. Still, the approach presents a num-
ber of good contributions towards GRE for situ-
ated dialogue in large-scale space. An appropriate
context, as a subset of the full domain, is deter-
mined through Ancestral Search. This search for
the intended referent is rooted in the “position of
the speaker and the hearer in the domain” (repre-
sented as d), a crucial first step towards situated-
ness. Their approach suffers from the shortcom-
ing that spatial relationships are treated as one-
place attributes by their GRE algorithm. For ex-
ample they transform the spatial containment re-
lation that holds between a room entity and a
building entity (“the library in the Cockroft build-
ing”) into a property of the room entity (BUILDING
NAME = COCKROFT) and not a two-place relation
(in(library,Cockroft)). Thus they avoid
recursive calls to the algorithm, which would be
needed if the intended referent is related to another
entity that needs to be properly referred to.
However, according to Dale and Reiter (1995),
these related entities do not necessarily serve as
discriminatory information. At least in large-scale
space, in contrast to a document structure that is
conceivably transparent to a reader, they function
as attention-directing elements that are introduced
to build up common ground by incrementally ex-
tending the hearer’s focus of attention. Moreover,
representing some spatial relations as two-place
predicates between two entities and some as one-
place predicates is an arbitrary decision.
We present an approach for context determina-
tion (or extension), that imposes less restrictions
on its knowledge base, and which can be used as a
sub-routine in existing GRE algorithms.
</bodyText>
<page confidence="0.995063">
127
</page>
<sectionHeader confidence="0.984605" genericHeader="method">
3 Situated Dialogue in Large-Scale Space
</sectionHeader>
<bodyText confidence="0.991580291666667">
Imagine the situation in Figure 1 did not take place
somewhere on campus, but rather inside building
3B. Certainly the robot would not have said “the
IT help desk is on the 1st floor in building 3B.”
To avoid confusing the human, an utterance like
“the IT help desk is on the 1st floor” would have
been appropriate. Likewise, if the IT help desk
happened to be located on another site of the uni-
versity, the robot would have had to identify its lo-
cation as being “on the 1st floor in building 3B on
the new campus.” The hierarchical representation
of space that people are known to assume (Cohn
and Hazarika, 2001), reflects upon the choice of
an appropriate context when producing REs.
In the above example the physical and spatial
situatedness of the dialogue participants play an
important role in determining which related parts
of space come into consideration as potential dis-
tractors. Another important observation concerns
the verbal behavior of humans when talking about
remote objects and places during a complex dia-
logue (i.e. more than just a question and a reply).
Consider the following example dialogue:
Person A: “Where is the exit?”
Person B: “You first go down this corridor.
Then you turn right. After a few steps you
will see the big glass doors.”
Person A: “And the bus station? Is it to the
left?”
The dialogue illustrates how utterances become
grounded in previously introduced discourse ref-
erents, both temporally and spatially. Initially,
the physical surroundings of the dialogue partners
form the context for anchoring references. As a di-
alogue unfolds, this point can conceptually move
to other locations that have been explicitly intro-
duced. Discourse markers denoting spatial or tem-
poral cohesion (e.g. “then” or “there”) can make
this move to a new anchor explicit, leading to a
“mental tour” through large-scale space.
We propose a general principle of Topological
Abstraction (TA) for context extension which is
rooted in what we will call the Referential Anchor
a.1 TA is designed for a multiple abstraction hier-
archy (e.g. represented as a lattice structure rather
than a simple tree). The Referential Anchor a, cor-
responding to the current focus of attention, forms
the nucleus of the context. In the simple case, a
</bodyText>
<footnote confidence="0.781885">
1similar to Ancestral Search (Paraboni et al., 2007)
</footnote>
<figureCaption confidence="0.998833">
Figure 2: Incremental TA in large-scale space
</figureCaption>
<bodyText confidence="0.999933333333333">
corresponds to the hearer’s physical location. As
illustrated above, a can also move along the “spa-
tial progression” of the most salient discourse en-
tity during a dialogue. If the intended referent is
outside the current context, TA extends the context
by incrementally ascending the spatial abstraction
hierarchy until the intended referent is an element
of the resulting sub-hierarchy, as illustrated in Fig-
ure 2. Below we describe two instantiations of the
TA principle, a TA algorithm for reference gener-
ation (TAA1) and TAA2 for reference resolution.
Context Determination for GRE TAA1 con-
structs a set of entities dominated by the Referen-
tial Anchor a (and a itself). If this set contains the
intended referent r, it is taken as the current utter-
ance context set. Else TAA1 moves up one level
of abstraction and adds the set of all child nodes to
the context set. This loop continues until r is in the
context set. At that point TAA1 stops and returns
the constructed context set (cf. Algorithm 1).
TAA1 is formulated to be neutral to the kind of
GRE algorithm that it is used for. It can be used
with the original Incremental Algorithm (Dale and
Reiter, 1995), augmented by a recursive call if a
relation to another entity is selected as a discrim-
inatory feature. It could in principle also be used
with the standard approach to GRE involving re-
lations (Dale and Haddock, 1991), but we agree
with Paraboni et al. (2007) that the mutually qual-
ified references that it can produce2 are not easily
resolvable if they pertain to circumstances where
a confirmatory search is costly (such as in large-
scale space). More recent approaches to avoid-
ing infinite loops when using relations in GRE
make use of a graph-based knowledge represen-
tation (Krahmer et al., 2003; Croitoru and van
Deemter, 2007). TAA1 is compatible with these
approaches, as well as with the salience based ap-
proach of (Krahmer and Theune, 2002).
</bodyText>
<footnote confidence="0.996537">
2An example for such a phenomenon is the expression
“the ball on the table” in a context with several tables and
several balls, but of which only one is on a table. Humans
find such REs natural and easy to resolve in visual scenes.
</footnote>
<equation confidence="0.670791285714286">
loc1 loc2 loc3
floor1_1 floor1_2
room1 room2
building1
loc4 (a) loc5
room3
1
2
floor2_1 floor2_2
room4 room5 (r)
loc6
building2
3
loc7 loc8
4
128
Algorithm 1 TAA1 (for reference generation)
Require: a = referential anchor; r = intended referent
Initialize context: C = {}
C = C ∪ topologicalChildren(a) ∪ {a}
if r ∈ C then
return C
else
Initialize: SUPERNODES = {a}
for each n ∈ SUPERNODES do
for each p ∈ topologicalParents(n) do
SUPERNODES = SUPERNODES ∪ {p}
C = C ∪ topologicalChildren(p)
</equation>
<figure confidence="0.907813">
end for
if r ∈ C then
return C
end if
end for
return failure
end if
Algorithm 2 TAA2 (for reference resolution)
Require: a = ref. anchor; desc(x) = description of referent
Initialize context: C = {}
Initialize possible referents: R = {}
</figure>
<equation confidence="0.8529276">
C = C ∪ topologicalChildren(a) ∪ {a}
R = desc(x) ∩ C
if R =6 {} then
return R
else
Initialize: SUPERNODES = {a}
for each n ∈ SUPERNODES do
for each p ∈ topologicalParents(n) do
SUPERNODES = SUPERNODES ∪ {p}
C = C ∪ topologicalChildren(p)
end for
R = desc(x) ∩ C
if R =6 {} then
return R
end if
</equation>
<subsectionHeader confidence="0.348961">
end for
</subsectionHeader>
<bodyText confidence="0.423435">
return failure
</bodyText>
<subsectionHeader confidence="0.746622">
end if
</subsectionHeader>
<bodyText confidence="0.998407277777778">
Resolving References to Elsewhere Analogous
to the GRE task, a conversational robot must be
able to understand verbal descriptions by its users.
In order to avoid overgenerating possible refer-
ents, we propose TAA2 (cf. Algorithm 2) which
tries to select an appropriate referent from a rel-
evant subset of the full knowledge base. It is ini-
tialized with a given semantic representation of the
referential expression, desc(x), in a format com-
patible with the knowledge base. Then, an appro-
priate entity satisfying this description is searched
for in the knowledge base. Similarly to TAA1,
the description is first matched against the current
context set C consisting of a and its child nodes. If
this set does not contain any instances that match
desc(x), TAA2 increases the context set along the
spatial abstraction axis until at least one possible
referent can be identified within the context.
</bodyText>
<sectionHeader confidence="0.996484" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99997225">
We have presented two algorithms for context de-
termination that can be used both for resolving and
generating REs in large-scale space.
We are currently planning a user study to evalu-
ate the performance of the TA algorithms. Another
important item for future work is the exact nature
of the spatial progression, modeled by “moving”
the referential anchor, in a situated dialogue.
</bodyText>
<sectionHeader confidence="0.998362" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9288185">
This work was supported by the EU FP7 ICT
Project “CogX” (FP7-ICT-215181).
</bodyText>
<sectionHeader confidence="0.996463" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99991175">
A. G. Cohn and S. M. Hazarika. 2001. Qualitative
spatial representation and reasoning: An overview.
Fundamenta Informaticae, 46:1–29.
M. Croitoru and K. van Deemter. 2007. A conceptual
graph approach to the generation of referring expres-
sions. In Proc. IJCAI-2007, Hyderabad, India.
R. Dale and N. Haddock. 1991. Generating referring
expressions involving relations. In Proc. of the 5th
Meeting of the EACL, Berlin, Germany, April.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the Gricean Maxims in the generation of re-
ferring expressions. Cognitive Science, 19(2):233–
263.
H. Horacek. 1997. An algorithm for generating ref-
erential descriptions with flexible interfaces. In
Proc. of the 35th Annual Meeting of the ACL and
8th Conf. of the EACL, Madrid, Spain.
J. Kelleher and G.-J. Kruijff. 2006. Incremental gener-
ation of spatial referring expressions in situated di-
alogue. In In Proc. Coling-ACL 06, Sydney, Aus-
tralia.
E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R.Kibble, editors, Information
Sharing: Givenness and Newness in Language Pro-
cessing. CSLI Publications, Stanford, CA, USA.
E. Krahmer, S. van Erk, and A. Verleg. 2003. Graph-
based generation of referring expressions. Compu-
tational Linguistics, 29(1).
B. Kuipers. 1977. Representing Knowledge of Large-
scale Space. Ph.D. thesis, Massachusetts Institute of
Technology, Cambridge, MA, USA.
I. Paraboni, K. van Deemter, and J. Masthoff. 2007.
Generating referring expressions: Making refer-
ents easy to identify. Computational Linguistics,
33(2):229–254, June.
H. Zender, O. Martinez Mozos, P. Jensfelt, G.-J. Krui-
jff, and W. Burgard. 2008. Conceptual spatial rep-
resentations for indoor mobile robots. Robotics and
Autonomous Systems, 56(6):493–502, June.
</reference>
<page confidence="0.998577">
129
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.955171">
<title confidence="0.9999185">A Situated Context Model for Resolution and Generation of Referring Expressions</title>
<author confidence="0.999962">Zender M Kruijff</author>
<affiliation confidence="0.99238">Language Technology Lab, German Research Center for Artificial Intelligence</affiliation>
<address confidence="0.975037">Saarbr¨ucken, Germany</address>
<email confidence="0.998402">gj,</email>
<abstract confidence="0.9992351">The background for this paper is the aim to build robotic assistants that can “naturally” interact with humans. One prerequisite for this is that the robot can correctly identify objects or places a user refers to, and produce comprehensible references itself. As robots typically act in environments that are larger than what is immediately perceivable, the problem arises how to identify the appropriate context, against which to resolve or produce a referring expression (RE). Existing algorithms for generating REs generally bypass this problem by assuming a given context. In this paper, we explicitly address this problem, proposing a method for context determination in large-scale space. We show how it can be applied both for resolving and producing REs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A G Cohn</author>
<author>S M Hazarika</author>
</authors>
<title>Qualitative spatial representation and reasoning: An overview. Fundamenta Informaticae,</title>
<date>2001</date>
<pages>46--1</pages>
<contexts>
<context position="8929" citStr="Cohn and Hazarika, 2001" startWordPosition="1459" endWordPosition="1462">ale Space Imagine the situation in Figure 1 did not take place somewhere on campus, but rather inside building 3B. Certainly the robot would not have said “the IT help desk is on the 1st floor in building 3B.” To avoid confusing the human, an utterance like “the IT help desk is on the 1st floor” would have been appropriate. Likewise, if the IT help desk happened to be located on another site of the university, the robot would have had to identify its location as being “on the 1st floor in building 3B on the new campus.” The hierarchical representation of space that people are known to assume (Cohn and Hazarika, 2001), reflects upon the choice of an appropriate context when producing REs. In the above example the physical and spatial situatedness of the dialogue participants play an important role in determining which related parts of space come into consideration as potential distractors. Another important observation concerns the verbal behavior of humans when talking about remote objects and places during a complex dialogue (i.e. more than just a question and a reply). Consider the following example dialogue: Person A: “Where is the exit?” Person B: “You first go down this corridor. Then you turn right.</context>
</contexts>
<marker>Cohn, Hazarika, 2001</marker>
<rawString>A. G. Cohn and S. M. Hazarika. 2001. Qualitative spatial representation and reasoning: An overview. Fundamenta Informaticae, 46:1–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Croitoru</author>
<author>K van Deemter</author>
</authors>
<title>A conceptual graph approach to the generation of referring expressions.</title>
<date>2007</date>
<booktitle>In Proc. IJCAI-2007,</booktitle>
<location>Hyderabad, India.</location>
<marker>Croitoru, van Deemter, 2007</marker>
<rawString>M. Croitoru and K. van Deemter. 2007. A conceptual graph approach to the generation of referring expressions. In Proc. IJCAI-2007, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>N Haddock</author>
</authors>
<title>Generating referring expressions involving relations.</title>
<date>1991</date>
<booktitle>In Proc. of the 5th Meeting of the EACL,</booktitle>
<location>Berlin, Germany,</location>
<contexts>
<context position="12050" citStr="Dale and Haddock, 1991" startWordPosition="1975" endWordPosition="1978">ext set. Else TAA1 moves up one level of abstraction and adds the set of all child nodes to the context set. This loop continues until r is in the context set. At that point TAA1 stops and returns the constructed context set (cf. Algorithm 1). TAA1 is formulated to be neutral to the kind of GRE algorithm that it is used for. It can be used with the original Incremental Algorithm (Dale and Reiter, 1995), augmented by a recursive call if a relation to another entity is selected as a discriminatory feature. It could in principle also be used with the standard approach to GRE involving relations (Dale and Haddock, 1991), but we agree with Paraboni et al. (2007) that the mutually qualified references that it can produce2 are not easily resolvable if they pertain to circumstances where a confirmatory search is costly (such as in largescale space). More recent approaches to avoiding infinite loops when using relations in GRE make use of a graph-based knowledge representation (Krahmer et al., 2003; Croitoru and van Deemter, 2007). TAA1 is compatible with these approaches, as well as with the salience based approach of (Krahmer and Theune, 2002). 2An example for such a phenomenon is the expression “the ball on th</context>
</contexts>
<marker>Dale, Haddock, 1991</marker>
<rawString>R. Dale and N. Haddock. 1991. Generating referring expressions involving relations. In Proc. of the 5th Meeting of the EACL, Berlin, Germany, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<title>Computational interpretations of the Gricean Maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263</pages>
<contexts>
<context position="3922" citStr="Dale and Reiter (1995)" startWordPosition="636" endWordPosition="639"> Language Generation, pages 126–129, Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics 126 do not address this issue here, but refer the interested reader to our recent work on multi-layered spatial maps for robots, bridging the gap between robot-centric and human-centric spatial representations (Zender et al., 2008). The other examples point out another important consideration: how much information does the human need to single out the intended referent among the possible entities that the robot could be referring to? According to the seminal work on GRE by Dale and Reiter (1995), one needs to distinguish whether the intended referent is already in the hearer’s focus of attention or not. This focus of attention can consist of a local visual scene (visual context) or a shared workspace (spatial context), but also contains recently mentioned entities (dialogue context). If the referent is already part of the current context, the GRE task merely consists of singling it out among the other members of the context, which act as distractors. In this case the generated RE contains discriminatory information, e.g. “the red ball” if several kinds of objects with different color</context>
<context position="5381" citStr="Dale and Reiter, 1995" startWordPosition="884" endWordPosition="887">wer supply in the equipment rack,” where “the equipment rack” is supposed to direct the hearers attention to the rack and its contents. In the following we propose an approach for context determination and extension that allows a mobile robot to produce and interpret REs to entities outside the current visual context. 2 Background Most GRE approaches are applied to very limited, visual scenes – so-called small-scale space. The domain of such systems is usually a small visual scene, e.g. a number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (Dale and Reiter, 1995; Horacek, 1997; Krahmer and Theune, 2002). Recently, Kelleher and Kruijff (2006) have presented an incremental GRE algorithm for situated dialogue with a robot about a table-top setting, i.e. also about small-scale space. In all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors. The intended referent is thus already in the hearer’s focus of attention. In contrast, robots typically act in large-scale space, i.e. space “larger than what can be perceived at once” (Kuipers, 1977). They need the ability to understand and produce re</context>
<context position="7590" citStr="Dale and Reiter (1995)" startWordPosition="1238" endWordPosition="1241">tuatedness. Their approach suffers from the shortcoming that spatial relationships are treated as oneplace attributes by their GRE algorithm. For example they transform the spatial containment relation that holds between a room entity and a building entity (“the library in the Cockroft building”) into a property of the room entity (BUILDING NAME = COCKROFT) and not a two-place relation (in(library,Cockroft)). Thus they avoid recursive calls to the algorithm, which would be needed if the intended referent is related to another entity that needs to be properly referred to. However, according to Dale and Reiter (1995), these related entities do not necessarily serve as discriminatory information. At least in large-scale space, in contrast to a document structure that is conceivably transparent to a reader, they function as attention-directing elements that are introduced to build up common ground by incrementally extending the hearer’s focus of attention. Moreover, representing some spatial relations as two-place predicates between two entities and some as oneplace predicates is an arbitrary decision. We present an approach for context determination (or extension), that imposes less restrictions on its kno</context>
<context position="11832" citStr="Dale and Reiter, 1995" startWordPosition="1937" endWordPosition="1940">resolution. Context Determination for GRE TAA1 constructs a set of entities dominated by the Referential Anchor a (and a itself). If this set contains the intended referent r, it is taken as the current utterance context set. Else TAA1 moves up one level of abstraction and adds the set of all child nodes to the context set. This loop continues until r is in the context set. At that point TAA1 stops and returns the constructed context set (cf. Algorithm 1). TAA1 is formulated to be neutral to the kind of GRE algorithm that it is used for. It can be used with the original Incremental Algorithm (Dale and Reiter, 1995), augmented by a recursive call if a relation to another entity is selected as a discriminatory feature. It could in principle also be used with the standard approach to GRE involving relations (Dale and Haddock, 1991), but we agree with Paraboni et al. (2007) that the mutually qualified references that it can produce2 are not easily resolvable if they pertain to circumstances where a confirmatory search is costly (such as in largescale space). More recent approaches to avoiding infinite loops when using relations in GRE make use of a graph-based knowledge representation (Krahmer et al., 2003;</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>R. Dale and E. Reiter. 1995. Computational interpretations of the Gricean Maxims in the generation of referring expressions. Cognitive Science, 19(2):233– 263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>An algorithm for generating referential descriptions with flexible interfaces.</title>
<date>1997</date>
<booktitle>In Proc. of the 35th Annual Meeting of the ACL and 8th Conf. of the EACL,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="5396" citStr="Horacek, 1997" startWordPosition="888" endWordPosition="889">ment rack,” where “the equipment rack” is supposed to direct the hearers attention to the rack and its contents. In the following we propose an approach for context determination and extension that allows a mobile robot to produce and interpret REs to entities outside the current visual context. 2 Background Most GRE approaches are applied to very limited, visual scenes – so-called small-scale space. The domain of such systems is usually a small visual scene, e.g. a number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (Dale and Reiter, 1995; Horacek, 1997; Krahmer and Theune, 2002). Recently, Kelleher and Kruijff (2006) have presented an incremental GRE algorithm for situated dialogue with a robot about a table-top setting, i.e. also about small-scale space. In all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors. The intended referent is thus already in the hearer’s focus of attention. In contrast, robots typically act in large-scale space, i.e. space “larger than what can be perceived at once” (Kuipers, 1977). They need the ability to understand and produce references to thi</context>
</contexts>
<marker>Horacek, 1997</marker>
<rawString>H. Horacek. 1997. An algorithm for generating referential descriptions with flexible interfaces. In Proc. of the 35th Annual Meeting of the ACL and 8th Conf. of the EACL, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kelleher</author>
<author>G-J Kruijff</author>
</authors>
<title>Incremental generation of spatial referring expressions in situated dialogue. In</title>
<date>2006</date>
<booktitle>In Proc. Coling-ACL 06,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="5462" citStr="Kelleher and Kruijff (2006)" startWordPosition="896" endWordPosition="899">o direct the hearers attention to the rack and its contents. In the following we propose an approach for context determination and extension that allows a mobile robot to produce and interpret REs to entities outside the current visual context. 2 Background Most GRE approaches are applied to very limited, visual scenes – so-called small-scale space. The domain of such systems is usually a small visual scene, e.g. a number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (Dale and Reiter, 1995; Horacek, 1997; Krahmer and Theune, 2002). Recently, Kelleher and Kruijff (2006) have presented an incremental GRE algorithm for situated dialogue with a robot about a table-top setting, i.e. also about small-scale space. In all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors. The intended referent is thus already in the hearer’s focus of attention. In contrast, robots typically act in large-scale space, i.e. space “larger than what can be perceived at once” (Kuipers, 1977). They need the ability to understand and produce references to things that are beyond the current visual and spatial context. In any</context>
</contexts>
<marker>Kelleher, Kruijff, 2006</marker>
<rawString>J. Kelleher and G.-J. Kruijff. 2006. Incremental generation of spatial referring expressions in situated dialogue. In In Proc. Coling-ACL 06, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Krahmer</author>
<author>M Theune</author>
</authors>
<title>Efficient contextsensitive generation of referring expressions.</title>
<date>2002</date>
<booktitle>Information Sharing: Givenness and Newness in Language Processing.</booktitle>
<editor>In K. van Deemter and R.Kibble, editors,</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="5423" citStr="Krahmer and Theune, 2002" startWordPosition="890" endWordPosition="893">re “the equipment rack” is supposed to direct the hearers attention to the rack and its contents. In the following we propose an approach for context determination and extension that allows a mobile robot to produce and interpret REs to entities outside the current visual context. 2 Background Most GRE approaches are applied to very limited, visual scenes – so-called small-scale space. The domain of such systems is usually a small visual scene, e.g. a number of objects, such as cups and tables, located in the same room), or other closed-context scenarios (Dale and Reiter, 1995; Horacek, 1997; Krahmer and Theune, 2002). Recently, Kelleher and Kruijff (2006) have presented an incremental GRE algorithm for situated dialogue with a robot about a table-top setting, i.e. also about small-scale space. In all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors. The intended referent is thus already in the hearer’s focus of attention. In contrast, robots typically act in large-scale space, i.e. space “larger than what can be perceived at once” (Kuipers, 1977). They need the ability to understand and produce references to things that are beyond the cur</context>
<context position="12581" citStr="Krahmer and Theune, 2002" startWordPosition="2064" endWordPosition="2067">le also be used with the standard approach to GRE involving relations (Dale and Haddock, 1991), but we agree with Paraboni et al. (2007) that the mutually qualified references that it can produce2 are not easily resolvable if they pertain to circumstances where a confirmatory search is costly (such as in largescale space). More recent approaches to avoiding infinite loops when using relations in GRE make use of a graph-based knowledge representation (Krahmer et al., 2003; Croitoru and van Deemter, 2007). TAA1 is compatible with these approaches, as well as with the salience based approach of (Krahmer and Theune, 2002). 2An example for such a phenomenon is the expression “the ball on the table” in a context with several tables and several balls, but of which only one is on a table. Humans find such REs natural and easy to resolve in visual scenes. loc1 loc2 loc3 floor1_1 floor1_2 room1 room2 building1 loc4 (a) loc5 room3 1 2 floor2_1 floor2_2 room4 room5 (r) loc6 building2 3 loc7 loc8 4 128 Algorithm 1 TAA1 (for reference generation) Require: a = referential anchor; r = intended referent Initialize context: C = {} C = C ∪ topologicalChildren(a) ∪ {a} if r ∈ C then return C else Initialize: SUPERNODES = {a} </context>
</contexts>
<marker>Krahmer, Theune, 2002</marker>
<rawString>E. Krahmer and M. Theune. 2002. Efficient contextsensitive generation of referring expressions. In K. van Deemter and R.Kibble, editors, Information Sharing: Givenness and Newness in Language Processing. CSLI Publications, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Krahmer</author>
<author>S van Erk</author>
<author>A Verleg</author>
</authors>
<title>Graphbased generation of referring expressions.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Krahmer, van Erk, Verleg, 2003</marker>
<rawString>E. Krahmer, S. van Erk, and A. Verleg. 2003. Graphbased generation of referring expressions. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kuipers</author>
</authors>
<title>Representing Knowledge of Largescale Space.</title>
<date>1977</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="5929" citStr="Kuipers, 1977" startWordPosition="976" endWordPosition="977">me room), or other closed-context scenarios (Dale and Reiter, 1995; Horacek, 1997; Krahmer and Theune, 2002). Recently, Kelleher and Kruijff (2006) have presented an incremental GRE algorithm for situated dialogue with a robot about a table-top setting, i.e. also about small-scale space. In all these cases, the context set is assumed to be identical to the visual scene that is shared between the interlocutors. The intended referent is thus already in the hearer’s focus of attention. In contrast, robots typically act in large-scale space, i.e. space “larger than what can be perceived at once” (Kuipers, 1977). They need the ability to understand and produce references to things that are beyond the current visual and spatial context. In any situated dialogue that involves entities beyond the current focus of attention, the task of extending the context becomes key. Paraboni et al. (2007) present an algorithm for context determination in hierarchically ordered domains, e.g. a university campus or a document structure. Their approach is mainly targeted at producing textual references to entities in written documents (e.g. figures, tables in book chapters). Consequently they do not address the challen</context>
</contexts>
<marker>Kuipers, 1977</marker>
<rawString>B. Kuipers. 1977. Representing Knowledge of Largescale Space. Ph.D. thesis, Massachusetts Institute of Technology, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Paraboni</author>
<author>K van Deemter</author>
<author>J Masthoff</author>
</authors>
<title>Generating referring expressions: Making referents easy to identify.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Paraboni, van Deemter, Masthoff, 2007</marker>
<rawString>I. Paraboni, K. van Deemter, and J. Masthoff. 2007. Generating referring expressions: Making referents easy to identify. Computational Linguistics, 33(2):229–254, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zender</author>
<author>O Martinez Mozos</author>
<author>P Jensfelt</author>
<author>G-J Kruijff</author>
<author>W Burgard</author>
</authors>
<title>Conceptual spatial representations for indoor mobile robots.</title>
<date>2008</date>
<journal>Robotics and Autonomous Systems,</journal>
<volume>56</volume>
<issue>6</issue>
<contexts>
<context position="3653" citStr="Zender et al., 2008" startWordPosition="591" endWordPosition="594">e descriptions when talking about things in the world. We Where is hh Where is the T Help desk IT help desk? It is t t is at &lt;45.56, -3.92, 10.45&gt; It is on the 1st It s on thefloor in building 1st floor in ding 3B. Proceedings of the 12th European Workshop on Natural Language Generation, pages 126–129, Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics 126 do not address this issue here, but refer the interested reader to our recent work on multi-layered spatial maps for robots, bridging the gap between robot-centric and human-centric spatial representations (Zender et al., 2008). The other examples point out another important consideration: how much information does the human need to single out the intended referent among the possible entities that the robot could be referring to? According to the seminal work on GRE by Dale and Reiter (1995), one needs to distinguish whether the intended referent is already in the hearer’s focus of attention or not. This focus of attention can consist of a local visual scene (visual context) or a shared workspace (spatial context), but also contains recently mentioned entities (dialogue context). If the referent is already part of t</context>
</contexts>
<marker>Zender, Mozos, Jensfelt, Kruijff, Burgard, 2008</marker>
<rawString>H. Zender, O. Martinez Mozos, P. Jensfelt, G.-J. Kruijff, and W. Burgard. 2008. Conceptual spatial representations for indoor mobile robots. Robotics and Autonomous Systems, 56(6):493–502, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>