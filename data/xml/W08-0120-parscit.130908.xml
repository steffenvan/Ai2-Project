<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000071">
<title confidence="0.9950315">
A Frame-Based Probabilistic Framework for Spoken Dialog Manage-
ment Using Dialog Examples
</title>
<author confidence="0.998659">
Kyungduk Kim, Cheongjae Lee, Sangkeun Jung and Gary Geunbae Lee
</author>
<affiliation confidence="0.999946">
Department of Computer Science and Engineering
Pohang University of Science &amp; Technology (POSTECH)
</affiliation>
<address confidence="0.844139">
San 31, Hyoja-Dong, Pohang, 790-784, Republic of Korea
</address>
<email confidence="0.933745">
{getta, lcj80, hugman, gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.982599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922411764706">
This paper proposes a probabilistic framework
for spoken dialog management using dialog
examples. To overcome the complexity prob-
lems of the classic partially observable Mar-
kov decision processes (POMDPs) based
dialog manager, we use a frame-based belief
state representation that reduces the complexi-
ty of belief update. We also used dialog ex-
amples to maintain a reasonable number of
system actions to reduce the complexity of the
optimizing policy. We developed weather in-
formation and car navigation dialog system
that employed a frame-based probabilistic
framework. This framework enables people to
develop a spoken dialog system using a prob-
abilistic approach without complexity prob-
lem of POMDP.
</bodyText>
<sectionHeader confidence="0.992535" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972111111111">
A robust dialog manager is an essential part of
spoken dialog systems, because many such sys-
tems have failed in practice due to errors in speech
recognition. Speech recognition errors can be
propagated to spoken language understanding
(SLU), so the speech input must be considered er-
ror-prone from a standpoint of dialog management.
Therefore robust dialog managers are necessary to
develop practical spoken dialog systems.
One approach to dialog management uses the
partially observable Markov decision process
(POMDP) as a statistical framework, because this
approach can model the uncertainty inherent in
human-machine dialog (Doshi and Roy, 2007).
The dialog manager uses a probabilistic, rather
than deterministic, approach to manage dialog. As
more information becomes available, the dialog
manager updates its belief states. A POMDP-based
dialog manager can learn the optimized policy that
maximizes expected rewards by reinforcement
learning.
But applying classic POMDP to a practical di-
alog system incurs a scalability problem. The com-
putational complexity of updating belief states and
optimizing the policy increases rapidly with the
size of the state space in a slot-filling dialog task.
To solve this scalability problem, the method of
compressing states or mapping the original state
space to summarized space can be used (Williams
and Young, 2006; Roy et al.,2005), but these algo-
rithms tend to approximate the state space exces-
sively. The complexity problem of POMDP comes
from updating beliefs that are out of the user’s in-
tention, and from calculating the reward of system
actions that do not satisfy user’s objective.
In this paper, we propose a new probabilistic
framework for spoken dialog management using
dialog examples. We adopted a frame-based belief
state representation to reduce the complexity of
belief update. Furthermore, we used an example-
based approach to generate only a reasonable
number of system action hypotheses in a new
framework. We developed a dialog system by us-
ing our new framework in weather information
service and car navigation service.
</bodyText>
<note confidence="0.69364375">
120
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 120–127,
Columbus, June 2008. c�2008 Association for Computational Linguistics
2 Overview 3 Frame-based Belief State Representation
</note>
<bodyText confidence="0.99975975">
We try to address two problems of applying
POMDP to slot-filling dialog management. 1)
Computational complexity of belief update: it is
difficult to maintain and update all belief states at
every turn of dialog since there are too many di-
alog states in slot-filling dialog tasks. 2) Computa-
tional complexity of policy optimizing: optimizing
complexity depends on both the space size of di-
alog states, and the number of available machine
actions. In slot-filling dialog tasks, a system action
can have various slot values so that the system
needs to choose an action among a large number of
action hypotheses.
In our new probabilistic framework (Figure 1),
we try to solve these problems. Our approach uses
1) the frame-based belief state representation to
solve the computational complexity problem of
belief update and 2) the dialog examples to gener-
ate action hypotheses to solve the computational
complexity of policy optimizing by reducing the
number of system action hypotheses. First, the sys-
tem groups belief states dynamically using frame-
based belief state representation according to us-
er’s utterance and its SLU result. Then the system
uses an example-based approach to generate only
system action hypotheses that are suitable for cur-
rent belief states. If there are too many hypotheses
for calculating expected utility, the system prunes
them away until only a reasonable number of hy-
potheses remains. The following describes the de-
tails of each system’s component and the dialog
managing process.
</bodyText>
<subsectionHeader confidence="0.441738">
System action
</subsectionHeader>
<figureCaption confidence="0.982181">
Figure 1. Overview of the system operation. Bold ar-
rows indicate the control flow. Thin arrows indicate the
data flow.
</figureCaption>
<bodyText confidence="0.999917125">
We assumed that the machine’s internal represen-
tation of the dialog state sm consists of three com-
ponents: user’s goal su, user’s last action au and
dialog history sd. This section briefly describes the
basic introduction of POMDP framework and ex-
plains each component of machine’s internal state
in the standpoint of our frame-based probabilistic
framework.
</bodyText>
<subsectionHeader confidence="0.958072">
3.1 POMDP for spoken dialog management
</subsectionHeader>
<bodyText confidence="0.9994295">
A POMDP is defined as a tuple that consists of six
substates: (S, A, P, R, Ω, O) where S is a set of
state, A is a set of action, P is a transition proba-
bility P(s’|s,a), R is a reward function R(s,a,s’), Ω
is a set of observation and O is an observation
model P(o|s,a). The current state is not determinis-
tic in a POMDP framework while it is determined
as a specific state in a Markov decision process
(MDP) framework. In a POMDP, the probability
distribution over all states s∈S, which is referred
as a belief state b(s), is maintained instead of de-
terministic state. At each time instant t, the system
chooses an action a∈A, and this causes the system
to move from current state s to next state s’ with
the transition probability P(s’ |s,a). Then, the sys-
tem is granted a reward R(s,a) while the system
receives an observation o with probability of
P(o|s’,a). The system computes the belief state in
the next time instance b’(s’) as a following:
where k is a normalizing factor. This process is
referred as belief update.
Optimizing a POMDP policy is a process of
finding a mapping function from belief states to
actions that maximizes the expected reward. The
system should compute a value function over be-
lief spaces to find optimized actions. However,
unlike as in a MDP, each value in a POMDP is a
function of an entire probability distribution and
belief spaces are very complex, so that a POMDP
has a scale problem of computing the exact value
function.
A POMDP for spoken dialog system is well
formulated in (Williams and Young, 2007). First, a
state s can be factored to three substates: (su, au, sd)
</bodyText>
<figure confidence="0.978856333333333">
Frame-based Belief
State Representation
User’s Utterance
SLU Result
Calculating
Utilities
User’s Intention,
Semantic Frame,
Dialog History
Generating
Hypotheses
Pruning
Hypotheses
Lexico-semantic
Similarity
Dialog
Example DB
121
</figure>
<bodyText confidence="0.999779166666667">
where su is a user goal state, au is a user action, and
sd is a dialog history. A system action am and user
action au can be cast as action a and observation o
respectively. With some independence assumption
between variables, the belief update equation can
be rewritten as following:
</bodyText>
<equation confidence="0.93937725">
  
k P a a P a s a
( ~  |) (  |, )
 
</equation>
<figure confidence="0.857185352941176">
u u u u m
 P(su  |su , am)  
b s b s a s
     
( ) ( , ,

au
s s
u d
b s a s
( , ,
  
u u d
P s a
( |
 
d u
</figure>
<bodyText confidence="0.9999585">
where is an automatic speech recognizer (ASR)
and SLU recognition result of user action. In our
framework, belief update is done based on this eq-
uation. But applying this directly to a spoken di-
alog system can have a problem because the
probabilities used in the equation are hard to esti-
mate from the corpus due to the data sparseness.
Therefore, we adopted Young’s (2007) belief up-
date formula that is simplified from the original
equation.
</bodyText>
<subsectionHeader confidence="0.998917">
3.2 User goal state
</subsectionHeader>
<bodyText confidence="0.999903388888889">
In a slot-filling dialog system, the user’s goal can
be represented as a fully-filled frame in which all
slots of the frame contain values specified by the
user’s intention. Therefore, if a dialog system has
W slots and each slot can have a value among V
candidates, then VW user goals can be represented
as frames. This means that the number of user
goals is related exponentially to the number of
slots. This number of user goals is intractable in
practical dialog systems.
Therefore, a method is needed to reduce the size
of the state space rather than maintaining all belief
states. To do this, we developed a frame-based be-
lief state representation in which the system dy-
namically groups set of equivalent states to a high-
level frame state. Frame state, which is a similar
concept to the partition in the hidden information
state (HIS) approach (Young et al, 2007)
represents the indistinguishable classes of user’s
goals. The biggest difference between frame-based
representation and partition-based representation is
that the former uses only user input to split the
frame state, whereas the latter uses the user input
and external ontology rules such as a prior proba-
bility for belief of split partition. Therefore, the
frame-based representation has relatively high do-
main portability because it does not need that kind
of external domain dependent information.
In the frame-based belief state representation, a
partially-filled frame state represents the current
user’s goal state for which the unfilled slot can be
filled in the future, while a fully-filled frame state
represents a complete user’s goal state. Figure 2
describes an example of the subsumption relation-
ship between partially filled frames and fully filled
frames.
</bodyText>
<figureCaption confidence="0.58939025">
Figure 2. Subsumption relationship between partially
filled frame and fully filled frame. The left frame is par-
tially filled and three frames in the right side are fully
filled.
</figureCaption>
<bodyText confidence="0.998697777777778">
At the start of a dialog, all states belong to the
root frame state f0. As the dialog progresses, this
root frame state is split into smaller frame states
whenever the value of a slot is filled by the user’s
input (Figure 3). First, if the user’s input [A=a]
fills the slot of the root frame state f0, then it splits
into two frame states: f1, which includes all user
goal states with the slot A having ‘a’ as a value;
and {f0-f1}, which is the relative complement of f1.
Next, if the user’s input [B=b] is entered to the
system, each frame f1 and {f0-f1} is split into small-
er frame states. The system updates not all belief
states but only the beliefs of the frame states, so
that the computational complexity remains rela-
tively small.
If each user’s goal has uniform distribution, the
belief of frame state b(f) can be calculated as fol-
lows:
</bodyText>
<figure confidence="0.998304233333333">
b W  # of user goals contained in frame f
# of all user goals
This can be computed as follows:

, sd , am )

u u d
)
,
)
122
Frame Splitting State Space
User Input
A = a
User Input
User Input
t0
t1
t2
2
b({{fof}f2}) 502
{{f0 - f1} - f2}
b(f2) 502
f2
(B = b)
b({f0f})49
Root
Frame State
f0
50
49
 
({ })50
13 2
{f1 – f3}
(A = a)
b(f0)  1
f1
(A = a)
1
b(f)  502
f3
(A = a)
(B = b)
b(fi) 1
50
f3
A = a
B = b
{f1 – f3}
A = a
B != b
A = a A != a
f0
{{f0 - f1} - f2}
f2
A != a
B = b
A != a
B != b
</figure>
<figureCaption confidence="0.9974915">
Figure 3. Splitting frame states and their beliefs with three user’s inputs. f0, f1, f2, ... denote frame states and b(f)
means the belief of frame state f. A, B, C are the slot labels and a, b, c are the respective values of these slots.
</figureCaption>
<equation confidence="0.924409">
B = b
{f0 - f1}
</equation>
<bodyText confidence="0.999819166666667">
where Sfillea means the set of slots that are filled by
the user’s input in frame state f, and SnotFillea means
the set of empty slots. Vs denotes the set of availa-
ble values for slot s, and Vs’ stands for the set of
values for slot s that were specified by the user in
other frame states.
</bodyText>
<subsectionHeader confidence="0.891483">
3.3 User action
</subsectionHeader>
<equation confidence="0.88605">
C = c
</equation>
<bodyText confidence="0.9997659">
The SLU result of current user&apos;s utterance is used
for the user action. The result frame of SLU con-
sists of a speech act, a main goal, and several
named-entity component slots for each user&apos;s utter-
ance. The speech act stands for the surface-level
speech act per single utterance and the main goal
slot is assigned from one of the predefined classes
which classify the main application actions in a
specific domain such as “search the weather
(SEARCH_WEATHER)” or “search the tempera-
ture (SEARCH _TEMPERATURE)” in the weather
information service domain. The tasks for filling
the named-entity component slots, such as, name
of the city, name of the state, are viewed as a se-
quence labeling task. The Figure 4 shows some
examples of predefined classes for SLU semantic
frame in weather information service dialog system
Our SLU module was developed based on the
concept spotting approach, which aims to extract
only the essential information for predefined mean-
</bodyText>
<equation confidence="0.973593">
f1 { f0 - f1}
</equation>
<bodyText confidence="0.8220782">
ing representation slots, and was implemented by
applying a conditional random field model (Lee et
al., 2007).
Figure 4 Example predefined classes for semantic frame
of SLU in weather information service dialog system.
</bodyText>
<subsectionHeader confidence="0.991669">
3.4 Dialog history
</subsectionHeader>
<bodyText confidence="0.9999456">
Similar to the traditional frame-based dialog
management approach, a frame can represent the
history of the dialog. The difference between the
traditional frame-based dialog manager and our
framework is that traditional frame-based dialog
</bodyText>
<page confidence="0.874948">
123
</page>
<bodyText confidence="0.9992788">
manager maintains only one frame while our
framework can maintain multiple dialog hypothes-
es. Moreover, each hypothesis in our framework
can have a probability as in the belief state of the
classic POMDP.
</bodyText>
<sectionHeader confidence="0.9940345" genericHeader="method">
4 Example-based System Action Genera-
tion
</sectionHeader>
<subsectionHeader confidence="0.663157">
4.1 Example-based system action hypothesis
generation
</subsectionHeader>
<bodyText confidence="0.999760055555556">
It is impossible to consider all of the system ac-
tions as hypotheses because the number of possible
actions is so large. We used an example-based ap-
proach to generate a reasonable number of system
action hypotheses as hinted in (Lee et al., 2006). In
this approach, the system retrieves the best dialog
example from dialog example database (DEDB)
which is semantically indexed from a dialog cor-
pus. To query a semantically close example for the
current situation, the system uses the user’s inten-
tion (speech act and main goal), semantic frame
(component slots) and discourse history as search
key constraints (Lee et al., 2006). These search
keys can be collected with SLU output (e.g., user
intention and semantic frame) and discourse histo-
ry in a dialog manager. Figure 5 describes an ex-
ample of search key for DEDB on a weather
information service system.
</bodyText>
<table confidence="0.8720605">
User’s utterance What will the temperature be tomorrow?
Weather_Type Time_Date
Search key Speech Act = wh_question
constraints Main Goal = search_temperature
WEATHER_TYPE = 1 (filled)
TIME_DATE = 1 (filled)
LOC_CITY = 0 (unfilled)
LOC_STATE = 0 (unfilled)
Lexico-semantic What will the [WEATHER_TYPE] be
Input [TIME_DATE]?
</table>
<figureCaption confidence="0.987649">
Figure 5. Example search key constraints for dialog
example database.
</figureCaption>
<bodyText confidence="0.999777346153846">
For each frame state f1, ..., fn, the system gene-
rates one or more system action hypotheses by
querying the DEDB respectively. Queried actions
may inconsistent with the current frame state be-
cause the situation of indexed dialog examples
may different from current dialog situation. There-
fore, the system maps the contents of dialog exam-
ple to information of current frame state. Slot
values of frame state and information from content
database (e.g., weather information database) are
used for making the action consistent. If the system
retrieves more than a threshold number of system
action hypotheses using the search key constrains,
then the system should prune away dialog exam-
ples to maintain only a reasonable number of hypo-
theses. We used lexico-semantic similarity
between the user utterance and the retrieved exam-
ples to limit the number of hypotheses. To measure
the lexico-semantic similarity, we first replace the
slot values in the user utterance by its slot names to
generate lexico-semantic input, and calculate the
normalized edit distance between that input and
retrieved examples (Figure 5). In the normalized
edit distance, we defined following cost function
C(i,j) to give a weight to the term which is re-
placed by its slot name.
</bodyText>
<equation confidence="0.99881575">
�0 if w1, i = w2,j
C i j = � I
( , ) 1 if w1, i#w2, j and W1, i , w2,j 0 Sslot_name
I11.5 if w1, i # w2, j and w1, i, w2,j E Sslot_name
</equation>
<bodyText confidence="0.999988055555556">
where w1,i is ith word of user’s utterance, w2,j is jth
word of dialog example’s utterance, and Sslot_name is
the set of slot names. According to the lexico-
semantic similarity, the system appends the top Nh-
ranked hypotheses to the final action hypotheses
(where Nh is the rank threshold).
Many existing systems used heuristics or rule-
based approaches to reduce the number of system
action hypotheses (Young et al., 2007). But these
methods are not flexible enough to handle all di-
alog flows because a system developer should de-
sign new heuristics or rules whenever the system
needs to support a new kind of dialog flow. The
example-based approach, on the contrary, can in-
stantly refine the control of dialog flows by adding
new dialog examples. This is a great advantage
when a system developer wants to change or refine
a dialog control flow.
</bodyText>
<subsectionHeader confidence="0.999521">
4.2 Calculating Expected Utilities
</subsectionHeader>
<bodyText confidence="0.999996">
We adopted the principle of maximum expected
utility to determine the optimized system actions
among the hypotheses (Paek and Horvitz, 2004).
</bodyText>
<equation confidence="0.973581444444444">
124
a*n = EU a �
a
= argmax E P(H = h  |�)u(a, h)
argmax (  |)
a h
h
= argmax ( ) ( , )
E b h u a h
</equation>
<bodyText confidence="0.999965666666667">
where � denotes all information about the envi-
ronment, u(a,h) means the utility of taking an ac-
tion when the internal state of the machine is h,
which consists of three substates, (f, au, sd) : f is a
frame state, au is a user’s last action, and sd is a
dialog history. The utility function u(a,h) can be
specific to each application. We defined a
handcrafted utility function to calculate the ex-
pected utility.
</bodyText>
<sectionHeader confidence="0.996847" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999867125">
We performed two evaluations. 1) Real user evalu-
ation: we measured the user satisfaction with vari-
ous factors by human. 2) Simulated user
evaluation: we implemented user simulator to
measure the system performance with a large
number of dialogs. We built dialog corpora in two
domains: weather information service and car na-
vigation.
</bodyText>
<subsectionHeader confidence="0.998657">
5.1 Real user evaluation
</subsectionHeader>
<bodyText confidence="0.999969580645161">
We built a dialog corpus in weather information
service to measure the performance of the dialog
system using our approach by real user evaluation.
This corpus consists of 99 dialogs with 503 user
utterances (turns). User’s utterances were anno-
tated with the semantic frame including speech
acts, main goal and component slots for training
the SLU module and indexing the DEDB.
To evaluate the preliminary performance, four
test volunteers among computer science people
evaluated our dialog system with five different
weather information-seeking tasks. The volunteers
typed their utterances with a keyboard rather than
using a real ASR because it is hard to control the
WER. We employed a simulated ASR error chan-
nel by generating random errors to evaluate the
performance of dialog management under various
levels of WER. We will explain the details of our
ASR channel simulator in Section 5.2. The WER is
controlled by this ASR channel simulator while the
volunteers were interacting with computer. To
measure the user perception of task completion
rate (TCR), the volunteers evaluated the system’s
response in each dialog to measure the success turn
rate (STR) and decided whether the entire dialog
was successful or not. We evaluated the perfor-
mance of our dialog system based on criteria out-
lined in (Litman and Pan, 2004) by measuring user
satisfaction, which is defined with a linear combi-
nation of three measures: TCR, Mean Recognition
Accuracy (MRA), and STR.
</bodyText>
<subsectionHeader confidence="0.465105">
User Satisfaction = αTCR +,BSTR + yMRA
</subsectionHeader>
<bodyText confidence="0.919998285714286">
In our evaluation, we set α, ,B and y to 1/3, so
that the maximum value of the user satisfaction is
one.
Figure 6 Dialog system performance with various word
error rates in weather information seeking tasks. Dotted
line is TCR; dashed line is STR; solid line is user satis-
faction.
TCR, STR and user satisfaction decreased with
WER. User satisfaction has relatively high value
when the WER is smaller than 20% (Figure 6). If
the WER is equal or over 20%, user satisfaction
has small value because the TCR decreases rapidly
in this range.
Generally, TCR has a higher value than STR,
because although a dialog turn may fail, users still
have a chance to use other expressions which can
be well recognized by the system. As a result of
this, even when some dialog turns fail, the task can
be completed successfully.
TCR decreases rapidly when WER ≥20%.
When WER is high, the probability of losing the
</bodyText>
<page confidence="0.7899">
125
</page>
<bodyText confidence="0.9998875">
information in a user utterance is also large. Espe-
cially, if words contain important meaning, i.e.,
values of component slots in SLU, it is difficult for
the system to generate a proper response.
STR is 0.83 when WER is zero, i.e., although all
user inputs are correctly recognized, the system
sometimes didn’t generate proper outputs. This
failure can be caused by SLU errors or malfunction
of the dialog manager. SLU errors can be propa-
gated to the dialog manager, and this leads the sys-
tem to generate a wrong response because SLU
results are inputs of dialog manger.
If the WER is 20%, user satisfaction is relatively
small because TCR decreases rapidly in this range.
This means that our approach is useful in a system
devoted to providing weather information, and is
relatively robust to speech errors if the WER is less
than 20%.
</bodyText>
<subsectionHeader confidence="0.997783">
5.2 Simulated user evaluation
</subsectionHeader>
<bodyText confidence="0.999988619047619">
We built another dialog corpus in car navigation
service to measure the performance of the dialog
system by simulated user evaluation. This corpus
consists of 123 dialogs with 510 user utterances
(turns). The SLU result frame of this corpus has 7
types of speech acts, 8 types of main goals, and 5
different component slots.
The user simulator and ASR channel simulator has
been used for evaluating the proposed dialog man-
agement framework. The user simulator has two
components: an Intention Simulator and a Surface
Simulator. The Intention Simulator generates the
next user intention given current discourse context,
and the Surface Simulator generates user sentence
to express the generated intention.
ASR channel simulator simulates the speech
recognition errors including substitution, deletion,
and insertions errors. It uses the phoneme confu-
sion matrix to estimate the probability distribution
for error simulation. ASR channel simulator dis-
torts the generated user utterance from Surface Si-
mulator. By simulating user intentions, surface
form of user sentence and ASR channel, we can
test the robustness of the proposed dialog system in
both speech recognition and speech understanding
errors.
We defined a final state of dialog to automati-
cally measure TCR of a simulated dialog. If a di-
alog flow reaches the final state, the evaluator
regards that the dialog was successfully completed.
TCRs and average dialog lengths were measured
under various WER conditions that were generated
by ASR channel simulator. Until the SLU result is
an actual input of the dialog manager, we also
measured the SLU accuracy. If a SLU result is
same as a user’s intention of the Intention Simula-
tor, then the evaluator considers that the result is
correct. Unlike in the real user evaluation, the di-
alog system could be evaluated with relatively
large amount of simulated dialogs in the simulated
user evaluation. 5000 simulated dialogs were gen-
erated for each WER condition.
</bodyText>
<figureCaption confidence="0.9899885">
Figure 7 TCR, SLU accuracy, and average dialog length
of the dialog system under various WER conditions.
</figureCaption>
<bodyText confidence="0.999848">
We found that the SLU accuracy and TCR li-
nearly decreased with the WER. Similar in the
human evaluation, TCR is about 0.9 when WER is
zero, and it becomes below 0.7 when WER is
higher than 20%. Average dialog length, on con-
trary, increased with WER, and it has similar val-
ues when WER is less than 10% although it
increased relatively rapidly when WER is higher
than 15%.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99997125">
This paper proposed a new probabilistic method to
manage the human-machine dialog by using the
frame-state belief state representation and the ex-
ample-based system action hypothesis generation.
The frame-based state representation reduces the
computational complexity of belief update by
grouping the indistinguishable user goal states.
And the system generates the system action hypo-
</bodyText>
<page confidence="0.770658">
126
</page>
<bodyText confidence="0.999981">
theses with the example-based approach in order to
refine the dialog flows easily. In addition, this ap-
proach employed the POMDP formalism to main-
tain belief distribution over dialog states so that the
system can be robust to speech recognition errors
by considering the uncertainty of user’s input.
A prototype system using our approach has been
implemented and evaluated by real and simulated
user. According to the preliminary evaluation, our
framework can be a useful approach to manage a
spoken dialog system.
We plan to progress the research on adopting a
formalized online search to determine the optimal
system action (Ross and Chaib-draa, 2007). With
the online searching, system doesn’t need to be-
have the useless computation because this ap-
proach searches only possible path. We expect that
this property of the online searching show the syn-
ergetic effect on dialog management if it combines
with example-based approach.
Similar to example-based approach, the case-
based reasoning approach (Eliasson, 2006) can be
helpful for our future research. Some properties
such as using previous cases to process current
case can be shared with our approach. We think
that some other properties including the concept of
online learning can be useful for making our ap-
proach concrete
</bodyText>
<sectionHeader confidence="0.997137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997715">
This research was supported by the MKE (Min-
istry of Knowledge Economy), Korea, under the
ITRC (Information Technology Research Center)
support program supervised by the IITA (Institute
for Information Technology Advancement) (IITA-
2008-C1090-0801-0045)
</bodyText>
<sectionHeader confidence="0.994293" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99994614">
Changki Lee, Jihyun Eun, Minwoo Jeong, and Gary
Geunbae Lee, Y. Hwang, M. Jang, “A multi-strategic
concept-spotting approach for robust understanding
of spoken Korean,” ETRI Journal, vol. 29, No.2, pp.
179-188, 2007.
Cheongjae Lee, Sangkeun Jung, Jihyun Eun, Minwoo
Jeong and Gary Geunbae Lee, “A situation-based di-
alogue management using dialogue examples,” in
Proceedings of International conference on Acoustics,
Speech, and Signal Processing, Toulouse, 2006.
Diane J. Litman and Shimei Pan, “Empirically evaluat-
ing an adaptable spoken dialogue system,” in Pro-
ceedings of the 8th International Conference on
Spoken Language Processing, pp. 2145-2148, 2004.
Finale Doshi and Nicholas Roy, “Efficient Model
Learning for Dialog Management,” in Proceeding of
the ACM/IEEE international conference on Human-
robot interaction, Washington DC, 2007.
Jason D. Williams and Steve Young, &amp;quot;Scaling POMDPs
for dialog management with composite summary
point-based value iteration (CSPBVI),&amp;quot; in Proceed-
ings of AAAI Workshop on Statistical and Empirical
Approaches for Spoken Dialogue Systems, Boston,
2006.
Jason D. Williams and Steve Young, &amp;quot; Partially Observ-
able Markov Decision Processes for Spoken Dialog
Systems.&amp;quot; Computer Speech and Language 21(2):
231-422, 2007
Karolina Eliasson, “The Use of Case-Based Reasoning
in a Human-Robot Dialog System”, Licentiate of
Engineering Thesis of Linköping Institute of Tech-
nology at Linköping University, 2006
Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun,
“Finding approximate pomdp solutions through be-
lief compression,” Journal of Artificial Intelligence
Research, vol. 23, pp.1–40, 2005.
Sptéphane Ross, Brahim Chaib-draa, “AEMS: An Any-
time Online Search Algorithm for Approximate Poli-
cy Refinement in Large POMDPs”, in Proceedings
of the 20th International Joint Conference on Artifi-
cial Intelligence, 2007
Steve Young, Jost Schatzmann, Karl Weilhammer and
Hui Ye, &amp;quot;The hidden information state approach to
dialog management,&amp;quot; in Proceedings of International
Conference on Acoustics, Speech, and Signal
Processing, Honolulu, 2007.
Tim Paek and Eric Horvitz, “Optimizing automated call
routing by integrating spoken dialog models with
queuing models,” in Proceedings of HLT-NAACL, pp.
41-48, Boston, 2004.
</reference>
<page confidence="0.86745">
127
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.862161">
<title confidence="0.994275">Frame-Based Probabilistic Framework for Spoken Dialog ment Using Dialog Examples</title>
<author confidence="0.992117">Lee Kim</author>
<author confidence="0.992117">Jung</author>
<author confidence="0.992117">Geunbae</author>
<affiliation confidence="0.9999385">Department of Computer Science and Pohang University of Science &amp; Technology</affiliation>
<address confidence="0.998257">San 31, Hyoja-Dong, Pohang, 790-784, Republic of</address>
<email confidence="0.932666">getta@postech.ac.kr</email>
<email confidence="0.932666">lcj80@postech.ac.kr</email>
<email confidence="0.932666">hugman@postech.ac.kr</email>
<email confidence="0.932666">gblee@postech.ac.kr</email>
<abstract confidence="0.996732">This paper proposes a probabilistic framework for spoken dialog management using dialog examples. To overcome the complexity problems of the classic partially observable Markov decision processes (POMDPs) based dialog manager, we use a frame-based belief state representation that reduces the complexity of belief update. We also used dialog examples to maintain a reasonable number of system actions to reduce the complexity of the optimizing policy. We developed weather information and car navigation dialog system that employed a frame-based probabilistic framework. This framework enables people to develop a spoken dialog system using a probabilistic approach without complexity problem of POMDP.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Changki Lee</author>
<author>Jihyun Eun</author>
<author>Minwoo Jeong</author>
<author>Gary Geunbae Lee</author>
<author>Y Hwang</author>
<author>M Jang</author>
</authors>
<title>A multi-strategic concept-spotting approach for robust understanding of spoken Korean,”</title>
<date>2007</date>
<journal>ETRI Journal,</journal>
<volume>29</volume>
<pages>179--188</pages>
<contexts>
<context position="13083" citStr="Lee et al., 2007" startWordPosition="2256" endWordPosition="2259">earch the temperature (SEARCH _TEMPERATURE)” in the weather information service domain. The tasks for filling the named-entity component slots, such as, name of the city, name of the state, are viewed as a sequence labeling task. The Figure 4 shows some examples of predefined classes for SLU semantic frame in weather information service dialog system Our SLU module was developed based on the concept spotting approach, which aims to extract only the essential information for predefined meanf1 { f0 - f1} ing representation slots, and was implemented by applying a conditional random field model (Lee et al., 2007). Figure 4 Example predefined classes for semantic frame of SLU in weather information service dialog system. 3.4 Dialog history Similar to the traditional frame-based dialog management approach, a frame can represent the history of the dialog. The difference between the traditional frame-based dialog manager and our framework is that traditional frame-based dialog 123 manager maintains only one frame while our framework can maintain multiple dialog hypotheses. Moreover, each hypothesis in our framework can have a probability as in the belief state of the classic POMDP. 4 Example-based System </context>
</contexts>
<marker>Lee, Eun, Jeong, Lee, Hwang, Jang, 2007</marker>
<rawString>Changki Lee, Jihyun Eun, Minwoo Jeong, and Gary Geunbae Lee, Y. Hwang, M. Jang, “A multi-strategic concept-spotting approach for robust understanding of spoken Korean,” ETRI Journal, vol. 29, No.2, pp. 179-188, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cheongjae Lee</author>
<author>Sangkeun Jung</author>
<author>Jihyun Eun</author>
</authors>
<title>Minwoo Jeong and Gary Geunbae Lee, “A situation-based dialogue management using dialogue examples,” in</title>
<date>2006</date>
<booktitle>Proceedings of International conference on Acoustics, Speech, and Signal Processing,</booktitle>
<location>Toulouse,</location>
<contexts>
<context position="14001" citStr="Lee et al., 2006" startWordPosition="2398" endWordPosition="2401">g manager and our framework is that traditional frame-based dialog 123 manager maintains only one frame while our framework can maintain multiple dialog hypotheses. Moreover, each hypothesis in our framework can have a probability as in the belief state of the classic POMDP. 4 Example-based System Action Generation 4.1 Example-based system action hypothesis generation It is impossible to consider all of the system actions as hypotheses because the number of possible actions is so large. We used an example-based approach to generate a reasonable number of system action hypotheses as hinted in (Lee et al., 2006). In this approach, the system retrieves the best dialog example from dialog example database (DEDB) which is semantically indexed from a dialog corpus. To query a semantically close example for the current situation, the system uses the user’s intention (speech act and main goal), semantic frame (component slots) and discourse history as search key constraints (Lee et al., 2006). These search keys can be collected with SLU output (e.g., user intention and semantic frame) and discourse history in a dialog manager. Figure 5 describes an example of search key for DEDB on a weather information se</context>
</contexts>
<marker>Lee, Jung, Eun, 2006</marker>
<rawString>Cheongjae Lee, Sangkeun Jung, Jihyun Eun, Minwoo Jeong and Gary Geunbae Lee, “A situation-based dialogue management using dialogue examples,” in Proceedings of International conference on Acoustics, Speech, and Signal Processing, Toulouse, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane J Litman</author>
<author>Shimei Pan</author>
</authors>
<title>Empirically evaluating an adaptable spoken dialogue system,”</title>
<date>2004</date>
<booktitle>in Proceedings of the 8th International Conference on Spoken Language Processing,</booktitle>
<pages>2145--2148</pages>
<contexts>
<context position="19629" citStr="Litman and Pan, 2004" startWordPosition="3345" endWordPosition="3348">or channel by generating random errors to evaluate the performance of dialog management under various levels of WER. We will explain the details of our ASR channel simulator in Section 5.2. The WER is controlled by this ASR channel simulator while the volunteers were interacting with computer. To measure the user perception of task completion rate (TCR), the volunteers evaluated the system’s response in each dialog to measure the success turn rate (STR) and decided whether the entire dialog was successful or not. We evaluated the performance of our dialog system based on criteria outlined in (Litman and Pan, 2004) by measuring user satisfaction, which is defined with a linear combination of three measures: TCR, Mean Recognition Accuracy (MRA), and STR. User Satisfaction = αTCR +,BSTR + yMRA In our evaluation, we set α, ,B and y to 1/3, so that the maximum value of the user satisfaction is one. Figure 6 Dialog system performance with various word error rates in weather information seeking tasks. Dotted line is TCR; dashed line is STR; solid line is user satisfaction. TCR, STR and user satisfaction decreased with WER. User satisfaction has relatively high value when the WER is smaller than 20% (Figure 6)</context>
</contexts>
<marker>Litman, Pan, 2004</marker>
<rawString>Diane J. Litman and Shimei Pan, “Empirically evaluating an adaptable spoken dialogue system,” in Proceedings of the 8th International Conference on Spoken Language Processing, pp. 2145-2148, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Finale Doshi</author>
<author>Nicholas Roy</author>
</authors>
<title>Efficient Model Learning for Dialog Management,”</title>
<date>2007</date>
<booktitle>in Proceeding of the ACM/IEEE international conference on Humanrobot interaction,</booktitle>
<location>Washington DC,</location>
<contexts>
<context position="1728" citStr="Doshi and Roy, 2007" startWordPosition="249" endWordPosition="252">essential part of spoken dialog systems, because many such systems have failed in practice due to errors in speech recognition. Speech recognition errors can be propagated to spoken language understanding (SLU), so the speech input must be considered error-prone from a standpoint of dialog management. Therefore robust dialog managers are necessary to develop practical spoken dialog systems. One approach to dialog management uses the partially observable Markov decision process (POMDP) as a statistical framework, because this approach can model the uncertainty inherent in human-machine dialog (Doshi and Roy, 2007). The dialog manager uses a probabilistic, rather than deterministic, approach to manage dialog. As more information becomes available, the dialog manager updates its belief states. A POMDP-based dialog manager can learn the optimized policy that maximizes expected rewards by reinforcement learning. But applying classic POMDP to a practical dialog system incurs a scalability problem. The computational complexity of updating belief states and optimizing the policy increases rapidly with the size of the state space in a slot-filling dialog task. To solve this scalability problem, the method of c</context>
</contexts>
<marker>Doshi, Roy, 2007</marker>
<rawString>Finale Doshi and Nicholas Roy, “Efficient Model Learning for Dialog Management,” in Proceeding of the ACM/IEEE international conference on Humanrobot interaction, Washington DC, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
<author>Steve Young</author>
</authors>
<title>Scaling POMDPs for dialog management with composite summary point-based value iteration (CSPBVI),&amp;quot;</title>
<date>2006</date>
<booktitle>in Proceedings of AAAI Workshop on Statistical and Empirical Approaches for Spoken Dialogue Systems,</booktitle>
<location>Boston,</location>
<contexts>
<context position="2439" citStr="Williams and Young, 2006" startWordPosition="356" endWordPosition="359">e dialog. As more information becomes available, the dialog manager updates its belief states. A POMDP-based dialog manager can learn the optimized policy that maximizes expected rewards by reinforcement learning. But applying classic POMDP to a practical dialog system incurs a scalability problem. The computational complexity of updating belief states and optimizing the policy increases rapidly with the size of the state space in a slot-filling dialog task. To solve this scalability problem, the method of compressing states or mapping the original state space to summarized space can be used (Williams and Young, 2006; Roy et al.,2005), but these algorithms tend to approximate the state space excessively. The complexity problem of POMDP comes from updating beliefs that are out of the user’s intention, and from calculating the reward of system actions that do not satisfy user’s objective. In this paper, we propose a new probabilistic framework for spoken dialog management using dialog examples. We adopted a frame-based belief state representation to reduce the complexity of belief update. Furthermore, we used an examplebased approach to generate only a reasonable number of system action hypotheses in a new </context>
</contexts>
<marker>Williams, Young, 2006</marker>
<rawString>Jason D. Williams and Steve Young, &amp;quot;Scaling POMDPs for dialog management with composite summary point-based value iteration (CSPBVI),&amp;quot; in Proceedings of AAAI Workshop on Statistical and Empirical Approaches for Spoken Dialogue Systems, Boston, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
<author>Steve Young</author>
</authors>
<title>Partially Observable Markov Decision Processes for Spoken Dialog Systems.&amp;quot;</title>
<date>2007</date>
<journal>Computer Speech and Language</journal>
<volume>21</volume>
<issue>2</issue>
<pages>231--422</pages>
<contexts>
<context position="6958" citStr="Williams and Young, 2007" startWordPosition="1102" endWordPosition="1105">stance b’(s’) as a following: where k is a normalizing factor. This process is referred as belief update. Optimizing a POMDP policy is a process of finding a mapping function from belief states to actions that maximizes the expected reward. The system should compute a value function over belief spaces to find optimized actions. However, unlike as in a MDP, each value in a POMDP is a function of an entire probability distribution and belief spaces are very complex, so that a POMDP has a scale problem of computing the exact value function. A POMDP for spoken dialog system is well formulated in (Williams and Young, 2007). First, a state s can be factored to three substates: (su, au, sd) Frame-based Belief State Representation User’s Utterance SLU Result Calculating Utilities User’s Intention, Semantic Frame, Dialog History Generating Hypotheses Pruning Hypotheses Lexico-semantic Similarity Dialog Example DB 121 where su is a user goal state, au is a user action, and sd is a dialog history. A system action am and user action au can be cast as action a and observation o respectively. With some independence assumption between variables, the belief update equation can be rewritten as following:    k P a a P a </context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>Jason D. Williams and Steve Young, &amp;quot; Partially Observable Markov Decision Processes for Spoken Dialog Systems.&amp;quot; Computer Speech and Language 21(2): 231-422, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karolina Eliasson</author>
</authors>
<title>The Use of Case-Based Reasoning in a Human-Robot Dialog System”,</title>
<date>2006</date>
<institution>Licentiate of Engineering Thesis of Linköping Institute of Technology at Linköping University,</institution>
<marker>Eliasson, 2006</marker>
<rawString>Karolina Eliasson, “The Use of Case-Based Reasoning in a Human-Robot Dialog System”, Licentiate of Engineering Thesis of Linköping Institute of Technology at Linköping University, 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Roy</author>
<author>Geoffrey Gordon</author>
<author>Sebastian Thrun</author>
</authors>
<title>Finding approximate pomdp solutions through belief compression,”</title>
<date>2005</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>23</volume>
<pages>1--40</pages>
<marker>Roy, Gordon, Thrun, 2005</marker>
<rawString>Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun, “Finding approximate pomdp solutions through belief compression,” Journal of Artificial Intelligence Research, vol. 23, pp.1–40, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sptéphane Ross</author>
</authors>
<title>Brahim Chaib-draa, “AEMS: An Anytime Online Search Algorithm for Approximate Policy Refinement in Large POMDPs”,</title>
<date>2007</date>
<booktitle>in Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<marker>Ross, 2007</marker>
<rawString>Sptéphane Ross, Brahim Chaib-draa, “AEMS: An Anytime Online Search Algorithm for Approximate Policy Refinement in Large POMDPs”, in Proceedings of the 20th International Joint Conference on Artificial Intelligence, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
<author>Jost Schatzmann</author>
<author>Karl Weilhammer</author>
<author>Hui Ye</author>
</authors>
<title>The hidden information state approach to dialog management,&amp;quot;</title>
<date>2007</date>
<booktitle>in Proceedings of International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<location>Honolulu,</location>
<contexts>
<context position="9034" citStr="Young et al, 2007" startWordPosition="1499" endWordPosition="1502">g V candidates, then VW user goals can be represented as frames. This means that the number of user goals is related exponentially to the number of slots. This number of user goals is intractable in practical dialog systems. Therefore, a method is needed to reduce the size of the state space rather than maintaining all belief states. To do this, we developed a frame-based belief state representation in which the system dynamically groups set of equivalent states to a highlevel frame state. Frame state, which is a similar concept to the partition in the hidden information state (HIS) approach (Young et al, 2007) represents the indistinguishable classes of user’s goals. The biggest difference between frame-based representation and partition-based representation is that the former uses only user input to split the frame state, whereas the latter uses the user input and external ontology rules such as a prior probability for belief of split partition. Therefore, the frame-based representation has relatively high domain portability because it does not need that kind of external domain dependent information. In the frame-based belief state representation, a partially-filled frame state represents the curr</context>
<context position="16817" citStr="Young et al., 2007" startWordPosition="2865" endWordPosition="2868"> give a weight to the term which is replaced by its slot name. �0 if w1, i = w2,j C i j = � I ( , ) 1 if w1, i#w2, j and W1, i , w2,j 0 Sslot_name I11.5 if w1, i # w2, j and w1, i, w2,j E Sslot_name where w1,i is ith word of user’s utterance, w2,j is jth word of dialog example’s utterance, and Sslot_name is the set of slot names. According to the lexicosemantic similarity, the system appends the top Nhranked hypotheses to the final action hypotheses (where Nh is the rank threshold). Many existing systems used heuristics or rulebased approaches to reduce the number of system action hypotheses (Young et al., 2007). But these methods are not flexible enough to handle all dialog flows because a system developer should design new heuristics or rules whenever the system needs to support a new kind of dialog flow. The example-based approach, on the contrary, can instantly refine the control of dialog flows by adding new dialog examples. This is a great advantage when a system developer wants to change or refine a dialog control flow. 4.2 Calculating Expected Utilities We adopted the principle of maximum expected utility to determine the optimized system actions among the hypotheses (Paek and Horvitz, 2004).</context>
</contexts>
<marker>Young, Schatzmann, Weilhammer, Ye, 2007</marker>
<rawString>Steve Young, Jost Schatzmann, Karl Weilhammer and Hui Ye, &amp;quot;The hidden information state approach to dialog management,&amp;quot; in Proceedings of International Conference on Acoustics, Speech, and Signal Processing, Honolulu, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Paek</author>
<author>Eric Horvitz</author>
</authors>
<title>Optimizing automated call routing by integrating spoken dialog models with queuing models,”</title>
<date>2004</date>
<booktitle>in Proceedings of HLT-NAACL,</booktitle>
<pages>41--48</pages>
<location>Boston,</location>
<contexts>
<context position="17416" citStr="Paek and Horvitz, 2004" startWordPosition="2964" endWordPosition="2967">ses (Young et al., 2007). But these methods are not flexible enough to handle all dialog flows because a system developer should design new heuristics or rules whenever the system needs to support a new kind of dialog flow. The example-based approach, on the contrary, can instantly refine the control of dialog flows by adding new dialog examples. This is a great advantage when a system developer wants to change or refine a dialog control flow. 4.2 Calculating Expected Utilities We adopted the principle of maximum expected utility to determine the optimized system actions among the hypotheses (Paek and Horvitz, 2004). 124 a*n = EU a � a = argmax E P(H = h |�)u(a, h) argmax ( |) a h h = argmax ( ) ( , ) E b h u a h where � denotes all information about the environment, u(a,h) means the utility of taking an action when the internal state of the machine is h, which consists of three substates, (f, au, sd) : f is a frame state, au is a user’s last action, and sd is a dialog history. The utility function u(a,h) can be specific to each application. We defined a handcrafted utility function to calculate the expected utility. 5 Experiments We performed two evaluations. 1) Real user evaluation: we measured the us</context>
</contexts>
<marker>Paek, Horvitz, 2004</marker>
<rawString>Tim Paek and Eric Horvitz, “Optimizing automated call routing by integrating spoken dialog models with queuing models,” in Proceedings of HLT-NAACL, pp. 41-48, Boston, 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>