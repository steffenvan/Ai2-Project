<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000245">
<title confidence="0.933987">
Translating Dialectal Arabic to English
</title>
<author confidence="0.998188">
Hassan Sajjad, Kareem Darwish Yonatan Belinkov
</author>
<affiliation confidence="0.9513985">
Qatar Computing Research Institute CSAIL
Qatar Foundation Massachusetts Institute of Technology
</affiliation>
<email confidence="0.992132">
jhsajjad,kdarwishj@qf.org.qa belinkov@mit.edu
</email>
<sectionHeader confidence="0.994636" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999983947368421">
We present a dialectal Egyptian Arabic
to English statistical machine translation
system that leverages dialectal to Modern
Standard Arabic (MSA) adaptation. In
contrast to previous work, we first nar-
row down the gap between Egyptian and
MSA by applying an automatic character-
level transformational model that changes
Egyptian to EG&apos;, which looks simi-
lar to MSA. The transformations include
morphological, phonological and spelling
changes. The transformation reduces
the out-of-vocabulary (OOV) words from
5.2% to 2.6% and gives a gain of 1.87
BLEU points. Further, adapting large
MSA/English parallel data increases the
lexical coverage, reduces OOVs to 0.7%
and leads to an absolute BLEU improve-
ment of 2.73 points.
</bodyText>
<sectionHeader confidence="0.998743" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.901027294117647">
Modern Standard Arabic (MSA) is the lingua
franca for the Arab world. Arabic speakers gen-
erally use dialects in daily interactions. There are
6 dominant dialects, namely Egyptian, Moroccan,
Levantine, Iraqi, Gulf, and Yemeni1. The dialects
may differ in vocabulary, morphology, syntax, and
spelling from MSA and most lack spelling con-
ventions.
Different dialects often make different lexical
choices to express concepts. For example, the con-
cept corresponding to “Oryd” YK
P@ (“I want”) is
expressed as “EAwz” ,ðA« in Egyptian, “Abgy”
ùªK
�.@ in Gulf, “Aby” ú
G.@ in Iraqi, and “bdy” ø� YK.
�
</bodyText>
<footnote confidence="0.908911">
in Levantine2. Often, words have different or op-
posite meanings in different dialects.
1http://en.wikipedia.org/wiki/
Varieties_of_Arabic
2All transliterations follow the Buckwalter scheme
</footnote>
<bodyText confidence="0.952426595238095">
Arabic dialects may differ morphologically
from MSA. For example, Egyptian Arabic uses a
negation construct similar to the French “ne pas”
negation construct. The Egyptian word “mlEbt$”
•~~J
~.ªÊÓ (or alternatively spelled LJ.ªËAÓ) (“I did
not play”) is composed of “m+lEbt+$”.
The pronunciations of letters often differ from
one dialect to another. For example, the letter “q”
†~ is typically pronounced in MSA as an unvoiced
uvular stop (as the “q” in “quote”), but as a glot-
tal stop in Egyptian and Levantine (like “A” in
“Alpine”) and a voiced velar stop in the Gulf (like
“g” in “gavel”). Differing pronunciations often re-
flect on spelling.
Social media platforms allowed people to ex-
press themselves more freely in writing. Although
MSA is used in formal writing, dialects are in-
creasingly being used on social media sites. Some
notable trends on social platforms include (Dar-
wish et al., 2012):
- Mixed language texts where bilingual (or mul-
tilingual) users code switch between Arabic and
English (or Arabic and French). In the exam-
ple “wSlny mrsy” ú
æ...QÓ ú��æÊ“ð (“got it thank
you”), “thank you” is the transliterated French
word “merci”.
– The use of phonetic transcription to match di-
alectal pronunciation. For example, “Sdq” L3Y“
(“truth”) is often written as “Sj”l.~• in Gulf di-
alect.
– Creative spellings, spelling mistakes, and word
elongations are ubiquitous in social texts.
– The use of new words like “lol” ÈñË (“LOL”).
– The attachment of new meanings to words such
as using “THn” &amp;£ to mean “very” while it
means “grinding” in MSA.
The Egyptian dialect has the largest number of
speakers and is the most commonly understood di-
alect in the Arab world. In this work, we focused
on translating dialectal Egyptian to English us-
</bodyText>
<page confidence="0.803338">
1
</page>
<bodyText confidence="0.96503295">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1–6,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
ing Egyptian to MSA adaptation. Unlike previous
work, we first narrowed the gap between Egyptian
and MSA using character-level transformations
and word n-gram models that handle spelling mis-
takes, phonological variations, and morphological
transformations. Later, we applied an adaptation
method to incorporate MSA/English parallel data.
The contributions of this paper are as follows:
– We trained an Egyptian/MSA transformation
model to make Egyptian look similar to MSA. We
publicly released the training data.
– We built a phrasal Machine Translation (MT)
system on adapted Egyptian/English parallel data,
which outperformed a non-adapted baseline by
1.87 BLEU points.
– We used phrase-table merging (Nakov and Ng,
2009) to utilize MSA/English parallel data with
the available in-domain parallel data.
</bodyText>
<sectionHeader confidence="0.994364" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.998015928571429">
Our work is related to research on MT from a re-
source poor language (to other languages) by piv-
oting on a closely related resource rich language.
This can be done by either translating between
the related languages using word-level translation,
character level transformations, and language spe-
cific rules (Durrani et al., 2010; Hajiˇc et al., 2000;
Nakov and Tiedemann, 2012), or by concatenating
the parallel data for both languages (Nakov and
Ng, 2009). These translation methods generally
require parallel data, for which hardly any exists
between dialects and MSA. Instead of translating
between a dialect and MSA, we tried to narrow
down the lexical, morphological and phonetic gap
between them using a character-level conversion
model, which we trained on a small set of parallel
dialect/MSA word pairs.
In the context of Arabic dialects3, most previous
work focused on converting dialects to MSA and
vice versa to improve the processing of dialects
(Sawaf, 2010; Chiang et al., 2006; Mohamed et
al., 2012; Utiyama and Isahara, 2008). Sawaf
(2010) proposed a dialect to MSA normalization
that used character-level rules and morphological
analysis. Salloum and Habash (2011) also used a
rule-based method to generate MSA paraphrases
of dialectal out-of-vocabulary (OOV) and low fre-
quency words. Instead of rules, we automatically
</bodyText>
<footnote confidence="0.8825915">
3Due to space limitations, we restrict discussion to work
on dialects only.
</footnote>
<bodyText confidence="0.999061947368421">
learnt character mappings from dialect/MSA word
pairs.
Zbib et al. (2012) explored several methods for
dialect/English MT. Their best Egyptian/English
system was trained on dialect/English parallel
data. They used two language models built from
the English GigaWord corpus and from a large
web crawl. Their best system outperformed man-
ually translating Egyptian to MSA then translat-
ing using an MSA/English system. In contrast, we
showed that training on in-domain dialectal data
irrespective of its small size is better than training
on large MSA/English data. Our LM experiments
also affirmed the importance of in-domain English
LMs. We also showed that a conversion does not
imply a straight forward usage of MSA resources
and there is a need for adaptation which we ful-
filled using phrase-table merging (Nakov and Ng,
2009).
</bodyText>
<subsectionHeader confidence="0.940302">
2.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999742535714286">
We constructed baselines that were based on the
following training data:
- An Egyptian/English parallel corpus consist-
ing of ≈38k sentences, which is part of the
LDC2012T09 corpus (Zbib et al., 2012). We ran-
domly divided it into 32k sentences for training,
2k for development and 4k for testing. We hence-
forth refer to this corpus as EG and the English
part of it as EG,,,. We did not have access to the
training/test splits of Zbib et al. (2012) to directly
compare to their results.
- An MSA/English parallel corpus consisting of
200k sentences from LDC4. We refer to this cor-
pus as the AR corpus.
For language modeling, we used either EG,,,
or the English side of the AR corpus plus the En-
glish side of NIST12 training data and English Gi-
gaWord v5. We refer to this corpus as GW.
We tokenized Egyptian and Arabic accord-
ing to the ATB tokenization scheme using the
MADA+TOKAN morphological analyzer and to-
kenizer v3.1 (Roth et al., 2008). Word elonga-
tions were already fixed in the corpus. We word-
aligned the parallel data using GIZA++ (Och and
Ney, 2003), and symmetrized the alignments using
grow-diag-final-and heuristic (Koehn et al., 2003).
We trained a phrasal MT system (Koehn et al.,
2003). We built five-gram LMs using KenLM
</bodyText>
<footnote confidence="0.9902935">
4Arabic News (LDC2004T17), eTIRR (LDC2004E72),
and parallel corpora the GALE program
</footnote>
<page confidence="0.963473">
2
</page>
<table confidence="0.9944695">
“
Train LM BLEU OOV
B1 AR GW 7.48 6.7
B2 EG GW 12.82 5.2
B3 EG EG,, 13.94 5.2
B4 EG EG,,,,GW 14.23 5.2
</table>
<tableCaption confidence="0.990572">
Table 1: Baseline results using the EG and AR
</tableCaption>
<bodyText confidence="0.97709219047619">
training sets with GW and EGen corpora for LM
training
with modified Kneser-Ney smoothing (Heafield,
2011). In case of more than one LM, we tuned
their weights on a development set using Mini-
mum Error Rate Training (Och and Ney, 2003).
We built several baseline systems as follows:
– B1 used AR for training a translation model and
GW for LM.
– B2-B4 systems used identical training data,
namely EG, with the GW, EGen, or both for B2,
B3, and B4 respectively for language modeling.
Table 1 reports the baseline results. The system
trained on AR (B1) performed poorly compared
to the one trained on EG (B2) with a 6.75 BLEU
points difference. This highlights the difference
between MSA and Egyptian. Using EG data for
training both the translation and language models
was effective. B4 used two LMs and yielded the
best results. For later comparison, we only use the
B4 baseline.
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="method">
3 Proposed Methods
</sectionHeader>
<subsectionHeader confidence="0.99962">
3.1 Egyptian to EG&apos; Conversion
</subsectionHeader>
<bodyText confidence="0.977504720588235">
As mentioned previously, dialects differ from
MSA in vocabulary, morphology, and phonology.
Dialectal spelling often follows dialectal pronun-
ciation, and dialects lack standard spelling con-
ventions. To address the vocabulary problem, we
used the EG corpus for training.
To address the spelling and morphological dif-
ferences, we trained a character-level mapping
model to generate MSA words from dialectal
ones using character transformations. To train the
model, we extracted the most frequent words from
a dialectal Egyptian corpus, which had 12,527
news comments (containing 327k words) from Al-
Youm Al-Sabe news site (Zaidan and Callison-
Burch, 2011) and translated them to their equiv-
alent MSA words. We hired a professional trans-
lator, who generated one or more translations of
the most frequent 5,581 words into MSA. Out of
these word pairs, 4,162 involved character-level
transformations due to phonological, morphologi-
cal, or spelling changes. We aligned the translated
pairs at character level using GIZA++ and Moses
in the manner described in Section 2.1. As in the
baseline of Kahki et al. (2011), given a source
word, we produced all of its possible segmenta-
tions along with their associated character-level
mappings. We restricted individual source char-
acter sequences to be 3 characters at most. We
retained all mapping sequences leading to valid
words in a large lexicon. We built the lexicon from
a set of 234,638 Aljazeera articles5 that span a 10
year period and contain 254M tokens. Spelling
mistakes in Aljazeera articles were very infre-
quent. We sorted the candidates by the product of
the constituent mapping probabilities and kept the
top 10 candidates. Then we used a trigram LM that
we built from the aforementioned Aljazeera arti-
cles to pick the most likely candidate in context.
We simply multiplied the character-level transfor-
mation probability with the LM probability – giv-
ing them equal weight. Since Egyptian has a “ne
pas” like negation construct that involves putting a
Ð” and “ �€” at the beginning and end of verbs,
we handled words that had negation by remov-
ing these two letters, then applying our character
transformation, and lastly adding the negation ar-
ticle “lA” B before the verb. We converted the EG
train, tune, and test parts. We refer to the converted
corpus as EG&apos;.
As an example, our system transformed
Yg �•�.j. ªJ
Ó ÑêÊ’jJ�K. ú
Î~Ë@ •�.(“what is hap-
pening to them does not please anyone”) to
Yg I. j. ªK
B ÑêËÉ’m~
ø� �YË@ •j.. Transform-
ing “Ally” ú
ÎË@ to “Al*y” ø
Ë@ involved a spelling
�
correction. The transformation of “byHSlhm”
ÑêÊ’jJ�K. to “yHSl lhm” ÑêË É’m� � involved a mor-
phological change and word splitting. Chang-
ing “myEjb$” �•�.j. ªJ�Ó to “lA yEjb” I. j. ªK
B in-
volved morphologically transforming a negation
construct.
</bodyText>
<subsectionHeader confidence="0.999839">
3.2 Combining AR and EG&apos;
</subsectionHeader>
<bodyText confidence="0.999956">
The aforementioned conversion generated a lan-
guage that is close, but not identical, to MSA.
In order to maximize the gain using both paral-
lel corpora, we used the phrase merging technique
described in Nakov and Ng (2009) to merge the
phrase tables generated from the AR and EG&apos; cor-
pora. If a phrase occurred in both phrase tables, we
</bodyText>
<footnote confidence="0.965185">
5http://www.aljazeera.net
</footnote>
<page confidence="0.995882">
3
</page>
<bodyText confidence="0.999717666666667">
adopted one of the following three solutions:
- Only added the phrase with its translations and
their probabilities from the AR phrase table. This
assumed AR alignments to be more reliable.
- Only added the phrase with its translations and
their probabilities from the EG&apos; phrase table. This
assumed EG&apos; alignments to be more reliable.
- Added translations of the phrase from both
phrase tables and left the choice to the decoder.
We added three additional features to the new
phrase table to avail the information about the ori-
gin of phrases (as in Nakov and Ng (2009)).
</bodyText>
<subsectionHeader confidence="0.998744">
3.3 Evaluation and Discussion
</subsectionHeader>
<bodyText confidence="0.9962565">
We performed the following experiments:
- S0 involved translating the EG&apos; test using AR.
- S1 and S2 trained on the EG&apos; with EG,,,, and
both EG,,,, and GW for LM training respectively.
- S. used phrase merging technique. All systems
trained on both EG&apos; and AR corpora. We built
separate phrase tables from the two corpora and
merged them. When merging, we preferred AR or
EG&apos; for SAR and SEG, respectively. For SALL,
we kept phrases from both phrase tables.
Table 2 summarizes results of using EG&apos; and
phrase table merging. S0 was slightly better than
B1, but lagged considerably behind training using
EG or EG&apos;. S1, which used only EG&apos; for train-
ing showed an improvement of 1.67 BLEU points
from the best baseline system (B4). Using both
language models (S2) led to slight improvement.
Phrase merging that preferred phrases learnt from
EG&apos; data over AR data performed the best with a
BLEU score of 16.96.
</bodyText>
<table confidence="0.999825375">
Train LM BLEU OOV
B4 EG EGe,GW 14.23 5.2
S0 AR EGe, 8.61 2.0
S1 EG&apos; EGe, 15.90 2.6
S2 EG&apos; EGe,GW 16.10 2.6
SAR PTAR EGe,GW 16.14 0.7
SEGI PTEG1 EGe,GW 16.96 0.7
SALL PTEGI,AR EGe,GW 16.73 0.7
</table>
<tableCaption confidence="0.908635333333333">
Table 2: Summary of results using different com-
binations of EG&apos;/English and MSA/English train-
ing data
</tableCaption>
<bodyText confidence="0.992417678571428">
We analyzed 100 test sentences that led to the
greatest absolute change in BLEU score, whether
positive or negative, between training with EG
and EG&apos;. The largest difference in BLEU was
0.69 in favor of EG&apos;. Translating the Egyp-
tian sentence “wbyHtrmwA AlnAs AltAnyp”
éJ��KA�JË@ €A�JË@ @ñÓQ��jJ�K.ð produced “@ñÓQ��jJ�K.ð (OOV)
the second people” (BLEU = 0.31). Conver-
sion changed “wbyHtrmwA” to “wyHtrmwA” and
“AltAnyp” aJ
KA�JË@ to “AlvAnyp” aJ
KA~JË@, leading to
“and they respect other people” (BLEU = 1).
Training with EG&apos; outperformed EG for 63 of the
sentences. Conversion improved MT, because it
reduced OOVs, enabled MADA+TOKAN to suc-
cessfully analyze words, and reduced spelling mis-
takes.
In further analysis, we examined 1% of the sen-
tences with the largest difference in BLEU score.
Out of these, more than 70% were cases where the
EG&apos; model achieved a higher BLEU score. For
each observed conversion error, we identified its
linguistic character, i.e. whether it is lexical, syn-
tactic, morphological or other. We found that in
more than half of the cases (≈57%) using morpho-
logical information could have improved the con-
version. Consider the following example, where
</bodyText>
<listItem confidence="0.6601744">
(1) is the original EG sentence and its EG/EN
translation, and (2) is the converted EG&apos; sentence
and its EG&apos;/EN translation:
1. 1/2�JJ. «P I. ‚k ø X �àB
�
lAn dy Hsb rgbtk
because this is according to your desire
2. é�JJ. «P I. ‚k è �Yë �à�B
lOn h*h Hsb rgbth
because this is according to his desire
</listItem>
<bodyText confidence="0.973604842105263">
In this case, “rgbtk” 1/2�JJ.�«P (“your wish”) was con-
verted to “rgbth” é�JJ.�«P (“his wish”) leading to an
unwanted change in the translation. This could be
avoided, for instance, by running a morphologi-
cal analyzer on the original and converted word,
and making sure their morphological features (in
this case, the person of the possessive) correspond.
In a similar case, the phrase “mEndy$ AEdA”
Z@Y«@ OLY�JªÓ was converted to “Endy OEdA’”
Z@Y«@ ø� Y�J«, thereby changing the translation from
”I don’t have enemies” to ”I have enemies”. Here,
again, a morphological analyzer could verify the
retaining of negation after conversion.
In another sentence, “knty” ú~æ J» (“you (fm.)
were”) was correctly converted to the MSA “knt”
I�J», which is used for feminine and masculine
�
forms. However, the induced ambiguity ended up
hurting translation.
</bodyText>
<page confidence="0.96183">
4
</page>
<bodyText confidence="0.999925">
Aside from morphological mistakes, conversion
often changed words completely. In one sen-
tence, the word “lbAnh” é7AJ.Ë (”chewing gum”)
was wrongly converted to “lOnh” é�KB (”because
it”), resulting in a wrong translation. Perhaps a
morphological analyzer, or just a part-of-speech
tagger, could enforce (or probabilistically encour-
age) a match in parts of speech.
The conversion also faces some other chal-
lenges. Consider the following example:
</bodyText>
<listItem confidence="0.898589666666667">
1. éJ��K�@ A JÊÔ« A�Jk@ @ñë
hwA AHnA EmlnA Ayyyh
he is we did we What ? ?
2. éK�@ A�JÊÔ« &amp;m�� ñë
hw nHn EmlnA Ayh
he we did we do ? ?
</listItem>
<bodyText confidence="0.999966291666667">
While the first two words “hwA AHnA” A:k@ @ñë
were correctly converted to “hw nHn” &amp;md ñë, the
final word “Ayyyh” éJ�;�@ (”what”) was shortened
but remained dialectal “Ayh” éK�@ rather than MSA
“mA/mA*A” AÓ/@AAÓ. There is a syntactic chal-
lenge in this sentence, since the Egyptian word or-
der in interrogative sentences is normally different
from the MSA word order: the interrogative par-
ticle appears at the end of the sentence instead of
at the beginning. Addressing this problem might
have improved translation.
The above analysis suggests that incorporat-
ing deeper linguistic information in the conversion
procedure could improve translation quality. In
particular, using a morphological analyzer seeems
like a promising possibility. One approach could
be to run a morphological analyzer for dialectal
Arabic (e.g. MADA-ARZ (Habash et al., 2013))
on the original EG sentence and another analyzer
for MSA (such as MADA) on the converted EG&apos;
sentence, and then to compare the morphological
features. Discrepancies should be probabilistically
incorporated in the conversion. Exploring this ap-
proach is left for future work.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999563">
We presented an Egyptian to English MT system.
In contrast to previous work, we used an auto-
matic conversion method to map Egyptian close
to MSA. The converted Egyptian EG&apos; had fewer
OOV words and spelling mistakes and improved
language handling. The MT system built on the
adapted parallel data showed an improvement of
1.87 BLEU points over our best baseline. Using
phrase table merging that combined AR and EG&apos;
training data in a way that preferred adapted di-
alectal data yielded an extra 0.86 BLEU points.
We will make the training data for our conversion
system publicly available.
For future work, we want to expand our work
to other dialects, while utilizing dialectal morpho-
logical analysis to improve conversion. Also, we
believe that improving English language model-
ing to match the genre of the translated sentences
can have significant positive impact on translation
quality.
</bodyText>
<sectionHeader confidence="0.998353" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684076923077">
David Chiang, Mona T. Diab, Nizar Habash, Owen
Rambow, and Safiullah Shareef. 2006. Parsing Ara-
bic dialects. In Proceedings of the 11th Conference
of the European Chapter of the Association for Com-
putational Linguistics, Trento, Italy.
Kareem Darwish, Walid Magdy, and Ahmed Mourad.
2012. Language processing for Arabic microblog
retrieval. In Proceedings of the 21st ACM inter-
national conference on Information and knowledge
management, CIKM ’12, Maui, Hawaii, USA.
Nadir Durrani, Hassan Sajjad, Alexander Fraser, and
Helmut Schmid. 2010. Hindi-to-Urdu machine
translation through transliteration. In Proceedings
of the 48th Annual Conference of the Association for
Computational Linguistics, Uppsala, Sweden.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, , and Nadi Tomeh. 2013. Morphological
analysis and disambiguation for dialectal Arabic. In
Proceedings of the Main Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Atlanta, US.
Jan Hajiˇc, Jan Hric, and Vladislav Kuboˇn. 2000. Ma-
chine translation of very close languages. In Pro-
ceedings of the sixth conference on Applied natural
language processing, Seattle, Washington.
Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, Edin-
burgh, UK.
Ali El Kahki, Kareem Darwish, Ahmed Saad El
Din, Mohamed Abd El-Wahab, Ahmed Hefny, and
Waleed Ammar. 2011. Improved transliteration
mining using graph reinforcement. In Proceedings
of the Conference on Empirical Methods in Natural
5 Language Processing, Edinburgh, UK.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology and North
American Association for Computational Linguis-
tics Conference, Edmonton, Canada.
Emad Mohamed, Behrang Mohit, and Kemal Oflazer.
2012. Transforming standard Arabic to colloquial
Arabic. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics, Short Paper, Jeju Island, Korea.
Preslav Nakov and Hwee Tou Ng. 2009. Improved
statistical machine translation for resource-poor lan-
guages using related resource-rich languages. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, Singa-
pore.
Preslav Nakov and J¨org Tiedemann. 2012. Combining
word-level and character-level models for machine
translation between closely-related languages. In
Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics, Short Paper,
Jeju Island, Korea.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1).
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic morphological
tagging, diacritization, and lemmatization using lex-
eme models and feature ranking. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Columbus, Ohio.
Wael Salloum and Nizar Habash. 2011. Dialectal
to standard Arabic paraphrasing to improve Arabic-
English statistical machine translation. In Proceed-
ings of the First Workshop on Algorithms and Re-
sources for Modelling of Dialects and Language Va-
rieties, Edinburgh, Scotland.
Hassan Sawaf. 2010. Arabic dialect handling in hybrid
machine translation. In Proceedings of the Confer-
ence of the Association for Machine Translation in
the Americas, Denver, Colorado.
Masao Utiyama and Hitoshi Isahara. 2008. A hybrid
approach for converting written Egyptian colloquial
dialect into diacritized Arabic. In Proceedings of
the 6th International Conference on Informatics and
Systems, Cairo University, Egypt.
Rabih Zbib, Erika Malchiodi, Jacob Devlin, David
Stallard, Spyros Matsoukas, Richard Schwartz, John
Makhoul, Omar F. Zaidan, and Chris Callison-
Burch. 2012. Machine translation of Arabic di-
alects. In Proceedings of the 2012 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Montreal, Canada.
</reference>
<bodyText confidence="0.960310333333333">
Omar F. Zaidan and Chris Callison-Burch. 2011. The
Arabic online commentary dataset: an annotated
dataset of informal Arabic with high dialectal con-
tent. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies: short papers - Volume
</bodyText>
<page confidence="0.756057">
2, Portland, Oregon. 6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.791362">
<title confidence="0.996796">Translating Dialectal Arabic to English</title>
<author confidence="0.963899">Hassan Sajjad</author>
<author confidence="0.963899">Kareem Darwish Yonatan Belinkov</author>
<affiliation confidence="0.9096595">Qatar Computing Research Institute CSAIL Qatar Foundation Massachusetts Institute of Technology</affiliation>
<email confidence="0.999525">belinkov@mit.edu</email>
<abstract confidence="0.99779535">We present a dialectal Egyptian Arabic to English statistical machine translation system that leverages dialectal to Modern Standard Arabic (MSA) adaptation. In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes to which looks similar to MSA. The transformations include morphological, phonological and spelling changes. The transformation reduces the out-of-vocabulary (OOV) words from 5.2% to 2.6% and gives a gain of 1.87 BLEU points. Further, adapting large MSA/English parallel data increases the lexical coverage, reduces OOVs to 0.7% and leads to an absolute BLEU improvement of 2.73 points.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Mona T Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Safiullah Shareef</author>
</authors>
<title>Parsing Arabic dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="5497" citStr="Chiang et al., 2006" startWordPosition="842" endWordPosition="845">2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on diale</context>
</contexts>
<marker>Chiang, Diab, Habash, Rambow, Shareef, 2006</marker>
<rawString>David Chiang, Mona T. Diab, Nizar Habash, Owen Rambow, and Safiullah Shareef. 2006. Parsing Arabic dialects. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
<author>Walid Magdy</author>
<author>Ahmed Mourad</author>
</authors>
<title>Language processing for Arabic microblog retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st ACM international conference on Information and knowledge management, CIKM ’12,</booktitle>
<location>Maui, Hawaii, USA.</location>
<contexts>
<context position="2654" citStr="Darwish et al., 2012" startWordPosition="395" endWordPosition="399">he pronunciations of letters often differ from one dialect to another. For example, the letter “q” †~ is typically pronounced in MSA as an unvoiced uvular stop (as the “q” in “quote”), but as a glottal stop in Egyptian and Levantine (like “A” in “Alpine”) and a voiced velar stop in the Gulf (like “g” in “gavel”). Differing pronunciations often reflect on spelling. Social media platforms allowed people to express themselves more freely in writing. Although MSA is used in formal writing, dialects are increasingly being used on social media sites. Some notable trends on social platforms include (Darwish et al., 2012): - Mixed language texts where bilingual (or multilingual) users code switch between Arabic and English (or Arabic and French). In the example “wSlny mrsy” ú æ...QÓ ú��æÊ“ð (“got it thank you”), “thank you” is the transliterated French word “merci”. – The use of phonetic transcription to match dialectal pronunciation. For example, “Sdq” L3Y“ (“truth”) is often written as “Sj”l.~• in Gulf dialect. – Creative spellings, spelling mistakes, and word elongations are ubiquitous in social texts. – The use of new words like “lol” ÈñË (“LOL”). – The attachment of new meanings to words such as using “TH</context>
</contexts>
<marker>Darwish, Magdy, Mourad, 2012</marker>
<rawString>Kareem Darwish, Walid Magdy, and Ahmed Mourad. 2012. Language processing for Arabic microblog retrieval. In Proceedings of the 21st ACM international conference on Information and knowledge management, CIKM ’12, Maui, Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>Hindi-to-Urdu machine translation through transliteration.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Conference of the Association for Computational Linguistics,</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="4834" citStr="Durrani et al., 2010" startWordPosition="737" endWordPosition="740">rasal Machine Translation (MT) system on adapted Egyptian/English parallel data, which outperformed a non-adapted baseline by 1.87 BLEU points. – We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data. 2 Previous Work Our work is related to research on MT from a resource poor language (to other languages) by pivoting on a closely related resource rich language. This can be done by either translating between the related languages using word-level translation, character level transformations, and language specific rules (Durrani et al., 2010; Hajiˇc et al., 2000; Nakov and Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to impro</context>
</contexts>
<marker>Durrani, Sajjad, Fraser, Schmid, 2010</marker>
<rawString>Nadir Durrani, Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2010. Hindi-to-Urdu machine translation through transliteration. In Proceedings of the 48th Annual Conference of the Association for Computational Linguistics, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
</authors>
<title>Morphological analysis and disambiguation for dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the Main Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Atlanta, US.</location>
<contexts>
<context position="17894" citStr="Habash et al., 2013" startWordPosition="2911" endWordPosition="2914">actic challenge in this sentence, since the Egyptian word order in interrogative sentences is normally different from the MSA word order: the interrogative particle appears at the end of the sentence instead of at the beginning. Addressing this problem might have improved translation. The above analysis suggests that incorporating deeper linguistic information in the conversion procedure could improve translation quality. In particular, using a morphological analyzer seeems like a promising possibility. One approach could be to run a morphological analyzer for dialectal Arabic (e.g. MADA-ARZ (Habash et al., 2013)) on the original EG sentence and another analyzer for MSA (such as MADA) on the converted EG&apos; sentence, and then to compare the morphological features. Discrepancies should be probabilistically incorporated in the conversion. Exploring this approach is left for future work. 4 Conclusion We presented an Egyptian to English MT system. In contrast to previous work, we used an automatic conversion method to map Egyptian close to MSA. The converted Egyptian EG&apos; had fewer OOV words and spelling mistakes and improved language handling. The MT system built on the adapted parallel data showed an impro</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, , and Nadi Tomeh. 2013. Morphological analysis and disambiguation for dialectal Arabic. In Proceedings of the Main Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Atlanta, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jan Hric</author>
<author>Vladislav Kuboˇn</author>
</authors>
<title>Machine translation of very close languages.</title>
<date>2000</date>
<booktitle>In Proceedings of the sixth conference on Applied natural language processing,</booktitle>
<location>Seattle, Washington.</location>
<marker>Hajiˇc, Hric, Kuboˇn, 2000</marker>
<rawString>Jan Hajiˇc, Jan Hric, and Vladislav Kuboˇn. 2000. Machine translation of very close languages. In Proceedings of the sixth conference on Applied natural language processing, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="8339" citStr="Heafield, 2011" startWordPosition="1315" endWordPosition="1316">already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 4Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 “ Train LM BLEU OOV B1 AR GW 7.48 6.7 B2 EG GW 12.82 5.2 B3 EG EG,, 13.94 5.2 B4 EG EG,,,,GW 14.23 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In case of more than one LM, we tuned their weights on a development set using Minimum Error Rate Training (Och and Ney, 2003). We built several baseline systems as follows: – B1 used AR for training a translation model and GW for LM. – B2-B4 systems used identical training data, namely EG, with the GW, EGen, or both for B2, B3, and B4 respectively for language modeling. Table 1 reports the baseline results. The system trained on AR (B1) performed poorly compared to the one trained on EG (B2) with a 6.75 BLEU points difference. This highlights the difference between MSA and Egyptian. Using E</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El Kahki</author>
<author>Kareem Darwish</author>
</authors>
<title>Ahmed Saad El Din, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural 5 Language Processing,</booktitle>
<location>Edinburgh, UK.</location>
<marker>El Kahki, Darwish, 2011</marker>
<rawString>Ali El Kahki, Kareem Darwish, Ahmed Saad El Din, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar. 2011. Improved transliteration mining using graph reinforcement. In Proceedings of the Conference on Empirical Methods in Natural 5 Language Processing, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="7907" citStr="Koehn et al., 2003" startWordPosition="1235" endWordPosition="1238">g of 200k sentences from LDC4. We refer to this corpus as the AR corpus. For language modeling, we used either EG,,, or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 4Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 “ Train LM BLEU OOV B1 AR GW 7.48 6.7 B2 EG GW 12.82 5.2 B3 EG EG,, 13.94 5.2 B4 EG EG,,,,GW 14.23 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In case of more than one LM, we tuned their weights on a development set using Minimum Error Rate Training (Och and Ney, 2003). We built several baseline systems as f</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>Transforming standard Arabic to colloquial Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Short Paper,</booktitle>
<location>Jeju Island,</location>
<contexts>
<context position="5519" citStr="Mohamed et al., 2012" startWordPosition="846" endWordPosition="849">ating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel da</context>
</contexts>
<marker>Mohamed, Mohit, Oflazer, 2012</marker>
<rawString>Emad Mohamed, Behrang Mohit, and Kemal Oflazer. 2012. Transforming standard Arabic to colloquial Arabic. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Short Paper, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Improved statistical machine translation for resource-poor languages using related resource-rich languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<contexts>
<context position="4409" citStr="Nakov and Ng, 2009" startWordPosition="670" endWordPosition="673">using character-level transformations and word n-gram models that handle spelling mistakes, phonological variations, and morphological transformations. Later, we applied an adaptation method to incorporate MSA/English parallel data. The contributions of this paper are as follows: – We trained an Egyptian/MSA transformation model to make Egyptian look similar to MSA. We publicly released the training data. – We built a phrasal Machine Translation (MT) system on adapted Egyptian/English parallel data, which outperformed a non-adapted baseline by 1.87 BLEU points. – We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data. 2 Previous Work Our work is related to research on MT from a resource poor language (to other languages) by pivoting on a closely related resource rich language. This can be done by either translating between the related languages using word-level translation, character level transformations, and language specific rules (Durrani et al., 2010; Hajiˇc et al., 2000; Nakov and Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require p</context>
<context position="6746" citStr="Nakov and Ng, 2009" startWordPosition="1033" endWordPosition="1036"> used two language models built from the English GigaWord corpus and from a large web crawl. Their best system outperformed manually translating Egyptian to MSA then translating using an MSA/English system. In contrast, we showed that training on in-domain dialectal data irrespective of its small size is better than training on large MSA/English data. Our LM experiments also affirmed the importance of in-domain English LMs. We also showed that a conversion does not imply a straight forward usage of MSA resources and there is a need for adaptation which we fulfilled using phrase-table merging (Nakov and Ng, 2009). 2.1 Baseline We constructed baselines that were based on the following training data: - An Egyptian/English parallel corpus consisting of ≈38k sentences, which is part of the LDC2012T09 corpus (Zbib et al., 2012). We randomly divided it into 32k sentences for training, 2k for development and 4k for testing. We henceforth refer to this corpus as EG and the English part of it as EG,,,. We did not have access to the training/test splits of Zbib et al. (2012) to directly compare to their results. - An MSA/English parallel corpus consisting of 200k sentences from LDC4. We refer to this corpus as </context>
<context position="12193" citStr="Nakov and Ng (2009)" startWordPosition="1958" endWordPosition="1961">m does not please anyone”) to Yg I. j. ªK B ÑêËÉ’m~ ø� �YË@ •j.. Transforming “Ally” ú ÎË@ to “Al*y” ø Ë@ involved a spelling � correction. The transformation of “byHSlhm” ÑêÊ’jJ�K. to “yHSl lhm” ÑêË É’m� � involved a morphological change and word splitting. Changing “myEjb$” �•�.j. ªJ�Ó to “lA yEjb” I. j. ªK B involved morphologically transforming a negation construct. 3.2 Combining AR and EG&apos; The aforementioned conversion generated a language that is close, but not identical, to MSA. In order to maximize the gain using both parallel corpora, we used the phrase merging technique described in Nakov and Ng (2009) to merge the phrase tables generated from the AR and EG&apos; corpora. If a phrase occurred in both phrase tables, we 5http://www.aljazeera.net 3 adopted one of the following three solutions: - Only added the phrase with its translations and their probabilities from the AR phrase table. This assumed AR alignments to be more reliable. - Only added the phrase with its translations and their probabilities from the EG&apos; phrase table. This assumed EG&apos; alignments to be more reliable. - Added translations of the phrase from both phrase tables and left the choice to the decoder. We added three additional f</context>
</contexts>
<marker>Nakov, Ng, 2009</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2009. Improved statistical machine translation for resource-poor languages using related resource-rich languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Combining word-level and character-level models for machine translation between closely-related languages.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Short Paper,</booktitle>
<location>Jeju Island,</location>
<contexts>
<context position="4883" citStr="Nakov and Tiedemann, 2012" startWordPosition="745" endWordPosition="748">apted Egyptian/English parallel data, which outperformed a non-adapted baseline by 1.87 BLEU points. – We used phrase-table merging (Nakov and Ng, 2009) to utilize MSA/English parallel data with the available in-domain parallel data. 2 Previous Work Our work is related to research on MT from a resource poor language (to other languages) by pivoting on a closely related resource rich language. This can be done by either translating between the related languages using word-level translation, character level transformations, and language specific rules (Durrani et al., 2010; Hajiˇc et al., 2000; Nakov and Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chian</context>
</contexts>
<marker>Nakov, Tiedemann, 2012</marker>
<rawString>Preslav Nakov and J¨org Tiedemann. 2012. Combining word-level and character-level models for machine translation between closely-related languages. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Short Paper, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="7818" citStr="Och and Ney, 2003" startWordPosition="1224" endWordPosition="1227"> (2012) to directly compare to their results. - An MSA/English parallel corpus consisting of 200k sentences from LDC4. We refer to this corpus as the AR corpus. For language modeling, we used either EG,,, or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 4Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 “ Train LM BLEU OOV B1 AR GW 7.48 6.7 B2 EG GW 12.82 5.2 B3 EG EG,, 13.94 5.2 B4 EG EG,,,,GW 14.23 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modified Kneser-Ney smoothing (Heafield, 2011). In case of more than one LM, we tuned their weights on a development set usin</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Columbus, Ohio.</location>
<contexts>
<context position="7700" citStr="Roth et al., 2008" startWordPosition="1203" endWordPosition="1206">is corpus as EG and the English part of it as EG,,,. We did not have access to the training/test splits of Zbib et al. (2012) to directly compare to their results. - An MSA/English parallel corpus consisting of 200k sentences from LDC4. We refer to this corpus as the AR corpus. For language modeling, we used either EG,,, or the English side of the AR corpus plus the English side of NIST12 training data and English GigaWord v5. We refer to this corpus as GW. We tokenized Egyptian and Arabic according to the ATB tokenization scheme using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Roth et al., 2008). Word elongations were already fixed in the corpus. We wordaligned the parallel data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using grow-diag-final-and heuristic (Koehn et al., 2003). We trained a phrasal MT system (Koehn et al., 2003). We built five-gram LMs using KenLM 4Arabic News (LDC2004T17), eTIRR (LDC2004E72), and parallel corpora the GALE program 2 “ Train LM BLEU OOV B1 AR GW 7.48 6.7 B2 EG GW 12.82 5.2 B3 EG EG,, 13.94 5.2 B4 EG EG,,,,GW 14.23 5.2 Table 1: Baseline results using the EG and AR training sets with GW and EGen corpora for LM training with modifie</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to standard Arabic paraphrasing to improve ArabicEnglish statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="5687" citStr="Salloum and Habash (2011)" startWordPosition="869" endWordPosition="872">lects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They used two language models built from the English GigaWord corpus and from a large web crawl. Their best system outperformed manually translating Egyptian to MSA</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to standard Arabic paraphrasing to improve ArabicEnglish statistical machine translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic dialect handling in hybrid machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="5476" citStr="Sawaf, 2010" startWordPosition="840" endWordPosition="841">d Tiedemann, 2012), or by concatenating the parallel data for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system</context>
</contexts>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic dialect handling in hybrid machine translation. In Proceedings of the Conference of the Association for Machine Translation in the Americas, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A hybrid approach for converting written Egyptian colloquial dialect into diacritized Arabic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Informatics and Systems,</booktitle>
<institution>Cairo University, Egypt.</institution>
<contexts>
<context position="5547" citStr="Utiyama and Isahara, 2008" startWordPosition="850" endWordPosition="853">a for both languages (Nakov and Ng, 2009). These translation methods generally require parallel data, for which hardly any exists between dialects and MSA. Instead of translating between a dialect and MSA, we tried to narrow down the lexical, morphological and phonetic gap between them using a character-level conversion model, which we trained on a small set of parallel dialect/MSA word pairs. In the context of Arabic dialects3, most previous work focused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They used two language m</context>
</contexts>
<marker>Utiyama, Isahara, 2008</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2008. A hybrid approach for converting written Egyptian colloquial dialect into diacritized Arabic. In Proceedings of the 6th International Conference on Informatics and Systems, Cairo University, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rabih Zbib</author>
<author>Erika Malchiodi</author>
<author>Jacob Devlin</author>
<author>David Stallard</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
<author>Omar F Zaidan</author>
<author>Chris CallisonBurch</author>
</authors>
<title>Machine translation of Arabic dialects.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="5992" citStr="Zbib et al. (2012)" startWordPosition="915" endWordPosition="918">ocused on converting dialects to MSA and vice versa to improve the processing of dialects (Sawaf, 2010; Chiang et al., 2006; Mohamed et al., 2012; Utiyama and Isahara, 2008). Sawaf (2010) proposed a dialect to MSA normalization that used character-level rules and morphological analysis. Salloum and Habash (2011) also used a rule-based method to generate MSA paraphrases of dialectal out-of-vocabulary (OOV) and low frequency words. Instead of rules, we automatically 3Due to space limitations, we restrict discussion to work on dialects only. learnt character mappings from dialect/MSA word pairs. Zbib et al. (2012) explored several methods for dialect/English MT. Their best Egyptian/English system was trained on dialect/English parallel data. They used two language models built from the English GigaWord corpus and from a large web crawl. Their best system outperformed manually translating Egyptian to MSA then translating using an MSA/English system. In contrast, we showed that training on in-domain dialectal data irrespective of its small size is better than training on large MSA/English data. Our LM experiments also affirmed the importance of in-domain English LMs. We also showed that a conversion does</context>
</contexts>
<marker>Zbib, Malchiodi, Devlin, Stallard, Matsoukas, Schwartz, Makhoul, Zaidan, CallisonBurch, 2012</marker>
<rawString>Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F. Zaidan, and Chris CallisonBurch. 2012. Machine translation of Arabic dialects. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Montreal, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>