<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001720">
<title confidence="0.999682">
A Nearest-Neighbor Approach to the
Automatic Analysis of Ancient Greek Morphology
</title>
<author confidence="0.976964">
John Lee
</author>
<affiliation confidence="0.8297115">
Spoken Language Systems
MIT Computer Science and Artificial Intelligence Laboratory
</affiliation>
<address confidence="0.727849">
Cambridge, MA 02139, USA
</address>
<email confidence="0.999167">
jsylee@csail.mit.edu
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999743">
We propose a data-driven method for au-
tomatically analyzing the morphology of
ancient Greek. This method improves on
existing ancient Greek analyzers in two
ways. First, through the use of a nearest-
neighbor machine learning framework, the
analyzer requires no hand-crafted rules.
Second, it is able to predict novel roots,
and to rerank its predictions by exploiting a
large, unlabelled corpus of ancient Greek.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999599375">
The civilization of ancient Greece, from which the
Western world has received much of its heritage,
has justly received a significant amount of schol-
arly attention. To gain a deeper understanding of
the civilization, access to the essays, poems, and
other Greek documents in the original language is
indispensable.
Ancient Greek is a highly inflected Indo-
European language1. A verb, for example, is in-
flected according to its person, number, voice,
tense/aspect and mood. According to (Crane,
1991), “a single verb could have roughly 1,000
forms, and, if we consider that any verb may be
preceded by up to three distinct prefixes, the num-
ber of forms explodes to roughly 5,000,000.” The
inflections are realized by prefixes and suffixes to
</bodyText>
<note confidence="0.680245">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.833963">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
1All Greek words are transcribed into the Roman alpha-
bet in this paper. The acute, grave and circumflex accents
are represented by diacritics, as in ´o, o` and ˜o, respectively.
Smooth breathing marks are omitted; rough breathing marks
are signalled by h. Underbars used in e and o represent eta
and omega.
</footnote>
<bodyText confidence="0.981989102564103">
the stem, and sometimes spelling changes within
the stem. These numerous forms can be further
complicated by accents, and by additional spelling
changes at morpheme boundaries for phonological
reasons. The overall effect can yield an inflected
form in which the root2 is barely recognizable.
Indeed, a staple exercise for students of ancient
Greek is to identify the root form of an inflected
verb. This skill is essential; without knowing the
root form, one cannot understand the meaning of
the word, or even look it up in a dictionary.
For Classics scholars, these myriad forms also
pose formidable challenges. In order to search for
occurrences of a word in a corpus, all of its forms
must be enumerated, since words do not frequently
appear in their root forms. This procedure be-
comes extremely labor-intensive for small words
that overlap with other common words (Crane,
1991).
Automatic morphological analysis of ancient
Greek would be useful for both educational and
research purposes. In fact, one of the first analyz-
ers was developed as a pedagogical tool (Packard,
1973). Today, a widely used analyzer is embed-
ded in the Perseus Digital Library (Crane, 1996),
an internet resource utilized by both students and
researchers.
This paper presents an analyzer of ancient Greek
that infers the root form of a word. It intro-
duces two innovations. First, it utilizes a nearest-
neighbor framework that requires no hand-crafted
rules, and provides analogies to facilitate learning.
2The root is also called the “base” or “lexical look-up”
form, since it is the form conventionally used in dictionary en-
tries. For verbs in ancient Greek, the root form is the first per-
son singular present active indicative form. (cf. for English,
it is the infinitive.) For nouns, it is the nominative singular
form. For adjectives, it is the nominative singular masculine
form.
</bodyText>
<page confidence="0.982327">
127
</page>
<note confidence="0.8893075">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 127–134
Manchester, August 2008
</note>
<table confidence="0.98583">
Person/Num Form Person/Num Form
1st/singular l´uo 1st/plural l´uomen
2nd/singular l´ueis 2nd/plural l´uete
3rd/singular l´uei 3rd/plural l´uousi(n)
</table>
<tableCaption confidence="0.998565">
Table 1: Paradigm table for the present active in-
</tableCaption>
<bodyText confidence="0.909525666666667">
dicative verb. It uses as example the verb l´uo (“to
loosen”), showing its inflections according to per-
son and number.
Second, and perhaps more significantly, it exploits
a large, unlabelled corpus to improve the predic-
tion of novel roots.
The rest of the paper is organized as follows. We
first motivate these innovations (§2) and summa-
rize previous research in morphological analysis
(§3). We then describe the data (§4) and our adap-
tations to the nearest-neighbor framework (§5-6),
followed by evaluation results (§7).
</bodyText>
<sectionHeader confidence="0.999367" genericHeader="introduction">
2 Innovations
</sectionHeader>
<subsectionHeader confidence="0.998877">
2.1 Use of Analogy and Nearest Neighbor
</subsectionHeader>
<bodyText confidence="0.9999455">
Typically, a student of ancient Greek is expected
to memorize a series of “paradigms”, such as the
one shown in Table 1, which can fill several pages
in a grammar book. Although the paradigm table
shows the inflection of only one particular verb,
l´uo (“to loosen”), the student needs to apply the
patterns to other verbs. In practice, rather than ab-
stracting the patterns, many students simply mem-
orize these “paradigmatic” verbs, to be used as
analogies for identifying the root form of an un-
seen verb. Suppose the unseen verb is ph´ereis
(“you carry”); the reasoning would then be, “I
know that l´ueis is the second person singular form
of the root l´uo; similarly, ph´ereis must be the sec-
ond person singular form of ph´ero.”
The use of analogy can be especially useful
when dealing with a large number of rules, for
example with the so-called “contract verbs”. The
stem of a contract verb ends in a vowel; when a
vowel-initial suffix is attached to the stem, spelling
changes occur. For instance, the stem plero- (“to
fill”) combined with the suffix -omen becomes
pler-o˜u-men, due to interaction between two omi-
crons at the boundary. While it is possible to derive
these changes from first principles, or memorize
the rules for all vowel permutations (e.g., “o” + “o”
= “o˜u”), it might be easier to recall the spelling
changes seen in a familiar verb (e.g., pler´oo →
plero˜umen), and then use analogy to infer the root
of an unseen verb.
The nearest-neighbor machine learning frame-
work is utilized to provide these analogies. Given
a word in an inflected form (e.g., ph´ereis), the algo-
rithm searches for the root form (ph´ero) among its
“neighbors”, by making substitutions to its prefix
and suffix. Valid substitutions are to be harvested
from pairs of inflected and root forms (e.g., (l´ueis,
l´uo)) in the training set; these pairs, then, can serve
as analogies to reinforce learning.
Furthermore, these affix substitutions can be
learned automatically, reducing the amount of en-
gineering efforts. They also increase the trans-
parency of the analyzer, showing explicitly how it
derives the root.
</bodyText>
<subsectionHeader confidence="0.995425">
2.2 Novel Roots
</subsectionHeader>
<bodyText confidence="0.999952117647059">
Ancient Greek, in its many dialects, has been
used from the time of Homer to the Middle
Ages, in texts of a wide range of genres. Even
the most comprehensive dictionaries do not com-
pletely cover its extensive vocabulary. To the best
of our knowledge, all existing analyzers for ancient
Greek require a pre-defined database of stems;
thus, they are likely to run into words with un-
known or novel roots, which they are not designed
to analyze.
Rather than expanding an existing database to
increase coverage, we create a mechanism to han-
dle all novel roots. Since words do not often appear
in their root forms, inferring a novel root from a
surface form is no easy task (Lind´en, 2008). We
propose the use of unlabelled data to guide the de-
termination of a novel root.
</bodyText>
<sectionHeader confidence="0.99811" genericHeader="method">
3 Previous Work
</sectionHeader>
<bodyText confidence="0.992415">
After a brief discussion on morphological analysis
in general, we will review existing analyzers for
ancient Greek in particular.
</bodyText>
<subsectionHeader confidence="0.999777">
3.1 Morphological Analysis
</subsectionHeader>
<bodyText confidence="0.9995247">
A fundamental task in morphological analysis is
the segmentation of a word into morphemes, that
is, the smallest meaningful units in the word. Un-
supervised methods have been shown to perform
well in this task. In the recent PASCAL challenge,
the best results were achieved by (Keshava and
Pitler, 2006). Their algorithm discovers affixes
by considering words that appear as substrings of
other words, and by estimating probabilities for
morpheme boundaries. Another successful ap-
</bodyText>
<page confidence="0.990883">
128
</page>
<bodyText confidence="0.999987">
proach is the use of Minimum Description Length,
which iteratively shortens the length of the mor-
phological grammar (Goldsmith, 2001).
Spelling changes at morpheme boundaries (e.g.,
deny but deni-al) can be captured by orthographic
rules such as “change y- to i- when the suffix is
-al”. Such rules are specified manually in the two-
level model of morphology (Koskenniemi, 1983),
but they can also be induced (Dasgupta, 2007). Al-
lomorphs (e.g., “deni” and “deny”) are also auto-
matically identified in (Dasgupta, 2007), but the
general problem of recognizing highly irregular
forms is examined more extensively in (Yarowsky
and Wicentowski, 2000). They attempt to align ev-
ery verb to its root form, by exploiting a combina-
tion of frequency similarity, context similarity, edit
distance and morphological transformation proba-
bilities, all estimated from an unannotated corpus.
An accuracy of 80.4% was achieved for highly ir-
regular words in the test set.
</bodyText>
<subsectionHeader confidence="0.981956">
3.2 Challenges for Ancient Greek
</subsectionHeader>
<bodyText confidence="0.9999724">
Ancient Greek presents a few difficulties that pre-
vent a naive application of the minimally super-
vised approach in (Yarowsky and Wicentowski,
2000). First, frequency and context analyses are
sensitive to data sparseness, which is more pro-
nounced in heavily inflected languages, such as
Greek, than in English. Many inflected forms do
not appear more than a few times. Second, many
root forms do not appear3 in the corpus. In Finnish
and Swahili, also highly inflected languages, only
40 to 50% of words appear in root forms (Lind´en,
2008). The same may be expected of ancient
Greek.
Indeed, for these languages, predicting novel
roots is a challenging problem. This task has
been tackled in (Adler et al., 2008) for modern
Hebrew, and in (Lind´en, 2008) for Finnish. In
the former, features such as letter n-grams and
word-formation patterns are used to predict the
morphology of Hebrew words unknown to an ex-
isting analyzer. In the latter, a probabilistic ap-
proach is used for harvesting prefixes and suf-
fixes in Finnish words, favoring the longer ones.
However, no strategy was proposed for irregular
spelling in stems.
</bodyText>
<footnote confidence="0.966151">
3The root forms of contract verbs, e.g. pler´oo, are not even
inflected forms.
</footnote>
<table confidence="0.998286666666667">
Surface Morphological Root
Form Annotation Form
kai(and) Conjunction kai
pne˜uma (spirit) Noun 3rd decl pne˜uma
theo˜u (God) Noun 2nd decl the´os
epeph´ereto (hover) Verb ph´ero
</table>
<tableCaption confidence="0.988865">
Table 2: Sample data from parts of Genesis 1:2
</tableCaption>
<bodyText confidence="0.709224333333333">
(“and the Spirit of God was hovering over ...”). The
original annotation is more extensive, and only the
portion utilized in this research is shown here.
</bodyText>
<subsectionHeader confidence="0.999476">
3.3 Ancient Greek Morphological Analysis
</subsectionHeader>
<bodyText confidence="0.999895965517241">
The two most well-known analyzers for ancient
Greek are both rule-based systems, requiring a pri-
ori knowledge of the possible stems and affixes,
which are manually compiled. To give a rough
idea, some 40,000 stems and 13,000 inflections are
known by the MORPHEUS system, which will be
described below.
The algorithm in MORPH (Packard, 1973)
searches for possible endings that would result in
a stem in its database. If unsuccessful, it then at-
tempts to remove prepositions and prefixes from
the beginning of the word. Accents, essential for
disambiguation in some cases, are ignored. The
analyzer was applied on Plato’s Apology to study
the distribution of word endings, for the purpose
of optimizing the order of grammar topics to be
covered in an introductory course. Evaluation of
the analyzer stressed this pedagogical perspective,
and the accuracy of the analyses is not reported.
MORPHEUS (Crane, 1991) augments MORPH
with a generation component which, given a stem,
enumerates all possible inflections in different di-
alects, including accents. When accents are con-
sidered during analysis, the precision of the ana-
lyzer improves by a quarter. However, the actual
precision and the test set are not specified.
In this paper, we have opted for a data-driven ap-
proach, to automatically determine the stems and
affixes from training data.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="method">
4 Data
</sectionHeader>
<subsectionHeader confidence="0.99888">
4.1 Morphology Data
</subsectionHeader>
<bodyText confidence="0.99982675">
We used the Septuagint corpus4 prepared by the
Center for Computer Analysis of Texts at the Uni-
versity of Pennsylvania. The Septuagint, dat-
ing from the third to first centuries BCE, is a
</bodyText>
<footnote confidence="0.979849">
4http://ccat.sas.upenn.edu/gopher/text/religion/biblical/
</footnote>
<page confidence="0.969163">
129
</page>
<table confidence="0.999866375">
Part-of-speech Percent
Verbs 68.6%
Adjectives 10.4%
Nouns (1st declension) 5.6%
Nouns (2nd declension masculine) 4.3%
Nouns (2nd declension neuter) 2.8%
Nouns (3rd declension) 7.6%
other 0.7%
</table>
<tableCaption confidence="0.895660333333333">
Table 3: Statistics on the parts-of-speech of the
words in the test set, considering only unique
words.
</tableCaption>
<bodyText confidence="0.999018466666667">
Greek translation of the Hebrew Bible. The corpus
is morphologically analyzed, and Table 2 shows
some sample data.
The corpus is split into training and test sets.
The training set is made up of the whole Septu-
agint except the first five books. It consists of about
470K words, with 37,842 unique words. The first
five books, also known as the Torah or Pentateuch,
constitute the test set. It contains about 120K
words, of which there are 3,437 unique words not
seen in the training set, and 7,381 unique words
seen in training set. A breakdown of the parts-of-
speech of the test set is provided in Table 3. Proper
nouns, many of which do not decline, are excluded
from our evaluation.
</bodyText>
<subsectionHeader confidence="0.986732">
4.2 Unlabelled Data
</subsectionHeader>
<bodyText confidence="0.999753">
To guide the prediction of novel roots, we utilize
the Thesaurus Linguae Graecae (Berkowitz and
Squitter, 1986) corpus. The corpus contains more
than one million unique words, drawn from a wide
variety of ancient Greek texts.
</bodyText>
<subsectionHeader confidence="0.9554965">
4.3 Evaluation
5.2 Stems and Affixes
</subsectionHeader>
<sectionHeader confidence="0.69836" genericHeader="method">
5 Nearest-Neighbor Approach
</sectionHeader>
<bodyText confidence="0.999786333333333">
The memory-based machine learning framework
performs well on a benchmark of language learn-
ing tasks (Daelemans, 1999), including morpho-
logical segmentation of Dutch (van den Bosch,
1999). In this framework, feature vectors are
extracted from the training set and stored in a
database of instances, called the instance base. A
distance metric is then defined. For each test in-
stance, its set of nearest neighbors is retrieved from
the instance base, and the majority label of the set
is returned.
We now adapt this framework to our task, first
defining the distance metric (current section), then
describing the search algorithm for nearest neigh-
bors (§6).
</bodyText>
<subsectionHeader confidence="0.860403">
5.1 Distance Metric
</subsectionHeader>
<bodyText confidence="0.999963820512821">
Every word consists of a stem, a (possibly empty)
prefix and a (possibly empty) suffix. If two words
share a common stem, one can be transformed to
the other by substituting its prefix and suffix with
their counterparts in the other word. We will call
these substitutions the prefix transformation and
the suffix transformation.
The “distance” between two words is to be de-
fined in terms of these transformations. It would
be desirable for words that are inflected from the
same root to be near neighbors. A distance met-
ric can achieve this effect by favoring prefix and
suffix transformations that are frequently observed
among words inflected from the same root. We
thus provisionally define “distance” as the sum of
the frequency counts of the prefix and suffix trans-
formations required to turn one word to the other.
Many common words in the test set are also seen
in the training set. Rather than artificially boosting
the accuracy rate, we will evaluate performance on
unique words rather than all words individually.
Some surface forms have more than one possi-
ble root form. For example, the word pur˜on may
be inflected from the noun pur´a (“altar”), or pur´os
(“wheat”), or p˜ur (“fire”). It would be necessary to
examine the context to select the appropriate noun,
but morphological disambiguation (Hakkani-T¨ur
et al., 2002) is beyond the scope of this paper. In
these cases, legitimate root forms proposed by our
analyzer may be rejected, but we pay this price in
return for an automatic evaluation procedure.
Defining “Stem” To count the frequencies of pre-
fix and suffix transformations, the stem of each
word in the training set must be determined. Ide-
ally, all words inflected from the same root should
share the same stem. Unfortunately, for ancient
Greek, it is difficult to insist upon such a common
stem. In some cases, the stems are completely dif-
ferent5; in others, the common stem is obfuscated
</bodyText>
<footnote confidence="0.589293833333333">
5Each verb can have up to six different stems, known as
the “principal parts”. In extreme cases, a stem may appear
completely unrelated to the root on the surface. For example,
oiso and ´enegkon are both stems of the root ph´ero (“to carry”).
A comparable example in English is the inflected verb form
went and its root form go.
</footnote>
<page confidence="0.985564">
130
</page>
<table confidence="0.9351595">
Word Prefix Stem Suffix Prefix Suffix
Transformation Transformation
</table>
<listItem confidence="0.978949">
(root) l´uo - l´u o (root,1) e ↔ e o ↔ eto
(1) el´ueto e l´u eto (root,2) e ↔ para o ↔ sai
(2) paral˜usai para l˜u sai (root,3) e ↔ ek o ↔ th´esontai
(3) ekluth´esontai ek lu th´esontai (1,2) e ↔ para eto ↔ sai
(1,3) e ↔ ek eto ↔ th´esontai
(2,3) para ↔ ek sai ↔ th´esontai
</listItem>
<tableCaption confidence="0.55057825">
Table 4: The verb root l´uo (“to loosen”) and three of its inflected forms are shown. Each inflected form
is compared with the root form, as well as the other inflected forms. The “stem”, defined as the longest
common substring, is determined for each pair. The prefix and suffix transformations are then extracted.
e represents the empty string.
</tableCaption>
<bodyText confidence="0.999118677419355">
in surface forms due to spelling changes6.
We resort to a functional definition of “stem” —
the longest common substring of a pair of words.
Some examples are shown in Table 4.
Refinements to Definition Three more refine-
ments to the definition of “stem” have been found
to be helpful. First, accents are ignored when de-
termining the longest common substring. Accents
on stems often change in the process of inflection.
These changes are illustrated in Table 4 by the stem
lu, whose letter u has an acute accent, a circumflex
accent, and no accent in the three inflected forms.
Second, a minimum length is required for the
stem. On the one hand, some pairs, such as ´ago
(“to lead”) and ´axo, do have a stem of length one
(“a”). On the other hand, allowing very short
stems can hurt performance, since many spurious
stems may be misconstrued, such as “e” between
ph´ero and ´enegkon. The minimum stem length is
empirically set at two for this paper.
Length alone cannot filter out all spurious stems.
For example, for the pair pat´eo (“to walk”) and an
inflected form katep´atesan, there are two equally
long candidate stems, *ate and pat. The latter
yields affixes such as “-´eo” and “-esan”, which are
relatively frequent7. On this basis, the latter stem
is chosen.
Some further ways to reduce the noise are to
require an affix transformation to occur at least
a minimum number of times in the training set,
and to restrict the phonological context in which
</bodyText>
<footnote confidence="0.992535">
6For example, the stem oz in the root form ´ozo (“to smell”)
is changed to os in ex´osthesan, an aorist passive form.
7The frequency of each affix is counted in a preliminary
round, with each affix receiving a half count in cases of tied
stem length.
</footnote>
<bodyText confidence="0.998510333333333">
the transformation can be applied8. While signifi-
cantly reducing recall, these additional restrictions
yield only a limited boost in precision.
</bodyText>
<sectionHeader confidence="0.998609" genericHeader="method">
6 Algorithm
</sectionHeader>
<bodyText confidence="0.9999377">
In the training step, a set of prefix and suffix trans-
formations, along with their counts, is compiled
for each part-of-speech. These counts enable us to
compute the distance between any two words, and
hence determine the “nearest neighbor” of a word.
At testing, given an inflected form, its neighbor
is any word to which it can be transformed using
the affix transformations. We first try to find its
nearest neighbor in the training set (§6.1); if no
neighbor is found, a novel root is predicted (§6.2).
</bodyText>
<subsectionHeader confidence="0.998512">
6.1 Finding Known Roots
</subsectionHeader>
<bodyText confidence="0.999819411764706">
If the input word itself appears in the training set,
we simply look up its morphological analysis.
If the input word is not seen in the training set,
its root form or another inflected form may still be
found. We try to transform the input word to the
nearest such word, i.e., by using the most frequent
prefix and suffix transformations, according to the
distance metric (§5.1).
Irregular Stem Spelling Typically, if there are
no spelling changes in the stem, the input word
can be transformed directly to the root, e.g., from
ph´ereis to ph´ero. If the spelling of the stem is sub-
stantially different, it is likely to be transformed
to another inflected form of the root that contains
the same irregular stem. For example, the word
prosex´enegken bears little resemblance to its root
ph´ero, but it can be mapped to the word ´enegken
</bodyText>
<footnote confidence="0.9991715">
8For example, a certain suffix transformation may be valid
only when the stem ends in certain letters.
</footnote>
<page confidence="0.997233">
131
</page>
<bodyText confidence="0.999943166666667">
in the training set, from which we retrieve its root
form ph´ero.
Search Order Some affixes are circumfixes; that
is, both the prefix and the suffix must occur to-
gether. For example, the suffix -eto cannot be ap-
plied on its own, but must always be used in con-
junction with the prefix e-, to form words such as
el´ueto, as shown in Table 4.
Other affixes, however, can freely mix with one
another, and not all combinations are attested in the
training set. This is particularly common when the
prefix contains two or more prepositions. For ex-
ample, the combination dia-kata- occurs only two
times in the training set, but it can potentially pair
with a large number of different suffixes.
Hence, the search for neighbors proceeds in two
stages. In the first stage (denoted CIRCUMFIX), the
search is restricted to circumfixes, that is, requir-
ing that at least one word-pair in the training set
contain both the prefix and suffix transformations.
This restriction is prone to data sparseness; if no
neighbor is found, the prefix and suffix transfor-
mations are then allowed to be applied separately
in the second stage (denoted PREFIX/SUFFIX).
</bodyText>
<subsectionHeader confidence="0.999815">
6.2 Proposing Novel Roots
</subsectionHeader>
<bodyText confidence="0.999964768115942">
A word may be derived from a root of which no
inflected form is seen in the training set. Natu-
rally, no neighbor would be found in the previous
step, and a novel root must be proposed. We ap-
ply the prefix and suffix transformations learned in
§5.2, using only circumfixes observed between an
inflected form and a root form. For obvious rea-
sons, the resulting string is no longer required to
be a neighbor, i.e., a word seen in the training set.
Typically, the various transformations produce
many candidate roots. For example, the word
homometriou (“born of the same mother”), a mas-
culine genitive adjective, can be transformed to its
root adjective homom´etrios, but it could equally
well be transformed into a hypothetical neuter
noun, *homom´etrion. Both are perfectly plausible
roots.
The automatically discovered affix transforma-
tions inevitably contain some noise. When dealing
with known roots, much of the noise is suppressed
because misapplications of these transformations
seldom turn the input word into a real word found
in the training set. When proposing novel roots,
we no longer enjoy this constraint. Although the
distance metric still helps discriminate against
invalid candidates, the increased ambiguity leads
to lower accuracy. We address this issue by
exploiting a large, unlabelled corpus.
Use of Unlabelled Corpus If a proposed root form
is correct, it should be able to generate some in-
flected forms attested in a large corpus. Intuitively,
the “productivity” of the root form may correlate
with its correctness.
To generate inflected forms from a root, we sim-
ply take the set of affix transformations observed
from inflected forms to roots, and reverse the trans-
formations. Continuing with the above example,
we generate inflected forms for both candidate
roots, the adjective homom´etrios, and the hypo-
thetical neuter noun *homom´etrion. While a few
inflected forms are generated by both candidates,
three are unique to the adjective — homom´etrios,
homom´etrioi and homom´etrian — the nominative
masculine singular and plural, and the accusative
feminine singular, respectively. None of these
could have been inflected from a neuter noun.
A straightforward notion of “productivity” of
a root would be simply the number of inflected
forms attested in the large corpus. It can be fur-
ther refined, however, by considering the preva-
lence of the inflected forms. That is, a form gen-
erated with more common affix transformations
should be given greater weight than one gener-
ated with less common ones. Suppose two candi-
date roots, the adjective telesph´oros (“bringing to
an end”) and the hypothetical verb *telesphor´oo,
are being considered. Both can generate the in-
flected form telesph´orou, the former as the mascu-
line genitive adjective, and the latter as either an
imperfect indicative or present imperative contract
verb. Since the inflection of the adjective is more
frequent in the training set than that of the rela-
tively rare class of contract verbs, the existence of
telesph´orou should lend greater weight to the ad-
jective.
Hence, the “productivity” metric of a novel root
is the number of words in the large corpus that it
can generate with affix transformations, weighted
by the frequencies of those transformations.
</bodyText>
<sectionHeader confidence="0.999717" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.990914">
Some statistics on the test set are presented in Ta-
ble 3. Of the 7,381 words that are seen in the train-
ing set, 98.2% received the correct root form. The
</bodyText>
<page confidence="0.989356">
132
</page>
<table confidence="0.9998108">
Transformation Type Proportion Accuracy
CIRCUMFIX 77.5% 94.5%
PREFIX/SUFFIX 10.8% 61.2%
Novel Roots 11.7% 50.0%
Overall 100% 85.7%
</table>
<tableCaption confidence="0.951688">
Table 5: After excluding known words, which at-
</tableCaption>
<bodyText confidence="0.9473716">
tain an accuracy of 98.2%, the performance on
the remaining 3437 unique words in the test set is
shown above. Please see §7 for discussions. Re-
sults for novel roots are presented in further detail
in Table 6.
</bodyText>
<table confidence="0.9989216">
Evaluation Method Accuracy
BASELINE 45.0%
TLG RERANK 50.0%
+Ignore accents 55.2%
+Oracle POS 65.5%
</table>
<tableCaption confidence="0.844985">
Table 6: Results for predicting novel roots, for
</tableCaption>
<bodyText confidence="0.97945424137931">
the 402 words for whom no neighbor was found.
BASELINE uses the distance metric (§5.1) as be-
fore; TLG RERANK exploits the unlabelled The-
saurus Linguae Graecae corpus to re-rank the top
candidates (§6.2) proposed by BASELINE.
remaining 1.8% had multiple possible roots; an ex-
amination of the context would be needed for dis-
ambiguation (see comments in §4.3).
Table 5 presents the accuracy of the predicted
roots, after excluding the 7,381 seen words. The
result is broken down according to the type of
transformation; for the “Novel Roots” type, more
detailed results are presented in Table 6.
As discussed in §6.1, the algorithm first
searched with CIRCUMFIX. For 77.5% of the
words, a neighbor was found using this sub-
set of affix transformations. The rest were then
processed using the back-up procedure, PRE-
FIX/SUFFIX, allowing prefix and suffix transfor-
mations culled from different word-pairs. This
procedure found neighbors for 10.8% of the words;
novel roots were hypothesized for the remainder.
Not surprisingly, known roots were more reli-
ably predicted (94.5%) with circumfixes than with
separate prefixes and suffixes (61.2%), but both
categories still achieved higher accuracy than the
challenging task of proposing novel roots (50.0%).
We now take a closer look at the errors for both
known and novel roots.
</bodyText>
<subsectionHeader confidence="0.980263">
7.1 Known Roots
</subsectionHeader>
<bodyText confidence="0.999988894736842">
There are three main sources of error. The first is
noise in the affix transformations. For example, the
spurious prefix transformation p↔ph was derived
from the pair ph´ero and perien´egkasan. When ap-
plied on pas´ato, along with a suffix transformation,
it yielded the false root form ph´asko.
A second source can be attributed to incorrect
affix boundaries. For example, ekteinantes was
misconstrued as having “e- ” rather than the prepo-
sition ek as prefix. This prefix is by itself per-
fectly viable, but “e-” and “-antes” cannot occur
together as a circumfix. The resulting string hap-
pened to match the root kteino, rather than the true
root teino.
A third source is confusion between parts-of-
speech, most commonly noun and verb. For ex-
ample, the nearest neighbor of the genitive noun
lup˜on was the verb lup´esei, yielding the verb root
lup´eo rather than the noun l´upe.
</bodyText>
<subsectionHeader confidence="0.97854">
7.2 Novel Roots
</subsectionHeader>
<bodyText confidence="0.980441678571428">
As a baseline, the distance metric (§5.1) was used
alone to rank the novel candidate roots. As seen in
Table 6, performance dropped to 45.0%.
When the Thesaurus Linguae Graecae corpus
was utilized to rerank the novel candidate roots
proposed by the baseline, an absolute gain9 of 5%
was achieved. A further 5.2% of the mistakes
were due to placing the accent incorrectly, such as
kten´otrophos rather than ktenotr´ophos, mostly on
nouns and adjectives. These mistakes are difficult
to rectify, since multiple positions are often possi-
ble10.
Finally, to measure the extent to which part-of-
speech (POS) confusions are responsible, we per-
formed an experiment in which the gold-standard
POS of each word was supplied to the analyzer
(see “Oracle POS” in Table 6). When deriving
novel roots, only those affix transformations be-
longing to the oracle POS were considered. With
this constraint, accuracy rose to 65.5%.
9The significance level is at p = 0.11, according to Mc-
Nemar’s test. The improvement is not statistically significant,
and may be a reflection of the relatively small test set.
10The accent in an inflected noun retains its position in the
root, unless that position violates certain phonological rules.
In many cases, there is no reliable way to predict the accent
position in the root noun from the position in the inflected
form.
</bodyText>
<page confidence="0.998799">
133
</page>
<sectionHeader confidence="0.997666" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999869181818182">
We have proposed a nearest-neighbor machine
learning framework for analyzing ancient Greek
morphology. This framework is data-driven, with
automatic discovery of stems and affixes. The ana-
lyzer is able to predict novel roots. A significant
novelty is the exploitation of a large, unlabelled
corpus to improve performance.
We plan to further improve the derivation of
novel roots by predicting their parts-of-speech
from context, and by incorporating distributional
information (Yarowsky and Wicentowski, 2000).
</bodyText>
<sectionHeader confidence="0.998283" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997577666666667">
The author would like to thank Stephanie Sen-
eff, Kalliroi Georgila, Konstantinos Katsiapis and
Steven Lulich for their insightful comments.
</bodyText>
<sectionHeader confidence="0.995978" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999945869565217">
Meni Adler, Yoav Goldberg, David Gabay, and Michael
Elhadad. 2008. Unsupervised Lexicon-based Res-
olution of Unknown Words for Full Morphological
Analysis. Proc. ACL. Columbus, OH.
Luci Berkowitz and Karl A. Squitter. 1986. Thesaurus
Linguae Graecae. Oxford University Press, UK.
Antal van den Bosch and Walter Daelemans. 1999.
Memory-based Morphological Analysis. Proc. ACL.
College Park, MD.
Gregory Crane. 1991. Generating and Parsing Clas-
sical Greek. Literary and Linguistic Computing,
6(4):243–245.
Gregory Crane. 1996. Perseus 2.0: Interactive Sources
and Studies on Ancient Greece. Yale University
Press, New Haven, CT.
Walter Daelemans, Antal van den Bosch and Jakub Za-
vrel. 1999. Forgetting Exceptions is Harmful in
Language Learning. Machine Learning, 34:11–41.
Sajib Dasgupta and Vincent Ng. 2007. High-
Performance, Language-Independent Morphological
Segmentation. Proc. HLT-NAACL. Rochester, NY.
John Goldsmith. 2001. Unsupervised Learning of the
Morphology of a Natural Language. Computational
Linguistics, 27(2):153–198.
Dilek Z. Hakkani-T¨ur, Kemal Oflazer, and G¨okhan T¨ur.
2002. Statistical Morphological Disambiguation for
Agglutinative Languages. Computers and the Hu-
manities, 36(4):381–410.
Samarth Keshava and Emily Pitler. 2006. A Simpler,
Intuitive Approach to Morpheme Induction. Proc.
2nd PASCAL Challenges Workshop. Venice, Italy.
Kimmo Koskenniemi. 1983. Two-level morphology:
a general computation model for word-form recog-
nition and production. Publication No. 11, Depart-
ment of General Linguistics, University of Helsinki.
Helsinki, Finland.
Krister Lind´en. 2008. A Probabilistic Model for
Guessing Base Forms of New Words by Analogy.
Proc. CICLing. Haifa, Israel.
David W. Packard. 1973. Computer-assisted Morpho-
logical Analysis of Ancient Greek. Proc. 5th Con-
ference on Computational Linguistics. Pisa, Italy.
David Yarowsky and Richard Wicentowski. 2000.
Minimally Supervised Morphological Analysis by
Multimodal Alignment. Proc. ACL. Hong Kong,
China.
</reference>
<page confidence="0.99863">
134
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.426643">
<title confidence="0.8450065">A Nearest-Neighbor Approach to Automatic Analysis of Ancient Greek Morphology</title>
<author confidence="0.701288">John</author>
<affiliation confidence="0.871398">Spoken Language MIT Computer Science and Artificial Intelligence</affiliation>
<address confidence="0.999753">Cambridge, MA 02139,</address>
<email confidence="0.999914">jsylee@csail.mit.edu</email>
<abstract confidence="0.998188">We propose a data-driven method for automatically analyzing the morphology of ancient Greek. This method improves on existing ancient Greek analyzers in two ways. First, through the use of a nearestneighbor machine learning framework, the analyzer requires no hand-crafted rules. Second, it is able to predict novel roots, and to rerank its predictions by exploiting a large, unlabelled corpus of ancient Greek.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
<author>Yoav Goldberg</author>
<author>David Gabay</author>
<author>Michael Elhadad</author>
</authors>
<title>Unsupervised Lexicon-based Resolution of Unknown Words for Full Morphological Analysis.</title>
<date>2008</date>
<booktitle>Proc. ACL.</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="9893" citStr="Adler et al., 2008" startWordPosition="1581" endWordPosition="1584">upervised approach in (Yarowsky and Wicentowski, 2000). First, frequency and context analyses are sensitive to data sparseness, which is more pronounced in heavily inflected languages, such as Greek, than in English. Many inflected forms do not appear more than a few times. Second, many root forms do not appear3 in the corpus. In Finnish and Swahili, also highly inflected languages, only 40 to 50% of words appear in root forms (Lind´en, 2008). The same may be expected of ancient Greek. Indeed, for these languages, predicting novel roots is a challenging problem. This task has been tackled in (Adler et al., 2008) for modern Hebrew, and in (Lind´en, 2008) for Finnish. In the former, features such as letter n-grams and word-formation patterns are used to predict the morphology of Hebrew words unknown to an existing analyzer. In the latter, a probabilistic approach is used for harvesting prefixes and suffixes in Finnish words, favoring the longer ones. However, no strategy was proposed for irregular spelling in stems. 3The root forms of contract verbs, e.g. pler´oo, are not even inflected forms. Surface Morphological Root Form Annotation Form kai(and) Conjunction kai pne˜uma (spirit) Noun 3rd decl pne˜um</context>
</contexts>
<marker>Adler, Goldberg, Gabay, Elhadad, 2008</marker>
<rawString>Meni Adler, Yoav Goldberg, David Gabay, and Michael Elhadad. 2008. Unsupervised Lexicon-based Resolution of Unknown Words for Full Morphological Analysis. Proc. ACL. Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luci Berkowitz</author>
<author>Karl A Squitter</author>
</authors>
<title>Thesaurus Linguae Graecae.</title>
<date>1986</date>
<publisher>Oxford University Press, UK.</publisher>
<contexts>
<context position="13532" citStr="Berkowitz and Squitter, 1986" startWordPosition="2165" endWordPosition="2168">e up of the whole Septuagint except the first five books. It consists of about 470K words, with 37,842 unique words. The first five books, also known as the Torah or Pentateuch, constitute the test set. It contains about 120K words, of which there are 3,437 unique words not seen in the training set, and 7,381 unique words seen in training set. A breakdown of the parts-ofspeech of the test set is provided in Table 3. Proper nouns, many of which do not decline, are excluded from our evaluation. 4.2 Unlabelled Data To guide the prediction of novel roots, we utilize the Thesaurus Linguae Graecae (Berkowitz and Squitter, 1986) corpus. The corpus contains more than one million unique words, drawn from a wide variety of ancient Greek texts. 4.3 Evaluation 5.2 Stems and Affixes 5 Nearest-Neighbor Approach The memory-based machine learning framework performs well on a benchmark of language learning tasks (Daelemans, 1999), including morphological segmentation of Dutch (van den Bosch, 1999). In this framework, feature vectors are extracted from the training set and stored in a database of instances, called the instance base. A distance metric is then defined. For each test instance, its set of nearest neighbors is retri</context>
</contexts>
<marker>Berkowitz, Squitter, 1986</marker>
<rawString>Luci Berkowitz and Karl A. Squitter. 1986. Thesaurus Linguae Graecae. Oxford University Press, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
<author>Walter Daelemans</author>
</authors>
<title>Memory-based Morphological Analysis.</title>
<date>1999</date>
<booktitle>Proc. ACL. College</booktitle>
<location>Park, MD.</location>
<marker>van den Bosch, Daelemans, 1999</marker>
<rawString>Antal van den Bosch and Walter Daelemans. 1999. Memory-based Morphological Analysis. Proc. ACL. College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Crane</author>
</authors>
<date>1991</date>
<booktitle>Generating and Parsing Classical Greek. Literary and Linguistic Computing,</booktitle>
<pages>6--4</pages>
<contexts>
<context position="1155" citStr="Crane, 1991" startWordPosition="171" endWordPosition="172">el roots, and to rerank its predictions by exploiting a large, unlabelled corpus of ancient Greek. 1 Introduction The civilization of ancient Greece, from which the Western world has received much of its heritage, has justly received a significant amount of scholarly attention. To gain a deeper understanding of the civilization, access to the essays, poems, and other Greek documents in the original language is indispensable. Ancient Greek is a highly inflected IndoEuropean language1. A verb, for example, is inflected according to its person, number, voice, tense/aspect and mood. According to (Crane, 1991), “a single verb could have roughly 1,000 forms, and, if we consider that any verb may be preceded by up to three distinct prefixes, the number of forms explodes to roughly 5,000,000.” The inflections are realized by prefixes and suffixes to © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 1All Greek words are transcribed into the Roman alphabet in this paper. The acute, grave and circumflex accents are represented by diacritics, as in ´o, o` and ˜o, respectively. Sm</context>
<context position="2763" citStr="Crane, 1991" startWordPosition="426" endWordPosition="427">s barely recognizable. Indeed, a staple exercise for students of ancient Greek is to identify the root form of an inflected verb. This skill is essential; without knowing the root form, one cannot understand the meaning of the word, or even look it up in a dictionary. For Classics scholars, these myriad forms also pose formidable challenges. In order to search for occurrences of a word in a corpus, all of its forms must be enumerated, since words do not frequently appear in their root forms. This procedure becomes extremely labor-intensive for small words that overlap with other common words (Crane, 1991). Automatic morphological analysis of ancient Greek would be useful for both educational and research purposes. In fact, one of the first analyzers was developed as a pedagogical tool (Packard, 1973). Today, a widely used analyzer is embedded in the Perseus Digital Library (Crane, 1996), an internet resource utilized by both students and researchers. This paper presents an analyzer of ancient Greek that infers the root form of a word. It introduces two innovations. First, it utilizes a nearestneighbor framework that requires no hand-crafted rules, and provides analogies to facilitate learning.</context>
<context position="11711" citStr="Crane, 1991" startWordPosition="1873" endWordPosition="1874">elow. The algorithm in MORPH (Packard, 1973) searches for possible endings that would result in a stem in its database. If unsuccessful, it then attempts to remove prepositions and prefixes from the beginning of the word. Accents, essential for disambiguation in some cases, are ignored. The analyzer was applied on Plato’s Apology to study the distribution of word endings, for the purpose of optimizing the order of grammar topics to be covered in an introductory course. Evaluation of the analyzer stressed this pedagogical perspective, and the accuracy of the analyses is not reported. MORPHEUS (Crane, 1991) augments MORPH with a generation component which, given a stem, enumerates all possible inflections in different dialects, including accents. When accents are considered during analysis, the precision of the analyzer improves by a quarter. However, the actual precision and the test set are not specified. In this paper, we have opted for a data-driven approach, to automatically determine the stems and affixes from training data. 4 Data 4.1 Morphology Data We used the Septuagint corpus4 prepared by the Center for Computer Analysis of Texts at the University of Pennsylvania. The Septuagint, dati</context>
</contexts>
<marker>Crane, 1991</marker>
<rawString>Gregory Crane. 1991. Generating and Parsing Classical Greek. Literary and Linguistic Computing, 6(4):243–245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Crane</author>
</authors>
<title>Perseus 2.0: Interactive Sources and Studies on Ancient Greece.</title>
<date>1996</date>
<publisher>Yale University Press,</publisher>
<location>New Haven, CT.</location>
<contexts>
<context position="3050" citStr="Crane, 1996" startWordPosition="472" endWordPosition="473">ars, these myriad forms also pose formidable challenges. In order to search for occurrences of a word in a corpus, all of its forms must be enumerated, since words do not frequently appear in their root forms. This procedure becomes extremely labor-intensive for small words that overlap with other common words (Crane, 1991). Automatic morphological analysis of ancient Greek would be useful for both educational and research purposes. In fact, one of the first analyzers was developed as a pedagogical tool (Packard, 1973). Today, a widely used analyzer is embedded in the Perseus Digital Library (Crane, 1996), an internet resource utilized by both students and researchers. This paper presents an analyzer of ancient Greek that infers the root form of a word. It introduces two innovations. First, it utilizes a nearestneighbor framework that requires no hand-crafted rules, and provides analogies to facilitate learning. 2The root is also called the “base” or “lexical look-up” form, since it is the form conventionally used in dictionary entries. For verbs in ancient Greek, the root form is the first person singular present active indicative form. (cf. for English, it is the infinitive.) For nouns, it i</context>
</contexts>
<marker>Crane, 1996</marker>
<rawString>Gregory Crane. 1996. Perseus 2.0: Interactive Sources and Studies on Ancient Greece. Yale University Press, New Haven, CT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
<author>Jakub Zavrel</author>
</authors>
<date>1999</date>
<booktitle>Forgetting Exceptions is Harmful in Language Learning. Machine Learning,</booktitle>
<pages>34--11</pages>
<marker>Daelemans, van den Bosch, Zavrel, 1999</marker>
<rawString>Walter Daelemans, Antal van den Bosch and Jakub Zavrel. 1999. Forgetting Exceptions is Harmful in Language Learning. Machine Learning, 34:11–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sajib Dasgupta</author>
<author>Vincent Ng</author>
</authors>
<title>HighPerformance, Language-Independent Morphological Segmentation.</title>
<date>2007</date>
<booktitle>Proc. HLT-NAACL.</booktitle>
<location>Rochester, NY.</location>
<marker>Dasgupta, Ng, 2007</marker>
<rawString>Sajib Dasgupta and Vincent Ng. 2007. HighPerformance, Language-Independent Morphological Segmentation. Proc. HLT-NAACL. Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised Learning of the Morphology of a Natural Language.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="8329" citStr="Goldsmith, 2001" startWordPosition="1331" endWordPosition="1332">A fundamental task in morphological analysis is the segmentation of a word into morphemes, that is, the smallest meaningful units in the word. Unsupervised methods have been shown to perform well in this task. In the recent PASCAL challenge, the best results were achieved by (Keshava and Pitler, 2006). Their algorithm discovers affixes by considering words that appear as substrings of other words, and by estimating probabilities for morpheme boundaries. Another successful ap128 proach is the use of Minimum Description Length, which iteratively shortens the length of the morphological grammar (Goldsmith, 2001). Spelling changes at morpheme boundaries (e.g., deny but deni-al) can be captured by orthographic rules such as “change y- to i- when the suffix is -al”. Such rules are specified manually in the twolevel model of morphology (Koskenniemi, 1983), but they can also be induced (Dasgupta, 2007). Allomorphs (e.g., “deni” and “deny”) are also automatically identified in (Dasgupta, 2007), but the general problem of recognizing highly irregular forms is examined more extensively in (Yarowsky and Wicentowski, 2000). They attempt to align every verb to its root form, by exploiting a combination of frequ</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>John Goldsmith. 2001. Unsupervised Learning of the Morphology of a Natural Language. Computational Linguistics, 27(2):153–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Z Hakkani-T¨ur</author>
<author>Kemal Oflazer</author>
<author>G¨okhan T¨ur</author>
</authors>
<date>2002</date>
<booktitle>Statistical Morphological Disambiguation for Agglutinative Languages. Computers and the Humanities,</booktitle>
<pages>36--4</pages>
<marker>Hakkani-T¨ur, Oflazer, T¨ur, 2002</marker>
<rawString>Dilek Z. Hakkani-T¨ur, Kemal Oflazer, and G¨okhan T¨ur. 2002. Statistical Morphological Disambiguation for Agglutinative Languages. Computers and the Humanities, 36(4):381–410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samarth Keshava</author>
<author>Emily Pitler</author>
</authors>
<title>A Simpler, Intuitive Approach to Morpheme Induction.</title>
<date>2006</date>
<booktitle>Proc. 2nd PASCAL Challenges Workshop.</booktitle>
<location>Venice, Italy.</location>
<contexts>
<context position="8015" citStr="Keshava and Pitler, 2006" startWordPosition="1284" endWordPosition="1287">g a novel root from a surface form is no easy task (Lind´en, 2008). We propose the use of unlabelled data to guide the determination of a novel root. 3 Previous Work After a brief discussion on morphological analysis in general, we will review existing analyzers for ancient Greek in particular. 3.1 Morphological Analysis A fundamental task in morphological analysis is the segmentation of a word into morphemes, that is, the smallest meaningful units in the word. Unsupervised methods have been shown to perform well in this task. In the recent PASCAL challenge, the best results were achieved by (Keshava and Pitler, 2006). Their algorithm discovers affixes by considering words that appear as substrings of other words, and by estimating probabilities for morpheme boundaries. Another successful ap128 proach is the use of Minimum Description Length, which iteratively shortens the length of the morphological grammar (Goldsmith, 2001). Spelling changes at morpheme boundaries (e.g., deny but deni-al) can be captured by orthographic rules such as “change y- to i- when the suffix is -al”. Such rules are specified manually in the twolevel model of morphology (Koskenniemi, 1983), but they can also be induced (Dasgupta, </context>
</contexts>
<marker>Keshava, Pitler, 2006</marker>
<rawString>Samarth Keshava and Emily Pitler. 2006. A Simpler, Intuitive Approach to Morpheme Induction. Proc. 2nd PASCAL Challenges Workshop. Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-level morphology: a general computation model for word-form recognition and production.</title>
<date>1983</date>
<journal>Publication</journal>
<volume>11</volume>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<location>Helsinki, Finland.</location>
<contexts>
<context position="8573" citStr="Koskenniemi, 1983" startWordPosition="1371" endWordPosition="1372">the best results were achieved by (Keshava and Pitler, 2006). Their algorithm discovers affixes by considering words that appear as substrings of other words, and by estimating probabilities for morpheme boundaries. Another successful ap128 proach is the use of Minimum Description Length, which iteratively shortens the length of the morphological grammar (Goldsmith, 2001). Spelling changes at morpheme boundaries (e.g., deny but deni-al) can be captured by orthographic rules such as “change y- to i- when the suffix is -al”. Such rules are specified manually in the twolevel model of morphology (Koskenniemi, 1983), but they can also be induced (Dasgupta, 2007). Allomorphs (e.g., “deni” and “deny”) are also automatically identified in (Dasgupta, 2007), but the general problem of recognizing highly irregular forms is examined more extensively in (Yarowsky and Wicentowski, 2000). They attempt to align every verb to its root form, by exploiting a combination of frequency similarity, context similarity, edit distance and morphological transformation probabilities, all estimated from an unannotated corpus. An accuracy of 80.4% was achieved for highly irregular words in the test set. 3.2 Challenges for Ancien</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Kimmo Koskenniemi. 1983. Two-level morphology: a general computation model for word-form recognition and production. Publication No. 11, Department of General Linguistics, University of Helsinki. Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krister Lind´en</author>
</authors>
<title>A Probabilistic Model for Guessing Base Forms of New Words by Analogy.</title>
<date>2008</date>
<booktitle>Proc. CICLing.</booktitle>
<location>Haifa, Israel.</location>
<marker>Lind´en, 2008</marker>
<rawString>Krister Lind´en. 2008. A Probabilistic Model for Guessing Base Forms of New Words by Analogy. Proc. CICLing. Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David W Packard</author>
</authors>
<title>Computer-assisted Morphological Analysis of Ancient Greek.</title>
<date>1973</date>
<booktitle>Proc. 5th Conference on Computational Linguistics.</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="2962" citStr="Packard, 1973" startWordPosition="457" endWordPosition="458">understand the meaning of the word, or even look it up in a dictionary. For Classics scholars, these myriad forms also pose formidable challenges. In order to search for occurrences of a word in a corpus, all of its forms must be enumerated, since words do not frequently appear in their root forms. This procedure becomes extremely labor-intensive for small words that overlap with other common words (Crane, 1991). Automatic morphological analysis of ancient Greek would be useful for both educational and research purposes. In fact, one of the first analyzers was developed as a pedagogical tool (Packard, 1973). Today, a widely used analyzer is embedded in the Perseus Digital Library (Crane, 1996), an internet resource utilized by both students and researchers. This paper presents an analyzer of ancient Greek that infers the root form of a word. It introduces two innovations. First, it utilizes a nearestneighbor framework that requires no hand-crafted rules, and provides analogies to facilitate learning. 2The root is also called the “base” or “lexical look-up” form, since it is the form conventionally used in dictionary entries. For verbs in ancient Greek, the root form is the first person singular </context>
<context position="11143" citStr="Packard, 1973" startWordPosition="1783" endWordPosition="1784">epeph´ereto (hover) Verb ph´ero Table 2: Sample data from parts of Genesis 1:2 (“and the Spirit of God was hovering over ...”). The original annotation is more extensive, and only the portion utilized in this research is shown here. 3.3 Ancient Greek Morphological Analysis The two most well-known analyzers for ancient Greek are both rule-based systems, requiring a priori knowledge of the possible stems and affixes, which are manually compiled. To give a rough idea, some 40,000 stems and 13,000 inflections are known by the MORPHEUS system, which will be described below. The algorithm in MORPH (Packard, 1973) searches for possible endings that would result in a stem in its database. If unsuccessful, it then attempts to remove prepositions and prefixes from the beginning of the word. Accents, essential for disambiguation in some cases, are ignored. The analyzer was applied on Plato’s Apology to study the distribution of word endings, for the purpose of optimizing the order of grammar topics to be covered in an introductory course. Evaluation of the analyzer stressed this pedagogical perspective, and the accuracy of the analyses is not reported. MORPHEUS (Crane, 1991) augments MORPH with a generatio</context>
</contexts>
<marker>Packard, 1973</marker>
<rawString>David W. Packard. 1973. Computer-assisted Morphological Analysis of Ancient Greek. Proc. 5th Conference on Computational Linguistics. Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Richard Wicentowski</author>
</authors>
<title>Minimally Supervised Morphological Analysis by Multimodal Alignment.</title>
<date>2000</date>
<booktitle>Proc. ACL. Hong Kong,</booktitle>
<contexts>
<context position="8840" citStr="Yarowsky and Wicentowski, 2000" startWordPosition="1409" endWordPosition="1412"> use of Minimum Description Length, which iteratively shortens the length of the morphological grammar (Goldsmith, 2001). Spelling changes at morpheme boundaries (e.g., deny but deni-al) can be captured by orthographic rules such as “change y- to i- when the suffix is -al”. Such rules are specified manually in the twolevel model of morphology (Koskenniemi, 1983), but they can also be induced (Dasgupta, 2007). Allomorphs (e.g., “deni” and “deny”) are also automatically identified in (Dasgupta, 2007), but the general problem of recognizing highly irregular forms is examined more extensively in (Yarowsky and Wicentowski, 2000). They attempt to align every verb to its root form, by exploiting a combination of frequency similarity, context similarity, edit distance and morphological transformation probabilities, all estimated from an unannotated corpus. An accuracy of 80.4% was achieved for highly irregular words in the test set. 3.2 Challenges for Ancient Greek Ancient Greek presents a few difficulties that prevent a naive application of the minimally supervised approach in (Yarowsky and Wicentowski, 2000). First, frequency and context analyses are sensitive to data sparseness, which is more pronounced in heavily in</context>
</contexts>
<marker>Yarowsky, Wicentowski, 2000</marker>
<rawString>David Yarowsky and Richard Wicentowski. 2000. Minimally Supervised Morphological Analysis by Multimodal Alignment. Proc. ACL. Hong Kong, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>