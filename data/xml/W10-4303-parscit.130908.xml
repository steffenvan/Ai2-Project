<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.321582">
<note confidence="0.599345">
Invited Talk
</note>
<title confidence="0.995664">
Dynamic Adaptation in Dialog Systems
</title>
<author confidence="0.950206">
Marilyn Walker
</author>
<affiliation confidence="0.946409">
University of California, Santa Cruz
</affiliation>
<bodyText confidence="0.999835285714286">
A hallmark of human robust intelligence is the ability to flexibly and dynami-
cally adapt behavior to the current situation. For dialog behavior, this entails adap-
tation to features of both the dialog partner (e.g., relationship, age, personality) and
the dialog situation (e.g., task context, asynchronous interaction, limited modalities
such as voice-only communication). We don’t completely understand how humans
do this, nor do we have the ability to produce such dynamically adaptable behavior
in human computer dialog interaction. In this talk I will discuss our recent work on
dynamic adaptation to the user, and present some experimental results showing that
it is possible to automatically generate both verbal and nonverbal system behaviors
that are perceived by the user as reliably expressing particular system personalities.
I will describe two of my current projects at UCSC that are integrating these ca-
pabilities into mobile dialogue systems: SpyFeet, a role playing augmented reality
game for encouraging girls to exercise, and Skipper, a dialogue system that gives
pedestrians directions in both urban and campus environments.
</bodyText>
<subsubsectionHeader confidence="0.641194">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, page 17,
</subsubsectionHeader>
<affiliation confidence="0.769979">
The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999515">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.629845">
<title confidence="0.991005">Invited Talk Dynamic Adaptation in Dialog Systems</title>
<author confidence="0.99987">Marilyn Walker</author>
<affiliation confidence="0.994353">University of California, Santa Cruz</affiliation>
<abstract confidence="0.992928">A hallmark of human robust intelligence is the ability to flexibly and dynamically adapt behavior to the current situation. For dialog behavior, this entails adaptation to features of both the dialog partner (e.g., relationship, age, personality) and the dialog situation (e.g., task context, asynchronous interaction, limited modalities such as voice-only communication). We don’t completely understand how humans do this, nor do we have the ability to produce such dynamically adaptable behavior in human computer dialog interaction. In this talk I will discuss our recent work on dynamic adaptation to the user, and present some experimental results showing that it is possible to automatically generate both verbal and nonverbal system behaviors that are perceived by the user as reliably expressing particular system personalities. I will describe two of my current projects at UCSC that are integrating these capabilities into mobile dialogue systems: SpyFeet, a role playing augmented reality game for encouraging girls to exercise, and Skipper, a dialogue system that gives pedestrians directions in both urban and campus environments.</abstract>
<note confidence="0.877915">of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and page 17, University of Tokyo, September 24-25, 2010. Association for Computational Linguistics 17</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>