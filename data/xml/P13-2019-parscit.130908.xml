<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002527">
<title confidence="0.992849">
Joint Inference for Heterogeneous Dependency Parsing
</title>
<author confidence="0.993657">
Guangyou Zhou and Jun Zhao
</author>
<affiliation confidence="0.9953095">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
</affiliation>
<address confidence="0.966795">
95 Zhongguancun East Road, Beijing 100190, China
</address>
<email confidence="0.998786">
{gyzhou,jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.856268" genericHeader="abstract">
Abstract
</sectionHeader>
<equation confidence="0.9716215">
ᡞ(with) Ⳃܝ(eyes) ᡩ৥(cast) 佭␃(Hongkong)
BA NN VV NR
</equation>
<bodyText confidence="0.999553631578948">
This paper is concerned with the problem
of heterogeneous dependency parsing. In
this paper, we present a novel joint infer-
ence scheme, which is able to leverage
the consensus information between het-
erogeneous treebanks in the parsing phase.
Different from stacked learning meth-
ods (Nivre and McDonald, 2008; Martins
et al., 2008), which process the depen-
dency parsing in a pipelined way (e.g., a
second level uses the first level outputs), in
our method, multiple dependency parsing
models are coordinated to exchange con-
sensus information. We conduct experi-
ments on Chinese Dependency Treebank
(CDT) and Penn Chinese Treebank (CTB),
experimental results show that joint infer-
ence can bring significant improvements
to all state-of-the-art dependency parsers.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999080933333333">
Dependency parsing is the task of building depen-
dency links between words in a sentence, which
has recently gained a wide interest in the natu-
ral language processing community and has been
used for many problems ranging from machine
translation (Ding and Palmer, 2004) to question
answering (Zhou et al., 2011a). Over the past few
years, supervised learning methods have obtained
state-of-the-art performance for dependency pars-
ing (Yamada and Matsumoto, 2003; McDonald
et al., 2005; McDonald and Pereira, 2006; Hall
et al., 2006; Zhou et al., 2011b; Zhou et al.,
2011c). These methods usually rely heavily on
the manually annotated treebanks for training the
dependency models. However, annotating syntac-
</bodyText>
<equation confidence="0.6377975">
ᡞ(with) Ⳃܝ(eyes) ᡩ৥(cast) 佭␃(Hongkong)
p n v ns
</equation>
<figureCaption confidence="0.935173">
Figure 1: Different grammar formalisms of syn-
</figureCaption>
<bodyText confidence="0.991873225806452">
tactic structures between CTB (upper) and CDT
(below). CTB is converted into dependency gram-
mar based on the head rules of (Zhang and Clark,
2008).
tic structure, either phrase-based or dependency-
based, is both time consuming and labor intensive.
Making full use of the existing manually annotated
treebanks would yield substantial savings in data-
annotation costs.
In this paper, we present a joint inference
scheme for heterogenous dependency parsing.
This scheme is able to leverage consensus in-
formation between heterogenous treebanks dur-
ing the inference phase instead of using individual
output in a pipelined way, such as stacked learning
methods (Nivre and McDonald, 2008; Martins et
al., 2008). The basic idea is very simple: although
heterogenous treebanks have different grammar
formalisms, they share some consensus informa-
tion in dependency structures for the same sen-
tence. For example in Figure 1, the dependency
structures actually share some partial agreements
for the same sentence, the two words “eyes” and
“Hongkong” depend on “cast” in both Chinese
Dependency Treebank (CDT) (Liu et al., 2006)
and Penn Chinese Treebank (CTB) (Xue et al.,
2005). Therefore, we would like to train the de-
pendency parsers on individual heterogenous tree-
bank and jointly parse the same sentences with
consensus information exchanged between them.
The remainder of this paper is divided as fol-
</bodyText>
<page confidence="0.984979">
104
</page>
<note confidence="0.6262025">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–109,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9831505">
Figure 2: General joint inference scheme of het-
erogeneous dependency parsing.
</figureCaption>
<bodyText confidence="0.9772292">
lows. Section 2 gives a formal description of
the joint inference for heterogeneous dependency
parsing. In section 3, we present the experimental
results. Finally, we conclude with ideas for future
research.
</bodyText>
<sectionHeader confidence="0.973193" genericHeader="method">
2 Our Approach
</sectionHeader>
<bodyText confidence="0.99912">
The general joint inference scheme of heteroge-
neous dependency parsing is shown in Figure 2.
Here, heterogeneous treebanks refer to two Chi-
nese treebanks: CTB and CDT, therefore we have
only two parsers, but the framework is generic
enough to integrate more parsers. For easy expla-
nation of the joint inference scheme, we regard a
parser without consensus information as a base-
line parser, a parser incorporates consensus infor-
mation called a joint parser. Joint inference pro-
vides a framework that accommodates and coordi-
nates multiple dependency parsing models. Sim-
ilar to Li et al. (2009) and Zhu et al. (2010),
the joint inference for heterogeneous dependency
parsing consists of four components: (1) Joint In-
ference Model; (2) Parser Coordination; (3) Joint
Inference Features; (4) Parameter Estimation.
</bodyText>
<subsectionHeader confidence="0.964968">
2.1 Joint Inference Model
</subsectionHeader>
<bodyText confidence="0.999811">
For a given sentence x, a joint dependency parsing
model finds the best dependency parsing tree y∗
among the set of possible candidate parses Y(x)
based on a scoring function Fs:
</bodyText>
<equation confidence="0.998565">
y� = arg max Fs(x, y) (1)
yEY(x)
</equation>
<bodyText confidence="0.9980634">
Following (Li et al., 2009), we will use dk to de-
note the kth joint parser, and also use the notation
Hk(x) for a list of parse candidates of sentence
x determined by dk. The sth joint parser can be
written as:
</bodyText>
<equation confidence="0.878161">
Fs(x, y) = Ps(x, y) + ∑ Tk(y, Hk(x)) (2)
k,k#s
</equation>
<bodyText confidence="0.998709">
where Ps(x, y) is the score function of the sth
baseline model, and each Ψk(y, Hk(x)) is a partial
consensus score function with respect to dk and is
defined over y and Hk(x):
</bodyText>
<equation confidence="0.9918465">
Tk(y, Hk(x)) = ∑ Ak,lfk,l(y, Hk(x)) (3)
l
</equation>
<bodyText confidence="0.9994512">
where each fk,l(y,Hk(x)) is a feature function
based on a consensus measure between y and
Hk(x), and Ak,l is the corresponding weight pa-
rameter. Feature index l ranges over all consensus-
based features in equation (3).
</bodyText>
<subsectionHeader confidence="0.997871">
2.2 Parser Coordination
</subsectionHeader>
<bodyText confidence="0.983468428571429">
Note that in equation (2), though the baseline score
function Ps(x, y) can be computed individually,
the case of Ψk(y,Hk(x)) is more complicated. It
is not feasible to enumerate all parse candidates
for dependency parsing. In this paper, we use a
bootstrapping method to solve this problem. The
basic idea is that we can use baseline models’ n-
best output as seeds, and iteratively refine joint
models’ n-best output with joint inference. The
joint inference process is shown in Algorithm 1.
Algorithm 1 Joint inference for multiple parsers
Step1: For each joint parser dk, perform inference with
a baseline model, and memorize all dependency parsing
candidates generated during inference in Hk(x);
Step2: For each candidate in Hk(x), we extract subtrees
and store them in H′ k(x). First, we extract bigram-subtrees
that contain two words. If two words have a dependency
relation, we add these two words as a subtree into H′k(x).
Similarly, we can extract trigram-subtrees. Note that the
dependency direction is kept. Besides, we also store the
“ROOT” word of each candidate in H′k(x);
Step3: Use joint parsers to re-parse the sentence x with
the baseline features and joint inference features (see sub-
section 2.3). For joint parser dk, consensus-based features
of any dependency parsing candidate are computed based
on current setting of H′ s(x) for all s but k. New depen-
dency parsing candidates generated by dk in re-parsing are
cached in H″k(x);
Step4: Update all Hk(x) with H′′k(x);
Step5: Iterate from Step2 to Step4 until a preset iteration
limit is reached.
In Algorithm 1, dependency parsing candidates
of different parsers can be mutually improved. For
example, given two parsers d1 and d2 with candi-
dates H1 and H2, improvements on H1 enable d2
to improve H2, and H1 benefits from improved
H2, and so on.
We can see that a joint parser does not en-
large the search space of its baseline model, the
only change is parse scoring. By running a com-
plete inference process, joint model can be applied
to re-parsing all candidates explored by a parser.
</bodyText>
<figure confidence="0.991709">
test data
consensus information exchange
Joint inference
Treebank1
Parser1
Treebank2
Parser2
</figure>
<page confidence="0.99314">
105
</page>
<bodyText confidence="0.999449333333333">
Thus Step3 can be viewed as full-scale candidates
reranking because the reranking scope is beyond
the limited n-best output currently cached in Wk.
</bodyText>
<subsectionHeader confidence="0.99638">
2.3 Joint Inference Features
</subsectionHeader>
<bodyText confidence="0.999851333333333">
In this section we introduce the consensus-based
feature functions fk,l(y,Wk(x)) introduced in
equation (3). The formulation can be written as:
</bodyText>
<equation confidence="0.996898">
�k,l(y, �k(x)) � ∑ P(y′|dk)Il(y, y′) (4)
y′∈Hk(x)
</equation>
<bodyText confidence="0.970802272727273">
where y is a dependency parse of x by using parser
ds (s =� k), y′ is a dependency parse in Wk(x)
and P(y′|dk) is the posterior probability of depen-
dency parse y′ parsed by parser dk given sentence
x. Il(y, y′) is a consensus measure defined on y
and y′ using different feature functions.
Dependency parsing model P(y′|dk) can be
predicted by using the global linear models
(GLMs) (e.g., McDonald et al. (2005); McDonald
and Pereira (2006)). The consensus-based score
functions Il(y, y′) include the following parts:
</bodyText>
<listItem confidence="0.999439533333333">
(1) head-modifier dependencies. Each head-
modifier dependency (denoted as “edge”) is a tu-
ple t =&lt; h, m, h -+ m &gt;, so Iedge(y, y′) =
EtEy S(t, y′).
(2) sibling dependencies: Each sibling de-
pendency (denoted as “sib”) is a tuple t =&lt;
i, h, m, h � i -+ m &gt;, so Isib(y, y′) =
EtEy S(t, y′).
(3) grandparent dependencies: Each grand-
parent dependency (denoted as “gp”) is a tuple
t =&lt; h, i, m, h -+ i -+ m &gt;, so Igp(y, y′) =
E&lt;h,i,m,h-+i-+m&gt;Ey S(t, y′).
(4) root feature: This feature (denoted as
“root”) indicates whether the multiple depen-
dency parsing trees share the same “ROOT”, so
</listItem>
<equation confidence="0.6943835">
Iroot(y, y′) = E&lt;ROOT&gt;Ey S(&lt; ROOT &gt;, y′).
S(·, ·) is a indicator function–S(t, y′) is 1 if
</equation>
<bodyText confidence="0.977890083333333">
t E y′ and 0 otherwise, feature index l E
{edge, sib, gp, root} in equation (4). Note that
&lt; h, m, h -+ m &gt; and &lt; m, h, m -+ h &gt; are
two different edges.
In our joint model, we extend the baseline fea-
tures of (McDonald et al., 2005; McDonald and
Pereira, 2006; Carreras, 2007) by conjoining with
the consensus-based features, so that we can learn
in which kind of contexts the different parsers
agree/disagree. For the third-order features (e.g.,
grand-siblings and tri-siblings) described in (Koo
et al., 2010), we will discuss it in future work.
</bodyText>
<subsectionHeader confidence="0.982233">
2.4 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.999990428571429">
The parameters are tuned to maximize the depen-
dency parsing performance on the development
set, using an algorithm similar to the average per-
ceptron algorithm due to its strong performance
and fast training (Koo et al., 2008). Due to lim-
ited space, we do not present the details. For more
information, please refer to (Koo et al., 2008).
</bodyText>
<sectionHeader confidence="0.999776" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999945487179487">
In this section, we describe the experiments
to evaluate our proposed approach by using
CTB4 (Xue et al., 2005) and CDT (Liu et al.,
2006). For the former, we adopt a set of head-
selection rules (Zhang and Clark, 2008) to convert
the phrase structure syntax of treebank into a de-
pendency tree representation. The standard data
split of CTB4 from Wang et al. (2007) is used. For
the latter, we randomly select 2,000 sentences for
test set, another 2,000 sentences for development
set, and others for training set.
We use two baseline parsers, one trained on
CTB4, and another trained on CDT in the ex-
periments. We choose the n-best size of 16 and
the best iteration time of four on the development
set since these settings empirically give the best
performance. CTB4 and CDT use two different
POS tag sets and transforming from one tag set
to another is difficult (Niu et al., 2009). To over-
come this problem, we use Stanford POS Tagger1
to train a universal POS tagger on the People’s
Daily corpus,2 a large-scale Chinese corpus (ap-
proximately 300 thousand sentences and 7 mil-
lion words) annotated with word segmentation and
POS tags. Then the POS tagger produces a uni-
versal layer of POS tags for both the CTB4 and
CDT. Note that the word segmentation standards
of these corpora (CTB4, CDT and People’s Daily)
slightly differs; however, we do not consider this
problem and leave it for future research.
The performance of the parsers is evaluated us-
ing the following metrics: UAS, DA, and CM,
which are defined by (Hall et al., 2006). All the
metrics except CM are calculated as mean scores
per word, and punctuation tokens are consistently
excluded.
We conduct experiments incrementally to eval-
uate the joint features used in our first-order and
second-order parsers. The first-order parser
</bodyText>
<footnote confidence="0.758736">
&apos;http://nlp.stanford.edu/software/tagger.shtml
zhttp://www.icl.pku.edu.cn
</footnote>
<page confidence="0.95005">
106
</page>
<table confidence="0.999954142857143">
– Features CTB4 CDT
UAS CM UAS CM
dep1 baseline 86.6 42.5 75.4 16.6
+ edge 88.01 (x1.41) 44.28 (x1.78) 77.10 (x1.70) 17.82 (x1.22)
+ root 87.22 (x0.62) 43.03 (x0.53) 75.83 (x0.43) 16.81 (x0.21)
+ both 88.19 (x1.59) 44.54 (x2.04) 77.16 (x1.76) 17.90 (x1.30)
CTB4 + CDT 87.32 43.08 75.91 16.89
dep2 baseline 88.38 48.81 77.52 19.70
+ edge 89.17 (x0.79) 49.73 (x0.92) 78.44 (x0.92) 20.85 (x1.15)
+ sib 88.94 (x0.56) 49.26 (x0.45) 78.02 (x0.50) 20.13 (x0.43)
+ gp 88.90 (x0.52) 49.11 (x0.30) 77.97 (x0.45) 20.06 (x0.36)
+ root 88.61 (x0.23) 48.88 (x0.07) 77.65 (x0.13) 19.88 (x0.18)
+ all 89.62 (x1.24) 50.15 (x1.34) 79.01 (x1.49) 21.11 (x1.41)
CTB4 + CDT 88.91 49.13 78.03 20.12
</table>
<tableCaption confidence="0.939931833333333">
Table 1: Dependency parsing results on the test set with different joint inference features. Abbreviations:
dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint
inference features; +* = the baseline features conjoined with the joint inference features derived from the
heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency
parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over
baseline models are shown in parentheses.
</tableCaption>
<table confidence="0.99685925">
Type Systems &lt; 40 Full
D dep2 90.86 88.38
MaltParser 87.1 85.8
Wang et al. (2007) 86.6 -
C MSTm.lt† 90.55 88.82
Martins et al. (2008)† 90.63 88.84
Surdeanu et al. (2010)† 89.40 86.63
H Zhao et al. (2009) 88.9 86.1
Ours 91.48 89.62
S Yu et al. (2008) - 87.26
Chen et al. (2009) 92.34 89.91
Chen et al. (2012) - 91.59
</table>
<tableCaption confidence="0.996836">
Table 2: Comparison of different approach on
</tableCaption>
<bodyText confidence="0.993262442307692">
CTB4 test set using UAS metric. MaltParser =
Hall et al. (2006); MSTMalt=Nivre and McDon-
ald (2008). Type D = discriminative dependency
parsers without using any external resources; C =
combined parsers (stacked and ensemble parsers);
H = discriminative dependency parsers using ex-
ternal resources derived from heterogeneous tree-
banks, S = discriminative dependency parsers us-
ing external unlabeled data. † The results on CTB4
were not directly reported in these papers, we im-
plemented the experiments in this paper.
(dep1) only incorporates head-modifier depen-
dency part (McDonald et al., 2005). The second-
order parser (dep2) uses the head-modifier and
sibling dependency parts (McDonald and Pereira,
2006), as well as the grandparent dependency
part (Carreras, 2007; Koo et al., 2008). Table 1
shows the experimental results.
As shown in Table 1, we note that adding more
joint inference features incrementally, the depen-
dency parsing performance is improved consis-
tently, for both treebanks (CTB4 or CDT). As a
final note, all comparisons between joint models
and baseline models in Table 1 are statistically sig-
nificant.3 Furthermore, we also present a base-
line method called “CTB4 + CDT” for compari-
son. This method first tags both CTB4 and CDT
with the universal POS tagger trained on the Peo-
ple’s Daily corpus, then simply concatenates the
two corpora and trains a dependency parser, and
finally tests on CTB4 and CDT using this single
model. The comparisons in Table 1 tell us that
very limited information is obtained without con-
sensus features by simply taking a union of the
dependencies and their contexts from the two tree-
banks.
To put our results in perspective, we also com-
pare our second-order joint parser with other best-
performing systems. “≤ 40” refers to the sentence
with the length up to 40 and “Full” refers to all
the sentences in test set. The results are shown
in Table 2, our approach significantly outperforms
many systems evaluated on this data set. Chen
et al. (2009) and Chen et al. (2012) reported a
very high accuracy using subtree-based features
and dependency language model based features
derived from large-scale data. Our systems did not
use such knowledge. Moreover, their technique is
orthogonal to ours, and we suspect that combin-
ing their subtree-based features into our systems
might get an even better performance. We do not
present the comparison of our proposed approach
</bodyText>
<footnote confidence="0.884825">
3We use the sign test at the sentence level. All the com-
parisons are significant at p &lt; 0.05.
</footnote>
<page confidence="0.983561">
107
</page>
<note confidence="0.998029444444444">
Type Systems UAS DA
D Duan et al. (2007) 83.88 84.36
Huang and Sagae (2010) 85.20 85.52
Zhang and Nivre (2011) 86.0 -
C Zhang and Clark (2008) - 86.21
Bohnet and Kuhn (2012) 87.5 -
H Li et al. (2012) 86.44 -
Ours 85.88 86.52
S Chen et al. (2009) - 86.70
</note>
<tableCaption confidence="0.880345333333333">
Table 3: Comparison of different approaches on
CTB5 test set. Abbreviations D, C, H and S are as
in Table 2.
</tableCaption>
<table confidence="0.999089666666667">
Treebanks #Sen # Better # NoChange # Worse
CTB4 355 74 255 26
CDT 2,000 341 1,562 97
</table>
<tableCaption confidence="0.999838">
Table 4: Statistics on joint inference output on
</tableCaption>
<bodyText confidence="0.960386785714286">
CTB4 and CDT development set.
with the state-of-the-art methods on CDT because
there is little work conducted on this treebank.
Some researchers conducted experiments on
CTB5 with a different data split: files 1-815 and
files 1,001-1,136 for training, files 886-931 and
1,148-1,151 for development, files 816-885 and
files 1,137-1,147 for testing. The development
and testing sets were also performed using gold-
standard assigned POS tags. We report the experi-
mental results on CTB5 test set in Table 4. Our re-
sults are better than most systems on this data split,
except Zhang and Nivre (2011), Li et al. (2012)
and Chen et al. (2009).
</bodyText>
<subsectionHeader confidence="0.999711">
3.1 Additional Results
</subsectionHeader>
<bodyText confidence="0.9999676875">
To obtain further information about how depen-
dency parsers benefit from the joint inference, we
conduct an initial experiment on CTB4 and CDT.
From Table 4, we find that out of 355 sentences on
the development set of CTB4, 74 sentences ben-
efit from the joint inference, while 26 sentences
suffer from it. For CDT, we also find that out of
2,000 sentences on the development set, 341 sen-
tences benefit from the joint inference, while 97
sentences suffer from it. Although the overall de-
pendency parsing results is improved, joint infer-
ence worsens dependency parsing result for some
sentences. In order to obtain further information
about the error sources, it is necessary to investi-
gate why joint inference gives negative results, we
will leave it for future work.
</bodyText>
<sectionHeader confidence="0.993541" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999923045454545">
We proposed a novel framework of joint infer-
ence, in which multiple dependency parsing mod-
els were coordinated to search for better depen-
dency parses by leveraging the consensus infor-
mation between heterogeneous treebanks. Exper-
imental results showed that joint inference signif-
icantly outperformed the state-of-the-art baseline
models.
There are some ways in which this research
could be continued. First, recall that the joint in-
ference scheme involves an iterative algorithm by
using bootstrapping. Intuitively, there is a lack of
formal guarantee. A natural avenue for further re-
search would be the use of more powerful algo-
rithms that provide certificates of optimality; e.g.,
dual decomposition that aims to develop decod-
ing algorithms with formal guarantees (Rush et
al., 2010). Second, we would like to combine our
heterogeneous treebank annotations into a unified
representation in order to make dependency pars-
ing results comparable across different annotation
guidelines (e.g., Tsarfaty et al. (2011)).
</bodyText>
<sectionHeader confidence="0.998386" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999925727272727">
This work was supported by the National Natural
Science Foundation of China (No. 61070106, No.
61272332 and No. 61202329), the National High
Technology Development 863 Program of China
(No. 2012AA011102), the National Basic Re-
search Program of China (No. 2012CB316300),
We thank the anonymous reviewers and the prior
reviewers of ACL-2012 and AAAI-2013 for their
insightful comments. We also thank Dr. Li Cai for
providing and preprocessing the data set used in
this paper.
</bodyText>
<sectionHeader confidence="0.998858" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9965135625">
B. Bohnet and J. Kuhn. 2012. The best of both worlds-
a graph-based completion model for transition-
based parsers. In Proceedings of EACL.
X. Carreras. 2007. Experiments with a Higher-order
Projective Dependency Parser. In Proceedings of
EMNLP-CoNLL, pages 957-961.
W. Chen, D. Kawahara, K. Uchimoto, and Torisawa.
2009. Improving Dependency Parsing with Subtrees
from Auto-Parsed Data. In Proceedings of EMNLP,
pages 570-579.
W. Chen, M. Zhang, and H. Li. 2012. Utilizing depen-
dency language models for graph-based dependency
parsing models. In Proceedings of ACL.
Y. Ding and M. Palmer. 2004. Synchronous depen-
dency insertion grammars: a grammar formalism
for syntax based statistical MT. In Proceedings of
</reference>
<page confidence="0.994399">
108
</page>
<reference confidence="0.999215730769231">
the Workshop on Recent Advances in Dependency
Grammar, pages 90-97.
X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic Mod-
els for Action-based Chinese Dependency Parsing.
In Proceedings of ECML/PKDD.
J. M. Eisner. 2000. Bilexical Grammars and Their
Cubic-Time Parsing Algorithm. Advanced in Prob-
abilistic and Other Parsing Technologies, pages 29-
62.
J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative
Classifier for Deterministic Dependency Parsing. In
Proceedings ofACL, pages 316-323.
L. Huang and K. Sagae. 2010. Dynamic Programming
for Linear-Time Incremental Parsing. In Proceed-
ings ofACL, pages 1077-1086.
T. Koo, X. Carreras, and M. Collins. 2008. Simple
Semi-Supervised Dependency Parsing. In Proceed-
ings ofACL.
T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D.
Sontag. 2010. Dual Decomposition for Parsing with
Non-Projective Head Automata. In Proceedings of
EMNLP.
M. Li, N. Duan, D. Zhang, C.-H. Li, and M. Zhou.
2009. Collaborative Decoding: Partial Hypothesis
Re-ranking Using Translation Consensus Between
Decoders. In Proceedings ofACL, pages 585-592.
Z. Li, T. Liu, and W. Che. 2012. Exploiting multiple
treebanks for parsing with Quasi-synchronous gram-
mars. In Proceedings ofACL.
T. Liu, J. Ma, and S. Li. 2006. Building a Dependency
Treebank for Improving Chinese Parser. Journal of
Chinese Languages and Computing, 16(4):207-224.
A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing.
2008. Stacking Dependency Parsers. In Proceed-
ings of EMNLP, pages 157-166.
R. McDonald and F. Pereira. 2006. Online Learning of
Approximate Dependency Parsing Algorithms. In
Proceedings of EACL, pages 81-88.
R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line Large-margin Training of Dependency Parsers.
In Proceedings ofACL, pages 91-98.
Z. Niu, H. Wang, and H. Wu. 2009. Exploiting Het-
erogeneous Treebanks for Parsing. In Proceedings
ofACL, pages 46-54.
J. Nivre and R. McDonld. 2008. Integrating Graph-
based and Transition-based Dependency Parsing. In
Proceedings ofACL, pages 950-958.
A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On Dual Decomposition and Linear Program-
ming Relation for Natural Language Processing. In
Proceedings of EMNLP.
M. Surdeanu and C. D. Manning. 2010. Ensemble
Models for Dependency Parsing: Cheap and Good?
In Proceedings of NAACL.
R. Tsarfaty, J. Nivre, and E. Andersson. 2011. Eval-
uating Dependency Parsing: Robust and Heuristics-
Free Cross-Annotation Evaluation. In Proceedings
of EMNLP.
J.-N Wang, J-.S. Chang, and K.-Y. Su. 1994. An Au-
tomatic Treebank Conversion Algorithm for Corpus
Sharing. In Proceedings ofACL, pages 248-254.
Q. I. Wang, D. Lin, and D. Schuurmans. 2007. Sim-
ple Training of Dependency Parsers via Structured
Boosting. In Proceedings of IJCAI, pages 1756-
1762.
N. Xue, F. Xia, F.-D. Chiou, and M. Palmer. 2005.
The Penn Chinese Treebank: Phrase Structure An-
notation of a Large Corpus. Natural Language En-
gineering, 10(4):1-30.
Yamada and Matsumoto. 2003. Statistical Sependency
Analysis with Support Vector Machines. In Pro-
ceedings of IWPT, pages 195-206.
D. H. Younger. 1967. Recognition and Parsing of
Context-Free Languages in Time n3. Information
and Control, 12(4):361-379, 1967.
K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chi-
nese Dependency Parsing with Large Scale Auto-
matically Constructed Case Structures. In Proceed-
ings of COLING, pages 1049-1056.
Y. Zhang and S. Clark. 2008. A Tale of Two
Parsers: Investigating and Combining Graph-based
and Transition-based Dependency Parsing Using
Beam-Search. In Proceedings of EMNLP, pages
562-571.
Y. Zhang and J. Nivre. 2011. Transition-based De-
pendency Parsing with Rich Non-local Features. In
Proceedings ofACL, pages 188-193.
H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross
Language Dependency Parsing Using a Bilingual
Lexicon. In Proceedings ofACL, pages 55-63.
G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrase-
Based Translation Model for Question Retrieval in
Community Question Answer Archives. In Pro-
ceedings ofACL, pages 653-662.
G. Zhou, J. Zhao, K. Liu, and L. Cai. 2011. Exploit-
ing Web-Derived Selectional Preference to Improve
Statistical Dependency Parsing. In Proceedings of
ACL, pages 1556-1565.
G. Zhou, L. Cai, K. Liu, and J. Zhao. 2011. Improving
Dependency Parsing with Fined-Grained Features.
In Proceedings of IJCNLP, pages 228-236.
M. Zhu, J. Zhu, and T. Xiao. 2010. Heterogeneous
Parsing via Collaborative Decoding. In Proceedings
of COLING, pages 1344-1352.
</reference>
<page confidence="0.998961">
109
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.800056">
<title confidence="0.998852">Joint Inference for Heterogeneous Dependency Parsing</title>
<author confidence="0.977557">Zhou</author>
<affiliation confidence="0.987717">National Laboratory of Pattern Institute of Automation, Chinese Academy of</affiliation>
<address confidence="0.86459">95 Zhongguancun East Road, Beijing 100190,</address>
<abstract confidence="0.998101095238095">BA NN VV NR This paper is concerned with the problem of heterogeneous dependency parsing. In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase. Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>J Kuhn</author>
</authors>
<title>The best of both worldsa graph-based completion model for transitionbased parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="16324" citStr="Bohnet and Kuhn (2012)" startWordPosition="2680" endWordPosition="2683">ased features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-</context>
</contexts>
<marker>Bohnet, Kuhn, 2012</marker>
<rawString>B. Bohnet and J. Kuhn. 2012. The best of both worldsa graph-based completion model for transitionbased parsers. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
</authors>
<title>Experiments with a Higher-order Projective Dependency Parser.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>957--961</pages>
<contexts>
<context position="9525" citStr="Carreras, 2007" startWordPosition="1554" endWordPosition="1555"> dependency (denoted as “gp”) is a tuple t =&lt; h, i, m, h -+ i -+ m &gt;, so Igp(y, y′) = E&lt;h,i,m,h-+i-+m&gt;Ey S(t, y′). (4) root feature: This feature (denoted as “root”) indicates whether the multiple dependency parsing trees share the same “ROOT”, so Iroot(y, y′) = E&lt;ROOT&gt;Ey S(&lt; ROOT &gt;, y′). S(·, ·) is a indicator function–S(t, y′) is 1 if t E y′ and 0 otherwise, feature index l E {edge, sib, gp, root} in equation (4). Note that &lt; h, m, h -+ m &gt; and &lt; m, h, m -+ h &gt; are two different edges. In our joint model, we extend the baseline features of (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007) by conjoining with the consensus-based features, so that we can learn in which kind of contexts the different parsers agree/disagree. For the third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, p</context>
<context position="14403" citStr="Carreras, 2007" startWordPosition="2352" endWordPosition="2353">sing any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The secondorder parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008). Table 1 shows the experimental results. As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT). As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3 Furthermore, we also present a baseline method called “CTB4 + CDT” for comparison. This method first tags both CTB4 and CDT with the universal POS tagger trained on the People’s Daily corpus, then simply concatenates the two corpora and trai</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>X. Carreras. 2007. Experiments with a Higher-order Projective Dependency Parser. In Proceedings of EMNLP-CoNLL, pages 957-961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chen</author>
<author>D Kawahara</author>
<author>K Uchimoto</author>
<author>Torisawa</author>
</authors>
<title>Improving Dependency Parsing with Subtrees from Auto-Parsed Data.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>570--579</pages>
<contexts>
<context position="13552" citStr="Chen et al. (2009)" startWordPosition="2219" endWordPosition="2222">rence features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper.</context>
<context position="15633" citStr="Chen et al. (2009)" startWordPosition="2561" endWordPosition="2564">ncy parser, and finally tests on CTB4 and CDT using this single model. The comparisons in Table 1 tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks. To put our results in perspective, we also compare our second-order joint parser with other bestperforming systems. “≤ 40” refers to the sentence with the length up to 40 and “Full” refers to all the sentences in test set. The results are shown in Table 2, our approach significantly outperforms many systems evaluated on this data set. Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 </context>
<context position="17282" citStr="Chen et al. (2009)" startWordPosition="2850" endWordPosition="2853">elopment set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-1,151 for development, files 816-885 and files 1,137-1,147 for testing. The development and testing sets were also performed using goldstandard assigned POS tags. We report the experimental results on CTB5 test set in Table 4. Our results are better than most systems on this data split, except Zhang and Nivre (2011), Li et al. (2012) and Chen et al. (2009). 3.1 Additional Results To obtain further information about how dependency parsers benefit from the joint inference, we conduct an initial experiment on CTB4 and CDT. From Table 4, we find that out of 355 sentences on the development set of CTB4, 74 sentences benefit from the joint inference, while 26 sentences suffer from it. For CDT, we also find that out of 2,000 sentences on the development set, 341 sentences benefit from the joint inference, while 97 sentences suffer from it. Although the overall dependency parsing results is improved, joint inference worsens dependency parsing result fo</context>
</contexts>
<marker>Chen, Kawahara, Uchimoto, Torisawa, 2009</marker>
<rawString>W. Chen, D. Kawahara, K. Uchimoto, and Torisawa. 2009. Improving Dependency Parsing with Subtrees from Auto-Parsed Data. In Proceedings of EMNLP, pages 570-579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chen</author>
<author>M Zhang</author>
<author>H Li</author>
</authors>
<title>Utilizing dependency language models for graph-based dependency parsing models.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="13583" citStr="Chen et al. (2012)" startWordPosition="2225" endWordPosition="2228">ne features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-</context>
<context position="15656" citStr="Chen et al. (2012)" startWordPosition="2566" endWordPosition="2569"> tests on CTB4 and CDT using this single model. The comparisons in Table 1 tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks. To put our results in perspective, we also compare our second-order joint parser with other bestperforming systems. “≤ 40” refers to the sentence with the length up to 40 and “Full” refers to all the sentences in test set. The results are shown in Table 2, our approach significantly outperforms many systems evaluated on this data set. Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (</context>
</contexts>
<marker>Chen, Zhang, Li, 2012</marker>
<rawString>W. Chen, M. Zhang, and H. Li. 2012. Utilizing dependency language models for graph-based dependency parsing models. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ding</author>
<author>M Palmer</author>
</authors>
<title>Synchronous dependency insertion grammars: a grammar formalism for syntax based statistical MT.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Recent Advances in Dependency Grammar,</booktitle>
<pages>90--97</pages>
<contexts>
<context position="1358" citStr="Ding and Palmer, 2004" startWordPosition="197" endWordPosition="200">st level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converte</context>
</contexts>
<marker>Ding, Palmer, 2004</marker>
<rawString>Y. Ding and M. Palmer. 2004. Synchronous dependency insertion grammars: a grammar formalism for syntax based statistical MT. In Proceedings of the Workshop on Recent Advances in Dependency Grammar, pages 90-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Duan</author>
<author>J Zhao</author>
<author>B Xu</author>
</authors>
<title>Probabilistic Models for Action-based Chinese Dependency Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of ECML/PKDD.</booktitle>
<contexts>
<context position="16191" citStr="Duan et al. (2007)" startWordPosition="2655" endWordPosition="2658"> many systems evaluated on this data set. Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researcher</context>
</contexts>
<marker>Duan, Zhao, Xu, 2007</marker>
<rawString>X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic Models for Action-based Chinese Dependency Parsing. In Proceedings of ECML/PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Eisner</author>
</authors>
<title>Bilexical Grammars and Their Cubic-Time Parsing Algorithm.</title>
<date>2000</date>
<booktitle>Advanced in Probabilistic and Other Parsing Technologies,</booktitle>
<pages>29--62</pages>
<marker>Eisner, 2000</marker>
<rawString>J. M. Eisner. 2000. Bilexical Grammars and Their Cubic-Time Parsing Algorithm. Advanced in Probabilistic and Other Parsing Technologies, pages 29-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Discriminative Classifier for Deterministic Dependency Parsing.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>316--323</pages>
<contexts>
<context position="1619" citStr="Hall et al., 2006" startWordPosition="236" endWordPosition="239">ing significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full use of the existing manually annotated treebanks would yield substantial</context>
<context position="11707" citStr="Hall et al., 2006" startWordPosition="1925" endWordPosition="1928">Stanford POS Tagger1 to train a universal POS tagger on the People’s Daily corpus,2 a large-scale Chinese corpus (approximately 300 thousand sentences and 7 million words) annotated with word segmentation and POS tags. Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT. Note that the word segmentation standards of these corpora (CTB4, CDT and People’s Daily) slightly differs; however, we do not consider this problem and leave it for future research. The performance of the parsers is evaluated using the following metrics: UAS, DA, and CM, which are defined by (Hall et al., 2006). All the metrics except CM are calculated as mean scores per word, and punctuation tokens are consistently excluded. We conduct experiments incrementally to evaluate the joint features used in our first-order and second-order parsers. The first-order parser &apos;http://nlp.stanford.edu/software/tagger.shtml zhttp://www.icl.pku.edu.cn 106 – Features CTB4 CDT UAS CM UAS CM dep1 baseline 86.6 42.5 75.4 16.6 + edge 88.01 (x1.41) 44.28 (x1.78) 77.10 (x1.70) 17.82 (x1.22) + root 87.22 (x0.62) 43.03 (x0.53) 75.83 (x0.43) 16.81 (x0.21) + both 88.19 (x1.59) 44.54 (x2.04) 77.16 (x1.76) 17.90 (x1.30) CTB4 +</context>
<context position="13700" citStr="Hall et al. (2006)" startWordPosition="2246" endWordPosition="2249">ply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The secondorder parser (dep2) uses the head-modifier and sibling de</context>
</contexts>
<marker>Hall, Nivre, Nilsson, 2006</marker>
<rawString>J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative Classifier for Deterministic Dependency Parsing. In Proceedings ofACL, pages 316-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
<author>K Sagae</author>
</authors>
<title>Dynamic Programming for Linear-Time Incremental Parsing.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>1077--1086</pages>
<contexts>
<context position="16226" citStr="Huang and Sagae (2010)" startWordPosition="2661" endWordPosition="2664"> data set. Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 wit</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>L. Huang and K. Sagae. 2010. Dynamic Programming for Linear-Time Incremental Parsing. In Proceedings ofACL, pages 1077-1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>X Carreras</author>
<author>M Collins</author>
</authors>
<title>Simple Semi-Supervised Dependency Parsing.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="10047" citStr="Koo et al., 2008" startWordPosition="1633" endWordPosition="1636">nd the baseline features of (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007) by conjoining with the consensus-based features, so that we can learn in which kind of contexts the different parsers agree/disagree. For the third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for develop</context>
<context position="14422" citStr="Koo et al., 2008" startWordPosition="2354" endWordPosition="2357">l resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The secondorder parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008). Table 1 shows the experimental results. As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT). As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3 Furthermore, we also present a baseline method called “CTB4 + CDT” for comparison. This method first tags both CTB4 and CDT with the universal POS tagger trained on the People’s Daily corpus, then simply concatenates the two corpora and trains a dependency par</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>T. Koo, X. Carreras, and M. Collins. 2008. Simple Semi-Supervised Dependency Parsing. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>A M Rush</author>
<author>M Collins</author>
<author>T Jaakkola</author>
<author>D Sontag</author>
</authors>
<title>Dual Decomposition for Parsing with Non-Projective Head Automata.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="9760" citStr="Koo et al., 2010" startWordPosition="1586" endWordPosition="1589">ame “ROOT”, so Iroot(y, y′) = E&lt;ROOT&gt;Ey S(&lt; ROOT &gt;, y′). S(·, ·) is a indicator function–S(t, y′) is 1 if t E y′ and 0 otherwise, feature index l E {edge, sib, gp, root} in equation (4). Note that &lt; h, m, h -+ m &gt; and &lt; m, h, m -+ h &gt; are two different edges. In our joint model, we extend the baseline features of (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007) by conjoining with the consensus-based features, so that we can learn in which kind of contexts the different parsers agree/disagree. For the third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselectio</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Sontag. 2010. Dual Decomposition for Parsing with Non-Projective Head Automata. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Li</author>
<author>N Duan</author>
<author>D Zhang</author>
<author>C-H Li</author>
<author>M Zhou</author>
</authors>
<title>Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>585--592</pages>
<contexts>
<context position="4363" citStr="Li et al. (2009)" startWordPosition="659" endWordPosition="662">research. 2 Our Approach The general joint inference scheme of heterogeneous dependency parsing is shown in Figure 2. Here, heterogeneous treebanks refer to two Chinese treebanks: CTB and CDT, therefore we have only two parsers, but the framework is generic enough to integrate more parsers. For easy explanation of the joint inference scheme, we regard a parser without consensus information as a baseline parser, a parser incorporates consensus information called a joint parser. Joint inference provides a framework that accommodates and coordinates multiple dependency parsing models. Similar to Li et al. (2009) and Zhu et al. (2010), the joint inference for heterogeneous dependency parsing consists of four components: (1) Joint Inference Model; (2) Parser Coordination; (3) Joint Inference Features; (4) Parameter Estimation. 2.1 Joint Inference Model For a given sentence x, a joint dependency parsing model finds the best dependency parsing tree y∗ among the set of possible candidate parses Y(x) based on a scoring function Fs: y� = arg max Fs(x, y) (1) yEY(x) Following (Li et al., 2009), we will use dk to denote the kth joint parser, and also use the notation Hk(x) for a list of parse candidates of se</context>
</contexts>
<marker>Li, Duan, Zhang, Li, Zhou, 2009</marker>
<rawString>M. Li, N. Duan, D. Zhang, C.-H. Li, and M. Zhou. 2009. Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders. In Proceedings ofACL, pages 585-592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Li</author>
<author>T Liu</author>
<author>W Che</author>
</authors>
<title>Exploiting multiple treebanks for parsing with Quasi-synchronous grammars.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="16350" citStr="Li et al. (2012)" startWordPosition="2687" endWordPosition="2690">guage model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-1,151 for development, fil</context>
</contexts>
<marker>Li, Liu, Che, 2012</marker>
<rawString>Z. Li, T. Liu, and W. Che. 2012. Exploiting multiple treebanks for parsing with Quasi-synchronous grammars. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Liu</author>
<author>J Ma</author>
<author>S Li</author>
</authors>
<title>Building a Dependency Treebank for Improving Chinese Parser.</title>
<date>2006</date>
<journal>Journal of Chinese Languages and Computing,</journal>
<pages>16--4</pages>
<contexts>
<context position="3001" citStr="Liu et al., 2006" startWordPosition="448" endWordPosition="451">nformation between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008). The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence. For example in Figure 1, the dependency structures actually share some partial agreements for the same sentence, the two words “eyes” and “Hongkong” depend on “cast” in both Chinese Dependency Treebank (CDT) (Liu et al., 2006) and Penn Chinese Treebank (CTB) (Xue et al., 2005). Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them. The remainder of this paper is divided as fol104 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–109, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 2: General joint inference scheme of heterogeneous dependency parsing. lows. Section 2 gives a formal description of the jo</context>
<context position="10312" citStr="Liu et al., 2006" startWordPosition="1681" endWordPosition="1684"> grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set. We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give </context>
</contexts>
<marker>Liu, Ma, Li, 2006</marker>
<rawString>T. Liu, J. Ma, and S. Li. 2006. Building a Dependency Treebank for Improving Chinese Parser. Journal of Chinese Languages and Computing, 16(4):207-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F T Martins</author>
<author>D Das</author>
<author>N A Smith</author>
<author>E P Xing</author>
</authors>
<title>Stacking Dependency Parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>157--166</pages>
<contexts>
<context position="644" citStr="Martins et al., 2008" startWordPosition="88" endWordPosition="91">erogeneous Dependency Parsing Guangyou Zhou and Jun Zhao National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences 95 Zhongguancun East Road, Beijing 100190, China {gyzhou,jzhao}@nlpr.ia.ac.cn Abstract ᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) BA NN VV NR This paper is concerned with the problem of heterogeneous dependency parsing. In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase. Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language</context>
<context position="2589" citStr="Martins et al., 2008" startWordPosition="385" endWordPosition="388">endency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full use of the existing manually annotated treebanks would yield substantial savings in dataannotation costs. In this paper, we present a joint inference scheme for heterogenous dependency parsing. This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008). The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence. For example in Figure 1, the dependency structures actually share some partial agreements for the same sentence, the two words “eyes” and “Hongkong” depend on “cast” in both Chinese Dependency Treebank (CDT) (Liu et al., 2006) and Penn Chinese Treebank (CTB) (Xue et al., 2005). Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with </context>
<context position="13409" citStr="Martins et al. (2008)" startWordPosition="2190" endWordPosition="2193">oint inference features. Abbreviations: dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint inference features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers</context>
</contexts>
<marker>Martins, Das, Smith, Xing, 2008</marker>
<rawString>A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing. 2008. Stacking Dependency Parsers. In Proceedings of EMNLP, pages 157-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online Learning of Approximate Dependency Parsing Algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="1600" citStr="McDonald and Pereira, 2006" startWordPosition="232" endWordPosition="235"> that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full use of the existing manually annotated treebanks woul</context>
<context position="8500" citStr="McDonald and Pereira (2006)" startWordPosition="1353" endWordPosition="1356">s section we introduce the consensus-based feature functions fk,l(y,Wk(x)) introduced in equation (3). The formulation can be written as: �k,l(y, �k(x)) � ∑ P(y′|dk)Il(y, y′) (4) y′∈Hk(x) where y is a dependency parse of x by using parser ds (s =� k), y′ is a dependency parse in Wk(x) and P(y′|dk) is the posterior probability of dependency parse y′ parsed by parser dk given sentence x. Il(y, y′) is a consensus measure defined on y and y′ using different feature functions. Dependency parsing model P(y′|dk) can be predicted by using the global linear models (GLMs) (e.g., McDonald et al. (2005); McDonald and Pereira (2006)). The consensus-based score functions Il(y, y′) include the following parts: (1) head-modifier dependencies. Each headmodifier dependency (denoted as “edge”) is a tuple t =&lt; h, m, h -+ m &gt;, so Iedge(y, y′) = EtEy S(t, y′). (2) sibling dependencies: Each sibling dependency (denoted as “sib”) is a tuple t =&lt; i, h, m, h � i -+ m &gt;, so Isib(y, y′) = EtEy S(t, y′). (3) grandparent dependencies: Each grandparent dependency (denoted as “gp”) is a tuple t =&lt; h, i, m, h -+ i -+ m &gt;, so Igp(y, y′) = E&lt;h,i,m,h-+i-+m&gt;Ey S(t, y′). (4) root feature: This feature (denoted as “root”) indicates whether the mu</context>
<context position="14343" citStr="McDonald and Pereira, 2006" startWordPosition="2341" endWordPosition="2344">and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The secondorder parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008). Table 1 shows the experimental results. As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT). As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3 Furthermore, we also present a baseline method called “CTB4 + CDT” for comparison. This method first tags both CTB4 and CDT with the universal POS tagger trained on the People’s Dai</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online Learning of Approximate Dependency Parsing Algorithms. In Proceedings of EACL, pages 81-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online Large-margin Training of Dependency Parsers.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>91--98</pages>
<contexts>
<context position="1572" citStr="McDonald et al., 2005" startWordPosition="228" endWordPosition="231">perimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full use of the existing manua</context>
<context position="8471" citStr="McDonald et al. (2005)" startWordPosition="1349" endWordPosition="1352">nference Features In this section we introduce the consensus-based feature functions fk,l(y,Wk(x)) introduced in equation (3). The formulation can be written as: �k,l(y, �k(x)) � ∑ P(y′|dk)Il(y, y′) (4) y′∈Hk(x) where y is a dependency parse of x by using parser ds (s =� k), y′ is a dependency parse in Wk(x) and P(y′|dk) is the posterior probability of dependency parse y′ parsed by parser dk given sentence x. Il(y, y′) is a consensus measure defined on y and y′ using different feature functions. Dependency parsing model P(y′|dk) can be predicted by using the global linear models (GLMs) (e.g., McDonald et al. (2005); McDonald and Pereira (2006)). The consensus-based score functions Il(y, y′) include the following parts: (1) head-modifier dependencies. Each headmodifier dependency (denoted as “edge”) is a tuple t =&lt; h, m, h -+ m &gt;, so Iedge(y, y′) = EtEy S(t, y′). (2) sibling dependencies: Each sibling dependency (denoted as “sib”) is a tuple t =&lt; i, h, m, h � i -+ m &gt;, so Isib(y, y′) = EtEy S(t, y′). (3) grandparent dependencies: Each grandparent dependency (denoted as “gp”) is a tuple t =&lt; h, i, m, h -+ i -+ m &gt;, so Igp(y, y′) = E&lt;h,i,m,h-+i-+m&gt;Ey S(t, y′). (4) root feature: This feature (denoted as “ro</context>
<context position="14231" citStr="McDonald et al., 2005" startWordPosition="2325" endWordPosition="2328">on of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The secondorder parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008). Table 1 shows the experimental results. As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT). As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3 Furthermore, we also present a baseline method called “CTB4 + CDT” fo</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online Large-margin Training of Dependency Parsers. In Proceedings ofACL, pages 91-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Niu</author>
<author>H Wang</author>
<author>H Wu</author>
</authors>
<title>Exploiting Heterogeneous Treebanks for Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>46--54</pages>
<contexts>
<context position="11054" citStr="Niu et al., 2009" startWordPosition="1812" endWordPosition="1815">ebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set. We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance. CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult (Niu et al., 2009). To overcome this problem, we use Stanford POS Tagger1 to train a universal POS tagger on the People’s Daily corpus,2 a large-scale Chinese corpus (approximately 300 thousand sentences and 7 million words) annotated with word segmentation and POS tags. Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT. Note that the word segmentation standards of these corpora (CTB4, CDT and People’s Daily) slightly differs; however, we do not consider this problem and leave it for future research. The performance of the parsers is evaluated using the following metrics: UAS,</context>
</contexts>
<marker>Niu, Wang, Wu, 2009</marker>
<rawString>Z. Niu, H. Wang, and H. Wu. 2009. Exploiting Heterogeneous Treebanks for Parsing. In Proceedings ofACL, pages 46-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>R McDonld</author>
</authors>
<title>Integrating Graphbased and Transition-based Dependency Parsing.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>950--958</pages>
<marker>Nivre, McDonld, 2008</marker>
<rawString>J. Nivre and R. McDonld. 2008. Integrating Graphbased and Transition-based Dependency Parsing. In Proceedings ofACL, pages 950-958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Rush</author>
<author>D Sontag</author>
<author>M Collins</author>
<author>T Jaakkola</author>
</authors>
<title>On Dual Decomposition and Linear Programming Relation for Natural Language Processing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="18886" citStr="Rush et al., 2010" startWordPosition="3107" endWordPosition="3110">e consensus information between heterogeneous treebanks. Experimental results showed that joint inference significantly outperformed the state-of-the-art baseline models. There are some ways in which this research could be continued. First, recall that the joint inference scheme involves an iterative algorithm by using bootstrapping. Intuitively, there is a lack of formal guarantee. A natural avenue for further research would be the use of more powerful algorithms that provide certificates of optimality; e.g., dual decomposition that aims to develop decoding algorithms with formal guarantees (Rush et al., 2010). Second, we would like to combine our heterogeneous treebank annotations into a unified representation in order to make dependency parsing results comparable across different annotation guidelines (e.g., Tsarfaty et al. (2011)). Acknowledgments This work was supported by the National Natural Science Foundation of China (No. 61070106, No. 61272332 and No. 61202329), the National High Technology Development 863 Program of China (No. 2012AA011102), the National Basic Research Program of China (No. 2012CB316300), We thank the anonymous reviewers and the prior reviewers of ACL-2012 and AAAI-2013 f</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola. 2010. On Dual Decomposition and Linear Programming Relation for Natural Language Processing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>C D Manning</author>
</authors>
<title>Ensemble Models for Dependency Parsing: Cheap and Good?</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<marker>Surdeanu, Manning, 2010</marker>
<rawString>M. Surdeanu and C. D. Manning. 2010. Ensemble Models for Dependency Parsing: Cheap and Good? In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tsarfaty</author>
<author>J Nivre</author>
<author>E Andersson</author>
</authors>
<title>Evaluating Dependency Parsing: Robust and HeuristicsFree Cross-Annotation Evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Tsarfaty, Nivre, Andersson, 2011</marker>
<rawString>R. Tsarfaty, J. Nivre, and E. Andersson. 2011. Evaluating Dependency Parsing: Robust and HeuristicsFree Cross-Annotation Evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-N Wang</author>
<author>J- S Chang</author>
<author>K-Y Su</author>
</authors>
<title>An Automatic Treebank Conversion Algorithm for Corpus Sharing.</title>
<date>1994</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>248--254</pages>
<marker>Wang, Chang, Su, 1994</marker>
<rawString>J.-N Wang, J-.S. Chang, and K.-Y. Su. 1994. An Automatic Treebank Conversion Algorithm for Corpus Sharing. In Proceedings ofACL, pages 248-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q I Wang</author>
<author>D Lin</author>
<author>D Schuurmans</author>
</authors>
<title>Simple Training of Dependency Parsers via Structured Boosting.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1756--1762</pages>
<contexts>
<context position="10537" citStr="Wang et al. (2007)" startWordPosition="1721" endWordPosition="1724">sing an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set. We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance. CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult (Niu et al., 2009). To overcome this problem, we use Stanford POS Tagger1 to train a universal POS ta</context>
<context position="13357" citStr="Wang et al. (2007)" startWordPosition="2180" endWordPosition="2183"> parsing results on the test set with different joint inference features. Abbreviations: dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint inference features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogene</context>
</contexts>
<marker>Wang, Lin, Schuurmans, 2007</marker>
<rawString>Q. I. Wang, D. Lin, and D. Schuurmans. 2007. Simple Training of Dependency Parsers via Structured Boosting. In Proceedings of IJCAI, pages 1756-1762.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>F Xia</author>
<author>F-D Chiou</author>
<author>M Palmer</author>
</authors>
<title>The Penn Chinese Treebank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering,</title>
<date>2005</date>
<pages>10--4</pages>
<contexts>
<context position="3052" citStr="Xue et al., 2005" startWordPosition="457" endWordPosition="460">e inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008). The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence. For example in Figure 1, the dependency structures actually share some partial agreements for the same sentence, the two words “eyes” and “Hongkong” depend on “cast” in both Chinese Dependency Treebank (CDT) (Liu et al., 2006) and Penn Chinese Treebank (CTB) (Xue et al., 2005). Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them. The remainder of this paper is divided as fol104 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–109, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 2: General joint inference scheme of heterogeneous dependency parsing. lows. Section 2 gives a formal description of the joint inference for heterogeneous dependency parsing.</context>
<context position="10285" citStr="Xue et al., 2005" startWordPosition="1675" endWordPosition="1678">third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set. We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>N. Xue, F. Xia, F.-D. Chiou, and M. Palmer. 2005. The Penn Chinese Treebank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 10(4):1-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yamada</author>
<author>Matsumoto</author>
</authors>
<title>Statistical Sependency Analysis with Support Vector Machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="1549" citStr="Yamada and Matsumoto, 2003" startWordPosition="224" endWordPosition="227">n Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full us</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Yamada and Matsumoto. 2003. Statistical Sependency Analysis with Support Vector Machines. In Proceedings of IWPT, pages 195-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Younger</author>
</authors>
<title>Recognition and Parsing of Context-Free Languages</title>
<date>1967</date>
<booktitle>in Time n3. Information and Control,</booktitle>
<pages>12--4</pages>
<marker>Younger, 1967</marker>
<rawString>D. H. Younger. 1967. Recognition and Parsing of Context-Free Languages in Time n3. Information and Control, 12(4):361-379, 1967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yu</author>
<author>D Kawahara</author>
<author>S Kurohashi</author>
</authors>
<title>Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>1049--1056</pages>
<contexts>
<context position="13525" citStr="Yu et al. (2008)" startWordPosition="2213" endWordPosition="2216">onsidering any joint inference features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the</context>
</contexts>
<marker>Yu, Kawahara, Kurohashi, 2008</marker>
<rawString>K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures. In Proceedings of COLING, pages 1049-1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>562--571</pages>
<contexts>
<context position="2034" citStr="Zhang and Clark, 2008" startWordPosition="302" endWordPosition="305">past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive. Making full use of the existing manually annotated treebanks would yield substantial savings in dataannotation costs. In this paper, we present a joint inference scheme for heterogenous dependency parsing. This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008). The basic idea is very simple: although het</context>
<context position="10391" citStr="Zhang and Clark, 2008" startWordPosition="1696" endWordPosition="1699"> discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008). 3 Experiments In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set. We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance. CTB4 and CDT use two different POS tag sets and transform</context>
<context position="16293" citStr="Zhang and Clark (2008)" startWordPosition="2674" endWordPosition="2677">y high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for tra</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. 2008. A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search. In Proceedings of EMNLP, pages 562-571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>J Nivre</author>
</authors>
<title>Transition-based Dependency Parsing with Rich Non-local Features.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>188--193</pages>
<contexts>
<context position="16261" citStr="Zhang and Nivre (2011)" startWordPosition="2667" endWordPosition="2670">hen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3We use the sign test at the sentence level. All the comparisons are significant at p &lt; 0.05. 107 Type Systems UAS DA D Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 - C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 - H Li et al. (2012) 86.44 - Ours 85.88 86.52 S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank. Some researchers conducted experiments on CTB5 with a different data split: files 1-8</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Y. Zhang and J. Nivre. 2011. Transition-based Dependency Parsing with Rich Non-local Features. In Proceedings ofACL, pages 188-193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhao</author>
<author>Y Song</author>
<author>C Kit</author>
<author>G Zhou</author>
</authors>
<title>Cross Language Dependency Parsing Using a Bilingual Lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>55--63</pages>
<contexts>
<context position="13479" citStr="Zhao et al. (2009)" startWordPosition="2203" endWordPosition="2206">d second-order parser; baseline = dep1 without considering any joint inference features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems &lt; 40 Full D dep2 90.86 88.38 MaltParser 87.1 85.8 Wang et al. (2007) 86.6 - C MSTm.lt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63 H Zhao et al. (2009) 88.9 86.1 Ours 91.48 89.62 S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directl</context>
</contexts>
<marker>Zhao, Song, Kit, Zhou, 2009</marker>
<rawString>H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross Language Dependency Parsing Using a Bilingual Lexicon. In Proceedings ofACL, pages 55-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>L Cai</author>
<author>J Zhao</author>
<author>K Liu</author>
</authors>
<title>PhraseBased Translation Model for Question Retrieval in Community Question Answer Archives.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>653--662</pages>
<contexts>
<context position="1399" citStr="Zhou et al., 2011" startWordPosition="204" endWordPosition="207">endency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the he</context>
</contexts>
<marker>Zhou, Cai, Zhao, Liu, 2011</marker>
<rawString>G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. PhraseBased Translation Model for Question Retrieval in Community Question Answer Archives. In Proceedings ofACL, pages 653-662.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>J Zhao</author>
<author>K Liu</author>
<author>L Cai</author>
</authors>
<title>Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1556--1565</pages>
<contexts>
<context position="1399" citStr="Zhou et al., 2011" startWordPosition="204" endWordPosition="207">endency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the he</context>
</contexts>
<marker>Zhou, Zhao, Liu, Cai, 2011</marker>
<rawString>G. Zhou, J. Zhao, K. Liu, and L. Cai. 2011. Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing. In Proceedings of ACL, pages 1556-1565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>L Cai</author>
<author>K Liu</author>
<author>J Zhao</author>
</authors>
<title>Improving Dependency Parsing with Fined-Grained Features.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>228--236</pages>
<contexts>
<context position="1399" citStr="Zhou et al., 2011" startWordPosition="204" endWordPosition="207">endency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers. 1 Introduction Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntacᡞ(with) Ⳃܝ(eyes) ᡩ(cast) 佭␃(Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the he</context>
</contexts>
<marker>Zhou, Cai, Liu, Zhao, 2011</marker>
<rawString>G. Zhou, L. Cai, K. Liu, and J. Zhao. 2011. Improving Dependency Parsing with Fined-Grained Features. In Proceedings of IJCNLP, pages 228-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhu</author>
<author>J Zhu</author>
<author>T Xiao</author>
</authors>
<title>Heterogeneous Parsing via Collaborative Decoding.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>1344--1352</pages>
<contexts>
<context position="4385" citStr="Zhu et al. (2010)" startWordPosition="664" endWordPosition="667">ach The general joint inference scheme of heterogeneous dependency parsing is shown in Figure 2. Here, heterogeneous treebanks refer to two Chinese treebanks: CTB and CDT, therefore we have only two parsers, but the framework is generic enough to integrate more parsers. For easy explanation of the joint inference scheme, we regard a parser without consensus information as a baseline parser, a parser incorporates consensus information called a joint parser. Joint inference provides a framework that accommodates and coordinates multiple dependency parsing models. Similar to Li et al. (2009) and Zhu et al. (2010), the joint inference for heterogeneous dependency parsing consists of four components: (1) Joint Inference Model; (2) Parser Coordination; (3) Joint Inference Features; (4) Parameter Estimation. 2.1 Joint Inference Model For a given sentence x, a joint dependency parsing model finds the best dependency parsing tree y∗ among the set of possible candidate parses Y(x) based on a scoring function Fs: y� = arg max Fs(x, y) (1) yEY(x) Following (Li et al., 2009), we will use dk to denote the kth joint parser, and also use the notation Hk(x) for a list of parse candidates of sentence x determined by</context>
</contexts>
<marker>Zhu, Zhu, Xiao, 2010</marker>
<rawString>M. Zhu, J. Zhu, and T. Xiao. 2010. Heterogeneous Parsing via Collaborative Decoding. In Proceedings of COLING, pages 1344-1352.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>