<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.9635955">
A SEMANTIC INTERPRETER FOR
SYSTEMIC GRAMMARS
</title>
<author confidence="0.761171">
Tim F. O&apos;Donoghue
</author>
<affiliation confidence="0.9059505">
timmyeuk.ac.leeds.ai
Division of Artificial Intelligence
School of Computer Studies
The University of Leeds
</affiliation>
<address confidence="0.961742">
Leeds LS2 9JT. UK
+44 532 335430
</address>
<sectionHeader confidence="0.777794" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999595384615385">
This paper describes a method for obtaining the
semantic representation for a syntax tree in Sys-
temic Grammar (SG). A prototype implementation
of this method — the REVELATION1 semantic inter-
preter — has been developed. It is derived from
a SG generator for a large subset of English —
GENESYS — and is &apos;thus, in contrast with most re-
versible grammars, ,an interpreter based on a gen-
erator. A task decomposition approach is adopted
for this reversal process which operates within the
framework of SG, thus demonstrating that Systemic
Grammars can be reversed and hence that a SG is
a truly bi-directional formalism,
</bodyText>
<sectionHeader confidence="0.979093" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.991603625000001">
SG (see Butler [4] for a good introduction) is a
useful model of language, having found many ap-
plications in the 4reas of stylistics, text analy-
sis, educational linguistics and artificial intelligence.
Some of these applications have been computa-
tional, the best known probably being Winograd&apos;s
SHRDLU [22]. However, most computational appli-
cations have been designed from a text-generation
viewpoint (such as Davey&apos;s PROTEUS [6], Mann
and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and
Tucker&apos;s GENESYS POD.
Because of this text-generation viewpoint of sys-
temic grammarian, the mechanism for sentence
analysis within SG the reverse of the sentence gen-
eration process) has received much less attention.
This paper describes one stage of the sentence anal-
ysis process: semantic interpretation.&apos;
&apos;This assumes that sentence analysis can be decomposed
into two processes: syntactic analysis (parsing) plus semantic
In Fawcett&apos;s SG,2 a syntax tree (whose leaves de-
fine a sentence) is generated from a set of semantic
choices. REVELATION1 reverses this process: it at-
tempts to find the set of semantic choices needed
to generate a given syntax tree. In sentence gener-
ation, a tree is generated, but only the leaves (the
words) are &apos;output&apos;, the rest of the tree is simply
deleted. In the reverse process, when a sentence is
input, a syntax tree must first be found before it can
be interpreted. REVELATION1 assumes that a sepa-
rate SG parser (not discussed here) is available; for
an example of such a parser see O&apos;Donoghue [20].
Thus REVELATION1 directly mirrors the generator,
while the parser mirrors the tree deletion process.
REVELATI0N1 has been developed within the
POPLOG environment.3 It is coded in a com-
bination of P0P11 [1] and Prolog [5] and utilizes
GENESYS. GENESYS is a very large SG generator for
English, written in Prolog (Fawcett and Tucker [10])
and it is version PG1.5 that has been used for the de-
velopment and testing of REVELATION 1. GENESYS
and REVELATION are part of a much larger project,
the COMMUNAL4 Project, the aim of which is
to build a natural language interface to a rich SG
oriented IKBS in the domain of personnel manage-
interpretation. These processes are not necessarily sequential,
although it greatly simplifies things if they are treated as
such. Here I assume a sequential scheme in which the parsing
process passes a syntax tree to the interpreter.
</bodyText>
<footnote confidence="0.8420016">
2 Fawcett&apos;s Systemic Functional Grammar [8, 9], his devel-
opment. of a Hallidayan SG.
3POPLOG is a multi-language development environment
containing incremental compilers for POP11 (the base lan-
guage), Prolog, Common Lisp and Standard ML, an inte-
grated editor and numerous support tools [12[.
4 The COMMUNAL Project at University of Wales Col-
lege of Cardiff (UWCC) Computational Linguistics Unit and
Leeds University School of Computer Studies was sponsored
by RSHE Malvern, ICL and Longman.
</footnote>
<page confidence="0.995191">
3.29
</page>
<figure confidence="0.9735985">
1C2
ULYI
VEZE
who open+ing
</figure>
<figureCaption confidence="0.999971">
Figure 1: A Typical PG 1.5 Syntax Tree
</figureCaption>
<bodyText confidence="0.996344">
men t.
This is not the first time a semantic interpreter
has been attempted for a large SG: Kasper [13] has
developed a sentence analysis method (both pars-
ing and interpretation together in my terminology)
based on the NIGEL grammar. In his approach the
SG is compiled into a Functional Unification Gram-
mar (FUG) (see Kay [14], a representation language
with some systemic links) and then existing (but ex-
tended) FUG parsing techniques are used to find a
syntax tree plus an interpretation for a sentence.
The REVELATION1 approach differs from this com-
pilation method since the interpretation is achieved
within a systemic framework. No other SG-based
model (to my knowledge) has been used for both
generation and interpretation in this way.
</bodyText>
<subsectionHeader confidence="0.488992">
Systemic Grammar
</subsectionHeader>
<bodyText confidence="0.999930322033898">
Fawcett&apos;s SG is a meaning-oriented model of lan-
guage in which there is a large &apos;and/or&apos; network of
semantic features, defining the choices in meaning
that are available. A syntax tree is generated by
traversing multiple paths (see later) through this
network, making choices in meaning, and so defin-
ing the meaning of the syntax tree to be generated.
These choices fire realization rules which specify the
structural implication of choosing certain features;
they map the semantic choices onto syntactic struc-
tures and so transform the chosen meaning into a
syntax tree (and hence a sentence) which expresses
that meaning.
As an example of the syntax trees which are gen-
erated by PG1.5, consider Figure 1. Systemic syn-
tax trees consist of a number of levels of structure
called units; the tree in Figure 1 has four: one clause
(Cl), two nominal groups (ngp) and a quantity-
quality group (qqgp). The components (immedi-
ate constituents) of each unit are elements of struc-
ture labelled to represent the functions fulfilled by
that component with respect to its unit. For exam-
ple: subject (S), main verb (M), second complement
(C2) and ender (E) in the clause, superlative de-
terminer (ds) and head (h) in the nominal groups,
superlative deictic determiner (dds) and apex (a)
in the quantity-quality group. Some items may ex-
pound more than one function in a unit, e.g. &amp;quot;is&amp;quot;
functions both as operator (0) and period-marking
auxiliary (Xpd) in the clause and is labelled with
the conflated functional label 0/Xpd. Some ele-
ments may be conflated with participant roles, e.g.
&amp;quot;who&amp;quot; is a subject playing the role of agent (Ag)
and so is labelled S/Ag. Similarly &amp;quot;the big+est
one&amp;quot; is a complement playing the role of affected
(Al) and hence is labelled C2/Af. The immedi-
ate constituent of an element of structure is either a
lexical item (either a word or punctuation, in which
case we say that the item expounds the element, e.g.
the lexical item &amp;quot;one&amp;quot; expounds h), or a further unit
(when we say a unit fills the element, e.g. the unit
qqgp fills ds).
having introduced the type of syntax tree that is
generated, let us now consider the actual process of
generation. The key concept in SG is that of choice
between small sets of meanings (systems of semantic
features). For example, the NUMBER system contains
the choices singular and plural. The choice sys-
tems in a systemic grammar are linked together by
&apos;and&apos; and &apos;or&apos; relationships to form a complex sys-
tem network, specifying the preconditions and con-
sequences of choosing features. Consider the sys-
tem network presented in Figure 2 (an excerpt from
PG 1.5 which contains k,&apos;450 systems, some contain-
ing many more features than the binary systems il-
lustrated in this example). In the systemic nota-
tion curly braces represent conjunctions and verti-
cal bars represent exclusive disjunctions, i.e. choice.
The upper-case labels are the names of systems and
</bodyText>
<page confidence="0.979874">
130
</page>
<figure confidence="0.999469666666667">
RFITRO I retrospective(15.8)
I not-retrospective.-
}
past-from-expect(15.7)
not-past-from-expect
immediate-expect(15.6)
unmarked-expect(15.5)
moon I information_
I directive
BEEd
&apos; expect(15.4)._
not-expect
</figure>
<figureCaption confidence="0.999562">
Figure 2: A fragment of the English &apos;tense&apos; Network
</figureCaption>
<bodyText confidence="0.8637463125">
directive
information,
information,
information,
information,
information,
information,
information,
retrospective, not-expect &amp;quot;touch&amp;quot;
retrospective, expect, immediate-expect &amp;quot;has been about to touch&amp;quot;
retrospective, expect, unmarked-expect &amp;quot;has been going to touch&amp;quot;
not-retrospective, expect, immediate-expect, past-from-expect &amp;quot;is about to have touched&amp;quot;
not-retrospective, expect, immediate-expect, not-past-from-expect &amp;quot;is about to touch&amp;quot;
not-retrospective, expect, unmarked-expect, past-from-expect &amp;quot;is going to have touched&amp;quot;
not-retrospective, expect, unmarked-expect, not-past-from-expect &amp;quot;is going to touch&amp;quot;
,
</bodyText>
<figureCaption confidence="0.999188">
Figure 3: Examples of &apos;tense&apos; Selection Expressions and their realizations
</figureCaption>
<figure confidence="0.93983675">
15.5 :unmarked-expect:
G 4 73, G &lt; &amp;quot;going to&amp;quot;.
15.6: immediate-expect:
G 4 73, G &lt; &amp;quot;about to&amp;quot;.
15.7 :past-from-expect:
Xpf 4 85, Xpf &lt; &amp;quot;have&amp;quot;,
if period-marked then Xpd &lt;+ &amp;quot;en&amp;quot;
else if unmarked-passive then Xp &lt;+ &amp;quot;en&amp;quot;.
</figure>
<figureCaption confidence="0.999908">
Figure 4: Realisation Rules
</figureCaption>
<bodyText confidence="0.999805173913044">
the lower-case labels are the names of the features in
those systems. Each system has an entry condition;
a precondition which must be met in order to en-
ter the system and make a choice. For example, to
enter the RETRO (retrospectivity) and EXPECT (ex-
pectation) systems, information must have been
chosen. To enter the PFE (past from expectation)
system, both not-retrospective and expect must
have been chosen. The sets of choices in meaning de-
fined by this network fragment are listed in Figure 3.
Each set of choices is a selection expression, i.e.
a path (typically bifurcating) through the network.
Associated with certain features are realization
rules. In Figure 2, the bracketted numbers are point-
ers to realization rules; thus realization rule 15.7 is
triggered by the feature past-from-expect. A real-
ization rule specifies the structural consequences of
choosing a feature; they map the semantic choices
onto syntactic structures. Often conditions are in-
volved; consider the realization rules shown in Fig-
ure 4 (PG1.5 contains P4500 realization rules, many
of which are far more complex than these examples).
The main types of rule are:
</bodyText>
<listItem confidence="0.961408416666667">
• Componence Rules: ElON, stating that the el-
ement El is at place N in the current unit
(thus placing an ordering on the components
of the unit currently being generated). These
place numbers are relative rather than physi-
cal; an element at place N states that the el-
ement (if realized) will appear after elements
whose places are less than N and before those
elements whose places are greater than N.
• Filling Rules: is_filled_by U, defining the
unit U to be generated, e.g. U=ngp.
• Conflation Rules: F2 by Fl, stating that the
two functions Fl and F2 are conflated with
one another in the current unit (e.g. a Sub-
ject which also functions as an Agent).
• Exponence Rules: El&lt;Word, stating that the
element El is expounded by an item (e.g.
M&lt;&amp;quot;open&amp;quot;), i.e. exponence creates terminal
constituents.
• Re-entry Rules: for F re_enter_at f, stat-
ing that the function F is filled by a unit which
is generated by re-entering the network at the
feature 1.
• Preference Rules: for F prefer Cf —.7,
</listItem>
<page confidence="0.963464">
131
</page>
<figure confidence="0.997588333333333">
Selection Expression
for Cl filling Z
Selection Expression
for ngp filling S
Selection Expression
for ngp filling C2
Selection Expression
for qqgp filling ds
Task 1 Task 2
</figure>
<figureCaption confidence="0.969661">
Figure 6: AO Tree Primitives
</figureCaption>
<figure confidence="0.999313">
Subtask lb
Subtask la
AND-node
AND-node
OR-node OR-node
</figure>
<figureCaption confidence="0.999973">
Figure 5: A Prototype Semantic Representation
</figureCaption>
<bodyText confidence="0.987250666666667">
stating that when re-entering to generate a
unit to fill the function F, the features Cf. .]
should be preferred, either absolutely (i.e.
&apos;pre-selection&apos;) or tentatively (expressed as a
percentage).
A sentence is generated by generating the syntax
tree for the sentence, the leaves in this tree being
the words of the sentence. The tree is generated by
generating each of its units in a top-down fashion.
Each unit is generated by a single pass through the
system network. This pass is expressed as a selec-
tion expression which lists the features chosen on
that pass. For example, suppose we wanted to gen-
erate the sentence &amp;quot;the prisoner was going to have
been killed&amp;quot;. The selection expression for the clause
would contain the features (plus many others, of
course):
information, not-retrospective, expect,
unmarked-expect, past-from-expect.
Any realization rules associated with features in the
selection expression are then executed. Rules 15.5
and 15.7 in Figure 4 generate a structure whose
leaves are &amp;quot;...going to ...have ... (be)en ...&amp;quot; . For
example, to generate the clause structure in Fig-
ure 1, the following realization statements were ex-
ecuted:
is_filled_by Cl
S435, 0437, M494, C24106, E4200
Ag by S, Xpd by 0, Af by C2
0&lt;&amp;quot;is&amp;quot;, M&lt;&amp;quot;open&amp;quot;, M&lt;+&amp;quot;+ing&amp;quot;, E&lt;&amp;quot;?&amp;quot;
for Ag re_enter_at stereotypical_thing
for Af re_enter_at thing
The re-entry realization statements show which
functions are to be filled by re-entering the system
network to generate further units. Re-entry can be
thought of as a recursive function call which gener-
ates a lower layer of structure in the tree — but
typically with some of the choices &apos;preferred&apos; via
the preference realization statement. Thus the syn-
tax tree in Figure 1 is generated with four passes:
the clause is generated first, followed by the nomi-
nal group filling the subject agent, followed by the
nominal group filling the affected complement, and
finally the quantity-quality group filling the superla-
tive determiner.
The information required to generate a syntax
tree can be expressed as a tree of selection expres-
sions; this is the semantic representation for the
sentence. Each node in the semantic representa-
tion corresponds to a unit in the syntax tree and
is labelled by the selection expression for that unit.
For example, a semantic representation of the form
shown in Figure 5 is needed to generate the syntax
tree in Figure 1.
</bodyText>
<subsectionHeader confidence="0.985256">
Interpreting a Syntax Tree
</subsectionHeader>
<bodyText confidence="0.99994865">
Given a syntax tree, the aim of interpretation is to
find the semantic representation which would gener-
ate that tree. This semantic representation includes
all the features that are needed to generate the tree
and so defines the &apos;meaning content&apos; of the syntax
tree.
In the process of generation, a syntax tree is gen-
erated by generating its units; in the process of in-
terpretation a syntax tree is understood by inter-
preting all of its units in a precisely analogous way.
Thus a unit interpretation is the selection expres-
sion which generated that unit. In general there can
be more than one selection expression for any given
unit, since the same syntactic structure can have
more than one meaning, just as a whole sentence
can have more than one meaning. The potential
unit interpretations are defined by constructing an
AO tree5 whose goal (root) is to prove unit realiza-
tion, i.e. prove that the unit can be generated. Each
potential solution of this AO tree defines a poten-
</bodyText>
<footnote confidence="0.819711625">
5 AO (AND/OR) trees provide a means for describing task
decomposition. These structures were first proposed by Sla-
gle [21] and have since been used in a variety of applications
including symbolic integration and theorem proving (Nilsson
[IA lists a number of applications with references). The AO
tree notation used throughout this paper is illustrated in Fig-
ure 6 with leaves — terminal tasks which cannot be decom-
posed any further — being represented as bold nodes.
</footnote>
<page confidence="0.982154">
132
</page>
<figure confidence="0.98595025">
Unit Interpretation
Unit Realisation
Realisation of
Descriptor I
Realisation of
Descriptor
Realisation of
Descriptor n
</figure>
<figureCaption confidence="0.999995">
Figure 7: Decomposition of Unit Interpretation
</figureCaption>
<bodyText confidence="0.999843428571428">
tial selection expression for the unit. The semantic
representation for the tree is given by some feasible
combination of the &apos;potential selection expressions
for each unit in the syntax tree. Not all combina-
tions of selection expressions are feasible since the
generation passes, nd hence the selection expres-
sions, are inierdeperident Thus:
</bodyText>
<listItem confidence="0.994694454545455">
• A pass is dependent upon previous, higher
passes through i the use of the unary boolean
operators on_prev_pass and on_first_pass in
conditions inside realization rules. These op-
erators are used to test the values of features
in passes for higher units in the syntax tree.
For example the condition on_first_pass
written is only true if written is selected on
the first pass.
• Subsequent passes are dependent upon the
pre-selections that are made with the pref-
</listItem>
<bodyText confidence="0.997525857142857">
erence rules. For example, when gen-
erating a question (such as that in Fig-
ure 1) it is necessary to pre-select the fea-
ture seeking-specification-of-thing for
the nominal group which fills the subject
agent. This enures that a Wh-subject is gen-
erated.
</bodyText>
<subsectionHeader confidence="0.797106">
Decomposing Unit Interpretation
</subsectionHeader>
<bodyText confidence="0.9998984">
The first step in unit interpretation is the de-
composition of the .unit&apos;s structure into a set of
descriptors;6 each describing a different aspect of
the unit&apos;s structure. For example, the descriptors
required to describe the clause in Figure 1 are:
</bodyText>
<tableCaption confidence="0.514492">
unit(C1)
el(1,S), el(2,0), el(3,M), el(4,C2), el(5,E)
conf(S,Ag), cOnf(0,Xpd), conf(C2,Af)
stem(0,&amp;quot;is&amp;quot;), Stem(M,&amp;quot;open&amp;quot;), stem(E,&amp;quot;?&amp;quot;)
suffix(M,&amp;quot;+ing&amp;quot;)
6A descriptor is simply an abstract description of a real-
ization; it attempts to Capture the effect of the realization
statements without using any of their syntax.
re_enter(S,Ag), re_enter(C2,Af)
</tableCaption>
<bodyText confidence="0.999910692307693">
The unit descriptor specifies the name of the cur-
rent unit, the el descriptor specifies the order-
ing of the component elements, the conf descrip-
tor specifies the conflation relationships, the stem
and suffix descriptors specify the items expound-
ing lexical elements, and the re_enter descriptor
specifies the non-terminal elements requiring a sub-
sequent pass to generate a unit to fill them.
Decomposition 1 [Unit Interpretation] Unit in-
terpretation is achieved by proving that the unit can
be realized. To do this, the unit&apos;s structure is de-
scribed, using a set of descriptors, and hence unit
realization is decomposed into a number of separate
realizations, with one realization for each descriptor.
Thus unit interpretation is achieved by realizing all
descriptors (hence realizing the whole unit). This
decomposition is illustrated in Figure 7.
Each descriptor is realized by some realization
statement (which will appear somewhere in the re-
alization rules). There is a simple mapping between
descriptors and suitable realization statements. For
some descriptors there is only a single suitable re-
alization statement: for example, unit(U) is only
realized by the statement is_filled_by U. Other
descriptors can be realized by a number of differ-
ent realization statements: for example, el(i,E11)
is realized by statements of the form EliON, where
the place N is greater than the places for and
less than the places for El1+1. This ensures correct
ordering of the constituent elements.
For each descriptor, a search of the realization
rules is performed to find any statements which re-
alize the descriptor. For example, for the descrip-
tor unit(C1) we would search for all occurrences
of is_filled_by Cl in the realization rules. After
the search is complete there will be a set of poten-
tially active rules for each descriptor, with each po-
tentially active rule containing a suitable statement
(or possibly more than one suitable statement) that
</bodyText>
<page confidence="0.995959">
133
</page>
<figure confidence="0.989981666666667">
Descriptor Realisation
Suitable Statements
Rule Activation One Precondition holds true
</figure>
<figureCaption confidence="0.999994">
Figure 8: Decomposition of Descriptor Realisation
</figureCaption>
<bodyText confidence="0.995154602941177">
would realize the descriptor. Associated with each
potentially active rule is a set of preconditions, one
precondition for each suitable statement. (If the
statement has no precondition, then the set of pre-
conditions will be empty.)
Decomposition 2 [Descriptor Realization] Prov-
ing that a descriptor can be realized is decomposed
into (i) activating any one of its potentially active
rules, and (ii) proving that any one of the precondi-
tions associated with that rule holds true (assuming
there are any preconditions). This decomposition is
illustrated in Figure 8.
What is required for a rule to be active? A rule
can only be active if there is a feasible path (feasi-
ble in the sense that all features on that path can
be selected) through the system network to a fea-
ture associated with that rule. There will be at
least one potential path to each rule; &apos;at least&apos; is
required since a rule can have more than one poten-
tial path if (i) it is associated with more than one
feature or (ii) it is dependent upon a disjunctive en-
try condition. Thus the potential paths to a rule
can be represented as a boolean expression; i.e. as
an exclusive disjunction of conjunctions:
pathl xor path2 xor xor pathN
where the path components are conjunctions com-
posed from the features in each potential path and
the exclusive disjunction represents choice between
potential paths. This expression can be simplified
into an expression of the form:
common and
(variantl xor xor variantN)
where common is a conjunction of features that
is common to all potential paths and variant 1
...variantN are the conjunctions of features pecu-
liar to each potential path. This expression can be
considered as a precondition for rule activation and
so must be true for the rule to be active.
Decomposition 3 [Rule Activation] Rule Activa-
tion is achieved by activating one of the potential
paths to that rule. The potential paths can be de-
composed into a common component and a number
of variant components. One potential path is active
if and only if the common component is active and
its variant component is also active. This decompo-
sition is illustrated in Figure 9.
At this stage in the decomposition all tip nodes
are problems of the form `boolean expression = T&apos;,
i.e. satisfiability problems. In order to define how
satisfiability problems are solved, the concept of a
truth function must first be introduced. A truth
function is a mapping between features and a three
valued logic (with truth values false, true and unde-
fined) which defines the value of each feature; true
indicating selected and false indicating not selected.
The problem of satisfiability for a boolean expres-
sion involves finding a truth function such that the
boolean expression evaluates7 to be true, such a
truth function is called a satisfying truth function
for the boolean expression. Unfortunately, this is
an intractable problem since a disjunction with n
disjuncts can have 3n-1 potential satisfying truth
functions, i.e. the task is exponential in problem size
(in fact, the problem of satisfiability has the honor
of being the first NP-Complete problem; see Garey
and Johnson [11]). As is the case with inherently in-
tractable problems; it is not worth searching for an
efficient, exact algorithm to perform the task; it is
</bodyText>
<footnote confidence="0.975112">
7Evaluation is performed with respect to Kleene&apos;s three
valued logic [15].
</footnote>
<page confidence="0.996922">
134
</page>
<figure confidence="0.9903565">
Rule Activation
Path Activation
</figure>
<figureCaption confidence="0.99998">
Figure 9: Decomposition of Rule Activation
Figure 10: Part of the AO Tree for Clause Interpretation
</figureCaption>
<figure confidence="0.988541157894737">
el(3,M)
M094
conf(S,Ag)
First Occurrence
Rule 2.04
Common
r -
agent-plus-manner
Second Occurrence
Rule 6.21
Cornmon
Variant
Isituation
Interpret Cl
Realise [Cl...)
Only Olecurrence
congruent-sit
simple-ago
agent-S. heme-cr
</figure>
<bodyText confidence="0.958717323529412">
more appropriate to consider a less ambitious prob-
lem. Consider the problem of partial satisfiability: it
is essentially the same as satisfiability except that it
does not attempt to satisfy disjunctive components
(since it is these components which make the satis-
fiability problem `hard&apos;). It requires a redefinition
of a truth function: in partial satisfiability a truth
function is a mapping between boolean expressions
(rather than simply features) and truth values. For
example, the expression (a or b) and c and not
d is partially satisfied by the function v:
v : tqa or T, v(c) = T, v(d) = F
Since disjunctions are effectively ignored, there is
a single unique partially satisfying truth function
for any boolean expression. Thus tip nodes labelled
with satisfiability problems are (partially) decom-
posed into a number of and-nodes; each and-node
being labelled by a feature (possibly negated) or a
disjunction which must be true. As an example of
a fully decomposed AO tree for unit interpretation,
consider the skeleton tree in Figure 10 which de-
fines the potential interpretations of the clause in
Figure 1.
A potential solution of an AO tree is specified by
a subset of the leaves that are necessary for the root
task to be achieved. A backtracking search is used
to generate potential solutions: since the AO tree is
finite, it is possible to inspect the structure of the
tree and order the search in such a way so that the
minimum amount of backtracking is performed.8 A
feasible interpretation for a unit is one of the po-
tential solutions in which the statements labelling
the leaves are all consistent. There are two ways in
which a leaf statement may be inconsistent:
</bodyText>
<footnote confidence="0.834835333333333">
8 The search scheme involves incrementally evaluating and
pruning the AO tree. Full details can be found in O&apos;Donoghue
[19], an in-depth report on the interpreter.
</footnote>
<page confidence="0.993177">
135
</page>
<tableCaption confidence="0.334782">
Selection Expression for CI filling Z
</tableCaption>
<table confidence="0.9913862">
ii:&apos;rAtOtti?A&apos;a;iRsfrIlierant‘es-jOitififFsatii°nrit:iPeal: i.csr&amp;quot;s■-%ig;7-gh:eig&apos;
At:a ItII:;enitelmqe,Za-tireutea:af-untheniatized,
grt&apos;lfrnli--,qTtel-VIOP:t1tItegtrg&apos;s11.aolllili;,1-gns&apos;errtg!fgurati°&amp;quot;&apos;
Selection Expression for ngp filling S Selection Expi ession for ngp filling C2
thin con r ent-tchin stereot l41-thsing, thing conifirtuuent-Tirif,:rire.?,trj,ge_gw,
rikUATsEUtt:linA&apos; c4u6ntiesVccr, rfAeltel-Gorn!ty:superlativtiation
t:ttiehegApon-s
st
Selection expressi n for qqgp filling ds
arn*v.locinu-;itiltaii4,111&apos;;g,&apos;b7,edneontt-iiilaVtligrIthhaivI§Ural-quality,
</table>
<figureCaption confidence="0.882806">
Figure 11: A Semantic Representation found by REVELATION1
</figureCaption>
<listItem confidence="0.993379142857143">
• The statements logically contradict, for exam-
ple: leaves labelled a = T and a = F. Or
b or c = T and b = F, c = F.
• The statements systemically contradict, for
example: a = T and b = T when a and b
are members of the same choice system (from
which at most one feature can be chosen).
</listItem>
<bodyText confidence="0.999784">
The leaf statements in a feasible solution define
which features must be true (i.e. selected) for the
unit to be realized, i.e. they specify a selection ex-
pression for the unit.
</bodyText>
<sectionHeader confidence="0.938876" genericHeader="evaluation">
Results and Discussion
</sectionHeader>
<bodyText confidence="0.999666037037037">
The semantic representation found by REVEL ATIO N1
for the syntax tree in Figure 1 is presented in Fig-
ure 11. We can get a flavor of the semantic repre-
sentation by identifying key features: the sentence
is a question (information, seeker) about an on-
going event (period—marked) which involves open-
ing something (make—open). It is a person that we
are seeking (person—sst). The thing that is being
opened is selected by superlativization (in fact it is
the biggest) and it is recoverable from the previous
discourse (the &amp;quot;one&amp;quot; referring to something that has
previously been mentioned).
Unfortunately this semantic representation is in-
complete. One of the factors contributing to this in-
completeness is that of &apos;unrealized&apos; selections: these
are features which have no associated realization
(e.g. not—expect in Figure 2). Consider the way
in which interpretation works: it tries to prove that
observed realizations have taken place and in so do-
ing infer the features that were selected. However,
if a realization does not take place as a (not nec-
essarily direct) result of a selection, then there is
no way to infer that the unrealized feature was se-
lected. Consider the POLARITY system where there
is a choice between positive and negative. The
positive choice is unrealized where as negative is
associated with the realization rule:
</bodyText>
<figure confidence="0.425721333333333">
17 :negative:
do_support,
0 &lt;+ un&apos;t&amp;quot;.
</figure>
<bodyText confidence="0.999984233333333">
Suppose we have a positive clause, &amp;quot;Who is opening
the biggest one?&amp;quot; (the example sentence from Fig-
ure 1). There is no way to tell from the structure of
the clause that the sentence is positive. However
by inspecting the realization rule associated with
negative we find that the (unconditional) state-
ment 0&lt;+&amp;quot;n&apos;t&amp;quot; can never be active as this would
realize the sentence &amp;quot;Who isn&apos;t opening the biggest
one?&amp;quot;. Thus rule 17 can never be active and so
negative can&apos;t be chosen, hence positive must be
chosen. Thus by a process of eliminating features
which cannot be true, it is possible to determine
unrealized features. REVELATION2 (currently under
development) will attempt to implement this pro-
cess of elimination by moving forward through the
system network (after a partial semantic represen-
tation has been obtained) systematically verifying
any realization rules that it meets, eliminating fea-
tures that cannot be chosen and so possibly inferring
something about unrealized features which need to
be chosen.
The other factor contributing to incompleteness
is the definition of partial satisfiability. Some fea-
tures in the network do not have realization rules
attached to them: typically these appear as condi-
tions on statements in realization rules. However,
if any of these features appear in disjunctive con-
ditions or disjunctive entry conditions to systems,
then nothing can be inferred about their values since
the definition of partial satisfiability ignores all dis-
</bodyText>
<page confidence="0.996365">
136
</page>
<bodyText confidence="0.999886396551724">
junctions. This problem can only be overcome by
searching for (exact) satisfying truth functions from
which all feature values can be inferred. REVELA-
TION2 attempts to solve this problem by deferring
the search for exact satisfying truth functions un-
til after a partial interpretation has been obtained:
the partial interpretation is obtained as for REVE-
LATION1, and then any disjunctions that have been
ignored while obtaining this interpretation are ex-
actly satisfied to try and fill the gaps in the partial
interpretation.
In addition to the work on the next generation of
interpreter, some work is being carried out on Pc 1.5
to make it more efficient; it is being tuned for inter-
pretation by simplifying and normalizing conditions
in the realization rules. This involves &apos;tightening up&apos;
the conditions by substituting xor for or wherever
possible and reducing the scope of any valid disjunc-
tions that remain (eig. a and (b or c) rather than
a and b or a and c).
Clearly efficiency is a problem, since the AO trees
explode into or-nodes, through the use of (i) dis-
junctive entry conditions in the system network and
(ii) disjunctive conditions in the realization rules. It
has been proved (Brew [3]) that systemic classifica-
tion is NP-Hard and is thus inherently intractable.
This led to the choice of partial satisfiability rather
than exact satisfiability (which itself is NP-Hard)
in REVELATION1, and the development of an effi-
cient technique for ,searching the AO trees which
utilizes incremental evaluation and pruning to re-
duce the number of backtracking points (full details
in O&apos;Donoghue [19])4 The delayed use of exact satis-
fiability being investigated in REVELATION2 is sim-
ilar to Brew&apos;s &apos;partial&apos; algorithm for checking sys-
temic descriptions. Brew&apos;s checking algorithm has
two stages, the first o being a simplification stage in
which all disjunctive:entry conditions are eliminated
from the system network by replacing them with a
uniquely generated feature. The resultant simplified
network can then be searched efficiently. The second
stage involves checking all of the features generated
in the first, stage, each generated feature referring to
a disjunctive entry condition. Here also we find a
delaying tactic in which disjunctions are satisfied as
late as possible in the search.
Although no theoretical calculations as to the
complexity of the REVELATION1 method and PG1.5
have been undertaken, we can get a feel for the scale
of the problem by considering the amount of CPU
time that was needed to obtain the semantic repre-
sentation of Figure IL On a SPARCstation 1 with
16M this task required25 CPU seconds, with this
time being halved on a Sun 4/490 with 32M. When
reading these timings bear in mind that REVELA-
TION1 is coded in POPLOG languages which are in-
crementally compiled into an interpreted virtual ma-
chine code.
</bodyText>
<sectionHeader confidence="0.687711" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999938785714286">
REVELATION1 has demonstrated that Fawcett&apos;s SG
is a bi-directional formalism, although in the case
of PC. 1.5, some reorganization was required to make
it run in reverse. The main problem in reversing a
SG seems to be that systemic grammars are written
from a predominantly text-generation viewpoint. In
developing their grammars systemic grammarians
are concerned with how the grammar will generate
rather than its suitability for interpretation. For
instance, special care ought to be taken when ex-
pressing conditions in realization rules: writing a
xor b rather than a or b can be a godsend to an
interpreter. Similarly, simplifying and normalizing
conditions so that they are as simple and specific as
possible is a great aid to interpretation. It reduces
the search space and hence speeds up interpretation
— even though, from a generative point of view, it
may make more sense to express a condition in a
&apos;long winded&apos; fashion that captures the generaliza-
tion the linguist is attempting to make.
Fawcett states (private communication) that in
developing his version of SG (which is different in
a number of ways — especially in the realization
component — from the NIGEL grammar of Mann
and Matthiessen) he always had in mind its poten-
tial for reversibility. Perhaps the surprising thing
is not, that modifications in GENESYS are indicated
by work on REVELATION, but how few modifications
appear to be required. Clearly, the need now is for
close collaboration between the builders of the suc-
cessor versions of GENESYS and and the successor
versions of REVELATION. Current research has pre-
cisely this goal; and we shall report the results in
due course.
REVELATION1 combined with Fawcett&apos;s SG ap-
pears to be a step in the right direction towards
a bi-directional systemic grammar. REVELATION2
may take a step closer. But a bi-directional systemic
grammar will only be achieved when interpretation-
minded people and generation-minded people get to-
gether and collaborate in developing such a gram-
mar.
</bodyText>
<page confidence="0.997072">
137
</page>
<sectionHeader confidence="0.997369" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999294">
I would like to thank Eric Atwell and Clive Souter
(Leeds University) for their valuable contributions
to earlier drafts of this paper and Robin Fawcett
(UWCC) for his comments and suggestions on the
final version.
</bodyText>
<sectionHeader confidence="0.999192" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999785978021978">
[1] Rosalind Barrett, Allan Ramsay, and Aaron
Sloman. POP11: a Practical Language for Ar-
tificial Intelligence. Ellis IIorwood, Chichester,
1985.
[2] James D. Benson and William S. Greaves, ed-
itors. Systemic Perspectives on Discourse: se-
lected papers from the 9th International Sys-
temic Workshop. Ablex, London, 1985.
[3] Chris Brew. &amp;quot;Partial Descriptions and Systemic
Grammar&amp;quot;. In Proceedings of the 13th Interna-
tional Conference on Computational Linguis-
tics (COLING &apos;90), 1990.
[4] Christopher S. Butler. Systemic Linguistics:
Theory and Applications. Batsford, London,
1985.
[5] William F. Clocksin and Chris S. Mellish. Pro-
gramming in Prolog. Springer Verlag, 3rd edi-
tion, 1987.
[6] Anthony Davey. Discourse Production: A
Computer Model of Some Aspects of a Speaker.
Edinburgh University Press, 1978.
[7] David R. Dowty, Lauri Karttunen, and
Arnold M. Zwicky, editors. Natural Language
Parsing: psychological, computational and the-
oretical perspectives. Studies in Natural Lan-
guage Processing. Cambridge University Press,
1985.
[8] Robin P. Fawcett. Cognitive Linguistics and
Social Interaction, volume 5 of Exeter Linguis-
tic Studies. Julius Groos Verlag, Heidlberg,
1980.
[9] Robin P. Fawcett. &amp;quot;Language Generation as
Choice in Social Interaction&amp;quot;. In Zock and
Subah [24], chapter 2, pages 27-49.
[10] Robin P. Fawcett and Gordon H. Tucker.
&amp;quot;Demonstration of GENESYS: a very large se-
mantically based Systemic Functional Gram-
mar&amp;quot;. In Proceedings of the 13th Interna-
tional Conference on Computational Linguis-
tics (COLING &apos;90), 1990.
[11] Michael R. Garey and David S. Johnson. Com-
puters and Intractability: A Guide to the The-
ory of NP-Completeness. Freeman, San Fran-
cisco, 1979.
[12] John Gibson. &amp;quot;AI Programming Environments
and the POPLOG System&amp;quot;. In Yazdani [23],
chapter 2, pages 35-47.
[13] Robert T. Kasper. &amp;quot;An Experimental Parser
for Systemic Grammars&amp;quot;. In Proceedings of
the 12th International Conference on Computa-
tional Linguistics (COLING &apos;88), August 1988.
Also available as USC/Information Sciences In-
stitute Reprint RS-88-212.
[14] Martin Kay. &amp;quot;Parsing in Functional Unification
Grammar&amp;quot;. In Dowty et al. [7], chapter 7, pages
251-278.
[15] Stephen C. Kleene. Introduction to Metamath-
ematies. North-Holland, 1952.
[16] William C. Mann and Christian M. I. M.
Matthiessen. &amp;quot;NIGEL: A Systemic Grammar
for Text Generation&amp;quot;. In Benson and Greaves
[2]. Also available as USC/Information Sciences
Institute Reprint RS-83-105.
[17] Christian M. I. M. Matthiessen and John A.
Bateman. Text Generation and Systemic-
Functional Linguistics: experiences from En-
glish and Japanese. Pinter, London, 1991. (in
press).
[18] Nils Nilsson. Principles of Artificial Intelli-
gence. Springer Verlag, 1983.
[19] Tim F. O&apos;Donoghue. &amp;quot;The REVELATION1 Se-
mantic Interpreter&amp;quot;. COMMUNAL Report 22,
School of Computer Studies, University of
Leeds, 1991.
[20] Tim F. O&apos;Donoghue. &amp;quot;The Vertical Strip
Parser: a lazy approach to parsing&amp;quot;. Report
91.15, School of Computer Studies, University
of Leeds, 1991.
[21] J. R. Slagle. &amp;quot;A Heuristic Program that Solves
Symbolic Integration Problems in Freshman
Calculus&amp;quot;. In E. Feigenbaum and J. Feldman,
editors, Computers and Thought, pages 191-
203. McGraw-Hill, New York, 1963.
[22] Terry Winograd. Language as a Cognitive Pro-
cess, Volume 1: Syntax. Addison Wesley, 1983.
[23] Masoud Yazdani, editor. Artificial Intelligence:
principles and applications. Chapman Hall,
1986.
[24] Michael Zock and Gerard Subah, editors. Ad-
vances in Natural Language Generation (Vol-
ume 2). Pinter, London, 1988.
</reference>
<page confidence="0.997344">
138
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.423149">
<title confidence="0.9977605">A SEMANTIC INTERPRETER SYSTEMIC GRAMMARS</title>
<author confidence="0.999955">Tim F O&apos;Donoghue</author>
<email confidence="0.819695">timmyeuk.ac.leeds.ai</email>
<affiliation confidence="0.998283">Division of Artificial School of Computer The University of</affiliation>
<address confidence="0.710746">Leeds LS2 9JT.</address>
<phone confidence="0.954399">44 532 335430</phone>
<abstract confidence="0.973441571428571">This paper describes a method for obtaining the semantic representation for a syntax tree in Systemic Grammar (SG). A prototype implementation of this method — the REVELATION1 semantic interpreter — has been developed. It is derived from a SG generator for a large subset of English — GENESYS — and is &apos;thus, in contrast with most reversible grammars, ,an interpreter based on a generator. A task decomposition approach is adopted for this reversal process which operates within the framework of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism,</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rosalind Barrett</author>
<author>Allan Ramsay</author>
<author>Aaron Sloman</author>
</authors>
<title>POP11: a Practical Language for Artificial Intelligence. Ellis IIorwood,</title>
<date>1985</date>
<location>Chichester,</location>
<contexts>
<context position="2568" citStr="[1]" startWordPosition="409" endWordPosition="409">given syntax tree. In sentence generation, a tree is generated, but only the leaves (the words) are &apos;output&apos;, the rest of the tree is simply deleted. In the reverse process, when a sentence is input, a syntax tree must first be found before it can be interpreted. REVELATION1 assumes that a separate SG parser (not discussed here) is available; for an example of such a parser see O&apos;Donoghue [20]. Thus REVELATION1 directly mirrors the generator, while the parser mirrors the tree deletion process. REVELATI0N1 has been developed within the POPLOG environment.3 It is coded in a combination of P0P11 [1] and Prolog [5] and utilizes GENESYS. GENESYS is a very large SG generator for English, written in Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in the domain of personnel manageinterpretation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. Here I assume a sequential scheme in which the</context>
</contexts>
<marker>[1]</marker>
<rawString>Rosalind Barrett, Allan Ramsay, and Aaron Sloman. POP11: a Practical Language for Artificial Intelligence. Ellis IIorwood, Chichester, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James D Benson</author>
<author>S William</author>
</authors>
<date>1985</date>
<booktitle>Systemic Perspectives on Discourse: selected papers from the 9th International Systemic Workshop.</booktitle>
<editor>Greaves, editors.</editor>
<publisher>Ablex,</publisher>
<location>London,</location>
<marker>[2]</marker>
<rawString>James D. Benson and William S. Greaves, editors. Systemic Perspectives on Discourse: selected papers from the 9th International Systemic Workshop. Ablex, London, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Brew</author>
</authors>
<title>Partial Descriptions and Systemic Grammar&amp;quot;.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING &apos;90),</booktitle>
<contexts>
<context position="29678" citStr="[3]" startWordPosition="4751" endWordPosition="4751">is being carried out on Pc 1.5 to make it more efficient; it is being tuned for interpretation by simplifying and normalizing conditions in the realization rules. This involves &apos;tightening up&apos; the conditions by substituting xor for or wherever possible and reducing the scope of any valid disjunctions that remain (eig. a and (b or c) rather than a and b or a and c). Clearly efficiency is a problem, since the AO trees explode into or-nodes, through the use of (i) disjunctive entry conditions in the system network and (ii) disjunctive conditions in the realization rules. It has been proved (Brew [3]) that systemic classification is NP-Hard and is thus inherently intractable. This led to the choice of partial satisfiability rather than exact satisfiability (which itself is NP-Hard) in REVELATION1, and the development of an efficient technique for ,searching the AO trees which utilizes incremental evaluation and pruning to reduce the number of backtracking points (full details in O&apos;Donoghue [19])4 The delayed use of exact satisfiability being investigated in REVELATION2 is similar to Brew&apos;s &apos;partial&apos; algorithm for checking systemic descriptions. Brew&apos;s checking algorithm has two stages, th</context>
</contexts>
<marker>[3]</marker>
<rawString>Chris Brew. &amp;quot;Partial Descriptions and Systemic Grammar&amp;quot;. In Proceedings of the 13th International Conference on Computational Linguistics (COLING &apos;90), 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher S Butler</author>
</authors>
<title>Systemic Linguistics: Theory and Applications.</title>
<date>1985</date>
<location>Batsford, London,</location>
<contexts>
<context position="859" citStr="[4]" startWordPosition="137" endWordPosition="137"> the semantic representation for a syntax tree in Systemic Grammar (SG). A prototype implementation of this method — the REVELATION1 semantic interpreter — has been developed. It is derived from a SG generator for a large subset of English — GENESYS — and is &apos;thus, in contrast with most reversible grammars, ,an interpreter based on a generator. A task decomposition approach is adopted for this reversal process which operates within the framework of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, Introduction SG (see Butler [4] for a good introduction) is a useful model of language, having found many applications in the 4reas of stylistics, text analysis, educational linguistics and artificial intelligence. Some of these applications have been computational, the best known probably being Winograd&apos;s SHRDLU [22]. However, most computational applications have been designed from a text-generation viewpoint (such as Davey&apos;s PROTEUS [6], Mann and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and Tucker&apos;s GENESYS POD. Because of this text-generation viewpoint of systemic grammarian, the mechanism for sentence analysis within SG</context>
</contexts>
<marker>[4]</marker>
<rawString>Christopher S. Butler. Systemic Linguistics: Theory and Applications. Batsford, London, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William F Clocksin</author>
<author>Chris S Mellish</author>
</authors>
<title>Programming in Prolog.</title>
<date>1987</date>
<publisher>Springer Verlag,</publisher>
<note>3rd edition,</note>
<contexts>
<context position="2583" citStr="[5]" startWordPosition="412" endWordPosition="412">ee. In sentence generation, a tree is generated, but only the leaves (the words) are &apos;output&apos;, the rest of the tree is simply deleted. In the reverse process, when a sentence is input, a syntax tree must first be found before it can be interpreted. REVELATION1 assumes that a separate SG parser (not discussed here) is available; for an example of such a parser see O&apos;Donoghue [20]. Thus REVELATION1 directly mirrors the generator, while the parser mirrors the tree deletion process. REVELATI0N1 has been developed within the POPLOG environment.3 It is coded in a combination of P0P11 [1] and Prolog [5] and utilizes GENESYS. GENESYS is a very large SG generator for English, written in Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in the domain of personnel manageinterpretation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. Here I assume a sequential scheme in which the parsing proces</context>
</contexts>
<marker>[5]</marker>
<rawString>William F. Clocksin and Chris S. Mellish. Programming in Prolog. Springer Verlag, 3rd edition, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Davey</author>
</authors>
<title>Discourse Production: A Computer Model of Some Aspects of a Speaker.</title>
<date>1978</date>
<publisher>Edinburgh University Press,</publisher>
<contexts>
<context position="1270" citStr="[6]" startWordPosition="198" endWordPosition="198">ss which operates within the framework of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, Introduction SG (see Butler [4] for a good introduction) is a useful model of language, having found many applications in the 4reas of stylistics, text analysis, educational linguistics and artificial intelligence. Some of these applications have been computational, the best known probably being Winograd&apos;s SHRDLU [22]. However, most computational applications have been designed from a text-generation viewpoint (such as Davey&apos;s PROTEUS [6], Mann and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and Tucker&apos;s GENESYS POD. Because of this text-generation viewpoint of systemic grammarian, the mechanism for sentence analysis within SG the reverse of the sentence generation process) has received much less attention. This paper describes one stage of the sentence analysis process: semantic interpretation.&apos; &apos;This assumes that sentence analysis can be decomposed into two processes: syntactic analysis (parsing) plus semantic In Fawcett&apos;s SG,2 a syntax tree (whose leaves define a sentence) is generated from a set of semantic choices. REVELATIO</context>
</contexts>
<marker>[6]</marker>
<rawString>Anthony Davey. Discourse Production: A Computer Model of Some Aspects of a Speaker. Edinburgh University Press, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
<author>Lauri Karttunen</author>
<author>M Arnold</author>
</authors>
<date>1985</date>
<booktitle>Natural Language Parsing: psychological, computational and theoretical perspectives. Studies in Natural Language Processing.</booktitle>
<editor>Zwicky, editors.</editor>
<publisher>Cambridge University Press,</publisher>
<marker>[7]</marker>
<rawString>David R. Dowty, Lauri Karttunen, and Arnold M. Zwicky, editors. Natural Language Parsing: psychological, computational and theoretical perspectives. Studies in Natural Language Processing. Cambridge University Press, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin P Fawcett</author>
</authors>
<title>Cognitive Linguistics and Social Interaction,</title>
<date>1980</date>
<volume>5</volume>
<institution>of Exeter Linguistic Studies. Julius Groos Verlag,</institution>
<location>Heidlberg,</location>
<contexts>
<context position="3272" citStr="[8, 9]" startWordPosition="527" endWordPosition="528"> Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in the domain of personnel manageinterpretation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. Here I assume a sequential scheme in which the parsing process passes a syntax tree to the interpreter. 2 Fawcett&apos;s Systemic Functional Grammar [8, 9], his development. of a Hallidayan SG. 3POPLOG is a multi-language development environment containing incremental compilers for POP11 (the base language), Prolog, Common Lisp and Standard ML, an integrated editor and numerous support tools [12[. 4 The COMMUNAL Project at University of Wales College of Cardiff (UWCC) Computational Linguistics Unit and Leeds University School of Computer Studies was sponsored by RSHE Malvern, ICL and Longman. 3.29 1C2 ULYI VEZE who open+ing Figure 1: A Typical PG 1.5 Syntax Tree men t. This is not the first time a semantic interpreter has been attempted for a la</context>
</contexts>
<marker>[8]</marker>
<rawString>Robin P. Fawcett. Cognitive Linguistics and Social Interaction, volume 5 of Exeter Linguistic Studies. Julius Groos Verlag, Heidlberg, 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robin P Fawcett</author>
</authors>
<title>Language Generation as Choice in Social Interaction&amp;quot;.</title>
<booktitle>In Zock and Subah [24], chapter 2,</booktitle>
<pages>27--49</pages>
<contexts>
<context position="3272" citStr="[8, 9]" startWordPosition="527" endWordPosition="528"> Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in the domain of personnel manageinterpretation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. Here I assume a sequential scheme in which the parsing process passes a syntax tree to the interpreter. 2 Fawcett&apos;s Systemic Functional Grammar [8, 9], his development. of a Hallidayan SG. 3POPLOG is a multi-language development environment containing incremental compilers for POP11 (the base language), Prolog, Common Lisp and Standard ML, an integrated editor and numerous support tools [12[. 4 The COMMUNAL Project at University of Wales College of Cardiff (UWCC) Computational Linguistics Unit and Leeds University School of Computer Studies was sponsored by RSHE Malvern, ICL and Longman. 3.29 1C2 ULYI VEZE who open+ing Figure 1: A Typical PG 1.5 Syntax Tree men t. This is not the first time a semantic interpreter has been attempted for a la</context>
</contexts>
<marker>[9]</marker>
<rawString>Robin P. Fawcett. &amp;quot;Language Generation as Choice in Social Interaction&amp;quot;. In Zock and Subah [24], chapter 2, pages 27-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin P Fawcett</author>
<author>Gordon H Tucker</author>
</authors>
<title>Demonstration of GENESYS: a very large semantically based Systemic Functional Grammar&amp;quot;.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING &apos;90),</booktitle>
<contexts>
<context position="2698" citStr="[10]" startWordPosition="431" endWordPosition="431">e is simply deleted. In the reverse process, when a sentence is input, a syntax tree must first be found before it can be interpreted. REVELATION1 assumes that a separate SG parser (not discussed here) is available; for an example of such a parser see O&apos;Donoghue [20]. Thus REVELATION1 directly mirrors the generator, while the parser mirrors the tree deletion process. REVELATI0N1 has been developed within the POPLOG environment.3 It is coded in a combination of P0P11 [1] and Prolog [5] and utilizes GENESYS. GENESYS is a very large SG generator for English, written in Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in the domain of personnel manageinterpretation. These processes are not necessarily sequential, although it greatly simplifies things if they are treated as such. Here I assume a sequential scheme in which the parsing process passes a syntax tree to the interpreter. 2 Fawcett&apos;s Systemic Functional Grammar [8, 9], his development. of a Ha</context>
</contexts>
<marker>[10]</marker>
<rawString>Robin P. Fawcett and Gordon H. Tucker. &amp;quot;Demonstration of GENESYS: a very large semantically based Systemic Functional Grammar&amp;quot;. In Proceedings of the 13th International Conference on Computational Linguistics (COLING &apos;90), 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Garey</author>
<author>David S Johnson</author>
</authors>
<title>Computers and Intractability: A Guide to the Theory of NP-Completeness. Freeman,</title>
<date>1979</date>
<location>San Francisco,</location>
<contexts>
<context position="22033" citStr="[11]" startWordPosition="3545" endWordPosition="3545">h feature; true indicating selected and false indicating not selected. The problem of satisfiability for a boolean expression involves finding a truth function such that the boolean expression evaluates7 to be true, such a truth function is called a satisfying truth function for the boolean expression. Unfortunately, this is an intractable problem since a disjunction with n disjuncts can have 3n-1 potential satisfying truth functions, i.e. the task is exponential in problem size (in fact, the problem of satisfiability has the honor of being the first NP-Complete problem; see Garey and Johnson [11]). As is the case with inherently intractable problems; it is not worth searching for an efficient, exact algorithm to perform the task; it is 7Evaluation is performed with respect to Kleene&apos;s three valued logic [15]. 134 Rule Activation Path Activation Figure 9: Decomposition of Rule Activation Figure 10: Part of the AO Tree for Clause Interpretation el(3,M) M094 conf(S,Ag) First Occurrence Rule 2.04 Common r - agent-plus-manner Second Occurrence Rule 6.21 Cornmon Variant Isituation Interpret Cl Realise [Cl...) Only Olecurrence congruent-sit simple-ago agent-S. heme-cr more appropriate to con</context>
</contexts>
<marker>[11]</marker>
<rawString>Michael R. Garey and David S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. Freeman, San Francisco, 1979.</rawString>
</citation>
<citation valid="false">
<authors>
<author>John Gibson</author>
</authors>
<title>AI Programming Environments and the POPLOG System&amp;quot;.</title>
<journal>In Yazdani</journal>
<volume>23</volume>
<pages>35--47</pages>
<marker>[12]</marker>
<rawString>John Gibson. &amp;quot;AI Programming Environments and the POPLOG System&amp;quot;. In Yazdani [23], chapter 2, pages 35-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
</authors>
<title>An Experimental Parser for Systemic Grammars&amp;quot;.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING &apos;88),</booktitle>
<pages>88--212</pages>
<contexts>
<context position="3891" citStr="[13]" startWordPosition="630" endWordPosition="630">nt. of a Hallidayan SG. 3POPLOG is a multi-language development environment containing incremental compilers for POP11 (the base language), Prolog, Common Lisp and Standard ML, an integrated editor and numerous support tools [12[. 4 The COMMUNAL Project at University of Wales College of Cardiff (UWCC) Computational Linguistics Unit and Leeds University School of Computer Studies was sponsored by RSHE Malvern, ICL and Longman. 3.29 1C2 ULYI VEZE who open+ing Figure 1: A Typical PG 1.5 Syntax Tree men t. This is not the first time a semantic interpreter has been attempted for a large SG: Kasper [13] has developed a sentence analysis method (both parsing and interpretation together in my terminology) based on the NIGEL grammar. In his approach the SG is compiled into a Functional Unification Grammar (FUG) (see Kay [14], a representation language with some systemic links) and then existing (but extended) FUG parsing techniques are used to find a syntax tree plus an interpretation for a sentence. The REVELATION1 approach differs from this compilation method since the interpretation is achieved within a systemic framework. No other SG-based model (to my knowledge) has been used for both gene</context>
</contexts>
<marker>[13]</marker>
<rawString>Robert T. Kasper. &amp;quot;An Experimental Parser for Systemic Grammars&amp;quot;. In Proceedings of the 12th International Conference on Computational Linguistics (COLING &apos;88), August 1988. Also available as USC/Information Sciences Institute Reprint RS-88-212.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Martin Kay</author>
</authors>
<title>Parsing in Functional Unification Grammar&amp;quot;.</title>
<pages>251--278</pages>
<note>In Dowty et al. [7], chapter 7,</note>
<contexts>
<context position="4114" citStr="[14]" startWordPosition="667" endWordPosition="667">s [12[. 4 The COMMUNAL Project at University of Wales College of Cardiff (UWCC) Computational Linguistics Unit and Leeds University School of Computer Studies was sponsored by RSHE Malvern, ICL and Longman. 3.29 1C2 ULYI VEZE who open+ing Figure 1: A Typical PG 1.5 Syntax Tree men t. This is not the first time a semantic interpreter has been attempted for a large SG: Kasper [13] has developed a sentence analysis method (both parsing and interpretation together in my terminology) based on the NIGEL grammar. In his approach the SG is compiled into a Functional Unification Grammar (FUG) (see Kay [14], a representation language with some systemic links) and then existing (but extended) FUG parsing techniques are used to find a syntax tree plus an interpretation for a sentence. The REVELATION1 approach differs from this compilation method since the interpretation is achieved within a systemic framework. No other SG-based model (to my knowledge) has been used for both generation and interpretation in this way. Systemic Grammar Fawcett&apos;s SG is a meaning-oriented model of language in which there is a large &apos;and/or&apos; network of semantic features, defining the choices in meaning that are availabl</context>
</contexts>
<marker>[14]</marker>
<rawString>Martin Kay. &amp;quot;Parsing in Functional Unification Grammar&amp;quot;. In Dowty et al. [7], chapter 7, pages 251-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen C Kleene</author>
</authors>
<title>Introduction to Metamathematies.</title>
<date>1952</date>
<publisher>North-Holland,</publisher>
<contexts>
<context position="22249" citStr="[15]" startWordPosition="3581" endWordPosition="3581">such a truth function is called a satisfying truth function for the boolean expression. Unfortunately, this is an intractable problem since a disjunction with n disjuncts can have 3n-1 potential satisfying truth functions, i.e. the task is exponential in problem size (in fact, the problem of satisfiability has the honor of being the first NP-Complete problem; see Garey and Johnson [11]). As is the case with inherently intractable problems; it is not worth searching for an efficient, exact algorithm to perform the task; it is 7Evaluation is performed with respect to Kleene&apos;s three valued logic [15]. 134 Rule Activation Path Activation Figure 9: Decomposition of Rule Activation Figure 10: Part of the AO Tree for Clause Interpretation el(3,M) M094 conf(S,Ag) First Occurrence Rule 2.04 Common r - agent-plus-manner Second Occurrence Rule 6.21 Cornmon Variant Isituation Interpret Cl Realise [Cl...) Only Olecurrence congruent-sit simple-ago agent-S. heme-cr more appropriate to consider a less ambitious problem. Consider the problem of partial satisfiability: it is essentially the same as satisfiability except that it does not attempt to satisfy disjunctive components (since it is these compon</context>
</contexts>
<marker>[15]</marker>
<rawString>Stephen C. Kleene. Introduction to Metamathematies. North-Holland, 1952.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William C Mann</author>
<author>Christian M I M Matthiessen</author>
</authors>
<title>NIGEL: A Systemic Grammar for Text Generation&amp;quot;.</title>
<booktitle>In Benson and Greaves</booktitle>
<contexts>
<context position="1309" citStr="[16, 17]" startWordPosition="203" endWordPosition="204">work of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, Introduction SG (see Butler [4] for a good introduction) is a useful model of language, having found many applications in the 4reas of stylistics, text analysis, educational linguistics and artificial intelligence. Some of these applications have been computational, the best known probably being Winograd&apos;s SHRDLU [22]. However, most computational applications have been designed from a text-generation viewpoint (such as Davey&apos;s PROTEUS [6], Mann and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and Tucker&apos;s GENESYS POD. Because of this text-generation viewpoint of systemic grammarian, the mechanism for sentence analysis within SG the reverse of the sentence generation process) has received much less attention. This paper describes one stage of the sentence analysis process: semantic interpretation.&apos; &apos;This assumes that sentence analysis can be decomposed into two processes: syntactic analysis (parsing) plus semantic In Fawcett&apos;s SG,2 a syntax tree (whose leaves define a sentence) is generated from a set of semantic choices. REVELATION1 reverses this process: it attempts t</context>
</contexts>
<marker>[16]</marker>
<rawString>William C. Mann and Christian M. I. M. Matthiessen. &amp;quot;NIGEL: A Systemic Grammar for Text Generation&amp;quot;. In Benson and Greaves</rawString>
</citation>
<citation valid="false">
<title>Also available as USC/Information Sciences Institute Reprint</title>
<pages>83--105</pages>
<marker>[2]</marker>
<rawString>. Also available as USC/Information Sciences Institute Reprint RS-83-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M I M Matthiessen</author>
<author>John A Bateman</author>
</authors>
<title>Text Generation and SystemicFunctional Linguistics: experiences from English and Japanese.</title>
<date>1991</date>
<location>Pinter, London,</location>
<note>(in press).</note>
<contexts>
<context position="1309" citStr="[16, 17]" startWordPosition="203" endWordPosition="204">work of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, Introduction SG (see Butler [4] for a good introduction) is a useful model of language, having found many applications in the 4reas of stylistics, text analysis, educational linguistics and artificial intelligence. Some of these applications have been computational, the best known probably being Winograd&apos;s SHRDLU [22]. However, most computational applications have been designed from a text-generation viewpoint (such as Davey&apos;s PROTEUS [6], Mann and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and Tucker&apos;s GENESYS POD. Because of this text-generation viewpoint of systemic grammarian, the mechanism for sentence analysis within SG the reverse of the sentence generation process) has received much less attention. This paper describes one stage of the sentence analysis process: semantic interpretation.&apos; &apos;This assumes that sentence analysis can be decomposed into two processes: syntactic analysis (parsing) plus semantic In Fawcett&apos;s SG,2 a syntax tree (whose leaves define a sentence) is generated from a set of semantic choices. REVELATION1 reverses this process: it attempts t</context>
</contexts>
<marker>[17]</marker>
<rawString>Christian M. I. M. Matthiessen and John A. Bateman. Text Generation and SystemicFunctional Linguistics: experiences from English and Japanese. Pinter, London, 1991. (in press).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Nilsson</author>
</authors>
<title>Principles of Artificial Intelligence.</title>
<date>1983</date>
<publisher>Springer Verlag,</publisher>
<marker>[18]</marker>
<rawString>Nils Nilsson. Principles of Artificial Intelligence. Springer Verlag, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim F O&apos;Donoghue</author>
</authors>
<title>The REVELATION1 Semantic Interpreter&amp;quot;.</title>
<date>1991</date>
<tech>COMMUNAL Report 22,</tech>
<institution>School of Computer Studies, University of Leeds,</institution>
<contexts>
<context position="24417" citStr="[19]" startWordPosition="3934" endWordPosition="3934">cessary for the root task to be achieved. A backtracking search is used to generate potential solutions: since the AO tree is finite, it is possible to inspect the structure of the tree and order the search in such a way so that the minimum amount of backtracking is performed.8 A feasible interpretation for a unit is one of the potential solutions in which the statements labelling the leaves are all consistent. There are two ways in which a leaf statement may be inconsistent: 8 The search scheme involves incrementally evaluating and pruning the AO tree. Full details can be found in O&apos;Donoghue [19], an in-depth report on the interpreter. 135 Selection Expression for CI filling Z ii:&apos;rAtOtti?A&apos;a;iRsfrIlierant‘es-jOitififFsatii°nrit:iPeal: i.csr&amp;quot;s■-%ig;7-gh:eig&apos; At:a ItII:;enitelmqe,Za-tireutea:af-untheniatized, grt&apos;lfrnli--,qTtel-VIOP:t1tItegtrg&apos;s11.aolllili;,1-gns&apos;errtg!fgurati°&amp;quot;&apos; Selection Expression for ngp filling S Selection Expi ession for ngp filling C2 thin con r ent-tchin stereot l41-thsing, thing conifirtuuent-Tirif,:rire.?,trj,ge_gw, rikUATsEUtt:linA&apos; c4u6ntiesVccr, rfAeltel-Gorn!ty:superlativtiation t:ttiehegApon-s st Selection expressi n for qqgp filling ds arn*v.locinu-;iti</context>
<context position="30080" citStr="[19]" startWordPosition="4812" endWordPosition="4812">since the AO trees explode into or-nodes, through the use of (i) disjunctive entry conditions in the system network and (ii) disjunctive conditions in the realization rules. It has been proved (Brew [3]) that systemic classification is NP-Hard and is thus inherently intractable. This led to the choice of partial satisfiability rather than exact satisfiability (which itself is NP-Hard) in REVELATION1, and the development of an efficient technique for ,searching the AO trees which utilizes incremental evaluation and pruning to reduce the number of backtracking points (full details in O&apos;Donoghue [19])4 The delayed use of exact satisfiability being investigated in REVELATION2 is similar to Brew&apos;s &apos;partial&apos; algorithm for checking systemic descriptions. Brew&apos;s checking algorithm has two stages, the first o being a simplification stage in which all disjunctive:entry conditions are eliminated from the system network by replacing them with a uniquely generated feature. The resultant simplified network can then be searched efficiently. The second stage involves checking all of the features generated in the first, stage, each generated feature referring to a disjunctive entry condition. Here also</context>
</contexts>
<marker>[19]</marker>
<rawString>Tim F. O&apos;Donoghue. &amp;quot;The REVELATION1 Semantic Interpreter&amp;quot;. COMMUNAL Report 22, School of Computer Studies, University of Leeds, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim F O&apos;Donoghue</author>
</authors>
<title>The Vertical Strip Parser: a lazy approach to parsing&amp;quot;.</title>
<date>1991</date>
<tech>Report 91.15,</tech>
<institution>School of Computer Studies, University of Leeds,</institution>
<contexts>
<context position="2361" citStr="[20]" startWordPosition="377" endWordPosition="377">cett&apos;s SG,2 a syntax tree (whose leaves define a sentence) is generated from a set of semantic choices. REVELATION1 reverses this process: it attempts to find the set of semantic choices needed to generate a given syntax tree. In sentence generation, a tree is generated, but only the leaves (the words) are &apos;output&apos;, the rest of the tree is simply deleted. In the reverse process, when a sentence is input, a syntax tree must first be found before it can be interpreted. REVELATION1 assumes that a separate SG parser (not discussed here) is available; for an example of such a parser see O&apos;Donoghue [20]. Thus REVELATION1 directly mirrors the generator, while the parser mirrors the tree deletion process. REVELATI0N1 has been developed within the POPLOG environment.3 It is coded in a combination of P0P11 [1] and Prolog [5] and utilizes GENESYS. GENESYS is a very large SG generator for English, written in Prolog (Fawcett and Tucker [10]) and it is version PG1.5 that has been used for the development and testing of REVELATION 1. GENESYS and REVELATION are part of a much larger project, the COMMUNAL4 Project, the aim of which is to build a natural language interface to a rich SG oriented IKBS in </context>
</contexts>
<marker>[20]</marker>
<rawString>Tim F. O&apos;Donoghue. &amp;quot;The Vertical Strip Parser: a lazy approach to parsing&amp;quot;. Report 91.15, School of Computer Studies, University of Leeds, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Slagle</author>
</authors>
<title>A Heuristic Program that Solves Symbolic Integration Problems in Freshman Calculus&amp;quot;.</title>
<date>1963</date>
<booktitle>Computers and Thought,</booktitle>
<pages>191--203</pages>
<editor>In E. Feigenbaum and J. Feldman, editors,</editor>
<publisher>McGraw-Hill,</publisher>
<location>New York,</location>
<contexts>
<context position="14604" citStr="[21]" startWordPosition="2358" endWordPosition="2358">on is the selection expression which generated that unit. In general there can be more than one selection expression for any given unit, since the same syntactic structure can have more than one meaning, just as a whole sentence can have more than one meaning. The potential unit interpretations are defined by constructing an AO tree5 whose goal (root) is to prove unit realization, i.e. prove that the unit can be generated. Each potential solution of this AO tree defines a poten5 AO (AND/OR) trees provide a means for describing task decomposition. These structures were first proposed by Slagle [21] and have since been used in a variety of applications including symbolic integration and theorem proving (Nilsson [IA lists a number of applications with references). The AO tree notation used throughout this paper is illustrated in Figure 6 with leaves — terminal tasks which cannot be decomposed any further — being represented as bold nodes. 132 Unit Interpretation Unit Realisation Realisation of Descriptor I Realisation of Descriptor Realisation of Descriptor n Figure 7: Decomposition of Unit Interpretation tial selection expression for the unit. The semantic representation for the tree is </context>
</contexts>
<marker>[21]</marker>
<rawString>J. R. Slagle. &amp;quot;A Heuristic Program that Solves Symbolic Integration Problems in Freshman Calculus&amp;quot;. In E. Feigenbaum and J. Feldman, editors, Computers and Thought, pages 191-203. McGraw-Hill, New York, 1963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Language as a Cognitive Process,</title>
<date>1983</date>
<volume>1</volume>
<publisher>Syntax. Addison Wesley,</publisher>
<contexts>
<context position="1147" citStr="[22]" startWordPosition="181" endWordPosition="181"> reversible grammars, ,an interpreter based on a generator. A task decomposition approach is adopted for this reversal process which operates within the framework of SG, thus demonstrating that Systemic Grammars can be reversed and hence that a SG is a truly bi-directional formalism, Introduction SG (see Butler [4] for a good introduction) is a useful model of language, having found many applications in the 4reas of stylistics, text analysis, educational linguistics and artificial intelligence. Some of these applications have been computational, the best known probably being Winograd&apos;s SHRDLU [22]. However, most computational applications have been designed from a text-generation viewpoint (such as Davey&apos;s PROTEUS [6], Mann and Matthiessen&apos;s NIGEL [16, 17] and Fawcett and Tucker&apos;s GENESYS POD. Because of this text-generation viewpoint of systemic grammarian, the mechanism for sentence analysis within SG the reverse of the sentence generation process) has received much less attention. This paper describes one stage of the sentence analysis process: semantic interpretation.&apos; &apos;This assumes that sentence analysis can be decomposed into two processes: syntactic analysis (parsing) plus seman</context>
</contexts>
<marker>[22]</marker>
<rawString>Terry Winograd. Language as a Cognitive Process, Volume 1: Syntax. Addison Wesley, 1983.</rawString>
</citation>
<citation valid="true">
<title>Intelligence: principles and applications.</title>
<date>1986</date>
<editor>Masoud Yazdani, editor. Artificial</editor>
<publisher>Chapman Hall,</publisher>
<marker>[23]</marker>
<rawString>Masoud Yazdani, editor. Artificial Intelligence: principles and applications. Chapman Hall, 1986.</rawString>
</citation>
<citation valid="true">
<date>1988</date>
<booktitle>Advances in Natural Language Generation</booktitle>
<volume>2</volume>
<editor>Michael Zock and Gerard Subah, editors.</editor>
<publisher>Pinter,</publisher>
<location>London,</location>
<marker>[24]</marker>
<rawString>Michael Zock and Gerard Subah, editors. Advances in Natural Language Generation (Volume 2). Pinter, London, 1988.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>