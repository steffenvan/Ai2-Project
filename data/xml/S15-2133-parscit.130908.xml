<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.044048">
<note confidence="0.50189475">
SPINOZA VU: An NLP Pipeline for Cross Document TimeLines
Tommaso Caselli Antske Fokkens Roser Morante Piek Vossen
Computational Lexicology &amp; Terminology Lab (CLTL)
VU Amsterdam, De Boelelaan 1105
</note>
<address confidence="0.860915">
1081 HV Amsterdam Nederland
</address>
<email confidence="0.998931">
{t.caselli}{antske.fokkens}{r.morantevallejo}{p.t.j.m.vossen}@vu.nl
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989">
This paper describes the system
SPINOZA VU developed for the SemEval
2015 Task 4: Cross Document TimeLines.
The system integrates output from the News-
Reader Natural Language Processing pipeline
and is designed following an entity based
model. The poor performance of the submit-
ted runs are mainly a consequence of error
propagation. Nevertheless, the error analysis
has shown that the interpretation module
behind the system performs correctly. An
out of competition version of the system has
fixed some errors and obtained competitive
results. Therefore, we consider the system an
important step towards a more complex task
such as storyline extraction.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914146341463">
This paper reports on a system (SPINOZA VU) for
timeline extraction developed at the CLTL Lab of
the VU Amsterdam in the context of the SemEval
2015 Task 4: Cross Document TimeLines. In this
task, a timeline is defined as a set of chronologically
anchored and ordered events extracted from a corpus
spanning over a (large) period of time with respect
to a target entity.
Cross-document timeline extraction benefits from
previous works and evaluation campaigns in Tem-
poral Processing, such as the TempEval evaluation
campaigns (Verhagen et al., 2007; Verhagen et al.,
2010; UzZaman et al., 2013) and aims at promoting
research in temporal processing by tackling the fol-
lowing issues: cross-document and cross-temporal
event detection and ordering; event coreference (in-
document and cross-document); and entity-based
temporal processing.
The SPINOZA VU system is based on the News-
Reader (NWR) NLP pipeline (Agerri et al., 2013;
Beloki et al., 2014), which has been developed
within the context of the NWR project1 and pro-
vides multi-layer annotations over raw texts from
tokenization up to temporal relations. The goal of
the NWR project is to build structured event in-
dexes from large volumes of news data addressing
the same research issues as the task. Within this
framework, we are developing a storyline module
which aims at providing more structured represen-
tation of events and their relations. Timeline extrac-
tion from raw text qualifies as the first component
of this new module. This is why we participated in
Track A and Subtrack A of the task, timeline extrac-
tion from raw text. Participating in Track B would
require a full re-engineering of the NWR pipeline
and of our system.
The remainder of the paper is structured as fol-
lows: Section 2 provides an overview of the model
implemented in the two versions of our system. Sec-
tion 3 presents the results and error analysis, and
Section 4 puts forward some conclusions.
</bodyText>
<sectionHeader confidence="0.994087" genericHeader="method">
2 From Model to System
</sectionHeader>
<bodyText confidence="0.99827325">
Timeline extraction involves a number of indepen-
dent though highly connected subtasks, the most
relevant ones being: entity resolution, event detec-
tion, event-participant linking, coreference resolu-
</bodyText>
<footnote confidence="0.991627">
1http://www.newsreader-project.eu
</footnote>
<page confidence="0.923759">
787
</page>
<bodyText confidence="0.905523307692308">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 787–791,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
tion, factuality profiling, and temporal relation pro-
cessing (ordering and anchoring).
We designed a system that addresses these sub-
tasks, first at document level, and then, at cross-
document level. We diverted from the general NWR
approach and adopted an entity based model and
representation rather than an event based one in or-
der to fit the task. This means that we used entities
as hub of information for timelines. Using an entity
driven representation allows us to better model the
following aspects:
</bodyText>
<listItem confidence="0.987965583333333">
• Event co-participation: the data collected
with this method facilitates the analysis of the
interactions between the participants involved
in an event individually;
• Event relations: in an entity based representa-
tion, event mentions with more than one entity
as their participants will be repeated in the final
representation (both at in-document at cross-
document levels); such a representation can be
further used to explore and discover additional
event relations2;
• Event coreference: we assume that two event
mentions (either in the same document or in
different documents) are coreferential if they
share the same participant set (i.e., entities) and
occur at the same time and place (Chen et al.,
2011; Cybulska and Vossen, 2013);
• Temporal relations: temporal relation pro-
cessing can benefit from an entity driven ap-
proach as sequences of events sharing the same
entities (i.e., co-participant events) can be as-
sumed to stand in precedence relation (Cham-
bers and Jurafsky, 2009; Chambers and Juraf-
sky, 2010).
</listItem>
<subsectionHeader confidence="0.981797">
2.1 The SPINOZA VU System
</subsectionHeader>
<bodyText confidence="0.9958419">
The NWR pipeline which forms the basis of the
SPINOZA VU system consists of 15 modules car-
rying out various NLP tasks and outputs the results
in NLP Annotation Format (Fokkens et al., 2014),
a layered standoff representation format. Two ver-
sions of the system have been developed, namely:
2We are referring to a broader set of relations that we la-
beled as “bridging relations” among events which involve co-
participation, primary and secondary causal relations, temporal
relations, and entailment relations.
</bodyText>
<listItem confidence="0.994197">
• SPINOZA VU 1 uses the output of a state of
the art system, TIPSem (Llorens et al., 2010),
for event detection and temporal relations;
• SPINOZA VU 2 is entirely based on data
from the NWR pipeline including the temporal
(TLINKs) and causal relation (CLINKs) layers.
</listItem>
<bodyText confidence="0.999864414634146">
The final output is based on a dedicated rule-
based module, the TimeLine (TML) module. We
will describe in the following paragraphs how each
subtask has been tackled with respect to each ver-
sion of the system.
Entity identification Entity identification relies
on the entity detection and disambiguation layer
(NERD) of the NWR pipeline. Each detected en-
tity is associated with a URI (a unique identifier),
either from DBpedia or a specifically created one
based on the strings describing the entity. We ex-
tracted the entities by merging information from the
NERD layer with that from the semantic role la-
belling (SRL) layer. We retained only those en-
tity mentions which fulfil the argument positions
of proto-agent (Arg0) or proto-patient (Arg1) in the
SRL layer.
Event detection and classification The
SPINOZA VU 1 event module is based on
TIPSem, which provides TimeML compliant data.
We developed post processing rules to convert the
TimeML event classes (OCCURRENCE, STATE,
I ACTION, I STATE, ASPECTUAL, REPORT-
ING and PERCEPTION) to specific FrameNet
frames (e.g., Communication, Being in operation,
Body movement) and/or Event Situation Ontology
(ESO) types (Segers et al., 2015) (e.g., contextual),
which correspond to the event types specified in the
task guidelines. For instance, not all mentions of
TimeML I STATE, I ACTION, OCCURRENCE
and STATE events can enter a timeline. The
alignment with FrameNet and ESO is made by
combining the data from the Word Sense Dis-
ambiguation (WSD) layer of the pipeline with
Predicate Matrix (version 1.1) (Lacalle et al., 2014).
As for the SPINOZA VU 2, we have used the
NWR SRL layer to identify and retain the eligi-
ble events. In this case the access to the Predi-
cate Matrix is not necessary as each predicate in
the SRL layer is also associated with corresponding
FrameNet frames and ESO types. Only the pred-
</bodyText>
<page confidence="0.989771">
788
</page>
<bodyText confidence="0.999763736842105">
icates matching specific FrameNet frames and/or
ESO types were retained as candidate events.
Factuality The factuality filter consists of a col-
lection of rules in order to determine whether an
event is within the scope of a factuality marker
negating an event or indicating that it is uncertain, in
which case the event is excluded from the set of el-
igible events. Factuality markers are different types
of modality and negation cues (adverbs, adjectives,
prepositions, modal auxiliaries, pronouns and deter-
miners). For instance, if a verb has a dependency
relation of type AM-MOD with a modal auxiliary is
excluded from the candidate event in the timeline.
Coreference relations Two levels of corefer-
ence need to be addressed: in-document and cross-
document. As for the former, both versions of the
system rely on the coreference layer (COREF layer)
of the pipeline. Concerning the cross-document
level, two strategies have been implemented:
</bodyText>
<listItem confidence="0.950472142857143">
• Cross-document entity mentions are identified
using the URI links associated with entity men-
tions; all entity mentions from different doc-
uments sharing the same URIs are associated
with the same entity instance;
• Cross-document event coreference is obtained
during a post-processing step of the timeline
creation following the assumption that two
event mentions denote the same event instance
(i.e., they co-refer) if they share the same par-
ticipants, time of occurrence and (possibly) lo-
cation. Entity-based timelines are used as a
basis to identify instances of cross-document
event coreferential expressions.
</listItem>
<bodyText confidence="0.998571">
Temporal Relations For the SPINOZA VU 1
version, we used the Temporal Relations from
TIPSem (TLINKs), including temporal expres-
sion detection and normalization. For the
SPINOZA VU 2 version, we used the TLINK and
CLINK layers of the NWR pipeline. As for the
CLINK layer, we converted all causal relations into
temporal ones, with the value BEFORE. For both
versions of the system we maximized temporal an-
choring by recovering the beginning or end point
of temporal expressions of type DURATION and re-
solving all TLINKs between a temporal expression
and a target event except “IS INCLUDED” relations
into an anchoring relation.
TimeLine Extraction The TimeLine Extrac-
tion (TML) module3 harmonizes and orders cross-
document temporal relations (anchoring and order-
ing). It provides a method for selecting the initial
(relevant) temporal relations (namely, all anchoring
relations) and enhance an updating mechanism of in-
formation so that additional temporal relations (both
anchoring and ordering relations) can be inferred.
Timelines are first created at a document level and
subsequently merged. The cross-document timeline
model is event-based and aims at building a global
timeline between all events and temporal expres-
sions regardless of the target entities. This approach
allows us to also make use of temporal information
provided by events that are not part of the final time-
lines. Finally, the target entities for the timelines are
extracted using two strategies: i) a perfect match be-
tween the target entities and the DBpedia URIs, and
ii) the Levenshtein distance (Levenshtein, 1966) be-
tween the target entities and the URIs. For this latter
strategy, an empirical threshold was set to maximize
precision on the basis of the trial data.
</bodyText>
<sectionHeader confidence="0.999702" genericHeader="evaluation">
3 Results and Error Analysis
</sectionHeader>
<bodyText confidence="0.999546833333333">
In Table 1 we report the results of both versions of
the system for Track A - Main. We also include
the results of the best performing system and out of
competition results of a new version of the system
(OC SPINOZA VU), which obtained competitive
results with respect the best system, WHUNLP 1.
</bodyText>
<table confidence="0.9989065">
System Version Corpus 1 Corpus 2 Corpus 3 Overall
SPINOZA VU 1 4.07 5.31 0.42 3.15
SPINOZA VU 2 2.67 0.62 0.00 1.05
OC SPINOZA VU 7.50 6.64 6.59 7.12
Best system
WHUNLP 1 8.31 6.01 6.86 7.28
</table>
<tableCaption confidence="0.9940015">
Table 1: System Results (micro F1 score) for the Se-
mEval 2015 Task 4 Task A - Main Track.
</tableCaption>
<bodyText confidence="0.9995976">
The OC SPINOZA VU system is based on
SPINOZA VU 2, and the main differences concern
temporal relations identification at in-document and
cross-document level, and entity extraction. In par-
ticular, we assume that: if a temporal expression
</bodyText>
<footnote confidence="0.979372">
3https://github.com/antske/
BiographyNet/tree/master/
TimeLineExtraction
</footnote>
<page confidence="0.998278">
789
</page>
<bodyText confidence="0.999625909090909">
occurs in the same sentence of an event, the tem-
poral expression is the event’s temporal anchor; if
no temporal expression occurs in the same sentence,
we check if there are any temporal expressions in
the two previous sentences or, if any, in the one fol-
lowing it. The event is then anchor to the closest
temporal expression identified. Finally, if no tem-
poral expression can be found in this sentence win-
dow, no temporal anchor is assigned to the event.
As for event ordering, we have used the order of ap-
pearance of the event in the document to establish
precedence relations. The final timeline is obtained
by ordering cross-document event with a modified
version of the TML module based on time anchors
only. Entity extraction is extended by adding pure
substring match.
Table 2 reports the results of the submitted sys-
tems and of the out of competition one. No other
results are reported for Track A - Subtask A because
only our system participated. The null results of the
out of competition system are due to the modified
version of the TML module.
</bodyText>
<table confidence="0.99876275">
System Version Corpus 1 Corpus 2 Corpus 3 Overall
SPINOZA VU 1 1.20 1.70 2.08 1.69
SPINOZA VU 2 0.00 0.92 0.00 0.27
OC SPINOZA VU 0.00 0.00 0.00 0.00
</table>
<tableCaption confidence="0.993905">
Table 2: System Results (micro F1 score) for the Se-
mEval 2015 Task 4 Task A - Subtrack.
</tableCaption>
<bodyText confidence="0.999931512820513">
Overall, the results of the submitted system are
not satisfying. Out of 37 entity based timelines, the
system produced results only for 31 of them. Three
sources of errors occur in both versions of our sys-
tem. Error analysis yields the following explana-
tions:
Event detection We analyzed both entity-based
event detection (all events associated with each tar-
get entity) and global event detection (all events re-
gardless of the target entities). On entity-based event
detection, SPINOZA VU 1 scores an average F1
score on the 31 detected entities of 23.58 (38.7 preci-
sion and 17.35 for recall), whereas SPINOZA VU 2
scores an average F1 of 20.46 (47.83 precision
and 13.32 recall). As for global event detection,
both versions of the system present a high recall
and low precision pattern, although with substan-
tial differences in terms of results. In particular,
SPINOZA VU 1 has an average recall of 44.96 and
an average precision of 25.5, while SPINOZA VU 2
has an average recall of 77.03 and an average preci-
sion of 14.86;
Entity detection This layer is strictly connected
to the event detection layer. The lower results are
mainly due to the output of the COREF and SRL
layers. Missing coreference chains (e.g. “the air-
craft” not connected to a target entity like “Airbus
A380”)) and wrong spans of event arguments nega-
tively impacts on the extraction of candidate events
for the timeline;
Event ordering and anchoring The difference
in performance between the submitted system and
OC SPINOZA VU clearly indicates that there is
room for improvement concerning the amount of
temporal relations (anchoring and ordering ones)
which are extracted. Furthermore, the difference in
performance between the Main track and the Sub-
track suggests that the main issues concern event or-
dering rather than their detection or anchoring.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999507375">
In this paper we presented the SPINOZA VU sys-
tem for timeline extraction system in the context of
the SemEval 2015 Task 4: Cross Document Time-
Lines. The low ranking show not only that the
task is very complex, but also that there is room
for improving the system, as the results of the
OC SPINOZA VU system show. The low perfor-
mance is mainly a consequence of a combination of
cascading errors and missing data from the different
modules of the system, namely event detection, tem-
poral relation extraction and entity detection. How-
ever, on the positive side, the theoretical model that
has guided the development of the system can be fur-
ther extended to address more complex tasks on top
of the timeline extraction, such as storyline extrac-
tion.
</bodyText>
<sectionHeader confidence="0.998811" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999711714285714">
Our thanks to the anonymous reviewers for their
suggestions and comments. This work has been sup-
ported by EU NewsReader Project (FP7-ICT-2011-
8 grant 316404), the NWO Spinoza Prize project
Understanding Language by Machines (sub-track 3)
and the BiographyNet project (Nr. 660.011.308),
funded by the Netherlands eScience Center.
</bodyText>
<page confidence="0.993718">
790
</page>
<sectionHeader confidence="0.996045" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999821266666667">
Rodrigo Agerri, Itziar Aldabe, Zuhaitz Beloki, Egoitz
Laparra, Maddalen Lopez de Lacalle, German Rigau,
Aitor Soroa, Antske Fokkens, Ruben Izquierdo,
Marieke van Erp, Piek Vossen, Christian Girardi, and
Anne-Lyse Minard. 2013. Event detection, version 2.
NewsReader Deliverable 4.2.2.
Zuhaitz Beloki, German Rigau, Aitor Soroa, Antske
Fokkens, Piek Vossen, Marco Rospocher, Francesco
Corcoglioniti, Roldano Cattoni, Thomas Ploeger, and
Willem Robert van Hage. 2014. System design.
NewsReader Deliverable 2.1.
Nathanael Chambers and Dan Jurafsky. 2009. Unsuper-
vised Learning of Narrative Schemas and their Partic-
ipants. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP, pages 602–610, Suntec, Singapore,
August.
Nathanael Chambers and Dan Jurafsky. 2010. A
Database of Narrative Schemas. In Proceedings of the
Seventh Conference on International Language Re-
sources and Evaluation (LREC’10), Valletta, Malta,
May.
Bin Chen, Jian Su, Sinno Jialin Pan, and Chew Lim Tan.
2011. A Unified Event Coreference Resolution by In-
tegrating Multiple Resolvers. In Proceedings of the
5th International Joint Conference on Natural Lan-
guage Processing, pages 102–110, Chiang Mai, Thai-
land.
Agata Cybulska and Piek Vossen. 2013. Semantic rela-
tions between events and their time, locations and par-
ticipants for event coreference resolution. In Proceed-
ings of Recent Advances in Natural Language Process-
ing (RANLP-2013), pages 156–163.
Antske Fokkens, Aitor Soroa, Zuhaitz Beloki, Niels Ock-
eloen, German Rigau, Willem Robert van Hage, and
Piek Vossen. 2014. NAF and GAF: Linking linguis-
tic annotations. In Proceedings 10th Joint ISO-ACL
SIGSEM Workshop on Interoperable Semantic Anno-
tation, pages 9–16.
Maddalen Lopez De Lacalle, Egoitz Laparra, and Ger-
man Rigau. 2014. Predicate Matrix: extending Sem-
Link through WordNet mappings. In Proceedings of
the Ninth International Conference on Language Re-
sources and Evaluation (LREC’14), Reykjavik, Ice-
land, May.
Vladimir I. Levenshtein. 1966. Binary codes capable of
correcting deletions, insertions and reversals. In Soviet
physics doklady, volume 10, pages 707–710.
Hector Llorens, Estela Saquete, and Borja Navarro.
2010. TIPSem (English and Spanish): Evaluating
CRFs and Semantic Roles in TempEval-2. In Pro-
ceedings of the 5th International Workshop on Seman-
tic Evaluation, pages 284–291.
Roxane Segers, Piek Vossen, Marco Rospocher, Luciano
Serafini, Egoitz Laparra, and German Rigau. 2015.
ESO: A Frame Based Ontology for Events and Implied
Situations. In Proceedings of Maplex2015.
Naushad UzZaman, Hector Llorens, James Allen, Leon
Derczynski, Marc Verhagen, and James Pustejovsky.
2013. SemEval-2013 Task 1: TempEval-3: Evaluat-
ing time expressions, events, and temporal relations.
In Proceedings of the 7th International Workshop on
Seman- tic Evaluation, pages 1–9.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 Task 15: TempEval Temporal
Relation Identification. In Proceedings of the 4th In-
ternational Workshop on Semantic Evaluation, pages
75–80, June.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 Task 13:
TempEval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57–62, Up-
psala, Sweden.
</reference>
<page confidence="0.997958">
791
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.735447">
<title confidence="0.999461">SPINOZA VU: An NLP Pipeline for Cross Document TimeLines</title>
<author confidence="0.999748">Tommaso Caselli Antske Fokkens Roser Morante Piek Vossen</author>
<affiliation confidence="0.8730145">Computational Lexicology &amp; Terminology Lab VU Amsterdam, De Boelelaan</affiliation>
<address confidence="0.99701">1081 HV Amsterdam</address>
<abstract confidence="0.997616764705882">This paper describes the system SPINOZA VU developed for the SemEval 2015 Task 4: Cross Document TimeLines. The system integrates output from the News- Reader Natural Language Processing pipeline and is designed following an entity based model. The poor performance of the submitted runs are mainly a consequence of error propagation. Nevertheless, the error analysis has shown that the interpretation module behind the system performs correctly. An out of competition version of the system has fixed some errors and obtained competitive results. Therefore, we consider the system an important step towards a more complex task such as storyline extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rodrigo Agerri</author>
</authors>
<title>Itziar Aldabe, Zuhaitz Beloki, Egoitz Laparra, Maddalen Lopez de Lacalle, German Rigau, Aitor Soroa, Antske Fokkens,</title>
<date>2013</date>
<location>Ruben Izquierdo, Marieke</location>
<marker>Agerri, 2013</marker>
<rawString>Rodrigo Agerri, Itziar Aldabe, Zuhaitz Beloki, Egoitz Laparra, Maddalen Lopez de Lacalle, German Rigau, Aitor Soroa, Antske Fokkens, Ruben Izquierdo, Marieke van Erp, Piek Vossen, Christian Girardi, and Anne-Lyse Minard. 2013. Event detection, version 2. NewsReader Deliverable 4.2.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zuhaitz Beloki</author>
</authors>
<title>German Rigau, Aitor Soroa, Antske Fokkens, Piek Vossen, Marco Rospocher, Francesco Corcoglioniti, Roldano Cattoni,</title>
<date>2014</date>
<booktitle>System design. NewsReader Deliverable 2.1.</booktitle>
<location>Thomas</location>
<marker>Beloki, 2014</marker>
<rawString>Zuhaitz Beloki, German Rigau, Aitor Soroa, Antske Fokkens, Piek Vossen, Marco Rospocher, Francesco Corcoglioniti, Roldano Cattoni, Thomas Ploeger, and Willem Robert van Hage. 2014. System design. NewsReader Deliverable 2.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised Learning of Narrative Schemas and their Participants.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>602--610</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="4838" citStr="Chambers and Jurafsky, 2009" startWordPosition="742" endWordPosition="746">ment levels); such a representation can be further used to explore and discover additional event relations2; • Event coreference: we assume that two event mentions (either in the same document or in different documents) are coreferential if they share the same participant set (i.e., entities) and occur at the same time and place (Chen et al., 2011; Cybulska and Vossen, 2013); • Temporal relations: temporal relation processing can benefit from an entity driven approach as sequences of events sharing the same entities (i.e., co-participant events) can be assumed to stand in precedence relation (Chambers and Jurafsky, 2009; Chambers and Jurafsky, 2010). 2.1 The SPINOZA VU System The NWR pipeline which forms the basis of the SPINOZA VU system consists of 15 modules carrying out various NLP tasks and outputs the results in NLP Annotation Format (Fokkens et al., 2014), a layered standoff representation format. Two versions of the system have been developed, namely: 2We are referring to a broader set of relations that we labeled as “bridging relations” among events which involve coparticipation, primary and secondary causal relations, temporal relations, and entailment relations. • SPINOZA VU 1 uses the output of a</context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised Learning of Narrative Schemas and their Participants. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 602–610, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>A Database of Narrative Schemas.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta, Malta,</location>
<contexts>
<context position="4868" citStr="Chambers and Jurafsky, 2010" startWordPosition="747" endWordPosition="751">tation can be further used to explore and discover additional event relations2; • Event coreference: we assume that two event mentions (either in the same document or in different documents) are coreferential if they share the same participant set (i.e., entities) and occur at the same time and place (Chen et al., 2011; Cybulska and Vossen, 2013); • Temporal relations: temporal relation processing can benefit from an entity driven approach as sequences of events sharing the same entities (i.e., co-participant events) can be assumed to stand in precedence relation (Chambers and Jurafsky, 2009; Chambers and Jurafsky, 2010). 2.1 The SPINOZA VU System The NWR pipeline which forms the basis of the SPINOZA VU system consists of 15 modules carrying out various NLP tasks and outputs the results in NLP Annotation Format (Fokkens et al., 2014), a layered standoff representation format. Two versions of the system have been developed, namely: 2We are referring to a broader set of relations that we labeled as “bridging relations” among events which involve coparticipation, primary and secondary causal relations, temporal relations, and entailment relations. • SPINOZA VU 1 uses the output of a state of the art system, TIPS</context>
</contexts>
<marker>Chambers, Jurafsky, 2010</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2010. A Database of Narrative Schemas. In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Chen</author>
<author>Jian Su</author>
<author>Sinno Jialin Pan</author>
<author>Chew Lim Tan</author>
</authors>
<title>A Unified Event Coreference Resolution by Integrating Multiple Resolvers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>102--110</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="4560" citStr="Chen et al., 2011" startWordPosition="699" endWordPosition="702">interactions between the participants involved in an event individually; • Event relations: in an entity based representation, event mentions with more than one entity as their participants will be repeated in the final representation (both at in-document at crossdocument levels); such a representation can be further used to explore and discover additional event relations2; • Event coreference: we assume that two event mentions (either in the same document or in different documents) are coreferential if they share the same participant set (i.e., entities) and occur at the same time and place (Chen et al., 2011; Cybulska and Vossen, 2013); • Temporal relations: temporal relation processing can benefit from an entity driven approach as sequences of events sharing the same entities (i.e., co-participant events) can be assumed to stand in precedence relation (Chambers and Jurafsky, 2009; Chambers and Jurafsky, 2010). 2.1 The SPINOZA VU System The NWR pipeline which forms the basis of the SPINOZA VU system consists of 15 modules carrying out various NLP tasks and outputs the results in NLP Annotation Format (Fokkens et al., 2014), a layered standoff representation format. Two versions of the system have</context>
</contexts>
<marker>Chen, Su, Pan, Tan, 2011</marker>
<rawString>Bin Chen, Jian Su, Sinno Jialin Pan, and Chew Lim Tan. 2011. A Unified Event Coreference Resolution by Integrating Multiple Resolvers. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 102–110, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Agata Cybulska</author>
<author>Piek Vossen</author>
</authors>
<title>Semantic relations between events and their time, locations and participants for event coreference resolution.</title>
<date>2013</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing (RANLP-2013),</booktitle>
<pages>156--163</pages>
<contexts>
<context position="4588" citStr="Cybulska and Vossen, 2013" startWordPosition="703" endWordPosition="706">n the participants involved in an event individually; • Event relations: in an entity based representation, event mentions with more than one entity as their participants will be repeated in the final representation (both at in-document at crossdocument levels); such a representation can be further used to explore and discover additional event relations2; • Event coreference: we assume that two event mentions (either in the same document or in different documents) are coreferential if they share the same participant set (i.e., entities) and occur at the same time and place (Chen et al., 2011; Cybulska and Vossen, 2013); • Temporal relations: temporal relation processing can benefit from an entity driven approach as sequences of events sharing the same entities (i.e., co-participant events) can be assumed to stand in precedence relation (Chambers and Jurafsky, 2009; Chambers and Jurafsky, 2010). 2.1 The SPINOZA VU System The NWR pipeline which forms the basis of the SPINOZA VU system consists of 15 modules carrying out various NLP tasks and outputs the results in NLP Annotation Format (Fokkens et al., 2014), a layered standoff representation format. Two versions of the system have been developed, namely: 2We</context>
</contexts>
<marker>Cybulska, Vossen, 2013</marker>
<rawString>Agata Cybulska and Piek Vossen. 2013. Semantic relations between events and their time, locations and participants for event coreference resolution. In Proceedings of Recent Advances in Natural Language Processing (RANLP-2013), pages 156–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antske Fokkens</author>
<author>Aitor Soroa</author>
<author>Zuhaitz Beloki</author>
<author>Niels Ockeloen</author>
<author>German Rigau</author>
<author>Willem Robert van Hage</author>
<author>Piek Vossen</author>
</authors>
<title>NAF and GAF: Linking linguistic annotations.</title>
<date>2014</date>
<booktitle>In Proceedings 10th Joint ISO-ACL SIGSEM Workshop on Interoperable Semantic Annotation,</booktitle>
<pages>9--16</pages>
<marker>Fokkens, Soroa, Beloki, Ockeloen, Rigau, van Hage, Vossen, 2014</marker>
<rawString>Antske Fokkens, Aitor Soroa, Zuhaitz Beloki, Niels Ockeloen, German Rigau, Willem Robert van Hage, and Piek Vossen. 2014. NAF and GAF: Linking linguistic annotations. In Proceedings 10th Joint ISO-ACL SIGSEM Workshop on Interoperable Semantic Annotation, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maddalen Lopez De Lacalle</author>
<author>Egoitz Laparra</author>
<author>German Rigau</author>
</authors>
<title>Predicate Matrix: extending SemLink through WordNet mappings.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<location>Reykjavik, Iceland,</location>
<marker>De Lacalle, Laparra, Rigau, 2014</marker>
<rawString>Maddalen Lopez De Lacalle, Egoitz Laparra, and German Rigau. 2014. Predicate Matrix: extending SemLink through WordNet mappings. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1966</date>
<booktitle>In Soviet physics doklady,</booktitle>
<volume>10</volume>
<pages>707--710</pages>
<contexts>
<context position="10679" citStr="Levenshtein, 1966" startWordPosition="1677" endWordPosition="1678">horing and ordering relations) can be inferred. Timelines are first created at a document level and subsequently merged. The cross-document timeline model is event-based and aims at building a global timeline between all events and temporal expressions regardless of the target entities. This approach allows us to also make use of temporal information provided by events that are not part of the final timelines. Finally, the target entities for the timelines are extracted using two strategies: i) a perfect match between the target entities and the DBpedia URIs, and ii) the Levenshtein distance (Levenshtein, 1966) between the target entities and the URIs. For this latter strategy, an empirical threshold was set to maximize precision on the basis of the trial data. 3 Results and Error Analysis In Table 1 we report the results of both versions of the system for Track A - Main. We also include the results of the best performing system and out of competition results of a new version of the system (OC SPINOZA VU), which obtained competitive results with respect the best system, WHUNLP 1. System Version Corpus 1 Corpus 2 Corpus 3 Overall SPINOZA VU 1 4.07 5.31 0.42 3.15 SPINOZA VU 2 2.67 0.62 0.00 1.05 OC SP</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. In Soviet physics doklady, volume 10, pages 707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja Navarro</author>
</authors>
<title>TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>284--291</pages>
<contexts>
<context position="5493" citStr="Llorens et al., 2010" startWordPosition="853" endWordPosition="856">1 The SPINOZA VU System The NWR pipeline which forms the basis of the SPINOZA VU system consists of 15 modules carrying out various NLP tasks and outputs the results in NLP Annotation Format (Fokkens et al., 2014), a layered standoff representation format. Two versions of the system have been developed, namely: 2We are referring to a broader set of relations that we labeled as “bridging relations” among events which involve coparticipation, primary and secondary causal relations, temporal relations, and entailment relations. • SPINOZA VU 1 uses the output of a state of the art system, TIPSem (Llorens et al., 2010), for event detection and temporal relations; • SPINOZA VU 2 is entirely based on data from the NWR pipeline including the temporal (TLINKs) and causal relation (CLINKs) layers. The final output is based on a dedicated rulebased module, the TimeLine (TML) module. We will describe in the following paragraphs how each subtask has been tackled with respect to each version of the system. Entity identification Entity identification relies on the entity detection and disambiguation layer (NERD) of the NWR pipeline. Each detected entity is associated with a URI (a unique identifier), either from DBpe</context>
</contexts>
<marker>Llorens, Saquete, Navarro, 2010</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja Navarro. 2010. TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 284–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxane Segers</author>
<author>Piek Vossen</author>
<author>Marco Rospocher</author>
<author>Luciano Serafini</author>
<author>Egoitz Laparra</author>
<author>German Rigau</author>
</authors>
<title>ESO: A Frame Based Ontology for Events and Implied Situations.</title>
<date>2015</date>
<booktitle>In Proceedings of Maplex2015.</booktitle>
<contexts>
<context position="6855" citStr="Segers et al., 2015" startWordPosition="1068" endWordPosition="1071">ayer with that from the semantic role labelling (SRL) layer. We retained only those entity mentions which fulfil the argument positions of proto-agent (Arg0) or proto-patient (Arg1) in the SRL layer. Event detection and classification The SPINOZA VU 1 event module is based on TIPSem, which provides TimeML compliant data. We developed post processing rules to convert the TimeML event classes (OCCURRENCE, STATE, I ACTION, I STATE, ASPECTUAL, REPORTING and PERCEPTION) to specific FrameNet frames (e.g., Communication, Being in operation, Body movement) and/or Event Situation Ontology (ESO) types (Segers et al., 2015) (e.g., contextual), which correspond to the event types specified in the task guidelines. For instance, not all mentions of TimeML I STATE, I ACTION, OCCURRENCE and STATE events can enter a timeline. The alignment with FrameNet and ESO is made by combining the data from the Word Sense Disambiguation (WSD) layer of the pipeline with Predicate Matrix (version 1.1) (Lacalle et al., 2014). As for the SPINOZA VU 2, we have used the NWR SRL layer to identify and retain the eligible events. In this case the access to the Predicate Matrix is not necessary as each predicate in the SRL layer is also as</context>
</contexts>
<marker>Segers, Vossen, Rospocher, Serafini, Laparra, Rigau, 2015</marker>
<rawString>Roxane Segers, Piek Vossen, Marco Rospocher, Luciano Serafini, Egoitz Laparra, and German Rigau. 2015. ESO: A Frame Based Ontology for Events and Implied Situations. In Proceedings of Maplex2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>James Allen</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2013 Task 1: TempEval-3: Evaluating time expressions, events, and temporal relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Seman- tic Evaluation,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="1565" citStr="UzZaman et al., 2013" startWordPosition="229" endWordPosition="232">extraction. 1 Introduction This paper reports on a system (SPINOZA VU) for timeline extraction developed at the CLTL Lab of the VU Amsterdam in the context of the SemEval 2015 Task 4: Cross Document TimeLines. In this task, a timeline is defined as a set of chronologically anchored and ordered events extracted from a corpus spanning over a (large) period of time with respect to a target entity. Cross-document timeline extraction benefits from previous works and evaluation campaigns in Temporal Processing, such as the TempEval evaluation campaigns (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013) and aims at promoting research in temporal processing by tackling the following issues: cross-document and cross-temporal event detection and ordering; event coreference (indocument and cross-document); and entity-based temporal processing. The SPINOZA VU system is based on the NewsReader (NWR) NLP pipeline (Agerri et al., 2013; Beloki et al., 2014), which has been developed within the context of the NWR project1 and provides multi-layer annotations over raw texts from tokenization up to temporal relations. The goal of the NWR project is to build structured event indexes from large volumes of</context>
</contexts>
<marker>UzZaman, Llorens, Allen, Derczynski, Verhagen, Pustejovsky, 2013</marker>
<rawString>Naushad UzZaman, Hector Llorens, James Allen, Leon Derczynski, Marc Verhagen, and James Pustejovsky. 2013. SemEval-2013 Task 1: TempEval-3: Evaluating time expressions, events, and temporal relations. In Proceedings of the 7th International Workshop on Seman- tic Evaluation, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 Task 15: TempEval Temporal Relation Identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluation,</booktitle>
<pages>75--80</pages>
<contexts>
<context position="1519" citStr="Verhagen et al., 2007" startWordPosition="221" endWordPosition="224">towards a more complex task such as storyline extraction. 1 Introduction This paper reports on a system (SPINOZA VU) for timeline extraction developed at the CLTL Lab of the VU Amsterdam in the context of the SemEval 2015 Task 4: Cross Document TimeLines. In this task, a timeline is defined as a set of chronologically anchored and ordered events extracted from a corpus spanning over a (large) period of time with respect to a target entity. Cross-document timeline extraction benefits from previous works and evaluation campaigns in Temporal Processing, such as the TempEval evaluation campaigns (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013) and aims at promoting research in temporal processing by tackling the following issues: cross-document and cross-temporal event detection and ordering; event coreference (indocument and cross-document); and entity-based temporal processing. The SPINOZA VU system is based on the NewsReader (NWR) NLP pipeline (Agerri et al., 2013; Beloki et al., 2014), which has been developed within the context of the NWR project1 and provides multi-layer annotations over raw texts from tokenization up to temporal relations. The goal of the NWR project is to build </context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval Temporal Relation Identification. In Proceedings of the 4th International Workshop on Semantic Evaluation, pages 75–80, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>57--62</pages>
<location>Uppsala,</location>
<contexts>
<context position="1542" citStr="Verhagen et al., 2010" startWordPosition="225" endWordPosition="228">task such as storyline extraction. 1 Introduction This paper reports on a system (SPINOZA VU) for timeline extraction developed at the CLTL Lab of the VU Amsterdam in the context of the SemEval 2015 Task 4: Cross Document TimeLines. In this task, a timeline is defined as a set of chronologically anchored and ordered events extracted from a corpus spanning over a (large) period of time with respect to a target entity. Cross-document timeline extraction benefits from previous works and evaluation campaigns in Temporal Processing, such as the TempEval evaluation campaigns (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013) and aims at promoting research in temporal processing by tackling the following issues: cross-document and cross-temporal event detection and ordering; event coreference (indocument and cross-document); and entity-based temporal processing. The SPINOZA VU system is based on the NewsReader (NWR) NLP pipeline (Agerri et al., 2013; Beloki et al., 2014), which has been developed within the context of the NWR project1 and provides multi-layer annotations over raw texts from tokenization up to temporal relations. The goal of the NWR project is to build structured event indexe</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57–62, Uppsala, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>