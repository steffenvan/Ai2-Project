<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993429">
Improving Syllabification Models with Phonotactic Knowledge
</title>
<author confidence="0.998565">
Karin M¨uller
</author>
<affiliation confidence="0.9986215">
Institute of Phonetic Sciences
University of Amsterdam
</affiliation>
<email confidence="0.995114">
kmueller@science.uva.nl
</email>
<sectionHeader confidence="0.999632" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998371875">
In language technology applications, unknown
words are a continuous problem. Especially, Text-
to-speech (TTS) systems like those described in
Sproat (1998) depend on the correct pronunciation
of those words. Most of these systems use large pro-
nunciation dictionaries to overcome this problem.
However, the lexicons are finite and every natural
language has productive word formation processes.
Thus, a TTS system needs a module which con-
verts letters to sounds and a second module which
syllabifies these sound sequences. The syllabifica-
tion information is important to assign the stress sta-
tus of the syllable, to calculate the phone duration
(Van Santen et al. (1997)), and to apply phonologi-
cal rules (Kahn (1976), Blevins (1995)). Many au-
tomatic syllabification methods have been suggested
e.g., (Daelemans and van den Bosch, 1992; Van den
Bosch, 1997; Kiraz and M¨obius, 1998; Vroomen
et al., 1998; M¨uller, 2001; Marchand et al., to ap-
pear 2006). M¨uller (2001) shows that incorporat-
ing syllable structure improves the prediction of syl-
lable boundaries. The syllabification accuracy in-
creases if the onset and coda is more fine-grained
(M¨uller, 2002). However, she only incorporates par-
tial phonotactic knowledge in her approach. For in-
stance, her models cannot express that the phoneme
/l/ is more likely to occur after an /s/ than after a
/t/ in English. The information that a phoneme is
very probable in a certain position (here, the /l/ ap-
pears as second consonant in a two-consonantal on-
set cluster) will not suffice to express English phono-
tactics of an entire consonant cluster. Moreover, she
</bodyText>
<sectionHeader confidence="0.666894" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999983935483871">
We report on a series of experiments
with probabilistic context-free grammars
predicting English and German syllable
structure. The treebank-trained grammars
are evaluated on a syllabification task. The
grammar used by M¨uller (2002) serves
as point of comparison. As she evalu-
ates the grammar only for German, we re-
implement the grammar and experiment
with additional phonotactic features. Us-
ing bi-grams within the syllable, we can
model the dependency from the previous
consonant in the onset and coda. A 10-
fold cross validation procedure shows that
syllabification can be improved by incor-
porating this type of phonotactic knowl-
edge. Compared to the grammar of M¨uller
(2002), syllable boundary accuracy in-
creases from 95.8% to 97.2% for En-
glish, and from 95.9% to 97.2% for Ger-
man. Moreover, our experiments with
different syllable structures point out that
there are dependencies between the on-
set on the nucleus for German but not
for English. The analysis of one of our
phonotactic grammars shows that inter-
esting phonotactic constraints are learned.
For instance, unvoiced consonants are the
most likely first consonants and liquids
and glides are preferred as second conso-
nants in two-consonantal onsets.
</bodyText>
<page confidence="0.992491">
11
</page>
<note confidence="0.8634675">
Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 11–20,
New York City, USA, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999884943396227">
only reports the performance of the German gram-
mar. Thus, we are interested if the detection of syl-
lable boundaries can be improved for both English
and German by adding further phonotactic knowl-
edge to a grammar.
Phonotactic constraints within the onset or coda
seem to be important for various tasks. Listeners in-
deed use phonotactic knowledge from their mother
language in various listening situations. Vitevitch
and Luce (1999), e.g., showed if English speak-
ers have to rate nonsense words how “English-like”
the stimuli are, highly probable phonotactic stimuli
were rated more “English-like” than stimuli with a
lower probability. Speakers make also use of their
phonotactic knowledge when they have to segment
a sequence into words. In a words spotting task,
Weber and Cutler (2006) found evidence that speak-
ers of American English can segment words much
easier when the sequence contains phonotactic con-
straints of their own language.
Beside many perception experiments which show
that phonotactic constraints are useful information,
many different methods have been suggested to
model phonotactic constraints for language tech-
nology applications. Krenn (1997), for instance,
uses Hidden Markov Models to tag syllable struc-
ture. The model decides whether a phoneme be-
longs to the onset, nucleus or coda. However, this
model does not incorporate fine-grained phonotac-
tics. Belz (2000) uses finite state automatons (FSA)
to model phonotactic structure of different sylla-
ble types. We use similar positional features of
syllables. Moreover, Carson-Berndsen (1998) and
Carson-Berndsen et al. (2004) focus on automat-
ically acquiring feature-based phonotactics by in-
duction of automata which can be used in speech
recognition. In our approach, we concentrate on
explicit phonotactic grammars as we want to test
different suggestions about the internal structure of
words from phonological approaches (e.g. Kessler
and Treiman (1997)). We assume, for instance, that
codas depend on the previous nucleus and that on-
sets depend on the subsequent nucleus.
In this paper, we present experiments on a series
of context-free grammars which integrate step by
step more phonological structure. The paper is or-
ganized as follows: we first introduce our grammar
development approach. In section 3, we describe our
experiments and the evaluation procedure. The sub-
sequent section 4 shows what kind of phonotactic in-
formation can be learned from a phonotactic gram-
mar. Last, we discuss our results and draw some
conclusions.
</bodyText>
<sectionHeader confidence="0.920365" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.998770578947368">
We build on the approach of M¨uller (2001) which
combines the advantages of treebank and brack-
eted corpora training. Her method consists of four
steps: (i) writing a (symbolic i.e. non-probabilistic)
context-free phonological grammar with syllable
boundaries, (ii) training this grammar on a pronunci-
ation dictionary which contains markers for syllable
boundaries (see Example 1; the pre-terminals “X[”
and “X]” denote the beginning and end of a sylla-
ble such that syllables like [strIN] can be unambigu-
ously processed during training), (iii) transforming
the resulting probabilistic phonological grammar by
dropping the syllable boundary markers1 (see Ex-
ample 2), and (iv) predicting syllable boundaries
of unseen phoneme strings by choosing their most
probable phonological tree according to the trans-
formed probabilistic grammar. The syllable bound-
aries can be extracted from the Syl node which gov-
erns a whole syllable.
</bodyText>
<listItem confidence="0.999678">
(1) Word , X[ Sylone ]X
(2) Word —* Sylone
</listItem>
<bodyText confidence="0.999725714285714">
We use a grammar development procedure to de-
scribe the phonological structure of words. We ex-
pect that a more fine-grained grammar increases the
precision of the prediction of syllable boundaries as
more phonotactic information can be learned. In the
following section, we describe the development of a
series of grammars.
</bodyText>
<subsectionHeader confidence="0.984302">
2.1 Grammar development
</subsectionHeader>
<bodyText confidence="0.988084555555555">
Our point of comparison is (i) the syllable com-
plexity grammar which was introduced by M¨uller
(2002). We develop four different grammars: (ii) the
phonotactic grammar, (iii) the phonotactic on-nuc
grammar (iv) the phonotactic nuc-coda grammar
and (v) the phonotactic on-nuc-coda grammar. All
five grammars share the following features: The
grammars describe a word which is composed of one
We also drop rules with zero probabilities
</bodyText>
<page confidence="0.997646">
12
</page>
<bodyText confidence="0.999978647058824">
to n syllables which in turn branch into onset and
rhyme. The rhyme is re-written by the nucleus and
the coda. Onset or coda could be empty. Further-
more, all grammar versions differentiate between
monosyllabic and polysyllabic words. In polysyl-
labic words, the syllables are divided into syllables
appearing word-initially, word-medially, and word-
finally. Additionally, the grammars distinguish be-
tween consonant clusters of different sizes (ranging
from one to five consonants).
We assume that phonotactic knowledge within
the onset and coda can help to solve a syllabifica-
tion task. Hence, we change the rules of the syl-
lable complexity grammar (M¨uller, 2002) such that
phonotactic dependencies are modeled. We express
the dependencies within the onset and coda as well
as the dependency from the nucleus by bi-grams.
</bodyText>
<subsectionHeader confidence="0.538526">
2.1.1 Grammar generation
</subsectionHeader>
<bodyText confidence="0.999688916666667">
The grammars are generated automatically (using
perl-scripts). As all possible phonemes in a language
are known, our grammar generates all possible re-
write rules. This generation process naturally over-
generates, which means that we receive rules which
will never occur in a language. There are, for in-
stance, rules which describe the impossible English
onset /tRS/. However, our training procedure and
our training data make sure that only those rules will
be chosen which occur in a certain language.
The monosyllabic English word string is used as
a running example to demonstrate the differences
of the grammar versions. The word string is tran-
scribed in the pronunciation dictionary CELEX as
([strIN]) (Baayen et al., 1993). The opening square
bracket, “[“, indicates the beginning of the syllable
and the closing bracket, “]”, the end of the syllable.
The word consists of the tri-consonantal onset [str]
followed by the nucleus, the short vowel [I] and the
coda [N].
In the following paragraphs, we will introduce the
different grammar versions. For comparison rea-
sons, we briefly describe the grammar of M¨uller
(2002) first.
</bodyText>
<subsectionHeader confidence="0.769393">
2.1.2 Syllable complexity grammar (M¨uller,
2002)
</subsectionHeader>
<bodyText confidence="0.999663666666667">
The syllable complexity grammar distinguishes
between onsets and codas which contain a differ-
ent number of consonants. There are different
rules which describe zero to n-consonantal onsets.
Tree (3) shows the complete analysis of the word
string.
</bodyText>
<listItem confidence="0.8729595">
(3) Word
Sylone
</listItem>
<equation confidence="0.99552975">
����� � � � � �
Onsetone
Onone.3.1
�� ��
s Onone.3.2
�� ��
t Onone.3.3
r
</equation>
<listItem confidence="0.8891715">
(4) Onone.3.1 — s Onone.3.2
(5) Onone.2.1 — s Onone.2.2
</listItem>
<bodyText confidence="0.950007571428571">
Rule 4, e.g., describes a tri-consonantal onset, e.g.,
[str]. This rule occurs in example tree 3 and will
be used for words such as string or spray. Rule (5)
describes a two-consonantal onset occurring in the
analysis of words such as snake or stand. However,
this grammar cannot model phonotactic dependen-
cies from the previous consonant.
</bodyText>
<subsectionHeader confidence="0.821074">
2.1.3 Phonotactic grammar
</subsectionHeader>
<bodyText confidence="0.99993475">
Thus, we develop a phonotactic grammar which
differs from the previous one. Now, a consonant in
the onset or coda depends on the preceding one. The
rules express bi-grams of the onset and coda conso-
nants. The main difference to the previous gram-
mars can be seen in the re-writing rules involving
phonemic preterminal nodes (rule 6) as well as ter-
minal nodes for consonants (rule 7).
</bodyText>
<listItem confidence="0.9996305">
(6) X.r.C.s.t — C X.r.C+.s.t
(7) X.r.C.s.t — C
</listItem>
<bodyText confidence="0.995929555555556">
Rules of this type bear four features for a conso-
nant C inside an onset or a coda (X=On, Cod),
namely: the position of the syllable in the word
(r=ini, med, fin, one), the current terminal node
(C = consonant), the succeeding consonant (C+),
the cluster size (t = 1... 5), and the position of a
consonant within a cluster (s = 1... 5).
The example tree (8) shows the analysis of the
word string with the current grammar version. The
</bodyText>
<figure confidence="0.919687857142857">
Rhymeone
�� � �
Nucleusone
I
N
Codaone.1
Coone.1.1
</figure>
<page confidence="0.873392">
13
</page>
<bodyText confidence="0.793113142857143">
words such as bring, king, ring or thing. If there is
a different nucleus, we get a different set of rules.
Rule 14, e.g., is required to analyze words such as
long, song, strong or gong.
rule (9) comes from the example tree showing that
the onset consonant [t] depends on the previous con-
sonant [s].
</bodyText>
<figure confidence="0.987591407407407">
(8) Word
Sylone
\
����� \ \ \ \
(13) Codaone.I.1 N Coone.t.1.1
(14) Codaone.O.1 �N Coone.t.1.1
(15) Word
Sylone
Codaone.1
Coone.t.1.1
N
Rhymeone
�� \ \
Nucleusone
I
Onsetone.3
Onone.s.3.1
�� \\
s Onone.t.3.2
�� \\
t Onone.r.3.3
\
����� \ \ \ \
r Onsetone.3 Rhymeone.I
Onone...3.1 ��� \
\\
(9) Onone.s.3.1 — s Onone.t.3.2
</figure>
<subsectionHeader confidence="0.51976">
2.1.4 Phonotactic on-nuc grammar
</subsectionHeader>
<bodyText confidence="0.999926363636364">
We also examine if there are dependencies of the
first onset consonant on the succeeding nucleus. The
dependency of the whole onset on the nucleus is
indirectly encoded by the bi-grams within the on-
set. The phonotactic onset-nucleus grammar distin-
guishes between same onsets with different nuclei.
In example tree (12), the triconsonantal onset start-
ing with a phoneme [s] depends on the Nucleus [I].
Rule (10) occurs in tree (12) and will be also used
for words such as strict or strip whereas rule (11) is
used for words such as strong or strop.
</bodyText>
<equation confidence="0.818425428571429">
(10) Onsetone.I.3 �Onone.s.3.1
(11) Onsetone.O.3 �Onone.s.3.1
(12) Word
Sylone.I
\
����� \ \ \ \
r
</equation>
<subsectionHeader confidence="0.881879">
2.1.5 Phonotactic nuc-coda grammar
</subsectionHeader>
<bodyText confidence="0.999961166666667">
The phonotactic nucleus-coda grammar encodes
the dependency of the first coda consonant on the
nucleus. The grammar distinguishes between codas
that occur with various nuclei. Rule 13 is used, for
instance, to analyze the word string, shown in Ex-
ample tree 15. The same rule will be applied for
</bodyText>
<equation confidence="0.9921062">
�� \\
s Onone.t.3.2
�� \\
t Onone.r.3.3
r
</equation>
<subsectionHeader confidence="0.871818">
2.1.6 Phonotactic on-nuc-coda grammar
</subsectionHeader>
<bodyText confidence="0.999971833333333">
The last tested grammar is the phonotactic onset-
nucleus-coda grammar. It is a combination of gram-
mar 2.1.4 and 2.1.5. In this grammar, the first con-
sonant of the onset and coda depend on the nucleus.
Tree 16 shows the full analysis of our running exam-
ple word string.
</bodyText>
<equation confidence="0.959133363636364">
(16) Word
Sylone.I
\
����� \ \ \ \
Onsetone.I.3
Onone.�.3.1
�� \\
s Onone.t.3.2
�� \\
t Onone.r.3.3
r
</equation>
<bodyText confidence="0.99914775">
The rules of the subtree (17) are the same for words
such as string or spring. However, words with a dif-
ferent nucleus such as strong will be analyzed with
a different set of rules.
</bodyText>
<figure confidence="0.714338178571429">
Onsetone.I.3
Onone...3.1
s Onone.t.3.2
�� \\
t Onone.r.3.3
Rhymeone.I
��� \
\\
Nucleusone.I
I
Codaone.1
Coone.N.1.1
N
Nucleusone.I Codaone.I.1
I Coone.N.1.1
N
Rhymeone.I
��� \
\\
Nucleusone.I
I
Codaone.I.1
Coone.N.1.1
N
14
(17) Word
Sylone.I
���� � � � �
</figure>
<sectionHeader confidence="0.989245" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999981866666667">
In this section, we report on our experiments with
four different phonotactic grammars introduced in
Section 2.1 (see grammar 2.1.3-2.1.6), as well as
with a re-implementation of Miller’s less complex
grammar (Miller, 2002). All these grammars are
trained on a corpus of transcribed words from the
pronunciation lexicon CELEX. We use the full forms
of the lexicon instead of the lemmas. The German
lexicon contains 304,928 words and the English lex-
icon 71,493 words. Homographs with the same pro-
nunciation but with different part of speech tags are
taken only once. We use for our German exper-
iments 274,435 words for training and 30,492 for
testing (evaluating). For our English experiments,
we use 64,343 for training and 7,249 for testing.
</bodyText>
<subsectionHeader confidence="0.999424">
3.1 Training procedure
</subsectionHeader>
<bodyText confidence="0.999735909090909">
We use the same training procedure as Miller
(2001). It is a kind of treebank training where we
obtain a probabilistic context-free grammar (PCFG)
by observing how often each rule was used in the
training corpus. The brackets of the input guaran-
tee an unambiguous analysis of each word. Thus,
the formula of treebank training given by (Charniak,
1996) is applied: r is a rule, let |r |be the number
of times r occurred in the parsed corpus and A(r) be
the non-terminal that r expands, then the probability
assigned to r is given by
</bodyText>
<equation confidence="0.581799">
Er/E{r&apos;jA(r&apos;)=a(r)} |rI|
</equation>
<bodyText confidence="0.9999207">
After training, we transform the PCFG by drop-
ping the brackets in the rules resulting in an anal-
ysis grammar. The bracket-less analysis grammar is
used for parsing the input without brackets; i.e., the
phoneme strings are parsed and the syllable bound-
aries are extracted from the most probable parse.
In our experiments, we use the same technique.
The advantage of this training method is that we
learn the distribution of the grammar which maxi-
mizes the likelihood of the corpus.
</bodyText>
<subsectionHeader confidence="0.999362">
3.2 Evaluation procedure
</subsectionHeader>
<bodyText confidence="0.999804222222222">
We evaluate our grammars on a syllabification task
which means that we use the trained grammars to
predict the syllable boundaries of an unseen corpus.
As we drop the explicit markers for syllable bound-
aries, the grammar can be used to predict the bound-
aries of arbitrary phoneme sequences. The bound-
aries can be extracted from the syl-span which gov-
erns an entire syllable.
Our training and evaluation procedure is a 10-fold
cross validation procedure. We divide the original
(German/English) corpus into ten parts equal in size.
We start the procedure by training on parts 1-9 and
evaluating on part 10. In a next step, we take parts
1-8 and 10 and evaluate on part 9. Then, we evaluate
on corpus 8 and so forth. In the end, this procedure
yields evaluation results for all 10 parts of the orig-
inal corpus. Finally, we calculate the average mean
of all evaluation results.
</bodyText>
<subsectionHeader confidence="0.460688">
3.2.1 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999941333333333">
Our three evaluation measures are word accuracy,
syllable accuracy and syllable boundary accuracy.
Word accuracy is a very strict measure and does not
depend on the number of syllables within a word. If
a word is correctly analyzed the accuracy increases.
We define word accuracy as
</bodyText>
<table confidence="0.2773374">
# of correctly analyzed words
total # of words
Syllable accuracy is defined as
# of correctly analyzed syllables
total # of syllables
</table>
<bodyText confidence="0.948761916666667">
The last evaluation metrics we used is the syllable
boundary accuracy. It expresses how reliable the
boundaries were recognized. It is defined as
# of correctly analyzed syllable boundaries
total # of syllable boundaries
The difference between the three metrics can
be seen in the following example. Let our
evaluation corpus consist of two words, transfer-
ring and wet. The transcription and the sylla-
ble boundaries are displayed in table 1. Let our
trained grammar predict the boundaries shown in
table 2. Then the word accuracy will be 50%
</bodyText>
<figure confidence="0.917804666666667">
Onsetone.I.3
Onone...3.1
Rhymeone.I
��� �
��
Nucleusone.I
I
Codaone.I.1
Coone.N.1.1
N
|r|
p(r) =
</figure>
<page confidence="0.656203">
15
</page>
<tableCaption confidence="0.681245333333333">
transferring trA:ns–f3:–rIN
wet wEt
Table 1: Example: evaluation corpus
transferring trA:n–sf3:–rIN
wet wEt
Table 2: Example: predicted boundaries
</tableCaption>
<figure confidence="0.893666833333333">
(1 correct word) the syllable accuracy will be 50%
2 words ,
(2 correct syllables), and the syllable boundary accu-
4 syllables
racy is 75% (3 correct syllable boundaries) The differ-
4 syllable boundaries
</figure>
<bodyText confidence="0.999055806451613">
ence between syllable accuracy and syllable bound-
ary accuracy is that the first metric punishes the
wrong prediction of a syllable boundary twice as
the complete syllable has to be correct. The syllable
boundary accuracy only judges the end of the sylla-
ble and counts how often it is correct. Mono-syllabic
words are also included in this measure. They serve
as a baseline as the syllable boundary will be always
correct. If we compare the baseline for English and
German (tables 3 and 4, respectively), we observe
that the English dictionary contains 10.3% monosyl-
labic words and the German one 1.59%.
Table 3 and table 4 show that phonotactic knowl-
edge improves the prediction of syllable bound-
aries. The syllable boundary accuracy increases
from 95.84% to 97.15% for English and from 95.9%
to 96.48% for German. One difference between the
two languages is if we encode the nucleus in the on-
set or coda rules, German can profit from this in-
formation compared to English. This might point at
a dependence of German onsets from the nucleus.
For English, it is even the case that the on-nuc and
the nuc-cod grammars worsen the results compared
to the phonotactic base grammar. Only the combi-
nation of the two grammars (the on-nuc-coda gram-
mar) achieves a higher accuracy than the phonotactic
grammar. We suspect that the on-nuc-coda grammar
encodes that onset and coda constrain each other on
the repetition of liquids or nasals between /s/C on-
sets and codas. For instance, lull and mam are okey,
whereas slull and smame are less good.
</bodyText>
<sectionHeader confidence="0.921038" genericHeader="method">
4 Learning phonotactics from PCFGs
</sectionHeader>
<bodyText confidence="0.997846">
We want to demonstrate in this section that our
phonotactic grammars does not only improve syl-
</bodyText>
<table confidence="0.980435">
grammar version word syllable syll bound.
accuracy accuracy accuracy
baseline 10.33%
(M¨uller, 2002) 89.27% 91.84% 95.84%
phonot. grammar 92.48% 94.35% 97.15%
phonot. on-nuc 92.29% 94.21% 97.09%
phonot. nuc-cod 92.39% 94.27% 97.11%
phonot. on-nuc-cod 92.64% 94.47% 97.22%
</table>
<tableCaption confidence="0.987066">
Table 3: Evaluation of four English grammar ver-
sions.
</tableCaption>
<table confidence="0.999463375">
grammar version word syllable syll bound.
accuracy accuracy accuracy
baseline 1.59%
(M¨uller, 2002) 86.06% 91.96% 95.90%
phonot. grammar 87.95% 93.09% 96.48%
phonot. nuc-cod 89.53% 94.09% 97.01%
phonot. on-nuc 89.97% 94.35% 97.15%
phonot. on-nuc-cod 90.45% 94.62% 97.29%
</table>
<tableCaption confidence="0.7988915">
Table 4: Evaluation of four German grammar ver-
sions.
</tableCaption>
<bodyText confidence="0.9998909">
labification accuracy but can be used to reveal in-
teresting phonotactic2 information at the same time.
Our intension is to show that it is possible to aug-
ment symbolic studies such as e.g., Hall (1992),
Pierrehumbert (1994), Wiese (1996), Kessler and
Treiman (1997), or Ewen and van der Hulst (2001)
with extensive probabilistic information. Due to
time and place constraints, we concentrate on two-
consonantal clusters of grammar 2.1.3.
Phonotactic restrictions are often expressed by ta-
bles which describe the possibility of combination
of consonants. Table 5 shows the possible combi-
nations of German two-consonantal onsets (Wiese,
1996). However, the table cannot express differ-
ences in frequency of occurrence between certain
clusters. For instance, it does not distinguish be-
tween onset clusters such as [pfl] and [kl]. If we con-
sider the frequency of occurrence in a German dic-
tionary then there is indeed a great difference. [kl] is
much more common than [pfl].
</bodyText>
<subsectionHeader confidence="0.970424">
4.1 German
</subsectionHeader>
<bodyText confidence="0.99998675">
Our method allows additional information to be
added to tables such as shown in table 5. In what
follows, the probabilities are taken from the rules
of grammar 2.1.3. Table 6 shows the probability of
</bodyText>
<footnote confidence="0.9582825">
2Note that we only deal with phonotactic phenomena on the
syllable level and not on the morpheme level.
</footnote>
<page confidence="0.985889">
16
</page>
<table confidence="0.999864846153846">
mono l R n m s v f t ts p k j z g
0.380 S 0.160 0.093 0.056 0.074 0.165 0.318 0.131
0.158 k 0.351 0.322 0.175 0.151
0.090 b 0.489 0.510
0.086 t 0.955 0.044
0.083 f 0.620 0.364 0.015
0.066 g 0.362 0.617 0.019
0.042 p 0.507 0.400 0.030 0.061
0.033 d 1.000
0.019 s 0.200 0.066 0.100 0.133 0.033 0.133 0.333
0.019 ts 1.000
0.011 pf 0.882 0.117
0.007 v 1.000
</table>
<tableCaption confidence="0.969133">
Table 6: German two-consonantal onsets in monosyllabic words - sorted by probability of occurrence
</tableCaption>
<table confidence="0.9997824375">
mono l r n m s v f t ts p k j z g w S d
0.322 s 0.157 0.001 0.099 0.060 0.001 0.004 0.223 0.150 0.174 0.006 0.120
0.148 k 0.375 0.390 0.003 0.003 0.030 0.196
0.093 b 0.420 0.574 0.004
0.083 f 0.591 0.333 0.075
0.079 p 0.480 0.457 0.056 0.005
0.072 g 0.283 0.709 0.006
0.068 t 0.686 0.039 0.274
0.048 d 0.822 0.112 0.065
0.035 h 0.089 0.910
0.018 T 0.857 0.047 0.095
0.014 S 0.878 0.030 0.030 0.060
0.004 m 1.000
0.003 n 1.000
0.002 l 1.000
0.002 v 1.000
</table>
<tableCaption confidence="0.987882">
Table 7: English two-consonantal onsets in monosyllabic words - sorted by probability of occurrence
</tableCaption>
<table confidence="0.802848">
Sonorants Obstruents
l R n m s v
Obstruents + + (+) - + -
p
</table>
<equation confidence="0.9987742">
t - + - - - (+)
k + + + (+) (+) +
b + + - - - -
d - + - - - -
g + + + (+) - -
f + + - - - -
v (+) + - - - +
ts - - - - -
pf + + - - - -
S + + + + - +
</equation>
<tableCaption confidence="0.850308">
Table 5: (Wiese, 1996) German onset clusters
</tableCaption>
<bodyText confidence="0.976818764705882">
occurrence of German obstruents ordered by their
probability of occurrence. [S] occurs very often in
German words as first consonant in two-consonantal
onsets word initially. In the first row of table 6,
the consonants which occur as second consonants
are listed. We observe, for instance, that [St] is
the most common two-consonantal onset in mono-
syllabic words. This consonant cluster appears in
words such as Staub (dust), stark (strong), or Stolz
(pride). We believe that there is a threshold indicat-
ing that a certain combination is very likely to come
from a loanword. If we define the probability of a
two-consonantal onset as
p(onset ini 2) =def p(C1) x p(C2)
where p(C1) is the probability of the rule
X.r.C1.s.t -* C1 X.r.C2.s.t
and p(C2) is the probability of the rule
</bodyText>
<equation confidence="0.707249">
X.r.C2.s.t -* C2,
</equation>
<bodyText confidence="0.9343925">
then we get a list of two-consonantal onsets ordered
by their probabilities:
</bodyText>
<equation confidence="0.956385">
p(St) &gt; ... &gt; p(sk) &gt; p(pfl) &gt; p(sl) &gt; ... &gt; p(sf)
</equation>
<bodyText confidence="0.999981733333333">
These onsets occur in words such as Steg (foot-
bridge), stolz (proud), Staat (state), Skalp (scalp),
Skat (skat) Pflicht (duty), Pflock (stake), or Slang
(slang) and Slum (slum). The least probable
combination is [sf] which appears in the German
word Sph¨are (sphere) coming from the Latin word
sphaera. The consonant cluster [sl] is also a very
uncommon onset. Words with this onset are usually
loanwords from English. The onset [sk], however, is
an onset which occur more often in German words.
Most of the words are originally from Latin and are
translated into German long ago. Interestingly, the
onset [pfl] is also a very uncommon onset. Most
of these onsets result from the second sound shift
where in certain positions the simple onset conso-
</bodyText>
<page confidence="0.997818">
17
</page>
<bodyText confidence="0.999962">
nant /p/ became the affricate /pf/. The English trans-
lation of these words shows that the second sound
shift was not applied to English. However, the most
probable two-consonantal onset is [St]. The whole
set of two-consonantal onsets can be seen in Table 8.
</bodyText>
<subsectionHeader confidence="0.982291">
4.2 English
</subsectionHeader>
<bodyText confidence="0.999895857142857">
English two-consonantal onsets show that unvoiced
first consonants are more common than voiced ones.
However, two combinations are missing. The alveo-
lar plosives /t/ and /d/ do not combine with the lateral
/l/ in English two-consonantal onsets. Table 8 shows
the most probable two-consonantal onsets sorted by
their joint probability.
</bodyText>
<subsectionHeader confidence="0.998685">
4.3 Comparison between English and German
</subsectionHeader>
<bodyText confidence="0.999858206896552">
The fricatives /s/ and /S/ are often regarded as extra
syllabic. According to our study on two-consonantal
onsets, these fricatives are very probable first con-
sonants and combine with more second consonants
than all other first consonants. They seem to form
an own class. Liquids and glides are the most impor-
tant second consonants. However, English prefers /r/
over /l/ in all syllable positions and /j/ over /w/ (ex-
cept in monosyllabic words) and /n/ as second con-
sonants. Nasals can only combine with very little
first consonants. In German, we observe that /R/ is
preferred over /l/ and /v/ over /n/ and /j/. Moreover,
the nasal /n/ is much more common in German than
in English as second consonants which applies espe-
cially to medial and final syllables.
When we compare the phonotactic restrictions of
two languages, it is also interesting to observe which
combinations are missing. If certain consonant clus-
ters are not very likely or never occur in a language,
this might have consequences for language under-
standing and language learning. Phonotactic gaps
in one language might cause spelling mistakes in a
second language. For instance, a typical Northern
German name is Detlef which is often misspelled in
English as Deltef. The onset cluster /tl/ can occur
in medial and final German syllables but not in En-
glish. The different phonetic realization of /l/ may
play a certain role that /lt/ is more natural than /tl/ in
English.
</bodyText>
<figure confidence="0.324890155555556">
Mono-syllabic: /st/ &gt; /kr/ &gt; /sk/ &gt; /kl/ &gt; /br/ &gt; /gr/ &gt; /sl/ &gt; /il/ &gt; /sp/ &gt; /tr/
&gt; /dr/ &gt; /bl/ &gt; /sw/ &gt; /pl/ &gt; /pr/ &gt; /sn/ &gt; /hw/ &gt; /kw/ &gt; /fr/ &gt; /gl/ &gt; /sm/ &gt;
/tw/ &gt; /Tr/ &gt; /Sr/ &gt; /fj/ &gt; /dj/ &gt; /kj/ &gt; /pj/ &gt; /mj/ &gt; /dw/ &gt; /hj/ &gt; /nj/ &gt; /tj/
&gt; /vj/ &gt; /lj/ &gt; /sj/ &gt; /Tw/ &gt; /sf/ &gt; /Tj/ &gt; /Sw/ &gt; /km/ &gt; /kv/ &gt; /gw/ &gt; /Sn/
&gt; /Sm/ &gt; /pS/ &gt; /bj/ &gt; /sr/ &gt; /sv/
Initial /pr/ &gt; /st/ &gt; /tr/ &gt; /kr/ &gt; /sp/ &gt; /sk/ &gt; /br/ &gt; /gr/ &gt; /il/ &gt; /kl/ &gt; /fr/ &gt;
/bl/ &gt; /pl/ &gt; /sl/ &gt; /kw/ &gt; /dr/ &gt; /sn/ &gt; /sw/ &gt; /gl/ &gt; /hw/ &gt; /nj/ &gt; /sm/ &gt; /sj/
&gt; /pj/ &gt; /Tr/ &gt; /mj/ &gt; /kj/ &gt; /dj/ &gt; /tw/ &gt; /tj/ &gt; /fj/ &gt; /hj/ &gt; /lj/ &gt; /bj/ &gt; /ps/
&gt; /Sr/ &gt; /dw/ &gt; /sf/ &gt; /vj/ &gt; /gj/ &gt; /gw/ &gt; /pw/ &gt; /mn/ &gt; /Sm/ &gt; /Tj/ &gt; /Tw/
&gt; /Sn/ &gt; /tsw/ &gt; /zj/ &gt; /pt/ &gt; /mw/ &gt; /kn/ &gt; /gz/
Medial: /st/ &gt; /tr/ &gt; /pr/ &gt; /sp/ &gt; /gr/ &gt; /kj/ &gt; /kr/ &gt; /kw/ &gt; /pl/ &gt; /br/ &gt; /tj/
&gt; /lj/ &gt; /dj/ &gt; /dr/ &gt; /kl/ &gt; /nj/ &gt; /sk/ &gt; /mj/ &gt; /fr/ &gt; /pj/ &gt; /bl/ &gt; /il/ &gt; /bj/
&gt; /gl/ &gt; /gj/ &gt; /fj/ &gt; /Sn/ &gt; /sj/ &gt; /vj/ &gt; /Sj/ &gt; /Tr/ &gt; /vr/ &gt; /gw/ &gt; /sl/ &gt;
/nr/ &gt; /sw/ &gt; /mr/ &gt; /sn/ &gt; /hj/ &gt; /hw/ &gt; /sm/ &gt; /zj/ &gt; /tSr/ &gt; /rj/ &gt; /sr/ &gt;
/dw/ &gt; /Zr/ &gt; /Sr/ &gt; /jw/ &gt; /tSw/ &gt; /tSn/ &gt; /vw/ &gt; /Dr/ &gt; /dZr/ &gt; /dn/ &gt; /Tj/
&gt; /tw/ &gt; /Sw/ &gt; /Zj/ &gt; /zr/ &gt; /zn/ &gt; /zw/ &gt; /Zw/ &gt; /dZj/ &gt; /dZn/ &gt; /dZw/
Final: /st/ &gt; /tr/ &gt; /kl/ &gt; /bl/ &gt; /gr/ &gt; /dr/ &gt; /pl/ &gt; /br/ &gt; /sk/ &gt; /sp/ &gt; /pr/
&gt; /kr/ &gt; /tj/ &gt; /fr/ &gt; /nj/ &gt; /il/ &gt; /lj/ &gt; /kw/ &gt; /dj/ &gt; /sj/ &gt; /kj/ &gt; /sl/ &gt; /gl/
&gt; /hw/ &gt; /Sn/ &gt; /vr/ &gt; /Sj/ &gt; /vj/ &gt; /bj/ &gt; /pj/ &gt; /fj/ &gt; /Tr/ &gt; /mj/ &gt; /gw/ &gt;
/sr/ &gt; /sw/ &gt; /sm/ &gt; /nr/ &gt; /sn/ &gt; /tSr/ &gt; /mr/ &gt; /tw/ &gt; /dZr/ &gt; /zj/ &gt; /gj/ &gt;
/dZj/ &gt; /Sr/ &gt; /Zr/ &gt; /sf/ &gt; /nw/ &gt; /zr/ &gt; /Tj/ &gt; /rj/ &gt; /Dr/ &gt; /vw/ &gt; /dw/ &gt;
/dn/ &gt; /tSj/ &gt; /pw/ &gt; /jw/ &gt; /hj/ &gt; /St/ &gt; /Zw/ &gt; /tSn/ &gt; /Zj/ &gt; /pn/ &gt; /Dj/ &gt;
/dZn/ &gt; /zn/ &gt; /Sw/ &gt; /Zn/ &gt; /tSw/ &gt; /Tw/ &gt; /bd/ &gt; /tsj/ &gt; /Dw/
Monosyllabic: /St/ &gt; /tR/ &gt; /Sv/ &gt; /Sl/ &gt; /kl/ &gt; /il/ &gt; /kR/ &gt; /Sp/ &gt; /bR/ &gt;
/bl/ &gt; /gR/ &gt; /SR/ &gt; /dR/ &gt; /fR/ &gt; /Sm/ &gt; /kn/ &gt; /gl/ &gt; /kv/ &gt; /pl/ &gt; /Sn/ &gt;
/tsv/ &gt; /pR/ &gt; /pil/ &gt; /vR/ &gt; /sk/ &gt; /sl/ &gt; /tv/ &gt; /ps/ &gt; /sp/ &gt; /sv/ &gt; /sm/ &gt;
/pfR/ &gt; /pn/ &gt; /gn/ &gt; /sn/ &gt; /fj/ &gt; /sf/
Initial: /St/ &gt; /tR/ &gt; /pR/ &gt; /Sp/ &gt; /kR/ &gt; /Sv/ &gt; /gR/ &gt; /Sl/ &gt; /fR/ &gt; /kl/ &gt;
/bR/ &gt; /bl/ &gt; /il/ &gt; /Sm/ &gt; /gl/ &gt; /tsv/ &gt; /pl/ &gt; /kv/ &gt; /kn/ &gt; /Sn/ &gt; /dR/ &gt;
/SR/ &gt; /sk/ &gt; /pil/ &gt; /ps/ &gt; /gn/ &gt; /sl/ &gt; /sm/ &gt; /sts/ &gt; /sf/ &gt; /sv/ &gt; /ks/ &gt;
/tv/ &gt; /vR/ &gt; /sn/ &gt; /mn/ &gt; /st/ &gt; /pn/ &gt; /sp/ &gt; /fj/ &gt; /pfR/ &gt; /mj/
Medial: /St/ &gt; /tR/ &gt; /bR/ &gt; /fR/ &gt; /Sl/ &gt; /gR/ &gt; /kR/ &gt; /bl/ &gt; /dR/ &gt; /Sp/
&gt; /kl/ &gt; /il/ &gt; /pR/ &gt; /gl/ &gt; /Sv/ &gt; /SR/ &gt; /st/ &gt; /pl/ &gt; /ks/ &gt; /kv/ &gt; /gn/ &gt;
/Sn/ &gt; /Sm/ &gt; /kn/ &gt; /tsv/ &gt; /pil/ &gt; /dl/ &gt; /dn/ &gt; /gm/ &gt; /sp/ &gt; /sn/ &gt; /fn/ &gt;
/bn/ &gt; /vj/ &gt; /xR/ &gt; /tn/ &gt; /sl/ &gt; /vR/ &gt; /sk/ &gt; /pj/ &gt; /ps/ &gt; /sts/ &gt; /xn/ &gt; /xl/
&gt; /ml/ &gt; /Rn/ &gt; /Nn/ &gt; /NR/ &gt; /zn/ &gt; /zl/ &gt; /mn/ &gt; /tl/ &gt; /sf/ &gt; /ln/ &gt; /tsR/
&gt; /tsl/ &gt; /sR/ &gt; /ft/ &gt; /zR/ &gt; /pfR/ &gt; /pt/ &gt; /nR/ &gt; /sg/ &gt; /pn/ &gt; /dm/ &gt; /tz/
&gt; /sv/ &gt; /zv/ &gt; /tv/
Final: /St/ &gt; /tR/ &gt; /bl/ &gt; /Sl/ &gt; /bR/ &gt; /il/ &gt; /kl/ &gt; /dR/ &gt; /gR/ &gt; /Sp/ &gt;
/kR/ &gt; /Sv/ &gt; /fR/ &gt; /SR/ &gt; /gl/ &gt; /ks/ &gt; /dl/ &gt; /pl/ &gt; /gn/ &gt; /pR/ &gt; /Sn/ &gt;
/Sm/ &gt; /kn/ &gt; /dn/ &gt; /kv/ &gt; /tsv/ &gt; /tl/ &gt; /ml/ &gt; /xl/ &gt; /tsl/ &gt; /gm/ &gt; /pil/ &gt;
/Nl/ &gt; /zl/ &gt; /tn/ &gt; /xR/ &gt; /vR/ &gt; /fn/ &gt; /bn/ &gt; /vj/ &gt; /zn/ &gt; /Nn/ &gt; /pn/ &gt;
/RR/ &gt; /mn/ &gt; /xn/ &gt; /zR/ &gt; /NR/ &gt; /lR/ &gt; /dZm/ &gt; /tsR/ &gt; /nl/ &gt; /gv/ &gt; /ps/
&gt; /ft/ &gt; /pfR/ &gt; /tZl/ &gt; /nR/ &gt; /sp/ &gt; /st/ &gt; /sv/ &gt; /sk/ &gt; /sR/ &gt; /sn/ &gt; /sl/ &gt;
/sm/ &gt; /sts/
</figure>
<tableCaption confidence="0.943885">
Table 8: Two-consonantal onsets ordered by joint
probability (top: English, bottom:German)
</tableCaption>
<page confidence="0.998681">
18
</page>
<sectionHeader confidence="0.999502" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999983176470588">
Comparison of the syllabification performance with
other systems is difficult: (i) different approaches
differ in their training and evaluation corpus;
(ii) comparisons across languages are hard to inter-
pret; (iii) comparisons across different approaches
require cautious interpretations. Nevertheless, we
want to refer to several approaches that examined
the syllabification task. Van den Bosch (1997) in-
vestigated the syllabification task with five induc-
tive learning algorithms. He reported a general-
ization error for words of 2.22% on English data.
However, the evaluation procedure differs from ours
as he evaluates each decision (after each phoneme)
made by his algorithms. Marchand et al. (to ap-
pear 2006) evaluated different syllabification algo-
rithms on three different pronunciation dictionaries.
Their best algorithm (SbA) achieved a word accu-
racy of 91.08%. The most direct point of compari-
son are the results presented by M¨uller (2002). Her
approach differs in two ways. First, she only eval-
uates the German grammar and second she trains
on a newspaper corpus. As we are interested in
how her grammars perform on our corpus, we re-
implemented her grammars and tested both in our
10-fold cross evaluation procedure. We find that the
first grammar (M¨uller, 2001) achieves 85.45% word
accuracy, 88.94% syllable accuracy and 94.37% syl-
lable boundary accuracy for English and 84.21%,
90.86%, 95.36% for German respectively. The re-
sults show that the syllable boundary accuracy in-
creases from 94,37% to 97.2% for English and from
95.3% to 97.2% for German. The experiments point
out that phonotactic knowledge is a valuable source
of information for syllabification.
</bodyText>
<sectionHeader confidence="0.999499" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999953388888889">
Phonotactic restrictions are important for language
perception and production. They influence the abil-
ity of children to segment words, and they help to
recognize words in nonsense sequences. In this
paper, we presented grammars which incorporate
phonotactic restrictions. The grammars were trained
and tested on a German and an English pronuncia-
tion dictionary. Our experiments show that English
and German profit from phonotactic knowledge to
predict syllable boundaries. We find evidence that
German codas depend on the nucleus which does
not apply for English. The English grammars which
model the dependency of part of the onset or coda
on the nucleus worsen the syllabification accuracy.
However, the combination of both show a better per-
formance than the base phonotactic grammar. This
suggests that there are constrains in the selection of
the onset and coda consonants.
</bodyText>
<sectionHeader confidence="0.99918" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999899428571428">
I would like to thank Paul Boersma who invited
me as a guest researcher at the Institute of Phonetic
Sciences of the University of Amsterdam. Special
thanks also to Detlef Prescher as well as to the three
anonymous reviewers, whose comments were very
useful while preparing the final version of this pa-
per.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998975">
Harald R. Baayen, Richard Piepenbrock, and H. van Rijn.
1993. The CELEX lexical database—Dutch, English,
German. (Release 1)[CD-ROM]. Philadelphia, PA:
Linguistic Data Consortium, Univ. Pennsylvania.
Anja Belz. 2000. Multi-syllable phonotactic mod-
elling. In Proceedings of SIGPHON 2000: Finite-
State Phonology, Luxembourg.
Juliette Blevins. 1995. The Syllable in Phonological
Theory. In John A. Goldsmith, editor, Handbook
of Phonological Theory, pages 206–244, Blackwell,
Cambridge MA.
Julie Carson-Berndsen, Robert Kelly, and Moritz Neuge-
bauer. 2004. Automatic Acquisition of Feature-Based
Phonotactic Resources. In Proceedings of the Work-
shop of the ACL Special Interest Group on Computa-
tional Phonology (SIGPHON), Barcelona, Spain.
Julie Carson-Berndsen. 1998. Time Map Phonology. Fi-
nite State Models and Event Logics in Speech Recog-
nition, volume 5 of Text, Speech and Language Tech-
nology. Springer.
Eugene Charniak. 1996. Tree-bank grammars. In Pro-
ceedings of the Thirteenth National Conference on Ar-
tificial Intelligence, AAAI Press/MIT Press, Menlo
Park.
Walter Daelemans and Antal van den Bosch. 1992. Gen-
eralization performance of backpropagation learning
on a syllabification task. In M.F.J. Drossaers and A Ni-
jholt, editors, Proceedings of TWLT3: Connectionism
and Natural Language Processing, pages 27–37, Uni-
versity of Twente.
</reference>
<page confidence="0.986234">
19
</page>
<reference confidence="0.996852803030303">
Colin J. Ewen and Harry van der Hulst. 2001.
The Phonological Structure of Words. An Introduc-
tion. Cambridge University Press, Cambridge, United
Kingdom.
Tracy Hall. 1992. Syllable structure and syllable related
processes in German. Niemeyer, T¨ubingen.
Daniel Kahn. 1976. Syllable-based Generalizations in
English Phonology. Ph.D. thesis, Massachusetts Insti-
tute of Technology, MIT.
Brett Kessler and Rebecca Treiman. 1997. Syllable
Structure and the Distribuation of Phonemes in En-
glish Syllables. Journal of Memory and Language,
37:295–311.
George Anton Kiraz and Bernd M¨obius. 1998. Mul-
tilingual Syllabification Using Weighted Finite-State
Transducers. In Proc. 3rd ESCA Workshop on Speech
Synthesis (Jenolan Caves), pages 59–64.
Brigitte Krenn. 1997. Tagging syllables. In Proceedings
of the 5th European Conference on Speech Commu-
nication and Technology, Eurospeech 97, pages 991–
994.
Yannick Marchand, Connie A. Adsett, and Robert I.
Damper. to appear 2006. Automatic syllabification in
English: A comparison of different algorithms. Lan-
guage and Speech.
Karin M¨uller. 2001. Automatic Detection of Syllable
Boundaries Combining the Advantages of Treebank
and Bracketed Corpora Training. In Proc. 39th Annual
Meeting of the ACL, Toulouse, France.
Karin M¨uller. 2002. Probabilistic Context-Free Gram-
mars for Phonology. In Proceedings of the Workshop
on Morphological and Phonological Learning at ACL
2002.
Janet Pierrehumbert. 1994. Syllable structure and word
structure: a study of triconsonantal clusters in English.
In Patricia A. Keating, editor, Phonological Structure
and Phonetic Form, volume III of Papers in Labo-
ratory Phonology, pages 168–188. University Press,
Cambridge.
Richard Sproat, editor. 1998. Multilingual Text-to-
Speech Synthesis: The Bell Labs Approach. Kluwer
Academic, Dordrecht.
Antal Van den Bosch. 1997. Learning to Pronounce
Written Words: A Study in Inductive Language Learn-
ing. Ph.D. thesis, Univ. Maastricht, Maastricht, The
Netherlands.
Jan P.H. Van Santen, Chilin Shih, Bernd M¨obius, Eve-
lyne Tzoukermann, and Michael Tanenblatt. 1997.
Multilingual duration modeling. In Proceedings of
the European Conference on Speech Communication
and Technology (Eurospeech), volume 5, pages 2651–
2654, Rhodos, Greece.
Michael S. Vitevitch and Paul A. Luce. 1999. Proba-
bilistic Phonotactics and Neighborhood Activation in
Spoken Word Recognition. Journal of Memory and
Language, (40):374–408.
Jean Vroomen, Antal van den Bosch, and Beatrice
de Gelder. 1998. A Connectionist Model for Boot-
strap Learning of Syllabic Structure. Language and
Cognitive Processes. Special issue on Language Ac-
quisition and Connectionism, 13(2/3):193–220.
Andrea Weber and Anne Cutler. 2006. First-language
phonotactics in second-language listening. Journal of
the Acoustical Society ofAmerica, 119(1):597–607.
Richard Wiese. 1996. The Phonology of German.
Clarendon Press, Oxford.
</reference>
<page confidence="0.994902">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.516872">
<title confidence="0.999796">Improving Syllabification Models with Phonotactic Knowledge</title>
<author confidence="0.988222">Karin</author>
<affiliation confidence="0.9986535">Institute of Phonetic University of</affiliation>
<intro confidence="0.524318">kmueller@science.uva.nl</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Harald R Baayen</author>
<author>Richard Piepenbrock</author>
<author>H van Rijn</author>
</authors>
<date>1993</date>
<booktitle>The CELEX lexical database—Dutch, English, German. (Release 1)[CD-ROM].</booktitle>
<institution>Linguistic Data Consortium, Univ. Pennsylvania.</institution>
<location>Philadelphia, PA:</location>
<marker>Baayen, Piepenbrock, van Rijn, 1993</marker>
<rawString>Harald R. Baayen, Richard Piepenbrock, and H. van Rijn. 1993. The CELEX lexical database—Dutch, English, German. (Release 1)[CD-ROM]. Philadelphia, PA: Linguistic Data Consortium, Univ. Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>Multi-syllable phonotactic modelling.</title>
<date>2000</date>
<booktitle>In Proceedings of SIGPHON 2000: FiniteState Phonology,</booktitle>
<location>Luxembourg.</location>
<contexts>
<context position="4601" citStr="Belz (2000)" startWordPosition="708" endWordPosition="709">er (2006) found evidence that speakers of American English can segment words much easier when the sequence contains phonotactic constraints of their own language. Beside many perception experiments which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on explicit phonotactic grammars as we want to test different suggestions about the internal structure of words from phonological approaches (e.g. Kessler and Treiman (1997)). We assume, for instance, that codas depend on the prev</context>
</contexts>
<marker>Belz, 2000</marker>
<rawString>Anja Belz. 2000. Multi-syllable phonotactic modelling. In Proceedings of SIGPHON 2000: FiniteState Phonology, Luxembourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juliette Blevins</author>
</authors>
<title>The Syllable in Phonological Theory. In</title>
<date>1995</date>
<booktitle>Handbook of Phonological Theory,</booktitle>
<pages>206--244</pages>
<editor>John A. Goldsmith, editor,</editor>
<location>Blackwell, Cambridge MA.</location>
<contexts>
<context position="899" citStr="Blevins (1995)" startWordPosition="129" endWordPosition="130">like those described in Sproat (1998) depend on the correct pronunciation of those words. Most of these systems use large pronunciation dictionaries to overcome this problem. However, the lexicons are finite and every natural language has productive word formation processes. Thus, a TTS system needs a module which converts letters to sounds and a second module which syllabifies these sound sequences. The syllabification information is important to assign the stress status of the syllable, to calculate the phone duration (Van Santen et al. (1997)), and to apply phonological rules (Kahn (1976), Blevins (1995)). Many automatic syllabification methods have been suggested e.g., (Daelemans and van den Bosch, 1992; Van den Bosch, 1997; Kiraz and M¨obius, 1998; Vroomen et al., 1998; M¨uller, 2001; Marchand et al., to appear 2006). M¨uller (2001) shows that incorporating syllable structure improves the prediction of syllable boundaries. The syllabification accuracy increases if the onset and coda is more fine-grained (M¨uller, 2002). However, she only incorporates partial phonotactic knowledge in her approach. For instance, her models cannot express that the phoneme /l/ is more likely to occur after an /</context>
</contexts>
<marker>Blevins, 1995</marker>
<rawString>Juliette Blevins. 1995. The Syllable in Phonological Theory. In John A. Goldsmith, editor, Handbook of Phonological Theory, pages 206–244, Blackwell, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Carson-Berndsen</author>
<author>Robert Kelly</author>
<author>Moritz Neugebauer</author>
</authors>
<title>Automatic Acquisition of Feature-Based Phonotactic Resources.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop of the ACL Special Interest Group on Computational Phonology (SIGPHON),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="4812" citStr="Carson-Berndsen et al. (2004)" startWordPosition="735" endWordPosition="738">ents which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on explicit phonotactic grammars as we want to test different suggestions about the internal structure of words from phonological approaches (e.g. Kessler and Treiman (1997)). We assume, for instance, that codas depend on the previous nucleus and that onsets depend on the subsequent nucleus. In this paper, we present experiments on a series of context-free grammars which integrate step by step more phonological structure. The paper is or</context>
</contexts>
<marker>Carson-Berndsen, Kelly, Neugebauer, 2004</marker>
<rawString>Julie Carson-Berndsen, Robert Kelly, and Moritz Neugebauer. 2004. Automatic Acquisition of Feature-Based Phonotactic Resources. In Proceedings of the Workshop of the ACL Special Interest Group on Computational Phonology (SIGPHON), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Carson-Berndsen</author>
</authors>
<title>Time Map Phonology. Finite State Models and Event Logics in Speech Recognition,</title>
<date>1998</date>
<booktitle>of Text, Speech and Language Technology.</booktitle>
<volume>5</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="4778" citStr="Carson-Berndsen (1998)" startWordPosition="732" endWordPosition="733">ide many perception experiments which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on explicit phonotactic grammars as we want to test different suggestions about the internal structure of words from phonological approaches (e.g. Kessler and Treiman (1997)). We assume, for instance, that codas depend on the previous nucleus and that onsets depend on the subsequent nucleus. In this paper, we present experiments on a series of context-free grammars which integrate step by step more phono</context>
</contexts>
<marker>Carson-Berndsen, 1998</marker>
<rawString>Julie Carson-Berndsen. 1998. Time Map Phonology. Finite State Models and Event Logics in Speech Recognition, volume 5 of Text, Speech and Language Technology. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Tree-bank grammars.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth National Conference on Artificial Intelligence, AAAI</booktitle>
<publisher>Press/MIT Press,</publisher>
<location>Menlo Park.</location>
<contexts>
<context position="14838" citStr="Charniak, 1996" startWordPosition="2382" endWordPosition="2383">ion but with different part of speech tags are taken only once. We use for our German experiments 274,435 words for training and 30,492 for testing (evaluating). For our English experiments, we use 64,343 for training and 7,249 for testing. 3.1 Training procedure We use the same training procedure as Miller (2001). It is a kind of treebank training where we obtain a probabilistic context-free grammar (PCFG) by observing how often each rule was used in the training corpus. The brackets of the input guarantee an unambiguous analysis of each word. Thus, the formula of treebank training given by (Charniak, 1996) is applied: r is a rule, let |r |be the number of times r occurred in the parsed corpus and A(r) be the non-terminal that r expands, then the probability assigned to r is given by Er/E{r&apos;jA(r&apos;)=a(r)} |rI| After training, we transform the PCFG by dropping the brackets in the rules resulting in an analysis grammar. The bracket-less analysis grammar is used for parsing the input without brackets; i.e., the phoneme strings are parsed and the syllable boundaries are extracted from the most probable parse. In our experiments, we use the same technique. The advantage of this training method is that </context>
</contexts>
<marker>Charniak, 1996</marker>
<rawString>Eugene Charniak. 1996. Tree-bank grammars. In Proceedings of the Thirteenth National Conference on Artificial Intelligence, AAAI Press/MIT Press, Menlo Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<title>Generalization performance of backpropagation learning on a syllabification task.</title>
<date>1992</date>
<booktitle>Proceedings of TWLT3: Connectionism and Natural Language Processing,</booktitle>
<pages>27--37</pages>
<editor>In M.F.J. Drossaers and A Nijholt, editors,</editor>
<institution>University of Twente.</institution>
<marker>Daelemans, van den Bosch, 1992</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 1992. Generalization performance of backpropagation learning on a syllabification task. In M.F.J. Drossaers and A Nijholt, editors, Proceedings of TWLT3: Connectionism and Natural Language Processing, pages 27–37, University of Twente.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin J Ewen</author>
<author>Harry van der Hulst</author>
</authors>
<title>The Phonological Structure of Words. An Introduction.</title>
<date>2001</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, United Kingdom.</location>
<marker>Ewen, van der Hulst, 2001</marker>
<rawString>Colin J. Ewen and Harry van der Hulst. 2001. The Phonological Structure of Words. An Introduction. Cambridge University Press, Cambridge, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy Hall</author>
</authors>
<title>Syllable structure and syllable related processes in German.</title>
<date>1992</date>
<location>Niemeyer, T¨ubingen.</location>
<contexts>
<context position="20373" citStr="Hall (1992)" startWordPosition="3291" endWordPosition="3292">on-nuc-cod 92.64% 94.47% 97.22% Table 3: Evaluation of four English grammar versions. grammar version word syllable syll bound. accuracy accuracy accuracy baseline 1.59% (M¨uller, 2002) 86.06% 91.96% 95.90% phonot. grammar 87.95% 93.09% 96.48% phonot. nuc-cod 89.53% 94.09% 97.01% phonot. on-nuc 89.97% 94.35% 97.15% phonot. on-nuc-cod 90.45% 94.62% 97.29% Table 4: Evaluation of four German grammar versions. labification accuracy but can be used to reveal interesting phonotactic2 information at the same time. Our intension is to show that it is possible to augment symbolic studies such as e.g., Hall (1992), Pierrehumbert (1994), Wiese (1996), Kessler and Treiman (1997), or Ewen and van der Hulst (2001) with extensive probabilistic information. Due to time and place constraints, we concentrate on twoconsonantal clusters of grammar 2.1.3. Phonotactic restrictions are often expressed by tables which describe the possibility of combination of consonants. Table 5 shows the possible combinations of German two-consonantal onsets (Wiese, 1996). However, the table cannot express differences in frequency of occurrence between certain clusters. For instance, it does not distinguish between onset clusters </context>
</contexts>
<marker>Hall, 1992</marker>
<rawString>Tracy Hall. 1992. Syllable structure and syllable related processes in German. Niemeyer, T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Kahn</author>
</authors>
<title>Syllable-based Generalizations in English Phonology.</title>
<date>1976</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology, MIT.</institution>
<contexts>
<context position="883" citStr="Kahn (1976)" startWordPosition="127" endWordPosition="128">TTS) systems like those described in Sproat (1998) depend on the correct pronunciation of those words. Most of these systems use large pronunciation dictionaries to overcome this problem. However, the lexicons are finite and every natural language has productive word formation processes. Thus, a TTS system needs a module which converts letters to sounds and a second module which syllabifies these sound sequences. The syllabification information is important to assign the stress status of the syllable, to calculate the phone duration (Van Santen et al. (1997)), and to apply phonological rules (Kahn (1976), Blevins (1995)). Many automatic syllabification methods have been suggested e.g., (Daelemans and van den Bosch, 1992; Van den Bosch, 1997; Kiraz and M¨obius, 1998; Vroomen et al., 1998; M¨uller, 2001; Marchand et al., to appear 2006). M¨uller (2001) shows that incorporating syllable structure improves the prediction of syllable boundaries. The syllabification accuracy increases if the onset and coda is more fine-grained (M¨uller, 2002). However, she only incorporates partial phonotactic knowledge in her approach. For instance, her models cannot express that the phoneme /l/ is more likely to </context>
</contexts>
<marker>Kahn, 1976</marker>
<rawString>Daniel Kahn. 1976. Syllable-based Generalizations in English Phonology. Ph.D. thesis, Massachusetts Institute of Technology, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brett Kessler</author>
<author>Rebecca Treiman</author>
</authors>
<date>1997</date>
<booktitle>Syllable Structure and the Distribuation of Phonemes in English Syllables. Journal of Memory and Language,</booktitle>
<pages>37--295</pages>
<contexts>
<context position="5144" citStr="Kessler and Treiman (1997)" startWordPosition="784" endWordPosition="787">da. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on explicit phonotactic grammars as we want to test different suggestions about the internal structure of words from phonological approaches (e.g. Kessler and Treiman (1997)). We assume, for instance, that codas depend on the previous nucleus and that onsets depend on the subsequent nucleus. In this paper, we present experiments on a series of context-free grammars which integrate step by step more phonological structure. The paper is organized as follows: we first introduce our grammar development approach. In section 3, we describe our experiments and the evaluation procedure. The subsequent section 4 shows what kind of phonotactic information can be learned from a phonotactic grammar. Last, we discuss our results and draw some conclusions. 2 Method We build on</context>
<context position="20437" citStr="Kessler and Treiman (1997)" startWordPosition="3297" endWordPosition="3300">on of four English grammar versions. grammar version word syllable syll bound. accuracy accuracy accuracy baseline 1.59% (M¨uller, 2002) 86.06% 91.96% 95.90% phonot. grammar 87.95% 93.09% 96.48% phonot. nuc-cod 89.53% 94.09% 97.01% phonot. on-nuc 89.97% 94.35% 97.15% phonot. on-nuc-cod 90.45% 94.62% 97.29% Table 4: Evaluation of four German grammar versions. labification accuracy but can be used to reveal interesting phonotactic2 information at the same time. Our intension is to show that it is possible to augment symbolic studies such as e.g., Hall (1992), Pierrehumbert (1994), Wiese (1996), Kessler and Treiman (1997), or Ewen and van der Hulst (2001) with extensive probabilistic information. Due to time and place constraints, we concentrate on twoconsonantal clusters of grammar 2.1.3. Phonotactic restrictions are often expressed by tables which describe the possibility of combination of consonants. Table 5 shows the possible combinations of German two-consonantal onsets (Wiese, 1996). However, the table cannot express differences in frequency of occurrence between certain clusters. For instance, it does not distinguish between onset clusters such as [pfl] and [kl]. If we consider the frequency of occurren</context>
</contexts>
<marker>Kessler, Treiman, 1997</marker>
<rawString>Brett Kessler and Rebecca Treiman. 1997. Syllable Structure and the Distribuation of Phonemes in English Syllables. Journal of Memory and Language, 37:295–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Anton Kiraz</author>
<author>Bernd M¨obius</author>
</authors>
<title>Multilingual Syllabification Using Weighted Finite-State Transducers.</title>
<date>1998</date>
<booktitle>In Proc. 3rd ESCA Workshop on Speech Synthesis (Jenolan Caves),</booktitle>
<pages>59--64</pages>
<marker>Kiraz, M¨obius, 1998</marker>
<rawString>George Anton Kiraz and Bernd M¨obius. 1998. Multilingual Syllabification Using Weighted Finite-State Transducers. In Proc. 3rd ESCA Workshop on Speech Synthesis (Jenolan Caves), pages 59–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
</authors>
<title>Tagging syllables.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th European Conference on Speech Communication and Technology, Eurospeech 97,</booktitle>
<pages>991--994</pages>
<contexts>
<context position="4378" citStr="Krenn (1997)" startWordPosition="672" endWordPosition="673">ic stimuli were rated more “English-like” than stimuli with a lower probability. Speakers make also use of their phonotactic knowledge when they have to segment a sequence into words. In a words spotting task, Weber and Cutler (2006) found evidence that speakers of American English can segment words much easier when the sequence contains phonotactic constraints of their own language. Beside many perception experiments which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on expl</context>
</contexts>
<marker>Krenn, 1997</marker>
<rawString>Brigitte Krenn. 1997. Tagging syllables. In Proceedings of the 5th European Conference on Speech Communication and Technology, Eurospeech 97, pages 991– 994.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yannick Marchand</author>
<author>Connie A Adsett</author>
<author>Robert I Damper</author>
</authors>
<title>to appear 2006. Automatic syllabification in English: A comparison of different algorithms. Language and Speech.</title>
<marker>Marchand, Adsett, Damper, </marker>
<rawString>Yannick Marchand, Connie A. Adsett, and Robert I. Damper. to appear 2006. Automatic syllabification in English: A comparison of different algorithms. Language and Speech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
</authors>
<title>Automatic Detection of Syllable Boundaries Combining the Advantages of Treebank and Bracketed Corpora Training.</title>
<date>2001</date>
<booktitle>In Proc. 39th Annual Meeting of the ACL,</booktitle>
<location>Toulouse, France.</location>
<marker>M¨uller, 2001</marker>
<rawString>Karin M¨uller. 2001. Automatic Detection of Syllable Boundaries Combining the Advantages of Treebank and Bracketed Corpora Training. In Proc. 39th Annual Meeting of the ACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
</authors>
<title>Probabilistic Context-Free Grammars for Phonology.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Morphological and Phonological Learning at ACL</booktitle>
<marker>M¨uller, 2002</marker>
<rawString>Karin M¨uller. 2002. Probabilistic Context-Free Grammars for Phonology. In Proceedings of the Workshop on Morphological and Phonological Learning at ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Pierrehumbert</author>
</authors>
<title>Syllable structure and word structure: a study of triconsonantal clusters</title>
<date>1994</date>
<booktitle>Phonological Structure and Phonetic Form, volume III of Papers in Laboratory Phonology,</booktitle>
<pages>168--188</pages>
<editor>in English. In Patricia A. Keating, editor,</editor>
<publisher>University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="20395" citStr="Pierrehumbert (1994)" startWordPosition="3293" endWordPosition="3294">.64% 94.47% 97.22% Table 3: Evaluation of four English grammar versions. grammar version word syllable syll bound. accuracy accuracy accuracy baseline 1.59% (M¨uller, 2002) 86.06% 91.96% 95.90% phonot. grammar 87.95% 93.09% 96.48% phonot. nuc-cod 89.53% 94.09% 97.01% phonot. on-nuc 89.97% 94.35% 97.15% phonot. on-nuc-cod 90.45% 94.62% 97.29% Table 4: Evaluation of four German grammar versions. labification accuracy but can be used to reveal interesting phonotactic2 information at the same time. Our intension is to show that it is possible to augment symbolic studies such as e.g., Hall (1992), Pierrehumbert (1994), Wiese (1996), Kessler and Treiman (1997), or Ewen and van der Hulst (2001) with extensive probabilistic information. Due to time and place constraints, we concentrate on twoconsonantal clusters of grammar 2.1.3. Phonotactic restrictions are often expressed by tables which describe the possibility of combination of consonants. Table 5 shows the possible combinations of German two-consonantal onsets (Wiese, 1996). However, the table cannot express differences in frequency of occurrence between certain clusters. For instance, it does not distinguish between onset clusters such as [pfl] and [kl]</context>
</contexts>
<marker>Pierrehumbert, 1994</marker>
<rawString>Janet Pierrehumbert. 1994. Syllable structure and word structure: a study of triconsonantal clusters in English. In Patricia A. Keating, editor, Phonological Structure and Phonetic Form, volume III of Papers in Laboratory Phonology, pages 168–188. University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<title>Multilingual Text-toSpeech Synthesis: The Bell Labs Approach.</title>
<date>1998</date>
<editor>Richard Sproat, editor.</editor>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="4778" citStr="(1998)" startWordPosition="733" endWordPosition="733">ion experiments which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (2000) uses finite state automatons (FSA) to model phonotactic structure of different syllable types. We use similar positional features of syllables. Moreover, Carson-Berndsen (1998) and Carson-Berndsen et al. (2004) focus on automatically acquiring feature-based phonotactics by induction of automata which can be used in speech recognition. In our approach, we concentrate on explicit phonotactic grammars as we want to test different suggestions about the internal structure of words from phonological approaches (e.g. Kessler and Treiman (1997)). We assume, for instance, that codas depend on the previous nucleus and that onsets depend on the subsequent nucleus. In this paper, we present experiments on a series of context-free grammars which integrate step by step more phono</context>
</contexts>
<marker>1998</marker>
<rawString>Richard Sproat, editor. 1998. Multilingual Text-toSpeech Synthesis: The Bell Labs Approach. Kluwer Academic, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal Van den Bosch</author>
</authors>
<title>Learning to Pronounce Written Words: A Study in Inductive Language Learning.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ.</institution>
<location>Maastricht, Maastricht, The Netherlands.</location>
<marker>Van den Bosch, 1997</marker>
<rawString>Antal Van den Bosch. 1997. Learning to Pronounce Written Words: A Study in Inductive Language Learning. Ph.D. thesis, Univ. Maastricht, Maastricht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan P H Van Santen</author>
<author>Chilin Shih</author>
<author>Bernd M¨obius</author>
<author>Evelyne Tzoukermann</author>
<author>Michael Tanenblatt</author>
</authors>
<title>Multilingual duration modeling.</title>
<date>1997</date>
<booktitle>In Proceedings of the European Conference on Speech Communication and Technology (Eurospeech),</booktitle>
<volume>5</volume>
<pages>2651--2654</pages>
<location>Rhodos, Greece.</location>
<marker>Van Santen, Shih, M¨obius, Tzoukermann, Tanenblatt, 1997</marker>
<rawString>Jan P.H. Van Santen, Chilin Shih, Bernd M¨obius, Evelyne Tzoukermann, and Michael Tanenblatt. 1997. Multilingual duration modeling. In Proceedings of the European Conference on Speech Communication and Technology (Eurospeech), volume 5, pages 2651– 2654, Rhodos, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael S Vitevitch</author>
<author>Paul A Luce</author>
</authors>
<title>Probabilistic Phonotactics and Neighborhood Activation in Spoken Word Recognition.</title>
<date>1999</date>
<journal>Journal of Memory and Language,</journal>
<pages>40--374</pages>
<contexts>
<context position="3642" citStr="Vitevitch and Luce (1999)" startWordPosition="561" endWordPosition="564">f the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 11–20, New York City, USA, June 2006. c�2006 Association for Computational Linguistics only reports the performance of the German grammar. Thus, we are interested if the detection of syllable boundaries can be improved for both English and German by adding further phonotactic knowledge to a grammar. Phonotactic constraints within the onset or coda seem to be important for various tasks. Listeners indeed use phonotactic knowledge from their mother language in various listening situations. Vitevitch and Luce (1999), e.g., showed if English speakers have to rate nonsense words how “English-like” the stimuli are, highly probable phonotactic stimuli were rated more “English-like” than stimuli with a lower probability. Speakers make also use of their phonotactic knowledge when they have to segment a sequence into words. In a words spotting task, Weber and Cutler (2006) found evidence that speakers of American English can segment words much easier when the sequence contains phonotactic constraints of their own language. Beside many perception experiments which show that phonotactic constraints are useful inf</context>
</contexts>
<marker>Vitevitch, Luce, 1999</marker>
<rawString>Michael S. Vitevitch and Paul A. Luce. 1999. Probabilistic Phonotactics and Neighborhood Activation in Spoken Word Recognition. Journal of Memory and Language, (40):374–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Vroomen</author>
<author>Antal van den Bosch</author>
<author>Beatrice de Gelder</author>
</authors>
<title>A Connectionist Model for Bootstrap Learning of Syllabic Structure. Language and Cognitive Processes. Special issue on Language Acquisition and Connectionism,</title>
<date>1998</date>
<pages>13--2</pages>
<marker>Vroomen, van den Bosch, de Gelder, 1998</marker>
<rawString>Jean Vroomen, Antal van den Bosch, and Beatrice de Gelder. 1998. A Connectionist Model for Bootstrap Learning of Syllabic Structure. Language and Cognitive Processes. Special issue on Language Acquisition and Connectionism, 13(2/3):193–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Weber</author>
<author>Anne Cutler</author>
</authors>
<title>First-language phonotactics in second-language listening.</title>
<date>2006</date>
<journal>Journal of the Acoustical Society ofAmerica,</journal>
<volume>119</volume>
<issue>1</issue>
<contexts>
<context position="3999" citStr="Weber and Cutler (2006)" startWordPosition="617" endWordPosition="620">ding further phonotactic knowledge to a grammar. Phonotactic constraints within the onset or coda seem to be important for various tasks. Listeners indeed use phonotactic knowledge from their mother language in various listening situations. Vitevitch and Luce (1999), e.g., showed if English speakers have to rate nonsense words how “English-like” the stimuli are, highly probable phonotactic stimuli were rated more “English-like” than stimuli with a lower probability. Speakers make also use of their phonotactic knowledge when they have to segment a sequence into words. In a words spotting task, Weber and Cutler (2006) found evidence that speakers of American English can segment words much easier when the sequence contains phonotactic constraints of their own language. Beside many perception experiments which show that phonotactic constraints are useful information, many different methods have been suggested to model phonotactic constraints for language technology applications. Krenn (1997), for instance, uses Hidden Markov Models to tag syllable structure. The model decides whether a phoneme belongs to the onset, nucleus or coda. However, this model does not incorporate fine-grained phonotactics. Belz (200</context>
</contexts>
<marker>Weber, Cutler, 2006</marker>
<rawString>Andrea Weber and Anne Cutler. 2006. First-language phonotactics in second-language listening. Journal of the Acoustical Society ofAmerica, 119(1):597–607.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Wiese</author>
</authors>
<title>The Phonology of German.</title>
<date>1996</date>
<publisher>Clarendon Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="20409" citStr="Wiese (1996)" startWordPosition="3295" endWordPosition="3296">le 3: Evaluation of four English grammar versions. grammar version word syllable syll bound. accuracy accuracy accuracy baseline 1.59% (M¨uller, 2002) 86.06% 91.96% 95.90% phonot. grammar 87.95% 93.09% 96.48% phonot. nuc-cod 89.53% 94.09% 97.01% phonot. on-nuc 89.97% 94.35% 97.15% phonot. on-nuc-cod 90.45% 94.62% 97.29% Table 4: Evaluation of four German grammar versions. labification accuracy but can be used to reveal interesting phonotactic2 information at the same time. Our intension is to show that it is possible to augment symbolic studies such as e.g., Hall (1992), Pierrehumbert (1994), Wiese (1996), Kessler and Treiman (1997), or Ewen and van der Hulst (2001) with extensive probabilistic information. Due to time and place constraints, we concentrate on twoconsonantal clusters of grammar 2.1.3. Phonotactic restrictions are often expressed by tables which describe the possibility of combination of consonants. Table 5 shows the possible combinations of German two-consonantal onsets (Wiese, 1996). However, the table cannot express differences in frequency of occurrence between certain clusters. For instance, it does not distinguish between onset clusters such as [pfl] and [kl]. If we consid</context>
<context position="22698" citStr="Wiese, 1996" startWordPosition="3756" endWordPosition="3757">574 0.004 0.083 f 0.591 0.333 0.075 0.079 p 0.480 0.457 0.056 0.005 0.072 g 0.283 0.709 0.006 0.068 t 0.686 0.039 0.274 0.048 d 0.822 0.112 0.065 0.035 h 0.089 0.910 0.018 T 0.857 0.047 0.095 0.014 S 0.878 0.030 0.030 0.060 0.004 m 1.000 0.003 n 1.000 0.002 l 1.000 0.002 v 1.000 Table 7: English two-consonantal onsets in monosyllabic words - sorted by probability of occurrence Sonorants Obstruents l R n m s v Obstruents + + (+) - + - p t - + - - - (+) k + + + (+) (+) + b + + - - - - d - + - - - - g + + + (+) - - f + + - - - - v (+) + - - - + ts - - - - - pf + + - - - - S + + + + - + Table 5: (Wiese, 1996) German onset clusters occurrence of German obstruents ordered by their probability of occurrence. [S] occurs very often in German words as first consonant in two-consonantal onsets word initially. In the first row of table 6, the consonants which occur as second consonants are listed. We observe, for instance, that [St] is the most common two-consonantal onset in monosyllabic words. This consonant cluster appears in words such as Staub (dust), stark (strong), or Stolz (pride). We believe that there is a threshold indicating that a certain combination is very likely to come from a loanword. If</context>
</contexts>
<marker>Wiese, 1996</marker>
<rawString>Richard Wiese. 1996. The Phonology of German. Clarendon Press, Oxford.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>