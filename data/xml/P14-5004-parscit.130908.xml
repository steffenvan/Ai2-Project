<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012988">
<title confidence="0.4647125">
Community Evaluation and Exchange of Word Vectors
atwordvectors.org
</title>
<author confidence="0.901972">
Manaal Faruqui and Chris Dyer
</author>
<affiliation confidence="0.721908">
Carnegie Mellon University
Pittsburgh, PA, 15213, USA
</affiliation>
<email confidence="0.998439">
{mfaruqui, cdyer}@cs.cmu.edu
</email>
<sectionHeader confidence="0.997371" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9938141875">
Vector space word representations are use-
ful for many natural language process-
ing applications. The diversity of tech-
niques for computing vector representa-
tions and the large number of evaluation
benchmarks makes reliable comparison a
tedious task both for researchers devel-
oping new vector space models and for
those wishing to use them. We present
a website and suite of offline tools that
that facilitate evaluation of word vectors
on standard lexical semantics benchmarks
and permit exchange and archival by users
who wish to find good vectors for their
applications. The system is accessible at:
www.wordvectors.org.
</bodyText>
<sectionHeader confidence="0.999483" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999743806451613">
Data-driven learning of vector-space word embed-
dings that capture lexico-semantic properties is
a technique of central importance in natural lan-
guage processing. Using co-occurrence statistics
from a large corpus of text (Deerwester et al.,
1990; Turney and Pantel, 2010), it is possible
to construct high-quality semantic vectors — as
judged by both correlations with human judge-
ments of semantic relatedness (Turney, 2006;
Agirre et al., 2009) and as features for down-
stream applications (Turian et al., 2010). A num-
ber of approaches that use the internal representa-
tions from models of word sequences (Collobert
and Weston, 2008) or continuous bags-of-context
wordsets (Mikolov et al., 2013) to arrive at vector
representations have also been shown to likewise
capture co-occurrence tendencies and meanings.
With an overwhelming number of techniques
to obtain word vector representations the task of
comparison and choosing the vectors best suitable
for a particular task becomes difficult. This is
further aggravated by the large number of exist-
ing lexical semantics evaluation benchmarks be-
ing constructed by the research community. For
example, to the best of our knowledge, for evaluat-
ing word similarity between a given pair of words,
there are currently at least 10 existing bench-
marks1 that are being used by researchers to prove
the effectiveness of their word vectors.
In this paper we describe an online application
that provides the following utilities:
</bodyText>
<listItem confidence="0.9958487">
• Access to a suite of word similarity evalua-
tion benchmarks
• Evaluation of user computed word vectors
• Visualizing word vectors in R2
• Evaluation and comparison of the available
open-source vectors on the suite
• Submission of user vectors for exhaustive of-
fline evaluation and leader board ranking
• Publicly available repository of word vectors
with performance details
</listItem>
<bodyText confidence="0.935927909090909">
Availability of such an evaluation system will
help in enabling better consistency and uniformity
in evaluation of word vector representations as
well as provide an easy to use interface for end-
users in a similar spirit to Socher et al. (2013a),
a website for text classification.2 Apart from the
online demo version, we also provide a software
that can be run in an offline mode on the command
line. Both the online and offline tools will be kept
updated with continuous addition of new relevant
tasks and vectors.
</bodyText>
<footnote confidence="0.999976">
1www.wordvectors.org/suite.php
2www.etcml.com
</footnote>
<page confidence="0.994309">
19
</page>
<affiliation confidence="0.4356045">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 19–24,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
</affiliation>
<sectionHeader confidence="0.874424" genericHeader="method">
2 Word Similarity Benchmarks
</sectionHeader>
<bodyText confidence="0.999947128205128">
We evaluate our word representations on 10 dif-
ferent benchmarks that have been widely used to
measure word similarity. The first one is the WS-
3533 dataset (Finkelstein et al., 2001) containing
353 pairs of English words that have been assigned
similarity ratings by humans. This data was fur-
ther divided into two fragments by Agirre et al.
(2009) who claimed that similarity (WS-SIM) and
relatedness (WS-REL)4 are two different kinds
of relations and should be dealt with separately.
The fourth and fifth benchmarks are the RG-65
(Rubenstein and Goodenough, 1965) and the MC-
30 (Miller and Charles, 1991) datasets that contain
65 and 30 pairs of nouns respectively and have
been given similarity rankings by humans. These
differ from WS-353 in that it contains only nouns
whereas the former contains all kinds of words.
The sixth benchmark is the MTurk-2875
(Radinsky et al., 2011) dataset that constitutes 287
pairs of words and is different from the previ-
ous benchmarks in that it has been constructed
by crowdsourcing the human similarity ratings
using Amazon Mechanical Turk (AMT). Simi-
lar in spirit is the MTruk-7716 (Halawi et al.,
2012) dataset that contains 771 word pairs whose
similarity was crowdsourced from AMT. An-
other, AMT created dataset is the MEN7 bench-
mark (Bruni et al., 2012) that consists of 3000
word pairs, randomly selected from words that
occur at least 700 times in the freely available
ukWaC and Wackypedia8 corpora combined.
The next two benchmarks were created to put
emphasis on different kinds of word types. To
specifically emphasize on verbs, Yang and Pow-
ers (2006) created a new benchmark YP-130 of
130 verb pairs with human similarity judgements.
Since, most of the earlier discussed datasets con-
tain word pairs that are relatively more frequent in
a corpus, Luong et al. (2013) create a new bench-
</bodyText>
<footnote confidence="0.988445416666667">
3http://www.cs.technion.ac.il/˜gabr/
resources/data/wordsim353/
4http://alfonseca.org/eng/research/
wordsim353.html
5http://tx.technion.ac.il/˜kirar/
Datasets.html
6http://www2.mta.ac.il/˜gideon/
mturk771.html
7http://clic.cimec.unitn.it/˜elia.
bruni/MEN.html
8http://wacky.sslmit.unibo.it/doku.
php?id=corpora
</footnote>
<bodyText confidence="0.9986606875">
mark (Rare-Word)9 that contains rare-words by
sampling words from different frequency bins to a
total of 2034 word pairs.
We calculate similarity between a given pair
of words by the cosine similarity between their
corresponding vector representation. We then re-
port Spearman’s rank correlation coefficient (My-
ers and Well, 1995) between the rankings pro-
duced by our model against the human rankings.
Multilingual Benchmarks. As is the case with
most NLP problems, the lexical semantics evalua-
tion benchmarks for languages other than English
have been limited. Currently, we provide a link
to some of these evaluation benchmarks from our
website and in future will expand the website to
encompass vector evaluation for other languages.
</bodyText>
<sectionHeader confidence="0.99783" genericHeader="method">
3 Visualization
</sectionHeader>
<bodyText confidence="0.999953142857143">
The existing benchmarks provide ways of vector
evaluation in a quantitative setting. To get an idea
of what kind of information the vectors encode it is
important to see how these vectors represent words
in n-dimensional space, where n is the length
of the vector. Visualization of high-dimensional
data is an important problem in many different do-
mains, and deals with data of widely varying di-
mensionality. Over the last few decades, a variety
of techniques for the visualization of such high-
dimensional data have been proposed (de Oliveira
and Levkowitz, 2003).
Since visualization in n dimensions is hard
when n &gt;= 3, we use the t-SNE (van der Maaten
and Hinton, 2008) tool10 to project our vectors into
R2. t-SNE converts high dimensional data set into
a matrix of pairwise similarities between individ-
ual elements and then provides a way to visual-
ize these distances in a way which is capable of
capturing much of the local structure of the high-
dimensional data very well, while also revealing
global structure such as the presence of clusters at
several scales.
In the demo system, we give the user an option
to input words that they need to visualize which
are fed to the t-SNE tool and the produced images
are shown to the user on the webpage. These im-
ages can then be downloaded and used. We have
</bodyText>
<footnote confidence="0.99178275">
9http://www-nlp.stanford.edu/˜lmthang/
morphoNLM/
10http://homepage.tudelft.nl/19j49/
t-SNE_files/tsne_python.zip
</footnote>
<page confidence="0.983551">
20
</page>
<figureCaption confidence="0.883221">
Figure 1: Antonyms (red) and synonyms (green) of beautiful represented by Faruqui and Dyer (2014)
(left) and Huang et al. (2012) (right).
</figureCaption>
<bodyText confidence="0.998656">
included two datasets by default which exhibit dif-
ferent properties of the language:
</bodyText>
<listItem confidence="0.9999845">
• Antonyms and synonyms of beautiful
• Common male-female nouns and pronouns
</listItem>
<bodyText confidence="0.999958230769231">
In the first plot, ideally the antonyms (ugly,
hideous, ...) and synonyms (pretty, gorgeous,
... ) of beautiful should form two separate clus-
ters in the plot. Figure 1 shows the plots of the
antonyms and synonyms of the word beautiful for
two available embeddings. The second default
word plot is the gender data set, every word in
which has a male and a female counterpart (ex.
grandmother and grandfather), this data set ex-
hibits both local and global properties. Locally,
the male and female counterparts should occur in
pairs together and globally there should be two
separate clusters of male and female.
</bodyText>
<sectionHeader confidence="0.989623" genericHeader="method">
4 Word Vector Representations
</sectionHeader>
<subsectionHeader confidence="0.955657">
4.1 Pre-trained Vectors
</subsectionHeader>
<bodyText confidence="0.999942736842105">
We haves collected several standard pre-trained
word vector representations freely available for re-
search purposes and provide a utility for the user
to test them on the suite of benchmarks, as well
as try out the visualization functionality. The user
can also choose the option to choose two different
types of word vectors and compare their perfor-
mance on the benchmarks. We will keep adding
word vectors on the website as and when they are
released. The following word vectors have been
included in our collection:
Metaoptimize. These word embeddings 11 have
been trained in (Turian et al., 2010) using a neu-
ral network language model and were shown to
be useful for named entity recognition (NER) and
phrase chunking.
SENNA. It is a software12 which outputs a host
of predictions: part-of-speech (POS) tags, chunk-
ing, NER etc (Collobert et al., 2011). The soft-
ware uses neural word embeddings trained over
Wikipedia data for over 2 months.
RNNLM. The recurrent neural network lan-
guage modeling toolkit13 comes with some
pre-trained embeddings on broadcast news
data (Mikolov et al., 2011).
Global Context. Huang et al. (2012) present a
model to incorporate document level information
into embeddings to generate semantically more in-
formed word vector representations. These em-
beddings14 capture both local and global context
of the words.
Skip-Gram. This model is a neural network lan-
guage model except for that it does not have a
hidden layer and instead of predicting the target
word, it predicts the context given the target word
(Mikolov et al., 2013). These embeddings are
much faster to train15 than the other neural em-
beddings.
</bodyText>
<footnote confidence="0.968672714285714">
11http://metaoptimize.com/projects/
wordreprs/
12http://ronan.collobert.com/senna/
13http://rnnlm.org/
14http://nlp.stanford.edu/˜socherr/
ACL2012_wordVectorsTextFile.zip
15https://code.google.com/p/word2vec/
</footnote>
<page confidence="0.998367">
21
</page>
<figureCaption confidence="0.999621">
Figure 2: Vector selection interface (right) of the demo system.
</figureCaption>
<bodyText confidence="0.999559571428572">
Multilingual. Faruqui and Dyer (2014) propose
a method based on canonical correlation analy-
sis to produce more informed monolingual vec-
tors using multilingual knowledge. Their method
is shown to perform well for both neural embed-
dings and LSA (Deerwester et al., 1990) based
vectors.16
</bodyText>
<subsectionHeader confidence="0.923312">
4.2 User-created Vectors
</subsectionHeader>
<bodyText confidence="0.999977">
Our demo system provides the user an option to
upload their word vectors to perform evaluation
and visualization. However, since the size of the
word vector file will be huge due to a lot of in-
frequent words that are not useful for evaluation,
we give an option to filter the word vectors file
to only include the words required for evaluation.
The script and the vocabulary file can be found on
the website online.
</bodyText>
<sectionHeader confidence="0.998269" genericHeader="method">
5 Offline Evaluation &amp; Public Access
</sectionHeader>
<bodyText confidence="0.9999276">
We provide an online portal where researchers can
upload their vectors which are then be evaluated
on a variety of NLP tasks and then placed on the
leader board.17 The motivation behind creating
such a portal is to make it easier for a user to se-
lect the kind of vector representation that is most
suitable for their task. In this scenario, instead of
asking the uploader to filter their word vectors for
a small vocabulary, they will be requested to up-
load their vectors for the entire vocabulary.
</bodyText>
<footnote confidence="0.942601333333333">
16http://cs.cmu.edu/˜mfaruqui/soft.html
17We provide an initial list of some such tasks to which we
will later add more tasks as they are developed.
</footnote>
<subsectionHeader confidence="0.846905">
5.1 Offline Evaluation
</subsectionHeader>
<bodyText confidence="0.99995303125">
Syntactic &amp; semantic relations. Mikolov et al.
(2013) present a new semantic and syntactic re-
lation dataset composed of analogous word pairs
of size 8869 and 10675 pairs resp.. It contains
pairs of tuples of word relations that follow a com-
mon relation. For example, in England : Lon-
don :: France : Paris, the two given pairs of words
follow the country-capital relation. We use the
vector offset method (Mikolov et al., 2013) to
compute the missing word in these relations. This
is non-trivial V-way classification task where V
is the size of the vocabulary.
Sentence Completion. The Microsoft Research
sentence completion dataset contains 1040 sen-
tences from each of which one word has been re-
moved. The task is to correctly predict the miss-
ing word from a given list of 5 other words per
sentence. We average the word vectors of a given
sentence qsent = ENi=1,i�j qwi/N, where wj is
the missing word and compute the cosine similar-
ity of qsent vector with each of the options. The
word with the highest similarity is chosen as the
missing word placeholder.
Sentiment Analysis Socher et al. (2013b) have
created a treebank which contains sentences an-
notated with fine-grained sentiment labels on both
the phrase and sentence level. They show that
compositional vector space models can be used
to predict sentiment at these levels with high ac-
curacy. The coarse-grained treebank, containing
only positive and negative classes has been split
into training, development and test datasets con-
</bodyText>
<page confidence="0.998582">
22
</page>
<figureCaption confidence="0.999835">
Figure 3: Screenshot of the command line version showing word similarity evaluation.
</figureCaption>
<bodyText confidence="0.9999305">
taining 6920, 872 and 1821 sentences respectively.
We train a logistic regression classifier with L2
regularization on the average of the word vectors
of a given sentence to predict the coarse-grained
sentiment tag at the sentence level.
TOEFL Synonyms. These are a set of 80 ques-
tions compiled by Landauer and Dutnais (1997),
where a given word needs to be matched to its
closest synonym from 4 given options. A num-
ber of systems have reported their results on this
dataset.18 We use cosine similarity to identify the
closest synonym.
</bodyText>
<subsectionHeader confidence="0.995801">
5.2 Offline Software
</subsectionHeader>
<bodyText confidence="0.999969363636364">
Along with the web demo system we are making
available a software which can be downloaded and
be used for evaluation of vector representations of-
fline on all the benchmarks listed above. Since, we
cannot distribute the evaluation benchmarks along
with the software because of licensing issues, we
would give links to the resources which should be
downloaded prior to using the software. This soft-
ware can be run on a command line interface. Fig-
ure 3 shows a screenshot of word similarity evalu-
ation using the software.
</bodyText>
<subsectionHeader confidence="0.998288">
5.3 Public Access
</subsectionHeader>
<bodyText confidence="0.999959111111111">
Usually corpora that the vectors are trained upon
are not available freely because of licensing issues
but it is easier to release the vectors that have been
trained on them. In the system that we have devel-
oped, we give the user an option to either make the
vectors freely available for everyone to use under a
GNU General Public License19 or a Creative Com-
mons License.20 If the user chooses not to make
the word vectors available, we would evaluate the
</bodyText>
<footnote confidence="0.9880465">
18http://aclweb.org/aclwiki/index.php?
title=TOEFL_Synonym_Questions_(State_of_
the_art)
19https://www.gnu.org/copyleft/gpl.html
20https://creativecommons.org/licenses/
by-nc-sa/4.0/legalcode
</footnote>
<bodyText confidence="0.9955475">
vectors and give it a position in the leader board
with proper citation to the publications/softwares.
</bodyText>
<sectionHeader confidence="0.995513" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998623846153846">
In this paper we have presented a demo system that
supports rapid and consistent evaluation of word
vector representations on a variety of tasks, visual-
ization with an easy-to-use web interface and ex-
change and comparison of different word vector
representations. The system also provides access
to a suite of evaluation benchmarks both for En-
glish and other languages. The functionalities of
the system are aimed at: (1) Being a portal for
systematic evaluation of lexical semantics tasks
that heavily rely on word vector representation, (2)
Making it easier for an end-user to choose the most
suitable vector representation schema.
</bodyText>
<sectionHeader confidence="0.982706" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997724">
We thank members of Noah’s Ark and c-lab for
their helpful comments about the demo system.
Thanks to Devashish Thakur for his help in set-
ting up the website. This work was supported by
the NSF through grant IIS-1352440.
</bodyText>
<sectionHeader confidence="0.998908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9874336">
Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana
Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009.
A study on similarity and relatedness using distribu-
tional and wordnet-based approaches. In Proceed-
ings of NAACL, NAACL ’09, pages 19–27, Strouds-
burg, PA, USA.
Elia Bruni, Gemma Boleda, Marco Baroni, and
Nam Khanh Tran. 2012. Distributional semantics
in technicolor. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 136–145,
Jeju Island, Korea, July. Association for Computa-
tional Linguistics.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: deep
</reference>
<page confidence="0.989894">
23
</page>
<reference confidence="0.997824504854369">
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning, ICML ’08, pages 160–167, New
York, NY, USA. ACM.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. J. Mach. Learn. Res., 12:2493–2537,
November.
Maria Cristina Ferreira de Oliveira and Haim Lev-
kowitz. 2003. From visual data exploration to vi-
sual data mining: A survey. IEEE Trans. Vis. Com-
put. Graph., 9(3):378–394.
S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W.
Furnas, and R. A. Harshman. 1990. Indexing by
latent semantic analysis. Journal of the American
Society for Information Science.
Manaal Faruqui and Chris Dyer. 2014. Improving
vector space word representations using multilingual
correlation. In Proceedings of the 14th Conference
of the European Chapter of the Association for Com-
putational Linguistics, Gothenburg, Sweden, April.
Association for Computational Linguistics.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. 2001. Placing search in context: the
concept revisited. In WWW ’01: Proceedings of the
10th international conference on World Wide Web,
pages 406–414, New York, NY, USA. ACM Press.
Guy Halawi, Gideon Dror, Evgeniy Gabrilovich, and
Yehuda Koren. 2012. Large-scale learning of word
relatedness with constraints. In KDD, pages 1406–
1414.
Eric H Huang, Richard Socher, Christopher D Man-
ning, and Andrew Y Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of the 50th ACL: Long
Papers-Volume 1, pages 873–882.
Thomas K Landauer and Susan T. Dutnais. 1997. A
solution to platos problem: The latent semantic anal-
ysis theory of acquisition, induction, and represen-
tation of knowledge. Psychological review, pages
211–240.
Minh-Thang Luong, Richard Socher, and Christo-
pher D. Manning. 2013. Better word representa-
tions with recursive neural networks for morphol-
ogy. In CoNLL, Sofia, Bulgaria.
Tomas Mikolov, Stefan Kombrink, Anoop Deoras,
Lukar Burget, and J Cernock`y. 2011. Rnnlm–
recurrent neural network language modeling toolkit.
Proc. of the 2011 ASRU Workshop, pages 196–201.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.
George A. Miller and Walter G. Charles. 1991. Con-
textual correlates of semantic similarity. Language
and Cognitive Processes, 6(1):1–28.
Jerome L. Myers and Arnold D. Well. 1995. Research
Design &amp; Statistical Analysis. Routledge, 1 edition,
June.
Kira Radinsky, Eugene Agichtein, Evgeniy
Gabrilovich, and Shaul Markovitch. 2011. A
word at a time: computing word relatedness using
temporal semantic analysis. In Proceedings of the
20th international conference on World wide web,
WWW ’11, pages 337–346, New York, NY, USA.
ACM.
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual correlates of synonymy. Commun. ACM,
8(10):627–633, October.
Richard Socher, Romain Paulus, Bryan McCann,
Kai Sheng Tai, and Andrew Y. Hu, JiaJi Ng. 2013a.
etcml.com - easy text classification with machine
learning. In Advances in Neural Information Pro-
cessing Systems (NIPS 2013).
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. 2013b. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1631–1642, Stroudsburg, PA, October.
Association for Computational Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th ACL, ACL ’10, pages 384–394, Stroudsburg,
PA, USA.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning : Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
pages 141–188.
Peter D. Turney. 2006. Similarity of semantic rela-
tions. Comput. Linguist., 32(3):379–416, Septem-
ber.
Laurens van der Maaten and Geoffrey Hinton. 2008.
Visualizing Data using t-SNE. Journal of Machine
Learning Research, 9:2579–2605, November.
Dongqiang Yang and David M. W. Powers. 2006. Verb
similarity on the taxonomy of wordnet. In In the 3rd
International WordNet Conference (GWC-06), Jeju
Island, Korea.
</reference>
<page confidence="0.999157">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.856279">
<title confidence="0.991515">Community Evaluation and Exchange of Word</title>
<author confidence="0.911562">Faruqui</author>
<affiliation confidence="0.997943">Carnegie Mellon</affiliation>
<address confidence="0.998502">Pittsburgh, PA, 15213,</address>
<abstract confidence="0.9962755">Vector space word representations are useful for many natural language processing applications. The diversity of techniques for computing vector representations and the large number of evaluation benchmarks makes reliable comparison a tedious task both for researchers developing new vector space models and for those wishing to use them. We present a website and suite of offline tools that that facilitate evaluation of word vectors on standard lexical semantics benchmarks and permit exchange and archival by users who wish to find good vectors for their applications. The system is accessible at:</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Enrique Alfonseca</author>
<author>Keith Hall</author>
<author>Jana Kravalova</author>
<author>Marius Pas¸ca</author>
<author>Aitor Soroa</author>
</authors>
<title>A study on similarity and relatedness using distributional and wordnet-based approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL, NAACL ’09,</booktitle>
<pages>pages</pages>
<location>Stroudsburg, PA, USA.</location>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pas¸ca, Soroa, 2009</marker>
<rawString>Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and wordnet-based approaches. In Proceedings of NAACL, NAACL ’09, pages 19–27, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elia Bruni</author>
<author>Gemma Boleda</author>
<author>Marco Baroni</author>
<author>Nam Khanh Tran</author>
</authors>
<title>Distributional semantics in technicolor.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>136--145</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="4773" citStr="Bruni et al., 2012" startWordPosition="737" endWordPosition="740">n given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas the former contains all kinds of words. The sixth benchmark is the MTurk-2875 (Radinsky et al., 2011) dataset that constitutes 287 pairs of words and is different from the previous benchmarks in that it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contains 771 word pairs whose similarity was crowdsourced from AMT. Another, AMT created dataset is the MEN7 benchmark (Bruni et al., 2012) that consists of 3000 word pairs, randomly selected from words that occur at least 700 times in the freely available ukWaC and Wackypedia8 corpora combined. The next two benchmarks were created to put emphasis on different kinds of word types. To specifically emphasize on verbs, Yang and Powers (2006) created a new benchmark YP-130 of 130 verb pairs with human similarity judgements. Since, most of the earlier discussed datasets contain word pairs that are relatively more frequent in a corpus, Luong et al. (2013) create a new bench3http://www.cs.technion.ac.il/˜gabr/ resources/data/wordsim353/</context>
</contexts>
<marker>Bruni, Boleda, Baroni, Tran, 2012</marker>
<rawString>Elia Bruni, Gemma Boleda, Marco Baroni, and Nam Khanh Tran. 2012. Distributional semantics in technicolor. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 136–145, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th international conference on Machine learning, ICML ’08,</booktitle>
<pages>160--167</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1459" citStr="Collobert and Weston, 2008" startWordPosition="214" endWordPosition="217">driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of techniques to obtain word vector representations the task of comparison and choosing the vectors best suitable for a particular task becomes difficult. This is further aggravated by the large number of existing lexical semantics evaluation benchmarks being constructed by the research community. For example, to the best of our knowledge, for evaluating word similarity between a given pair</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, ICML ’08, pages 160–167, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>12--2493</pages>
<contexts>
<context position="9615" citStr="Collobert et al., 2011" startWordPosition="1487" endWordPosition="1490">ctionality. The user can also choose the option to choose two different types of word vectors and compare their performance on the benchmarks. We will keep adding word vectors on the website as and when they are released. The following word vectors have been included in our collection: Metaoptimize. These word embeddings 11 have been trained in (Turian et al., 2010) using a neural network language model and were shown to be useful for named entity recognition (NER) and phrase chunking. SENNA. It is a software12 which outputs a host of predictions: part-of-speech (POS) tags, chunking, NER etc (Collobert et al., 2011). The software uses neural word embeddings trained over Wikipedia data for over 2 months. RNNLM. The recurrent neural network language modeling toolkit13 comes with some pre-trained embeddings on broadcast news data (Mikolov et al., 2011). Global Context. Huang et al. (2012) present a model to incorporate document level information into embeddings to generate semantically more informed word vector representations. These embeddings14 capture both local and global context of the words. Skip-Gram. This model is a neural network language model except for that it does not have a hidden layer and in</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. J. Mach. Learn. Res., 12:2493–2537, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Cristina Ferreira de Oliveira</author>
<author>Haim Levkowitz</author>
</authors>
<title>From visual data exploration to visual data mining: A survey.</title>
<date>2003</date>
<journal>IEEE Trans. Vis. Comput. Graph.,</journal>
<volume>9</volume>
<issue>3</issue>
<marker>de Oliveira, Levkowitz, 2003</marker>
<rawString>Maria Cristina Ferreira de Oliveira and Haim Levkowitz. 2003. From visual data exploration to visual data mining: A survey. IEEE Trans. Vis. Comput. Graph., 9(3):378–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Deerwester</author>
<author>S T Dumais</author>
<author>T K Landauer</author>
<author>G W Furnas</author>
<author>R A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science.</journal>
<contexts>
<context position="1072" citStr="Deerwester et al., 1990" startWordPosition="152" endWordPosition="155">searchers developing new vector space models and for those wishing to use them. We present a website and suite of offline tools that that facilitate evaluation of word vectors on standard lexical semantics benchmarks and permit exchange and archival by users who wish to find good vectors for their applications. The system is accessible at: www.wordvectors.org. 1 Introduction Data-driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of tec</context>
<context position="10945" citStr="Deerwester et al., 1990" startWordPosition="1673" endWordPosition="1676"> These embeddings are much faster to train15 than the other neural embeddings. 11http://metaoptimize.com/projects/ wordreprs/ 12http://ronan.collobert.com/senna/ 13http://rnnlm.org/ 14http://nlp.stanford.edu/˜socherr/ ACL2012_wordVectorsTextFile.zip 15https://code.google.com/p/word2vec/ 21 Figure 2: Vector selection interface (right) of the demo system. Multilingual. Faruqui and Dyer (2014) propose a method based on canonical correlation analysis to produce more informed monolingual vectors using multilingual knowledge. Their method is shown to perform well for both neural embeddings and LSA (Deerwester et al., 1990) based vectors.16 4.2 User-created Vectors Our demo system provides the user an option to upload their word vectors to perform evaluation and visualization. However, since the size of the word vector file will be huge due to a lot of infrequent words that are not useful for evaluation, we give an option to filter the word vectors file to only include the words required for evaluation. The script and the vocabulary file can be found on the website online. 5 Offline Evaluation &amp; Public Access We provide an online portal where researchers can upload their vectors which are then be evaluated on a </context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Chris Dyer</author>
</authors>
<title>Improving vector space word representations using multilingual correlation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="7894" citStr="Faruqui and Dyer (2014)" startWordPosition="1203" endWordPosition="1206"> of capturing much of the local structure of the highdimensional data very well, while also revealing global structure such as the presence of clusters at several scales. In the demo system, we give the user an option to input words that they need to visualize which are fed to the t-SNE tool and the produced images are shown to the user on the webpage. These images can then be downloaded and used. We have 9http://www-nlp.stanford.edu/˜lmthang/ morphoNLM/ 10http://homepage.tudelft.nl/19j49/ t-SNE_files/tsne_python.zip 20 Figure 1: Antonyms (red) and synonyms (green) of beautiful represented by Faruqui and Dyer (2014) (left) and Huang et al. (2012) (right). included two datasets by default which exhibit different properties of the language: • Antonyms and synonyms of beautiful • Common male-female nouns and pronouns In the first plot, ideally the antonyms (ugly, hideous, ...) and synonyms (pretty, gorgeous, ... ) of beautiful should form two separate clusters in the plot. Figure 1 shows the plots of the antonyms and synonyms of the word beautiful for two available embeddings. The second default word plot is the gender data set, every word in which has a male and a female counterpart (ex. grandmother and gr</context>
<context position="10714" citStr="Faruqui and Dyer (2014)" startWordPosition="1636" endWordPosition="1639">f the words. Skip-Gram. This model is a neural network language model except for that it does not have a hidden layer and instead of predicting the target word, it predicts the context given the target word (Mikolov et al., 2013). These embeddings are much faster to train15 than the other neural embeddings. 11http://metaoptimize.com/projects/ wordreprs/ 12http://ronan.collobert.com/senna/ 13http://rnnlm.org/ 14http://nlp.stanford.edu/˜socherr/ ACL2012_wordVectorsTextFile.zip 15https://code.google.com/p/word2vec/ 21 Figure 2: Vector selection interface (right) of the demo system. Multilingual. Faruqui and Dyer (2014) propose a method based on canonical correlation analysis to produce more informed monolingual vectors using multilingual knowledge. Their method is shown to perform well for both neural embeddings and LSA (Deerwester et al., 1990) based vectors.16 4.2 User-created Vectors Our demo system provides the user an option to upload their word vectors to perform evaluation and visualization. However, since the size of the word vector file will be huge due to a lot of infrequent words that are not useful for evaluation, we give an option to filter the word vectors file to only include the words requir</context>
</contexts>
<marker>Faruqui, Dyer, 2014</marker>
<rawString>Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, Gothenburg, Sweden, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eytan Ruppin</author>
</authors>
<title>Placing search in context: the concept revisited.</title>
<date>2001</date>
<booktitle>In WWW ’01: Proceedings of the 10th international conference on World Wide Web,</booktitle>
<pages>406--414</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3659" citStr="Finkelstein et al., 2001" startWordPosition="554" endWordPosition="557"> an offline mode on the command line. Both the online and offline tools will be kept updated with continuous addition of new relevant tasks and vectors. 1www.wordvectors.org/suite.php 2www.etcml.com 19 Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 19–24, Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics 2 Word Similarity Benchmarks We evaluate our word representations on 10 different benchmarks that have been widely used to measure word similarity. The first one is the WS3533 dataset (Finkelstein et al., 2001) containing 353 pairs of English words that have been assigned similarity ratings by humans. This data was further divided into two fragments by Agirre et al. (2009) who claimed that similarity (WS-SIM) and relatedness (WS-REL)4 are two different kinds of relations and should be dealt with separately. The fourth and fifth benchmarks are the RG-65 (Rubenstein and Goodenough, 1965) and the MC30 (Miller and Charles, 1991) datasets that contain 65 and 30 pairs of nouns respectively and have been given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas th</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2001. Placing search in context: the concept revisited. In WWW ’01: Proceedings of the 10th international conference on World Wide Web, pages 406–414, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Halawi</author>
<author>Gideon Dror</author>
<author>Evgeniy Gabrilovich</author>
<author>Yehuda Koren</author>
</authors>
<title>Large-scale learning of word relatedness with constraints.</title>
<date>2012</date>
<booktitle>In KDD,</booktitle>
<pages>1406--1414</pages>
<contexts>
<context position="4620" citStr="Halawi et al., 2012" startWordPosition="711" endWordPosition="714">e RG-65 (Rubenstein and Goodenough, 1965) and the MC30 (Miller and Charles, 1991) datasets that contain 65 and 30 pairs of nouns respectively and have been given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas the former contains all kinds of words. The sixth benchmark is the MTurk-2875 (Radinsky et al., 2011) dataset that constitutes 287 pairs of words and is different from the previous benchmarks in that it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contains 771 word pairs whose similarity was crowdsourced from AMT. Another, AMT created dataset is the MEN7 benchmark (Bruni et al., 2012) that consists of 3000 word pairs, randomly selected from words that occur at least 700 times in the freely available ukWaC and Wackypedia8 corpora combined. The next two benchmarks were created to put emphasis on different kinds of word types. To specifically emphasize on verbs, Yang and Powers (2006) created a new benchmark YP-130 of 130 verb pairs with human similarity judgements. Since, most of the earlier discussed datasets contain word p</context>
</contexts>
<marker>Halawi, Dror, Gabrilovich, Koren, 2012</marker>
<rawString>Guy Halawi, Gideon Dror, Evgeniy Gabrilovich, and Yehuda Koren. 2012. Large-scale learning of word relatedness with constraints. In KDD, pages 1406– 1414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th ACL: Long Papers-Volume</booktitle>
<volume>1</volume>
<pages>873--882</pages>
<contexts>
<context position="7925" citStr="Huang et al. (2012)" startWordPosition="1209" endWordPosition="1212">ucture of the highdimensional data very well, while also revealing global structure such as the presence of clusters at several scales. In the demo system, we give the user an option to input words that they need to visualize which are fed to the t-SNE tool and the produced images are shown to the user on the webpage. These images can then be downloaded and used. We have 9http://www-nlp.stanford.edu/˜lmthang/ morphoNLM/ 10http://homepage.tudelft.nl/19j49/ t-SNE_files/tsne_python.zip 20 Figure 1: Antonyms (red) and synonyms (green) of beautiful represented by Faruqui and Dyer (2014) (left) and Huang et al. (2012) (right). included two datasets by default which exhibit different properties of the language: • Antonyms and synonyms of beautiful • Common male-female nouns and pronouns In the first plot, ideally the antonyms (ugly, hideous, ...) and synonyms (pretty, gorgeous, ... ) of beautiful should form two separate clusters in the plot. Figure 1 shows the plots of the antonyms and synonyms of the word beautiful for two available embeddings. The second default word plot is the gender data set, every word in which has a male and a female counterpart (ex. grandmother and grandfather), this data set exhib</context>
<context position="9890" citStr="Huang et al. (2012)" startWordPosition="1530" endWordPosition="1533">ection: Metaoptimize. These word embeddings 11 have been trained in (Turian et al., 2010) using a neural network language model and were shown to be useful for named entity recognition (NER) and phrase chunking. SENNA. It is a software12 which outputs a host of predictions: part-of-speech (POS) tags, chunking, NER etc (Collobert et al., 2011). The software uses neural word embeddings trained over Wikipedia data for over 2 months. RNNLM. The recurrent neural network language modeling toolkit13 comes with some pre-trained embeddings on broadcast news data (Mikolov et al., 2011). Global Context. Huang et al. (2012) present a model to incorporate document level information into embeddings to generate semantically more informed word vector representations. These embeddings14 capture both local and global context of the words. Skip-Gram. This model is a neural network language model except for that it does not have a hidden layer and instead of predicting the target word, it predicts the context given the target word (Mikolov et al., 2013). These embeddings are much faster to train15 than the other neural embeddings. 11http://metaoptimize.com/projects/ wordreprs/ 12http://ronan.collobert.com/senna/ 13http:</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th ACL: Long Papers-Volume 1, pages 873–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dutnais</author>
</authors>
<title>A solution to platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review,</title>
<date>1997</date>
<pages>211--240</pages>
<contexts>
<context position="14014" citStr="Landauer and Dutnais (1997)" startWordPosition="2188" endWordPosition="2191">models can be used to predict sentiment at these levels with high accuracy. The coarse-grained treebank, containing only positive and negative classes has been split into training, development and test datasets con22 Figure 3: Screenshot of the command line version showing word similarity evaluation. taining 6920, 872 and 1821 sentences respectively. We train a logistic regression classifier with L2 regularization on the average of the word vectors of a given sentence to predict the coarse-grained sentiment tag at the sentence level. TOEFL Synonyms. These are a set of 80 questions compiled by Landauer and Dutnais (1997), where a given word needs to be matched to its closest synonym from 4 given options. A number of systems have reported their results on this dataset.18 We use cosine similarity to identify the closest synonym. 5.2 Offline Software Along with the web demo system we are making available a software which can be downloaded and be used for evaluation of vector representations offline on all the benchmarks listed above. Since, we cannot distribute the evaluation benchmarks along with the software because of licensing issues, we would give links to the resources which should be downloaded prior to u</context>
</contexts>
<marker>Landauer, Dutnais, 1997</marker>
<rawString>Thomas K Landauer and Susan T. Dutnais. 1997. A solution to platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, pages 211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minh-Thang Luong</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Better word representations with recursive neural networks for morphology. In CoNLL,</title>
<date>2013</date>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="5291" citStr="Luong et al. (2013)" startWordPosition="823" endWordPosition="826">ty was crowdsourced from AMT. Another, AMT created dataset is the MEN7 benchmark (Bruni et al., 2012) that consists of 3000 word pairs, randomly selected from words that occur at least 700 times in the freely available ukWaC and Wackypedia8 corpora combined. The next two benchmarks were created to put emphasis on different kinds of word types. To specifically emphasize on verbs, Yang and Powers (2006) created a new benchmark YP-130 of 130 verb pairs with human similarity judgements. Since, most of the earlier discussed datasets contain word pairs that are relatively more frequent in a corpus, Luong et al. (2013) create a new bench3http://www.cs.technion.ac.il/˜gabr/ resources/data/wordsim353/ 4http://alfonseca.org/eng/research/ wordsim353.html 5http://tx.technion.ac.il/˜kirar/ Datasets.html 6http://www2.mta.ac.il/˜gideon/ mturk771.html 7http://clic.cimec.unitn.it/˜elia. bruni/MEN.html 8http://wacky.sslmit.unibo.it/doku. php?id=corpora mark (Rare-Word)9 that contains rare-words by sampling words from different frequency bins to a total of 2034 word pairs. We calculate similarity between a given pair of words by the cosine similarity between their corresponding vector representation. We then report Spe</context>
</contexts>
<marker>Luong, Socher, Manning, 2013</marker>
<rawString>Minh-Thang Luong, Richard Socher, and Christopher D. Manning. 2013. Better word representations with recursive neural networks for morphology. In CoNLL, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Stefan Kombrink</author>
<author>Anoop Deoras</author>
<author>Lukar Burget</author>
<author>J Cernock`y</author>
</authors>
<title>Rnnlm– recurrent neural network language modeling toolkit.</title>
<date>2011</date>
<booktitle>Proc. of the 2011 ASRU Workshop,</booktitle>
<pages>196--201</pages>
<marker>Mikolov, Kombrink, Deoras, Burget, Cernock`y, 2011</marker>
<rawString>Tomas Mikolov, Stefan Kombrink, Anoop Deoras, Lukar Burget, and J Cernock`y. 2011. Rnnlm– recurrent neural network language modeling toolkit. Proc. of the 2011 ASRU Workshop, pages 196–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</title>
<date>2013</date>
<contexts>
<context position="1521" citStr="Mikolov et al., 2013" startWordPosition="222" endWordPosition="225">semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of techniques to obtain word vector representations the task of comparison and choosing the vectors best suitable for a particular task becomes difficult. This is further aggravated by the large number of existing lexical semantics evaluation benchmarks being constructed by the research community. For example, to the best of our knowledge, for evaluating word similarity between a given pair of words, there are currently at least 10 existing benchmarks</context>
<context position="10320" citStr="Mikolov et al., 2013" startWordPosition="1600" endWordPosition="1603">nths. RNNLM. The recurrent neural network language modeling toolkit13 comes with some pre-trained embeddings on broadcast news data (Mikolov et al., 2011). Global Context. Huang et al. (2012) present a model to incorporate document level information into embeddings to generate semantically more informed word vector representations. These embeddings14 capture both local and global context of the words. Skip-Gram. This model is a neural network language model except for that it does not have a hidden layer and instead of predicting the target word, it predicts the context given the target word (Mikolov et al., 2013). These embeddings are much faster to train15 than the other neural embeddings. 11http://metaoptimize.com/projects/ wordreprs/ 12http://ronan.collobert.com/senna/ 13http://rnnlm.org/ 14http://nlp.stanford.edu/˜socherr/ ACL2012_wordVectorsTextFile.zip 15https://code.google.com/p/word2vec/ 21 Figure 2: Vector selection interface (right) of the demo system. Multilingual. Faruqui and Dyer (2014) propose a method based on canonical correlation analysis to produce more informed monolingual vectors using multilingual knowledge. Their method is shown to perform well for both neural embeddings and LSA </context>
<context position="12165" citStr="Mikolov et al. (2013)" startWordPosition="1881" endWordPosition="1884"> variety of NLP tasks and then placed on the leader board.17 The motivation behind creating such a portal is to make it easier for a user to select the kind of vector representation that is most suitable for their task. In this scenario, instead of asking the uploader to filter their word vectors for a small vocabulary, they will be requested to upload their vectors for the entire vocabulary. 16http://cs.cmu.edu/˜mfaruqui/soft.html 17We provide an initial list of some such tasks to which we will later add more tasks as they are developed. 5.1 Offline Evaluation Syntactic &amp; semantic relations. Mikolov et al. (2013) present a new semantic and syntactic relation dataset composed of analogous word pairs of size 8869 and 10675 pairs resp.. It contains pairs of tuples of word relations that follow a common relation. For example, in England : London :: France : Paris, the two given pairs of words follow the country-capital relation. We use the vector offset method (Mikolov et al., 2013) to compute the missing word in these relations. This is non-trivial V-way classification task where V is the size of the vocabulary. Sentence Completion. The Microsoft Research sentence completion dataset contains 1040 sentenc</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Walter G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="4081" citStr="Miller and Charles, 1991" startWordPosition="622" endWordPosition="625">Similarity Benchmarks We evaluate our word representations on 10 different benchmarks that have been widely used to measure word similarity. The first one is the WS3533 dataset (Finkelstein et al., 2001) containing 353 pairs of English words that have been assigned similarity ratings by humans. This data was further divided into two fragments by Agirre et al. (2009) who claimed that similarity (WS-SIM) and relatedness (WS-REL)4 are two different kinds of relations and should be dealt with separately. The fourth and fifth benchmarks are the RG-65 (Rubenstein and Goodenough, 1965) and the MC30 (Miller and Charles, 1991) datasets that contain 65 and 30 pairs of nouns respectively and have been given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas the former contains all kinds of words. The sixth benchmark is the MTurk-2875 (Radinsky et al., 2011) dataset that constitutes 287 pairs of words and is different from the previous benchmarks in that it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contains 771 word pairs whose similarity was cr</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>George A. Miller and Walter G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome L Myers</author>
<author>Arnold D Well</author>
</authors>
<date>1995</date>
<journal>Research Design &amp; Statistical Analysis. Routledge,</journal>
<volume>1</volume>
<pages>edition,</pages>
<contexts>
<context position="5950" citStr="Myers and Well, 1995" startWordPosition="888" endWordPosition="892">nion.ac.il/˜gabr/ resources/data/wordsim353/ 4http://alfonseca.org/eng/research/ wordsim353.html 5http://tx.technion.ac.il/˜kirar/ Datasets.html 6http://www2.mta.ac.il/˜gideon/ mturk771.html 7http://clic.cimec.unitn.it/˜elia. bruni/MEN.html 8http://wacky.sslmit.unibo.it/doku. php?id=corpora mark (Rare-Word)9 that contains rare-words by sampling words from different frequency bins to a total of 2034 word pairs. We calculate similarity between a given pair of words by the cosine similarity between their corresponding vector representation. We then report Spearman’s rank correlation coefficient (Myers and Well, 1995) between the rankings produced by our model against the human rankings. Multilingual Benchmarks. As is the case with most NLP problems, the lexical semantics evaluation benchmarks for languages other than English have been limited. Currently, we provide a link to some of these evaluation benchmarks from our website and in future will expand the website to encompass vector evaluation for other languages. 3 Visualization The existing benchmarks provide ways of vector evaluation in a quantitative setting. To get an idea of what kind of information the vectors encode it is important to see how the</context>
</contexts>
<marker>Myers, Well, 1995</marker>
<rawString>Jerome L. Myers and Arnold D. Well. 1995. Research Design &amp; Statistical Analysis. Routledge, 1 edition, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kira Radinsky</author>
<author>Eugene Agichtein</author>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>A word at a time: computing word relatedness using temporal semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference on World wide web, WWW ’11,</booktitle>
<pages>337--346</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4358" citStr="Radinsky et al., 2011" startWordPosition="668" endWordPosition="671">ings by humans. This data was further divided into two fragments by Agirre et al. (2009) who claimed that similarity (WS-SIM) and relatedness (WS-REL)4 are two different kinds of relations and should be dealt with separately. The fourth and fifth benchmarks are the RG-65 (Rubenstein and Goodenough, 1965) and the MC30 (Miller and Charles, 1991) datasets that contain 65 and 30 pairs of nouns respectively and have been given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas the former contains all kinds of words. The sixth benchmark is the MTurk-2875 (Radinsky et al., 2011) dataset that constitutes 287 pairs of words and is different from the previous benchmarks in that it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contains 771 word pairs whose similarity was crowdsourced from AMT. Another, AMT created dataset is the MEN7 benchmark (Bruni et al., 2012) that consists of 3000 word pairs, randomly selected from words that occur at least 700 times in the freely available ukWaC and Wackypedia8 corpora combined. The next two benchmarks wer</context>
</contexts>
<marker>Radinsky, Agichtein, Gabrilovich, Markovitch, 2011</marker>
<rawString>Kira Radinsky, Eugene Agichtein, Evgeniy Gabrilovich, and Shaul Markovitch. 2011. A word at a time: computing word relatedness using temporal semantic analysis. In Proceedings of the 20th international conference on World wide web, WWW ’11, pages 337–346, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Commun. ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="4041" citStr="Rubenstein and Goodenough, 1965" startWordPosition="614" endWordPosition="617">sociation for Computational Linguistics 2 Word Similarity Benchmarks We evaluate our word representations on 10 different benchmarks that have been widely used to measure word similarity. The first one is the WS3533 dataset (Finkelstein et al., 2001) containing 353 pairs of English words that have been assigned similarity ratings by humans. This data was further divided into two fragments by Agirre et al. (2009) who claimed that similarity (WS-SIM) and relatedness (WS-REL)4 are two different kinds of relations and should be dealt with separately. The fourth and fifth benchmarks are the RG-65 (Rubenstein and Goodenough, 1965) and the MC30 (Miller and Charles, 1991) datasets that contain 65 and 30 pairs of nouns respectively and have been given similarity rankings by humans. These differ from WS-353 in that it contains only nouns whereas the former contains all kinds of words. The sixth benchmark is the MTurk-2875 (Radinsky et al., 2011) dataset that constitutes 287 pairs of words and is different from the previous benchmarks in that it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contain</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John B. Goodenough. 1965. Contextual correlates of synonymy. Commun. ACM, 8(10):627–633, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Romain Paulus</author>
<author>Bryan McCann</author>
<author>Kai Sheng Tai</author>
<author>Andrew Y Hu</author>
<author>JiaJi Ng</author>
</authors>
<title>etcml.com - easy text classification with machine learning.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS</booktitle>
<contexts>
<context position="2913" citStr="Socher et al. (2013" startWordPosition="443" endWordPosition="446"> • Access to a suite of word similarity evaluation benchmarks • Evaluation of user computed word vectors • Visualizing word vectors in R2 • Evaluation and comparison of the available open-source vectors on the suite • Submission of user vectors for exhaustive offline evaluation and leader board ranking • Publicly available repository of word vectors with performance details Availability of such an evaluation system will help in enabling better consistency and uniformity in evaluation of word vector representations as well as provide an easy to use interface for endusers in a similar spirit to Socher et al. (2013a), a website for text classification.2 Apart from the online demo version, we also provide a software that can be run in an offline mode on the command line. Both the online and offline tools will be kept updated with continuous addition of new relevant tasks and vectors. 1www.wordvectors.org/suite.php 2www.etcml.com 19 Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 19–24, Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics 2 Word Similarity Benchmarks We evaluate our word representation</context>
<context position="13209" citStr="Socher et al. (2013" startWordPosition="2063" endWordPosition="2066">s is non-trivial V-way classification task where V is the size of the vocabulary. Sentence Completion. The Microsoft Research sentence completion dataset contains 1040 sentences from each of which one word has been removed. The task is to correctly predict the missing word from a given list of 5 other words per sentence. We average the word vectors of a given sentence qsent = ENi=1,i�j qwi/N, where wj is the missing word and compute the cosine similarity of qsent vector with each of the options. The word with the highest similarity is chosen as the missing word placeholder. Sentiment Analysis Socher et al. (2013b) have created a treebank which contains sentences annotated with fine-grained sentiment labels on both the phrase and sentence level. They show that compositional vector space models can be used to predict sentiment at these levels with high accuracy. The coarse-grained treebank, containing only positive and negative classes has been split into training, development and test datasets con22 Figure 3: Screenshot of the command line version showing word similarity evaluation. taining 6920, 872 and 1821 sentences respectively. We train a logistic regression classifier with L2 regularization on t</context>
</contexts>
<marker>Socher, Paulus, McCann, Tai, Hu, Ng, 2013</marker>
<rawString>Richard Socher, Romain Paulus, Bryan McCann, Kai Sheng Tai, and Andrew Y. Hu, JiaJi Ng. 2013a. etcml.com - easy text classification with machine learning. In Advances in Neural Information Processing Systems (NIPS 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1631--1642</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA,</location>
<contexts>
<context position="2913" citStr="Socher et al. (2013" startWordPosition="443" endWordPosition="446"> • Access to a suite of word similarity evaluation benchmarks • Evaluation of user computed word vectors • Visualizing word vectors in R2 • Evaluation and comparison of the available open-source vectors on the suite • Submission of user vectors for exhaustive offline evaluation and leader board ranking • Publicly available repository of word vectors with performance details Availability of such an evaluation system will help in enabling better consistency and uniformity in evaluation of word vector representations as well as provide an easy to use interface for endusers in a similar spirit to Socher et al. (2013a), a website for text classification.2 Apart from the online demo version, we also provide a software that can be run in an offline mode on the command line. Both the online and offline tools will be kept updated with continuous addition of new relevant tasks and vectors. 1www.wordvectors.org/suite.php 2www.etcml.com 19 Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 19–24, Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics 2 Word Similarity Benchmarks We evaluate our word representation</context>
<context position="13209" citStr="Socher et al. (2013" startWordPosition="2063" endWordPosition="2066">s is non-trivial V-way classification task where V is the size of the vocabulary. Sentence Completion. The Microsoft Research sentence completion dataset contains 1040 sentences from each of which one word has been removed. The task is to correctly predict the missing word from a given list of 5 other words per sentence. We average the word vectors of a given sentence qsent = ENi=1,i�j qwi/N, where wj is the missing word and compute the cosine similarity of qsent vector with each of the options. The word with the highest similarity is chosen as the missing word placeholder. Sentiment Analysis Socher et al. (2013b) have created a treebank which contains sentences annotated with fine-grained sentiment labels on both the phrase and sentence level. They show that compositional vector space models can be used to predict sentiment at these levels with high accuracy. The coarse-grained treebank, containing only positive and negative classes has been split into training, development and test datasets con22 Figure 3: Screenshot of the command line version showing word similarity evaluation. taining 6920, 872 and 1821 sentences respectively. We train a logistic regression classifier with L2 regularization on t</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013b. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631–1642, Stroudsburg, PA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th ACL, ACL ’10,</booktitle>
<pages>384--394</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1338" citStr="Turian et al., 2010" startWordPosition="194" endWordPosition="197">o find good vectors for their applications. The system is accessible at: www.wordvectors.org. 1 Introduction Data-driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of techniques to obtain word vector representations the task of comparison and choosing the vectors best suitable for a particular task becomes difficult. This is further aggravated by the large number of existing lexical semantics evaluation benchmarks being constructed </context>
<context position="9360" citStr="Turian et al., 2010" startWordPosition="1444" endWordPosition="1447"> Pre-trained Vectors We haves collected several standard pre-trained word vector representations freely available for research purposes and provide a utility for the user to test them on the suite of benchmarks, as well as try out the visualization functionality. The user can also choose the option to choose two different types of word vectors and compare their performance on the benchmarks. We will keep adding word vectors on the website as and when they are released. The following word vectors have been included in our collection: Metaoptimize. These word embeddings 11 have been trained in (Turian et al., 2010) using a neural network language model and were shown to be useful for named entity recognition (NER) and phrase chunking. SENNA. It is a software12 which outputs a host of predictions: part-of-speech (POS) tags, chunking, NER etc (Collobert et al., 2011). The software uses neural word embeddings trained over Wikipedia data for over 2 months. RNNLM. The recurrent neural network language modeling toolkit13 comes with some pre-trained embeddings on broadcast news data (Mikolov et al., 2011). Global Context. Huang et al. (2012) present a model to incorporate document level information into embedd</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th ACL, ACL ’10, pages 384–394, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning : Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>141--188</pages>
<contexts>
<context position="1098" citStr="Turney and Pantel, 2010" startWordPosition="156" endWordPosition="159">vector space models and for those wishing to use them. We present a website and suite of offline tools that that facilitate evaluation of word vectors on standard lexical semantics benchmarks and permit exchange and archival by users who wish to find good vectors for their applications. The system is accessible at: www.wordvectors.org. 1 Introduction Data-driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of techniques to obtain word vec</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning : Vector space models of semantics. Journal of Artificial Intelligence Research, pages 141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Similarity of semantic relations.</title>
<date>2006</date>
<journal>Comput. Linguist.,</journal>
<volume>32</volume>
<issue>3</issue>
<contexts>
<context position="1250" citStr="Turney, 2006" startWordPosition="181" endWordPosition="182">exical semantics benchmarks and permit exchange and archival by users who wish to find good vectors for their applications. The system is accessible at: www.wordvectors.org. 1 Introduction Data-driven learning of vector-space word embeddings that capture lexico-semantic properties is a technique of central importance in natural language processing. Using co-occurrence statistics from a large corpus of text (Deerwester et al., 1990; Turney and Pantel, 2010), it is possible to construct high-quality semantic vectors — as judged by both correlations with human judgements of semantic relatedness (Turney, 2006; Agirre et al., 2009) and as features for downstream applications (Turian et al., 2010). A number of approaches that use the internal representations from models of word sequences (Collobert and Weston, 2008) or continuous bags-of-context wordsets (Mikolov et al., 2013) to arrive at vector representations have also been shown to likewise capture co-occurrence tendencies and meanings. With an overwhelming number of techniques to obtain word vector representations the task of comparison and choosing the vectors best suitable for a particular task becomes difficult. This is further aggravated by</context>
</contexts>
<marker>Turney, 2006</marker>
<rawString>Peter D. Turney. 2006. Similarity of semantic relations. Comput. Linguist., 32(3):379–416, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurens van der Maaten</author>
<author>Geoffrey Hinton</author>
</authors>
<title>Visualizing Data using t-SNE.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--2579</pages>
<marker>van der Maaten, Hinton, 2008</marker>
<rawString>Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using t-SNE. Journal of Machine Learning Research, 9:2579–2605, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dongqiang Yang</author>
<author>David M W Powers</author>
</authors>
<title>Verb similarity on the taxonomy of wordnet.</title>
<date>2006</date>
<booktitle>In In the 3rd International WordNet Conference (GWC-06),</booktitle>
<location>Jeju Island,</location>
<contexts>
<context position="5076" citStr="Yang and Powers (2006)" startWordPosition="786" endWordPosition="790">at it has been constructed by crowdsourcing the human similarity ratings using Amazon Mechanical Turk (AMT). Similar in spirit is the MTruk-7716 (Halawi et al., 2012) dataset that contains 771 word pairs whose similarity was crowdsourced from AMT. Another, AMT created dataset is the MEN7 benchmark (Bruni et al., 2012) that consists of 3000 word pairs, randomly selected from words that occur at least 700 times in the freely available ukWaC and Wackypedia8 corpora combined. The next two benchmarks were created to put emphasis on different kinds of word types. To specifically emphasize on verbs, Yang and Powers (2006) created a new benchmark YP-130 of 130 verb pairs with human similarity judgements. Since, most of the earlier discussed datasets contain word pairs that are relatively more frequent in a corpus, Luong et al. (2013) create a new bench3http://www.cs.technion.ac.il/˜gabr/ resources/data/wordsim353/ 4http://alfonseca.org/eng/research/ wordsim353.html 5http://tx.technion.ac.il/˜kirar/ Datasets.html 6http://www2.mta.ac.il/˜gideon/ mturk771.html 7http://clic.cimec.unitn.it/˜elia. bruni/MEN.html 8http://wacky.sslmit.unibo.it/doku. php?id=corpora mark (Rare-Word)9 that contains rare-words by sampling </context>
</contexts>
<marker>Yang, Powers, 2006</marker>
<rawString>Dongqiang Yang and David M. W. Powers. 2006. Verb similarity on the taxonomy of wordnet. In In the 3rd International WordNet Conference (GWC-06), Jeju Island, Korea.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>