<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.914747">
ECNUCS: Recognizing Cross-lingual Textual Entailment Using Multiple
Text Similarity and Text Difference Measures
</title>
<author confidence="0.976213">
Jiang ZHAO
</author>
<affiliation confidence="0.889550333333333">
Department of Computer
Science and Technology
East China Normal University
</affiliation>
<address confidence="0.596642">
Shanghai, P.R.China
</address>
<email confidence="0.992138">
51121201042@ecnu.cn
</email>
<author confidence="0.569252">
Man LAN∗
</author>
<affiliation confidence="0.629892666666667">
Department of Computer
Science and Technology
East China Normal University
</affiliation>
<address confidence="0.634238">
Shanghai, P.R.China
</address>
<email confidence="0.997144">
mlan@cs.ecnu.edu.cn
</email>
<note confidence="0.688828333333333">
Zheng-Yu NIU
Baidu Inc.
Beijing, P.R.China
</note>
<email confidence="0.99274">
niuzhengyu@baidu.com
</email>
<sectionHeader confidence="0.994639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999318625">
This paper presents our approach used for
cross-lingual textual entailment task (task 8)
organized within SemEval 2013. Cross-
lingual textual entailment (CLTE) tries to de-
tect the entailment relationship between two
text fragments in different languages. We
solved this problem in three steps. Firstly,
we use a off-the-shelf machine translation
(MT) tool to convert the two input texts into
the same language. Then after performing a
text preprocessing, we extract multiple feature
types with respect to surface text and gram-
mar. We also propose novel feature types
regarding to sentence difference and seman-
tic similarity based on our observations in the
preliminary experiments. Finally, we adopt a
multiclass SVM algorithm for classification.
The results on the cross-lingual data collec-
tions provided by SemEval 2013 show that (1)
we can build portable and effective systems
across languages using MT and multiple ef-
fective features; (2) our systems achieve the
best results among the participants on two test
datasets, i.e., FRA-ENG and DEU-ENG.
</bodyText>
<sectionHeader confidence="0.998886" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999808065217392">
The Cross-lingual Textual Entailment (CLTE) task
in SemEval 2013 consists in detecting the entail-
ment relationship between two topic-related text
fragments (usually called T(ext) and H(ypothesis))
in different languages, which is a cross-lingual ex-
tension of TE task in (Dagan and Glickman, 2004).
We say T entails H if the meaning of H can be in-
ferred from the meaning of T. Mehdad et al. (2010b)
firstly proposed this problem within a new challeng-
ing application scenario, i.e., content synchroniza-
tion. In consideration of the directionality, the task
needs to assign one of the following entailment judg-
ments to a pair of sentences (1) forward: unidirec-
tional entailment from T to H; (2) backward: unidi-
rectional entailment from H to T; (3) bidirectional:
the two fragments entail each other (i.e., semantic
equivalence); (4) non-entailment: there is no entail-
ment between T and H.
During the last decades, many researchers and
communities have paid a lot of attention to resolve
the TE detection (e.g., seven times of the Rec-
ognizing Textual Entailment Challenge, i.e., from
RTE1 to RET7, have been held) since identifying
the relationship between two sentences is at the core
of many NLP applications, such as text summa-
rization (Lloret et al., 2008) or question answer-
ing (Harabagiu and Hickl, 2006). For example,
in text summarization, a redundant sentence should
be omitted from the summary if this sentence can
be entailed from other expressions in the summary.
CLTE extends those tasks with lingual dimension-
ality, where more than one language is involved.
Although it is a relatively new task, a basic solu-
tion has been provided in (Mehdad et al., 2010b),
which brings the problem back to monolingual sce-
nario using MT to translate H into the language of
T. The promising performance indicates the poten-
tialities of such a simple approach which integrates
MT and monolingual TE algorithms (Castillo, 2011;
Jimenez et al., 2012; Mehdad et al., 2010a).
In this work, we regard CLTE as a multiclass clas-
sification problem, in which multiple feature types
are used in conjunction with a multiclass SVM clas-
sifier. Specifically, our approach can be divided
into three steps. Firstly, following (Espl`a-Gomis
et al., 2012; Meng et al., 2012), we use MT to
</bodyText>
<page confidence="0.960118">
118
</page>
<bodyText confidence="0.992218347826087">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 118–123, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
bridge the gap of language differences between T
and H. Secondly, we perform a preprocessing pro-
cedure to maximize the similarity of the two text
fragments so as to make a more accurate calcula-
tion of surface text similarity measures. Besides sev-
eral features described in previous work (Malakasi-
otis, 2009; Espl`a-Gomis et al., 2012), we also pro-
pose several novel features regarding to sentence dif-
ference and semantic similarity. Finally, all these
features are combined together and serves as input
of a multiclass SVM classifier. After analyzing of
the results obtained in preliminary experiments, we
also cast this problem as a hierarchical classification
problem.
The remainder of the paper is organized as fol-
lows. Section 2 describes different features used in
our systems. Section 3 presents the system settings
including the datasets and preprocessing. Section 4
shows the results of different systems on different
language pairs. Finally, we conclude this paper with
future work in Section 5.
</bodyText>
<sectionHeader confidence="0.997338" genericHeader="introduction">
2 Features
</sectionHeader>
<bodyText confidence="0.997738">
In this section, we will describe a variety of feature
types used in our experiments.
</bodyText>
<subsectionHeader confidence="0.994397">
2.1 Basic features
</subsectionHeader>
<bodyText confidence="0.999872866666667">
The BC feature set consists of length measures on
variety sets including |A|, |B|, |A−B|, |B−A|, |AU
B|, |A n B|, |A|/|B |and |B|/|A|, where A and B
represent two texts, and the length of set is the num-
ber of non-repeated elements in this set. Once we
view the text as a set of words, A − B means the set
of words found in A but not in B, A U B means the
set of words found in either A or B and AnB means
the set of shared words found in both A and B.
Given a pair of texts, i.e., &lt;T,H&gt;, which are in
different languages, we use MT to translate one of
them to make them in the same language. Thus,
we can get two pairs of texts, i.e., &lt;Tt,H&gt; and
&lt;T,Ht&gt;. We apply the above eight length measures
to the two pairs, resulting in a total of 16 features.
</bodyText>
<subsectionHeader confidence="0.999302">
2.2 Surface Text Similarity features
</subsectionHeader>
<bodyText confidence="0.997622333333333">
Following (Malakasiotis and Androutsopoulos,
2007), the surface text similarity (STS) feature set
contains nine similarity measures:
</bodyText>
<equation confidence="0.415569625">
Jaccard coefficient: It is defined as |A∩B|
|A∪B|, where
|A n B |and |A U B |are as in the BC.
Dice coefficient: Defined as 2 A |+A∩B |,Bj
+B
Overlap coefficient: This is the ollowing quantity,
B|
Overlap(A, B) = |AA |.
</equation>
<bodyText confidence="0.99202175">
Weighted overlap coefficient: We assign the tf*idf
value to each word in the sentence to distinguish
the importance of different words. The weighted
overlap coefficient is defined as follows:
</bodyText>
<equation confidence="0.661844666666667">
→−
Cosine similarity: cos(−�x , �−x·−→y
y ) = II−→x H−→y II, where
</equation>
<bodyText confidence="0.8246205">
�− x and y are vectorial representations of texts (i.e.
A and B) in tf * idf schema.
</bodyText>
<equation confidence="0.945550571428571">
Manhattan distance: Defined as M(−�x , y ) =
n
|xi − yi|.
Euclidean distance: Defined as E(−�x , y ) =
� n
(xi − yi)2.
i=1
</equation>
<bodyText confidence="0.999506888888889">
Edit distance: This is the minimum number of op-
erations needed to transform A to B. We define an
operation as an insertion, deletion or substitution of
a word.
Jaro-Winker distance: Following (Winkler and
others, 1999), the Jaro-Winkler distance is a mea-
sure of similarity between two strings at the word
level.
In total, we can get 11 features in this feature set.
</bodyText>
<subsectionHeader confidence="0.999197">
2.3 Sematic Similarity features
</subsectionHeader>
<bodyText confidence="0.996478153846154">
Almost every previous work used the surface texts
or exploited the meanings of words in the dictio-
nary to calculate the similarity of two sentences
rather than the actual meaning in the sentence. In
this feature set (SS), we introduce a latent model
to model the semantic representations of sentences
since latent models are capable of capturing the
contextual meaning of words in sentences. We
used weighted textual matrix factorization (WTMF)
(Guo and Diab, 2012) to model the semantics of
the sentences. The model factorizes the original
term-sentence matrix X into two matrices such that
Xi,j Pt� PT∗,iQ∗,j, where P∗,i is a latent semantics
</bodyText>
<equation confidence="0.9232448">
WOverlap(A, B) = Ewi∈A∩B Wwi ,
Ewi∈A Wwi
where Wwi is the weight of word wi.
E
i=1
</equation>
<page confidence="0.99055">
119
</page>
<bodyText confidence="0.990022571428572">
vector profile for word wi and Q∗,j is the vector pro-
file that represents the sentence sj. The weight ma-
trix W is introduced in the optimization process in
order to model the missing words at the right level
of emphasis. We propose three similarity measures
according to different strategies:
wtw: word-to-word based similarity defined as
</bodyText>
<equation confidence="0.6131944">
120 classification, therefore we count the number of un-
wiEA Wwi
wts: word-to-sentence based similarity defined as
sim(A, B) = lg r,wi∈A Wwi P∗,i·Q∗,k
r,wi∈A Wwi
</equation>
<bodyText confidence="0.910823">
sts: sentence-to-sentence based similarity defined as
sim(A, B) = lg (Q∗,i · Q∗,j).
Also we calculate the cosine similarity, Euclidean
and Manhattan distance, weighted overlap coeffi-
cient using those semantics vectors, resulting in 10
features.
</bodyText>
<subsectionHeader confidence="0.9911845">
2.4 Sentence Difference features
2.6 Bias features
</subsectionHeader>
<bodyText confidence="0.739934">
r,
</bodyText>
<equation confidence="0.835442">
wi∈A Wwi·���wj ∈B�P∗,i,P∗,j�
sim(A, B) = lg V,
V,
.
</equation>
<bodyText confidence="0.986405979166667">
matched words in each sentence that belong to a
small set of POS tags (here consider only NN, JJ,
RB, VB an
d CD tags), which produces 10 features,
resulting in a total of 13 sentence difference features.
apply the STS measures on this new
In addition, we use the Stanford Parser to get the
dependency information represented in a form of re-
lation units (e.g. nsubj(example, this)). We calculate
the BC measures on those units and the overlap co-
efficients together with the harmonic mean
“sentence”.
of them.
Finally, we get 22 features.
Stan
ford NER toolkit. We set the feature to 1 if the
named entities in one sentence are found in the other
sentence, otherwise -1. As a result, this feature set
contains 9 features.
be entailed by the other sentence. That is, we can
infer the entailment class through the number of un-
matched words. We regard this label as our third
feature type. Secondly, different POS types of un-
matched words may have different impacts on the
Most of those above measures are symmetric and
only a few are asymmetric, which means they may
not be very suitable for the task that requires dealing
with directional problems. We solve this problem by
introducing sentence difference measures.
We observed that many entailment relationships
between two sentences are determined by only tiny
parts of the sentences. As a result, the similarity of
such two sentences by using above measures will be
close to 1, which may mislead the classifier. Fur-
thermore, almost all similarity measures in STS are
symmetric, which means the same similarity has no
help to distinguish the different directions. Based on
the above considerations, we propose a novel sen-
tence difference (SD) feature set to discover the dif-
ferences between two sentences and tell the classi-
fier the possibility the entailment should not hold.
The sentence difference features are extracted as
follows. Firstly, a word in one sentence is consid-
ered as matched if we can find the same word in the
other sentence. Then we find all matched words and
count the number of unmatched words in each sen-
tence, resulting in 2 features. If one sentence has
no unmatched words, we say that this sentence can
</bodyText>
<subsectionHeader confidence="0.904926">
2.5 Grammatical Relationship features
</subsectionHeader>
<bodyText confidence="0.9921583125">
The grammatical relationship feature type (GR) is
designed to capture the grammatical relationship be-
tween two sentences. We first replace the words in a
sentence with their part-of-speech (POS) tags, then
The bias features (BS) are to check the differences
between two sentences in certain special aspects,
such as polarity and named entity. We use a method
based on subjectivity of lexicons (Loughran and Mc-
Donald, 2011) to get the polarity of a sentence by
simply comparing the numbers of positive and neg-
ative words. If the numbers are the same, then we
set the feature to 1, otherwise -1. Also, we check
whether one sentence entails the other using only
the named entity information. We consider four cat-
egories of named entities, i.e., person, organization,
location, number, which are recognized by using the
</bodyText>
<sectionHeader confidence="0.993754" genericHeader="method">
3 Experimental Setting
</sectionHeader>
<bodyText confidence="0.987379909090909">
We evaluated our approach using the data sets
provided in the task 8 of SemEval 2013 (Ne-
gri et al., 2013). The data sets consist of a
collection of 1500 text fragment pairs (1000 for
training consisting of training and test set in Se-
mEval 2012 and 500 for test) in each language
pair. Four different language pairs are provided:
German-English, French-English, Italian-English
and Spanish-English. See (Negri et al., 2013) for
more detailed descri
ption.
</bodyText>
<subsectionHeader confidence="0.994833">
3.1 Preprocess
</subsectionHeader>
<bodyText confidence="0.999996153846154">
We performed the following text preprocessing.
Firstly, we employed the state-of-the-art Statistical
Machine Translator, i.e., Google translator, to trans-
late each pair of texts &lt;T,H&gt; into &lt;Tt,H&gt; and
&lt;T,Ht&gt;, thus they were in the same language. Then
we extracted all above described feature sets from
the pair &lt;Tt,H&gt; (note that &lt;T,Ht&gt; are also used
in BC), so the below steps were mainly operated on
this pair. After that, all sentences were tokenized
and lemmatized using the Stanford Lemmatizer and
all stop words were removed, followed by the equiv-
alent replacement procedure. The replacement pro-
cedure consists of the following 3 steps:
Abbreviative replacement. Many phrases or orga-
nizations can be abbreviated to a set of capitalized
letters, e.g. “Iew Jersey” is usually wrote as “IJ”
for short. In this step, we checked every word whose
length is 2 or 3 and if it is the same as the “word”
consisting of the first letters of the successive words
in another sentence, then we replaced it by them.
Semantic replacement. We observed that although
some lemmas in H and T were in the different forms,
they actually shared the same meaning, e.g. “hap-
pen” and “occur”. Here, we focused on replacing a
lemma in one sentence with another lemma in the
other sentence if they were: 1) in the same syn-
onymy set; or 2) gloss-related. Two lemmas were
gloss-related if a lemma appeared in the gloss of the
other. For example, the gloss of “trip” is “a jour-
ney for some purpose” (WordNet 2.1 was used for
looking up the synonymy and gloss of a lemma), so
the lemma “journey” is gloss-related with “trip”. No
word sense disambiguation was performed and all
synsets for a particular lemma were considered.
Context replacement. The context of a lemma
is defined as the non-stopword lemmas around it.
Given two text fragments, i.e., T. ...be erroneously
label as a “register sex offender.” and H. ...be mis-
takenly inscribe as a “register sex offender”., af-
ter the semantic replacement, we can recognize the
lemma “erroneously” was replaceable by “mistak-
enly”. However, WordNet 2.1 cannot recognize the
lemmas “label” and “inscribe” which can also be
replaceable. To address this problem, we simply as-
sumed that two lemmas surrounded by the same con-
text can be replaceable as well. In the experiments,
we set the window size of context replacement as 3.
This step is the foundation of the extraction of
the sentence different features and can also allevi-
ate the imprecise similarity measure problem exist-
ing in STS caused by the possibility of the lemmas
in totally different forms sharing the same sense.
</bodyText>
<subsectionHeader confidence="0.998407">
3.2 System Configuration
</subsectionHeader>
<bodyText confidence="0.9998906">
We selected 500 samples from the training data as
development set (i.e. test set in SemEval 2012) and
performed a series of preliminary experiments to
evaluate the effectiveness of different feature types
in isolation and also in different combinations. Ac-
cording to the results on the development set, we
configured five different systems on each language
pair as our final submissions with different feature
types and classification strategies. Table1 shows the
five configurations of those systems.
</bodyText>
<subsectionHeader confidence="0.586651">
System Feature Set Description
</subsectionHeader>
<table confidence="0.933635428571429">
1 all flat, SVM
2 best feature sets flat, SVM
3 best feature sets flat, Majority Voting
flat, only 500 instances
4 best feature sets
for train, SVM
5 best feature sets hierarchical, SVM
</table>
<tableCaption confidence="0.9492285">
Table 1: System configurations using different strategies
based on the results of preliminary experiments.
</tableCaption>
<bodyText confidence="0.999963105263158">
Among them, System 1 serves as a baseline that
used all features and was trained using a flat SVM
while System 2 used only the best feature combi-
nations. In our preliminary experiments, different
language pairs had different best feature combina-
tions (showed in Table 2). In System 3 we per-
formed a majority voting strategy to combine the
results of different algorithm (i.e. MaxEnt, SVM,
liblinear) to further improve performance. System
4 is a backup system that used only the training set
in SemEval 2012 to explore the influence of the dif-
ferent size of train set. Based on the analysis of the
preliminary results on development set, we also find
that the misclassification mainly occur between the
class of backward and others. So in System 5, we
adopted hierarchical classification technique to filter
out backward class in the first level using a binary
classifier and then conducted multi-class classifica-
tion among the remaining three classes.
</bodyText>
<page confidence="0.995873">
121
</page>
<bodyText confidence="0.999970875">
We used a linear SVM with the trade-off parame-
ter C=1000 (also in liblinear). The parameters in SS
are set as below: the dimension of sematic space is
100, the weight of missing words is 100 and the reg-
ularization factor is 0.01. In the hierarchical classifi-
cation, we use the liblinear (Fan et al., 2008) to train
a binary classifier and SVM for a multi-class classi-
fier with the same parameters in other Systems.
</bodyText>
<sectionHeader confidence="0.99829" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.999958">
Table 2 lists the final results of our five systems on
the test samples in terms of four language pairs. The
best feature set combinations for different language
pairs are also shown. The last two rows list the re-
sults of the best and runner-up team among six par-
ticipants, which is released by the organizers.
From this table, we have some interesting find-
ings.
Firstly, the feature types BC and SD appear in all
best feature combinations. This indicates that the
length and sentence difference information are good
and effective label indicators.
Secondly, based on the comparison between Sys-
tem 1 and System 2, we find that the behavior of the
best feature sets of different language pairs on test
and development datasets is quite different. Specif-
ically, the best feature set performs better on FRA-
ENG and DEU-ENG data sets than the full feature
set. However, the full feature set performs the best
on SPA-ENG and ITA-ENG data sets. The reason
may be the different distribution properties of test
and development data sets.
Thirdly, although the only difference between
System 2 and System 4 is the size of training sam-
ples, System 4 trained on a small number of training
instances even makes a 1.6% improvement in accu-
racy over System 2 on DEU-ENG data set. This
is beyond our expectation and it indicates that the
CLTE may not be sensitive to the size of data set.
Fourthly, by adopting a majority voting scheme,
System 3 achieves the best results on two data sets
among five systems and obtains 45.8% accuracy on
FRA-ENG which is the best result among all partic-
ipants. This indicates the majority voting strategy is
a effective way to boost the performance.
Fifthly, System 5 which adopts hierarchical clas-
sification technique fails to make further improve-
ment. But it still outperforms the runner-up system
in this task on FRA-ENG and DEU-ENG. We spec-
ulate that the failure of System 5 may be caused by
the errors sensitive to hierarchical structure in hier-
archical classification.
In general, our approaches obtained very good
results on all the language pairs. On FRA-ENG
and DEU-ENG, we achieved the best results among
the 16 systems with the accuracy 45.8% and 45.3%
respectively and largely outperformed the runner-
up. The results on SPA-ENG and ITA-ENG were
also promising, achieving the second and third place
among the 16 systems.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999852">
We have proposed several effectively features con-
sisting of sentence semantic similarity and sentence
difference, which work together with other features
presented by the previous work to solve the cross-
lingual textual entailment problem. With the aid
of machine translation, we can handle the cross-
linguality. We submitted five systems on each lan-
guage pair and obtained the best result on two data
sets, i.e., FRA-ENG and DEU-ENG, and ranked the
2nd and the 3rd on other two language pairs respec-
tively. Interestingly, we find some simple feature
types like BC and SD are good class indicators and
can be easily acquired. In future work, we will in-
vestigate the discriminating power of different fea-
ture types in the CLTE task on different languages.
</bodyText>
<sectionHeader confidence="0.995135" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997414">
The authors would like to thank the organizers and
reviewers for this interesting task and their helpful
suggestions and comments, which improves the fi-
nal version of this paper. This research is supported
by grants from National Natural Science Foundation
of China (No.60903093), Shanghai Pujiang Talent
Program (No.09PJ1404500), Doctoral Fund of Min-
istry of Education of China (No. 20090076120029)
and Shanghai Knowledge Service Platform Project
(No. ZF1213).
</bodyText>
<sectionHeader confidence="0.979639" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.621811">
Julio Javier Castillo. 2011. A wordnet-based seman-
tic approach to textual entailment and cross-lingual
</bodyText>
<page confidence="0.987317">
122
</page>
<table confidence="0.999788">
System SPA-ENG ITA-ENG FRA-ENG DEU-ENG
1 0.428 0.426 0.438 0.422
2 0.404 0.420 0.450 0.436
3 0.408 0.426 0.458 0.432
4 0.422 0.416 0.436 0.452
5 0.392 0.402 0.442 0.426
Best BC+STS+SS BC+SD+SS SD+BC+STS BC+STS+SS
feature set +GR+SD +GR+BS +BS+SD
Best 0.434 0.454 0.458 0.452
runner-up 0.428 0.432 0.426 0.414
</table>
<tableCaption confidence="0.999578">
Table 2: The accuracy results of our systems on different language pairs released by the organizer.
</tableCaption>
<reference confidence="0.998413486111111">
textual entailment. International Journal of Machine
Learning and Cybernetics, 2(3):177–189.
Ido Dagan and Oren Glickman. 2004. Probabilistic tex-
tual entailment: Generic applied modeling of language
variability. In Proceedings of the PASCAL Workshop
on Learning Methodsfor Text Understanding and Min-
ing.
Miquel Espl`a-Gomis, Felipe S´anchez-Martinez, and
Mikel L. Forcada. 2012. Ualacant: Using online ma-
chine translation for cross-lingual textual entailment.
In Proceedings of the Sixth International Workshop on
Semantic Evaluation (SemEval 2012), pages 472–476,
Montr´eal, Canada, 7-8 June.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. Liblinear: A library
for large linear classification. The Journal ofMachine
Learning Research, 9:1871–1874.
Weiwei Guo and Mona Diab. 2012. Modeling sentences
in the latent space. In Proceedings of the 50th Annual
Meeting of the Associationfor Computational Linguis-
tics.
Sanda Harabagiu and Andrew Hickl. 2006. Methods for
using textual entailment in open-domain question an-
swering. In Proceedings ofthe 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Associationfor Computational Linguis-
tics, pages 905–912, Sydney, Australia, July.
Sergio Jimenez, Claudia Becerra, and Alexander Gel-
bukh. 2012. Soft cardinality+ ml: Learning adaptive
similarity functions for cross-lingual textual entail-
ment. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012).
Elena Lloret, Oscar Ferr´andez, Rafael Munoz, and
Manuel Palomar. 2008. A text summarization ap-
proach under the influence of textual entailment. In
Proceedings of the 5th International Workshop on
Natural Language Processing and Cognitive Science
(NLPCS 2008), pages 22–31.
Tim Loughran and Bill McDonald. 2011. When is a
liability not a liability? textual analysis, dictionaries,
and 10-ks. The Journal ofFinance, 66(1):35–65.
Prodromos Malakasiotis and Ion Androutsopoulos.
2007. Learning textual entailment using svms and
string similarity measures. In Proceedings of the ACL-
PASCAL Workshop on Textual Entailment and Para-
phrasing, pages 42–47.
Prodromos Malakasiotis. 2009. Paraphrase recognition
using machine learning to combine similarity mea-
sures. In Proceedings of the ACL-IJCNLP 2009 Stu-
dent Research Workshop, pages 27–35.
Yashar Mehdad, Alessandro Moschitti, and Fabio Mas-
simo Zanzotto. 2010a. Syntactic/semantic structures
for textual entailment recognition. In Human Lan-
guage Technologies: The 2010 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 1020–1028.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010b. Towards cross-lingual textual entailment. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 321–
324, Los Angeles, California, June.
Fandong Meng, Hao Xiong, and Qun Liu. 2012. Ict:
A translation based method for cross-lingual textual
entailment. In Proceedings of the Sixth International
Workshop on Semantic Evaluation (SemEval 2012),
pages 715–720, Montr´eal, Canada, 7-8 June.
M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and
D. Giampiccolo. 2013. Semeval-2013 Task 8: Cross-
lingual Textual Entailment for Content Synchroniza-
tion. In Proceedings of the 7th International Workshop
on Semantic Evaluation (SemEval 2013).
</reference>
<bodyText confidence="0.608342">
William E Winkler et al. 1999. The state of record link-
age and current research problems.
</bodyText>
<page confidence="0.998622">
123
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.062402">
<title confidence="0.9900365">ECNUCS: Recognizing Cross-lingual Textual Entailment Using Multiple Text Similarity and Text Difference Measures</title>
<author confidence="0.993966">Jiang</author>
<affiliation confidence="0.990468666666667">Department of Science and East China Normal</affiliation>
<address confidence="0.798172">Shanghai,</address>
<email confidence="0.890895">51121201042@ecnu.cn</email>
<affiliation confidence="0.988609666666667">Department of Science and East China Normal</affiliation>
<address confidence="0.778433">Shanghai,</address>
<email confidence="0.983123">mlan@cs.ecnu.edu.cn</email>
<author confidence="0.3283795">Zheng-Yu Baidu</author>
<affiliation confidence="0.590771">Beijing,</affiliation>
<email confidence="0.999174">niuzhengyu@baidu.com</email>
<abstract confidence="0.99616216">This paper presents our approach used for cross-lingual textual entailment task (task 8) organized within SemEval 2013. Crosslingual textual entailment (CLTE) tries to detect the entailment relationship between two text fragments in different languages. We solved this problem in three steps. Firstly, we use a off-the-shelf machine translation (MT) tool to convert the two input texts into the same language. Then after performing a text preprocessing, we extract multiple feature types with respect to surface text and grammar. We also propose novel feature types regarding to sentence difference and semantic similarity based on our observations in the preliminary experiments. Finally, we adopt a multiclass SVM algorithm for classification. The results on the cross-lingual data collections provided by SemEval 2013 show that (1) we can build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>textual entailment</author>
</authors>
<journal>International Journal of Machine Learning and Cybernetics,</journal>
<volume>2</volume>
<issue>3</issue>
<marker>entailment, </marker>
<rawString>textual entailment. International Journal of Machine Learning and Cybernetics, 2(3):177–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic textual entailment: Generic applied modeling of language variability.</title>
<date>2004</date>
<booktitle>In Proceedings of the PASCAL Workshop on Learning Methodsfor Text Understanding and Mining.</booktitle>
<contexts>
<context position="1798" citStr="Dagan and Glickman, 2004" startWordPosition="253" endWordPosition="256">ication. The results on the cross-lingual data collections provided by SemEval 2013 show that (1) we can build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG. 1 Introduction The Cross-lingual Textual Entailment (CLTE) task in SemEval 2013 consists in detecting the entailment relationship between two topic-related text fragments (usually called T(ext) and H(ypothesis)) in different languages, which is a cross-lingual extension of TE task in (Dagan and Glickman, 2004). We say T entails H if the meaning of H can be inferred from the meaning of T. Mehdad et al. (2010b) firstly proposed this problem within a new challenging application scenario, i.e., content synchronization. In consideration of the directionality, the task needs to assign one of the following entailment judgments to a pair of sentences (1) forward: unidirectional entailment from T to H; (2) backward: unidirectional entailment from H to T; (3) bidirectional: the two fragments entail each other (i.e., semantic equivalence); (4) non-entailment: there is no entailment between T and H. During the</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. 2004. Probabilistic textual entailment: Generic applied modeling of language variability. In Proceedings of the PASCAL Workshop on Learning Methodsfor Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miquel Espl`a-Gomis</author>
<author>Felipe S´anchez-Martinez</author>
<author>Mikel L Forcada</author>
</authors>
<title>Ualacant: Using online machine translation for cross-lingual textual entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>472--476</pages>
<location>Montr´eal,</location>
<marker>Espl`a-Gomis, S´anchez-Martinez, Forcada, 2012</marker>
<rawString>Miquel Espl`a-Gomis, Felipe S´anchez-Martinez, and Mikel L. Forcada. 2012. Ualacant: Using online machine translation for cross-lingual textual entailment. In Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), pages 472–476, Montr´eal, Canada, 7-8 June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>Xiang-Rui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal ofMachine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="16960" citStr="Fan et al., 2008" startWordPosition="2797" endWordPosition="2800"> find that the misclassification mainly occur between the class of backward and others. So in System 5, we adopted hierarchical classification technique to filter out backward class in the first level using a binary classifier and then conducted multi-class classification among the remaining three classes. 121 We used a linear SVM with the trade-off parameter C=1000 (also in liblinear). The parameters in SS are set as below: the dimension of sematic space is 100, the weight of missing words is 100 and the regularization factor is 0.01. In the hierarchical classification, we use the liblinear (Fan et al., 2008) to train a binary classifier and SVM for a multi-class classifier with the same parameters in other Systems. 4 Results and discussion Table 2 lists the final results of our five systems on the test samples in terms of four language pairs. The best feature set combinations for different language pairs are also shown. The last two rows list the results of the best and runner-up team among six participants, which is released by the organizers. From this table, we have some interesting findings. Firstly, the feature types BC and SD appear in all best feature combinations. This indicates that the </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal ofMachine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Modeling sentences in the latent space.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics.</booktitle>
<contexts>
<context position="7610" citStr="Guo and Diab, 2012" startWordPosition="1240" endWordPosition="1243">e is a measure of similarity between two strings at the word level. In total, we can get 11 features in this feature set. 2.3 Sematic Similarity features Almost every previous work used the surface texts or exploited the meanings of words in the dictionary to calculate the similarity of two sentences rather than the actual meaning in the sentence. In this feature set (SS), we introduce a latent model to model the semantic representations of sentences since latent models are capable of capturing the contextual meaning of words in sentences. We used weighted textual matrix factorization (WTMF) (Guo and Diab, 2012) to model the semantics of the sentences. The model factorizes the original term-sentence matrix X into two matrices such that Xi,j Pt� PT∗,iQ∗,j, where P∗,i is a latent semantics WOverlap(A, B) = Ewi∈A∩B Wwi , Ewi∈A Wwi where Wwi is the weight of word wi. E i=1 119 vector profile for word wi and Q∗,j is the vector profile that represents the sentence sj. The weight matrix W is introduced in the optimization process in order to model the missing words at the right level of emphasis. We propose three similarity measures according to different strategies: wtw: word-to-word based similarity defin</context>
</contexts>
<marker>Guo, Diab, 2012</marker>
<rawString>Weiwei Guo and Mona Diab. 2012. Modeling sentences in the latent space. In Proceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Andrew Hickl</author>
</authors>
<title>Methods for using textual entailment in open-domain question answering.</title>
<date>2006</date>
<booktitle>In Proceedings ofthe 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Associationfor Computational Linguistics,</booktitle>
<pages>905--912</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="2808" citStr="Harabagiu and Hickl, 2006" startWordPosition="422" endWordPosition="425">T to H; (2) backward: unidirectional entailment from H to T; (3) bidirectional: the two fragments entail each other (i.e., semantic equivalence); (4) non-entailment: there is no entailment between T and H. During the last decades, many researchers and communities have paid a lot of attention to resolve the TE detection (e.g., seven times of the Recognizing Textual Entailment Challenge, i.e., from RTE1 to RET7, have been held) since identifying the relationship between two sentences is at the core of many NLP applications, such as text summarization (Lloret et al., 2008) or question answering (Harabagiu and Hickl, 2006). For example, in text summarization, a redundant sentence should be omitted from the summary if this sentence can be entailed from other expressions in the summary. CLTE extends those tasks with lingual dimensionality, where more than one language is involved. Although it is a relatively new task, a basic solution has been provided in (Mehdad et al., 2010b), which brings the problem back to monolingual scenario using MT to translate H into the language of T. The promising performance indicates the potentialities of such a simple approach which integrates MT and monolingual TE algorithms (Cast</context>
</contexts>
<marker>Harabagiu, Hickl, 2006</marker>
<rawString>Sanda Harabagiu and Andrew Hickl. 2006. Methods for using textual entailment in open-domain question answering. In Proceedings ofthe 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Associationfor Computational Linguistics, pages 905–912, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Soft cardinality+ ml: Learning adaptive similarity functions for cross-lingual textual entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="3440" citStr="Jimenez et al., 2012" startWordPosition="526" endWordPosition="529">e, in text summarization, a redundant sentence should be omitted from the summary if this sentence can be entailed from other expressions in the summary. CLTE extends those tasks with lingual dimensionality, where more than one language is involved. Although it is a relatively new task, a basic solution has been provided in (Mehdad et al., 2010b), which brings the problem back to monolingual scenario using MT to translate H into the language of T. The promising performance indicates the potentialities of such a simple approach which integrates MT and monolingual TE algorithms (Castillo, 2011; Jimenez et al., 2012; Mehdad et al., 2010a). In this work, we regard CLTE as a multiclass classification problem, in which multiple feature types are used in conjunction with a multiclass SVM classifier. Specifically, our approach can be divided into three steps. Firstly, following (Espl`a-Gomis et al., 2012; Meng et al., 2012), we use MT to 118 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 118–123, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics bridge the gap of lan</context>
</contexts>
<marker>Jimenez, Becerra, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez, Claudia Becerra, and Alexander Gelbukh. 2012. Soft cardinality+ ml: Learning adaptive similarity functions for cross-lingual textual entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Lloret</author>
<author>Oscar Ferr´andez</author>
<author>Rafael Munoz</author>
<author>Manuel Palomar</author>
</authors>
<title>A text summarization approach under the influence of textual entailment.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Workshop on Natural Language Processing and Cognitive Science (NLPCS</booktitle>
<pages>22--31</pages>
<marker>Lloret, Ferr´andez, Munoz, Palomar, 2008</marker>
<rawString>Elena Lloret, Oscar Ferr´andez, Rafael Munoz, and Manuel Palomar. 2008. A text summarization approach under the influence of textual entailment. In Proceedings of the 5th International Workshop on Natural Language Processing and Cognitive Science (NLPCS 2008), pages 22–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Loughran</author>
<author>Bill McDonald</author>
</authors>
<title>When is a liability not a liability? textual analysis, dictionaries, and 10-ks. The Journal ofFinance,</title>
<date>2011</date>
<pages>66--1</pages>
<contexts>
<context position="11367" citStr="Loughran and McDonald, 2011" startWordPosition="1867" endWordPosition="1871"> matched words and count the number of unmatched words in each sentence, resulting in 2 features. If one sentence has no unmatched words, we say that this sentence can 2.5 Grammatical Relationship features The grammatical relationship feature type (GR) is designed to capture the grammatical relationship between two sentences. We first replace the words in a sentence with their part-of-speech (POS) tags, then The bias features (BS) are to check the differences between two sentences in certain special aspects, such as polarity and named entity. We use a method based on subjectivity of lexicons (Loughran and McDonald, 2011) to get the polarity of a sentence by simply comparing the numbers of positive and negative words. If the numbers are the same, then we set the feature to 1, otherwise -1. Also, we check whether one sentence entails the other using only the named entity information. We consider four categories of named entities, i.e., person, organization, location, number, which are recognized by using the 3 Experimental Setting We evaluated our approach using the data sets provided in the task 8 of SemEval 2013 (Negri et al., 2013). The data sets consist of a collection of 1500 text fragment pairs (1000 for </context>
</contexts>
<marker>Loughran, McDonald, 2011</marker>
<rawString>Tim Loughran and Bill McDonald. 2011. When is a liability not a liability? textual analysis, dictionaries, and 10-ks. The Journal ofFinance, 66(1):35–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prodromos Malakasiotis</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Learning textual entailment using svms and string similarity measures.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>42--47</pages>
<contexts>
<context position="5977" citStr="Malakasiotis and Androutsopoulos, 2007" startWordPosition="956" endWordPosition="959"> number of non-repeated elements in this set. Once we view the text as a set of words, A − B means the set of words found in A but not in B, A U B means the set of words found in either A or B and AnB means the set of shared words found in both A and B. Given a pair of texts, i.e., &lt;T,H&gt;, which are in different languages, we use MT to translate one of them to make them in the same language. Thus, we can get two pairs of texts, i.e., &lt;Tt,H&gt; and &lt;T,Ht&gt;. We apply the above eight length measures to the two pairs, resulting in a total of 16 features. 2.2 Surface Text Similarity features Following (Malakasiotis and Androutsopoulos, 2007), the surface text similarity (STS) feature set contains nine similarity measures: Jaccard coefficient: It is defined as |A∩B| |A∪B|, where |A n B |and |A U B |are as in the BC. Dice coefficient: Defined as 2 A |+A∩B |,Bj +B Overlap coefficient: This is the ollowing quantity, B| Overlap(A, B) = |AA |. Weighted overlap coefficient: We assign the tf*idf value to each word in the sentence to distinguish the importance of different words. The weighted overlap coefficient is defined as follows: →− Cosine similarity: cos(−�x , �−x·−→y y ) = II−→x H−→y II, where �− x and y are vectorial representatio</context>
</contexts>
<marker>Malakasiotis, Androutsopoulos, 2007</marker>
<rawString>Prodromos Malakasiotis and Ion Androutsopoulos. 2007. Learning textual entailment using svms and string similarity measures. In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prodromos Malakasiotis</author>
</authors>
<title>Paraphrase recognition using machine learning to combine similarity measures.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Student Research Workshop,</booktitle>
<pages>27--35</pages>
<contexts>
<context position="4325" citStr="Malakasiotis, 2009" startWordPosition="664" endWordPosition="666">l`a-Gomis et al., 2012; Meng et al., 2012), we use MT to 118 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 118–123, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics bridge the gap of language differences between T and H. Secondly, we perform a preprocessing procedure to maximize the similarity of the two text fragments so as to make a more accurate calculation of surface text similarity measures. Besides several features described in previous work (Malakasiotis, 2009; Espl`a-Gomis et al., 2012), we also propose several novel features regarding to sentence difference and semantic similarity. Finally, all these features are combined together and serves as input of a multiclass SVM classifier. After analyzing of the results obtained in preliminary experiments, we also cast this problem as a hierarchical classification problem. The remainder of the paper is organized as follows. Section 2 describes different features used in our systems. Section 3 presents the system settings including the datasets and preprocessing. Section 4 shows the results of different s</context>
</contexts>
<marker>Malakasiotis, 2009</marker>
<rawString>Prodromos Malakasiotis. 2009. Paraphrase recognition using machine learning to combine similarity measures. In Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 27–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Alessandro Moschitti</author>
<author>Fabio Massimo Zanzotto</author>
</authors>
<title>Syntactic/semantic structures for textual entailment recognition.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1020--1028</pages>
<contexts>
<context position="1897" citStr="Mehdad et al. (2010" startWordPosition="276" endWordPosition="279">build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG. 1 Introduction The Cross-lingual Textual Entailment (CLTE) task in SemEval 2013 consists in detecting the entailment relationship between two topic-related text fragments (usually called T(ext) and H(ypothesis)) in different languages, which is a cross-lingual extension of TE task in (Dagan and Glickman, 2004). We say T entails H if the meaning of H can be inferred from the meaning of T. Mehdad et al. (2010b) firstly proposed this problem within a new challenging application scenario, i.e., content synchronization. In consideration of the directionality, the task needs to assign one of the following entailment judgments to a pair of sentences (1) forward: unidirectional entailment from T to H; (2) backward: unidirectional entailment from H to T; (3) bidirectional: the two fragments entail each other (i.e., semantic equivalence); (4) non-entailment: there is no entailment between T and H. During the last decades, many researchers and communities have paid a lot of attention to resolve the TE dete</context>
<context position="3166" citStr="Mehdad et al., 2010" startWordPosition="482" endWordPosition="485">l Entailment Challenge, i.e., from RTE1 to RET7, have been held) since identifying the relationship between two sentences is at the core of many NLP applications, such as text summarization (Lloret et al., 2008) or question answering (Harabagiu and Hickl, 2006). For example, in text summarization, a redundant sentence should be omitted from the summary if this sentence can be entailed from other expressions in the summary. CLTE extends those tasks with lingual dimensionality, where more than one language is involved. Although it is a relatively new task, a basic solution has been provided in (Mehdad et al., 2010b), which brings the problem back to monolingual scenario using MT to translate H into the language of T. The promising performance indicates the potentialities of such a simple approach which integrates MT and monolingual TE algorithms (Castillo, 2011; Jimenez et al., 2012; Mehdad et al., 2010a). In this work, we regard CLTE as a multiclass classification problem, in which multiple feature types are used in conjunction with a multiclass SVM classifier. Specifically, our approach can be divided into three steps. Firstly, following (Espl`a-Gomis et al., 2012; Meng et al., 2012), we use MT to 11</context>
</contexts>
<marker>Mehdad, Moschitti, Zanzotto, 2010</marker>
<rawString>Yashar Mehdad, Alessandro Moschitti, and Fabio Massimo Zanzotto. 2010a. Syntactic/semantic structures for textual entailment recognition. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 1020–1028.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Towards cross-lingual textual entailment.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>321--324</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="1897" citStr="Mehdad et al. (2010" startWordPosition="276" endWordPosition="279">build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG. 1 Introduction The Cross-lingual Textual Entailment (CLTE) task in SemEval 2013 consists in detecting the entailment relationship between two topic-related text fragments (usually called T(ext) and H(ypothesis)) in different languages, which is a cross-lingual extension of TE task in (Dagan and Glickman, 2004). We say T entails H if the meaning of H can be inferred from the meaning of T. Mehdad et al. (2010b) firstly proposed this problem within a new challenging application scenario, i.e., content synchronization. In consideration of the directionality, the task needs to assign one of the following entailment judgments to a pair of sentences (1) forward: unidirectional entailment from T to H; (2) backward: unidirectional entailment from H to T; (3) bidirectional: the two fragments entail each other (i.e., semantic equivalence); (4) non-entailment: there is no entailment between T and H. During the last decades, many researchers and communities have paid a lot of attention to resolve the TE dete</context>
<context position="3166" citStr="Mehdad et al., 2010" startWordPosition="482" endWordPosition="485">l Entailment Challenge, i.e., from RTE1 to RET7, have been held) since identifying the relationship between two sentences is at the core of many NLP applications, such as text summarization (Lloret et al., 2008) or question answering (Harabagiu and Hickl, 2006). For example, in text summarization, a redundant sentence should be omitted from the summary if this sentence can be entailed from other expressions in the summary. CLTE extends those tasks with lingual dimensionality, where more than one language is involved. Although it is a relatively new task, a basic solution has been provided in (Mehdad et al., 2010b), which brings the problem back to monolingual scenario using MT to translate H into the language of T. The promising performance indicates the potentialities of such a simple approach which integrates MT and monolingual TE algorithms (Castillo, 2011; Jimenez et al., 2012; Mehdad et al., 2010a). In this work, we regard CLTE as a multiclass classification problem, in which multiple feature types are used in conjunction with a multiclass SVM classifier. Specifically, our approach can be divided into three steps. Firstly, following (Espl`a-Gomis et al., 2012; Meng et al., 2012), we use MT to 11</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2010b. Towards cross-lingual textual entailment. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 321– 324, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fandong Meng</author>
<author>Hao Xiong</author>
<author>Qun Liu</author>
</authors>
<title>Ict: A translation based method for cross-lingual textual entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>715--720</pages>
<location>Montr´eal,</location>
<contexts>
<context position="3749" citStr="Meng et al., 2012" startWordPosition="576" endWordPosition="579">en provided in (Mehdad et al., 2010b), which brings the problem back to monolingual scenario using MT to translate H into the language of T. The promising performance indicates the potentialities of such a simple approach which integrates MT and monolingual TE algorithms (Castillo, 2011; Jimenez et al., 2012; Mehdad et al., 2010a). In this work, we regard CLTE as a multiclass classification problem, in which multiple feature types are used in conjunction with a multiclass SVM classifier. Specifically, our approach can be divided into three steps. Firstly, following (Espl`a-Gomis et al., 2012; Meng et al., 2012), we use MT to 118 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 118–123, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics bridge the gap of language differences between T and H. Secondly, we perform a preprocessing procedure to maximize the similarity of the two text fragments so as to make a more accurate calculation of surface text similarity measures. Besides several features described in previous work (Malakasiotis, 2009; Espl`a-Gomis et al., 2</context>
</contexts>
<marker>Meng, Xiong, Liu, 2012</marker>
<rawString>Fandong Meng, Hao Xiong, and Qun Liu. 2012. Ict: A translation based method for cross-lingual textual entailment. In Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), pages 715–720, Montr´eal, Canada, 7-8 June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2013 Task 8: Crosslingual Textual Entailment for Content Synchronization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="11889" citStr="Negri et al., 2013" startWordPosition="1958" endWordPosition="1962">and named entity. We use a method based on subjectivity of lexicons (Loughran and McDonald, 2011) to get the polarity of a sentence by simply comparing the numbers of positive and negative words. If the numbers are the same, then we set the feature to 1, otherwise -1. Also, we check whether one sentence entails the other using only the named entity information. We consider four categories of named entities, i.e., person, organization, location, number, which are recognized by using the 3 Experimental Setting We evaluated our approach using the data sets provided in the task 8 of SemEval 2013 (Negri et al., 2013). The data sets consist of a collection of 1500 text fragment pairs (1000 for training consisting of training and test set in SemEval 2012 and 500 for test) in each language pair. Four different language pairs are provided: German-English, French-English, Italian-English and Spanish-English. See (Negri et al., 2013) for more detailed descri ption. 3.1 Preprocess We performed the following text preprocessing. Firstly, we employed the state-of-the-art Statistical Machine Translator, i.e., Google translator, to translate each pair of texts &lt;T,H&gt; into &lt;Tt,H&gt; and &lt;T,Ht&gt;, thus they were in the same </context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2013</marker>
<rawString>M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. 2013. Semeval-2013 Task 8: Crosslingual Textual Entailment for Content Synchronization. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>