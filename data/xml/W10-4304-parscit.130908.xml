<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.976811">
Modeling User Satisfaction Transitions in Dialogues from Overall Ratings
</title>
<author confidence="0.90698">
Ryuichiro Higashinakat, Yasuhiro Minamit, Kohji Dohsakat, and Toyomi Megurot
</author>
<affiliation confidence="0.829381">
t NTT Cyber Space Laboratories, NTT Corporation
t NTT Communication Science Laboratories, NTT Corporation
</affiliation>
<email confidence="0.91805">
higashinaka.ryuichiro@lab.ntt.co.jp
{minami,dohsaka,meguro}@cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.997133" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999696346153846">
This paper proposes a novel approach
for predicting user satisfaction transitions
during a dialogue only from the ratings
given to entire dialogues, with the aim
of reducing the cost of creating refer-
ence ratings for utterances/dialogue-acts
that have been necessary in conventional
approaches. In our approach, we first
train hidden Markov models (HMMs) of
dialogue-act sequences associated with
each overall rating. Then, we combine
such rating-related HMMs into a single
HMM to decode a sequence of dialogue-
acts into state sequences representing to
which overall rating each dialogue-act is
most related, which leads to our rating pre-
dictions. Experimental results in two di-
alogue domains show that our approach
can make reasonable predictions; it signif-
icantly outperforms a baseline and nears
the upper bound of a supervised approach
in some evaluation criteria. We also
show that introducing states that represent
dialogue-act sequences that occur com-
monly in all ratings into an HMM signifi-
cantly improves prediction accuracy.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998216">
In recent years, there has been intensive work
on the automatic evaluation of dialogues (Walker
et al., 1997; M¨oller et al., 2008). Automatic
evaluation makes it possible to predict the per-
formance of dialogue systems without the costly
process of performing surveys with human sub-
jects, leading to a rapid improvement cycle for
dialogue systems. It is also useful for detect-
ing problematic situations in an ongoing dialogue
(Walker et al., 2002; Herm et al., 2008; Kim,
2007). In these studies, the typical approach is
to train a prediction model, such as a regression
or classification model, using features represent-
ing the whole or a part of a dialogue together with
human reference labels (e.g., reference ratings).
However, creating such reference labels by hand
can be extremely costly when we want to predict
user satisfaction transitions during a dialogue be-
cause we need to create reference labels after each
utterance/dialogue-act in the training data (Engel-
brecht et al., 2009).
This paper proposes a novel approach for pre-
dicting user satisfaction transitions during a dia-
logue only from the dialogues with overall rat-
ings. The approach makes it possible to avoid
creating reference labels for utterances/dialogue-
acts and only requires a single reference label for
each dialogue. More specifically, we predict the
user satisfaction rating after each dialogue-act in a
dialogue only by using dialogues with dialogue-
level (overall) user satisfaction ratings as train-
ing data. Our basic approach is to train hid-
den Markov models (HMMs) of dialogue-act se-
quences associated with each overall rating and
combine such rating-related HMMs into a single
HMM. We use this combined HMM to decode a
sequence of dialogue-acts by the Viterbi algorithm
(Rabiner, 1990) into state sequences that indicate
from which rating-related HMM each dialogue-act
is most likely to have been generated, leading to
our rating predictions for the dialogue-acts. This
paper experimentally examines the validity of our
approach and explores several model topologies
for possible improvement.
In Section 2, we review related work on auto-
matic evaluation of dialogues. In Section 3, we
describe our approach in detail. In Section 4, we
describe the experiment we performed to verify
our approach and present the results. In Section
5, we summarize and mention future work.
</bodyText>
<sectionHeader confidence="0.999952" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9995696">
Regression models are typically utilized for eval-
uating the quality of an entire dialogue. Most fa-
mously, the PARADISE framework (Walker et al.,
1997) learns from data a linear regression model
that predicts dialogue-level user satisfaction from
various objective characteristics of a dialogue that
concern task success and dialogue costs. This
framework is widely used today and a number of
extensions have been proposed to improve the pre-
diction performance (M¨oller et al., 2008); how-
</bodyText>
<note confidence="0.62258">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 18–27,
The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics
</note>
<page confidence="0.998994">
18
</page>
<bodyText confidence="0.999756531914894">
ever, it is not aimed at predicting user satisfaction
transitions.
Classification models are widely employed to
detect problematic situations in an ongoing dia-
logue. Walker et al. (2002) developed the Prob-
lematic Dialogue Predictor for the “How May I
Help You” system (Gorin et al., 1997) to robustly
transfer problematic calls to human operators in
call routing tasks. They derive speech recogni-
tion, language understanding, and dialogue man-
agement features from the first few turns of a dia-
logue and apply a decision tree classifier to detect
problematic calls. For a similar task, Hirschberg
et al. (2004) and Herm et al. (2008) used prosodic
and emotional features. Kim (2007) recently pro-
posed an approach for online call quality monitor-
ing so that problematic calls can be transferred to
human operators as quickly as possible rather than
waiting for the first few turns.
N-grams and HMM-based approaches have also
been actively studied. Hara et al. (2010) proposed
predicting the most likely user satisfaction level of
a dialogue by using N-grams of dialogues for each
satisfaction level in the music navigation domain.
Isomura et al. (2009) used HMMs to evaluate the
naturalness of a dialogue in their interview system.
They trained HMMs that model dialogue-act se-
quences between human subjects and used them to
evaluate human-machine dialogues by the output
probabilities of the HMMs. Recently, there have
been approaches to predict user satisfaction tran-
sitions by evaluating the quality of individual ut-
terances in a dialogue. For example, Engelbrecht
et al. (2009) predicted user satisfaction ratings af-
ter each user utterance by HMMs trained from
utterance-level features and utterance-level refer-
ence ratings.
The problem with these approaches is that they
require a lot of training data, especially when we
want to predict the quality of smaller units such
as utterances. Our aim is to reduce such cost.
Our work is similar to Engelbrecht’s work (Engel-
brecht et al., 2009) in that we use HMMs to predict
user satisfaction transitions during a dialogue but
different in that we only use dialogue-level ratings
to model dialogue-act-level user satisfaction tran-
sitions.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.984195196428572">
We aim to predict user satisfaction transitions only
from dialogues with overall ratings. More for-
mally, given a dialogue di of a set of dialogues
D (= {dl ...dN}), we want to predict the user
satisfaction rating after each dialogue-act in di,
namely, r&apos;(da(di7 1)) ...r&apos;(da(di7 mi)), using D
with their dialogue-level ratings r(di) ...r(dN).
Figure 1: SHMMs connected ergodically. In the
figure, an oval marked with speaker1/speaker2
indicates a state that emits speaker1/speaker2’s
dialogue-acts. Arrows denote transitions and
numbers before speaker1/speaker2 are state IDs.
Boxes group together the states related to a partic-
ular overall rating.
Here, da(di7 l) denotes the l-th dialogue-act in di,
N the total number of dialogues, and mi the total
number of dialogue-acts in di.
Our basic idea is to train HMMs representing
dialogue-act sequences of dialogues for each over-
all rating and combine these rating-related HMMs
into a single HMM that can assign ratings for
dialogue-acts by estimating from which HMM
each dialogue-act has most likely to have been
generated by the Viterbi decoding. We use HMMs
because they can deal with sequences that evolve
over time and have been successfully utilized to
model and evaluate dialogue-act sequences (Shi-
rai, 1996; Isomura et al., 2009; Engelbrecht et
al., 2009). The generative feature of an HMM is
also useful when we want to build a probabilis-
tic dialogue manager that produces the most likely
dialogue-act sequences (Hori et al., 2008) or that
aims to maximize a reward function in partially
observable Markov decision processes (Williams
and Young, 2007; Minami et al., 2009).
When there are K levels of user satisfaction as
overall ratings, we create K HMMs each of which
is trained using the dialogue-act sequences in dia-
logues Dk ⊂ D, where Dk = {∀di7 |r(di) = k}.
We use the EM-algorithm to train HMMs. Here,
we assume that each HMM has two states, each
of which emits dialogue-acts of one of the con-
versational participants. This type of HMM is
called a speaker HMM (SHMM) and has been
successfully utilized to model two-party conversa-
tion (Meguro et al., 2009).
As an illustrative example, Fig. 1 shows two
SHMMs for ratings 1 and 2 that are connected
ergodically. We can simply use these connected
SHMMs (namely, states 1, 2, 3, and 4) to decode a
sequence of dialogue-acts into state sequences and
thereby obtain rating predictions. For example, if
the optimal state sequence obtained by the Viterbi
decoding is {4, 2, 1, 3, 2}, we can convert it into
ratings &lt;2, 1, 1, 2, 1&gt; using the ratings associated
with the states.
</bodyText>
<figure confidence="0.955863075">
Speaker HMM for Rating 1
1:speaker1 2:speaker2
Speaker HMM for Rating 2
3:speaker1 4:speaker2
19
Speaker HMM for Rating 1
1:speaker1 2:speaker2
Speaker HMM for All Ratings
5:speaker1 6:speaker2
M1...MK become
less likely to
output common
sequences
Step 1
Step 2
Rating
1
Train
Retrain
M0 M1
M1
M1+0
Rating
k
Train
Retrain
M0
Mk
Mk+0
Rating
K
Mk
Train
Retrain
M0
MK
MK+0
MK
3:speaker1 4:speaker2
Speaker HMM for Rating 2
</figure>
<figureCaption confidence="0.999836">
Figure 2: SHMMs with an additional SHMM
trained from all dialogues.
</figureCaption>
<bodyText confidence="0.997339214285714">
Introducing Common States: The simple er-
godic model may not be sufficient for appropri-
ately assigning ratings to input dialogue-act se-
quences because it is often the case that there
are dialogue-act sequences, such as greetings and
question-answer pairs, that commonly occur in ev-
ery dialogue. If we forcefully assign a rating for
such dialogue-act sequences, it may result in de-
grading the prediction accuracy. Therefore, in
addition to the simple ergodic model, we intro-
duce another SHMM that represents dialogue-act
sequences of dialogues for all ratings (see Fig.
2). This additional SHMM models dialogue-act
sequences that occur commonly in all dialogues
and it can simply be trained using all dialogues.
Hence, we call the states in this SHMM common
states. When this SHMM is added to the ergodic
model, it may be possible to reduce the possibil-
ity of our having to forcefully assign inappropriate
scores to common dialogue-act sequences. In this
model, when the optimal state sequence is {1, 4,
5, 6, 2}, the predicted ratings become &lt;1, 2, 0, 0,
1&gt;. Here, we assume that the SHMM for all rat-
ings corresponds to rating 0, which is reasonable
because common dialogue-acts should not affect
ratings. The obtained ratings can also be inter-
preted as &lt;1, 2, 2, 2, 1&gt; when we assume that
the rating of a dialogue-act is taken over from the
previous turn.
Using Concatenated Training: We have so far
presented two model topologies, one with K
SHMMs connected ergodically and the other with
K + 1 SHMMs having an additional SHMM rep-
resenting all ratings. However, we still have a
problem; that is, we need to find optimal transi-
tion probabilities between the SHMMs of different
ratings. Our solution is to use concatenated train-
ing (Lee, 1989). The procedure for concatenated
training is illustrated in Fig. 3 and has the follow-
ing three steps.
step 1 Train an SHMM Mk (Mk E M, 1 &lt;
k &lt; K) using dialogues Dk, where Dk =
</bodyText>
<figure confidence="0.991496357142857">
Copy
All
Ratings
Train +
M0
Concatenate
Step 3
AVG
M0
Mconcat
If the fitting has
converged for
all Mk+0
END
Step 2’
Transition probabilities
of M0 are redistributed
between M0 and Mk
M1 Mk MK
Split Mconcat into
pairs again and
retrain Mk+0
M1+0
Mk+0
MK+0
M0 M1
M0 Mk
M0 MK
</figure>
<figureCaption confidence="0.999165">
Figure 3: Three steps to combine SHMMs using
concatenated training.
</figureCaption>
<bodyText confidence="0.995523764705882">
{bdijr(di) = k}, and an SHMM M0 using
all dialogues; i.e., D. Here, K means the
maximum level of user satisfaction and r(di)
the rating assigned to di.
step 2 Connect each Mk E M with a copy of
M0 using equal initial and transition proba-
bilities (we call this connected model Mk+0)
and retrain Mk+0 with bdi E Dk, where
r(di) = k.
step 3 Merge all models Mk+0 (1 &lt; k &lt; K) to
produce one concatenated HMM (M...t).
Here, the output probabilities of the copies
of M0 are averaged over K when all models
are merged to create a combined model. If
the fitting of all Mk+0 models has converged
against the training data, exit this procedure;
otherwise, go to step 2 by connecting a copy
of M0 and Mk for all k. Here, the transi-
tion probabilities from M0 to Ml(l =� k) are
summed and equally distributed between the
copied M0’s self-loop and transitions to the
states in Mk.
In concatenated training, the transition and out-
put probabilities can be optimized between M0
and Mk, meaning that the output probabilities
of dialogue-act sequences that are common and
also found in Mk can be moved from Mk to
M0. This makes the distribution of Mk sharp (not
broad/uniform), making it likely to output only
the dialogue-acts specific to a rating k. As re-
gards M0, its distribution of output probabilities
can also be sharpened for dialogue-acts that oc-
cur commonly in all ratings. This sharpening of
distributions is likely to be helpful in assigning
</bodyText>
<page confidence="0.967673">
20
</page>
<bodyText confidence="0.99979225">
appropriate ratings to dialogue-act sequences. In
the next section, we experimentally examine how
these proposed HMMs perform in modeling and
predicting user satisfaction transitions in dialogue.
</bodyText>
<sectionHeader confidence="0.997887" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999964833333333">
To verify our approach, we first prepared dialogue
data. Then, we trained our HMMs and compared
them with a random baseline and an upper bound
that uses a supervised approach; that is, an HMM
is trained using reference labels on the dialogue-
act level.
</bodyText>
<subsectionHeader confidence="0.998776">
4.1 Dialogue Data
</subsectionHeader>
<bodyText confidence="0.9999895">
We used dialogues in two domains; the animal
discussion (AD) domain and the attentive listen-
ing (AL) domain. All dialogues are in Japanese.
In both domains, the data we used were text dia-
logues. We did not use spoken dialogue data be-
cause we wanted to avoid particular problems of
voice, such as filled pauses and overlaps, although
we aim to deal with spoken dialogue in the future.
</bodyText>
<subsectionHeader confidence="0.83429">
4.1.1 Animal Discussion
</subsectionHeader>
<bodyText confidence="0.99986353125">
We used the dialogue data in the AD domain that
we previously collected (Higashinaka et al., 2008).
In this domain, the system and user talk about likes
and dislikes about animals via a text chat inter-
face. The data consist of 1000 dialogues between
a dialogue system and 50 human users. Each
user conversed with the system 20 times, includ-
ing two example dialogues at the beginning. All
user/system utterances have been annotated with
dialogue-acts. There are 29 dialogue-act types in-
cluding those related to self-disclosure, question,
response, and greetings. For example, a dialogue-
act DISC-P denotes one’s self-disclosure about a
proposition P. Here, P is either like(X,A) or
dislike(X,A) where X is a conversational par-
ticipant and A a certain animal. DISC-R denotes
one’s self-disclosure of a reason for a proposition.
See (Higashinaka et al., 2008) for the details of the
dialogue-acts.
For our experiment, we created two subsets of
the data. We first extracted 180 dialogues by
taking all 18 non-example dialogues for the ini-
tial ten users sorted by user ID (AD-SUB1; 4147
user dialogue-acts and 6628 system dialogue-
acts). Then, from AD-SUB1, we randomly ex-
tracted nine dialogues per user to form another
subset of 90 dialogues (AD-SUB2; 2050 user
dialogue-acts and 3290 system dialogue-acts). An
annotator, who was not one of the authors, la-
beled AD-SUB1 with dialogue-level user satis-
faction ratings and AD-SUB2 with utterance-level
ratings. More specifically, each dialogue/utterance
</bodyText>
<table confidence="0.980424583333333">
Utterance (dialogue-acts) Sm Cl Wi
SYS Do you like rabbits? (DA: Q-DISC-P) 6 6 6
USR I like rabbits. They are cute.
(DA: DISC-P, DISC-R)
SYS Indeed they are cute. (DA: REPEAT) 6 6 6
SYS Tell me why you like rabbits. 6 5 6
(DA: Q-DISC-R-OTHER)
USR I like them because they are small and
warm. (DA: DISC-P-R)
SYS You like them because they are warm. 7 5 7
(DA: REPEAT)
Overall rating for the dialogue 7 5 6
</table>
<figureCaption confidence="0.956247">
Figure 4: Excerpt of a dialogue with utterance-
</figureCaption>
<bodyText confidence="0.9461192">
level user satisfaction ratings for smoothness
(Sm), closeness (Cl), and willingness (Wi) in the
AD domain. SYS and USR denote system and
user, respectively. The dialogue was translated by
the authors.
was given three different user satisfaction rat-
ings related to “Smoothness of the conversation”,
“Closeness perceived by the user towards the sys-
tem”, and “Willingness to continue the conversa-
tion”. The ratings ranged from 1 to 7, where 1
is the worst and 7 the best (see Fig. 4 for exam-
ples of utterance-level and overall ratings given by
the annotator for an excerpt of a dialogue). In a
manner similar to (Evanini et al., 2008), we used a
third-person’s user satisfaction rating for the sake
of consistency.
For utterance-level ratings, the annotator care-
fully read each utterance and gave ratings after
each system utterance according to how she would
have felt after receiving each system utterance if
she had been the user in the dialogue. To make
the situation more realistic, she was not allowed
to look down at the dialogue after the current ut-
terance. At the beginning of a dialogue, the rat-
ings always started from four (neutral). When the
annotator gave dialogue-level ratings, she looked
through the entire dialogue and rated its quality
(smoothness, closeness, and willingness) accord-
ing to how she would have felt after having had
the dialogue in question.
</bodyText>
<subsectionHeader confidence="0.794708">
4.1.2 Attentive Listening
</subsectionHeader>
<bodyText confidence="0.999997307692308">
We collected human-human listening-oriented di-
alogues in a manner similar to (Meguro et al.,
2009). In this AL domain, a listener attentively
listens to the other in order to satisfy the speaker’s
desire to speak and to make himself/herself heard.
We collected such listening-oriented dialogues us-
ing a website where users taking the roles of lis-
teners and speakers were matched up to have con-
versations. There were ten listeners who always
stayed at the website and 37 speakers who could
talk to them anytime the listeners were available.
They were all paid for their participation. A con-
versation was done through a text-chat interface.
</bodyText>
<page confidence="0.994681">
21
</page>
<bodyText confidence="0.999982651162791">
The use of facial and other non-linguistic expres-
sions were not allowed for analysis purposes. The
participants were instructed to end the conversa-
tion approximately after ten minutes. Within a
three-week period, each speaker was instructed to
have at least two conversations a day, resulting in
our collecting 1260 listening-oriented dialogues.
Two independent annotators labeled each utter-
ance with 40 dialogue-act types, including those
related to self-disclosure, question, internal argu-
ment, sympathy, and information giving. The
inter-annotator agreement was reasonable, with
0.57 in Cohen’s κ. Although we cannot describe
the full details of our dialogue-acts for lack of
space, we have dialogue-acts DISC-EVAL-POS for
one’s self-disclosure of his/her positive evalua-
tion towards a certain entity, DISC-EXP for one’s
self-disclosure of his/her experience, and SELF-Q-
DESIRE for one’s internal argument about his/her
desire (e.g., “Have I ever wanted to go abroad?”).
We used the dialogue-act annotation of one of the
annotators in this work.
An annotator gave dialogue-level user satis-
faction ratings to all 1260 dialogues (AL-ALL;
31779 speaker dialogue-acts and 28681 listener
dialogue-acts). Then, we made a subset of the
data by randomly selecting ten dialogues for
each of the ten listeners to obtain 100 dialogues
(AL-SUB1; 2453 speaker dialogue-acts and 2197
listener dialogue-acts). Finally, the annotator
gave utterance-level ratings to AL-SUB1. The
utterance-level ratings were given only after lis-
teners’ utterances. The annotator gave three rat-
ings as in the AD domain; namely, smoothness,
closeness, and good listening. Instead of willing-
ness, we have a “good listener” criterion asking
for how good the annotator thinks the listener is
from the viewpoint of attentive listening; for ex-
ample, how well the listener is making it easy for
the speaker to speak. All ratings ranged from 1 to
7. See Fig. 5 for a sample dialogue in the AL do-
main with utterance-level and overall ratings given
by the annotator.
</bodyText>
<subsectionHeader confidence="0.997373">
4.2 Training HMMs
</subsectionHeader>
<bodyText confidence="0.997568363636363">
From the dialogue data and their dialogue-level
ratings, we created our proposed HMMs. We had
five topology variations:
ergodic0: The simple ergodic model with no ad-
ditional SHMM for all ratings. See Fig.
1 for the topology. This HMM has 7
SHMMs connected ergodically with equal
initial/transition probabilities.
ergodic1: The simple ergodic model with an ad-
ditional SHMM for all ratings. See Fig. 2
for the topology. This HMM has 8 (7 +
</bodyText>
<table confidence="0.977236285714286">
Utterance (dialogue-acts) Sm Cl GL
LIS You know, in spring, Japanese food tastes de- 5 5 5
licious. (DA: DISC-EVAL-POS)
SPK This time every year, I make a plan to go on
a healthy diet. But ... (DA: DISC-HABIT)
LIS Uh-huh (DA: ACK) 6 5 6
SPK The temperature goes up suddenly!
(DA: INFO)
SPK It’s always too late! (DA: DISC-EVAL-NEG)
LIS Clothing worn gets less and less while not be- 6 6 6
ing able to lose weight. (DA: DISC-FACT)
SPK Well, people around me soon get used to my
body shape though. (DA: DISC-FACT)
Overall rating for the dialogue 7 7 7
</table>
<figureCaption confidence="0.953097">
Figure 5: Excerpt of a dialogue with utterance-
</figureCaption>
<bodyText confidence="0.952589652173913">
level user satisfaction ratings for smoothness
(Sm), closeness (Cl), and good listener (GL) in the
AL domain. SPK and LIS denote speaker and lis-
tener, respectively. Both the speaker and listener
are human.
1) SHMMs connected ergodically with equal
initial/transition probabilities.
ergodic2: Same as ergodic1 except that the num-
ber of common states is doubled so that com-
mon dialogue-act sequences can be more ac-
curately modeled. Note that without concate-
nated training, SHMMs for each rating may
also have sharp distributions for common se-
quences. One possible solution to avoid this
is to sharpen the distributions of common
states by increasing its number of states.
concat1: 8 (7 + 1) SHMMs combined using con-
catenated training. See Fig. 3 for the topol-
ogy.
concat2: Same as concat1 except that the number
of common states is doubled.
[See Appendices A and B for the actual examples
of the obtained models]
</bodyText>
<subsubsectionHeader confidence="0.67478">
4.2.1 Baseline and Upper Bound
</subsubsectionHeader>
<bodyText confidence="0.9982076">
We created the following baseline (random) and
upper bound (supervised) models for comparison:
random: This outputs ratings 1–7 at random.
supervised: This is an HMM trained in a man-
ner similar to (Engelbrecht et al., 2009). This
model is the same as ergodic0 in topology but
different in that the initial, transition, and out-
put probabilities are trained in a supervised
manner using the dialogue-acts and dialogue-
act-level reference ratings in AD-SUB2 and
AL-SUB1. Since we only have ratings for
system/listener utterances in the corpora, in
order to make training data, we assumed that
the ratings for dialogue-acts corresponding
to user/speaker utterances were the same as
</bodyText>
<page confidence="0.982726">
22
</page>
<bodyText confidence="0.9998585">
those after the previous system/listener utter-
ances. This model simulates the ideal situ-
ation where we possess user satisfaction rat-
ings for all dialogue-acts in the data.
</bodyText>
<subsectionHeader confidence="0.99392">
4.3 Evaluation Procedure
</subsectionHeader>
<bodyText confidence="0.999940380952381">
We performed a ten-fold cross validation. We first
separated utterance-level labeled data (i.e., AD-
SUB2 or AL-SUB1) into 10 disjoint sets. Then,
for each set S, we used dialogue-level labeled
data (i.e., AD-SUB1 or AL-ALL) excluding S
for training HMMs. Here, ‘supervised’ only used
the utterance-level labeled data excluding S for
training. Then, we made the models (i.e., er-
godic0, ergodic1, ergodic2, concat1, concat2, ran-
dom and supervised) output rating sequences for
the dialogue-acts in S and evaluated them with the
reference ratings in S. We repeated this process
ten times to evaluate the overall performance.
Since utterance-level ratings are provided only
after system/listener utterances, we only evaluated
ratings after dialogue-acts corresponding to sys-
tem/listener utterances. When a system/listener
utterance contained multiple dialogue-acts, the
dialogue-acts were assumed to have the same rat-
ing as that utterance. When the output rating
sequences contain 0, which can be the case for
ergodic1–2 and concat1–2, the 0 is replaced by the
most previous non-zero rating. When 0 is found at
the beginning of a dialogue, it remained 0. Al-
though our reference ratings always started with
four (cf. Section 4.1.1), we did not use this in-
formation to fill initial zeros because we wanted
to evaluate the prediction accuracy when we do
not have any prior knowledge. Since some mod-
els may benefit from avoiding evaluating dialogue-
acts at the beginning because of these zeros, we
simply compared the rating sequences where all
models produced non-zero values. For exam-
ple, when we have three output rating sequences
&lt;0,5,6,0,4&gt;, &lt;0,0,1,2,0&gt;, and &lt;1,2,3,4,5&gt; for a
given dialogue-act sequence, the zeros that follow
non-zero values are first filled with their preceed-
ing values, and thereby we obtain &lt;0,5,6,6,4&gt;,
&lt;0,0,1,2,2&gt;, and &lt;1,2,3,4,5&gt;. Then, by cropping
the common non-zero span, we obtain &lt;6,6,4&gt;,
&lt;1,2,2&gt;, and &lt;3,4,5&gt;, and use these rating se-
quences for evaluation.
</bodyText>
<subsubsectionHeader confidence="0.453237">
4.3.1 Evaluation Criteria
</subsubsectionHeader>
<bodyText confidence="0.999210916666667">
We used two kinds of evaluation criteria: one for
evaluating individual matches and the other for
evaluating distributions.
Evaluating Individual Matches: We used the
match rate and mean absolute error to evaluate the
matching of reference and hypothesis rating se-
quences. They are derived by the equations shown
below. In the equations, R (= {R1 ... RL}) and
H (= {H1 ... HL}) denote reference and hypoth-
esis rating sequences for a dialogue, respectively.
L is the length of R and H (Note that they have
the same length).
</bodyText>
<listItem confidence="0.982033">
• Match Rate (MR)
</listItem>
<equation confidence="0.77282425">
MR(R, H) = L
1
i=1
~L match(Ri, Hi), (1)
</equation>
<bodyText confidence="0.999897">
where ‘match’ returns 1 or 0 depending on
whether a rating in R matches that in H.
</bodyText>
<listItem confidence="0.985489">
• Mean Absolute Error (MAE)
</listItem>
<equation confidence="0.98991625">
~L
1
MAE(R, H) =
L i=1
</equation>
<bodyText confidence="0.991963285714286">
Evaluating Distributions: In generative mod-
els, it is important that the output distribution
matches that of the reference. Therefore, we ad-
ditionally use Kullback-Leibler divergence, match
rate per rating, and mean absolute error per rat-
ing. The Kullback-Leibler divergence evaluates
the shape of output distributions. The match rate
per rating and mean absolute error per rating eval-
uate how accurately each individual rating can
be predicted; namely, the accuracy for predict-
ing dialogue-acts with one rating is equally val-
ued with those for other ratings irrespective of the
distribution of ratings in the reference. It is im-
portant to use these metrics in the practical as well
as information theoretic sense because it is no use
predicting only easy-to-guess ratings; we should
be able to correctly predict rare but still important
cases. For example, rating 1 in human-human di-
alogue is quite rare; however, predicting it is very
important for detecting problematic situations in a
dialogue.
</bodyText>
<listItem confidence="0.992344">
• Kullback-Leibler Divergence (KL)
</listItem>
<equation confidence="0.965792">
P(H, r) · log(P(H, r)), (3)
P(R, r)
</equation>
<bodyText confidence="0.997798166666667">
where K is the maximum user satisfaction rating
(i.e. 7 in this experiment), R and H denote the se-
quentially concatenated reference/hypothesis rat-
ing sequences of the entire dialogues, and P(∗, r)
denotes the occurrence probability that a rating r
is found in an arbitrary rating sequence.
</bodyText>
<listItem confidence="0.978816">
• Match Rate per rating (MR/r)
</listItem>
<equation confidence="0.9967845">
MR/r(R, H) = K r=1
1 K iE{iJRi=rl
E match(Ri, Hi)
iE{iJRi=rl
E 1 ,
(4)
|Ri − Hi|. (2)
K
KL(R, H) = E
r=1
</equation>
<page confidence="0.996491">
23
</page>
<table confidence="0.999969875">
Criterion random ergodic0 ergodic1 ergodic2 concat1 concat2 supervised
Smoothness MR 0.142e0e1 0.111 0.111 0.157e0e1 0.153 0.199e0e1r 0.275c1e0e1e2r
MAE 1.988e0e1 2.212 2.212 1.980 1.936e0e1 1.870e0e1 1.420c1c2e0e1e2r
KL 0.287 0.699 0.699 0.562 0.280 0.369 0.162
MR/r 0.143 0.137 0.137 0.176 0.136 0.177 0.217
MAE/r 2.286 2.414 2.414 2.152 2.301 2.206 1.782
Closeness MR 0.143 0.129 0.129 0.171e0e1 0.174 0.189e0e1 0.279c1c2e0e1e2r
MAE 2.028 2.066 2.066 1.964 1.798e0e1r 1.886 1.431c1c2e0e1e2r
KL 0.195 0.449 0.449 0.261 0.138 0.263 0.092
MR/r 0.143 0.156 0.156 0.170 0.155 0.164 0.231
MAE/r 2.283 2.236 2.236 2.221 2.079 2.067 1.702
Willingness MR 0.143e0e1 0.112 0.112 0.180e0e1 0.152 0.183e0e1 0.283c1c2e0e1e2r
MAE 2.005 2.133 2.133 1.962 1.801e0e1r 1.882 1.403c1c2e0e1e2r
KL 0.225 0.568 0.568 0.507 0.238 0.255 0.125
MR/r 0.143 0.152 0.152 0.192 0.181 0.167 0.224
MAE/r 2.286 2.258 2.258 2.107 1.958 2.164 1.705
</table>
<tableCaption confidence="0.99944">
Table 1: The match rate (MR), mean absolute error (MAE), Kullback-Leibler divergence (KL), match
</tableCaption>
<bodyText confidence="0.9416692">
rate per rating (MR/r) and mean absolute error per rating (MAE/r) for our proposed HMMs, the random
baseline, and the upper bound (supervised) for the AD domain. ‘e0–e2’, ‘c1–c2’, and ‘r’ indicate the sta-
tistical significance (p&lt;0.01) over ergodic0–2, concat1–2, and random, respectively. Bold font indicates
the best value within each row (except for ‘supervised’).
where Ri and Hi denote ratings at i-th positions.
</bodyText>
<listItem confidence="0.988064">
• Mean Absolute Error per rating (MAE/r)
</listItem>
<equation confidence="0.978643">
x
1
MAE/r(R, H) =
K r=1
(5)
</equation>
<subsectionHeader confidence="0.993754">
4.4 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999979881355932">
Tables 1 and 2 show the evaluation results for the
AD and AL domains, respectively. The MR and
MAE values are averaged over all dialogues. To
compare the means of the MR and MAE, we per-
formed a non-parametric multiple comparison test
[Steel-Dwass test (Dwass, 1960)]. We did not per-
form a statistical test for other criteria because it
was difficult to perform sample-wise comparison
for distributions. Naturally, ‘supervised’ is the
best performing model for all criteria in both do-
mains. Therefore, we focus on how much our pro-
posed models differ from the baseline (random)
and the upper bound (supervised).
In the AD domain, we find that ergodic0 and er-
godic1 performed rather poorly and concat1 and
concat2 performed fairly well, significantly out-
performing the random baseline. However, it is
also clear that we still need a great deal of im-
provement for our models to reach the level of
‘supervised’. A promising sign is that concat2
is not significantly different from ‘supervised’ in
smoothness. Here, ergodic0 and ergodic1 re-
turned the exact same results. This means that the
state transition paths did not go through the com-
mon states at all in ergodic1, suggesting that the
common states in ergodic1 have very broad out-
put distributions and the optimal path could not
go through the common states, instead preferring
other states having sharper distributions. How-
ever, this phenomenon was rightly avoided by in-
troducing more common states as seen in the re-
sults for ergodic2; nonetheless, as the results for
concat1 and concat2 indicate, the transition prob-
abilities have to be trained appropriately to obtain
better results.
In the AL domain, although the tendency of
the evaluation results is the same as that for the
AD domain, concat2 is clearly the best perform-
ing model. It outperformed other models in al-
most all cases except for “Good Listener” for
which concat1 performed better. In fact, the MR/r
and MAE/r of concat1 are quite close to those of
‘supervised’, suggesting the potential of our ap-
proach.
Overall, although we still need further improve-
ment in order for our models to be closer to the
upper bound, we showed that we can, to some ex-
tent, predict user satisfaction transitions in a dia-
logue only from overall ratings of dialogues using
our proposed HMMs. We also showed that model
topologies and learning methods can make signif-
icant differences. Especially, we found the intro-
duction of common states to be crucial in making
appropriate models for prediction. Since our mod-
els, especially concat2, significantly outperformed
the baseline, we believe that our approach can be
one of the viable options for automatically predict-
ing user satisfaction transitions when there exist
only overall rating data.
</bodyText>
<sectionHeader confidence="0.988047" genericHeader="method">
5 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.99928325">
We presented a novel approach for modeling user
satisfaction transitions only from dialogues with
overall ratings. The experimental results show that
it is possible to predict user satisfaction transi-
</bodyText>
<equation confidence="0.9108572">
E |Ri − Hi|
i∈{i|Ri=r}
.
E 1
i∈{i|Ri=r}
</equation>
<page confidence="0.997451">
24
</page>
<table confidence="0.99997475">
Criterion random ergodic0 ergodic1 ergodic2 concat1 concat2 supervised
Smoothness MR 0.143e0e1e2 0.069 0.069 0.131e0e1 0.173e0e1 0.243c1e0e1e2r 0.439c1c2e0e1e2r
MAE 1.868e0e1e2 2.519 2.519 2.433 1.687e0e1e2r 1.594e0e1e2r 0.802c1c2e0e1e2r
KL 0.989 2.253 2.253 2.319 0.851 0.753 0.087
MR/r 0.141 0.118 0.118 0.156 0.161 0.167 0.231
MAE/r 2.289 2.500 2.500 2.492 2.093 2.077 1.868
Closeness MR 0.143e0e1 0.050 0.050 0.175e0e1 0.158e0e1 0.263c1e0e1e2r 0.425c1c2e0e1e2r
MAE 1.849e0e1e2 2.357 2.357 2.316 1.778e0e1e2 1.562e0e1e2r 0.890c1c2e0e1e2r
KL 1.022 2.137 2.137 2.220 1.155 0.909 0.109
MR/r 0.143 0.090 0.090 0.122 0.117 0.159 0.237
MAE/r 2.281 2.577 2.577 2.811 2.260 2.039 1.972
Good Listener MR 0.143e0e1 0.075 0.075 0.145e0e1 0.199e0e1 0.206e0e1e2 0.422c1c2e0e1e2r
MAE 1.890e0e1e2 2.237 2.237 2.150 1.634e0e1e2r 1.634e0e1e2r 0.852c1c2e0e1e2r
KL 0.945 1.738 1.738 1.782 0.924 0.824 0.087
MR/r 0.143 0.121 0.121 0.184 0.224 0.200 0.227
MAE/r 2.284 2.358 2.358 2.236 1.911 2.083 1.769
</table>
<tableCaption confidence="0.999651">
Table 2: Evaluation results for the AL domain. See Table 1 for the notations in the table.
</tableCaption>
<bodyText confidence="0.999914105263158">
tions to some extent by our approach and that in-
troducing common states and concatenated train-
ing can significantly improve prediction accuracy.
For improvement, we plan to explore new dialogic
features for emissions, different topologies, and
other optimization functions, such as discrimina-
tive ones. We also need to validate our approach
using dialogue-act recognition results instead of
hand-labeled dialogue-acts. We also want to ap-
ply our approach to sequence mining in dialogues
where we have categories instead of ratings for di-
alogues. It is also necessary to test whether our
HMMs can be generalized over different raters,
since user satisfaction ratings may differ greatly
among individuals. Although there remain such
issues, we believe we have presented a new di-
rection in automatic evaluation of dialogues and
the experimental results show that our approach is
promising.
</bodyText>
<sectionHeader confidence="0.734219" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.785050583333333">
Meyer Dwass. 1960. Some k-sample rank-order tests. In
Ingram Olkin et al., editor, Contributions to Probability
and Statistics, pages 198–202. Stanford University Press.
Klaus-Peter Engelbrecht, Florian G¨odde, Felix Hartard,
Hamed Ketabdar, and Sebastian M¨oller. 2009. Model-
ing user satisfaction with hidden Markov models. In Proc.
SIGDIAL, pages 170–177.
Keelan Evanini, Phillip Hunter, Jackson Liscombe, David
Suendermann, Krishna Dayanidhi, and Roberto Pierac-
cini. 2008. Caller experience: A method for evaluating
dialog systems and its automatic prediction. In Proc. SLT,
pages 129–132.
Allen L. Gorin, Giuseppe Riccardi, and Jerry H. Wright.
1997. How may I help you? Speech Communication,
23(1-2):113–127.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda. 2010.
Estimation method of user satisfaction using N-gram-
based dialog history model for spoken dialog system. In
Proc. LREC, pages 78–83.
Ota Herm, Alexander Schmitt, and Jackson Liscombe. 2008.
When calls go wrong: How to detect problematic calls
based on log-files and emotions? In Proc. INTER-
SPEECH, pages 463–466.
Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki.
2008. Effects of self-disclosure and empathy in human-
computer dialogue. In Proc. SLT, pages 109–112.
Julia Hirschberg, Diane Litman, and Marc Swerts. 2004.
Prosodic and other cues to speech recognition failures.
Speech Communication, 43:155–175.
Chiori Hori, Kiyonori Ohtake, Teruhisa Misu, Hideki Kash-
ioka, and Satoshi Nakamura. 2008. Dialog management
using weighted finite-state transducers. In Proc. INTER-
SPEECH, pages 211–214.
Naoki Isomura, Fujio Toriumi, and Kenichiro Ishii. 2009.
Evaluation method of non-task-oriented dialogue system
using HMM. IEICE Transactions on Information and Sys-
</reference>
<bodyText confidence="0.851107973684211">
tems, J92-D(4):542–551.
Woosung Kim. 2007. Online call quality monitoring for
automating agent-based call centers. In Proc. INTER-
SPEECH, pages 130–133.
Kai-Fu Lee. 1989. Automatic speech recognition: the de-
velopment of the SPHINX system. Kluwer Academic Pub-
lishers.
Toyomi Meguro, Ryuichiro Higashinaka,Kohji Dohsaka,Ya-
suhiro Minami, and Hideki Isozaki. 2009. Analysis of
listening-oriented dialogue for building listening agents.
In Proc. SIGDIAL, pages 124–127.
Yasuhiro Minami, Akira Mori, Toyomi Meguro, Ryuichiro
Higashinaka, Kohji Dohsaka, and Eisaku Maeda. 2009.
Dialogue control algorithm for ambient intelligence based
on partially observable Markov decision processes. In
Proc. IWSDS, pages 254–263.
Sebastian M¨oller, Klaus-Peter Engelbrecht, and Robert
Schleicher. 2008. Predicting the quality and usability of
spoken dialogue services. Speech Communication, 50(8-
9):730–744.
Lawrence R. Rabiner. 1990. A tutorial on hidden Markov
models and selected applications in speech recognition.
Readings in speech recognition, 53(3):267–296.
Katsuhiko Shirai. 1996. Modeling of spoken dialogue with
and without visual information. In Proc. ICSLP, vol-
ume 1, pages 188–191.
Marilyn A. Walker, Diane Litman, Candace A. Kamm, and
Alicia Abella. 1997. PARADISE: A framework for evalu-
ating spoken dialogue agents. In Proc. EACL, pages 271–
280.
Marilyn A. Walker, Irene Langkilde-Geary, Helen Wright
Hastie, Jerry Wright, and Allen Gorin. 2002. Automat-
ically training a problematic dialogue predictor for a spo-
ken dialogue system. Journal ofArtificial Intelligence Re-
search, 16(1):293–319.
Jason D. Williams and Steve Young. 2007. Partially ob-
servable Markov decision processes for spoken dialog sys-
tems. Computer Speech &amp; Language, 21(2):393–422.
</bodyText>
<page confidence="0.997219">
25
</page>
<bodyText confidence="0.9046172">
Appendix A. HMM obtained by concat2 for Willingness rating in the AD domain.
This HMM is the model obtained for one of the folds in the experiment. Square and oval states emit
a system’s dialogue-act and a user’s dialogue-act, respectively. Emissions (dialogue-acts) are shown in
each state as a table with their probabilities. Only the emissions and transitions over the probability of
0.1 are displayed for the sake of brevity. Here, ‘pi’ denotes initial probability.
</bodyText>
<figure confidence="0.999847564971751">
0.10
0.14
0.19
0.10
Q-DISC-OTHER 0.21
DISC-DISAGREE-P 0.46
0.20
0.12
0.15
USER (pi: 0.00)
SYSTEM (pi: 0.00)
0.15
rating:4
0.20
GREETING
Q-DISC-R
DISC-P-R
0.22
RES
GOODBYE
DISC-P-R
DISC-P
0.19
0.61
0.22
Q-DISC-P-OPEN 0.18
0.33
0.13
0.11
SYSTEM (pi: 0.00)
USER (pi: 0.00)
0.46
OTHER 0.26
Q-DISC-R 0.18
0.21
rating:3
0.54
DISC-AGREE-P
0.46
GOODBYE
Q-DISC-P
DISC-P
DISC-P
0.12
0.14
0.12
Q-DISC-OTHER 0.22
0.12
DISC-R-OTHER 0.41
0.10
0.14
0.17
DISC-AGREE-P 0.28
USER (pi: 0.00)
SYSTEM (pi: 0.00)
rating:5
0.45
GOODBYE
REPEAT
REPEAT
DISC-R
EMP
0.15
0.62
0.16
0.22
0.18
0.14
0.15
DISC-R-OTHER 0.45
0.16
0.11
SYSTEM (pi: 0.00)
0.51
EMP 0.10
REPEAT 0.10
DISC-OTHER 0.23
0.19
ACK 0.31
0.20
USER (pi: 0.00)
0.16
rating:7
GOODBYE
0.46
Q-DISC-P
DISC-R
DISC-P
0.13
ACK 0.14
DISC-R-OTHER 0.30
USER (pi: 0.00)
0.16
0.61
0.37
ACK 0.35
DISC-AGREE-P 0.14
DISC-DISAGREE-P 0.14
REPEAT 0.10
0.12
SYSTEM (pi: 0.00)
DISC-R-OTHER 0.17
Q-DISC-R-OTHER 0.24
Q-DISC-R 0.23
0.51
SYSTEM (pi: 1.00)
rating:0
0.27
0.37
0.35
0.12
0.15
SYSTEM (pi: 0.00)
0.30
DISC-OTHER 0.14
0.27
0.10
USER (pi: 0.00)
USER (pi: 0.00)
0.31
DISC-P 0.40
DISC-R 0.26
0.56
ACK 0.81
EMP 0.11
rating:1
0.26
0.33
Q-DISC-P
0.49
OTHER
ACK
0.23
0.52
0.26
0.21
0.22
0.16
OTHER 0.29
Q-DISC-OTHER 0.20
Q-DISC-R 0.23
SYSTEM (pi: 0.00)
ACK 0.77
Q-DISC-P 0.14
USER (pi: 0.00)
0.59
rating:2
0.22
0.23
0.17
0.11
0.11
0.25
0.32
0.16
DISC-DISAGREE-P 0.35
0.13
0.15
0.15
0.16
0.27
0.14
0.18
0.16
SYSTEM (pi: 0.00)
0.19
USER (pi: 0.00)
DISC-DISAGREE-OTHER
Q-DISC-P-OPEN
rating:6
0.17
DISC-OTHER
DISC-R
DISC-P
DISC-P-R
REPEAT
EMP
</figure>
<page confidence="0.98309">
26
</page>
<sectionHeader confidence="0.961033" genericHeader="method">
Appendix B. HMM obtained by concat1 for Good Listener rating in the AL domain.
</sectionHeader>
<bodyText confidence="0.99948725">
This HMM is the model obtained for one of the folds in the experiment. Square and oval states emit a lis-
tener’s dialogue-act and a speaker’s dialogue-act, respectively. We find DICS-EVAL-NEG (self-disclosure
of one’s evaluation with a negative polarity) in the rating score 1 and DICS-EVAL-POS in the rating score
7, indicating that it may be better to make speakers talk about positive evaluations to be a good listener.
</bodyText>
<figure confidence="0.99960598013245">
0.19
0.38
0.22
rating:4
LISTENER (pi: 0.04)
GREETING 0.23
SYNPATHY 0.16
Q-FACT 0.14
0.41
0.23
SPEAKER (pi: 0.10)
GREETING
0.31
0.10
Q-FACT
DISC-EVAL-NEG 0.15
0.16
0.24
0.18
0.32
0.23
0.23
rating:5
LISTENER (pi: 0.00)
SYNPATHY 0.17
DISC-EVAL-POS 0.20
0.39
0.31
SPEAKER (pi: 0.00)
0.27
DISC-FACT
0.20
SYNPATHY
DISC-EVAL-POS 0.17
0.15
0.16
0.24
0.22
0.30
0.22
0.12
rating:7
LISTENER (pi: 0.04)
0.24
GREETING
DISC-EVAL-POS 0.22
0.11
INFO
0.13
CONFIRM
0.38
0.31
SPEAKER (pi: 0.10)
0.18
GREETING
0.26
DISC-FACT
DISC-EVAL-POS 0.16
0.18
INFO
0.17
0.26
0.12
0.22
0.26
rating:1
LISTENER (pi: 0.01)
GREETING 0.28
DISC-FACT 0.19
INFO 0.15
0.32
0.32
0.33
SPEAKER (pi: 0.14)
GREETING 0.23
0.33
Q-FACT 0.13
DISC-EVAL-NEG 0.12
0.24
rating:0
LISTENER (pi: 0.16)
GREETING 0.13
0.12
DISC-FACT 0.10
DISC-EVAL-POS 0.11
0.350.32
SPEAKER (pi: 0.41)
GREETING 0.13
DISC-FACT 0.15
SYNPATHY 0.15
0.21
0.22
0.29
0.21
0.39
rating:6
LISTENER (pi: 0.00)
0.19
SYNPATHY
DISC-EVAL-POS 0.24
0.14
CONFIRM
0.33
0.29
SPEAKER (pi: 0.00)
0.26
SYNPATHY
DISC-EVAL-POS 0.23
0.25
INFO
0.11
DISC-EXP
0.27
0.24
0.21
0.24
0.15
0.27
0.13
0.18
rating:3
LISTENER (pi: 0.00)
DISC-FACT 0.32
0.24
Q-FACT
0.10
THANK
0.11
Q-INFO
0.21
0.33
SPEAKER (pi: 0.00)
0.34
DISC-FACT
DISC-EVAL-NEG 0.12
0.34
0.16
0.23
0.24
0.14
rating:2
LISTENER (pi: 0.00)
DISC-FACT 0.21
0.18
INFO
0.35
0.36
SPEAKER (pi: 0.00)
0.22
INFO
Q-FACT 0.12
</figure>
<page confidence="0.7742975">
0.25
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.214413">
<title confidence="0.99997">Modeling User Satisfaction Transitions in Dialogues from Overall Ratings</title>
<author confidence="0.994432">Yasuhiro Kohji</author>
<affiliation confidence="0.570037">tNTT Cyber Space Laboratories, NTT</affiliation>
<address confidence="0.259155">tNTT Communication Science Laboratories, NTT</address>
<abstract confidence="0.999380148148148">This paper proposes a novel approach for predicting user satisfaction transitions during a dialogue only from the ratings given to entire dialogues, with the aim of reducing the cost of creating reference ratings for utterances/dialogue-acts that have been necessary in conventional approaches. In our approach, we first train hidden Markov models (HMMs) of dialogue-act sequences associated with each overall rating. Then, we combine such rating-related HMMs into a single HMM to decode a sequence of dialogueacts into state sequences representing to which overall rating each dialogue-act is most related, which leads to our rating predictions. Experimental results in two dialogue domains show that our approach can make reasonable predictions; it significantly outperforms a baseline and nears the upper bound of a supervised approach in some evaluation criteria. We also show that introducing states that represent dialogue-act sequences that occur commonly in all ratings into an HMM significantly improves prediction accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meyer Dwass</author>
</authors>
<title>Some k-sample rank-order tests.</title>
<date>1960</date>
<booktitle>Contributions to Probability and Statistics,</booktitle>
<pages>198--202</pages>
<editor>In Ingram Olkin et al., editor,</editor>
<publisher>Stanford University Press.</publisher>
<contexts>
<context position="29222" citStr="Dwass, 1960" startWordPosition="4744" endWordPosition="4745">‘e0–e2’, ‘c1–c2’, and ‘r’ indicate the statistical significance (p&lt;0.01) over ergodic0–2, concat1–2, and random, respectively. Bold font indicates the best value within each row (except for ‘supervised’). where Ri and Hi denote ratings at i-th positions. • Mean Absolute Error per rating (MAE/r) x 1 MAE/r(R, H) = K r=1 (5) 4.4 Evaluation Results Tables 1 and 2 show the evaluation results for the AD and AL domains, respectively. The MR and MAE values are averaged over all dialogues. To compare the means of the MR and MAE, we performed a non-parametric multiple comparison test [Steel-Dwass test (Dwass, 1960)]. We did not perform a statistical test for other criteria because it was difficult to perform sample-wise comparison for distributions. Naturally, ‘supervised’ is the best performing model for all criteria in both domains. Therefore, we focus on how much our proposed models differ from the baseline (random) and the upper bound (supervised). In the AD domain, we find that ergodic0 and ergodic1 performed rather poorly and concat1 and concat2 performed fairly well, significantly outperforming the random baseline. However, it is also clear that we still need a great deal of improvement for our m</context>
</contexts>
<marker>Dwass, 1960</marker>
<rawString>Meyer Dwass. 1960. Some k-sample rank-order tests. In Ingram Olkin et al., editor, Contributions to Probability and Statistics, pages 198–202. Stanford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus-Peter Engelbrecht</author>
<author>Florian G¨odde</author>
<author>Felix Hartard</author>
<author>Hamed Ketabdar</author>
<author>Sebastian M¨oller</author>
</authors>
<title>Modeling user satisfaction with hidden Markov models.</title>
<date>2009</date>
<booktitle>In Proc. SIGDIAL,</booktitle>
<pages>170--177</pages>
<marker>Engelbrecht, G¨odde, Hartard, Ketabdar, M¨oller, 2009</marker>
<rawString>Klaus-Peter Engelbrecht, Florian G¨odde, Felix Hartard, Hamed Ketabdar, and Sebastian M¨oller. 2009. Modeling user satisfaction with hidden Markov models. In Proc. SIGDIAL, pages 170–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keelan Evanini</author>
<author>Phillip Hunter</author>
<author>Jackson Liscombe</author>
<author>David Suendermann</author>
<author>Krishna Dayanidhi</author>
<author>Roberto Pieraccini</author>
</authors>
<title>Caller experience: A method for evaluating dialog systems and its automatic prediction.</title>
<date>2008</date>
<booktitle>In Proc. SLT,</booktitle>
<pages>129--132</pages>
<contexts>
<context position="16906" citStr="Evanini et al., 2008" startWordPosition="2762" endWordPosition="2765">satisfaction ratings for smoothness (Sm), closeness (Cl), and willingness (Wi) in the AD domain. SYS and USR denote system and user, respectively. The dialogue was translated by the authors. was given three different user satisfaction ratings related to “Smoothness of the conversation”, “Closeness perceived by the user towards the system”, and “Willingness to continue the conversation”. The ratings ranged from 1 to 7, where 1 is the worst and 7 the best (see Fig. 4 for examples of utterance-level and overall ratings given by the annotator for an excerpt of a dialogue). In a manner similar to (Evanini et al., 2008), we used a third-person’s user satisfaction rating for the sake of consistency. For utterance-level ratings, the annotator carefully read each utterance and gave ratings after each system utterance according to how she would have felt after receiving each system utterance if she had been the user in the dialogue. To make the situation more realistic, she was not allowed to look down at the dialogue after the current utterance. At the beginning of a dialogue, the ratings always started from four (neutral). When the annotator gave dialogue-level ratings, she looked through the entire dialogue a</context>
</contexts>
<marker>Evanini, Hunter, Liscombe, Suendermann, Dayanidhi, Pieraccini, 2008</marker>
<rawString>Keelan Evanini, Phillip Hunter, Jackson Liscombe, David Suendermann, Krishna Dayanidhi, and Roberto Pieraccini. 2008. Caller experience: A method for evaluating dialog systems and its automatic prediction. In Proc. SLT, pages 129–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allen L Gorin</author>
<author>Giuseppe Riccardi</author>
<author>Jerry H Wright</author>
</authors>
<title>How may I help you? Speech Communication,</title>
<date>1997</date>
<pages>23--1</pages>
<contexts>
<context position="4765" citStr="Gorin et al., 1997" startWordPosition="719" endWordPosition="722"> number of extensions have been proposed to improve the prediction performance (M¨oller et al., 2008); howProceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 18–27, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 18 ever, it is not aimed at predicting user satisfaction transitions. Classification models are widely employed to detect problematic situations in an ongoing dialogue. Walker et al. (2002) developed the Problematic Dialogue Predictor for the “How May I Help You” system (Gorin et al., 1997) to robustly transfer problematic calls to human operators in call routing tasks. They derive speech recognition, language understanding, and dialogue management features from the first few turns of a dialogue and apply a decision tree classifier to detect problematic calls. For a similar task, Hirschberg et al. (2004) and Herm et al. (2008) used prosodic and emotional features. Kim (2007) recently proposed an approach for online call quality monitoring so that problematic calls can be transferred to human operators as quickly as possible rather than waiting for the first few turns. N-grams an</context>
</contexts>
<marker>Gorin, Riccardi, Wright, 1997</marker>
<rawString>Allen L. Gorin, Giuseppe Riccardi, and Jerry H. Wright. 1997. How may I help you? Speech Communication, 23(1-2):113–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunao Hara</author>
<author>Norihide Kitaoka</author>
<author>Kazuya Takeda</author>
</authors>
<title>Estimation method of user satisfaction using N-grambased dialog history model for spoken dialog system.</title>
<date>2010</date>
<booktitle>In Proc. LREC,</booktitle>
<pages>78--83</pages>
<contexts>
<context position="5439" citStr="Hara et al. (2010)" startWordPosition="828" endWordPosition="831">rs in call routing tasks. They derive speech recognition, language understanding, and dialogue management features from the first few turns of a dialogue and apply a decision tree classifier to detect problematic calls. For a similar task, Hirschberg et al. (2004) and Herm et al. (2008) used prosodic and emotional features. Kim (2007) recently proposed an approach for online call quality monitoring so that problematic calls can be transferred to human operators as quickly as possible rather than waiting for the first few turns. N-grams and HMM-based approaches have also been actively studied. Hara et al. (2010) proposed predicting the most likely user satisfaction level of a dialogue by using N-grams of dialogues for each satisfaction level in the music navigation domain. Isomura et al. (2009) used HMMs to evaluate the naturalness of a dialogue in their interview system. They trained HMMs that model dialogue-act sequences between human subjects and used them to evaluate human-machine dialogues by the output probabilities of the HMMs. Recently, there have been approaches to predict user satisfaction transitions by evaluating the quality of individual utterances in a dialogue. For example, Engelbrecht</context>
</contexts>
<marker>Hara, Kitaoka, Takeda, 2010</marker>
<rawString>Sunao Hara, Norihide Kitaoka, and Kazuya Takeda. 2010. Estimation method of user satisfaction using N-grambased dialog history model for spoken dialog system. In Proc. LREC, pages 78–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ota Herm</author>
<author>Alexander Schmitt</author>
<author>Jackson Liscombe</author>
</authors>
<title>When calls go wrong: How to detect problematic calls based on log-files and emotions?</title>
<date>2008</date>
<booktitle>In Proc. INTERSPEECH,</booktitle>
<pages>463--466</pages>
<contexts>
<context position="1860" citStr="Herm et al., 2008" startWordPosition="266" endWordPosition="269"> states that represent dialogue-act sequences that occur commonly in all ratings into an HMM significantly improves prediction accuracy. 1 Introduction In recent years, there has been intensive work on the automatic evaluation of dialogues (Walker et al., 1997; M¨oller et al., 2008). Automatic evaluation makes it possible to predict the performance of dialogue systems without the costly process of performing surveys with human subjects, leading to a rapid improvement cycle for dialogue systems. It is also useful for detecting problematic situations in an ongoing dialogue (Walker et al., 2002; Herm et al., 2008; Kim, 2007). In these studies, the typical approach is to train a prediction model, such as a regression or classification model, using features representing the whole or a part of a dialogue together with human reference labels (e.g., reference ratings). However, creating such reference labels by hand can be extremely costly when we want to predict user satisfaction transitions during a dialogue because we need to create reference labels after each utterance/dialogue-act in the training data (Engelbrecht et al., 2009). This paper proposes a novel approach for predicting user satisfaction tra</context>
<context position="5108" citStr="Herm et al. (2008)" startWordPosition="775" endWordPosition="778">ot aimed at predicting user satisfaction transitions. Classification models are widely employed to detect problematic situations in an ongoing dialogue. Walker et al. (2002) developed the Problematic Dialogue Predictor for the “How May I Help You” system (Gorin et al., 1997) to robustly transfer problematic calls to human operators in call routing tasks. They derive speech recognition, language understanding, and dialogue management features from the first few turns of a dialogue and apply a decision tree classifier to detect problematic calls. For a similar task, Hirschberg et al. (2004) and Herm et al. (2008) used prosodic and emotional features. Kim (2007) recently proposed an approach for online call quality monitoring so that problematic calls can be transferred to human operators as quickly as possible rather than waiting for the first few turns. N-grams and HMM-based approaches have also been actively studied. Hara et al. (2010) proposed predicting the most likely user satisfaction level of a dialogue by using N-grams of dialogues for each satisfaction level in the music navigation domain. Isomura et al. (2009) used HMMs to evaluate the naturalness of a dialogue in their interview system. The</context>
</contexts>
<marker>Herm, Schmitt, Liscombe, 2008</marker>
<rawString>Ota Herm, Alexander Schmitt, and Jackson Liscombe. 2008. When calls go wrong: How to detect problematic calls based on log-files and emotions? In Proc. INTERSPEECH, pages 463–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Hideki Isozaki</author>
</authors>
<title>Effects of self-disclosure and empathy in humancomputer dialogue.</title>
<date>2008</date>
<booktitle>In Proc. SLT,</booktitle>
<pages>109--112</pages>
<contexts>
<context position="14426" citStr="Higashinaka et al., 2008" startWordPosition="2348" endWordPosition="2351">s a supervised approach; that is, an HMM is trained using reference labels on the dialogueact level. 4.1 Dialogue Data We used dialogues in two domains; the animal discussion (AD) domain and the attentive listening (AL) domain. All dialogues are in Japanese. In both domains, the data we used were text dialogues. We did not use spoken dialogue data because we wanted to avoid particular problems of voice, such as filled pauses and overlaps, although we aim to deal with spoken dialogue in the future. 4.1.1 Animal Discussion We used the dialogue data in the AD domain that we previously collected (Higashinaka et al., 2008). In this domain, the system and user talk about likes and dislikes about animals via a text chat interface. The data consist of 1000 dialogues between a dialogue system and 50 human users. Each user conversed with the system 20 times, including two example dialogues at the beginning. All user/system utterances have been annotated with dialogue-acts. There are 29 dialogue-act types including those related to self-disclosure, question, response, and greetings. For example, a dialogueact DISC-P denotes one’s self-disclosure about a proposition P. Here, P is either like(X,A) or dislike(X,A) where</context>
</contexts>
<marker>Higashinaka, Dohsaka, Isozaki, 2008</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki. 2008. Effects of self-disclosure and empathy in humancomputer dialogue. In Proc. SLT, pages 109–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Diane Litman</author>
<author>Marc Swerts</author>
</authors>
<title>Prosodic and other cues to speech recognition failures.</title>
<date>2004</date>
<journal>Speech Communication,</journal>
<pages>43--155</pages>
<contexts>
<context position="5085" citStr="Hirschberg et al. (2004)" startWordPosition="770" endWordPosition="773"> Linguistics 18 ever, it is not aimed at predicting user satisfaction transitions. Classification models are widely employed to detect problematic situations in an ongoing dialogue. Walker et al. (2002) developed the Problematic Dialogue Predictor for the “How May I Help You” system (Gorin et al., 1997) to robustly transfer problematic calls to human operators in call routing tasks. They derive speech recognition, language understanding, and dialogue management features from the first few turns of a dialogue and apply a decision tree classifier to detect problematic calls. For a similar task, Hirschberg et al. (2004) and Herm et al. (2008) used prosodic and emotional features. Kim (2007) recently proposed an approach for online call quality monitoring so that problematic calls can be transferred to human operators as quickly as possible rather than waiting for the first few turns. N-grams and HMM-based approaches have also been actively studied. Hara et al. (2010) proposed predicting the most likely user satisfaction level of a dialogue by using N-grams of dialogues for each satisfaction level in the music navigation domain. Isomura et al. (2009) used HMMs to evaluate the naturalness of a dialogue in thei</context>
</contexts>
<marker>Hirschberg, Litman, Swerts, 2004</marker>
<rawString>Julia Hirschberg, Diane Litman, and Marc Swerts. 2004. Prosodic and other cues to speech recognition failures. Speech Communication, 43:155–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiori Hori</author>
<author>Kiyonori Ohtake</author>
<author>Teruhisa Misu</author>
<author>Hideki Kashioka</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Dialog management using weighted finite-state transducers.</title>
<date>2008</date>
<booktitle>In Proc. INTERSPEECH,</booktitle>
<pages>211--214</pages>
<contexts>
<context position="8159" citStr="Hori et al., 2008" startWordPosition="1257" endWordPosition="1260">ch overall rating and combine these rating-related HMMs into a single HMM that can assign ratings for dialogue-acts by estimating from which HMM each dialogue-act has most likely to have been generated by the Viterbi decoding. We use HMMs because they can deal with sequences that evolve over time and have been successfully utilized to model and evaluate dialogue-act sequences (Shirai, 1996; Isomura et al., 2009; Engelbrecht et al., 2009). The generative feature of an HMM is also useful when we want to build a probabilistic dialogue manager that produces the most likely dialogue-act sequences (Hori et al., 2008) or that aims to maximize a reward function in partially observable Markov decision processes (Williams and Young, 2007; Minami et al., 2009). When there are K levels of user satisfaction as overall ratings, we create K HMMs each of which is trained using the dialogue-act sequences in dialogues Dk ⊂ D, where Dk = {∀di7 |r(di) = k}. We use the EM-algorithm to train HMMs. Here, we assume that each HMM has two states, each of which emits dialogue-acts of one of the conversational participants. This type of HMM is called a speaker HMM (SHMM) and has been successfully utilized to model two-party co</context>
</contexts>
<marker>Hori, Ohtake, Misu, Kashioka, Nakamura, 2008</marker>
<rawString>Chiori Hori, Kiyonori Ohtake, Teruhisa Misu, Hideki Kashioka, and Satoshi Nakamura. 2008. Dialog management using weighted finite-state transducers. In Proc. INTERSPEECH, pages 211–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoki Isomura</author>
<author>Fujio Toriumi</author>
<author>Kenichiro Ishii</author>
</authors>
<title>Evaluation method of non-task-oriented dialogue system using HMM.</title>
<date>2009</date>
<journal>IEICE Transactions on Information and Sys-</journal>
<contexts>
<context position="5625" citStr="Isomura et al. (2009)" startWordPosition="857" endWordPosition="860">ssifier to detect problematic calls. For a similar task, Hirschberg et al. (2004) and Herm et al. (2008) used prosodic and emotional features. Kim (2007) recently proposed an approach for online call quality monitoring so that problematic calls can be transferred to human operators as quickly as possible rather than waiting for the first few turns. N-grams and HMM-based approaches have also been actively studied. Hara et al. (2010) proposed predicting the most likely user satisfaction level of a dialogue by using N-grams of dialogues for each satisfaction level in the music navigation domain. Isomura et al. (2009) used HMMs to evaluate the naturalness of a dialogue in their interview system. They trained HMMs that model dialogue-act sequences between human subjects and used them to evaluate human-machine dialogues by the output probabilities of the HMMs. Recently, there have been approaches to predict user satisfaction transitions by evaluating the quality of individual utterances in a dialogue. For example, Engelbrecht et al. (2009) predicted user satisfaction ratings after each user utterance by HMMs trained from utterance-level features and utterance-level reference ratings. The problem with these a</context>
<context position="7955" citStr="Isomura et al., 2009" startWordPosition="1223" endWordPosition="1226"> denotes the l-th dialogue-act in di, N the total number of dialogues, and mi the total number of dialogue-acts in di. Our basic idea is to train HMMs representing dialogue-act sequences of dialogues for each overall rating and combine these rating-related HMMs into a single HMM that can assign ratings for dialogue-acts by estimating from which HMM each dialogue-act has most likely to have been generated by the Viterbi decoding. We use HMMs because they can deal with sequences that evolve over time and have been successfully utilized to model and evaluate dialogue-act sequences (Shirai, 1996; Isomura et al., 2009; Engelbrecht et al., 2009). The generative feature of an HMM is also useful when we want to build a probabilistic dialogue manager that produces the most likely dialogue-act sequences (Hori et al., 2008) or that aims to maximize a reward function in partially observable Markov decision processes (Williams and Young, 2007; Minami et al., 2009). When there are K levels of user satisfaction as overall ratings, we create K HMMs each of which is trained using the dialogue-act sequences in dialogues Dk ⊂ D, where Dk = {∀di7 |r(di) = k}. We use the EM-algorithm to train HMMs. Here, we assume that ea</context>
</contexts>
<marker>Isomura, Toriumi, Ishii, 2009</marker>
<rawString>Naoki Isomura, Fujio Toriumi, and Kenichiro Ishii. 2009. Evaluation method of non-task-oriented dialogue system using HMM. IEICE Transactions on Information and Sys-</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>