<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000976">
<title confidence="0.9993585">
Automatic Generation of a Lexical Resource to support Semantic Role
Labeling in Portuguese
</title>
<author confidence="0.996684">
Magali Sanches Duran Sandra Aluísio
</author>
<affiliation confidence="0.7736368">
Center for Computational Linguistics (NILC)
São Paulo University (USP)
São Carlos-SP, Brazil
Center for Computational Linguistics (NILC)
São Paulo University (USP)
</affiliation>
<address confidence="0.913307">
São Carlos-SP, Brazil
</address>
<email confidence="0.99763">
magali.duran@uol.com.br sandra@icmc.usp.br
</email>
<sectionHeader confidence="0.995565" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996643518518519">
This paper reports an approach to automatical-
ly generate a lexical resource to support in-
cremental semantic role labeling annotation in
Portuguese. The data come from the corpus
Propbank-Br (Propbank of Brazilian Portu-
guese) and from the lexical resource of Eng-
lish Propbank, as both share the same
structure. In order to enable the strategy, we
added extra annotation to Propbank-Br. This
approach is part of a previous decision to in-
vert the process of implementing a Propbank
project, by first annotating a core corpus and
only then generating a lexical resource to ena-
ble further annotation tasks. The reasoning
behind such inversion is to explore the task
empirically before distributing the annotation
task and to provide simultaneously: 1) a first
training corpus for SRL in Brazilian Portu-
guese and 2) annotated examples to compose
a lexical resource to support SRL. The main
contribution of this paper is to point out to
what extent linguistic effort may be reduced,
thereby speeding up the construction of a lexi-
cal resource to support SRL for less resourced
languages. The corpus Propbank-Br, with the
extra annotation described herein, is publicly
available.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939108108108">
The task of semantic role labeling (SRL) consists
of identifying a predicate (a verb or a predicate
noun) and its arguments, assigning to each argu-
ment the semantic roles it play in the argumental
structure (Palmer et al. 2010). For example, in the
sentence “Parents complain to education depart-
ment about schools constantly switching uni-
forms”, there are two predicates: “complain” and
“switching”. The argumental structure of “com-
plain” is: “Parents” (agent), “to the education de-
partment” (recipient), “about schools constantly
switching uniforms” (theme). The argumental
structure of “switching” is: “schools” (agent);
“constantly” (time/frequency); “uniforms” (theme).
There is no consensus regarding an ideal
set of semantic role labels and, for this reason, the
first difficult decision in a project of SRL is to
choose which set to adopt. No matter which set is
used, it is not always easy to decide which label to
assign to each argument during the annotation task.
In order to facilitate such decision, some projects
of SRL developed lexical resources that predict the
set of semantic roles required by each predicate.
Some of such resources define semantic roles for
verb classes, as Verbnet (Kipper et al. 2006); oth-
ers for semantic frames, as Framenet (Baker et al.
1998); others define semantic roles for verb senses,
as Propbank (Palmer et al. 2005) or for predicate
nouns, as Nombank (Meyers et al, 2004).
The more detailed and clear is the lexical re-
source, the easier the decision about which role
label to assign during a manual annotation task.
This is very important, because when we ease SRL
annotation, we increase the likelihood of obtaining
a high inter-annotator agreement and, consequent-
ly, the likelihood of obtaining a good precision for
machine learning classifiers for the task.
</bodyText>
<page confidence="0.986686">
216
</page>
<note confidence="0.4390785">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 216–221,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.855526373913044">
Among the lexical resources available for SRL structure to produce large training corpus for SRL
in English, we consider that of Propbank1 the best classifiers.
one for supporting a distributed task of SRL anno- It is not a simple task to construct a lexical re-
tation. From hereafter, we will refer to such lexical source, equivalent to Propbank, to support SRL in
resource simply as Propbank, regardless the fact another language. Everyone that consults regularly
that Propbank encompass both the lexical resource the Unified Verb-Index3, the system that gives ac-
and the annotated corpus. cess to Propbank’s frame files, may observe that
Propbank does not require any linguistic exper- Propbank has been improved over the years, incor-
tise from the annotators and, instead of using role porating evidence provided by continuous annota-
labels as “agent” and “patient”, it uses a small set tion experience. In a project with limited budget
of numbered arguments, like Arg0 (for agents, and time, it is natural to think about reusing exist-
causers or experiencers) and Arg1 (for patients and ing resources in order to maximize the results. In
themes), which are described differently for each this paper, we report the strategies used to build a
verb sense. For example, the verb sense “give.01” lexical resource to support SRL in Portuguese
predicts an Arg0: “giver”, an Arg1: “thing given” (hereafter referred as Verbo-Brasil), profiting from
and an Arg2: “entity given to”. This kind of de- the English resource developed within the Prop-
scription renders the roles very clear for annota- bank project and of annotated instances of the cor-
tors, regardless their background on semantic role pus Propbank-Br (Duran and Aluísio, 2012).
labels. The remainder of this paper is organized as fol-
Propbank has 56492 frame files, which are files lows. Section 2 explains the strategies used in min-
containing (a) simple and complex predicates asso- imizing the efforts towards the construction of
ciated to a given verb; (b) a coarse distinction of frame files; Section 3 briefly addresses an extrinsic
the verb senses; (c) the set of semantic roles of evaluation of Verbo-Brasil obtained from a par-
each sense of a verb (rolesets) and (d) several an- ticular SRL annotation task. Finally, in Section 4,
notated examples to show how the semantic roles we present our conclusions and future work.
may occur in real texts.
In practice, the annotator consults this kind of
lexical resource while performing the annotation
task. In the frame file of the verb being annotated,
he looks for the sense that best suits the instance of
annotation in question. Once identified the verb
sense, the annotator needs to identify the constitu-
ents that play the semantic roles predicted for that
verb sense, assigning them the respective role la-
bels.
In short, the lexical resource of verbal frame
files works as a repository of knowledge for SRL,
accessible during the annotation task, that reduces
the learning curve of SRL and facilitates the as-
signment of annotation tasks to several annotators.
Provided that every instance receives a double-
blind annotation, the quality of the annotation may
be controlled through inter-annotator agreement.
Instances with disagreement may be discarded or
receive linguists’ adjudication. This kind of lexical
resource, therefore, is an essential part of the infra-
2 Methodology
Initially, we intended to construct Verbo-Brasil by
manually creating frame files for the 1000 most
frequent verbs in Portuguese, using the editor of
frame files Cornerstone (Choi et. al. 2010), devel-
oped within the Propbank project. We envisaged,
from the beginning, the possibility of reusing anno-
tated instances of the corpus Propbank-Br, de-
scribed in the Subsection 2.1, as examples to
illustrate verb senses. However, when we started
the task, we realized it was possible to automatical-
ly construct frame files, reducing the effort re-
quired for the task. Automatization entailed the use
of two strategies. The first strategy constituted the
creation of frame files using the existing data from
both the corpus of the earlier version of Propbank-
Br and the lexical repository of the English Prop-
bank plus some new data, which was incorporated
for this purpose in an updated version of Propbank-
Br; this strategy is described in the Subsection 2.2.
In the second strategy, described in Subsection 2.3,
we duplicated the structure of the framefiles from
1 http://verbs.colorado.edu/~mpalmer/projects/ace.html
2 As informed in the site of the Verb-Index, updated on
08/01/2013.
3 http://verbs.colorado.edu/verb-index/
217
the English Propbank to Propbank-Br for every add the extra information required to the corpus
verb which, in English, possessed a single sense. Propbank-Br. Aiming this, we created six “word
2.1 The corpus Propbank-Br tags” in corpus Propbank-Br, using the same anno-
The corpus Propbank-Br (Duran and Aluisio, tation tool used to annotate the original corpus
2012) was annotated by a sole linguist, aiming to (SALTO – Burchardt et al. 2006), as may be seen
provide a training corpus for SRL. During this pro- in Fig.1.
cess, we investigated to which extent the Propbank
guidelines were reusable for undertaking an analo-
gous approach to SRL in Portuguese. We ascer-
tained the need of some adjustments in the
guidelines in order to deal with differences be-
tween the Portuguese and English languages, as
well as the differences between the parser outputs
of the respective treebanks. As there was no lexical
resource to support the annotation task, the sense
distinction was made simultaneously to the annota-
tion task, taking as base the guidelines of Propbank
4 5.
The annotation was over the Brazilian portion of
Bosque corpus (Afonso et. al. 2002), containing
4213 sentences. Bosque corpus is a treebank anno-
tated by the parser Palavras (Bick, 2000) and re-
vised by linguists. The sentences produced 6142
instances for annotation. Two SRL classifiers were
trained on the resulting corpus. One of them (Alva-
Manchego and Rosa, 2012) adopted a semi-
supervised approach and obtained an F-Measure of
82.3%; the other (Fonseca and Rosa, 2013) adopt-
ed a neural architecture to label semantic argu-
ments, disregarding the syntactic layer of
annotation, and obtained an F-Measure of 62.82%.
2.2 Reusing existing data from Propbank-Br
and English Propbank
To enable this strategy, it was necessary to add
previously some extra data in the corpus Prop-
bank-Br, a manual task that was by far quicker
than constructing the frame files from scratch.
First, we defined which fields of the frame file
could be filled in with information from English
Propbank, which ones could be filled in with in-
formation from Propbank-Br and which fields
would require new information, not available in
</bodyText>
<figureCaption confidence="0.955378769230769">
any one of the existing resources. The idea was to
Figure 1. Extra annotation inserted in Propbank-Br.
The word tags are:
(1) PB-roleset: an equivalent roleset-id in
Propbank, was used as field key to bring,
from Propbank, the semantic roles, the se-
mantic roles description, the related Verb-
net classes and the Verbnet roles to the
framefiles (Fig. 2);
(2) t-glosa: field that was filled in only in the
first occurrence of a verb sense; it contains
a brief description or a synonym of this
sense of the verb to distinguish it from the
</figureCaption>
<table confidence="0.9036728125">
other possible senses.
(3) Nota (note): field used for observations re-
garding a roleset contained within a verb’s
framefile when further clarification is
thought to be helpful to the annotator;
(4) Predicate_lemma: field, filled in only in
the first occurrence of a verb sense, con-
taining the verb lemma or the name of a
complex predicate (phrasal verb) when ap-
plicable;
(5) Sentido (sense): field that indicates which
verb sense is the one being used in the sen-
tence in question, also referred as roleset
id, and is filled in for all instances. Once
classified, the sentences can be subse-
quently added as examples of their respec-
</table>
<figure confidence="0.6205287">
4http://verbs.colorado.edu/~mpalmer/projects/ace/PBguideline
s.pdf
5 http://verbs.colorado.edu/~mpalmer/projects/ace/ Fram-
ingGuidelines.pdf
218
tive verb sense within the appropriate
frame file;
(6) Iota_do_exemplo (example note): field
used to convey information about a given
example.
</figure>
<figureCaption confidence="0.995242">
Figure 2. Data brought from Propbank using the
roleset id as field key.
</figureCaption>
<bodyText confidence="0.999878484848485">
Once we had created the word tags in the cor-
pus, we undertook the annotation task to fill in
them, as showed in the Fig.1. The greater the num-
ber of senses of a verb (polysemy), the greater was
the difficulty to elect an English equivalent in Eng-
lish Propbank to fill in the word tag “PB_roleset”.
We realized that highly polysemous verbs would
demand special attention in the next phase of the
process, that is, during the revision of frame files
automatically generated.
The annotation task provided the identification
of 1453 verb senses in Portuguese for 1060 verb
lemmas (an average of 1.37 senses per lemma).
From the 1060 verb lemmas annotated in the cor-
pus, 80% present only one sense, 13% present two
senses; 3% present three senses and 4% present
four or more senses. Only 109 of the 1453 senses
identified in Portuguese did not have an equivalent
verb sense in English identified in Propbank. Con-
sequently, as the frame files of such 109 verbs
could not obtain the fields brought from Propbank
automatically, they required manual edition.
Using the XML frame file structure of Prop-
bank, we defined the automatic generation of
frame files, combining data from Propbank-Br and
from Propbank, as shown in Fig.3. In the frame file
structure, we used the field called “framnet”
(aimed to store mappings to Framenet) for the in-
formation brought from the word tag “PB-roleset”,
that is, the equivalent roleset id in the English
Propbank. The Propbank roleset id was the field
key to access and bring data from the respective
English frame file.
</bodyText>
<figureCaption confidence="0.967921">
Figure 3. Frame file combining data from Propbank-Br
and data brought from Propbank
</figureCaption>
<bodyText confidence="0.999772285714286">
The strategy succeeded, and we achieved 1060
frame files with 1453 verb senses and 6142 anno-
tated examples. After the generation, we began the
revision of frame files with the most frequent
verbs, translating the description of semantic roles,
as may be seen in Fig.4. Currently, 541 frame files
are fully revised.
</bodyText>
<figureCaption confidence="0.923474666666667">
Figure 4. Frame file that combines information from
corpus Propbank-Br and from Propbank’s equivalent
roleset.
</figureCaption>
<subsectionHeader confidence="0.9867885">
2.3 Extension of the lexical resource using
monosemous verbs
</subsectionHeader>
<bodyText confidence="0.997915666666667">
During the task of filling in the word tags in the
corpus Propbank-Br, we observed that verbs pre-
senting a unique sense (monosemous verbs) were
</bodyText>
<page confidence="0.997553">
219
</page>
<bodyText confidence="0.999981377777778">
the easiest to link to an English verb sense in Prop-
bank and almost always the equivalent verb sense
was the unique sense of the respective frame file.
This led us to hypothetize that monosemous verbs
in Portuguese, would probably correspond to mon-
osemous verbs in English and vice-versa, whenev-
er an equivalent verb exists.
On that basis, we decided to extend our resource
taking as the start point the frame files that have a
single verb sense in English Propbank. We identi-
fied 3737 English frame files that met such condi-
tion. We then translated only the verb lemmas of
such frame files. Translation was executed auto-
matically using Google translator and revised
manually. We chose Google translator because we
needed to translate at once 3737 out-of-context
verb lemmas in a quickly and uncomplicated man-
ner. It would be ideal if Google translator returned
the word class of the results, thus allowing us to
filter the verbs (we would only have obtained such
result if we had translated the verbs one-by-one).
For several verbs, the automatic translation pro-
vided no output. Among the output words in Por-
tuguese, there were several nouns, many of which
do not correspond to any verb in Portuguese (eg.
“to hangar”, “to shark”, “to tassle”). We then re-
vised the translation, providing better equivalents
when necessary and marking an “N” for those
translated lexical items that were not verbs in Por-
tuguese. After eliminating: (1) repetitions of trans-
lated verbs (two or more verbs translated into a
same verb in Portuguese) and (2) verbs that we
already had in our database, we obtained 1538 new
verbs to extend our resource.
The next step was to duplicate the respective
English frame files, using the name of the verb in
Portuguese to substitute the name of the English
verb in the fields “roleset id” and “predicate lem-
ma”. Subsequently, we replaced the example sen-
tences in English by ones in Portuguese, extracted
from corpus PLN-Br (Bruckschen et al., 2008).
Lastly, to complete these new frame files, we are
now annotating the examples with semantic role
labels. Cornerstone frame files editor is being used
for this task.
</bodyText>
<sectionHeader confidence="0.999622" genericHeader="introduction">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999981894736842">
The two strategies we reported to automatically
generate Portuguese frame files gave us 2598
framefiles. The 541 frame files already revised
correspond to the verbs with frequency above 1000
in the corpus PLN-Br, which include the most pol-
ysemous verbs in Portuguese. Such verbs were
target of a double-blind annotation task of 8345
instances extracted from the same corpus. The an-
notation task has just been accomplished and will
be fully reported in a later date; the Kappa inter
annotator agreement (Carletta, 1996) for verb
sense identification was 0.93.
This annotation task gave us feedback to evalu-
ate and improve the respective frame files. Among
the actions taken during the annotation task we can
cite: adding new senses identified in the corpus;
merging or splitting senses for verbs that presented
low inter-annotator agreement; including new ex-
amples to better illustrate a verb sense.
</bodyText>
<sectionHeader confidence="0.923107" genericHeader="method">
4 Concluding Remarks and Future work
</sectionHeader>
<bodyText confidence="0.9999524">
The approach we adopted to build a Propbank-like
lexical resource to support SRL in Brazilian Portu-
guese may be of use for other researchers working
on under-represented languages and with a limited
budget.
The 541 already revised frame files were used in
a double-blind annotation SRL task that obtained a
Kappa inter-annotator agreement for sense distinc-
tion of 0.93.
In the future, we plan to use Verbnet classes, an
information brought from the equivalent verb sense
in Propbank, to find in Verbnet-Br (Scarton et al.,
2014) verb senses that are not in Verbo-Brasil.
As soon as we accomplish the revision of the
frame files, we will make Verbo-Brasil publicly
available. The new version of the corpus Prop-
bank-Br, with the extra annotation described in this
paper is now available for download at
nilc.icmc.usp.br/portlex/index.php/en/downloadsin
gl.
</bodyText>
<sectionHeader confidence="0.997483" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99941175">
Part of the results presented in this paper were ob-
tained through research activity in the project enti-
tled “Semantic Processing of Texts in Brazilian
Portuguese”, sponsored by Samsung Eletrônica da
Amazônia Ltda, under the terms of Brazilian fed-
eral law number 8.248/91. We also thank financial
support from FAPESP and CAPES, process num-
ber 151/2013 (Portal de Min@s project).
</bodyText>
<page confidence="0.987724">
220
</page>
<note confidence="0.94706">
Computational Processing of Portuguese (PROPOR
2014). Heidelberg: Springer Verlag, 2014. v. 1. p.
153-164.
</note>
<sectionHeader confidence="0.962998" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684518518519">
Afonso S. ; Bick, E. ; Haber, E. ; Santos, D. (2002) Flo-
resta sintá(c)tica: a treebank for Portuguese. Procee-
dings of LREC 2002.
Alva Manchego, F. E.; Rosa, J. L. G. (2012). Semantic
Role Labeling for Brazilian Portuguese: A Bench-
mark. In IBERAMIA 2012, Lecture Notes in Artifici-
al Intelligence, v. 7637 p. 481–490. Springer.
Baker, C.F.; Fillmore, C. J.; Lowe. J. B. (1998).The
Berkeley FrameNet Project. Proceedings of Compu-
tational Linguistics 1998 Conference.
Bick, E. (2000). The Parsing System Palavras Automat-
ic Grammatical Analysis of Portuguese in a Con-
straint Grammar Framework. Aarhus, Denmark,
Aarhus University Press.
Bruckschen, M., Muniz, F., Souza, J. G. C., Fuchs, J. T.,
Infante, K., Muniz, M., Gonçalves, P. N., Vieira, R.;
Aluísio, S. M. (2008) “Anotação Linguística em
XML do Corpus PLN-BR”. NILC-TR-09-08, 39 p.
Burchardt, A.; Erk, K.; Frank, A.; Kowalski, A.; Pado,
S. (2006) SALTO - A Versatile Multi-Level Annota-
tion Tool. Proceedings of LREC 2006.
Carletta, Jean. (1996) Assessing agreement on classifi-
cation tasks: The kappa statistic. Computational Lin-
guistics, 22(2), pp. 249–254.
Choi, J. D.; Bonial, C.; Palmer, M. (2010) Propbank
Frameset Annotation Guidelines Using a Dedicated
Editor, Cornerstone. Proceedings of LREC-2010.
Duran, M. S.; Aluísio, S. M. (2012). Propbank-Br: a
Brazilian Treebank annotated with semantic role la-
bels. Proceedings of LREC 2012, pp. 1862-1867.
Fonseca, E. R.; Rosa, J. L. G. (2013) A Two-Step Con-
volutional Neural Network Approach for Semantic
Role Labeling. Proceedings of IJCNN 2013 Interna-
tional Joint Conference on Neural Networks.
Kipper,K.; Korhonen, Anna; Ryant, N.; Palmer, M.
(2006). Extensive Classifications of English verbs.
Proceedings of the 12th EURALEX International
Congress. Turin, Italy.
Meyers, A.; Reeves, R.; Macleod, C.; Szekely, R.; Ziel-
inska, V.; Young, B.; Grishman, R. (2004), The
NomBank Project: An Interim Report. Proceedings.
of HLT-EACL Workshop: Frontiers in Corpus Anno-
tation.
Palmer, M.; Gildea, D.; Kingsbury, P. (2005). The
Proposition Bank: An Annotated Corpus of Semantic
Roles. Computational Linguistics, 31:1, pp. 71-105.
Palmer, M.; Gildea, D.; Xue, N. (2010). Semantic Role
Labeling. Synthesis Lectures on Human Language
Technology Series, ed. Graeme Hirst, Mogan &amp;
Claypoole.
Scarton, C. ; Duran, M. S.; Aluísio, S. M. (2014) Using
Cross-linguistic Knowledge to Build VerbNet-Style
Lexicons: Results for a (Brazilian) Portuguese Verb-
Net. Proceedings of the International Conference on
</reference>
<page confidence="0.9983">
221
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.399081">
<title confidence="0.990904">Automatic Generation of a Lexical Resource to support Semantic Labeling in Portuguese</title>
<author confidence="0.997298">Magali Sanches Duran Sandra Aluísio</author>
<affiliation confidence="0.9618445">Center for Computational Linguistics São Paulo University</affiliation>
<address confidence="0.687245">São Carlos-SP, Brazil</address>
<affiliation confidence="0.956563">Center for Computational Linguistics São Paulo University</affiliation>
<address confidence="0.82298">São Carlos-SP, Brazil</address>
<email confidence="0.826246">magali.duran@uol.com.brsandra@icmc.usp.br</email>
<abstract confidence="0.997220071428572">This paper reports an approach to automatically generate a lexical resource to support incremental semantic role labeling annotation in Portuguese. The data come from the corpus Propbank-Br (Propbank of Brazilian Portuguese) and from the lexical resource of English Propbank, as both share the same structure. In order to enable the strategy, we added extra annotation to Propbank-Br. This approach is part of a previous decision to invert the process of implementing a Propbank project, by first annotating a core corpus and only then generating a lexical resource to enable further annotation tasks. The reasoning behind such inversion is to explore the task empirically before distributing the annotation task and to provide simultaneously: 1) a first training corpus for SRL in Brazilian Portuguese and 2) annotated examples to compose a lexical resource to support SRL. The main contribution of this paper is to point out to what extent linguistic effort may be reduced, thereby speeding up the construction of a lexical resource to support SRL for less resourced languages. The corpus Propbank-Br, with the extra annotation described herein, is publicly available.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>Floresta sintá(c)tica: a treebank for Portuguese.</title>
<date>2002</date>
<booktitle>Proceedings of LREC</booktitle>
<marker>Bick, 2002</marker>
<rawString>Afonso S. ; Bick, E. ; Haber, E. ; Santos, D. (2002) Floresta sintá(c)tica: a treebank for Portuguese. Proceedings of LREC 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alva Manchego</author>
<author>F E</author>
<author>J L G Rosa</author>
</authors>
<title>Semantic Role Labeling for Brazilian Portuguese: A Benchmark.</title>
<date>2012</date>
<booktitle>In IBERAMIA 2012, Lecture Notes in Artificial Intelligence,</booktitle>
<pages>7637--481</pages>
<publisher>Springer.</publisher>
<marker>Manchego, E, Rosa, 2012</marker>
<rawString>Alva Manchego, F. E.; Rosa, J. L. G. (2012). Semantic Role Labeling for Brazilian Portuguese: A Benchmark. In IBERAMIA 2012, Lecture Notes in Artificial Intelligence, v. 7637 p. 481–490. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B</author>
</authors>
<title>Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>Proceedings of Computational Linguistics</booktitle>
<note>Conference.</note>
<marker>B, 1998</marker>
<rawString>Baker, C.F.; Fillmore, C. J.; Lowe. J. B. (1998).The Berkeley FrameNet Project. Proceedings of Computational Linguistics 1998 Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>The Parsing System Palavras Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework.</title>
<date>2000</date>
<publisher>University Press.</publisher>
<location>Aarhus, Denmark, Aarhus</location>
<contexts>
<context position="9364" citStr="Bick, 2000" startWordPosition="1478" endWordPosition="1479">RL in Portuguese. We ascertained the need of some adjustments in the guidelines in order to deal with differences between the Portuguese and English languages, as well as the differences between the parser outputs of the respective treebanks. As there was no lexical resource to support the annotation task, the sense distinction was made simultaneously to the annotation task, taking as base the guidelines of Propbank 4 5. The annotation was over the Brazilian portion of Bosque corpus (Afonso et. al. 2002), containing 4213 sentences. Bosque corpus is a treebank annotated by the parser Palavras (Bick, 2000) and revised by linguists. The sentences produced 6142 instances for annotation. Two SRL classifiers were trained on the resulting corpus. One of them (AlvaManchego and Rosa, 2012) adopted a semisupervised approach and obtained an F-Measure of 82.3%; the other (Fonseca and Rosa, 2013) adopted a neural architecture to label semantic arguments, disregarding the syntactic layer of annotation, and obtained an F-Measure of 62.82%. 2.2 Reusing existing data from Propbank-Br and English Propbank To enable this strategy, it was necessary to add previously some extra data in the corpus Propbank-Br, a m</context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>Bick, E. (2000). The Parsing System Palavras Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. Aarhus, Denmark, Aarhus University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bruckschen</author>
<author>F Muniz</author>
<author>J G C Souza</author>
<author>J T Fuchs</author>
<author>K Infante</author>
<author>M Muniz</author>
<author>P N Gonçalves</author>
<author>R Vieira</author>
<author>S M Aluísio</author>
</authors>
<date>2008</date>
<booktitle>Anotação Linguística em XML do Corpus PLN-BR”.</booktitle>
<pages>09--08</pages>
<contexts>
<context position="16044" citStr="Bruckschen et al., 2008" startWordPosition="2580" endWordPosition="2583">r those translated lexical items that were not verbs in Portuguese. After eliminating: (1) repetitions of translated verbs (two or more verbs translated into a same verb in Portuguese) and (2) verbs that we already had in our database, we obtained 1538 new verbs to extend our resource. The next step was to duplicate the respective English frame files, using the name of the verb in Portuguese to substitute the name of the English verb in the fields “roleset id” and “predicate lemma”. Subsequently, we replaced the example sentences in English by ones in Portuguese, extracted from corpus PLN-Br (Bruckschen et al., 2008). Lastly, to complete these new frame files, we are now annotating the examples with semantic role labels. Cornerstone frame files editor is being used for this task. 3 Evaluation The two strategies we reported to automatically generate Portuguese frame files gave us 2598 framefiles. The 541 frame files already revised correspond to the verbs with frequency above 1000 in the corpus PLN-Br, which include the most polysemous verbs in Portuguese. Such verbs were target of a double-blind annotation task of 8345 instances extracted from the same corpus. The annotation task has just been accomplishe</context>
</contexts>
<marker>Bruckschen, Muniz, Souza, Fuchs, Infante, Muniz, Gonçalves, Vieira, Aluísio, 2008</marker>
<rawString>Bruckschen, M., Muniz, F., Souza, J. G. C., Fuchs, J. T., Infante, K., Muniz, M., Gonçalves, P. N., Vieira, R.; Aluísio, S. M. (2008) “Anotação Linguística em XML do Corpus PLN-BR”. NILC-TR-09-08, 39 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Burchardt</author>
<author>K Erk</author>
<author>A Frank</author>
<author>A Kowalski</author>
<author>S Pado</author>
</authors>
<title>SALTO - A Versatile Multi-Level Annotation Tool.</title>
<date>2006</date>
<booktitle>Proceedings of LREC</booktitle>
<contexts>
<context position="8556" citStr="Burchardt et al. 2006" startWordPosition="1342" endWordPosition="1345">ramefiles from 1 http://verbs.colorado.edu/~mpalmer/projects/ace.html 2 As informed in the site of the Verb-Index, updated on 08/01/2013. 3 http://verbs.colorado.edu/verb-index/ 217 the English Propbank to Propbank-Br for every add the extra information required to the corpus verb which, in English, possessed a single sense. Propbank-Br. Aiming this, we created six “word 2.1 The corpus Propbank-Br tags” in corpus Propbank-Br, using the same annoThe corpus Propbank-Br (Duran and Aluisio, tation tool used to annotate the original corpus 2012) was annotated by a sole linguist, aiming to (SALTO – Burchardt et al. 2006), as may be seen provide a training corpus for SRL. During this pro- in Fig.1. cess, we investigated to which extent the Propbank guidelines were reusable for undertaking an analogous approach to SRL in Portuguese. We ascertained the need of some adjustments in the guidelines in order to deal with differences between the Portuguese and English languages, as well as the differences between the parser outputs of the respective treebanks. As there was no lexical resource to support the annotation task, the sense distinction was made simultaneously to the annotation task, taking as base the guidel</context>
</contexts>
<marker>Burchardt, Erk, Frank, Kowalski, Pado, 2006</marker>
<rawString>Burchardt, A.; Erk, K.; Frank, A.; Kowalski, A.; Pado, S. (2006) SALTO - A Versatile Multi-Level Annotation Tool. Proceedings of LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>249--254</pages>
<contexts>
<context position="16742" citStr="Carletta, 1996" startWordPosition="2694" endWordPosition="2695">h semantic role labels. Cornerstone frame files editor is being used for this task. 3 Evaluation The two strategies we reported to automatically generate Portuguese frame files gave us 2598 framefiles. The 541 frame files already revised correspond to the verbs with frequency above 1000 in the corpus PLN-Br, which include the most polysemous verbs in Portuguese. Such verbs were target of a double-blind annotation task of 8345 instances extracted from the same corpus. The annotation task has just been accomplished and will be fully reported in a later date; the Kappa inter annotator agreement (Carletta, 1996) for verb sense identification was 0.93. This annotation task gave us feedback to evaluate and improve the respective frame files. Among the actions taken during the annotation task we can cite: adding new senses identified in the corpus; merging or splitting senses for verbs that presented low inter-annotator agreement; including new examples to better illustrate a verb sense. 4 Concluding Remarks and Future work The approach we adopted to build a Propbank-like lexical resource to support SRL in Brazilian Portuguese may be of use for other researchers working on under-represented languages an</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Carletta, Jean. (1996) Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2), pp. 249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Choi</author>
<author>C Bonial</author>
<author>M Palmer</author>
</authors>
<title>Propbank Frameset Annotation Guidelines Using a Dedicated Editor, Cornerstone.</title>
<date>2010</date>
<booktitle>Proceedings of LREC-2010.</booktitle>
<marker>Choi, Bonial, Palmer, 2010</marker>
<rawString>Choi, J. D.; Bonial, C.; Palmer, M. (2010) Propbank Frameset Annotation Guidelines Using a Dedicated Editor, Cornerstone. Proceedings of LREC-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Duran</author>
<author>S M Aluísio</author>
</authors>
<title>Propbank-Br: a Brazilian Treebank annotated with semantic role labels.</title>
<date>2012</date>
<booktitle>Proceedings of LREC 2012,</booktitle>
<pages>1862--1867</pages>
<contexts>
<context position="5237" citStr="Duran and Aluísio, 2012" startWordPosition="817" endWordPosition="820">order to maximize the results. In themes), which are described differently for each this paper, we report the strategies used to build a verb sense. For example, the verb sense “give.01” lexical resource to support SRL in Portuguese predicts an Arg0: “giver”, an Arg1: “thing given” (hereafter referred as Verbo-Brasil), profiting from and an Arg2: “entity given to”. This kind of de- the English resource developed within the Propscription renders the roles very clear for annota- bank project and of annotated instances of the cortors, regardless their background on semantic role pus Propbank-Br (Duran and Aluísio, 2012). labels. The remainder of this paper is organized as folPropbank has 56492 frame files, which are files lows. Section 2 explains the strategies used in mincontaining (a) simple and complex predicates asso- imizing the efforts towards the construction of ciated to a given verb; (b) a coarse distinction of frame files; Section 3 briefly addresses an extrinsic the verb senses; (c) the set of semantic roles of evaluation of Verbo-Brasil obtained from a pareach sense of a verb (rolesets) and (d) several an- ticular SRL annotation task. Finally, in Section 4, notated examples to show how the semant</context>
</contexts>
<marker>Duran, Aluísio, 2012</marker>
<rawString>Duran, M. S.; Aluísio, S. M. (2012). Propbank-Br: a Brazilian Treebank annotated with semantic role labels. Proceedings of LREC 2012, pp. 1862-1867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E R Fonseca</author>
<author>J L G Rosa</author>
</authors>
<title>A Two-Step Convolutional Neural Network Approach for Semantic Role Labeling.</title>
<date>2013</date>
<booktitle>Proceedings of IJCNN 2013 International Joint Conference on Neural Networks.</booktitle>
<contexts>
<context position="9649" citStr="Fonseca and Rosa, 2013" startWordPosition="1522" endWordPosition="1525">ce to support the annotation task, the sense distinction was made simultaneously to the annotation task, taking as base the guidelines of Propbank 4 5. The annotation was over the Brazilian portion of Bosque corpus (Afonso et. al. 2002), containing 4213 sentences. Bosque corpus is a treebank annotated by the parser Palavras (Bick, 2000) and revised by linguists. The sentences produced 6142 instances for annotation. Two SRL classifiers were trained on the resulting corpus. One of them (AlvaManchego and Rosa, 2012) adopted a semisupervised approach and obtained an F-Measure of 82.3%; the other (Fonseca and Rosa, 2013) adopted a neural architecture to label semantic arguments, disregarding the syntactic layer of annotation, and obtained an F-Measure of 62.82%. 2.2 Reusing existing data from Propbank-Br and English Propbank To enable this strategy, it was necessary to add previously some extra data in the corpus Propbank-Br, a manual task that was by far quicker than constructing the frame files from scratch. First, we defined which fields of the frame file could be filled in with information from English Propbank, which ones could be filled in with information from Propbank-Br and which fields would require</context>
</contexts>
<marker>Fonseca, Rosa, 2013</marker>
<rawString>Fonseca, E. R.; Rosa, J. L. G. (2013) A Two-Step Convolutional Neural Network Approach for Semantic Role Labeling. Proceedings of IJCNN 2013 International Joint Conference on Neural Networks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kipper</author>
<author>Anna Korhonen</author>
<author>N Ryant</author>
<author>M Palmer</author>
</authors>
<title>Extensive Classifications of English verbs.</title>
<date>2006</date>
<booktitle>Proceedings of the 12th EURALEX International Congress.</booktitle>
<location>Turin, Italy.</location>
<contexts>
<context position="2774" citStr="Kipper et al. 2006" startWordPosition="423" endWordPosition="426">“schools” (agent); “constantly” (time/frequency); “uniforms” (theme). There is no consensus regarding an ideal set of semantic role labels and, for this reason, the first difficult decision in a project of SRL is to choose which set to adopt. No matter which set is used, it is not always easy to decide which label to assign to each argument during the annotation task. In order to facilitate such decision, some projects of SRL developed lexical resources that predict the set of semantic roles required by each predicate. Some of such resources define semantic roles for verb classes, as Verbnet (Kipper et al. 2006); others for semantic frames, as Framenet (Baker et al. 1998); others define semantic roles for verb senses, as Propbank (Palmer et al. 2005) or for predicate nouns, as Nombank (Meyers et al, 2004). The more detailed and clear is the lexical resource, the easier the decision about which role label to assign during a manual annotation task. This is very important, because when we ease SRL annotation, we increase the likelihood of obtaining a high inter-annotator agreement and, consequently, the likelihood of obtaining a good precision for machine learning classifiers for the task. 216 Proceedin</context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2006</marker>
<rawString>Kipper,K.; Korhonen, Anna; Ryant, N.; Palmer, M. (2006). Extensive Classifications of English verbs. Proceedings of the 12th EURALEX International Congress. Turin, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Reeves</author>
<author>C Macleod</author>
<author>R Szekely</author>
<author>V Zielinska</author>
<author>B Young</author>
<author>R Grishman</author>
</authors>
<title>The NomBank Project: An Interim Report. Proceedings. of HLT-EACL Workshop: Frontiers in Corpus Annotation.</title>
<date>2004</date>
<contexts>
<context position="2971" citStr="Meyers et al, 2004" startWordPosition="457" endWordPosition="460">oject of SRL is to choose which set to adopt. No matter which set is used, it is not always easy to decide which label to assign to each argument during the annotation task. In order to facilitate such decision, some projects of SRL developed lexical resources that predict the set of semantic roles required by each predicate. Some of such resources define semantic roles for verb classes, as Verbnet (Kipper et al. 2006); others for semantic frames, as Framenet (Baker et al. 1998); others define semantic roles for verb senses, as Propbank (Palmer et al. 2005) or for predicate nouns, as Nombank (Meyers et al, 2004). The more detailed and clear is the lexical resource, the easier the decision about which role label to assign during a manual annotation task. This is very important, because when we ease SRL annotation, we increase the likelihood of obtaining a high inter-annotator agreement and, consequently, the likelihood of obtaining a good precision for machine learning classifiers for the task. 216 Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 216–221, Denver, Colorado, June 4–5, 2015. Among the lexical resources available for SRL structure to pro</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Meyers, A.; Reeves, R.; Macleod, C.; Szekely, R.; Zielinska, V.; Young, B.; Grishman, R. (2004), The NomBank Project: An Interim Report. Proceedings. of HLT-EACL Workshop: Frontiers in Corpus Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<pages>71--105</pages>
<contexts>
<context position="2915" citStr="Palmer et al. 2005" startWordPosition="447" endWordPosition="450">d, for this reason, the first difficult decision in a project of SRL is to choose which set to adopt. No matter which set is used, it is not always easy to decide which label to assign to each argument during the annotation task. In order to facilitate such decision, some projects of SRL developed lexical resources that predict the set of semantic roles required by each predicate. Some of such resources define semantic roles for verb classes, as Verbnet (Kipper et al. 2006); others for semantic frames, as Framenet (Baker et al. 1998); others define semantic roles for verb senses, as Propbank (Palmer et al. 2005) or for predicate nouns, as Nombank (Meyers et al, 2004). The more detailed and clear is the lexical resource, the easier the decision about which role label to assign during a manual annotation task. This is very important, because when we ease SRL annotation, we increase the likelihood of obtaining a high inter-annotator agreement and, consequently, the likelihood of obtaining a good precision for machine learning classifiers for the task. 216 Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 216–221, Denver, Colorado, June 4–5, 2015. Among </context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Palmer, M.; Gildea, D.; Kingsbury, P. (2005). The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31:1, pp. 71-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>N Xue</author>
</authors>
<date>2010</date>
<booktitle>Semantic Role Labeling. Synthesis Lectures on Human Language Technology Series,</booktitle>
<editor>ed. Graeme Hirst, Mogan &amp; Claypoole.</editor>
<contexts>
<context position="1778" citStr="Palmer et al. 2010" startWordPosition="270" endWordPosition="273">rtuguese and 2) annotated examples to compose a lexical resource to support SRL. The main contribution of this paper is to point out to what extent linguistic effort may be reduced, thereby speeding up the construction of a lexical resource to support SRL for less resourced languages. The corpus Propbank-Br, with the extra annotation described herein, is publicly available. 1 Introduction The task of semantic role labeling (SRL) consists of identifying a predicate (a verb or a predicate noun) and its arguments, assigning to each argument the semantic roles it play in the argumental structure (Palmer et al. 2010). For example, in the sentence “Parents complain to education department about schools constantly switching uniforms”, there are two predicates: “complain” and “switching”. The argumental structure of “complain” is: “Parents” (agent), “to the education department” (recipient), “about schools constantly switching uniforms” (theme). The argumental structure of “switching” is: “schools” (agent); “constantly” (time/frequency); “uniforms” (theme). There is no consensus regarding an ideal set of semantic role labels and, for this reason, the first difficult decision in a project of SRL is to choose </context>
</contexts>
<marker>Palmer, Gildea, Xue, 2010</marker>
<rawString>Palmer, M.; Gildea, D.; Xue, N. (2010). Semantic Role Labeling. Synthesis Lectures on Human Language Technology Series, ed. Graeme Hirst, Mogan &amp; Claypoole.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M S Duran</author>
<author>S M Aluísio</author>
</authors>
<title>Using Cross-linguistic Knowledge to Build VerbNet-Style Lexicons: Results for a (Brazilian) Portuguese VerbNet.</title>
<date>2014</date>
<booktitle>Proceedings of the International Conference on</booktitle>
<marker>Duran, Aluísio, 2014</marker>
<rawString>Scarton, C. ; Duran, M. S.; Aluísio, S. M. (2014) Using Cross-linguistic Knowledge to Build VerbNet-Style Lexicons: Results for a (Brazilian) Portuguese VerbNet. Proceedings of the International Conference on</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>