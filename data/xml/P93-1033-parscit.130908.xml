<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000814">
<title confidence="0.8187215">
AN EMPIRICAL STUDY ON THEMATIC KNOWLEDGE ACQUISITION
BASED ON SYNTACTIC CLUES AND HEURISTICS
</title>
<author confidence="0.994105">
Rey-Long Liu* and Von-Wun Soo**
</author>
<affiliation confidence="0.862154666666667">
Department of Computer Science
National Tsing-Hua University
HsinChu, Taiwan, R.O.C.
</affiliation>
<email confidence="0.995066">
Email: dr798303@cs.nthu.edu.tw* and soo@c.s.nthu.edu.tw**
</email>
<sectionHeader confidence="0.99735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999621222222222">
Thematic knowledge is a basis of semantic interpreta-
tion. In this paper, we propose an acquisition method
to acquire thematic knowledge by exploiting syntactic
clues from training sentences. The syntactic clues,
which may be easily collected by most existing syn-
tactic processors, reduce the hypothesis space of the
thematic roles. The ambiguities may be further
resolved by the evidences either from a trainer or
from a large corpus. A set of heurist_cs based on
linguistic constraints is employed to guide the ambi-
guity resolution process. When a trainer is available,
the system generates new sentences vd- ose thematic
validities can be justified by the trainer. When a large
corpus is available, the thematic validity may be justi-
fied by observing the sentences in the corpus. Using
this way, a syntactic processor may become a
thematic recognizer by simply deriving its thematic
knowledge from its own syntactic knowledge.
</bodyText>
<keyword confidence="0.909471666666667">
Keywords: Thematic Knowledge Acquisition, Syntac-
tic Clues, Heuristics-guided Ambiguity Resolution,
Corpus-based Acquisition, Interactive Acquisition
</keyword>
<sectionHeader confidence="0.999556" genericHeader="keywords">
I. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.998351946428572">
Natural language processing (NLP) systems need
various knowledge including syntaclic, semantic,
discourse, and pragmatic knowledge in different
applications. Perhaps due to the relatively well-
established syntactic theories and formalisms, there
were many syntactic processing systems either manu-
ally constructed or automatically extended by various
acquisition methods (Asker92, Berwiek85, Brent91,
Liu92b, Lytinen90, Samuelsson91, Simmons91 Sanfi-
lippo92, Smadja91 and Sekine92). However, the satis-
factory representation and acquisition methods of
domain-independent semantic, discourse, and prag-
matic knowledge are not yet developed or computa-
tionally implemented. NLP systems often suffer the
dilemma of semantic representation. Sophisticated
representation of semantics has better expressive
power but imposes difficulties on acquisition in prac-
tice. On the other hand, the poor adequacy of naive
semantic representation may deteriorate the perfor-
mance of NLP systems. Therefore, for plausible
acquisition and processing, domain-dependent seman-
tic bias was aften employed in many previous acquisi-
tion systems (Grishman92b, Lang88, Lu89, and
Velardi91).
In this paper, we present an implemented sys-
tem that acquires domain-independent thematic
knowledge using available syntactic resources (e.g.
syntactic processing systems and syntactically pro-
cessed corpora). Thematic knowledge can represent
semantic or conceptual entities. For correct and effi-
cient parsinz, thematic expectation serves as a basis
for conflict resolution (Taraban88). For natural
language understanding and other applications (e.g.
machine translation), thematic role recognition is a
major step. Thematic relations may serve as the voca-
bulary shared by the parser, the discourse model, and
the world knowledge (Tanenhaus89). More impor-
tantly, since thematic structures are perhaps most
closely linked to syntactic structures (Jackendoff72),
thematic knowledge acquisition may be more feasible
when only Lyntactic resources are available. The con-
sideration of the availability of the resources from
which thematic knowledge may be derived promotes
the practica feasibility of the acquisition method.
In general, lexical knowledge of a lexical head
should (at least) include 1) the number of arguments
of the lexic.1 head, 2) syntactic properties of the argu-
ments, and 3) thematic roles of the arguments (the
argument t.&apos;ructure). The former two components
may be either already constructed in available syntac-
tic processors or acquired by many syntactic acquisi-
tion systems. However, the acquisition of the thematic
roles of the arguments deserves more exploration. A
constituent Pay have different thematic roles for dif-
ferent verbs in different uses. For example, &amp;quot;John&amp;quot; has
different thematic roles in (1.1) - (1.4).
</bodyText>
<listItem confidence="0.64596575">
(1.1) [Agenz John] turned on the light.
(1.2) [Goal John] inherited a million dollars.
(1.3) The ,nagic wand turned [Theme John] into a
frog.
</listItem>
<page confidence="0.999608">
243
</page>
<tableCaption confidence="0.999831">
Table 1. Syntactic clues for hypothesizing thematic roles
</tableCaption>
<table confidence="0.949283">
Theta role Constituent Animate Subject Object Preposition in PP
Agent(Ag) NP Y y n by
Goal(Go) NP ? y(animate) y till,untill,to,into,down
Source(So) NP ? y(animate) y from
Instrument(In) NP n y(no Ag) n with,by
Theme(Th) NP ? y y of,about
Beneficiary(Be) NP y n y for
Location(Lo) NP,ADJP n y n at,in,on,under
Time(Ti) NP(Ti) n y n at,in,before,after,about,by,on,during
Quantity(Qu) NP(Qu) n - for
Proposition(Po) Proposition n n n none
Manner(Ma) ADVP,PP n n n in,with
Cause(Ca) NP n y n by,for,because of
Result(Re) NP n n y in,into
</table>
<bodyText confidence="0.976087666666667">
(1.4) The letter reached [Goal John] yesterday.
To acquire thematic lexical knowledge, precise
thematic roles of arguments in the sentences needs to
be determined.
In the next section, the thematic roles con-
sidered in this paper are listed. The syntactic proper-
ties of the thematic roles are also summarized. The
syntactic properties serve as a preliminary filter to
reduce the hypothesis space of possible thematic roles
of arguments in training sentences. To further resolve
the ambiguities, heuristics based on various linguistic
phenomena and constraints are introduced in section
3. The heuristics serve as a general guidance for the
system to collect valuable information to discriminate
thematic roles. Current status of the experiment is
reported in section 4. In section 5, the method is
evaluated and related to previous methodologies. We
conclude, in section 6, that by properly collecting
discrimination information from available sources,
thematic knowledge acquisition may be more feasible
in practice.
</bodyText>
<sectionHeader confidence="0.997825" genericHeader="introduction">
2. THEMATIC ROLES AND SYNTAC-
TIC CLUES
</sectionHeader>
<bodyText confidence="0.9950308">
The thematic roles considered in this paper and the
syntactic clues for identifying them are presented in
Table 1. The syntactic clues include 1) the possible
syntactic constituents of the arguments, 2) whether
animate or inanimate arguments, 3) grammatical
functions (subject or object) of the arguments when
they are Noun Phrases (NPs), and 4) p:epositions of
the prepositional phrase in which the at guments may
occur. The syntactic constituents inclede NP, Propo-
sition (Po), Adverbial Phrase (ADIJP), Adjective
Phrase (ADJP), and Prepositional phrase (PP). In
addition to common animate nouns (e.g. he, she, and
I), proper nouns are treated as animate NPs as well.
In Table 1, &amp;quot;y&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;?&amp;quot;, and &amp;quot;-&amp;quot; denote &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;,
&amp;quot;don&apos;t care&amp;quot;, and &amp;quot;seldom&amp;quot; respectively. For example,
an Agent should be an animate NP which may be at
the subject (but not object) position, and if it is in a
PP, the preposition of the PP should be &amp;quot;by&amp;quot; (e.g.
&amp;quot;John&amp;quot; in &amp;quot;the light is turned on by John&amp;quot;).
We consider the thematic roles to be well-
known and referred, although slight differences might
be found in various works. The intrinsic properties of
the thematic roles had been discussed from various
perspectiver; in previous literatures (Jackendoff72 and
Gruber76). Grimshaw88 and Levin86 discussed the
problems of thematic role marking in so-called light
verbs and adjectival passives. More detailed descrip-
tion of the thematic roles may be found in the litera-
tures. To illustrate the thematic roles, consider (2.1)-
(2.9).
</bodyText>
<listItem confidence="0.81134675">
(2.1) [Ag The robber] robbed [So the bank] of [Th the
money].
(2.2) [Th The rock] rolled down [Go the hill].
(2.3) [In The key] can open [Th the door].
(2.4) [Go Will] inherited [Qu a million dollars].
(2.5) [Th The letter] finally reached [Go John].
(2.6) [Lo The restaurant] can dine [Th fifty people].
(2.7) [Ca A fire] burned down [Th the house].
(2.8) [Ag Lthn] bought [Be Mary] [Th a coat] [Ma
reluctantly].
(2.9) [Ag John] promised [Go Mary] [Po to marry
her].
When a training sentence is entered, arguments of
lexical yens in the sentence need to be extracted
before lean ing. This can be achieved by invoking a
syntactic ptocessor.
</listItem>
<page confidence="0.999442">
244
</page>
<tableCaption confidence="0.98521">
Table 2. Heuristics for discriminating ther atic roles
</tableCaption>
<listItem confidence="0.993750785714286">
• Volition Heuristic (VH): Purposive constructions (e.g. in order to) aria purposive adverbials (e.g. deliberately and
intentionally) may occur in sentences with Agent arguments (Gruber76).
• Imperative Heuristic (IH): Imperatives are permissible only for Agent subjects (Gruber76).
• Thematic Hierarchy Heuristic (THH): Given a thematic hierarchy (from higher to lower) &amp;quot;Agent &gt; Location,
Source, Goal &gt; Theme&amp;quot;, the passive by-phrases must reside at a higher level than the derived subjects in the hierar-
chy (i.e. the Thematic Hierarchy Condition in Jackendoff72). In this papzr, we set up the hierarchy: Agent &gt; Loca-
tion, Source, Goal, Instrument, Cause &gt; Theme, Beneficiary, Time, Quantity, Proposition, Manner, Result. Subjects
and objects cannot reside at the same level.
• Preposition Heuristic (PH): The prepositions of the PPs in which the arguments occur often convey good
discrimination information for resolving thematic roles ambiguities (see the &amp;quot;Preposition in PP&amp;quot; column in Table 1).
• One-Theme Heuristic (0TH): An argument is preferred to be Theme if it is the only possible Theme in the argu-
ment structure.
• Uniqueness Heuristic (UH): No two arguments may receive the same thematic role (exclusive of conjunctions
and anaphora which co-relate two constituents assigned with the same thematic role).
</listItem>
<bodyText confidence="0.999749315789474">
If the sentence is selected from a syntactically pro-
cessed corpus (such as the PENN treebank) the argu-
ments may be directly extracted from the corpus. To
identify the thematic roles of the arguments, Table 1
is consulted.
For example, consider (2.1) as the training sen-
tence. Since &amp;quot;the robber&amp;quot; is an animate NP with the
subject grammatical function, it can only qualify for
Ag, Go, So, and Th. Similarly, since &amp;quot;the bank&amp;quot; is an
inanimate NP with the object grammatical function, it
can only satisfy the requirements of Go, So, Th, and
Re. Because of the preposition &amp;quot;of&apos;, &amp;quot;tn3 money&amp;quot; can
only be Th. As a result, after consulting the con-
straints in Table 1, &amp;quot;the robber&amp;quot;, &amp;quot;the bank&amp;quot;, and &amp;quot;the
money&amp;quot; can only be (Ag, Go, So, &apos;a), (Go, So, Th,
Re), and (Tll) respectively. Therefore., although the
clues in Table 1 may serve as a filter, lots of thematic
role ambiguities still call for other discrimination
information and resolution mechanisms.
</bodyText>
<sectionHeader confidence="0.999913333333333" genericHeader="method">
3. FINDING EXTRA INFORMATION
FOR RESOLVING THETA ROLE
AMBIGUITIES
</sectionHeader>
<bodyText confidence="0.999956885714286">
The remaining thematic role ambiguities should be
resolved by the evidences from other sources.
Trainers and corpora are the two most commonly
available sources of the extra information. Interactive
acquisition had been applied in various systems in
which the oracle from the trainer may reduce most
ambiguities (e.g. Lang88, Liu93, Lu89, and
Velardi91). Corpus-based acquisition systems may
also converge to a satisfactory performance by col-
lecting evidences from a large corpus (e.g. Brent91,
Sekine92, Smadja91, and Zernik89). We are con-
cerned with the kinds of information the available
sources may contribute to thematic knowledge
acquisition.
The heuristics to discriminate thematic roles are
proposed in Table 2. The heuristics suggest the sys-
tem the ways of collecting useful information for
resolving ambiguities. Volition Heuristic and Impera-
tive Heurit &apos;lc are for confirming the Agent role,
One-Theme Heuristic is for Theme, while Thematic
Hierarchy Heuristic, Preposition Heuristic and
Uniqueness, Heuristic may be used in a general way.
It shO-ild be noted that, for the purposes of effi-
cient acquisition, not all of the heuristics were identi-
cal to the corresponding original linguistic postula-
tions. For example, Thematic Hierarchy Heuristic was
motivated by the Thematic Hierarchy Condition
(Jackendoff72) but embedded with more constraints
to filter ou , more hypotheses. One-Theme Heuristic
was a relaxed version of the statement &amp;quot;every sen-
tence has a theme&amp;quot; which might be too strong in many
cases (Jack mdoff87).
Because of the space limit, we only use an
example to illustrate the idea. Consider (2.1) &amp;quot;The
robber rob-,ed the bank of the money&amp;quot; again. As
</bodyText>
<page confidence="0.990458">
245
</page>
<bodyText confidence="0.97874395">
mentioned above, after applying the preliminary syn-
tactic clues, &amp;quot;the robber&amp;quot;, &amp;quot;the bank&amp;quot;, and &amp;quot;the
money&amp;quot; may be (Ag, Go, So, Th), (Ge, So, Th, Re),
and (Th) respectively. By applying Uniqueness
Heuristic to the Theme role, the argument structure of
&amp;quot;rob&amp;quot; in the sentence can only be
(AS1) &amp;quot;(Ag, Go, So), (Go, So, Re), (Th)&amp;quot;,
which means that, the external argument is (Ag, Go,
So) and the internal arguments are (Go, So, Re) and
(Th). Based on the intermediate result, Volition
Heuristic, Imperative Heuristic, Thematic Hierarchy
Heuristic, and Preposition Heuristic could be invoked
to further resolve ambiguities.
Volition Heuristic and Imperative Heuristic ask
the learner to verify the validities of the sentences
such as &amp;quot;John intentionally robbed the bank&amp;quot; (&amp;quot;John&amp;quot;
and &amp;quot;the robber&amp;quot; matches because they have the same
properties considered in Table 1 and Table 2). If the
sentence is &amp;quot;accepted&amp;quot;, an Agent is needed for &amp;quot;rob&amp;quot;.
Therefore, the argument structure becomes
</bodyText>
<listItem confidence="0.666749">
(AS2) &amp;quot;(Ag), (Go, So, Re), (Th)&amp;quot;.
</listItem>
<bodyText confidence="0.995848142857143">
Thematic Hierarchy Heuristic guides the
learner to test the validity of the passive form of (2.1).
Similarly, since sentences like &amp;quot;The bank is robbed by
Mary&amp;quot; could be valid, &amp;quot;The robber&amp;quot; is higher than
&amp;quot;the bank&amp;quot; in the Thematic Hierarchy. Therefore, the
learner may conclude that either AS3 or AS4 may be
the argument structure of &amp;quot;rob&amp;quot;:
</bodyText>
<listItem confidence="0.9834475">
(AS3) &amp;quot;(Ag), (Go, So, Re), (Th)&amp;quot;
(AS4) &amp;quot;(Go, So), (Re), fTh)&amp;quot;.
</listItem>
<bodyText confidence="0.994129333333333">
Preposition Heuristic suggests the learner to to
resolve ambiguities based on the prepositions of PPs.
For example, it may suggest the system to confirm:
The money is from the bank? If sc, &amp;quot;the bank&amp;quot; is
recognized as Source. The argument structure
becomes
</bodyText>
<listItem confidence="0.48313">
(AS5) &amp;quot;(Ag, Go), (So), (Th)&amp;quot;.
</listItem>
<bodyText confidence="0.993332083333333">
Combining (AS5) with (AS3) or (ASi; with (AS2),
the learner may conclude that the argt raent structure
of &amp;quot;rob&amp;quot; is &amp;quot;(Ag), (So), (Th)&amp;quot;.
In summary, as the arguments of lexical heads
are entered to the acquisition system, the clues in
Table 1 are consulted first to reduce the hypothesis
space. The heuristics in Table 2 are then invoked to
further resolve the ambiguities by collecting useful
information from other sources. The information that
the heuristics suggest the system to collect is the
thematic validities of the sentences that may help to
confirm the target thematic roles.
The confirmation information required by Voli-
tion Heuristic, Imperative Heuristic. rtnd Thematic
Hierarchy Heuristic may come from corpora (and of
course trainers as well), while Preposition Heuristic
sometimes needs the information only available from
trainers. This is because the derivation of new PPs
might generate ungrammatical sentences not available
in general .;orpora. For example, (3.1) from (2.3)
&amp;quot;The key can open the door&amp;quot; is grammatical, while
(3.2) from (2.5) &amp;quot;The letter finally reached John&amp;quot; is
ungrammatical.
(3.1) The door is opened by the key.
(3.2) *The I-3tter finally reached to John.
Therefore, simple queries as above are preferred in
the method.
It should also be noted that since these heuris-
tics only serve as the guidelines for finding discrimi-
nation information, the sequence of their applications
does not have significant effects on the result of
learning. However, the number of queries may be
minimized by applying the heuristics in the order:
Volition Heuristic and Imperative Heuristic -&gt;
Thematic Hierarchy Heuristic -&gt; Preposition Heuris-
tic. One-Th-me Heuristic and Uniqueness Heuristic
are invoked each time current hypotheses of thematic
roles are changed by the application of the clues, Vol-
ition Heuristic, Imperative Heuristic, Thematic
Hierarchy Heuristic, or Preposition Heuristic. This is
because One-Theme Heuristic and Uniqueness
Heuristic are constraint-based. Given a hypothesis of
thematic rotes, they may be employed to filter out
impossible combinations of thematic roles without
using any wieries. Therefore, as a query is issued by
other heuristics and answered by the trainer or the
corpus, the two heuristics may be used to &amp;quot;extend&amp;quot; the
result by further reducing the hypothesis space.
</bodyText>
<sectionHeader confidence="0.999779" genericHeader="method">
4. EXPERIMENT
</sectionHeader>
<bodyText confidence="0.9999105625">
As described above, the proposed acquisition method
requires syntactic information of arguments as input
(recall Table 1). We believe that the syntactic infor-
mation is one of the most commonly available
resources. ;t may be collected from a syntactic pro-
cessor or a 3yntactically processed corpus. To test the
method wita a public corpus as in Grishman92a, the
PENN Tre ;Bank was used as a syntactically pro-
cessed corpus for learning. Argument packets
(including VP packets and NP packets) were
extracted .torn ATIS corpus (including JUN90,
SRI_TB, and TI_TB tree files), MARI corpus (includ-
ing AMBI(, and WBUR tree files), MUC1 corpus,
and MUC2 corpus of the treebank. VP packets and
NP packets recorded syntactic properties of the argu-
ments of verbs and nouns respectively.
</bodyText>
<page confidence="0.998613">
246
</page>
<tableCaption confidence="0.998457">
Table 3. Argument extraction from TreeBank
</tableCaption>
<table confidence="0.9991008">
Corpus Sentences Words VP packets Verbs NP packets Nouns
ATIS 1373 15286 1716 138 959 188
MARI 543 9897 1067 509 425 288
MUC1 1026 22662 1916 732 907 490
MUC2 3341 73548 6410 1556 3313 1177
</table>
<bodyText confidence="0.999343829545455">
Since not all constructions involving movement
were tagged with trace information in the corpus, to
derive the arguments, the procedure needs to consider
the constructions of passivization, interjection, and
unbounded dependency (e.g. in relative clauses and
wh-questions). That is, it needs to determine whether
a constituent is an argument of a verb (or noun),
whether an argument is moved, and if so, which con-
stituent is the moved argument. Basically, Case
Theory, Theta Theory (Chomsky81), and Foot
Feature Principle (Gazdar85) were employed to locate
the arguments (Liu92a, Liu92b).
Table 3 summarizes the results of the argument
extraction. About 96% of the trees were extracted.
Parse trees with too many words (60) or nodes (i.e. 50
subgoals of parsing) were discarded. Al VP packets
in the parse trees were derived, but only the NP pack-
ets having PPs as modifiers were extracted. These PPs
could help the system to hypothesize argument struc-
tures of nouns. The extracted packets were assimi-
lated into an acquisition system (called EBNLA,
Liu92a) as syntactic subcategorization frames. Dif-
ferent morphologies of lexicons were not counted as
different verbs and nouns.
As an example of the extracted argument pack-
ets, consider the following sentence from MUC1:
&amp;quot;..., at la linea, ..., where a FARC front ambushed an
llth brigade army patrol&amp;quot;.
The extraction procedure derived the following VP
packet for &amp;quot;ambushed&amp;quot;:
ambushed (NP: a FARC front) (WHADVP: where)
(NP: an 11th brigade army patrol)
The first NP was the external argument of the verb.
Other constituents were internal arg rnents of the
verb. The procedure could not deternire whether an
argument was optional or not.
In the corpora, most packets were for a small
number of verbs (e.g. 296 packets for &amp;quot;show&amp;quot; were
found in ATIS). Only 1 to 2 packets could be found
for most verbs. Therefore, although the parse trees
could provide good quality of argument packets, the
information was too sparse to resolve thematic role
ambiguities. This is a weakness embedded in most
corpus-based acquisition methods, since the learner
might finally fail to collect sufficient information after
spending much effort to process the corpus. In that
case, the ambiguities need to be temporarily
suspended. To seed-up learning and focus on the
usage of the proposed method, a trainer was asked to
check the thematic validities (yes/no) of the sentences
generated b.,&apos; the learner.
Excluding packets of some special verbs to be
discussed later and erroneous packets (due to a small
amount of inconsistencies and incompleteness of the
corpus and the extraction procedure), the packets
were fed into the acquisition system (one packet for a
verb). The average accuracy rate of the acquired argu-
ment structures was 0.86. An argument structure was
counted as correct if it was unambiguous and con-
firmed by the trainer. On average, for resolving ambi-
guities, 113 queries were generated for every 100 suc-
cessfully acquired argument structures. The packets
from ATIS caused less ambiguities, since in this
corpus there were many imperative sentences to
which Impemtive Heuristic may be applied. Volition
Heuristic,Tlematic Hierarchy Heuristic, and Preposi-
tion Heuristic had almost equal frequencies of appli-
cation in the experiment.
As an example of how the clues and heuristics
could successfully derive argument structures of
verbs, consider the sentence from ATIS:
&amp;quot;The flight going to San Francisco ...&amp;quot;.
Without issuing any queries, the learner concluded
that an argument structure of &amp;quot;go&amp;quot; is &amp;quot;(Th), (Go)&amp;quot;.
This was because, according to the clues, &amp;quot;San Fran-
cisco&amp;quot; could only be Goal, while according to One-
Theme Heuristic, &amp;quot;the flight&amp;quot; was recognized as
Theme. Most argument structures were acquired
using 1 to 2 queries.
The result showed that, after (manually or
automatically) acquiring an argument packet (i.e. a
syntactic sebcategorization frame plus the syntactic
constituent Df the external argument) of a verb, the
acquisition method could be invoked to upgrade the
syntactic knowledge to thematic knowledge by issu-
ing only 113 queries for every 100 argument packets.
Since checking the validity of the generated sentences
is not a heavy burden for the trainer (answering &apos;yes&apos;
</bodyText>
<page confidence="0.994166">
247
</page>
<bodyText confidence="0.979678195121951">
or &apos;no&apos; only), the method may be attached to various
systems for promoting incremental extensibility of
thematic knowledge.
The way of counting the accuracy rate of the
acquired argument structures deserves notice. Failed
cases were mainly due to the clues and heuristics that
were too strong or overly committed. For example,
the thematic role of &amp;quot;the man&amp;quot; in (4.1) from MARI
could not be acquired using the clues and heuristics.
(4.1) Laura ran away with the man.
In the terminology of Gruber76, this is an expression
of accompaniment which is not considered in the
clues and heuristics. As another example, consider
(4.2) also from MARI.
(42) The greater Boston area ranked eight among
major cities for incidence of AIDS.
The clues and heuristics could not draw any conclu-
sions on the possible thematic roles of &amp;quot;eight&amp;quot;.
On the other hand, the cases counted as &amp;quot;failed&amp;quot;
did not always lead to &amp;quot;erroneous&amp;quot; argument struc-
tures. For example, &amp;quot;Mary&amp;quot; in (2.9) &amp;quot;John promised
Mary to marry her&amp;quot; was treated as Theme rather than
Goal, because &amp;quot;Mary&amp;quot; is the only possible Theme.
Although &amp;quot;Mary&amp;quot; may be Theme in this case as well,
treating &amp;quot;Mary&amp;quot; as Goal is more fme-grained.
The clues and heuristics may often lead to
acceptable argument structures, even if the argument
structures are inherently ambiguous. For example, an
NP might function as more than one thematic role
within a sentence (Jackendoff87). In (4.3), &amp;quot;John&amp;quot;
may be Agent or Source.
(4.3) John sold Mary a coat.
Since Thematic Hierarchy Heuristic assumes that sub-
jects and objects cannot reside at the same level,
&amp;quot;John&amp;quot; must not be assigned as Source. Therefore,
&amp;quot;John&amp;quot; and &amp;quot;Mary&amp;quot; are assigned as Agent and Goal
respectively, and the ambiguity is resolved.
In addition, some thematic roles may cause
ambiguities if only syntactic evidences are available.
Experiencer, such as &amp;quot;John&amp;quot; in (4.4), and Maleficiary,
such as &amp;quot;Mary&amp;quot; in (4.5), are the two examples.
</bodyText>
<listItem confidence="0.951938">
(4.4) Mary surprised John.
(4.5) Mary suffers a headache.
</listItem>
<bodyText confidence="0.999945166666667">
There are difficulties in distinguishing Experiencer,
Agent, Maleficiary and Theme. Fortunately, the verbs
with Experiencer and Maleficiary may be enumerated
before learning. Therefore, the argumem: structures of
these verbs are manually constructed rather than
learned by the proposed method.
</bodyText>
<sectionHeader confidence="0.876659" genericHeader="method">
S. RELATED WORK
</sectionHeader>
<bodyText confidence="0.999919759259259">
To explore the acquisition of domain-independent
semantic knowledge, the universal linguistic con-
straints postulated by many linguistic studies may
provide general (and perhaps coarse-grained) hints.
The hints may be integrated with domain-specific
semantic bias for various applications as well. In the
branch of the study, GB theory (Chomsky81) and
universal feature instantiation principles (Gazdar85)
had been shown to be applicable in syntactic
knowledge acquisition (Berwick85, Liu92a, Liu92b).
The proposed method is closely related to those
methodolog,.es. The major difference is that, various
thematic theories are selected and computationalized
for thematic knowledge acquisition. The idea of
structural patterns in Montemagni92 is similar to
Preposition Heuristic in that the patterns suggest gen-
eral guidance to information extraction.
Extra information resources are needed for
thematic knowledge acquisition. From the cognitive
point of view, morphological, syntactic, semantic,
contextual (Jacobs88), pragmatic, world knowledge,
and observations of the environment (Webster89,
Siskind90) all important resources. However, the
availability of the resources often deteriorated the
feasibility of learning from a practical standpoint.
The acquisition often becomes &amp;quot;circular&amp;quot; when rely-
ing on semantic information to acquire target seman-
tic information.
Prede:ined domain linguistic knowledge is
another imoortant information for constraining the
hypothesis space in learning (or for semantic
bootstrapping). From this point of view, lexical
categories (Zemik89, Zemik90) and theory of lexical
semantics (Pustejovsky87a, Pustejovsky87b) played
similar roles as the clues and heuristics employed in
this paper. The previous approaches had demon-
strated thec -etical interest, but their performance on
large-scale acquisition was not elaborated. We feel
that, requiring the system to use available resources
only (i.e. antactic processors and/or syntactically
processed corpora) may make large-scale implemen-
tations more feasible. The research investigates the
issue as tofl. what extent an acquisition system may
acquire thematic knowledge when only the syntactic
resources a:e available.
McClelland86 showed a connectionist model
for thematic role assignment. By manually encoding
training ass.gnments and semantic microfeatures for a
limited number of verbs and nouns, the connectionist
network learned how to assign roles. Stochastic
approaches (Smadja91, Sekine92) also employed
available corpora to acquire collocational data for
resolving Ambiguities in parsing. However, they
acquired numerical values by observing the whole
</bodyText>
<page confidence="0.991383">
248
</page>
<bodyText confidence="0.9998245">
training corpus (non-incremental learning). Explana-
tion for those numerical values is difficult to derive in
those models. As far as the large-scale thematic
knowledge acquisition is concerned, the incremental
extensibility of the models needs to be further
improved.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="conclusions">
6. CONCLUSION
</sectionHeader>
<bodyText confidence="0.999010611111111">
Preliminary syntactic analysis could be achieved by
many natural language processing systems. Toward
semantic interpretation on input sentences, thematic
lexical knowledge is needed. Although each lexicon
may have its own idiosyncratic thematic requirements
on arguments, there exist syntactic clues for
hypothesizing the thematic roles of the arguments.
Therefore, exploiting the information derived from
syntactic analysis to acquire thematic knowledge
becomes a plausible way to build an extensible
thematic dictionary. In this paper, various syntactic
clues are integrated to hypothesize thematic roles of
arguments in training sentences. Heuristics-guided
ambiguity resolution is invoked to collect extra
discrimination information from the trainer or the
corpus. As more syntactic resources become avail-
able, the method could upgrade the acquired
knowledge from syntactic level to thematic level.
</bodyText>
<sectionHeader confidence="0.964144" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999571666666667">
This research is supported in part by NSC (National
Science Council of R.O.C.) under the grant NSC82-
0408-E-007-029 and NSC81-0408-E007-19 from
which we obtained the PENN TreeBank by Dr.
Hsien-Chin Liou. We would like to thank the
anonymous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999465939393939">
[Asker92] Asker L., Gamback B., Samuelsson C.,
EBL2: An Application to Automatic Lexical Acquisi-
tion, Proc. of COLING, pp. 1172-1176, 1992.
[Berwick85] Berwick R. C., The Acquisition of Syn-
tactic Knowledge, The MIT Press, Cambridge, Mas-
sachusetts, London, England, 1985.
[Brent91] Brent M. R., Automatic Acquisition of Sub-
categorization Frames from Untagged Text, Proc. of
the 29th annual meeting of the ACL, pp. 209-214,
1991.
[Chomsky81] Chomsky N., Lectures on Government
and Binding, FOriS Publications - Dordrecht, 1981.
[Gazdar85] Gazdar G., Klein E., Pullum G. K., and
Sag I. A., Generalized Phrase Struoire Grammar,
Harvard University Press, Cambridge Massachusetts,
1985.
[Grimshaw88] Grimshaw J. and Mester A., Light
Verbs and Theta-Marking, Linguistic Inquiry, Vol.
19, No. 2, pp. 205-232, 1988.
[Grishman92a] Grishman R., Macleod C., and Ster-
ling J., Evaluating Parsing Strategies Using Stand-
ardized Parse Files, Proc. of the Third Applied NLP,
pp. 156-161, 1992.
[Grishman92b] Grishman R. and Sterling J., Acquisi-
tion of Selei tional Patterns, Proc. of COLING-92, pp.
658-664, 1992.
[Gruber76] Gruber J. S., Lexical Structures in Syntax
and Semantics, North-Holland Publishing Company,
1976.
[Jackendoff72] Jackendoff R. S., Semantic Interpreta-
tion in Generative Grammar, The MIT Press, Cam-
bridge, MasAchusetts, 1972.
[Jackendoff87] Jackendoff R. S., The Status of
Thematic Relations in Linguistic Theory, Linguistic
Inquiry, Vo&apos;. 18, No. 3, pp.369-411, 1987.
[Jacobs88] Jacobs P. and Zernik U., Acquiring Lexi-
cal Knowledge from Text: A Case Study, Proc. of
AAAI, pp. 739-744, 1988.
(Lang88] Lang F.-M. and Hirschman L., Improved
Portability and Parsing through Interactive Acquisi-
tion of Semantic Information, Proc. of the second
conference on Applied Natural Language Processing,
pp. 49-57, p88.
[Levin86] Lvin B. and Rappaport M., The Formation
of Adjectival Passives, Linguistic Inquiry, Vol. 17,
No. 4, pp. 623-661, 1986.
[Liu92a] Liu R.-L. and Soo V.-W., Augmenting and
Efficiently Utilizing Domain Theory in Explanation-
Based Naufal Language Acquisition, Proc. of the
Ninth International Machine Learning Conference,
ML92, pp. 282-289, 1992.
[Liu92b] Liu R.-L and Soo V.-W., Acquisition of
Unbounded Dependency Using Explanation-Based
Learning, Proc. of ROCLING V, 1992.
[Liu93] Lb R.-L. and Soo V.-W., Parsing-Driven
Generalization for Natural Language Acquisition,
International Journal of Pattern Recognition and
Artificial Intelligence, Vol. 7, No. 3, 1993.
[Lu89] Lu R., Liu Y., and Li X., Computer-Aided
Grammar Acquisition in the Chinese Understanding
System COSAGA, Proc. of IJCAL pp. 1550-1555,
1989.
[Lytinen90] Lytinen S. L. and Moon C. E., A Com-
parison of Learning Techniques in Second Language
Learning, 1- roc. of the 7th Machine Learning confer-
ence, pp. 3&amp;quot;, 7-383, 1990.
</reference>
<page confidence="0.982172">
249
</page>
<reference confidence="0.999923953125">
[McClelland86] McClelland J. L. and Kawamoto A.
H., Mechanisms of Sentence Processing: Assigning
Roles to Constituents of Sentences, in Parallel Distri-
buted Processing, Vol. 2, pp. 272-325, 1986.
[Montemagni92] Montemagni S. and Vanderwende
L., Structural Patterns vs. String Patterns for Extract-
ing Semantic Information from Dictioaary, Proc. of
COLING-92, pp. 546-552, 1992.
[Pustejovsky87a] Pustejovsky J. and Berger S., The
Acquisition of Conceptual Structure for the Lexicon,
Proc. of AAAI, pp. 566-570, 1987.
[Pustejovsky87b] Pustejovsky J, On the Acquisition of
Lexical Entries: The Perceptual Origin of Thematic
Relation, Proc. of the 25th annual meeting of the
ACL, pp. 172-178, 1987.
[Samuelsson91] Samuelsson C. and Rayner M.,
Quantitative Evaluation of Explanation-Based Learn-
ing as an Optimization Tool for a Large-Scale
Natural Language System, Proc. of IJCAI, pp. 609-
615, 1991.
[Sanfilippo92] Sanfilippo A. and Pozanski V., The
Acquisition of Lexical Knowledge from Combined
Machine-Readable Dictionary Sources, Proc. of the
Third Conference on Applied NLP, pp. 80-87, 1992.
[Sekine92] Sekine S., Carroll J. J., Ananiadou S., and
Tsujii J., Automatic Learning for Semantic Colloca-
tion, Proc. of the Third Conference on Applied NLP,
pp. 104-110, 1992.
[Simmons91] Simmons R. F. and Yu Y.-H., The
Acquisition and Application of Context Sensitive
Grammar for English, Proc. of the 29th annual meet-
ing of the ACL, pp. 122-129, 1991.
[Siskind90] Siskind J. M., Acquiring Core Meanings
of Words, Represented as Jackendoff-style Concep-
tual structures, from Correlated Streams of Linguistic
and Non-linguistic Input, Proc. of the 28th annual
meeting of the ACL, pp. 143-156, 1990.
[Smadja91] Smadja F. A., From N-Grams to Colloca-
tions: An Evaluation of EXTRACT. Proc. of the 29th
annual meeting of the ACL, pp. 279-284, 1991.
[Tanenhaus89] Tanenhaus M. K. and Carlson G. N.,
Lexical Structure and Language Comprehension, in
Lexical Representation and Process, William
Marson-Wilson (ed.), The MIT Press, 1989.
[Taraban88] Taraban R. and McClelland J. L., Consti-
tuent Attachment and Thematic Role Assignment in
Sentence Processing: Influences of Content-Based
Expectations, Journal of memory and language, 27,
pp. 597-632, 1988.
[Velardi91] Velardi P., Pazienza M. 1., and Fasolo
M., How to Encode Semantic Knowledge: A Method
for Meaning Representation and Computer-Aided
Acquisition,.Fomputational Linguistic, Vol. 17, No. 2,
pp. 153-170, 1991.
[Webster891 Webster M. and Marcus M., Automatic
Acquisition of the Lexical Semantics of Verbs from
Sentence Frames, Proc. of the 27th annual meeting of
the ACL, pp. 177-184, 1989.
[Zernik89] Zernik U., Lexicon Acquisition: Learning
from Corpus by Capitalizing on Lexical Categories,
Proc. of UCAI, pp. 1556-1562, 1989.
[Zernik90] Zernik U. and Jacobs P., Tagging for
Learning: Collecting Thematic Relation from Corpus,
Proc. of COLING, pp. 34-39, 1990.
</reference>
<page confidence="0.997155">
250
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.578842">
<title confidence="0.9838435">AN EMPIRICAL STUDY ON THEMATIC KNOWLEDGE ACQUISITION BASED ON SYNTACTIC CLUES AND HEURISTICS</title>
<author confidence="0.997988">Rey-Long Liu</author>
<author confidence="0.997988">Von-Wun Soo</author>
<affiliation confidence="0.9998955">Department of Computer Science National Tsing-Hua University</affiliation>
<address confidence="0.999471">HsinChu, Taiwan, R.O.C.</address>
<email confidence="0.976415">dr798303@cs.nthu.edu.tw*andsoo@c.s.nthu.edu.tw**</email>
<abstract confidence="0.999898842105263">Thematic knowledge is a basis of semantic interpretation. In this paper, we propose an acquisition method to acquire thematic knowledge by exploiting syntactic clues from training sentences. The syntactic clues, which may be easily collected by most existing syntactic processors, reduce the hypothesis space of the thematic roles. The ambiguities may be further resolved by the evidences either from a trainer or from a large corpus. A set of heurist_cs based on linguistic constraints is employed to guide the ambiresolution process. trainer is available, system generates new sentences ose thematic validities can be justified by the trainer. When a large corpus is available, the thematic validity may be justified by observing the sentences in the corpus. Using this way, a syntactic processor may become a thematic recognizer by simply deriving its thematic knowledge from its own syntactic knowledge.</abstract>
<keyword confidence="0.891826">Knowledge Acquisition, Syntactic Clues, Heuristics-guided Ambiguity Resolution,</keyword>
<intro confidence="0.710226">Corpus-based Acquisition, Interactive Acquisition</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Asker</author>
<author>B Gamback</author>
<author>C Samuelsson</author>
</authors>
<title>EBL2: An Application to Automatic Lexical Acquisition,</title>
<date>1992</date>
<booktitle>Proc. of COLING,</booktitle>
<pages>1172--1176</pages>
<marker>[Asker92]</marker>
<rawString>Asker L., Gamback B., Samuelsson C., EBL2: An Application to Automatic Lexical Acquisition, Proc. of COLING, pp. 1172-1176, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Berwick</author>
</authors>
<title>The Acquisition of Syntactic Knowledge,</title>
<date>1985</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts, London, England,</location>
<marker>[Berwick85]</marker>
<rawString>Berwick R. C., The Acquisition of Syntactic Knowledge, The MIT Press, Cambridge, Massachusetts, London, England, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>Automatic Acquisition of Subcategorization Frames from Untagged Text,</title>
<date>1991</date>
<booktitle>Proc. of the 29th annual meeting of the ACL,</booktitle>
<pages>209--214</pages>
<marker>[Brent91]</marker>
<rawString>Brent M. R., Automatic Acquisition of Subcategorization Frames from Untagged Text, Proc. of the 29th annual meeting of the ACL, pp. 209-214, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding, FOriS Publications -</booktitle>
<location>Dordrecht,</location>
<marker>[Chomsky81]</marker>
<rawString>Chomsky N., Lectures on Government and Binding, FOriS Publications - Dordrecht, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G K Pullum</author>
<author>I A Sag</author>
</authors>
<title>Generalized Phrase Struoire Grammar,</title>
<date>1985</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge Massachusetts,</location>
<marker>[Gazdar85]</marker>
<rawString>Gazdar G., Klein E., Pullum G. K., and Sag I. A., Generalized Phrase Struoire Grammar, Harvard University Press, Cambridge Massachusetts, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grimshaw</author>
<author>A Mester</author>
</authors>
<title>Light Verbs and Theta-Marking,</title>
<date>1988</date>
<journal>Linguistic Inquiry,</journal>
<volume>19</volume>
<pages>205--232</pages>
<marker>[Grimshaw88]</marker>
<rawString>Grimshaw J. and Mester A., Light Verbs and Theta-Marking, Linguistic Inquiry, Vol. 19, No. 2, pp. 205-232, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>C Macleod</author>
<author>J Sterling</author>
</authors>
<title>Evaluating Parsing Strategies Using Standardized Parse Files,</title>
<date>1992</date>
<booktitle>Proc. of the Third Applied NLP,</booktitle>
<pages>156--161</pages>
<marker>[Grishman92a]</marker>
<rawString>Grishman R., Macleod C., and Sterling J., Evaluating Parsing Strategies Using Standardized Parse Files, Proc. of the Third Applied NLP, pp. 156-161, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>J Sterling</author>
</authors>
<title>Acquisition of Selei tional Patterns,</title>
<date>1992</date>
<booktitle>Proc. of COLING-92,</booktitle>
<pages>658--664</pages>
<marker>[Grishman92b]</marker>
<rawString>Grishman R. and Sterling J., Acquisition of Selei tional Patterns, Proc. of COLING-92, pp. 658-664, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Gruber</author>
</authors>
<title>Lexical Structures in Syntax and Semantics,</title>
<date>1976</date>
<publisher>North-Holland Publishing Company,</publisher>
<marker>[Gruber76]</marker>
<rawString>Gruber J. S., Lexical Structures in Syntax and Semantics, North-Holland Publishing Company, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Jackendoff</author>
</authors>
<title>Semantic Interpretation in Generative Grammar,</title>
<date>1972</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MasAchusetts,</location>
<marker>[Jackendoff72]</marker>
<rawString>Jackendoff R. S., Semantic Interpretation in Generative Grammar, The MIT Press, Cambridge, MasAchusetts, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Jackendoff</author>
</authors>
<title>The Status of Thematic Relations in Linguistic Theory,</title>
<date>1987</date>
<journal>Linguistic Inquiry, Vo&apos;.</journal>
<volume>18</volume>
<pages>369--411</pages>
<marker>[Jackendoff87]</marker>
<rawString>Jackendoff R. S., The Status of Thematic Relations in Linguistic Theory, Linguistic Inquiry, Vo&apos;. 18, No. 3, pp.369-411, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jacobs</author>
<author>U Zernik</author>
</authors>
<title>Acquiring Lexical Knowledge from Text: A Case Study,</title>
<date>1988</date>
<booktitle>Proc. of AAAI,</booktitle>
<pages>739--744</pages>
<marker>[Jacobs88]</marker>
<rawString>Jacobs P. and Zernik U., Acquiring Lexical Knowledge from Text: A Case Study, Proc. of AAAI, pp. 739-744, 1988. (Lang88] Lang F.-M. and Hirschman L., Improved Portability and Parsing through Interactive Acquisition of Semantic Information, Proc. of the second conference on Applied Natural Language Processing, pp. 49-57, p88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lvin</author>
<author>M Rappaport</author>
</authors>
<title>The Formation of Adjectival Passives,</title>
<date>1986</date>
<journal>Linguistic Inquiry,</journal>
<volume>17</volume>
<pages>623--661</pages>
<marker>[Levin86]</marker>
<rawString>Lvin B. and Rappaport M., The Formation of Adjectival Passives, Linguistic Inquiry, Vol. 17, No. 4, pp. 623-661, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-L Liu</author>
<author>V-W Soo</author>
</authors>
<title>Augmenting and Efficiently Utilizing Domain Theory in ExplanationBased Naufal Language Acquisition,</title>
<date>1992</date>
<booktitle>Proc. of the Ninth International Machine Learning Conference, ML92,</booktitle>
<pages>282--289</pages>
<marker>[Liu92a]</marker>
<rawString>Liu R.-L. and Soo V.-W., Augmenting and Efficiently Utilizing Domain Theory in ExplanationBased Naufal Language Acquisition, Proc. of the Ninth International Machine Learning Conference, ML92, pp. 282-289, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-L Liu</author>
<author>V-W Soo</author>
</authors>
<title>Acquisition of Unbounded Dependency Using Explanation-Based Learning,</title>
<date>1992</date>
<booktitle>Proc. of ROCLING V,</booktitle>
<marker>[Liu92b]</marker>
<rawString>Liu R.-L and Soo V.-W., Acquisition of Unbounded Dependency Using Explanation-Based Learning, Proc. of ROCLING V, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-L Lb</author>
<author>V-W Soo</author>
</authors>
<title>Parsing-Driven Generalization for Natural Language Acquisition,</title>
<date>1993</date>
<journal>International Journal of Pattern Recognition and Artificial Intelligence,</journal>
<volume>7</volume>
<marker>[Liu93]</marker>
<rawString>Lb R.-L. and Soo V.-W., Parsing-Driven Generalization for Natural Language Acquisition, International Journal of Pattern Recognition and Artificial Intelligence, Vol. 7, No. 3, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Lu</author>
<author>Y Liu</author>
<author>X Li</author>
</authors>
<title>Computer-Aided Grammar Acquisition in the Chinese Understanding System COSAGA,</title>
<date>1989</date>
<booktitle>Proc. of IJCAL</booktitle>
<pages>1550--1555</pages>
<marker>[Lu89]</marker>
<rawString>Lu R., Liu Y., and Li X., Computer-Aided Grammar Acquisition in the Chinese Understanding System COSAGA, Proc. of IJCAL pp. 1550-1555, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Lytinen</author>
<author>C E Moon</author>
</authors>
<title>A Comparison of Learning Techniques</title>
<date>1990</date>
<booktitle>in Second Language Learning, 1- roc. of the 7th Machine Learning conference,</booktitle>
<pages>3--7</pages>
<marker>[Lytinen90]</marker>
<rawString>Lytinen S. L. and Moon C. E., A Comparison of Learning Techniques in Second Language Learning, 1- roc. of the 7th Machine Learning conference, pp. 3&amp;quot;, 7-383, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L McClelland</author>
<author>A H Kawamoto</author>
</authors>
<title>Mechanisms of Sentence Processing: Assigning Roles to Constituents of Sentences,</title>
<date>1986</date>
<booktitle>in Parallel Distributed Processing,</booktitle>
<volume>2</volume>
<pages>272--325</pages>
<marker>[McClelland86]</marker>
<rawString>McClelland J. L. and Kawamoto A. H., Mechanisms of Sentence Processing: Assigning Roles to Constituents of Sentences, in Parallel Distributed Processing, Vol. 2, pp. 272-325, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Montemagni</author>
<author>L Vanderwende</author>
</authors>
<title>Structural Patterns vs. String Patterns for Extracting Semantic Information from Dictioaary,</title>
<date>1992</date>
<booktitle>Proc. of COLING-92,</booktitle>
<pages>546--552</pages>
<marker>[Montemagni92]</marker>
<rawString>Montemagni S. and Vanderwende L., Structural Patterns vs. String Patterns for Extracting Semantic Information from Dictioaary, Proc. of COLING-92, pp. 546-552, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>S Berger</author>
</authors>
<title>The Acquisition of Conceptual Structure for the Lexicon,</title>
<date>1987</date>
<booktitle>Proc. of AAAI,</booktitle>
<pages>566--570</pages>
<marker>[Pustejovsky87a]</marker>
<rawString>Pustejovsky J. and Berger S., The Acquisition of Conceptual Structure for the Lexicon, Proc. of AAAI, pp. 566-570, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>On the Acquisition of Lexical Entries: The Perceptual Origin of Thematic Relation,</title>
<date>1987</date>
<booktitle>Proc. of the 25th annual meeting of the ACL,</booktitle>
<pages>172--178</pages>
<marker>[Pustejovsky87b]</marker>
<rawString>Pustejovsky J, On the Acquisition of Lexical Entries: The Perceptual Origin of Thematic Relation, Proc. of the 25th annual meeting of the ACL, pp. 172-178, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
<author>M Rayner</author>
</authors>
<title>Quantitative Evaluation of Explanation-Based Learning as an Optimization Tool for a Large-Scale Natural Language System,</title>
<date>1991</date>
<booktitle>Proc. of IJCAI,</booktitle>
<pages>609--615</pages>
<marker>[Samuelsson91]</marker>
<rawString>Samuelsson C. and Rayner M., Quantitative Evaluation of Explanation-Based Learning as an Optimization Tool for a Large-Scale Natural Language System, Proc. of IJCAI, pp. 609-615, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sanfilippo</author>
<author>V Pozanski</author>
</authors>
<title>The Acquisition of Lexical Knowledge from Combined Machine-Readable Dictionary Sources,</title>
<date>1992</date>
<booktitle>Proc. of the Third Conference on Applied NLP,</booktitle>
<pages>80--87</pages>
<marker>[Sanfilippo92]</marker>
<rawString>Sanfilippo A. and Pozanski V., The Acquisition of Lexical Knowledge from Combined Machine-Readable Dictionary Sources, Proc. of the Third Conference on Applied NLP, pp. 80-87, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
<author>J J Carroll</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>Automatic Learning for Semantic Collocation,</title>
<date>1992</date>
<booktitle>Proc. of the Third Conference on Applied NLP,</booktitle>
<pages>104--110</pages>
<marker>[Sekine92]</marker>
<rawString>Sekine S., Carroll J. J., Ananiadou S., and Tsujii J., Automatic Learning for Semantic Collocation, Proc. of the Third Conference on Applied NLP, pp. 104-110, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
<author>Y-H Yu</author>
</authors>
<title>The Acquisition and Application of Context Sensitive Grammar for English,</title>
<date>1991</date>
<booktitle>Proc. of the 29th annual meeting of the ACL,</booktitle>
<pages>122--129</pages>
<marker>[Simmons91]</marker>
<rawString>Simmons R. F. and Yu Y.-H., The Acquisition and Application of Context Sensitive Grammar for English, Proc. of the 29th annual meeting of the ACL, pp. 122-129, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Siskind</author>
</authors>
<title>Acquiring Core Meanings of Words, Represented as Jackendoff-style Conceptual structures, from</title>
<date>1990</date>
<booktitle>Correlated Streams of Linguistic and Non-linguistic Input, Proc. of the 28th annual meeting of the ACL,</booktitle>
<pages>143--156</pages>
<marker>[Siskind90]</marker>
<rawString>Siskind J. M., Acquiring Core Meanings of Words, Represented as Jackendoff-style Conceptual structures, from Correlated Streams of Linguistic and Non-linguistic Input, Proc. of the 28th annual meeting of the ACL, pp. 143-156, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
</authors>
<title>From N-Grams to Collocations: An Evaluation of EXTRACT.</title>
<date>1991</date>
<booktitle>Proc. of the 29th annual meeting of the ACL,</booktitle>
<pages>279--284</pages>
<marker>[Smadja91]</marker>
<rawString>Smadja F. A., From N-Grams to Collocations: An Evaluation of EXTRACT. Proc. of the 29th annual meeting of the ACL, pp. 279-284, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M K Tanenhaus</author>
<author>G N Carlson</author>
</authors>
<date>1989</date>
<booktitle>Lexical Structure and Language Comprehension, in Lexical Representation and Process, William Marson-Wilson (ed.), The</booktitle>
<publisher>MIT Press,</publisher>
<marker>[Tanenhaus89]</marker>
<rawString>Tanenhaus M. K. and Carlson G. N., Lexical Structure and Language Comprehension, in Lexical Representation and Process, William Marson-Wilson (ed.), The MIT Press, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Taraban</author>
<author>J L McClelland</author>
</authors>
<title>Constituent Attachment and Thematic Role Assignment in Sentence Processing: Influences of Content-Based Expectations,</title>
<date>1988</date>
<journal>Journal of memory and language,</journal>
<volume>27</volume>
<pages>597--632</pages>
<marker>[Taraban88]</marker>
<rawString>Taraban R. and McClelland J. L., Constituent Attachment and Thematic Role Assignment in Sentence Processing: Influences of Content-Based Expectations, Journal of memory and language, 27, pp. 597-632, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Velardi</author>
<author>M Pazienza</author>
</authors>
<title>How to Encode Semantic Knowledge: A Method for Meaning Representation and Computer-Aided Acquisition,.Fomputational Linguistic,</title>
<date>1991</date>
<booktitle>Webster891</booktitle>
<volume>17</volume>
<pages>153--170</pages>
<marker>[Velardi91]</marker>
<rawString>Velardi P., Pazienza M. 1., and Fasolo M., How to Encode Semantic Knowledge: A Method for Meaning Representation and Computer-Aided Acquisition,.Fomputational Linguistic, Vol. 17, No. 2, pp. 153-170, 1991. [Webster891 Webster M. and Marcus M., Automatic Acquisition of the Lexical Semantics of Verbs from Sentence Frames, Proc. of the 27th annual meeting of the ACL, pp. 177-184, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Zernik</author>
</authors>
<title>Lexicon Acquisition: Learning from Corpus by Capitalizing on Lexical Categories,</title>
<date>1989</date>
<booktitle>Proc. of UCAI,</booktitle>
<pages>1556--1562</pages>
<marker>[Zernik89]</marker>
<rawString>Zernik U., Lexicon Acquisition: Learning from Corpus by Capitalizing on Lexical Categories, Proc. of UCAI, pp. 1556-1562, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Zernik</author>
<author>P Jacobs</author>
</authors>
<title>Tagging for Learning: Collecting Thematic Relation from Corpus,</title>
<date>1990</date>
<booktitle>Proc. of COLING,</booktitle>
<pages>34--39</pages>
<marker>[Zernik90]</marker>
<rawString>Zernik U. and Jacobs P., Tagging for Learning: Collecting Thematic Relation from Corpus, Proc. of COLING, pp. 34-39, 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>