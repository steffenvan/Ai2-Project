<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000703">
<title confidence="0.962612">
SEMILAR: The Semantic Similarity Toolkit
</title>
<author confidence="0.99698">
Vasile Rus, Mihai Lintean, Rajendra Banjade, Nobal Niraula, and Dan Stefanescu
</author>
<affiliation confidence="0.9962405">
Department of Computer Science
The University of Memphis
</affiliation>
<address confidence="0.853163">
Memphis, TN 38152
</address>
<email confidence="0.998084">
{vrus,rbanjade,mclinten,nbnraula,dstfnscu}@memphis.edu
</email>
<sectionHeader confidence="0.98297" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998024454545455">
We present in this paper SEMILAR, the SE-
Mantic simILARity toolkit. SEMILAR im-
plements a number of algorithms for assessing
the semantic similarity between two texts. It is
available as a Java library and as a Java
standalone ap-plication offering GUI-based
access to the implemented semantic similarity
methods. Furthermore, it offers facilities for
manual se-mantic similarity annotation by ex-
perts through its component SEMILAT (a
SEMantic simILarity Annotation Tool).
</bodyText>
<sectionHeader confidence="0.995116" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988863242424243">
We present in this paper the design and im-
plementation of SEMILAR, the SEMantic
simILARity toolkit. SEMILAR
(www.semanticsimilarity.org) includes im-
plementations of a number of algorithms pro-
posed over the last decade or so to address
various instances of the general problem of
text-to-text semantic similarity. Semantic sim-
ilarity is an approach to language understand-
ing that is widely used in real applications. It
is a practical alternative to the true under-
standing approach, which is intractable as it
requires world knowledge, a yet to-be-solved
problem in Artificial Intelligence.
Text A: York had no problem with MTA’s in-
sisting the decision to shift funds had been within
its legal rights.
Text B: York had no problem with MTA’s say-
ing the decision to shift funds was within its
powers.
Given such two texts, the paraphrase identifi-
cation task is about automatically assessing
whether Text A is a paraphrase of, i.e. has the
same meaning as, Text B. The example above is
a positive instance, meaning that Text A is a par-
aphrase of Text B and vice versa.
The importance of semantic similarity in Nat-
ural Language Processing (NLP) is highlighted
by the diversity of datasets and shared task eval-
uation campaigns (STECs) that have been pro-
posed over the last decade (Dolan, Quirk, and
Brockett, 2004; McCarthy &amp; McNamara, 2008;
Agirre et al., 2012). These datasets include in-
stances from various applications. Indeed, there
is a need to identify and quantify semantic rela-
tions between texts in many applications. For
instance, paraphrase identification, an instance of
the semantic similarity problem, is an important
step in a number of applications including Natu-
ral Language Generation, Question Answering,
and dialogue-based Intelligent Tutoring Systems.
In Natural Language Generation, paraphrases are
a method to increase diversity of generated text
(Iordanskaja et al. 1991). In Question Answer-
ing, multiple answers that are paraphrases of
each other could be considered as evidence for
the correctness of the answer (Ibrahim et al.
2003). In Intelligent Tutoring Sys-tems (Rus et
al., 2009; Lintean et al., 2010; Lintean, 2011),
paraphrase identification is useful to assess
whether students’ articulated answers to deep
questions (e.g. conceptual physics questions) are
similar-to/paraphrases-of ideal answers.
Generally, the problem of semantic similarity
between two texts, denoted text A and text B, is
defined as quantifying and identifying the pres-
ence of semantic relations between the two texts,
e.g. to what extent text A has the same meaning
as or is a paraphrase of text B (paraphrase rela-
tion; Dolan, Quirk, and Brockett, 2004). Other
semantic relations that have been investigated
systematically in the recent past are entailment,
i.e. to what extent text A entails or logically in-
fers text B (Dagan, Glickman, &amp; Magnini, 2004),
and elaboration, i.e. is text B is an elaboration of
text A? (McCarthy &amp; McNamara, 2008).
</bodyText>
<page confidence="0.730563">
163
</page>
<note confidence="0.9230515">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 163–168,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999728">
Figure 1. Snapshot of SEMILAR. The Data View tab is shown.
</figureCaption>
<bodyText confidence="0.999960692307692">
Semantic similarity can be broadly construed
between texts of any size. Depending on the
granularity of the texts, we can talk about the
following fundamental text-to-text similarity
problems: word-to-word similarity, phrase-to-
phrase similarity, sentence-to-sentence similari-
ty, paragraph-to-paragraph similarity, or docu-
ment-to-document similarity. Mixed combina-
tions are also possible such as assessing the simi-
larity of a word to a sentence or a sentence to a
paragraph. For instance, in summarization it
might be useful to assess how well a sentence
summarizes an entire paragraph.
</bodyText>
<sectionHeader confidence="0.960702" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999330518518519">
The problem of word-to-word similarity has been
extensively studied over the past decades and a
word-to-word similarity library (WordNet Simi-
larity) has been developed by Pedersen and col-
leagues (Pedersen, Patwardhan, &amp; Michelizzi,
2004).
Methods to assess the semantic similarity of
larger texts, in particular sentences, have been
proposed over the last decade (Corley and
Mihalcea, 2005; Fernando &amp; Stevenson, 2008;
Rus, Lintean, Graesser, &amp; McNamara 2009).
Androutsopoulos &amp; Malakasiotis (2010) com-
piled a survey of methods for paraphrasing and
entailment semantic relation identification at sen-
tence level. Despite all the proposed methods to
assess semantic similarity between two texts, no
semantic similarity library or toolkit, similar to
the WordNet library for word-to-word similarity,
exists for larger texts. Given the importance of
semantic similarity, there is an acute need for
such a library and toolkit. The developed SEMI-
LAR library and toolkit presented here fulfill this
need.
In particular, the development of the semantic
similarity toolkit SEMILAR has been motivated
by the need for an integrated environment that
would provide:
</bodyText>
<listItem confidence="0.917721894736842">
• easy access to implementations of various
semantic similarity approaches from the
same user-friendly interface and/or library.
• easy access to semantic similarity methods
that work at different levels of text granulari-
ty: word-to-word, sentence-to-sentence, par-
agraph-to-paragraph, document-to-
document, or a combination (SEMILAR in-
tegrates word-to-word similarity measures).
• authoring methods for semantic similarity.
• a common environment for that allows sys-
tematic and fair comparison of semantic sim-
ilarity methods.
• facilities to manually annotate texts with se-
mantic similarity relations using a graphical
user interface that make such annotations
easier for experts (this component is called
SEMILAT component - a SEMantic similari-
ty Annotation Tool).
</listItem>
<bodyText confidence="0.92586675">
SEMILAR is thus a one-stop-shop for investi-
gating, annotating, and authoring methods for the
semantic similarity of texts of any level of granu-
larity.
</bodyText>
<sectionHeader confidence="0.933227" genericHeader="method">
3 SEMILAR: The Semantic Similarity
Toolkit
</sectionHeader>
<bodyText confidence="0.9973345">
The authors of the SEMILAR toolkit (see Figure
1) have been involved in assessing the semantic
</bodyText>
<page confidence="0.873454">
164
</page>
<bodyText confidence="0.999739314285714">
large space of possibilities. The parameters in-
clude preprocessing options (collocation detec-
tion, punctuation, stopword removal, etc.), filter-
ing options (all words, content words, etc.),
weighting schemes (global vs. local weighting,
binary weighting, etc.), and normalization factors
(largest text, weighted average, etc.). A total of
3,456 variants of lexical overlap can be generat-
ed by different parameter settings in SEMILAR.
Lintean (2011) has shown that performance on
lexical overlap methods on the tasks of para-
phrase identification and textual entailment tasks
can vary significantly depending on the selected
parameters. Some lexical overlap variations lead
to performance results rivaling more sophisticat-
ed, state-of-the-art methods.
It should be noted that the overlap category of
methods can be extended to include N-gram
overlap methods (see the N-gram overlap meth-
ods proposed by the Machine Translation com-
munity such as BLEU and METEOR). SEMI-
LAR offers bigram and unigram overlap methods
including the BLEU and METEOR scores.
A natural approach to text-to-text similarity
methods is to rely on word-to-word similarity
measures. Many of the methods presented next
compute the similarity of larger texts using indi-
vidual word similarities.
Mihalcea, Corley, &amp; Strappavara (2006;
MCS) proposed a greedy method based on word-
to-word similarity measures. For each word in
text A (or B) the maximum similarity score to
any word in the other text B (or A) is used. An
idf-weighted average is then computed as shown
in the equation below.
</bodyText>
<equation confidence="0.997901">
w 
1
(
2
idfw
()
{T
T } idf(w)
1
w 
sim(T1 , T2)
T-1
}-1Sim(w,T1)*idf(w) }
2
)
2 }
</equation>
<bodyText confidence="0.999930545454545">
The word-to-word similarity function sim(w,
T) in the equation above can be instantiated to
any word-to-word similarity measure (e.g.
WordNet similarities or Latent Semantic Analy-
sis). The vast majority of word-to-word similari-
ty measures that rely on WordNet are concept-to-
concept measures and to be able to use them one
must map words in the input texts onto concepts
in WordNet, i.e. word sense disambiguation
(WSD) is needed. As of this writing, SEMILAR
addresses the issue in two simple ways: (1) se-
</bodyText>
<equation confidence="0.916857">
T}max{Sim(w,T2)*idf(w) }
1

</equation>
<bodyText confidence="0.999979647058823">
similarity of texts for more than a decade. During
this time, they have conducted a careful require-
ments analysis for an integrated software toolkit
that would integrate various methods for seman-
tic similarity assessment. The result of this effort
is the prototype presented here. We briefly pre-
sent the components of SEMILAR next and then
describe in more detail the core component of
SEMILAR, i.e. the set of semantic similarity
methods that are currently available. It should be
noted that we are continuously adding new se-
mantic similarity methods and features to SEMI-
LAR.
The SEMILAR toolkit includes the following
components: project management; data view-
browsing-visualization; preprocessing (e.g., col-
location identification, part-of-speech tagging,
phrase or dependency parsing, etc.), semantic
similarity methods (word-level and sentence-
level), classification components for qualitative
decision making with respect to textual semantic
relations (naïve Bayes, Decision Trees, Support
Vector Machines, and Neural Network), kernel-
based methods (sequence kernels, word sequence
kernels, and tree kernels; as of this writing, we
are still implementing several other tree kernel
methods); debugging and testing facilities for
model selection; and annotation components (al-
lows domain expert to manually annotate texts
with semantic relations using GUI-based facili-
ties; Rus et al., 2012). For space reasons, we only
detail next the main algorithms in the core com-
ponent, i.e. the major text-to-text similarity algo-
rithms currently available in SEMILAR.
</bodyText>
<sectionHeader confidence="0.9747085" genericHeader="method">
4 The Semantic Similarity Methods
Available in SEMILAR
</sectionHeader>
<bodyText confidence="0.999967529411765">
The core component of SEMILAR is a set of
text-to-text semantic similarity methods. We
have implemented methods that handle both uni-
directional similarity measures as well as bidirec-
tional similarity measures. For instance, the se-
mantic relation of entailment between two texts
is unidirectional (a text T logically entails a hy-
pothesis text H but H does not entail T) while the
paraphrase relation is bidirectional (text A has
same meaning as text B and vice versa).
Lexical Overlap. Given two texts, the sim-
plest method to assess their semantic similarity is
to compute lexical overlap, i.e. how many words
they have in common. There are many lexical
overlap variations. Indeed, a closer look at lexi-
cal overlap reveals a number of parameters that
turns the simple lexical overlap problem into a
</bodyText>
<page confidence="0.748063">
165
</page>
<bodyText confidence="0.998571031746032">
lecting the most frequent sense for each word,
which is sense #1 in WordNet, and (2) using all
the senses for each word and then take the max-
imum (or average) of the relatedness scores for
each pair of word senses. We label the former
method as ONE (sense one), whereas the latter is
labeled as ALL-MAX or ALL-AVG (all senses
maximum score or all senses average score, re-
spectively). Furthermore, most WordNet-based
measures only work within a part-of-speech cat-
egory, e.g. only between nouns.
Other types of word-to-word measures, such
as those based on Latent Semantic Analysis or
Latent Dirichlet Allocation, do not have a word-
sense disambiguation challenge.
Rus and Lintean (2012; Rus-Lintean-
Optimal Matching or ROM) proposed an opti-
mal solution for text-to-text similarity based on
word-to-word similarity measures. The optimal
lexical matching is based on the optimal assign-
ment problem, a fundamental combinatorial op-
timization problem which consists of finding a
maximum weight matching in a weighted bipar-
tite graph.
Given a weighted complete bipartite graph
, where edge has weight
, the optimal assignment problem is to
find a matching M from X to Y with maximum
weight.
A typical application is about assigning a
group of workers, e.g. words in text A in our
case, to a set of jobs (words in text B in our case)
based on the expertise level, measured by
, of each worker at each job. By adding
dummy workers or jobs we may assume that X
and Y have the same size, n, and can be viewed
as and Y = .
In the semantic similarity case, the weight
is the word-to-word similarity between a word x
in text A and a word y in text B.
The assignment problem can also be stated as
finding a permutation of {1, 2, 3, ... , n} for
which is maximum. Such an
assignment is called optimum assignment. The
Kuhn-Munkres algorithm (Kuhn, 1955) can find
a solution to the optimum assignment problem in
polynomial time.
Rus and colleagues (Rus et al., 2009; Rus &amp;
Graesser, 2006; Rus-Syntax-Iegation or RSI)
used a lexical overlap component combined with
syntactic overlap and negation handling to com-
pute an unidirectional subsumption score be-
tween two sentences, T (Text) and H (Hypothe-
sis), in entailment recognition and student input
assessment in Intelligent Tutoring Systems. Each
text is regarded as a graph with words as
nodes/vertices and syntactic dependencies as
edges. The subsumption score reflects how much
a text is subsumed or contained by another. The
equation below provides the overall subsumption
score, which can be averaged both ways to com-
pute a similarity score, as opposed to just the
subsumption score, between the two texts.
</bodyText>
<equation confidence="0.989826">
 max match V
( , V
Vt Tv
 h t
V Hv
h 
)
 
 max match E
( ,
Et Te
 Et
h
E He
h 
)
1 
</equation>
<bodyText confidence="0.996771631578947">
The lexical component can be used by itself
(given a weight of 1 with the syntactic compo-
nent given a weight of 0) in which case the simi-
larity between the two texts is just a composi-
tional extension of word-to-word similarity
measures. The match function in the equation
can be any word-to-word similarity measure in-
cluding simple word match, WordNet similarity
measures, LSA, or LDA-based similarity
measures.
Fernando and Stevenson (FST; 2008) pro-
posed a method in which similarities among all
pairs of words are taken into account for compu-
ting the similarity of two texts. Each text is rep-
resented as a binary vector (1 – the word occurs
in the text; 0 – the word does not occur in the
text). They use a similarity matrix operator W
that contains word-to-word similarities between
any two words.
</bodyText>
<equation confidence="0.5608655">

aW b
a b

sin( a, b)  
|
</equation>
<bodyText confidence="0.998772866666667">
Each element wi; represents the word-level
semantic similarity between word ai in text A
and word b; in text B. Any word-to-word seman-
tic similarity measure can be used.
Lintean and Rus (2010; weighted-LSA or
wLSA) extensively studied methods for semantic
similarity based on Latent Semantic Analysis
(LSA; Landauer et al., 2006). LSA represents
words as vectors in a 300-500 dimensional LSA
space. An LSA vector for larger texts can be de-
rived by vector algebra, e.g. by summing up the
individual words’ vectors. The similarity of two
texts A and B can be computed using the cosine
(normalized dot product) of their LSA vectors.
Alternatively, the individual word vectors can be
</bodyText>
<page confidence="0.432588">
(
</page>
<figure confidence="0.973293944444445">
rel
)
(
#neg
1)
)
|

|
|
2
Eh
 |Vh

  T

subsump( ,  
T H ) (
</figure>
<page confidence="0.434838">
166
</page>
<bodyText confidence="0.973317592592593">
combined through weighted sums. Lintean and
Rus (2010) experimented with a combination of
3 local weights and 3 global weights. All these
versions of LSA-based text-to-text similarity
measures are available in SEMILAR.
SEMILAR also includes a set of similarity
measures based on the unsupervised method La-
tent Dirichlet Allocation (LDA; Blei, Ig, &amp;
Jordnan, 2003; Rus, Banjade, &amp; Iiraula,
2013). LDA is a probabilistic generative model
in which documents are viewed as distributions
over a set of topics (θd - text d’s distribution over
topics) and topics are distributions over words (φt
– topic t’s distribution over words). That is, each
word in a document is generated from a distribu-
tion over words that is specific to each topic.
A first LDA-based semantic similarity meas-
ure among words would then be defined as a dot-
product between the corresponding vectors rep-
resenting the contributions of each word to a top-
ic (φt(w) – represents the probability of word w
in topic t). It should be noted that the contribu-
tions of each word to the topics does not consti-
tute a distribution, i.e. the sum of contributions is
not 1. Assuming the number of topics T, then a
simple word-to-word measure is defined by the
formula below.
</bodyText>
<equation confidence="0.616044666666667">
LDA w w w v
— 2 ( , ) (p ( )(p ( )
= t w t v
</equation>
<bodyText confidence="0.996237232142858">
More global text-to-text similarity measures could
be defined in several ways as detailed next.
Because in LDA a document is a distribution
over topics, the similarity of two texts needs to
be computed in terms of similarity of distribu-
tions. The Kullback-Leibler (KL) divergence
defines a distance, or how dissimilar, two distri-
butions p and q are as in the formula below.
KL p q
( ,
)
qi
If we replace p with θd (text/document d’s dis-
tribution over topics) and q with θc
(text/document c’s distribution over topics) we
obtain the KL distance between two documents
(documents d and c in our example). The KL
distance has two major problems. In case qi is
zero KL is not defined. Then, KL is not symmet-
ric. The Information Radius measure (IR) solves
these problems by considering the average of pi
and qi as below. Also, the IR can be transformed
into a symmetric similarity measure as in the fol-
lowing (Dagan, Lee, &amp; Pereira, 1997):
The Hellinger and Manhattan distances be-
tween two distributions are two other options
that avoid the shortcomings of the KL distance.
Both are options are implemented in SEMILAR.
LDA similarity measures between two docu-
ments or texts c and d can also include similarity
of topics. That is, the text-to-text similarity is
obtained multiplying the similarities between the
distribution over topics (θd and θc) and distribu-
tion over words (φt1 and φt2). The similarity of
topics can be computed using the same methods
illustrated above as the topics are distributions
over words (for all the details see Rus, Banjade,
&amp; Niraula, 2013).
The last semantic similarity method presented
in this paper is based on the Quadratic Assign-
ment Problem (QAP). The QAP method aims at
finding an optimal assignment from words in text
A to words in text B, based on individual word-
to-word similarity measures, while simultaneous-
ly maximizing the match between the syntactic
dependencies of the words.
The Koopmans-Beckmann (1957) formulation
of the QAP problem best fits this purpose. The
goal of the original QAP formulation, in the do-
main of economic activity, was to minimize the
objective function QAP shown below where ma-
trix F describes the flow between any two facili-
ties, matrix D indicates the distances between
locations, and matrix B provides the cost of lo-
cating facilities to specific locations. F, D, and B
are symmetric and non-negative.
</bodyText>
<equation confidence="0.797771">
n n n
QAP F D B
( , , ) = E E f d + E b• )
min i=1j=1 l�j �(i)�(j) i=1 i,)c(i
</equation>
<bodyText confidence="0.9998931">
The fi,j term denotes the flow between facili-
ties i and j which are placed at locations n(i) and
n(j), respectively. The distance between these
locations is dn(i)n(j). In our case, F and D describe
dependencies between words in one sentence
while B captures the word-to-word similarity
between words in opposite sentences. Also, we
have weighted each term in the above formula-
tion and instead of minimizing the sum we are
maximizing it resulting in the formulation below.
</bodyText>
<figure confidence="0.972680318181818">
max ( , , )
QAP F D B     f  
(1 )
 
i   i i i
b
1 , ( ) ( )
i j d 
i j
1 j  1 , ( )
n n n

T
E
t=1
T

i1
pi
log
pi
167
</figure>
<sectionHeader confidence="0.95485" genericHeader="discussions">
5 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.999774571428572">
The above methods were experimented with on
various datasets for paraphrase, entailment, and
elaboration. For paraphrase identification, the
QAP method provides best accuracy results
(=77.6%) on the test subset of the Microsoft Re-
search Paraphrase corpus, one of the largest par-
aphrase datasets.
Due to space constraints, we have not de-
scribed all the features available in SEMILAR.
For a complete list of features, latest news, refer-
ences, and updates of the SEMILAR toolkit
along with downloadable resources including
software and data files, the reader can visit this
link: www.semanticsimilarity.org.
</bodyText>
<sectionHeader confidence="0.994562" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999878333333333">
This research was supported in part by Institute
for Education Sciences under award
R305A100875. Any opinions, findings, and con-
clusions or recommendations expressed in this
material are solely the authors’ and do not neces-
sarily reflect the views of the sponsoring agency.
</bodyText>
<sectionHeader confidence="0.990213" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999255375">
Androutsopoulos, I. &amp; Malakasiotis, P. 2010. A sur-
vey of paraphrasing and textual entailment meth-
ods. Journal of Artificial Intelligence Research,
38:135-187.
Agirre, E., Cer, D., Diab, M., &amp; Gonzalez-Agirre, A.
(2012). SemEval-2012 Task 6: A Pilot on Semantic
Textual Similarity, First Joint Conference on Lexi-
cal and Computational Semantics (*SEM), Mon-
treal, Canada, June 7-8, 2012.
Blei, D.M., Ng, A.Y., &amp; Jordan, M.I. 2003. Latent
dirichlet allocation, The Journal of Machine Learn-
ing Research 3, 993-1022.
Corley, C., &amp; Mihalcea, R. (2005). Measuring the
Semantic Similarity of Texts. In Proceedings of the
ACL Workshop on Empirical Modeling of Seman-
tic Equivalence and Entailment. Ann Arbor, MI.
Dagan, I., Glickman, O., &amp; Magnini, B. (2004). The
PASCAL Recognising textual entailment Chal-
lenge. In Quinorero-Candela, J.; Dagan, I.; Magni-
ni, B.; d&apos;Alche-Buc, F. (Eds.), Machine Learning
Challenges. Lecture Notes in Computer Science,
Vol. 3944, pp. 177-190, Springer, 2006.
Dolan, B., Quirk, C., &amp; Brockett, C. (2004). Unsuper-
vised construction of large paraphrase corpora: Ex-
ploiting massively parallel news sources. In Pro-
ceedings of the 20th International Conference on
Computational Linguistics (COLING-2004), Gene-
va, Switzerland.
Fernando, S. &amp; Stevenson, M. (2008). A semantic
similarity approach to paraphrase detec-
tion, Computational Linguistics UK (CLUK 2008)
11th Annual Research Colloquium.
Lintean, M., Moldovan, C., Rus, V., &amp; McNamara D.
(2010). The Role of Local and Global Weighting in
Assessing the Semantic Similarity of Texts Using
Latent Semantic Analysis. Proceedings of the 23rd
International Florida Artificial Intelligence Re-
search Society Conference. Daytona Beach, FL.
Lintean, M. (2011). Measuring Semantic Similarity:
Representations and Methods, PhD Thesis, De-
partment of Computer Science, The University of
Memphis, 2011.
Ibrahim, A., Katz, B., &amp; Lin, J. (2003). Extracting
structural paraphrases from aligned monolingual
corpora In Proceedings of the Second International
Workshop on Paraphrasing, (ACL 2003).
Iordanskaja, L., Kittredge, R., &amp; Polgere, A. (1991).
Natural Language Generation in Artificial Intelli-
gence and Computational Linguistics. Lexical se-
lection and paraphrase in a meaning-text genera-
tion model, Kluwer Academic.
McCarthy, P.M. &amp; McNamara, D.S. (2008). User-
Language Paraphrase Corpus Challenge
https://umdrive.memphis.edu/pmmccrth/public/Par
aphraseCorpus/Paraphrase site.htm. Retrieved
2/20/2010 online, 2009.
Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004).
WordNet::Similarity - Measuring the Relatedness
of Concepts, In the Proceedings of the Nineteenth
National Conference on Artificial Intelligence
(AAAI-04), pp. 1024-1025, July 25-29, 2004, San
Jose, CA (Intelligent Systems Demonstration).
Rus, V., Lintean M., Graesser, A.C., &amp; McNamara,
D.S. (2009). Assessing Student Paraphrases Using
Lexical Semantics and Word Weighting. In Pro-
ceedings of the 14th International Conference on
Artificial Intelligence in Education, Brighton, UK.
Rus, V., Lintean, M., Moldovan, C., Baggett, W.,
Niraula, N., Morgan, B. (2012). The SIMILAR
Corpus: A Resource to Foster the Qualitative Un-
derstanding of Semantic Similarity of Texts, In
Semantic Relations II: Enhancing Resources and
Applications, The 8th Language Resources and
Evaluation Conference (LREC 2012), May 23-25,
Instanbul, Turkey.
Rus, V., Banjade, R., &amp; Niraula, N. (2013). Similarity
Measures based on Latent Dirichlet Allocation,
The 14th International Conference on Intelligent
Text Procesing and Computational Linguistics,
March 24-30, 2013, Samos, Greece.
</reference>
<page confidence="0.915242">
168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.878243">
<title confidence="0.997662">SEMILAR: The Semantic Similarity Toolkit</title>
<author confidence="0.989466">Vasile Rus</author>
<author confidence="0.989466">Mihai Lintean</author>
<author confidence="0.989466">Rajendra Banjade</author>
<author confidence="0.989466">Nobal Niraula</author>
<author confidence="0.989466">Dan</author>
<affiliation confidence="0.999731">Department of Computer The University of</affiliation>
<address confidence="0.991201">Memphis, TN 38152</address>
<email confidence="0.999693">vrus@memphis.edu</email>
<email confidence="0.999693">rbanjade@memphis.edu</email>
<email confidence="0.999693">mclinten@memphis.edu</email>
<email confidence="0.999693">nbnraula@memphis.edu</email>
<email confidence="0.999693">dstfnscu@memphis.edu</email>
<abstract confidence="0.99095825">We present in this paper SEMILAR, the SE- Mantic simILARity toolkit. SEMILAR implements a number of algorithms for assessing the semantic similarity between two texts. It is available as a Java library and as a Java standalone ap-plication offering GUI-based access to the implemented semantic similarity methods. Furthermore, it offers facilities for manual se-mantic similarity annotation by experts through its component SEMILAT (a SEMantic simILarity Annotation Tool).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>P Malakasiotis</author>
</authors>
<title>A survey of paraphrasing and textual entailment methods.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>38--135</pages>
<contexts>
<context position="5041" citStr="Androutsopoulos &amp; Malakasiotis (2010)" startWordPosition="756" endWordPosition="759"> a paragraph. For instance, in summarization it might be useful to assess how well a sentence summarizes an entire paragraph. 2 Motivation The problem of word-to-word similarity has been extensively studied over the past decades and a word-to-word similarity library (WordNet Similarity) has been developed by Pedersen and colleagues (Pedersen, Patwardhan, &amp; Michelizzi, 2004). Methods to assess the semantic similarity of larger texts, in particular sentences, have been proposed over the last decade (Corley and Mihalcea, 2005; Fernando &amp; Stevenson, 2008; Rus, Lintean, Graesser, &amp; McNamara 2009). Androutsopoulos &amp; Malakasiotis (2010) compiled a survey of methods for paraphrasing and entailment semantic relation identification at sentence level. Despite all the proposed methods to assess semantic similarity between two texts, no semantic similarity library or toolkit, similar to the WordNet library for word-to-word similarity, exists for larger texts. Given the importance of semantic similarity, there is an acute need for such a library and toolkit. The developed SEMILAR library and toolkit presented here fulfill this need. In particular, the development of the semantic similarity toolkit SEMILAR has been motivated by the </context>
</contexts>
<marker>Androutsopoulos, Malakasiotis, 2010</marker>
<rawString>Androutsopoulos, I. &amp; Malakasiotis, P. 2010. A survey of paraphrasing and textual entailment methods. Journal of Artificial Intelligence Research, 38:135-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Cer</author>
<author>M Diab</author>
<author>A Gonzalez-Agirre</author>
</authors>
<date>2012</date>
<booktitle>SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity, First Joint Conference on Lexical and Computational Semantics (*SEM),</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="2101" citStr="Agirre et al., 2012" startWordPosition="321" endWordPosition="324">A’s saying the decision to shift funds was within its powers. Given such two texts, the paraphrase identification task is about automatically assessing whether Text A is a paraphrase of, i.e. has the same meaning as, Text B. The example above is a positive instance, meaning that Text A is a paraphrase of Text B and vice versa. The importance of semantic similarity in Natural Language Processing (NLP) is highlighted by the diversity of datasets and shared task evaluation campaigns (STECs) that have been proposed over the last decade (Dolan, Quirk, and Brockett, 2004; McCarthy &amp; McNamara, 2008; Agirre et al., 2012). These datasets include instances from various applications. Indeed, there is a need to identify and quantify semantic relations between texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of </context>
</contexts>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Agirre, E., Cer, D., Diab, M., &amp; Gonzalez-Agirre, A. (2012). SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity, First Joint Conference on Lexical and Computational Semantics (*SEM), Montreal, Canada, June 7-8, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>A Y Ng</author>
<author>M I Jordan</author>
</authors>
<title>Latent dirichlet allocation,</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research</journal>
<volume>3</volume>
<pages>993--1022</pages>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>Blei, D.M., Ng, A.Y., &amp; Jordan, M.I. 2003. Latent dirichlet allocation, The Journal of Machine Learning Research 3, 993-1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Corley</author>
<author>R Mihalcea</author>
</authors>
<title>Measuring the Semantic Similarity of Texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment.</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="4932" citStr="Corley and Mihalcea, 2005" startWordPosition="742" endWordPosition="745">tions are also possible such as assessing the similarity of a word to a sentence or a sentence to a paragraph. For instance, in summarization it might be useful to assess how well a sentence summarizes an entire paragraph. 2 Motivation The problem of word-to-word similarity has been extensively studied over the past decades and a word-to-word similarity library (WordNet Similarity) has been developed by Pedersen and colleagues (Pedersen, Patwardhan, &amp; Michelizzi, 2004). Methods to assess the semantic similarity of larger texts, in particular sentences, have been proposed over the last decade (Corley and Mihalcea, 2005; Fernando &amp; Stevenson, 2008; Rus, Lintean, Graesser, &amp; McNamara 2009). Androutsopoulos &amp; Malakasiotis (2010) compiled a survey of methods for paraphrasing and entailment semantic relation identification at sentence level. Despite all the proposed methods to assess semantic similarity between two texts, no semantic similarity library or toolkit, similar to the WordNet library for word-to-word similarity, exists for larger texts. Given the importance of semantic similarity, there is an acute need for such a library and toolkit. The developed SEMILAR library and toolkit presented here fulfill th</context>
</contexts>
<marker>Corley, Mihalcea, 2005</marker>
<rawString>Corley, C., &amp; Mihalcea, R. (2005). Measuring the Semantic Similarity of Texts. In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment. Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>B Magnini</author>
</authors>
<title>The PASCAL Recognising textual entailment Challenge. In</title>
<date>2004</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>3944</volume>
<pages>177--190</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="3601" citStr="Dagan, Glickman, &amp; Magnini, 2004" startWordPosition="546" endWordPosition="550">swers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investigated systematically in the recent past are entailment, i.e. to what extent text A entails or logically infers text B (Dagan, Glickman, &amp; Magnini, 2004), and elaboration, i.e. is text B is an elaboration of text A? (McCarthy &amp; McNamara, 2008). 163 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 163–168, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 1. Snapshot of SEMILAR. The Data View tab is shown. Semantic similarity can be broadly construed between texts of any size. Depending on the granularity of the texts, we can talk about the following fundamental text-to-text similarity problems: word-to-word similarity, phrase-tophrase similarity, sentence-to</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2004</marker>
<rawString>Dagan, I., Glickman, O., &amp; Magnini, B. (2004). The PASCAL Recognising textual entailment Challenge. In Quinorero-Candela, J.; Dagan, I.; Magnini, B.; d&apos;Alche-Buc, F. (Eds.), Machine Learning Challenges. Lecture Notes in Computer Science, Vol. 3944, pp. 177-190, Springer, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dolan</author>
<author>C Quirk</author>
<author>C Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING-2004),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="2052" citStr="Dolan, Quirk, and Brockett, 2004" startWordPosition="312" endWordPosition="316"> within its legal rights. Text B: York had no problem with MTA’s saying the decision to shift funds was within its powers. Given such two texts, the paraphrase identification task is about automatically assessing whether Text A is a paraphrase of, i.e. has the same meaning as, Text B. The example above is a positive instance, meaning that Text A is a paraphrase of Text B and vice versa. The importance of semantic similarity in Natural Language Processing (NLP) is highlighted by the diversity of datasets and shared task evaluation campaigns (STECs) that have been proposed over the last decade (Dolan, Quirk, and Brockett, 2004; McCarthy &amp; McNamara, 2008; Agirre et al., 2012). These datasets include instances from various applications. Indeed, there is a need to identify and quantify semantic relations between texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Ans</context>
<context position="3400" citStr="Dolan, Quirk, and Brockett, 2004" startWordPosition="514" endWordPosition="518">he answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investigated systematically in the recent past are entailment, i.e. to what extent text A entails or logically infers text B (Dagan, Glickman, &amp; Magnini, 2004), and elaboration, i.e. is text B is an elaboration of text A? (McCarthy &amp; McNamara, 2008). 163 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 163–168, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 1. Snapshot of SEMILAR. The Data View tab is shown. Semantic similarity can be broadly construed between tex</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Dolan, B., Quirk, C., &amp; Brockett, C. (2004). Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of the 20th International Conference on Computational Linguistics (COLING-2004), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fernando</author>
<author>M Stevenson</author>
</authors>
<title>A semantic similarity approach to paraphrase detection,</title>
<date>2008</date>
<booktitle>Computational Linguistics UK (CLUK 2008) 11th Annual Research Colloquium.</booktitle>
<contexts>
<context position="4960" citStr="Fernando &amp; Stevenson, 2008" startWordPosition="746" endWordPosition="749">h as assessing the similarity of a word to a sentence or a sentence to a paragraph. For instance, in summarization it might be useful to assess how well a sentence summarizes an entire paragraph. 2 Motivation The problem of word-to-word similarity has been extensively studied over the past decades and a word-to-word similarity library (WordNet Similarity) has been developed by Pedersen and colleagues (Pedersen, Patwardhan, &amp; Michelizzi, 2004). Methods to assess the semantic similarity of larger texts, in particular sentences, have been proposed over the last decade (Corley and Mihalcea, 2005; Fernando &amp; Stevenson, 2008; Rus, Lintean, Graesser, &amp; McNamara 2009). Androutsopoulos &amp; Malakasiotis (2010) compiled a survey of methods for paraphrasing and entailment semantic relation identification at sentence level. Despite all the proposed methods to assess semantic similarity between two texts, no semantic similarity library or toolkit, similar to the WordNet library for word-to-word similarity, exists for larger texts. Given the importance of semantic similarity, there is an acute need for such a library and toolkit. The developed SEMILAR library and toolkit presented here fulfill this need. In particular, the </context>
</contexts>
<marker>Fernando, Stevenson, 2008</marker>
<rawString>Fernando, S. &amp; Stevenson, M. (2008). A semantic similarity approach to paraphrase detection, Computational Linguistics UK (CLUK 2008) 11th Annual Research Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lintean</author>
<author>C Moldovan</author>
<author>V Rus</author>
<author>D McNamara</author>
</authors>
<title>The Role of Local and Global Weighting in Assessing the Semantic Similarity of Texts Using Latent Semantic Analysis.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Florida Artificial Intelligence Research Society Conference.</booktitle>
<location>Daytona Beach, FL.</location>
<contexts>
<context position="2873" citStr="Lintean et al., 2010" startWordPosition="435" endWordPosition="438">applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of each other could be considered as evidence for the correctness of the answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investigated systematically in</context>
</contexts>
<marker>Lintean, Moldovan, Rus, McNamara, 2010</marker>
<rawString>Lintean, M., Moldovan, C., Rus, V., &amp; McNamara D. (2010). The Role of Local and Global Weighting in Assessing the Semantic Similarity of Texts Using Latent Semantic Analysis. Proceedings of the 23rd International Florida Artificial Intelligence Research Society Conference. Daytona Beach, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lintean</author>
</authors>
<title>Measuring Semantic Similarity: Representations and Methods,</title>
<date>2011</date>
<tech>PhD Thesis,</tech>
<institution>Department of Computer Science, The University of Memphis,</institution>
<contexts>
<context position="2889" citStr="Lintean, 2011" startWordPosition="439" endWordPosition="440">ance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of each other could be considered as evidence for the correctness of the answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investigated systematically in the recent past</context>
<context position="7201" citStr="Lintean (2011)" startWordPosition="1073" endWordPosition="1074">ny level of granularity. 3 SEMILAR: The Semantic Similarity Toolkit The authors of the SEMILAR toolkit (see Figure 1) have been involved in assessing the semantic 164 large space of possibilities. The parameters include preprocessing options (collocation detection, punctuation, stopword removal, etc.), filtering options (all words, content words, etc.), weighting schemes (global vs. local weighting, binary weighting, etc.), and normalization factors (largest text, weighted average, etc.). A total of 3,456 variants of lexical overlap can be generated by different parameter settings in SEMILAR. Lintean (2011) has shown that performance on lexical overlap methods on the tasks of paraphrase identification and textual entailment tasks can vary significantly depending on the selected parameters. Some lexical overlap variations lead to performance results rivaling more sophisticated, state-of-the-art methods. It should be noted that the overlap category of methods can be extended to include N-gram overlap methods (see the N-gram overlap methods proposed by the Machine Translation community such as BLEU and METEOR). SEMILAR offers bigram and unigram overlap methods including the BLEU and METEOR scores. </context>
</contexts>
<marker>Lintean, 2011</marker>
<rawString>Lintean, M. (2011). Measuring Semantic Similarity: Representations and Methods, PhD Thesis, Department of Computer Science, The University of Memphis, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ibrahim</author>
<author>B Katz</author>
<author>J Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing, (ACL</booktitle>
<contexts>
<context position="2799" citStr="Ibrahim et al. 2003" startWordPosition="423" endWordPosition="426"> a need to identify and quantify semantic relations between texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of each other could be considered as evidence for the correctness of the answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 200</context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>Ibrahim, A., Katz, B., &amp; Lin, J. (2003). Extracting structural paraphrases from aligned monolingual corpora In Proceedings of the Second International Workshop on Paraphrasing, (ACL 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>R Kittredge</author>
<author>A Polgere</author>
</authors>
<title>Natural Language Generation in Artificial Intelligence and Computational Linguistics. Lexical selection and paraphrase in a meaning-text generation model,</title>
<date>1991</date>
<publisher>Kluwer Academic.</publisher>
<contexts>
<context position="2635" citStr="Iordanskaja et al. 1991" startWordPosition="396" endWordPosition="399"> decade (Dolan, Quirk, and Brockett, 2004; McCarthy &amp; McNamara, 2008; Agirre et al., 2012). These datasets include instances from various applications. Indeed, there is a need to identify and quantify semantic relations between texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of each other could be considered as evidence for the correctness of the answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic re</context>
</contexts>
<marker>Iordanskaja, Kittredge, Polgere, 1991</marker>
<rawString>Iordanskaja, L., Kittredge, R., &amp; Polgere, A. (1991). Natural Language Generation in Artificial Intelligence and Computational Linguistics. Lexical selection and paraphrase in a meaning-text generation model, Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P M McCarthy</author>
<author>D S McNamara</author>
</authors>
<title>UserLanguage Paraphrase Corpus Challenge https://umdrive.memphis.edu/pmmccrth/public/Par aphraseCorpus/Paraphrase site.htm. Retrieved 2/20/2010 online,</title>
<date>2008</date>
<contexts>
<context position="2079" citStr="McCarthy &amp; McNamara, 2008" startWordPosition="317" endWordPosition="320">York had no problem with MTA’s saying the decision to shift funds was within its powers. Given such two texts, the paraphrase identification task is about automatically assessing whether Text A is a paraphrase of, i.e. has the same meaning as, Text B. The example above is a positive instance, meaning that Text A is a paraphrase of Text B and vice versa. The importance of semantic similarity in Natural Language Processing (NLP) is highlighted by the diversity of datasets and shared task evaluation campaigns (STECs) that have been proposed over the last decade (Dolan, Quirk, and Brockett, 2004; McCarthy &amp; McNamara, 2008; Agirre et al., 2012). These datasets include instances from various applications. Indeed, there is a need to identify and quantify semantic relations between texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers th</context>
<context position="3692" citStr="McCarthy &amp; McNamara, 2008" startWordPosition="563" endWordPosition="566">nswers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investigated systematically in the recent past are entailment, i.e. to what extent text A entails or logically infers text B (Dagan, Glickman, &amp; Magnini, 2004), and elaboration, i.e. is text B is an elaboration of text A? (McCarthy &amp; McNamara, 2008). 163 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 163–168, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Figure 1. Snapshot of SEMILAR. The Data View tab is shown. Semantic similarity can be broadly construed between texts of any size. Depending on the granularity of the texts, we can talk about the following fundamental text-to-text similarity problems: word-to-word similarity, phrase-tophrase similarity, sentence-to-sentence similarity, paragraph-to-paragraph similarity, or document-to-document similarity</context>
</contexts>
<marker>McCarthy, McNamara, 2008</marker>
<rawString>McCarthy, P.M. &amp; McNamara, D.S. (2008). UserLanguage Paraphrase Corpus Challenge https://umdrive.memphis.edu/pmmccrth/public/Par aphraseCorpus/Paraphrase site.htm. Retrieved 2/20/2010 online, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet::Similarity - Measuring the Relatedness of Concepts,</title>
<date>2004</date>
<booktitle>In the Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04),</booktitle>
<pages>1024--1025</pages>
<institution>(Intelligent Systems Demonstration).</institution>
<location>San Jose, CA</location>
<contexts>
<context position="4779" citStr="Pedersen, Patwardhan, &amp; Michelizzi, 2004" startWordPosition="718" endWordPosition="722">rd-to-word similarity, phrase-tophrase similarity, sentence-to-sentence similarity, paragraph-to-paragraph similarity, or document-to-document similarity. Mixed combinations are also possible such as assessing the similarity of a word to a sentence or a sentence to a paragraph. For instance, in summarization it might be useful to assess how well a sentence summarizes an entire paragraph. 2 Motivation The problem of word-to-word similarity has been extensively studied over the past decades and a word-to-word similarity library (WordNet Similarity) has been developed by Pedersen and colleagues (Pedersen, Patwardhan, &amp; Michelizzi, 2004). Methods to assess the semantic similarity of larger texts, in particular sentences, have been proposed over the last decade (Corley and Mihalcea, 2005; Fernando &amp; Stevenson, 2008; Rus, Lintean, Graesser, &amp; McNamara 2009). Androutsopoulos &amp; Malakasiotis (2010) compiled a survey of methods for paraphrasing and entailment semantic relation identification at sentence level. Despite all the proposed methods to assess semantic similarity between two texts, no semantic similarity library or toolkit, similar to the WordNet library for word-to-word similarity, exists for larger texts. Given the impo</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet::Similarity - Measuring the Relatedness of Concepts, In the Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04), pp. 1024-1025, July 25-29, 2004, San Jose, CA (Intelligent Systems Demonstration).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>M Lintean</author>
<author>A C Graesser</author>
<author>D S McNamara</author>
</authors>
<title>Assessing Student Paraphrases Using Lexical Semantics and Word Weighting.</title>
<date>2009</date>
<booktitle>In Proceedings of the 14th International Conference on Artificial Intelligence in Education,</booktitle>
<location>Brighton, UK.</location>
<contexts>
<context position="2851" citStr="Rus et al., 2009" startWordPosition="431" endWordPosition="434">een texts in many applications. For instance, paraphrase identification, an instance of the semantic similarity problem, is an important step in a number of applications including Natural Language Generation, Question Answering, and dialogue-based Intelligent Tutoring Systems. In Natural Language Generation, paraphrases are a method to increase diversity of generated text (Iordanskaja et al. 1991). In Question Answering, multiple answers that are paraphrases of each other could be considered as evidence for the correctness of the answer (Ibrahim et al. 2003). In Intelligent Tutoring Sys-tems (Rus et al., 2009; Lintean et al., 2010; Lintean, 2011), paraphrase identification is useful to assess whether students’ articulated answers to deep questions (e.g. conceptual physics questions) are similar-to/paraphrases-of ideal answers. Generally, the problem of semantic similarity between two texts, denoted text A and text B, is defined as quantifying and identifying the presence of semantic relations between the two texts, e.g. to what extent text A has the same meaning as or is a paraphrase of text B (paraphrase relation; Dolan, Quirk, and Brockett, 2004). Other semantic relations that have been investig</context>
<context position="13284" citStr="Rus et al., 2009" startWordPosition="2064" endWordPosition="2067"> on the expertise level, measured by , of each worker at each job. By adding dummy workers or jobs we may assume that X and Y have the same size, n, and can be viewed as and Y = . In the semantic similarity case, the weight is the word-to-word similarity between a word x in text A and a word y in text B. The assignment problem can also be stated as finding a permutation of {1, 2, 3, ... , n} for which is maximum. Such an assignment is called optimum assignment. The Kuhn-Munkres algorithm (Kuhn, 1955) can find a solution to the optimum assignment problem in polynomial time. Rus and colleagues (Rus et al., 2009; Rus &amp; Graesser, 2006; Rus-Syntax-Iegation or RSI) used a lexical overlap component combined with syntactic overlap and negation handling to compute an unidirectional subsumption score between two sentences, T (Text) and H (Hypothesis), in entailment recognition and student input assessment in Intelligent Tutoring Systems. Each text is regarded as a graph with words as nodes/vertices and syntactic dependencies as edges. The subsumption score reflects how much a text is subsumed or contained by another. The equation below provides the overall subsumption score, which can be averaged both ways </context>
</contexts>
<marker>Rus, Lintean, Graesser, McNamara, 2009</marker>
<rawString>Rus, V., Lintean M., Graesser, A.C., &amp; McNamara, D.S. (2009). Assessing Student Paraphrases Using Lexical Semantics and Word Weighting. In Proceedings of the 14th International Conference on Artificial Intelligence in Education, Brighton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>M Lintean</author>
<author>C Moldovan</author>
<author>W Baggett</author>
<author>N Niraula</author>
<author>B Morgan</author>
</authors>
<title>The SIMILAR Corpus: A Resource to Foster the Qualitative Understanding of Semantic Similarity of Texts,</title>
<date>2012</date>
<booktitle>In Semantic Relations II: Enhancing Resources and Applications, The 8th Language Resources and Evaluation Conference (LREC</booktitle>
<location>Instanbul, Turkey.</location>
<contexts>
<context position="10316" citStr="Rus et al., 2012" startWordPosition="1555" endWordPosition="1558">ncy parsing, etc.), semantic similarity methods (word-level and sentencelevel), classification components for qualitative decision making with respect to textual semantic relations (naïve Bayes, Decision Trees, Support Vector Machines, and Neural Network), kernelbased methods (sequence kernels, word sequence kernels, and tree kernels; as of this writing, we are still implementing several other tree kernel methods); debugging and testing facilities for model selection; and annotation components (allows domain expert to manually annotate texts with semantic relations using GUI-based facilities; Rus et al., 2012). For space reasons, we only detail next the main algorithms in the core component, i.e. the major text-to-text similarity algorithms currently available in SEMILAR. 4 The Semantic Similarity Methods Available in SEMILAR The core component of SEMILAR is a set of text-to-text semantic similarity methods. We have implemented methods that handle both unidirectional similarity measures as well as bidirectional similarity measures. For instance, the semantic relation of entailment between two texts is unidirectional (a text T logically entails a hypothesis text H but H does not entail T) while the </context>
</contexts>
<marker>Rus, Lintean, Moldovan, Baggett, Niraula, Morgan, 2012</marker>
<rawString>Rus, V., Lintean, M., Moldovan, C., Baggett, W., Niraula, N., Morgan, B. (2012). The SIMILAR Corpus: A Resource to Foster the Qualitative Understanding of Semantic Similarity of Texts, In Semantic Relations II: Enhancing Resources and Applications, The 8th Language Resources and Evaluation Conference (LREC 2012), May 23-25, Instanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>R Banjade</author>
<author>N Niraula</author>
</authors>
<title>Similarity Measures based on Latent Dirichlet Allocation,</title>
<date>2013</date>
<booktitle>The 14th International Conference on Intelligent Text Procesing and Computational Linguistics,</booktitle>
<location>Samos, Greece.</location>
<contexts>
<context position="18493" citStr="Rus, Banjade, &amp; Niraula, 2013" startWordPosition="2993" endWordPosition="2997">he Hellinger and Manhattan distances between two distributions are two other options that avoid the shortcomings of the KL distance. Both are options are implemented in SEMILAR. LDA similarity measures between two documents or texts c and d can also include similarity of topics. That is, the text-to-text similarity is obtained multiplying the similarities between the distribution over topics (θd and θc) and distribution over words (φt1 and φt2). The similarity of topics can be computed using the same methods illustrated above as the topics are distributions over words (for all the details see Rus, Banjade, &amp; Niraula, 2013). The last semantic similarity method presented in this paper is based on the Quadratic Assignment Problem (QAP). The QAP method aims at finding an optimal assignment from words in text A to words in text B, based on individual wordto-word similarity measures, while simultaneously maximizing the match between the syntactic dependencies of the words. The Koopmans-Beckmann (1957) formulation of the QAP problem best fits this purpose. The goal of the original QAP formulation, in the domain of economic activity, was to minimize the objective function QAP shown below where matrix F describes the f</context>
</contexts>
<marker>Rus, Banjade, Niraula, 2013</marker>
<rawString>Rus, V., Banjade, R., &amp; Niraula, N. (2013). Similarity Measures based on Latent Dirichlet Allocation, The 14th International Conference on Intelligent Text Procesing and Computational Linguistics, March 24-30, 2013, Samos, Greece.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>