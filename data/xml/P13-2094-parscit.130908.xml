<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.023197">
<title confidence="0.981033">
Co-Regression for Cross-Language Review Rating Prediction
</title>
<author confidence="0.998455">
Xiaojun Wan
</author>
<affiliation confidence="0.9873695">
Institute of Computer Science and Technology, The MOE Key Laboratory of
Computational Linguistics, Peking University, Beijing 100871, China
</affiliation>
<email confidence="0.992659">
wanxiaojun@pku.edu.cn
</email>
<sectionHeader confidence="0.993767" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999671933333333">
The task of review rating prediction can be
well addressed by using regression algorithms
if there is a reliable training set of reviews
with human ratings. In this paper, we aim to
investigate a more challenging task of cross-
language review rating prediction, which
makes use of only rated reviews in a source
language (e.g. English) to predict the rating
scores of unrated reviews in a target language
(e.g. German). We propose a new co-
regression algorithm to address this task by
leveraging unlabeled reviews. Evaluation re-
sults on several datasets show that our pro-
posed co-regression algorithm can consistently
improve the prediction results.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991000000001">
With the development of e-commerce, more and
more people like to buy products on the web and
express their opinions about the products by
writing reviews. These reviews usually contain
valuable information for other people’s reference
when they buy the same or similar products. In
some applications, it is useful to categorize a re-
view into either positive or negative, but in many
real-world scenarios, it is important to provide
numerical ratings rather than binary decisions.
The task of review rating prediction aims to
automatically predict the rating scores of unrated
product reviews. It is considered as a finer-
grained task than the binary sentiment classifica-
tion task. Review rating prediction has been
modeled as a multi-class classification or regres-
sion task, and the regression based methods have
shown better performance than the multi-class
classification based methods in recent studies (Li
et al. 2011). Therefore, we focus on investigating
regression-based methods in this study.
Traditionally, the review rating prediction task
has been investigated in a monolingual setting,
which means that the training reviews with hu-
man ratings and the test reviews are in the same
language. However, a more challenging task is to
predict the rating scores of the reviews in a target
language (e.g. German) by making use of the
rated reviews in a different source language (e.g.
English), which is called Cross-Language Re-
view Rating Prediction. Considering that the re-
sources (i.e. the rated reviews) for review rating
prediction in different languages are imbalanced,
it would be very useful to make use of the re-
sources in resource-rich languages to help ad-
dress the review rating prediction task in re-
source-poor languages.
The task of cross-language review rating pre-
diction can be typically addressed by using ma-
chine translation services for review translation,
and then applying regression methods based on
the monolingual training and test sets. However,
due to the poor quality of machine translation,
the reviews translated from one language A to
another language B are usually very different
from the original reviews in language B, because
the words or syntax of the translated reviews
may be erroneous or non-native. This phenome-
non brings great challenges for existing regres-
sion algorithms.
In this study, we propose a new co-regression
algorithm to address the above problem by lever-
aging unlabeled reviews in the target language.
Our algorithm can leverage both views of the
reviews in the source language and the target
language to collaboratively determine the confi-
dently predicted ones out of the unlabeled re-
views, and then use the selected examples to
enlarge the training set. Evaluation results on
several datasets show that our proposed co-
regression algorithm can consistently improve
the prediction results.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999859857142857">
Most previous works on review rating prediction
model this problem as a multi-class classification
task or a regression task. Various features have
been exploited from the review text, including
words, patterns, syntactic structure, and semantic
topic (Qu et al. 2010; Pang and Lee, 2005; Leung
et al. 2006; Ganu et al. 2009). Traditional learn-
</bodyText>
<page confidence="0.976564">
526
</page>
<bodyText confidence="0.932523741935484">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
ing models, such as SVM, are adopted for rating
prediction. Most recently, Li et al. (2011) pro-
pose a novel tensor-based learning framework to
incorporate reviewer and product information
into the text based learner for rating prediction.
Saggion et al. (2012) study the use of automatic
text summaries instead of the full reviews for
movie review rating prediction. In addition to
predicting the overall rating of a full review,
multi-aspect rating prediction has also been in-
vestigated (Lu et al. 2011b; Snyder and Barzilay,
2007; Zhu et al. 2009; Wang et al. 2010; Lu et al.
2009; Titov and McDonald, 2008). All the above
previous works are working under a monolingual
setting, and to the best of our knowledge, there
exists no previous work on cross-language re-
view rating prediction.
It is noteworthy that a few studies have been
conducted for the task of cross-lingual sentiment
classification or text classification, which aims to
make use of labeled data in a language for the
binary classification task in a different language
(Mihalcea et al., 2007; Banea et al., 2008; Wan
2009; Lu et al. 2011a; Meng et al. 2012; Shi et
al., 2010; Prettenhofer and Stein 2010). However,
the binary classification task is very different
from the regression task studied in this paper,
and the proposed methods in the above previous
works cannot be directly applied.
</bodyText>
<sectionHeader confidence="0.9594695" genericHeader="method">
3 Problem Definition and Baseline Ap-
proaches
</sectionHeader>
<bodyText confidence="0.9999429">
Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the
labeled training set of reviews in a source lan-
guage (e.g. English), where xi is the i-th review
and yi is its real-valued label, and n is the number
of labeled examples; Let T denote the test review
set in a different target language (e.g. German);
Then the task of cross-language review rating
prediction aims at automatically predicting the
rating scores of the reviews in T by leveraging
the labeled reviews in L. No labeled reviews in
the target language are allowed to be used.
The task is a regression problem and it is chal-
lenging due to the language gap between the la-
beled training dataset and the test dataset. Fortu-
nately, due to the development of machine trans-
lation techniques, a few online machine transla-
tion services can be used for review translation.
We adopt Google Translate1 for review transla-
tion. After review translation, the training re-
views and the test reviews are now in the same
</bodyText>
<footnote confidence="0.797561">
1 http://translate.google.com
</footnote>
<bodyText confidence="0.998221892857143">
language, and any regression algorithm (e.g. lo-
gistic regression, least squares regression, KNN
regressor) can be applied for learning and predic-
tion. In this study, without loss of generality, we
adopt the widely used regression SVM (Vapnik
1995; Joachims 1999) implemented in the
SVMLight toolkit2 as the basic regressor. For
comparative analysis, we simply use the default
parameter values in SVMLight with linear kernel.
The features include all unigrams and bigrams in
the review texts, and the value of each feature is
simply set to its frequency (TF) in a review.
Using features in different languages, we have
the following baseline approaches for addressing
the cross-language regression problem.
REG_S: It conducts regression learning and
prediction in the source language.
REG_T: It conducts regression learning and
prediction in the target language.
REG_ST: It conducts regression learning and
prediction with all the features in both languages.
REG_STC: It combines REG_S and REG_T
by averaging their prediction values.
However, the above regression methods do not
perform very well due to the unsatisfactory ma-
chine translation quality and the various lan-
guage expressions. Therefore, we need to find
new approaches to improve the above methods.
</bodyText>
<sectionHeader confidence="0.98777" genericHeader="method">
4 Our Proposed Approach
</sectionHeader>
<subsectionHeader confidence="0.947151">
4.1 Overview
</subsectionHeader>
<bodyText confidence="0.99999280952381">
Our basic idea is to make use of some amounts
of unlabeled reviews in the target language to
improve the regression performance. Consider-
ing that the reviews have two views in two lan-
guages and inspired by the co-training style algo-
rithms (Blum and Mitchell, 1998; Zhou and Li,
2005), we propose a new co-training style algo-
rithm called co-regression to leverage the unla-
beled data in a collaborative way. The proposed
co-regression algorithm can make full use of
both the features in the source language and the
features in the target language in a unified
framework similar to (Wan 2009). Each review
has two versions in the two languages. The
source-language features and the target-language
features for each review are considered two re-
dundant views of the review. In the training
phase, the co-regression algorithm is applied to
learn two regressors in the two languages. In the
prediction phase, the two regressors are applied
to predict two rating scores of the review. The
</bodyText>
<footnote confidence="0.961023">
2 http://svmlight.joachims.org
</footnote>
<page confidence="0.994555">
527
</page>
<bodyText confidence="0.999128">
final rating score of the review is the average of
the two rating scores.
</bodyText>
<subsectionHeader confidence="0.992674">
4.2 Our Proposed Co-Regression Algorithm
</subsectionHeader>
<bodyText confidence="0.996796728395062">
In co-training for classification, some confidently
classified examples by one classifier are pro-
vided for the other classifier, and vice versa.
Each of the two classifiers can improve by learn-
ing from the newly labeled examples provided
by the other classifier. The intuition is the same
for co-regression. However, in the classification
scenario, the confidence value of each prediction
can be easily obtained through consulting the
classifier. For example, the SVM classifier pro-
vides a confidence value or probability for each
prediction. However, in the regression scenario,
the confidence value of each prediction is not
provided by the regressor. So the key question is
how to get the confidence value of each labeled
example. In (Zhou and Li, 2005), the assumption
is that the most confidently labeled example of a
regressor should be with such a property, i.e. the
error of the regressor on the labeled example set
(i.e. the training set) should decrease the most if
the most confidently labeled example is utilized.
In other words, the confidence value of each la-
beled example is measured by the decrease of the
error (e.g. mean square error) on the labeled set
of the regressor utilizing the information pro-
vided by the example. Thus, each example in the
unlabeled set is required to be checked by train-
ing a new regression model utilizing the example.
However, the model training process is usually
very time-consuming for many regression algo-
rithms, which significantly limits the use of the
work in (Zhou and Li, 2005). Actually, in (Zhou
and Li, 2005), only the lazy learning based KNN
regressor is adopted. Moreover, the confidence
of the labeled examples is assessed based only on
the labeled example set (i.e. the training set),
which makes the generalization ability of the
regressor not good.
In order to address the above problem, we
propose a new confidence evaluation strategy
based on the consensus of the two regressors.
Our intuition is that if the two regressors agree
on the prediction scores of an example very well,
then the example is very confidently labeled. On
the contrary, if the prediction scores of an exam-
ple by the two regressors are very different, we
can hardly make a decision whether the example
is confidently labeled or not. Therefore, we use
the absolute difference value between the predic-
tion scores of the two regressors as the confi-
dence value of a labeled example, and if the ex-
ample is chosen, its final prediction score is the
average of the two prediction scores. Based on
this strategy, the confidently labeled examples
can be easily and efficiently chosen from the
unlabeled set as in the co-training algorithm, and
these examples are then added into the labeled
set for re-training the two regressors.
Our proposed co-regression algorithm is illus-
trated in Figure 1. In the proposed co-regression
algorithm, any regression algorithm can be used
as the basic regressor to construct Rsource and Rtar-
get, and in this study, we adopt the same regres-
sion SVM implemented in the SVMLight toolkit
with default parameter values. Similarly, the fea-
tures include both unigrams and bigrams and the
feature weight is simply set to term frequency.
There are two parameters in the algorithm: I is
the iteration number and m is the growth size in
each iteration. I and m can be empirically set ac-
cording to the total size of the unlabeled set U,
and we have I×m≤ |U|.
Our proposed co-regression algorithm is much
more efficient than the COREG algorithm (Zhou
and Li, 2005). If we consider the time-
consuming regression learning process as one
Given:
- Fsource and Ftarget are redundantly sufficient
sets of features, where Fsource represents
the source language features, Ftarget repre-
sents the target language features;
</bodyText>
<figure confidence="0.921617227272727">
- L is a set of labeled training reviews;
- U is a set of unlabeled reviews;
Loop for I iterations:
1. Learn the first regressor Rsource from L
based on Fsource;
2. Use Rsource to label reviews from U based
on Fsource; Let source
yˆ i denote the predic-
tion score of review xi;
3. Learn the second classifier Rtarget from L
based on Ftarget;
4. Use Rtarget to label reviews from U based
on Ftarget; Let y, arget denote the predic-
tion score of review xi;
5. Choose m most confidently predicted re-
views E={ top m reviews with the small-
est value of yˆ, arget − A ource } from U,
where the final prediction score of each
review in E is y; arget + ysource 2 ;
i
6. Removes reviews E from U and add re-
views E with the corresponding predic-
</figure>
<figureCaption confidence="0.9868855">
tion scores to L;
Figure 1. Our proposed co-regression algorithm
</figureCaption>
<page confidence="0.824334">
528
</page>
<figure confidence="0.999817044444444">
M S E
1.35
1.33
1.31
1.29
1.27
1.25
1.23
1.21
1.19
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
(c) Target language=German &amp; Category=music
Rsource
Rtarget
co-regression
REG_S
REG_T
REG_ST
REG_STC
COREG
MSE
1.22
1.18
1.16
1.14
1.12
1.2
1.1
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
(a) Target language=German &amp; Category=books
MSE
1.26
1.24
1.22
1.18
1.16
1.14
1.12
1.2
1.1
1 10 20 30 40 50 60 70 80 90 100110120130140150
Iteration Number (I)
(b) Target language=German &amp; Category=dvd
</figure>
<figureCaption confidence="0.999962">
Figure 2. Comparison results vs. Iteration Number (I) (Rsource and Rtarget are the two component regressors)
</figureCaption>
<bodyText confidence="0.999716705882353">
basic operation and make use of all unlabeled
examples in U, the computational complexity of
COREG is O(|U|+I). By contrast, the computa-
tional complexity of our proposed co-regression
algorithm is just O(I). Since |U |is much larger
than I, our proposed co-regression algorithm is
much more efficient than COREG, and thus our
proposed co-regression algorithm is more suit-
able to be used in applications with a variety of
regression algorithms.
Moreover, in our proposed co-regression algo-
rithm, the confidence of each prediction is de-
termined collaboratively by two regressors. The
selection is not restricted by the training set, and
it is very likely that a portion of good examples
can be chosen for generalize the regressor to-
wards the test set.
</bodyText>
<sectionHeader confidence="0.986169" genericHeader="method">
5 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.999953909090909">
We used the WEBIS-CLS-10 corpus3 provided
by (Prettenhofer and Stein, 2010) for evaluation.
It consists of Amazon product reviews for three
product categories (i.e. books, dvds and music)
written in different languages including English,
German, etc. For each language-category pair
there exist three sets of training documents, test
documents, and unlabeled documents. The train-
ing and test sets comprise 2000 documents each,
whereas the number of unlabeled documents var-
ies from 9000 – 170000. The dataset is provided
with the rating score between 1 to 5 assigned by
users, which can be used for the review rating
prediction task. We extracted texts from both the
summary field and the text field to represent a
review text. We then extracted the rating score as
a review’s corresponding real-valued label. In
the cross-language scenario, we regarded English
as the source language, and regarded German as
the target language. The experiments were con-
ducted on each product category separately.
Without loss of generality, we sampled and used
</bodyText>
<footnote confidence="0.9722655">
3 http://www.uni-weimar.de/medien/webis/research/corpora/
corpus-webis-cls-10.html
</footnote>
<bodyText confidence="0.998966">
only 8000 unlabeled documents for each product
category. We use Mean Square Error (MSE) as
the evaluation metric, which penalizes more se-
vere errors more heavily.
In the experiments, our proposed co-regression
algorithm (i.e. “co-regression”) is compared with
the COREG algorithm in (Zhou and Li, 2005)
and a few other baselines. For our proposed co-
regression algorithm, the growth size m is simply
set to 50. We implemented the COREG algo-
rithm by replacing the KNN regressor with the
regression SVM and the pool size is also set to
50. The iteration number I varies from 1 to 150.
The comparison results are shown in Figure 2.
We can see that on all product categories, the
MSE values of our co-regression algorithm and
the two component regressors tend to decline
over a wide range of I, which means that the se-
lected confidently labeled examples at each itera-
tion are indeed helpful to improve the regressors.
Our proposed co-regression algorithm outper-
forms all the baselines (including COREG) over
different iteration members, which verifies the
effectiveness of our proposed algorithm. We can
also see that the COREG algorithm does not per-
form well for this cross-language regression task.
Overall, our proposed co-regression algorithm
can consistently improve the prediction results.
</bodyText>
<sectionHeader confidence="0.997012" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999607142857143">
In this paper, we study a new task of cross-
language review rating prediction and propose a
new co-regression algorithm to address this task.
In future work, we will apply the proposed co-
regression algorithm to other cross-language or
cross-domain regression problems in order to
verify its robustness.
</bodyText>
<sectionHeader confidence="0.998327" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.989605">
The work was supported by NSFC (61170166),
Beijing Nova Program (2008B03) and National
High-Tech R&amp;D Program (2012AA011101).
</bodyText>
<page confidence="0.997616">
529
</page>
<sectionHeader confidence="0.990306" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999404205607477">
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity
analysis using machine translation. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pp. 127-135.
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classifi-
cation. In Annual Meeting-Association For Com-
putational Linguistics.
Avrim Blum and Tom Mitchell. 1998. Combining
labeled and unlabeled data with co-training. In Pro-
ceedings of the eleventh annual conference on
Computational learning theory, pp. 92-100.
Hang Cui, Vibhu Mittal, and Mayur Datar. 2006.
Comparative experiments on sentiment classifica-
tion for online product reviews. In Proceedings of
the National Conference on Artificial Intelligence.
Gayatree Ganu, Noemie Elhadad, and Amélie Marian.
2009. Beyond the stars: Improving rating predic-
tions using review text content. In WebDB.
Thorsten Joachims, 1999. Making large-Scale SVM
Learning Practical. Advances in Kernel Methods -
Support Vector Learning, MIT-Press.
CaneWing Leung, Stephen Chi Chan, and Fu Chung.
2006. Integrating collaborative filtering and senti-
ment analysis: A rating inference approach. In
ECAI Workshop, pages 300–307.
Fangtao Li, Nathan Liu, Hongwei Jin, Kai Zhao,
Qiang Yang and Xiaoyan Zhu. 2011. Incorporating
reviewer and product information for review rating
prediction. In Proceedings of the Twenty-Second
International Joint Conference on Artificial Intelli-
gence (IJCAI2011).
Yue Lu, ChengXiang Zhai, Neel Sundaresan. 2009.
Rated Aspect Summarization of Short Comments.
Proceedings of the World Wide Conference 2009
( WWW&apos;09), pages 131-140.
Bin Lu, Chenhao Tan, Claire Cardie, Ka Yin Benja-
min TSOU. 2011a. Joint bilingual sentiment classi-
fication with unlabeled parallel corpora. In Pro-
ceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human
Language Technologies, pp. 320-330.
Bin Lu, Myle Ott, Claire Cardie and Benjamin K.
Tsou. 2011b. Multi-aspect sentiment analysis with
topic models. In Proceedings of Data Minig
Workshps (ICDMW), 2011 IEEE 11th Interna-
tional Conference on, pp. 81-88, IEEE.
Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou,
Ge Xu, and Houfeng Wang. 2012. Cross-Lingual
Mixture Model for Sentiment Classification. In
Proceedings of ACL-2012.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2007. Learning multilingual subjective language
via cross-lingual projections. In Proceedings of
ACL-2007.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natu-
ral language processing-Volume 10, pp. 79-86,
2002.
Bo Pang and Lillian Lee. 2005. Seeing stars: Exploit-
ing class relationships for sentiment categorization
with respect to rating scales. In Proceedings of the
ACL, pages 115–124.
Peter Prettenhofer and Benno Stein. 2010. Cross-
Language Text Classification using Structural Cor-
respondence Learning. In 48th Annual Meeting of
the Association of Computational Linguistics
(ACL 10), 1118-1127.
Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum.
2010. The bag-of-opinions method for review rat-
ing prediction from sparse text patterns. In COL-
ING, pages 913–921, Stroudsburg, PA, USA, 2010.
ACL.
Horacio Saggion, Elena Lloret, and Manuel Palomar.
2012. Can text summaries help predict ratings? a
case study of movie reviews. Natural Language
Processing and Information Systems (2012): 271-
276.
Lei Shi, Rada Mihalcea, and Mingjun Tian. 2010.
Cross language text classification by model transla-
tion and semi-supervised learning. In Proceedings
of the 2010 Conference on Empirical Methods in
Natural Language Processing, pp. 1057-1067, 2010.
Benjamin Snyder and Regina Barzilay. 2007. Multi-
ple aspect ranking using the good grief algorithm.
Proceedings of the Joint Human Language Tech-
nology/North American Chapter of the ACL Con-
ference (HLT-NAACL).
Ivan Titov and Ryan McDonald. 2008. A joint model
of text and aspect ratings for sentiment summariza-
tion. In Proceedings of ACL-08:HLT, pages 308-
316.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational
Linguistics, pp. 417-424.
Vladimir N. Vapnik, 1995. The Nature of Statistical
Learning Theory. Springer.
Xiaojun Wan. 2009. Co-training for cross-lingual
sentiment classification. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
</reference>
<page confidence="0.966931">
530
</page>
<reference confidence="0.999637611111111">
Natural Language Processing of the AFNLP, pp.
235-243.
Hongning Wang, Yue Lu, ChengXiang Zhai. 2010.
Latent Aspect Rating Analysis on Review Text
Data: A Rating Regression Approach. Proceedings
of the 17th ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining
(KDD&apos;10), pages 115-124.
Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and
Muhua Zhu. 2009. Multi-aspect opinion polling
from textual reviews. In Proceedings of the 18th
ACM conference on Information and knowledge
management, pp. 1799-1802. ACM.
Zhi-Hua Zhou and Ming Li. 2005. Semi-supervised
regression with co-training. In Proceedings of the
19th international joint conference on Artificial in-
telligence, pp. 908-913. Morgan Kaufmann Pub-
lishers Inc.
</reference>
<page confidence="0.997956">
531
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968583">
<title confidence="0.999849">Co-Regression for Cross-Language Review Rating Prediction</title>
<author confidence="0.998788">Xiaojun Wan</author>
<affiliation confidence="0.999966">Institute of Computer Science and Technology, The MOE Key Laboratory</affiliation>
<address confidence="0.979486">Computational Linguistics, Peking University, Beijing 100871, China</address>
<email confidence="0.991786">wanxiaojun@pku.edu.cn</email>
<abstract confidence="0.99986225">The task of review rating prediction can be well addressed by using regression algorithms if there is a reliable training set of reviews with human ratings. In this paper, we aim to investigate a more challenging task of crosslanguage review rating prediction, which makes use of only rated reviews in a source language (e.g. English) to predict the rating scores of unrated reviews in a target language (e.g. German). We propose a new coregression algorithm to address this task by leveraging unlabeled reviews. Evaluation results on several datasets show that our proposed co-regression algorithm can consistently improve the prediction results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
<author>Samer Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>127--135</pages>
<contexts>
<context position="5377" citStr="Banea et al., 2008" startWordPosition="837" endWordPosition="840"> has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test review set in a differ</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>Carmen Banea, Rada Mihalcea, Janyce Wiebe, and Samer Hassan. 2008. Multilingual subjectivity analysis using machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 127-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Annual Meeting-Association For Computational Linguistics.</booktitle>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Annual Meeting-Association For Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In Proceedings of the eleventh annual conference on Computational learning theory,</booktitle>
<pages>92--100</pages>
<contexts>
<context position="8262" citStr="Blum and Mitchell, 1998" startWordPosition="1306" endWordPosition="1309">s in both languages. REG_STC: It combines REG_S and REG_T by averaging their prediction values. However, the above regression methods do not perform very well due to the unsatisfactory machine translation quality and the various language expressions. Therefore, we need to find new approaches to improve the above methods. 4 Our Proposed Approach 4.1 Overview Our basic idea is to make use of some amounts of unlabeled reviews in the target language to improve the regression performance. Considering that the reviews have two views in two languages and inspired by the co-training style algorithms (Blum and Mitchell, 1998; Zhou and Li, 2005), we propose a new co-training style algorithm called co-regression to leverage the unlabeled data in a collaborative way. The proposed co-regression algorithm can make full use of both the features in the source language and the features in the target language in a unified framework similar to (Wan 2009). Each review has two versions in the two languages. The source-language features and the target-language features for each review are considered two redundant views of the review. In the training phase, the co-regression algorithm is applied to learn two regressors in the </context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh annual conference on Computational learning theory, pp. 92-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Vibhu Mittal</author>
<author>Mayur Datar</author>
</authors>
<title>Comparative experiments on sentiment classification for online product reviews.</title>
<date>2006</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<marker>Cui, Mittal, Datar, 2006</marker>
<rawString>Hang Cui, Vibhu Mittal, and Mayur Datar. 2006. Comparative experiments on sentiment classification for online product reviews. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>Noemie Elhadad</author>
<author>Amélie Marian</author>
</authors>
<title>Beyond the stars: Improving rating predictions using review text content.</title>
<date>2009</date>
<booktitle>In WebDB.</booktitle>
<contexts>
<context position="4089" citStr="Ganu et al. 2009" startWordPosition="632" endWordPosition="635">atively determine the confidently predicted ones out of the unlabeled reviews, and then use the selected examples to enlarge the training set. Evaluation results on several datasets show that our proposed coregression algorithm can consistently improve the prediction results. 2 Related Work Most previous works on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicti</context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, Noemie Elhadad, and Amélie Marian. 2009. Beyond the stars: Improving rating predictions using review text content. In WebDB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<date>1999</date>
<booktitle>Making large-Scale SVM Learning Practical. Advances in Kernel Methods -Support Vector Learning,</booktitle>
<location>MIT-Press.</location>
<contexts>
<context position="6964" citStr="Joachims 1999" startWordPosition="1105" endWordPosition="1106">ing dataset and the test dataset. Fortunately, due to the development of machine translation techniques, a few online machine translation services can be used for review translation. We adopt Google Translate1 for review translation. After review translation, the training reviews and the test reviews are now in the same 1 http://translate.google.com language, and any regression algorithm (e.g. logistic regression, least squares regression, KNN regressor) can be applied for learning and prediction. In this study, without loss of generality, we adopt the widely used regression SVM (Vapnik 1995; Joachims 1999) implemented in the SVMLight toolkit2 as the basic regressor. For comparative analysis, we simply use the default parameter values in SVMLight with linear kernel. The features include all unigrams and bigrams in the review texts, and the value of each feature is simply set to its frequency (TF) in a review. Using features in different languages, we have the following baseline approaches for addressing the cross-language regression problem. REG_S: It conducts regression learning and prediction in the source language. REG_T: It conducts regression learning and prediction in the target language. </context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims, 1999. Making large-Scale SVM Learning Practical. Advances in Kernel Methods -Support Vector Learning, MIT-Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CaneWing Leung</author>
<author>Stephen Chi Chan</author>
<author>Fu Chung</author>
</authors>
<title>Integrating collaborative filtering and sentiment analysis: A rating inference approach.</title>
<date>2006</date>
<booktitle>In ECAI Workshop,</booktitle>
<pages>300--307</pages>
<contexts>
<context position="4070" citStr="Leung et al. 2006" startWordPosition="628" endWordPosition="631">anguage to collaboratively determine the confidently predicted ones out of the unlabeled reviews, and then use the selected examples to enlarge the training set. Evaluation results on several datasets show that our proposed coregression algorithm can consistently improve the prediction results. 2 Related Work Most previous works on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In a</context>
</contexts>
<marker>Leung, Chan, Chung, 2006</marker>
<rawString>CaneWing Leung, Stephen Chi Chan, and Fu Chung. 2006. Integrating collaborative filtering and sentiment analysis: A rating inference approach. In ECAI Workshop, pages 300–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Nathan Liu</author>
<author>Hongwei Jin</author>
<author>Kai Zhao</author>
</authors>
<title>Qiang Yang and Xiaoyan Zhu.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence (IJCAI2011).</booktitle>
<contexts>
<context position="1825" citStr="Li et al. 2011" startWordPosition="274" endWordPosition="277"> useful to categorize a review into either positive or negative, but in many real-world scenarios, it is important to provide numerical ratings rather than binary decisions. The task of review rating prediction aims to automatically predict the rating scores of unrated product reviews. It is considered as a finergrained task than the binary sentiment classification task. Review rating prediction has been modeled as a multi-class classification or regression task, and the regression based methods have shown better performance than the multi-class classification based methods in recent studies (Li et al. 2011). Therefore, we focus on investigating regression-based methods in this study. Traditionally, the review rating prediction task has been investigated in a monolingual setting, which means that the training reviews with human ratings and the test reviews are in the same language. However, a more challenging task is to predict the rating scores of the reviews in a target language (e.g. German) by making use of the rated reviews in a different source language (e.g. English), which is called Cross-Language Review Rating Prediction. Considering that the resources (i.e. the rated reviews) for review</context>
<context position="4390" citStr="Li et al. (2011)" startWordPosition="675" endWordPosition="678">ous works on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the</context>
</contexts>
<marker>Li, Liu, Jin, Zhao, 2011</marker>
<rawString>Fangtao Li, Nathan Liu, Hongwei Jin, Kai Zhao, Qiang Yang and Xiaoyan Zhu. 2011. Incorporating reviewer and product information for review rating prediction. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence (IJCAI2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
<author>Neel Sundaresan</author>
</authors>
<title>Rated Aspect Summarization of Short Comments.</title>
<date>2009</date>
<booktitle>Proceedings of the World Wide Conference 2009 ( WWW&apos;09),</booktitle>
<pages>131--140</pages>
<contexts>
<context position="4881" citStr="Lu et al. 2009" startWordPosition="756" endWordPosition="759">n for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, </context>
</contexts>
<marker>Lu, Zhai, Sundaresan, 2009</marker>
<rawString>Yue Lu, ChengXiang Zhai, Neel Sundaresan. 2009. Rated Aspect Summarization of Short Comments. Proceedings of the World Wide Conference 2009 ( WWW&apos;09), pages 131-140.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2011a</author>
</authors>
<title>Joint bilingual sentiment classification with unlabeled parallel corpora.</title>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>320--330</pages>
<contexts>
<context position="4390" citStr="(2011)" startWordPosition="678" endWordPosition="678">on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the</context>
</contexts>
<marker>2011a, </marker>
<rawString>Bin Lu, Chenhao Tan, Claire Cardie, Ka Yin Benjamin TSOU. 2011a. Joint bilingual sentiment classification with unlabeled parallel corpora. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pp. 320-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Multi-aspect sentiment analysis with topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of Data Minig Workshps (ICDMW), 2011 IEEE 11th International Conference on,</booktitle>
<pages>81--88</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="4802" citStr="Lu et al. 2011" startWordPosition="740" endWordPosition="743">Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 201</context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie and Benjamin K. Tsou. 2011b. Multi-aspect sentiment analysis with topic models. In Proceedings of Data Minig Workshps (ICDMW), 2011 IEEE 11th International Conference on, pp. 81-88, IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinfan Meng</author>
<author>Furu Wei</author>
<author>Xiaohua Liu</author>
<author>Ming Zhou</author>
<author>Ge Xu</author>
<author>Houfeng Wang</author>
</authors>
<title>Cross-Lingual Mixture Model for Sentiment Classification.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL-2012.</booktitle>
<contexts>
<context position="5422" citStr="Meng et al. 2012" startWordPosition="847" endWordPosition="850">nyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test review set in a different target language (e.g. German); Then the t</context>
</contexts>
<marker>Meng, Wei, Liu, Zhou, Xu, Wang, 2012</marker>
<rawString>Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou, Ge Xu, and Houfeng Wang. 2012. Cross-Lingual Mixture Model for Sentiment Classification. In Proceedings of ACL-2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carmen Banea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-2007.</booktitle>
<contexts>
<context position="5357" citStr="Mihalcea et al., 2007" startWordPosition="833" endWordPosition="836">spect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test re</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of ACL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>79--86</pages>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pp. 79-86, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="4051" citStr="Pang and Lee, 2005" startWordPosition="624" endWordPosition="627">age and the target language to collaboratively determine the confidently predicted ones out of the unlabeled reviews, and then use the selected examples to enlarge the training set. Evaluation results on several datasets show that our proposed coregression algorithm can consistently improve the prediction results. 2 Related Work Most previous works on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rati</context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the ACL, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Prettenhofer</author>
<author>Benno Stein</author>
</authors>
<title>CrossLanguage Text Classification using Structural Correspondence Learning.</title>
<date>2010</date>
<booktitle>In 48th Annual Meeting of the Association of Computational Linguistics (ACL</booktitle>
<volume>10</volume>
<pages>1118--1127</pages>
<contexts>
<context position="5470" citStr="Prettenhofer and Stein 2010" startWordPosition="855" endWordPosition="858"> 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test review set in a different target language (e.g. German); Then the task of cross-language review rating prediction a</context>
<context position="15186" citStr="Prettenhofer and Stein, 2010" startWordPosition="2473" endWordPosition="2476">s much larger than I, our proposed co-regression algorithm is much more efficient than COREG, and thus our proposed co-regression algorithm is more suitable to be used in applications with a variety of regression algorithms. Moreover, in our proposed co-regression algorithm, the confidence of each prediction is determined collaboratively by two regressors. The selection is not restricted by the training set, and it is very likely that a portion of good examples can be chosen for generalize the regressor towards the test set. 5 Empirical Evaluation We used the WEBIS-CLS-10 corpus3 provided by (Prettenhofer and Stein, 2010) for evaluation. It consists of Amazon product reviews for three product categories (i.e. books, dvds and music) written in different languages including English, German, etc. For each language-category pair there exist three sets of training documents, test documents, and unlabeled documents. The training and test sets comprise 2000 documents each, whereas the number of unlabeled documents varies from 9000 – 170000. The dataset is provided with the rating score between 1 to 5 assigned by users, which can be used for the review rating prediction task. We extracted texts from both the summary f</context>
</contexts>
<marker>Prettenhofer, Stein, 2010</marker>
<rawString>Peter Prettenhofer and Benno Stein. 2010. CrossLanguage Text Classification using Structural Correspondence Learning. In 48th Annual Meeting of the Association of Computational Linguistics (ACL 10), 1118-1127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lizhen Qu</author>
<author>Georgiana Ifrim</author>
<author>Gerhard Weikum</author>
</authors>
<title>The bag-of-opinions method for review rating prediction from sparse text patterns.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>913--921</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="4031" citStr="Qu et al. 2010" startWordPosition="620" endWordPosition="623">the source language and the target language to collaboratively determine the confidently predicted ones out of the unlabeled reviews, and then use the selected examples to enlarge the training set. Evaluation results on several datasets show that our proposed coregression algorithm can consistently improve the prediction results. 2 Related Work Most previous works on review rating prediction model this problem as a multi-class classification task or a regression task. Various features have been exploited from the review text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews f</context>
</contexts>
<marker>Qu, Ifrim, Weikum, 2010</marker>
<rawString>Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum. 2010. The bag-of-opinions method for review rating prediction from sparse text patterns. In COLING, pages 913–921, Stroudsburg, PA, USA, 2010. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
<author>Elena Lloret</author>
<author>Manuel Palomar</author>
</authors>
<title>Can text summaries help predict ratings? a case study of movie reviews. Natural Language Processing and Information Systems</title>
<date>2012</date>
<pages>271--276</pages>
<contexts>
<context position="4559" citStr="Saggion et al. (2012)" startWordPosition="700" endWordPosition="703">view text, including words, patterns, syntactic structure, and semantic topic (Qu et al. 2010; Pang and Lee, 2005; Leung et al. 2006; Ganu et al. 2009). Traditional learn526 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of</context>
</contexts>
<marker>Saggion, Lloret, Palomar, 2012</marker>
<rawString>Horacio Saggion, Elena Lloret, and Manuel Palomar. 2012. Can text summaries help predict ratings? a case study of movie reviews. Natural Language Processing and Information Systems (2012): 271-276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
<author>Mingjun Tian</author>
</authors>
<title>Cross language text classification by model translation and semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1057--1067</pages>
<contexts>
<context position="5440" citStr="Shi et al., 2010" startWordPosition="851" endWordPosition="854">, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test review set in a different target language (e.g. German); Then the task of cross-langu</context>
</contexts>
<marker>Shi, Mihalcea, Tian, 2010</marker>
<rawString>Lei Shi, Rada Mihalcea, and Mingjun Tian. 2010. Cross language text classification by model translation and semi-supervised learning. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pp. 1057-1067, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Multiple aspect ranking using the good grief algorithm.</title>
<date>2007</date>
<booktitle>Proceedings of the Joint Human Language Technology/North American Chapter of the ACL Conference (HLT-NAACL).</booktitle>
<contexts>
<context position="4830" citStr="Snyder and Barzilay, 2007" startWordPosition="744" endWordPosition="747">s 526–531, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et</context>
</contexts>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. Proceedings of the Joint Human Language Technology/North American Chapter of the ACL Conference (HLT-NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08:HLT,</booktitle>
<pages>308--316</pages>
<contexts>
<context position="4908" citStr="Titov and McDonald, 2008" startWordPosition="760" endWordPosition="763">nal Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification t</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. A joint model of text and aspect ratings for sentiment summarization. In Proceedings of ACL-08:HLT, pages 308-316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pp. 417-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer.</publisher>
<contexts>
<context position="6948" citStr="Vapnik 1995" startWordPosition="1103" endWordPosition="1104">labeled training dataset and the test dataset. Fortunately, due to the development of machine translation techniques, a few online machine translation services can be used for review translation. We adopt Google Translate1 for review translation. After review translation, the training reviews and the test reviews are now in the same 1 http://translate.google.com language, and any regression algorithm (e.g. logistic regression, least squares regression, KNN regressor) can be applied for learning and prediction. In this study, without loss of generality, we adopt the widely used regression SVM (Vapnik 1995; Joachims 1999) implemented in the SVMLight toolkit2 as the basic regressor. For comparative analysis, we simply use the default parameter values in SVMLight with linear kernel. The features include all unigrams and bigrams in the review texts, and the value of each feature is simply set to its frequency (TF) in a review. Using features in different languages, we have the following baseline approaches for addressing the cross-language regression problem. REG_S: It conducts regression learning and prediction in the source language. REG_T: It conducts regression learning and prediction in the t</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik, 1995. The Nature of Statistical Learning Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
</authors>
<title>Co-training for cross-lingual sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>235--243</pages>
<contexts>
<context position="5387" citStr="Wan 2009" startWordPosition="841" endWordPosition="842">tigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein 2010). However, the binary classification task is very different from the regression task studied in this paper, and the proposed methods in the above previous works cannot be directly applied. 3 Problem Definition and Baseline Approaches Let L={(x1, y1), ..., (xi, yi), ..., (xn, yn)} denote the labeled training set of reviews in a source language (e.g. English), where xi is the i-th review and yi is its real-valued label, and n is the number of labeled examples; Let T denote the test review set in a different target</context>
<context position="8588" citStr="Wan 2009" startWordPosition="1363" endWordPosition="1364">proach 4.1 Overview Our basic idea is to make use of some amounts of unlabeled reviews in the target language to improve the regression performance. Considering that the reviews have two views in two languages and inspired by the co-training style algorithms (Blum and Mitchell, 1998; Zhou and Li, 2005), we propose a new co-training style algorithm called co-regression to leverage the unlabeled data in a collaborative way. The proposed co-regression algorithm can make full use of both the features in the source language and the features in the target language in a unified framework similar to (Wan 2009). Each review has two versions in the two languages. The source-language features and the target-language features for each review are considered two redundant views of the review. In the training phase, the co-regression algorithm is applied to learn two regressors in the two languages. In the prediction phase, the two regressors are applied to predict two rating scores of the review. The 2 http://svmlight.joachims.org 527 final rating score of the review is the average of the two rating scores. 4.2 Our Proposed Co-Regression Algorithm In co-training for classification, some confidently class</context>
</contexts>
<marker>Wan, 2009</marker>
<rawString>Xiaojun Wan. 2009. Co-training for cross-lingual sentiment classification. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pp. 235-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach.</title>
<date>2010</date>
<booktitle>Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;10),</booktitle>
<pages>115--124</pages>
<contexts>
<context position="4865" citStr="Wang et al. 2010" startWordPosition="752" endWordPosition="755"> c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prettenhofer and Stein </context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Hongning Wang, Yue Lu, ChengXiang Zhai. 2010. Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach. Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;10), pages 115-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingbo Zhu</author>
<author>Huizhen Wang</author>
<author>Benjamin K Tsou</author>
<author>Muhua Zhu</author>
</authors>
<title>Multi-aspect opinion polling from textual reviews.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>1799--1802</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4847" citStr="Zhu et al. 2009" startWordPosition="748" endWordPosition="751"> August 4-9 2013. c�2013 Association for Computational Linguistics ing models, such as SVM, are adopted for rating prediction. Most recently, Li et al. (2011) propose a novel tensor-based learning framework to incorporate reviewer and product information into the text based learner for rating prediction. Saggion et al. (2012) study the use of automatic text summaries instead of the full reviews for movie review rating prediction. In addition to predicting the overall rating of a full review, multi-aspect rating prediction has also been investigated (Lu et al. 2011b; Snyder and Barzilay, 2007; Zhu et al. 2009; Wang et al. 2010; Lu et al. 2009; Titov and McDonald, 2008). All the above previous works are working under a monolingual setting, and to the best of our knowledge, there exists no previous work on cross-language review rating prediction. It is noteworthy that a few studies have been conducted for the task of cross-lingual sentiment classification or text classification, which aims to make use of labeled data in a language for the binary classification task in a different language (Mihalcea et al., 2007; Banea et al., 2008; Wan 2009; Lu et al. 2011a; Meng et al. 2012; Shi et al., 2010; Prett</context>
</contexts>
<marker>Zhu, Wang, Tsou, Zhu, 2009</marker>
<rawString>Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and Muhua Zhu. 2009. Multi-aspect opinion polling from textual reviews. In Proceedings of the 18th ACM conference on Information and knowledge management, pp. 1799-1802. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi-Hua Zhou</author>
<author>Ming Li</author>
</authors>
<title>Semi-supervised regression with co-training.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th international joint conference on Artificial intelligence,</booktitle>
<pages>908--913</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<contexts>
<context position="8282" citStr="Zhou and Li, 2005" startWordPosition="1310" endWordPosition="1313">STC: It combines REG_S and REG_T by averaging their prediction values. However, the above regression methods do not perform very well due to the unsatisfactory machine translation quality and the various language expressions. Therefore, we need to find new approaches to improve the above methods. 4 Our Proposed Approach 4.1 Overview Our basic idea is to make use of some amounts of unlabeled reviews in the target language to improve the regression performance. Considering that the reviews have two views in two languages and inspired by the co-training style algorithms (Blum and Mitchell, 1998; Zhou and Li, 2005), we propose a new co-training style algorithm called co-regression to leverage the unlabeled data in a collaborative way. The proposed co-regression algorithm can make full use of both the features in the source language and the features in the target language in a unified framework similar to (Wan 2009). Each review has two versions in the two languages. The source-language features and the target-language features for each review are considered two redundant views of the review. In the training phase, the co-regression algorithm is applied to learn two regressors in the two languages. In th</context>
<context position="9887" citStr="Zhou and Li, 2005" startWordPosition="1565" endWordPosition="1568">versa. Each of the two classifiers can improve by learning from the newly labeled examples provided by the other classifier. The intuition is the same for co-regression. However, in the classification scenario, the confidence value of each prediction can be easily obtained through consulting the classifier. For example, the SVM classifier provides a confidence value or probability for each prediction. However, in the regression scenario, the confidence value of each prediction is not provided by the regressor. So the key question is how to get the confidence value of each labeled example. In (Zhou and Li, 2005), the assumption is that the most confidently labeled example of a regressor should be with such a property, i.e. the error of the regressor on the labeled example set (i.e. the training set) should decrease the most if the most confidently labeled example is utilized. In other words, the confidence value of each labeled example is measured by the decrease of the error (e.g. mean square error) on the labeled set of the regressor utilizing the information provided by the example. Thus, each example in the unlabeled set is required to be checked by training a new regression model utilizing the e</context>
<context position="12646" citStr="Zhou and Li, 2005" startWordPosition="2033" endWordPosition="2036"> used as the basic regressor to construct Rsource and Rtarget, and in this study, we adopt the same regression SVM implemented in the SVMLight toolkit with default parameter values. Similarly, the features include both unigrams and bigrams and the feature weight is simply set to term frequency. There are two parameters in the algorithm: I is the iteration number and m is the growth size in each iteration. I and m can be empirically set according to the total size of the unlabeled set U, and we have I×m≤ |U|. Our proposed co-regression algorithm is much more efficient than the COREG algorithm (Zhou and Li, 2005). If we consider the timeconsuming regression learning process as one Given: - Fsource and Ftarget are redundantly sufficient sets of features, where Fsource represents the source language features, Ftarget represents the target language features; - L is a set of labeled training reviews; - U is a set of unlabeled reviews; Loop for I iterations: 1. Learn the first regressor Rsource from L based on Fsource; 2. Use Rsource to label reviews from U based on Fsource; Let source yˆ i denote the prediction score of review xi; 3. Learn the second classifier Rtarget from L based on Ftarget; 4. Use Rtar</context>
<context position="16541" citStr="Zhou and Li, 2005" startWordPosition="2675" endWordPosition="2678">the cross-language scenario, we regarded English as the source language, and regarded German as the target language. The experiments were conducted on each product category separately. Without loss of generality, we sampled and used 3 http://www.uni-weimar.de/medien/webis/research/corpora/ corpus-webis-cls-10.html only 8000 unlabeled documents for each product category. We use Mean Square Error (MSE) as the evaluation metric, which penalizes more severe errors more heavily. In the experiments, our proposed co-regression algorithm (i.e. “co-regression”) is compared with the COREG algorithm in (Zhou and Li, 2005) and a few other baselines. For our proposed coregression algorithm, the growth size m is simply set to 50. We implemented the COREG algorithm by replacing the KNN regressor with the regression SVM and the pool size is also set to 50. The iteration number I varies from 1 to 150. The comparison results are shown in Figure 2. We can see that on all product categories, the MSE values of our co-regression algorithm and the two component regressors tend to decline over a wide range of I, which means that the selected confidently labeled examples at each iteration are indeed helpful to improve the r</context>
</contexts>
<marker>Zhou, Li, 2005</marker>
<rawString>Zhi-Hua Zhou and Ming Li. 2005. Semi-supervised regression with co-training. In Proceedings of the 19th international joint conference on Artificial intelligence, pp. 908-913. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>