<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9320875">
Statistical Machine Translation Using Coercive Two-Level Syntactic
Transduction
</title>
<author confidence="0.949541">
Charles Schafer and David Yarowsky
</author>
<affiliation confidence="0.8935115">
Center for Language and Speech Processing / Department of Computer Science
Johns Hopkins University
</affiliation>
<address confidence="0.89669">
Baltimore, MD 21218 USA
</address>
<email confidence="0.998674">
Icschafer,yarowskyl@cs.jhu.edu
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965875">
We define, implement and evaluate a novel model for
statistical machine translation, which is based on shal-
low syntactic analysis (part-of-speech tagging and phrase
chunking) in both the source and target languages. It
is able to model long-distance constituent motion and
other syntactic phenomena without requiring a full parse
in either language. We also examine aspects of lexical
transfer, suggesting and exploring a concept of transla-
tion coercion across parts of speech, as well as a transfer
model based on lemma-to-lemma translation probabili-
ties, which holds promise for improving machine trans-
lation of low-density languages. Experiments are per-
formed in both Arabic-to-English and French-to-English
translation demonstrating the efficacy of the proposed
techniques. Performance is automatically evaluated via
the Bleu score metric.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976416666667">
In this work we define, implement and evaluate a novel
model for statistical machine translation (SMT).
Our goal was to produce a SMT system for translat-
ing foreign languages into English which utilizes some
syntactic information in both the foreign language and
English without, however, requiring a full parse in either
language. Some advantages of not relying on full parses
include that (1) there is a lack of availability of parsers
for many languages of interest; (2) parsing time com-
plexity represents a potential bottleneck for both model
training and testing.
Intuitively, the explicit modeling of syntactic phenom-
ena should be of benefit in the machine translation task;
the ability to handle long-distance motion in an intelli-
gently constrained way is a salient example of such a
benefit. Allowing unconstrained translation reorderings
at the word level generates a very large set of permu-
tations that pose a difficult search problem at decoding
time. We propose a model that makes use of shallow
parses (text chunking) to support long-distance motion
of phrases without requiring deeper analysis of syntax.
The resources required to train this system on a new lan-
guage are minimal, and we gain the ability to model
long-distance movement and some interesting proper-
ties of lexical translation across parts of speech. One of
the source languages we examine in this paper, Arabic,
has a canonical sentence-level order of Verb-Subject-
Object, which means that translation into English (with
a standard ordering of Subject-Verb-Object) commonly
requires motion of entire phrasal constituents, which is
not true of French-to-English translation, to cite one lan-
guage pair whose characteristics have wielded great in-
fluence in the history of work on statistical machine
translation. A key motivation for and objective of this
work was to build a translation model and feature space
to handle the above-described phenomenon effectively.
</bodyText>
<sectionHeader confidence="0.998554" genericHeader="introduction">
2 Prior Work
</sectionHeader>
<bodyText confidence="0.999958677966102">
Statistical machine translation, as pioneered by IBM
(e.g. Brown et al., 1993), is grounded in the noisy chan-
nel model. And similar to the related channel problems
of speech and handwriting recognition, the original SMT
language pair French-English exhibits a relatively close
linear correlation in source and target sequence. Much
common local motion that is observed for French, such
as adjective-noun swapping, is adequately modeled by
the relative-position-based distortion models of the clas-
sic IBM approach. Unfortunately, these distortion mod-
els are less effective for languages such as Japanese or
Arabic, which have substantially different top-level sen-
tential word orders from English, and hence longer dis-
tance constituent motion.
Wu (1997) and Jones and Havrilla (1998) have sought
to more closely tie the allowed motion of constituents
between languages to those syntactic transductions sup-
ported by the independent rotation of parse tree con-
stituents. Yamada and Knight (2000, 2001) and Alshawi
et al. (2000) have effectively extended such syntactic
transduction models to fully functional SMT systems,
based on channel model tree transducers and finite state
head transducers respectively. While these models are
well suited for the effective handling of highly divergent
sentential word orders, the above frameworks have a lim-
itation shared with probabilistic context free grammars
that the preferred ordering of subtrees is insufficiently
constrained by their embedding context, which is espe-
cially problematic for very deep syntactic parses.
In contrast, Och et al. (1999) have avoided the con-
straints of tree-based syntactic models and allow the rel-
atively flat motion of empirically derived phrasal chunks,
which need not adhere to traditional constituent bound-
aries.
Our current paper takes a middle path, by grounding
motion in syntactic transduction, but in a much flatter 2-
level model of syntactic analysis, based on flat embed-
ded noun-phrases in a flat sentential constituent-based
chunk sequence that can be driven by syntactic brack-
eters and POS tag models rather than a full parser, facili-
tating its transfer to lower density languages. The flatter
2-level structures also better support transductions condi-
tioned to full sentential context than do deeply embedded
tree models, while retaining the empirically observed ad-
vantages of translation ordering independence of noun-
phrases.
Another improvement over Och et al. and Yamada and
Knight is the use of the finite state machine (FSM) mod-
elling framework (e.g. Bangalore and Riccardi, 2000),
which offers the considerable advantage of a flexible
framework for decoding, as well as a representation
which is suitable for the fixed two-level phrasal mod-
elling employed here.
Finally, the original cross-part-of-speech lexical coer-
cion models presented in Section 4.3.3 have related work
in the primarily-syntactic coercion models utilized by
Dorr and Habash (2002) and Habash and Door (2003),
although their induction and modelling are quite differ-
ent from the approach here.
</bodyText>
<sectionHeader confidence="0.999813" genericHeader="method">
3 Resources
</sectionHeader>
<bodyText confidence="0.999925146341463">
As in other SMT approaches, the primary training re-
source is a sentence-aligned parallel bilingual corpus.
We further require that each side of the corpus be part-
of-speech (POS) tagged and phrase chunked; our lab
has previously developed techniques for rapid training
of such tools (Cucerzan and Yarowsky, 2002). Our trans-
lation experiments were carried out on two languages:
Arabic and French. The Arabic training corpus was a
subset of the United Nations (UN) parallel corpus which
is being made available by the Linguistic Data Consor-
tium. For French-English training, we used a portion of
the Canadian Hansards. Both corpora utilized sentence-
level alignments publicly distributed by the Linguistic
Data Consortium.
POS tagging and phrase chunking in English were
done using the trained systems provided with the fnTBL
Toolkit (Ngai and Florian, 2001); both were trained
from the annotated Penn Treebank corpus (Marcus et al.,
1993). French POS tagging was done using the trained
French lexical tagger also provided with the fnTBL soft-
ware. For Arabic, we used a colleague’s POS tagger and
tokenizer (clitic separation was also performed prior to
POS tagging), which was rapidly developed in our lab-
oratory. Simple regular-expression-based phrase chun-
kers were developed by the authors for both Arabic and
French, requiring less than a person-day each using ex-
isting multilingual learning tools.
A further input to our system is a set of word alignment
links on the parallel corpus. These are used to compute
word translation probabilities and phrasal alignments.
The word alignments can in principle come from any
source: a dictionary, a specialized alignment program,
or another SMT system. We used alignments generated
by Giza++ (Och and Ney, 2000) by running it in both di-
rections (e.g., Arabic —&gt; English and English —&gt; Arabic)
on our parallel corpora. The union of these bidirectional
alignments was used to compute cross-language phrase
correspondences by simple majority voting, and for pur-
poses of estimating word translation probabilities, each
link in this union was treated as an independent instance
of word translation.
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="method">
4 Translation Model
</sectionHeader>
<bodyText confidence="0.999963">
Now we turn to a detailed description of the proposed
translation model. The exposition will give a formal
specification and also will follow a running example
throughout, using one of the actual Arabic test set sen-
tences. This example, its gloss, system translation and
reference human translation are shown in Table 1.
The translation model (TM) we describe is trained di-
rectly from counts in the data, and is a direct model, not
a noisy channel model. It consists of three nested com-
ponents: (1) a sentence-level model of phrase correspon-
dence and reordering, (2) a model of intra-phrase trans-
lation, and (3) models of lexical transfer, or word transla-
tion. We make a key assumption in our construction that
translation at each of these three levels is independent of
the others.
</bodyText>
<subsectionHeader confidence="0.992568">
4.1 Sentence Translation
</subsectionHeader>
<bodyText confidence="0.99947680952381">
As mentioned, both the foreign language and English
corpora are input with “hard” phrase bracketings and la-
beled with “hard” phrase types (e.g., NP, VP1, PPNP2,
etc.) as given by the output of the phrase chunker. These
are denoted in the top-level model presentation in Table
2(1). Given word alignment links, as described in Sec-
tion 2, we compute phrasal alignments on training data.
We contrain these to have cardinality
(foreign)N —&gt; 1(English). Next, we collect counts over
aligned phrase sequences and use the relative frequen-
cies to estimate the probability distribution in Table 2(2).
Particularly for smaller training corpora, unseen foreign-
language phrase sequences are a problem, so we imple-
mented a simple backoff method which assigns proba-
bility to translations of unseen foreign-language phrase
sequences. Table 2(3) encapsulates the remainder of the
translation model, which is described below.
As an example, Table 3 shows the most probable
aligned English phrase sequence generations given an
Arabic simple sentence having the canonical VSO or-
dering. Also, note that all probabilities in the following
</bodyText>
<footnote confidence="0.999287666666667">
1VP in our parlance is perhaps more properly called a verb chunk:
it consists of a verb, its auxiliaries, and contiguous adverbs.
2PPNP consists of a NP with its prepositional head attached.
</footnote>
<note confidence="0.9878865">
Arabic Example Sentence From Test Set
(ARABIC) twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp b- AEtmAd m$rwE Al- mqrr Al- tAly :
(PHR.-BRACKETED AR.) [twSy] [Al- ljnp Al- sAdsp] [Al- jmEyp Al- EAmp] [b- AEtmAd m$rwE Al- mqrr Al- tAly] [:]
(AN ENG. GLOSS) [recommends] [the committee the sixth] [the assembly the general] [to adoption draft the decision the following] [:]
(ENG. MT OUTPUT) [the sixth committee] [recommends] [the general assembly] [in the adoption of the following draft resolution] [:]
(REFERENCE TRANS.) the sixth committee recommends to the general assembly the adoption of the following draft decision:
</note>
<tableCaption confidence="0.9803556">
Table 1: An Arabic translation from the test set. We revisit portions of this example throughout the text. All Arabic
strings in this paper are rendered in the reversible Buckwalter transliteration. In addition, all words or symbols referring
to Arabic and French in this paper are italicized.
figures and tables are from the actual Arabic and French
trained systems.
</tableCaption>
<table confidence="0.9989308">
Arabic Phrase Aligned English Prob.
Sequence Phrase Sequence
VP1 NP2 NP3 NP2 VP1 NP3 0.23
VP1 NP2 NP3 VP1 NP2 PP3 0.10
VP1 NP2 NP3 NP3 VP1,2 0.06
</table>
<tableCaption confidence="0.998708">
Table 3: Top learned sentence-level reorderings for Ara-
</tableCaption>
<bodyText confidence="0.85561025">
bic, for canonical Arabic simple sentence structure VP
(verb) NP (subject) NP (object). Subscripts in English
phrase sequence are alignments to positions in the corre-
sponding Arabic phrase sequence.
</bodyText>
<subsectionHeader confidence="0.98323">
4.2 Phrase Translation
</subsectionHeader>
<bodyText confidence="0.999723326530613">
Given an Arabic test sentence, a distribution of aligned
English phrase sequences is proposed by the sentence-
level model described in the previous section and in Ta-
ble 2. Each proposed English phrase in each of the phrase
sequence possibilities, therefore, comes to the middle
level of the translation model with access to the identity
of the French phrases aligned to it. Phrase translation is
implemented as shown in Table 4. The phrase transla-
tion model is structured with several levels of backoff: if
no observations exist from training data for a particular
level, the model backs off to the next-more-general level.
In all cases, generation of an English phrase is condi-
tioned on the foreign phrase as well as the type
(NP, VP, etc.) of the English phrase.
Table 4 (1) describes the initial phrase translation
model. It comes into play if the precise sequence of
foreign words has been observed aligning to an En-
glish phrase of the appropriate type. In the example,
we are trying to generate an NP given the Arabic word
string “Al- ljnp Al- sAdsp” (literally: “the committee the
sixth”). If this has been observed in data, then that rela-
tive frequency distribution serves as the translation prob-
ability distribution. Table 11 contains examples of some
of these literal phrase translations from the French data.
The next stage of backoff from the above, literal level
is a model that generates aligned English POS tag se-
quences given foreign POS tag sequences: details and
an example can be found in Table 4(2). The sequence
alignments determine the position in English phrase and
the part-of-speech into which we translate the foreign
word. Again, translation is also conditioned on the En-
glish phrase type. Table 5 and Table 6 show the most
probable aligned English sequence generations for two
of the phrases in the example sentence.
If there were no counts for (foreign-POS-sequence,
english-phrase-type) then we back off to counts
collected over (foreign-coarse-POS-sequence, english-
phrase-type), where a coarse POS is, for example, N in-
stead of NOUN-SG. This is shown in Table 4(3).
In case further backoff is needed, as shown in Table
4(4), we begin stripping POS-tags off the “less signifi-
cant” (non-head) end of the foreign POS-sequence until
we are left with a phrase sequence that has been seen in
training, and from this a corresponding English phrase
distribution is observable. We define the “less signifi-
cant” end of a phrase to be the end if it is head-initial,
or the beginning if it is head-final, and at this point ig-
nore issues such as nested structure in French and Arabic
NP’s.
</bodyText>
<subsectionHeader confidence="0.492867">
Aligned English POS-tag Sequence Translation Probabilities
</subsectionHeader>
<bodyText confidence="0.68209">
(conditioned on Arabic POS-tag sequence from NP in example)
</bodyText>
<equation confidence="0.999556416666667">
P( DT0 JJ4 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.22
P( JJ4 NN1 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.20
P( DT0 NN1 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13
P( DT0 VBN4 NNS2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13
P( DT1 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.04
P( DT3 JJ4 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03
P( DT1 VBN4 NNS2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03
P( DT0 NN4 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P( JJ4 NNS2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P( DT1 JJ4 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P( NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
P( NN4 NN2 DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02
</equation>
<bodyText confidence="0.9830375">
Table 5: From the running Arabic example, top English
NP generations given an Arabic phrase DET NOUN-SG
DET ADJ. Note: 0 denotes a null alignment (generation
from null). Generation from a null alignment is allowed
for specified parts of speech, such as determiners and
prepositions.
</bodyText>
<subsectionHeader confidence="0.995953">
4.3 Lexical Transfer
4.3.1 The Basic Model
</subsectionHeader>
<bodyText confidence="0.9680656">
In the basic model of word generation, phrases may be
translated directly as single atomic entities (as in Table
4(1)), or via phrasal decomposition to individual words
translated independently, conditioned only on the source
word and target POS. Word translation in the latter case
</bodyText>
<table confidence="0.932935076923077">
Top-level Definition of Translation Model
Example Instantiation of Model Variables Model Description
P( the sixth committee recommends the general assembly..  |P( english words  |foreign words) =
twSy Al- ljnp Al- sAdsp Al-jmEyp Al- EAmp .. ) = P( foreign bracketing , foreign phrase sequence  |foreign words )
P( [twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 ..  |P( english phrase sequence, phrase alignment matrix |
twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. ) foreign phrase sequence )
P( NP2 VP1 NP3 PPNP4 PUNC5  |P( english words, english bracketing , english phrase sequence |
VP1 NP2 NP3 PPNP4 PUNC5 ) foreign words , foreign bracketing , foreign phrase sequence ,
P( [the sixth committee]NP2 [recommends]V P1 english phrase sequence , phrase alignment matrix )
[the general assembly]NP3 .. |
[twSy]V P1 [Al- ljnp Al- sAdsp]NP1 [Al- jmEyp Al- EAmp]NP2 .. ,
end of a foreign sequence. The idea is to do this until we reach a subsequence that has
been seen in training data, and which we therefore have a distribution of valid generatons for. The term
</table>
<equation confidence="0.947735444444444">
in (2) - (4)
is a position alignment matrix. At all times, we generate not just an English POS-tag sequence, but rather an aligned
sequence. Similarly, in the lexical transfer probabilities shown in this table, there is a function
which takes an
English sequence position index and returns the (unique) foreign word position to which it is
“lesssignificant”
Wiz
Wiz()
aligned4.
P(
, VP ) = .28
|XML |xmlLoc_6 xmlBold_no xmlItalic_no xmlFontSize_smaller xmlPic_no xmlTable_no xmlBullet_no bi_xmlSFBIA_continue bi_xmlPara_continue
VBZ1VERB-IMP1
|XML |xmlLoc_6 xmlBold_no xmlItalic_no xmlFontSize_smaller xmlPic_no xmlTable_no xmlBullet_no bi_xmlSFBIA_new bi_xmlPara_continue
P( VBP1 � VERB-IMP1 , VP ) = .17
P( VBD1 � VERB-IMP1 , VP ) = .09
...
P( MD VB1 � VERB-IMP1 , VP ) = .06
</equation>
<bodyText confidence="0.9993935">
Arabic phrase VERB-IMP. know the English POS of the word we are trying to gen-
erate in addition to the foreign word that is generating it.
Consequently, we condition translation on English POS
as well as the foreign word. Table 7 describes the backoff
path for basic lexical transfer and presents a motivating
example in the French word droit. Translation probabili-
ties for one of the words in the example Arabic sentence
be found in Table 8.
</bodyText>
<equation confidence="0.9777646">
VP1
PUNC5
NP2
NP3 PPNP4
)
</equation>
<bodyText confidence="0.475282">
is done in the context that the model has already pro-
posed asequence of POS tags for the phrase. Thus we
</bodyText>
<tableCaption confidence="0.983006">
Table 2: Statement of the translation model at top level.
</tableCaption>
<table confidence="0.553883666666667">
Phrase
Model with Backoff Pathways
Example Instantiations Model Statement
</table>
<equation confidence="0.976161150684932">
P
the sixth committee
Al-
, NP )
P(the sixth committee
(1)
WE2 ..
WF2 ..
)
C(
WF2 ..
typeE) =
NN2
DET1 NOUN-SG2 DET3
)
Al-,DT)
NN )
)
)
= 0)
NN2
N2 D3 A4 , NP ) (3)
TcoarseF2
)
(the
)
)
)
=
N2 D3 , NP ) (4)
= 0)
N2
(4)
..
Translation
(
|
ljnpAl- sAdsp
=
|Al- ljnpAl-sAdsp , NP
P ( WE1
WEn|WF1
WFm, phrtypeE
 (backoff if
WF1
WFm,phr
0)P( DT1JJ4
|
ADJ4 , NP )(2)P ( TfineE1TfineE2.. TfineEn, i |TfineF1TfineF2.. TfineFm, phrtypeE
P( the
P( WE1|WFi(1), TfineE1 )P( committee|ljnp
P( WE2|WFi(2), TfineE2
P( sixth|sAdsp , JJ )..  P( WEn|WFi(n) , TfineEn
(backoff ifC( TfineF1TfineF2.. TfineFm, phrtypeE)
P( DT1JJ4
|D1
P ( TfineE1TfineE2..TfineEn,i|TcoarseF1
..TcoarseFm, phrtypeE
P
|Al- , DT )P( WE1|WFi(1) , TfineE1
P ( committee|ljnp , NN )P( WE2|WFi(2) , TfineE2
P( sixth|sAdsp , JJ )..  P( WEn|WFi(n),TfineEn
(backoff ifC( TcoarseF1TcoarseF2 .. TcoarseFm, phrtypeE
0)P( ?  |D1
P ( TfineE1TfineE2.. TfineEn,i |TcoarseF1TcoarseF2 .. TcoarseFm−1, phrtypeE )* ? * .. * ? * ? * .. * ?
(backoff ifC( TcoarseF1TcoarseF2 .. TcoarseFm−1, phrtypeE)
P( ?  |D1
, NP
P ( TfineE1TfineE2
TfineEn, i |TcoarseF1 TcoarseF2 .. TcoarseFm−2 , phr typeE)
* ? * .. * ? * ? * .. * ?
  (backoff if C( TcoarseF1 TcoarseF2 .. TcoarseFm−2 , phr typeE) = 0)
.... ....
</equation>
<tableCaption confidence="0.9045166">
Table 4: The phrase translation model, with backoff. Examples on the left side are from one of the Arabic test
sentences. (1) is the direct, lexical translation level. (2) - (4) constitute the backoff path to handle detailed phenomena
unseen in the training set. (2) is a model of fine POS-tag reordering and lexical generation; (3) is similar, but conditions
generation on coarse POS-tag sequences in the foreign language. (4) is a model for progressively stripping off POS-
tags from the
</tableCaption>
<table confidence="0.632955666666667">
Aligned English POS-tag Sequence Translation Probabilities
(conditioned on Arabic POS-tag sequence fro
m VP in example)
</table>
<tableCaption confidence="0.786235333333333">
Table 6: From the Arabic example, top English VP gen-
erations given an
can
</tableCaption>
<subsubsectionHeader confidence="0.320726">
4.3.2 Generation via a Lemma Model
</subsubsectionHeader>
<bodyText confidence="0.980619666666667">
To counter sparse data problems in estimating word
tran
slation probabilities, we also implemented a lemma-
</bodyText>
<subsectionHeader confidence="0.942609">
Word Generation
Examples Model with Backoff Pathways
</subsectionHeader>
<equation confidence="0.932944809523809">
P(WE |droit, NNS) P(WE|WF , TfineE )
rights 0.4389 p(rights  |droit, NNS)
benefits 0.0690
people 0.0533
laws 0.0188
1 (backoffif C(WF , TfineE ) = 0)
P(WE |droit, N) P(WE|WF , TcoarseE )
right 0.4970
law 0.1318
rights 0.0424 p(rights  |droit , N)
property 0.0115
1 (backoffif C(WF , TcoarseE) = 0)
P(WE |droit) P(WE|WF )
right 0.2919
entitled 0.0663
law 0.0652
the 0.0249
to 0.0240
rights 0.0210 p( rights  |droit )
1 (backoff if C(WF ) = 0)
p( UNKNOWN WORD |WF ) = 1
</equation>
<bodyText confidence="0.88779925">
Table 7: Description of the conditioning for different lev-
els of backoff in the lexical transfer model. The exam-
ple shows translations for the French word droit (“right”)
conditioned on decreasingly specific values. The pro-
gressively lower ranking of the correct translation as we
move from fine, to coarse, to no POS, illustrates the ben-
efit of conditioning generation on the English part of
speech.
</bodyText>
<table confidence="0.99780055">
Arabic Word English POS English Wd. Prob.
ljnp NN committee 0.591
ljnp NN commission 0.233
ljnp NN subcommittee 0.035
ljnp NN acc 0.013
ljnp NN report 0.005
ljnp NN ece 0.004
ljnp NN icrc 0.004
ljnp NN aalcc 0.004
ljnp NN escap 0.004
ljnp NN escwa 0.004
ljnp NN eca 0.003
ljnp NNS members 0.088
ljnp NNS recommendations 0.033
ljnp NNS copuos 0.033
ljnp NNS questions 0.027
ljnp NNS representatives 0.024
ljnp N committee 0.577
ljnp N commission 0.227
ljnp N subcommittee 0.035
</table>
<tableCaption confidence="0.963902">
Table 8: From running example, translation probabilities for Arabic
noun ljnp, “committee”.
</tableCaption>
<bodyText confidence="0.9997134">
based model for word translation. Under this model,
translation distributions are estimated by counting word
alignment links between foreign and English lemmas, as-
suming a lemmatization of both sides of the parallel cor-
pus as input. The form of the model is illustrated below:
</bodyText>
<equation confidence="0.999672875">
P( WE  |WF,TcoarseF ,TfineE) =
P( WE  |lemmaE , TcoarseF , TfineE )*
P( lemmaE  |lemmaF , TcoarseF , TfineE )*
P( lemmaF  |WF , TcoarseF , TfineE )
4 approximated by
P(WE  |lemmaE , TfineE)*
P( lemmaE  |lemmaF , TcoarseE )*
P( lemmaF  |WF , TcoarseF )
</equation>
<bodyText confidence="0.999806058823529">
First, note that P( lemmaF I WF , TcoarseF ) is very
simply a hard lemma assignment by the foreign lan-
guage lemmatizer. Second, English word generation
from English lemma and coarse POS (P( WE I lemmaE
, TfineE )) is programmatic, and can be handled by
means of rules in conjunction with a lookup table for
irregular forms. The only distribution here that must be
estimated from data is P( lemmaE I lemmaF , TcoarseE
). This is done as described above. Furthermore, given
an electronic translation dictionary, even this distribution
can be pre-loaded: indeed, we expect this to be an
advantage of the lemma model, and an example of
a good opportunity for integrating compiled human
knowledge about language into an SMT system. Some
examples of the lemma model combating sparse data
problems inherent in the basic word-to-word models can
be found in Table 9.
</bodyText>
<subsectionHeader confidence="0.821752">
4.3.3 Coercion
</subsectionHeader>
<bodyText confidence="0.999983684210527">
Lexical coercion is a phenomenon that sometimes occurs
when we condition translation of a foreign word on the
word and the English part-of-speech. We find that the
system we have described frequently learns this behav-
ior: specifically, the model learns in some cases how
to generate, for instance, a nominal form with similar
meaning from a French adjective, or an adjectival real-
ization of a French verb’s meaning; some examples of
this phenomenon are shown in Table 10. We find this
coercion effect to be of interest because it identifies in-
teresting associations of meaning. For example, in Table
10 “willing” and “ready” are both sensible ways to re-
alize the meaning of the action “to accept” in a passive,
descriptive mode. droit behaves similarly. Though the
English verb “to right’ or “to be righted” does not have
the philosophical/judicial entitlement sense of the noun
“right”, we see that the model has learned to realize the
meaning in an active, verbal form: e.g., VBG ‘receiving”
and VB “qualify”.
</bodyText>
<sectionHeader confidence="0.994827" genericHeader="method">
5 Decoding
</sectionHeader>
<bodyText confidence="0.999035482142858">
Decoding was implemented by constructing finite-state
machines (FSMs) per evaluation sentence to encode
relevant portions (for the individual sentence in ques-
tion) ofthe component translation distributions described
above. Operations on these FSMs are performed using
the AT&amp;T FSM Toolkit (Mohri et al., 1997). The FSM
constructed for a test sentence is subsequently composed
with a FSM trigram language model created via the SRI
Language Modeling Toolkit (Stolcke, 2002). Thus we
use the trigram language model to implement rescoring
of the (direct) translation probabilities for the English
word sequences in the translation model lattice.
We found that using the finite-state framework and the
general-purpose AT&amp;T toolkit greatly facilitates decoder
development by freeing the implementation from details
of machine composition and best-path searching, etc.
The structure of the translation model finite-state ma-
chines is as illustrated in Figure 1. The sentence-level
(aligned phrase sequence generation) and phrase-level
(aligned intra-phrase sequence generation) translation
probabilities are encoded on epsilon arcs in the ma-
chines. Word translation probabilities are placed onto
arcs emitting the word as an output symbol (in the fig-
ure, note the arcs emitting “committee”, “the”, etc.). The
FSM in Figure 1 corresponds to the Arabic example sen-
tence used throughout this paper. In the portion of the
machine shown, the (best) path which generated the ex-
ample sentence is drawn in bold. Finally, Figure 2 is
a rendering of the actual FSM (aggressively pruned for
display purposes) that generated the example Arabic sen-
tence; although labels and details are not visible, it may
provide a visual aid for better understanding the structure
of the FSM lattices generated here.
As a practical matter in decoding, during translation
model FSM construction we modified arc costs for out-
put words in the following way: a fixed bonus was as-
signed for generating a “content” word translating to a
“content” word. Determining what qualifies as a con-
tent word was done on the basis of a list of content POS
tags for each language. For example, all types of nouns,
verbs and adjectives were listed as content tags; deter-
miners, prepositions, and most other closed-class parts of
speech were not. This implements a reasonable penalty
on undesirable output sentence lengths. Without such a
penalty, translation outputs tend to be very short: long
sentence hypotheses are penalized de facto merely by
containing many word translation probabilities. An ad-
ditional trick in decoding is to use only the N-best trans-
lation options for sentence-level, phrase-level, and word-
level translation. We found empirically (and very consis-
tently) in dev-test experiments that restricting the syntac-
tic transductions to a 30-best list and word translations to
a 15-best list had no negative impact on Bleu score. The
benefit, of course, is that the translation lattices are dra-
matically reduced in size, speeding up composition and
search operations.
</bodyText>
<figure confidence="0.999294114035092">
W:another/4.082
W:with/1.853
W:for/3.134
699
678
W:o / .0 6
W__:of/.238
W:at
W__:in/.
W_:ta
W__:beoe/4.435
W:with/3.075
W_:for/2.60
W__:because/4.073
W_:o
W_:as/
W_:up/5.0
W__:wto
W_:since/5.054
W_:so/5.103
W__:tough/4.435
W_:to/3.971
W__:abou
W_:no/3.547
W:any/3.434
W_:so
W_:this/.26
W_:these/3.201
W_:evey/.
W_:evey/.241
W_:aother/4.082
722
W__:a/3.066
W__:next/1.854
T_IN#NGEN+DT#N#NGEN+IN#NGEN+DT#J#N#NN:&lt;epsilon&gt;/3.545
W_:the/0.132
W:this/2.266
W:thse/3.201
W:another/4.082
W_:flowing/0.27
Wt/4.61
W_:wth/1.853
r/3.134
W:as/2.616
W:on/2.046 654
641 W:of/.238
W:by/1.908
W_:ud
W:at/3.536
W__:in/1.425
W:hat/2.614
aftr/4.880
W__:beo
W:w t /3.075
W:adoption/0.71
W_:o/
W__:becau.073
W_:fo/3.270
W_:as/3.201
W__:through/4.435
W_:to/3.971
W__:about/3.426
W_:be.602
W__:ay/3.3
W_:so
T_to/NUL#the/NUL#gneral#asembly:&lt;epsilon&gt;/1.
W_:to/-0
527 W_:by/-0
572 W:wish/-0 W:of/-0
Tthe/NUL#gnerl#asembly:&lt;epsilon&gt;/0.530
Tthe#gnerl#asembly:&lt;epsilon&gt;/2.12
W_:decision/1.00
W__:raporteur/0.69
P__VP:&lt;epsilon&gt;/-0
Trecomends:&lt;epsilon&gt;/0.227
W:2/-0
T_IN#NGEN+DT#NN#NGEN+IN#DT#J#N#NN:&lt;epsilon&gt;/4.895
397
419
T2:&lt;epsilon&gt;/0.631
T_the/NULL#wish/NUL#of/NUL#the/NUL#general#a
G_:&lt;epsilon&gt;/-0
P_NP:&lt;epsilon&gt;/-0
W:xslax/-0
W:gneral/-0
448
W:with/1.853
:for/3.134
Trecommends:&lt;epsilon&gt;/0.2
T-/NULL:&lt;ep 418
37
T-:&lt;epsilon&gt;/0.1
W_:commite/-0 G:&lt;epsilon&gt;/-0 384 PO:&lt;epsilon&gt;/-0 403
298 W:in/-0 35
386 W:order/-0
G__:&lt;epsilon&gt;/-0 T_with/NUL#regard/NUL:&lt;epsilon&gt;/3.091
302
P_VP:&lt;epsilon&gt;/-0
Tin/NULL#docu
364
Tto/NUL#
304
T_by/NULL#2#police/NUL#officers/NUL 296
_into/NUL#the/NULL#world/NUL#ecnomy/NUL:&lt;epsilon&gt;/3.091 W:into/-0
297
T_in/NUL#only/NUL#2:&lt;epsilon&gt;/3.091
_o/NUL#just/NUL#2:&lt;epsilon&gt;/3.091 W:for/-0
6 30
538
e#ase b y: eps o /3.6
Tthe/NULL#asembly:&lt;epsilon&gt;/1.941
PO:&lt;epsilon&gt;/-0
W__:te/0
T__prsent/NULL:&lt;epsilon&gt;/0.693
W__:prsent/-0
:resolution/.339
.841
W_:draft/0.04
573
570
G__:&lt;epsilon&gt;/-0
40
G_:&lt;epsilon&gt;/-0
PPNP:&lt;epsilon&gt;/-0
W__:next/1.854
W:s t 0 /
_ecomend:&lt;epsilon&gt;/3.20 13
289
Trecomends:&lt;epsilon&gt;/0.2 31
Trecommended:&lt;epsilon&gt;/2.759
312
W:recommend/-0
W:recomen
W_:eco
G:&lt;epsilon&gt;/-0
PO:&lt;epsilon&gt;/-0
412 T-:&lt;epsilon&gt;/0.129
W:on/2.917
G:&lt;epsilon&gt;/-0
359 W:document/-0
395
G__:&lt;epsilon&gt;/-0
W:the/-0
TIN#NGEN+DT#N#NGEN+IN#J#NNS#NGEN+IN#N:&lt;epsilon&gt;/4.64
T_IN#NGEN+DT#N#NGEN+IN#DTJ#N#NGEN+I#NN:&lt;epsilon&gt;/5.049
IN#NGEN+DT#N#NGEN+IN#NGEN+DT#J#N#NGEN+IN#N:&lt;epsilon&gt;/.43
723
W:at/3.536
W:in/1.425
W:that/4.161
W:out/.410
W:within/4.76
W:p
W:to/-0
358 W:2.7/-0 382
W:2/-0
353 381 W:police/-0
360 W:the/-0
W:only/-0
354
W:in/-0
679
Tsixth#commite:&lt;epsilon&gt;/1.871
ed/-0
W:oficers/-0
W_:ecnomy/-0
W
640 W:on/2.046
W:by/1.908
W:in/1.4
730
396
P_VP:&lt;epsilon&gt;/-0
401
376
309
W_:on/2.917
W:of/1.969
W__:agast/
W_:by/2.975
W_:ude
W_:at/
W_:/.215
W:that/2.614
W_:ater/4.80
W_:before/4.435
W_:with/3.075
402
W_:2/-0
W:some/3.097
W:this/2.26
W:these/3.201
G:&lt;epsilon&gt;/-0
W_:xslax/-0
W_:adoption/0.71
W:2/-0
361
308
T2:&lt;epsilon&gt;/0.631
356 W_:just/-0
W_:rapporteur/0.69
286
P_NP:&lt;epsilon&gt;/-0
W_:2/-0
W:with/1.853
W: / . 5
W_:that/2.614
375 W:as/2.616
W_:of/.238
W_:by/1.908
425
W:under/3.942
W_:at/
W_:/
W_:wt
W:in/2.215
W:
W:in/2.215
W:that/2.614
W:for/2.60
W:of/1.69
G:&lt;epsilon&gt;/-0
350
307 P_PNP:&lt;epsilon&gt;/-0 W_:review/-0
Tfor/NULL#2:&lt;epso
W:for/-0
303
T_with/NUL#article/NUL#2:&lt;epsilon&gt;/2.397 W__:article/-0
294
240 W:with/-0 W_:xslax/-0
_to/N:epso
W:2/-0
W:to/-0
W:p ov s o / .9
W:appropriation/3.1
642
G__:&lt;epsilon&gt;/-0
714
G__:&lt;epsilon&gt;/-60
T_2#xslax/NUL:&lt;epsilon&gt;/.194
184
213
212
_to/NU
33 W:with/-0 371
65
W_:following/0.27
732
:2/-0
W:sixth/-0
155
W_:commite/-0
P_PNP:&lt;epsilon&gt;/-0
639
704
W__:sponors/.131
W__:draft/.404
P_NP:&lt;epsilon&gt;/-0
:pso/.
_te/Nitee:&lt;epsilon&gt;
W__:eco
W__:in/1.425
T_to/NULL#2/NUL:&lt;epsilo
TundeNepsilon&gt;/3.091
W_:the/0.132
190
o e ds/ 0
159
336
W__:2/-0
W:because/4.073
W:
W_:as
W__:toug/.3
54
W:following/0.227
W_:next/1.854
352
T_2:&lt;epsilon&gt;/0.631
W:recom
W_:recommend/-0
P_VP:&lt;epsilon&gt;/-0
T__2:&lt;epsilon&gt;/0.631
W:the/.18
W:adoption/0.71
731
G_:&lt;epsilon&gt;/-0
680
#asse b y: eps o /
neral#asembly:&lt;epsilon&gt;/2.12
l#asembly:&lt;epsilon&gt;/0.530
W:gneral/-0
W:asembly/-0
PNP:&lt;epsilon&gt;/-0
16
252
290
T_2#xslax/NUL:&lt;epsilon&gt;/1.194
G_:&lt;epsilon&gt;/-0
160
G:&lt;epsilon&gt;/-0
P_NP:&lt;epsilon&gt;/-0
W_:to/3.971 578 W:decision/1.00
W_:abou W:raporteu
:projects/2.972
W_:implications/2.139
W__:/3.704
W_:tan/4.147
W:sponsors/1.31 625
W_:over/4.385
W__:draft/0.404
W_:pe/3.9 624
W_:rapporteur/0.69
P_VP:&lt;epsilon&gt;/-0
PVP:&lt;epsilon&gt;/-0
G:&lt;epsilon&gt;/-0
P__NP:&lt;epsilon&gt;/-0
285
mends:&lt;epsilon&gt;/0.227
W_:following/0.227
138
G__:&lt;epsilon&gt;/-0
W:recommends/-0
207
674
W_:ta
705
P_O:&lt;epsilon&gt;/-0
17
259
G__:&lt;epsilon&gt;/-0
670
T__recommends:&lt;epsilon&gt;/0.27
W__:comitee/-0
256
T__IN#NGEN+DT#N#NGEN+IN#J#N#NNS:&lt;epsilon&gt;/4.13
5
582 W
W:this/.26
W:these/3.201
G_:&lt;epsilon&gt;/-60
G:&lt;epsilon&gt;/-60
G_:&lt;epsilon&gt;/-0
W_:commite/-0
W__:sixth/-0
W:of/2.238
237
W
__:raporteur/0.69
254
csion/1.00
W_:recommends/-0
W:provision/1.929
W:apropriation/3.108
480
W:adoption/0.711
W:in/1.425
G_:&lt;epsilon&gt;/-0
W:spo so s/ 3 .
W:projects/2.972
W:implications/2.139
W_:project/1.841
T__recommends:&lt;epsilon&gt;/0.27
:betwe / 60
W_:dug/.57
W_:/3.7
W__:than/4.147
W :ov.385
179
W_:about/3.426
W_:if/3.704
W__:per/3.988
W:a /3. 0
W_:an/2.837
W :so
394
453
W:t at/ .597
W_:a/
W__:tose/3.154
P_VP:&lt;epsilon&gt;/-0
W:at/3.201
W:in/.215
13
W_:on/2.046
hse/3.201
T_IN#NGEN+DT#NN#NGEN+INJ#N#NNS:&lt;epsilon&gt;/4.133
W__:-/-0
W
W
W:for/2.60
W:because/4.073
W__:draft/.404
W_:sixth/-0
W_:the/0.132
W__:out/4
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#J#NN#N:&lt;epsilon&gt;/3.545
W__:on/2.917
W__:o/.
W_:u
T__-:&lt;epsilon&gt;/0.129
W__:-/-0
G_:&lt;epsilon&gt;/-0
13
2
39
12
W__:comitee/-0
W__:-/-0
208
P_O:&lt;epsilon&gt;/-0
P_VP:&lt;epsilon&gt;/-0
25
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#N:&lt;epsilon&gt;/3.54
Tsixth#comite:&lt;epsilon&gt;/1.871
16
G_:&lt;epsilon&gt;/-0
G_:&lt;epsilon&gt;/-0
W_:tan/4.147
W_:pe/3.
W:with/3.075
W__:of/1.969
S__:&lt;s&gt;/6.717
P_O:&lt;epsilon&gt;/-0
PO:&lt;epsilon&gt;/-0
T__IN#NGEN+DT#N#NGEN+IN#DT#JJ#N#NN:&lt;epsilon&gt;/4.895
W__:the/0.132
W__:sixth/-0
110
P__NP:&lt;epsilon&gt;/-0
35
S__:&lt;s&gt;/5.868
W:by/1.908
W:in/1.425
W:with/1.853
:for/3.134
W:as/2.616
P_NP:&lt;epsilon&gt;/-0
S__:&lt;s&gt;/6.698
PNP:&lt;epsilon&gt;/-0
180
S:&lt;s&gt;/5.629
S__:&lt;s&gt;/6.620
S__:&lt;s&gt;/5.411
S__:&lt;s&gt;/6.74
S__:&lt;s&gt;/6.657
W__:comitee/-0
210
114
546
n2.046
W_:o/
W:adoption/0.711
51
483
284
P_NP:&lt;epsilon&gt;/-0
W_:asembly/-0
7
W__:o/.9
W__:by/.9
W__:at/3.
W__:in/.
W_:tat/2.614
T_the/NULL#asembly:&lt;epsilon&gt;/1.941
W:general/-0
P_PNP:&lt;epsilon&gt;/-0
+DT#NN#NGEN+INJ#NS#NGEN+IN#N:&lt;epsilon&gt;/4.64
W_:about/3.426
W_:/3.7
W:than/4.147
W__:pe/3
W:the/-0
76
74
TIN#NGEN+DT#N#NGEN+IN#DT#J#N#NGEN+IN#NN:&lt;epsilon&gt;/5.049
PNP:&lt;epsilon&gt;/-0
PNP:&lt;epsilon&gt;/-0
PNP:&lt;epsilon&gt;/-0
W:comitee/-0
PVP:&lt;epsilon&gt;/-0
165
G_:&lt;epsilon&gt;/-0
388
95
107
196
W_:recommends/-0
W:asembly/-0
W_:in/1.425
457
W:the/.18
W__:o/.
G:&lt;epsilon&gt;/-0
T__the/NUL#assembly:&lt;epsilon&gt;/1.941
321
366
S__:&lt;s&gt;/6.26
S:&lt;s&gt;/6.546
S:&lt;s&gt;/6.381
S__:&lt;s&gt;/6.71
S__:&lt;s&gt;/6.825
S__:&lt;s&gt;/5.835
S__:&lt;s&gt;/6.385
S__:&lt;s&gt;/6.529
S__:&lt;s&gt;/6.396
T_2#xslax/NULL:&lt;epsilon&gt;/1.194
W__:xslax/-0
245 PNP:&lt;epsilon&gt;/-0
W_:ge
W:adoption/0.71
580 604
W_:da
174
205
W:the/1.188
1
G_:&lt;epsilon&gt;/-0
W_:ad/-0
230
.154
31
W:consider/-0
251
W:had/-0
PADJP:&lt;epsilon&gt;/-0
PO:&lt;epsilon&gt;/-0
W:asean/-0
W
G:&lt;epsilon&gt;/-0
123
W_:/-0
Tthe/NUL#assembly:&lt;epsilon&gt;/1.941
Tthe/NUL#general#asembly:&lt;epsilon&gt;/0.938 271
Tthe#general#asembly:&lt;epsilon&gt;/2.12
Tthe/NUL#ge
W_:decided/-0
n/2.837
W__:the/-0
rned/-0
97
109
G:&lt;epsilon&gt;/-0
23
PNP:&lt;epsilon&gt;/-0
18
175
198
PPNP:&lt;epsilon&gt;/-0
71
W: s a / 0
G_:epso 130 _N:epso 151 _#:epso 176 W__:/0 206
:2/-0
91 G:&lt;epsilon&gt;/-0 19 PO:&lt;epsilon&gt;/-0 140 T-:&lt;epsilon&gt;/0.129 61 W:/-0 193
W__:
W_:asembly/-0
82
T2:&lt;epsilon&gt;/0.631
by/NUeps o / .085
T__by/NUL#the#gneral#asembly:&lt;epsilon&gt;/2.725
l#asembly:&lt;epsilon&gt;/2.748
ith/NULL#general#asembly#decsion/NULL:&lt;epsilon&gt;/3.13
PNP:&lt;epsilon&gt;/-0
by
W_:to/
W:asembly/-0
G:&lt;epsilon&gt;/-0
219
385
322
408
459
T_::&lt;epsilon&gt;/.028
24
T2#xslax/NULL:&lt;epsilon&gt;/1.194
242
W__:accoub
G_:&lt;epsilon&gt;/-0
W:gneral/-0
T_acountable:&lt;epsilon&gt;/0.693
310
W__:the/1.18
W__:tat/
W_:a/1.736
W_:xslax/-0
G:&lt;epsilon&gt;/-0
T-:&lt;epsilon&gt;/0.129
19
G:&lt;p
W_:on/2.046
167
106
G:&lt;epsilon&gt;/-0
PVP:&lt;epsilon&gt;/-0
T__IN#NGEN+DT#N#NGEN+IN#J#N#NNS:&lt;epsilon&gt;/4.13
T__729#xslax/NUL:&lt;epsilon&gt;/2.674
__78a/NU:epso/.
/NUL#advisory#commite:&lt;epsilon&gt;/.26
Tthe/NULL#commite:epso
W:729/-0
W:728/-0
W:the/-0
o : ow g/0. 7
W_:next/1.854
PVP:&lt;epsilon&gt;/-0
01
103
31
Tthe/NU
201
W__:comitee/-0
V : eps o / 0
_NP:&lt;epsilon&gt;/-0
NP&lt;siln&gt;/-0
_N:epso
:comite/-0
P_PNP:&lt;epsilon&gt;/-0
W:advisory/-0
W__:because/4.073
W_:from/3.270
W_:as/3.201
W_:to/3.971
W_:about/3.426
102
G:&lt;epsilon&gt;/-0
W__:/-0
584 W:implications/2.139
W:sponsors/1.31
W:projects/2.972
W:those/3.154 G:&lt;epsilon&gt;/-60 PO:&lt;epsilon&gt;/-0 T:&lt;epsilon&gt;/0.028
Trecomends:&lt;epsilon&gt;/0.27
172
W__:the/-0
Tsixth#committe:&lt;epsilon&gt;/1.871 173
NP:&lt;epsilon&gt;/-0
G:&lt;epsilon&gt;/-0
PNP:&lt;epsilon&gt;/-0
W:sixth/-0
Tby/NULL#the/NULL#sixth/NUL#comitee:&lt;epsilon&gt;/1.589
W:t at/ .6
W_:the/-0 389
N:epso 429 W__:ay/3.3 W:al/3.201 W:draft/0.404
W:provision/1.929
W:on/2.046 W:some/3.097
W:apropriation/3.108
277
seby:epso
738/0
W__:the/-0
Tto/NUL#the#general#asembly:&lt;epsilon&gt;/2.748
276
__by/NUL#the/NUL#general#asembly:&lt;epsilon&gt;/1.085
#the#general#asembly
W:rapporteur/0.69
PVP:&lt;epsilon&gt;/-0
168
W:recommends/-0
25 G:&lt;epsilon&gt;/-0 248
PPNP:&lt;epsilon&gt;/-0
G:&lt;epsilon&gt;/-0
W__:raporteur/0.69
PNP:&lt;epsilon&gt;/-0
146
20
324
W:the/-0
W:gneral/-0
W__:-/-0
W_:by/.90
W:at/3.536
psilon&gt;/-0
44
N G N# #J#N#NG N
W_:asembly/-0
W:adoption/0.711
T_the/NUL#general#assembly:&lt;epsilon&gt;/0.938
Twillconsir&lt;siln&gt;/2.42
__ad#deed:epso
G:&lt;epsilon&gt;/-0
609
250
278
W__:of/1.969
W:comite/-0
21 G:&lt;epsilon&gt;/-0
W:sixth/-0
W:will/-0
:as/3. 0
tough/.435
:to/3
392
W:in/1.425
/1.853
W:for/.134
n&gt;/-0
187
Trecomends:&lt;epsilon&gt;/0.227
164
W
W:decided/-0
292 Tacountable&lt;eiln&gt;/0.693 348 W:acountable/-0
:epso
349
W:the/-0
216
W:recomends/-0
W_:the/.188
W :tat/2.597
Tthe/NUL#sixth#committe:p
W:comitee/-0
PNP:&lt;epsilon&gt;/-0
W_:abo3.426
W_:if/3.704
W__:than/4.147
W_:over/4.385
W__:per/3.98
:out/4.410
G:&lt;epsilon&gt;/-0
PADJP:&lt;epsilon&gt;/-0
W:gneral/-0
721
186
Trecommends:&lt;epsilon&gt;/0.27
261
410
Tthe#gneral#asembly:&lt;epsilon&gt;/2.122
268
314 W:the/-0
by:epso
315
W:as/2.616
W_:o/
W:of/2.238
W_:by/1.908
W_:in/1.425
W_:draft/0.04
W_:recomends/-0
316
W_:the/0.132
460
W_:provision/1.929
P__O:&lt;epsilon&gt;/-0
W__:assembly/-0
G__:&lt;epsilon&gt;/-0
W_:adoption/0.711
W_:folowing/0.227
G__:&lt;epsilon&gt;/-0
432
W_:the/1.188
G_:&lt;epsilon&gt;/-0
W__:adoption/0.711
495
W__:adoption/0.711
W__:adoption/0.711
492
260
W_:the/0.132
P_PNP:&lt;epsilon&gt;/-0
516
W_:flowing/0.27
W:if/3.704
W_:the/.188
P_NP:&lt;epsilon&gt;/-0
W__:o/
W_:because/4.073
W_:o
W__:as/3.201
W__:to/3
W__:folowing/0.227
W_:adoption/0.711
W_:the/.188
613
48
W__:o/.
W_:the/.188
P__PNP:&lt;epsilon&gt;/-0
W__:draft/.404
T__IN#NGEN+DT#N#NGEN+IN#DT#JJ#NN#NGEN+IN#N:&lt;epsilon&gt;/5.049
T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#J#NN#NGEN+IN#N:&lt;epsilon&gt;
IN#NGEN+DT#N#NGEN+IN#J#NNS#NGEN+I#NN:&lt;epsilon&gt;/4.644
T_IN#NGEN+DT#NN#NGEN+IN#DT#J#N#NN:&lt;epsilon&gt;/4.895
W:i
435
W:in/1.425
557
W:p s ov o / .9 9
W_:apopation/3.108
W:acrediation/3.18
494
_:adoption/0.711
W:t s/ 66
.
W__:thse/3.201
:the/.188
W_:the/0.132
710
W_:as/
W__:through/4.435
W_:into/3.971
W_:abou
T_IN#NGEN+DT#N#NGEN+IN#NGEN+DT#J#N#NN:&lt;epsilon&gt;/3.545
:a/1.736
/3.154
W_:a/3
W__:on/2.046
W__:o/.
W__:by/.908
Tthe/NULL#asembly:&lt;epsilon&gt;/1.941
the/-0
291
ral#asembly:&lt;epsilon&gt;/0.530
344
346
W_:sponsors/1.31
614
G_:&lt;epsilon&gt;/-0
W_:of/1.69
W_:in/2.215
462
490 W:apropration/3.108
W:acrediation/3.18
W__:assembly/-0
W__:raporteur/0.69
T_IN#NGEN+DT#N#NGEN+IN#J#N#NS:&lt;epsilon&gt;/4.13
W:cop
W__:implications/2.139
W_:sponsors/1.31
W:projects/2.972
G_:&lt;epsilon&gt;/-60
W:decision/1.00 612
W__:raporteur/0.69
589
W_:on/2.917
W_:o/1.969
W__:against/4.731
W_:by/2.975
W_:under/4.248
W_:at/
W_:in/.215
W_:flowing/0.27
W__:next/1.854
25 PO:&lt;epsilon&gt;/-0
2#xslax/NUL:&lt;epsilon&gt;/.194
632
T2:&lt;epsilon&gt;/0.631
673
W:to/-0
W:on/-0
W:at/-0
W_:2/-0
697 W:xslax/-0
W:2/-0
W:world/-0 719 :economy/-0
W:under/.248
W:at/3.201
W__:tat/
W_:be
W__:wt/3
W__:for/2.60
W_:bec/4.073
W
520
icle/-0
W__:oly/-0
672
W:ac ed at
W__:adoption/0.71
T_with/NUL#article/NUL#2:&lt;epsilon&gt;/2.397 W:with/-0
T_in/NULL#only/NUL#2:&lt;epsilon&gt;/3.091 60 W:in/-0
T_for/NUL#just/NUL#2:&lt;epsilon&gt;/3.091
/NUL#ecnomy/NUL:&lt;epsilon&gt;/3.091
69 W:into/-0
r/NUL#review/NULL:&lt;epsilon&gt;/3.091
658
Tin/NUL#order/NULL:&lt;epsilon&gt;/3.091
Twith/NUL#regard/NUL:&lt;epsilon&gt;/3.091
65
T_in/NUL#document:&lt;epsilon&gt;/3.091
T__to/NUL#2.7/NUL#in/N:epso
67
T_by/NULL#2#police/NUL#oficers/NULL:&lt;epsilon&gt;/3.091
659
W:
W:a/1.736
W:those/3.154
W:al/3.201
W_:an/2.837
W_:o
W__:just/-0
P_PNP:&lt;epsilon&gt;/-0
689
693
G_:&lt;epsilon&gt;/-0
W_:as/3
691
cument/-0
W
W:in/-0
692
W:of/.238
.536
W:in/1.425
421 with/1.853
W:as/2.616
W_:on/2.046
W_:/-0
W_:oficers/-0
718
706
T:&lt;epsilon&gt;/0.028
576
W:adoption/0.71
W:provsion/1.929
504
W:t ese/3. 0
W_:the/.1
W:hat/2.597
:a/1.736
hose/3.154
W_:al/3.201
W_:te
W:by/2.975
P_O:&lt;epsilon&gt;/-0
W_:with/-0
P__O:&lt;epsilon&gt;/-0
569
619
G:&lt;epsilon&gt;/-0
W:concerned/-0
W:next/1.854
W:folowing/0.227
596
698
574
532
W:at/3. 0
W_:in/.215
W_:that/2.614
W_:with/3.075
W:decsion/1.0
675
598
T_I#NGEN+DT#N#NGEN+I#NGEN+DTJ#N#N:&lt;epsilon&gt;/3.45
G_:&lt;epsilon&gt;/-60
W_:so
:p oject/ .8
W__:implications/2.139
W_:sponsors/1.31
W:projects/2.972
TI#NGEN+DT#N#NGEN+IN#DT#J#N#N:&lt;epsilon&gt;/4.895
W:decsion/1.
W__:raporteur/0.69
G_:&lt;epsilon&gt;/-60
W:on/2.046
of238
W_:by/.90
W_:/
379
W_:next/1.854
W:folowing/0.227
TIN#NGEN+DT#N#NGEN+IN#JJ#N#NNS:&lt;epso
W: o / .660
W__:because/4.073
W_:from/3.270
W:as/3. 0
W:t s/ . 66
W_:on/2.917 W_:into/3.971
W:from/3.270
__ts W:about/3.426
W_:of/1.969
W:the/
W:with/1.853 W_:/3.704 W:as/3.201
W_:by/2.975
W_:pe/3.9 W:on/2.917
W_:povs
478
W_:on/2.917
W__:adopto/0.711 W:of/1.69
W__:on/2.046 W_:o/
W:some/3.097 W__:adoption/0.71 530 W:by/2.975
W__:of/2.238 W:by/1.908
in2.215
W_:the/.18
W__:tat/
W:a/1.736 ut/3.426
W:with/1.853 473 W__:wt/3
W:on/2.917 W__:for/2.60
T__IN#NGEN+DT#NN#NGEN+IN#J#N#NNS:&lt;epsilon&gt;/4.133 W:as/2.616
W:on/2.046 W:of/1.969
W:b.908
in/1.425
W:with/1.853
W:
W:on/2.046
W:of/2.238
W:by/1.908
W:decision/1.00
3
2.139
W:flowing/0.27
95
618
635
W__:dat/0
W:project/1.841
W:decision/1.00
W:raporteu
617
W_:flowing/0.27
416 TIN#NGEN+DT#N#NGEN+IN#NGEN+DT#J#N#N:&lt;epsilon&gt;/3.545
T_IN#NGEN+DT#N#NGEN+IN#DT#J#NN#N:epso 44
W_:o
529 56
594
Wwith/3.075
W_:o
W_:o W__:the/0.132
472
W:in/1.425
474
W:adoption/0.711
W:that/2.614
531
W:on/2.917
W:of/1.969
W__:by/2.975
</figure>
<figureCaption confidence="0.988318666666667">
Figure 2: A portion of the translation model for an Arabic test sen-
tence, compacted and aggressively pruned by path probability for dis-
play purposes.
</figureCaption>
<sectionHeader confidence="0.554575" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.974815766666666">
Results Tables A and B below list evaluation results for
translation on the Arabic and French test sets respec-
tively. In each case, results for a comparison system –
the Giza++ IBM Model 4 implementation (Och and Ney,
2000) with the ReWrite decoder (Marcu and Germann,
2002) – are included as a benchmark. Results were gen-
erated for training corpora of varying sizes. For Arabic,
we ran our system on two large subsets of the UN cor-
pus and evaluated on a 200-sentence held-out set (refer
to Results Table A below). For the 150K sentence Ara-
bic training set, Giza++ and the shallow syntax model
achieved very similar performance. We were unable to
obtain evaluation numbers for Giza++/ReWrite on the
large Arabic training set, however, since its language
model component has a vocabulary size limit which was
exceeded in the larger corpus. In French we observed the
systems to perform similarly on the small training sets
we used (Results Table B). We performed some exper-
iments in classifier combination using the two compat-
ible (150K-training-sentence) Arabic systems, wherein
a small devtest set was used to identify simple system
combination parameters based on model confidence and
sentence length. In situations where our system was con-
fident we used its output, and used Giza++ output other-
wise. We achieved a 3% boost in Bleu score over Giza++
performance on the evaluation set with these very sim-
ple classifier combination techniques, and anticipate that
research in this direction – classifier combination of di-
versely trained SMT systems – could yield significant
performance improvements.
</bodyText>
<figure confidence="0.982755789473684">
P(commission  |ljnp)
P(the  |NULL)
P( DT w, NN 1  |NOUN−SG )
1
&amp;quot;commission&amp;quot;
...
&amp;quot;the&amp;quot;
...
.. .
S
... next phrase,
etc ...
&amp;quot;committee&amp;quot;
...
&amp;quot;an
&amp;quot;
P(an  |NULL) P(committee  |ljnp)
P(NP VP NP .. |VP NP NP .. )
2 1 3 1 2 3
</figure>
<figureCaption confidence="0.9840925">
Figure 1: An illustration of the translation model structure for an
Arabic test sentence.
</figureCaption>
<table confidence="0.974503">
Bleu Score
System 150K 500K
Trn. Sent. Trn. Sent.
Giza++/ReWrite Decoder 0.17 *
2-level Syntax Model 0.17 0.18
</table>
<reference confidence="0.431551071428571">
Results Table A: Results comparison for Arabic to English
translation on the UN corpus, with a 200-sentence evaluation
set. Note that Giza++/ReWrite cannot be run for the 500K
sentence training set; the CMU Language Modeling Toolkit,
which ReWrite uses, has a vocabulary size limit which is
exceeded in the 500K corpus.
Bleu Score
System 5K 20K
Trn. Sent. Trn. Sent.
Giza++/ReWrite Decoder 0.08 0.11
2-level Syntax Model 0.08 0.09
Results Table B: Results comparison for French to English
translation on the Canadian Hansards corpus (200-sentence
evaluation set).
</reference>
<sectionHeader confidence="0.998997" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999983310344828">
We have described and implemented an original syntax-
based statistical translation model that yields baseline re-
sults which compete successfully with other state-of-the-
art SMT models. This is particularly encouraging in that
the authors are not well-versed in Arabic or French and
it appears that the quality of the rule-based phrase chun-
kers we developed in a single person-day offers substan-
tial room for improvement. We expect to be able to at-
tain improved bracketings from native speakers and, in
addition, via translingual projection of existing brack-
eters. Secondly, the lemma model we have proposed for
lexical transfer provides an efficient framework for in-
tegrating electronic dictionaries into SMT models. Al-
though we have at this time no large electronic dictionar-
ies for either Arabic or French, efforts are underway to
acquire electronic or scanned paper dictionaries for this
purpose. We did evaluate the lemma models in isola-
tion for French and Arabic without dictionary inclusion,
but in each experiment the results did not differ signifi-
cantly from the word-specific lexical transfer models, de-
spite their substantially reduced dimensionality. We an-
ticipate that the relatively seamless direct incorporation
of dictionaries into the lemma-based models will be par-
ticularly effective for translating low-density languages,
which suffer from data sparseness in the face of limited
parallel text. Finally, we incorporated lexical translation
coercion models into this full SMT framework, the in-
duction of which is a phenomenon of interest in its own
right.
</bodyText>
<sectionHeader confidence="0.998587" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9995325">
This work was supported in part by NSF grant number IIS-9985033. In
addition, we owe many thanks to colleagues who generously lent their
time and insights. David Smith shared his tools for Arabic part-of-
speech tagging and morphological analysis and answered many ques-
tions about the Arabic language. Thanks to Skankar Kumar and San-
jeev Khudanpur for numerous helpful discussions.
</bodyText>
<sectionHeader confidence="0.998596" genericHeader="references">
9 References
</sectionHeader>
<reference confidence="0.99924775">
H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning depen-
dency translation models as collections of finite state head transducers
Computational Linguistics, 26(1), 45–60.
S. Bangalore and G. Riccardi. 2000. Stochastic finite-state models for
spoken language machine translation. In Proceedings of the Workshop
on Embedded Machine Translation Systems., pp. 52–59.
P. Brown, S. Della Pietra, V. Della Pietra and R. Mercer. 1993. The
mathematics of statistical machine translation: Parameter estimation.
Computational Linguistics, 12(2), 263–312.
S. Cucerzan and D. Yarowsky. 2002. Bootstrapping a Multilingual
Part-of-speech Tagger in One Person-day. Proceedings of the Sixth
Conference on Natural Language Learning (CoNLL), Taipei, 2002.
B. Dorr and N. Habash. 2002. Interlingua approximation: A
generation-heavy approach. In Proceedings of AMTA-2002.
W. A. Gale and K. W. Church. 1991. A Program for Aligning
Sentences in Bilingual Corpora. In 29th Annual Meeting of the ACL,
Berkeley, CA.
N. Habash and B. Dorr. 2003. A categorial variation database for
English. In Proceedings ofNAACL-HLT 2003
D. Jones and R. Havrilla. 1998. Twisted pair grammar: Support for
rapid development of machine translation for low density languages.
In Proceedings of AMTA98, pp. 318–332.
D. Marcu and U. Germann. 2002. The ISI ReWrite Decoder Release
0.7.0b. http://www.isi.edu/licensed-sw/rewrite-decoder/.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a
large annotated corpus of English: the Penn Treebank. Computational
Linguistics, Vol. 19.
M. Mohri, F. Pereira, and M. Riley. 1997.
ATT General-purpose finite-state machine software tools.
http://www.research.att.com/sw/tools/fsm/.
G. Ngai and R. Florian. Transformation-based learning in the fast lane.
In Proceedings ofNorth Americal ACL 2001, pages 40-47, June 2001.
F. J. Och and H. Ney. 2000. Improved statistical alignment models.
In Proceedings of the 38th Annual Meeting of the Association for
Computational Linguistics, pages 440–447.
F.J. Och, C. Tillmann, H. Ney. Improved Alignment Models for
Statistical Machine Translation. In Proceedings of EMNLP 1999, pp.
20-28.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2001. Bleu: a method
for automatic evaluation of machine translation. Technical Report
RC22176 (W0109-022), IBM Research Division.
A. Stolcke. 2002. SRILM - an extensible language modeling
toolkit. In Proceedings of the International Conference on Spo-
ken Language Processing, pages 901-904. Denver, CO, USA.
http://www.speech.sri.com/projects/srilm/.
D. Wu. 1997. Stochastic inversion transduction grammars and
bilingual parsing of parallel corpora. Computational Linguistics,
23(3), 377–404.
K. Yamada and K. Knight. 2001. A syntax-based statistical translation
model. In Proceedings ofACL-2001, pp. 523–529.
K. Yamada and K. Night. 2002. A decoder for syntax-based statistical
MT In Proceedings ofACL-2002, pp. 303–310.
</reference>
<table confidence="0.983643257142857">
Word Translation Probabilities
Word translation for mangeant conditioned on
French Word, EnglishPOS
mangeant VBG eating 1.00
mangeant VB go 0.50
mangeant VB anticipate 0.50
mangeant VBD were 1.00
mangeant VBP knelt 1.00
mangeant NN bill 1.00
Word translation for mangeant conditioned on
French Word, English Coarse POS
mangeant V eating 0.44
mangeant V were 0.22
mangeant V knelt 0.11
mangeant V go 0.11
mangeant V anticipate 0.11
mangeant N bill 1.00
Word translation for mangeant conditioned on
French Word only
mangeant eating 0.29
mangeant were 0.14
mangeant go 0.07
mangeant bill 0.07
Word translation for mangeant
conditioned on French Word, EnglishPOS
mangeant RB mostly 1.00
mangeant JJ final 1.00
mangeant VBN obtained 1.00
mangeant VBG eating 1.00
mangeant WP who 1.00
mangeant IN through 1.00
mangeant NN lard 1.00
mangeant VBZ eats 0.50
mangeant VBZ comes 0.50
Lemma Translation Probabilities
</table>
<bodyText confidence="0.869584151515151">
Generation of a verb lemma given manger
manger V eat 0.60
manger V feed 0.05
manger V have 0.04
Generation of a noun lemma given manger
manger N meal 0.06
manger N trough 0.04
manger N loaf 0.04
manger N food 0.04
Generation of an adj. lemma given manger
manger J hungry 0.33
Raw lemma translation probabilities
(ignoring English Coarse POS)
manger eat 0.28
manger to 0.03
manger feed 0.03
manger out 0.02
manger have 0.02
manger are 0.02
manger , 0.02
manger you 0.01
manger meal 0.01
Table 9: Direct generation (word-to-word translation probabilities
at the various levels of backoff) is contrasted with lemma generation.
Manger (`to eat”) is a relatively rare word in the Hansards. Note that
due to low counts, the desired verb POS (target of generation) for `eat”
may not have been observed as a translation in training data. In addi-
tion, in this situation, noisy word alignments may cause an incorrect
translation to have similar estimated translation probability. This prob-
lem is addressed by the lemma model; note the much sharper probabil-
ity distribution for verb lemmas given manger. Generation of English
inflections given lemma and target POS is algorithmic (and irregular
exceptions are handled via a lookup table).
</bodyText>
<table confidence="0.99916344">
French Wd. Eng. POS Eng. Wd. Prob.
accepter JJ unacceptable 0.12
accepter JJ acceptable 0.12
accepter JJ willing 0.11
accepter JJ ready 0.03
accepter NN acceptance 0.09
accepter NN amendment 0.03
droit VBN entitled 0.66
droit VBN allowed 0.09
droit VBN denied 0.03
droit VBN given 0.02
droit VBN permitted 0.02
droit VBN justified 0.01
droit VBN qualified 0.01
droit VBN allotted 0.01
droit VB qualify 0.14
droit VB be 0.11
droit VB have 0.09
droit VB receive 0.08
droit VB get 0.07
droit VB expect 0.03
droit VBG receiving 0.11
droit VBG getting 0.08
droit NNS rights 0.44
droit NNS benefits 0.69
</table>
<tableCaption confidence="0.653835">
Table 10: Examples of word translation coercions. Co-
</tableCaption>
<bodyText confidence="0.9946574">
ercions of the French verb accepter “to accept” and the
French noun droit “right” (there is parallel polysemy be-
tween the two languages for this word, but the predom-
inant sense in our corpus is the philosophical/judicial
sense, as opposed to the direction).
</bodyText>
<table confidence="0.995384823529412">
Eng. Phrase French Eng. Prob.
Type Phrase Phrase
NP dans le cas pr´esent a situation 0.25
NP dans le cas pr´esent the subject of debate 0.25
NP dans le cas pr´esent the position 0.25
NP dans le cas pr´esent it 0.25
VP dans le cas pr´esent should apply 1.00
ADVP dans le cas pr´esent really 1.00
PPNP dans le cas pr´esent in this case 0.63
PPNP dans le cas pr´esent in this instance 0.04
PPNP dans le cas pr´esent in this actual case 0.04
PPNP dans le cas pr´esent in this particular case 0.04
PPNP dans le cas pr´esent in that case 0.04
PPNP dans le cas pr´esent in the present circumstances 0.04
VP acceptons accept 0.48
VP acceptons agree 0.14
NP acceptons this consent 1.00
</table>
<bodyText confidence="0.707523222222222">
PPNP par an per year 0.67
PPNP par an in each year 0.03
PPNP par an for a year 0.03
ADVP par an annually 1.00
NP par an a year 0.79
NP par an each year 0.02
NP un discours a speech 0.83
NP un discours an address 0.05
VP un discours to speak 1.00
</bodyText>
<tableCaption confidence="0.9419395">
Table 11: Examples of direct phrase translations (see Ta-
ble 4(1)), including some coercions.
</tableCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539595">
<title confidence="0.99931">Statistical Machine Translation Using Coercive Two-Level Syntactic Transduction</title>
<author confidence="0.991694">Charles Schafer</author>
<author confidence="0.991694">David</author>
<affiliation confidence="0.7763345">Center for Language and Speech Processing / Department of Computer Johns Hopkins</affiliation>
<address confidence="0.999584">Baltimore, MD 21218</address>
<abstract confidence="0.999093588235294">We define, implement and evaluate a novel model for statistical machine translation, which is based on shallow syntactic analysis (part-of-speech tagging and phrase chunking) in both the source and target languages. It is able to model long-distance constituent motion and other syntactic phenomena without requiring a full parse in either language. We also examine aspects of lexical transfer, suggesting and exploring a concept of translaparts of speech, as well as a transfer model based on lemma-to-lemma translation probabilities, which holds promise for improving machine translation of low-density languages. Experiments are performed in both Arabic-to-English and French-to-English translation demonstrating the efficacy of the proposed techniques. Performance is automatically evaluated via the Bleu score metric.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Results Table A: Results comparison for Arabic to English translation on the UN corpus, with a 200-sentence evaluation set. Note that Giza++/ReWrite cannot be run for the 500K sentence training set; the CMU Language Modeling Toolkit, which ReWrite uses, has a vocabulary size limit which is exceeded in the 500K corpus.</title>
<marker></marker>
<rawString>Results Table A: Results comparison for Arabic to English translation on the UN corpus, with a 200-sentence evaluation set. Note that Giza++/ReWrite cannot be run for the 500K sentence training set; the CMU Language Modeling Toolkit, which ReWrite uses, has a vocabulary size limit which is exceeded in the 500K corpus.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bleu Score</author>
</authors>
<title>System 5K Trn. Sent. 20K Trn. Sent. Giza++/ReWrite Decoder Results Table B: Results comparison for French to English translation on the Canadian Hansards corpus (200-sentence evaluation set).</title>
<marker>Score, </marker>
<rawString>Bleu Score System 5K Trn. Sent. 20K Trn. Sent. Giza++/ReWrite Decoder Results Table B: Results comparison for French to English translation on the Canadian Hansards corpus (200-sentence evaluation set).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>S Bangalore</author>
<author>S Douglas</author>
</authors>
<title>Learning dependency translation models as collections of finite state head transducers</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<pages>45--60</pages>
<contexts>
<context position="4114" citStr="Alshawi et al. (2000)" startWordPosition="612" endWordPosition="615">un swapping, is adequately modeled by the relative-position-based distortion models of the classic IBM approach. Unfortunately, these distortion models are less effective for languages such as Japanese or Arabic, which have substantially different top-level sentential word orders from English, and hence longer distance constituent motion. Wu (1997) and Jones and Havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree constituents. Yamada and Knight (2000, 2001) and Alshawi et al. (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finite state head transducers respectively. While these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have a limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses. In contrast, Och et al. (1999) have avoided the constraints of</context>
</contexts>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collections of finite state head transducers Computational Linguistics, 26(1), 45–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Riccardi</author>
</authors>
<title>Stochastic finite-state models for spoken language machine translation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop on Embedded Machine Translation Systems.,</booktitle>
<pages>52--59</pages>
<contexts>
<context position="5663" citStr="Bangalore and Riccardi, 2000" startWordPosition="847" endWordPosition="850"> flat embedded noun-phrases in a flat sentential constituent-based chunk sequence that can be driven by syntactic bracketers and POS tag models rather than a full parser, facilitating its transfer to lower density languages. The flatter 2-level structures also better support transductions conditioned to full sentential context than do deeply embedded tree models, while retaining the empirically observed advantages of translation ordering independence of nounphrases. Another improvement over Och et al. and Yamada and Knight is the use of the finite state machine (FSM) modelling framework (e.g. Bangalore and Riccardi, 2000), which offers the considerable advantage of a flexible framework for decoding, as well as a representation which is suitable for the fixed two-level phrasal modelling employed here. Finally, the original cross-part-of-speech lexical coercion models presented in Section 4.3.3 have related work in the primarily-syntactic coercion models utilized by Dorr and Habash (2002) and Habash and Door (2003), although their induction and modelling are quite different from the approach here. 3 Resources As in other SMT approaches, the primary training resource is a sentence-aligned parallel bilingual corpu</context>
</contexts>
<marker>Bangalore, Riccardi, 2000</marker>
<rawString>S. Bangalore and G. Riccardi. 2000. Stochastic finite-state models for spoken language machine translation. In Proceedings of the Workshop on Embedded Machine Translation Systems., pp. 52–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>2</issue>
<pages>263--312</pages>
<contexts>
<context position="3170" citStr="Brown et al., 1993" startWordPosition="470" endWordPosition="473">ce-level order of Verb-SubjectObject, which means that translation into English (with a standard ordering of Subject-Verb-Object) commonly requires motion of entire phrasal constituents, which is not true of French-to-English translation, to cite one language pair whose characteristics have wielded great influence in the history of work on statistical machine translation. A key motivation for and objective of this work was to build a translation model and feature space to handle the above-described phenomenon effectively. 2 Prior Work Statistical machine translation, as pioneered by IBM (e.g. Brown et al., 1993), is grounded in the noisy channel model. And similar to the related channel problems of speech and handwriting recognition, the original SMT language pair French-English exhibits a relatively close linear correlation in source and target sequence. Much common local motion that is observed for French, such as adjective-noun swapping, is adequately modeled by the relative-position-based distortion models of the classic IBM approach. Unfortunately, these distortion models are less effective for languages such as Japanese or Arabic, which have substantially different top-level sentential word ord</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra and R. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 12(2), 263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>D Yarowsky</author>
</authors>
<title>Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day.</title>
<date>2002</date>
<booktitle>Proceedings of the Sixth Conference on Natural Language Learning (CoNLL),</booktitle>
<location>Taipei,</location>
<contexts>
<context position="6470" citStr="Cucerzan and Yarowsky, 2002" startWordPosition="970" endWordPosition="973">re. Finally, the original cross-part-of-speech lexical coercion models presented in Section 4.3.3 have related work in the primarily-syntactic coercion models utilized by Dorr and Habash (2002) and Habash and Door (2003), although their induction and modelling are quite different from the approach here. 3 Resources As in other SMT approaches, the primary training resource is a sentence-aligned parallel bilingual corpus. We further require that each side of the corpus be partof-speech (POS) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (Cucerzan and Yarowsky, 2002). Our translation experiments were carried out on two languages: Arabic and French. The Arabic training corpus was a subset of the United Nations (UN) parallel corpus which is being made available by the Linguistic Data Consortium. For French-English training, we used a portion of the Canadian Hansards. Both corpora utilized sentencelevel alignments publicly distributed by the Linguistic Data Consortium. POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corp</context>
</contexts>
<marker>Cucerzan, Yarowsky, 2002</marker>
<rawString>S. Cucerzan and D. Yarowsky. 2002. Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day. Proceedings of the Sixth Conference on Natural Language Learning (CoNLL), Taipei, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
<author>N Habash</author>
</authors>
<title>Interlingua approximation: A generation-heavy approach.</title>
<date>2002</date>
<booktitle>In Proceedings of AMTA-2002.</booktitle>
<contexts>
<context position="6035" citStr="Dorr and Habash (2002)" startWordPosition="901" endWordPosition="904">ng the empirically observed advantages of translation ordering independence of nounphrases. Another improvement over Och et al. and Yamada and Knight is the use of the finite state machine (FSM) modelling framework (e.g. Bangalore and Riccardi, 2000), which offers the considerable advantage of a flexible framework for decoding, as well as a representation which is suitable for the fixed two-level phrasal modelling employed here. Finally, the original cross-part-of-speech lexical coercion models presented in Section 4.3.3 have related work in the primarily-syntactic coercion models utilized by Dorr and Habash (2002) and Habash and Door (2003), although their induction and modelling are quite different from the approach here. 3 Resources As in other SMT approaches, the primary training resource is a sentence-aligned parallel bilingual corpus. We further require that each side of the corpus be partof-speech (POS) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (Cucerzan and Yarowsky, 2002). Our translation experiments were carried out on two languages: Arabic and French. The Arabic training corpus was a subset of the United Nations (UN) parallel corpu</context>
</contexts>
<marker>Dorr, Habash, 2002</marker>
<rawString>B. Dorr and N. Habash. 2002. Interlingua approximation: A generation-heavy approach. In Proceedings of AMTA-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the ACL,</booktitle>
<location>Berkeley, CA.</location>
<marker>Gale, Church, 1991</marker>
<rawString>W. A. Gale and K. W. Church. 1991. A Program for Aligning Sentences in Bilingual Corpora. In 29th Annual Meeting of the ACL, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>B Dorr</author>
</authors>
<title>A categorial variation database for English.</title>
<date>2003</date>
<booktitle>In Proceedings ofNAACL-HLT</booktitle>
<marker>Habash, Dorr, 2003</marker>
<rawString>N. Habash and B. Dorr. 2003. A categorial variation database for English. In Proceedings ofNAACL-HLT 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jones</author>
<author>R Havrilla</author>
</authors>
<title>Twisted pair grammar: Support for rapid development of machine translation for low density languages.</title>
<date>1998</date>
<booktitle>In Proceedings of AMTA98,</booktitle>
<pages>318--332</pages>
<contexts>
<context position="3873" citStr="Jones and Havrilla (1998)" startWordPosition="574" endWordPosition="577">roblems of speech and handwriting recognition, the original SMT language pair French-English exhibits a relatively close linear correlation in source and target sequence. Much common local motion that is observed for French, such as adjective-noun swapping, is adequately modeled by the relative-position-based distortion models of the classic IBM approach. Unfortunately, these distortion models are less effective for languages such as Japanese or Arabic, which have substantially different top-level sentential word orders from English, and hence longer distance constituent motion. Wu (1997) and Jones and Havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree constituents. Yamada and Knight (2000, 2001) and Alshawi et al. (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finite state head transducers respectively. While these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have a limitation shared with probabilistic conte</context>
</contexts>
<marker>Jones, Havrilla, 1998</marker>
<rawString>D. Jones and R. Havrilla. 1998. Twisted pair grammar: Support for rapid development of machine translation for low density languages. In Proceedings of AMTA98, pp. 318–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>U Germann</author>
</authors>
<date>2002</date>
<booktitle>The ISI ReWrite Decoder Release 0.7.0b.</booktitle>
<pages>http://www.isi.edu/licensed-sw/rewrite-decoder/.</pages>
<contexts>
<context position="42042" citStr="Marcu and Germann, 2002" startWordPosition="5726" endWordPosition="5729">3.545 T_IN#NGEN+DT#N#NGEN+IN#DT#J#NN#N:epso 44 W_:o 529 56 594 Wwith/3.075 W_:o W_:o W__:the/0.132 472 W:in/1.425 474 W:adoption/0.711 W:that/2.614 531 W:on/2.917 W:of/1.969 W__:by/2.975 Figure 2: A portion of the translation model for an Arabic test sentence, compacted and aggressively pruned by path probability for display purposes. 6 Evaluation Results Tables A and B below list evaluation results for translation on the Arabic and French test sets respectively. In each case, results for a comparison system – the Giza++ IBM Model 4 implementation (Och and Ney, 2000) with the ReWrite decoder (Marcu and Germann, 2002) – are included as a benchmark. Results were generated for training corpora of varying sizes. For Arabic, we ran our system on two large subsets of the UN corpus and evaluated on a 200-sentence held-out set (refer to Results Table A below). For the 150K sentence Arabic training set, Giza++ and the shallow syntax model achieved very similar performance. We were unable to obtain evaluation numbers for Giza++/ReWrite on the large Arabic training set, however, since its language model component has a vocabulary size limit which was exceeded in the larger corpus. In French we observed the systems t</context>
</contexts>
<marker>Marcu, Germann, 2002</marker>
<rawString>D. Marcu and U. Germann. 2002. The ISI ReWrite Decoder Release 0.7.0b. http://www.isi.edu/licensed-sw/rewrite-decoder/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="7094" citStr="Marcus et al., 1993" startWordPosition="1067" endWordPosition="1070">r translation experiments were carried out on two languages: Arabic and French. The Arabic training corpus was a subset of the United Nations (UN) parallel corpus which is being made available by the Linguistic Data Consortium. For French-English training, we used a portion of the Canadian Hansards. Both corpora utilized sentencelevel alignments publicly distributed by the Linguistic Data Consortium. POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al., 1993). French POS tagging was done using the trained French lexical tagger also provided with the fnTBL software. For Arabic, we used a colleague’s POS tagger and tokenizer (clitic separation was also performed prior to POS tagging), which was rapidly developed in our laboratory. Simple regular-expression-based phrase chunkers were developed by the authors for both Arabic and French, requiring less than a person-day each using existing multilingual learning tools. A further input to our system is a set of word alignment links on the parallel corpus. These are used to compute word translation probab</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, Vol. 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohri</author>
<author>F Pereira</author>
<author>M Riley</author>
</authors>
<date>1997</date>
<note>ATT General-purpose finite-state machine software tools. http://www.research.att.com/sw/tools/fsm/.</note>
<contexts>
<context position="24640" citStr="Mohri et al., 1997" startWordPosition="4004" endWordPosition="4007">scriptive mode. droit behaves similarly. Though the English verb “to right’ or “to be righted” does not have the philosophical/judicial entitlement sense of the noun “right”, we see that the model has learned to realize the meaning in an active, verbal form: e.g., VBG ‘receiving” and VB “qualify”. 5 Decoding Decoding was implemented by constructing finite-state machines (FSMs) per evaluation sentence to encode relevant portions (for the individual sentence in question) ofthe component translation distributions described above. Operations on these FSMs are performed using the AT&amp;T FSM Toolkit (Mohri et al., 1997). The FSM constructed for a test sentence is subsequently composed with a FSM trigram language model created via the SRI Language Modeling Toolkit (Stolcke, 2002). Thus we use the trigram language model to implement rescoring of the (direct) translation probabilities for the English word sequences in the translation model lattice. We found that using the finite-state framework and the general-purpose AT&amp;T toolkit greatly facilitates decoder development by freeing the implementation from details of machine composition and best-path searching, etc. The structure of the translation model finite-s</context>
</contexts>
<marker>Mohri, Pereira, Riley, 1997</marker>
<rawString>M. Mohri, F. Pereira, and M. Riley. 1997. ATT General-purpose finite-state machine software tools. http://www.research.att.com/sw/tools/fsm/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ngai</author>
<author>R Florian</author>
</authors>
<title>Transformation-based learning in the fast lane.</title>
<date>2001</date>
<booktitle>In Proceedings ofNorth Americal ACL</booktitle>
<pages>40--47</pages>
<contexts>
<context position="7013" citStr="Ngai and Florian, 2001" startWordPosition="1054" endWordPosition="1057">eloped techniques for rapid training of such tools (Cucerzan and Yarowsky, 2002). Our translation experiments were carried out on two languages: Arabic and French. The Arabic training corpus was a subset of the United Nations (UN) parallel corpus which is being made available by the Linguistic Data Consortium. For French-English training, we used a portion of the Canadian Hansards. Both corpora utilized sentencelevel alignments publicly distributed by the Linguistic Data Consortium. POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al., 1993). French POS tagging was done using the trained French lexical tagger also provided with the fnTBL software. For Arabic, we used a colleague’s POS tagger and tokenizer (clitic separation was also performed prior to POS tagging), which was rapidly developed in our laboratory. Simple regular-expression-based phrase chunkers were developed by the authors for both Arabic and French, requiring less than a person-day each using existing multilingual learning tools. A further input to our system is a set of word alignmen</context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>G. Ngai and R. Florian. Transformation-based learning in the fast lane. In Proceedings ofNorth Americal ACL 2001, pages 40-47, June 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="7913" citStr="Och and Ney, 2000" startWordPosition="1197" endWordPosition="1200">rmed prior to POS tagging), which was rapidly developed in our laboratory. Simple regular-expression-based phrase chunkers were developed by the authors for both Arabic and French, requiring less than a person-day each using existing multilingual learning tools. A further input to our system is a set of word alignment links on the parallel corpus. These are used to compute word translation probabilities and phrasal alignments. The word alignments can in principle come from any source: a dictionary, a specialized alignment program, or another SMT system. We used alignments generated by Giza++ (Och and Ney, 2000) by running it in both directions (e.g., Arabic —&gt; English and English —&gt; Arabic) on our parallel corpora. The union of these bidirectional alignments was used to compute cross-language phrase correspondences by simple majority voting, and for purposes of estimating word translation probabilities, each link in this union was treated as an independent instance of word translation. 4 Translation Model Now we turn to a detailed description of the proposed translation model. The exposition will give a formal specification and also will follow a running example throughout, using one of the actual A</context>
<context position="41991" citStr="Och and Ney, 2000" startWordPosition="5718" endWordPosition="5721">IN#NGEN+DT#N#NGEN+IN#NGEN+DT#J#N#N:&lt;epsilon&gt;/3.545 T_IN#NGEN+DT#N#NGEN+IN#DT#J#NN#N:epso 44 W_:o 529 56 594 Wwith/3.075 W_:o W_:o W__:the/0.132 472 W:in/1.425 474 W:adoption/0.711 W:that/2.614 531 W:on/2.917 W:of/1.969 W__:by/2.975 Figure 2: A portion of the translation model for an Arabic test sentence, compacted and aggressively pruned by path probability for display purposes. 6 Evaluation Results Tables A and B below list evaluation results for translation on the Arabic and French test sets respectively. In each case, results for a comparison system – the Giza++ IBM Model 4 implementation (Och and Ney, 2000) with the ReWrite decoder (Marcu and Germann, 2002) – are included as a benchmark. Results were generated for training corpora of varying sizes. For Arabic, we ran our system on two large subsets of the UN corpus and evaluated on a 200-sentence held-out set (refer to Results Table A below). For the 150K sentence Arabic training set, Giza++ and the shallow syntax model achieved very similar performance. We were unable to obtain evaluation numbers for Giza++/ReWrite on the large Arabic training set, however, since its language model component has a vocabulary size limit which was exceeded in the</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Improved Alignment Models for Statistical Machine Translation.</title>
<date>1999</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>20--28</pages>
<contexts>
<context position="4682" citStr="Och et al. (1999)" startWordPosition="694" endWordPosition="697">and Knight (2000, 2001) and Alshawi et al. (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finite state head transducers respectively. While these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have a limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses. In contrast, Och et al. (1999) have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks, which need not adhere to traditional constituent boundaries. Our current paper takes a middle path, by grounding motion in syntactic transduction, but in a much flatter 2- level model of syntactic analysis, based on flat embedded noun-phrases in a flat sentential constituent-based chunk sequence that can be driven by syntactic bracketers and POS tag models rather than a full parser, facilitating its transfer to lower density languages. The flatter 2-level str</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>F.J. Och, C. Tillmann, H. Ney. Improved Alignment Models for Statistical Machine Translation. In Proceedings of EMNLP 1999, pp. 20-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<tech>Technical Report RC22176 (W0109-022),</tech>
<institution>IBM Research Division.</institution>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report RC22176 (W0109-022), IBM Research Division.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, CO, USA. http://www.speech.sri.com/projects/srilm/.</location>
<contexts>
<context position="24802" citStr="Stolcke, 2002" startWordPosition="4031" endWordPosition="4032">right”, we see that the model has learned to realize the meaning in an active, verbal form: e.g., VBG ‘receiving” and VB “qualify”. 5 Decoding Decoding was implemented by constructing finite-state machines (FSMs) per evaluation sentence to encode relevant portions (for the individual sentence in question) ofthe component translation distributions described above. Operations on these FSMs are performed using the AT&amp;T FSM Toolkit (Mohri et al., 1997). The FSM constructed for a test sentence is subsequently composed with a FSM trigram language model created via the SRI Language Modeling Toolkit (Stolcke, 2002). Thus we use the trigram language model to implement rescoring of the (direct) translation probabilities for the English word sequences in the translation model lattice. We found that using the finite-state framework and the general-purpose AT&amp;T toolkit greatly facilitates decoder development by freeing the implementation from details of machine composition and best-path searching, etc. The structure of the translation model finite-state machines is as illustrated in Figure 1. The sentence-level (aligned phrase sequence generation) and phrase-level (aligned intra-phrase sequence generation) t</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, pages 901-904. Denver, CO, USA. http://www.speech.sri.com/projects/srilm/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<pages>377--404</pages>
<contexts>
<context position="3843" citStr="Wu (1997)" startWordPosition="571" endWordPosition="572">ated channel problems of speech and handwriting recognition, the original SMT language pair French-English exhibits a relatively close linear correlation in source and target sequence. Much common local motion that is observed for French, such as adjective-noun swapping, is adequately modeled by the relative-position-based distortion models of the classic IBM approach. Unfortunately, these distortion models are less effective for languages such as Japanese or Arabic, which have substantially different top-level sentential word orders from English, and hence longer distance constituent motion. Wu (1997) and Jones and Havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree constituents. Yamada and Knight (2000, 2001) and Alshawi et al. (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finite state head transducers respectively. While these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have a limitation s</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3), 377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL-2001,</booktitle>
<pages>523--529</pages>
<marker>Yamada, Knight, 2001</marker>
<rawString>K. Yamada and K. Knight. 2001. A syntax-based statistical translation model. In Proceedings ofACL-2001, pp. 523–529.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Night</author>
</authors>
<title>A decoder for syntax-based statistical MT</title>
<date>2002</date>
<booktitle>In Proceedings ofACL-2002,</booktitle>
<pages>303--310</pages>
<marker>Yamada, Night, 2002</marker>
<rawString>K. Yamada and K. Night. 2002. A decoder for syntax-based statistical MT In Proceedings ofACL-2002, pp. 303–310.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>