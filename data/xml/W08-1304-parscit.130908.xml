<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021017">
<title confidence="0.988457">
Toward a cross-framework parser annotation standard
</title>
<author confidence="0.995495">
Dan Flickinger
</author>
<affiliation confidence="0.98797">
CSLI, Stanford University
</affiliation>
<email confidence="0.994896">
danf@stanford.edu
</email>
<sectionHeader confidence="0.993814" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999899333333333">
Efficient and precise comparison of parser
results across frameworks will require a
negotiated agreement on a target represen-
tation which embodies a good balance of
three competing dimensions: consistency,
clarity, and flexibility. The various annota-
tions provided in the COLING-08 shared
task for the ten ’required’ Wall Street Jour-
nal sentences can serve as a useful ba-
sis for these negotations. While there is
of course substantial overlap in the con-
tent of the various schemes for these sen-
tences, no one of the schemes is ideal.
This paper presents some desiderata for
a negotiated target annotation scheme for
which straightforward mappings can be
constructed from each of the supplied an-
notation schemes.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997805">
Efficient and precise comparison of parser results
across frameworks will require a negotiated agree-
ment on a target representation which embodies a
good balance of three competing dimensions: con-
sistency, clarity, and flexibility. The various anno-
tations provided in the COLING-08 shared task for
the ten ’required’ Wall Street Journal sentences can
serve as a useful basis for these negotations. While
there is of course substantial overlap in the content
of the various schemes for these sentences, no one
of the schemes is ideal, containing either too much
or too little detail, or sometimes both.
</bodyText>
<note confidence="0.728628">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.985545666666667">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<sectionHeader confidence="0.7345385" genericHeader="method">
2 Predicate-argument structures, not
labelled bracketings
</sectionHeader>
<bodyText confidence="0.990159485714286">
Competing linguistic frameworks can vary dramat-
ically in the syntactic structures they assign to sen-
tences, and this variation makes cross-framework
comparison of labelled bracketings difficult and
in the limit uninteresting. The syntactic struc-
tures of Combinatory Categorial Grammar (CCG:
Steedman (2000), Hockenmaier (2003), Clark and
Curran (2003)), for example, contrast sharply
with those of the Penn Treebank Marcus et al.
(1993), and the PTB structures differ in many less
dramatic though equally important details from
those assigned in Lexical Functional Grammar
(LFG: Bresnan and Kaplan (1982)) or Head-driven
Phrase Structure Grammar (HPSG: Pollard and
Sag (1994)). We even find variation in the assign-
ments of part-of-speech tags for individual tokens,
for example with words like “missionary” or “clas-
sical” treated as adjectives in some of the annota-
tions and as nouns in others. Furthermore, a sim-
ple labelled bracketing of surface tokens obscures
the fact that a single syntactic constituent can fill
multiple roles in the logical structure expressed
by a sentence, as with controlled subjects, relative
clauses, appositives, coordination, etc. More de-
tailed discussions of the obstacles to directly com-
paring syntactic structures include Preiss (2003),
Clark and Curran (2007), and most recently Sagae
et al. (2008).
Since it is this underlying logical content that
we seek when parsing a sentence, the target anno-
tation for cross-framework comparison should not
include marking of syntactic constituents, but fo-
cus instead on the predicate argument structures
determined by the syntactic analysis, as proposed
ten years ago by Carroll et al. (1998). Several of
</bodyText>
<page confidence="0.98721">
24
</page>
<reference confidence="0.308481">
Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 24–28
Manchester, August 2008
</reference>
<bodyText confidence="0.901173333333333">
the annotations provided in the shared task already
do this, providing a good set of starting points for
negotiating a common target.
</bodyText>
<sectionHeader confidence="0.952471" genericHeader="method">
3 General annotation characteristics
</sectionHeader>
<bodyText confidence="0.999128333333333">
Some of the issues in need of negotiation are quite
general in nature, while many others involve spe-
cific phenomena. First, the general ones:
</bodyText>
<subsectionHeader confidence="0.999317">
3.1 Unique identifiers
</subsectionHeader>
<bodyText confidence="0.999990607142857">
Since a given word can appear multiple times
within a single sentence, each token-derived el-
ement of the annotation needs a unique identi-
fier. Some of the supplied annotations use the to-
ken position in the sentence for this purpose, but
this is not general enough to support competing
hypotheses about the number of tokens in a sen-
tence. A sharp example of this is the word pixie-
like in sentence 56, which one of the annotations
(CONLL08) analyzes as two tokens, quite reason-
ably, since -like is a fully productive compound-
ing element. So a better candidate for the unique
identifier for each annotation element would be the
initial character position of the source token in the
original sentence, including spaces and punctua-
tion marks as characters. Thus in the sentence the
dog slept the annotation elements would be the-
1, dog-5, and slept-9. The original sentences in
this shared task were presented with spaces added
around punctuation, and before “n’t”. so the char-
acter positions for this task would be computed
taking this input as given. Using character posi-
tions rather than token positions would also better
accommodate differing treatments of multi-word
expressions, as for example with Los Angeles in
sentence 9, which most of the supplied schemes
annotate as two tokens with Los modifying Ange-
les, but which PARC treats as a single entity.
</bodyText>
<subsectionHeader confidence="0.99985">
3.2 One token in multiple roles
</subsectionHeader>
<bodyText confidence="0.997910269230769">
Most of the supplied annotations include some no-
tational convention to record the fact that (a phrase
headed by) a single token can fill more than one
logical role at the predicate-argument level of rep-
resentation. This is clear for controlled subjects
as in the one for play in sentence 53: “doesn’t
have to play...concertos”, and equally clear for the
missing objects in tough-type adjective phrases,
like the object of apply in sentence 133: “impos-
sible to apply”. This multiple filling of roles by
a single syntactic constituent can be readily ex-
pressed in a target annotation of the predicate argu-
ment structure if the token heading that constituent
bears the unique positional identifier which has al-
ready been motivated above. Supplied annotation
schemes that already directly employ this approach
include PARC and Stanford, and the necessary
positional information is also readily available in
the CCG-PA, HPSG-PA, and CONLL08 schemes,
though not in the RASP-GR or PTB notations. It
will be desirable to employ this same convention
for the logical dependencies in other constructions
with missing arguments, including relative clauses,
other unbounded dependencies like questions, and
comparative constructions like sentence 608’s than
President Bush has allowed .
</bodyText>
<subsectionHeader confidence="0.998861">
3.3 Stem vs surface form
</subsectionHeader>
<bodyText confidence="0.999983083333333">
Some of the supplied annotations (CCG-PA,
RASP-GR, and Stanford) simply use the surface
forms of the tokens as the elements of relations,
while most of the others identify the stem forms
for each token. While stemming might introduce
an additional source of inconsistency in the anno-
tations, the resulting annotations will be better nor-
malized if the stems rather than the surface forms
of words are used. This normalization would also
open the door to making such annotations more
suitable for validation by reasoning engines, or for
later word-sense annotation, or for applications.
</bodyText>
<subsectionHeader confidence="0.998029">
3.4 Identification of root
</subsectionHeader>
<bodyText confidence="0.9999744">
Most but not all of the supplied annotation
schemes identify which token supplies the outer-
most predication for the sentence, either directly
or indirectly. An explicit marking of this outer-
most element, typically the finite verb of the main
clause of a sentence, should be included in the tar-
get annotation, since it avoids the spurious ambi-
guity found for example in the HPSG-PA annota-
tion for sentence 22, which looks like it would be
identical for both of the following two sentences:
</bodyText>
<listItem confidence="0.9997685">
• Not all those who wrote oppose the changes.
• Not all those who oppose the changes wrote.
</listItem>
<subsectionHeader confidence="0.639065">
3.5 Properties of entities and events
</subsectionHeader>
<bodyText confidence="0.9996896">
Some of the supplied annotation schemes include
information about morphosyntactically marked
properties of nouns and verbs, including person,
number, gender, tense, and aspect. Providing for
explicit marking of these properties in a common
</bodyText>
<page confidence="0.990618">
25
</page>
<bodyText confidence="0.999977826086957">
target annotation is desirable, at least to the level of
detail adopted by several of the supplied schemes.
While several of the supplied annotation
schemes marked some morphosyntactic properties
some of the time, the PARC annotation of positive
degree for all adjectives reminds us that it would be
useful to adopt a notion of default values for these
properties in the target annotation. These defaults
would be explicitly defined once, and then only
non-default values would need to be marked ex-
plicitly in the annotation for a given sentence. For
example, the PARC annotation marks the ’perf’
(perfect) attribute for a verb only when it has a
positive value, implicitly using the negative value
as the default. This use of defaults would improve
the readability of the target annotation without any
loss of information.
Marking of the contrast between declarative, in-
terrogative, and imperative clauses is included in
some but not all of the annotation schemes. Since
this contrast is highly salient and (almost always)
easily determined, it should be marked explicitly in
the target annotation, at least for the main clause.
</bodyText>
<subsectionHeader confidence="0.970207">
3.6 Named entities
</subsectionHeader>
<bodyText confidence="0.999965888888889">
The supplied annotations represent a variety of ap-
proaches to the treatment of named entities where
multiple tokens comprise the relevant noun phrase,
as in sentence 53’s “The oboist Heinz Holliger”.
Several schemes treat both oboist and Heinz sim-
ply as modifiers of Holliger, drawing no distinc-
tion between the two. The PARC and PTB anno-
tations identify Heinz Holliger as a named entity,
with oboist as a modifier, and only the CONLL08
scheme analyses this expression as an apposition,
with oboist as the head predicate of the whole PN.
Since complex proper names appear frequently
with modifiers and in apposition constructions, and
since competing syntactic and semantic analyses
can be argued for many such constituents, the tar-
get annotation should contain enough detail to il-
luminate the substantive differences without exag-
gerating them. Interestingly, this suggests that the
evaluation of a given analysis in comparison with a
gold standard in the target annotation may require
some computation of near-equivalence at least for
entities in complex noun phrases. If scheme A
treats Holliger as the head token for use in exter-
nal dependencies involving the above noun phrase,
while scheme B treats oboist as the head token, it
will be important in evaluation to exploit the fact
that both schemes each establish some relation be-
tween oboist and Holliger which can be interpreted
as substitutional equivalence with respect to those
external dependencies. This means that even when
a target annotation scheme has been agreed upon,
and a mapping defined to convert a native anno-
tated analyis into a target annotation, it will still be
necessary to create non-trivial software which can
evaluate the mapped analysis against a gold stan-
dard analysis.
</bodyText>
<sectionHeader confidence="0.917052" genericHeader="method">
4 Notational conventions to be negotiated
</sectionHeader>
<bodyText confidence="0.999791">
A number of notational conventions will have to be
negotiated for a common target annotation scheme,
ranging from quite general design decisions to de-
tails about very specific linguistic phenomena.
</bodyText>
<subsectionHeader confidence="0.999588">
4.1 Naming of arguments and relations
</subsectionHeader>
<bodyText confidence="0.999997814814815">
It seems plausible that agreement could be reached
quickly on the names for at least the core gram-
matical functions of subject, direct object, indirect
object, and verbal complement, and perhaps also
on the names for adjectival and adverbial modi-
fiers. Prepositions are more challenging, since they
are very often two-place relations, and often live
on the blurry border between arguments and ad-
juncts. For example, most of the supplied anno-
tation schemes treated the by-PP following moved
in sentence 608 as a marker for the logical subject
of the passive verb, but this was at least not clear
in the CCG-PA annotation. In sentence 56, there
was variation in how the from and to PPs were an-
notated, with CONLL08 making the two to PPs
dependents of the from PP rather than of the verb
range.
Some of the supplied annotation schemes in-
troduced reasonable but idiosyncratic names for
other frequently occurring relations or dependen-
cies such as relative clauses, appositives, noun-
noun compounds, and subordinate clauses. An in-
ventory of these frequently occurring phenomena
should be constructed, and a target name negoti-
ated for each, recognizing that there will always be
a long tail of less frequently occurring phenomena
where names will not (yet) have been negotiated.
</bodyText>
<subsectionHeader confidence="0.971172">
4.2 Coordination
</subsectionHeader>
<bodyText confidence="0.93090325">
Perhaps the single most frequent source of appar-
ent incompatibility in the supplied annotations for
the ten required sentences in this task involves co-
ordination. Some schemes, like HPSG-PA and
</bodyText>
<page confidence="0.990592">
26
</page>
<bodyText confidence="0.999937774193548">
Stanford, treat the first conjunct as the primary en-
tity which participates in other predications, with
the other conjunct(s) dependent on the first, though
even here they usually (but not always) distribute
conjoined verbal arguments with separate predica-
tions for each conjunct. Some schemes, like the
PTB, PARC, and RASP-GR, represent the group-
ing of three or more conjuncts as flat, while others
like the Stanford scheme represent them as pairs.
Most schemes make each conjunction word itself
explicit, but for example the PARC annotation of
866 marks only one occurrence of and even though
this three-part coordinate structure includes two
explicit conjunctions.
While the distribution of conjoined elements in
coordinate structures may be the most practical tar-
get annotation, it should at least be noted that this
approach will not accommodate collective read-
ings of coordinate NPs as in well-known examples
like “Tom and Mary carried the piano upstairs.”
But the alternative, to introduce a new conjoined
entity for every coordinate structure, may be too
abstract to find common support among develop-
ers of current annotation schemes, and perhaps not
worth the effort at present.
However, it should be possible to come to agree-
ment on how to annotate the distribution of con-
joined elements consistently, such that it is clear
both which elements are included in a coordinate
structure, and what role each plays in the relevant
predicate argument structures.
</bodyText>
<subsectionHeader confidence="0.996835">
4.3 Verb-particle expressions
</subsectionHeader>
<bodyText confidence="0.999979115384615">
Another phenomenon exhibited several times in
these ten sentences involves verb-particle expres-
sions, as with thrash out and perhaps also stop by.
Most of the supplied schemes distinguished this
dependency, but some simply treated the particle
as a modifier of the verb. It would be desirable
to explicitly distinguish in a target annotation the
contrast between stopped a session and stopped by
a session without having to hunt around in the an-
notation to see if there happens to be a modifier of
stop that would dramaticaly change its meaning.
The example with stop by a session also high-
lights the need for an annotation scheme which lo-
calizes the differences between competing analy-
ses where possible. Though all of the supplied an-
notations treat by as a particle just like up in “look
up the answer”, in fact by fails the clearest test for
being a particle, namely the ability to appear after
the NP argument: “*He stopped the session by.”
An analysis treating “by the session” as a selected-
for PP with a semantically empty by might bet-
ter fit the linguistic facts, but the target annotation
could remain neutral about this syntactic debate if
it simply recorded the predicate as stop by, taking
an NP argument just as is usually done for the com-
plement of rely in “rely on us”.
</bodyText>
<subsectionHeader confidence="0.999242">
4.4 Less frequent phenomena
</subsectionHeader>
<bodyText confidence="0.999990571428571">
Since each new phenomenon encountered may
well require negotiation in order to arrive at a
common target annotation, it will be important to
include some provisional annotation for relations
that have not yet been negotiated. Even these
ten example sentences include a few expressions
where there was little or no agreement among the
schemes about the annotations, such as “if not
more so” in sentence 30, or “to be autographed”
in sentence 216. It would be convenient if the
target annotation scheme included a noncommittal
representation for some parts of a given sentence
explicitly noting the lack of clarity about what the
structure should be.
</bodyText>
<subsectionHeader confidence="0.710726">
4.5 Productive derivational morphology
</subsectionHeader>
<bodyText confidence="0.9999935">
It was surprising that only one of the annota-
tion schemes (CONLL08) explicitly annotated the
nominal gerund conducting in sentence 53 as pro-
ductively related to the verb conduct.. While the
issue of derivational morphology is of course a
slippery slope, the completely productive gerund-
forming process in English should be accommo-
dated in any target annotation scheme, as should a
small number of other highly productive and mor-
phologically marked derivational regularities, in-
cluding participial verbs used as prenominal mod-
ifiers, and comparative and superlative adjectives.
Including this stemming would provide an infor-
mative level of detail in the target annotation, and
one which can almost always be readily deter-
mined from the syntactic context.
</bodyText>
<sectionHeader confidence="0.996272" genericHeader="conclusions">
5 Next steps
</sectionHeader>
<bodyText confidence="0.999833571428571">
The existing annotation schemes supplied for this
task exhibit substantial common ground in the
nature and level of detail of information being
recorded, making plausible the idea of investing a
modest amount of joint effort to negotiate a com-
mon target representation which addresses at least
some of the issues identified here. The initial com-
</bodyText>
<page confidence="0.992673">
27
</page>
<bodyText confidence="0.999056">
mon target annotation scheme should be one which
has the following properties:
</bodyText>
<listItem confidence="0.917427666666667">
• Each existing scheme’s annotations can be
readily mapped to those of the target scheme
via an automatic procedure.
• The annotations appear in compact, humanly
readable form as sets of tuples recording
either predicate-argument dependencies or
properties of entities and events, such as num-
ber and tense.
• The inventory of recorded distinctions is rich
</listItem>
<bodyText confidence="0.9973041">
enough to accommodate most of what any
one scheme records, though it may not be
a superset of all such distinctions. For ex-
ample, some scheme might record quantifier
scope information, yet the target annotation
scheme might not, either because it is not of
high priority for most participants, or because
it would be difficult to produce consistently in
a gold standard.
The primary purposes of such a target annotation
scheme should be to facilitate the automatic com-
parison of results across frameworks, and to sup-
port evaluation of results against gold standard
analyses expressed in this target scheme. It might
also be possible to define the scheme such that the
target annotations contain enough information to
serve as the basis for some application-level tasks
such as reasoning, but the primary design criteria
should be to enable detailed comparison of analy-
ses.
</bodyText>
<sectionHeader confidence="0.999276" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999160625">
Bresnan, Joan and Ronald M. Kaplan, 1982. Lexical-
Functional Grammar. A Formal System for Gram-
matical Representation. The Mental Representation
of Grammatical Relations, ed. Joan Bresnan. MIT
Press, Cambridge, MA.
Carroll, John, Edward Briscoe and Antonio Sanfilippo.
1998. Parser evaluation: a survey and a new pro-
posal. Proceedings of the 1st International Confer-
ence on Language Resources and Evaluation.
Clark, Stephen and James R. Curran. 2003. Log-linear
models for wide-coverage CCG parsing. Proceed-
ings of the 2003 conference on Empirical methods in
natural language processing, pp.97–104.
Clark, Stephen and James R. Curran. 2007.
Formalism-Independent Parser Evaluation with
CCG and DepBank. Proceedings of the Association
for Computational Linguistics 2007.
Harrison, P., S. Abney, D. Flickinger, C. Gdaniec,
R. Grishman, D. Hindle, B. Ingria, M. Marcus, B.
Santorini, , and T. Strzalkowski. 1991. Evaluat-
ing syntax performance of parser/grammars of En-
glish. Natural Language Processing Systems Eval-
uation Workshop, Technical Report RL- TR-91-6, J.
G. Neal and S. M. Walter, eds.
Hockenmaier, Julia. 2003. Data and Models for Sta-
tistical Parsing with Combinatory Categorial Gram-
mar. Ph.D. thesis, University of Edinburgh.
Marcus, Mitchell P., Beatrice Santorini and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English. The Penn Treebank. Computa-
tional Linguistics 19:313–330.
Pollard, Carl and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press and CSLI Publications, Chicago, IL
and Stanford, CA.
Preiss, Judita. 2003. Using Grammatical Relations to
Compare Parsers. Proceedings of the European As-
sociation for Computational Linguistics 2003.
Sagae, Kenji, Yusuke Miyao, Takuya Matsuzaki and
Jun’ichi Tsujii. 2008. Challenges in Map-
ping of Syntactic Representations for Framework-
Independent Parser Evaluation. Proceedings of the
Workshop on Automated Syntatic Annotationsfor In-
teroperable Language Resources at the 1st Inter-
national Conference on Global Interoperability for
Language Resources, pp.61–68.
Steedman, Mark. 2000. The syntactic process. MIT
Press, Cambridge, MA.
</reference>
<page confidence="0.999071">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.847759">
<title confidence="0.99937">Toward a cross-framework parser annotation standard</title>
<author confidence="0.999785">Dan Flickinger</author>
<address confidence="0.863781">CSLI, Stanford</address>
<email confidence="0.999868">danf@stanford.edu</email>
<abstract confidence="0.999053947368421">Efficient and precise comparison of parser results across frameworks will require a negotiated agreement on a target representation which embodies a good balance of three competing dimensions: consistency, clarity, and flexibility. The various annotations provided in the COLING-08 shared task for the ten ’required’ Wall Street Journal sentences can serve as a useful basis for these negotations. While there is of course substantial overlap in the content of the various schemes for these sentences, no one of the schemes is ideal. This paper presents some desiderata for a negotiated target annotation scheme for which straightforward mappings can be constructed from each of the supplied annotation schemes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2008</date>
<booktitle>Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,</booktitle>
<pages>24--28</pages>
<location>Manchester,</location>
<marker>2008</marker>
<rawString>Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 24–28 Manchester, August 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
<author>Ronald M Kaplan</author>
</authors>
<title>LexicalFunctional Grammar. A Formal System for Grammatical Representation. The Mental Representation of Grammatical Relations,</title>
<date>1982</date>
<editor>ed. Joan Bresnan.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2289" citStr="Bresnan and Kaplan (1982)" startWordPosition="329" endWordPosition="332">labelled bracketings Competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore, a simple labelled bracketing of surface tokens obscures the fact that a single syntactic constituent can fill multiple roles in the logical structure expressed by a sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. More detailed discussions of the obstacles</context>
</contexts>
<marker>Bresnan, Kaplan, 1982</marker>
<rawString>Bresnan, Joan and Ronald M. Kaplan, 1982. LexicalFunctional Grammar. A Formal System for Grammatical Representation. The Mental Representation of Grammatical Relations, ed. Joan Bresnan. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Edward Briscoe</author>
<author>Antonio Sanfilippo</author>
</authors>
<title>Parser evaluation: a survey and a new proposal.</title>
<date>1998</date>
<booktitle>Proceedings of the 1st International Conference on Language Resources and Evaluation.</booktitle>
<marker>Carroll, Briscoe, Sanfilippo, 1998</marker>
<rawString>Carroll, John, Edward Briscoe and Antonio Sanfilippo. 1998. Parser evaluation: a survey and a new proposal. Proceedings of the 1st International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Log-linear models for wide-coverage CCG parsing.</title>
<date>2003</date>
<booktitle>Proceedings of the 2003 conference on Empirical methods in natural language processing,</booktitle>
<pages>97--104</pages>
<contexts>
<context position="2036" citStr="Clark and Curran (2003)" startWordPosition="290" endWordPosition="293">o little detail, or sometimes both. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 2 Predicate-argument structures, not labelled bracketings Competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore, a simple labelled bracketing of surface tok</context>
</contexts>
<marker>Clark, Curran, 2003</marker>
<rawString>Clark, Stephen and James R. Curran. 2003. Log-linear models for wide-coverage CCG parsing. Proceedings of the 2003 conference on Empirical methods in natural language processing, pp.97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<date>2007</date>
<booktitle>Formalism-Independent Parser Evaluation with CCG and DepBank. Proceedings of the Association for Computational Linguistics</booktitle>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, Stephen and James R. Curran. 2007. Formalism-Independent Parser Evaluation with CCG and DepBank. Proceedings of the Association for Computational Linguistics 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Harrison</author>
<author>S Abney</author>
<author>D Flickinger</author>
<author>C Gdaniec</author>
<author>R Grishman</author>
<author>D Hindle</author>
<author>B Ingria</author>
<author>M Marcus</author>
<author>B Santorini</author>
</authors>
<title>Evaluating syntax performance of parser/grammars of English. Natural Language Processing Systems Evaluation Workshop,</title>
<date>1991</date>
<tech>Technical Report RL- TR-91-6,</tech>
<editor>J. G. Neal and S. M. Walter, eds.</editor>
<marker>Harrison, Abney, Flickinger, Gdaniec, Grishman, Hindle, Ingria, Marcus, Santorini, 1991</marker>
<rawString>Harrison, P., S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, D. Hindle, B. Ingria, M. Marcus, B. Santorini, , and T. Strzalkowski. 1991. Evaluating syntax performance of parser/grammars of English. Natural Language Processing Systems Evaluation Workshop, Technical Report RL- TR-91-6, J. G. Neal and S. M. Walter, eds.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and Models for Statistical Parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="2011" citStr="Hockenmaier (2003)" startWordPosition="288" endWordPosition="289">ither too much or too little detail, or sometimes both. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 2 Predicate-argument structures, not labelled bracketings Competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore, a simple labelled </context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Hockenmaier, Julia. 2003. Data and Models for Statistical Parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics</title>
<date>1993</date>
<contexts>
<context position="2121" citStr="Marcus et al. (1993)" startWordPosition="304" endWordPosition="307">ion-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 2 Predicate-argument structures, not labelled bracketings Competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore, a simple labelled bracketing of surface tokens obscures the fact that a single syntactic constituent can fill multiple roles in </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>The University of Chicago Press and CSLI Publications,</publisher>
<location>Chicago, IL and Stanford, CA.</location>
<contexts>
<context position="2360" citStr="Pollard and Sag (1994)" startWordPosition="339" endWordPosition="342"> in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore, a simple labelled bracketing of surface tokens obscures the fact that a single syntactic constituent can fill multiple roles in the logical structure expressed by a sentence, as with controlled subjects, relative clauses, appositives, coordination, etc. More detailed discussions of the obstacles to directly comparing syntactic structures include Preiss (2003), Clar</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, Carl and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. The University of Chicago Press and CSLI Publications, Chicago, IL and Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judita Preiss</author>
</authors>
<title>Using Grammatical Relations to Compare Parsers.</title>
<date>2003</date>
<booktitle>Proceedings of the European Association for Computational Linguistics</booktitle>
<marker>Preiss, 2003</marker>
<rawString>Preiss, Judita. 2003. Using Grammatical Relations to Compare Parsers. Proceedings of the European Association for Computational Linguistics 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Yusuke Miyao</author>
<author>Takuya Matsuzaki</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Challenges in Mapping of Syntactic Representations for FrameworkIndependent Parser Evaluation.</title>
<date>2008</date>
<booktitle>Proceedings of the Workshop on Automated Syntatic Annotationsfor Interoperable Language Resources at the 1st International Conference on Global Interoperability for Language Resources,</booktitle>
<pages>61--68</pages>
<marker>Sagae, Miyao, Matsuzaki, Tsujii, 2008</marker>
<rawString>Sagae, Kenji, Yusuke Miyao, Takuya Matsuzaki and Jun’ichi Tsujii. 2008. Challenges in Mapping of Syntactic Representations for FrameworkIndependent Parser Evaluation. Proceedings of the Workshop on Automated Syntatic Annotationsfor Interoperable Language Resources at the 1st International Conference on Global Interoperability for Language Resources, pp.61–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The syntactic process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1991" citStr="Steedman (2000)" startWordPosition="286" endWordPosition="287">eal, containing either too much or too little detail, or sometimes both. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 2 Predicate-argument structures, not labelled bracketings Competing linguistic frameworks can vary dramatically in the syntactic structures they assign to sentences, and this variation makes cross-framework comparison of labelled bracketings difficult and in the limit uninteresting. The syntactic structures of Combinatory Categorial Grammar (CCG: Steedman (2000), Hockenmaier (2003), Clark and Curran (2003)), for example, contrast sharply with those of the Penn Treebank Marcus et al. (1993), and the PTB structures differ in many less dramatic though equally important details from those assigned in Lexical Functional Grammar (LFG: Bresnan and Kaplan (1982)) or Head-driven Phrase Structure Grammar (HPSG: Pollard and Sag (1994)). We even find variation in the assignments of part-of-speech tags for individual tokens, for example with words like “missionary” or “classical” treated as adjectives in some of the annotations and as nouns in others. Furthermore</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000. The syntactic process. MIT Press, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>