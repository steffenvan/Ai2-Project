<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000671">
<title confidence="0.988988">
One Translation per Discourse
</title>
<author confidence="0.993592">
Marine Carpuat
</author>
<affiliation confidence="0.997168">
Center for Computational Learning Systems
Columbia University
</affiliation>
<address confidence="0.552533">
475 Riverside Drive, New York, NY 10115
</address>
<email confidence="0.999318">
marine@ccls.columbia.edu
</email>
<sectionHeader confidence="0.993909" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999595">
We revisit the one sense per discourse hypoth-
esis of Gale et al. in the context of machine
translation. Since a given sense can be lex-
icalized differently in translation, do we ob-
serve one translation per discourse? Analy-
sis of manual translations reveals that the hy-
pothesis still holds when using translations in
parallel text as sense annotation, thus con-
firming that translational differences repre-
sent useful sense distinctions. Analysis of
Statistical Machine Translation (SMT) out-
put showed that despite ignoring document
structure, the one translation per discourse hy-
pothesis is strongly supported in part because
of the low variability in SMT lexical choice.
More interestingly, cases where the hypoth-
esis does not hold can reveal lexical choice
errors. A preliminary study showed that en-
forcing the one translation per discourse con-
straint in SMT can potentially improve trans-
lation quality, and that SMT systems might
benefit from translating sentences within their
entire document context.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9992935">
The one sense per discourse hypothesis formulated
by Gale et al. (1992b) has proved to be a simple
yet powerful observation and has been successfully
used in word sense disambiguation (WSD) and re-
lated tasks (e.g., Yarowsky (1995); Agirre and Rigau
∗The author was partially funded by GALE DARPA Con-
tract No. HR0011-06-C-0023. Any opinions, findings and con-
clusions or recommendations expressed in this material are
those of the authors and do not necessarily reflect the views of
the Defense Advanced Research Projects Agency.
(1996)). In this paper, we investigate its potential
usefulness in the context of machine translation.
A growing body of work suggests that transla-
tional differences represent observable sense distinc-
tions that are useful in applications. In monolin-
gual WSD, word alignments in parallel corpora have
been successfully used as learning evidence (Resnik
and Yarowsky, 1999; Diab and Resnik, 2002; Ng
et al., 2003). In Statistical Machine Translation
(SMT), recent work shows that WSD helps trans-
lation quality when the WSD system directly uses
translation candidates as sense inventories (Carpuat
and Wu, 2007; Chan et al., 2007; Gim´enez and
M`arquez, 2007).
In this paper, we revisit the one sense per dis-
course hypothesis using word translations in paral-
lel text as senses. Our first goal is to empirically
evaluate whether the one translation per document
hypothesis holds on French-English reference cor-
pora, thus verifying whether translations exhibit the
same properties as monolingual senses. Our second
goal consists in evaluating whether the one trans-
lation per discourse hypothesis has the potential to
be as useful to statistical machine translation as the
one sense per discourse hypothesis to WSD. Cur-
rent Statistical Machine Translation (SMT) systems
translate one sentence at a time, ignoring any docu-
ment level information. Implementing a one trans-
lation per document constraint might help provide
consistency in translation for sentences drawn from
the same document.
After briefly discussing related work, we will
show that the one translation per discourse hypoth-
esis holds on automatic word alignments of manu-
ally translated data. Despite ignoring any informa-
tion beyond the sentential level, automatic SMT out-
</bodyText>
<page confidence="0.992381">
19
</page>
<note confidence="0.992152">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 19–27,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999301">
put also strongly exhibits the one translation per dis-
course property. In addition, we will show that hav-
ing more than one translation per discourse in SMT
output often reveals lexical choice errors, and that
enforcing the constraint might help improve overall
consistency across sentences and translation quality
throughout documents.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998061">
In the original one sense per discourse study, Gale
et al. (1992b) considered a sample of 9 polyse-
mous English words. A total of 5 judges were
showed pairs of concordance lines for these words
taken from Grolier’s Encyclopedia and asked to
identify whether they shared the same sense. Re-
sults strongly support the one sense per discourse
hypothesis: 94% of polysemous words drawn from
the same document have the same sense. The ex-
periment was replicated with the same conclusion
on the Brown corpus. Yarowsky (1995) successfully
used this observation as an approximate annotation
technique in an unsupervised WSD model.
A subsequent larger scale study of polysemy
based on the WordNet sense inventory in the SEM-
COR corpus does not support the hypothesis as
strongly (Krovetz, 1998). Only 77% of ambiguous
words have a single sense per discourse. Analysis
revealed that the one sense per discourse hypothesis
is only supported for homonymous senses and not
for finer-grained sense distinction.
In machine translation, discourse level informa-
tion has only been indirectly used by adaptation of
translation or language models to specific genre or
topics (e.g., Foster and Kuhn (2007); Koehn and
Schroeder (2007)). While phrase-based SMT mod-
els incorporate the one sense per collocation hypoth-
esis by attempting to translate phrases rather than
single words (Koehn et al., 2007), the one sense per
discourse hypothesis has not been explicitly used in
SMT modeling. Even the recent generation of SMT
models that explicitly use WSD modeling to per-
form lexical choice rely on sentence context rather
than wider document context and translate sentences
in isolation (Carpuat and Wu, 2007; Chan et al.,
2007; Gim´enez and M`arquez, 2007; Stroppa et al.,
2007; Specia et al., 2008). Other context-sensitive
SMT approaches (Gimpel and Smith, 2008) and
global lexical choice models (Bangalore et al., 2007)
also translate sentences independently.
</bodyText>
<sectionHeader confidence="0.6560225" genericHeader="method">
3 One translation per discourse in
reference translations
</sectionHeader>
<bodyText confidence="0.999983904761905">
In this section we investigate whether the one sense
per discourse hypothesis holds in translation. Does
one sense per discourse mean one translation per
discourse?
On the one hand, one translation per discourse
might be too strict a constraint to allow for variations
in lexicalization of a given sense. While a WSD task
produces a set of predefined sense labels, a single
sense might be correctly translated in many differ-
ent ways in a full sentence translation.
On the other hand, if the author of the source lan-
guage text is assumed to consistently use one sense
per word per document, translators might also prefer
consistent translations of the same source language
word throughout a document. In addition, translated
text tends to exhibit more regularities than original
text, as shown by machine learning approches to
discriminate between “translationese” and original
texts (Baroni and Bernardini, 2006) although pat-
terns of syntactic regularity seemed more informa-
tive than lexical choice for those experiments.
</bodyText>
<subsectionHeader confidence="0.999807">
3.1 Manual translation data
</subsectionHeader>
<bodyText confidence="0.999945277777778">
We will test the one translation per discourse hy-
pothesis on a corpus of French and English trans-
lations, using standard freely available MT data sets
and software.
We use a corpus of 90 French-English news arti-
cles made available for the WMT evaluations1. All
development data that contained article boundaries
were used. The data is split into two sets of about
27k words each as described in Table 1. The arti-
cles cover topics ranging from international and lo-
cal politics to sports and music. They are drawn
from a wide variety of newspapers and magazines
originally published in various European languages.
As a result, even though only a single English ref-
erence translation is available, it was produced by
several different interpreters. It would have been in-
teresting to perform this analysis with multiple ref-
erences, but this is unfortunately not possible with
</bodyText>
<footnote confidence="0.989101">
1http://www.statmt.org/wmt09/translation-task.html
</footnote>
<page confidence="0.979702">
20
</page>
<table confidence="0.999785857142857">
Test set Language Sentences Tokens Types Singletons
French 1070 27440 5958 3727
no. 1 English (ref) 1070 24544 5566 3342
English (SMT) 1070 24758 5075 2932
French 1080 27924 6150 3839
no. 2 English (ref) 1080 24825 5686 3414
English (SMT) 1080 25128 5240 3080
</table>
<tableCaption confidence="0.9606485">
Table 1: Data statistics for the bilingual corpus, including the French side, the manually translated English side (ref)
and the automatic English translations (SMT)
</tableCaption>
<bodyText confidence="0.995537142857143">
the French-English data currently available.
Since golden word-alignments are not available,
we automatically word align the corpus using stan-
dard SMT training techniques. Using IBM-4 align-
ment models learned on the large WMT training
corpus (see Section 4.1 for more details), we align
GIZA++(Och and Ney, 2003) to obtain the IBM-
4 alignments in both translation directions, expand
their intersection with additional links using the
grow-diag-final-and heuristic (Koehn et al., 2007).
This creates a total of 51660 alignment links, and
about 89% of French tokens are aligned to at least
one English token. Note that all links involving stop-
words are not considered for the rest of the study.
</bodyText>
<subsectionHeader confidence="0.998417">
3.2 One translation per discourse holds
</subsectionHeader>
<bodyText confidence="0.999979368421053">
For every French lemma that occurs more than once
in a document, we compute the number of English
translations. In order to allow for morphological and
syntactic variations, we compute those statistics us-
ing English lemmas obtained by running Treetagger
(Schmid, 1994) with the standard French and En-
glish parameter settings2. A higher level of general-
ization is introduced by conducting the same analy-
sis using stems, which are simply defined as 4-letter
prefixes.
We have a total of 2316 different lemma types and
6603 lemma-document pairs. The scale of this em-
pirical evaluation is much larger than in Gale et al.
(1992a) where only 9 target words were considered
and in Krovetz (1998) which used the entire SEM-
COR corpus vocabulary.
The resulting distribution of number of English
translations per French word-document pair is given
in the first half of Table 2. Remarkably, more than
</bodyText>
<footnote confidence="0.738168">
2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/
</footnote>
<bodyText confidence="0.9989801">
98% of the French lemmas are aligned to no more
than 2 English translations and 80% of French lem-
mas have a single translation per document. While
these numbers are not as high as the 94% agreement
reported by Gale et al. (1992b) in their empirical
study, they still strongly support the one translation
per discourse hypothesis.
Generalizing from lemmas to stems yields a 4.3
point increase in the percentage of French lemmas
with a single translation per document. Note that
using stems might yield to false positives since dif-
ferent words can share the same prefix, however,
since we only compare words that align to the same
French word in a given document, the amount of
noise introduced should be small. Manual inspec-
tion shows that this increase is often due to varia-
tions in the POS of the translation, more specifically
variations between noun and verb forms which share
the same 4-letter prefix as can be seen in the follow-
ing examples:
</bodyText>
<construct confidence="0.697215428571429">
verb vs. noun conclude vs. conclusion,
investigate vs. investigation,
apply vs. application, inject
vs. injection, establish vs.
establishment, criticize vs.
critism, recruit vs. recruitment,
regulate vs. regulation
</construct>
<subsectionHeader confidence="0.800585">
3.3 Exceptions: one sense but more than one
translation per discourse
</subsectionHeader>
<bodyText confidence="0.9996926">
We investigate what happens in the 15 to 20% of
cases where a French word is not consistenly trans-
lated throughout a document. Do these translation
differences reflect sense ambiguity in French, or are
they close variations in English lexical choice? For
</bodyText>
<page confidence="0.996662">
21
</page>
<table confidence="0.9994395">
reference SMT
lemmas stems lemmas stems
1 80.82% 85.14% 83.03% 86.38%
2 17.88% 13.91% 15.43% 12.47%
3 01.12% 00.95% 01.25% 00.85%
4 00.18% 00.00% 00.17% 00.22%
</table>
<tableCaption confidence="0.85247">
Table 2: Distribution of number of English translation per
document using the word-aligned reference translations
and the automatic SMT translations
</tableCaption>
<bodyText confidence="0.975678673076923">
a given French word, how semantically similar are
the various English translations?
We measure semantic similarity using the shortest
path length in WordNet (Fellbaum, 1998) as imple-
mented in the WordNet Similarity package (Peder-
sen et al., 2004). The path length is defined as the
number of WordNet nodes or synsets in a path be-
tween two words: words that belong to the same
synset therefore have a shortest path length of 1,
while words that are related via a common synonym,
hypernym or hyponym have a shortest path length of
2. Note that this similarity metric is only defined for
two WordNet vocabulary words of the same POS.
For 57% of the French lemmas with multiple
translations, those translations can be linked by a
WordNet path of no more than 4 nodes. In 19% of
the cases, the translations belong to the same synset,
another 19% are separated by a path of length 2 only.
Given that sense distinctions in WordNet are very
fine-grained, these numbers show that the transla-
tions have very similar meanings. In other words,
while the one sense per translation hypothesis does
not hold for those 57%, the one sense per discourse
hypothesis still holds.
Examples of those synonymous translations are
given below:
synonyms with SPL = 1 adjust and adapt,
earn and gain, movie and film,
education and training, holiday
and day
synonyms with SPL = 2 travel and
circulate, scientist and
researcher, investigation and
inquiry, leave and abandon,
witness and eyewitness
synonyms with SPL = 3 ratio and
proportion, quiet and peace, plane
and aircraft
3.4 Exceptions: more than one sense per
discourse
Among the words with a high WordNet path length
or no existing path, we find translations that are
not synonyms or semantically similar words, but re-
lated words sometimes with different POS. They fall
within two categories.
The first category is that of fine-grained sense dis-
tinctions for which the one sense per discourse hy-
pothesis has been showed to break for monolingual
WordNet sense distinctions Krovetz (1998). How-
ever, for those closely related words, it would be
possible to write correct English translations that use
the same English form throughout a document.
</bodyText>
<figureCaption confidence="0.789487333333333">
Nationality translation Tibet vs. Tibetan,
French vs. France, Paris vs.
Parisian, Europe vs. European,
French vs. Frenchman
Agent/entity policeman vs. police,
alderman vs. city
</figureCaption>
<bodyText confidence="0.999470291666666">
The second category of not identical but related
translations is explained by a limitation of our ex-
periment set-up: we are looking at single-word
translations while the translation of a longer mul-
tiword phrase should be considered as a whole. In
the following example, the French word ´emission
is aligned to both emission and greenhouse in
the same document, because French does not re-
peat the long phrase ´emission de gaz a` effet
de serre throughout the document, while the
more concise English translation greenhouse gas
emissions is used throughout:
Fr apr`es la p´eriode de r´eduction des
´emissions [...] la Hongrie a
pris l’engagement de r´eduire les
´emissions de gaz a` effet de serre
de 6 pour cent [...]
En [...] to cut greenhouse gas
emissions after 2012 [...]
Hungary agreed to cut its
greenhouse gas emissions by 6
percent [...]
Finally, there are a few rare instances where the
different translations for a French word reflect a
</bodyText>
<page confidence="0.982735">
22
</page>
<bodyText confidence="0.999576363636363">
sense distinction in French and could not be cor-
rectly translated in English with the same English
word. These are cases where both the one sense per
discourse hypothesis and the one translation per dis-
course break, and where it is not possible to para-
phrase the English sentences to fullfill either con-
straints. In these instances, the French word is
used in two different senses related by metonymy,
but the metonymy relation does not translate into
English and two non-synonym English words are
used as a result. For instance, the French word
bureau translates to both office and desk in the
same document, while retraite translates both to
retirement and pension.
We found a single instance where two homonym
senses of the French word coffre are in the same
sentence. This sentence seems to be a headline,
which suggests that the author or translator delib-
erately used the ambiguous repetition to attract the
attention of the reader.
Fr un coffre dans le coffre
En a trunk in the boot
</bodyText>
<sectionHeader confidence="0.912177" genericHeader="method">
4 One translation per discourse in SMT
</sectionHeader>
<bodyText confidence="0.999979555555556">
We now turn to empirically testing the one transla-
tion per discourse hypothesis on automatically trans-
lated text.
While there is an implicit assumption that a well-
written document produced by a human writer will
not introduce unncessary ambiguities, most SMT
systems translate one sentence at a time, without any
model of discourse or document. This might suggest
that the one translation per discourse hypothesis will
not be as strongly supported as by manual transla-
tions.
However, this effect might be compensated by the
tendency of automatically translated text to exhibit
little variety in lexical choice as MT systems tend to
produce very literal word for word translations. As
can be seen in Table 1 the reference translations use
a larger vocabulary than the automatic translations
for the same text.
</bodyText>
<subsectionHeader confidence="0.998141">
4.1 Automatically translated data
</subsectionHeader>
<bodyText confidence="0.999983791666667">
We build a standard SMT system and automatically
translate the data set described in Section 3.1. We
strictly follow the instructions for building a phrase-
based SMT system that is close to the state-of-the-
art in the WMT evaluations3, using the large training
sets of about 460M words from Europarl and news.
We use the Moses phrase-based statistical ma-
chine translation system (Koehn et al., 2007) and
follow standard training, tuning and decoding strate-
gies. The translation model consists of a stan-
dard Moses phrase-table with lexicalized reorder-
ing. Bidirectional GIZA++ word alignments are
intersected using the grow-diag-final-and heuristic.
Translations of phrases of up to 7 words long are
collected and scored with translation probilities and
lexical weighting. The English language model is
a 4-gram model with Kneser-Ney smoothing, built
with the SRI language modeling toolkit (Stolcke,
2002).
The word alignment between French input sen-
tences and English SMT output is easily obtained
as a by-product of decoding. We have a total of
56003 alignment links, and 96% of French tokens
are linked to a least one English translation.
</bodyText>
<subsectionHeader confidence="0.984316">
4.2 One translation per discourse holds
</subsectionHeader>
<bodyText confidence="0.999920857142857">
We perform the same analysis as for the manual
translations. The distribution of the number of trans-
lations for a given French word that occurs repeat-
edly in a document still strongly supports the one
translation per document hypothesis (Table 2). In
fact, SMT lexical choice seems to be more regular
than in manual translations.
</bodyText>
<subsectionHeader confidence="0.638642">
4.3 Exceptions: where SMT and reference
disagree
</subsectionHeader>
<bodyText confidence="0.999971166666667">
Again, it is interesting to look at instances where the
hypothesis is not verified. We will not focus on the
exceptions that fall in the categories previously ob-
served in Section 3. Instead, we take a closer look
at cases where the reference consistently uses the
same English translation, while SMT selects differ-
ent translation candidates.
There are cases where the SMT system arbitrar-
ily chooses different synonymous translation candi-
dates for the same word in different sentences. This
is not incorrect but will affect translation quality
as measured by automatic metrics which compare
</bodyText>
<footnote confidence="0.93415">
3http://www.statmt.org/wmt09/baseline.html
</footnote>
<page confidence="0.991515">
23
</page>
<table confidence="0.999712636363636">
Test set Decoding Input METEOR BLEU NIST
Moses 49.05 20.45 6.135
+postprocess (transprob) 48.73 19.93 6.064
+postprocess (bestmatch) 50.01 20.64 6.220
no. 1 +decode (transprob) 49.04 20.44 6.128
+decode (bestmatch) 49.36 20.70 6.179
Moses 49.60 21.10 6.211
+postprocess (transprob) 49.20 20.43 6.128
+postprocess (bestmatch) 50.56 21.19 6.291
no. 2 +decode (transprob) 49.58 21.02 6.201
+decode (bestmatch) 50.60 21.21 6.243
</table>
<tableCaption confidence="0.989504">
Table 3: Enforcing one translation per discourse can help METEOR, BLEU and NIST scores when using the super-
vised sense disambiguation technique (bestmatch). Relying on the unsupervised context-independent SMT translation
probabilities (transprob) does not help.
</tableCaption>
<bodyText confidence="0.99406252631579">
matches between SMT output and manually trans-
lated references. For instance, in a single docu-
ment, the French agents pathog`enes translates
to both (1) pathogens and (2) disease-causing
agents while the reference consistently translates
to pathogens. Similarly, the French phrase parmi
les d´etenus is inconsistently translated to among
detainees and among those arrested in the
same document.
Synonym translations detainees vs.
arrested, apartment vs. flat,
good vs. beautiful, unit vs.
cell
However, the majority of differences in trans-
lation reflect lexical choice errors. For in-
stance, the French adjective biologique is in-
correctly disambiguated as organic in the phrase
fille biologique which should be translated as
biological daughter.
</bodyText>
<subsectionHeader confidence="0.422083">
SMT lexical choice errors conseiller:
</subsectionHeader>
<figureCaption confidence="0.870339571428571">
advisor vs. councillor,
arrondissement: district vs.
rounding-off, bal: ball vs.
court, biologique: biological vs.
organic, assurance: insurance vs.
assurance, franchise: frankness
vs. deductible
</figureCaption>
<bodyText confidence="0.999761166666667">
While some of those translation distinctions can
be explained by differences in topics, all of those
French words occur in a large number of documents
and cannot be disambiguated by topic alone. This
suggests that local sentential context is not sufficient
to correctly disambiguate translation candidates.
</bodyText>
<sectionHeader confidence="0.974689" genericHeader="method">
5 Detecting SMT errors
</sectionHeader>
<bodyText confidence="0.999964375">
Based on the observations from the previous sec-
tion, we further evaluate whether breaking the one
translation per discourse hypothesis is indicative of
a translation error. For this purpose, we attempt to
correct the translations provided by the Moses SMT
system by enforcing the one translation per dis-
course constraint and evaluate the impact on trans-
lation quality.
</bodyText>
<subsectionHeader confidence="0.995353">
5.1 Enforcing one translation per discourse
</subsectionHeader>
<bodyText confidence="0.999988">
In order to get a sense of the potential impact of the
one translation per discourse constraint in SMT, we
attempt to enforce it using two simple postprocess-
ing techniques.
First, we select a set of French words which
are not consistently translated to a single English
words in a given document. We apply a document
frequency-based filter to select content words for
each document. This yields a set of 595 French tar-
get word types occurring in a total of 89 documents.
Second, we propose a single English translation
for all the occurrences of the French target in a
document. We used two different strategies: (1)
the fully unsupervised strategy consists in select-
ing the translation with highest probability among
those produced by the baseline SMT system, and
</bodyText>
<page confidence="0.976995">
24
</page>
<bodyText confidence="0.9042175">
Moses Young people under 25 years face various drawbacks when a contract with an assurance at
+postprocess an accessible price , as can be the low experience in the conduct and seniority of driving
licences.
young people under 25 years against various drawbacks when a contract with an insurance
at an accessible price, as can be the small experience in the conduct and seniority of driving
licences.
Moses drivers the most far-sighted can opt for insurance any risk with frankness , so that they get
+postprocess blankets insurance to any risk but at a price more accessible.
drivers the most far-sighted can opt for insurance any risk with exemption , so that they get
blankets insurance to any risk but at a price more accessible.
Moses “ These ill are isolated , nurses puts gloves rubber and masks of protection and we have
+postprocess antibiotics adapted to treat them, ” said Tibor Nyulasi .
“ These patient are isolated, personnel puts gloves rubber and masks of protection and we
have antibiotics appropriate to treat them, ” say Tibor Nyulasi .
Moses according to the Ministry of Defence, they also served to make known to the public the real
+postprocess aims of the presence of the army abroad.
according to the Ministry of Defence , they also use to make known to the public the real
purpose of the presence of the army abroad.
Moses the public authorities also prepare Christmas .
+postprocess the public authorities also puritan Christmas .
</bodyText>
<tableCaption confidence="0.897253">
Table 4: Examples of translation improvement (bold) and degradation (italics) by enforcing the one translation per
discourse constraint through postprocessing
</tableCaption>
<bodyText confidence="0.99573455">
(2) the supervised strategy picks, among the base-
line SMT translations, the one that matches the ref-
erence. Note that the supervised strategy does not
predict perfect translations, but an approximation of
the golden translations: in addition to noise in word
alignments due to phrasal translations, the transla-
tions selected are lemmas that might not be in the
correctly inflected form for use in the full sentence
translation.
Third, we integrate the selected translation candi-
dates by (1) postprocessing the baseline SMT out-
put - the translations of the French target word are
simply replaced by the recommended translation,
and (2) encouraging the SMT system to choose the
recommended translations by annotating SMT in-
put using the xml input markup scheme - again,
this approach is not optimal as it introduces ad-
ditional translation candidates without probability
scores and forces single word translation to compete
with phrasal translation even if they are consistent.
</bodyText>
<subsectionHeader confidence="0.999414">
5.2 Impact on translation quality
</subsectionHeader>
<bodyText confidence="0.999989909090909">
As reported in Table 3, small increases in METEOR
(Banerjee and Lavie, 2005), BLEU (Papineni et al.,
2002) and NIST scores (Doddington, 2002) suggest
that SMT output matches the references better af-
ter postprocessing or decoding with the suggested
lemma translations. Examples of both improved and
degraded lexical choice are given in Table 4.
Since we are modifying translations for a limited
set of single-words only, only 10% to 30% of the test
set sentences are translated differently. We manu-
ally inspected a random sample of 100 of those sen-
tence pairs for two different systems: postprocess
(bestmatch) and decode (bestmatch). For each sen-
tence pair, we determined whether the “one sense
per discourse” processing improved, degraded or
made no difference in translation quality compared
to the baseline Moses output. Among the sentence
pairs where a real change in translation quality was
observed, the postprocessing heuristic yielded im-
provements in 62.5% (decode) and 64.5% (postpro-
cess) of sentences considered. For 41% (decode)
and 57% (postprocess) of the sentences in the sam-
</bodyText>
<page confidence="0.992844">
25
</page>
<bodyText confidence="0.999434285714286">
ple, changes only consisted of synonym substitution,
morphological variations or local reorderings which
did not impact translation quality.
Taken together, these results suggest that the “one
sense per discourse” constraint should be useful to
SMT and that it would be worthwile to integrate it
directly into SMT modeling.
</bodyText>
<sectionHeader confidence="0.999172" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99999668">
We investigated the one sense per discourse hy-
pothesis (Gale et al., 1992b) in the context of ma-
chine translation. Analysis of manual translations
showed that the hypothesis still holds when using
translations in parallel text as sense annotation, thus
confirming that translational differences represent
useful sense distinctions. Analysis of SMT out-
put showed that despite ignoring document struc-
ture, the one translation per discourse hypothesis is
strongly supported in part because of the low vari-
ability in SMT lexical choice. More interestingly,
cases where the hypothesis does not hold can re-
veal lexical choice errors in an unsupervised fash-
ion. A preliminary study showed that enforcing
the one translation per discourse constraint in SMT
can potentially improve translation quality, and that
SMT systems might benefit from translating sen-
tences within their entire document context.
In future work, we will (1) evaluate whether one
translation per discourse holds for other language
pairs such as Arabic-English and Chinese-English,
which are not as closely related as French-English
and for which multiple reference corpora are avail-
able, and (2) directly implement the one translation
per discourse constraint within SMT.
</bodyText>
<sectionHeader confidence="0.973896" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.7681034">
Eneko Agirre and German Rigau. Word sense dis-
ambiguation using conceptual density. In Pro-
ceedings of COLING’96, pages 16–22, Copen-
hagen, Denmark, 1996.
Satanjeev Banerjee and Alon Lavie. METEOR:
An automatic metric for MT evaluation with im-
proved correlation with human judgement. In
Proceedings of Workshop on Intrinsic and Extrin-
sic Evaluation Measures for MT and/or Summa-
rization at the 43th Annual Meeting of the Associ-
</bodyText>
<reference confidence="0.9930234">
ation of Computational Linguistics (ACL-2005),
Ann Arbor, Michigan, June 2005.
Srinivas Bangalore, Patrick Haffner, and Stephan
Kanthak. Statistical machine translation through
global lexical selection and sentence reconstruc-
tion. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics,
pages 152–159, Prague, Czech Republic, June
2007. Association for Computational Linguistics.
Marco Baroni and Silvia Bernardini. A new ap-
proach to the study of translationese: Machine-
learning the difference between original and
translated text. Literary and Linguistic Comput-
ing, 21(3):259–274, 2006.
Marine Carpuat and Dekai Wu. Improving statis-
tical machine translation using word sense dis-
ambiguation. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural
Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL 2007),
pages 61–72, Prague, June 2007.
Yee Seng Chan, Hwee Tou Ng, and David Chi-
ang. Word sense disambiguation improves statis-
tical machine translation. In 45th Annual Meeting
of the Association for Computational Linguistics
(ACL-07), Prague, June 2007.
Mona Diab and Philip Resnik. An unsupervised
method for word sense tagging using parallel text.
In Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics, pages
255–262, Philadelphia, Pennsylvania, July 2002.
George Doddington. Automatic evaluation of
machine translation quality using n-gram co-
occurrence statistics. In Proceedings of the
Human Language Technology conference (HLT-
2002), San Diego, CA, 2002.
Christiane Fellbaum, editor. WordNet: An Elec-
tronic Lexical Database. MIT Press, 1998.
George Foster and Roland Kuhn. Mixture-model
adaptation for SMT. In Proceedings of the Sec-
ond Workshop on Statistical Machine Translation,
pages 128–135, Prague, Czech Republic, June
2007.
William A. Gale, Kenneth W. Church, and David
Yarowsky. A method for disambiguating word
</reference>
<page confidence="0.9492">
26
</page>
<reference confidence="0.999568125">
senses in a large corpus. Computers and the Hu-
manities, 26:415–439, 1992.
William A. Gale, Kenneth W. Church, and David
Yarowsky. One sense per discourse. In Proceed-
ings of the workshop on Speech and Natural Lan-
guage, Harriman, NY, February 1992.
Jes´us Gim´enez and Lluis M`arquez. Context-aware
discriminative phrase selection for statistical ma-
chine translation. In Workshop on Statistical Ma-
chine Translation, Prague, June 2007.
Kevin Gimpel and Noah Smith. Rich source-
side context for statistical machine translation.
In Workshop on Statistical Machine Translation,
Columbus, Ohio, June 2008.
Philipp Koehn and Josh Schroeder. Experiments in
domain adaptation for statistical machine transla-
tion. In Workshop on Statistical Machine Trans-
lation, Prague, June 2007.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. Moses:
Open source toolkit for statistical machine trans-
lation. In Annual Meeting of the Association for
Computational Linguistics (ACL), demonstration
session, Prague, Czech Republic, June 2007.
Robert Krovetz. More than one sense per discourse.
In NEC Princeton NJ Labs., Research Memoran-
dum, 1998.
Hwee Tou Ng, Bin Wang, and Yee Seng Chan. Ex-
ploiting parallel texts for word sense disambigua-
tion: An empirical study. In Proceedings of ACL-
03, Sapporo, Japan, pages 455–462, 2003.
Franz Josef Och and Hermann Ney. A system-
atic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–52,
2003.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, 2002.
Ted Pedersen, Siddharth Patwardhan, and Jason
Michelizzi. WordNet::Similarity - Measuring the
relatedness of concepts. In Proceedings of Fifth
Annual Meeting of the North American Chap-
ter of the Association for Computational Linguis-
tics (NAACL-04), pages 38–41, Boston, MA, May
2004.
Philip Resnik and David Yarowsky. Distinguising
systems and distinguishing senses: New evalua-
tion methods for word sense disambiguation. Nat-
ural Language Engineering, 5(2):113–133, 1999.
Helmut Schmid. Probabilistic part–of–speech tag-
ging using decision trees. In Proceedings of the
Conference on New Methods in Language Pro-
cessin, pages 44–49, Manchester, UK, 1994.
Lucia Specia, Baskaran Sankaran, and Maria das
Grac¸as Volpe Nunes. n-best reranking for the ef-
ficient integration of word sense disambiguation
and statistical machine translation. In Proceed-
ings of the Conference on Computational Linguis-
tics and Intelligent Text Processing (CICLing’08),
Haifa, Israel, February 2008.
Andreas Stolcke. SRILM—an extensible language
modeling toolkit. In International Conference on
Spoken Language Processing, Denver, Colorado,
September 2002.
Nicolas Stroppa, Antal van den Bosch, and Andy
Way. Exploiting source similarity for smt using
context-informed features. In Proceedings of the
11th Conference on Theoretical and Methodolog-
ical Issues in Machine Translation (TMI 2007),
Skovde, Sweden, September 2007.
David Yarowsky. Unsupervised word sense disam-
biguation rivaling supervised methods. In Pro-
ceedings of the 33rd Annual Meeting of the As-
sociation for Computational Linguistics, pages
189–196, Cambridge, MA, 1995.
</reference>
<page confidence="0.998809">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.536034">
<title confidence="0.999208">One Translation per Discourse</title>
<author confidence="0.971667">Marine</author>
<affiliation confidence="0.781427">Center for Computational Learning Columbia</affiliation>
<address confidence="0.998815">475 Riverside Drive, New York, NY</address>
<email confidence="0.998963">marine@ccls.columbia.edu</email>
<abstract confidence="0.999221625">We revisit the one sense per discourse hypothof Gale al. the context of machine translation. Since a given sense can be lexicalized differently in translation, do we observe one translation per discourse? Analysis of manual translations reveals that the hypothesis still holds when using translations in parallel text as sense annotation, thus confirming that translational differences represent useful sense distinctions. Analysis of Statistical Machine Translation (SMT) output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors. A preliminary study showed that enforcing the one translation per discourse constraint in SMT can potentially improve translation quality, and that SMT systems might benefit from translating sentences within their entire document context.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2005</date>
<booktitle>ation of Computational Linguistics (ACL-2005),</booktitle>
<location>Ann Arbor, Michigan,</location>
<marker>2005</marker>
<rawString>ation of Computational Linguistics (ACL-2005), Ann Arbor, Michigan, June 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Patrick Haffner</author>
<author>Stephan Kanthak</author>
</authors>
<title>Statistical machine translation through global lexical selection and sentence reconstruction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>152--159</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5902" citStr="Bangalore et al., 2007" startWordPosition="904" endWordPosition="907">collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approaches (Gimpel and Smith, 2008) and global lexical choice models (Bangalore et al., 2007) also translate sentences independently. 3 One translation per discourse in reference translations In this section we investigate whether the one sense per discourse hypothesis holds in translation. Does one sense per discourse mean one translation per discourse? On the one hand, one translation per discourse might be too strict a constraint to allow for variations in lexicalization of a given sense. While a WSD task produces a set of predefined sense labels, a single sense might be correctly translated in many different ways in a full sentence translation. On the other hand, if the author of </context>
</contexts>
<marker>Bangalore, Haffner, Kanthak, 2007</marker>
<rawString>Srinivas Bangalore, Patrick Haffner, and Stephan Kanthak. Statistical machine translation through global lexical selection and sentence reconstruction. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 152–159, Prague, Czech Republic, June 2007. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>A new approach to the study of translationese: Machinelearning the difference between original and translated text.</title>
<date>2006</date>
<journal>Literary and Linguistic Computing,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="6913" citStr="Baroni and Bernardini, 2006" startWordPosition="1061" endWordPosition="1064">on of a given sense. While a WSD task produces a set of predefined sense labels, a single sense might be correctly translated in many different ways in a full sentence translation. On the other hand, if the author of the source language text is assumed to consistently use one sense per word per document, translators might also prefer consistent translations of the same source language word throughout a document. In addition, translated text tends to exhibit more regularities than original text, as shown by machine learning approches to discriminate between “translationese” and original texts (Baroni and Bernardini, 2006) although patterns of syntactic regularity seemed more informative than lexical choice for those experiments. 3.1 Manual translation data We will test the one translation per discourse hypothesis on a corpus of French and English translations, using standard freely available MT data sets and software. We use a corpus of 90 French-English news articles made available for the WMT evaluations1. All development data that contained article boundaries were used. The data is split into two sets of about 27k words each as described in Table 1. The articles cover topics ranging from international and l</context>
</contexts>
<marker>Baroni, Bernardini, 2006</marker>
<rawString>Marco Baroni and Silvia Bernardini. A new approach to the study of translationese: Machinelearning the difference between original and translated text. Literary and Linguistic Computing, 21(3):259–274, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>61--72</pages>
<location>Prague,</location>
<contexts>
<context position="2334" citStr="Carpuat and Wu, 2007" startWordPosition="352" endWordPosition="355">ects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have been successfully used as learning evidence (Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007). In this paper, we revisit the one sense per discourse hypothesis using word translations in parallel text as senses. Our first goal is to empirically evaluate whether the one translation per document hypothesis holds on French-English reference corpora, thus verifying whether translations exhibit the same properties as monolingual senses. Our second goal consists in evaluating whether the one translation per discourse hypothesis has the potential to be as useful to statistical machine translation as the one sense per discourse hypothesis to WS</context>
<context position="5687" citStr="Carpuat and Wu, 2007" startWordPosition="871" endWordPosition="874">indirectly used by adaptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approaches (Gimpel and Smith, 2008) and global lexical choice models (Bangalore et al., 2007) also translate sentences independently. 3 One translation per discourse in reference translations In this section we investigate whether the one sense per discourse hypothesis holds in translation. Does one sense per discourse mean one translation per discourse? On the one hand, one translation per discourse might be too strict a constraint to allow for variations in lexicalization</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 61–72, Prague, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In 45th Annual Meeting of the Association for Computational Linguistics (ACL-07),</booktitle>
<location>Prague,</location>
<contexts>
<context position="2353" citStr="Chan et al., 2007" startWordPosition="356" endWordPosition="359">In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have been successfully used as learning evidence (Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007). In this paper, we revisit the one sense per discourse hypothesis using word translations in parallel text as senses. Our first goal is to empirically evaluate whether the one translation per document hypothesis holds on French-English reference corpora, thus verifying whether translations exhibit the same properties as monolingual senses. Our second goal consists in evaluating whether the one translation per discourse hypothesis has the potential to be as useful to statistical machine translation as the one sense per discourse hypothesis to WSD. Current Statisti</context>
<context position="5706" citStr="Chan et al., 2007" startWordPosition="875" endWordPosition="878">ptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approaches (Gimpel and Smith, 2008) and global lexical choice models (Bangalore et al., 2007) also translate sentences independently. 3 One translation per discourse in reference translations In this section we investigate whether the one sense per discourse hypothesis holds in translation. Does one sense per discourse mean one translation per discourse? On the one hand, one translation per discourse might be too strict a constraint to allow for variations in lexicalization of a given sense. </context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. Word sense disambiguation improves statistical machine translation. In 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), Prague, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Philip Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel text.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>255--262</pages>
<location>Philadelphia, Pennsylvania,</location>
<contexts>
<context position="2120" citStr="Diab and Resnik, 2002" startWordPosition="319" endWordPosition="322">ract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have been successfully used as learning evidence (Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007). In this paper, we revisit the one sense per discourse hypothesis using word translations in parallel text as senses. Our first goal is to empirically evaluate whether the one translation per document hypothesis holds on French-English reference corpora, thus verifying whether translations exhibit the same properties as monolingual se</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>Mona Diab and Philip Resnik. An unsupervised method for word sense tagging using parallel text. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 255–262, Philadelphia, Pennsylvania, July 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology conference (HLT2002),</booktitle>
<location>San Diego, CA,</location>
<contexts>
<context position="25192" citStr="Doddington, 2002" startWordPosition="3976" endWordPosition="3977">he translations of the French target word are simply replaced by the recommended translation, and (2) encouraging the SMT system to choose the recommended translations by annotating SMT input using the xml input markup scheme - again, this approach is not optimal as it introduces additional translation candidates without probability scores and forces single word translation to compete with phrasal translation even if they are consistent. 5.2 Impact on translation quality As reported in Table 3, small increases in METEOR (Banerjee and Lavie, 2005), BLEU (Papineni et al., 2002) and NIST scores (Doddington, 2002) suggest that SMT output matches the references better after postprocessing or decoding with the suggested lemma translations. Examples of both improved and degraded lexical choice are given in Table 4. Since we are modifying translations for a limited set of single-words only, only 10% to 30% of the test set sentences are translated differently. We manually inspected a random sample of 100 of those sentence pairs for two different systems: postprocess (bestmatch) and decode (bestmatch). For each sentence pair, we determined whether the “one sense per discourse” processing improved, degraded o</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the Human Language Technology conference (HLT2002), San Diego, CA, 2002.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="9823" citStr="(1998)" startWordPosition="1529" endWordPosition="1529">mber of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of generalization is introduced by conducting the same analysis using stems, which are simply defined as 4-letter prefixes. We have a total of 2316 different lemma types and 6603 lemma-document pairs. The scale of this empirical evaluation is much larger than in Gale et al. (1992a) where only 9 target words were considered and in Krovetz (1998) which used the entire SEMCOR corpus vocabulary. The resulting distribution of number of English translations per French word-document pair is given in the first half of Table 2. Remarkably, more than 2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 98% of the French lemmas are aligned to no more than 2 English translations and 80% of French lemmas have a single translation per document. While these numbers are not as high as the 94% agreement reported by Gale et al. (1992b) in their empirical study, they still strongly support the one translation per discourse hypothesis. General</context>
<context position="13902" citStr="(1998)" startWordPosition="2191" endWordPosition="2191">ion and inquiry, leave and abandon, witness and eyewitness synonyms with SPL = 3 ratio and proportion, quiet and peace, plane and aircraft 3.4 Exceptions: more than one sense per discourse Among the words with a high WordNet path length or no existing path, we find translations that are not synonyms or semantically similar words, but related words sometimes with different POS. They fall within two categories. The first category is that of fine-grained sense distinctions for which the one sense per discourse hypothesis has been showed to break for monolingual WordNet sense distinctions Krovetz (1998). However, for those closely related words, it would be possible to write correct English translations that use the same English form throughout a document. Nationality translation Tibet vs. Tibetan, French vs. France, Paris vs. Parisian, Europe vs. European, French vs. Frenchman Agent/entity policeman vs. police, alderman vs. city The second category of not identical but related translations is explained by a limitation of our experiment set-up: we are looking at single-word translations while the translation of a longer multiword phrase should be considered as a whole. In the following examp</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. WordNet: An Electronic Lexical Database. MIT Press, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixture-model adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5188" citStr="Foster and Kuhn (2007)" startWordPosition="792" endWordPosition="795">pproximate annotation technique in an unsupervised WSD model. A subsequent larger scale study of polysemy based on the WordNet sense inventory in the SEMCOR corpus does not support the hypothesis as strongly (Krovetz, 1998). Only 77% of ambiguous words have a single sense per discourse. Analysis revealed that the one sense per discourse hypothesis is only supported for homonymous senses and not for finer-grained sense distinction. In machine translation, discourse level information has only been indirectly used by adaptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other c</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. Mixture-model adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135, Prague, Czech Republic, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and the Humanities,</title>
<date>1992</date>
<location>26:415–439,</location>
<contexts>
<context position="1269" citStr="Gale et al. (1992" startWordPosition="188" endWordPosition="191">lation (SMT) output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors. A preliminary study showed that enforcing the one translation per discourse constraint in SMT can potentially improve translation quality, and that SMT systems might benefit from translating sentences within their entire document context. 1 Introduction The one sense per discourse hypothesis formulated by Gale et al. (1992b) has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation (WSD) and related tasks (e.g., Yarowsky (1995); Agirre and Rigau ∗The author was partially funded by GALE DARPA Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that tr</context>
<context position="4072" citStr="Gale et al. (1992" startWordPosition="615" endWordPosition="618">t19 Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 19–27, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics put also strongly exhibits the one translation per discourse property. In addition, we will show that having more than one translation per discourse in SMT output often reveals lexical choice errors, and that enforcing the constraint might help improve overall consistency across sentences and translation quality throughout documents. 2 Related Work In the original one sense per discourse study, Gale et al. (1992b) considered a sample of 9 polysemous English words. A total of 5 judges were showed pairs of concordance lines for these words taken from Grolier’s Encyclopedia and asked to identify whether they shared the same sense. Results strongly support the one sense per discourse hypothesis: 94% of polysemous words drawn from the same document have the same sense. The experiment was replicated with the same conclusion on the Brown corpus. Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. A subsequent larger scale study of polysemy </context>
<context position="9757" citStr="Gale et al. (1992" startWordPosition="1515" endWordPosition="1518">very French lemma that occurs more than once in a document, we compute the number of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of generalization is introduced by conducting the same analysis using stems, which are simply defined as 4-letter prefixes. We have a total of 2316 different lemma types and 6603 lemma-document pairs. The scale of this empirical evaluation is much larger than in Gale et al. (1992a) where only 9 target words were considered and in Krovetz (1998) which used the entire SEMCOR corpus vocabulary. The resulting distribution of number of English translations per French word-document pair is given in the first half of Table 2. Remarkably, more than 2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 98% of the French lemmas are aligned to no more than 2 English translations and 80% of French lemmas have a single translation per document. While these numbers are not as high as the 94% agreement reported by Gale et al. (1992b) in their empirical study, they still stro</context>
<context position="26553" citStr="Gale et al., 1992" startWordPosition="4186" endWordPosition="4189">uality was observed, the postprocessing heuristic yielded improvements in 62.5% (decode) and 64.5% (postprocess) of sentences considered. For 41% (decode) and 57% (postprocess) of the sentences in the sam25 ple, changes only consisted of synonym substitution, morphological variations or local reorderings which did not impact translation quality. Taken together, these results suggest that the “one sense per discourse” constraint should be useful to SMT and that it would be worthwile to integrate it directly into SMT modeling. 6 Conclusion We investigated the one sense per discourse hypothesis (Gale et al., 1992b) in the context of machine translation. Analysis of manual translations showed that the hypothesis still holds when using translations in parallel text as sense annotation, thus confirming that translational differences represent useful sense distinctions. Analysis of SMT output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors in an unsupervised fashion. A preliminary stud</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. A method for disambiguating word senses in a large corpus. Computers and the Humanities, 26:415–439, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the workshop on Speech and Natural Language,</booktitle>
<location>Harriman, NY,</location>
<contexts>
<context position="1269" citStr="Gale et al. (1992" startWordPosition="188" endWordPosition="191">lation (SMT) output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors. A preliminary study showed that enforcing the one translation per discourse constraint in SMT can potentially improve translation quality, and that SMT systems might benefit from translating sentences within their entire document context. 1 Introduction The one sense per discourse hypothesis formulated by Gale et al. (1992b) has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation (WSD) and related tasks (e.g., Yarowsky (1995); Agirre and Rigau ∗The author was partially funded by GALE DARPA Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that tr</context>
<context position="4072" citStr="Gale et al. (1992" startWordPosition="615" endWordPosition="618">t19 Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 19–27, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics put also strongly exhibits the one translation per discourse property. In addition, we will show that having more than one translation per discourse in SMT output often reveals lexical choice errors, and that enforcing the constraint might help improve overall consistency across sentences and translation quality throughout documents. 2 Related Work In the original one sense per discourse study, Gale et al. (1992b) considered a sample of 9 polysemous English words. A total of 5 judges were showed pairs of concordance lines for these words taken from Grolier’s Encyclopedia and asked to identify whether they shared the same sense. Results strongly support the one sense per discourse hypothesis: 94% of polysemous words drawn from the same document have the same sense. The experiment was replicated with the same conclusion on the Brown corpus. Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. A subsequent larger scale study of polysemy </context>
<context position="9757" citStr="Gale et al. (1992" startWordPosition="1515" endWordPosition="1518">very French lemma that occurs more than once in a document, we compute the number of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of generalization is introduced by conducting the same analysis using stems, which are simply defined as 4-letter prefixes. We have a total of 2316 different lemma types and 6603 lemma-document pairs. The scale of this empirical evaluation is much larger than in Gale et al. (1992a) where only 9 target words were considered and in Krovetz (1998) which used the entire SEMCOR corpus vocabulary. The resulting distribution of number of English translations per French word-document pair is given in the first half of Table 2. Remarkably, more than 2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 98% of the French lemmas are aligned to no more than 2 English translations and 80% of French lemmas have a single translation per document. While these numbers are not as high as the 94% agreement reported by Gale et al. (1992b) in their empirical study, they still stro</context>
<context position="26553" citStr="Gale et al., 1992" startWordPosition="4186" endWordPosition="4189">uality was observed, the postprocessing heuristic yielded improvements in 62.5% (decode) and 64.5% (postprocess) of sentences considered. For 41% (decode) and 57% (postprocess) of the sentences in the sam25 ple, changes only consisted of synonym substitution, morphological variations or local reorderings which did not impact translation quality. Taken together, these results suggest that the “one sense per discourse” constraint should be useful to SMT and that it would be worthwile to integrate it directly into SMT modeling. 6 Conclusion We investigated the one sense per discourse hypothesis (Gale et al., 1992b) in the context of machine translation. Analysis of manual translations showed that the hypothesis still holds when using translations in parallel text as sense annotation, thus confirming that translational differences represent useful sense distinctions. Analysis of SMT output showed that despite ignoring document structure, the one translation per discourse hypothesis is strongly supported in part because of the low variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors in an unsupervised fashion. A preliminary stud</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. One sense per discourse. In Proceedings of the workshop on Speech and Natural Language, Harriman, NY, February 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gim´enez</author>
<author>Lluis M`arquez</author>
</authors>
<title>Context-aware discriminative phrase selection for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Workshop on Statistical Machine Translation,</booktitle>
<location>Prague,</location>
<marker>Gim´enez, M`arquez, 2007</marker>
<rawString>Jes´us Gim´enez and Lluis M`arquez. Context-aware discriminative phrase selection for statistical machine translation. In Workshop on Statistical Machine Translation, Prague, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah Smith</author>
</authors>
<title>Rich sourceside context for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Workshop on Statistical Machine Translation,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="5844" citStr="Gimpel and Smith, 2008" startWordPosition="895" endWordPosition="898">ile phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approaches (Gimpel and Smith, 2008) and global lexical choice models (Bangalore et al., 2007) also translate sentences independently. 3 One translation per discourse in reference translations In this section we investigate whether the one sense per discourse hypothesis holds in translation. Does one sense per discourse mean one translation per discourse? On the one hand, one translation per discourse might be too strict a constraint to allow for variations in lexicalization of a given sense. While a WSD task produces a set of predefined sense labels, a single sense might be correctly translated in many different ways in a full </context>
</contexts>
<marker>Gimpel, Smith, 2008</marker>
<rawString>Kevin Gimpel and Noah Smith. Rich sourceside context for statistical machine translation. In Workshop on Statistical Machine Translation, Columbus, Ohio, June 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Workshop on Statistical Machine Translation,</booktitle>
<location>Prague,</location>
<contexts>
<context position="5216" citStr="Koehn and Schroeder (2007)" startWordPosition="796" endWordPosition="799">chnique in an unsupervised WSD model. A subsequent larger scale study of polysemy based on the WordNet sense inventory in the SEMCOR corpus does not support the hypothesis as strongly (Krovetz, 1998). Only 77% of ambiguous words have a single sense per discourse. Analysis revealed that the one sense per discourse hypothesis is only supported for homonymous senses and not for finer-grained sense distinction. In machine translation, discourse level information has only been indirectly used by adaptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approac</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. Experiments in domain adaptation for statistical machine translation. In Workshop on Statistical Machine Translation, Prague, June 2007.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5382" citStr="Koehn et al., 2007" startWordPosition="822" endWordPosition="825">s strongly (Krovetz, 1998). Only 77% of ambiguous words have a single sense per discourse. Analysis revealed that the one sense per discourse hypothesis is only supported for homonymous senses and not for finer-grained sense distinction. In machine translation, discourse level information has only been indirectly used by adaptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the one sense per discourse hypothesis has not been explicitly used in SMT modeling. Even the recent generation of SMT models that explicitly use WSD modeling to perform lexical choice rely on sentence context rather than wider document context and translate sentences in isolation (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007; Stroppa et al., 2007; Specia et al., 2008). Other context-sensitive SMT approaches (Gimpel and Smith, 2008) and global lexical choice models (Bangalore et al., 2007) also translate sentences independently. 3 One translation per discourse in refe</context>
<context position="8886" citStr="Koehn et al., 2007" startWordPosition="1368" endWordPosition="1371">he bilingual corpus, including the French side, the manually translated English side (ref) and the automatic English translations (SMT) the French-English data currently available. Since golden word-alignments are not available, we automatically word align the corpus using standard SMT training techniques. Using IBM-4 alignment models learned on the large WMT training corpus (see Section 4.1 for more details), we align GIZA++(Och and Ney, 2003) to obtain the IBM4 alignments in both translation directions, expand their intersection with additional links using the grow-diag-final-and heuristic (Koehn et al., 2007). This creates a total of 51660 alignment links, and about 89% of French tokens are aligned to at least one English token. Note that all links involving stopwords are not considered for the rest of the study. 3.2 One translation per discourse holds For every French lemma that occurs more than once in a document, we compute the number of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of genera</context>
<context position="17453" citStr="Koehn et al., 2007" startWordPosition="2773" endWordPosition="2776">ms tend to produce very literal word for word translations. As can be seen in Table 1 the reference translations use a larger vocabulary than the automatic translations for the same text. 4.1 Automatically translated data We build a standard SMT system and automatically translate the data set described in Section 3.1. We strictly follow the instructions for building a phrasebased SMT system that is close to the state-of-theart in the WMT evaluations3, using the large training sets of about 460M words from Europarl and news. We use the Moses phrase-based statistical machine translation system (Koehn et al., 2007) and follow standard training, tuning and decoding strategies. The translation model consists of a standard Moses phrase-table with lexicalized reordering. Bidirectional GIZA++ word alignments are intersected using the grow-diag-final-and heuristic. Translations of phrases of up to 7 words long are collected and scored with translation probilities and lexical weighting. The English language model is a 4-gram model with Kneser-Ney smoothing, built with the SRI language modeling toolkit (Stolcke, 2002). The word alignment between French input sentences and English SMT output is easily obtained a</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. Moses: Open source toolkit for statistical machine translation. In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic, June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Krovetz</author>
</authors>
<title>More than one sense per discourse.</title>
<date>1998</date>
<booktitle>In NEC Princeton NJ Labs., Research Memorandum,</booktitle>
<contexts>
<context position="4789" citStr="Krovetz, 1998" startWordPosition="733" endWordPosition="734">nce lines for these words taken from Grolier’s Encyclopedia and asked to identify whether they shared the same sense. Results strongly support the one sense per discourse hypothesis: 94% of polysemous words drawn from the same document have the same sense. The experiment was replicated with the same conclusion on the Brown corpus. Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. A subsequent larger scale study of polysemy based on the WordNet sense inventory in the SEMCOR corpus does not support the hypothesis as strongly (Krovetz, 1998). Only 77% of ambiguous words have a single sense per discourse. Analysis revealed that the one sense per discourse hypothesis is only supported for homonymous senses and not for finer-grained sense distinction. In machine translation, discourse level information has only been indirectly used by adaptation of translation or language models to specific genre or topics (e.g., Foster and Kuhn (2007); Koehn and Schroeder (2007)). While phrase-based SMT models incorporate the one sense per collocation hypothesis by attempting to translate phrases rather than single words (Koehn et al., 2007), the o</context>
<context position="9823" citStr="Krovetz (1998)" startWordPosition="1528" endWordPosition="1529">e the number of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of generalization is introduced by conducting the same analysis using stems, which are simply defined as 4-letter prefixes. We have a total of 2316 different lemma types and 6603 lemma-document pairs. The scale of this empirical evaluation is much larger than in Gale et al. (1992a) where only 9 target words were considered and in Krovetz (1998) which used the entire SEMCOR corpus vocabulary. The resulting distribution of number of English translations per French word-document pair is given in the first half of Table 2. Remarkably, more than 2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/ 98% of the French lemmas are aligned to no more than 2 English translations and 80% of French lemmas have a single translation per document. While these numbers are not as high as the 94% agreement reported by Gale et al. (1992b) in their empirical study, they still strongly support the one translation per discourse hypothesis. General</context>
<context position="13902" citStr="Krovetz (1998)" startWordPosition="2190" endWordPosition="2191">vestigation and inquiry, leave and abandon, witness and eyewitness synonyms with SPL = 3 ratio and proportion, quiet and peace, plane and aircraft 3.4 Exceptions: more than one sense per discourse Among the words with a high WordNet path length or no existing path, we find translations that are not synonyms or semantically similar words, but related words sometimes with different POS. They fall within two categories. The first category is that of fine-grained sense distinctions for which the one sense per discourse hypothesis has been showed to break for monolingual WordNet sense distinctions Krovetz (1998). However, for those closely related words, it would be possible to write correct English translations that use the same English form throughout a document. Nationality translation Tibet vs. Tibetan, French vs. France, Paris vs. Parisian, Europe vs. European, French vs. Frenchman Agent/entity policeman vs. police, alderman vs. city The second category of not identical but related translations is explained by a limitation of our experiment set-up: we are looking at single-word translations while the translation of a longer multiword phrase should be considered as a whole. In the following examp</context>
</contexts>
<marker>Krovetz, 1998</marker>
<rawString>Robert Krovetz. More than one sense per discourse. In NEC Princeton NJ Labs., Research Memorandum, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Bin Wang</author>
<author>Yee Seng Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL03,</booktitle>
<pages>455--462</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="2138" citStr="Ng et al., 2003" startWordPosition="323" endWordPosition="326">23. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have been successfully used as learning evidence (Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007). In this paper, we revisit the one sense per discourse hypothesis using word translations in parallel text as senses. Our first goal is to empirically evaluate whether the one translation per document hypothesis holds on French-English reference corpora, thus verifying whether translations exhibit the same properties as monolingual senses. Our second g</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>Hwee Tou Ng, Bin Wang, and Yee Seng Chan. Exploiting parallel texts for word sense disambiguation: An empirical study. In Proceedings of ACL03, Sapporo, Japan, pages 455–462, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="8715" citStr="Och and Ney, 2003" startWordPosition="1344" endWordPosition="1347"> English (SMT) 1070 24758 5075 2932 French 1080 27924 6150 3839 no. 2 English (ref) 1080 24825 5686 3414 English (SMT) 1080 25128 5240 3080 Table 1: Data statistics for the bilingual corpus, including the French side, the manually translated English side (ref) and the automatic English translations (SMT) the French-English data currently available. Since golden word-alignments are not available, we automatically word align the corpus using standard SMT training techniques. Using IBM-4 alignment models learned on the large WMT training corpus (see Section 4.1 for more details), we align GIZA++(Och and Ney, 2003) to obtain the IBM4 alignments in both translation directions, expand their intersection with additional links using the grow-diag-final-and heuristic (Koehn et al., 2007). This creates a total of 51660 alignment links, and about 89% of French tokens are aligned to at least one English token. Note that all links involving stopwords are not considered for the rest of the study. 3.2 One translation per discourse holds For every French lemma that occurs more than once in a document, we compute the number of English translations. In order to allow for morphological and syntactic variations, we com</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–52, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="25157" citStr="Papineni et al., 2002" startWordPosition="3969" endWordPosition="3972">stprocessing the baseline SMT output - the translations of the French target word are simply replaced by the recommended translation, and (2) encouraging the SMT system to choose the recommended translations by annotating SMT input using the xml input markup scheme - again, this approach is not optimal as it introduces additional translation candidates without probability scores and forces single word translation to compete with phrasal translation even if they are consistent. 5.2 Impact on translation quality As reported in Table 3, small increases in METEOR (Banerjee and Lavie, 2005), BLEU (Papineni et al., 2002) and NIST scores (Doddington, 2002) suggest that SMT output matches the references better after postprocessing or decoding with the suggested lemma translations. Examples of both improved and degraded lexical choice are given in Table 4. Since we are modifying translations for a limited set of single-words only, only 10% to 30% of the test set sentences are translated differently. We manually inspected a random sample of 100 of those sentence pairs for two different systems: postprocess (bestmatch) and decode (bestmatch). For each sentence pair, we determined whether the “one sense per discour</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity - Measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-04),</booktitle>
<pages>38--41</pages>
<location>Boston, MA,</location>
<contexts>
<context position="12132" citStr="Pedersen et al., 2004" startWordPosition="1887" endWordPosition="1891">ch, or are they close variations in English lexical choice? For 21 reference SMT lemmas stems lemmas stems 1 80.82% 85.14% 83.03% 86.38% 2 17.88% 13.91% 15.43% 12.47% 3 01.12% 00.95% 01.25% 00.85% 4 00.18% 00.00% 00.17% 00.22% Table 2: Distribution of number of English translation per document using the word-aligned reference translations and the automatic SMT translations a given French word, how semantically similar are the various English translations? We measure semantic similarity using the shortest path length in WordNet (Fellbaum, 1998) as implemented in the WordNet Similarity package (Pedersen et al., 2004). The path length is defined as the number of WordNet nodes or synsets in a path between two words: words that belong to the same synset therefore have a shortest path length of 1, while words that are related via a common synonym, hypernym or hyponym have a shortest path length of 2. Note that this similarity metric is only defined for two WordNet vocabulary words of the same POS. For 57% of the French lemmas with multiple translations, those translations can be linked by a WordNet path of no more than 4 nodes. In 19% of the cases, the translations belong to the same synset, another 19% are s</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. WordNet::Similarity - Measuring the relatedness of concepts. In Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-04), pages 38–41, Boston, MA, May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>Distinguising systems and distinguishing senses: New evaluation methods for word sense disambiguation.</title>
<date>1999</date>
<journal>Natural Language Engineering,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="2097" citStr="Resnik and Yarowsky, 1999" startWordPosition="315" endWordPosition="318">y funded by GALE DARPA Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have been successfully used as learning evidence (Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng et al., 2003). In Statistical Machine Translation (SMT), recent work shows that WSD helps translation quality when the WSD system directly uses translation candidates as sense inventories (Carpuat and Wu, 2007; Chan et al., 2007; Gim´enez and M`arquez, 2007). In this paper, we revisit the one sense per discourse hypothesis using word translations in parallel text as senses. Our first goal is to empirically evaluate whether the one translation per document hypothesis holds on French-English reference corpora, thus verifying whether translations exhibit the same prope</context>
</contexts>
<marker>Resnik, Yarowsky, 1999</marker>
<rawString>Philip Resnik and David Yarowsky. Distinguising systems and distinguishing senses: New evaluation methods for word sense disambiguation. Natural Language Engineering, 5(2):113–133, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part–of–speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the Conference on New Methods in Language Processin,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="9403" citStr="Schmid, 1994" startWordPosition="1456" endWordPosition="1457"> intersection with additional links using the grow-diag-final-and heuristic (Koehn et al., 2007). This creates a total of 51660 alignment links, and about 89% of French tokens are aligned to at least one English token. Note that all links involving stopwords are not considered for the rest of the study. 3.2 One translation per discourse holds For every French lemma that occurs more than once in a document, we compute the number of English translations. In order to allow for morphological and syntactic variations, we compute those statistics using English lemmas obtained by running Treetagger (Schmid, 1994) with the standard French and English parameter settings2. A higher level of generalization is introduced by conducting the same analysis using stems, which are simply defined as 4-letter prefixes. We have a total of 2316 different lemma types and 6603 lemma-document pairs. The scale of this empirical evaluation is much larger than in Gale et al. (1992a) where only 9 target words were considered and in Krovetz (1998) which used the entire SEMCOR corpus vocabulary. The resulting distribution of number of English translations per French word-document pair is given in the first half of Table 2. R</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. Probabilistic part–of–speech tagging using decision trees. In Proceedings of the Conference on New Methods in Language Processin, pages 44–49, Manchester, UK, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Specia</author>
<author>Baskaran Sankaran</author>
</authors>
<title>and Maria das Grac¸as Volpe Nunes. n-best reranking for the efficient integration of word sense disambiguation and statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics and Intelligent Text Processing (CICLing’08),</booktitle>
<location>Haifa, Israel,</location>
<marker>Specia, Sankaran, 2008</marker>
<rawString>Lucia Specia, Baskaran Sankaran, and Maria das Grac¸as Volpe Nunes. n-best reranking for the efficient integration of word sense disambiguation and statistical machine translation. In Proceedings of the Conference on Computational Linguistics and Intelligent Text Processing (CICLing’08), Haifa, Israel, February 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM—an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In International Conference on Spoken Language Processing,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="17958" citStr="Stolcke, 2002" startWordPosition="2847" endWordPosition="2848"> Europarl and news. We use the Moses phrase-based statistical machine translation system (Koehn et al., 2007) and follow standard training, tuning and decoding strategies. The translation model consists of a standard Moses phrase-table with lexicalized reordering. Bidirectional GIZA++ word alignments are intersected using the grow-diag-final-and heuristic. Translations of phrases of up to 7 words long are collected and scored with translation probilities and lexical weighting. The English language model is a 4-gram model with Kneser-Ney smoothing, built with the SRI language modeling toolkit (Stolcke, 2002). The word alignment between French input sentences and English SMT output is easily obtained as a by-product of decoding. We have a total of 56003 alignment links, and 96% of French tokens are linked to a least one English translation. 4.2 One translation per discourse holds We perform the same analysis as for the manual translations. The distribution of the number of translations for a given French word that occurs repeatedly in a document still strongly supports the one translation per document hypothesis (Table 2). In fact, SMT lexical choice seems to be more regular than in manual transla</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. SRILM—an extensible language modeling toolkit. In International Conference on Spoken Language Processing, Denver, Colorado, September 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Stroppa</author>
<author>Antal van den Bosch</author>
<author>Andy Way</author>
</authors>
<title>Exploiting source similarity for smt using context-informed features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI</booktitle>
<location>Skovde, Sweden,</location>
<marker>Stroppa, van den Bosch, Way, 2007</marker>
<rawString>Nicolas Stroppa, Antal van den Bosch, and Andy Way. Exploiting source similarity for smt using context-informed features. In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007), Skovde, Sweden, September 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="1429" citStr="Yarowsky (1995)" startWordPosition="216" endWordPosition="217"> variability in SMT lexical choice. More interestingly, cases where the hypothesis does not hold can reveal lexical choice errors. A preliminary study showed that enforcing the one translation per discourse constraint in SMT can potentially improve translation quality, and that SMT systems might benefit from translating sentences within their entire document context. 1 Introduction The one sense per discourse hypothesis formulated by Gale et al. (1992b) has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation (WSD) and related tasks (e.g., Yarowsky (1995); Agirre and Rigau ∗The author was partially funded by GALE DARPA Contract No. HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency. (1996)). In this paper, we investigate its potential usefulness in the context of machine translation. A growing body of work suggests that translational differences represent observable sense distinctions that are useful in applications. In monolingual WSD, word alignments in parallel corpora have be</context>
<context position="4523" citStr="Yarowsky (1995)" startWordPosition="692" endWordPosition="693">e overall consistency across sentences and translation quality throughout documents. 2 Related Work In the original one sense per discourse study, Gale et al. (1992b) considered a sample of 9 polysemous English words. A total of 5 judges were showed pairs of concordance lines for these words taken from Grolier’s Encyclopedia and asked to identify whether they shared the same sense. Results strongly support the one sense per discourse hypothesis: 94% of polysemous words drawn from the same document have the same sense. The experiment was replicated with the same conclusion on the Brown corpus. Yarowsky (1995) successfully used this observation as an approximate annotation technique in an unsupervised WSD model. A subsequent larger scale study of polysemy based on the WordNet sense inventory in the SEMCOR corpus does not support the hypothesis as strongly (Krovetz, 1998). Only 77% of ambiguous words have a single sense per discourse. Analysis revealed that the one sense per discourse hypothesis is only supported for homonymous senses and not for finer-grained sense distinction. In machine translation, discourse level information has only been indirectly used by adaptation of translation or language</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 189–196, Cambridge, MA, 1995.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>