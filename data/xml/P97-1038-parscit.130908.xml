<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.939312">
An Alignment Method for Noisy Parallel Corpora based on
Image Processing Techniques
</title>
<author confidence="0.846069">
Jason S. Chang and Mathis H. Chen
</author>
<affiliation confidence="0.995226">
Department of Computer Science,
National Tsing Hua University, Taiwan
</affiliation>
<email confidence="0.94961">
jschang@cs.nthu.edu.tw mathis @nlplab.cs.nthu.edu.tw
</email>
<note confidence="0.907215">
Phone: +886-3-5731069 Fax: +886-3-5723694
</note>
<sectionHeader confidence="0.977835" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999942117647059">
This paper presents a new approach to bitext
correspondence problem (BCP) of noisy bilingual
corpora based on image processing (IP) techniques.
By using one of several ways of estimating the
lexical translation probability (LTP) between pairs
of source and target words, we can turn a bitext
into a discrete gray-level image. We contend that
the BCP, when seen in this light, bears a striking
resemblance to the line detection problem in IP.
Therefore, BCPs, including sentence and word
alignment, can benefit from a wealth of effective,
well established IP techniques, including
convolution-based filters, texture analysis and
Hough transform. This paper describes a new
program, PlotAlign that produces a word-level
bitext map for noisy or non-literal bitext, based on
these techniques.
</bodyText>
<keyword confidence="0.5063185">
Keywords: alignment, bilingual corpus,
image processing
</keyword>
<sectionHeader confidence="0.998688" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999947956521739">
Aligned corpora have proved very useful in many
tasks, including statistical machine translation,
bilingual lexicography (Daille, Gaussier and Lange
1993), and word sense disambiguation (Gale,
Church and Yarowslcy 1992; Chen, Ker, Sheng,
and Chang 1997). Several methods have recently
been proposed for sentence alignment of the
Hansards, an English-French corpus of Canadian
parliamentary debates (Brown, Lai and Mercer
1991; Gale and Church 1991a; Simard, Foster and
Isabelle 1992; Chen 1993), and for other language
pairs such as English-German, English-Chinese,
and English-Japanese (Church, Dagan, Gale, Fung,
Helfman and Satish 1993; Kay and Roscheisen
1993; Wu 1994).
The statistical approach to machine translation
(SMT) can be understood as a word-by-word
model consisting of two sub-models: a language
model for generating a source text segment S and a
translation model for mapping S to its translation
T. Brown et al. (1993) also recommend using a
bilingual corpus to train the parameters of Pr(S I 7),
translation probability (TP) in the translation
model. In the context of SMT, Brown et al.
(1993) present a series of five models of Pr(S I 7)
for word alignment. The authors propose using
an adaptive Expectation and Maximization (EM)
algorithm to estimate parameters for lexical
translation probability (LTP) and distortion
probability (DP), two factors in the TP, from an
aligned bitext. The EM algorithm iterates
between two phases to estimate LTP and DP until
both functions converge.
Church (1993) observes that reliably distinguishing
sentence boundaries for a noisy bitext obtained
from an OCR device is quite difficult. Dagan,
Church and Gale (1993) recommend aligning
words directly without the preprocessing phase of
sentence alignment. They propose using
char_align to produce a rough character-level
alignment first. The rough alignment provides a
basis for estimating the translation probability
based on position, as well as limits the range of
target words being considered for each source word.
Char_align (Church 1993) is based on the
observation that there are many instances of
</bodyText>
<page confidence="0.994547">
297
</page>
<figureCaption confidence="0.997634">
Figure 1. Dotplot. An example of a dotplot of
alignment showing only likely dots which lie
</figureCaption>
<bodyText confidence="0.996746923076923">
within a short distance from the diagonal.
cognates among the languages in the Indo-
European family. However, Fung and Church
(1994) point out that such a constraint does not
exist between languages across language groups
such as Chinese and English. The authors
propose a K-vec approach which is based on a k-
way partition of the bilingual corpus. Fung and
McKeown (1994) propose using a similar measure
based on Dynamic Time Warping (DTW) between
occurrence recency sequences to improve on the K-
vec method.
The char-align, K-vec and DTW approaches rely
on dynamic programming strategy to reach a rough
alignment. As Chen (1993) points out, dynamic
programming is particularly susceptible to
deletions occurring in one of the two languages.
Thus, dynamic programming based sentence
alignment algorithms rely on paragraph anchors
(Brown et al. 1991) or lexical information, such as
cognates (Simard 1992), to maintain a high
accuracy rate. These methods are not robust with
respect to non-literal translations and large
deletions (Simard 1996). This paper presents a
new approach based on image processing (IP)
techniques, which is immune to such predicaments.
</bodyText>
<sectionHeader confidence="0.956889" genericHeader="introduction">
2. BCP as image processing
</sectionHeader>
<subsectionHeader confidence="0.99994">
2.1 Estimation of LTP
</subsectionHeader>
<bodyText confidence="0.9989118">
A wide variety of ways of LTP estimation have
been proposed in the literature of computational
linguistics, including Dice coefficient (Kay and
Roscheisen 1993), mutual information, 02 (Gale
and Church 1991b), dictionary and thesaurus
</bodyText>
<tableCaption confidence="0.965264">
Table 1. Linguistic constraints. Linguistic constraints
at various level of alignment resolution give rise to
different types of image pattern that are susceptible
</tableCaption>
<table confidence="0.958837375">
to well established IP techniques.
Constraints Image IP techniques Alignment
Pattern Resolution
Structure Edge Convolution Phrase
preserving Feature Sentence
One-to-one Texture extraction Discourse
Non-crossing Line Hough
transform
</table>
<bodyText confidence="0.491548333333333">
information (Ker and Chang 1996), cognates
(Simard 1992), K-vec (Fung and Church 1994),
DTW (Fung and McKeown 1994), etc.
</bodyText>
<equation confidence="0.926258">
Dice coefficient:
2. prob(s, t)
Dice(s, t) =
prob(s)+ prob(t)
mutual information:
prob(s,t)
MI (s , t) = log
prob(s)â€¢ prob(t)
</equation>
<bodyText confidence="0.999954166666667">
Like the image of a natural scene, the linguistic or
statistical estimate of LTP gives rise to signal as
well as noise. These signal and noise can be
viewed as a gray-level dotplot (Church and Gale
1991), as Figure 1 shows.
We observe that the BCP, when cast as a gray-level
image, bears a striking resemblance to IP problems,
including edge detection, texture classification, and
line detection. Therefore, the BCP can benefit
from a wealth of effective, well established IP
techniques, including convolution-based filtering,
texture analysis, and Hough transform.
</bodyText>
<subsectionHeader confidence="0.999832">
2.2 Properties of aligned corpora
</subsectionHeader>
<bodyText confidence="0.9987215">
The PlotAlign algorithms are based on three
linguistic constraints that can be observed at
different level of alignment resolution, including
phrase, sentence, and discourse:
</bodyText>
<page confidence="0.99132">
298
</page>
<listItem confidence="0.99916325">
1. Structure preserving constraint: The connec-
tion target of a word tend to be located next to
that of its neighboring words.
2. One-to-one constraint: Each source word token
connect to at most one target word token.
3. Non-crossing constraint: The connection target
of a sentence does not come before that of its
preceding sentence.
</listItem>
<sectionHeader confidence="0.545303" genericHeader="method">
MEMMEMMEMMEME
M =EMMEN=
MEMEMMEMEM MEM
MENEM MIME
</sectionHeader>
<figure confidence="0.484670333333333">
mom= um
MIIIMMEMMEMM ME
=EMMEN=
MEM= 0 =MENEM
MIIMMEMMEMMEMEM
IIIIIAMIIIIMME
MEMMEMMEMMEMEN
INEEMEM =EMMEN
MIOMMUMMMMOOM41
</figure>
<figureCaption confidence="0.587973">
Figure 2. Short edges and textural pattern in a
dotplot. The shaded cells are positions
</figureCaption>
<bodyText confidence="0.997418">
where a high LTP value is registered. The
cell with a dark dot in it is an alignment
connection.
Each of these constraints lead to a specific pattern
in the dotplot. The structure preserving constraint
means that the connections of adjacent words tend
to form short, diagonal edges on the dotplot. For
instance, Figure 2 shows that the adjacent words
such as &amp;quot;He hopes&amp;quot; and &amp;quot;achieve all&amp;quot; lead to
diagonal edges, 00 and 00 in the dotplot.
However, edges with different orientation may also
appear due to some morphological constraints.
For instance, the token &amp;quot;aim&amp;quot; connects to a
Mandarin compound &amp;quot;p14,&amp;quot; thereby gives rise to
the horizontal edge 00. The one-to-one
assumption leads to a textural pattern that can be
categorized as a region of dense dots distributed
much like the l&apos;s in a permutation matrix. For
instance, the vicinity of connection dot 0 (end, At)
is denser than that of a non-connection say (end,
). Furthermore, the nearby connections 0, 0,
and 0, form a texture much like a permutation
matrix with roughly one dot per row and per
column. The non-crossing assumption means that
the connection target of a sentence will not come
before that of its preceding sentence. For instance,
Figure 1 shows that there are clearly two long lines
representing a sequence of sentences where this
constraint holds. The gap between these two lines
results from the deletion of several sentences in the
translation process.
</bodyText>
<figure confidence="0.999319529411765">
(a)
000
500
400
2 300
c.)
200
100
600
500
400
300
0
200
100
Ion 200 300 400 500 600 700
English
</figure>
<figureCaption confidence="0.989271">
Figure 3. Convolution. (a) LTP dotplot before
convolution; and (b) after convolution.
</figureCaption>
<subsectionHeader confidence="0.999397">
2.3 Convolution and local edge detection
</subsectionHeader>
<bodyText confidence="0.9998078">
Convolution is the method of choice for enhancing
and detecting the edges in an image. For noise or
incomplete image, as in the case of LTP dotplot, a
discrete convolution-based filter is effective in
filling a missing or under-estimated dot which is
surrounded by neighboring dots with high LTP
value according to the structure preserving con-
straint. A filtering mask stipulates the relative
location of these supporting dots. The filtering
can be proceed as follows to obtain Pr(sx, ti), the
</bodyText>
<figure confidence="0.997638">
He
ho s
to
achieve
all
his
aims
the
end
of
the
.â€¢
â€¢
500
600
700
100 200 300 400
English
</figure>
<page confidence="0.99409">
299
</page>
<bodyText confidence="0.999095285714286">
density indicate that connections fall on the vicinity
of the cell. With this in mind, we proceed as
follows to extract features for textural discrimina-
tion:
translation probability of the position (x, y), from
t(Sx+i, ty+j), the LTP values of itself and neighboring
cells:
</bodyText>
<equation confidence="0.996285">
Pt(S x, t) = t( Sx+j, t y+ i)X mask(i,i)
-w i= -w
</equation>
<bodyText confidence="0.999764666666667">
where w is a pre-determined parameter specifying
the size of the convolution filter. Connections that
fall outside this window are assumed to have no
affect on Pr(sx , ti).
For simplicity, two 3x3 filters can be employed to
detect and accentuate the signal:
</bodyText>
<table confidence="0.9754562">
-1 -1 -1 2 -1 -1
2 2 2 2 -1
-1 -1 -1 -1 -1 2
However, a 5 by 5 filter, empirically derived from
the data, performs much better.
-0.04 -0.11 -0.20 -0.15 -0.11
0.08 -0.01 -0.25 -0.19 -0.15
-0.13 0.27 1.00 0.27 -013
-0.13 -0.16 -0.22 0.02 0.11
-0.10 -0.14 -0.19 -0.10 -0.02
</table>
<subsectionHeader confidence="0.999431">
2.4 Texture analysis
</subsectionHeader>
<bodyText confidence="0.975225333333333">
Following the common practice in IP for texture
analysis, we propose to extract features to
discriminate a connection region in the dotplot from
non-connection regions. First, the dotplot should
be normalized and binarized, leaving the expected
number of dots, in order to reduce complexity and
simplify computation. Then, projectional
transformation to either or both axes of the
languages involved will compress the data further
without losing too much information. That
further reduces the 2D texture discrimination task
to a 1D problem. For instance, Figure 4 shows
that the vicinity of a connection (by, ) is
characterized by evenly distributed high LTP
values, while that of a non-connection is not.
According to the one-to-one constraint, we should
be looking for dense and continuous 1D occurrence
of dots. A cell with high density and high power
</bodyText>
<listItem confidence="0.970776625">
1. Normalize the LTP value row-wise and column-
wise.
2. For a window of n x m cells, set the t (s, t)
values of k cells with highest LTP values to 1
and the rest to 0, k = max (n, m).
3. Compute the density and deviation features:
projection:
1
</listItem>
<equation confidence="0.998120777777778">
p (x, y) = v
I gx, y + j)
density:
Ep(x + y)
d (x, y) = IW
2w+ 1
power density:
pd (x, y) =
i=1
</equation>
<bodyText confidence="0.999985111111111">
where w and v are the width and height of a window
for feature extraction, and c is the bound for the
resolution of texture. The bound depends on the
coverage rate of LTP estimates; 2 or 3 seems to
produce satisfactory results.
Since the one-to-one constraint is a sentence level
phenomena, the values for w and v should be
chosen to correspond to the lengths of average
sentences in each of the two languages.
</bodyText>
<subsectionHeader confidence="0.999509">
2.5 Hough transform and line detection
</subsectionHeader>
<bodyText confidence="0.9999864">
The purpose of Hough transform (HT) algorithm,
in short, is to map all points of a line in the original
space to a single accumulative value in the
parameter space. We can describe a line on x-y
plane in the form p = x.sin0 + y.cose. Therefore,
</bodyText>
<page confidence="0.986905">
300
</page>
<bodyText confidence="0.998927857142857">
a point (p, 0) on the p - 0 plane describes a line on
the x-y plane. Furthermore, HT is insensitive to
perturbation in the sense the line of (p, 0) is very
close to that of (p-1-p, 0-th0). That enables
HT-based line detection algorithm to find high
resolution, one-pixel-wide lines, as well as lower-
resolution lines.
</bodyText>
<figure confidence="0.337911">
1 1 1 12 11 12 1/2
</figure>
<figureCaption confidence="0.7569365">
Figure 4. Projection. The histogram of horizontal
projection of the data in Figure 2.
</figureCaption>
<bodyText confidence="0.99800847826087">
As mentioned above, many alignment algorithms
rely on anchors, such as cognates, to keep
alignment on track. However, that is only
possible for bitext of certain language pairs and
text genres. For a clean bitext, such as the
Hansards, most dynamic programming based
algorithms perform well (Simard 1996). To the
contrary, a noisy bitext with large deletions,
inversions and non-literal translations will appear
as disconnected segments on the dotplot. Gaps
between these segments may overpower dynamic
programming, and lead to a low precision rate.
Simard (1996) shows that for the Hansards corpus,
most sentence-align algorithms yield a precision
rate over 90%. For a noisy corpus, such as
literary bitext, the rate drops below 50%.
Contrary to the dynamic programming based
methods, Hough transform always detect the most
apparent line segments even in a noisy dotplot.
Before applying Hough transform, the same
processes of normalization and thresholding are
performed first. The algorithm is described as
follows:
</bodyText>
<listItem confidence="0.980668785714286">
1. Normalize the LTP value row-wise and column-
wise.
2. For a window of n x m cells, set the t(s, t) values
of k cells with highest LTP values to 1 and the
rest to 0, k = max (n, m).
3. Set incidence (p, 0) = 0, for all -k5_13.5.k, -90Â°
&lt; 0 &lt; 0Â°,
4. For each cell (x, y), t(x, y) = 1 and -90Â° 0 00
,
increment incidence (x cos 0 + y sin 0, 0) by 1.
5. Keep (p, 0) pairs that have high incidence value,
incidence (p, 9)&gt; X. Subsequently, filter out
dot (x, y) that does not lie on such a line, (p, 0)
or within a certain distance 8 from (p, 0).
</listItem>
<sectionHeader confidence="0.927164" genericHeader="method">
3. Experiments
</sectionHeader>
<bodyText confidence="0.998807076923077">
To asses the effectiveness of the PlotAlign
algorithms, we conducted a series of experiments.
A novel and its translation was chosen as the test
data. For simplicity, we have selected mutual
information to estimate LTP. Statistics of mutual
information between a source and target words is
estimated using an outside source, example
sentences and translation in the Longman English-
Chinese Dictionary of Contemporary English
(LecDOCE, Longman Group, 1992). An addi-
tional list of some 3,200 English person names and
Chinese translations are used to enhance the
coverage of proper nouns in the bitext.
</bodyText>
<figure confidence="0.9987340625">
,M1111111=IMMEMENIIIIM
hoie MENNIMMIIIIIMEN
to
MIIIMMENNEMIIII: NMI
....â€¢â€¢_ t.....
NM- MENNEME11111111 U.
aims Uâ€¢â€¢â€¢UUUUUUU
â€¢11â€¢MENECIENIMMENNI
MoNENENNEMMENEEN
end ENNIMICI MEM.
of
theNEENMENNEEMEMil
INNENEMEMMEMEN
=MENEM IIIENNEMMEN
IMICIEI
achieve
</figure>
<page confidence="0.923564">
301
</page>
<note confidence="0.77662">
L7P Estimation of Testing Data
</note>
<table confidence="0.8151069375">
500
Ansuer5eyt7a lumanjudge . ..
. â€¢.,
1 iâ€¢ :i
/
/ ...â€¢
..&apos;â€˜&apos;
Jr
./
&apos;:..&amp;quot;
.0
,...#&apos;
t*&amp;quot;..
â€”.â€” ,_â€¢.â€” ... â€” â€” â€” â€” â€”. â€¢
&apos; â€¢ . â€¢:â€¢ ... . â€¢â€¢ . i : â€¢
â€¢ I : .; â€¢ â€¢ â€¢ t t â€¢
â€¢ S 0. â€¢ â€¢ . .
.â€¢ â€¢â€¢â€¢ . . ..
III. . â€¢ â€¢..... . 4...1. â€¢â€¢â€¢â€¢â€¢â€¢ :ft . ..:.â€¢ i
â€¢â€¢â€¢ â€¢ â€¢ -. â€¢ X.. â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ . . : â€¢ â€¢ â€¢ &apos;
â€¢ * I .6 ::: - i : â€¢â€¢ â€¢
â€¢â€¢: aâ€¢ ....4 â€¢ â€¢ ...! â€¢
..... ; â€¢ : . .; . ; aa&apos; â€¢ 1
â€¢â€¢ â€¢â€¢â€¢â€¢â€¢â€¢ 1111&apos;
&amp;quot;4 :â€¢â€¢&apos;â€¢ . . â€¢ .â€¢ ..
â€¢ â€¢ NEE . .â€¢â€¢
....â€¢,.. â€¢ â€¢ â€¢
,.... .. .
â€¢
â€¢,.: i .. ,
. m.... â€¢Fif.
â€¢.â€¢ â€¢ . .....â€¢ â€¢
</table>
<figure confidence="0.9797077">
100
0
503
450
350
250
100
0
0 100 200 300 400 500
Enghsh
</figure>
<figureCaption confidence="0.978634">
Figure 5. Alignment by a human judge.
</figureCaption>
<figure confidence="0.9684485">
030 0 100 2(1) 3C0 400 500 600
English
</figure>
<figureCaption confidence="0.957548571428571">
Figure 6. LTP estimation of the test data.
Figure 5 displays the result of word alignment by a
human judge. Only 40% of English text and 70%
of Chinese text have a connection counterpart. This
indicates the translation is not literal and there are
many deletions. For instance, the following
sentences are freely translated:
</figureCaption>
<figure confidence="0.509855333333333">
la. It was only a quarter to eleven.
lb. JR,A.A.+7,k..:-_&amp;quot;.&amp;quot; 1,1 0 (10:45.)
2a. She was tall, maybe five ten and a half, but she didn&apos;t
stoop.
2b. Jo (175cm)
3a. Larry Cochran tried to keep a discreet distance away.
</figure>
<bodyText confidence="0.905989538461538">
He knew his quarry was elusive and self-protective:
there were few candid pictures of her, which was what
would make these valuable. He walked on the opposite
side of the street from her; usime a zoom lens, he had
already shot a whole roll of film. When they came to
Seventy-ninth Street, he caught a real break when she
crossed over to him, and he realised he might be able
to squeeze off full-face shots. Maybe, if it clouded over
more, she might take off her dark glasses. That would
be a real coup.
3b. V-4-L4i&amp;A,FttA. 4k. 401 AAA E.44 â€”
*AA-
flit ill 11-fltft tt-ET 404 *A-0 4o
</bodyText>
<sectionHeader confidence="0.84494" genericHeader="evaluation">
4. Result and Discussion
</sectionHeader>
<bodyText confidence="0.9998065">
Figure 6 shows that the coverage and precision of
the LTP estimate is not very high. That is to be
expected since the translation is not literal and the
mutual information estimate based on an outside
source might not be relevant. Nevertheless,
PlotAlign algorithms seem to be robust enough to
produce reasonably high precision that can be seen
from Figure 3. Figure 3(a) shows that a
normalization and thresholding process based on
one-to-one constraints does a good job of filtering
out noise. Figure 3(b) shows that convolution-
based filtering remove more noise according to the
assumption of structure preserving constraint.
Texture analysis does an even better job in noise
suppression. Figure 7(a) and 7(b) show that
signal-to-noise ratio (SNR) is greatly improved.
The filtering based on Hough Transform, contrary
to the other two filtering methods, prefers
connection that is consistent with other connections
globally. It does a pretty good job of identifying a
long line segment. However, isolated, short
segments, surrounded by deletions are likely to be
missed out. Figure 8(b) shows that filtering based
on HT missed out the short line segment appearing
near the center of the dotplot shown in Figure 6(b).
Nevertheless, this short segment presents most
vividly in the result of textural filter, shown in
Figure 7(b). By combining filters on all three
levels of resolution, we gather as much evidence as
possible for optimal result.
</bodyText>
<page confidence="0.9932">
302
</page>
<figure confidence="0.979778714285714">
â€¢ (a)
0 ICO 2C0 30) 400 50) 600
English
(b)
Texture Analysis: Acc&gt;4, DEV.c4
0 100 203 300 4C0 503 6(0
English
</figure>
<figureCaption confidence="0.9912725">
Figure 7. Texture Analysis. (a) Threshold = 3; (b)
Threshold =4.
</figureCaption>
<tableCaption confidence="0.990564">
Table 2. Hough Transform.
</tableCaption>
<table confidence="0.98954825">
P 0 N p 0 Np ON
5 -42 10 0 -43 6 -61 -56 6
23 0 9 7 -41 6 -83 -60 6
313 0 9 -2 -45 6 113 0 6
387 0 9 -2 -48 6 252 0 6
0 -45 8 -3 -49 6 323 0 6
0 -49 8 -6 -46 6 348 0 6
4 -43 8 -9 -50 6 420 0 6
3 -44 7 32 -1 6 486 0 6
-18 -90 7 46 -31 6 498 0 6
-24 -51 7 -11 -54 6 566 0 6
-38 -53 7 -43 -54 6 -107 -67 6
-39 -53 7 -46 -54 6 -120 -59 6
109 0 7 -53 -57 6 -226 -75 6
226 0 7 -M -65 6 -MS -00 6
Hough Transform (Threshold: 4)
</table>
<figure confidence="0.80681225">
111111111111111111111111111
15 11111111111111111111111111
100 200 300 400 500 600
English
</figure>
<figureCaption confidence="0.998079">
Figure 8. Hough transform of the test data.
</figureCaption>
<sectionHeader confidence="0.996319" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.9997576">
The algorithm&apos;s performance discussed herein can
definitely be improved by enhancing the various
components of the algorithms, e.g. introducing
bilingual dictionaries and thesauri. However, the
PlotAlign algorithms constitute a functional core
for processing noisy bitext. While the evaluation
is based on an English-Chinese bitext, the linguistic
constraints motivating the algorithms seem to be
quite general and, to a large extent, language
independent. If that is the case, the algorithms
</bodyText>
<figure confidence="0.999367">
â€¢
I
â€¢
â€¢
e
â€¢
-45
.60
-75 -400 -300 -200 -100 p(offset) 8) 200
-15 . â€¢ (Threshold:
-45 Hough Transform 0 100
-60
-75
-400
300
401
-300 -200 -100 0 103 2(0) 303 4I0I
p(offset)
11111111111M111111111111
1111111111111111111111111111
503
400
. 300
200
10)
400
300
2(0
100
</figure>
<page confidence="0.99825">
303
</page>
<bodyText confidence="0.9998385">
should be effective to other language pairs. The
prospects for English-Japanese or Chinese-
Japanese, in particular, seem highly promising.
Performing the alignment task as image processing
proves to be an effective approach and sheds new
light on the bitext correspondence problem. We
are currently looking at the possibilities of
exploiting powerful and well established IP
techniques to attack other problems in natural
language processing.
</bodyText>
<sectionHeader confidence="0.935242" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9991904">
This work is supported by National Science
Council, Taiwan under contracts NSC-862-745-
E007-009 and NSC-862-213-E007-049. And we
would like to thank Ling-ling Wang and Jyh-shing
Jang for their valuable comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998368" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999983522727273">
1. Brown, P. F., J. C. Lai and R. L. Mercer, (1991).
Aligning Sentences in Parallel Corpora, In Proceedings
of the 29th Annual Meeting of the Association for
Computational Linguistics, 169-176, Berkeley, CA,
USA.
2. Brown, P. F., S. A. Della Pietra, V. J. Della Pietra, and R.
L. Mercer, (1993). The Mathematics of Statistical
Machine Translation: Parameter Estimation,
Computational Linguistics, 19:2, 263-311.
3. Chen, J. N., J. S. Chang, H. H. Sheng and S. J. Ker,
(1997). Word Sense Disambiguation using a Bilingual
Machine Readable Dictionary. To appear in Natural
Language Engineering.
4. Chen, Stanley F., (1993). Aligning Sentences in
Bilingual Corpora Using Lexical Information, In
Proceedings of the 31st Annual Meeting of the
Association for Computational Linguistics (ACL-91), 9-
16, Ohio, USA.
5. Church, K. W., I. Dagan, W. A. Gale, P. Fung, J.
Helfman, and B. Satish, (1993). Aligning Parallel Texts:
Do Methods Developed for English-French Generalized
to Asian Languages? In Proceedings of the First Pacific
Asia Conference on Formal and Computational
Linguistics, 1-12.
6. Church, Kenneth W. (1993), Char_align: A Program for
Aligning Parallel Texts at the Character Level, In
Proceedings of the 3 Ith Annual Meeting of the
Association for Computational Linguistics (ACL-93),
Columbus, OH, USA
7. Dagan, I., K. W. Church and W. A. Gale, (1993). Robust
Bilingual Word Alignment for Machine Aided
Translation, In Proceedings of the Workshop on Very
Large Corpora : Academic and Industrial Perspectives,
1-8, Columbus, Ohio, USA.
8. Daille, B., E. Gaussier and J.-M. Lange, (1994).
Towards Automatic Extraction of Monolingual and
Bilingual Terminology, In Proceedings of the 15th
International Conference on Computational Linguistics,
515-521, Kyoto, Japan.
9. Fung, P. and K. McKeown, (1994). Aligning Noisy
Parallel Corpora across Language Groups: Word Pair
Feature Matching by Dynamic Time Warping, In
Proceedings of the First Conference of the Association
for Machine Translation in the Americas(AMTA-94),
81-88, Columbia, Maryland, USA.
10. Fung, Pascale and Kenneth W. Church (1994), K-vec: A
New Approach for Aligning Parallel Texts, In Proceed-
ings of the 15th International Conference on
Computational Linguistics (COLING-94), 1096-1140,
Kyoto, Japan.
11. Gale, W. A. and K. W. Church, (1991a). A Program for
Aligning Sentences in Bilingual Corpora, In Proceedings
of the 29th Annual Meeting of the Association for
Computational Linguistics(ACL-91), 177-184, Berkeley,
CA, USA.
12. Gale, W. A. and K. W. Church, (1991b). Identifying
Word Correspondences in Parallel Texts, In Proceedings
of the Fourth DARPA Speech and Natural Language
Workshop, 152-157, Pacific Grove, CA, USA.
13. Gale, W. A., K. W. Church and D. Yarowsky, (1992),
Using Bilingual Materials to Develop Word Sense
Disambiguation Methods, In Proceedings of the 4th
International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI-92),
101-112, Montreal, Canada.
14. Kay, M. and M. ROscheisen, (1993). Text-translation
Alignment, Computational Linguistics, 19:1, 121-142.
15. Ker, Sur J. and Jason S. Chang (1997), Class-based
Approach to Word Alignment, to appear in
Computational Linguistics, 23:2.
16. Longman Group, (1992). Longman English-Chinese
Dictionary of Contemporary English, Published by
Longman Group (Far East) Ltd., Hong Kong.
17. Simard, M., G. F. Foster, and P. Isabelle, (1992). Using
Cognates to Align Sentences in Bilingual Corpora, In
Proceedings of the Fourth International Conference on
Theoretical and Methodological Issues in Machine
Translation (TMI-92), 67-81, Montreal, Canada.
18. Simard, Michel and Pierre Plamondon (1996), Bilingual
Sentence Alignment: Balancing Robustness and
Accuracy, in Proceedings of the First Conference of the
Association for Machine Translation in the Americas
(AMTA-96), 135-144, Montreal, Quebec, Canada.
19. Wu, Dekai (1994), Aligning a Parallel English-Chinese
Corpus Statistically with Lexical Criteria, in Proceedings
of the 32nd Annual Meeting of the Association for
Computational Linguistics, (ACL-94) 80-87, Las Cruces,
New Mexicao, USA.
</reference>
<page confidence="0.99933">
304
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.343074">
<title confidence="0.998789">An Alignment Method for Noisy Parallel Corpora based on Image Processing Techniques</title>
<author confidence="0.999979">Jason S Chang</author>
<author confidence="0.999979">Mathis H Chen</author>
<affiliation confidence="0.946995">Department of Computer Science, National Tsing Hua University, Taiwan</affiliation>
<email confidence="0.754239">jschang@cs.nthu.edu.twmathis@nlplab.cs.nthu.edu.tw</email>
<phone confidence="0.998865">886-3-5731069 Fax: +886-3-5723694</phone>
<abstract confidence="0.999908444444444">This paper presents a new approach to bitext correspondence problem (BCP) of noisy bilingual corpora based on image processing (IP) techniques. By using one of several ways of estimating the lexical translation probability (LTP) between pairs of source and target words, we can turn a bitext into a discrete gray-level image. We contend that the BCP, when seen in this light, bears a striking resemblance to the line detection problem in IP. Therefore, BCPs, including sentence and word alignment, can benefit from a wealth of effective, well established IP techniques, including convolution-based filters, texture analysis and Hough transform. This paper describes a new produces a word-level bitext map for noisy or non-literal bitext, based on these techniques.</abstract>
<keyword confidence="0.996683">Keywords: alignment, bilingual corpus,</keyword>
<intro confidence="0.523411">image processing</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora,</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>169--176</pages>
<location>Berkeley, CA, USA.</location>
<contexts>
<context position="15299" citStr="(1)" startWordPosition="2572" endWordPosition="2572">esting Data 500 Ansuer5eyt7a lumanjudge . .. . â€¢., 1 iâ€¢ :i / / ...â€¢ ..&apos;â€˜&apos; Jr ./ &apos;:..&amp;quot; .0 ,...#&apos; t*&amp;quot;.. â€”.â€” ,_â€¢.â€” ... â€” â€” â€” â€” â€”. â€¢ &apos; â€¢ . â€¢:â€¢ ... . â€¢â€¢ . i : â€¢ â€¢ I : .; â€¢ â€¢ â€¢ t t â€¢ â€¢ S 0. â€¢ â€¢ . . .â€¢ â€¢â€¢â€¢ . . .. III. . â€¢ â€¢..... . 4...1. â€¢â€¢â€¢â€¢â€¢â€¢ :ft . ..:.â€¢ i â€¢â€¢â€¢ â€¢ â€¢ -. â€¢ X.. â€¢ â€¢ â€¢ â€¢ â€¢ â€¢ . . : â€¢ â€¢ â€¢ &apos; â€¢ * I .6 ::: - i : â€¢â€¢ â€¢ â€¢â€¢: aâ€¢ ....4 â€¢ â€¢ ...! â€¢ ..... ; â€¢ : . .; . ; aa&apos; â€¢ 1 â€¢â€¢ â€¢â€¢â€¢â€¢â€¢â€¢ 1111&apos; &amp;quot;4 :â€¢â€¢&apos;â€¢ . . â€¢ .â€¢ .. â€¢ â€¢ NEE . .â€¢â€¢ ....â€¢,.. â€¢ â€¢ â€¢ ,.... .. . â€¢ â€¢,.: i .. , . m.... â€¢Fif. â€¢.â€¢ â€¢ . .....â€¢ â€¢ 100 0 503 450 350 250 100 0 0 100 200 300 400 500 Enghsh Figure 5. Alignment by a human judge. 030 0 100 2(1) 3C0 400 500 600 English Figure 6. LTP estimation of the test data. Figure 5 displays the result of word alignment by a human judge. Only 40% of English text and 70% of Chinese text have a connection counterpart. This indicates the translation is not literal and there are many deletions. For instance, the following sentences are freely translated: la. It was only a quarter to eleven. lb. JR,A.A.+7,k..:-_&amp;quot;.&amp;quot; 1,1 0 (10:45.) 2a. She was tall, maybe five ten and a half, but she didn&apos;t stoop. 2b. Jo (175cm) 3a. Larry Cochran tried to keep a discreet distance away. He knew his quarry was elusive and</context>
</contexts>
<marker>1.</marker>
<rawString>Brown, P. F., J. C. Lai and R. L. Mercer, (1991). Aligning Sentences in Parallel Corpora, In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, 169-176, Berkeley, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<marker>2.</marker>
<rawString>Brown, P. F., S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer, (1993). The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguistics, 19:2, 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J N Chen</author>
<author>J S Chang</author>
<author>H H Sheng</author>
<author>S J Ker</author>
</authors>
<title>Word Sense Disambiguation using a Bilingual Machine Readable Dictionary. To appear in Natural Language Engineering.</title>
<date>1997</date>
<marker>3.</marker>
<rawString>Chen, J. N., J. S. Chang, H. H. Sheng and S. J. Ker, (1997). Word Sense Disambiguation using a Bilingual Machine Readable Dictionary. To appear in Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Aligning Sentences in Bilingual Corpora Using Lexical Information,</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL-91),</booktitle>
<pages>9--16</pages>
<location>Ohio, USA.</location>
<marker>4.</marker>
<rawString>Chen, Stanley F., (1993). Aligning Sentences in Bilingual Corpora Using Lexical Information, In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL-91), 9-16, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>I Dagan</author>
<author>W A Gale</author>
<author>P Fung</author>
<author>J Helfman</author>
<author>B Satish</author>
</authors>
<title>Aligning Parallel Texts: Do Methods Developed for English-French Generalized to Asian Languages?</title>
<date>1993</date>
<booktitle>In Proceedings of the First Pacific Asia Conference on Formal and Computational Linguistics,</booktitle>
<pages>1--12</pages>
<marker>5.</marker>
<rawString>Church, K. W., I. Dagan, W. A. Gale, P. Fung, J. Helfman, and B. Satish, (1993). Aligning Parallel Texts: Do Methods Developed for English-French Generalized to Asian Languages? In Proceedings of the First Pacific Asia Conference on Formal and Computational Linguistics, 1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>Char_align: A Program for Aligning Parallel Texts at the Character Level,</title>
<date>1993</date>
<booktitle>In Proceedings of the 3 Ith Annual Meeting of the Association for Computational Linguistics (ACL-93),</booktitle>
<location>Columbus, OH, USA</location>
<marker>6.</marker>
<rawString>Church, Kenneth W. (1993), Char_align: A Program for Aligning Parallel Texts at the Character Level, In Proceedings of the 3 Ith Annual Meeting of the Association for Computational Linguistics (ACL-93), Columbus, OH, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>K W Church</author>
<author>W A Gale</author>
</authors>
<title>Robust Bilingual Word Alignment for Machine Aided Translation,</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora : Academic and Industrial Perspectives,</booktitle>
<pages>1--8</pages>
<location>Columbus, Ohio, USA.</location>
<marker>7.</marker>
<rawString>Dagan, I., K. W. Church and W. A. Gale, (1993). Robust Bilingual Word Alignment for Machine Aided Translation, In Proceedings of the Workshop on Very Large Corpora : Academic and Industrial Perspectives, 1-8, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
<author>E Gaussier</author>
<author>J-M Lange</author>
</authors>
<title>Towards Automatic Extraction of Monolingual and Bilingual Terminology,</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>515--521</pages>
<location>Kyoto, Japan.</location>
<marker>8.</marker>
<rawString>Daille, B., E. Gaussier and J.-M. Lange, (1994). Towards Automatic Extraction of Monolingual and Bilingual Terminology, In Proceedings of the 15th International Conference on Computational Linguistics, 515-521, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>K McKeown</author>
</authors>
<title>Aligning Noisy Parallel Corpora across Language Groups: Word Pair Feature Matching by Dynamic Time Warping,</title>
<date>1994</date>
<booktitle>In Proceedings of the First Conference of the Association for Machine Translation in the Americas(AMTA-94), 81-88,</booktitle>
<location>Columbia, Maryland, USA.</location>
<marker>9.</marker>
<rawString>Fung, P. and K. McKeown, (1994). Aligning Noisy Parallel Corpora across Language Groups: Word Pair Feature Matching by Dynamic Time Warping, In Proceedings of the First Conference of the Association for Machine Translation in the Americas(AMTA-94), 81-88, Columbia, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Kenneth W Church</author>
</authors>
<title>K-vec: A New Approach for Aligning Parallel Texts,</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94),</booktitle>
<pages>1096--1140</pages>
<location>Kyoto, Japan.</location>
<marker>10.</marker>
<rawString>Fung, Pascale and Kenneth W. Church (1994), K-vec: A New Approach for Aligning Parallel Texts, In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94), 1096-1140, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora,</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics(ACL-91),</booktitle>
<pages>177--184</pages>
<location>Berkeley, CA, USA.</location>
<marker>11.</marker>
<rawString>Gale, W. A. and K. W. Church, (1991a). A Program for Aligning Sentences in Bilingual Corpora, In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics(ACL-91), 177-184, Berkeley, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>Identifying Word Correspondences in Parallel Texts,</title>
<date>1991</date>
<booktitle>In Proceedings of the Fourth DARPA Speech and Natural Language Workshop,</booktitle>
<pages>152--157</pages>
<location>Pacific Grove, CA, USA.</location>
<marker>12.</marker>
<rawString>Gale, W. A. and K. W. Church, (1991b). Identifying Word Correspondences in Parallel Texts, In Proceedings of the Fourth DARPA Speech and Natural Language Workshop, 152-157, Pacific Grove, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>Using Bilingual Materials to Develop Word Sense Disambiguation Methods,</title>
<date>1992</date>
<booktitle>In Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92),</booktitle>
<pages>101--112</pages>
<location>Montreal, Canada.</location>
<marker>13.</marker>
<rawString>Gale, W. A., K. W. Church and D. Yarowsky, (1992), Using Bilingual Materials to Develop Word Sense Disambiguation Methods, In Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92), 101-112, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M ROscheisen</author>
</authors>
<date>1993</date>
<journal>Text-translation Alignment, Computational Linguistics,</journal>
<volume>19</volume>
<pages>121--142</pages>
<marker>14.</marker>
<rawString>Kay, M. and M. ROscheisen, (1993). Text-translation Alignment, Computational Linguistics, 19:1, 121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sur J Ker</author>
<author>Jason S Chang</author>
</authors>
<title>Class-based Approach to Word Alignment,</title>
<date>1997</date>
<pages>23--2</pages>
<note>to appear in Computational Linguistics,</note>
<marker>15.</marker>
<rawString>Ker, Sur J. and Jason S. Chang (1997), Class-based Approach to Word Alignment, to appear in Computational Linguistics, 23:2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longman Group</author>
</authors>
<title>Longman English-Chinese Dictionary of Contemporary English,</title>
<date>1992</date>
<institution>Longman Group (Far East) Ltd., Hong Kong.</institution>
<note>Published by</note>
<marker>16.</marker>
<rawString>Longman Group, (1992). Longman English-Chinese Dictionary of Contemporary English, Published by Longman Group (Far East) Ltd., Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G F Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Bilingual Corpora,</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92),</booktitle>
<pages>67--81</pages>
<location>Montreal, Canada.</location>
<marker>17.</marker>
<rawString>Simard, M., G. F. Foster, and P. Isabelle, (1992). Using Cognates to Align Sentences in Bilingual Corpora, In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92), 67-81, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Pierre Plamondon</author>
</authors>
<title>Bilingual Sentence Alignment: Balancing Robustness and Accuracy,</title>
<date>1996</date>
<booktitle>in Proceedings of the First Conference of the Association for Machine Translation in the Americas (AMTA-96),</booktitle>
<pages>135--144</pages>
<location>Montreal, Quebec, Canada.</location>
<marker>18.</marker>
<rawString>Simard, Michel and Pierre Plamondon (1996), Bilingual Sentence Alignment: Balancing Robustness and Accuracy, in Proceedings of the First Conference of the Association for Machine Translation in the Americas (AMTA-96), 135-144, Montreal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria,</title>
<date>1994</date>
<booktitle>in Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, (ACL-94) 80-87,</booktitle>
<location>Las Cruces, New Mexicao, USA.</location>
<marker>19.</marker>
<rawString>Wu, Dekai (1994), Aligning a Parallel English-Chinese Corpus Statistically with Lexical Criteria, in Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, (ACL-94) 80-87, Las Cruces, New Mexicao, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>