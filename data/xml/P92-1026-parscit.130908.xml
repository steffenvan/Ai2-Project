<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.769146">
HANDLING LINEAR PRECEDENCE CONSTRAINTS BY UNIFICATION
</note>
<author confidence="0.810631">
Judith Engelkamp, Gregor Erbach and Hans Uszkoreit
</author>
<affiliation confidence="0.807627">
Universitiit des Saarlandes, Computational Linguistics, and
</affiliation>
<note confidence="0.488209">
Deutsches Forschungszentrum fiir Kfinstliche Intelligenz
D-6600 Saarbrucken 11, Germany
</note>
<email confidence="0.989687">
engelkamp@coli.uni-sb.de
</email>
<sectionHeader confidence="0.988863" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9999349">
Linear precedence (LP) rules are widely used for
stating word order principles. They have been adopted
as constraints by HPSG but no encoding in the
formalism has been provided. Since they only order
siblings, they are not quite adequate, at least not for
German. We propose a notion of LP constraints that
applies to linguistically motivated branching domains
such as head domains. We show a type-based encoding
in an HPSG-style formalism that supports processing.
The encoding can be achieved by a compilation step.
</bodyText>
<sectionHeader confidence="0.998569" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.998480402439024">
Most contemporary grammar models employed in
computational linguistics separate statements about
dominance from those that determine linear precedence.
The approaches for encoding linear precedence (LP)
statements differ along several dimensions.
Depending on the underlying grammatical theory,
different criteria are employed in formulating ordering
statements. Ordering constraints may be expressed by
referring to the category, grammatical function,
discourse role, and many other syntactic, semantic,
morphological or phonological features.
Depending on the grammar formalism, different
languages are used for stating the constraints on
permissible linearizations. LP rules, first proposed by
Gazdar and Pullum (1982) for GPSG, are used, in
different guises, by several contemporary grammar
formalisms. In Functional Unification Grammar (Kay
1985) and implemented versions of Lexical Functional
Grammar, pattern languages with the power of regular
expressions have been utilized.
Depending on the grammar model, LP statements
apply within different ordering domains. In most
frameworks, such as GPSG and HPSG, the ordering
domains are local trees. Initial trees constitute the
ordering domain in ID/LP TAGS (Joshi 1987). In
current LFG (Kaplan &amp; Zaenen 1988), functional
precedence rules apply to functional domains. Reape
Research for this paper was mainly carried out in
the project LILOG supported by IBM Germany. Some
of the research was performed in the project DISCO
which is funded by the German Federal Ministry for
Research and Technology under Grant-No.: ITW 9002.
We wish to thank our colleagues in Saarbriicken, three
anonymous referees and especially Mark Hepple for
their valuable comments and suggestions.
(1989) constructs word order domains by means of a
special union operation on embedded tree domains.
It remains an open question which choices along
these dimensions will turn out to be most adequate for
the description of word order in natural language.
In this paper we do not attempt to resolve the
linguistic issue of the most adequate universal
treatment of word order. However we will present a
method for integrating word order constraints in a typed
feature unification formalism without adding new
formal devices.
Although some proposals for the interaction
between feature unification and LP constraints have
been published (e.g. Seiffert 1991), no encoding has
yet been shown that integrates LP constraints in the
linguistic type system of a typed feature unification
formalism. Linguistic processing with a head-driven
phrase structure grammar (HPSG) containing LP
constraints has not yet been described in the literature.
Since no implemented NL system has been
demonstrated so far that handles partially free word
order of German and many other languages in a
satisfactory way, we have made an attempt to utilize
the formal apparatus of HPSG for a new approach to
processing with LP constraints. However, our method
is not bound to the formalism of HPSG.
In this paper we will demonstrate how LP
constraints can be incorporated into the linguistic type
system of HPSG through the use of parametrized
types. Neither additional operations nor any special
provisions for linear precedence in the processing
algorithm are required. LP constraints are applied
through regular unification whenever the head
combines with a complement or adjunct.
Although we use certain LP-relevant features in
our examples, our aproach does not hinge on the
selection of specific linguistic criteria for constraining
linear order.
Since there is no conclusive evidence to the
contrary, we assume the simplest constraint language
for formulating LP statements, i.e., binary LP
constraints. For computational purposes such
constraints are compiled into the type definitions for
grammatical categories.
With respect to the ordering domain, our LP
constraints differ from the LP constraints commonly
assumed in HPSG (Pollard &amp; Sag 1987) in that they
</bodyText>
<page confidence="0.996586">
201
</page>
<bodyText confidence="0.9994016875">
apply to nonsibling constituents in head domains.
While LP constraints control the order of nodes that are
not siblings, information is accumulated in trees in
such a way that it is always possible to detect a
violation of an LP constraint locally by checking
sibling nodes.
This modification is necessary for the proper
treatment of German word order. It is also needed by all
grammar models that are on the one hand confined to
binary branching structures such as nearly all versions
of categorial grammar but that would, on the other
hand, benefit from a notion of LP constraints.
Our approach has been tested with small sets of
LP constraints. The grammar was written and run in
STUF, the typed unification formalism used in the
project LILOG.
</bodyText>
<sectionHeader confidence="0.866727" genericHeader="method">
LINGUISTIC MOTIVATION
</sectionHeader>
<bodyText confidence="0.9999043">
This section presents the linguistic motivation for
our approach. LP statements in GPSG (Gazdar et al.
1985) constrain the possibility of linearizing
immediate dominance (ID) rules. By taking the right-
hand sides of ID rules as their domain, they allow only
the ordering of sibling constituents. Consequently,
grammars must be designed in such a way that all
constituents which are to be ordered by LP constraints
must be dominated by one node in the tree, so that
&amp;quot;flat&amp;quot; phrase structures result, as illustrated in figure 1.
</bodyText>
<equation confidence="0.915936333333333">
VT11£1X
V°
sollte
should
NP[nom] ADV NP[dat] NP[acc] y0
der Kurier nachher einem Spion den Brief zustecken
</equation>
<bodyText confidence="0.957772971428571">
the courier later a spy the letter slip
The courier was later supposed to slip a spy the letter.
Figure 1
Uszkoreit (1986) argues that such flat structures
are not well suited for the description of languages
such as German and Dutch. The main reasonl is so-
called complex fronting, i.e., the fronting of a non-
finite verb together with some of its complements and
adjuncts as it is shown in (1). Since it is a well
established fact that only one constituent can be
fronted, the flat structure can account for the German
examples in (1), but not for the ones in (2).
(1) sollte der Kurier nachher einem Spion den Brief
zustecken
zustecken sollte der Kurier nachher einem
Spion den Brief
den Brief sollte der Kurier nachher einem
Spion zustecken
Further reasons are discussed in Uszkoreit
(1991b).
einem Spion sollte der Kurier nachher den
Brief zustecken
nachher sollte der Kurier einem Spion den
Brief zustecken
der Kurier sollte nachher einem Spion den
Brief zustecken
(2) den Brief zustecken sollte der Kurier
nachher einem Spion
einem Spion den Brief zustecken sollte
der Kurier nachher
nachher einem Spion den Brief
zustecken sollte der Kurier
In the hierarchical tree structure in figure 2, the
boxed constituents can be fronted, accounting for the
examples in (1) and (2).
</bodyText>
<figure confidence="0.39518">
vfllaX
den Brief zustecken
</figure>
<figureCaption confidence="0.931352">
Figure 2
</figureCaption>
<bodyText confidence="0.833438555555555">
But with this tree structure, LP constraints can no
longer be enforced over siblings. The new domain for
linear order is a head domain, defined as follows:
A head domain consists of the lexical head
of a phrase, and its complements and adjuncts.
LP constraints must be respected within a head
domain.
An LP-constraint is an ordered pair &lt;A,B&gt;
of category descriptions, such that whenever a
node a subsumed by A and a node f3 subsumed
by B occur within the domain of an LP-rule (in
the case of GPSG a local tree, in our case a
head domain), a precedes 13.
An LP constraint &lt;A,B&gt; is conventionally written
as A &lt; B. It follows from the definition that B can
never precede A in an LP domain. In the next section,
we will show how this property is exploited in our
encoding of LP constraints.
</bodyText>
<sectionHeader confidence="0.748303" genericHeader="method">
ENCODING OF LP CONSTRAINTS
</sectionHeader>
<bodyText confidence="0.786665">
From a formal point of view, we want to encode
LP constraints in such a way that
</bodyText>
<figure confidence="0.99653925">
INP[dat] V
einem pion
NP[acc]
nachher
</figure>
<page confidence="0.985742">
202
</page>
<listItem confidence="0.9883192">
• violation of an LP constraint results in unification
failure, and
• LP constraints, which operate on head domains,
can be enforced in local trees by checking sibling
nodes.
</listItem>
<bodyText confidence="0.999617166666667">
The last condition can be ensured if every node in
a projection carries information about which con-
stituents are contained in its head domain.
An LP constraint A &lt;B implies that it can never
be the case that B precedes A. We make use of this
fact by the following additions to the grammar:
</bodyText>
<listItem confidence="0.99313075">
• Every category A carries the information that B
must not occur to its left.
• Every category B carries the information A must
not occur to its right.
</listItem>
<bodyText confidence="0.962054590909091">
This duplication of encoding is necessary because
only the complements/adjuncts check whether the pro-
jection with which they are combined contains some-
thing that is incompatible with the LP constraints. A
projection contains only information about which
constituents are contained in its head domain, but no
restrictions on its left and right context2.
In the following example, we assume the LP-rules
A&lt;B and B&lt;C. The lexical head of the tree is X°, and
the projections are X, and Xmax. The complements
are A, B and C. Each projection contains information
about the constituents contained in it, and each
complement contains information about what must
not occur to its left and right. A complement is only
combined with a projection if the projection does not
contain any category that the complement prohibits on
its right or left, depending on which side the
projection is added.
X&amp;quot;&apos;
(A, B,
A
[left: —113] (B, C)
</bodyText>
<equation confidence="0.834241333333333">
[
left: (C.)
right --A
C x°
[right —A )
Figure 3
</equation>
<bodyText confidence="0.995924384615385">
Having now roughly sketched our approach, we
will turn to the questions of how a violation of LP
constraints results in unification failure, how the
2Alternatively, the projections of the head could as
well accumulate the ordering restrictions while the
arguments and adjuncts only carry information about
their own LP-relevant features. The choice between
the alternatives has no linguistic implications since it
only affects the grammar compiled for processing and
not the one written by the linguist.
information associated with the projections is built
up, and what to do if LP constraints operate on feature
structures rather than on atomic categories.
</bodyText>
<sectionHeader confidence="0.998465" genericHeader="method">
VIOLATION OF LP-CONSTRAINTS
AS UNIFICATION FAILURE
</sectionHeader>
<bodyText confidence="0.934287416666667">
As a conceptual starting point, we take a number
of LP constraints. For the expository purposes of this
paper, we oversimplifiy and assume just the following
four LP constraints:
nom &lt; dat (nominative case precedes
dative case)
nom &lt; acc (nominative case precedes
accusative case)
dat &lt; acc (dative case precedes accusative
case)
pro &lt; nonpro (pronominal NPs precede
non-pronominal NPs)
</bodyText>
<figureCaption confidence="0.810866">
Figure 4
</figureCaption>
<bodyText confidence="0.995174333333333">
Note that nom, dat, acc, pro and nonpro are not
syntactic categories, but rather values of syntactic
features. A constituent, for example the pronoun ihn
(him) may be both pronominal and in the accusative
case. For each of the above values, we introduce an
extra boolean feature, as illustrated in figure 5.
</bodyText>
<listItem confidence="0.839119">
NOM bool
DAT boot
ACC boot
PRO boot
NON-PRO boot-
</listItem>
<figureCaption confidence="0.604762">
Figure 5
</figureCaption>
<bodyText confidence="0.999906333333333">
Arguments encode in their feature structures what
must not occur to their left and right sides. The dative
NP einem Spion (a spy), for example, must not have
any accusative constituent to its left, and no
nominative or pronominal constituent to its right, as
encoded in the following feature structure. The feature
structures that constrain the left and right contexts of
arguments only use &apos;-&apos; as a value for the LP-relevant
features.
</bodyText>
<figureCaption confidence="0.995917">
Figure 6: Feature Structure for einem Spion
</figureCaption>
<bodyText confidence="0.6250826">
Lexical heads, and projections of the head contain a
feature LP-STORE, which carries information about
the LP-relevant information occuring within their
head domain (figure 7).
NOM-
DAT -
LP-STORE ACC -
PRO-
-
.NON-PRO
</bodyText>
<figureCaption confidence="0.998001">
Figure 7: empty LP-STORE
</figureCaption>
<figure confidence="0.943787">
[LEFT [ACC -
RIGHT {NOM --
PRO -
</figure>
<page confidence="0.996473">
203
</page>
<bodyText confidence="0.99849">
In our example, where the verbal lexical head is
not affected by any LP constraints, the LP-STORE
contains the information that no LP-relevant features
are present.
For a projection like einen Brief zusteckt (a
letter[acc] slips), we get the following LP-STORE.
</bodyText>
<equation confidence="0.7903546">
NOM-
DAT -
LP-STORE ACC +
PRO -
_NON-PRO +
</equation>
<figureCaption confidence="0.999168">
Figure 8: LP-STORE of einen Brief zusteckt
</figureCaption>
<bodyText confidence="0.9999564">
The NP einem Spion (figure 6) can be combined
with the projection einen Brief zusteckt (figure 8) to
form the projection einem Spion einen Brief zusteckt
(a spy[dat] a letter[acc] slips) because the RIGHT
feature of einem Spion and the LP-STORE of einen
Brief zusteckt do not contain incompatible
information, i.e., they can be unified. This is how
violations of LP constraints are checked by
unification. The projection einem Spion einen Brief
zusteckt has the following LP-STORE.
</bodyText>
<equation confidence="0.9686444">
NOM -
DAT +
LP-STORE ACC +
PRO -
NON-PRO +_
</equation>
<figureCaption confidence="0.998668">
Figure 9: LP-STORE of einem Spion einen Brief zusteckt
</figureCaption>
<bodyText confidence="0.999640333333333">
The constituent ihn zusteckt (figure 10) could not
be combined with the non-pronominal NP einem
Spion (figure 6).
</bodyText>
<equation confidence="0.979311">
NOM -
DAT -
LP-STORE ACC +
PRO +
_NON-PRO -
</equation>
<figureCaption confidence="0.942249">
Figure 10: LP-STORE of ihn zusteckt
</figureCaption>
<bodyText confidence="0.999925125">
In this case, the value of the RIGHT feature of the
argument einem Spion is not unifiable with the LP-
STORE of the head projection ihn zusteckt because
the feature PRO has two different atoms (+ and -) as
its value. This is an example of a violation of an LP
constraint leading to unification failure.
In the next section, we show how LP-STOREs
are manipulated.
</bodyText>
<sectionHeader confidence="0.986113" genericHeader="method">
MANIPULATION OF THE LP-STORE
</sectionHeader>
<bodyText confidence="0.998586555555556">
Since information about constituents is added to
the LP-STORE, it would be tempting to add this
information by unification, and to leave the initial LP-
STORE unspecified for all features. This is not
possible because violation of LP constraints is also
checked by unification. In the process of this
unification, values for features are added that may lead
to unwanted unification failure when information
about a constituent is added higher up in the tree.
Instead, the relation between the LP-STORE of a
projection and the LP-STORE of its mother node is
encoded in the argument that is added to the projection.
In this way, the argument &amp;quot;changes&amp;quot; the LP-STORE
by &amp;quot;adding information about itself&apos;. Arguments there-
fore have the additional features LP-IN and LP-OUT.
When an argument is combined with a projection, the
projection&apos;s LP-STORE is unified with the argument&apos;s
LP-IN, and the argument&apos;s LP-OUT is the mother
node&apos;s LP-STORE. The relation between LP-IN and
LP-OUT is specified in the feature structure of the
argument, as illustrated in figure 11 for the accusative
pronoun ihn, which is responsible for changing figure
7 into figure 10. No matter what the value for the
features ACC and PRO may be in the projection that
the argument combines with, it is &apos;+&apos; for both features
in the mother node. All other features are left
unchanged3.
</bodyText>
<figure confidence="0.803290666666667">
Fl
N
Fl
</figure>
<figureCaption confidence="0.987066">
Figure 11
</figureCaption>
<bodyText confidence="0.9998145">
Note that only a &apos;+&apos; is added as value for LP-
relevant features in LP-OUT, never a &apos;-&apos;. In this way,
only positive information is accumulated, while
negative information is &amp;quot;removed&amp;quot;. Positive
information is never &amp;quot;removed&amp;quot;.
Even though an argument or adjunct constituent
may have an LP-STORE, resulting from LP
constraints that are relevant within the constituent, it
is ignored when the constituent becomes argument or
adjunct to some head. Our encoding ensures that LP
constraints apply to all head domains in a given
sentence, but not across head domains.
It still remains to be explained how complex
phrases that become arguments receive their LP-IN,
LP-OUT, RIGHT and LEFT features. These are
specified in the lexical entry of the head of the phrase,
but they are ignored until the maximal projection of
the head becomes argument or adjunct to some other
head. They must, however, be passed on unchanged
from the lexical head to its maximal projection. When
3Coreference variables are indicated by boxed
numbers. [ ] is the feature structure that contains no
information (TOP) and can be unified with any other
feature structure.
</bodyText>
<figure confidence="0.99682">
NOM
DAT
LP-IN ACC [ ]
PRO [
_NON-PRO
NOM
DAT
LP-OUT ACC +
PRO +
NON-PRO
</figure>
<page confidence="0.993316">
204
</page>
<bodyText confidence="0.999432818181818">
the maximal projection becomes an argument/adjunct,
they are used to check LP constrains and &amp;quot;change&amp;quot; the
LP-STORE of the head&apos;s projection.
Our method also allows for the description of head-
initial and head-final constructions. In German, for
example, we find prepositions (e.g. far), postpositions
(e.g. halber) and some words that can be both pre- and
postpostions (e.g. wegen).
The LP-rules would state that a postposition
follows everything else, and that a preposition precedes
everything else.
</bodyText>
<equation confidence="0.781595">
[PRE +] &lt; [I
[1 &lt; [POST +1
Figure 12
</equation>
<bodyText confidence="0.9995058">
The information about whether something is a
preposition or a postposition is encoded in the lexical
entry of the preposition or postposition. In the
following figure, the LP-STORE of the lexical head
contains also positive values.
</bodyText>
<equation confidence="0.769547">
[LP-STORE [P°ST 1-]]
PRE -
Figure 13: part of the lexical entry of a postposition
[LP-STORE [P°ST -
PRE +-
</equation>
<figureCaption confidence="0.990441">
Figure 14: part of the lexical entry of a preposition
</figureCaption>
<bodyText confidence="0.998378">
A word that can be both a preposition and a
postposition is given a disjunction of the two lexical
entries:
</bodyText>
<equation confidence="0.9420325">
POST -] -
[LP-STORE [PRE +
{[pRE-
POST..+11...
</equation>
<figureCaption confidence="0.648247">
Figure 15
</figureCaption>
<bodyText confidence="0.994241666666667">
All complements and adjuncts encode the fact that
there must be no preposition to their right, and no
postposition to their left.
</bodyText>
<figure confidence="0.4164395">
[RIGHT [PRE -]]
LEFT [POST -]
</figure>
<figureCaption confidence="0.882872">
Figure 16
</figureCaption>
<bodyText confidence="0.996995">
The manipulation of the LP-STORE by the
features LP-IN and LP-OUT works as usual.
The above example illustrates that our method of
encoding LP constraints works not only for verbal
domains, but for any projection of a lexical head. The
order of quantifiers and adjectives in a noun phrase can
be described by LP constraints.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="method">
INTEGRATION INTO HPSG
</sectionHeader>
<bodyText confidence="0.99954175">
In this section, our encoding of LP constraints is
incorporated into HPSG (Pollard &amp; Sag 1987). We
deviate from the standard HPSG grammar in the
following respects:
</bodyText>
<listItem confidence="0.9865798">
• The features mentioned above for the encoding of
LP-constraints are added.
• Only binary branching grammar rules are used.
• Two new principles for handling LP-constraints are
added to the grammar.
</listItem>
<bodyText confidence="0.999669375">
Further we shall assume a set-valued SUBCAT
feature as introduced by Pollard (1990) for the
description of German. Using sets instead of lists as
the values of SUBCAT ensures that the order of the
complements is only constrained by LP-statements.
In the following figure, the attributes needed for
the handling of LP-constraints are assigned their place
in the HPSG feature system.
</bodyText>
<figure confidence="0.9324328">
SYNSEM I LOC LP-IN [
HEAD LP-OUT [ ]
LEFT [ ]
RIGHT [ ]
LP-STORE [ ]
</figure>
<figureCaption confidence="0.99541">
Figure 17
</figureCaption>
<bodyText confidence="0.999894285714286">
The paths SYNSEMILOCIHEADI [LP-IN,LP-
OUT,RIGHT,LEFT] contain information that is
relevant when the constituents becomes an
argument/adjunct. They are HEAD features so that
they can be specified in the lexical head of the
constituent and are percolated via the Head Feature
Principle to the maximal projection. The path
SYNSEMILOCILP-STORE contains information
about LP-relevant features contained in the projection
dominated by the node described by the feature
structure. LP-STORE can obviously not be a head
feature because it is &amp;quot;changed&amp;quot; when an argument or
adjunct is added to the projection.
In figures 18 and 19, the principles that enforce
LP-constraints are given&amp; Depending on whether the
head is to the right or to the left of the comple-
ment/adjunct, two versions of the principle are dis-
tinguished. This distinction is necessary because linear
order is crucial. Note that neither the HEAD features
of the head are used in checking LP constraints, nor
the LP-STORE of the complement or adjunct.
</bodyText>
<figure confidence="0.957303785714286">
4The dots (...) abbreviate the path SYNSEMILOCAL
[PHON append( , 4)
... [LP-STORE I]
PHON 4
[PHON
... [LP-STORE
1..
HEAD[EFT
LP-IN
LP-OUT
-LP-STORE [
II
III
Head Complement/Adjunct
</figure>
<figureCaption confidence="0.984581">
Figure 18: Left-Head LP-Principle
</figureCaption>
<page confidence="0.967873">
205
</page>
<figure confidence="0.553862">
III
</figure>
<figureCaption confidence="0.930411">
Figure 19: Right-Head LP-Principle
</figureCaption>
<bodyText confidence="0.998187272727273">
In the following examples, we make use of the
parametrized type notation used in the grammar
formalism STUF (DOrre 1991). A parametrized type
has one or more parameters instantiated with feature
structures. The name of the type (with its parameters)
is given to the left of the := sign, the feature structure
to the right.
In the following we define the parametrized types
nom(X,Y), dat(X,Y), pro(X,Y), and non-pro(X,Y),
where X is the incoming LP-STORE and Y is the
outgoing LP-STORE.
</bodyText>
<figure confidence="0.884393285714286">
NOM[]
DAT
T10111 ACC
PRO Ri
NON-PRO
[DAT -
ACC -
</figure>
<figureCaption confidence="0.924941">
Figure 20
</figureCaption>
<table confidence="0.918079">
NOM 11 NOM RI
DAT DAT
non-pro ACC RI , ACC RI :=
PRO 4 PRO 4
NON-PRO E] ...NON-PRO +
[SYNSEMILOC [HEAD [RIGHT I PRO -Th
</table>
<figureCaption confidence="0.700941">
Figure 23
</figureCaption>
<bodyText confidence="0.9998326">
The above type definitions can be used in the
definition of lexical entries. Since the word ihm,
whose lexical entry5 is given in figure 24, is both
dative case and pronominal, it must contain both
types. While the restrictions on the left and right
context invoked by dat/2 and pro/2 can be unified6,
matters are not that simple for the LP-IN and LP-OUT
features. Since their purpose is to &amp;quot;change&amp;quot; rather than
to &amp;quot;add&amp;quot; information, simple unification is not
possible. Instead, LP-IN of ihm becomes the in-
coming LP-STORE of dat/2, the outgoing LP-
STORE of dat/2 becomes the incoming LP-STORE of
pro/2, and the outgoing LP-STORE of pro/2 becomes
LP-OUT of ihm, such that the effect of both changes
is accumulated.
</bodyText>
<figure confidence="0.85887875">
ihm :=
[SYNSEMLOC [HEAD [LP-IN
LP-OUT I-31
datdap A PrOCIL/
</figure>
<figureCaption confidence="0.973534">
Figure 24: lexical entry for ihm
</figureCaption>
<bodyText confidence="0.881270833333333">
After expansion of the types, the following feature
structure results. Exactly the same feature structure had
been resulted if dat/2 and pro/2 would have been
exchanA.ed in the above lexical entry
,12,1) A daglifb ), because the effect of both is
to instantiate a +&apos; in LP-OUT.
</bodyText>
<figure confidence="0.932756914285714">
[PHON append(11,[11
... [LP-STORE E[
PHON
El
{PHON
... [LP-STORE
Heal
_LP-STORE [I
Complement/Adjunct
RIGHT
HEAD [IGHT
EAD
LP-IN
LP-OUT
4
-NOM
DAT
, ACC
PRO
NON-PRO
{SYNSEMILOC[HEAD[CASE nom
LEFT
RI
RI
A
I II
RI
NOM II NOM RI
DATE] DAT +
dat ACC El , ACC :=
PRO El PRO RI
_NON-PRO _NON-PRO
[SYNSEMILOC [HEAD [LEFT I ACC -
RIGHT I NOM -
CASE dat
</figure>
<figureCaption confidence="0.6114">
Figure 21
</figureCaption>
<bodyText confidence="0.5543675">
— —
NOM
</bodyText>
<sectionHeader confidence="0.837256833333333" genericHeader="method">
DAT [ ]
LP-IN ACC
PRO [ ]
NON-PRO
NOM
DAT +
</sectionHeader>
<table confidence="0.873206375">
SYNSEMILOC HEAD LP-OUT ACC
PRO +
NON-PRO
mr [ACC -
— NON-PRO -
RIGHT [NOM -]
—CASE dat
RI
El
RI
NOM RI NOM
DAT El DAT Fl
pro ACC El ACC RI :=
PRO [1 PRO +
.NON-PRO NON-PRO
[ SYNSEIVIILOC [HEAD [LEFT I NON-PRO -]]]
</table>
<figureCaption confidence="0.923119">
Figure 22
Figure 25: expanded lexical entry for ihm
</figureCaption>
<bodyText confidence="0.8734075">
50nly the information which is relevant for the
processing of LP constraints is included in this lexical
entry.
6dat/2 means the type dat with two parameters.
</bodyText>
<page confidence="0.997112">
206
</page>
<bodyText confidence="0.9975535">
The next figure shows the lexical entry for a non-
pronominal NP, with a disjunction of three cases.
</bodyText>
<equation confidence="0.7419765">
Peter :=
id A
(nomfi,[1) v datd], ) v aced], EN A non-prod],[])
Figure 26
</equation>
<sectionHeader confidence="0.994078" genericHeader="method">
COMPILATION OF THE ENCODING
</sectionHeader>
<bodyText confidence="0.983564155555555">
As the encoding of LP constraints presented above
is intended for processing rather than grammar writing,
a compilation step will initialize the lexical entries
automatically according to a given grammar including
a separated list of LP-constraints. Consequently the
violation of LP-constraints results in unification
failure. For reasons of space we only present the basic
idea.
The compilation step is based on the assumption
that the features of the LP-constraints are
morphologically motivated, i.e. appear in the lexicon.
If this is not the case (for example for focus, thematic
roles) we introduce the feature with a disjunction of its
possible values. This drawback we hope to overcome
by employing functional dependencies instead of LP-IN
and LP-OUT features.
For each side of an LP-constraint we introduce
boolean features. For example for [A: v] &lt; [B: w] we
introduce the features a_v and b_w. This works also for
LP-constraints involving more than one feature such as
[PRO + 1 [PRO +
CASE ac CASE da
For encoding the possible combinations of values
for the participating features, we introduce binary
auxiliary features such as pro_plus_case_acc, because
we need to encode that there is at least a single
constituent which is both pronominal and accusative.
Each lexical entry has to be modified as follows:
I. A lexical entry that can serve as the head of a
phrase receives the additional feature LP-STORE.
2. An entry that can serve as the head of a phrase
and bears LP-relevant information, i.e. a projection of
it is subsumed by one side of some LP-constraint, has
to be extended by the features LP-IN, LP-OUT, LEFT,
RIGHT.
3. The remaining entries percolate the LP
information unchanged by passing through the
information via LP-IN and LP-OUT.
The values of the features LEFT and RIGHT
follow from the LP-constraints and the LP-relevant
information of the considered lexical entry.
The values of LP-STORE, LP-IN and LP-OUT
depend on whether the considered lexical entry bears the
information that is represented by the boolean feature
(attribute A with value v for boolean feature a_v).
</bodyText>
<note confidence="0.5009894">
entry bears the entry doesn&apos;t bear
information the information
LP-STORE + —
LP-IN TOP new variable x
LP-OUT + coreference to x
</note>
<sectionHeader confidence="0.986442" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.999993153846154">
We have presented a formal method for the
treatment of LP constraints, which requires no addition
to standard feature unification formalisms. It should
be emphasized that our encoding only affects the
compiled grammar used for the processing. The
linguist does not lose any of the descriptive means nor
the conceptual clarity that an ID/LP formalism offers.
Yet he gains an adequate computational interpretation
of LP constraints.
Because of the declarative specification of LP con-
straints, this encoding is neutral with respect to pro-
cessing direction (parsing-generation). It does not
depend on specific strategies (top-down vs. bottom-up)
although, as usual, some combinations are more
efficient than others. This is an advantage over the
formalization of unification ID/LP grammars in
Seiffert (1991) and the approach by Erbach (1991).
Seiffert&apos;s approach, in which LP constraints operate
over siblings, requires an addition to the parsing algo-
rithm, by which LP constraints are checked during
processing to detect violations as early as possible,
and again after processing, in case LP-relevant infor-
mation has been added later by unification. Erbach&apos;s
approach can handle LP constraints in head domains
by building up a list of constituents over which the
LP constraints are enforced, but also requires an
addition to the parsing algorithm for checking LP
constraints during as well as after processing.
Our encoding of LP constraints does not require
any particular format of the grammar, such as left- or
right-branching structures. Therefore it can be
incorporated into a variety of linguistic analyses.
There is no need to work out the formal semantics of
LP constraints because feature unification formalisms
already have a well-defined formal semantics.
Reape (1989) proposes a different strategy for
treating partially free word order. His approach also
permits the application of LP constraints across local
trees. This is achieved by separating word order
variation from the problem of building a semantically
motivated phrase structure. Permutation across
constituents can be described by merging the fringes
(terminal yields) of the constituents using the
operation of sequence union. All orderings imposed on
the two merged fringes by LP constraints are preserved
in the merged fringe.
Reape treats clause union and scrambling as
permutation that does not affect constituent structure.
Although we are intrigued by the elegance and
descriptive power of Reape&apos;s approach, we keep our
bets with our more conservative proposal. The main
problem we see with Reape&apos;s strategy is the additional
</bodyText>
<note confidence="0.354598">
[SYNSEMILOC [HEAD [INLPP-
L-OUT&apos;
</note>
<page confidence="0.992621">
207
</page>
<bodyText confidence="0.999990209302326">
burden for the LP component of the grammar. For
every single constituent that is scrambled out of some
clause into a higher clause, the two clauses need to be
sequence-unioned. A new type of LP constraints that
refer to the position of the constituents in the phrase or
dependency structure is employed for ensuring that the
two clauses are not completely interleaved. Hopefully
future research will enable us to arrive at better
judgements on the adequacy of the different approaches.
Pollard (1990) proposes an HPSG solution to
German word order that lets the main verb first
combine with some of its arguments and adjuncts in a
local tree. The resulting constituent can be fronted.
The remaining arguments and adjuncts are raised to the
subcategorization list7 of the auxiliary verb above the
main verb. Yet, even if a flat structure is assumed for
both the fronted part of the clause and the part
remaining in situ as in (Pollard 1990), LP constraints
have to order major constituents across the two parts.
For a discussion, see Uszkoreit (1991b).
Uszkoreit (1991b) applies LP principles to head
domains but employs a finite-state automaton for the
encoding of LP constraints. We are currently still
investigating the differences between this approach and
the one presented here.
Just as most other formal appraoches to linear pre-
cedence, we treat LP-rules as absolute constraints
whose violation makes a string unacceptable. Sketchy
as the data may be, they suggest that violation of
certain LP-constraints merely makes a sentence less
acceptable. Degrees of acceptability are not easily
captured in feature structures as they are viewed today.
In terms of our theory, we must ensure that the
unification of the complement&apos;s or adjunct&apos;s left or
right context restriction with the head&apos;s LP-STORE
does not fail in case of a value clash, but rather results
in a feature structure with lower acceptability than the
structure in which there is no feature clash. But until
we have developed a well-founded theory of degrees of
acceptability, and explored appropriate formal means
such as weighted feature structures, as proposed in
(Uszkoreit 1991a), we will either have to ignore order-
ing principles or treat them as absolute constraints.
</bodyText>
<sectionHeader confidence="0.999751" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.997675725806452">
[Done 1991]
Jochen Nine. The Language of STUF. In: Herzog, 0.
and Rollinger, C.-R. (eds.): Text Understanding in
LILOG. Springer, Berlin.
[Erbach 1991]
Gregor Erbach. A flexible parser for a linguistic
experimentation environment. In: Herzog, 0. and
Rollinger, C.-R. (eds.): Text Understanding in LILOG.
Springer, Berlin.
7Actually, in Pollards proposal the subcat feature
is set-valued.
[Gazdar &amp; Pullum 19821
Gerald Gazdar, G. K. Pullum. Generalized Phrase
Structure Grammar. A Theoretical Synopsis. Indiana
Linguistics Club, Bloomington, Indiana.
[Gazdar et al. 1985]
Gerald Gazdar, Ewan Klein, G. K. Pullum, Ivan Sag.
Generalized Phrase Structure Grammar. Basil
Blackwell, Oxford, UK
[Joshi 19871
A. K. Joshi. Word-Over Variation in Natural Language
Generation. In: Proceedings of AAAI-87, 550-555
[Kaplan &amp; Zaenen 1988]
R. M. Kaplan, A. Zaenen. Functional Uncertainty and
Functional Precedence in Continental West Germanic.
In: H. Trost (ed.), Proceedings of 4. osterreichische
Artificial-Intelligence-Tagung. Springer, Berlin.
[Kay 1985]
Martin Kay. Parsing in Functional Unification
Grammar. In: D. Dowty, L. Karttunen and A. Zwicky
(eds.), Natural Language Parsing. Cambridge
University Press, Cambidge, UK.
[Pollard 1990]
Carl Pollard. On Head Non-Movement. In: Proceedings
of the Symposium on Discontinuous Constituency,
Tilburg, ITK.
[Pollard &amp; Sag 1987]
Carl Pollard, Ivan Sag. Information-based syntax and
semantics. Vol. 1: Fundamentals. CSLI Lecture Notes
No. 13, Stanford, CA.
[Reape 1989]
Mike Reape. A Logical Treatment of Semi-Free Word
Order and Bounded Discontinuous Constituency. In:
Proceedings of the 4th Meeting of the European
Chapter of the ACL, Manchester, UK.
[Seiffert 1991]
Roland Seiffert. Unification-ID/LP Grammars:
Formalization and Parsing. In: Herzog, 0. and
Rollinger, C.-R. (eds.): Text Understanding in LILOG.
Springer, Berlin.
[Uszkoreit 19861
Hans Uszkoreit. Linear Precedence in Discontinuous
Constituents: Complex Fronting in German. CSLI
Report CSLI-86-47. Stanford, CA.
[Uszkoreit 1991a]
Hans Uszkoreit. Strategies for Adding Control
Information to Declarative Grammars. Proceedings of
ACL &apos;91, Berkeley.
[Uszkoreit 1991b]
Hans Uszkoreit. Linear Prededence in Head Domains.
Workshop on HPSG and German, Saarbriicken, FRG
(Proceedings to be published)
</reference>
<page confidence="0.997744">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.733646">
<title confidence="0.997073">HANDLING LINEAR PRECEDENCE CONSTRAINTS BY UNIFICATION</title>
<author confidence="0.985081">Judith Engelkamp</author>
<author confidence="0.985081">Gregor Erbach</author>
<author confidence="0.985081">Hans Uszkoreit</author>
<affiliation confidence="0.922844">Universitiit des Saarlandes, Computational Linguistics, and Deutsches Forschungszentrum fiir Kfinstliche Intelligenz</affiliation>
<address confidence="0.96327">D-6600 Saarbrucken 11, Germany</address>
<email confidence="0.998461">engelkamp@coli.uni-sb.de</email>
<abstract confidence="0.986513090909091">Linear precedence (LP) rules are widely used for stating word order principles. They have been adopted as constraints by HPSG but no encoding in the formalism has been provided. Since they only order siblings, they are not quite adequate, at least not for German. We propose a notion of LP constraints that applies to linguistically motivated branching domains such as head domains. We show a type-based encoding in an HPSG-style formalism that supports processing. The encoding can be achieved by a compilation step.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<date>1991</date>
<contexts>
<context position="25876" citStr="(1991)" startWordPosition="4255" endWordPosition="4255">he compiled grammar used for the processing. The linguist does not lose any of the descriptive means nor the conceptual clarity that an ID/LP formalism offers. Yet he gains an adequate computational interpretation of LP constraints. Because of the declarative specification of LP constraints, this encoding is neutral with respect to processing direction (parsing-generation). It does not depend on specific strategies (top-down vs. bottom-up) although, as usual, some combinations are more efficient than others. This is an advantage over the formalization of unification ID/LP grammars in Seiffert (1991) and the approach by Erbach (1991). Seiffert&apos;s approach, in which LP constraints operate over siblings, requires an addition to the parsing algorithm, by which LP constraints are checked during processing to detect violations as early as possible, and again after processing, in case LP-relevant information has been added later by unification. Erbach&apos;s approach can handle LP constraints in head domains by building up a list of constituents over which the LP constraints are enforced, but also requires an addition to the parsing algorithm for checking LP constraints during as well as after proces</context>
</contexts>
<marker>1991</marker>
<rawString>[Done 1991]</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jochen Nine</author>
</authors>
<title>The Language of STUF.</title>
<booktitle>Text Understanding in LILOG.</booktitle>
<editor>In: Herzog, 0. and Rollinger, C.-R. (eds.):</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<marker>Nine, </marker>
<rawString>Jochen Nine. The Language of STUF. In: Herzog, 0. and Rollinger, C.-R. (eds.): Text Understanding in LILOG. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<title>Gregor Erbach. A flexible parser for a linguistic experimentation environment.</title>
<date>1991</date>
<editor>In: Herzog, 0. and Rollinger, C.-R. (eds.):</editor>
<publisher>Springer,</publisher>
<location>Erbach</location>
<contexts>
<context position="25876" citStr="(1991)" startWordPosition="4255" endWordPosition="4255">he compiled grammar used for the processing. The linguist does not lose any of the descriptive means nor the conceptual clarity that an ID/LP formalism offers. Yet he gains an adequate computational interpretation of LP constraints. Because of the declarative specification of LP constraints, this encoding is neutral with respect to processing direction (parsing-generation). It does not depend on specific strategies (top-down vs. bottom-up) although, as usual, some combinations are more efficient than others. This is an advantage over the formalization of unification ID/LP grammars in Seiffert (1991) and the approach by Erbach (1991). Seiffert&apos;s approach, in which LP constraints operate over siblings, requires an addition to the parsing algorithm, by which LP constraints are checked during processing to detect violations as early as possible, and again after processing, in case LP-relevant information has been added later by unification. Erbach&apos;s approach can handle LP constraints in head domains by building up a list of constituents over which the LP constraints are enforced, but also requires an addition to the parsing algorithm for checking LP constraints during as well as after proces</context>
</contexts>
<marker>1991</marker>
<rawString>[Erbach 1991] Gregor Erbach. A flexible parser for a linguistic experimentation environment. In: Herzog, 0. and Rollinger, C.-R. (eds.): Text Understanding in LILOG. Springer, Berlin.</rawString>
</citation>
<citation valid="false">
<title>7Actually, in Pollards proposal the subcat feature is set-valued.</title>
<marker></marker>
<rawString>7Actually, in Pollards proposal the subcat feature is set-valued.</rawString>
</citation>
<citation valid="false">
<title>Generalized Phrase Structure Grammar. A Theoretical Synopsis. Indiana Linguistics Club,</title>
<location>Bloomington, Indiana.</location>
<marker></marker>
<rawString>[Gazdar &amp; Pullum 19821 Gerald Gazdar, G. K. Pullum. Generalized Phrase Structure Grammar. A Theoretical Synopsis. Indiana Linguistics Club, Bloomington, Indiana.</rawString>
</citation>
<citation valid="true">
<title>Ivan Sag. Generalized Phrase Structure Grammar. Basil Blackwell,</title>
<date>1985</date>
<location>Oxford, UK</location>
<marker>1985</marker>
<rawString>[Gazdar et al. 1985] Gerald Gazdar, Ewan Klein, G. K. Pullum, Ivan Sag. Generalized Phrase Structure Grammar. Basil Blackwell, Oxford, UK</rawString>
</citation>
<citation valid="false">
<title>Word-Over Variation in Natural Language Generation. In:</title>
<booktitle>Proceedings of AAAI-87,</booktitle>
<pages>550--555</pages>
<marker></marker>
<rawString>[Joshi 19871 A. K. Joshi. Word-Over Variation in Natural Language Generation. In: Proceedings of AAAI-87, 550-555</rawString>
</citation>
<citation valid="true">
<date>1988</date>
<booktitle>Functional Uncertainty and Functional Precedence in Continental</booktitle>
<editor>West Germanic. In: H. Trost (ed.),</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<marker>1988</marker>
<rawString>[Kaplan &amp; Zaenen 1988] R. M. Kaplan, A. Zaenen. Functional Uncertainty and Functional Precedence in Continental West Germanic. In: H. Trost (ed.), Proceedings of 4. osterreichische Artificial-Intelligence-Tagung. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<title>Martin Kay. Parsing in Functional Unification Grammar. In:</title>
<date>1985</date>
<editor>D. Dowty, L. Karttunen and A. Zwicky (eds.),</editor>
<publisher>Cambridge University Press, Cambidge, UK.</publisher>
<marker>1985</marker>
<rawString>[Kay 1985] Martin Kay. Parsing in Functional Unification Grammar. In: D. Dowty, L. Karttunen and A. Zwicky (eds.), Natural Language Parsing. Cambridge University Press, Cambidge, UK.</rawString>
</citation>
<citation valid="true">
<title>Carl Pollard. On Head Non-Movement. In:</title>
<date>1990</date>
<booktitle>Proceedings of the Symposium on Discontinuous Constituency,</booktitle>
<location>Tilburg, ITK.</location>
<contexts>
<context position="18394" citStr="(1990)" startWordPosition="2998" endWordPosition="2998"> but for any projection of a lexical head. The order of quantifiers and adjectives in a noun phrase can be described by LP constraints. INTEGRATION INTO HPSG In this section, our encoding of LP constraints is incorporated into HPSG (Pollard &amp; Sag 1987). We deviate from the standard HPSG grammar in the following respects: • The features mentioned above for the encoding of LP-constraints are added. • Only binary branching grammar rules are used. • Two new principles for handling LP-constraints are added to the grammar. Further we shall assume a set-valued SUBCAT feature as introduced by Pollard (1990) for the description of German. Using sets instead of lists as the values of SUBCAT ensures that the order of the complements is only constrained by LP-statements. In the following figure, the attributes needed for the handling of LP-constraints are assigned their place in the HPSG feature system. SYNSEM I LOC LP-IN [ HEAD LP-OUT [ ] LEFT [ ] RIGHT [ ] LP-STORE [ ] Figure 17 The paths SYNSEMILOCIHEADI [LP-IN,LPOUT,RIGHT,LEFT] contain information that is relevant when the constituents becomes an argument/adjunct. They are HEAD features so that they can be specified in the lexical head of the co</context>
<context position="28214" citStr="(1990)" startWordPosition="4618" endWordPosition="4618">posal. The main problem we see with Reape&apos;s strategy is the additional [SYNSEMILOC [HEAD [INLPPL-OUT&apos; 207 burden for the LP component of the grammar. For every single constituent that is scrambled out of some clause into a higher clause, the two clauses need to be sequence-unioned. A new type of LP constraints that refer to the position of the constituents in the phrase or dependency structure is employed for ensuring that the two clauses are not completely interleaved. Hopefully future research will enable us to arrive at better judgements on the adequacy of the different approaches. Pollard (1990) proposes an HPSG solution to German word order that lets the main verb first combine with some of its arguments and adjuncts in a local tree. The resulting constituent can be fronted. The remaining arguments and adjuncts are raised to the subcategorization list7 of the auxiliary verb above the main verb. Yet, even if a flat structure is assumed for both the fronted part of the clause and the part remaining in situ as in (Pollard 1990), LP constraints have to order major constituents across the two parts. For a discussion, see Uszkoreit (1991b). Uszkoreit (1991b) applies LP principles to head </context>
</contexts>
<marker>1990</marker>
<rawString>[Pollard 1990] Carl Pollard. On Head Non-Movement. In: Proceedings of the Symposium on Discontinuous Constituency, Tilburg, ITK.</rawString>
</citation>
<citation valid="true">
<title>Carl Pollard, Ivan Sag. Information-based syntax and semantics.</title>
<date>1987</date>
<booktitle>Fundamentals. CSLI Lecture Notes No. 13,</booktitle>
<volume>1</volume>
<location>Stanford, CA.</location>
<marker>1987</marker>
<rawString>[Pollard &amp; Sag 1987] Carl Pollard, Ivan Sag. Information-based syntax and semantics. Vol. 1: Fundamentals. CSLI Lecture Notes No. 13, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<title>Mike Reape. A Logical Treatment of Semi-Free Word Order and Bounded Discontinuous Constituency. In:</title>
<date>1989</date>
<booktitle>Proceedings of the 4th Meeting of the European Chapter of the ACL,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="2549" citStr="(1989)" startWordPosition="357" endWordPosition="357">g domains are local trees. Initial trees constitute the ordering domain in ID/LP TAGS (Joshi 1987). In current LFG (Kaplan &amp; Zaenen 1988), functional precedence rules apply to functional domains. Reape Research for this paper was mainly carried out in the project LILOG supported by IBM Germany. Some of the research was performed in the project DISCO which is funded by the German Federal Ministry for Research and Technology under Grant-No.: ITW 9002. We wish to thank our colleagues in Saarbriicken, three anonymous referees and especially Mark Hepple for their valuable comments and suggestions. (1989) constructs word order domains by means of a special union operation on embedded tree domains. It remains an open question which choices along these dimensions will turn out to be most adequate for the description of word order in natural language. In this paper we do not attempt to resolve the linguistic issue of the most adequate universal treatment of word order. However we will present a method for integrating word order constraints in a typed feature unification formalism without adding new formal devices. Although some proposals for the interaction between feature unification and LP cons</context>
<context position="26850" citStr="(1989)" startWordPosition="4406" endWordPosition="4406">andle LP constraints in head domains by building up a list of constituents over which the LP constraints are enforced, but also requires an addition to the parsing algorithm for checking LP constraints during as well as after processing. Our encoding of LP constraints does not require any particular format of the grammar, such as left- or right-branching structures. Therefore it can be incorporated into a variety of linguistic analyses. There is no need to work out the formal semantics of LP constraints because feature unification formalisms already have a well-defined formal semantics. Reape (1989) proposes a different strategy for treating partially free word order. His approach also permits the application of LP constraints across local trees. This is achieved by separating word order variation from the problem of building a semantically motivated phrase structure. Permutation across constituents can be described by merging the fringes (terminal yields) of the constituents using the operation of sequence union. All orderings imposed on the two merged fringes by LP constraints are preserved in the merged fringe. Reape treats clause union and scrambling as permutation that does not affe</context>
</contexts>
<marker>1989</marker>
<rawString>[Reape 1989] Mike Reape. A Logical Treatment of Semi-Free Word Order and Bounded Discontinuous Constituency. In: Proceedings of the 4th Meeting of the European Chapter of the ACL, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<title>Roland Seiffert. Unification-ID/LP Grammars: Formalization and Parsing.</title>
<date>1991</date>
<booktitle>Text Understanding in LILOG.</booktitle>
<editor>In: Herzog, 0. and Rollinger, C.-R. (eds.):</editor>
<publisher>Springer,</publisher>
<institution>Seiffert</institution>
<location>Berlin.</location>
<contexts>
<context position="25876" citStr="(1991)" startWordPosition="4255" endWordPosition="4255">he compiled grammar used for the processing. The linguist does not lose any of the descriptive means nor the conceptual clarity that an ID/LP formalism offers. Yet he gains an adequate computational interpretation of LP constraints. Because of the declarative specification of LP constraints, this encoding is neutral with respect to processing direction (parsing-generation). It does not depend on specific strategies (top-down vs. bottom-up) although, as usual, some combinations are more efficient than others. This is an advantage over the formalization of unification ID/LP grammars in Seiffert (1991) and the approach by Erbach (1991). Seiffert&apos;s approach, in which LP constraints operate over siblings, requires an addition to the parsing algorithm, by which LP constraints are checked during processing to detect violations as early as possible, and again after processing, in case LP-relevant information has been added later by unification. Erbach&apos;s approach can handle LP constraints in head domains by building up a list of constituents over which the LP constraints are enforced, but also requires an addition to the parsing algorithm for checking LP constraints during as well as after proces</context>
</contexts>
<marker>1991</marker>
<rawString>[Seiffert 1991] Roland Seiffert. Unification-ID/LP Grammars: Formalization and Parsing. In: Herzog, 0. and Rollinger, C.-R. (eds.): Text Understanding in LILOG. Springer, Berlin.</rawString>
</citation>
<citation valid="false">
<title>Linear Precedence in Discontinuous Constituents: Complex Fronting in German.</title>
<tech>CSLI Report CSLI-86-47.</tech>
<location>Stanford, CA.</location>
<marker></marker>
<rawString>[Uszkoreit 19861 Hans Uszkoreit. Linear Precedence in Discontinuous Constituents: Complex Fronting in German. CSLI Report CSLI-86-47. Stanford, CA.</rawString>
</citation>
<citation valid="false">
<title>[Uszkoreit 1991a] Hans Uszkoreit. Strategies for Adding Control Information to Declarative Grammars.</title>
<booktitle>Proceedings of ACL &apos;91,</booktitle>
<location>Berkeley.</location>
<marker></marker>
<rawString>[Uszkoreit 1991a] Hans Uszkoreit. Strategies for Adding Control Information to Declarative Grammars. Proceedings of ACL &apos;91, Berkeley.</rawString>
</citation>
<citation valid="false">
<title>[Uszkoreit 1991b] Hans Uszkoreit. Linear Prededence in Head Domains.</title>
<booktitle>Workshop on HPSG and German, Saarbriicken, FRG (Proceedings</booktitle>
<note>to be published</note>
<marker></marker>
<rawString>[Uszkoreit 1991b] Hans Uszkoreit. Linear Prededence in Head Domains. Workshop on HPSG and German, Saarbriicken, FRG (Proceedings to be published)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>