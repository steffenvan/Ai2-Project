<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.998373">
A Strategy for Generating Evaluative Arguments
</title>
<author confidence="0.951409">
Giuseppe Carenini
</author>
<affiliation confidence="0.881442666666667">
Intelligent Systems Program
University of Pittsburgh,
Pittsburgh, PA 15260, USA
</affiliation>
<email confidence="0.984006">
carenini@cs.pittedu
</email>
<author confidence="0.845352">
Johanna D. Moore
</author>
<affiliation confidence="0.896843333333333">
The Human Communication Research Centre,
University of Edinburgh,
2 Buccleuch Place, Edinburgh EH8 9LW, UK.
</affiliation>
<email confidence="0.991121">
jmoore@cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.99732" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995958916666667">
We propose an argumentation strategy for
generating evaluative arguments that can be
applied in systems serving as personal assistants
or advisors. By following guidelines from
argumentation theory and by employing a
quantitative model of the user&apos;s preferences, the
strategy generates arguments that are tailored to
the user, properly arranged and concise. Our
proposal extends the scope of previous
approaches both in terms of types of arguments
generated, and in terms of compliance with
principles from argumentation theory.
</bodyText>
<sectionHeader confidence="0.975434" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.998987">
Arguing involves an intentional communicative
act that attempts to create, change or reinforce
the beliefs and attitudes of another person.
Factual and causal arguments attempt to affect
beliefs (i.e. assessments that something is or is
not the case), whereas evaluative arguments
attempt to affect attitudes (i.e., evaluative
tendencies typically phrased in terms of like and
dislike or favor and disfavor).
With the ever growing use of the Web, an
increasing number of systems that serve as
personal assistants, advisors, or sales assistants
are becoming available online&apos;. These systems
frequently need to generate evaluative
arguments for domain entities. For instance, a
real-estate assistant may need to compare two
houses, arguing that one would be a better
choice than the other for its user.
Argumentation theory (Mayberry and Golden
1996; Miller and Levine 1996; Corbett and
Connors 1999) indicates that effective
arguments should be constructed following three
</bodyText>
<footnote confidence="0.826232">
&apos; See for instance www.activebuyersguide.com
</footnote>
<bodyText confidence="0.99965652631579">
general principles. First, arguments should be
constructed considering the dispositions of the
audience towards the information presented.
Second, sub-arguments supporting or opposing
the main argument claim should be carefully
arranged by considering their strength of support
or opposition. Third, effective arguments should
be concise, presenting only pertinent and cogent
information.
In this paper, we propose an argumentation
strategy for generating evaluative arguments that
can be applied in systems serving as personal
assistants or advisors. By following principles
and guidelines from argumentation theory and
by employing a quantitative model of the user&apos;s
preference, our strategy generates evaluative
arguments that are tailored to the user, properly
arranged and concise.
Although a preliminary version of our
argumentative strategy was cursorily described
in a previous short paper (Carenini and Moore
1999), this paper includes several additional
contributions. First, we discuss how the strategy
is grounded in the argumentation literature.
Then, we provide details on the measures of
argument strength and importance used in
selecting and ordering argument support. Next,
we generalize the argumentative strategy and
correct some errors in its preliminary version.
Finally, we discuss how our strategy extends the
scope of previous approaches to generating
evaluative arguments in terms of coverage (i.e.,
types of arguments), and in terms of compliance
with principles from argumentation theory.
Because of space limitations, we only dikuss
previous work on generating evaluative
arguments, rather than previous work on
generating arguments in general.
</bodyText>
<page confidence="0.999329">
47
</page>
<sectionHeader confidence="0.961271" genericHeader="method">
1 Guidelines from Argumentation Theory
</sectionHeader>
<bodyText confidence="0.999411470588235">
An argumentation strategy specifies what
content should be included in the argument and
how it should be arranged. This comprises
several decisions: what represents supporting (or
opposing) evidence for the main claim, where to
position the main claim of the argument, what
supporting (or opposing) evidence to include
and how to order it, and how to order supporting -
and opposing evidence with respect to each
other.
Argumentation theory has developed guidelines
specifying how these decisions can be
effectively made (see (Mayberry and Golden
1996; Miller and Levine 1996; Corbett and
Connors 1999; McGuire 1968) for details; see
also (Marcu 1996) for an alternative discussion
of some of the same guidelines).
</bodyText>
<listItem confidence="0.96057328125">
(a) What represents supporting (or opposing)
evidence for a claim — Guidelines for this
decision vary depending on the argument type.
Limiting our analysis to evaluative arguments,
argumentation theory indicates that supporting
and opposing evidence should be identified
according to a model of the reader&apos;s values and
preferences. For instance, the risk involved in a
game can be used as evidence for why your
reader should like the game, only if the reader
likes risky situations.
(b) Positioning the main claim - Claims are
often presented up front, usually for the sake of
clarity. Placing the claim early helps readers
follow the line of reasoning. However, delaying
the claim until the end of the argument can be
effective, particularly when readers are likely to
find the claim objectionable or emotionally
shattering.
(c) Selecting supporting (and opposing)
evidence - Often an argument cannot mention all
the available evidence, usually for the sake of
brevity. Only strong evidence should be
presented in detail, whereas weak evidence
should be either briefly mentioned or omitted
entirely.
(d) Arranging/Ordering supporting evidence —
Typically the strongest support should be
presented first, in order to get at least provisional
agreement from the reader early on. If at all
possible, at least one very effective piece of
supporting evidence should be saved for the end
</listItem>
<bodyText confidence="0.997039166666667">
of the argument, in order to leave the reader with
a final impression of the argument&apos;s strength.
This guideline proposed in (Mayberry and
Golden 1996) is a compromise between the
climax and the anti-climax approaches discussed
in (McGuire 1968).
</bodyText>
<listItem confidence="0.994713380952381">
(e) Addressing and ordering the
counterarguments (opposing evidence) — There
.are ...three ....options. for dhis..xlecision: not to
mention any counterarguments, to acknowledge
them without directly refuting them, to
acknowledge them and directly refuting them.
Weak counterarguments may be omitted.
Stronger counterarguments should be briefly
acknowledged, because that shows the reader
that you are aware of the issue&apos;s complexity; and
it also contributes to the impression that you are
reasonable and broad-minded. You may need to
refute a counterargument once you have
acknowledged it, if the reader agrees with a
position substantially different from yours.
Counterarguments should be ordered to
minimize their effectiveness: strong ones should
be placed in the middle, weak ones upfront and
at the end.
09 Ordering supporting and opposing evidence
— A preferred ordering between supporting and
</listItem>
<bodyText confidence="0.990161409090909">
opposing evidence appears to depend on
whether the reader is aware of the opposing
evidence. If so, the preferred ordering is
opposing before supporting, and the reverse
otherwise.
Although these guidelines provide useful
information on the types of content to include in
an evaluative argument and how to arrange it,
the design of a computational argumentative
strategy based on these guidelines requires that
the concepts mentioned in the guidelines be
formalized in a coherent computational
framework. This includes: explicitly
representing the reader&apos;s values and preferences
(used in guideline a); operationally defining the
term &amp;quot;objectionable claim&amp;quot; (used in guideline b)
through a measure of the discrepancy between
the reader&apos;s -initial position and the argument&apos;s
main clairn2; providing a measure of evidence
strength (needed in guidelines c, d, and e); and
An operational definition for &amp;quot;emotionally
shattering&amp;quot; is outside the scope of this paper.
</bodyText>
<page confidence="0.993077">
48
</page>
<figure confidence="0.996921909090909">
OBJECTIVES COMPONENT VALUE FUNCTIONS
0...1.,...,.... ATTRIBUTES
Location
.0.76.•••■
0..7z
House
Value
0.X
Size 0.8
,.........s...
Neighborhood xl I vl (xl)
Distance-from-park
i/-of-room
Storage-space
gi=nl 0
x1=n2 02
xl=n3 1
x2 I V2()
o=&lt;x2&lt;=5 1.(1/5* x2y
x2&amp;quot;.5 o
•
..
</figure>
<figureCaption confidence="0.999555">
Figure 1 Sample additive multiattribute value function (AMVF)
</figureCaption>
<bodyText confidence="0.981341625">
representing whether the reader is or is not
aware of certain facts (needed in guideline 0.
2 From Guidelines to the Argumentation
Strategy
We assume that the reader&apos;s values and
preferences are represented as an additive
multiattribute value function (AMVF), a
conceptualization based on multiattribute utility
theory (MAUT)(Clemen 1996). Besides being
widely used in decision theory (where they were
originally developed), conceptualizations based
on MAUT have recently become a common
choice in the field of user modelling (Jameson,
Schafer et al. 1995). Similar models are also
used in Psychology, in the study of consumer
behaviour (Solomon 1998).
</bodyText>
<subsectionHeader confidence="0.996162">
2.1 Background on AMVF
</subsectionHeader>
<bodyText confidence="0.940068071428572">
An AMVF is a model of a person&apos;s values and
preferences with respect to entities in a certain
class. It comprises a value tree and a set of
component value functions, one for each
attribute of the entity. A value tree is a
decomposition of the value of an entity into a
hierarchy of aspects of the entity3, in which the
leaves correspond to the entity primitive
attributes (see Figure 1 for a simple value tree in
the real estate domain). The arcs of the tree are
weighted to represent the importance of the
value of an objective in contributing to the value
3 In decision theory these aspects are called
objectives. For consistency with previous work, we
will follow this terminology in the remainder of the
paper.
of its parent in the tree (e.g., in Figure 1 location
is more than twice as important as size in
determining the value of a house). Note that the
sum of the weights at each level is equal to 1. A
component value function for an attribute
expresses the preferability of each attribute
value as a number in the [0,1] interval. For
instance, in Figure 1, neighborhood n2 has
preferability 0.3, and a distance-from-park of 1
mile has preferability (1 - (1/5* 1))=0.8.
Formally, an AMVF predicts the value v(e) of an
entity e as follows:
</bodyText>
<equation confidence="0.893804">
v(e) = Ew, v,(x), where
</equation>
<bodyText confidence="0.831618117647059">
— (xl,...,x„) is the vector of attribute values for
an entity e
- Vattribute i, v, is the component value
function, which maps the least preferable x,
to 0, the most preferable to 1, and the other
x, to values in [0,1]
- w, is the weight for attribute i, with 0_5 w, 5_1
and Ew, =1
- w, is equal to the product of all the weights
from the root of the value tree to the
attribute i
A function v0(e) can also be defined for each
objective. When applied to an entity, this
function °returns the value of the entity with
respect to that objective. For instance, assuming
the value tree shown in Figure 1, we have:
v,
</bodyText>
<equation confidence="0.826007666666667">
ocation(e)=
= (0.4*1.•
?Neighborhood (e))+(0•6* DIst- from- park (6))
</equation>
<bodyText confidence="0.998077">
Thus, given someone&apos;s AMVF, it is possible to
compute how valuable an entity is to that
</bodyText>
<page confidence="0.997354">
49
</page>
<bodyText confidence="0.9985334">
individual. Furthermore, it is possible to
compute how valuable any objective (i.e., any
aspect of that entity) is for that person. All of
these values are expressed as a number in the
interval [0,1].
</bodyText>
<subsectionHeader confidence="0.995374">
2.2 Computational Definition of Concepts
Mentioned in Guidelines
</subsectionHeader>
<bodyText confidence="0.99907">
Presenting an evaluative argument is an attempt
to persuade the reader that a value judgment
applies to a subject. The value judgement, also
called the argumentative intent, can either be
positive (in favour of the subject), or negative
(against the subject)4. The subject can be a
single entity (e.g., &amp;quot;This book is very good&amp;quot;), the
difference between two entities (e.g., &amp;quot;City-a is
somewhat better than city-b&amp;quot;), or any other form
of comparison among entities in a set (e.g.,
&amp;quot;This city is the best in North America&amp;quot;).
Guideline (a) - Given the reader&apos;s AMVF, it is
straightforward to establish what represent
supporting or opposing evidence for an
argument with a given argumentative intent and
a given subject. In fact, if the argumentative
intent is positive, objectives for which the
subject has positive value can be used as
supporting evidence, whereas objectives for
which the subject has a negative value can be
used as opposing evidence (the opposite holds
when the argumentative intent is negative). The
value of different subjects is measured as
follows. If the subject is a single entity e, the
value of the subject for an objective o is vo(e),
and it is positive when it is greater than 0.5, the
midpoint of [0,1] (negative otherwise). In
contrast, if the subject is a comparison between
two entities (e.g., v(e1) &gt; v(e2)), the value of the
subject for an objective o is [vo(ed — v0(e2)], and
it is positive when it is greater than 0 (negative
otherwise).
Guidelines (b) - Since argumentative intent is a
value judgment, we can reasonably assume that
instead of being simply positive or negative, it
may be specified more precisely as a number in
the interval [0,1] (or as a specification that can
be normalized in this interval). Then, the term
</bodyText>
<footnote confidence="0.822657666666667">
4 Arguments can also be neutral. However, in this
paper we do not discuss arguments with a neutral
argumentative intent.
</footnote>
<bodyText confidence="0.964423433333333">
&amp;quot;objectionable claim&amp;quot; can be operationally
defined. If we introduce a measure-of-
discrepancy(MD) as the absolute value of the
difference between the argumentative intent and
the reader&apos;s expected value of the subject before
the argument is presented (based on her AMVF),
a claim becomes more and more &amp;quot;objectionable&amp;quot;
for a reader as MD moves from 0 to I.
Guidelines.,(c) (e) -The &apos;strength of the
evidence in support of (or opposition to) the
main argument claim is critical in selecting and
organizing the argument content. To define a
measure of the strength of support (or
opposition), we adopt and extend previous work
on explaining decision theoretic advice based on
an AMVF. (Klein 1994) presents explanation
strategies (not based on argumentation theory) to
justify the preference of one alternative from a
pair. In these strategies, the compellingness of an
objective measures the objective&apos;s strength in
determining the overall value difference between
the two alternatives, other things being equal.
And an objective is notably-compelling? (i.e.,
worth mentioning) if it is an outlier in a
population of objectives with respect to
compellingness. The formal definitions are:
compellingness(o,ab a2, refo) =
= w(o,refo)[vo(ad —vo(a2)l, where
- o is an objective, al and a2 are alternatives,
refo is an ancestor of o in the value tree
</bodyText>
<listItem confidence="0.691009333333333">
- w(o,refo) is the product of the weights of all
the links from o to refo
- vo is the component value function for leaf
objectives (i.e., attributes), and it is the
recursive evaluation over children(o) for
nonleaf objectives
</listItem>
<equation confidence="0.8300745">
notablv-compelling?(o,opop,a 1, a2, refo)
compellingness(o,a a2, refo) &gt;ux-i-ka„ , where
</equation>
<listItem confidence="0.7516538">
- o, al, a, and refo are defined as in the
previous Def; opop is an objective
population (e.g., siblings(o)), and I opop I &gt;2
- p E opop,. x EX = Icompellingness(p,a 1, a2,
refo)
- is the mean of X, a, is the standard
deviation and k is a user-defined constant
We have defined similar measures for arguing
the value of a single entity and we named them
s-compellingness and s-notably-compelling?.
</listItem>
<page confidence="0.992555">
50
</page>
<bodyText confidence="0.999930769230769">
An objective can be s-compelling either because
of its strength or because of its weakness in
contributing to the value of an alternative. So, if
m, measures how much the value of an objective
contributes to the overall value difference of an
alternative from the worst possible case&apos; and m2
measures how much the value of an objective
contributes to the overall value difference of the
- alternative •from the,„best.:.possiblecase,- -we
define s-compellingness as the greatest of the
two quantities m, and m2. Following the
terminology introduced in the two previous
Equations we have:
</bodyText>
<equation confidence="0.968137">
s-compellingness(o,a,refo) =
= w(o,refo)[max[vo(a) — 0];[1 — v0(a)]i
</equation>
<bodyText confidence="0.9997215">
We give to s-notably-compelling? a definition
analogous to the one for notably-compelling?
</bodyText>
<equation confidence="0.914455">
s-notably-compelling?(o,opop,a,refo)
s-compellingness(o,a,refo) I &gt;1.4,-Fka„ ,
</equation>
<bodyText confidence="0.951967">
Guideline (f) - An AMVF does not represent
whether the reader is or is not aware of certain
facts. We assume this information is represented
separately.
</bodyText>
<subsectionHeader confidence="0.97583">
2.3 The Argumentation Strategy
</subsectionHeader>
<bodyText confidence="0.999172818181818">
We have applied the formal definitions
described in the previous section to develop the
argumentative strategy shown in Figure 2. The
strategy is designed for generating honest and
balanced arguments, which present an
evaluation of the subject equivalent to the one
you would expect the reader to hold according to
her model of preferences (i.e., the argumentative
intent is equal to the expected value, so MD=0)6.
We now examine the strategy in detail, after
introducing necessary terminology. The subject
</bodyText>
<footnote confidence="0.7257513">
5 a,.„ is an alternative such that Vo v„(a„„,,,)=0,
whereas ah,.„ is an alternative such that Vo v0(abc.„)=1
6 An alternative strategy, for generating arguments
whose argumentative intent was greater (or lower)
than the expected value, could also be defined in our
framework. However, this strategy should boost the
evaluation of supporting evidence and include only
weak counterarguments, or hide them overall (the
opposite if the target value was lower than the
expected value)
</footnote>
<bodyText confidence="0.9995825">
is either a single entity or a pair of entities in the
domain of interest. Root can be any objective in
the value tree for the evaluation (e.g., the overall
value of a house, its location, its amenities).
ArgInt is the argumentative intent of the
argument, a number in [0,1]. The constant k, part
of the definitions of notably-compelling? and s-
notably-compelling?, determines the degree of
c-onciseness oftheargument. The„E.xpress-Value
function, used at the end of the strategy,
indicates that the objective applied to the subject
must be realized in natural language with a
certain argumentative intent.
In the first part of the strategy, depending on the
nature of the subject, an appropriate measure of
evidence strength is assigned, along with the
appropriate predicate that determines whether a
piece of evidence is worth mentioning. After
that, only evidence that is worth mentioning is
assigned as supporting or opposing evidence by
comparing its value to the argument intent. In
the second part, ordering constraints from
argumentation theory are applied7. Notice that
we assume a predicate Aware that is true when
the user is aware of a certain fact, false
otherwise. Finally, in the third part of the
strategy, the argument claim is expressed in
natural language. The opposing evidence (i.e.,
ContrastingSubObjectives), that must be
considered, but not in detail, is also expressed in
natural language. In contrast, supporting
evidence is presented in detail, by recursively
calling the strategy on each supporting piece of
evidence.
</bodyText>
<subsectionHeader confidence="0.9982">
2.4 Implementation and Application
</subsectionHeader>
<bodyText confidence="0.991451923076923">
The argumentation strategy has been
implemented as a set of plan operators. Using
these operators the Longbow discourse planner
(Young and Moore 1994) selects and arranges
the content of the argument. We have applied
our strategy in a system that serves as a real-
estate personal assistant (Carenini 2000a). The
system presents information about houses
available on the market in graphical format. The
user explores this information by means of
interactive techniques, and can request a natural
The steps in the strategy are marked with the
guideline they arc based on.
</bodyText>
<page confidence="0.996078">
51
</page>
<figure confidence="0.8883487">
Argue(subject, Root, ArgInt, k)
;; assignments and content selection
If subject = single-entity = e then Silo, = vo,(e)
Measure-of-strength = s-compellingness
Worth-mention? = s-notably-compelling?
Else If subject = e1,e2 then SV,,, (e, )— v
Measure-of-strength = compellingness
Worth-mention? = notably-compelling?
Eliminate all objectives o,I Worth-mention? (o„ siblings(o,), subject, Root)
AllEvidence children (Root)
AllInFavor all .91 o E AllEvidence n (SV, ArgInt)
SecondBestObjInFavor&lt;— second most compelling objective ol o E AllInFavor
RemainingObjectivesInFavor(— AllInFavor - SecondBestObjInFavor
ContrastingObjectives AllEvidence - AllInFavor
;; ordering the selected content
AddOrdering(Root AllEvidence) ;; we assume MDCI, so claim is not objectionable
If Aware(User, ContrastingObjectives) then ;guideline(f)
AddOrdering(ContrastingObjectives AllInFavor)
Else AddOrdering(ContrastingObjectives ›- AllInFavor);
AddOrdering(RemainingObjectivesInFavor SecondBestObjInFavor) ;guideline(d)
</figure>
<figureCaption confidence="0.393204">
Sort(RemainingObjectives/nFavor; decreasing order according to Measure-of-strength) ;guideline(d)
Sort(ContrastingObjectives; strong ones in the middle, weak ones upfront and at the end) ;guideline(e)
</figureCaption>
<table confidence="0.9515148">
;; steps for expressing or further argue the content ;guideline(e)
Express-Value(subject, Root, ArgInt)
For all o AllInFavor , If --Jeaf(o) then Argue(subject, o, SV„, k)
Else Express-Val ue(subject, o, SVo)
For all o E ContrastingObjectives. Express-Value(subject, o, SV0)
</table>
<figure confidence="0.712407285714286">
Legend: (a b) H a preceeds b
(v, i&apos;,) H v, and v, are both positive or negative values
(see Section 0 for what this means for different subjects)
;guideline(c)
;guideline(a)
;guideline(a)
;guideline(b)
</figure>
<figureCaption confidence="0.996872">
Figure 2 The Argumentation strategy
</figureCaption>
<page confidence="0.995095">
52
</page>
<bodyText confidence="0.999775875">
language evaluation of any house just by
dragging the graphical representation of the
house to a query button. The evaluative
arguments generated by the system are concise,
properly arranged and tailored to the user&apos;s
preferences8. For sample arguments generated
by our strategy see (Carenini 2000b) in this
proceedings.
</bodyText>
<sectionHeader confidence="0.99701" genericHeader="method">
3 Previous Work
</sectionHeader>
<bodyText confidence="0.986969051948052">
Although considerable research has been
devoted to study the generation of evaluative
arguments, all approaches proposed so far are
limited in the type of evaluative arguments
generated, and in the extent to which they
comply with guidelines from argumentation
literature.
(Elhadad 1992) investigated a general
computational framework that covers all aspects
of generating evaluative arguments of single
entities, from content selection and structuring to
fine-grained realization decisions. However, his
work concentrates on the linguistic aspects. His
approach to content selection and structuring
does not provide a measure of evidence strength,
which is necessary to implement several of the
guidelines from argumentation literature we
have examined.
Other studies have focused more on the process
of content selection and structuring. However,
with respect to our proposal, they still suffer
from some limitations. (Monk 1989) describes a
system that uses a measure of evidence strength
to tailor evaluations of hotel rooms to its users.
However, her system adopts a qualitative
measure of evidence strength (an ordinal scale
that appears to range from very-important to not-
important). This limits the ability of the system
to select and arrange argument evidence,
because qualitative measures only support
approximate comparisons and are notoriously
difficult to combine (e.g., how many
&amp;quot;somewhat-important&amp;quot; pieces of evidence are
equivalent to an &amp;quot;important&amp;quot;. ,. piece of
evidence?).
s The generation of fluent English also required the
development of microplannin2 and realization
components. For lack of space, we do not discuss
them in this paper.
(Elzer, Chu-Carroli et al. 1994; Chu-Carroll and
Carberry 1998) studied the generation of
evaluative arguments in the context of
collaborative planning dialogues. Although they
also adopt a qualitative measure of evidence
strength, when an evaluation is needed this
measure is mapped into numerical values so that
preferences can be compared and combined
effectiveIyAbakvever;awitivrespeet to &apos;-oUr•
approach, this work makes two strong
simplifying assumptions. It only considers the
decomposition of the preference for an entity
into preferences for its primitive attributes (not
considering that complex preferences frequently
have a hierarchical structure). Additionally, it
assumes that the same dialogue turn cannot
provide both supporting and opposing evidence.
(Kolln 1995) proposes a framework for
generating evaluative arguments which is based
on a quantitative measure of evidence strength.
Evidence strength is computed on a fuzzy
hierarchical representation of user preferences.
Although this fuzzy representation may
represent a viable alternative to the AMVF we
have discussed in this paper, Kolln&apos;s proposal is
rather sketchy in describing how his measure of
strength can be used to select and arrange the
argument content.
Finally, (Klein 1994) is the previous work most
relevant to our proposal. Klein developed a
framework for generating explanations to justify
the preference of an entity out of a pair. These
strategies were not based on argumentation
theory. As described in Section 2.2, from this
work, we have adapted a measure of evidence
strength (i.e., cotnpellingness), and a measure
that defines when a piece of evidence is worth
mentioning (i.e., notably-compelling?).
</bodyText>
<subsectionHeader confidence="0.516979">
Conclusions and Future Work
</subsectionHeader>
<bodyText confidence="0.999873">
In this paper, we propose . an argumentation
strategy that extends previous research on
generating evaluative arguments in two ways.
Our . strategy -.covers the -. -generation, of
evaluations of a single entity, as well as
comparisons between two entities. Furthermore,
our strategy generates arguments, which are
concise, properly arranged and tailored to a
hierarchical model of user&apos;s preferences, by
</bodyText>
<page confidence="0.995607">
53
</page>
<bodyText confidence="0.99996664">
following a comprehensive set of guidelines
from argumentation theory.
Several issues require further investigation.
First, we plan to generalize our approach to
more complex models of user preferences.
Second, although our strategy is based on
insights from argumentation theory, the ultimate
arbiter for effectiveness is empirical evaluation.
Therefore, we have _developed ,an—ev.aluation
environment to verify whether arguments
generated by our strategy actually affect user
attitudes in the intended direction (Carenini
2000b). A third area for future work is the
exploration of techniques to improve the
coherence of arguments generated by our
strategy. In the short term, we intend to integrate
the ordering heuristics suggested in (Reed and
Long 1997). In the long term, by modelling user
attention and retention, we intend to enable our
strategy to assess in a principled way when
repeating the same information can strengthen
argument force. Finally, we plan to extend our
strategy to evaluative arguments for
comparisons between mixtures of entities and
set of entities.
</bodyText>
<sectionHeader confidence="0.998197" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9991">
Our thanks go to the members of the Autobrief
project: S. Roth, N. Green, S. Kerpedjiev and J.
Mattis. We also thank C. Conati for comments
on drafts of this paper. This work was supported
by grant number DAA-1593K0005 from the
Advanced Research Projects Agency (ARPA).
Its contents are solely responsibility of the
authors.
</bodyText>
<sectionHeader confidence="0.999456" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99980503125">
Carenini, G. (2000a). Evaluating Multimedia
Interactive Arguments in the Context of Data
Exploration Tasks. PhD Thesis, Intelligent System
Program, University of Pittsburgh.
Carenini, G. (2000b). A Framework to Evaluate
Evaluative Arguments. Int. Conference on Natural
Language- Generation, Mitzpe.Ramon, Israel.
Carenini, G. and J. Moore (1999). Tailoring
Evaluative Arguments to User&apos;s Preferences. User
Modelling, Banff, Canada: 299-301.
Chu-Carroll, J. and S. Carberry (1998). Collaborative
Response Generation in Planning Dialogues.
Computational Linguistics 24(2): 355-400.
Clemen, R: T. (1996). Making Hard Decisions: an
introduction to decision analysis. Duxbury Press
Corbett, E. P. J. and R. J. Connors (1999). Classical
Rhetoric for the Modern Student, Oxford
University Press.
Elhadad, M. (1992). Using Argumentation to Control
Lexical Choice: A Functional Unification
Implementation. PhD Thesis, CS. Columbia. NY.
Elzer, .S.,-...1—Chu,Carroll,....et. al. (.1994). Recognizing
and Utilizing User Preferences in Collaborative
Consultation Dialogues. Proceedings of Fourth
Int. Conf. of User Modeling. Hyannis, MA: 19-24.
Jameson, A., R. Schafer, et al. (1995). Adaptive
provision of Evaluation-Oriented Information:
Tasks and techniques. Proc. of 14th IJCAI.
Montreal, Canada.
Klein, D. (1994). Decision Analytic Intelligent
Systems: Automated &amp;planation and Knowledge
Acquisition, Lawrence Erlbaum Associates.
Kolln, M. E. (1995). Employing User Attitudes in
Text Planning. 5th European Workshop on Natural
Language Generation, Leiden, The Netherlands.
Marcu, D. (1996). The Conceptual and Linguistic
Facets of Persuasive Arguments. ECAI workshop -
Gaps and Bridges: New Directions in Planning and
Natural Language Generation.
Mayberry, K. J. and R. E. Golden (1996). For
Argument&apos;s Sake: A Guide to Writing Effective
Arguments, Harper Collins, College Publisher.
McGuire, W. J. (1968). The Nature of Attitudes and
Attitudes Change. The Handbook of Social
Psychology. G. Lindzey and E. Aronson, Addison-
Wesley. 3: 136-314.
Miller, M. D. and T. R. Levine (1996). Persuasion.
An Integrated Approach to Communication Theory
and Research. M. B. Salwen and D. W. Stack.
Mahwah, New Jersey: 261-276.
Monk, K. (1989). User Models and Conversational
Settings: Modeling the User&apos;s Wants. User Models
in Dialog Systems. A. Kobsa and W. Wahlster,
Springer-Verlag: 364-385.
Reed, C. and D. Long (1997). Content Ordering in
the Generation of Persuasive Discourse. Proc. of
the 15th &apos;JCR&apos;, Nagoya, Japan.
Solomon, M. R. (1998). Consumer Behavior: Buying,
Having, and Being. Prentice Hall.
Young, M. R. and J. D. Moore (1994). Does
Discourse Planning Require a Special-Purpose
Planner? Proc. of the AAAI-94 Workshop on
planning for Interagent Communication. Seattle,
WA.
</reference>
<page confidence="0.999023">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.865827">
<title confidence="0.999534">A Strategy for Generating Evaluative Arguments</title>
<author confidence="0.962862">Giuseppe</author>
<affiliation confidence="0.994469">Intelligent Systems University of</affiliation>
<address confidence="0.969644">Pittsburgh, PA 15260,</address>
<email confidence="0.982598">carenini@cs.pittedu</email>
<author confidence="0.998717">Johanna D Moore</author>
<affiliation confidence="0.9958445">The Human Communication Research Centre, University of Edinburgh,</affiliation>
<address confidence="0.963872">2 Buccleuch Place, Edinburgh EH8 9LW, UK.</address>
<email confidence="0.998894">jmoore@cogsci.ed.ac.uk</email>
<abstract confidence="0.999358307692308">We propose an argumentation strategy for generating evaluative arguments that can be applied in systems serving as personal assistants or advisors. By following guidelines from argumentation theory and by employing a quantitative model of the user&apos;s preferences, the strategy generates arguments that are tailored to the user, properly arranged and concise. Our proposal extends the scope of previous approaches both in terms of types of arguments generated, and in terms of compliance with principles from argumentation theory.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Carenini</author>
</authors>
<title>Evaluating Multimedia Interactive Arguments in the Context of Data Exploration Tasks.</title>
<date>2000</date>
<tech>PhD Thesis,</tech>
<institution>Intelligent System Program, University of Pittsburgh.</institution>
<contexts>
<context position="18943" citStr="Carenini 2000" startWordPosition="2955" endWordPosition="2956">age. The opposing evidence (i.e., ContrastingSubObjectives), that must be considered, but not in detail, is also expressed in natural language. In contrast, supporting evidence is presented in detail, by recursively calling the strategy on each supporting piece of evidence. 2.4 Implementation and Application The argumentation strategy has been implemented as a set of plan operators. Using these operators the Longbow discourse planner (Young and Moore 1994) selects and arranges the content of the argument. We have applied our strategy in a system that serves as a realestate personal assistant (Carenini 2000a). The system presents information about houses available on the market in graphical format. The user explores this information by means of interactive techniques, and can request a natural The steps in the strategy are marked with the guideline they arc based on. 51 Argue(subject, Root, ArgInt, k) ;; assignments and content selection If subject = single-entity = e then Silo, = vo,(e) Measure-of-strength = s-compellingness Worth-mention? = s-notably-compelling? Else If subject = e1,e2 then SV,,, (e, )— v Measure-of-strength = compellingness Worth-mention? = notably-compelling? Eliminate all o</context>
<context position="21225" citStr="Carenini 2000" startWordPosition="3250" endWordPosition="3251"> o, SVo) For all o E ContrastingObjectives. Express-Value(subject, o, SV0) Legend: (a b) H a preceeds b (v, i&apos;,) H v, and v, are both positive or negative values (see Section 0 for what this means for different subjects) ;guideline(c) ;guideline(a) ;guideline(a) ;guideline(b) Figure 2 The Argumentation strategy 52 language evaluation of any house just by dragging the graphical representation of the house to a query button. The evaluative arguments generated by the system are concise, properly arranged and tailored to the user&apos;s preferences8. For sample arguments generated by our strategy see (Carenini 2000b) in this proceedings. 3 Previous Work Although considerable research has been devoted to study the generation of evaluative arguments, all approaches proposed so far are limited in the type of evaluative arguments generated, and in the extent to which they comply with guidelines from argumentation literature. (Elhadad 1992) investigated a general computational framework that covers all aspects of generating evaluative arguments of single entities, from content selection and structuring to fine-grained realization decisions. However, his work concentrates on the linguistic aspects. His approa</context>
<context position="25584" citStr="Carenini 2000" startWordPosition="3881" endWordPosition="3882"> properly arranged and tailored to a hierarchical model of user&apos;s preferences, by 53 following a comprehensive set of guidelines from argumentation theory. Several issues require further investigation. First, we plan to generalize our approach to more complex models of user preferences. Second, although our strategy is based on insights from argumentation theory, the ultimate arbiter for effectiveness is empirical evaluation. Therefore, we have _developed ,an—ev.aluation environment to verify whether arguments generated by our strategy actually affect user attitudes in the intended direction (Carenini 2000b). A third area for future work is the exploration of techniques to improve the coherence of arguments generated by our strategy. In the short term, we intend to integrate the ordering heuristics suggested in (Reed and Long 1997). In the long term, by modelling user attention and retention, we intend to enable our strategy to assess in a principled way when repeating the same information can strengthen argument force. Finally, we plan to extend our strategy to evaluative arguments for comparisons between mixtures of entities and set of entities. Acknowledgements Our thanks go to the members o</context>
</contexts>
<marker>Carenini, 2000</marker>
<rawString>Carenini, G. (2000a). Evaluating Multimedia Interactive Arguments in the Context of Data Exploration Tasks. PhD Thesis, Intelligent System Program, University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
</authors>
<title>A Framework to Evaluate Evaluative Arguments.</title>
<date>2000</date>
<booktitle>Int. Conference on Natural Language- Generation,</booktitle>
<location>Mitzpe.Ramon,</location>
<contexts>
<context position="18943" citStr="Carenini 2000" startWordPosition="2955" endWordPosition="2956">age. The opposing evidence (i.e., ContrastingSubObjectives), that must be considered, but not in detail, is also expressed in natural language. In contrast, supporting evidence is presented in detail, by recursively calling the strategy on each supporting piece of evidence. 2.4 Implementation and Application The argumentation strategy has been implemented as a set of plan operators. Using these operators the Longbow discourse planner (Young and Moore 1994) selects and arranges the content of the argument. We have applied our strategy in a system that serves as a realestate personal assistant (Carenini 2000a). The system presents information about houses available on the market in graphical format. The user explores this information by means of interactive techniques, and can request a natural The steps in the strategy are marked with the guideline they arc based on. 51 Argue(subject, Root, ArgInt, k) ;; assignments and content selection If subject = single-entity = e then Silo, = vo,(e) Measure-of-strength = s-compellingness Worth-mention? = s-notably-compelling? Else If subject = e1,e2 then SV,,, (e, )— v Measure-of-strength = compellingness Worth-mention? = notably-compelling? Eliminate all o</context>
<context position="21225" citStr="Carenini 2000" startWordPosition="3250" endWordPosition="3251"> o, SVo) For all o E ContrastingObjectives. Express-Value(subject, o, SV0) Legend: (a b) H a preceeds b (v, i&apos;,) H v, and v, are both positive or negative values (see Section 0 for what this means for different subjects) ;guideline(c) ;guideline(a) ;guideline(a) ;guideline(b) Figure 2 The Argumentation strategy 52 language evaluation of any house just by dragging the graphical representation of the house to a query button. The evaluative arguments generated by the system are concise, properly arranged and tailored to the user&apos;s preferences8. For sample arguments generated by our strategy see (Carenini 2000b) in this proceedings. 3 Previous Work Although considerable research has been devoted to study the generation of evaluative arguments, all approaches proposed so far are limited in the type of evaluative arguments generated, and in the extent to which they comply with guidelines from argumentation literature. (Elhadad 1992) investigated a general computational framework that covers all aspects of generating evaluative arguments of single entities, from content selection and structuring to fine-grained realization decisions. However, his work concentrates on the linguistic aspects. His approa</context>
<context position="25584" citStr="Carenini 2000" startWordPosition="3881" endWordPosition="3882"> properly arranged and tailored to a hierarchical model of user&apos;s preferences, by 53 following a comprehensive set of guidelines from argumentation theory. Several issues require further investigation. First, we plan to generalize our approach to more complex models of user preferences. Second, although our strategy is based on insights from argumentation theory, the ultimate arbiter for effectiveness is empirical evaluation. Therefore, we have _developed ,an—ev.aluation environment to verify whether arguments generated by our strategy actually affect user attitudes in the intended direction (Carenini 2000b). A third area for future work is the exploration of techniques to improve the coherence of arguments generated by our strategy. In the short term, we intend to integrate the ordering heuristics suggested in (Reed and Long 1997). In the long term, by modelling user attention and retention, we intend to enable our strategy to assess in a principled way when repeating the same information can strengthen argument force. Finally, we plan to extend our strategy to evaluative arguments for comparisons between mixtures of entities and set of entities. Acknowledgements Our thanks go to the members o</context>
</contexts>
<marker>Carenini, 2000</marker>
<rawString>Carenini, G. (2000b). A Framework to Evaluate Evaluative Arguments. Int. Conference on Natural Language- Generation, Mitzpe.Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J Moore</author>
</authors>
<title>Tailoring Evaluative Arguments to User&apos;s Preferences. User Modelling,</title>
<date>1999</date>
<pages>299--301</pages>
<location>Banff, Canada:</location>
<contexts>
<context position="2804" citStr="Carenini and Moore 1999" startWordPosition="390" endWordPosition="393"> effective arguments should be concise, presenting only pertinent and cogent information. In this paper, we propose an argumentation strategy for generating evaluative arguments that can be applied in systems serving as personal assistants or advisors. By following principles and guidelines from argumentation theory and by employing a quantitative model of the user&apos;s preference, our strategy generates evaluative arguments that are tailored to the user, properly arranged and concise. Although a preliminary version of our argumentative strategy was cursorily described in a previous short paper (Carenini and Moore 1999), this paper includes several additional contributions. First, we discuss how the strategy is grounded in the argumentation literature. Then, we provide details on the measures of argument strength and importance used in selecting and ordering argument support. Next, we generalize the argumentative strategy and correct some errors in its preliminary version. Finally, we discuss how our strategy extends the scope of previous approaches to generating evaluative arguments in terms of coverage (i.e., types of arguments), and in terms of compliance with principles from argumentation theory. Because</context>
</contexts>
<marker>Carenini, Moore, 1999</marker>
<rawString>Carenini, G. and J. Moore (1999). Tailoring Evaluative Arguments to User&apos;s Preferences. User Modelling, Banff, Canada: 299-301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chu-Carroll</author>
<author>S Carberry</author>
</authors>
<title>Collaborative Response Generation in Planning Dialogues.</title>
<date>1998</date>
<journal>Computational Linguistics</journal>
<volume>24</volume>
<issue>2</issue>
<pages>355--400</pages>
<contexts>
<context position="22986" citStr="Chu-Carroll and Carberry 1998" startWordPosition="3505" endWordPosition="3508"> of evidence strength (an ordinal scale that appears to range from very-important to notimportant). This limits the ability of the system to select and arrange argument evidence, because qualitative measures only support approximate comparisons and are notoriously difficult to combine (e.g., how many &amp;quot;somewhat-important&amp;quot; pieces of evidence are equivalent to an &amp;quot;important&amp;quot;. ,. piece of evidence?). s The generation of fluent English also required the development of microplannin2 and realization components. For lack of space, we do not discuss them in this paper. (Elzer, Chu-Carroli et al. 1994; Chu-Carroll and Carberry 1998) studied the generation of evaluative arguments in the context of collaborative planning dialogues. Although they also adopt a qualitative measure of evidence strength, when an evaluation is needed this measure is mapped into numerical values so that preferences can be compared and combined effectiveIyAbakvever;awitivrespeet to &apos;-oUr• approach, this work makes two strong simplifying assumptions. It only considers the decomposition of the preference for an entity into preferences for its primitive attributes (not considering that complex preferences frequently have a hierarchical structure). Ad</context>
</contexts>
<marker>Chu-Carroll, Carberry, 1998</marker>
<rawString>Chu-Carroll, J. and S. Carberry (1998). Collaborative Response Generation in Planning Dialogues. Computational Linguistics 24(2): 355-400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R T Clemen</author>
</authors>
<title>Making Hard Decisions: an introduction to decision analysis.</title>
<date>1996</date>
<publisher>Duxbury Press</publisher>
<contexts>
<context position="8473" citStr="Clemen 1996" startWordPosition="1241" endWordPosition="1242">IBUTES Location .0.76.•••■ 0..7z House Value 0.X Size 0.8 ,.........s... Neighborhood xl I vl (xl) Distance-from-park i/-of-room Storage-space gi=nl 0 x1=n2 02 xl=n3 1 x2 I V2() o=&lt;x2&lt;=5 1.(1/5* x2y x2&amp;quot;.5 o • .. Figure 1 Sample additive multiattribute value function (AMVF) representing whether the reader is or is not aware of certain facts (needed in guideline 0. 2 From Guidelines to the Argumentation Strategy We assume that the reader&apos;s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). Besides being widely used in decision theory (where they were originally developed), conceptualizations based on MAUT have recently become a common choice in the field of user modelling (Jameson, Schafer et al. 1995). Similar models are also used in Psychology, in the study of consumer behaviour (Solomon 1998). 2.1 Background on AMVF An AMVF is a model of a person&apos;s values and preferences with respect to entities in a certain class. It comprises a value tree and a set of component value functions, one for each attribute of the entity. A value tree is a decomposition of the value of an entity</context>
</contexts>
<marker>Clemen, 1996</marker>
<rawString>Clemen, R: T. (1996). Making Hard Decisions: an introduction to decision analysis. Duxbury Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>E P J Corbett</author>
<author>R J Connors</author>
</authors>
<title>Classical Rhetoric for the Modern Student,</title>
<date>1999</date>
<publisher>University Press.</publisher>
<location>Oxford</location>
<contexts>
<context position="1762" citStr="Corbett and Connors 1999" startWordPosition="249" endWordPosition="252">guments attempt to affect attitudes (i.e., evaluative tendencies typically phrased in terms of like and dislike or favor and disfavor). With the ever growing use of the Web, an increasing number of systems that serve as personal assistants, advisors, or sales assistants are becoming available online&apos;. These systems frequently need to generate evaluative arguments for domain entities. For instance, a real-estate assistant may need to compare two houses, arguing that one would be a better choice than the other for its user. Argumentation theory (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999) indicates that effective arguments should be constructed following three &apos; See for instance www.activebuyersguide.com general principles. First, arguments should be constructed considering the dispositions of the audience towards the information presented. Second, sub-arguments supporting or opposing the main argument claim should be carefully arranged by considering their strength of support or opposition. Third, effective arguments should be concise, presenting only pertinent and cogent information. In this paper, we propose an argumentation strategy for generating evaluative arguments that</context>
<context position="4197" citStr="Corbett and Connors 1999" startWordPosition="596" endWordPosition="599">m Argumentation Theory An argumentation strategy specifies what content should be included in the argument and how it should be arranged. This comprises several decisions: what represents supporting (or opposing) evidence for the main claim, where to position the main claim of the argument, what supporting (or opposing) evidence to include and how to order it, and how to order supporting - and opposing evidence with respect to each other. Argumentation theory has developed guidelines specifying how these decisions can be effectively made (see (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999; McGuire 1968) for details; see also (Marcu 1996) for an alternative discussion of some of the same guidelines). (a) What represents supporting (or opposing) evidence for a claim — Guidelines for this decision vary depending on the argument type. Limiting our analysis to evaluative arguments, argumentation theory indicates that supporting and opposing evidence should be identified according to a model of the reader&apos;s values and preferences. For instance, the risk involved in a game can be used as evidence for why your reader should like the game, only if the reader likes risky situations. (b)</context>
</contexts>
<marker>Corbett, Connors, 1999</marker>
<rawString>Corbett, E. P. J. and R. J. Connors (1999). Classical Rhetoric for the Modern Student, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elhadad</author>
</authors>
<title>Using Argumentation to Control Lexical Choice: A Functional Unification Implementation.</title>
<date>1992</date>
<tech>PhD Thesis,</tech>
<location>CS. Columbia. NY.</location>
<contexts>
<context position="21552" citStr="Elhadad 1992" startWordPosition="3298" endWordPosition="3299">aluation of any house just by dragging the graphical representation of the house to a query button. The evaluative arguments generated by the system are concise, properly arranged and tailored to the user&apos;s preferences8. For sample arguments generated by our strategy see (Carenini 2000b) in this proceedings. 3 Previous Work Although considerable research has been devoted to study the generation of evaluative arguments, all approaches proposed so far are limited in the type of evaluative arguments generated, and in the extent to which they comply with guidelines from argumentation literature. (Elhadad 1992) investigated a general computational framework that covers all aspects of generating evaluative arguments of single entities, from content selection and structuring to fine-grained realization decisions. However, his work concentrates on the linguistic aspects. His approach to content selection and structuring does not provide a measure of evidence strength, which is necessary to implement several of the guidelines from argumentation literature we have examined. Other studies have focused more on the process of content selection and structuring. However, with respect to our proposal, they sti</context>
</contexts>
<marker>Elhadad, 1992</marker>
<rawString>Elhadad, M. (1992). Using Argumentation to Control Lexical Choice: A Functional Unification Implementation. PhD Thesis, CS. Columbia. NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Elzer</author>
<author>Carroll - 1—Chu</author>
</authors>
<title>Recognizing and Utilizing User Preferences in Collaborative Consultation Dialogues.</title>
<date>1994</date>
<booktitle>Proceedings of Fourth Int. Conf. of User Modeling.</booktitle>
<location>Hyannis, MA:</location>
<marker>Elzer, 1—Chu, 1994</marker>
<rawString>Elzer, .S.,-...1—Chu,Carroll,....et. al. (.1994). Recognizing and Utilizing User Preferences in Collaborative Consultation Dialogues. Proceedings of Fourth Int. Conf. of User Modeling. Hyannis, MA: 19-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jameson</author>
<author>R Schafer</author>
</authors>
<title>Adaptive provision of Evaluation-Oriented Information: Tasks and techniques.</title>
<date>1995</date>
<booktitle>Proc. of 14th IJCAI.</booktitle>
<location>Montreal, Canada.</location>
<marker>Jameson, Schafer, 1995</marker>
<rawString>Jameson, A., R. Schafer, et al. (1995). Adaptive provision of Evaluation-Oriented Information: Tasks and techniques. Proc. of 14th IJCAI. Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
</authors>
<title>Decision Analytic Intelligent Systems: Automated &amp;planation and Knowledge Acquisition, Lawrence Erlbaum Associates.</title>
<date>1994</date>
<contexts>
<context position="13698" citStr="Klein 1994" startWordPosition="2137" endWordPosition="2138">iscrepancy(MD) as the absolute value of the difference between the argumentative intent and the reader&apos;s expected value of the subject before the argument is presented (based on her AMVF), a claim becomes more and more &amp;quot;objectionable&amp;quot; for a reader as MD moves from 0 to I. Guidelines.,(c) (e) -The &apos;strength of the evidence in support of (or opposition to) the main argument claim is critical in selecting and organizing the argument content. To define a measure of the strength of support (or opposition), we adopt and extend previous work on explaining decision theoretic advice based on an AMVF. (Klein 1994) presents explanation strategies (not based on argumentation theory) to justify the preference of one alternative from a pair. In these strategies, the compellingness of an objective measures the objective&apos;s strength in determining the overall value difference between the two alternatives, other things being equal. And an objective is notably-compelling? (i.e., worth mentioning) if it is an outlier in a population of objectives with respect to compellingness. The formal definitions are: compellingness(o,ab a2, refo) = = w(o,refo)[vo(ad —vo(a2)l, where - o is an objective, al and a2 are alterna</context>
<context position="24183" citStr="Klein 1994" startWordPosition="3677" endWordPosition="3678">structure). Additionally, it assumes that the same dialogue turn cannot provide both supporting and opposing evidence. (Kolln 1995) proposes a framework for generating evaluative arguments which is based on a quantitative measure of evidence strength. Evidence strength is computed on a fuzzy hierarchical representation of user preferences. Although this fuzzy representation may represent a viable alternative to the AMVF we have discussed in this paper, Kolln&apos;s proposal is rather sketchy in describing how his measure of strength can be used to select and arrange the argument content. Finally, (Klein 1994) is the previous work most relevant to our proposal. Klein developed a framework for generating explanations to justify the preference of an entity out of a pair. These strategies were not based on argumentation theory. As described in Section 2.2, from this work, we have adapted a measure of evidence strength (i.e., cotnpellingness), and a measure that defines when a piece of evidence is worth mentioning (i.e., notably-compelling?). Conclusions and Future Work In this paper, we propose . an argumentation strategy that extends previous research on generating evaluative arguments in two ways. O</context>
</contexts>
<marker>Klein, 1994</marker>
<rawString>Klein, D. (1994). Decision Analytic Intelligent Systems: Automated &amp;planation and Knowledge Acquisition, Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Kolln</author>
</authors>
<title>Employing User Attitudes</title>
<date>1995</date>
<booktitle>in Text Planning. 5th European Workshop on Natural Language Generation,</booktitle>
<location>Leiden, The Netherlands.</location>
<contexts>
<context position="23703" citStr="Kolln 1995" startWordPosition="3605" endWordPosition="3606">gh they also adopt a qualitative measure of evidence strength, when an evaluation is needed this measure is mapped into numerical values so that preferences can be compared and combined effectiveIyAbakvever;awitivrespeet to &apos;-oUr• approach, this work makes two strong simplifying assumptions. It only considers the decomposition of the preference for an entity into preferences for its primitive attributes (not considering that complex preferences frequently have a hierarchical structure). Additionally, it assumes that the same dialogue turn cannot provide both supporting and opposing evidence. (Kolln 1995) proposes a framework for generating evaluative arguments which is based on a quantitative measure of evidence strength. Evidence strength is computed on a fuzzy hierarchical representation of user preferences. Although this fuzzy representation may represent a viable alternative to the AMVF we have discussed in this paper, Kolln&apos;s proposal is rather sketchy in describing how his measure of strength can be used to select and arrange the argument content. Finally, (Klein 1994) is the previous work most relevant to our proposal. Klein developed a framework for generating explanations to justify </context>
</contexts>
<marker>Kolln, 1995</marker>
<rawString>Kolln, M. E. (1995). Employing User Attitudes in Text Planning. 5th European Workshop on Natural Language Generation, Leiden, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>The Conceptual and Linguistic Facets of Persuasive Arguments.</title>
<date>1996</date>
<booktitle>ECAI workshop -Gaps and Bridges: New Directions in Planning and Natural Language Generation.</booktitle>
<contexts>
<context position="4247" citStr="Marcu 1996" startWordPosition="606" endWordPosition="607"> content should be included in the argument and how it should be arranged. This comprises several decisions: what represents supporting (or opposing) evidence for the main claim, where to position the main claim of the argument, what supporting (or opposing) evidence to include and how to order it, and how to order supporting - and opposing evidence with respect to each other. Argumentation theory has developed guidelines specifying how these decisions can be effectively made (see (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999; McGuire 1968) for details; see also (Marcu 1996) for an alternative discussion of some of the same guidelines). (a) What represents supporting (or opposing) evidence for a claim — Guidelines for this decision vary depending on the argument type. Limiting our analysis to evaluative arguments, argumentation theory indicates that supporting and opposing evidence should be identified according to a model of the reader&apos;s values and preferences. For instance, the risk involved in a game can be used as evidence for why your reader should like the game, only if the reader likes risky situations. (b) Positioning the main claim - Claims are often pre</context>
</contexts>
<marker>Marcu, 1996</marker>
<rawString>Marcu, D. (1996). The Conceptual and Linguistic Facets of Persuasive Arguments. ECAI workshop -Gaps and Bridges: New Directions in Planning and Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Mayberry</author>
<author>R E Golden</author>
</authors>
<title>For Argument&apos;s Sake: A Guide to Writing Effective Arguments, Harper Collins,</title>
<date>1996</date>
<publisher>College Publisher.</publisher>
<contexts>
<context position="1711" citStr="Mayberry and Golden 1996" startWordPosition="241" endWordPosition="244">hing is or is not the case), whereas evaluative arguments attempt to affect attitudes (i.e., evaluative tendencies typically phrased in terms of like and dislike or favor and disfavor). With the ever growing use of the Web, an increasing number of systems that serve as personal assistants, advisors, or sales assistants are becoming available online&apos;. These systems frequently need to generate evaluative arguments for domain entities. For instance, a real-estate assistant may need to compare two houses, arguing that one would be a better choice than the other for its user. Argumentation theory (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999) indicates that effective arguments should be constructed following three &apos; See for instance www.activebuyersguide.com general principles. First, arguments should be constructed considering the dispositions of the audience towards the information presented. Second, sub-arguments supporting or opposing the main argument claim should be carefully arranged by considering their strength of support or opposition. Third, effective arguments should be concise, presenting only pertinent and cogent information. In this paper, we propose an argumentatio</context>
<context position="4147" citStr="Mayberry and Golden 1996" startWordPosition="588" endWordPosition="591">nerating arguments in general. 47 1 Guidelines from Argumentation Theory An argumentation strategy specifies what content should be included in the argument and how it should be arranged. This comprises several decisions: what represents supporting (or opposing) evidence for the main claim, where to position the main claim of the argument, what supporting (or opposing) evidence to include and how to order it, and how to order supporting - and opposing evidence with respect to each other. Argumentation theory has developed guidelines specifying how these decisions can be effectively made (see (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999; McGuire 1968) for details; see also (Marcu 1996) for an alternative discussion of some of the same guidelines). (a) What represents supporting (or opposing) evidence for a claim — Guidelines for this decision vary depending on the argument type. Limiting our analysis to evaluative arguments, argumentation theory indicates that supporting and opposing evidence should be identified according to a model of the reader&apos;s values and preferences. For instance, the risk involved in a game can be used as evidence for why your reader should like the ga</context>
<context position="5845" citStr="Mayberry and Golden 1996" startWordPosition="856" endWordPosition="859"> all the available evidence, usually for the sake of brevity. Only strong evidence should be presented in detail, whereas weak evidence should be either briefly mentioned or omitted entirely. (d) Arranging/Ordering supporting evidence — Typically the strongest support should be presented first, in order to get at least provisional agreement from the reader early on. If at all possible, at least one very effective piece of supporting evidence should be saved for the end of the argument, in order to leave the reader with a final impression of the argument&apos;s strength. This guideline proposed in (Mayberry and Golden 1996) is a compromise between the climax and the anti-climax approaches discussed in (McGuire 1968). (e) Addressing and ordering the counterarguments (opposing evidence) — There .are ...three ....options. for dhis..xlecision: not to mention any counterarguments, to acknowledge them without directly refuting them, to acknowledge them and directly refuting them. Weak counterarguments may be omitted. Stronger counterarguments should be briefly acknowledged, because that shows the reader that you are aware of the issue&apos;s complexity; and it also contributes to the impression that you are reasonable and </context>
</contexts>
<marker>Mayberry, Golden, 1996</marker>
<rawString>Mayberry, K. J. and R. E. Golden (1996). For Argument&apos;s Sake: A Guide to Writing Effective Arguments, Harper Collins, College Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J McGuire</author>
</authors>
<title>The Nature of Attitudes and Attitudes Change.</title>
<date>1968</date>
<journal>AddisonWesley.</journal>
<booktitle>The Handbook of Social Psychology. G. Lindzey</booktitle>
<volume>3</volume>
<pages>136--314</pages>
<contexts>
<context position="4212" citStr="McGuire 1968" startWordPosition="600" endWordPosition="601">argumentation strategy specifies what content should be included in the argument and how it should be arranged. This comprises several decisions: what represents supporting (or opposing) evidence for the main claim, where to position the main claim of the argument, what supporting (or opposing) evidence to include and how to order it, and how to order supporting - and opposing evidence with respect to each other. Argumentation theory has developed guidelines specifying how these decisions can be effectively made (see (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999; McGuire 1968) for details; see also (Marcu 1996) for an alternative discussion of some of the same guidelines). (a) What represents supporting (or opposing) evidence for a claim — Guidelines for this decision vary depending on the argument type. Limiting our analysis to evaluative arguments, argumentation theory indicates that supporting and opposing evidence should be identified according to a model of the reader&apos;s values and preferences. For instance, the risk involved in a game can be used as evidence for why your reader should like the game, only if the reader likes risky situations. (b) Positioning th</context>
<context position="5939" citStr="McGuire 1968" startWordPosition="872" endWordPosition="873">detail, whereas weak evidence should be either briefly mentioned or omitted entirely. (d) Arranging/Ordering supporting evidence — Typically the strongest support should be presented first, in order to get at least provisional agreement from the reader early on. If at all possible, at least one very effective piece of supporting evidence should be saved for the end of the argument, in order to leave the reader with a final impression of the argument&apos;s strength. This guideline proposed in (Mayberry and Golden 1996) is a compromise between the climax and the anti-climax approaches discussed in (McGuire 1968). (e) Addressing and ordering the counterarguments (opposing evidence) — There .are ...three ....options. for dhis..xlecision: not to mention any counterarguments, to acknowledge them without directly refuting them, to acknowledge them and directly refuting them. Weak counterarguments may be omitted. Stronger counterarguments should be briefly acknowledged, because that shows the reader that you are aware of the issue&apos;s complexity; and it also contributes to the impression that you are reasonable and broad-minded. You may need to refute a counterargument once you have acknowledged it, if the r</context>
</contexts>
<marker>McGuire, 1968</marker>
<rawString>McGuire, W. J. (1968). The Nature of Attitudes and Attitudes Change. The Handbook of Social Psychology. G. Lindzey and E. Aronson, AddisonWesley. 3: 136-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Miller</author>
<author>T R Levine</author>
</authors>
<title>Persuasion. An Integrated Approach to Communication Theory</title>
<date>1996</date>
<pages>261--276</pages>
<location>New Jersey:</location>
<contexts>
<context position="1735" citStr="Miller and Levine 1996" startWordPosition="245" endWordPosition="248">), whereas evaluative arguments attempt to affect attitudes (i.e., evaluative tendencies typically phrased in terms of like and dislike or favor and disfavor). With the ever growing use of the Web, an increasing number of systems that serve as personal assistants, advisors, or sales assistants are becoming available online&apos;. These systems frequently need to generate evaluative arguments for domain entities. For instance, a real-estate assistant may need to compare two houses, arguing that one would be a better choice than the other for its user. Argumentation theory (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999) indicates that effective arguments should be constructed following three &apos; See for instance www.activebuyersguide.com general principles. First, arguments should be constructed considering the dispositions of the audience towards the information presented. Second, sub-arguments supporting or opposing the main argument claim should be carefully arranged by considering their strength of support or opposition. Third, effective arguments should be concise, presenting only pertinent and cogent information. In this paper, we propose an argumentation strategy for generatin</context>
<context position="4171" citStr="Miller and Levine 1996" startWordPosition="592" endWordPosition="595">ral. 47 1 Guidelines from Argumentation Theory An argumentation strategy specifies what content should be included in the argument and how it should be arranged. This comprises several decisions: what represents supporting (or opposing) evidence for the main claim, where to position the main claim of the argument, what supporting (or opposing) evidence to include and how to order it, and how to order supporting - and opposing evidence with respect to each other. Argumentation theory has developed guidelines specifying how these decisions can be effectively made (see (Mayberry and Golden 1996; Miller and Levine 1996; Corbett and Connors 1999; McGuire 1968) for details; see also (Marcu 1996) for an alternative discussion of some of the same guidelines). (a) What represents supporting (or opposing) evidence for a claim — Guidelines for this decision vary depending on the argument type. Limiting our analysis to evaluative arguments, argumentation theory indicates that supporting and opposing evidence should be identified according to a model of the reader&apos;s values and preferences. For instance, the risk involved in a game can be used as evidence for why your reader should like the game, only if the reader l</context>
</contexts>
<marker>Miller, Levine, 1996</marker>
<rawString>Miller, M. D. and T. R. Levine (1996). Persuasion. An Integrated Approach to Communication Theory and Research. M. B. Salwen and D. W. Stack. Mahwah, New Jersey: 261-276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Monk</author>
</authors>
<title>User Models and Conversational Settings: Modeling the User&apos;s Wants. User Models in Dialog Systems.</title>
<date>1989</date>
<journal>A. Kobsa</journal>
<pages>364--385</pages>
<publisher>Springer-Verlag:</publisher>
<contexts>
<context position="22196" citStr="Monk 1989" startWordPosition="3388" endWordPosition="3389">nal framework that covers all aspects of generating evaluative arguments of single entities, from content selection and structuring to fine-grained realization decisions. However, his work concentrates on the linguistic aspects. His approach to content selection and structuring does not provide a measure of evidence strength, which is necessary to implement several of the guidelines from argumentation literature we have examined. Other studies have focused more on the process of content selection and structuring. However, with respect to our proposal, they still suffer from some limitations. (Monk 1989) describes a system that uses a measure of evidence strength to tailor evaluations of hotel rooms to its users. However, her system adopts a qualitative measure of evidence strength (an ordinal scale that appears to range from very-important to notimportant). This limits the ability of the system to select and arrange argument evidence, because qualitative measures only support approximate comparisons and are notoriously difficult to combine (e.g., how many &amp;quot;somewhat-important&amp;quot; pieces of evidence are equivalent to an &amp;quot;important&amp;quot;. ,. piece of evidence?). s The generation of fluent English also </context>
</contexts>
<marker>Monk, 1989</marker>
<rawString>Monk, K. (1989). User Models and Conversational Settings: Modeling the User&apos;s Wants. User Models in Dialog Systems. A. Kobsa and W. Wahlster, Springer-Verlag: 364-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Reed</author>
<author>D Long</author>
</authors>
<title>Content Ordering in the Generation of Persuasive Discourse.</title>
<date>1997</date>
<booktitle>Proc. of the 15th &apos;JCR&apos;,</booktitle>
<location>Nagoya, Japan.</location>
<contexts>
<context position="25814" citStr="Reed and Long 1997" startWordPosition="3917" endWordPosition="3920">ralize our approach to more complex models of user preferences. Second, although our strategy is based on insights from argumentation theory, the ultimate arbiter for effectiveness is empirical evaluation. Therefore, we have _developed ,an—ev.aluation environment to verify whether arguments generated by our strategy actually affect user attitudes in the intended direction (Carenini 2000b). A third area for future work is the exploration of techniques to improve the coherence of arguments generated by our strategy. In the short term, we intend to integrate the ordering heuristics suggested in (Reed and Long 1997). In the long term, by modelling user attention and retention, we intend to enable our strategy to assess in a principled way when repeating the same information can strengthen argument force. Finally, we plan to extend our strategy to evaluative arguments for comparisons between mixtures of entities and set of entities. Acknowledgements Our thanks go to the members of the Autobrief project: S. Roth, N. Green, S. Kerpedjiev and J. Mattis. We also thank C. Conati for comments on drafts of this paper. This work was supported by grant number DAA-1593K0005 from the Advanced Research Projects Agenc</context>
</contexts>
<marker>Reed, Long, 1997</marker>
<rawString>Reed, C. and D. Long (1997). Content Ordering in the Generation of Persuasive Discourse. Proc. of the 15th &apos;JCR&apos;, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Solomon</author>
</authors>
<title>Consumer Behavior: Buying, Having, and Being.</title>
<date>1998</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="8786" citStr="Solomon 1998" startWordPosition="1289" endWordPosition="1290">is not aware of certain facts (needed in guideline 0. 2 From Guidelines to the Argumentation Strategy We assume that the reader&apos;s values and preferences are represented as an additive multiattribute value function (AMVF), a conceptualization based on multiattribute utility theory (MAUT)(Clemen 1996). Besides being widely used in decision theory (where they were originally developed), conceptualizations based on MAUT have recently become a common choice in the field of user modelling (Jameson, Schafer et al. 1995). Similar models are also used in Psychology, in the study of consumer behaviour (Solomon 1998). 2.1 Background on AMVF An AMVF is a model of a person&apos;s values and preferences with respect to entities in a certain class. It comprises a value tree and a set of component value functions, one for each attribute of the entity. A value tree is a decomposition of the value of an entity into a hierarchy of aspects of the entity3, in which the leaves correspond to the entity primitive attributes (see Figure 1 for a simple value tree in the real estate domain). The arcs of the tree are weighted to represent the importance of the value of an objective in contributing to the value 3 In decision th</context>
</contexts>
<marker>Solomon, 1998</marker>
<rawString>Solomon, M. R. (1998). Consumer Behavior: Buying, Having, and Being. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Young</author>
<author>J D Moore</author>
</authors>
<title>Does Discourse Planning Require a Special-Purpose Planner?</title>
<date>1994</date>
<booktitle>Proc. of the AAAI-94 Workshop on planning for Interagent Communication.</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="18790" citStr="Young and Moore 1994" startWordPosition="2927" endWordPosition="2930">t is true when the user is aware of a certain fact, false otherwise. Finally, in the third part of the strategy, the argument claim is expressed in natural language. The opposing evidence (i.e., ContrastingSubObjectives), that must be considered, but not in detail, is also expressed in natural language. In contrast, supporting evidence is presented in detail, by recursively calling the strategy on each supporting piece of evidence. 2.4 Implementation and Application The argumentation strategy has been implemented as a set of plan operators. Using these operators the Longbow discourse planner (Young and Moore 1994) selects and arranges the content of the argument. We have applied our strategy in a system that serves as a realestate personal assistant (Carenini 2000a). The system presents information about houses available on the market in graphical format. The user explores this information by means of interactive techniques, and can request a natural The steps in the strategy are marked with the guideline they arc based on. 51 Argue(subject, Root, ArgInt, k) ;; assignments and content selection If subject = single-entity = e then Silo, = vo,(e) Measure-of-strength = s-compellingness Worth-mention? = s-</context>
</contexts>
<marker>Young, Moore, 1994</marker>
<rawString>Young, M. R. and J. D. Moore (1994). Does Discourse Planning Require a Special-Purpose Planner? Proc. of the AAAI-94 Workshop on planning for Interagent Communication. Seattle, WA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>