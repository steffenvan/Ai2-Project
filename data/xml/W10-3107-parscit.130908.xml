<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009360">
<title confidence="0.99731">
Levels of Certainty in Knowledge-Intensive Corpora:
An Initial Annotation Study
</title>
<author confidence="0.996496">
Aron Henriksson
</author>
<affiliation confidence="0.8882735">
DSV/KTH-Stockholm University
Sweden
</affiliation>
<email confidence="0.988638">
aronhen@dsv.su.se
</email>
<sectionHeader confidence="0.993585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999984916666667">
In this initial annotation study, we sug-
gest an appropriate approach for determin-
ing the level of certainty in text, including
classification into multiple levels of cer-
tainty, types of statement and indicators of
amplified certainty. A primary evaluation,
based on pairwise inter-annotator agree-
ment (IAA) using Fl-score, is performed
on a small corpus comprising documents
from the World Bank. While IAA results
are low, the analysis will allow further re-
finement of the created guidelines.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983173483870968">
Despite ongoing efforts to codify knowledge, it is
often communicated in an informal manner. In
our choice of words and expressions, we implicitly
or explicitly judge the certainty of the knowledge
we wish to convey. This fact makes it possible
to gauge the reliability of knowledge based on the
subjective perspective of the author.
As knowledge is often difficult to ascertain, it
seems reasonable to regard knowledge on a contin-
uum of varying degrees of certainty, as opposed to
a binary (mis)conception. This corresponds to the
notion of epistemic modality: the degree of confi-
dence in, or commitment to, the truth of proposi-
tions (Hyland, 1998). Hedging is a means of af-
fecting epistemic modality by qualifying proposi-
tions, realized through tentative words and expres-
sions such as possibly and tends to.
A holistic perspective on certainty—in which
not only speculation is considered, but also signs
of increased certainty—requires a classification
into various levels. Applying such an approach
to knowledge-intensive corpora, it may in due
course be possible to evaluate unstructured, infor-
mal knowledge. This would not least be valuable
to organizational knowledge management prac-
Sumithra Velupillai
DSV/KTH-Stockholm University
Sweden
sumithra@dsv.su.se
tices, where it could provide a rough indicator of
reliability in internal knowledge audits.
</bodyText>
<sectionHeader confidence="0.998099" genericHeader="introduction">
2 Related Research
</sectionHeader>
<bodyText confidence="0.9995105625">
The hedging concept was first introduced by
Lakoff (1973) but has only really come into the
spotlight in more recent years. Studies have
mainly taken place in the biomedical domain, with
Hyland’s (1998) influential work investigating the
phenomenon in scientific research articles. Spec-
ulative keywords and negations, along with their
linguistic scopes, are annotated in the BioScope
corpus by Vincze et al. (2008), which contains a
large collection of medical and biological text (sci-
entific articles and abstracts, as well as radiology
reports). After several iterations of refining their
guidelines, they report IAA values ranging from
77.6 to 92.37 Fl-score for speculative keywords
(62.5 and 95.54 Fl-score for full scope). This cor-
pus is freely available and has been used for train-
ing and evaluation of automatic classifiers, see e.g.
Morante and Daelemans (2009). One of the main
findings is that hedge cues are highly domain-
dependent. Automatic identification of other pri-
vate states, including opinions, represents a sim-
ilar task, see e.g. Wiebe et al. (2005). Diab et
al. (2009) study annotation of committed and non-
committed belief and show that automatic tagging
of such classes is feasible. A different annotation
approach is proposed by Rubin et al. (2006), in
which certainty in newspaper articles is catego-
rized along four dimensions: level, perspective, fo-
cus and time. Similarly, five dimensions are used
in Wilbur et al. (2006) for the creation of an an-
notated corpus of biomedical text: focus, polarity,
certainty, evidence and directionality.
</bodyText>
<sectionHeader confidence="0.990848" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.9978835">
Based on previous approaches and an extensive lit-
erature review, we propose a set of guidelines that
</bodyText>
<page confidence="0.995952">
41
</page>
<subsubsectionHeader confidence="0.34394">
Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 41–45,
</subsubsectionHeader>
<bodyText confidence="0.994013590163934">
Uppsala, July 2010.
(1) incorporates some new features and (2) shifts
the perspective to suit knowledge-intensive cor-
pora, e.g. comprising organizational knowledge
documents. Besides categorization into levels of
certainty, this approach distinguishes between two
types of statement and underscores the need to
take into account words and expressions that add
certainty to a proposition.
A small corpus of 10 World Bank documents—
a publicly available resource known as Viewpoints
(The World Bank Group, 2010)—is subsequently
annotated in two sets by different annotators. The
corpus is from a slightly different domain to those
previously targeted and represents an adequate al-
ternative to knowledge documents internal to an
organization by fulfilling the criterion of knowl-
edge intensity. The process is carried out in a
Prot´eg´e plugin: Knowtator (Ogren, 2006). Pair-
wise IAA, measured as Fl-score, is calculated to
evaluate the feasibility of the approach.
Statements are annotated at the clause level, as
sentences often contain subparts subject to differ-
ent levels of certainty. These are not predefined
and the span of classes is determined by the an-
notator. Furthermore, a distinction is made be-
tween different types of statement: statements that
give an account of something, typically a report
of past events, and statements that express con-
crete knowledge claims. The rationale behind this
distinction is that text comprises statements that
make more or less claims of constituting knowl-
edge. Thus, knowledge claims—often less preva-
lent than accounts—should be given more weight
in the overall assessment, as the application lies
in automatically evaluating the reliability of infor-
mal knowledge. Assuming the view of knowledge
and certainty as continuous, it is necessary to dis-
cretize that into a number of intervals, albeit more
than two. Hence, accounts and claims are cate-
gorized according to four levels of certainty: very
certain, quite certain, quite uncertain and very un-
certain. In addition to the statement classes, four
indicators make up the total of twelve. We in-
troduce certainty amplifiers, which have received
little attention in previous work. These are lin-
guistic features that add certainty to a statement,
e.g. words like definitely and expressions like
without a shadow of a doubt. Hedging indica-
tors, on the other hand, have gained much atten-
tion recently and signify uncertainty. The source
hedge class is applicable to instances where the
source of epistemic judgement is stated explicitly,
yet only when it provides a hedging function (e.g.
some say). Modality strengtheners are features
that strengthen the effect of epistemic modality
when used in conjunction with other (un)certainty
indicators—but alone do not signify any polarity
orientation—and may be in the form of vagueness
(e.g. &lt;could be&gt; around that number) or quantity
gradations (e.g. very &lt;sure&gt;).
</bodyText>
<sectionHeader confidence="0.999899" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.9990648">
The corpus contains a total of 772 sentences,
which are annotated twice: set #1 by one anno-
tator and set #2 by five annotators, annotating two
documents each. The statistics in Table 1 show
a discrepancy over the two sets in the number of
classified statements, which is likely due to diffi-
culties in determining the scope of clauses. There
are likewise significant differences in the propor-
tion between accounts and claims, as had been an-
ticipated.
</bodyText>
<table confidence="0.990307666666667">
Accounts Claims
Set #1 Set #2 Set #1 Set #2
726 574 395 393
</table>
<tableCaption confidence="0.999825">
Table 1: Frequencies of accounts and claims.
</tableCaption>
<bodyText confidence="0.998104428571429">
Despite the problem of discriminating between ac-
counts and claims, they seem to be susceptible to
varying levels of certainty. The average distribu-
tion of certainty for account statements is depicted
in Figure 1. As expected, an overwhelming ma-
jority (87%) of such statements are quite certain,
merely relating past events and established facts.
</bodyText>
<figureCaption confidence="0.936212">
Figure 1: Average distribution of certainty in ac-
count statements.
</figureCaption>
<bodyText confidence="0.9802018">
By comparison, knowledge claims are more
commonly hedged (23%), although the majority
is still quite certain. Interestingly, claims are also
expressed with added confidence more often than
accounts—around one in every ten claims.
</bodyText>
<page confidence="0.997801">
42
</page>
<figureCaption confidence="0.993791">
Figure 2: Average distribution of certainty in
knowledge claims.
</figureCaption>
<bodyText confidence="0.998842916666667">
As expected, the most common indicator is of
hedging. Common cues include may, can, might,
could, indicate(s), generally and typically. Many
of these cues are also among the most common in
the biomedical sub-corpus of BioScope (Vincze et
al., 2008). It is interesting to note the fairly com-
mon phenomenon of certainty amplifiers. These
are especially interesting, as they have not been
studied much before, although Wiebe et al. (2005)
incorporate intensity ratings in their annotation
scheme. There is agreement on words like clearly,
strongly and especially.
</bodyText>
<table confidence="0.9998976">
Indicator Set #1 Set #2
Certainty amplifier 61 29
Hedging indicator 151 133
Source hedge 0 40
Modality strengthener 9 122
</table>
<tableCaption confidence="0.998327">
Table 2: Frequency of indicators
</tableCaption>
<bodyText confidence="0.993813222222222">
To evaluate the approach, we calculate IAA by
pairwise F1-score, considering set #1 as the gold
standard, i.e. as correctly classified, in relation to
which the other subsets are evaluated. We do this
for exact matches and partial matches1. For exact
matches in a single document, the F1-score val-
ues range from an extremely low 0.09 to a some-
what higher—although still poor—0.52, yielding
an overall average of 0.28. These results clearly
reflect the difficulty of the task, although one has
to keep in mind the impact of the discrepancy in
the number of annotations. This is partly reflected
in the higher overall average for partial matches:
0.41.
Certainty amplifiers and hedging indicators
have F1-scores that range up to 0.53 and 0.55 re-
spectively (ditto for partial matches) in a single
document. Over the entire corpus, however, the
</bodyText>
<footnote confidence="0.7926075">
1Partial matches are calculated on a character level while
exact matches are calculated on a token level.
</footnote>
<bodyText confidence="0.999726470588235">
averages come down to 0.27 for certainty ampli-
fiers (0.30 for partial matches) and 0.33 for hedg-
ing indicators (0.35 for partial matches).
Given the poor results, we want to find out
whether the main difficulty is presented by having
to judge certainty according to four levels of cer-
tainty, or whether it lies in having to distinguish
between types of statement. We therefore general-
ize the eight statement-related classes into a single
division between accounts and claims. Naturally,
the agreement is higher than for any single class,
with 0.44 for the former and 0.41 for the latter.
A substantial increase is seen in partial matches,
with 0.70 for accounts and 0.55 for claims. The
results are, however, sufficiently low to conclude
that there were real difficulties in distinguishing
between the two.
</bodyText>
<table confidence="0.994360666666667">
Statement Type Exact F1 Partial F1
Account 0.44 0.70
Claim 0.41 0.55
</table>
<tableCaption confidence="0.9619115">
Table 3: Pairwise IAA per statement type, F1-
scores for exact and partial matches.
</tableCaption>
<bodyText confidence="0.9990347">
We subsequently generalize the eight classes into
four, according to their level of certainty alone.
The results are again low: quite certain yields
the highest agreement at 0.47 (0.76 for partial
matches), followed by quite uncertain at 0.24
(0.35 for partial matches). These numbers suggest
that this part of the task is likewise difficult. The
rise in F1-scores for partial matches is noteworthy,
as it highlights the problem of different interpreta-
tions of clause spans.
</bodyText>
<table confidence="0.9996278">
Certainty Level Exact F1 Partial F1
Very certain 0.15 0.15
Quite certain 0.47 0.76
Quite uncertain 0.24 0.35
Very uncertain 0.08 0.08
</table>
<tableCaption confidence="0.993411">
Table 4: Pairwise IAA per certainty level, F1-
scores for exact and partial matches
</tableCaption>
<sectionHeader confidence="0.99889" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999933666666667">
In the guidelines, it is suggested that the level of
certainty can typically be gauged by identifying
the number of indicators. There is, however, a se-
rious drawback to this approach. Hedging indica-
tors, in particular, are inherently uncertain to dif-
ferent degrees. Consider the words possibly and
</bodyText>
<page confidence="0.999484">
43
</page>
<bodyText confidence="0.978534958333333">
probably. According to the guidelines, a single
occurrence of either of these hedging indicators
would normally render a statement quite uncer-
tain. Giving freer hands to the annotator might
be a way to evade this problem; however, it is not
likely to lead to any more consistent annotations.
Kilicoglu and Bergler (2008) address this by as-
signing weights to hedging cues.
A constantly recurring bone of contention is
presented by the relationship between certainty
and precision. One of the hardest judgements to
make is whether imprecision, or vagueness, is a
sign of uncertainty. Consider the following exam-
ple from the corpus:
Cape Verde had virtually no private sec-
tor.
Clearly, this statement would be more certain if it
had said: Cape Verde had no private sector. How-
ever, virtually no could be substituted with, say,
a very small, in which case the statement would
surely not be deemed uncertain. Perhaps precision
is a dimension of knowledge that should be ana-
lyzed in conjunction with certainty, but be anno-
tated separately.
</bodyText>
<sectionHeader confidence="0.995335" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999718375">
There are, of course, a number of ways one can
go about annotating the level of certainty from
a knowledge perspective. Some modifications to
the approach described here are essential—which
the low IAA values are testament to—while oth-
ers may be worth exploring. Below is a selection
of five key changes to the approach that may lead
to improved results:
</bodyText>
<listItem confidence="0.771217533333333">
1. Explicate statement types. Although there
seems to be a useful difference between the
two types, the distinction needs to be further
explicated in the guidelines.
2. Focus on indicators. It is clear that indicators
cannot be judged in an identical fashion only
because they have been identified as signify-
ing either certainty or uncertainty. It is not
simply the number of occurrences of indica-
tors that determines the level of certainty but
rather how strong those indicators are. A pos-
sible solution is to classify indicators accord-
ing to the level of certainty they affect.
3. Discard rare classes. Very rare phenomena
that do not have a significant impact on the
</listItem>
<bodyText confidence="0.94692536">
overall assessment can be sacrificed without
affecting the results negatively, which may
also make the task a little less difficult.
4. Clarify guidelines. A more general remedy
is to clarify further the guidelines, including
instructions on how to determine the scope of
clauses; alternatively, predefine them.
5. Instruct annotators. Exposing annotators
to the task would surely result in increased
agreement, in particular if they agree be-
forehand on the distinctions described in the
guidelines. At the same time, you do not
want to steer the process too much. Perhaps
the task is inherently difficult to define in de-
tail. Studies on how to exploit subjective an-
notations might be interesting to explore, see
e.g. Reidsma and op den Akker (2008).
In the attempt to gauge the reliability of knowl-
edge, incorporating multiple levels of certainty
becomes necessary, as does indicators of in-
creased certainty. Given the similar rates of
agreement on hedging indicators and certainty
amplifiers (0.33 and 0.27 respectively; 0.30 and
0.35 for partial matches), the latter class seem
to be confirmed. It is an existing and impor-
tant phenomenon, although—like hedging indica-
tors—difficult to judge. Moreover, a differentia-
tion between types of statement is important due
to their—to different degrees—varying claims of
constituting knowledge. An automatic classifier
built on such an approach could be employed with
significant benefit to organizations actively man-
aging their collective knowledge. The advantage
of being aware of the reliability of knowledge are
conceivably manifold: it could, for instance, be
(1) provided as an attribute to end-users brows-
ing documents, (2) used as metadata by search
engines, (3) used in knowledge audits and knowl-
edge gap analyses, enabling organizations to learn
when knowledge in a particular area needs to be
consolidated. It is, of course, also applicable in a
more general information extraction sense: infor-
mation that is extracted from text needs to have a
certainty indicator attached to it.
A dimension other than certainty that has a clear
impact on knowledge is precision. It would be in-
teresting to evaluate the reliability of knowledge
based on a combination of certainty and precision.
The annotated World Bank corpus will be made
available for further research on the Web.
</bodyText>
<page confidence="0.998905">
44
</page>
<sectionHeader confidence="0.98968" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992596181818182">
Mona T. Diab, Lori Levin, Teruko Mitamura, Owen
Rambow, Vinodkumar Prabhakaram, and Weiwei
Guo. 2009. Committed belief annotation and tag-
ging. In Proceedings of the Third Linguistic Annota-
tion Workshop, ACL-IJCNLP, pages 68–73, Suntec,
Singapore, August. ACL and AFNLP.
Ken Hyland. 1998. Hedging in Scientific Research Ar-
ticles. John Benjamins Publishing Company, Ams-
terdam/Philadelphia.
Halil Kilicoglu and Sabine Bergler. 2008. Recogniz-
ing speculative language in biomedical research ar-
ticles: a linguistically motivated perspective. BMC
Bioinformatics, 9.
George Lakoff. 1973. Hedges: A study in meaning
criteria and the logic of fuzzy concepts. Journal of
Philosophical Logic, 2:458–508.
Roser Morante and Walter Daelemans. 2009. Learning
the scope of hedge cues in biomedical texts. In Pro-
ceedings of the Workshop on BioNLP, pages 28–36,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
Philip V. Ogren. 2006. Knowtator: a prot´eg´e plug-in
for annotated corpus construction. In Proceedings of
the 2006 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 273–275, Mor-
ristown, NJ, USA. Association for Computational
Linguistics.
Dennis Reidsma and Rieks op den Akker. 2008. Ex-
ploiting ’subjective’ annotations. In HumanJudge
’08: Proceedings of the Workshop on Human Judge-
ments in Computational Linguistics, pages 8–16,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Victoria L. Rubin, Elizabeth D. Liddy, and Noriko
Kando. 2006. Certainty identification in texts: Cat-
egorization model and manual tagging results. In
Computing Affect and Attitutde in Text: Theory and
Applications. Springer.
The World Bank Group. 2010. Documents
&amp; Reports. http://go.worldbank.org/
3BU2Z3YZ40, Accessed May 13, 2010.
Veronika Vincze, Gy¨orgy Szaarvas, Rich´ard Farkas,
Gy¨orgy M´ora, and J´anos Csirik. 2008. The bio-
scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Evalu-
ation, 39:165–210.
J. W. Wilbur, A. Rzhetsky, and H. Shatkay. 2006. New
directions in biomedical text annotation: definitions,
guidelines and corpus construction. BMC Bioinfor-
matics, 7:356+, July.
</reference>
<page confidence="0.99933">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.660926">
<title confidence="0.9921625">Levels of Certainty in Knowledge-Intensive An Initial Annotation Study</title>
<author confidence="0.917024">Aron</author>
<email confidence="0.8124965">DSV/KTH-Stockholmaronhen@dsv.su.se</email>
<abstract confidence="0.999283615384615">In this initial annotation study, we suggest an appropriate approach for determining the level of certainty in text, including classification into multiple levels of certainty, types of statement and indicators of amplified certainty. A primary evaluation, based on pairwise inter-annotator agree- (IAA) using is performed on a small corpus comprising documents the While IAA results are low, the analysis will allow further refinement of the created guidelines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mona T Diab</author>
<author>Lori Levin</author>
<author>Teruko Mitamura</author>
<author>Owen Rambow</author>
<author>Vinodkumar Prabhakaram</author>
<author>Weiwei Guo</author>
</authors>
<title>Committed belief annotation and tagging.</title>
<date>2009</date>
<journal>ACL and AFNLP.</journal>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP,</booktitle>
<pages>68--73</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="3132" citStr="Diab et al. (2009)" startWordPosition="470" endWordPosition="473">ical text (scientific articles and abstracts, as well as radiology reports). After several iterations of refining their guidelines, they report IAA values ranging from 77.6 to 92.37 Fl-score for speculative keywords (62.5 and 95.54 Fl-score for full scope). This corpus is freely available and has been used for training and evaluation of automatic classifiers, see e.g. Morante and Daelemans (2009). One of the main findings is that hedge cues are highly domaindependent. Automatic identification of other private states, including opinions, represents a similar task, see e.g. Wiebe et al. (2005). Diab et al. (2009) study annotation of committed and noncommitted belief and show that automatic tagging of such classes is feasible. A different annotation approach is proposed by Rubin et al. (2006), in which certainty in newspaper articles is categorized along four dimensions: level, perspective, focus and time. Similarly, five dimensions are used in Wilbur et al. (2006) for the creation of an annotated corpus of biomedical text: focus, polarity, certainty, evidence and directionality. 3 Method Based on previous approaches and an extensive literature review, we propose a set of guidelines that 41 Proceedings</context>
</contexts>
<marker>Diab, Levin, Mitamura, Rambow, Prabhakaram, Guo, 2009</marker>
<rawString>Mona T. Diab, Lori Levin, Teruko Mitamura, Owen Rambow, Vinodkumar Prabhakaram, and Weiwei Guo. 2009. Committed belief annotation and tagging. In Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP, pages 68–73, Suntec, Singapore, August. ACL and AFNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Hyland</author>
</authors>
<title>Hedging in Scientific Research Articles.</title>
<date>1998</date>
<publisher>John Benjamins Publishing Company, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="1316" citStr="Hyland, 1998" startWordPosition="199" endWordPosition="200">owledge, it is often communicated in an informal manner. In our choice of words and expressions, we implicitly or explicitly judge the certainty of the knowledge we wish to convey. This fact makes it possible to gauge the reliability of knowledge based on the subjective perspective of the author. As knowledge is often difficult to ascertain, it seems reasonable to regard knowledge on a continuum of varying degrees of certainty, as opposed to a binary (mis)conception. This corresponds to the notion of epistemic modality: the degree of confidence in, or commitment to, the truth of propositions (Hyland, 1998). Hedging is a means of affecting epistemic modality by qualifying propositions, realized through tentative words and expressions such as possibly and tends to. A holistic perspective on certainty—in which not only speculation is considered, but also signs of increased certainty—requires a classification into various levels. Applying such an approach to knowledge-intensive corpora, it may in due course be possible to evaluate unstructured, informal knowledge. This would not least be valuable to organizational knowledge management pracSumithra Velupillai DSV/KTH-Stockholm University Sweden sumi</context>
</contexts>
<marker>Hyland, 1998</marker>
<rawString>Ken Hyland. 1998. Hedging in Scientific Research Articles. John Benjamins Publishing Company, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halil Kilicoglu</author>
<author>Sabine Bergler</author>
</authors>
<title>Recognizing speculative language in biomedical research articles: a linguistically motivated perspective.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="11949" citStr="Kilicoglu and Bergler (2008)" startWordPosition="1870" endWordPosition="1873">ussion In the guidelines, it is suggested that the level of certainty can typically be gauged by identifying the number of indicators. There is, however, a serious drawback to this approach. Hedging indicators, in particular, are inherently uncertain to different degrees. Consider the words possibly and 43 probably. According to the guidelines, a single occurrence of either of these hedging indicators would normally render a statement quite uncertain. Giving freer hands to the annotator might be a way to evade this problem; however, it is not likely to lead to any more consistent annotations. Kilicoglu and Bergler (2008) address this by assigning weights to hedging cues. A constantly recurring bone of contention is presented by the relationship between certainty and precision. One of the hardest judgements to make is whether imprecision, or vagueness, is a sign of uncertainty. Consider the following example from the corpus: Cape Verde had virtually no private sector. Clearly, this statement would be more certain if it had said: Cape Verde had no private sector. However, virtually no could be substituted with, say, a very small, in which case the statement would surely not be deemed uncertain. Perhaps precisio</context>
</contexts>
<marker>Kilicoglu, Bergler, 2008</marker>
<rawString>Halil Kilicoglu and Sabine Bergler. 2008. Recognizing speculative language in biomedical research articles: a linguistically motivated perspective. BMC Bioinformatics, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Hedges: A study in meaning criteria and the logic of fuzzy concepts.</title>
<date>1973</date>
<journal>Journal of Philosophical Logic,</journal>
<pages>2--458</pages>
<contexts>
<context position="2100" citStr="Lakoff (1973)" startWordPosition="310" endWordPosition="311"> perspective on certainty—in which not only speculation is considered, but also signs of increased certainty—requires a classification into various levels. Applying such an approach to knowledge-intensive corpora, it may in due course be possible to evaluate unstructured, informal knowledge. This would not least be valuable to organizational knowledge management pracSumithra Velupillai DSV/KTH-Stockholm University Sweden sumithra@dsv.su.se tices, where it could provide a rough indicator of reliability in internal knowledge audits. 2 Related Research The hedging concept was first introduced by Lakoff (1973) but has only really come into the spotlight in more recent years. Studies have mainly taken place in the biomedical domain, with Hyland’s (1998) influential work investigating the phenomenon in scientific research articles. Speculative keywords and negations, along with their linguistic scopes, are annotated in the BioScope corpus by Vincze et al. (2008), which contains a large collection of medical and biological text (scientific articles and abstracts, as well as radiology reports). After several iterations of refining their guidelines, they report IAA values ranging from 77.6 to 92.37 Fl-s</context>
</contexts>
<marker>Lakoff, 1973</marker>
<rawString>George Lakoff. 1973. Hedges: A study in meaning criteria and the logic of fuzzy concepts. Journal of Philosophical Logic, 2:458–508.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on BioNLP,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="2913" citStr="Morante and Daelemans (2009)" startWordPosition="433" endWordPosition="436">omenon in scientific research articles. Speculative keywords and negations, along with their linguistic scopes, are annotated in the BioScope corpus by Vincze et al. (2008), which contains a large collection of medical and biological text (scientific articles and abstracts, as well as radiology reports). After several iterations of refining their guidelines, they report IAA values ranging from 77.6 to 92.37 Fl-score for speculative keywords (62.5 and 95.54 Fl-score for full scope). This corpus is freely available and has been used for training and evaluation of automatic classifiers, see e.g. Morante and Daelemans (2009). One of the main findings is that hedge cues are highly domaindependent. Automatic identification of other private states, including opinions, represents a similar task, see e.g. Wiebe et al. (2005). Diab et al. (2009) study annotation of committed and noncommitted belief and show that automatic tagging of such classes is feasible. A different annotation approach is proposed by Rubin et al. (2006), in which certainty in newspaper articles is categorized along four dimensions: level, perspective, focus and time. Similarly, five dimensions are used in Wilbur et al. (2006) for the creation of an</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the Workshop on BioNLP, pages 28–36, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip V Ogren</author>
</authors>
<title>Knowtator: a prot´eg´e plug-in for annotated corpus construction.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>273--275</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4686" citStr="Ogren, 2006" startWordPosition="707" endWordPosition="708">between two types of statement and underscores the need to take into account words and expressions that add certainty to a proposition. A small corpus of 10 World Bank documents— a publicly available resource known as Viewpoints (The World Bank Group, 2010)—is subsequently annotated in two sets by different annotators. The corpus is from a slightly different domain to those previously targeted and represents an adequate alternative to knowledge documents internal to an organization by fulfilling the criterion of knowledge intensity. The process is carried out in a Prot´eg´e plugin: Knowtator (Ogren, 2006). Pairwise IAA, measured as Fl-score, is calculated to evaluate the feasibility of the approach. Statements are annotated at the clause level, as sentences often contain subparts subject to different levels of certainty. These are not predefined and the span of classes is determined by the annotator. Furthermore, a distinction is made between different types of statement: statements that give an account of something, typically a report of past events, and statements that express concrete knowledge claims. The rationale behind this distinction is that text comprises statements that make more or</context>
</contexts>
<marker>Ogren, 2006</marker>
<rawString>Philip V. Ogren. 2006. Knowtator: a prot´eg´e plug-in for annotated corpus construction. In Proceedings of the 2006 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 273–275, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Reidsma</author>
<author>Rieks op den Akker</author>
</authors>
<title>Exploiting ’subjective’ annotations.</title>
<date>2008</date>
<booktitle>In HumanJudge ’08: Proceedings of the Workshop on Human Judgements in Computational Linguistics,</booktitle>
<pages>8--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Reidsma, den Akker, 2008</marker>
<rawString>Dennis Reidsma and Rieks op den Akker. 2008. Exploiting ’subjective’ annotations. In HumanJudge ’08: Proceedings of the Workshop on Human Judgements in Computational Linguistics, pages 8–16, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria L Rubin</author>
<author>Elizabeth D Liddy</author>
<author>Noriko Kando</author>
</authors>
<title>Certainty identification in texts: Categorization model and manual tagging results.</title>
<date>2006</date>
<booktitle>In Computing Affect and Attitutde in Text: Theory and Applications.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="3314" citStr="Rubin et al. (2006)" startWordPosition="499" endWordPosition="502"> Fl-score for speculative keywords (62.5 and 95.54 Fl-score for full scope). This corpus is freely available and has been used for training and evaluation of automatic classifiers, see e.g. Morante and Daelemans (2009). One of the main findings is that hedge cues are highly domaindependent. Automatic identification of other private states, including opinions, represents a similar task, see e.g. Wiebe et al. (2005). Diab et al. (2009) study annotation of committed and noncommitted belief and show that automatic tagging of such classes is feasible. A different annotation approach is proposed by Rubin et al. (2006), in which certainty in newspaper articles is categorized along four dimensions: level, perspective, focus and time. Similarly, five dimensions are used in Wilbur et al. (2006) for the creation of an annotated corpus of biomedical text: focus, polarity, certainty, evidence and directionality. 3 Method Based on previous approaches and an extensive literature review, we propose a set of guidelines that 41 Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 41–45, Uppsala, July 2010. (1) incorporates some new features and (2) shifts the perspective to sui</context>
</contexts>
<marker>Rubin, Liddy, Kando, 2006</marker>
<rawString>Victoria L. Rubin, Elizabeth D. Liddy, and Noriko Kando. 2006. Certainty identification in texts: Categorization model and manual tagging results. In Computing Affect and Attitutde in Text: Theory and Applications. Springer.</rawString>
</citation>
<citation valid="true">
<title>The World Bank Group.</title>
<date>2010</date>
<booktitle>Documents &amp; Reports. http://go.worldbank.org/ 3BU2Z3YZ40, Accessed</booktitle>
<marker>2010</marker>
<rawString>The World Bank Group. 2010. Documents &amp; Reports. http://go.worldbank.org/ 3BU2Z3YZ40, Accessed May 13, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gy¨orgy Szaarvas</author>
<author>Rich´ard Farkas</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
</authors>
<title>The bioscope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<marker>Vincze, Szaarvas, Farkas, M´ora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gy¨orgy Szaarvas, Rich´ard Farkas, Gy¨orgy M´ora, and J´anos Csirik. 2008. The bioscope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--165</pages>
<contexts>
<context position="3112" citStr="Wiebe et al. (2005)" startWordPosition="466" endWordPosition="469">of medical and biological text (scientific articles and abstracts, as well as radiology reports). After several iterations of refining their guidelines, they report IAA values ranging from 77.6 to 92.37 Fl-score for speculative keywords (62.5 and 95.54 Fl-score for full scope). This corpus is freely available and has been used for training and evaluation of automatic classifiers, see e.g. Morante and Daelemans (2009). One of the main findings is that hedge cues are highly domaindependent. Automatic identification of other private states, including opinions, represents a similar task, see e.g. Wiebe et al. (2005). Diab et al. (2009) study annotation of committed and noncommitted belief and show that automatic tagging of such classes is feasible. A different annotation approach is proposed by Rubin et al. (2006), in which certainty in newspaper articles is categorized along four dimensions: level, perspective, focus and time. Similarly, five dimensions are used in Wilbur et al. (2006) for the creation of an annotated corpus of biomedical text: focus, polarity, certainty, evidence and directionality. 3 Method Based on previous approaches and an extensive literature review, we propose a set of guidelines</context>
<context position="8434" citStr="Wiebe et al. (2005)" startWordPosition="1300" endWordPosition="1303">restingly, claims are also expressed with added confidence more often than accounts—around one in every ten claims. 42 Figure 2: Average distribution of certainty in knowledge claims. As expected, the most common indicator is of hedging. Common cues include may, can, might, could, indicate(s), generally and typically. Many of these cues are also among the most common in the biomedical sub-corpus of BioScope (Vincze et al., 2008). It is interesting to note the fairly common phenomenon of certainty amplifiers. These are especially interesting, as they have not been studied much before, although Wiebe et al. (2005) incorporate intensity ratings in their annotation scheme. There is agreement on words like clearly, strongly and especially. Indicator Set #1 Set #2 Certainty amplifier 61 29 Hedging indicator 151 133 Source hedge 0 40 Modality strengthener 9 122 Table 2: Frequency of indicators To evaluate the approach, we calculate IAA by pairwise F1-score, considering set #1 as the gold standard, i.e. as correctly classified, in relation to which the other subsets are evaluated. We do this for exact matches and partial matches1. For exact matches in a single document, the F1-score values range from an extr</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39:165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Wilbur</author>
<author>A Rzhetsky</author>
<author>H Shatkay</author>
</authors>
<title>New directions in biomedical text annotation: definitions, guidelines and corpus construction.</title>
<date>2006</date>
<journal>BMC Bioinformatics,</journal>
<pages>7--356</pages>
<contexts>
<context position="3490" citStr="Wilbur et al. (2006)" startWordPosition="527" endWordPosition="530">iers, see e.g. Morante and Daelemans (2009). One of the main findings is that hedge cues are highly domaindependent. Automatic identification of other private states, including opinions, represents a similar task, see e.g. Wiebe et al. (2005). Diab et al. (2009) study annotation of committed and noncommitted belief and show that automatic tagging of such classes is feasible. A different annotation approach is proposed by Rubin et al. (2006), in which certainty in newspaper articles is categorized along four dimensions: level, perspective, focus and time. Similarly, five dimensions are used in Wilbur et al. (2006) for the creation of an annotated corpus of biomedical text: focus, polarity, certainty, evidence and directionality. 3 Method Based on previous approaches and an extensive literature review, we propose a set of guidelines that 41 Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 41–45, Uppsala, July 2010. (1) incorporates some new features and (2) shifts the perspective to suit knowledge-intensive corpora, e.g. comprising organizational knowledge documents. Besides categorization into levels of certainty, this approach distinguishes between two type</context>
</contexts>
<marker>Wilbur, Rzhetsky, Shatkay, 2006</marker>
<rawString>J. W. Wilbur, A. Rzhetsky, and H. Shatkay. 2006. New directions in biomedical text annotation: definitions, guidelines and corpus construction. BMC Bioinformatics, 7:356+, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>