<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.100708">
<title confidence="0.970186">
Studying Discourse and Dialogue with SIDGrid*
</title>
<author confidence="0.990182">
Gina-Anne Levow
</author>
<affiliation confidence="0.85922">
Department of Computer Science
University of Chicago
Chicago, IL 60611, USA
</affiliation>
<email confidence="0.998784">
levow@cs.uchicago.edu
</email>
<sectionHeader confidence="0.995584" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995884533333333">
Teaching Computational Linguistics is in-
herently multi-disciplinary and frequently
poses challenges and provides opportunities in
teaching to a student body with diverse ed-
ucational backgrounds and goals. This pa-
per describes the use of a computational en-
vironment (SIDGrid) that facilitates interdis-
ciplinary instruction by providing support for
students with little computational background
as well as extending the scale of projects ac-
cessible to students with more advanced com-
putational skills. The environment facilitates
the use of hands-on exercises and is being ap-
plied to interdisciplinary instruction in Dis-
course and Dialogue.
</bodyText>
<sectionHeader confidence="0.998972" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997353846153846">
Teaching Computational Linguistics poses many
challenges but also provides many opportunities.
Students in Computational Linguistics courses come
from diverse academic backgrounds, including com-
puter science, linguistics, and psychology. The
students enter with differing experience and expo-
sure to programming, computational and mathemat-
ical models, and linguistic, psycholinguistic and so-
ciolinguistic theories that inform the practice and
study of computational linguistics. However, study-
ing in a common class provides students with the op-
portunity to gain exposure to diverse perspectives on
their research problems and to apply computational
</bodyText>
<footnote confidence="0.622388">
&amp;quot;The work is supported by a University of Chicago Aca-
demic Technology Innovation Grant.
</footnote>
<bodyText confidence="0.99984478125">
tools and techniques to expand the range and scope
of problems they can investigate.
While there are many facets of these instructional
challenges that must be addressed to support a suc-
cessful course with a multi-disciplinary class and
perspective, this paper focuses on the use and de-
velopment of a computational environment to sup-
port laboratory exercises for students from diverse
backgrounds. The framework aims to facilitate col-
laborative projects, reduce barriers of entry for stu-
dents with little prior computational experience, and
to provide access to large-scale distributed process-
ing resources for students with greater computa-
tional expertise to expand the scope and scale of
their projects and exercises.
Specifically, we exploit the Social Informatics
Data Grid (SIDGrid) framework developed as part
of the NSF-funded Cyberinfrastructure project, ”Cy-
berinfrastructure for Collaborative Research in the
Social and Behavioral Sciences (PI: Stevens)”, to
support hands-on annotation and analysis exercises
in a computational linguistics course focused on dis-
course and dialogue. We begin by describing the
SIDGrid framework for annotation, archiving, and
analysis of multi-modal, multi-measure data. We
then describe the course setting and the applica-
tion of SIDGrid functionality to expand exercise and
project possibilities. Finally, we discuss the impact
of this framework for multi-disciplinary instruction
in computational linguistics as well as the limita-
tions of the current implementation of the frame-
work.
</bodyText>
<page confidence="0.975572">
106
</page>
<note confidence="0.7594865">
Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 106–113,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.880755" genericHeader="method">
2 SIDGrid Framework
</sectionHeader>
<subsectionHeader confidence="0.984639">
2.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999482735294118">
Recent research programs in multi-modal environ-
ments, including understanding and analysis of
multi-party meeting data and oral history recording
projects, have created an explosion of multi-modal
data sets, including video and audio recordings,
transcripts and other annotations, and increased in-
terest in annotation and analysis of such data. A
number of systems have been developed to man-
age and support annotation of multi-modal data, in-
cluding Annotation Graphs (Bird and Liberman,
2001), Exmeralda (Schmidt, 2004), NITE XML
Toolkit (Carletta et al., 2003), Multitool (Allwood
et al., 2001), Anvil (Kipp, 2001), and Elan (Wit-
tenburg et al., 2006). The Social Informatics Data
Grid (SIDGrid), developed under the NSF Cyberin-
frastructure Program, aims to extend the capabilities
of such systems by focusing on support for large-
scale, extensible distributed data annotation, shar-
ing, and analysis. The system is open-source and
multi-platform and based on existing open-source
software and standards. The system greatly eases the
integration of annotation with analysis though user-
defined functions both on the client-side for data ex-
ploration and on the TeraGrid for large-scale dis-
tributed data processing. A web-accessible repos-
itory supports data search, sharing, and distributed
annotation. While the framework is general, anal-
ysis of spoken and multi-modal discourse and dia-
logue data is a primary application.
The details of the system are presented below.
Sections 2.2, 2.3, and 2.4 describe the annota-
tion client, the web-accessible data repository, and
the portal to the TeraGrid, respectively, as shown in
Figure 1 below.
</bodyText>
<subsectionHeader confidence="0.999626">
2.2 The SIDGrid Client
</subsectionHeader>
<bodyText confidence="0.99989275">
The SIDGrid client provides an interactive multi-
modal annotation interface, building on the open-
source ELAN annotation tool from the Max Planck
Institute1. A screenshot appears in Figure 2. ELAN
supports display and synchronized playback of mul-
tiple video files, audio files, and arbitrarily many
annotation ”tiers” in its ”music-score”-style graph-
ical interface. The annotations are assumed to be
</bodyText>
<footnote confidence="0.977329">
1http://www.mpi.nl/tools/elan.html
</footnote>
<figureCaption confidence="0.9997035">
Figure 1: System Architecture
Figure 2: Screenshot of the annotation client interface,
with video, time-aligned textual annotations, and time se-
ries displays.
</figureCaption>
<bodyText confidence="0.999918166666667">
time-aligned intervals with, typically, text content;
the system leverages Unicode to provide multilin-
gual support. Time series such as pitch tracks or
motion capture data can be displayed synchronously.
The user may interactively add, edit, and do sim-
ple search in annotations. For example, in multi-
modal multi-party spoken data, annotation tiers cor-
responding to aligned text transcriptions, head nods,
pause, gesture, and reference can be created.
The client expands on this functionality by al-
lowing the application of user-defined analysis pro-
grams to media, time series, and annotations asso-
ciated with the current project, such as a conver-
sation, to yield time series files or annotation tiers
displayed in the client interface. Any program with
a command-line or scriptable interface installed on
the user’s system may be added to a pull-down list
for invocation. For example, to support a prosodic
</bodyText>
<figure confidence="0.998492833333333">
Web-interface
to TeraGrid &amp;
Repository
Data Repository
Client
TeraGrid
</figure>
<page confidence="0.994147">
107
</page>
<bodyText confidence="0.999688555555556">
analysis of multi-party meeting data, the user can se-
lect a Praat (Boersma, 2001) script to perform pitch
or intensity tracking. Also, the client provides inte-
grated import and export capabilities for the central
repository. New and updated experiments and an-
notations may be uploaded directly to the archive
from within the client interface. Existing experi-
ments may be loaded from local disk or downloaded
from the repository for additional annotation.
</bodyText>
<subsectionHeader confidence="0.998909">
2.3 The SIDGrid Repository
</subsectionHeader>
<bodyText confidence="0.999989692307692">
The SIDGrid repository provides a web-accessible,
central archive of multi-modal data, annotations, and
analyses. This archive facilitates distributed anno-
tation efforts by multiple researchers working on a
common data set by allowing shared storage and ac-
cess to annotations, while keeping a history of up-
dates to the shared data, annotations, and analysis.
The browser-based interface to the archive allows
the user to browse or search the on-line data col-
lection by media type, tags, project identifier, and
group or owner. Once selected, all or part of any ex-
periment may be downloaded. In addition to lists of
experiment names or thumbnail images, the web in-
terface also provides a streaming preview of the se-
lected media and annotations, allowing verification
prior to download. (Figure 3)
All data is stored in a MySQL database. Anno-
tation tiers are converted to an internal time-span
based representation, while media and time series
files are linked in unanalyzed. This format allows
generation of ELAN format files for download to the
client tool without regard to the original source form
of the annotation file. The database structure further
enables the potential for flexible search of the stored
annotations both within and across multiple annota-
tion types.
</bodyText>
<subsectionHeader confidence="0.999">
2.4 The TeraGrid Portal
</subsectionHeader>
<bodyText confidence="0.999993138888889">
The large-scale multimedia data collected for multi-
modal research poses significant computational
challenges. Signal processing of gigabytes of me-
dia files requires processing horsepower that may
strain many local sites, as do approaches such as
multi-dimensional scaling for semantic analysis and
topic segmentation. To enable users to more effec-
tively exploit this data, the SIDGrid provides a por-
tal to the TeraGrid (Pennington, 2002), the largest
distributed cyberinfrastructure for open scientific
research, which uses high-speed network connec-
tions to link high performance computers and large
scale data stores distributed across the United States.
While the TeraGrid has been exploited within the as-
tronomy and physics communities, it has been little
used by the computational linguistics community.
The SIDGrid portal to the TeraGrid allows large-
scale experimentation by providing access to large-
scale distributed processing clusters to enable par-
allel processing on very high capacity servers. The
SIDGrid portal to the TeraGrid allows the user to
specify a set of files in the repository and a program
or programs to run on them on the Grid-based re-
sources. Once a program is installed on the Grid,
the processing can be distributed automatically to
different TeraGrid nodes. Software supports arbi-
trarily complex workflow specifications, but the cur-
rent SIDGrid interface provides simple support for
high degrees of data-parallel processing, as well as a
graphical display indicating the progress of the dis-
tributed program execution, as shown in Figure 4.
The results are then reintegrated with the original
experiments in the on-line repository. Currently in-
stalled programs support distributed acoustic analy-
sis using Praat, statistical analysis using R, and ma-
trix computations using Matlab and Octave.
</bodyText>
<subsectionHeader confidence="0.996573">
2.5 Software Availability
</subsectionHeader>
<bodyText confidence="0.999954833333333">
The client software is freely available. Ac-
cess to the public portion of the repository
is possible through the project website at
https://sidgrid.ci.uchicago.edu;
full access to the repository to create new experi-
ments may also be requested there.
</bodyText>
<sectionHeader confidence="0.871997" genericHeader="method">
3 Course Setting and Activities
</sectionHeader>
<bodyText confidence="0.9998064">
We explore the use of this framework in a course
which focuses on a subarea of Computational Lin-
guistics, specifically discourse and dialogue, tar-
geted at graduate students interested in research in
this area. This topic is the subject of research not
only in computational speech and language process-
ing, but also in linguistics, psychology, sociology,
anthropology, and philosophy. Research in this area
draws on a growing, large-scale collection of text
and multi-modal interaction data that often relies on
</bodyText>
<page confidence="0.996573">
108
</page>
<figureCaption confidence="0.999363333333333">
Figure 3: Screenshot of the archive download interface, with thumbnails of available video and download and analysis
controls.
Figure 4: Progress of execution of programs on TeraGrid. Table lists file identifiers and status. Graph shows progress.
</figureCaption>
<page confidence="0.994976">
109
</page>
<bodyText confidence="0.998851888888889">
computational tools to support annotation, archiv-
ing, and analysis. However, prior offerings of this
course through the Computer Science Department
had attracted primarily Computer Science gradu-
ate students, even though readings for the course
spanned the range of related fields. In collabora-
tion with researchers in co-verbal gesture in the Psy-
chology department, we hoped to increase the attrac-
tion and accessibility of the course material and ex-
ercises to a more diverse student population. Af-
ter advertising the course to a broader population
through the Linguistics Department mailing list, em-
phasizing the use of computational tools but lack of
requirements for previous programming experience,
the resulting class included members of the Linguis-
tics, Slavic Studies, Psychology, and Computer Sci-
ence Departments, about half of whom had some
prior programming experience, but few were expert.
</bodyText>
<subsectionHeader confidence="0.987068">
3.1 Hands-on Exercises
</subsectionHeader>
<bodyText confidence="0.999942117647059">
Currently, we have only included a small number of
software tools as proof-of-concept and to enable par-
ticular course exercises in discourse and dialogue.
This first set of exercises explores three main prob-
lems in this area: topic segmentation, dialogue act
tagging, and turn-taking.
The topic segmentation exercise investigates the
impact of segment granularity and automatic speech
recognition errors on topic segmentation of conver-
sational speech. The data is drawn from the Cross-
Language Speech Retrieval Track of the Cross-
language Evaluation Forum (CLEF CL-SR) (Pecina
et al., 2007) collection. This collection includes au-
tomatic transcriptions of interviews from an oral his-
tory project, accompanied by manual segmentation
created as part of the MALACH project (Franz et al.,
2003). The exercise employs the web-based portal
to the TeraGrid to perform segmentation of multiple
interviews in parallel on the Grid, followed by eval-
uation in parallel. We perform segmentation using
LCSeg (Galley et al., 2003) and evaluate using the
Pk and WindowDiff metrics. Students identify the
best segmentation parameters for these interviews
and perform error analysis to assess the effect of
ASR errors.
The dialogue act tagging exercise involves both
annotation and analysis components. The students
are asked to download and annotate a small portion
of a conversation from the AMI corpus (Carletta et
al., 2005) with dialogue act tags. The AMI cor-
pus of multiparty meetings includes recorded video,
recorded audio, aligned manual transcriptions, and
manually annotated head and hand gesture. Stu-
dents annotate from text alone, with audio, with
video, and with all modalities. Local ”transforma-
tions”, programs or scripts associated with the an-
notation client, can also provide prosodic analysis
of features such as pitch and intensity. Students
are asked to assess the influence of different fea-
tures on their annotation process and to compare to
a gold standard annotation which is later provided.
The automatic analysis phase is performed on the
web-based portal to assess the impact of different
feature sets on automatic tagging. The tagging is
done in the Feature Latent Semantic Analysis frame-
work (Serafin and Di Eugenio, 2004), augmented
with additional prosodic and multi-modal features
drawn from the annotation. Since this analysis re-
quires Singular Value Decomposition of the poten-
tially large Feature-by-Dialogue-Act matrices, it is
often impractical to execute on single personal or
even departmental servers. Furthermore, feature ex-
traction, such as pitch tracking, of the full conver-
sation can itself strain the computational resources
available to students. Grid-based processing over-
comes both of these problems.
Exercises on turn-taking follow similar patterns.
An initial phase requires annotation and assessment
exercises by the students in the ELAN-based client
tool and downloaded from the web-based repository.
Subsequent phases of the exercises include applica-
tion and investigation of automatic techniques us-
ing the web-based environment and computational
resources of the TeraGrid. Clearly, many other exer-
cises could be framed within this general paradigm,
and we plan to extend the options available to stu-
dents as our interests and available software and data
sets permit.
</bodyText>
<sectionHeader confidence="0.988591" genericHeader="method">
4 Impact on Interdisciplinary Instruction
</sectionHeader>
<bodyText confidence="0.9999154">
We designed these hands-on exercises to allow stu-
dents to investigate important problems in discourse
and dialogue through exploration of the data and
application of automatic techniques to recognize
these phenomena. We aimed in addition to exploit
</bodyText>
<page confidence="0.995066">
110
</page>
<bodyText confidence="0.999973875">
the cyberinfrastructure framework to achieve three
main goals: lower barriers of entry to use of com-
putational tools by students with little prior pro-
gramming experience, enable students with greater
computational skills to expand the scale and scope
of their experiments, and to support collaborative
projects and a broader, interdisciplinary perspective
on research in discourse and dialogue.
</bodyText>
<subsectionHeader confidence="0.99307">
4.1 Enabling All Users
</subsectionHeader>
<bodyText confidence="0.99999625">
A key goal in employing this architecture was to en-
able students with little or no programming expe-
rience to exploit advanced computational tools and
techniques. The integration of so-called ”transfor-
mations”, actually arbitrary program applications, in
both the annotation client and the web-based portal
to the TeraGrid, supports this goal. In both cases,
drop-down menus to select programs and text- and
check-boxes to specify parameters provide graphi-
cal user interfaces to what can otherwise be complex
command-line specifications. In particular, the web-
based portal removes requirements for local instal-
lation of software, shielding the user from problems
due to complex installations, variations in platforms
and operating systems, and abstruse command-line
syntax. In addition, the web-based archive provides
simple mechanisms to browse and download a range
of data sources. The students all found the archive,
download, and transformation mechanisms easy to
use, regardless of prior programming experience. It
is important to remember that the goal of this envi-
ronment is not to replace existing software systems
for Natural Language Processing, such the Natural
Language Toolkit (NLTK) (Bird and Loper, 2004),
but rather to provide a simpler interface to such soft-
ware tools and to support their application to poten-
tially large data sets, irrespective of the processing
power of the individual user’ system.
</bodyText>
<subsectionHeader confidence="0.999024">
4.2 Enabling Large-Scale Experimentation
</subsectionHeader>
<bodyText confidence="0.999964485714286">
A second goal is to enable larger-scale experimenta-
tion by both expert and non-expert users. The use of
the web-based portal to the TeraGrid provides such
opportunities. The portal provides access to highly
distributed parallel processing capabilities. For ex-
ample, in the case of the segmentation of the oral
history interviews above, the user can select several
interviews, say 60, to segment by checking the as-
sociated check-boxes in the interface. The portal
software will automatically identify available pro-
cessing nodes and distribute the segmentation jobs
for the corresponding interviews to each of the avail-
able nodes to be executed in parallel. Not only are
there many processing nodes, but these nodes are of
very high capacity in terms of CPU speed, number
of CPUs, and available memory.
The multigigabyte data files associated with the
growing number of multi-modal discourse and dia-
logue corpora, such as the AMI and ICSI Meeting
Recorder collections, make such processing power
highly desirable. For example, pitch tracking for
such corpora is beyond the memory limitations of
any single machine in the department, while such
tasks are quickly processed on the powerful Tera-
Grid machines.
Expert users are also granted privileges to upload
their own user-defined programs to be executed on
the Grid. Finally, web services also enable execu-
tion of arbitrary read-only queries on the underly-
ing database of annotations, media files, and time-
series data through standard Structure Query Lan-
guage (SQL) calls. All these capabilities enhance
the scope of problems that more skilled program-
mers can employ in the study of discourse and dia-
logue phenomena.
</bodyText>
<subsectionHeader confidence="0.997827">
4.3 Interdisciplinary Collaboration and
Perspectives
</subsectionHeader>
<bodyText confidence="0.999507833333333">
The web-based archive in the SIDGrid framework
also provides support for group distributed collab-
orative projects. The archive provides a Unix-style
permission structure that allows data sharing within
groups. The process of project creation, annota-
tion, and experimentation maintains a version his-
tory. Uploads of new annotations create new ver-
sions; older versions are not deleted or overwritten.
Experimental runs are also archived, providing an
experiment history and shared access to intermedi-
ate and final results. Script and software versions
are also maintained. While the version control is not
nearly as sophisticated as that provided by GForge
or Subversion, this simple model requires no spe-
cial training and facilitates flexible, web-based dis-
tributed access and collaboration.
Finally, the interleaving of annotation and auto-
mated experimented permitted by this integrated ar-
</bodyText>
<page confidence="0.997379">
111
</page>
<bodyText confidence="0.999985375">
chitecture provides the students with additional in-
sight into different aspects of research on discourse
and dialogue. Students from linguistics and psy-
chology gain greater experience in automatic analy-
sis and recognition of discourse phenomena, while
more computationally oriented students develop a
greater appreciation of the challenges of annotation
and theoretical issues in analysis of dialogue data.
</bodyText>
<sectionHeader confidence="0.951828" genericHeader="evaluation">
5 Challenges and Costs
</sectionHeader>
<bodyText confidence="0.99998375">
The capabilities and opportunities for study of com-
putational approaches to discourse and dialogue af-
forded within the SIDGrid framework do require
some significant investment of time and effort. In-
corporating new data sets and software packages
requires programming expertise. The framework
can, in principle, incorporate arbitrary data types:
media, physiological measures, manual and auto-
matic annotations, and even motion tracking. The
data must be converted into the ELAN .eaf for-
mat to be deployed effectively by the annotation
client and interpreted correctly by the archive’s un-
derlying database. Converters have been created
for several established formats2, such as Annota-
tion Graphs (Bird and Liberman, 2001), ANVIL
(Kipp, 2001), and EXMARaLDA(Schmidt, 2004),
and projects are underway to improve interoperabil-
ity between formats. However, new formats such as
the CLEF Cross-language Speech Retrieval SGML
format and NITE XML(Carletta et al., 2003) format
for the AMI data used here, required the implemen-
tation of software to convert the source format to one
suitable for use by SIDGrid.
Incorporating new Grid-based ”transformation”
programs can also range in required effort. For self-
contained programs in supported frameworks - cur-
rently, Perl, Python, Praat, and Octave - adding a
new program requires only a simple browser-based
upload. Compiled programs, such as LCSeg here,
must be compatible with the operating systems and
64-bit architecture on the Grid servers, often requir-
ing recompilation and occasionally addition of li-
braries to existing Grid installations. Finally, soft-
ware with licensing restrictions can only run on a
local cluster rather than on the full TeraGrid. Thus,
public domain programs and systems that rely on
</bodyText>
<footnote confidence="0.915949">
2www.multimodal-annotation.org
</footnote>
<bodyText confidence="0.9997955">
such are preferred; for example, Octave-based pro-
grams are preferred to Matlab-based ones.
Finally, one must remember that the SIDGrid
framework is itself an ongoing research project. It
provides many opportunities to enhance interdisci-
plinary instruction in Computational Linguistics, es-
pecially in areas involving multi-modal data. How-
ever, the functionality is still under active develop-
ment, and current system users are beta-testers. The
use of the system, both in coursework and in re-
search, has driven improvements and expansions in
service.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="conclusions">
6 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999920416666666">
We have explored the use of the SIDGrid framework
for annotation, archiving, and analysis of multi-
modal data to enhance hands-on activities in the
study of discourse and dialogue in a highly inter-
disciplinary course setting. Our preliminary efforts
have demonstrated the potential for the framework
to lower barriers of entry for students with less pro-
gramming experience to apply computational tech-
niques while enabling large-scale investigation of
discourse and dialogue phenomena by more expert
users. Annotation, analysis, and automatic recog-
nition exercises relating to topic segmentation, di-
alogue act tagging, and turn-taking give students a
broader perspective on research and issues in dis-
course and dialogue. These exercises also allow
students to contribute to class discussion and col-
laborative projects drawing on their diverse disci-
plinary backgrounds. We plan to extend our current
suite of hands-on exercises to cover other aspects of
discourse and dialogue, both in terms of data sets
and software, including well-known toolkits such as
NLTK. We hope that this expanded framework will
encourage additional interdisciplinary collaborative
projects among students.
</bodyText>
<sectionHeader confidence="0.998293" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999977857142857">
We would like to thank Susan Duncan and David
McNeill for their participation in this project as well
as the University of Chicago Academic Technology
Innovation program. We would also like to thank
Sonjia Waxmonsky for her assistance in implement-
ing the course exercises, and the entire SIDGRID
team for providing the necessary system infrastruc-
</bodyText>
<page confidence="0.993866">
112
</page>
<bodyText confidence="0.998683666666667">
ture. We are particularly appreciative of the response
to our bug reports and functionality requests by Tom
Uram and Sarah Kenny.
</bodyText>
<sectionHeader confidence="0.99623" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999838131147541">
Jens Allwood, Leif Groenqvist, Elisabeth Ahlsen, and
Magnus Gunnarsson. 2001. Annotations and tools for
an activity based spoken language corpus. In Proceed-
ings of the Second SIGdial Workshop on Discourse
and Dialogue, pages 1–10.
S. Bird and M. Liberman. 2001. A formal frame-
work for linguistic annotation. Speech Communica-
tion, 33(1,2):23–60.
Steven Bird and Edward Loper. 2004. Nltk: The natural
language toolkit. In Proceedings of the ACL demon-
stration session, pages 214–217.
P. Boersma. 2001. Praat, a system for doing phonetics
by computer. Glot International, 5(9–10):341–345.
J. Carletta, S. Evert, U. Heid, J. Kilgour, J. Robertson,
and H. Voormann. 2003. The NITE XML Toolkit:
flexible annotation for multi-modal language data. Be-
havior Research Methods, Instruments, and Comput-
ers, special issue on Measuring Behavior, 35(3):353–
363.
Jean Carletta, Simone Ashby, Sebastien Bourban, Mike
Flynn, Mael Guillemot, Thomas Hain, Jaroslav
Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa
Kronenthal, Guillaume Lathoud, Mike Lincoln, Agnes
Lisowska, Iain A. McCowan, Wilfried Post, Dennis
Reidsma, and Pierre Wellner. 2005. The AMI meet-
ings corpus. In Proceedings of the Measuring Be-
havior 2005 symposium on Annotating and measuring
Meeting Behavior.
M. Franz, B. Ramabhadran, T. Ward, and M. Picheny.
2003. Automated transcription and topic segmenta-
tion of large spoken archives. In Proceedings of EU-
ROSPEECH.
Michel Galley, Kathleen McKeown, Eric Fosler-Lussier,
and Hongyan Jing. 2003. Discourse segmentation of
multi-party conversation. In Proceedings ofACL’03.
M. Kipp. 2001. Anvil- a generic annotation tool for mul-
timodal dialogue. In Proceedings of the 7th European
Conference on Speech Communication and Technol-
ogy (Eurospeech), pages 1367–1370.
Pavel Pecina, Petra Hoffmannova, Gareth J. F. Jones,
Ying Zhang, and Douglas W. Oard. 2007. Overview
of the clef-2007 cross language speech retrieval track.
In Working Notes for CLEF 2007.
Rob Pennington. 2002. Terascale clusters and the Tera-
Grid. In Proceedings for HPC Asia, pages 407–413.
Invited talk.
T. Schmidt. 2004. Transcribing and annotating spoken
language with EXMARaLDA. In Proceedings of the
LREC-Workshop on XML-based richly annotated cor-
pora.
Riccardo Serafin and Barbara Di Eugenio. 2004. Flsa:
Extending latent semantic analysis with features for
dialogue act classification. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04), Main Volume, pages 692–699,
Barcelona, Spain, July.
P. Wittenburg, H. Brugman, A. Russel, A. Klassmann,
and H. Sloetjes. 2006. Elan: a professional framework
for multimodality research. In Proceedings of Lan-
guage Resources and Evaluation Conference (LREC)
2006.
</reference>
<page confidence="0.999313">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.450512">
<title confidence="0.990359">Discourse and Dialogue with</title>
<author confidence="0.811086">Gina-Anne</author>
<affiliation confidence="0.999497">Department of Computer University of</affiliation>
<address confidence="0.783846">Chicago, IL 60611,</address>
<email confidence="0.999777">levow@cs.uchicago.edu</email>
<abstract confidence="0.97812825">Teaching Computational Linguistics is inherently multi-disciplinary and frequently poses challenges and provides opportunities in teaching to a student body with diverse educational backgrounds and goals. This paper describes the use of a computational environment (SIDGrid) that facilitates interdisciplinary instruction by providing support for students with little computational background as well as extending the scale of projects accessible to students with more advanced computational skills. The environment facilitates the use of hands-on exercises and is being applied to interdisciplinary instruction in Discourse and Dialogue.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jens Allwood</author>
<author>Leif Groenqvist</author>
<author>Elisabeth Ahlsen</author>
<author>Magnus Gunnarsson</author>
</authors>
<title>Annotations and tools for an activity based spoken language corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="3913" citStr="Allwood et al., 2001" startWordPosition="551" endWordPosition="554"> Framework 2.1 Motivation Recent research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined functions both on the client-side for data exploration and on the TeraGrid for large-scale distributed d</context>
</contexts>
<marker>Allwood, Groenqvist, Ahlsen, Gunnarsson, 2001</marker>
<rawString>Jens Allwood, Leif Groenqvist, Elisabeth Ahlsen, and Magnus Gunnarsson. 2001. Annotations and tools for an activity based spoken language corpus. In Proceedings of the Second SIGdial Workshop on Discourse and Dialogue, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>M Liberman</author>
</authors>
<title>A formal framework for linguistic annotation.</title>
<date>2001</date>
<journal>Speech Communication,</journal>
<pages>33--1</pages>
<contexts>
<context position="3810" citStr="Bird and Liberman, 2001" startWordPosition="536" endWordPosition="539"> pages 106–113, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics 2 SIDGrid Framework 2.1 Motivation Recent research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined f</context>
<context position="21378" citStr="Bird and Liberman, 2001" startWordPosition="3187" endWordPosition="3190">gue afforded within the SIDGrid framework do require some significant investment of time and effort. Incorporating new data sets and software packages requires programming expertise. The framework can, in principle, incorporate arbitrary data types: media, physiological measures, manual and automatic annotations, and even motion tracking. The data must be converted into the ELAN .eaf format to be deployed effectively by the annotation client and interpreted correctly by the archive’s underlying database. Converters have been created for several established formats2, such as Annotation Graphs (Bird and Liberman, 2001), ANVIL (Kipp, 2001), and EXMARaLDA(Schmidt, 2004), and projects are underway to improve interoperability between formats. However, new formats such as the CLEF Cross-language Speech Retrieval SGML format and NITE XML(Carletta et al., 2003) format for the AMI data used here, required the implementation of software to convert the source format to one suitable for use by SIDGrid. Incorporating new Grid-based ”transformation” programs can also range in required effort. For selfcontained programs in supported frameworks - currently, Perl, Python, Praat, and Octave - adding a new program requires o</context>
</contexts>
<marker>Bird, Liberman, 2001</marker>
<rawString>S. Bird and M. Liberman. 2001. A formal framework for linguistic annotation. Speech Communication, 33(1,2):23–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Edward Loper</author>
</authors>
<title>Nltk: The natural language toolkit.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL demonstration session,</booktitle>
<pages>214--217</pages>
<contexts>
<context position="17375" citStr="Bird and Loper, 2004" startWordPosition="2583" endWordPosition="2586">local installation of software, shielding the user from problems due to complex installations, variations in platforms and operating systems, and abstruse command-line syntax. In addition, the web-based archive provides simple mechanisms to browse and download a range of data sources. The students all found the archive, download, and transformation mechanisms easy to use, regardless of prior programming experience. It is important to remember that the goal of this environment is not to replace existing software systems for Natural Language Processing, such the Natural Language Toolkit (NLTK) (Bird and Loper, 2004), but rather to provide a simpler interface to such software tools and to support their application to potentially large data sets, irrespective of the processing power of the individual user’ system. 4.2 Enabling Large-Scale Experimentation A second goal is to enable larger-scale experimentation by both expert and non-expert users. The use of the web-based portal to the TeraGrid provides such opportunities. The portal provides access to highly distributed parallel processing capabilities. For example, in the case of the segmentation of the oral history interviews above, the user can select se</context>
</contexts>
<marker>Bird, Loper, 2004</marker>
<rawString>Steven Bird and Edward Loper. 2004. Nltk: The natural language toolkit. In Proceedings of the ACL demonstration session, pages 214–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boersma</author>
</authors>
<title>Praat, a system for doing phonetics by computer.</title>
<date>2001</date>
<journal>Glot International,</journal>
<pages>5--9</pages>
<contexts>
<context position="6631" citStr="Boersma, 2001" startWordPosition="962" endWordPosition="963">. The client expands on this functionality by allowing the application of user-defined analysis programs to media, time series, and annotations associated with the current project, such as a conversation, to yield time series files or annotation tiers displayed in the client interface. Any program with a command-line or scriptable interface installed on the user’s system may be added to a pull-down list for invocation. For example, to support a prosodic Web-interface to TeraGrid &amp; Repository Data Repository Client TeraGrid 107 analysis of multi-party meeting data, the user can select a Praat (Boersma, 2001) script to perform pitch or intensity tracking. Also, the client provides integrated import and export capabilities for the central repository. New and updated experiments and annotations may be uploaded directly to the archive from within the client interface. Existing experiments may be loaded from local disk or downloaded from the repository for additional annotation. 2.3 The SIDGrid Repository The SIDGrid repository provides a web-accessible, central archive of multi-modal data, annotations, and analyses. This archive facilitates distributed annotation efforts by multiple researchers worki</context>
</contexts>
<marker>Boersma, 2001</marker>
<rawString>P. Boersma. 2001. Praat, a system for doing phonetics by computer. Glot International, 5(9–10):341–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>S Evert</author>
<author>U Heid</author>
<author>J Kilgour</author>
<author>J Robertson</author>
<author>H Voormann</author>
</authors>
<title>The NITE XML Toolkit: flexible annotation for multi-modal language data.</title>
<date>2003</date>
<journal>Behavior Research Methods, Instruments, and Computers, special issue on Measuring Behavior,</journal>
<volume>35</volume>
<issue>3</issue>
<pages>363</pages>
<contexts>
<context position="3879" citStr="Carletta et al., 2003" startWordPosition="546" endWordPosition="549">Computational Linguistics 2 SIDGrid Framework 2.1 Motivation Recent research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined functions both on the client-side for data exploration and on the Tera</context>
<context position="21618" citStr="Carletta et al., 2003" startWordPosition="3221" endWordPosition="3224"> types: media, physiological measures, manual and automatic annotations, and even motion tracking. The data must be converted into the ELAN .eaf format to be deployed effectively by the annotation client and interpreted correctly by the archive’s underlying database. Converters have been created for several established formats2, such as Annotation Graphs (Bird and Liberman, 2001), ANVIL (Kipp, 2001), and EXMARaLDA(Schmidt, 2004), and projects are underway to improve interoperability between formats. However, new formats such as the CLEF Cross-language Speech Retrieval SGML format and NITE XML(Carletta et al., 2003) format for the AMI data used here, required the implementation of software to convert the source format to one suitable for use by SIDGrid. Incorporating new Grid-based ”transformation” programs can also range in required effort. For selfcontained programs in supported frameworks - currently, Perl, Python, Praat, and Octave - adding a new program requires only a simple browser-based upload. Compiled programs, such as LCSeg here, must be compatible with the operating systems and 64-bit architecture on the Grid servers, often requiring recompilation and occasionally addition of libraries to exi</context>
</contexts>
<marker>Carletta, Evert, Heid, Kilgour, Robertson, Voormann, 2003</marker>
<rawString>J. Carletta, S. Evert, U. Heid, J. Kilgour, J. Robertson, and H. Voormann. 2003. The NITE XML Toolkit: flexible annotation for multi-modal language data. Behavior Research Methods, Instruments, and Computers, special issue on Measuring Behavior, 35(3):353– 363.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jean Carletta</author>
<author>Simone Ashby</author>
<author>Sebastien Bourban</author>
<author>Mike Flynn</author>
<author>Mael Guillemot</author>
<author>Thomas Hain</author>
<author>Jaroslav Kadlec</author>
<author>Vasilis Karaiskos</author>
<author>Wessel Kraaij</author>
<author>Melissa Kronenthal</author>
<author>Guillaume Lathoud</author>
<author>Mike Lincoln</author>
<author>Agnes Lisowska</author>
<author>Iain A McCowan</author>
<author>Wilfried Post</author>
<author>Dennis Reidsma</author>
<author>Pierre Wellner</author>
</authors>
<title>The AMI meetings corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the Measuring Behavior</booktitle>
<contexts>
<context position="13552" citStr="Carletta et al., 2005" startWordPosition="2016" endWordPosition="2019">3). The exercise employs the web-based portal to the TeraGrid to perform segmentation of multiple interviews in parallel on the Grid, followed by evaluation in parallel. We perform segmentation using LCSeg (Galley et al., 2003) and evaluate using the Pk and WindowDiff metrics. Students identify the best segmentation parameters for these interviews and perform error analysis to assess the effect of ASR errors. The dialogue act tagging exercise involves both annotation and analysis components. The students are asked to download and annotate a small portion of a conversation from the AMI corpus (Carletta et al., 2005) with dialogue act tags. The AMI corpus of multiparty meetings includes recorded video, recorded audio, aligned manual transcriptions, and manually annotated head and hand gesture. Students annotate from text alone, with audio, with video, and with all modalities. Local ”transformations”, programs or scripts associated with the annotation client, can also provide prosodic analysis of features such as pitch and intensity. Students are asked to assess the influence of different features on their annotation process and to compare to a gold standard annotation which is later provided. The automati</context>
</contexts>
<marker>Carletta, Ashby, Bourban, Flynn, Guillemot, Hain, Kadlec, Karaiskos, Kraaij, Kronenthal, Lathoud, Lincoln, Lisowska, McCowan, Post, Reidsma, Wellner, 2005</marker>
<rawString>Jean Carletta, Simone Ashby, Sebastien Bourban, Mike Flynn, Mael Guillemot, Thomas Hain, Jaroslav Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa Kronenthal, Guillaume Lathoud, Mike Lincoln, Agnes Lisowska, Iain A. McCowan, Wilfried Post, Dennis Reidsma, and Pierre Wellner. 2005. The AMI meetings corpus. In Proceedings of the Measuring Behavior 2005 symposium on Annotating and measuring Meeting Behavior.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Franz</author>
<author>B Ramabhadran</author>
<author>T Ward</author>
<author>M Picheny</author>
</authors>
<title>Automated transcription and topic segmentation of large spoken archives.</title>
<date>2003</date>
<booktitle>In Proceedings of EUROSPEECH.</booktitle>
<contexts>
<context position="12932" citStr="Franz et al., 2003" startWordPosition="1920" endWordPosition="1923"> of exercises explores three main problems in this area: topic segmentation, dialogue act tagging, and turn-taking. The topic segmentation exercise investigates the impact of segment granularity and automatic speech recognition errors on topic segmentation of conversational speech. The data is drawn from the CrossLanguage Speech Retrieval Track of the Crosslanguage Evaluation Forum (CLEF CL-SR) (Pecina et al., 2007) collection. This collection includes automatic transcriptions of interviews from an oral history project, accompanied by manual segmentation created as part of the MALACH project (Franz et al., 2003). The exercise employs the web-based portal to the TeraGrid to perform segmentation of multiple interviews in parallel on the Grid, followed by evaluation in parallel. We perform segmentation using LCSeg (Galley et al., 2003) and evaluate using the Pk and WindowDiff metrics. Students identify the best segmentation parameters for these interviews and perform error analysis to assess the effect of ASR errors. The dialogue act tagging exercise involves both annotation and analysis components. The students are asked to download and annotate a small portion of a conversation from the AMI corpus (Ca</context>
</contexts>
<marker>Franz, Ramabhadran, Ward, Picheny, 2003</marker>
<rawString>M. Franz, B. Ramabhadran, T. Ward, and M. Picheny. 2003. Automated transcription and topic segmentation of large spoken archives. In Proceedings of EUROSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen McKeown</author>
</authors>
<title>Eric Fosler-Lussier, and Hongyan Jing.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL’03.</booktitle>
<marker>Galley, McKeown, 2003</marker>
<rawString>Michel Galley, Kathleen McKeown, Eric Fosler-Lussier, and Hongyan Jing. 2003. Discourse segmentation of multi-party conversation. In Proceedings ofACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
</authors>
<title>Anvil- a generic annotation tool for multimodal dialogue.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech),</booktitle>
<pages>1367--1370</pages>
<contexts>
<context position="3933" citStr="Kipp, 2001" startWordPosition="556" endWordPosition="557">nt research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined functions both on the client-side for data exploration and on the TeraGrid for large-scale distributed data processing. A we</context>
<context position="21398" citStr="Kipp, 2001" startWordPosition="3192" endWordPosition="3193">ramework do require some significant investment of time and effort. Incorporating new data sets and software packages requires programming expertise. The framework can, in principle, incorporate arbitrary data types: media, physiological measures, manual and automatic annotations, and even motion tracking. The data must be converted into the ELAN .eaf format to be deployed effectively by the annotation client and interpreted correctly by the archive’s underlying database. Converters have been created for several established formats2, such as Annotation Graphs (Bird and Liberman, 2001), ANVIL (Kipp, 2001), and EXMARaLDA(Schmidt, 2004), and projects are underway to improve interoperability between formats. However, new formats such as the CLEF Cross-language Speech Retrieval SGML format and NITE XML(Carletta et al., 2003) format for the AMI data used here, required the implementation of software to convert the source format to one suitable for use by SIDGrid. Incorporating new Grid-based ”transformation” programs can also range in required effort. For selfcontained programs in supported frameworks - currently, Perl, Python, Praat, and Octave - adding a new program requires only a simple browser</context>
</contexts>
<marker>Kipp, 2001</marker>
<rawString>M. Kipp. 2001. Anvil- a generic annotation tool for multimodal dialogue. In Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech), pages 1367–1370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
<author>Petra Hoffmannova</author>
<author>Gareth J F Jones</author>
<author>Ying Zhang</author>
<author>Douglas W Oard</author>
</authors>
<title>Overview of the clef-2007 cross language speech retrieval track. In Working Notes for CLEF</title>
<date>2007</date>
<contexts>
<context position="12732" citStr="Pecina et al., 2007" startWordPosition="1890" endWordPosition="1893"> expert. 3.1 Hands-on Exercises Currently, we have only included a small number of software tools as proof-of-concept and to enable particular course exercises in discourse and dialogue. This first set of exercises explores three main problems in this area: topic segmentation, dialogue act tagging, and turn-taking. The topic segmentation exercise investigates the impact of segment granularity and automatic speech recognition errors on topic segmentation of conversational speech. The data is drawn from the CrossLanguage Speech Retrieval Track of the Crosslanguage Evaluation Forum (CLEF CL-SR) (Pecina et al., 2007) collection. This collection includes automatic transcriptions of interviews from an oral history project, accompanied by manual segmentation created as part of the MALACH project (Franz et al., 2003). The exercise employs the web-based portal to the TeraGrid to perform segmentation of multiple interviews in parallel on the Grid, followed by evaluation in parallel. We perform segmentation using LCSeg (Galley et al., 2003) and evaluate using the Pk and WindowDiff metrics. Students identify the best segmentation parameters for these interviews and perform error analysis to assess the effect of A</context>
</contexts>
<marker>Pecina, Hoffmannova, Jones, Zhang, Oard, 2007</marker>
<rawString>Pavel Pecina, Petra Hoffmannova, Gareth J. F. Jones, Ying Zhang, and Douglas W. Oard. 2007. Overview of the clef-2007 cross language speech retrieval track. In Working Notes for CLEF 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Pennington</author>
</authors>
<title>Terascale clusters and the TeraGrid.</title>
<date>2002</date>
<booktitle>In Proceedings for HPC Asia,</booktitle>
<pages>407--413</pages>
<note>Invited talk.</note>
<contexts>
<context position="8766" citStr="Pennington, 2002" startWordPosition="1293" endWordPosition="1294"> file. The database structure further enables the potential for flexible search of the stored annotations both within and across multiple annotation types. 2.4 The TeraGrid Portal The large-scale multimedia data collected for multimodal research poses significant computational challenges. Signal processing of gigabytes of media files requires processing horsepower that may strain many local sites, as do approaches such as multi-dimensional scaling for semantic analysis and topic segmentation. To enable users to more effectively exploit this data, the SIDGrid provides a portal to the TeraGrid (Pennington, 2002), the largest distributed cyberinfrastructure for open scientific research, which uses high-speed network connections to link high performance computers and large scale data stores distributed across the United States. While the TeraGrid has been exploited within the astronomy and physics communities, it has been little used by the computational linguistics community. The SIDGrid portal to the TeraGrid allows largescale experimentation by providing access to largescale distributed processing clusters to enable parallel processing on very high capacity servers. The SIDGrid portal to the TeraGri</context>
</contexts>
<marker>Pennington, 2002</marker>
<rawString>Rob Pennington. 2002. Terascale clusters and the TeraGrid. In Proceedings for HPC Asia, pages 407–413. Invited talk.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schmidt</author>
</authors>
<title>Transcribing and annotating spoken language with EXMARaLDA.</title>
<date>2004</date>
<booktitle>In Proceedings of the LREC-Workshop on XML-based richly annotated corpora.</booktitle>
<contexts>
<context position="3837" citStr="Schmidt, 2004" startWordPosition="541" endWordPosition="542">June 2008. c�2008 Association for Computational Linguistics 2 SIDGrid Framework 2.1 Motivation Recent research programs in multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined functions both on the client</context>
<context position="21428" citStr="Schmidt, 2004" startWordPosition="3195" endWordPosition="3196">gnificant investment of time and effort. Incorporating new data sets and software packages requires programming expertise. The framework can, in principle, incorporate arbitrary data types: media, physiological measures, manual and automatic annotations, and even motion tracking. The data must be converted into the ELAN .eaf format to be deployed effectively by the annotation client and interpreted correctly by the archive’s underlying database. Converters have been created for several established formats2, such as Annotation Graphs (Bird and Liberman, 2001), ANVIL (Kipp, 2001), and EXMARaLDA(Schmidt, 2004), and projects are underway to improve interoperability between formats. However, new formats such as the CLEF Cross-language Speech Retrieval SGML format and NITE XML(Carletta et al., 2003) format for the AMI data used here, required the implementation of software to convert the source format to one suitable for use by SIDGrid. Incorporating new Grid-based ”transformation” programs can also range in required effort. For selfcontained programs in supported frameworks - currently, Perl, Python, Praat, and Octave - adding a new program requires only a simple browser-based upload. Compiled progra</context>
</contexts>
<marker>Schmidt, 2004</marker>
<rawString>T. Schmidt. 2004. Transcribing and annotating spoken language with EXMARaLDA. In Proceedings of the LREC-Workshop on XML-based richly annotated corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riccardo Serafin</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>Flsa: Extending latent semantic analysis with features for dialogue act classification.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>692--699</pages>
<location>Barcelona, Spain,</location>
<marker>Serafin, Di Eugenio, 2004</marker>
<rawString>Riccardo Serafin and Barbara Di Eugenio. 2004. Flsa: Extending latent semantic analysis with features for dialogue act classification. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 692–699, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wittenburg</author>
<author>H Brugman</author>
<author>A Russel</author>
<author>A Klassmann</author>
<author>H Sloetjes</author>
</authors>
<title>Elan: a professional framework for multimodality research.</title>
<date>2006</date>
<booktitle>In Proceedings of Language Resources and Evaluation Conference (LREC)</booktitle>
<contexts>
<context position="3969" citStr="Wittenburg et al., 2006" startWordPosition="560" endWordPosition="564"> multi-modal environments, including understanding and analysis of multi-party meeting data and oral history recording projects, have created an explosion of multi-modal data sets, including video and audio recordings, transcripts and other annotations, and increased interest in annotation and analysis of such data. A number of systems have been developed to manage and support annotation of multi-modal data, including Annotation Graphs (Bird and Liberman, 2001), Exmeralda (Schmidt, 2004), NITE XML Toolkit (Carletta et al., 2003), Multitool (Allwood et al., 2001), Anvil (Kipp, 2001), and Elan (Wittenburg et al., 2006). The Social Informatics Data Grid (SIDGrid), developed under the NSF Cyberinfrastructure Program, aims to extend the capabilities of such systems by focusing on support for largescale, extensible distributed data annotation, sharing, and analysis. The system is open-source and multi-platform and based on existing open-source software and standards. The system greatly eases the integration of annotation with analysis though userdefined functions both on the client-side for data exploration and on the TeraGrid for large-scale distributed data processing. A web-accessible repository supports dat</context>
</contexts>
<marker>Wittenburg, Brugman, Russel, Klassmann, Sloetjes, 2006</marker>
<rawString>P. Wittenburg, H. Brugman, A. Russel, A. Klassmann, and H. Sloetjes. 2006. Elan: a professional framework for multimodality research. In Proceedings of Language Resources and Evaluation Conference (LREC) 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>