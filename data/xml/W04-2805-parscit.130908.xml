<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000985">
<title confidence="0.87138">
Scalable Construction-Based Parsing and Semantic Analysis
</title>
<author confidence="0.989556">
John Bryant
</author>
<affiliation confidence="0.9987285">
Department of Computer Science
University of California at Berkeley
</affiliation>
<address confidence="0.824397">
Berkeley, CA 94720
</address>
<email confidence="0.998559">
jbryant@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.996653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999815">
In ScaNaLU 2002, Chang et al presented a
scalable natural language formalism called
Embodied Construction Grammar (ECG)
(Chang et al., 2002). ECG makes deep un-
derstanding systems possible because it is a
rigorous, unified formalism that incorporates
the semantic and pragmatic insights found
in cognitive linguistics. The work described
in this paper builds on (Chang et al., 2002)
because it leverages the ECG formalism to
perform deep, scalable construction-based
parsing and semantic analysis.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999989255813954">
As described by (Chang et al., 2002), the semantic and
pragmatic insights provided by cognitive linguistics must
be incorporated into a language understanding system be-
fore deep understanding can take place. Embodied Con-
struction Grammar (ECG) (Chang et al., 2002), (Bergen
and Chang, 2002) is a rigorous, formalism incorporat-
ing such insight. It provides formal mechanism for de-
scribing cognitive primitives like linguistic constructions
(Goldberg, 1995), image schemas (Lakoff, 1987), frames
(Fillmore, 1982), and mental spaces (Fauconnier and
Turner, 2002), as well as cross-domain mappings.
From a system-building point of view, however, the
importance of ECG lies in its scalability. Within its
unification-based framework, constructions, frames and
mental spaces are combined compositionally, yielding a
network of entwined semantic and pragmatic structures
representing the overall interpretation. This makes it pos-
sible for ECG to scale to much more complex linguistic
data that previous formalisms would allow.
The work described in this paper builds on this system-
building perspective since it is a system that leverages the
ECG formalism to perform deep, scalable construction-
based parsing and semantic analysis. It incorporates an
implementation of ECG’s semantic and constructional
primitives as well as integrating scalable language anal-
ysis algorithms like level-based parsing (Abney, 1996).
This system is called the constructional analyzer and it
fits into a larger framework for scalable, simulation-based
language understanding.
In a simulation-based model of language understand-
ing, interpretation of an utterance is split into two phases:
analysis and enactment. Analysis is the process of map-
ping forms to context-independent meanings, providing
the input parameters for enactment. Enactment uses
an active, simulation-based model to generate context-
specific inference. This process-level separation of anal-
ysis and inference provides further scalability.
The next three sections describe the ECG formal-
ism, simulation-based understanding and partial parsing.
Then the constructional analyzer is described along with
an example. The paper closes with a description of a lan-
guage analysis task requiring the deep semantic represen-
tation afforded by the constructional analyzer.
</bodyText>
<sectionHeader confidence="0.9933235" genericHeader="introduction">
2 The Embodied Construction Grammar
formalism
</sectionHeader>
<bodyText confidence="0.999709">
The grammar formalism that makes constructional anal-
ysis possible is the Embodied Construction Grammar.
ECG combines a syntax and knowledge representation
in a unification-based framework. This allows both con-
structions and frame-based, schematic knowledge to be
expressed succinctly in the same formalism.
As usual for construction grammar, the grammar
rules in ECG are pairs, mapping a particular lexi-
cal/morphological/syntactic pattern to a (partial) specifi-
cation of a situation. In ECG, this description of a situa-
tion is known as a semantic specification (semspec). The
semspec combines embodied semantic primitives like
</bodyText>
<figure confidence="0.996071444444445">
schema Into
subcase of Trajector-Landmark
evokes s as SPG
roles
landmark: Container
constraints
trajector !s.trajector
s.source !landmark.exterior
s.goal !landmark.interior
</figure>
<figureCaption confidence="0.959046">
Figure 2: The Into schema.
</figureCaption>
<figure confidence="0.9556112">
construction IntoCxn
subcase of Spatial-Relation
form: Word
selff.orth -“into”
meaning: Into
</figure>
<figureCaption confidence="0.985594">
Figure 3: The Into lexical construction.
</figureCaption>
<figure confidence="0.992123722222222">
schema Container
subcase of Image-Schema
roles
interior :
exterior :
portal :
boundary:
schema SPG
subcase of Image-Schema
roles
source :
path :
goal :
schema Trajector-Landmark
subcase of Image-Schema
roles
trajector:
landmark:
</figure>
<figureCaption confidence="0.999986">
Figure 1: Some image schemas in ECG notation.
</figureCaption>
<bodyText confidence="0.999970112903226">
image schemas (Lakoff, 1987) and executing schemas
(Narayanan, 1997) with frame-based knowledge (Fill-
more, 1982) to completely specify the meaning of an ut-
terance.
Meaning in ECG is represented by schemas. Schemas,
much like frames, are schematic, role-based conceptual
and semantic structures. But as they are intended to de-
scribe an embodied, parameter-based representation of
language, the schema formalism is augmented by special
semantic operators that make cognitive linguistic insights
easier to express.
As an initial starting point into the formalism, figure 1
shows three canonical image schemas in ECG notation.
Each schema is initially defined by the keyword schema,
and after the name, an optional subcase of line denotes
the structures from which the current schema inherits.
Much like frames, ECG schemas (and constructions) are
arranged into a type hierarchy from which a schema can
inherit structure. In this case, each image schema inherits
from the Image-Schema type. Following the subcase of,
comes the optional roles block, denoted by the roles key-
word. Just like the roles of a frame, the roles of a schema
are the parameters of the concept being described.
These simple image schemas do not show off all of
ECG’s schema mechanism, however. For a more com-
plete picture, we now focus on the Into schema shown
in figure 2. The Into schema subcases the Trajector-
Landmark schema, and thus inherits the trajector and
landmark roles from its parent. The Into schema further
constrains the landmark role by constraining it to be of
type Container.
The Into schema also introduces the new evokes op-
erator which makes the specified type locally accessible
via the given alias. In this case, the evoked SPG schema
acts as the background frame, capturing into’s notion of
motion. This is the primary virtue of the evokes opera-
tor. It provides a way to place concepts such as bachelor
into the context of their larger background frames, as de-
scribed by (Fillmore, 1982).
After the roles block in the Into schema, comes the op-
tional constraints block. Constraints act as the semantic
glue with the$identifying its two argument slots. When
a set of slots have been coindexed, a proposed filler to
any one of those slots must satisfy the restrictions of all
of them. In the Into schema, the locally defined land-
mark.interior1 role2 is identified with the evoked SPG’s
goal role, while the landmark.exterior role is coindexed
with the SPG’s source role. These constraints schemati-
cally describe how the use of into suggests motion from
outside some container to the inside of that container.
Figure 3 shows the Into lexical construction. Every
construction starts with the keyword construction, fol-
lowed by the name of the construction. Then comes the
optional subcase of keyword that relates constructions to
the constructional type system. The ECG version of the
Into construction has a form and meaning pole, notated
by the keywords form and meaning.
Constructions can type their form and meaning poles.
In the case of our Into construction, the form pole is of
schema type Word3 and the meaning pole is of type Into
schema. A typed meaning pole indicates that a particu-
lar construction denotes an instance of that type. Thus
</bodyText>
<footnote confidence="0.98972775">
1ECG uses slot chain notation.
2The landmark role has an interiorrole because it was con-
strained to be of type Container.
3Form in ECG is also represented with schemas.
</footnote>
<bodyText confidence="0.998994645833333">
our Into construction claims that the word into means an
instance of the complex relation described by the Into
schema.
The Into construction also exhibits the assignment op-
erator ( ). This operator fills a slot with an atomic value.
In our Into construction’s form pole, the orth4 feature
brought in from the Word schema is assigned the atomic
string into.
Figure 4 shows the clausal Caused-Motion construc-
tion, an example of which is The basketball player threw
the ball into the basket. This construction has an agent
(the player) which acts upon a patient (throwing the
ball) thereby moving it along a path (into the basket).
Since the Caused-Motion construction links a particular
syntactic form, that of a referring expression, a force-
application verb, a referring expression and a path to a
Caused-Motion-Scene5, the construction is different from
the ones we have covered so far in that it has constituents
that are themselves constructions. Thus instead of typing
the form block, the form block has constraints relating
the constituents.
Each of the construction’s four constituents are defined
in the constructional block. Each constituent is assigned
a local name, and then after the colon, the constructional
type is defined. If necessary, like in the case of the Verb
constituent, a semantic type is added in brackets.
The ordering of these constituents is specified by
adding form constraints to the form block. When the con-
structional analyzer searches for instances of a construc-
tion, these form constraints must be satisfied. The two
supported constraints are before which requires that the
left argument be somewhere the left of the right argument
in the input, and meets which requires the left argument
to be directly before the right argument in the input.
In the Caused-Motion construction, the form con-
straints require that the agent be directly before the verb
and the verb be before the path and patient. Notice that
the relative order of the path and patient is left unspec-
ified6. Because ECG allows constituent order to be un-
specified like this, ECG can express with one rule what a
CFG might have to express with an exponential number
of rules.
The meaning pole of the construction uses the seman-
tic machinery that has already been described. It links
the agent.’s category to the agent of the scene as well as
setting patient..category to the trajector of the specified
path. Notice that the constraints use the m and f sub-
scripts when referring to the constructional constituents’
</bodyText>
<footnote confidence="0.9976014">
4Orth is short for orthography.
5A caused motion scene is one where the agent applies force
to the patient resulting in a shift in the position of the patient.
6This might be a partial solution for dealing with what are
called heavy NPs.
</footnote>
<figure confidence="0.896353409090909">
construction Caused-Motion
subcase of Clause
constructional
agent : REFExP
verb : VERB [APPLY-FORCE]
patient : REFExP
path : SPATIAL-PREDICATION
form
af meetsvf
v f before p f
v f befor e pa f
meaning : Caused-Motion-Scene
self..action � , verb.
agent..category self..agent
patient..category self..patient
self..path � , path.m
schema Caused-Motion-Scene
subcase of Transitive-Scene
evokes c as Cause-Effect
roles
result-motion: Move
path: SPG
constraints
c.cause action
c.effect result-motion
result-motion. executor � , patient
result-motion. path � , path
path.trajector � , patient
schema Transitive-Scene
subcase of Scene
evokes a as Apply-Force
roles
patient: Entity
constraints
action a
patient a.patient
schema Scene schema Cause-Effect
roles roles
agent: Agent cause: Action
action: Action effect: Action
schema Apply-Force
subcase of Action
roles
patient: Entity
</figure>
<figureCaption confidence="0.9807">
Figure 4: The Caused-Motion Construction and related
schemas.
</figureCaption>
<bodyText confidence="0.999681666666667">
form and meaning poles, respectively, and can be applied
to any construction as if they were just dotting into the
structure.
With a formal language for describing constructions,
many avenues are opened. The most important for the
sake of this work, is that it is possible to translate ECG
descriptions into feature structures. For the most part,
this translation is straightforward. For example, schemas,
constructions are represented as feature structures and
their roles are represented (unsurprisingly) as roles.
The evokes operator, however, requires a little more
care to properly model its nonlocal semantics. In this
case, the evoked type is generated outside of the evok-
ing structure. The evoked structure’s alias is represented
as a local role coindexed with the nonlocal structure7.
</bodyText>
<sectionHeader confidence="0.982464" genericHeader="method">
3 Simulation-Based Language
Understanding
</sectionHeader>
<bodyText confidence="0.999895766666666">
Simulation-based language understanding draws infer-
ences about actions and events by executing an active
model. The active models are called x-schemas (short
for executing schemas) which are extensions to stochas-
tic petri nets. In order to draw inferences about an action
like walking, the system performs a simulation by exe-
cuting its internal model of walking.
To tailor the inference to a particular scenario, the sim-
ulator needs to set the parameters of the x-schema rep-
resentation appropriately. These parameters are the free
variables that control how the simulation executes. For
example, the walking x-schema would have parameters
for who the walker is and for the path (or direction) of
motion. So in the sentence Harry walked into the cafe,
the walker would be Harry and the path would be into
the cafe.
But before a language understanding system can uti-
lize the virtues of such a model, the parameters must be
extracted from the utterance. This is where the construc-
tional analyzer comes in. If the constructions have fea-
tures designed to interact with the simulator, each con-
structional analysis will provide the parameters to the
simulation, and the analyzer and simulator will interact
to understand the utterance.
Researchers have integrated the constructional ana-
lyzer with a simulation engine, creating a unique and
powerful method for language understanding. Such a sys-
tem would even be able to do “exotic” metaphorical in-
ference with ease, since metaphorical inference is just a
special kind of parameterization8.
</bodyText>
<footnote confidence="0.9963225">
7With this implementation, ECG does not require any exten-
sions to standard unification algorithms.
8See (Narayanan, 1997) for more information about
metaphorical inference.
</footnote>
<sectionHeader confidence="0.945333" genericHeader="method">
4 Syntactic Chunking
</sectionHeader>
<bodyText confidence="0.999972852941176">
Traditional chunking is a simple parsing algorithm where
each syntax rule is transformed into a finite state rec-
ognizer. The recognizers are arranged into levels, con-
trolling the order of the reductions. A chunker starts at
the lowest level (and hopefully most-certain reductions)
which are done by the part of speech tagger. Then it
proceeds up the levels toward the less certain reductions.
This bottom up approach assumes (obviously incorrectly)
that reductions can be made locally and bottom-up with-
out any notion of global context, giving the algorithm
speed and state savings.
Within a single level, the reductions are done greedily.
Going left to right through the input, whenever a particu-
lar pattern is recognized, the longest match of that pattern
is reduced. Figure 5 shows the steps that an Abney chun-
ker goes through for the sentence, The woman in the lab
coat thought you were sleeping.
This figure exposes both the virtues and weaknesses of
chunking–the weakness being the fact that the parse for
the sentence does not attach the prepositional phrase in
the lab coat, treating it instead as a sister to the the woman
noun group. But it also illustrates the robustness of the
system in that while the grammar has no rule for reduced
relative, it still correctly labels the syntactic groups. In
other words, the incompleteness of the grammar does not
cause phrases to be rejected since there is no requirement
that a successful parse converge to a complete sentence.
Thus such a parser is well-suited for spoken language
(Hinrichs et al., 2000), where Hinrichs, et al were able
to get 93% “correctness” 9 at finding the various syntactic
groups from an error prone spoken language input. Un-
surprisingly without any semantics, they were only able
to achieve 54% “correctness” when generating the com-
plete parse tree from the chunk analysis.
</bodyText>
<sectionHeader confidence="0.98147" genericHeader="method">
5 The Constructional Analyzer
</sectionHeader>
<bodyText confidence="0.950017833333333">
Because the approach to constructional analysis we de-
scribe in this report uses a level-based processing model,
it can be considered a relative of such shallow informa-
tion extraction tools. But instead of doing shallow se-
mantic analysis for the purposes of information extrac-
tion, it utilizes both the semantic richness of construc-
tion grammar and extended computational mechanisms
to do full constructional analysis, resulting in both a com-
plete syntactic analysis and a deep semantic analysis. The
constructional analyzer integrates the following computa-
tional capabilities to make deep analysis possible.
•Support for unification
</bodyText>
<footnote confidence="0.902447">
9They do not give a notion of what correctness means in
their paper.
</footnote>
<figure confidence="0.5891752">
L3 S S
L2 NG PG V NG V
L1 NG P NG V NG V
L0 D N P D N N Vtns Pron Aux Ving
the woman in the lab coat thought you were sleeping
</figure>
<figureCaption confidence="0.74234375">
Figure 5: A Partial Parse from (Abney, 1996). Since this processing model is bottom up, first the level 0 reductions
are performed, then the level 1 reductions, then level 2 and finally level 3. In the nonterminals, G is used (for group)
instead ofp (for phrase) to clearly indicate that these are non-recursive chunks. Each grammar symbol spans all the
input to its left until another grammar is encountered.
</figureCaption>
<bodyText confidence="0.962292">
•Support for multiple concurrent analyses with a
chart
•Support for the more flexible form relations found
in ECG
</bodyText>
<subsectionHeader confidence="0.724132">
•Support for ECG’s semantic expressiveness
5.1 The Basics of the Constructional Analyzer
</subsectionHeader>
<bodyText confidence="0.999965913043478">
Since ECG is a unification-based formalism, supporting
unification is a necessary first step. Along with unifica-
tion, a chart is employed by the system to keep track of
the many possible analyses generated during rule-based
language analysis.
On the form side, the analyzer cannot use finite state
machines or even context free grammars to do matching
because of ECG’s more relaxed notion of form. ECG
does not require the grammar writer to specify a total
ordering on a construction’s constituents, and thus rec-
ognizers requiring a total ordering (like CFG parsers) in
each rule are unusable. The constructional analyzer in-
stead uses a computational unit called a construction rec-
ognizer.
A construction recognizer is the chunk of active knowl-
edge into which a construction gets transformed. Each
construction recognizer is designed to check both the
form and meaning constraints of just the construction it
models. In other words, instead of a monolithic parser
that takes the grammar rules as input, the constructional
analyzer itself is a collection of active construction rec-
ognizers working together to generate the constructional
analysis.
</bodyText>
<subsectionHeader confidence="0.99953">
5.2 An Example
</subsectionHeader>
<bodyText confidence="0.992213888888889">
In order to make the previous discussion more concrete,
let’s analyze an example sentence using the Caused-
Motion construction described earlier. The sentence we
will consider is The basketball player threw the ball into
the basket. Given a grammar that can handle simple refer-
ring expressions of the form (Det) Adj* Noun+ (making
sure to add the appropriate semantics) and spatial phrases,
we can arrange the rules into levels (see figure 6) and gen-
erate analyses that use the Caused-Motion construction.
</bodyText>
<listItem confidence="0.994224333333333">
0. Lexical constructions
1. Noun noun compounds
2. Adjectives
3. Referring expressions
4. Spatial Predications
5. Clausal constructions
</listItem>
<figureCaption confidence="0.999672">
Figure 6: The levels used in the example analysis.
</figureCaption>
<figure confidence="0.974556777777778">
construction Noun-Noun-Compound
subcase of Category
constructional
a: CATEGORY
b: CATEGORY
form
af meets bf
mean ing
self. � b.
</figure>
<figureCaption confidence="0.9775855">
Figure 7: A Generic Noun-Noun-Compound construction
that just sets the meaning of the construction as a whole
to be that of the second constituent. It relies on the struc-
ture merging process (Bryant, 2003) to infer the correct
relation between the two Category constituents.
Figure 7 shows an example noun-noun compound con-
</figureCaption>
<bodyText confidence="0.939690888888889">
struction used in the analysis that puts constituents of
type category10 together to generate an instance of type
Noun-Noun-Compound which is itself subtype of cate-
gory. Thus the rule is recursive with itself and any other
category requiring rule. Notice that it is on the same level
that all other category constructions are assigned. The
constructional analyzer allows the constructions assigned
to the same level to be mutually recursive.
After the Category constructions are processed, simple
</bodyText>
<footnote confidence="0.992087666666667">
10An instance of the category construction can either be
what is usually considered a noun like dog or a noun-noun com-
pound like vinyl siding salesman or gas meter turn-off valve.
</footnote>
<figureCaption confidence="0.864963">
Figure 8: The constituent graph structure for the Caused-
Motion construction. Each constituent corresponds to a
</figureCaption>
<bodyText confidence="0.980133581395349">
node in the constituent graph. At any particular point, the
construction recognizer is only allowed to search for con-
stituents with no incoming edges. When a constituent is
found, its node is removed from the graph along with any
outgoing edges from that node. After removing a node,
the construction recognizer is now allowed to search for
different, newly-released constituents or if there are no
nodes left, then a valid instance of the construction (at
least with respect to the form constraints) has been found.
referring expressions are generated. After the referring
expressions, Spatial-Predication constructions are recog-
nized on the next level, and the constructional analyzer
is finally ready to match the Caused-Motion construction.
Figures 8 and 9 (and the rest of this section) describe the
matching process schematically.
In frame A of figure 9, the construction recognizer is
in its initial state and it has not found any of the con-
stituents for the Caused-Motion construction. In B, the
recognizer has found a referring expression correspond-
ing to the basketball player, and since it unifies with the
agent role of the Caused-Motion construction, it is ac-
cepted as the first constituent. Notice how the node in the
graph corresponding to the agent is removed indicating
that it has been found.
In frames C and D, the same scenario takes place ex-
cept it is the verb threw and the referring expression the
ball that satisfy the form and meaning requirements of
their corresponding constituents. Notice in C that the
construction recognizer is now allowed to find either the
patient or the path since both nodes have no incoming
edges. In E, we see a completely matched Caused-Motion
construction with a complete Caused-Motion scene and
an empty constituent graph indicating that a complete in-
stance of this construction has been found.
In short, the construction recognizer builds up a graph
data structure to keep track of the constituents and an in-
progress semspec to keep track of the semantics. Each
constituent that satisfies the form and semantic con-
straints updates the constituent graph and the in-progress
partial semspec. The final result for a successful match
has the agent of the caused motion scene to be the player,
the patient being the ball, and the goal of the path being
the interior of the basket.
</bodyText>
<subsectionHeader confidence="0.998952">
5.3 Computational Complexity
</subsectionHeader>
<bodyText confidence="0.999971965517241">
At its core, the constructional analyzer is just a unifica-
tion parser that needs to support the quirks of a particu-
lar grammar formalism. The quirk that most affects the
computational complexity of the constructional analyzer
is ECG’s support for partial constituent order.
Barton (1985) showed that parsing with unordered
CFG rules is NP-complete. Since an ECG grammar can
leave all constituency unordered, the worst case runtime
must be exponential with respect to the utterance. An ac-
tual grammar of this sort is unlikely, however, and thus
it is useful to symbolically bound the runtime of the ana-
lyzer in terms of the number of unifications it performs.
For purposes of the complexity analysis, call the num-
ber of levelsl, the number of recognizers at each level
r, and assume an input ofkwords. Further assuming
that there areO(k)states in each chart entry, and that the
number of constituent orderings allowed by a grammar
rule isjfor the max ofcconstituents used in any rule.
The worst-case runtime would then be O(lrkcj) since
there would be kc combinations of unifications for each
of thejconstituent orderings associated with a particular
recognizer.
Clearly any product ofcandjmuch over 2 makes the
algorithm intractable for all but the smallest grammars.
Consequently, an open area of research is a mechanism
for concentrating effort on the most promising syntactic
and semantic combinations using methods of the sort de-
scribed in (Narayanan and Jurafsky, 1998) and (Bryant,
2003).
</bodyText>
<sectionHeader confidence="0.98524" genericHeader="evaluation">
6 Applications
</sectionHeader>
<bodyText confidence="0.999837666666667">
The constructional analyzer is currently being put to use
in two tasks that require the deep semantics that it pro-
vides.The first task is that of Simulation-Based Language
Understanding (Narayanan, 1997) has already been de-
scribed. The second is the task of inductive learning of
child constructions (Chang and Maia, 2001).
</bodyText>
<subsectionHeader confidence="0.998873">
6.1 Child Language Learning
</subsectionHeader>
<bodyText confidence="0.9992902">
The language learning model used by Chang (Chang and
Maia, 2001) is a comprehension-based model of language
learning built on the following assumptions:
•There is significant prior knowledge going into the
learning process.
</bodyText>
<figure confidence="0.997150666666667">
agent verb
patient
path
</figure>
<figureCaption confidence="0.9977535">
Figure 9: Snapshots of the internal state of the Caused-Motion construction recognizer on the sentence The basketball
player threw the ball into the basket.
</figureCaption>
<figure confidence="0.996875095238095">
agent
verb
patient
the
basketball
player
threw the ball
threw
the
basketball
player
verb
patient
agent
path
agent
verb
patient
path
B
agent
verb
patient
path
Caused-Motion Scene
agent:
action:
path:
patient:
path.trajector:
the
basketball
player
Caused-Motion Scene
agent: the player
action:
path:
patient:
path.trajector:
Caused-Motion Scene
agent: the player
action: threw
path:
patient:
path.trajector:
the basketball
player
threw the ball into the
basket
Caused-Motion Scene
agent: the player
action: threw
path: into the basket
patient: the ball
path.trajector: the basket
E
Caused-Motion
A
Caused-Motion
agent verb
patient
path
verb
patient
path
Caused-Motion
C
patient
path
Caused-Motion Scene
agent: the player
action: threw
path:
patient: the ball
path.trajector: the ball
patient
path
Caused-Motion
D
agent
Caused-Motion
path
path
verb
</figure>
<bodyText confidence="0.993698677419355">
•The learning is incremental and based on experi-
ence.
•The learning is tied to language use. i.e. Frequency
of language data affects the learning.
The model analyzes the incoming utterance using the
current set of constructions that have been learned. If
the current analysis generated by the constructional an-
alyzer cannot explain all of the semantic content found
in the current scenario associated with the utterance, the
model hypothesizes new constructions. This hypothesis
process pairs up the unused form relations with the miss-
ing semantic relations to produce constructions that fill
in the semantic/pragmatic gap. Since the hypothesis pro-
cess is under-constrained, the model generates multiple
constructions in an attempt to explain the same missing
semantic content. The more useful of these constructions
in later analyses are the ones that get reinforced while the
others wither away.
This model of learning depends on the language an-
alyzer to initially try and explain the semantics of the
scene. But for such an analyzer to be useful it needs
to be semantically focused. It also needs to be capa-
ble of incremental analysis as well as tolerant of noise
and missing constructions. These requirements line up
perfectly with the constructional analyzer’s virtues pri-
marily because the language learning task heavily influ-
enced the design of the constructional analyzer. In effect,
the constructional analyzer was built on the assumption
that all grammars, not just grammars in the process of
being learned, will lack coverage when faced with real
language.
</bodyText>
<sectionHeader confidence="0.998918" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999543866666667">
Cognitive linguistics has provided the theoretical basis
for turning natural language systems into broad coverage
systems, but a formal mechanism to describe these the-
ories was a necessary first step before natural language
systems could take advantage. ECG stepped in to provide
such formal mechanism, and the first system to profit is
the constructional analyzer.
The work is far from over, however. While the current
system does (theoretically) scale with respect to linguistic
coverage, it still does not scale with respect to computa-
tional performance. Thus further computational work is
necessary. The deep semantics must be leveraged to make
the systems computationally faster and more robust. Ini-
tial work in this direction has already begun (Narayanan
and Jurafsky,1998) (Bryant, 2003).
</bodyText>
<sectionHeader confidence="0.994076" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992732717948718">
Steven Abney. 1996. Partial parsing via finite-state cas-
cades. In Proceedings of the ESSLLI ’96 Robust Pars-
ing Workshop.
Benjamin Bergen and Nancy Chang. 2002. Embodied
construction grammar in simulation-based language
understanding. Technical Report TR-02-004, ICSI. To
appear in Oestman and Reid, eds., Construction Gram-
mar(s): Cognitive and Cross Lingusitic Dimensions.
John Benjamins.
John Bryant. 2003. Constructional analysis. Master’s
thesis, UC Berkeley.
Nancy Chang and Tiago Maia. 2001. Learning grammat-
ical constructions. In Proceedings of the Conference of
the Cognitive Science Society.
Nancy Chang, Jerome Feldman, Robert Porzel, and
Keith Sanders. 2002. Scaling cognitive linguis-
tics:formalisms for language understanding.
Gilles Fauconnier and Mark Turner. 2002. The Way
We Think:Conceptual Blending and The Mind’s Hid-
den Complexities. Basic Books.
Charles Fillmore. 1982. Frame semantics. In Linguis-
tics in the Morning Calm, pages 111–138. Linguistics
Society of Korea.
Adele Goldberg. 1995. Constructions: A Construction
Grammar Approach to Argument Structure. University
of Chicago Press.
Erhard Hinrichs, Sandra Huebler, Valia Kordoni, and
Frank Mueller. 2000. Robust chunk parsing for spon-
taneous speech. In Wolfgang Wahlster, editor, Verb-
mobil:Foundations of Speech-to-Speech Translation,
pages 163–182. Springer.
George Lakoff. 1987. Women, Fire, and Dangerous
Things. University of Chicago Press.
Srini Narayanan and Daniel Jurafsky. 1998. Bayesian
models of sentence processing. In Proceedings of the
Conference of the Cognitive Science Society.
Srini Narayanan. 1997. Knowledge-Based Action Rep-
resentations for Metaphor and Aspect. Ph.D. thesis,
University of California at Berkeley.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.884298">
<title confidence="0.999943">Scalable Construction-Based Parsing and Semantic Analysis</title>
<author confidence="0.983666">John</author>
<affiliation confidence="0.9981045">Department of Computer University of California at</affiliation>
<address confidence="0.918381">Berkeley, CA</address>
<email confidence="0.999314">jbryant@icsi.berkeley.edu</email>
<abstract confidence="0.998594076923077">In ScaNaLU 2002, Chang et al presented a scalable natural language formalism called Embodied Construction Grammar (ECG) (Chang et al., 2002). ECG makes deep understanding systems possible because it is a rigorous, unified formalism that incorporates the semantic and pragmatic insights found in cognitive linguistics. The work described in this paper builds on (Chang et al., 2002) because it leverages the ECG formalism to perform deep, scalable construction-based parsing and semantic analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1996</date>
<booktitle>In Proceedings of the ESSLLI ’96 Robust Parsing Workshop.</booktitle>
<contexts>
<context position="2109" citStr="Abney, 1996" startWordPosition="296" endWordPosition="297">ally, yielding a network of entwined semantic and pragmatic structures representing the overall interpretation. This makes it possible for ECG to scale to much more complex linguistic data that previous formalisms would allow. The work described in this paper builds on this systembuilding perspective since it is a system that leverages the ECG formalism to perform deep, scalable constructionbased parsing and semantic analysis. It incorporates an implementation of ECG’s semantic and constructional primitives as well as integrating scalable language analysis algorithms like level-based parsing (Abney, 1996). This system is called the constructional analyzer and it fits into a larger framework for scalable, simulation-based language understanding. In a simulation-based model of language understanding, interpretation of an utterance is split into two phases: analysis and enactment. Analysis is the process of mapping forms to context-independent meanings, providing the input parameters for enactment. Enactment uses an active, simulation-based model to generate contextspecific inference. This process-level separation of analysis and inference provides further scalability. The next three sections des</context>
<context position="16692" citStr="Abney, 1996" startWordPosition="2604" endWordPosition="2605">rmation extraction, it utilizes both the semantic richness of construction grammar and extended computational mechanisms to do full constructional analysis, resulting in both a complete syntactic analysis and a deep semantic analysis. The constructional analyzer integrates the following computational capabilities to make deep analysis possible. •Support for unification 9They do not give a notion of what correctness means in their paper. L3 S S L2 NG PG V NG V L1 NG P NG V NG V L0 D N P D N N Vtns Pron Aux Ving the woman in the lab coat thought you were sleeping Figure 5: A Partial Parse from (Abney, 1996). Since this processing model is bottom up, first the level 0 reductions are performed, then the level 1 reductions, then level 2 and finally level 3. In the nonterminals, G is used (for group) instead ofp (for phrase) to clearly indicate that these are non-recursive chunks. Each grammar symbol spans all the input to its left until another grammar is encountered. •Support for multiple concurrent analyses with a chart •Support for the more flexible form relations found in ECG •Support for ECG’s semantic expressiveness 5.1 The Basics of the Constructional Analyzer Since ECG is a unification-base</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Steven Abney. 1996. Partial parsing via finite-state cascades. In Proceedings of the ESSLLI ’96 Robust Parsing Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Bergen</author>
<author>Nancy Chang</author>
</authors>
<title>Embodied construction grammar in simulation-based language understanding.</title>
<date>2002</date>
<tech>Technical Report TR-02-004,</tech>
<editor>ICSI.</editor>
<publisher>John Benjamins.</publisher>
<note>To appear in Oestman</note>
<contexts>
<context position="994" citStr="Bergen and Chang, 2002" startWordPosition="137" endWordPosition="140">possible because it is a rigorous, unified formalism that incorporates the semantic and pragmatic insights found in cognitive linguistics. The work described in this paper builds on (Chang et al., 2002) because it leverages the ECG formalism to perform deep, scalable construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, however, the importance of ECG lies in its scalability. Within its unification-based framework, constructions, frames and mental spaces are combined compositionally, yielding a network of entwined semantic and pragmatic structures representing the overall i</context>
</contexts>
<marker>Bergen, Chang, 2002</marker>
<rawString>Benjamin Bergen and Nancy Chang. 2002. Embodied construction grammar in simulation-based language understanding. Technical Report TR-02-004, ICSI. To appear in Oestman and Reid, eds., Construction Grammar(s): Cognitive and Cross Lingusitic Dimensions. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Bryant</author>
</authors>
<title>Constructional analysis. Master’s thesis,</title>
<date>2003</date>
<institution>UC Berkeley.</institution>
<contexts>
<context position="19448" citStr="Bryant, 2003" startWordPosition="3038" endWordPosition="3039">es into levels (see figure 6) and generate analyses that use the Caused-Motion construction. 0. Lexical constructions 1. Noun noun compounds 2. Adjectives 3. Referring expressions 4. Spatial Predications 5. Clausal constructions Figure 6: The levels used in the example analysis. construction Noun-Noun-Compound subcase of Category constructional a: CATEGORY b: CATEGORY form af meets bf mean ing self. � b. Figure 7: A Generic Noun-Noun-Compound construction that just sets the meaning of the construction as a whole to be that of the second constituent. It relies on the structure merging process (Bryant, 2003) to infer the correct relation between the two Category constituents. Figure 7 shows an example noun-noun compound construction used in the analysis that puts constituents of type category10 together to generate an instance of type Noun-Noun-Compound which is itself subtype of category. Thus the rule is recursive with itself and any other category requiring rule. Notice that it is on the same level that all other category constructions are assigned. The constructional analyzer allows the constructions assigned to the same level to be mutually recursive. After the Category constructions are pro</context>
<context position="24209" citStr="Bryant, 2003" startWordPosition="3804" endWordPosition="3805">ber of constituent orderings allowed by a grammar rule isjfor the max ofcconstituents used in any rule. The worst-case runtime would then be O(lrkcj) since there would be kc combinations of unifications for each of thejconstituent orderings associated with a particular recognizer. Clearly any product ofcandjmuch over 2 makes the algorithm intractable for all but the smallest grammars. Consequently, an open area of research is a mechanism for concentrating effort on the most promising syntactic and semantic combinations using methods of the sort described in (Narayanan and Jurafsky, 1998) and (Bryant, 2003). 6 Applications The constructional analyzer is currently being put to use in two tasks that require the deep semantics that it provides.The first task is that of Simulation-Based Language Understanding (Narayanan, 1997) has already been described. The second is the task of inductive learning of child constructions (Chang and Maia, 2001). 6.1 Child Language Learning The language learning model used by Chang (Chang and Maia, 2001) is a comprehension-based model of language learning built on the following assumptions: •There is significant prior knowledge going into the learning process. agent v</context>
</contexts>
<marker>Bryant, 2003</marker>
<rawString>John Bryant. 2003. Constructional analysis. Master’s thesis, UC Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chang</author>
<author>Tiago Maia</author>
</authors>
<title>Learning grammatical constructions.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="24548" citStr="Chang and Maia, 2001" startWordPosition="3855" endWordPosition="3858">algorithm intractable for all but the smallest grammars. Consequently, an open area of research is a mechanism for concentrating effort on the most promising syntactic and semantic combinations using methods of the sort described in (Narayanan and Jurafsky, 1998) and (Bryant, 2003). 6 Applications The constructional analyzer is currently being put to use in two tasks that require the deep semantics that it provides.The first task is that of Simulation-Based Language Understanding (Narayanan, 1997) has already been described. The second is the task of inductive learning of child constructions (Chang and Maia, 2001). 6.1 Child Language Learning The language learning model used by Chang (Chang and Maia, 2001) is a comprehension-based model of language learning built on the following assumptions: •There is significant prior knowledge going into the learning process. agent verb patient path Figure 9: Snapshots of the internal state of the Caused-Motion construction recognizer on the sentence The basketball player threw the ball into the basket. agent verb patient the basketball player threw the ball threw the basketball player verb patient agent path agent verb patient path B agent verb patient path Caused-</context>
</contexts>
<marker>Chang, Maia, 2001</marker>
<rawString>Nancy Chang and Tiago Maia. 2001. Learning grammatical constructions. In Proceedings of the Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chang</author>
<author>Jerome Feldman</author>
<author>Robert Porzel</author>
<author>Keith Sanders</author>
</authors>
<title>Scaling cognitive linguistics:formalisms for language understanding.</title>
<date>2002</date>
<contexts>
<context position="740" citStr="Chang et al., 2002" startWordPosition="100" endWordPosition="103">rnia at Berkeley Berkeley, CA 94720 jbryant@icsi.berkeley.edu Abstract In ScaNaLU 2002, Chang et al presented a scalable natural language formalism called Embodied Construction Grammar (ECG) (Chang et al., 2002). ECG makes deep understanding systems possible because it is a rigorous, unified formalism that incorporates the semantic and pragmatic insights found in cognitive linguistics. The work described in this paper builds on (Chang et al., 2002) because it leverages the ECG formalism to perform deep, scalable construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, how</context>
</contexts>
<marker>Chang, Feldman, Porzel, Sanders, 2002</marker>
<rawString>Nancy Chang, Jerome Feldman, Robert Porzel, and Keith Sanders. 2002. Scaling cognitive linguistics:formalisms for language understanding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Fauconnier</author>
<author>Mark Turner</author>
</authors>
<title>The Way We Think:Conceptual Blending and The Mind’s Hidden Complexities.</title>
<date>2002</date>
<publisher>Basic Books.</publisher>
<contexts>
<context position="1263" citStr="Fauconnier and Turner, 2002" startWordPosition="173" endWordPosition="176">ble construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, however, the importance of ECG lies in its scalability. Within its unification-based framework, constructions, frames and mental spaces are combined compositionally, yielding a network of entwined semantic and pragmatic structures representing the overall interpretation. This makes it possible for ECG to scale to much more complex linguistic data that previous formalisms would allow. The work described in this paper builds on this systembuilding perspective since it is a system that leverages the ECG formalism to perform</context>
</contexts>
<marker>Fauconnier, Turner, 2002</marker>
<rawString>Gilles Fauconnier and Mark Turner. 2002. The Way We Think:Conceptual Blending and The Mind’s Hidden Complexities. Basic Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Fillmore</author>
</authors>
<title>Frame semantics.</title>
<date>1982</date>
<journal>Linguistics Society of Korea.</journal>
<booktitle>In Linguistics in the Morning Calm,</booktitle>
<pages>111--138</pages>
<contexts>
<context position="1214" citStr="Fillmore, 1982" startWordPosition="168" endWordPosition="169">ECG formalism to perform deep, scalable construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, however, the importance of ECG lies in its scalability. Within its unification-based framework, constructions, frames and mental spaces are combined compositionally, yielding a network of entwined semantic and pragmatic structures representing the overall interpretation. This makes it possible for ECG to scale to much more complex linguistic data that previous formalisms would allow. The work described in this paper builds on this systembuilding perspective since it is a s</context>
<context position="4397" citStr="Fillmore, 1982" startWordPosition="613" endWordPosition="615">!s.trajector s.source !landmark.exterior s.goal !landmark.interior Figure 2: The Into schema. construction IntoCxn subcase of Spatial-Relation form: Word selff.orth -“into” meaning: Into Figure 3: The Into lexical construction. schema Container subcase of Image-Schema roles interior : exterior : portal : boundary: schema SPG subcase of Image-Schema roles source : path : goal : schema Trajector-Landmark subcase of Image-Schema roles trajector: landmark: Figure 1: Some image schemas in ECG notation. image schemas (Lakoff, 1987) and executing schemas (Narayanan, 1997) with frame-based knowledge (Fillmore, 1982) to completely specify the meaning of an utterance. Meaning in ECG is represented by schemas. Schemas, much like frames, are schematic, role-based conceptual and semantic structures. But as they are intended to describe an embodied, parameter-based representation of language, the schema formalism is augmented by special semantic operators that make cognitive linguistic insights easier to express. As an initial starting point into the formalism, figure 1 shows three canonical image schemas in ECG notation. Each schema is initially defined by the keyword schema, and after the name, an optional s</context>
<context position="6264" citStr="Fillmore, 1982" startWordPosition="921" endWordPosition="922">ses the TrajectorLandmark schema, and thus inherits the trajector and landmark roles from its parent. The Into schema further constrains the landmark role by constraining it to be of type Container. The Into schema also introduces the new evokes operator which makes the specified type locally accessible via the given alias. In this case, the evoked SPG schema acts as the background frame, capturing into’s notion of motion. This is the primary virtue of the evokes operator. It provides a way to place concepts such as bachelor into the context of their larger background frames, as described by (Fillmore, 1982). After the roles block in the Into schema, comes the optional constraints block. Constraints act as the semantic glue with the$identifying its two argument slots. When a set of slots have been coindexed, a proposed filler to any one of those slots must satisfy the restrictions of all of them. In the Into schema, the locally defined landmark.interior1 role2 is identified with the evoked SPG’s goal role, while the landmark.exterior role is coindexed with the SPG’s source role. These constraints schematically describe how the use of into suggests motion from outside some container to the inside </context>
</contexts>
<marker>Fillmore, 1982</marker>
<rawString>Charles Fillmore. 1982. Frame semantics. In Linguistics in the Morning Calm, pages 111–138. Linguistics Society of Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adele Goldberg</author>
</authors>
<title>Constructions: A Construction Grammar Approach to Argument Structure.</title>
<date>1995</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1159" citStr="Goldberg, 1995" startWordPosition="161" endWordPosition="162">uilds on (Chang et al., 2002) because it leverages the ECG formalism to perform deep, scalable construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, however, the importance of ECG lies in its scalability. Within its unification-based framework, constructions, frames and mental spaces are combined compositionally, yielding a network of entwined semantic and pragmatic structures representing the overall interpretation. This makes it possible for ECG to scale to much more complex linguistic data that previous formalisms would allow. The work described in this paper bu</context>
</contexts>
<marker>Goldberg, 1995</marker>
<rawString>Adele Goldberg. 1995. Constructions: A Construction Grammar Approach to Argument Structure. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard Hinrichs</author>
<author>Sandra Huebler</author>
<author>Valia Kordoni</author>
<author>Frank Mueller</author>
</authors>
<title>Robust chunk parsing for spontaneous speech.</title>
<date>2000</date>
<booktitle>Verbmobil:Foundations of Speech-to-Speech Translation,</booktitle>
<pages>163--182</pages>
<editor>In Wolfgang Wahlster, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="15493" citStr="Hinrichs et al., 2000" startWordPosition="2398" endWordPosition="2401">es and weaknesses of chunking–the weakness being the fact that the parse for the sentence does not attach the prepositional phrase in the lab coat, treating it instead as a sister to the the woman noun group. But it also illustrates the robustness of the system in that while the grammar has no rule for reduced relative, it still correctly labels the syntactic groups. In other words, the incompleteness of the grammar does not cause phrases to be rejected since there is no requirement that a successful parse converge to a complete sentence. Thus such a parser is well-suited for spoken language (Hinrichs et al., 2000), where Hinrichs, et al were able to get 93% “correctness” 9 at finding the various syntactic groups from an error prone spoken language input. Unsurprisingly without any semantics, they were only able to achieve 54% “correctness” when generating the complete parse tree from the chunk analysis. 5 The Constructional Analyzer Because the approach to constructional analysis we describe in this report uses a level-based processing model, it can be considered a relative of such shallow information extraction tools. But instead of doing shallow semantic analysis for the purposes of information extra</context>
</contexts>
<marker>Hinrichs, Huebler, Kordoni, Mueller, 2000</marker>
<rawString>Erhard Hinrichs, Sandra Huebler, Valia Kordoni, and Frank Mueller. 2000. Robust chunk parsing for spontaneous speech. In Wolfgang Wahlster, editor, Verbmobil:Foundations of Speech-to-Speech Translation, pages 163–182. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Women, Fire, and Dangerous Things.</title>
<date>1987</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1189" citStr="Lakoff, 1987" startWordPosition="165" endWordPosition="166">cause it leverages the ECG formalism to perform deep, scalable construction-based parsing and semantic analysis. 1 Introduction As described by (Chang et al., 2002), the semantic and pragmatic insights provided by cognitive linguistics must be incorporated into a language understanding system before deep understanding can take place. Embodied Construction Grammar (ECG) (Chang et al., 2002), (Bergen and Chang, 2002) is a rigorous, formalism incorporating such insight. It provides formal mechanism for describing cognitive primitives like linguistic constructions (Goldberg, 1995), image schemas (Lakoff, 1987), frames (Fillmore, 1982), and mental spaces (Fauconnier and Turner, 2002), as well as cross-domain mappings. From a system-building point of view, however, the importance of ECG lies in its scalability. Within its unification-based framework, constructions, frames and mental spaces are combined compositionally, yielding a network of entwined semantic and pragmatic structures representing the overall interpretation. This makes it possible for ECG to scale to much more complex linguistic data that previous formalisms would allow. The work described in this paper builds on this systembuilding pe</context>
<context position="4313" citStr="Lakoff, 1987" startWordPosition="603" endWordPosition="604">rajector-Landmark evokes s as SPG roles landmark: Container constraints trajector !s.trajector s.source !landmark.exterior s.goal !landmark.interior Figure 2: The Into schema. construction IntoCxn subcase of Spatial-Relation form: Word selff.orth -“into” meaning: Into Figure 3: The Into lexical construction. schema Container subcase of Image-Schema roles interior : exterior : portal : boundary: schema SPG subcase of Image-Schema roles source : path : goal : schema Trajector-Landmark subcase of Image-Schema roles trajector: landmark: Figure 1: Some image schemas in ECG notation. image schemas (Lakoff, 1987) and executing schemas (Narayanan, 1997) with frame-based knowledge (Fillmore, 1982) to completely specify the meaning of an utterance. Meaning in ECG is represented by schemas. Schemas, much like frames, are schematic, role-based conceptual and semantic structures. But as they are intended to describe an embodied, parameter-based representation of language, the schema formalism is augmented by special semantic operators that make cognitive linguistic insights easier to express. As an initial starting point into the formalism, figure 1 shows three canonical image schemas in ECG notation. Each </context>
</contexts>
<marker>Lakoff, 1987</marker>
<rawString>George Lakoff. 1987. Women, Fire, and Dangerous Things. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Bayesian models of sentence processing.</title>
<date>1998</date>
<booktitle>In Proceedings of the Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="24190" citStr="Narayanan and Jurafsky, 1998" startWordPosition="3799" endWordPosition="3802"> each chart entry, and that the number of constituent orderings allowed by a grammar rule isjfor the max ofcconstituents used in any rule. The worst-case runtime would then be O(lrkcj) since there would be kc combinations of unifications for each of thejconstituent orderings associated with a particular recognizer. Clearly any product ofcandjmuch over 2 makes the algorithm intractable for all but the smallest grammars. Consequently, an open area of research is a mechanism for concentrating effort on the most promising syntactic and semantic combinations using methods of the sort described in (Narayanan and Jurafsky, 1998) and (Bryant, 2003). 6 Applications The constructional analyzer is currently being put to use in two tasks that require the deep semantics that it provides.The first task is that of Simulation-Based Language Understanding (Narayanan, 1997) has already been described. The second is the task of inductive learning of child constructions (Chang and Maia, 2001). 6.1 Child Language Learning The language learning model used by Chang (Chang and Maia, 2001) is a comprehension-based model of language learning built on the following assumptions: •There is significant prior knowledge going into the learni</context>
</contexts>
<marker>Narayanan, Jurafsky, 1998</marker>
<rawString>Srini Narayanan and Daniel Jurafsky. 1998. Bayesian models of sentence processing. In Proceedings of the Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Knowledge-Based Action Representations for Metaphor and Aspect.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="4353" citStr="Narayanan, 1997" startWordPosition="608" endWordPosition="609">es landmark: Container constraints trajector !s.trajector s.source !landmark.exterior s.goal !landmark.interior Figure 2: The Into schema. construction IntoCxn subcase of Spatial-Relation form: Word selff.orth -“into” meaning: Into Figure 3: The Into lexical construction. schema Container subcase of Image-Schema roles interior : exterior : portal : boundary: schema SPG subcase of Image-Schema roles source : path : goal : schema Trajector-Landmark subcase of Image-Schema roles trajector: landmark: Figure 1: Some image schemas in ECG notation. image schemas (Lakoff, 1987) and executing schemas (Narayanan, 1997) with frame-based knowledge (Fillmore, 1982) to completely specify the meaning of an utterance. Meaning in ECG is represented by schemas. Schemas, much like frames, are schematic, role-based conceptual and semantic structures. But as they are intended to describe an embodied, parameter-based representation of language, the schema formalism is augmented by special semantic operators that make cognitive linguistic insights easier to express. As an initial starting point into the formalism, figure 1 shows three canonical image schemas in ECG notation. Each schema is initially defined by the keywo</context>
<context position="13863" citStr="Narayanan, 1997" startWordPosition="2132" endWordPosition="2133">designed to interact with the simulator, each constructional analysis will provide the parameters to the simulation, and the analyzer and simulator will interact to understand the utterance. Researchers have integrated the constructional analyzer with a simulation engine, creating a unique and powerful method for language understanding. Such a system would even be able to do “exotic” metaphorical inference with ease, since metaphorical inference is just a special kind of parameterization8. 7With this implementation, ECG does not require any extensions to standard unification algorithms. 8See (Narayanan, 1997) for more information about metaphorical inference. 4 Syntactic Chunking Traditional chunking is a simple parsing algorithm where each syntax rule is transformed into a finite state recognizer. The recognizers are arranged into levels, controlling the order of the reductions. A chunker starts at the lowest level (and hopefully most-certain reductions) which are done by the part of speech tagger. Then it proceeds up the levels toward the less certain reductions. This bottom up approach assumes (obviously incorrectly) that reductions can be made locally and bottom-up without any notion of global</context>
<context position="24429" citStr="Narayanan, 1997" startWordPosition="3837" endWordPosition="3838">ejconstituent orderings associated with a particular recognizer. Clearly any product ofcandjmuch over 2 makes the algorithm intractable for all but the smallest grammars. Consequently, an open area of research is a mechanism for concentrating effort on the most promising syntactic and semantic combinations using methods of the sort described in (Narayanan and Jurafsky, 1998) and (Bryant, 2003). 6 Applications The constructional analyzer is currently being put to use in two tasks that require the deep semantics that it provides.The first task is that of Simulation-Based Language Understanding (Narayanan, 1997) has already been described. The second is the task of inductive learning of child constructions (Chang and Maia, 2001). 6.1 Child Language Learning The language learning model used by Chang (Chang and Maia, 2001) is a comprehension-based model of language learning built on the following assumptions: •There is significant prior knowledge going into the learning process. agent verb patient path Figure 9: Snapshots of the internal state of the Caused-Motion construction recognizer on the sentence The basketball player threw the ball into the basket. agent verb patient the basketball player threw</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>Srini Narayanan. 1997. Knowledge-Based Action Representations for Metaphor and Aspect. Ph.D. thesis, University of California at Berkeley.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>