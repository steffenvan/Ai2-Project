<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000821">
<title confidence="0.974176">
That’s sick dude!:
Automatic identification of word sense change across different timescales
</title>
<author confidence="0.997604">
Sunny Mitra1, Ritwik Mitra1, Martin Riedl2,
Chris Biemann2, Animesh Mukherjee1, Pawan Goyal1
</author>
<affiliation confidence="0.839804666666667">
1Dept. of Computer Science and Engineering,
Indian Institute of Technology Kharagpur, India – 721302
2 FG Language Technology, Computer Science Department, TU Darmstadt, Germany
</affiliation>
<email confidence="0.9246595">
1{ sunnym,ritwikm,animeshm,pawang}@cse.iitkgp.ernet.in
2{riedl,biem}@cs.tu-darmstadt.de
</email>
<sectionHeader confidence="0.997243" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959125">
In this paper, we propose an unsupervised
method to identify noun sense changes
based on rigorous analysis of time-varying
text data available in the form of millions
of digitized books. We construct distribu-
tional thesauri based networks from data
at different time points and cluster each
of them separately to obtain word-centric
sense clusters corresponding to the differ-
ent time points. Subsequently, we com-
pare these sense clusters of two different
time points to find if (i) there is birth of
a new sense or (ii) if an older sense has
got split into more than one sense or (iii)
if a newer sense has been formed from the
joining of older senses or (iv) if a partic-
ular sense has died. We conduct a thor-
ough evaluation of the proposed method-
ology both manually as well as through
comparison with WordNet. Manual eval-
uation indicates that the algorithm could
correctly identify 60.4% birth cases from
a set of 48 randomly picked samples and
57% split/join cases from a set of 21 ran-
domly picked samples. Remarkably, in
44% cases the birth of a novel sense is
attested by WordNet, while in 46% cases
and 43% cases split and join are respec-
tively confirmed by WordNet. Our ap-
proach can be applied for lexicography, as
well as for applications like word sense
disambiguation or semantic search.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995555319149">
Two of the fundamental components of a natu-
ral language communication are word sense dis-
covery (Jones, 1986) and word sense disambigua-
tion (Ide and Veronis, 1998). While discovery
corresponds to acquisition of vocabulary, disam-
biguation forms the basis of understanding. These
two aspects are not only important from the per-
spective of developing computer applications for
natural languages but also form the key compo-
nents of language evolution and change.
Words take different senses in different contexts
while appearing with other words. Context plays
a vital role in disambiguation of word senses as
well as in the interpretation of the actual mean-
ing of words. For instance, the word “bank” has
several distinct interpretations, including that of a
“financial institution” and the “shore of a river.”
Automatic discovery and disambiguation of word
senses from a given text is an important and chal-
lenging problem which has been extensively stud-
ied in the literature (Jones, 1986; Ide and Vero-
nis, 1998; Sch¨utze, 1998; Navigli, 2009). How-
ever, another equally important aspect that has not
been so far well investigated corresponds to one
or more changes that a word might undergo in its
sense. This particular aspect is getting increas-
ingly attainable as more and more time-varying
text data become available in the form of millions
of digitized books (Goldberg and Orwant, 2013)
gathered over the last centuries. As a motivat-
ing example one could consider the word “sick”
– while according to the standard English dictio-
naries the word is normally used to refer to some
sort of illness, a new meaning of “sick” refer-
ring to something that is “crazy” or “cool” is cur-
rently getting popular in the English vernacular.
This change is further interesting because while
traditionally “sick” has been associated to some-
thing negative in general, the current meaning as-
sociates positivity with it. In fact, a rock band
by the name of “Sick Puppies” has been founded
which probably is inspired by the newer sense of
the word sick. The title of this paper has been
motivated by the above observation. Note that
this phenomena of change in word senses has ex-
isted ever since the beginning of human commu-
nication (Bamman and Crane, 2011; Michel et
</bodyText>
<page confidence="0.941915">
1020
</page>
<note confidence="0.842917">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1020–1029,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.996338268292683">
al., 2011; Wijaya and Yeniterzi, 2011; Mihalcea
and Nastase, 2012); however, with the advent of
modern technology and the availability of huge
volumes of time-varying data it now has become
possible to automatically track such changes and,
thereby, help the lexicographers in word sense dis-
covery, and design engineers in enhancing vari-
ous NLP/IR applications (e.g., disambiguation, se-
mantic search etc.) that are naturally sensitive to
change in word senses.
The above motivation forms the basis of the
central objective set in this paper, which is to de-
vise a completely unsupervised approach to track
noun sense changes in large texts available over
multiple timescales. Toward this objective we
make the following contributions: (a) devise a
time-varying graph clustering based sense induc-
tion algorithm, (b) use the time-varying sense
clusters to develop a split-join based approach for
identifying new senses of a word, and (c) evalu-
ate the performance of the algorithms on various
datasets using different suitable approaches along
with a detailed error analysis. Remarkably, com-
parison with the English WordNet indicates that
in 44% cases, as identified by our algorithm, there
has been a birth of a completely novel sense, in
46% cases a new sense has split off from an older
sense and in 43% cases two or more older senses
have merged in to form a new sense.
The remainder of the paper is organized as fol-
lows. In the next section we present a short re-
view of the literature. In Section 3 we briefly
describe the datasets and outline the process of
co-occurrence graph construction. In Section 4
we present an approach based on graph cluster-
ing to identify the time-varying sense clusters and
in Section 5 we present the split-merge based ap-
proach for tracking word sense changes. Evalu-
ation methods are summarized in Section 6. Fi-
nally, conclusions and further research directions
are outlined in Section 7.
</bodyText>
<sectionHeader confidence="0.999902" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999870137931034">
Word sense disambiguation as well as word sense
discovery have both remained key areas of re-
search right from the very early initiatives in nat-
ural language processing research. Ide and Vero-
nis (1998) present a very concise survey of the his-
tory of ideas used in word sense disambiguation;
for a recent survey of the state-of-the-art one can
refer to (Navigli, 2009). Some of the first attempts
to automatic word sense discovery were made by
Karen Sp¨arck Jones (1986); later in lexicography,
it has been extensively used as a pre-processing
step for preparing mono- and multi-lingual dictio-
naries (Kilgarriff and Tugwell, 2001; Kilgarriff,
2004). However, as we have already pointed out
that none of these works consider the temporal as-
pect of the problem.
In contrast, the current study, is inspired by
works on language dynamics and opinion spread-
ing (Mukherjee et al., 2011; Maity et al., 2012;
Loreto et al., 2012) and automatic topic detection
and tracking (Allan et al., 1998). However, our
work differs significantly from those proposed in
the above studies. Opinion formation deals with
the self-organisation and emergence of shared vo-
cabularies whereas our work focuses on how the
different senses of these vocabulary words change
over time and thus become “out-of-vocabulary”.
Topic detection involves detecting the occurrence
of a new event such as a plane crash, a murder, a
jury trial result, or a political scandal in a stream
of news stories from multiple sources and track-
ing is the process of monitoring a stream of news
stories to find those that track (or discuss) the
same event. This is done on shorter timescales
(hours, days), whereas our study focuses on larger
timescales (decades, centuries) and we are inter-
ested in common nouns, verbs and adjectives as
opposed to events that are characterized mostly by
named entities. Other similar works on dynamic
topic modelling can be found in (Blei and Laf-
ferty, 2006; Wang and McCallum, 2006). Google
books n-gram viewer1 is a phrase-usage graphing
tool which charts the yearly count of selected letter
combinations, words, or phrases as found in over
5.2 million digitized books. It only reports fre-
quency of word usage over the years, but does not
give any correlation among them as e.g., in (Heyer
et al., 2009), and does not analyze their senses.
A few approaches suggested by (Bond et al.,
2009; P¨a¨akk¨o and Lind´en, 2012) attempt to aug-
ment WordNet synsets primarily using methods
of annotation. Another recent work by Cook et
al. (2013) attempts to induce word senses and then
identify novel senses by comparing two different
corpora: the “focus corpora” (i.e., a recent version
of the corpora) and the “reference corpora” (older
version of the corpora). However, this method
is limited as it only considers two time points to
</bodyText>
<footnote confidence="0.988696">
1https://books.google.com/ngrams
</footnote>
<page confidence="0.996706">
1021
</page>
<bodyText confidence="0.999952391304348">
identify sense changes as opposed to our approach
which is over a much larger timescale, thereby, ef-
fectively allowing us to track the points of change
and the underlying causes. One of the closest
work to what we present here has been put forward
by (Tahmasebi et al., 2011), where the authors an-
alyze a newspaper corpus containing articles be-
tween 1785 and 1985. The authors mainly report
the frequency patterns of certain words that they
found to be candidates for change; however a de-
tailed cause analysis as to why and how a particu-
lar word underwent a sense change has not been
demonstrated. Further, systematic evaluation of
the results obtained by the authors has not been
provided.
All the above points together motivated us to
undertake the current work where we introduce,
for the first time, a completely unsupervised and
automatic method to identify the change of a word
sense and the cause for the same. Further, we also
present an extensive evaluation of the proposed al-
gorithm in order to test its overall accuracy and
performance.
</bodyText>
<sectionHeader confidence="0.985762" genericHeader="method">
3 Datasets and graph construction
</sectionHeader>
<bodyText confidence="0.999941161290323">
In this section, we outline a brief description
of the dataset used for our experiments and
the graph construction procedure. The primary
source of data have been the millions of digitized
books made available through the Google Book
project (Goldberg and Orwant, 2013). The Google
Book syntactic n-grams dataset provides depen-
dency fragment counts by the years. However, in-
stead of using the plain syntactic n-grams, we use
a far richer representation of the data in the form of
a distributional thesaurus (Lin, 1997; Rychl´y and
Kilgarriff, 2007). In specific, we prepare a distri-
butional thesaurus (DT) for each of the time peri-
ods separately and subsequently construct the re-
quired networks. We briefly outline the procedure
of thesauri construction here referring the reader
to (Riedl and Biemann, 2013) for further details.
In this approach, we first extract each word and a
set of its context features, which are formed by la-
beled and directed dependency parse edges as pro-
vided in the dataset. Following this, we compute
the frequencies of the word, the context and the
words along with their context. Next we calculate
the lexicographer’s mutual information LMI (Kil-
garriff, 2004) between a word and its features and
retain only the top 1000 ranked features for ev-
ery word. Finally, we construct the DT network as
follows: each word is a node in the network and
the edge weight between two nodes is defined as
the number of features that the two corresponding
words share in common.
</bodyText>
<sectionHeader confidence="0.843549" genericHeader="method">
4 Tracking sense changes
</sectionHeader>
<bodyText confidence="0.999989076923077">
The basic idea of our algorithm for tracking sense
changes is as follows. If a word undergoes a
sense change, this can be detected by comparing
its senses obtained from two different time pe-
riods. Since we aim to detect this change au-
tomatically, we require distributional representa-
tions corresponding to word senses for different
time periods. We, therefore, utilize the basic hy-
pothesis of unsupervised sense induction to in-
duce the sense clusters over various time periods
and then compare these clusters to detect sense
change. The basic premises of the ‘unsupervised
sense induction’ are briefly described below.
</bodyText>
<subsectionHeader confidence="0.996393">
4.1 Unsupervised sense induction
</subsectionHeader>
<bodyText confidence="0.998937793103449">
We use the co-occurrence based graph clustering
framework introduced in (Biemann, 2006). The
algorithm proceeds in three basic steps. Firstly,
a co-occurrence graph is created for every target
word found in DT. Next, the neighbourhood/ego
graph is clustered using the Chinese Whispers
(CW) algorithm (see (McAuley and Leskovec,
2012) for similar approaches). The algorithm, in
particular, produces a set of clusters for each target
word by decomposing its open neighborhood. We
hypothesize that each different cluster corresponds
to a particular sense of the target word. For a de-
tailed description, the reader is referred to (Bie-
mann, 2011).
If a word undergoes sense change, this can be
detected by comparing the sense clusters obtained
from two different time periods by the algorithm
outlined above. For this purpose, we use statis-
tics from the DT corresponding to two different
time intervals, say tvi and tvj. We then run the
sense induction algorithm over these two different
datasets. Now, for a given word w that appears
in both the datasets, we get two different set of
clusters, say Ci and Cj. Without loss of gener-
ality, let us assume that our algorithm detects m
sense clusters for the word w in tvi and n sense
clusters in tvj. Let Ci = {si1, si2, . . . , sinn} and
Cj = {sj1, sj2, ... , sjn}, where skz denotes zth
sense cluster for word w during time interval tvk.
</bodyText>
<page confidence="0.979774">
1022
</page>
<bodyText confidence="0.999946">
We next describe our algorithm for detecting sense
change from these sets of sense clusters.
</bodyText>
<subsectionHeader confidence="0.958392">
4.2 Split, join, birth and death
</subsectionHeader>
<bodyText confidence="0.997479">
We hypothesize that word w can undergo sense
change from one time interval (tvi) to another
(tvj) as per one of the following scenarios:
Split A sense cluster siz in tvi splits into two (or
more) sense clusters, sjp, and sjp2 in tvj
Join Two sense clusters siz, and siz2 in tvi join to
make a single cluster sjp in tvj
Birth A new sense cluster sjp appears in tvj,
which was absent in tvi
Death A sense cluster siz in tvi dies out and does
not appear in tvj
To detect split, join, birth or death, we build an
(m+1)x(n+1) matrix I to capture the intersec-
tion between sense clusters of two different time
periods. The first m rows and n columns corre-
spond to the sense clusters in tvi and tvj espec-
tively. We append an additional row and column to
capture the fraction of words, which did not show
up in any of the sense clusters in another time in-
terval. So, an element Ikl of the matrix
</bodyText>
<listItem confidence="0.937249">
• 1 &lt; k &lt; m, 1 &lt; l &lt; n: denotes the frac-
tion of words in a newer sense cluster sjl,
that were also present in an older sense clus-
ter sik.
• k = m + 1,1 &lt; l &lt; n: denotes the fraction
of words in the sense cluster sjl, that were not
present in any of the m clusters in tvi.
• 1 &lt; k &lt; m, l = n + 1: denotes the fraction
of words in the sense cluster sik, that did not
show up in any of the n clusters in tvj.
</listItem>
<bodyText confidence="0.998933571428571">
Thus, the matrix I captures all the four possible
scenarios for sense change. Since we can not
expect a perfect split, birth etc., we used certain
threshold values to detect if a candidate word is
undergoing sense change via one of these four
cases. In Figure 1, as an example, we illustrate
the birth of a new sense for the word ‘compiler’.
</bodyText>
<subsectionHeader confidence="0.994059">
4.3 Multi-stage filtering
</subsectionHeader>
<bodyText confidence="0.999895217391304">
To make sure that the candidate words obtained
via our algorithm are meaningful, we applied
multi-stage filtering to prune the candidate word
list. The following criterion were used for the fil-
tering:
Stage 1 We utilize the fact that the CW algorithm
is non-deterministic in nature. We apply CW
three times over the source and target time inter-
vals. We obtain the candidate word lists using our
algorithm for the three runs, then take the inter-
section to output those words, which came up in
all the three runs.
Stage 2 From the above list, we retain only those
candidate words, which have a part-of-speech tag
‘NN’ or ‘NNS’, as we focus on nouns for this
work.
Stage 3 We sort the candidate list obtained in
Stage 2 as per their occurrence in the first time
period. Then, we remove the top 20% and the
bottom 20% words from this list. Therefore, we
consider the torso of the frequency distribution
which is the most informative part for this type
of an analysis.
</bodyText>
<sectionHeader confidence="0.999647" genericHeader="method">
5 Experimental framework
</sectionHeader>
<bodyText confidence="0.999986909090909">
For our experiments, we utilized DTs created for
8 different time periods: 1520-1908, 1909-1953,
1954-1972, 1973-1986, 1987-1995, 1996-2001,
2002-2005 and 2006-2008 (Biedl et al., 2014).
The time periods were set such that the amount
of data in each time period is roughly the same.
We will also use T1 to T8 to denote these time pe-
riods. The parameters for CW clustering were set
as follows. The size of the neighbourhood (N)
to be clustered was set to 200. The parameter n
regulating the edge density in this neighbourhood
was set to 200 as well. The parameter a was set to
lin, which corresponds to favouring smaller clus-
ters by hub downweighing2. The threshold values
used to detect the sense changes were as follows.
For birth, at least 80% words of the target cluster
should be novel. For split, each split cluster should
have at least 30% words of the source cluster and
the total intersection of all the split clusters should
be &gt; 80%. The same parameters were used for the
join and death case with the interchange of source
and target clusters.
</bodyText>
<subsectionHeader confidence="0.998642">
5.1 Signals of sense change
</subsectionHeader>
<bodyText confidence="0.989185">
Making comparisons between all the pairs of time
periods gave us 28 candidate words lists. For
</bodyText>
<footnote confidence="0.9983575">
2data available at http://sf.net/p/jobimtext/
wiki/LREC2014_Google_DT/
</footnote>
<page confidence="0.924457">
1023
</page>
<figureCaption confidence="0.999943">
Figure 1: Example of the birth of a new sense for the word ‘compiler’
</figureCaption>
<bodyText confidence="0.9986667">
each of these comparison, we applied the multi-
stage filtering to obtain the pruned list of candidate
words. Table 1 provides some statistics about the
number of candidate words obtained correspond-
ing to the birth case. The rows correspond to the
source time-period and the columns correspond to
the target time periods. An element of the table
shows the number of candidate words obtained
by comparing the corresponding source and target
time periods.
</bodyText>
<tableCaption confidence="0.8251925">
Table 1: Number of candidate birth senses be-
tween all time periods
</tableCaption>
<table confidence="0.998307625">
T2 T3 T4 T5 T6 T7 T8
T1 2498 3319 3901 4220 4238 4092 3578
T2 1451 2330 2789 2834 2789 2468
T3 917 1460 1660 1827 1815
T4 517 769 1099 1416
T5 401 818 1243
T6 682 1107
T7 609
</table>
<bodyText confidence="0.999826066666667">
The table clearly shows a trend. For most of
the cases, the number of candidate birth senses
tends to increase as we go from left to right. Sim-
ilarly, this number decreases as we go down in
the table. This is quite intuitive since going from
left to right corresponds to increasing the gap be-
tween two time periods while going down cor-
responds to decreasing this gap. As the gap in-
creases (decreases), one would expect more (less)
new senses coming in. Even while moving diago-
nally, the candidate words tend to decrease as we
move downwards. This corresponds to the fact
that the number of years in the time periods de-
creases as we move downwards, and therefore, the
gap also decreases.
</bodyText>
<subsectionHeader confidence="0.999562">
5.2 Stability analysis &amp; sense change location
</subsectionHeader>
<bodyText confidence="0.999979161290323">
Formally, we consider a sense change from tvz
to tvj stable if it was also detected while com-
paring tvz with the following time periods tvks.
This number of subsequent time periods, where
the same sense change is detected, helps us to de-
termine the age of a new sense. Similarly, for a
candidate sense change from tvz to tvj, we say that
the location of the sense change is tvj if and only
if that sense change does not get detected by com-
paring tvz with any time interval tvk, intermediate
between tvz and tvj.
Table 1 gives a lot of candidate words for sense
change. However, not all the candidate words
were stable. Thus, it was important to prune these
results using stability analysis. Also, it is to be
noted that these results do not pin-point to the ex-
act time-period, when the sense change might have
taken place. For instance, among the 4238 candi-
date birth sense detected by comparing T1 and T6,
many of these new senses might have come up in
between T2 to T5 as well. We prune these lists fur-
ther based on the stability of the sense, as well as
to locate the approximate time interval, in which
the sense change might have occurred.
Table 2 shows the number of stable (at least
twice) senses as well as the number of stable
sense changes located in that particular time pe-
riod. While this decreases recall, we found this to
be beneficial for the accuracy of the method.
Once we were able to locate the senses as well
as to find the age of the senses, we attempted to
</bodyText>
<page confidence="0.999128">
1024
</page>
<tableCaption confidence="0.993084">
Table 2: Number of candidate birth senses ob-
tained for different time periods
</tableCaption>
<table confidence="0.995805">
T2 T3 T4 T5 T6 T7
T1 2498 3319 3901 4220 4238 4092
stable 537 989 1368 1627 1540 1299
located 537 754 772 686 420 300
T2 1451 2330 2789 2834 2789
stable 343 718 938 963 810
located 343 561 517 357 227
</table>
<bodyText confidence="0.85360825">
select some representative words and plotted them
on a timeline as per the birth period and their age
in Figure 2. The source time period here is 1909-
1953.
</bodyText>
<sectionHeader confidence="0.999205" genericHeader="evaluation">
6 Evaluation framework
</sectionHeader>
<bodyText confidence="0.999973583333333">
During evaluation, we considered the clusters ob-
tained using the 1909-1953 time-slice as our refer-
ence and attempted to track sense change by com-
paring these with the clusters obtained for 2002-
2005. The sense change detected was categorized
as to whether it was a new sense (birth), a single
sense got split into two or more senses (split) or
two or more senses got merged (join) or a particu-
lar sense died (death). We present a few instances
of the resulting clusters in the paper and refer the
reader to the supplementary material3 for the rest
of the results.
</bodyText>
<subsectionHeader confidence="0.998019">
6.1 Manual evaluation
</subsectionHeader>
<bodyText confidence="0.999347166666667">
The algorithm detected a lot of candidate words
for the cases of birth, split/join as well as death.
Since it was difficult to go through all the candi-
date sense changes for all the comparisons man-
ually, we decided to randomly select some can-
didate words, which were flagged by our algo-
rithm as undergoing sense change, while compar-
ing 1909-1953 and 2002-2005 DT. We selected 48
random samples of candidate words for birth cases
and 21 random samples for split/join cases. One
of the authors annotated each of the birth cases
identifying whether or not the algorithm signalled
a true sense change while another author did the
same task for the split/join cases. The accuracy as
per manual evaluation was found to be 60.4% for
the birth cases and 57% for the split/join cases.
Table 3 shows the evaluation results for a few
candidate words, flagged due to birth. Columns
</bodyText>
<footnote confidence="0.972009">
3http://cse.iitkgp.ac.in/resgrp/cnerg/
acl2014_wordsense/
</footnote>
<bodyText confidence="0.999766304347826">
correspond to the candidate words, words obtained
in the cluster of each candidate word (we will use
the term ‘birth cluster’ for these words, hence-
forth), which indicated a new sense, the results
of manual evaluation as well as the possible sense
this birth cluster denotes.
Table 4 shows the corresponding evaluation re-
sults for a few candidate words, flagged due to
split or join.
A further analysis of the words marked due
to birth in the random samples indicates that
there are 22 technology-related words, 2 slangs,
3 economics related words and 2 general words.
For the split-join case we found that there are
3 technology-related words while the rest of the
words are general. Therefore one of the key ob-
servations is that most of the technology related
words (where the neighborhood is completely
new) could be extracted from our birth results. In
contrast, for the split-join instances most of the re-
sults are from the general category since the neigh-
borhood did not change much here; it either got
split or merged from what it was earlier.
</bodyText>
<subsectionHeader confidence="0.994838">
6.2 Automated evaluation with WordNet
</subsectionHeader>
<bodyText confidence="0.997679961538462">
In addition to manual evaluation, we also per-
formed automated evaluation for the candidate
words. We chose WordNet for automated evalua-
tion because not only does it have a wide coverage
of word senses but also it is being maintained and
updated regularly to incorporate new senses. We
did this evaluation for the candidate birth, join and
split sense clusters obtained by comparing 1909-
1953 time period with respect to 2002-2005. For
our evaluation, we developed an aligner to align
the word clusters obtained with WordNet senses.
The aligner constructs a WordNet dictionary for
the purpose of synset alignment. The CW clus-
ter is then aligned to WordNet synsets by compar-
ing the clusters with WordNet graph and the synset
with the maximum alignment score is returned as
the output. In summary, the aligner tool takes as
input the CW cluster and returns a WordNet synset
id that corresponds to the cluster words. The eval-
uation settings were as follows:
Birth: For a candidate word flagged as birth, we
first find out the set of all WordNet synset ids for
its CW clusters in the source time period (1909-
1953 in this case). Let Sinit denote the union of
these synset ids. We then find WordNet synset id
for its birth-cluster, say snew. Then, if snew ∈/
</bodyText>
<page confidence="0.995947">
1025
</page>
<figureCaption confidence="0.997326">
Figure 2: Examples of birth senses placed on a timeline as per their location as well as age
</figureCaption>
<tableCaption confidence="0.9707845">
Table 3: Manual evaluation for seven randomly chosen candidate birth clusters between time periods
1909-1953 and 2002-2005
</tableCaption>
<table confidence="0.914384916666667">
Sl Candidate birth cluster Evaluation judgement,
No. Word comments
1 implant gel, fibre, coatings, cement, materials, metal, filler No, New set of words but
silicone, composite, titanium, polymer, coating similar sense already existed
2 passwords browsers, server, functionality, clients, workstation Yes, New sense related
printers, software, protocols, hosts, settings, utilities to ‘a computer sense’
3 giants multinationals, conglomerates, manufacturers Yes, New sense as ‘an
corporations, competitors, enterprises, companies organization with very great
businesses, brands, firms size or force’
4 donation transplantation, donation, fertilization, transfusions Yes, The new usage of donation
transplant, transplants, insemination, donors, donor ... associated with body organs etc.
5 novice negro, fellow, emigre, yankee, realist, quaker, teen No, this looks like a false
</table>
<bodyText confidence="0.961944111111111">
male, zen, lady, admiring, celebrity, thai, millionaire ... positive
6 partitions server, printers, workstation, platforms, arrays Yes, New usage related to
modules, computers, workstations, kernel ... the ‘computing’ domain
7 yankees athletics, cubs, tigers, sox, bears, braves, pirates Yes, related to the ‘New
cardinals, dodgers, yankees, giants, cardinals ... York Yankees’ team
Sinit, it implies that this is a new sense that was
not present in the source clusters and we call it a
‘success’ as per WordNet.
Join: For the join case, we find WordNet synset
ids s1 and s2 for the clusters obtained in the
source time period and snew for the join cluster
in the target time period. If s1 =� s2 and snew is
either s1 or s2, we call it a ‘success’.
Split: For the split case, we find WordNet synset
id sold for the source cluster and synset ids s1
and s2 for the target split clusters. If s1 =� s2
and either s1, or s2 retains the id sold, we call it a
‘success’.
</bodyText>
<tableCaption confidence="0.7874055">
Table 5 show the results of WordNet based eval-
uation. In case of birth we observe a success of
Table 5: Results of the automatic evaluation using
WordNet
</tableCaption>
<table confidence="0.99731625">
Category No. of Candidate Words Success Cases
Birth 810 44%
Split 24 46%
Join 28 43%
</table>
<bodyText confidence="0.999414">
44% while for split and join we observe a success
of 46% and 43% respectively. We then manually
verified some of the words that were deemed as
successes, as well as investigated WordNet sense
they were mapped to. Table 6 shows some of the
words for which the evaluation detected success
along with WordNet senses. Clearly, the cluster
words correspond to a newer sense for these words
</bodyText>
<page confidence="0.998333">
1026
</page>
<tableCaption confidence="0.950885">
Table 4: Manual evaluation for five randomly chosen candidate split/join clusters between time periods
1909-1953 and 2002-2005
</tableCaption>
<table confidence="0.9787748">
Sl Candidate Source and target clusters
No. Word
1 intonation S: whisper, glance, idioms, gesture, chant, sob, inflection, diction, sneer, rhythm, accents ...
(split) T1: nod, tone, grimace, finality, gestures, twang, shake, shrug, irony, scowl, twinkle ...
T2: accents, phrase, rhythm, style, phonology, diction, utterance, cadence, harmonies ...
Yes, T1 corresponds to intonation in normal conversations while T2 corresponds to the use of accents in
formal and research literature
2 diagonal S: coast, edge, shoreline, coastline, border, surface, crease, edges, slope, sides, seaboard ...
(split) T1: circumference, center, slant, vertex, grid, clavicle, margin, perimeter, row, boundary..
T2: border, coast, seaboard, seashore, shoreline, waterfront, shore, shores, coastline, coasts
Yes, the split T1 is based on mathematics where as T2 is based on geography
3 mantra S1: sutra, stanza, chanting, chants, commandments, monologue, litany, verse, verses ...
(join) S2: praise, imprecation, benediction, praises, curse, salutation, benedictions, eulogy ...
T: blessings, spell, curses, spells, rosary, prayers, blessing, prayer, benediction ...
Yes, the two seemingly distinct senses of mantra - a contextual usage for chanting and prayer (S1)
and another usage in its effect - salutations, benedictions (S2) have now merged in T.
4 continuum S: circumference, ordinate, abscissa, coasts, axis, path, perimeter, arc, plane axis ...
(split) T1: roadsides, corridors, frontier, trajectories, coast, shore, trail, escarpment, highways ...
T2: arc, ellipse, meridians, equator, axis, axis, plane, abscissa, ordinate, axis, meridian ....
Yes, the split S1 denotes the usage of ‘continuum’ with physical objects while the
the split S2 corresponds to its usages in mathematics domain.
5 headmaster S1: master, overseer, councillor, chancellor, tutors, captain, general, principal ...
(join) S2: mentor, confessor, tutor, founder, rector, vicar, graduate, counselor, lawyer...
T: chaplain, commander, surveyor, coordinator, consultant, lecturer, inspector...
No, it seems a false positive
</table>
<bodyText confidence="0.886572">
and the mapped WordNet synset matches the birth
cluster to a very high degree.
</bodyText>
<subsectionHeader confidence="0.999834">
6.3 Evaluation with a slang list
</subsectionHeader>
<bodyText confidence="0.99996495">
Slangs are words and phrases that are regarded as
very informal, and are typically restricted to a par-
ticular context. New slang words come up every
now and then, and this plays an integral part in the
phenomena of sense change. We therefore decided
to perform an evaluation as to how many slang
words were being detected by our candidate birth
clusters. We used a list of slangs available from
the slangcity website4. We collected slangs for the
years 2002-2005 and found the intersection with
our candidate birth words. Note that the website
had a large number of multi-word expressions that
we did not consider in our study. Further, some
of the words appeared as either erroneous or very
transient (not existing more than a few months) en-
tires, which had to be removed from the list. All
these removal left us with a very little space for
comparison; however, despite this we found 25
slangs from the website that were present in our
birth results, e.g. ‘bum’, ‘sissy’, ‘thug’, ‘dude’ etc.
</bodyText>
<footnote confidence="0.996395">
4http://slangcity.com/email_archive/
index_2003.htm
</footnote>
<subsectionHeader confidence="0.997685">
6.4 Evaluation of candidate death clusters
</subsectionHeader>
<bodyText confidence="0.999994375">
Much of our evaluation was focussed on the birth
sense clusters, mainly because these are more in-
teresting from a lexicographic perspective. Addi-
tionally, the main theme of this work was to de-
tect new senses for a given word. To detect a
true death of a sense, persistence analysis was re-
quired, that is, to verify if the sense was persist-
ing earlier and vanished after a certain time period.
While such an analysis goes beyond the scope of
this paper, we selected some interesting candidate
“death” senses. Table 7 shows some of these inter-
esting candidate words, their death cluster along
with the possible vanished meaning, identified by
the authors. While these words are still used in a
related sense, the original meaning does not exist
in the modern usage.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999868571428571">
In this paper, we presented a completely unsu-
pervised method to detect word sense changes
by analyzing millions of digitized books archived
spanning several centuries. In particular, we con-
structed DT networks over eight different time
windows, clustered these networks and compared
these clusters to identify the emergence of novel
</bodyText>
<page confidence="0.998301">
1027
</page>
<tableCaption confidence="0.99825">
Table 6: Example of randomly chosen candidate birth clusters mapped to WordNet
</tableCaption>
<table confidence="0.986497125">
Sl Candidate birth cluster Synset Id,
No. Word WordNet sense
1 macro code, query, handler, program, procedure, subroutine 6582403, a set sequence of steps,
module, script part of larger computer program
2 caller browser, compiler, sender, routers, workstation, cpu 4175147, a computer that
host, modem, router, server provides client stations with access to files
3 searching coding, processing, learning, computing, scheduling 1144355, programming: setting an
planning, retrieval, routing, networking, navigation order and time for planned events
4 hooker bitch, whore, stripper, woman slut, prostitute 10485440, a woman who
girl, dancer ... engages in sexual intercourse for money
5 drones helicopters, fighters, rockets, flights, planes 4264914, a craft capable of
vehicles, bomber, missions, submarines ... traveling in outer space
6 amps inverters, capacitor, oscillators, switches, mixer 2955247, electrical device characterized
transformer, windings, capacitors, circuits ... by its capacity to store an electric charge
7 compilers interfaces, algorithms, programming, software 6566077, written programs pertaining
modules, libraries, routines, tools, utilities ... to the operation of a computer system
</table>
<tableCaption confidence="0.96616">
Table 7: Some representative examples for candidate death sense clusters
</tableCaption>
<table confidence="0.7459998">
Sl Candidate death cluster Vanished meaning
No. Word
1 slop jeans, velveteen, tweed, woollen, rubber, sealskin, wear clothes and bedding supplied to
oilskin, sheepskin, velvet, calico, deerskin, goatskin, cloth ... sailors by the navy
2 blackmail subsidy, rent, presents, tributes, money, fine, bribes Origin: denoting protection money
dues, tolls, contributions, contribution, customs, duties ... levied by Scottish chiefs
3 repertory dictionary, study, compendium, bibliography, lore, directory Origin: denoting an index
catalogues, science, catalog, annals, digest, literature ... or catalog: from late Latin repertorium
4 phrasing contour, outline, construction, handling, grouping, arrangement in the sense ‘style or manner of
structure, modelling, selection, form ... expression’: via late Latin Greek phrasis
</table>
<bodyText confidence="0.999960302325582">
senses. The performance of our method has been
evaluated manually as well as by comparison with
WordNet and a list of slang words. Through man-
ual evaluation we found that the algorithm could
correctly identify 60.4% birth cases from a set of
48 random samples and 57% split/join cases from
a set of 21 randomly picked samples. Quite strik-
ingly, we observe that (i) in 44% cases the birth of
a novel sense is attested by WordNet, (ii) in 46%
cases the split of an older sense is signalled on
comparison with WordNet and (iii) in 43% cases
the join of two senses is attested by WordNet.
These results might have strong lexicographic im-
plications – even if one goes by very moderate es-
timates almost half of the words would be candi-
date entries in WordNet if they were not already
part of it. This method can be extremely useful
in the construction of lexico-semantic networks
for low-resource languages, as well as for keeping
lexico-semantic resources up to date in general.
Future research directions based on this work
are manifold. On one hand, our method can be
used by lexicographers in designing new dictio-
naries where candidate new senses can be semi-
automatically detected and included, thus greatly
reducing the otherwise required manual effort.
On the other hand, this method can be directly
used for various NLP/IR applications like seman-
tic search, automatic word sense discovery as well
as disambiguation. For semantic search, taking
into account the newer senses of the word can in-
crease the relevance of the query result. Similarly,
a disambiguation engine informed with the newer
senses of a word can increase the efficiency of
disambiguation, and recognize senses uncovered
by the inventory that would otherwise have to be
wrongly assigned to covered senses. In addition,
this method can be also extended to the ‘NNP’
part-of-speech (i.e., named entities) to identify
changes in role of a person/place. Furthermore,
it would be interesting to apply this method to lan-
guages other than English and to try to align new
senses of cognates across languages.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998216428571429">
AM would like to thank DAAD for supporting the
faculty exchange programme to TU Darmstadt.
PG would like to thank Google India Private Ltd.
for extending travel support to attend the confer-
ence. MR and CB have been supported by an IBM
SUR award and by LOEWE as part of the research
center Digital Humanities.
</bodyText>
<page confidence="0.981233">
1028
</page>
<bodyText confidence="0.988331">
S. K. Maity, T. M. Venkat and A. Mukherjee. 2012.
Opinion formation in time-varying social networks:
The case of the naming game. Phys. Rev. E, 86,
036110.
</bodyText>
<sectionHeader confidence="0.870616" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.624567333333333">
J. Allan, R. Papka and V. Lavrenko. 1998. On-line
new event detection and tracking. In proceedings of
SIGIR, 37–45, Melbourne, Australia.
</bodyText>
<reference confidence="0.999949969072165">
D. Bamman and G. Crane. 2011. Measuring Historical
Word Sense Variation. In proceedings of JCDL, 1–
10, New York, NY, USA.
C. Biemann. 2006. Chinese whispers - an efficient
graph clustering algorithm and its application to nat-
ural language processing problems. In proceedings
of TextGraphs, 73–80, New York, USA.
C. Biemann. 2011. Structure Discovery in Natural
Language. Springer Heidelberg Dordrecht London
New York. ISBN 978-3-642-25922-7.
D. Blei and J. Lafferty. 2006. Dynamic topic mod-
els. In proceedings of ICML, 113–120, Pittsburgh,
Pennsylvania.
F. Bond, H. Isahara, S. Fujita, K. Uchimoto, T. Kurib-
ayash and K. Kanzaki. 2009. Enhancing the
Japanese WordNet. In proceedings of workshop on
Asian Language Resources, 1–8, Suntec, Singapore.
P. Cook, J. H. Lau, M. Rundell, D. McCarthy, T. Bald-
win. 2013. A lexicographic appraisal of an auto-
matic approach for detecting new word senses. In
proceedings of eLex, 49-65, Tallinn, Estonia.
Y. Goldberg and J. Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large cor-
pus of English books. In proceedings of the Joint
Conference on Lexical and Computational Seman-
tics (*SEM), 241–247, Atlanta, GA, USA.
G. Heyer, F. Holz and S. Teresniak. 2009. Change of
topics over time – tracking topics by their change of
meaning. In proceedings of KDIR, Madeira, Portu-
gal.
N. Ide and J. Veronis. 1998. Introduction to the special
issue on word sense disambiguation: The state of the
art. Computational Linguistics, 24(1):1–40.
A. Kilgarriff, P. Rychly, P. Smrz, and D. Tugwell.
2004. The sketch engine. In Proceedings of EU-
RALEX, 105–116, Lorient, France.
A. Kilgarriff and D. Tugwell. 2001. Word sketch: Ex-
traction and display of significant collocations for
lexicography. In proceedings of COLLOCATION:
Computational Extraction, Analysis and Exploita-
tion, 32–38, Toulouse, France.
D. Lin. 1997. Using syntactic dependency as local
context to resolve word sense ambiguity. In pro-
ceedings of ACL/EACL, 64–71, Madrid, Spain.
V. Loreto, A. Mukherjee and F. Tria. 2012. On the ori-
gin of the hierarchy of color names. PNAS, 109(18),
6819–6824.
J. McAuley and J. Leskovec. 2012. Learning to dis-
cover social circles in ego networks. In proceedings
of NIPS, 548–556, Nevada, USA.
J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K.
Gray, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig,
J. Orwant, S. Pinker, M. A. Nowak and E. L. Aiden.
2011. Quantitative analysis of culture using millions
of digitized books. Science, 331(6014):176–182.
R. Mihalcea and V. Nastase. 2012. Word epoch disam-
biguation: finding how words change over time. In
proceedings of ACL, 259–263, Jeju Island, Korea.
A. Mukherjee, F. Tria, A. Baronchelli, A. Puglisi and V.
Loreto. 2011. Aging in language dynamics. PLoS
ONE, 6(2): e16677.
R. Navigli. 2009. Word sense disambiguation: a sur-
vey. ACM Computing Surveys, 41(2):1–69.
P. P¨a¨akk¨o and K. Lind´en. 2012. Finding a location
for a new word in WordNet. In proceedings of the
Global WordNet Conference, Matsue, Japan.
M. Riedl and C. Biemann. 2013. Scaling to large3
data: An efficient and effective method to compute
distributional thesauri. In proceedings of EMNLP,
884–890, Seattle, Washington, USA.
M. Riedl, R. Steuer and C. Biemann. 2014. Distributed
distributional similarities of Google books over the
centuries. In proceedings of LREC, Reykjavik, Ice-
land.
P. Rychl´y and A. Kilgarriff. 2007. An efficient al-
gorithm for building a distributional thesaurus (and
other sketch engine developments). In proceedings
of ACL, poster and demo sessions, 41–44, Prague,
Czech Republic.
H. Sch¨utze. 1998. Automatic word sense discrimina-
tion. Computational Linguistics, 24(1):97–123.
K. Sp¨ark-Jones. 1986. Synonymy and Semantic Clas-
sification. Edinburgh University Press. ISBN 0-
85224-517-3.
N. Tahmasebi, T. Risse and S. Dietze. 2011. Towards
automatic language evolution tracking: a study on
word sense tracking. In proceedings of EvoDyn, vol.
784, Bonn, Germany.
X. Wang and A. McCallum. 2006. Topics over time:
a non-Markov continuous-time model of topical
trends. In proceedings of KDD, 424–433, Philadel-
phia, PA, USA.
D. Wijaya and R. Yeniterzi. 2011. Understanding se-
mantic change of words over centuries. In proceed-
ings of the workshop on Detecting and Exploiting
Cultural Diversity on the Social Web, 35–40, Glas-
gow, Scotland, UK.
</reference>
<page confidence="0.99623">
1029
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.764568">
<title confidence="0.980086">That’s sick dude!: Automatic identification of word sense change across different timescales</title>
<author confidence="0.988151">Ritwik Martin Animesh Pawan</author>
<affiliation confidence="0.998405">of Computer Science and Indian Institute of Technology Kharagpur, India –</affiliation>
<address confidence="0.83081">2FG Language Technology, Computer Science Department, TU Darmstadt,</address>
<abstract confidence="0.999496">In this paper, we propose an unsupervised method to identify noun sense changes based on rigorous analysis of time-varying text data available in the form of millions of digitized books. We construct distributional thesauri based networks from data at different time points and cluster each of them separately to obtain word-centric sense clusters corresponding to the different time points. Subsequently, we compare these sense clusters of two different time points to find if (i) there is birth of a new sense or (ii) if an older sense has got split into more than one sense or (iii) if a newer sense has been formed from the joining of older senses or (iv) if a particular sense has died. We conduct a thorough evaluation of the proposed methodology both manually as well as through comparison with WordNet. Manual evaluation indicates that the algorithm could correctly identify 60.4% birth cases from a set of 48 randomly picked samples and 57% split/join cases from a set of 21 randomly picked samples. Remarkably, in 44% cases the birth of a novel sense is attested by WordNet, while in 46% cases and 43% cases split and join are respectively confirmed by WordNet. Our approach can be applied for lexicography, as well as for applications like word sense disambiguation or semantic search.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bamman</author>
<author>G Crane</author>
</authors>
<title>Measuring Historical Word Sense Variation.</title>
<date>2011</date>
<booktitle>In proceedings of JCDL, 1– 10,</booktitle>
<location>New York, NY, USA.</location>
<contexts>
<context position="4006" citStr="Bamman and Crane, 2011" startWordPosition="646" endWordPosition="649"> “sick” referring to something that is “crazy” or “cool” is currently getting popular in the English vernacular. This change is further interesting because while traditionally “sick” has been associated to something negative in general, the current meaning associates positivity with it. In fact, a rock band by the name of “Sick Puppies” has been founded which probably is inspired by the newer sense of the word sick. The title of this paper has been motivated by the above observation. Note that this phenomena of change in word senses has existed ever since the beginning of human communication (Bamman and Crane, 2011; Michel et 1020 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1020–1029, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics al., 2011; Wijaya and Yeniterzi, 2011; Mihalcea and Nastase, 2012); however, with the advent of modern technology and the availability of huge volumes of time-varying data it now has become possible to automatically track such changes and, thereby, help the lexicographers in word sense discovery, and design engineers in enhancing various NLP/IR applications (e.g., disambiguation, se</context>
</contexts>
<marker>Bamman, Crane, 2011</marker>
<rawString>D. Bamman and G. Crane. 2011. Measuring Historical Word Sense Variation. In proceedings of JCDL, 1– 10, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Biemann</author>
</authors>
<title>Chinese whispers - an efficient graph clustering algorithm and its application to natural language processing problems.</title>
<date>2006</date>
<booktitle>In proceedings of TextGraphs,</booktitle>
<pages>73--80</pages>
<location>New York, USA.</location>
<contexts>
<context position="12337" citStr="Biemann, 2006" startWordPosition="2011" endWordPosition="2012">ected by comparing its senses obtained from two different time periods. Since we aim to detect this change automatically, we require distributional representations corresponding to word senses for different time periods. We, therefore, utilize the basic hypothesis of unsupervised sense induction to induce the sense clusters over various time periods and then compare these clusters to detect sense change. The basic premises of the ‘unsupervised sense induction’ are briefly described below. 4.1 Unsupervised sense induction We use the co-occurrence based graph clustering framework introduced in (Biemann, 2006). The algorithm proceeds in three basic steps. Firstly, a co-occurrence graph is created for every target word found in DT. Next, the neighbourhood/ego graph is clustered using the Chinese Whispers (CW) algorithm (see (McAuley and Leskovec, 2012) for similar approaches). The algorithm, in particular, produces a set of clusters for each target word by decomposing its open neighborhood. We hypothesize that each different cluster corresponds to a particular sense of the target word. For a detailed description, the reader is referred to (Biemann, 2011). If a word undergoes sense change, this can b</context>
</contexts>
<marker>Biemann, 2006</marker>
<rawString>C. Biemann. 2006. Chinese whispers - an efficient graph clustering algorithm and its application to natural language processing problems. In proceedings of TextGraphs, 73–80, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Biemann</author>
</authors>
<title>Structure Discovery in Natural Language.</title>
<date>2011</date>
<pages>978--3</pages>
<publisher>Springer</publisher>
<location>Heidelberg Dordrecht London New York. ISBN</location>
<contexts>
<context position="12891" citStr="Biemann, 2011" startWordPosition="2096" endWordPosition="2098">sed graph clustering framework introduced in (Biemann, 2006). The algorithm proceeds in three basic steps. Firstly, a co-occurrence graph is created for every target word found in DT. Next, the neighbourhood/ego graph is clustered using the Chinese Whispers (CW) algorithm (see (McAuley and Leskovec, 2012) for similar approaches). The algorithm, in particular, produces a set of clusters for each target word by decomposing its open neighborhood. We hypothesize that each different cluster corresponds to a particular sense of the target word. For a detailed description, the reader is referred to (Biemann, 2011). If a word undergoes sense change, this can be detected by comparing the sense clusters obtained from two different time periods by the algorithm outlined above. For this purpose, we use statistics from the DT corresponding to two different time intervals, say tvi and tvj. We then run the sense induction algorithm over these two different datasets. Now, for a given word w that appears in both the datasets, we get two different set of clusters, say Ci and Cj. Without loss of generality, let us assume that our algorithm detects m sense clusters for the word w in tvi and n sense clusters in tvj.</context>
</contexts>
<marker>Biemann, 2011</marker>
<rawString>C. Biemann. 2011. Structure Discovery in Natural Language. Springer Heidelberg Dordrecht London New York. ISBN 978-3-642-25922-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>J Lafferty</author>
</authors>
<title>Dynamic topic models.</title>
<date>2006</date>
<booktitle>In proceedings of ICML,</booktitle>
<pages>113--120</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="8091" citStr="Blei and Lafferty, 2006" startWordPosition="1310" endWordPosition="1314">detecting the occurrence of a new event such as a plane crash, a murder, a jury trial result, or a political scandal in a stream of news stories from multiple sources and tracking is the process of monitoring a stream of news stories to find those that track (or discuss) the same event. This is done on shorter timescales (hours, days), whereas our study focuses on larger timescales (decades, centuries) and we are interested in common nouns, verbs and adjectives as opposed to events that are characterized mostly by named entities. Other similar works on dynamic topic modelling can be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨a¨akk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce w</context>
</contexts>
<marker>Blei, Lafferty, 2006</marker>
<rawString>D. Blei and J. Lafferty. 2006. Dynamic topic models. In proceedings of ICML, 113–120, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bond</author>
<author>H Isahara</author>
<author>S Fujita</author>
<author>K Uchimoto</author>
<author>T Kuribayash</author>
<author>K Kanzaki</author>
</authors>
<title>Enhancing the Japanese WordNet.</title>
<date>2009</date>
<booktitle>In proceedings of workshop on Asian Language Resources, 1–8,</booktitle>
<location>Suntec, Singapore.</location>
<contexts>
<context position="8524" citStr="Bond et al., 2009" startWordPosition="1385" endWordPosition="1388">ouns, verbs and adjectives as opposed to events that are characterized mostly by named entities. Other similar works on dynamic topic modelling can be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨a¨akk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce word senses and then identify novel senses by comparing two different corpora: the “focus corpora” (i.e., a recent version of the corpora) and the “reference corpora” (older version of the corpora). However, this method is limited as it only considers two time points to 1https://books.google.com/ngrams 1021 identify sense changes as opposed to our approach which is over a much larger timescale, thereby, effectively allowing us to </context>
</contexts>
<marker>Bond, Isahara, Fujita, Uchimoto, Kuribayash, Kanzaki, 2009</marker>
<rawString>F. Bond, H. Isahara, S. Fujita, K. Uchimoto, T. Kuribayash and K. Kanzaki. 2009. Enhancing the Japanese WordNet. In proceedings of workshop on Asian Language Resources, 1–8, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cook</author>
<author>J H Lau</author>
<author>M Rundell</author>
<author>D McCarthy</author>
<author>T Baldwin</author>
</authors>
<title>A lexicographic appraisal of an automatic approach for detecting new word senses.</title>
<date>2013</date>
<booktitle>In proceedings of eLex,</booktitle>
<pages>49--65</pages>
<location>Tallinn, Estonia.</location>
<contexts>
<context position="8670" citStr="Cook et al. (2013)" startWordPosition="1408" endWordPosition="1411">an be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨a¨akk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce word senses and then identify novel senses by comparing two different corpora: the “focus corpora” (i.e., a recent version of the corpora) and the “reference corpora” (older version of the corpora). However, this method is limited as it only considers two time points to 1https://books.google.com/ngrams 1021 identify sense changes as opposed to our approach which is over a much larger timescale, thereby, effectively allowing us to track the points of change and the underlying causes. One of the closest work to what we present here has been put forward by (Tahmasebi et al., 2</context>
</contexts>
<marker>Cook, Lau, Rundell, McCarthy, Baldwin, 2013</marker>
<rawString>P. Cook, J. H. Lau, M. Rundell, D. McCarthy, T. Baldwin. 2013. A lexicographic appraisal of an automatic approach for detecting new word senses. In proceedings of eLex, 49-65, Tallinn, Estonia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Goldberg</author>
<author>J Orwant</author>
</authors>
<title>A dataset of syntactic-ngrams over time from a very large corpus of English books.</title>
<date>2013</date>
<booktitle>In proceedings of the Joint Conference on Lexical and Computational Semantics (*SEM),</booktitle>
<pages>241--247</pages>
<location>Atlanta, GA, USA.</location>
<contexts>
<context position="3159" citStr="Goldberg and Orwant, 2013" startWordPosition="498" endWordPosition="501">ncial institution” and the “shore of a river.” Automatic discovery and disambiguation of word senses from a given text is an important and challenging problem which has been extensively studied in the literature (Jones, 1986; Ide and Veronis, 1998; Sch¨utze, 1998; Navigli, 2009). However, another equally important aspect that has not been so far well investigated corresponds to one or more changes that a word might undergo in its sense. This particular aspect is getting increasingly attainable as more and more time-varying text data become available in the form of millions of digitized books (Goldberg and Orwant, 2013) gathered over the last centuries. As a motivating example one could consider the word “sick” – while according to the standard English dictionaries the word is normally used to refer to some sort of illness, a new meaning of “sick” referring to something that is “crazy” or “cool” is currently getting popular in the English vernacular. This change is further interesting because while traditionally “sick” has been associated to something negative in general, the current meaning associates positivity with it. In fact, a rock band by the name of “Sick Puppies” has been founded which probably is i</context>
<context position="10350" citStr="Goldberg and Orwant, 2013" startWordPosition="1684" endWordPosition="1687">vated us to undertake the current work where we introduce, for the first time, a completely unsupervised and automatic method to identify the change of a word sense and the cause for the same. Further, we also present an extensive evaluation of the proposed algorithm in order to test its overall accuracy and performance. 3 Datasets and graph construction In this section, we outline a brief description of the dataset used for our experiments and the graph construction procedure. The primary source of data have been the millions of digitized books made available through the Google Book project (Goldberg and Orwant, 2013). The Google Book syntactic n-grams dataset provides dependency fragment counts by the years. However, instead of using the plain syntactic n-grams, we use a far richer representation of the data in the form of a distributional thesaurus (Lin, 1997; Rychl´y and Kilgarriff, 2007). In specific, we prepare a distributional thesaurus (DT) for each of the time periods separately and subsequently construct the required networks. We briefly outline the procedure of thesauri construction here referring the reader to (Riedl and Biemann, 2013) for further details. In this approach, we first extract each</context>
</contexts>
<marker>Goldberg, Orwant, 2013</marker>
<rawString>Y. Goldberg and J. Orwant. 2013. A dataset of syntactic-ngrams over time from a very large corpus of English books. In proceedings of the Joint Conference on Lexical and Computational Semantics (*SEM), 241–247, Atlanta, GA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heyer</author>
<author>F Holz</author>
<author>S Teresniak</author>
</authors>
<title>Change of topics over time – tracking topics by their change of meaning.</title>
<date>2009</date>
<booktitle>In proceedings of KDIR,</booktitle>
<location>Madeira, Portugal.</location>
<contexts>
<context position="8439" citStr="Heyer et al., 2009" startWordPosition="1370" endWordPosition="1373">udy focuses on larger timescales (decades, centuries) and we are interested in common nouns, verbs and adjectives as opposed to events that are characterized mostly by named entities. Other similar works on dynamic topic modelling can be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨a¨akk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce word senses and then identify novel senses by comparing two different corpora: the “focus corpora” (i.e., a recent version of the corpora) and the “reference corpora” (older version of the corpora). However, this method is limited as it only considers two time points to 1https://books.google.com/ngrams 1021 identify sense changes as opposed to our</context>
</contexts>
<marker>Heyer, Holz, Teresniak, 2009</marker>
<rawString>G. Heyer, F. Holz and S. Teresniak. 2009. Change of topics over time – tracking topics by their change of meaning. In proceedings of KDIR, Madeira, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>J Veronis</author>
</authors>
<title>Introduction to the special issue on word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="1935" citStr="Ide and Veronis, 1998" startWordPosition="303" endWordPosition="306">rithm could correctly identify 60.4% birth cases from a set of 48 randomly picked samples and 57% split/join cases from a set of 21 randomly picked samples. Remarkably, in 44% cases the birth of a novel sense is attested by WordNet, while in 46% cases and 43% cases split and join are respectively confirmed by WordNet. Our approach can be applied for lexicography, as well as for applications like word sense disambiguation or semantic search. 1 Introduction Two of the fundamental components of a natural language communication are word sense discovery (Jones, 1986) and word sense disambiguation (Ide and Veronis, 1998). While discovery corresponds to acquisition of vocabulary, disambiguation forms the basis of understanding. These two aspects are not only important from the perspective of developing computer applications for natural languages but also form the key components of language evolution and change. Words take different senses in different contexts while appearing with other words. Context plays a vital role in disambiguation of word senses as well as in the interpretation of the actual meaning of words. For instance, the word “bank” has several distinct interpretations, including that of a “financ</context>
<context position="6355" citStr="Ide and Veronis (1998)" startWordPosition="1025" endWordPosition="1029">scribe the datasets and outline the process of co-occurrence graph construction. In Section 4 we present an approach based on graph clustering to identify the time-varying sense clusters and in Section 5 we present the split-merge based approach for tracking word sense changes. Evaluation methods are summarized in Section 6. Finally, conclusions and further research directions are outlined in Section 7. 2 Related work Word sense disambiguation as well as word sense discovery have both remained key areas of research right from the very early initiatives in natural language processing research. Ide and Veronis (1998) present a very concise survey of the history of ideas used in word sense disambiguation; for a recent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspire</context>
</contexts>
<marker>Ide, Veronis, 1998</marker>
<rawString>N. Ide and J. Veronis. 1998. Introduction to the special issue on word sense disambiguation: The state of the art. Computational Linguistics, 24(1):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>P Rychly</author>
<author>P Smrz</author>
<author>D Tugwell</author>
</authors>
<title>The sketch engine.</title>
<date>2004</date>
<booktitle>In Proceedings of EURALEX,</booktitle>
<pages>105--116</pages>
<location>Lorient, France.</location>
<marker>Kilgarriff, Rychly, Smrz, Tugwell, 2004</marker>
<rawString>A. Kilgarriff, P. Rychly, P. Smrz, and D. Tugwell. 2004. The sketch engine. In Proceedings of EURALEX, 105–116, Lorient, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>D Tugwell</author>
</authors>
<title>Word sketch: Extraction and display of significant collocations for lexicography.</title>
<date>2001</date>
<booktitle>In proceedings of COLLOCATION: Computational Extraction, Analysis and Exploitation,</booktitle>
<pages>32--38</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="6782" citStr="Kilgarriff and Tugwell, 2001" startWordPosition="1095" endWordPosition="1098"> Word sense disambiguation as well as word sense discovery have both remained key areas of research right from the very early initiatives in natural language processing research. Ide and Veronis (1998) present a very concise survey of the history of ideas used in word sense disambiguation; for a recent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspired by works on language dynamics and opinion spreading (Mukherjee et al., 2011; Maity et al., 2012; Loreto et al., 2012) and automatic topic detection and tracking (Allan et al., 1998). However, our work differs significantly from those proposed in the above studies. Opinion formation deals with the self-organisation and emergence of shared vocabularies whereas our work focuses on how the different senses of these vocabulary</context>
</contexts>
<marker>Kilgarriff, Tugwell, 2001</marker>
<rawString>A. Kilgarriff and D. Tugwell. 2001. Word sketch: Extraction and display of significant collocations for lexicography. In proceedings of COLLOCATION: Computational Extraction, Analysis and Exploitation, 32–38, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Using syntactic dependency as local context to resolve word sense ambiguity.</title>
<date>1997</date>
<booktitle>In proceedings of ACL/EACL,</booktitle>
<pages>64--71</pages>
<location>Madrid,</location>
<contexts>
<context position="10598" citStr="Lin, 1997" startWordPosition="1727" endWordPosition="1728">hm in order to test its overall accuracy and performance. 3 Datasets and graph construction In this section, we outline a brief description of the dataset used for our experiments and the graph construction procedure. The primary source of data have been the millions of digitized books made available through the Google Book project (Goldberg and Orwant, 2013). The Google Book syntactic n-grams dataset provides dependency fragment counts by the years. However, instead of using the plain syntactic n-grams, we use a far richer representation of the data in the form of a distributional thesaurus (Lin, 1997; Rychl´y and Kilgarriff, 2007). In specific, we prepare a distributional thesaurus (DT) for each of the time periods separately and subsequently construct the required networks. We briefly outline the procedure of thesauri construction here referring the reader to (Riedl and Biemann, 2013) for further details. In this approach, we first extract each word and a set of its context features, which are formed by labeled and directed dependency parse edges as provided in the dataset. Following this, we compute the frequencies of the word, the context and the words along with their context. Next we</context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>D. Lin. 1997. Using syntactic dependency as local context to resolve word sense ambiguity. In proceedings of ACL/EACL, 64–71, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Loreto</author>
<author>A Mukherjee</author>
<author>F Tria</author>
</authors>
<title>On the origin of the hierarchy of color names.</title>
<date>2012</date>
<journal>PNAS,</journal>
<volume>109</volume>
<issue>18</issue>
<pages>6819--6824</pages>
<contexts>
<context position="7074" citStr="Loreto et al., 2012" startWordPosition="1145" endWordPosition="1148">ent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspired by works on language dynamics and opinion spreading (Mukherjee et al., 2011; Maity et al., 2012; Loreto et al., 2012) and automatic topic detection and tracking (Allan et al., 1998). However, our work differs significantly from those proposed in the above studies. Opinion formation deals with the self-organisation and emergence of shared vocabularies whereas our work focuses on how the different senses of these vocabulary words change over time and thus become “out-of-vocabulary”. Topic detection involves detecting the occurrence of a new event such as a plane crash, a murder, a jury trial result, or a political scandal in a stream of news stories from multiple sources and tracking is the process of monitori</context>
</contexts>
<marker>Loreto, Mukherjee, Tria, 2012</marker>
<rawString>V. Loreto, A. Mukherjee and F. Tria. 2012. On the origin of the hierarchy of color names. PNAS, 109(18), 6819–6824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McAuley</author>
<author>J Leskovec</author>
</authors>
<title>Learning to discover social circles in ego networks.</title>
<date>2012</date>
<booktitle>In proceedings of NIPS,</booktitle>
<pages>548--556</pages>
<location>Nevada, USA.</location>
<contexts>
<context position="12583" citStr="McAuley and Leskovec, 2012" startWordPosition="2046" endWordPosition="2049">e, utilize the basic hypothesis of unsupervised sense induction to induce the sense clusters over various time periods and then compare these clusters to detect sense change. The basic premises of the ‘unsupervised sense induction’ are briefly described below. 4.1 Unsupervised sense induction We use the co-occurrence based graph clustering framework introduced in (Biemann, 2006). The algorithm proceeds in three basic steps. Firstly, a co-occurrence graph is created for every target word found in DT. Next, the neighbourhood/ego graph is clustered using the Chinese Whispers (CW) algorithm (see (McAuley and Leskovec, 2012) for similar approaches). The algorithm, in particular, produces a set of clusters for each target word by decomposing its open neighborhood. We hypothesize that each different cluster corresponds to a particular sense of the target word. For a detailed description, the reader is referred to (Biemann, 2011). If a word undergoes sense change, this can be detected by comparing the sense clusters obtained from two different time periods by the algorithm outlined above. For this purpose, we use statistics from the DT corresponding to two different time intervals, say tvi and tvj. We then run the s</context>
</contexts>
<marker>McAuley, Leskovec, 2012</marker>
<rawString>J. McAuley and J. Leskovec. 2012. Learning to discover social circles in ego networks. In proceedings of NIPS, 548–556, Nevada, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-B Michel</author>
<author>Y K Shen</author>
<author>A P Aiden</author>
<author>A Veres</author>
<author>M K Gray</author>
<author>J P Pickett</author>
<author>D Hoiberg</author>
<author>D Clancy</author>
<author>P Norvig</author>
<author>J Orwant</author>
<author>S Pinker</author>
<author>M A Nowak</author>
<author>E L Aiden</author>
</authors>
<title>Quantitative analysis of culture using millions of digitized books.</title>
<date>2011</date>
<journal>Science,</journal>
<volume>331</volume>
<issue>6014</issue>
<marker>Michel, Shen, Aiden, Veres, Gray, Pickett, Hoiberg, Clancy, Norvig, Orwant, Pinker, Nowak, Aiden, 2011</marker>
<rawString>J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K. Gray, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant, S. Pinker, M. A. Nowak and E. L. Aiden. 2011. Quantitative analysis of culture using millions of digitized books. Science, 331(6014):176–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>V Nastase</author>
</authors>
<title>Word epoch disambiguation: finding how words change over time.</title>
<date>2012</date>
<booktitle>In proceedings of ACL, 259–263, Jeju Island,</booktitle>
<contexts>
<context position="4287" citStr="Mihalcea and Nastase, 2012" startWordPosition="684" endWordPosition="687">ty with it. In fact, a rock band by the name of “Sick Puppies” has been founded which probably is inspired by the newer sense of the word sick. The title of this paper has been motivated by the above observation. Note that this phenomena of change in word senses has existed ever since the beginning of human communication (Bamman and Crane, 2011; Michel et 1020 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1020–1029, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics al., 2011; Wijaya and Yeniterzi, 2011; Mihalcea and Nastase, 2012); however, with the advent of modern technology and the availability of huge volumes of time-varying data it now has become possible to automatically track such changes and, thereby, help the lexicographers in word sense discovery, and design engineers in enhancing various NLP/IR applications (e.g., disambiguation, semantic search etc.) that are naturally sensitive to change in word senses. The above motivation forms the basis of the central objective set in this paper, which is to devise a completely unsupervised approach to track noun sense changes in large texts available over multiple time</context>
</contexts>
<marker>Mihalcea, Nastase, 2012</marker>
<rawString>R. Mihalcea and V. Nastase. 2012. Word epoch disambiguation: finding how words change over time. In proceedings of ACL, 259–263, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mukherjee</author>
<author>F Tria</author>
<author>A Baronchelli</author>
<author>A Puglisi</author>
<author>V Loreto</author>
</authors>
<title>Aging in language dynamics.</title>
<date>2011</date>
<journal>PLoS ONE,</journal>
<volume>6</volume>
<issue>2</issue>
<pages>16677</pages>
<contexts>
<context position="7032" citStr="Mukherjee et al., 2011" startWordPosition="1137" endWordPosition="1140">used in word sense disambiguation; for a recent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspired by works on language dynamics and opinion spreading (Mukherjee et al., 2011; Maity et al., 2012; Loreto et al., 2012) and automatic topic detection and tracking (Allan et al., 1998). However, our work differs significantly from those proposed in the above studies. Opinion formation deals with the self-organisation and emergence of shared vocabularies whereas our work focuses on how the different senses of these vocabulary words change over time and thus become “out-of-vocabulary”. Topic detection involves detecting the occurrence of a new event such as a plane crash, a murder, a jury trial result, or a political scandal in a stream of news stories from multiple sourc</context>
</contexts>
<marker>Mukherjee, Tria, Baronchelli, Puglisi, Loreto, 2011</marker>
<rawString>A. Mukherjee, F. Tria, A. Baronchelli, A. Puglisi and V. Loreto. 2011. Aging in language dynamics. PLoS ONE, 6(2): e16677.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
</authors>
<title>Word sense disambiguation: a survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="2812" citStr="Navigli, 2009" startWordPosition="443" endWordPosition="444">f language evolution and change. Words take different senses in different contexts while appearing with other words. Context plays a vital role in disambiguation of word senses as well as in the interpretation of the actual meaning of words. For instance, the word “bank” has several distinct interpretations, including that of a “financial institution” and the “shore of a river.” Automatic discovery and disambiguation of word senses from a given text is an important and challenging problem which has been extensively studied in the literature (Jones, 1986; Ide and Veronis, 1998; Sch¨utze, 1998; Navigli, 2009). However, another equally important aspect that has not been so far well investigated corresponds to one or more changes that a word might undergo in its sense. This particular aspect is getting increasingly attainable as more and more time-varying text data become available in the form of millions of digitized books (Goldberg and Orwant, 2013) gathered over the last centuries. As a motivating example one could consider the word “sick” – while according to the standard English dictionaries the word is normally used to refer to some sort of illness, a new meaning of “sick” referring to somethi</context>
<context position="6521" citStr="Navigli, 2009" startWordPosition="1057" endWordPosition="1058">nse clusters and in Section 5 we present the split-merge based approach for tracking word sense changes. Evaluation methods are summarized in Section 6. Finally, conclusions and further research directions are outlined in Section 7. 2 Related work Word sense disambiguation as well as word sense discovery have both remained key areas of research right from the very early initiatives in natural language processing research. Ide and Veronis (1998) present a very concise survey of the history of ideas used in word sense disambiguation; for a recent survey of the state-of-the-art one can refer to (Navigli, 2009). Some of the first attempts to automatic word sense discovery were made by Karen Sp¨arck Jones (1986); later in lexicography, it has been extensively used as a pre-processing step for preparing mono- and multi-lingual dictionaries (Kilgarriff and Tugwell, 2001; Kilgarriff, 2004). However, as we have already pointed out that none of these works consider the temporal aspect of the problem. In contrast, the current study, is inspired by works on language dynamics and opinion spreading (Mukherjee et al., 2011; Maity et al., 2012; Loreto et al., 2012) and automatic topic detection and tracking (Al</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>R. Navigli. 2009. Word sense disambiguation: a survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P¨a¨akk¨o</author>
<author>K Lind´en</author>
</authors>
<title>Finding a location for a new word in WordNet.</title>
<date>2012</date>
<booktitle>In proceedings of the Global WordNet Conference,</booktitle>
<location>Matsue, Japan.</location>
<marker>P¨a¨akk¨o, Lind´en, 2012</marker>
<rawString>P. P¨a¨akk¨o and K. Lind´en. 2012. Finding a location for a new word in WordNet. In proceedings of the Global WordNet Conference, Matsue, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Riedl</author>
<author>C Biemann</author>
</authors>
<title>Scaling to large3 data: An efficient and effective method to compute distributional thesauri.</title>
<date>2013</date>
<booktitle>In proceedings of EMNLP, 884–890,</booktitle>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="10889" citStr="Riedl and Biemann, 2013" startWordPosition="1770" endWordPosition="1773">ized books made available through the Google Book project (Goldberg and Orwant, 2013). The Google Book syntactic n-grams dataset provides dependency fragment counts by the years. However, instead of using the plain syntactic n-grams, we use a far richer representation of the data in the form of a distributional thesaurus (Lin, 1997; Rychl´y and Kilgarriff, 2007). In specific, we prepare a distributional thesaurus (DT) for each of the time periods separately and subsequently construct the required networks. We briefly outline the procedure of thesauri construction here referring the reader to (Riedl and Biemann, 2013) for further details. In this approach, we first extract each word and a set of its context features, which are formed by labeled and directed dependency parse edges as provided in the dataset. Following this, we compute the frequencies of the word, the context and the words along with their context. Next we calculate the lexicographer’s mutual information LMI (Kilgarriff, 2004) between a word and its features and retain only the top 1000 ranked features for every word. Finally, we construct the DT network as follows: each word is a node in the network and the edge weight between two nodes is </context>
</contexts>
<marker>Riedl, Biemann, 2013</marker>
<rawString>M. Riedl and C. Biemann. 2013. Scaling to large3 data: An efficient and effective method to compute distributional thesauri. In proceedings of EMNLP, 884–890, Seattle, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Riedl</author>
<author>R Steuer</author>
<author>C Biemann</author>
</authors>
<title>Distributed distributional similarities of Google books over the centuries.</title>
<date>2014</date>
<booktitle>In proceedings of LREC, Reykjavik,</booktitle>
<marker>Riedl, Steuer, Biemann, 2014</marker>
<rawString>M. Riedl, R. Steuer and C. Biemann. 2014. Distributed distributional similarities of Google books over the centuries. In proceedings of LREC, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rychl´y</author>
<author>A Kilgarriff</author>
</authors>
<title>An efficient algorithm for building a distributional thesaurus (and other sketch engine developments).</title>
<date>2007</date>
<booktitle>In proceedings of ACL, poster and demo sessions,</booktitle>
<pages>41--44</pages>
<location>Prague, Czech Republic.</location>
<marker>Rychl´y, Kilgarriff, 2007</marker>
<rawString>P. Rychl´y and A. Kilgarriff. 2007. An efficient algorithm for building a distributional thesaurus (and other sketch engine developments). In proceedings of ACL, poster and demo sessions, 41–44, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>H. Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sp¨ark-Jones</author>
</authors>
<title>Synonymy and Semantic Classification.</title>
<date>1986</date>
<pages>0--85224</pages>
<publisher>Edinburgh University Press. ISBN</publisher>
<marker>Sp¨ark-Jones, 1986</marker>
<rawString>K. Sp¨ark-Jones. 1986. Synonymy and Semantic Classification. Edinburgh University Press. ISBN 0-85224-517-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tahmasebi</author>
<author>T Risse</author>
<author>S Dietze</author>
</authors>
<title>Towards automatic language evolution tracking: a study on word sense tracking.</title>
<date>2011</date>
<booktitle>In proceedings of EvoDyn,</booktitle>
<volume>784</volume>
<location>Bonn, Germany.</location>
<contexts>
<context position="9274" citStr="Tahmasebi et al., 2011" startWordPosition="1506" endWordPosition="1509"> Cook et al. (2013) attempts to induce word senses and then identify novel senses by comparing two different corpora: the “focus corpora” (i.e., a recent version of the corpora) and the “reference corpora” (older version of the corpora). However, this method is limited as it only considers two time points to 1https://books.google.com/ngrams 1021 identify sense changes as opposed to our approach which is over a much larger timescale, thereby, effectively allowing us to track the points of change and the underlying causes. One of the closest work to what we present here has been put forward by (Tahmasebi et al., 2011), where the authors analyze a newspaper corpus containing articles between 1785 and 1985. The authors mainly report the frequency patterns of certain words that they found to be candidates for change; however a detailed cause analysis as to why and how a particular word underwent a sense change has not been demonstrated. Further, systematic evaluation of the results obtained by the authors has not been provided. All the above points together motivated us to undertake the current work where we introduce, for the first time, a completely unsupervised and automatic method to identify the change o</context>
</contexts>
<marker>Tahmasebi, Risse, Dietze, 2011</marker>
<rawString>N. Tahmasebi, T. Risse and S. Dietze. 2011. Towards automatic language evolution tracking: a study on word sense tracking. In proceedings of EvoDyn, vol. 784, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wang</author>
<author>A McCallum</author>
</authors>
<title>Topics over time: a non-Markov continuous-time model of topical trends.</title>
<date>2006</date>
<booktitle>In proceedings of KDD,</booktitle>
<pages>424--433</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="8117" citStr="Wang and McCallum, 2006" startWordPosition="1315" endWordPosition="1318">of a new event such as a plane crash, a murder, a jury trial result, or a political scandal in a stream of news stories from multiple sources and tracking is the process of monitoring a stream of news stories to find those that track (or discuss) the same event. This is done on shorter timescales (hours, days), whereas our study focuses on larger timescales (decades, centuries) and we are interested in common nouns, verbs and adjectives as opposed to events that are characterized mostly by named entities. Other similar works on dynamic topic modelling can be found in (Blei and Lafferty, 2006; Wang and McCallum, 2006). Google books n-gram viewer1 is a phrase-usage graphing tool which charts the yearly count of selected letter combinations, words, or phrases as found in over 5.2 million digitized books. It only reports frequency of word usage over the years, but does not give any correlation among them as e.g., in (Heyer et al., 2009), and does not analyze their senses. A few approaches suggested by (Bond et al., 2009; P¨a¨akk¨o and Lind´en, 2012) attempt to augment WordNet synsets primarily using methods of annotation. Another recent work by Cook et al. (2013) attempts to induce word senses and then identi</context>
</contexts>
<marker>Wang, McCallum, 2006</marker>
<rawString>X. Wang and A. McCallum. 2006. Topics over time: a non-Markov continuous-time model of topical trends. In proceedings of KDD, 424–433, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wijaya</author>
<author>R Yeniterzi</author>
</authors>
<title>Understanding semantic change of words over centuries.</title>
<date>2011</date>
<booktitle>In proceedings of the workshop on Detecting and Exploiting Cultural Diversity on the Social Web,</booktitle>
<location>35–40, Glasgow, Scotland, UK.</location>
<contexts>
<context position="4258" citStr="Wijaya and Yeniterzi, 2011" startWordPosition="680" endWordPosition="683"> meaning associates positivity with it. In fact, a rock band by the name of “Sick Puppies” has been founded which probably is inspired by the newer sense of the word sick. The title of this paper has been motivated by the above observation. Note that this phenomena of change in word senses has existed ever since the beginning of human communication (Bamman and Crane, 2011; Michel et 1020 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1020–1029, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics al., 2011; Wijaya and Yeniterzi, 2011; Mihalcea and Nastase, 2012); however, with the advent of modern technology and the availability of huge volumes of time-varying data it now has become possible to automatically track such changes and, thereby, help the lexicographers in word sense discovery, and design engineers in enhancing various NLP/IR applications (e.g., disambiguation, semantic search etc.) that are naturally sensitive to change in word senses. The above motivation forms the basis of the central objective set in this paper, which is to devise a completely unsupervised approach to track noun sense changes in large texts</context>
</contexts>
<marker>Wijaya, Yeniterzi, 2011</marker>
<rawString>D. Wijaya and R. Yeniterzi. 2011. Understanding semantic change of words over centuries. In proceedings of the workshop on Detecting and Exploiting Cultural Diversity on the Social Web, 35–40, Glasgow, Scotland, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>