<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007623">
<title confidence="0.934899">
UBC-ALM: Combining k-NN with SVD for WSD
</title>
<author confidence="0.700497">
Eneko Agirre and Oier Lopez de Lacalle
</author>
<affiliation confidence="0.815622333333333">
IXA NLP Group
University of the Basque Country
Donostia, Basque Country
</affiliation>
<email confidence="0.998165">
{e.agirre,jibloleo}@ehu.es
</email>
<sectionHeader confidence="0.997377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997337769230769">
This work describes the University of the
Basque Country system (UBC-ALM) for
lexical sample and all-words WSD subtasks
of SemEval-2007 task 17, where it per-
formed in the second and fifth positions re-
spectively. The system is based on a com-
bination of k-Nearest Neighbor classifiers,
with each classifier learning from a distinct
set of features: local features (syntactic, col-
locations features), topical features (bag-of-
words, domain information) and latent fea-
tures learned from a reduced space using
Singular Value Decomposition.
</bodyText>
<sectionHeader confidence="0.999499" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997187">
Our group (UBC-ALM) participated in the lexical
sample and all-words WSD subtasks of SemEval-
2007 task 17. We applied a combination of different
k-Nearest Neighbor (k-NN) classifiers. Each clas-
sifier manages different information sources (fea-
tures), making the combination a powerful solution.
This algorithm was previously tested on the datasets
from previous editions of Senseval (Agirre et al.,
2005; Agirre et al., 2006). Before submission, the
performance of the system was tested on the Se-
mEval lexical sample training data. For learning we
use a rich set of features, including latent features
obtained from a reduced space using Singular Value
Decomposition (SVD).
This paper is organized as follows. The learning
features are presented in section 2, and the learning
algorithm and the combinations of single k-NNs are
given in section 3. Section 4 focuses on the tuning
experiments. Finally, section 5 summarizes the offi-
cial results and some conclusions.
</bodyText>
<sectionHeader confidence="0.987762" genericHeader="method">
2 Feature set
</sectionHeader>
<bodyText confidence="0.999967285714286">
We relied on an extensive set of features of differ-
ent types, obtained by means of different tools and
resources. We defined two main groups: the origi-
nal features extracted directly from the text, and the
SVD features obtained after applying SVD decom-
position and projecting the original features into the
new semantic space (Agirre et al., 2005).
</bodyText>
<subsectionHeader confidence="0.983637">
2.1 Original features
</subsectionHeader>
<bodyText confidence="0.999591409090909">
Local collocations: bigrams and trigrams formed
with the words around the target. These features are
constituted by lemmas, word-forms, or PoS tags1.
Other local features are those formed with the previ-
ous/posterior lemma/word-form in the context.
Syntactic dependencies: syntactic dependencies
were extracted using heuristic patterns, and regular
expressions defined with the PoS tags around the tar-
get2. The following relations were used: object, sub-
ject, noun-modifier, preposition, and sibling.
Bag-of-words features: we extract the lemmas
of the content words in the whole context, and in a
±4-word window around the target. We also obtain
salient bigrams in the context, with the methods and
the software described in (Pedersen, 2001).
Domain features: The WordNet Domains re-
source was used to identify the most relevant do-
mains in the context. Following the relevance for-
mula presented in (Magnini and Cavagli´a, 2000), we
defined 2 feature types: (1) the most relevant do-
main, and (2) a list of domains above a predefined
threshold3.
</bodyText>
<footnote confidence="0.999688333333333">
1The PoS tagging was performed with the fnTBL toolkit
(Ngai and Florian, 2001).
2This software was kindly provided by David Yarowsky’s
group, from Johns Hopkins University.
3The software to obtain the relevant domains was kindly
provided by Gerard Escudero’s group, from Universitat Politec-
</footnote>
<page confidence="0.982319">
342
</page>
<bodyText confidence="0.8093865">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 342–345,
Prague, June 2007. c�2007 Association for Computational Linguistics
</bodyText>
<subsectionHeader confidence="0.997089">
2.2 SVD features
</subsectionHeader>
<bodyText confidence="0.997818416666667">
Singular Value Decomposition (SVD) is an interest-
ing solution to the sparse data problem. This tech-
nique reduces the dimensions of the vectorial space
finding correlations and collapsing features. It also
gives the chance to use unlabeled data as an addi-
tional source of correlations.
M ∋ Rmxn, a matrix of features-by-document is
built from the training corpus and decomposed into
three matrices, as shown in Eq. (1). U and V , row
and column matrix, respectively, have orthonormal
columns and E is a diagonal matrix which contains
k eigenvalues in descending order.
</bodyText>
<equation confidence="0.990509333333333">
k=min{m,n}
M = UEV T = � σiuiviT (1)
i=1
</equation>
<bodyText confidence="0.977293">
We used the singular value matrix (E) and the
column matrix (U) to create a projection matrix,
which is used to project the data (represented in fea-
tures vectors) from the original space to a reduced
space. Prior to that we selected the first p columns
from the E and U matrices (p &lt; k): tp = iT UpE�1
p
We have explored two different variants in order
to build a matrix, and obtain the SVD features:
SVD One Matrix per Target word (SVD-
OMT). For each word (i) we extracted all the fea-
tures from the given training (test) corpus, (ii) built
the feature-by-document matrix from training cor-
pus, (iii) decomposed it with SVD, and (iv) project
all the training (test) data. Note that this variant has
been only used in the lexical sample task due to its
costly computational requirements.
SVD Single Matrix for All target words (SVD-
SMA): (i) we extracted bag-of-words features from
the British National Corpus (BNC) (Leech, 1992),
(ii) built the feature-by-document matrix, (iii) de-
compose it with SVD, and (iv) project all the data
(train/test).
</bodyText>
<sectionHeader confidence="0.97418" genericHeader="method">
3 Learning Algorithm
</sectionHeader>
<bodyText confidence="0.986379818181818">
The machine learning (ML) algorithm presented in
this section rely on the previously described fea-
tures. Each occurrence or instance is represented by
the features found in the context (fi). Given an oc-
currence of a word, the ML method below returns a
nica de Catalunya
weight for each sense (weight(sk)). The sense with
maximum weight will be selected.
We use a set of combination of the k-Nearest
Neighbor (k-NN) to tag the target words in both the
lexical sample and all-words tasks.
</bodyText>
<subsectionHeader confidence="0.993779">
3.1 k-Nearest Neighbor
</subsectionHeader>
<bodyText confidence="0.999956272727273">
k-NN is a memory-based learning method, where
the neighbors are the k most similar contexts, repre-
sented by feature vectors (ci), of the test vector (
The similarity among instances is measured by the
cosine of their vectors. The test instance is labeled
with the sense obtaining the maximum sum of the
weighted votes of the k most similar contexts. The
vote is weighted depending on its (neighbor) posi-
tion in the ordered rank, with the closest being first.
Eq. (2) formalizes k-NN, where Ci corresponds to
the sense label of the i-th closest neighbor.
</bodyText>
<equation confidence="0.97510075">
��1
k if Ci = S�
i (2)
0 otherwise
</equation>
<subsectionHeader confidence="0.998574">
3.2 k-NN combinations and feature splits
</subsectionHeader>
<bodyText confidence="0.999951333333333">
As seen in section 2 we use a variety of heteroge-
neous sets of features. Our previous experience has
shown that splitting the problem up into more co-
herent spaces, training different classifiers in each
feature space, and then combining them into a sin-
gle classifier is a good way to improve the results
(Agirre et al., 2005; Agirre et al., 2006). Depend-
ing on the feature type (original features or features
extracted from SVD projection) we split different
sets of feature spaces. In total we tried 10 features
spaces.
For the original features:
</bodyText>
<listItem confidence="0.999958555555556">
• all feats: Extracted all original features.
• all notdom: All original features except do-
main features.
• local: All the original features except domain
and bag-of-words features.
• topic: The sum of bag-of-words and domain
features.
• bow: Bag-of-word features.
• dom: Domain features.
</listItem>
<figure confidence="0.94798925">
A
arg max
Si
i=1
</figure>
<page confidence="0.996829">
343
</page>
<table confidence="0.999772727272727">
Combination accuracy
all feats+topic+local+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.8
all feats+all notdom+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.7
all feats+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.5
all notdom+topic+local+SVD-SMA+SVD-OMT[all feats]+SVD-OMT[topic]+SVD-OMT[local] 88.5
all feats+all notdom+topic+local 88.4
all notdom+local+SVD-SMA 88.3
all feats+all notdom+local+SVD-SMA 88.2
all notdom+topic+local 88.1
all feats+topic+local 88.1
word-by-word optimization 89.5
</table>
<tableCaption confidence="0.998818">
Table 1: Result for the best k-NN combinations in 3 fold cross-validation SemEval lexical sample.
</tableCaption>
<bodyText confidence="0.961699">
For the SVD features:
</bodyText>
<listItem confidence="0.999920714285714">
• SVD-OMT[all feats]: OMT matrix applied to
all original features.
• SVD-OMT[local]: OMT matrix to the local
original features.
• SVD-OMT[topic]: OMT matrix to the topic
original features.
• SVD-SMA: Features obtained from the projec-
</listItem>
<bodyText confidence="0.967543777777778">
tion of bow features with the SMA matrix.
Depending on the ML method one can try differ-
ent approaches to combine classifiers. In this work,
we exploited the fact that a k-NN classifier can be
seen as k points casting each one vote. The votes
are weigthed by the inverse ratio of its position in
the rank (k − ri + 1)/k, where ri is the rank. Each
of the k-NN classifiers is trained on a different fea-
ture space and then combined.
</bodyText>
<sectionHeader confidence="0.996977" genericHeader="method">
4 Experiments on training data
</sectionHeader>
<bodyText confidence="0.9999095">
We optimized and tuned the system differently for
each kind of tasks. We will examine each in turn.
</bodyText>
<subsectionHeader confidence="0.916471">
4.1 Optimization for the lexical sample task
</subsectionHeader>
<bodyText confidence="0.9998692">
For the lexical sample task we only use the train-
ing data provided. We tuned the classifiers using 3
fold cross-validation on the SemEval lexical sample
training data. We tried to optimize several param-
eters: number of neighbors, SVD dimensions and
best combination of the single k-NNs. We set k as
one of 1, 3, 5 and 7, and the SVD dimension (d) as
one of 50,100, 200 and 300. We also fixed the best
combination. This is the optimization procedure we
followed:
</bodyText>
<listItem confidence="0.792479692307692">
1. For each single classifier and feature set (see
section 2), check each parameter combination.
2. Fix the parameters for each single classifier. In
our case, k = 5 and k = 7 had similar results,
so we postponed the decision. d = 200 was the
best dimension for all classifiers, except SVD-
OMT[topic] which was d = 50.
3. For the best parameter settings (k = 5; k = 7
and d = 200; d = 50 when SVD-OMT[topic])
make a priori meaningful combinations (due
to CPU requirements, not all combination were
feasible).
4. Choose the x best combination overall, and op-
</listItem>
<bodyText confidence="0.992879111111111">
timize word by word among these combination.
We set x = 8 for this work, k was fixed in 5,
and d = 200 (except with SVD-OMT[topic]
which was d = 50).
Table 1 shows the best results for 3 fold cross-
validation in SemEval lexical sample training cor-
pus. The figures show that optimizing each word the
performance increases 0.7 percentage points over
the best combination.
</bodyText>
<subsectionHeader confidence="0.950838">
4.2 Optimization for the all-words task
</subsectionHeader>
<bodyText confidence="0.999868714285714">
To train the classifiers for the all-words task we just
used Semcor (Miller et al., 1993). In (Agirre et
al., 2006) we already tested our approach on the
Senseval-3 all-words task. The best performance
for the Senseval-3 all-words task was obtained with
k = 5 and d = 200, but we decided to to perform
further experiments to search for the best combina-
tion. We tested the performance of the combination
of single k-NN training on Semcor and testing both
on the Senseval-3 all-words data (cf. Table 2) and on
the training data from SemEval-2007 lexical sample
(cf. Table 3).
Note that tables 2 and 3 show contradictory re-
sults. Given that in SemEval-2007 lexical sample
</bodyText>
<page confidence="0.996065">
344
</page>
<table confidence="0.9994715">
Combination rec. prec.
all feats+local+notbow 0.685 0.685
all feats+local+SVD-SMA 0.679 0.679
all feats+topic+local+SVD-SMA 0.689 0.689
</table>
<tableCaption confidence="0.539266666666667">
Table 2: Results for the best k-NN combinations in
Senseval-3 all-words, using Semcor as training cor-
pus.
</tableCaption>
<table confidence="0.999605">
Combination rec. prec.
all feats+SVD-SMA 0.666 0.666
all feats+local+SVD-SMA 0.661 0.661
all feats+topic+local+SVD-SMA 0.664 0.664
</table>
<tableCaption confidence="0.993637333333333">
Table 3: Results for the best k-NN combinations in
training part of SemEval lexical sample, using Sem-
cor as training corpus.
</tableCaption>
<table confidence="0.999555714285714">
Task Method Rank rec. prec.
LS Best 1 0.887 0.887
LS UBC-ALM 2 0.869 0.869
LS Baseline - 0.780 0.780
AW Best 1 0.591 0.591
AW k-NN combination 5 0.544 0.544
AW Baseline - 0.514 0.514
</table>
<tableCaption confidence="0.770663">
Table 4: Official results for SemEval-2007 task 17
lexical sample and all-words subtasks.
</tableCaption>
<bodyText confidence="0.998928333333333">
the senses are more coarse grained, we decided to
take the best combination on Senseval-3 all-words
for the final submission.
</bodyText>
<sectionHeader confidence="0.999684" genericHeader="evaluation">
5 Results and conclusions
</sectionHeader>
<bodyText confidence="0.998258526315789">
Table 4 shows the performance obtained by our sys-
tem and the winning systems in the SemEval lexi-
cal sample and all-words evaluation. On the lexical
sample evaluation our system is 2.6 lower than the
cross-validation evaluation. This can be a sign of a
slight overfitting on the training data. All in all we
ranked second over 13 systems.
Our all-words system did not perform so well.
Our system is around 4.7 points below the winning
system, ranking 5th from a total of 14, and 3 points
above the baseline given by the organizers. This is
a disappointing result when compared to our previ-
ous work on Senseval-3 all-words where we were
able to beat the best official results (Agirre et al.,
2006). Note that the test set was rather small, with
465 occurrences only, which might indicate that the
performance differences are not statistically signifi-
cant. We plan to further investigate the reasons for
our results.
</bodyText>
<sectionHeader confidence="0.998635" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999738">
We wish to thank to David Martinez for helping us
extracting learning features. This work has been
partially funded by the Spanish education ministry
(project KNOW). Oier Lopez de Lacalle is sup-
ported by a PhD grant from the Basque Government.
</bodyText>
<sectionHeader confidence="0.999425" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999810787878788">
E. Agirre, O.Lopez de Lacalle, and David Martinez.
2005. Exploring feature spaces with svd and unlabeled
data for Word Sense Disambiguation. In Proceedings
ofthe Conference on Recent Advances on Natural Lan-
guage Processing (RANLP’05), Borovets, Bulgaria.
E. Agirre, O. Lopez de Lacalle, and D. Martinez. 2006.
Exploring feature spaces with svd and unlabeled data
for Word Sense Disambiguation. In Proceedings
of the XXII Conference of Sociedad Espaola para
el Procesamiento del Lenguaje Natural (SEPLN’06),
Zaragoza, Spain.
G. Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1–13.
B. Magnini and G. Cavagli´a. 2000. Integrating subject
field codes into WordNet. In Proceedings of the Sec-
ond International LREC Conference, Athens, Greece.
G.A. Miller, C. Leacock, R. Tengi, and R.Bunker. 1993.
A Semantic Concordance. In Proceedings of the
ARPA Human Language Technology Workshop. Dis-
tributed as Human Language Technology by San Ma-
teo, CA: Morgan Kaufmann Publishers., pages 303–
308, Princeton, NJ.
G. Ngai and R. Florian. 2001. Transformation-Based
Learning in the Fast Lane. Proceedings of the Second
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 40-47,
Pittsburgh, PA, USA.
T. Pedersen. 2001. A Decision Tree of Bigrams is an
Accurate Predictor of Word Sense. In Proceedings
of the Second Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL-01), Pittsburgh, PA.
</reference>
<page confidence="0.999133">
345
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.446186">
<title confidence="0.999175">UBC-ALM: Combining k-NN with SVD for WSD</title>
<author confidence="0.927616">Eneko Agirre</author>
<author confidence="0.927616">Oier Lopez de_Lacalle</author>
<affiliation confidence="0.9988595">IXA NLP Group University of the Basque Country</affiliation>
<address confidence="0.687995">Donostia, Basque Country</address>
<abstract confidence="0.976641928571429">This work describes the University of the Basque Country system (UBC-ALM) for lexical sample and all-words WSD subtasks of SemEval-2007 task 17, where it performed in the second and fifth positions respectively. The system is based on a comof Neighbor classifiers, with each classifier learning from a distinct set of features: local features (syntactic, collocations features), topical features (bag-ofwords, domain information) and latent features learned from a reduced space using Singular Value Decomposition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Lopez de Lacalle</author>
<author>David Martinez</author>
</authors>
<title>Exploring feature spaces with svd and unlabeled data for Word Sense Disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings ofthe Conference on Recent Advances on Natural Language Processing (RANLP’05), Borovets,</booktitle>
<marker>Agirre, de Lacalle, Martinez, 2005</marker>
<rawString>E. Agirre, O.Lopez de Lacalle, and David Martinez. 2005. Exploring feature spaces with svd and unlabeled data for Word Sense Disambiguation. In Proceedings ofthe Conference on Recent Advances on Natural Language Processing (RANLP’05), Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Lopez de Lacalle</author>
<author>D Martinez</author>
</authors>
<title>Exploring feature spaces with svd and unlabeled data for Word Sense Disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the XXII Conference of Sociedad Espaola para el Procesamiento del Lenguaje Natural (SEPLN’06),</booktitle>
<location>Zaragoza,</location>
<marker>Agirre, de Lacalle, Martinez, 2006</marker>
<rawString>E. Agirre, O. Lopez de Lacalle, and D. Martinez. 2006. Exploring feature spaces with svd and unlabeled data for Word Sense Disambiguation. In Proceedings of the XXII Conference of Sociedad Espaola para el Procesamiento del Lenguaje Natural (SEPLN’06), Zaragoza, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="5142" citStr="Leech, 1992" startWordPosition="815" endWordPosition="816">xplored two different variants in order to build a matrix, and obtain the SVD features: SVD One Matrix per Target word (SVDOMT). For each word (i) we extracted all the features from the given training (test) corpus, (ii) built the feature-by-document matrix from training corpus, (iii) decomposed it with SVD, and (iv) project all the training (test) data. Note that this variant has been only used in the lexical sample task due to its costly computational requirements. SVD Single Matrix for All target words (SVDSMA): (i) we extracted bag-of-words features from the British National Corpus (BNC) (Leech, 1992), (ii) built the feature-by-document matrix, (iii) decompose it with SVD, and (iv) project all the data (train/test). 3 Learning Algorithm The machine learning (ML) algorithm presented in this section rely on the previously described features. Each occurrence or instance is represented by the features found in the context (fi). Given an occurrence of a word, the ML method below returns a nica de Catalunya weight for each sense (weight(sk)). The sense with maximum weight will be selected. We use a set of combination of the k-Nearest Neighbor (k-NN) to tag the target words in both the lexical sa</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>G. Leech. 1992. 100 million words of English: the British National Corpus. Language Research, 28(1):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavagli´a</author>
</authors>
<title>Integrating subject field codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International LREC Conference,</booktitle>
<location>Athens, Greece.</location>
<marker>Magnini, Cavagli´a, 2000</marker>
<rawString>B. Magnini and G. Cavagli´a. 2000. Integrating subject field codes into WordNet. In Proceedings of the Second International LREC Conference, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>C Leacock</author>
<author>R Tengi</author>
<author>R Bunker</author>
</authors>
<title>A Semantic Concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop. Distributed as Human Language Technology by</booktitle>
<pages>303--308</pages>
<publisher>Morgan Kaufmann Publishers.,</publisher>
<location>San Mateo, CA:</location>
<contexts>
<context position="10309" citStr="Miller et al., 1993" startWordPosition="1657" endWordPosition="1660">ombinations (due to CPU requirements, not all combination were feasible). 4. Choose the x best combination overall, and optimize word by word among these combination. We set x = 8 for this work, k was fixed in 5, and d = 200 (except with SVD-OMT[topic] which was d = 50). Table 1 shows the best results for 3 fold crossvalidation in SemEval lexical sample training corpus. The figures show that optimizing each word the performance increases 0.7 percentage points over the best combination. 4.2 Optimization for the all-words task To train the classifiers for the all-words task we just used Semcor (Miller et al., 1993). In (Agirre et al., 2006) we already tested our approach on the Senseval-3 all-words task. The best performance for the Senseval-3 all-words task was obtained with k = 5 and d = 200, but we decided to to perform further experiments to search for the best combination. We tested the performance of the combination of single k-NN training on Semcor and testing both on the Senseval-3 all-words data (cf. Table 2) and on the training data from SemEval-2007 lexical sample (cf. Table 3). Note that tables 2 and 3 show contradictory results. Given that in SemEval-2007 lexical sample 344 Combination rec.</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>G.A. Miller, C. Leacock, R. Tengi, and R.Bunker. 1993. A Semantic Concordance. In Proceedings of the ARPA Human Language Technology Workshop. Distributed as Human Language Technology by San Mateo, CA: Morgan Kaufmann Publishers., pages 303– 308, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ngai</author>
<author>R Florian</author>
</authors>
<title>Transformation-Based Learning in the Fast Lane.</title>
<date>2001</date>
<booktitle>Proceedings of the Second Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="3206" citStr="Ngai and Florian, 2001" startWordPosition="492" endWordPosition="495">. Bag-of-words features: we extract the lemmas of the content words in the whole context, and in a ±4-word window around the target. We also obtain salient bigrams in the context, with the methods and the software described in (Pedersen, 2001). Domain features: The WordNet Domains resource was used to identify the most relevant domains in the context. Following the relevance formula presented in (Magnini and Cavagli´a, 2000), we defined 2 feature types: (1) the most relevant domain, and (2) a list of domains above a predefined threshold3. 1The PoS tagging was performed with the fnTBL toolkit (Ngai and Florian, 2001). 2This software was kindly provided by David Yarowsky’s group, from Johns Hopkins University. 3The software to obtain the relevant domains was kindly provided by Gerard Escudero’s group, from Universitat Politec342 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 342–345, Prague, June 2007. c�2007 Association for Computational Linguistics 2.2 SVD features Singular Value Decomposition (SVD) is an interesting solution to the sparse data problem. This technique reduces the dimensions of the vectorial space finding correlations and collapsing features. I</context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>G. Ngai and R. Florian. 2001. Transformation-Based Learning in the Fast Lane. Proceedings of the Second Conference of the North American Chapter of the Association for Computational Linguistics, pages 40-47, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
</authors>
<title>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-01),</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="2826" citStr="Pedersen, 2001" startWordPosition="430" endWordPosition="431">ord-forms, or PoS tags1. Other local features are those formed with the previous/posterior lemma/word-form in the context. Syntactic dependencies: syntactic dependencies were extracted using heuristic patterns, and regular expressions defined with the PoS tags around the target2. The following relations were used: object, subject, noun-modifier, preposition, and sibling. Bag-of-words features: we extract the lemmas of the content words in the whole context, and in a ±4-word window around the target. We also obtain salient bigrams in the context, with the methods and the software described in (Pedersen, 2001). Domain features: The WordNet Domains resource was used to identify the most relevant domains in the context. Following the relevance formula presented in (Magnini and Cavagli´a, 2000), we defined 2 feature types: (1) the most relevant domain, and (2) a list of domains above a predefined threshold3. 1The PoS tagging was performed with the fnTBL toolkit (Ngai and Florian, 2001). 2This software was kindly provided by David Yarowsky’s group, from Johns Hopkins University. 3The software to obtain the relevant domains was kindly provided by Gerard Escudero’s group, from Universitat Politec342 Proc</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>T. Pedersen. 2001. A Decision Tree of Bigrams is an Accurate Predictor of Word Sense. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-01), Pittsburgh, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>