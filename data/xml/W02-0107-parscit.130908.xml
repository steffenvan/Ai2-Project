<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.063033">
<note confidence="0.987422333333333">
Proceedings of the Workshop on Effective Tools and Methodologies for Teaching
Natural Language Processing and Computational Linguistics, Philadelphia,
July 2002, pp. 46-53. Association for Computational Linguistics.
</note>
<title confidence="0.997234">
A niche at the nexus: situating an NLP curriculum interdisciplinarily
</title>
<author confidence="0.996726">
Deryle Lonsdale
</author>
<affiliation confidence="0.957679">
Department of Linguistics
Brigham Young University
</affiliation>
<address confidence="0.979615">
Provo, UT, USA, 84602
</address>
<email confidence="0.999616">
lonz@byu.edu
</email>
<sectionHeader confidence="0.995652" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935181818182">
This paper discusses the establishment and
implementation of a curriculum for teach-
ing NLP. At the core are two classes which
involve some theoretical background, ex-
tensive hands-on experience with state-of-
the-art technologies, and practical applica-
tion in the form of an intensive program-
ming project. Issues involving interdis-
ciplinary coordination, curriculum design,
and challenges in teaching this discipline
are discussed.
</bodyText>
<sectionHeader confidence="0.991402" genericHeader="method">
1 Institutional context
</sectionHeader>
<bodyText confidence="0.999945">
Our university initiated teaching of an NLP curricu-
lum in 1998. At the core are two classes which
both include some theoretical background, extensive
hands-on experience with state-of-the-art technolo-
gies, and practical application in the form of an in-
tensive programming project. They are meant to be
comparable in quality and scope to the best NLP
courses taught elsewhere. Each semester that these
classes were taught, the university administered an
anonymous survey to students to gauge their sat-
isfaction with the course and its contents. Issues
involving interdisciplinary coordination, curriculum
design, student satisfaction, and challenges unique to
teaching this discipline are presented in this paper.
First, though, necessary relevant background on the
campus and student demographics is presented.
The university is one of the largest private univer-
sities in the U.S. with an enrollment of about 30,000
(with 2,000 graduate students). Uncharacteristically,
almost three-fourths of the student body speaks a
non-English language.
The College of Humanities houses Linguistics,
Philosophy, and several language and literature de-
partments. Over 60 languages are taught within the
college to students from all disciplines. The Linguis-
tics Department offers undergraduate and master de-
grees (but no Ph.D.); over 150 undergraduate majors
are currently enrolled. The richness of the linguistic
environment in this college has a great bearing on the
results discussed in this paper. The College of Physi-
cal and Mathematical Sciences houses the Computer
Science (CS) Department (and several others teach-
ing the “hard” sciences). CS faculty strive to meet
the demands of flourishing undergrad and graduate
programs, and by necessity offer courses primarily
in the core areas of CS.
Until 1998 there was almost no interaction
between the CS and Linguistics departments, no
courses were taught in NLP or CL, and no research
brought together students across college boundaries.
Recently, however, the situation has improved. For
several reasons, NLP classes were initiated at the
university in 1998: faculty hires into Linguistics
held such interests, campus research projects needed
students with this type of experience, an NLP
infrastructure was necessary for internal work of the
university and its sponsor, and the improvement of
job prospects for Linguistics students was targeted.
Creating learning opportunities in NLP would help
on all of these accounts. This paper discusses the
two new NLP classes that have been developed and
taught during the last four years in response to these
needs.
Both courses are referred to as NLP classes rather
than as CL classes. One commonly expressed dis-
tinction between the two areas is that CL is more the-
oretical and cognitive in orientation, whereas NLP
has a more engineering and applied focus1. By this
criterion the two classes discussed in this paper are
clearly NLP-oriented.
</bodyText>
<sectionHeader confidence="0.948942" genericHeader="method">
2 NLP for the humanities
</sectionHeader>
<bodyText confidence="0.99994544">
For several years a program called Computers and
the Humanities (CHum) in the College of Human-
ities has provided a computer background for hu-
manities undergrads; this is necessary because CS
courses have traditionally been unavailable to non-
CS majors. The CHum track can lead to a minor
specialization for any humanities degree and attracts
students from all corners of the college. The CHum
offerings include a dozen classes meant to take stu-
dents from the most basic contexts (computer end-
user) through computer research tools use, basic pro-
gramming, and programming projects. More re-
cently the programming language taught has been
Visual Basic (though see below). In the last ten years
enrollment in this popular program has increased
tenfold.
Computer support for humanities students is laud-
able. Several labs are available, supplied with good
computational resources and adequate supervision
by student consultants. Many students also choose
to use their own computers at home or at work to
fulfill assignments. Occasionally off-campus com-
puter use for homework is not possible when propri-
etary software or corpora acquired by the university
for classroom use cannot be distributed off-campus.
</bodyText>
<subsectionHeader confidence="0.998521">
2.1 A parsing class
</subsectionHeader>
<bodyText confidence="0.999988055555556">
In recent years CHum course content has involved
increasingly more language processing. Twice
now, an intermediate-level class has been taught in
natural-language parsing and grammar engineering.
The class was taught the Unix and Emacs environ-
ments, basic LISP programming, and lexicon and
phrase-structure grammar development techniques;
all of these were new areas of focus for a CHum
class. One text was used for this class (Allen,
1995), and the associated parsers available from its
author were actively used by the students in their
coursework. The textbook was followed rather
closely and was quite accessible even to humanities
students at this level. Instruction involved two
80-minute lecture classes per week and was given in
a technologically enhanced (TELE) classroom fea-
turing an ethernet-connected instructional computer,
overhead LCD projection, multimedia devices, and
a touch-sensitive projection wall (smart-screen).
Lectures were delivered primarily via PowerPoint,
running parsing engines, and accessing commercial
and research project websites for materials and
discussion.
CHum parsing course evaluations were very good
to excellent (around 5.5-6.0 on a 7-point scale), ex-
ceeding college and department means across-the-
board in 30 categories. Lowest (i.e. average satis-
faction) ratings went to the text book used. The only
critical comments mentioned a desire for more in-
class lab time (a carry-over from prerequisite classes
which are held in computer lab classrooms with
a computer for every student). Whereas in lower
classes the focus was on learning particular program-
ming constructs, the parsing class content was more
abstract and required less classroom-time program-
ming demonstrations.
</bodyText>
<subsectionHeader confidence="0.999415">
2.2 A speech programming class
</subsectionHeader>
<bodyText confidence="0.999237875">
Though the parsing class was popular and success-
ful, it has not been taught in the last year and a
half. Instead, the intermediate-level CHum class has
focused on teaching speech applications program-
ming, again to meet infrastructure and pedagogical
needs. In this class2 the first third of the semester in-
cludes intensive instruction in phonetics, phonology,
and speech phenomena (using (J.M.Pickett, 1999)),
as well as in TCL programming. The balance of
the semester involves instruction on manipulating
a speech toolkit, developing and leveraging associ-
ated data resources (lexicons and corpora, phrase-
structure grammars, discourse moves), and under-
standing applications implementation (file formats,
speaker adaptation, interaction, agents, v-commerce,
speech translation).
</bodyText>
<footnote confidence="0.988879666666667">
1See, for example, Hans Uszkoreit’s website at
www.coli.uni-sb.de/&apos;hansu/what is cl.html.
2See humanities.byu.edu/classes/chum387dl/homepage.html.
</footnote>
<bodyText confidence="0.999956130434783">
Sample homework assignments include: running,
writing, and debugging simple TCL programs; de-
veloping and extending speech corpora and lexicons;
manipulating speech data with toolkits (e.g. PRAAT
(Boersma and Weenink, 1996) and SFS3); extending
a simple recognizer; and creating new speech-based
dialogue scenarios. For the latter tasks the OGI
toolkit (Cole, 1999) has proven particularly helpful,
and the students find the environment stimulating,
interesting, and versatile enough for a wide array of
experimentation from both the linguistics and toolkit
programming sides.
A final programming project is required; its de-
liverables include a proposal, interim report on
progress, final presentation and class demonstration,
and a final write-up including commented source
code and a paper discussing related work, the ap-
proach taken, and results. Sample final projects in-
clude speech interfaces for ubiquitous task-specific
access (e.g. intelligent kitchen appliances, automo-
bile navigation, and large XML-marked document
access), a call-center application for a dentist’s of-
fice, and a spoken-language identifier.
</bodyText>
<subsectionHeader confidence="0.993802">
2.3 Future CHum prospects
</subsectionHeader>
<bodyText confidence="0.999872342857143">
Computers and the Humanities course offerings are
dynamic and flexible, and more NLP-related content
is being offered beyond the parsing and speech tech-
nologies classes already mentioned. For example,
currently an advanced seminar class is (for the first
time) teaching XML and the annotation of linguistic
data.
It should be noted that recent CHum efforts have
been attracting CS students as well, who don’t cur-
rently have an outlet for NLP-related coursework in
their home department. This introduces a slight chal-
lenge for the instructor since an asymmetry exists
between humanities and CS students’ programming
abilities. To date, though, this has not proved very
problematic since the CS students were willing to
rely on their own initiative to apply classroom con-
cepts to more complex programming projects than
their humanities peers could attempt. Presumably in
the future if this becomes a problem a speech class
might be offered in the CS department, or a in higher
section in CHum.
An important and very recent development will
ensure further strengthening of NLP-related courses
within the College of Humanities. With the intro-
duction of a new campus-wide interdisciplinary un-
dergraduate minor in Computing and Information
(CpIn), the CS department has secured several new
tenure-track slots to be hosted externally by depart-
ments across campus. The College of Humani-
ties has been allocated one of these slots, and the
new faculty member will be housed within the Lin-
guistics Department. More course offerings at the
CS/Linguistics nexus will be possible in the near fu-
ture as a result. In turn, these classes will serve as
electives for CpIn students.
</bodyText>
<sectionHeader confidence="0.936411" genericHeader="method">
3 An advanced NLP course
</sectionHeader>
<bodyText confidence="0.99998525">
The linchpin of the NLP curriculum is the advanced
NLP course4. Hosted in the Linguistics department,
it also has been cross-listed as a CS course. It
is intended primarily for graduate students, though
it is open to advanced undergrads with requisite
background. Proficiency is assumed in at least one
programming language; in addition, a background
in algorithms, data structures, and some basic dis-
crete math is also required. Linguistics students and
CHum students with a solid background in linguis-
tics and good programming skills are accepted with
the instructor’s approval.
</bodyText>
<subsectionHeader confidence="0.999947">
3.1 Course goals and student demographics
</subsectionHeader>
<bodyText confidence="0.9999380625">
The course’s goals are: to teach how computational
techniques are used successfully in various areas of
NLP; to demonstrate by hands-on experience how to
use NLP tools in the performance of linguisticallyin-
teresting tasks; to demonstrate the application of a
novel, nontrivial approach to solving some aspect of
NLP-related computation; and to read, understand,
and assess current research literature and trends in
the relevant areas. The class is by design very broad
in scope, trying to address as many areas of NLP
as possible in a semester. The breadth of coverage
entails that the depth in any one area cannot be ad-
dressed fully; still, each topic is addressed at some
nontrivial level of detail. The topics are sequenced
in such a way as to build upon previously introduced
topics. For example, units on part-of-speech tagging
</bodyText>
<footnote confidence="0.615038">
3See www.phon.ucl.ac.uk/resource/sfs/. 4See humanities.byu.edu/classes/ling581dl/homepage.html.
</footnote>
<bodyText confidence="0.999916777777778">
and lexicons precede those on parsing, which in turn
precede those on speech understanding.
The class has been taught four times so far, with
an average of ten students per semester (plus inter-
ested faculty who sat in on classes without regis-
tering). Each class had an equal three-way balance
of students from CS, Linguistics, and other areas of
campus (physics, engineering, and even modern lan-
guages). Half of the students are undergrads and
half are graduates. Without exception, every student
had knowledge of at least one non-English language.
One of the challenges, but also unique opportunities,
of this class is to bring their disparate backgrounds
together in class discussions. For example class dis-
cussion, homework assignments, and final projects
often center around the students’ linguistic knowl-
edge and their application of principles learned to the
processing of non-English languages.
</bodyText>
<subsectionHeader confidence="0.999324">
3.2 Course content
</subsectionHeader>
<bodyText confidence="0.99987756">
Materials: Class lectures, discussions, and demon-
strations are based primarily on the content of two
NLP texts (Manning and Sch¨utze, 1999; Cole et al.,
1997) and several supplementary readings from the
Web5. The class is held thrice weekly in one-hour
sessions; it too is held in a TELE room. Each student
is required to “adopt” a lecture topic from the cur-
riculum: researching intensively this particular field,
preparing a lecture in consultation with the instruc-
tor, and teaching the class. Often students choose an
area that reflects the strengths of their background,
and as a result their lectures, materials and discus-
sions are of high quality.
Coursework: Students are generally free to do
their homework in any of the labs on campus or
on their own machines elsewhere. In some cases,
however, this is not possible due to licensing con-
straints on software needed for work in the course:
several resources require that the data or programs
only be used on an on-campus computer licensed to
the CS and/or Linguistics departments. For this rea-
son a Unix server has been acquired by the Linguis-
tics department and set up with the requisite software
to act as a classwork project server. Students can
also access the machine remotely to do their work
</bodyText>
<footnote confidence="0.591872666666667">
5Particularly useful are researchers’ personal and project
pages worldwide, the ACL NLP/CL Universe, and the arXiv
Computation and Language archive.
</footnote>
<bodyText confidence="0.999648456521739">
within these constraints. Students from the CS de-
partment have access to CS and Linguistics servers
where class-related resources can be used. Students
also have access to the campus supercomputer when
necessary for NLP projects, under the instructor’s
supervision.
Sample non-trivialhands-on and programming as-
signments are given weekly. They include such
topics as: work with various corpus manipulation
and annotation tools, use of various POS taggers
and their comparison (Brill, 1992; Tufis and Mason,
1998), development of morphophonological rules
in PC-Kimmo (Antworth, 1990), understanding and
manipulating content from WordNet databases (Fell-
baum, 1998), aligning bitext, using and evaluating
a machine translation system, developing a phrase-
structure grammar for syntactic and then semantic
chart parsing, experimenting with information re-
trieval, working with a speech toolkit to develop a
simple application, or developing knowledge for a
text generation engine (Tomita and Nyberg, 1988).
Tutorials are provided for for any necessary remedial
work that the student might need or desire in such
topics as using the Emacs editor, using Unix shell
scripts, or writing Perl or Tcl scripts.
Final project: A final programming project is
required, similar in scope to that described above
for the humanities course: close coordination with
the instructor, meeting milestones, documenting and
demonstrating the final product, and producing a
write-up of the significance and contributions of the
result. Of course, a much higher standard is required
of these advanced students. The student is free to
choose any relevant project, the programming lan-
guage(s) to be used, and the theoretical approach to
be taken. Sample final projects cover almost as wide
a range of topics as those covered in the curriculum6.
Linguisticsstudentsoften focus on the programmatic
development of knowledge sources whereas CS stu-
dents tend to engineer large-scale integrations of sev-
eral components in novel ways to address multi-
faceted issues. The most common tendency with all
students is to scope their work a little too ambitiously
at first; close consultation with the instructor is cru-
cial throughout the process. Teamwork is permitted,
and often a Linguistics student will pair up with a CS
</bodyText>
<footnote confidence="0.691323">
6See humanities.byu.edu/classes/ling581dl/egnlpprojs.htm.
</footnote>
<bodyText confidence="0.99968925">
one; this usually results in good knowledge and skill
transfer for both parties.
Evaluations: A three-hour (non-programming)
final exam is given which tests a knowledge of con-
cepts, algorithms, tools, procedures, and approaches
learned throught the semester. Class evaluation rat-
ings by students have improved over time, from
very good (5.1/7.0, first time offered) to exceptional
(6.7/7.0, last semester). The most frequent com-
plaints concerned amount of background that the
textbook assumes, and the lack of a midterm exami-
nation to help students gauge their progress.7
</bodyText>
<sectionHeader confidence="0.995759" genericHeader="method">
4 Other courses
</sectionHeader>
<bodyText confidence="0.995789258064516">
The infrastructure developed for teaching the two
courses mentioned above has also been successfully
applied in other classes as well. This section explains
how other classes have benefited from the NLP in-
frastructure being put in place.
A linguistics major undergrad survey course cov-
ers all of the core areas of linguistics (phonet-
ics, phonology, morphology, syntax, semantics, and
pragmatics) as well as several application areas.
Interestingly, one chapter of the textbook used in
this class even contains a very cursory overview of
computational linguistics (Klavans, 2001). Several
already-mentioned tools supporting the NLP classes
have also been used in the undergrad survey class: a
speech toolkit for sound wave manipulation, Word-
Net for lexical semantics, and a morphology engine
for English.
The Linguistics department offers a translation
theory and practice class, which traditionally attracts
up to 40 students with advanced capabilities in as
many as 25 languages per class section. With the
NLP infrastructurerecently developed, more techno-
logical exercises have been added to the curriculum
involving WordNet, bitext alignment, corpus and
lexicography tools, software localization (l10n) and
internationalization (i18n), machine-assisted trans-
lation, and machine translation systems (standalone
and web-based).
Other Linguistics classes also have recently lever-
aged the NLP infrastructure: a graduate seman-
tics class uses WordNet, a grad phonology class
</bodyText>
<footnote confidence="0.777029333333333">
7The instructor as a general rule does not give graduate
classes midterms; this is being rethought for the NLP class be-
cause of student comment.
</footnote>
<bodyText confidence="0.998978727272727">
works with a speech toolkit, a grad morphology class
uses a morphology engine, and a language modeling
seminar uses machine learning and other exemplar-
based methods. In the CS department, a series of
two 90-minute lectures in l10n and i18n has been
developed and is regularly presented to the grad
class in human-computer interation. Finally, sev-
eral foreign-language classes outside of the Linguis-
tics/CS area have used recently-assembled tools such
as corpora, part-of-speech taggers, and WordNets in
their own instruction and student assignments.
</bodyText>
<sectionHeader confidence="0.9954" genericHeader="method">
5 Extracurricular opportunities
</sectionHeader>
<bodyText confidence="0.999981">
As with any field of endeavor, chances to apply NLP
principles acquired in the classroom enrich greatly a
student’s learning experience and solidify the con-
cepts taught. Various outlets are provided on our
campus for experiencing the field.
</bodyText>
<subsectionHeader confidence="0.991658">
5.1 Research opportunities
</subsectionHeader>
<bodyText confidence="0.999929076923077">
Several research projects in both the Linguistics and
CS departments welcome undergrad and graduate
students. Weekly meetings involve keeping abreast
of current research literature, discussing project de-
liverables, and practicing conference paper presen-
tations. Groups where NLP-related work is done fo-
cus on: a data-driven, exemplar-based approach to
language modeling, integrating speech tools and dis-
course engines for task-oriented language learning,
extraction and integration of web-based document
content, technologies in human and machine trans-
lation, and cognitive modeling of natural-language
processing. Attendance is voluntary and no course
credit is given, but generally participation in project
work is enthusiastic and consistent, especially since
the NLP class was initiated.
One relevant change in the NLP offerings is wor-
thy of note: at first, the advanced NLP class was of-
fered in Winter semester, with many students treat-
ing it like a capstone class in their last semester.
They would then leave the school for further grad-
uate work or employment. Consequently the class
was recently moved from Winter to Fall, keeping the
students’ experience on campus for at least another
semester’s worth of project participation.
The university sponsors a mechanism for funding
undergraduate research projects. Proposals are re-
viewed by faculty, and the very competitive program
offers cash awards to the winners, who are required
to submit a written report synthesizing results ob-
tained. NLP students have had phenomenal success
in winning these awards and have gained valuable
experience with such projects as: morphological en-
gines for Cebuano and Farsi, cognitive modeling of
word-sense disambiguation, modeling task-oriented
discourse structure, and developing exemplar-based
machine translation. One advantage for NLP stu-
dents in this competition is that interdisciplinary re-
search is more likely to win funding.
</bodyText>
<subsectionHeader confidence="0.999563">
5.2 Beyond the campus
</subsectionHeader>
<bodyText confidence="0.999986318181818">
In its short time, the NLP environment has also pro-
vided several students with the requisite skills to be
placed in summer internships, most of them compet-
itive and paid. Students have been placed in an Euro-
pean MT project, a U.S. industrial NLP research lab,
another university’s language acquisition research
project, and a defense-funded research institute. Par-
ticularly appealing to their sponsors was the combi-
nation of proven foreign-language aptitudes with a
computational background and an understanding of
NLP techniques and tools.
Students whose project work is promising are
encouraged to present their work at conferences,
and several have presented their work at local, na-
tional, and international venues. Particularly note-
worthy projects have also served as the founda-
tion for peer-reviewed conference papers, under-
grad honors theses, and master’s theses. Success-
fully defended or ongoing theses in six departments
(Linguistics, Spanish/Portuguese, Asian Languages,
Language Acquisition, CS, and Physics) were initi-
ated in the NLP class.
</bodyText>
<sectionHeader confidence="0.921222" genericHeader="method">
6 Reflections on issues
</sectionHeader>
<bodyText confidence="0.999585">
Naturally, communication and cooperation across
department and college lines offers continual chal-
lenges for an interdisciplinary NLP curriculum.
Still, both sides recognize the unique linguisticskills
present in our students and the need to develop
an environment fostering wider NLP expertise on-
campus. Students, for their part, are attracted to such
offerings and seem satisfied.
</bodyText>
<subsectionHeader confidence="0.974968">
6.1 NLP and CL
</subsectionHeader>
<bodyText confidence="0.999996">
One as-yet unrealized goal is to develop and offer
a class in computational linguistics. Since Linguis-
tics doesn’t offer a Ph.D. degree, advanced grads are
not available to the program; current students typ-
ically do not have, in this teacher’s estimation, ap-
propriate background in computational complexity,
algorithmic analysis, AI techniques, formal logic,
math/stats, and formal linguistics to be adequately
prepared for an intensive CL class. To be sure, many
students have a background in some of these areas,
but not across a wide enough base to prove necessary
for theoretical CL work. This may change over time,
if a Ph.D. program is adopted; in the meantime, the
NLP courses do fill a necessary niche.
Another promising recent development might
help stimulate progress in this area: a newly hired
CS faculty member with a computational linguistics
background will begin teaching in that department
next year. Initially, it has been decided to offer two
somewhat complementary NLP classes. The CS
Department will offer one class, which will resem-
ble the advanced class discussed above, including
using that textbook. The other class, hosted by
Linguistics, will use a different text (Jurafsky and
Martin, 2000) with its content focused more on
the lexicon, morphology, speech, semantics, and
deep parsing. Overlap between the two courses
will be minimized as much as possible, with the
goal of broadening NLP content offerings. Whether
students will be attracted to a two-course sequence
of NLP remains an open question.
</bodyText>
<subsectionHeader confidence="0.993674">
6.2 Resource issues
</subsectionHeader>
<bodyText confidence="0.999976037735849">
A few obstacles and difficulties have been experi-
enced in spite of the overall positive aspects of im-
plementing an NLP curriculum mentioned in this pa-
per. A few of these are sketched in this section.
Texts: A frequent complaint from Linguistics (but
not CS) students enrolled in the advanced NLP class
is that textbook discussions almost invariably focus
on English. Since these students have all studied lin-
guistics intensively, including exposure to a large va-
riety of language typologies and nontrivial issues of
language analysis and complexity, these discussions
seem overly narrow and simplistic in many cases.
As mentioned earlier, classroom discussion can to
some extent elicit the wider-scope issues that interest
them. Certainly the vast array of Web-published re-
search findings also helps to fill this void. Still, sev-
eral students have voiced the desire for a comprehen-
sive NLP textbook that would address typologically
diverse issues.
Support: One clear disadvantage to hosting an
NLP class in the College of Humanities’ Linguis-
tics Department is one of comparatively limited re-
sources. CS resources for coursework computers,
research facilities, and student labs are noticeably
superior. Software acquisition and licensing proce-
dures, resolution of networking issues, and computer
support are more problematic in a non-CS context on
our campus. This is primarily a problem for CS stu-
dents, who occasionally chafe at the need to use non-
CS computers for coursework.
Tools: Tools accessibility is the greatest difficulty
perceived by this author in trying to develop co-
hesive and coherent course content. With its ad-
mittedly fast-paced progress, the field of NLP has
seen the development of a plethora of systems, tools,
modules, and development environments for a wide
array of tasks. Keeping track of these products,
and assessing their availability and appropriateness
for student use, is a daunting task. Several help-
ful resources assist this teacher besides those already
mentioned. Listservs like LinguistList8, Corpora9,
and LN10 notify subscribers of new NLP software.
There are even a few hierarchically-structured meta-
indexes for NLP tools: among others, the ACL Uni-
verse (mentioned above), Colibri11, and especially
the Natural Language Software Registry12. These
repositories, while helpful and greatly appreciated,
tend to be spotty and idiosyncratic at best in their
consideration of resources. Certainly a more system-
atic and comprehensive clearinghouse of NLP tools
would be a boon to educators and researchers, partic-
ularly if its contents could be individually annotated
for pedagogical applicability.
</bodyText>
<footnote confidence="0.9999132">
8See www.linguistlist.org.
9See www.hit.uib.no/corpora/.
10See www.biomath.jussieu.fr/LN/.
11See colibri.let.uu.nl/.
12See registry.dfki.de.
</footnote>
<subsectionHeader confidence="0.984012">
6.3 Teacher background
</subsectionHeader>
<bodyText confidence="0.999965580645161">
In a recent analysis of several years’ worth of linguis-
tics job announcements, Richard Sproat offered in-
teresting conclusions relevant to employment in lin-
guistics13. He notes “a prejudice that linguists are
not typically well trained in computational skills”,
and the fact that “relatively few linguistics programs
have got serious about providing their students with
extensive computational training.” In most current
CL courses, he claims, “there is little emphasis on
practical applications”. If these observations hold,
the NLP offerings discussed in this paper serve a
valuable purpose in providing Linguistics (and CS)
students much-needed practical experience in lan-
guage computation technologies.
Sproat also detects a trend in linguistics showing
“little effort to hire faculty members who have had
extensive industrial experience”, whereas in CS such
experience is often desired, valued, and sought. He
concludes that: “Departments thinking of building
up [CL] programs would be well advised to consider
people with industrial experience.” The present au-
thor’s 11-year experience in the NLP industry be-
fore pursuing graduate CL studies has proven invalu-
able in administering an NLP curriculum, facilitat-
ing such tasks as: advising students in their pro-
gramming projects; directing them in job searches
and internship opportunities; helping them propose
and establish research agendas; collaborating with
commercial and governmental sponsors; and deal-
ing with issues of software licensing and technology
transfer.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9995451">
Our experience has shown that a small core of NLP
classes housed in a Linguistics department and serv-
ing well-prepared students from other fields can
greatly enhance the research and pedagogical infras-
tructure across many disciplines on-campus, while
also preparing students for further grad studies or
careers in the industrial NLP sector. Though chal-
lenges and issues remain, NLP courses are enjoying
good enrollment, high satisfaction ratings, and ap-
preciable learning outcomes.
</bodyText>
<footnote confidence="0.847809">
13See www.research.att.com/rws/lingjobs.
</footnote>
<sectionHeader confidence="0.968186" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999385042553191">
James Allen. 1995. Natural Language Understanding.
Benjamin/Cummings Publishing.
Evan Antworth. 1990. PC-KIMMO: a two-level proec-
ssor for morphological analysis. Number 16 in Oc-
casional Publications in Academic Computing. Sum-
mer Institute of Linguistics, Dallas, TX. See also
www.sil.org/pckimmo/.
P. Boersma and D. J. M. Weenink. 1996. Praat, a system
for doing phonetics by computer, version 3.4. Techni-
cal Report 132, Institute of Phonetic Sciences, Amster-
dam. See also fonsg3.let.uva.nl/praat/.
Eric Brill. 1992. A simple rule-based part of speech tag-
ger. In Proceedings of the DARPA speech and natural
language workshop.
R. Cole, J. Mariani, H. Uszkoreit, A. Zaenen, and V. Zue,
editors. 1997. Survey of the State of the Art in Human
Language Technology. Cambridge University Press.
Ron Cole. 1999. Tools for research and education in
speech science. In Proceedings of the International
Conference of Phonetic Sciences, San Francisco, CA,
August. See also cslu.cse.ogi.edu/toolkit/index.html.
Christiane Fellbaum. 1998. WordNet: An electronic lex-
ical database. MIT Press, Cambridge, MA. See also
www.cogsci.princeton.edu/-wn/.
J.M.Pickett. 1999. The Acoustics of Speech Communica-
tion. Allyn &amp; Bacon.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Natural
Language Processing, Computational Linguistics, and
Speech Recognition. Prentice-Hall.
Judith Klavans. 2001. Computational linguistics. In
William O’Grady, John Archibald, Mark Aronoff, and
Janie Rees-Miller, editors, Contemporary Linguistics:
an Introduction. Bedford/St. Martin’s.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Process-
ing. The MIT Press.
Masaru Tomita and Eric H. Nyberg, 3rd. 1988. Gener-
ation Kit and Transformation Kit: Version 3.2 user’s
manual. Technical Report CMU-CMT-88-MEMO,
Carnegie Mellon Center for Machine Translation, Oc-
tober.
Dan Tufis and Oliver Mason. 1998. Tagging Romanian
texts: a case study for QTAG, a language-independent
probabilistic tagger. In Proceedings of the First Inter-
national Conference on Language Resources and Eval-
uation (LREC), Grenada, Spain, May.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.015482">
<title confidence="0.5394315">Proceedings of the Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics, Philadelphia, July 2002, pp. 46-53. Association for Computational Linguistics. A niche at the nexus: situating an NLP curriculum interdisciplinarily Deryle Department of</title>
<author confidence="0.748966">Brigham Young</author>
<affiliation confidence="0.768764">Provo, UT, USA,</affiliation>
<email confidence="0.999881">lonz@byu.edu</email>
<abstract confidence="0.999358004909986">This paper discusses the establishment and implementation of a curriculum for teaching NLP. At the core are two classes which involve some theoretical background, extensive hands-on experience with state-ofthe-art technologies, and practical application in the form of an intensive programming project. Issues involving interdisciplinary coordination, curriculum design, and challenges in teaching this discipline are discussed. 1 Institutional context Our university initiated teaching of an NLP curriculum in 1998. At the core are two classes which both include some theoretical background, extensive hands-on experience with state-of-the-art technologies, and practical application in the form of an intensive programming project. They are meant to be comparable in quality and scope to the best NLP courses taught elsewhere. Each semester that these classes were taught, the university administered an anonymous survey to students to gauge their satisfaction with the course and its contents. Issues involving interdisciplinary coordination, curriculum design, student satisfaction, and challenges unique to teaching this discipline are presented in this paper. First, though, necessary relevant background on the campus and student demographics is presented. The university is one of the largest private universities in the U.S. with an enrollment of about 30,000 (with 2,000 graduate students). Uncharacteristically, almost three-fourths of the student body speaks a non-English language. The College of Humanities houses Linguistics, Philosophy, and several language and literature departments. Over 60 languages are taught within the college to students from all disciplines. The Linguistics Department offers undergraduate and master degrees (but no Ph.D.); over 150 undergraduate majors are currently enrolled. The richness of the linguistic environment in this college has a great bearing on the results discussed in this paper. The College of Physical and Mathematical Sciences houses the Computer Science (CS) Department (and several others teaching the “hard” sciences). CS faculty strive to meet the demands of flourishing undergrad and graduate programs, and by necessity offer courses primarily in the core areas of CS. Until 1998 there was almost no interaction between the CS and Linguistics departments, no courses were taught in NLP or CL, and no research brought together students across college boundaries. Recently, however, the situation has improved. For several reasons, NLP classes were initiated at the university in 1998: faculty hires into Linguistics held such interests, campus research projects needed students with this type of experience, an NLP infrastructure was necessary for internal work of the university and its sponsor, and the improvement of job prospects for Linguistics students was targeted. Creating learning opportunities in NLP would help on all of these accounts. This paper discusses the two new NLP classes that have been developed and taught during the last four years in response to these needs. Both courses are referred to as NLP classes rather than as CL classes. One commonly expressed distinction between the two areas is that CL is more theoretical and cognitive in orientation, whereas NLP a more engineering and applied By this criterion the two classes discussed in this paper are clearly NLP-oriented. 2 NLP for the humanities For several years a program called Computers and the Humanities (CHum) in the College of Humanities has provided a computer background for humanities undergrads; this is necessary because CS courses have traditionally been unavailable to non- CS majors. The CHum track can lead to a minor specialization for any humanities degree and attracts students from all corners of the college. The CHum offerings include a dozen classes meant to take students from the most basic contexts (computer enduser) through computer research tools use, basic programming, and programming projects. More recently the programming language taught has been Visual Basic (though see below). In the last ten years enrollment in this popular program has increased tenfold. Computer support for humanities students is laudable. Several labs are available, supplied with good computational resources and adequate supervision by student consultants. Many students also choose to use their own computers at home or at work to fulfill assignments. Occasionally off-campus computer use for homework is not possible when proprietary software or corpora acquired by the university for classroom use cannot be distributed off-campus. 2.1 A parsing class In recent years CHum course content has involved increasingly more language processing. Twice now, an intermediate-level class has been taught in natural-language parsing and grammar engineering. The class was taught the Unix and Emacs environments, basic LISP programming, and lexicon and phrase-structure grammar development techniques; all of these were new areas of focus for a CHum class. One text was used for this class (Allen, 1995), and the associated parsers available from its author were actively used by the students in their coursework. The textbook was followed rather closely and was quite accessible even to humanities students at this level. Instruction involved two 80-minute lecture classes per week and was given in a technologically enhanced (TELE) classroom featuring an ethernet-connected instructional computer, overhead LCD projection, multimedia devices, and a touch-sensitive projection wall (smart-screen). Lectures were delivered primarily via PowerPoint, running parsing engines, and accessing commercial and research project websites for materials and discussion. CHum parsing course evaluations were very good to excellent (around 5.5-6.0 on a 7-point scale), exceeding college and department means across-theboard in 30 categories. Lowest (i.e. average satisfaction) ratings went to the text book used. The only critical comments mentioned a desire for more inclass lab time (a carry-over from prerequisite classes which are held in computer lab classrooms with a computer for every student). Whereas in lower classes the focus was on learning particular programming constructs, the parsing class content was more abstract and required less classroom-time programming demonstrations. 2.2 A speech programming class Though the parsing class was popular and successful, it has not been taught in the last year and a half. Instead, the intermediate-level CHum class has focused on teaching speech applications programming, again to meet infrastructure and pedagogical In this the first third of the semester includes intensive instruction in phonetics, phonology, and speech phenomena (using (J.M.Pickett, 1999)), as well as in TCL programming. The balance of the semester involves instruction on manipulating a speech toolkit, developing and leveraging associated data resources (lexicons and corpora, phrasestructure grammars, discourse moves), and understanding applications implementation (file formats, speaker adaptation, interaction, agents, v-commerce, speech translation). for example, Hans Uszkoreit’s website at is cl.html. humanities.byu.edu/classes/chum387dl/homepage.html. Sample homework assignments include: running, writing, and debugging simple TCL programs; developing and extending speech corpora and lexicons; manipulating speech data with toolkits (e.g. PRAAT and Weenink, 1996) and extending a simple recognizer; and creating new speech-based dialogue scenarios. For the latter tasks the OGI toolkit (Cole, 1999) has proven particularly helpful, and the students find the environment stimulating, interesting, and versatile enough for a wide array of experimentation from both the linguistics and toolkit programming sides. A final programming project is required; its deliverables include a proposal, interim report on progress, final presentation and class demonstration, and a final write-up including commented source code and a paper discussing related work, the approach taken, and results. Sample final projects include speech interfaces for ubiquitous task-specific access (e.g. intelligent kitchen appliances, automobile navigation, and large XML-marked document access), a call-center application for a dentist’s office, and a spoken-language identifier. 2.3 Future CHum prospects Computers and the Humanities course offerings are dynamic and flexible, and more NLP-related content is being offered beyond the parsing and speech technologies classes already mentioned. For example, currently an advanced seminar class is (for the first time) teaching XML and the annotation of linguistic data. It should be noted that recent CHum efforts have been attracting CS students as well, who don’t currently have an outlet for NLP-related coursework in their home department. This introduces a slight challenge for the instructor since an asymmetry exists between humanities and CS students’ programming abilities. To date, though, this has not proved very problematic since the CS students were willing to rely on their own initiative to apply classroom concepts to more complex programming projects than their humanities peers could attempt. Presumably in the future if this becomes a problem a speech class might be offered in the CS department, or a in higher section in CHum. An important and very recent development will ensure further strengthening of NLP-related courses within the College of Humanities. With the introduction of a new campus-wide interdisciplinary undergraduate minor in Computing and Information (CpIn), the CS department has secured several new tenure-track slots to be hosted externally by departments across campus. The College of Humanities has been allocated one of these slots, and the new faculty member will be housed within the Linguistics Department. More course offerings at the CS/Linguistics nexus will be possible in the near future as a result. In turn, these classes will serve as electives for CpIn students. 3 An advanced NLP course The linchpin of the NLP curriculum is the advanced Hosted in the Linguistics department, it also has been cross-listed as a CS course. It is intended primarily for graduate students, though it is open to advanced undergrads with requisite background. Proficiency is assumed in at least one programming language; in addition, a background in algorithms, data structures, and some basic discrete math is also required. Linguistics students and CHum students with a solid background in linguistics and good programming skills are accepted with the instructor’s approval. 3.1 Course goals and student demographics The course’s goals are: to teach how computational techniques are used successfully in various areas of NLP; to demonstrate by hands-on experience how to use NLP tools in the performance of linguisticallyinteresting tasks; to demonstrate the application of a novel, nontrivial approach to solving some aspect of NLP-related computation; and to read, understand, and assess current research literature and trends in the relevant areas. The class is by design very broad in scope, trying to address as many areas of NLP as possible in a semester. The breadth of coverage entails that the depth in any one area cannot be addressed fully; still, each topic is addressed at some nontrivial level of detail. The topics are sequenced in such a way as to build upon previously introduced topics. For example, units on part-of-speech tagging www.phon.ucl.ac.uk/resource/sfs/. humanities.byu.edu/classes/ling581dl/homepage.html. and lexicons precede those on parsing, which in turn precede those on speech understanding. The class has been taught four times so far, with an average of ten students per semester (plus interested faculty who sat in on classes without registering). Each class had an equal three-way balance of students from CS, Linguistics, and other areas of campus (physics, engineering, and even modern languages). Half of the students are undergrads and half are graduates. Without exception, every student had knowledge of at least one non-English language. One of the challenges, but also unique opportunities, of this class is to bring their disparate backgrounds together in class discussions. For example class discussion, homework assignments, and final projects often center around the students’ linguistic knowledge and their application of principles learned to the processing of non-English languages. 3.2 Course content Class lectures, discussions, and demonstrations are based primarily on the content of two NLP texts (Manning and Sch¨utze, 1999; Cole et al., 1997) and several supplementary readings from the The class is held thrice weekly in one-hour sessions; it too is held in a TELE room. Each student is required to “adopt” a lecture topic from the curriculum: researching intensively this particular field, preparing a lecture in consultation with the instructor, and teaching the class. Often students choose an area that reflects the strengths of their background, and as a result their lectures, materials and discussions are of high quality. Students are generally free to do their homework in any of the labs on campus or on their own machines elsewhere. In some cases, however, this is not possible due to licensing constraints on software needed for work in the course: several resources require that the data or programs only be used on an on-campus computer licensed to the CS and/or Linguistics departments. For this reason a Unix server has been acquired by the Linguistics department and set up with the requisite software to act as a classwork project server. Students can also access the machine remotely to do their work useful are researchers’ personal and project pages worldwide, the ACL NLP/CL Universe, and the arXiv Computation and Language archive. within these constraints. Students from the CS department have access to CS and Linguistics servers where class-related resources can be used. Students also have access to the campus supercomputer when necessary for NLP projects, under the instructor’s supervision. Sample non-trivialhands-on and programming assignments are given weekly. They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need or desire in such topics as using the Emacs editor, using Unix shell scripts, or writing Perl or Tcl scripts. A final programming project is required, similar in scope to that described above for the humanities course: close coordination with the instructor, meeting milestones, documenting and demonstrating the final product, and producing a write-up of the significance and contributions of the result. Of course, a much higher standard is required of these advanced students. The student is free to choose any relevant project, the programming language(s) to be used, and the theoretical approach to be taken. Sample final projects cover almost as wide range of topics as those covered in the Linguisticsstudentsoften focus on the programmatic development of knowledge sources whereas CS students tend to engineer large-scale integrations of several components in novel ways to address multifaceted issues. The most common tendency with all students is to scope their work a little too ambitiously at first; close consultation with the instructor is crucial throughout the process. Teamwork is permitted, and often a Linguistics student will pair up with a CS humanities.byu.edu/classes/ling581dl/egnlpprojs.htm. one; this usually results in good knowledge and skill transfer for both parties. A three-hour (non-programming) final exam is given which tests a knowledge of concepts, algorithms, tools, procedures, and approaches learned throught the semester. Class evaluation ratings by students have improved over time, from very good (5.1/7.0, first time offered) to exceptional (6.7/7.0, last semester). The most frequent complaints concerned amount of background that the textbook assumes, and the lack of a midterm examito help students gauge their 4 Other courses The infrastructure developed for teaching the two courses mentioned above has also been successfully applied in other classes as well. This section explains how other classes have benefited from the NLP infrastructure being put in place. A linguistics major undergrad survey course covers all of the core areas of linguistics (phonetics, phonology, morphology, syntax, semantics, and pragmatics) as well as several application areas. Interestingly, one chapter of the textbook used in this class even contains a very cursory overview of computational linguistics (Klavans, 2001). Several already-mentioned tools supporting the NLP classes have also been used in the undergrad survey class: a speech toolkit for sound wave manipulation, Word- Net for lexical semantics, and a morphology engine for English. The Linguistics department offers a translation theory and practice class, which traditionally attracts up to 40 students with advanced capabilities in as many as 25 languages per class section. With the NLP infrastructurerecently developed, more technological exercises have been added to the curriculum involving WordNet, bitext alignment, corpus and lexicography tools, software localization (l10n) and internationalization (i18n), machine-assisted translation, and machine translation systems (standalone and web-based). Other Linguistics classes also have recently leveraged the NLP infrastructure: a graduate semantics class uses WordNet, a grad phonology class instructor as a general rule does not give graduate classes midterms; this is being rethought for the NLP class because of student comment. works with a speech toolkit, a grad morphology class uses a morphology engine, and a language modeling seminar uses machine learning and other exemplarbased methods. In the CS department, a series of two 90-minute lectures in l10n and i18n has been developed and is regularly presented to the grad class in human-computer interation. Finally, several foreign-language classes outside of the Linguistics/CS area have used recently-assembled tools such as corpora, part-of-speech taggers, and WordNets in their own instruction and student assignments. 5 Extracurricular opportunities As with any field of endeavor, chances to apply NLP principles acquired in the classroom enrich greatly a student’s learning experience and solidify the concepts taught. Various outlets are provided on our campus for experiencing the field. 5.1 Research opportunities Several research projects in both the Linguistics and CS departments welcome undergrad and graduate students. Weekly meetings involve keeping abreast of current research literature, discussing project deliverables, and practicing conference paper presentations. Groups where NLP-related work is done focus on: a data-driven, exemplar-based approach to language modeling, integrating speech tools and discourse engines for task-oriented language learning, extraction and integration of web-based document content, technologies in human and machine translation, and cognitive modeling of natural-language processing. Attendance is voluntary and no course credit is given, but generally participation in project work is enthusiastic and consistent, especially since the NLP class was initiated. One relevant change in the NLP offerings is worthy of note: at first, the advanced NLP class was offered in Winter semester, with many students treating it like a capstone class in their last semester. They would then leave the school for further graduate work or employment. Consequently the class was recently moved from Winter to Fall, keeping the students’ experience on campus for at least another semester’s worth of project participation. The university sponsors a mechanism for funding undergraduate research projects. Proposals are reviewed by faculty, and the very competitive program offers cash awards to the winners, who are required to submit a written report synthesizing results obtained. NLP students have had phenomenal success in winning these awards and have gained valuable experience with such projects as: morphological engines for Cebuano and Farsi, cognitive modeling of word-sense disambiguation, modeling task-oriented discourse structure, and developing exemplar-based machine translation. One advantage for NLP students in this competition is that interdisciplinary research is more likely to win funding. 5.2 Beyond the campus In its short time, the NLP environment has also provided several students with the requisite skills to be placed in summer internships, most of them competitive and paid. Students have been placed in an European MT project, a U.S. industrial NLP research lab, another university’s language acquisition research project, and a defense-funded research institute. Particularly appealing to their sponsors was the combination of proven foreign-language aptitudes with a computational background and an understanding of NLP techniques and tools. Students whose project work is promising are encouraged to present their work at conferences, and several have presented their work at local, national, and international venues. Particularly noteworthy projects have also served as the foundation for peer-reviewed conference papers, undergrad honors theses, and master’s theses. Successfully defended or ongoing theses in six departments (Linguistics, Spanish/Portuguese, Asian Languages, Language Acquisition, CS, and Physics) were initiated in the NLP class. 6 Reflections on issues Naturally, communication and cooperation across department and college lines offers continual challenges for an interdisciplinary NLP curriculum. Still, both sides recognize the unique linguisticskills present in our students and the need to develop an environment fostering wider NLP expertise oncampus. Students, for their part, are attracted to such offerings and seem satisfied. 6.1 NLP and CL One as-yet unrealized goal is to develop and offer a class in computational linguistics. Since Linguistics doesn’t offer a Ph.D. degree, advanced grads are not available to the program; current students typically do not have, in this teacher’s estimation, appropriate background in computational complexity, algorithmic analysis, AI techniques, formal logic, math/stats, and formal linguistics to be adequately prepared for an intensive CL class. To be sure, many students have a background in some of these areas, but not across a wide enough base to prove necessary for theoretical CL work. This may change over time, if a Ph.D. program is adopted; in the meantime, the NLP courses do fill a necessary niche. Another promising recent development might help stimulate progress in this area: a newly hired CS faculty member with a computational linguistics background will begin teaching in that department next year. Initially, it has been decided to offer two somewhat complementary NLP classes. The CS Department will offer one class, which will resemble the advanced class discussed above, including using that textbook. The other class, hosted by Linguistics, will use a different text (Jurafsky and Martin, 2000) with its content focused more on the lexicon, morphology, speech, semantics, and deep parsing. Overlap between the two courses will be minimized as much as possible, with the goal of broadening NLP content offerings. Whether students will be attracted to a two-course sequence of NLP remains an open question. 6.2 Resource issues A few obstacles and difficulties have been experienced in spite of the overall positive aspects of implementing an NLP curriculum mentioned in this paper. A few of these are sketched in this section. A frequent complaint from Linguistics (but not CS) students enrolled in the advanced NLP class is that textbook discussions almost invariably focus on English. Since these students have all studied linguistics intensively, including exposure to a large variety of language typologies and nontrivial issues of language analysis and complexity, these discussions seem overly narrow and simplistic in many cases. As mentioned earlier, classroom discussion can to some extent elicit the wider-scope issues that interest them. Certainly the vast array of Web-published research findings also helps to fill this void. Still, several students have voiced the desire for a comprehensive NLP textbook that would address typologically diverse issues. One clear disadvantage to hosting an NLP class in the College of Humanities’ Linguistics Department is one of comparatively limited resources. CS resources for coursework computers, research facilities, and student labs are noticeably superior. Software acquisition and licensing procedures, resolution of networking issues, and computer support are more problematic in a non-CS context on our campus. This is primarily a problem for CS students, who occasionally chafe at the need to use non- CS computers for coursework. Tools accessibility is the greatest difficulty perceived by this author in trying to develop cohesive and coherent course content. With its admittedly fast-paced progress, the field of NLP has seen the development of a plethora of systems, tools, modules, and development environments for a wide array of tasks. Keeping track of these products, and assessing their availability and appropriateness for student use, is a daunting task. Several helpful resources assist this teacher besides those already Listservs like notify subscribers of new NLP software. There are even a few hierarchically-structured metaindexes for NLP tools: among others, the ACL Uni- (mentioned above), and especially Natural Language Software These repositories, while helpful and greatly appreciated, tend to be spotty and idiosyncratic at best in their consideration of resources. Certainly a more systematic and comprehensive clearinghouse of NLP tools would be a boon to educators and researchers, particularly if its contents could be individually annotated for pedagogical applicability. www.linguistlist.org. www.hit.uib.no/corpora/. www.biomath.jussieu.fr/LN/. colibri.let.uu.nl/. registry.dfki.de. 6.3 Teacher background In a recent analysis of several years’ worth of linguistics job announcements, Richard Sproat offered interesting conclusions relevant to employment in lin- He notes “a prejudice that linguists are not typically well trained in computational skills”, and the fact that “relatively few linguistics programs have got serious about providing their students with extensive computational training.” In most current CL courses, he claims, “there is little emphasis on practical applications”. If these observations hold, the NLP offerings discussed in this paper serve a valuable purpose in providing Linguistics (and CS) students much-needed practical experience in language computation technologies. Sproat also detects a trend in linguistics showing “little effort to hire faculty members who have had extensive industrial experience”, whereas in CS such experience is often desired, valued, and sought. He concludes that: “Departments thinking of building up [CL] programs would be well advised to consider people with industrial experience.” The present author’s 11-year experience in the NLP industry before pursuing graduate CL studies has proven invaluable in administering an NLP curriculum, facilitating such tasks as: advising students in their programming projects; directing them in job searches and internship opportunities; helping them propose and establish research agendas; collaborating with commercial and governmental sponsors; and dealing with issues of software licensing and technology transfer. 7 Conclusion Our experience has shown that a small core of NLP classes housed in a Linguistics department and serving well-prepared students from other fields can greatly enhance the research and pedagogical infrastructure across many disciplines on-campus, while also preparing students for further grad studies or careers in the industrial NLP sector. Though challenges and issues remain, NLP courses are enjoying good enrollment, high satisfaction ratings, and appreciable learning outcomes. www.research.att.com/rws/lingjobs.</abstract>
<note confidence="0.672258384615385">References Allen. 1995. Language Benjamin/Cummings Publishing. Antworth. 1990. a two-level proecfor morphological Number 16 in Occasional Publications in Academic Computing. Summer Institute of Linguistics, Dallas, TX. See also www.sil.org/pckimmo/. P. Boersma and D. J. M. Weenink. 1996. Praat, a system for doing phonetics by computer, version 3.4. Technical Report 132, Institute of Phonetic Sciences, Amsterdam. See also fonsg3.let.uva.nl/praat/. Eric Brill. 1992. A simple rule-based part of speech tag- In of the DARPA speech and natural R. Cole, J. Mariani, H. Uszkoreit, A. Zaenen, and V. Zue, 1997. of the State of the Art in Human Cambridge University Press. Ron Cole. 1999. Tools for research and education in science. In of the International of Phonetic San Francisco, CA, August. See also cslu.cse.ogi.edu/toolkit/index.html. Fellbaum. 1998. An electronic lex- MIT Press, Cambridge, MA. See also 1999. Acoustics of Speech Communica- Allyn &amp; Bacon. Jurafsky and James H. Martin. 2000.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Natural Language Understanding.</title>
<date>1995</date>
<publisher>Benjamin/Cummings Publishing.</publisher>
<contexts>
<context position="5461" citStr="Allen, 1995" startWordPosition="822" endWordPosition="823">er use for homework is not possible when proprietary software or corpora acquired by the university for classroom use cannot be distributed off-campus. 2.1 A parsing class In recent years CHum course content has involved increasingly more language processing. Twice now, an intermediate-level class has been taught in natural-language parsing and grammar engineering. The class was taught the Unix and Emacs environments, basic LISP programming, and lexicon and phrase-structure grammar development techniques; all of these were new areas of focus for a CHum class. One text was used for this class (Allen, 1995), and the associated parsers available from its author were actively used by the students in their coursework. The textbook was followed rather closely and was quite accessible even to humanities students at this level. Instruction involved two 80-minute lecture classes per week and was given in a technologically enhanced (TELE) classroom featuring an ethernet-connected instructional computer, overhead LCD projection, multimedia devices, and a touch-sensitive projection wall (smart-screen). Lectures were delivered primarily via PowerPoint, running parsing engines, and accessing commercial and </context>
</contexts>
<marker>Allen, 1995</marker>
<rawString>James Allen. 1995. Natural Language Understanding. Benjamin/Cummings Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan Antworth</author>
</authors>
<title>PC-KIMMO: a two-level proecssor for morphological analysis.</title>
<date>1990</date>
<journal>Number</journal>
<booktitle>in Occasional Publications in Academic Computing. Summer Institute of Linguistics,</booktitle>
<volume>16</volume>
<location>Dallas, TX.</location>
<note>See also www.sil.org/pckimmo/.</note>
<contexts>
<context position="14986" citStr="Antworth, 1990" startWordPosition="2257" endWordPosition="2258">omputation and Language archive. within these constraints. Students from the CS department have access to CS and Linguistics servers where class-related resources can be used. Students also have access to the campus supercomputer when necessary for NLP projects, under the instructor’s supervision. Sample non-trivialhands-on and programming assignments are given weekly. They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need or desire in such topics as using the Emacs editor, using Unix shell scripts, or writing Perl </context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>Evan Antworth. 1990. PC-KIMMO: a two-level proecssor for morphological analysis. Number 16 in Occasional Publications in Academic Computing. Summer Institute of Linguistics, Dallas, TX. See also www.sil.org/pckimmo/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boersma</author>
<author>D J M Weenink</author>
</authors>
<title>Praat, a system for doing phonetics by computer, version 3.4.</title>
<date>1996</date>
<tech>Technical Report 132,</tech>
<institution>Institute of Phonetic Sciences,</institution>
<location>Amsterdam.</location>
<note>See also fonsg3.let.uva.nl/praat/.</note>
<contexts>
<context position="7917" citStr="Boersma and Weenink, 1996" startWordPosition="1161" endWordPosition="1164">t, developing and leveraging associated data resources (lexicons and corpora, phrasestructure grammars, discourse moves), and understanding applications implementation (file formats, speaker adaptation, interaction, agents, v-commerce, speech translation). 1See, for example, Hans Uszkoreit’s website at www.coli.uni-sb.de/&apos;hansu/what is cl.html. 2See humanities.byu.edu/classes/chum387dl/homepage.html. Sample homework assignments include: running, writing, and debugging simple TCL programs; developing and extending speech corpora and lexicons; manipulating speech data with toolkits (e.g. PRAAT (Boersma and Weenink, 1996) and SFS3); extending a simple recognizer; and creating new speech-based dialogue scenarios. For the latter tasks the OGI toolkit (Cole, 1999) has proven particularly helpful, and the students find the environment stimulating, interesting, and versatile enough for a wide array of experimentation from both the linguistics and toolkit programming sides. A final programming project is required; its deliverables include a proposal, interim report on progress, final presentation and class demonstration, and a final write-up including commented source code and a paper discussing related work, the ap</context>
</contexts>
<marker>Boersma, Weenink, 1996</marker>
<rawString>P. Boersma and D. J. M. Weenink. 1996. Praat, a system for doing phonetics by computer, version 3.4. Technical Report 132, Institute of Phonetic Sciences, Amsterdam. See also fonsg3.let.uva.nl/praat/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the DARPA speech and natural language workshop.</booktitle>
<contexts>
<context position="14892" citStr="Brill, 1992" startWordPosition="2245" endWordPosition="2246">esearchers’ personal and project pages worldwide, the ACL NLP/CL Universe, and the arXiv Computation and Language archive. within these constraints. Students from the CS department have access to CS and Linguistics servers where class-related resources can be used. Students also have access to the campus supercomputer when necessary for NLP projects, under the instructor’s supervision. Sample non-trivialhands-on and programming assignments are given weekly. They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need </context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Eric Brill. 1992. A simple rule-based part of speech tagger. In Proceedings of the DARPA speech and natural language workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cole</author>
<author>J Mariani</author>
<author>H Uszkoreit</author>
<author>A Zaenen</author>
<author>V Zue</author>
<author>editors</author>
</authors>
<date>1997</date>
<booktitle>Survey of the State of the Art in Human Language Technology.</booktitle>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="13158" citStr="Cole et al., 1997" startWordPosition="1966" endWordPosition="1969">s. Without exception, every student had knowledge of at least one non-English language. One of the challenges, but also unique opportunities, of this class is to bring their disparate backgrounds together in class discussions. For example class discussion, homework assignments, and final projects often center around the students’ linguistic knowledge and their application of principles learned to the processing of non-English languages. 3.2 Course content Materials: Class lectures, discussions, and demonstrations are based primarily on the content of two NLP texts (Manning and Sch¨utze, 1999; Cole et al., 1997) and several supplementary readings from the Web5. The class is held thrice weekly in one-hour sessions; it too is held in a TELE room. Each student is required to “adopt” a lecture topic from the curriculum: researching intensively this particular field, preparing a lecture in consultation with the instructor, and teaching the class. Often students choose an area that reflects the strengths of their background, and as a result their lectures, materials and discussions are of high quality. Coursework: Students are generally free to do their homework in any of the labs on campus or on their own</context>
</contexts>
<marker>Cole, Mariani, Uszkoreit, Zaenen, Zue, editors, 1997</marker>
<rawString>R. Cole, J. Mariani, H. Uszkoreit, A. Zaenen, and V. Zue, editors. 1997. Survey of the State of the Art in Human Language Technology. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Cole</author>
</authors>
<title>Tools for research and education in speech science.</title>
<date>1999</date>
<booktitle>In Proceedings of the International Conference of Phonetic Sciences,</booktitle>
<location>San Francisco, CA,</location>
<note>See also cslu.cse.ogi.edu/toolkit/index.html.</note>
<contexts>
<context position="8059" citStr="Cole, 1999" startWordPosition="1184" endWordPosition="1185">ementation (file formats, speaker adaptation, interaction, agents, v-commerce, speech translation). 1See, for example, Hans Uszkoreit’s website at www.coli.uni-sb.de/&apos;hansu/what is cl.html. 2See humanities.byu.edu/classes/chum387dl/homepage.html. Sample homework assignments include: running, writing, and debugging simple TCL programs; developing and extending speech corpora and lexicons; manipulating speech data with toolkits (e.g. PRAAT (Boersma and Weenink, 1996) and SFS3); extending a simple recognizer; and creating new speech-based dialogue scenarios. For the latter tasks the OGI toolkit (Cole, 1999) has proven particularly helpful, and the students find the environment stimulating, interesting, and versatile enough for a wide array of experimentation from both the linguistics and toolkit programming sides. A final programming project is required; its deliverables include a proposal, interim report on progress, final presentation and class demonstration, and a final write-up including commented source code and a paper discussing related work, the approach taken, and results. Sample final projects include speech interfaces for ubiquitous task-specific access (e.g. intelligent kitchen appli</context>
</contexts>
<marker>Cole, 1999</marker>
<rawString>Ron Cole. 1999. Tools for research and education in speech science. In Proceedings of the International Conference of Phonetic Sciences, San Francisco, CA, August. See also cslu.cse.ogi.edu/toolkit/index.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<note>See also www.cogsci.princeton.edu/-wn/.</note>
<contexts>
<context position="15066" citStr="Fellbaum, 1998" startWordPosition="2266" endWordPosition="2268">department have access to CS and Linguistics servers where class-related resources can be used. Students also have access to the campus supercomputer when necessary for NLP projects, under the instructor’s supervision. Sample non-trivialhands-on and programming assignments are given weekly. They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need or desire in such topics as using the Emacs editor, using Unix shell scripts, or writing Perl or Tcl scripts. Final project: A final programming project is required, similar </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An electronic lexical database. MIT Press, Cambridge, MA. See also www.cogsci.princeton.edu/-wn/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Pickett</author>
</authors>
<title>The Acoustics of Speech Communication.</title>
<date>1999</date>
<publisher>Allyn &amp; Bacon.</publisher>
<contexts>
<context position="7177" citStr="Pickett, 1999" startWordPosition="1074" endWordPosition="1075">r classes the focus was on learning particular programming constructs, the parsing class content was more abstract and required less classroom-time programming demonstrations. 2.2 A speech programming class Though the parsing class was popular and successful, it has not been taught in the last year and a half. Instead, the intermediate-level CHum class has focused on teaching speech applications programming, again to meet infrastructure and pedagogical needs. In this class2 the first third of the semester includes intensive instruction in phonetics, phonology, and speech phenomena (using (J.M.Pickett, 1999)), as well as in TCL programming. The balance of the semester involves instruction on manipulating a speech toolkit, developing and leveraging associated data resources (lexicons and corpora, phrasestructure grammars, discourse moves), and understanding applications implementation (file formats, speaker adaptation, interaction, agents, v-commerce, speech translation). 1See, for example, Hans Uszkoreit’s website at www.coli.uni-sb.de/&apos;hansu/what is cl.html. 2See humanities.byu.edu/classes/chum387dl/homepage.html. Sample homework assignments include: running, writing, and debugging simple TCL pr</context>
</contexts>
<marker>Pickett, 1999</marker>
<rawString>J.M.Pickett. 1999. The Acoustics of Speech Communication. Allyn &amp; Bacon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="24440" citStr="Jurafsky and Martin, 2000" startWordPosition="3667" endWordPosition="3670"> This may change over time, if a Ph.D. program is adopted; in the meantime, the NLP courses do fill a necessary niche. Another promising recent development might help stimulate progress in this area: a newly hired CS faculty member with a computational linguistics background will begin teaching in that department next year. Initially, it has been decided to offer two somewhat complementary NLP classes. The CS Department will offer one class, which will resemble the advanced class discussed above, including using that textbook. The other class, hosted by Linguistics, will use a different text (Jurafsky and Martin, 2000) with its content focused more on the lexicon, morphology, speech, semantics, and deep parsing. Overlap between the two courses will be minimized as much as possible, with the goal of broadening NLP content offerings. Whether students will be attracted to a two-course sequence of NLP remains an open question. 6.2 Resource issues A few obstacles and difficulties have been experienced in spite of the overall positive aspects of implementing an NLP curriculum mentioned in this paper. A few of these are sketched in this section. Texts: A frequent complaint from Linguistics (but not CS) students en</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Klavans</author>
</authors>
<title>Computational linguistics. In</title>
<date>2001</date>
<editor>William O’Grady, John Archibald, Mark Aronoff, and Janie Rees-Miller, editors, Contemporary</editor>
<publisher>Bedford/St. Martin’s.</publisher>
<contexts>
<context position="17910" citStr="Klavans, 2001" startWordPosition="2696" endWordPosition="2697">ge their progress.7 4 Other courses The infrastructure developed for teaching the two courses mentioned above has also been successfully applied in other classes as well. This section explains how other classes have benefited from the NLP infrastructure being put in place. A linguistics major undergrad survey course covers all of the core areas of linguistics (phonetics, phonology, morphology, syntax, semantics, and pragmatics) as well as several application areas. Interestingly, one chapter of the textbook used in this class even contains a very cursory overview of computational linguistics (Klavans, 2001). Several already-mentioned tools supporting the NLP classes have also been used in the undergrad survey class: a speech toolkit for sound wave manipulation, WordNet for lexical semantics, and a morphology engine for English. The Linguistics department offers a translation theory and practice class, which traditionally attracts up to 40 students with advanced capabilities in as many as 25 languages per class section. With the NLP infrastructurerecently developed, more technological exercises have been added to the curriculum involving WordNet, bitext alignment, corpus and lexicography tools, s</context>
</contexts>
<marker>Klavans, 2001</marker>
<rawString>Judith Klavans. 2001. Computational linguistics. In William O’Grady, John Archibald, Mark Aronoff, and Janie Rees-Miller, editors, Contemporary Linguistics: an Introduction. Bedford/St. Martin’s.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press.</publisher>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaru Tomita</author>
<author>Eric H Nyberg</author>
</authors>
<title>Generation Kit and Transformation Kit: Version 3.2 user’s manual.</title>
<date>1988</date>
<tech>Technical Report CMU-CMT-88-MEMO,</tech>
<institution>Carnegie Mellon Center for Machine Translation,</institution>
<contexts>
<context position="15403" citStr="Tomita and Nyberg, 1988" startWordPosition="2313" endWordPosition="2316">th various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need or desire in such topics as using the Emacs editor, using Unix shell scripts, or writing Perl or Tcl scripts. Final project: A final programming project is required, similar in scope to that described above for the humanities course: close coordination with the instructor, meeting milestones, documenting and demonstrating the final product, and producing a write-up of the significance and contributions of the result. Of course, a much higher standard is required of these advanced students. The student is f</context>
</contexts>
<marker>Tomita, Nyberg, 1988</marker>
<rawString>Masaru Tomita and Eric H. Nyberg, 3rd. 1988. Generation Kit and Transformation Kit: Version 3.2 user’s manual. Technical Report CMU-CMT-88-MEMO, Carnegie Mellon Center for Machine Translation, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufis</author>
<author>Oliver Mason</author>
</authors>
<title>Tagging Romanian texts: a case study for QTAG, a language-independent probabilistic tagger.</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Grenada, Spain,</location>
<contexts>
<context position="14916" citStr="Tufis and Mason, 1998" startWordPosition="2247" endWordPosition="2250">ersonal and project pages worldwide, the ACL NLP/CL Universe, and the arXiv Computation and Language archive. within these constraints. Students from the CS department have access to CS and Linguistics servers where class-related resources can be used. Students also have access to the campus supercomputer when necessary for NLP projects, under the instructor’s supervision. Sample non-trivialhands-on and programming assignments are given weekly. They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison (Brill, 1992; Tufis and Mason, 1998), development of morphophonological rules in PC-Kimmo (Antworth, 1990), understanding and manipulating content from WordNet databases (Fellbaum, 1998), aligning bitext, using and evaluating a machine translation system, developing a phrasestructure grammar for syntactic and then semantic chart parsing, experimenting with information retrieval, working with a speech toolkit to develop a simple application, or developing knowledge for a text generation engine (Tomita and Nyberg, 1988). Tutorials are provided for for any necessary remedial work that the student might need or desire in such topics</context>
</contexts>
<marker>Tufis, Mason, 1998</marker>
<rawString>Dan Tufis and Oliver Mason. 1998. Tagging Romanian texts: a case study for QTAG, a language-independent probabilistic tagger. In Proceedings of the First International Conference on Language Resources and Evaluation (LREC), Grenada, Spain, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>