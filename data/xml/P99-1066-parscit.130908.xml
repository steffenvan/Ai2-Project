<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004870">
<title confidence="0.9600365">
Automatic Compensation for Parser Figure-of-Merit Flaws*
Don Blaheta and Eugene Charniak
</title>
<email confidence="0.841856">
fdpb,ecl@cs.brown.edu
</email>
<affiliation confidence="0.885003">
Department of Computer Science
</affiliation>
<address confidence="0.450093">
Box 1910 / 115 Waterman St.-4th floor
Brown University
Providence, RI 02912
</address>
<sectionHeader confidence="0.962184" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999218">
Best-first chart parsing utilises a figure of
merit (FOM) to efficiently guide a parse by
first attending to those edges judged better.
In the past it has usually been static; this
paper will show that with some extra infor-
mation, a parser can compensate for FOM
flaws which otherwise slow it down. Our re-
sults are faster than the prior best by a fac-
tor of 2.5; and the speedup is won with no
significant decrease in parser accuracy.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939444444445">
Sentence parsing is a task which is tra-
ditionally rather computationally intensive.
The best known practical methods are still
roughly cubic in the length of the sentence—
less than ideal when dealing with nontrivial
sentences of 30 or 40 words in length, as fre-
quently found in the Penn Wall Street Jour-
nal treebank corpus.
Fortunately, there is now a body of litera-
ture on methods to reduce parse time so that
the exhaustive limit is never reached in prac-
tice.&apos; For much of the work, the chosen ve-
hicle is chart parsing. In this technique, the
parser begins at the word or tag level and
uses the rules of a context-free grammar to
build larger and larger constituents. Com-
pleted constituents are stored in the cells
of a chart according to their location and
</bodyText>
<footnote confidence="0.978712428571429">
* This research was funded in part by NSF Grant
IRI-9319516 and ONR Grant N0014-96-1-0549.
1 An exhaustive parse always &amp;quot;overgenerates&amp;quot; be-
cause the grammar contains thousands of extremely
rarely applied rules; these are (correctly) rejected
even by the simplest parsers, eventually, but it would
be better to avoid them entirely.
</footnote>
<bodyText confidence="0.999713526315789">
length. Incomplete constituents (&amp;quot;edges&amp;quot;)
are stored in an agenda. The exhaustion
of the agenda definitively marks the comple-
tion of the parsing algorithm, but the parse
needn&apos;t take that long; already in the early
work on chart parsing, (Kay, 1970) suggests
that by ordering the agenda one can find
a parse without resorting to an exhaustive
search. The introduction of statistical pars-
ing brought with an obvious tactic for rank-
ing the agenda: (Bobrow, 1990) and (Chi-
trao and Grishman, 1990) first used proba-
bilistic context free grammars (PCFGs) to
generate probabilities for use in a figure of
merit (FOM). Later work introduced other
FOMs formed from PCFG data (Kochman
and Kupin, 1991); (Magerman and Marcus,
1991); and (Miller and Fox, 1994).
More recently, we have seen parse times
lowered by several orders of magnitude. The
(Caraballo and Charniak, 1998) article con-
siders a number of different figures of merit
for ordering the agenda, and ultimately rec-
ommends one that reduces the number of
edges required for a full parse into the thou-
sands. (Goldwater et al., 1998) (henceforth
[Go1d98j) introduces an edge-based tech-
nique, (instead of constituent-based), which
drops the average edge count into the hun-
dreds.
However, if we establish &amp;quot;perfection&amp;quot; as
the minimum number of edges needed to
generate the correct parse-47.5 edges on av-
erage in our corpus—we can hope for still
more improvement. This paper looks at two
new figures of merit, both of which take the
[0o1d98] figure (of &amp;quot;independent&amp;quot; merit) as
a starting point in calculating a new figure
</bodyText>
<page confidence="0.997436">
513
</page>
<bodyText confidence="0.999973">
of merit for each edge, taking into account
some additional information. Our work fur-
ther lowers the average edge count, bringing
it from the hundreds into the dozens.
</bodyText>
<sectionHeader confidence="0.658424" genericHeader="method">
2 Figure of independent merit
</sectionHeader>
<bodyText confidence="0.999624222222222">
(Caraballo and Charniak, 1998) and
[Go1d981 use a figure which indicates the
merit of a given constituent or edge, relative
only to itself and its children but indepen-
dent of the progress of the parse—we will
call this the edge&apos;s independent merit (IM).
The philosophical backing for this figure is
that we would like to rank an edge based on
the value
</bodyText>
<equation confidence="0.989728">
P(NIAlto,n) , (1)
</equation>
<bodyText confidence="0.999205">
where M, k represents an edge of type i (NP,
2
S, etc.), which encompasses words j through
k —1 of the sentence, and to, represents all n
part-of-speech tags, from 0 to n — 1. (As in
the previous research, we simplify by look-
ing at a tag stream, ignoring lexical infor-
mation.) Given a few basic independence as-
sumptions (Caraballo and Charniak, 1998),
this value can be calculated as
</bodyText>
<equation confidence="0.997854">
P(NjAito,n) = p(to,n)
</equation>
<bodyText confidence="0.99676">
with and a representing the well-known
&amp;quot;inside&amp;quot; and &amp;quot;outside&amp;quot; probability functions:
</bodyText>
<equation confidence="0.992014">
f&apos;f Till ) = Till (3)
a(N.1,k) P(toj, Ni,k,tk,n) • (4)
</equation>
<bodyText confidence="0.9999061">
Unfortunately, the outside probability is not
calculable until after a parse is completed.
Thus, the IM is an approximation; if we can-
not calculate the full outside probability (the
probability of this constituent occurring with
all the other tags in the sentence), we can
at least calculate the probability of this con-
stituent occurring with the previous and sub-
sequent tag. This approximation, as given in
(Caraballo and Charniak, 1998), is
</bodyText>
<equation confidence="0.9280805">
P(/qk Itj_ )0(N1A)P(tk &apos;NIA)
P(ti,k Iti_i)P(tk Itk-i) •
</equation>
<bodyText confidence="0.995509375">
Of the five values required, P(Arj,k
P(tk 14-1), and P(tkIN.1,k) can be observed
directly from the training data; the inside
probability is estimated using the most prob-
able parse for No and the tag sequence
probability is estimated using a bitag ap-
proximation.
Two different probability distributions are
used in this estimate, and the PCFG prob-
abilities in the numerator tend to be a bit
lower than the bitag probabilities in the de-
nominator; this is more of a factor in larger
constituents, so the figure tends to favour
the smaller ones. To adjust the distribu-
tions to counteract this effect, we will use
a normalisation constant n as in [Gold98].
Effectively, the inside probability 3 is mul-
tiplied by n1-3, preventing the discrepancy
and hence the preference for shorter edges.
In this paper we will use n 1.3 throughout;
this is the factor by which the two distribu-
tions differ, and was also empirically shown
to be the best tradeoff between number of
popped edges and accuracy (in [Gold981).
</bodyText>
<sectionHeader confidence="0.983831" genericHeader="method">
3 Finding FOM flaws
</sectionHeader>
<bodyText confidence="0.999480782608696">
Clearly, any improvement to be had would
need to come through eliminating the in-
correct edges before they are popped from
the agenda—that is, improving the figure of
merit. We observed that the FOMs used
tended to cause the algorithm to spend too
much time in one area of a sentence, gener-
ating multiple parses for the same substring,
before it would generate even one parse for
another area. The reason for that is that the
figures of independent merit are frequently
good as relative measures for ranking differ-
ent parses of the same section of the sen-
tence, but not so good as absolute measures
for ranking parses of different substrings.
For instance, if the word &amp;quot;there&amp;quot; as an
NP in &amp;quot;there&apos;s a hole in the bucket&amp;quot; had
a low probability, it would tend to hold up
the parsing of a sentence; since the bi-tag
probability of &amp;quot;there&amp;quot; occurring at the be-
ginning of a sentence is very high, the de-
nominator of the IM would overbalance the
numerator. (Note that this is a contrived
</bodyText>
<equation confidence="0.849585">
13(N,k)a(Ni,k) , (2)
(5)
</equation>
<page confidence="0.970189">
514
</page>
<bodyText confidence="0.9997925">
example—the actual problem cases are more
obscure.) Of course, a different figure of in-
dependent merit might have different char-
acteristics, but with many of them there will
be cases where the figure is flawed, causing
a single, vital edge to remain on the agenda
while the parser &apos;thrashes&apos; around in other
parts of the sentence with higher IM values.
We could characterise this observation as
follows:
</bodyText>
<construct confidence="0.55926975">
Postulate 1 The longer an edge stays in the
agenda without any competitors, the more
likely it is to be correct (even if it has a low
figure of independent merit).
</construct>
<bodyText confidence="0.9994475">
A better figure, then, would take into ac-
count whether a given piece of text had al-
ready been parsed or not. We took two ap-
proaches to finding such a figure.
</bodyText>
<sectionHeader confidence="0.994251" genericHeader="method">
4 Compensating for flaws
</sectionHeader>
<subsectionHeader confidence="0.989974">
4.1 Experiment 1: Table lookup
</subsectionHeader>
<bodyText confidence="0.999903051724138">
In one approach to the problem, we tried
to start our program with no extra informa-
tion and train it statistically to counter the
problem mentioned in the previous section.
There are four values mentioned in Postu-
late 1: correctness, time (amount of work
done), number of competitors, and figure of
independent merit. We defined them as fol-
lows:
Correctness. The obvious definition is that
an edge 1\rj,k is correct if a constituent
appears in the parse given in the
treebank. There is an unobvious but
unfortunate consequence of choosing
this definition, however; in many cases
(especially with larger constituents),
the &amp;quot;correct&amp;quot; rule appears just once in
the entire corpus, and is thus consid-
ered too unlikely to be chosen by the
parser as correct. If the &amp;quot;correct&amp;quot; parse
were never achieved, we wouldn&apos;t have
any statistic at all as to the likelihood of
the first, second, or third competitor be-
ing better than the others. If we define
&amp;quot;correct&amp;quot; for the purpose of statistics-
gathering as &amp;quot;in the MAP parse&amp;quot;, the
problem is diminished. Both defini-
tions were tried for gathering statis-
tics, though of course only the first was
used for measuring accuracy of output
parses.
Work. Here, the most logical measure for
amount of work done is the number
of edges popped off the agenda. We
use it both because it is conveniently
processor-independent and because it
offers us a tangible measure of perfec-
tion (47.5 edges—the average number of
edges in the correct parse of a sentence).
Competitorship. At the most basic level,
the competitors of a given edge Arlk
would be all those edges such that
m &lt; j and n &gt; k. Initially we only con-
sidered an edge a &apos;competitor&apos; if it met
this definition and were already in the
chart; later we tried considering an edge
to be a competitor if it had a higher in-
dependent merit, no matter whether it
be in the agenda or the chart. We also
tried a hybrid of the two.
Merit. The independent merit of an edge is
defined in section 2. Unlike earlier work,
which used what we call &amp;quot;Independent
Merit&amp;quot; as the FOM for parsing, we use
this figure as just one of many sources
of information about a given edge.
Given our postulate, the ideal figure of
merit would be
</bodyText>
<equation confidence="0.877496">
P (correct IW, C, . (6)
</equation>
<bodyText confidence="0.999908125">
We can save information about this proba-
bility for each edge in every parse; but to
be useful in a statistical model, the IM must
first be discretised, and all three prior statis-
tics need to be grouped, to avoid sparse data
problems. We bucketed all three logarithmi-
cally, with bases 4, 2, and 10, respectively.
This gives us the following approximation:
</bodyText>
<equation confidence="0.9449825">
P(correct
Llog4 W , Llog2 ,[log10 . (7)
</equation>
<bodyText confidence="0.9898665">
To somewhat counteract the effect of dis-
cretising the IM figure, each time we needed
</bodyText>
<page confidence="0.941876">
515
</page>
<equation confidence="0.992858">
FOM =- P (correct J Llog4W , Llog2 , [log10 /MD ( flogio — log10 IM)
+ P (correct I Llog4W [1°g2C ,11°gio (log10 IM — [log10 IM]) (8)
</equation>
<bodyText confidence="0.999947123076923">
to calculate a figure of merit, we looked up
the table entry on either side of the IM and
interpolated. Thus the actual value used as a
figure of merit was that given in equation (8).
Each trial consisted of a training run and
a testing run. The training runs consisted of
using a grammar induced on treebank sec-
tions 2-21 to run the edge-based best-first
algorithm (with the IM alone as figure of
merit) on section 24, collecting the statis-
tics along the way. It seems relatively obvi-
ous that each edge should be counted when
it is created. But our postulate involves
edges which have stayed on the agenda for
a long time without accumulating competi-
tors; thus we wanted to update our counts
when an edge happened to get more com-
petitors, and as time passed. Whenever the
number of edges popped crossed into a new
logarithmic bucket (i.e. whenever it passed
a power of four), we re-counted every edge
in the agenda in that new bucket. In ad-
dition, when the number of competitors of a
given edge passed a bucket boundary (power
of two), that edge would be re-counted. In
this manner, we had a count of exactly how
many edges—correct or not—had a given IM
and a given number of competitors at a given
point in the parse.
Already at this stage we found strong evi-
dence for our postulate. We were paying par-
ticular attention to those edges with a low
IM and zero competitors, because those were
the edges that were causing problems when
the parser ignored them. When, considering
this subset of edges, we looked at a graph of
the percentage of edges in the agenda which
were correct, we saw an increase of orders of
magnitude as work increased—see Figure 1.
For the testing runs, then, we used as fig-
ure of merit the value in expression 8. Aside
from that change, we used the same edge-
based best-first parsing algorithm as before.
The test runs were all made on treebank sec-
tion 22, with all sentences longer than 40
words thrown out; thus our results can be
directly compared to those in the previous
work.
We made several trials, using different def-
initions of &apos;correct&apos; and &apos;competitor&apos;, as de-
scribed above. Some performed much bet-
ter than others, as seen in Table 1, which
gives our results, both in terms of accuracy
and speed, as compared to the best previous
result, given in [Go1d98]. The trial descrip-
tions refer back to the multiple definitions
given for &apos;correct&apos; and &apos;competitor&apos; at the
beginning of this section. While our best
speed improvement (48.6% of the previous
minimum) was achieved with the first run,
it is associated with a significant loss in ac-
curacy. Our best results overall, listed in
the last row of the table, let us cut the edge
count by almost half while reducing labelled
precision/recall by only 0.24%.
</bodyText>
<subsectionHeader confidence="0.942416">
4.2 Experiment 2: Demeriting
</subsectionHeader>
<bodyText confidence="0.998293333333333">
We hoped, however, that we might be able
to find a way to simplify the algorithm such
that it would be easier to implement and/or
</bodyText>
<figure confidence="0.991498714285714">
0.12
- L J = -4
- L Iog10lM J = -5
_e_ I logiolM i = -6
L logiolM J = -7
- L logioN = -8
0 04 -
0
0.
2
0.
0.02 -
2.5 3.5 4 4.5 5.5
log4 edges popped
</figure>
<figureCaption confidence="0.9756145">
Figure 1: Zero competitors, low IM—
Proportion of agenda edges correct vs. work
</figureCaption>
<figure confidence="0.982428">
0.1 -
8
00.05-
</figure>
<page confidence="0.996422">
516
</page>
<tableCaption confidence="0.999805">
Table 1: Performance of various statistical schemata
</tableCaption>
<table confidence="0.965315">
Trial description Labelled Labelled Change in Edges Percent
Precision Recall LP/LR avg. popped2 of std.
[Go1d98) standard 75.814% 73.334% 229.73
Correct, Chart competitors 74.982% 72.920% -.623% 111.59 48.6%
Correct, higher-merit competitors 75.588% 73.190% -.185% 135.23 58.9%
Correct, Chart or higher-merit 75.433% 73.152% -.282% 128.94 56.1%
MAP, higher-merit competitors 75.365% 73.220% -.239% 120.47 52.4%
109101m o log2 competitors
</table>
<figureCaption confidence="0.987106">
Figure 2: Stats at 64-255 edges popped
</figureCaption>
<bodyText confidence="0.927534941176471">
faster to run, without sacrificing accuracy.
To that end, we looked over the data, view-
ing it as (among other things) a series of
&amp;quot;planes&amp;quot; seen by setting the amount of work
constant (see Figure 2). Viewed like this, the
original algorithm behaves like a scan line,
parallel to the competitor axis, scanning for
the one edge with the highest figure of (in-
dependent) merit. However, one look at fig-
ure 2 dramatically confirms our postulate—
that an edge with zero competitors can have
an IM orders of magnitude lower than an
edge with many competitors, and still be
more likely to be correct. Effectively, then,
under the table lookup algorithm, the scan
2Previous work has shown that the parser per-
forms better if it runs slightly past the first parse;
so for every run referenced in this paper, the parser
was allowed to run to first parse plus a tenth. All
reported final counts for popped edges are thus 1.1
times the count at first parse.
line is not parallel to the competitor axis,
but rather angled so that the low-IM low-
competitor items pass the scan before the
high-IM high-competitor items. This can be
simulated by multiplying each edge&apos;s inde-
pendent merit by a demeriting factor 5 per
competitor (thus a total of 69. Its exact
value would determine the steepness of the
scan line.
Each trial consisted of one run, an edge-
based best-first parse of treebank section 22
(with sentences longer than 40 words thrown
out, as before), using the new figure of merit:
</bodyText>
<equation confidence="0.9768205">
(5C riP(MkIti-1)0(Nj,k)P(tkIk)) (9)
P(tj,kiti_i)P(tkitk-i)
</equation>
<bodyText confidence="0.999501181818182">
This idea works extremely well. It is, pre-
dictably, easier to implement; somewhat sur-
prisingly, though, it actually performs bet-
ter than the method it approximates. When
o = .7, for instance, the accuracy loss is only
.28%, comparable to the table lookup result,
but the number of edges popped drops to
just 91.23, or 39.7% of the prior result found
in [Go1d98]. Using other demeriting factors
gives similarly dramatic decreases in edge
count, with varying effects on accuracy—see
Figures 3 and 4.
It is not immediately clear as to why de-
meriting improves performance so dramat-
ically over the table lookup method. One
possibility is that the statistical method runs
into too many sparse data problems around
the fringe of the data set—were we able to
use a larger data set, we might see the statis-
tics approach the curve defined by the de-
meriting. Another is that the bucketing is
too coarse, although the interpolation along
</bodyText>
<page confidence="0.977694">
517
</page>
<figure confidence="0.738881">
demeriting factor 8
</figure>
<figureCaption confidence="0.967045">
Figure 3: Edges popped vs. 6
</figureCaption>
<figure confidence="0.9973834">
78.5
0 labelled precision
labelled recall
72.5
720
</figure>
<figureCaption confidence="0.999894">
Figure 4: Precision and recall vs. 6
</figureCaption>
<bodyText confidence="0.997386">
the independent merit axis would seem to
mitigate that problem.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999988473684211">
In the prior work, we see the average edge
cost of a chart parse reduced from 170,000
or so down to 229.7. This paper gives a sim-
ple modification to the [Go1d98] algorithm
that further reduces this count to just over
90 edges, less than two times the perfect
minimum number of edges. In addition to
speeding up tag-stream parsers, it seems rea-
sonable to assume that the demeriting sys-
tem would work in other classes of parsers
such as the lexicalised model of (Charniak,
1997)-as long as the parsing technique has
some sort of demeritable ranking system, or
at least some way of paying less attention
to already-filled positions, the kernel of the
system should be applicable. Furthermore,
because of its ease of implementation, we
strongly recommend the demeriting system
to those working with best-first parsing.
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999762775">
Robert J. Bobrow. 1990. Statistical agenda
parsing. In DARPA Speech and Language
Workshop, pages 222-224.
Sharon Caraballo and Eugene Charniak.
1998. New figures of merit for best-
first probabilistic chart parsing. Compu-
tational Linguistics, 24(2):275-298, June.
Eugene Charniak. 1997. Statistical pars-
ing with a context-free grammar and word
statistics. In Proceedings of the Fourteenth
National Conference on Artificial Intelli-
gence, pages 598-603, Menlo Park. AAAI
Press/MIT Press.
Mahesh V. Chitrao and Ralph Grishman.
1990. Statistical parsing of messages. In
DARPA Speech and Language Workshop,
pages 263-266.
Sharon Goldwater, Eugene Charniak, and
Mark Johnson. 1998. Best-first edge-
based chart parsing. In 6th Annual Work-
shop for Very Large Corpora, pages 127-
133.
Martin Kay. 1970. Algorithm schemata and
data structures in syntactic processing. In
Barbara J. Grosz, Karen Sparck Jones,
and Bonne Lynn Weber, editors, Readings
in Natural Language Processing, pages 35-
70. Morgan Kaufmann, Los Altos, CA.
Fred Kochman and Joseph Kupin. 1991.
Calculating the probability of a partial
parse of a sentence. In DARPA Speech and
Language Workshop, pages 273-240.
David M. Magerman and Mitchell P. Mar-
cus. 1991. Parsing the voyager domain
using pearl. In DARPA Speech and Lan-
guage Workshop, pages 231-236.
Scott Miller and Heidi Fox. 1994. Auto-
matic grammar acquisition. In Proceed-
ings of the Human Language Technology
Workshop, pages 268-271.
</reference>
<figure confidence="0.999240129032258">
0.8
0.9
240
220
200
100
80
0 0.1 0.2 0.3 0.4 0.5 0.8 0.7
76
&apos;Fp). 75.5
&apos;6
075
o0
a)
-D 74.5
a)
0 0
rt)
&amp;quot;6 74
0
C7)
E. 73.5
0.5) 730-
0
000
0
0 0 0 0
0 0
0
0.1 02 0.3 0.4 0.5 0.8 0.7 0.8 0.9
demeriting factor 8
</figure>
<page confidence="0.936835">
518
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946963">
<title confidence="0.999845">Automatic Compensation for Parser Figure-of-Merit Flaws*</title>
<author confidence="0.999614">Don Blaheta</author>
<author confidence="0.999614">Eugene Charniak</author>
<email confidence="0.999279">fdpb,ecl@cs.brown.edu</email>
<affiliation confidence="0.999108">Computer Science</affiliation>
<address confidence="0.960292">Box 1910 / 115 Waterman St.-4th floor</address>
<affiliation confidence="0.998566">Brown University</affiliation>
<abstract confidence="0.998861">Best-first chart parsing utilises a figure of merit (FOM) to efficiently guide a parse by first attending to those edges judged better. In the past it has usually been static; this paper will show that with some extra information, a parser can compensate for FOM flaws which otherwise slow it down. Our results are faster than the prior best by a factor of 2.5; and the speedup is won with no significant decrease in parser accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert J Bobrow</author>
</authors>
<title>Statistical agenda parsing.</title>
<date>1990</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>222--224</pages>
<contexts>
<context position="2227" citStr="Bobrow, 1990" startWordPosition="369" endWordPosition="370"> extremely rarely applied rules; these are (correctly) rejected even by the simplest parsers, eventually, but it would be better to avoid them entirely. length. Incomplete constituents (&amp;quot;edges&amp;quot;) are stored in an agenda. The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Gol</context>
</contexts>
<marker>Bobrow, 1990</marker>
<rawString>Robert J. Bobrow. 1990. Statistical agenda parsing. In DARPA Speech and Language Workshop, pages 222-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
<author>Eugene Charniak</author>
</authors>
<title>New figures of merit for bestfirst probabilistic chart parsing.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--2</pages>
<contexts>
<context position="2631" citStr="Caraballo and Charniak, 1998" startWordPosition="432" endWordPosition="435">g, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds. However, if we establish &amp;quot;perfection&amp;quot; as the minimum number of edges needed to generate the correct parse-47.5 edges on average in our corpus—we can hope for still more improvement. This paper looks at two new figures of merit, both of whi</context>
<context position="4255" citStr="Caraballo and Charniak, 1998" startWordPosition="712" endWordPosition="715">n constituent or edge, relative only to itself and its children but independent of the progress of the parse—we will call this the edge&apos;s independent merit (IM). The philosophical backing for this figure is that we would like to rank an edge based on the value P(NIAlto,n) , (1) where M, k represents an edge of type i (NP, 2 S, etc.), which encompasses words j through k —1 of the sentence, and to, represents all n part-of-speech tags, from 0 to n — 1. (As in the previous research, we simplify by looking at a tag stream, ignoring lexical information.) Given a few basic independence assumptions (Caraballo and Charniak, 1998), this value can be calculated as P(NjAito,n) = p(to,n) with and a representing the well-known &amp;quot;inside&amp;quot; and &amp;quot;outside&amp;quot; probability functions: f&apos;f Till ) = Till (3) a(N.1,k) P(toj, Ni,k,tk,n) • (4) Unfortunately, the outside probability is not calculable until after a parse is completed. Thus, the IM is an approximation; if we cannot calculate the full outside probability (the probability of this constituent occurring with all the other tags in the sentence), we can at least calculate the probability of this constituent occurring with the previous and subsequent tag. This approximation, as given</context>
</contexts>
<marker>Caraballo, Charniak, 1998</marker>
<rawString>Sharon Caraballo and Eugene Charniak. 1998. New figures of merit for bestfirst probabilistic chart parsing. Computational Linguistics, 24(2):275-298, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical parsing with a context-free grammar and word statistics.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourteenth National Conference on Artificial Intelligence,</booktitle>
<pages>598--603</pages>
<publisher>AAAI Press/MIT Press.</publisher>
<location>Menlo Park.</location>
<marker>Charniak, 1997</marker>
<rawString>Eugene Charniak. 1997. Statistical parsing with a context-free grammar and word statistics. In Proceedings of the Fourteenth National Conference on Artificial Intelligence, pages 598-603, Menlo Park. AAAI Press/MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahesh V Chitrao</author>
<author>Ralph Grishman</author>
</authors>
<title>Statistical parsing of messages.</title>
<date>1990</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>263--266</pages>
<contexts>
<context position="2260" citStr="Chitrao and Grishman, 1990" startWordPosition="372" endWordPosition="376">pplied rules; these are (correctly) rejected even by the simplest parsers, eventually, but it would be better to avoid them entirely. length. Incomplete constituents (&amp;quot;edges&amp;quot;) are stored in an agenda. The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth </context>
</contexts>
<marker>Chitrao, Grishman, 1990</marker>
<rawString>Mahesh V. Chitrao and Ralph Grishman. 1990. Statistical parsing of messages. In DARPA Speech and Language Workshop, pages 263-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Best-first edgebased chart parsing.</title>
<date>1998</date>
<booktitle>In 6th Annual Workshop for Very Large Corpora,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="2847" citStr="Goldwater et al., 1998" startWordPosition="470" endWordPosition="473">90) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds. However, if we establish &amp;quot;perfection&amp;quot; as the minimum number of edges needed to generate the correct parse-47.5 edges on average in our corpus—we can hope for still more improvement. This paper looks at two new figures of merit, both of which take the [0o1d98] figure (of &amp;quot;independent&amp;quot; merit) as a starting point in calculating a new figure 513 of merit for each edge, taking into account some additional information. Our work further lowers the average ed</context>
</contexts>
<marker>Goldwater, Charniak, Johnson, 1998</marker>
<rawString>Sharon Goldwater, Eugene Charniak, and Mark Johnson. 1998. Best-first edgebased chart parsing. In 6th Annual Workshop for Very Large Corpora, pages 127-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Algorithm schemata and data structures in syntactic processing.</title>
<date>1970</date>
<booktitle>Readings in Natural Language Processing,</booktitle>
<pages>35--70</pages>
<editor>In Barbara J. Grosz, Karen Sparck Jones, and Bonne Lynn Weber, editors,</editor>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, CA.</location>
<contexts>
<context position="2016" citStr="Kay, 1970" startWordPosition="334" endWordPosition="335">ccording to their location and * This research was funded in part by NSF Grant IRI-9319516 and ONR Grant N0014-96-1-0549. 1 An exhaustive parse always &amp;quot;overgenerates&amp;quot; because the grammar contains thousands of extremely rarely applied rules; these are (correctly) rejected even by the simplest parsers, eventually, but it would be better to avoid them entirely. length. Incomplete constituents (&amp;quot;edges&amp;quot;) are stored in an agenda. The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and </context>
</contexts>
<marker>Kay, 1970</marker>
<rawString>Martin Kay. 1970. Algorithm schemata and data structures in syntactic processing. In Barbara J. Grosz, Karen Sparck Jones, and Bonne Lynn Weber, editors, Readings in Natural Language Processing, pages 35-70. Morgan Kaufmann, Los Altos, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Kochman</author>
<author>Joseph Kupin</author>
</authors>
<title>Calculating the probability of a partial parse of a sentence.</title>
<date>1991</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>273--240</pages>
<contexts>
<context position="2458" citStr="Kochman and Kupin, 1991" startWordPosition="405" endWordPosition="408">The exhaustion of the agenda definitively marks the completion of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds. However, if we establish &amp;quot;perfection&amp;quot; as the minimum number of edg</context>
</contexts>
<marker>Kochman, Kupin, 1991</marker>
<rawString>Fred Kochman and Joseph Kupin. 1991. Calculating the probability of a partial parse of a sentence. In DARPA Speech and Language Workshop, pages 273-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Parsing the voyager domain using pearl.</title>
<date>1991</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>231--236</pages>
<contexts>
<context position="2487" citStr="Magerman and Marcus, 1991" startWordPosition="409" endWordPosition="412">a definitively marks the completion of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds. However, if we establish &amp;quot;perfection&amp;quot; as the minimum number of edges needed to generate the cor</context>
</contexts>
<marker>Magerman, Marcus, 1991</marker>
<rawString>David M. Magerman and Mitchell P. Marcus. 1991. Parsing the voyager domain using pearl. In DARPA Speech and Language Workshop, pages 231-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Heidi Fox</author>
</authors>
<title>Automatic grammar acquisition.</title>
<date>1994</date>
<booktitle>In Proceedings of the Human Language Technology Workshop,</booktitle>
<pages>268--271</pages>
<contexts>
<context position="2515" citStr="Miller and Fox, 1994" startWordPosition="414" endWordPosition="417">on of the parsing algorithm, but the parse needn&apos;t take that long; already in the early work on chart parsing, (Kay, 1970) suggests that by ordering the agenda one can find a parse without resorting to an exhaustive search. The introduction of statistical parsing brought with an obvious tactic for ranking the agenda: (Bobrow, 1990) and (Chitrao and Grishman, 1990) first used probabilistic context free grammars (PCFGs) to generate probabilities for use in a figure of merit (FOM). Later work introduced other FOMs formed from PCFG data (Kochman and Kupin, 1991); (Magerman and Marcus, 1991); and (Miller and Fox, 1994). More recently, we have seen parse times lowered by several orders of magnitude. The (Caraballo and Charniak, 1998) article considers a number of different figures of merit for ordering the agenda, and ultimately recommends one that reduces the number of edges required for a full parse into the thousands. (Goldwater et al., 1998) (henceforth [Go1d98j) introduces an edge-based technique, (instead of constituent-based), which drops the average edge count into the hundreds. However, if we establish &amp;quot;perfection&amp;quot; as the minimum number of edges needed to generate the correct parse-47.5 edges on ave</context>
</contexts>
<marker>Miller, Fox, 1994</marker>
<rawString>Scott Miller and Heidi Fox. 1994. Automatic grammar acquisition. In Proceedings of the Human Language Technology Workshop, pages 268-271.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>