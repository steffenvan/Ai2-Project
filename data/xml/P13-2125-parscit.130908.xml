<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011553">
<title confidence="0.975796">
Learning Semantic Textual Similarity with Structural Representations
</title>
<author confidence="0.95937">
Aliaksei Severyn(1) and Massimo Nicosia(1) and Alessandro Moschitti1,2
</author>
<affiliation confidence="0.947887">
(1)DISI, University of Trento, 38123 Povo (TN), Italy
</affiliation>
<email confidence="0.931571">
{severyn,m.nicosia,moschitti}@disi.unitn.it
</email>
<note confidence="0.725826">
(2)QCRI, Qatar Foundation, Doha, Qatar
</note>
<email confidence="0.994595">
amoschitti@qf.org.qa
</email>
<sectionHeader confidence="0.993752" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995010666666667">
Measuring semantic textual similarity
(STS) is at the cornerstone of many NLP
applications. Different from the major-
ity of approaches, where a large number
of pairwise similarity features are used to
represent a text pair, our model features
the following: (i) it directly encodes input
texts into relational syntactic structures;
(ii) relies on tree kernels to handle feature
engineering automatically; (iii) combines
both structural and feature vector repre-
sentations in a single scoring model, i.e.,
in Support Vector Regression (SVR); and
(iv) delivers significant improvement over
the best STS systems.
</bodyText>
<sectionHeader confidence="0.998777" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997244">
In STS the goal is to learn a scoring model that
given a pair of two short texts returns a similar-
ity score that correlates with human judgement.
Hence, the key aspect of having an accurate STS
framework is the design of features that can ade-
quately represent various aspects of the similarity
between texts, e.g., using lexical, syntactic and se-
mantic similarity metrics.
The majority of approaches treat input text pairs
as feature vectors where each feature is a score
corresponding to a certain type of similarity. This
approach is conceptually easy to implement and
the STS shared task at SemEval 2012 (Agirre et
al., 2012) (STS-2012) has shown that the best sys-
tems were built following this idea, i.e., a num-
ber of features encoding similarity of an input text
pair were combined in a single scoring model, e.g.,
SVR. Nevertheless, one limitation of using only
similarity features to represent a text pair is that of
low representation power.
The novelty of our approach is that we treat the
input text pairs as structural objects and rely on the
power of kernel learning to extract relevant struc-
tures. To link the documents in a pair we mark the
nodes in the related structures with a special rela-
tional tag. This way effective structural relational
patterns are implicitly encoded in the trees and
can be automatically learned by the kernel-based
machines. We combine our relational structural
model with the features from two best systems of
STS-2012. Finally, we use the approach of classi-
fier stacking to combine several structural models
into the feature vector representation.
The contribution of this paper is as follows: (i) it
provides a convincing evidence that adding struc-
tural features automatically extracted by structural
kernels yields a significant improvement in accu-
racy; (ii) we define a combination kernel that inte-
grates both structural and feature vector represen-
tations within a single scoring model, e.g., Sup-
port Vector Regression; (iii) we provide a sim-
ple way to construct relational structural models
that can be built using off-the-shelf NLP tools;
(iv) we experiment with four structural representa-
tions and show that constituency and dependency
trees represent the best source for learning struc-
tural relationships; and (v) using a classifier stack-
ing approach, structural models can be easily com-
bined and integrated into existing feature-based
STS models.
</bodyText>
<sectionHeader confidence="0.939099" genericHeader="method">
2 Structural Relational Similarity
</sectionHeader>
<bodyText confidence="0.9998395">
The approach of relating pairs of input struc-
tures by learning predictable syntactic transforma-
tions has shown to deliver state-of-the-art results
in question answering, recognizing textual entail-
ment, and paraphrase detection, e.g. (Wang et al.,
2007; Wang and Manning, 2010; Heilman and
Smith, 2010). Previous work relied on fairly com-
plex approaches, e.g. applying quasi-synchronous
grammar formalism and variations of tree edit dis-
tance alignments, to extract syntactic patterns re-
lating pairs of input structures. Our approach
is conceptually simpler, as it regards the prob-
lem within the kernel learning framework, where
we first encode salient syntactic/semantic proper-
</bodyText>
<page confidence="0.972275">
714
</page>
<bodyText confidence="0.912708125">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
ties of the input text pairs into tree structures and
rely on tree kernels to automatically generate rich
feature spaces. This work extends in several di-
rections our earlier work in question answering,
e.g., (Moschitti et al., 2007; Moschitti and Quar-
teroni, 2008), in textual entailment recognition,
e.g., (Moschitti and Zanzotto, 2007), and more in
general in relational text categorization (Moschitti,
2008; Severyn and Moschitti, 2012).
In this section we describe: (i) a kernel frame-
work to combine structural and vector models; (ii)
structural kernels to handle feature engineering;
and (iii) suitable structural representations for re-
lational learning.
</bodyText>
<subsectionHeader confidence="0.986813">
2.1 Structural Kernel Learning
</subsectionHeader>
<bodyText confidence="0.971126034482759">
In supervised learning, given labeled data
{(xi,yi)}ni=1, the goal is to estimate a decision
function h(x) = y that maps input examples to
their targets. A conventional approach is to rep-
resent a pair of texts as a set of similarity fea-
tures {fi}, s.t. the predictions are computed as
h(x) = w · x = Ei wifi, where w is the model
weight vector. Hence, the learning problem boils
down to estimating individual weights of each of
the similarity features fi. One downside of such
approach is that a great deal of similarity infor-
mation encoded in a given text pair is lost when
modeled by single real-valued scores.
A more versatile approach in terms of the input
representation relies on kernels. In a typical kernel
learning approach, e.g., SVM, the prediction func-
tion for a test input x takes on the following form
h(x) = Ei αiyiK(x,xi), where αi are the model
parameters estimated from the training data, yi are
target variables, xi are support vectors, and K(·, ·)
is a kernel function.
To encode both structural representation and
similarity feature vectors of a given text pair in a
single model we define each document in a pair
to be composed of a tree and a vector: ht,vi.
To compute a kernel between two text pairs xi
and xj we define the following all-vs-all kernel,
where all possible combinations of components,
x(1) and x(2), from each text pair are consid-
</bodyText>
<equation confidence="0.996617888888889">
ered: K(xi,xj) = K(x(1)
i ,x(1)
j )+K(x(1)
i ,x(2)
j )+
K(x(2)
i ,x(1)
j ) + K(x(2)
i ,x(2)
</equation>
<bodyText confidence="0.970439384615384">
j ). Each of the ker-
nel computations K can be broken down into
the following: K(x(1),
Kfvec(v(1),v(2)), where KTK computes a struc-
tural kernel and Kfvec is a kernel over feature vec-
tors, e.g., linear, polynomial or RBF, etc. Further
in the text we refer to structural tree kernel models
as TK and explicit feature vector representation as
fvec.
Having defined a way to jointly model text pairs
using structural TK representations along with the
similarity features fvec, we next briefly review
tree kernels and our relational structures.
</bodyText>
<subsectionHeader confidence="0.998722">
2.2 Tree Kernels
</subsectionHeader>
<bodyText confidence="0.999916875">
We use tree structures as our base representation
since they provide sufficient flexibility in repre-
sentation and allow for easier feature extraction
than, for example, graph structures. Hence, we
rely on tree kernels to compute KTK(·, ·). Given
two trees it evaluates the number of substructures
(or fragments) they have in common, i.e., it is a
measure of their overlap. Different TK functions
are characterized by alternative fragment defini-
tions. In particular, we focus on the Syntactic Tree
kernel (STK) (Collins and Duffy, 2002) and a Par-
tial Tree Kernel (PTK) (Moschitti, 2006).
STK generates all possible substructures rooted in
each node of the tree with the constraint that pro-
duction rules can not be broken (i.e., any node in a
tree fragment must include either all or none of its
children).
PTK can be more effectively applied to both con-
stituency and dependency parse trees. It general-
izes STK as the fragments it generates can contain
any subset of nodes, i.e., PTK allows for breaking
the production rules and generating an extremely
rich feature space, which results in higher gener-
alization ability.
</bodyText>
<subsectionHeader confidence="0.99744">
2.3 Structural representations
</subsectionHeader>
<bodyText confidence="0.999748111111111">
In this paper, we define simple-to-build relational
structures based on: (i) a shallow syntactic tree,
(ii) constituency, (iii) dependency and (iv) phrase-
dependency trees.
Shallow tree is a two-level syntactic hierarchy
built from word lemmas (leaves), part-of-speech
tags (preterminals) that are further organized into
chunks. It was shown to significantly outperform
feature vector baselines for modeling relationships
between question answer pairs (Severyn and Mos-
chitti, 2012).
Constituency tree. While shallow syntactic pars-
ing is very fast, here we consider using con-
stituency structures as a potentially richer source
of syntactic/semantic information.
Dependency tree. We propose to use depen-
dency relations between words to derive an alter-
native structural representation. In particular, de-
</bodyText>
<equation confidence="0.994115">
x(2)) = KTK(t(1),t(2)) +
</equation>
<page confidence="0.994153">
715
</page>
<figureCaption confidence="0.899983">
Figure 1: A phrase dependency-based structural representation of a text pair (s1, s2): A woman with
a knife is slicing a pepper (s1) vs. A women slicing green pepper (s2) with a high semantic similarity
(human judgement score 4.0 out of 5.0). Related tree fragments are linked with a REL tag.
</figureCaption>
<bodyText confidence="0.999615833333333">
pendency relations are used to link words in a way
that they are always at the leaf level. This reorder-
ing of the nodes helps to avoid the situation where
nodes with words tend to form long chains. This
is essential for PTK to extract meaningful frag-
ments. We also plug part-of-speech tags between
the word nodes and nodes carrying their grammat-
ical role.
Phrase-dependency tree. We explore a phrase-
dependency tree similar to the one defined in (Wu
et al., 2009). It represents an alternative struc-
ture derived from the dependency tree, where the
dependency relations between words belonging to
the same phrase (chunk) are collapsed in a unified
node. Different from (Wu et al., 2009), the col-
lapsed nodes are stored as a shallow subtree rooted
at the unified node. This node organization is par-
ticularly suitable for PTK that effectively runs a
sequence kernel on the tree fragments inside each
chunk subtree. Fig 1 gives an example of our vari-
ation of a phrase dependency tree.
As a final consideration, if a document contains
multiple sentences they are merged in a single tree
with a common root. To encode the structural
relationships between documents in a pair a spe-
cial REL tag is used to link the related structures.
We adopt a simple strategy to establish such links:
words from two documents that have a common
lemma get their parents (POS tags) and grandpar-
ents, non-terminals, marked with a REL tag.
</bodyText>
<sectionHeader confidence="0.961215" genericHeader="method">
3 Pairwise similarity features.
</sectionHeader>
<bodyText confidence="0.977096810810811">
Along with the direct representation of input text
pairs as structural objects our framework is also
capable of encoding pairwise similarity feature
vectors (fvec), which we describe below.
Baseline features. (base) We adopt similar-
ity features from two best performing systems
of STS-2012, which were publicly released1:
namely, the Takelab2 system (ˇSari´c et al., 2012)
and the UKP Lab’s system3 (Bar et al., 2012).
Both systems represent input texts with similarity
features combining multiple text similarity mea-
sures of varying complexity.
UKP (U) provides metrics based on match-
ing of character, word n-grams and common
subsequences. It also includes features derived
from Explicit Semantic Analysis (Gabrilovich and
Markovitch, 2007) and aggregation of word sim-
ilarity based on lexical-semantic resources, e.g.,
WordNet. In total it provides 18 features.
Takelab (T) includes n-gram matching of vary-
ing size, weighted word matching, length differ-
ence, WordNet similarity and vector space simi-
larity where pairs of input sentences are mapped
into Latent Semantic Analysis (LSA) space. The
features are computed over several sentence rep-
resentations where stop words are removed and/or
lemmas are used in place of raw tokens. The total
number of Takelab’s features is 21. The combined
system consists of 39 features.
Additional features. We also augment the U and
T feature sets, with an additional set of features (A)
which includes: a cosine similarity scores com-
puted over (i) n-grams of part-of-speech tags (up
to 4-grams), (ii) SuperSense tags (Ciaramita and
1Note that only a subset of the features used in the fi-
nal evaluation was released, which results in lower accuracy
when compared to the official rankings.
</bodyText>
<footnote confidence="0.970518666666667">
2http://takelab.fer.hr/sts/
3https://code.google.com/p/dkpro-similarity-
asl/wiki/SemEval2013
</footnote>
<page confidence="0.998037">
716
</page>
<bodyText confidence="0.999924461538461">
Altun, 2006), (iii) named entities, (iv) dependency
triplets, and (v) PTK syntactic similarity scores
computed between documents in a pair, where as
input representations we use raw dependency and
constituency trees. To alleviate the problem of do-
main adaptation, where datasets used for training
and testing are drawn from different sources, we
include additional features to represent the com-
bined text of a pair: (i) bags (B) of lemmas, de-
pendency triplets, production rules (from the con-
stituency parse tree) and a normalized length of
the entire pair; and (ii) a manually encoded cor-
pus type (M), where we use a binary feature with
a non-zero entry corresponding to a dataset type.
This helps the learning algorithm to learn implic-
itly the individual properties of each dataset.
Stacking. To integrate multiple TK representa-
tions into a single model we apply a classifier
stacking approach (Fast and Jensen, 2008). Each
of the learned TK models is used to generate pre-
dictions which are then plugged as features into
the final fvec representation, s.t. the final model
uses only explicit feature vector representation. To
obtain prediction scores, we apply 5-fold cross-
validation scheme, s.t. for each of the held-out
folds we obtain independent predictions.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99998">
We present the results of our model tested on the
data from the Core STS task at SemEval 2012.
</bodyText>
<subsectionHeader confidence="0.995165">
4.1 Setup
</subsectionHeader>
<bodyText confidence="0.999898722222222">
Data. To compare with the best systems of the
STS-2012 we followed the same setup used in
the final evaluation, where 3 datasets (MSRpar,
MSRvid and SMTeuroparl) are used for training
and 5 for testing (two “surprise” datasets were
added: OnWN and SMTnews). We use the entire
training data to obtain a single model for making
predictions on each test set.
Software. To encode TK models along with the
similarity feature vectors into a single regression
scoring model, we use an SVR framework imple-
mented in SVM-Light-TK4. We use the follow-
ing parameter settings -t 5 -F 1 -W A -C
+, which specifies a combination of trees and fea-
ture vectors (-C +), STK over trees (-F 1) (-F
3 for PTK) computed in all-vs-all mode (-W A)
and polynomial kernel of degree 3 for the feature
vector (active by default).
</bodyText>
<footnote confidence="0.834115">
4http://disi.unitn.it/moschitti/Tree-Kernel.htm
</footnote>
<bodyText confidence="0.99958875">
Metrics. We report the following metrics em-
ployed in the final evaluation: Pearson correlation
for individual test sets5 and Mean – an average
score weighted by the test set size.
</bodyText>
<subsectionHeader confidence="0.766463">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999950421052632">
Table 1 summarizes the results of combining TK
models with a strong feature vector model. We
test structures defined in Sec. 2.3 when using STK
and PTK. The results show that: (i) combining
all three features sets (U, T, A) provides a strong
baseline system that we attempt to further improve
with our relational structures; (ii) the generality of
PTK provides an advantage over STK for learn-
ing more versatile models; (iii) constituency and
dependency representations seem to perform bet-
ter than shallow and phrase-dependency trees; (iv)
using structures with no relational linking does not
work; (v) TK models provide a far superior source
of structural similarity than U + T + A that already
includes PTK similarity scores as features, and fi-
nally (vi) the domain adaptation problem can be
addressed by including corpus specific features,
which leads to a large improvement over the pre-
vious best system.
</bodyText>
<sectionHeader confidence="0.98931" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999903083333333">
We have presented an approach where text pairs
are directly treated as structural objects. This pro-
vides a much richer representation for the learning
algorithm to extract useful syntactic and shallow
semantic patterns. We have provided an exten-
sive experimental study of four different structural
representations, e.g. shallow, constituency, de-
pendency and phrase-dependency trees using STK
and PTK. The novelty of our approach is that it
goes beyond a simple combination of tree kernels
with feature vectors as: (i) it directly encodes input
text pairs into relationally linked structures; (ii) the
learned structural models are used to obtain pre-
diction scores thus making it easy to plug into ex-
isting feature-based models, e.g. via stacking; (iii)
to our knowledge, this work is the first to apply
structural kernels and combinations in a regres-
sion setting; and (iv) our model achieves the state
of the art in STS largely improving the best pre-
vious systems. Our structural learning approach
to STS is conceptually simple and does not re-
quire additional linguistic sources other than off-
the-shelf syntactic parsers. It is particularly suit-
able for NLP tasks where the input domain comes
</bodyText>
<footnote confidence="0.997771">
5we also report the results for a concatenation of all five
test sets (ALL)
</footnote>
<page confidence="0.985391">
717
</page>
<figure confidence="0.9795594">
Experiment U T A S CDP STK PTK B M ALL Mean MSRp MSRv SMTe OnWN SMTn
• .7060 .6087 .6080 .8390 .2540 .6820 .4470
fvec • .7589 .6863 .6814 .8637 .4950 .7091 .5395
model • • .8079 .7161 .7134 .8837 .5519 .7343 .5607
• • • .8187 .7137 .7157 .8833 .5131 .7355 .5809
• • • • • .8261 .6982 .7026 .8870 .4807 .7258 .5333
• • • • • .8326 .6970 .7020 .8925 .4826 .7190 .5253
TK • • • • • .8341 .7024 .7086 .8921 .4671 .7319 .5495
models • • • • • .8211 .6693 .6994 .8903 .2980 .7035 .5603
with STK • • • • • .8362 .7026 .6927 .8896 .5282 .7144 .5485
and PTK • • • • • .8458 .7047 .6935 .8953 .5080 .7101 .5834
• • • • • .8468 .6954 .6717 .8902 .4652 .7089 .6133
• • • • • .8326 .6693 .7108 .8879 .4922 .7215 .5156
• • • ◦ .8218 .6899 .6644 .8726 .4846 .7228 .5684
REL tag • • • ◦ .8250 .7000 .6806 .8822 .5171 .7145 .5769
• • • • • .8539 .7132 .6993 .9005 .4772 .7189 .6481
domain • • • • • .8529 .7249 .7080 .8984 .5142 .7263 .6700
adaptation • • • • • • .8546 .7156 .6989 .8979 .4884 .7181 .6609
• • • • • • .8810 .7416 .7210 .8971 .5912 .7328 .6778
UKP (best system of STS-2012) .8239 .6773 .6830 .8739 .5280 .6641 .4937
</figure>
<tableCaption confidence="0.902506">
Table 1: Results on STS-2012. First set of experiments studies the combination of fvec models from
</tableCaption>
<bodyText confidence="0.85673">
UKP (U), Takelab (T) and (A). Next we show results for four structural representations: shallow (S),
constituency (C), dependency (D) and phrase-dependency (P) trees with STK and PTK; next row set
demonstrates the necessity of relational linking for two best structures, i.e. C and D (empty circle denotes
a structures with no relational linking.); finally, domain adaptation via bags of features (B) of the entire
pair and (M) manually encoded dataset type show the state of the art results.
as pairs of objects, e.g., question answering, para-
phrasing and recognizing textual entailment.
</bodyText>
<sectionHeader confidence="0.998738" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.937634">
This research is supported by the EU’s Seventh
Framework Program (FP7/2007-2013) under the
#288024 LIMOSINE project.
</bodyText>
<sectionHeader confidence="0.998608" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885892857143">
Eneko Agirre, Daniel Cer, Mona Diab, and Gonzalez-
Agirre. 2012. Semeval-2012 task 6: A pilot on se-
mantic textual similarity. In *SEM.
Daniel Bar, Chris Biemann, Iryna Gurevych, and
Torsten Zesch. 2012. Ukp: Computing seman-
tic textual similarity by combining multiple content
similarity measures. In SemEval.
Massimiliano Ciaramita and Yasemin Altun. 2006.
Broad-coverage sense disambiguation and informa-
tion extraction with a supersense sequence tagger. In
EMNLP.
Michael Collins and Nigel Duffy. 2002. New Ranking
Algorithms for Parsing and Tagging: Kernels over
Discrete Structures, and the Voted Perceptron. In
ACL.
Andrew S. Fast and David Jensen. 2008. Why stacked
models perform effective collective classification.
In ICDM.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using wikipedia-
based explicit semantic analysis. In IJCAI.
Michael Heilman and Noah A. Smith. 2010. Tree edit
models for recognizing textual entailments, para-
phrases, and answers to questions. In NAACL.
Alessandro Moschitti and Silvia Quarteroni. 2008.
Kernels on linguistic structures for answer extrac-
tion. In ACL.
Alessandro Moschitti and Fabio Massimo Zanzotto.
2007. Fast and effective kernels for relational learn-
ing from texts. In ICML.
Alessandro Moschitti, Silvia Quarteroni, Roberto
Basili, and Suresh Manandhar. 2007. Exploit-
ing syntactic and shallow semantic kernels for ques-
tion/answer classification. In ACL.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In ECML.
Alessandro Moschitti. 2008. Kernel methods, syntax
and semantics for relational text categorization. In
CIKM.
Aliaksei Severyn and Alessandro Moschitti. 2012.
Structural relationships for large-scale learning of
answer re-ranking. In SIGIR.
Frane ˇSari´c, Goran Glavaˇs, Mladen Karan, Jan ˇSnajder,
and Bojana Dalbelo Baˇsi´c. 2012. Takelab: Systems
for measuring semantic text similarity. In SemEval.
Mengqiu Wang and Christopher D. Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question answer-
ing. In ACL.
Mengqiu Wang, Noah A. Smith, and Teruko Mitaura.
2007. What is the jeopardy model? a quasi-
synchronous grammar for qa. In EMNLP.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In EMNLP.
</reference>
<page confidence="0.995005">
718
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.602976">
<title confidence="0.999203">Learning Semantic Textual Similarity with Structural Representations</title>
<affiliation confidence="0.99541">University of Trento, 38123 Povo (TN),</affiliation>
<address confidence="0.790321">Qatar Foundation, Doha,</address>
<email confidence="0.995339">amoschitti@qf.org.qa</email>
<abstract confidence="0.999266625">Measuring semantic textual similarity (STS) is at the cornerstone of many NLP applications. Different from the majority of approaches, where a large number of pairwise similarity features are used to represent a text pair, our model features the following: (i) it directly encodes input texts into relational syntactic structures; (ii) relies on tree kernels to handle feature engineering automatically; (iii) combines both structural and feature vector representations in a single scoring model, i.e., in Support Vector Regression (SVR); and (iv) delivers significant improvement over the best STS systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>GonzalezAgirre</author>
</authors>
<title>Semeval-2012 task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In *SEM.</booktitle>
<contexts>
<context position="1558" citStr="Agirre et al., 2012" startWordPosition="226" endWordPosition="229">he goal is to learn a scoring model that given a pair of two short texts returns a similarity score that correlates with human judgement. Hence, the key aspect of having an accurate STS framework is the design of features that can adequately represent various aspects of the similarity between texts, e.g., using lexical, syntactic and semantic similarity metrics. The majority of approaches treat input text pairs as feature vectors where each feature is a score corresponding to a certain type of similarity. This approach is conceptually easy to implement and the STS shared task at SemEval 2012 (Agirre et al., 2012) (STS-2012) has shown that the best systems were built following this idea, i.e., a number of features encoding similarity of an input text pair were combined in a single scoring model, e.g., SVR. Nevertheless, one limitation of using only similarity features to represent a text pair is that of low representation power. The novelty of our approach is that we treat the input text pairs as structural objects and rely on the power of kernel learning to extract relevant structures. To link the documents in a pair we mark the nodes in the related structures with a special relational tag. This way e</context>
</contexts>
<marker>Agirre, Cer, Diab, GonzalezAgirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, and GonzalezAgirre. 2012. Semeval-2012 task 6: A pilot on semantic textual similarity. In *SEM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Bar</author>
<author>Chris Biemann</author>
<author>Iryna Gurevych</author>
<author>Torsten Zesch</author>
</authors>
<title>Ukp: Computing semantic textual similarity by combining multiple content similarity measures.</title>
<date>2012</date>
<booktitle>In SemEval.</booktitle>
<contexts>
<context position="11071" citStr="Bar et al., 2012" startWordPosition="1758" endWordPosition="1761">trategy to establish such links: words from two documents that have a common lemma get their parents (POS tags) and grandparents, non-terminals, marked with a REL tag. 3 Pairwise similarity features. Along with the direct representation of input text pairs as structural objects our framework is also capable of encoding pairwise similarity feature vectors (fvec), which we describe below. Baseline features. (base) We adopt similarity features from two best performing systems of STS-2012, which were publicly released1: namely, the Takelab2 system (ˇSari´c et al., 2012) and the UKP Lab’s system3 (Bar et al., 2012). Both systems represent input texts with similarity features combining multiple text similarity measures of varying complexity. UKP (U) provides metrics based on matching of character, word n-grams and common subsequences. It also includes features derived from Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007) and aggregation of word similarity based on lexical-semantic resources, e.g., WordNet. In total it provides 18 features. Takelab (T) includes n-gram matching of varying size, weighted word matching, length difference, WordNet similarity and vector space similarity where pair</context>
</contexts>
<marker>Bar, Biemann, Gurevych, Zesch, 2012</marker>
<rawString>Daniel Bar, Chris Biemann, Iryna Gurevych, and Torsten Zesch. 2012. Ukp: Computing semantic textual similarity by combining multiple content similarity measures. In SemEval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Yasemin Altun</author>
</authors>
<title>Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<marker>Ciaramita, Altun, 2006</marker>
<rawString>Massimiliano Ciaramita and Yasemin Altun. 2006. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7473" citStr="Collins and Duffy, 2002" startWordPosition="1176" endWordPosition="1179">vec, we next briefly review tree kernels and our relational structures. 2.2 Tree Kernels We use tree structures as our base representation since they provide sufficient flexibility in representation and allow for easier feature extraction than, for example, graph structures. Hence, we rely on tree kernels to compute KTK(·, ·). Given two trees it evaluates the number of substructures (or fragments) they have in common, i.e., it is a measure of their overlap. Different TK functions are characterized by alternative fragment definitions. In particular, we focus on the Syntactic Tree kernel (STK) (Collins and Duffy, 2002) and a Partial Tree Kernel (PTK) (Moschitti, 2006). STK generates all possible substructures rooted in each node of the tree with the constraint that production rules can not be broken (i.e., any node in a tree fragment must include either all or none of its children). PTK can be more effectively applied to both constituency and dependency parse trees. It generalizes STK as the fragments it generates can contain any subset of nodes, i.e., PTK allows for breaking the production rules and generating an extremely rich feature space, which results in higher generalization ability. 2.3 Structural r</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew S Fast</author>
<author>David Jensen</author>
</authors>
<title>Why stacked models perform effective collective classification.</title>
<date>2008</date>
<booktitle>In ICDM.</booktitle>
<contexts>
<context position="13394" citStr="Fast and Jensen, 2008" startWordPosition="2113" endWordPosition="2116"> and testing are drawn from different sources, we include additional features to represent the combined text of a pair: (i) bags (B) of lemmas, dependency triplets, production rules (from the constituency parse tree) and a normalized length of the entire pair; and (ii) a manually encoded corpus type (M), where we use a binary feature with a non-zero entry corresponding to a dataset type. This helps the learning algorithm to learn implicitly the individual properties of each dataset. Stacking. To integrate multiple TK representations into a single model we apply a classifier stacking approach (Fast and Jensen, 2008). Each of the learned TK models is used to generate predictions which are then plugged as features into the final fvec representation, s.t. the final model uses only explicit feature vector representation. To obtain prediction scores, we apply 5-fold crossvalidation scheme, s.t. for each of the held-out folds we obtain independent predictions. 4 Experiments We present the results of our model tested on the data from the Core STS task at SemEval 2012. 4.1 Setup Data. To compare with the best systems of the STS-2012 we followed the same setup used in the final evaluation, where 3 datasets (MSRpa</context>
</contexts>
<marker>Fast, Jensen, 2008</marker>
<rawString>Andrew S. Fast and David Jensen. 2008. Why stacked models perform effective collective classification. In ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="11395" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="1803" endWordPosition="1806"> of encoding pairwise similarity feature vectors (fvec), which we describe below. Baseline features. (base) We adopt similarity features from two best performing systems of STS-2012, which were publicly released1: namely, the Takelab2 system (ˇSari´c et al., 2012) and the UKP Lab’s system3 (Bar et al., 2012). Both systems represent input texts with similarity features combining multiple text similarity measures of varying complexity. UKP (U) provides metrics based on matching of character, word n-grams and common subsequences. It also includes features derived from Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007) and aggregation of word similarity based on lexical-semantic resources, e.g., WordNet. In total it provides 18 features. Takelab (T) includes n-gram matching of varying size, weighted word matching, length difference, WordNet similarity and vector space similarity where pairs of input sentences are mapped into Latent Semantic Analysis (LSA) space. The features are computed over several sentence representations where stop words are removed and/or lemmas are used in place of raw tokens. The total number of Takelab’s features is 21. The combined system consists of 39 features. Additional feature</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using wikipediabased explicit semantic analysis. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Noah A Smith</author>
</authors>
<title>Tree edit models for recognizing textual entailments, paraphrases, and answers to questions.</title>
<date>2010</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="3665" citStr="Heilman and Smith, 2010" startWordPosition="556" endWordPosition="559"> four structural representations and show that constituency and dependency trees represent the best source for learning structural relationships; and (v) using a classifier stacking approach, structural models can be easily combined and integrated into existing feature-based STS models. 2 Structural Relational Similarity The approach of relating pairs of input structures by learning predictable syntactic transformations has shown to deliver state-of-the-art results in question answering, recognizing textual entailment, and paraphrase detection, e.g. (Wang et al., 2007; Wang and Manning, 2010; Heilman and Smith, 2010). Previous work relied on fairly complex approaches, e.g. applying quasi-synchronous grammar formalism and variations of tree edit distance alignments, to extract syntactic patterns relating pairs of input structures. Our approach is conceptually simpler, as it regards the problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into </context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>Michael Heilman and Noah A. Smith. 2010. Tree edit models for recognizing textual entailments, paraphrases, and answers to questions. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
</authors>
<title>Kernels on linguistic structures for answer extraction.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4495" citStr="Moschitti and Quarteroni, 2008" startWordPosition="677" endWordPosition="681"> input structures. Our approach is conceptually simpler, as it regards the problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into tree structures and rely on tree kernels to automatically generate rich feature spaces. This work extends in several directions our earlier work in question answering, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008), in textual entailment recognition, e.g., (Moschitti and Zanzotto, 2007), and more in general in relational text categorization (Moschitti, 2008; Severyn and Moschitti, 2012). In this section we describe: (i) a kernel framework to combine structural and vector models; (ii) structural kernels to handle feature engineering; and (iii) suitable structural representations for relational learning. 2.1 Structural Kernel Learning In supervised learning, given labeled data {(xi,yi)}ni=1, the goal is to estimate a decision function h(x) = y that maps input examples to their targets. A conventional appr</context>
</contexts>
<marker>Moschitti, Quarteroni, 2008</marker>
<rawString>Alessandro Moschitti and Silvia Quarteroni. 2008. Kernels on linguistic structures for answer extraction. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Fabio Massimo Zanzotto</author>
</authors>
<title>Fast and effective kernels for relational learning from texts.</title>
<date>2007</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="4568" citStr="Moschitti and Zanzotto, 2007" startWordPosition="687" endWordPosition="690">problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into tree structures and rely on tree kernels to automatically generate rich feature spaces. This work extends in several directions our earlier work in question answering, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008), in textual entailment recognition, e.g., (Moschitti and Zanzotto, 2007), and more in general in relational text categorization (Moschitti, 2008; Severyn and Moschitti, 2012). In this section we describe: (i) a kernel framework to combine structural and vector models; (ii) structural kernels to handle feature engineering; and (iii) suitable structural representations for relational learning. 2.1 Structural Kernel Learning In supervised learning, given labeled data {(xi,yi)}ni=1, the goal is to estimate a decision function h(x) = y that maps input examples to their targets. A conventional approach is to represent a pair of texts as a set of similarity features {fi}</context>
</contexts>
<marker>Moschitti, Zanzotto, 2007</marker>
<rawString>Alessandro Moschitti and Fabio Massimo Zanzotto. 2007. Fast and effective kernels for relational learning from texts. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question/answer classification.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4462" citStr="Moschitti et al., 2007" startWordPosition="673" endWordPosition="676">tterns relating pairs of input structures. Our approach is conceptually simpler, as it regards the problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into tree structures and rely on tree kernels to automatically generate rich feature spaces. This work extends in several directions our earlier work in question answering, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008), in textual entailment recognition, e.g., (Moschitti and Zanzotto, 2007), and more in general in relational text categorization (Moschitti, 2008; Severyn and Moschitti, 2012). In this section we describe: (i) a kernel framework to combine structural and vector models; (ii) structural kernels to handle feature engineering; and (iii) suitable structural representations for relational learning. 2.1 Structural Kernel Learning In supervised learning, given labeled data {(xi,yi)}ni=1, the goal is to estimate a decision function h(x) = y that maps input examples to t</context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting syntactic and shallow semantic kernels for question/answer classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In ECML.</booktitle>
<contexts>
<context position="7523" citStr="Moschitti, 2006" startWordPosition="1187" endWordPosition="1188">l structures. 2.2 Tree Kernels We use tree structures as our base representation since they provide sufficient flexibility in representation and allow for easier feature extraction than, for example, graph structures. Hence, we rely on tree kernels to compute KTK(·, ·). Given two trees it evaluates the number of substructures (or fragments) they have in common, i.e., it is a measure of their overlap. Different TK functions are characterized by alternative fragment definitions. In particular, we focus on the Syntactic Tree kernel (STK) (Collins and Duffy, 2002) and a Partial Tree Kernel (PTK) (Moschitti, 2006). STK generates all possible substructures rooted in each node of the tree with the constraint that production rules can not be broken (i.e., any node in a tree fragment must include either all or none of its children). PTK can be more effectively applied to both constituency and dependency parse trees. It generalizes STK as the fragments it generates can contain any subset of nodes, i.e., PTK allows for breaking the production rules and generating an extremely rich feature space, which results in higher generalization ability. 2.3 Structural representations In this paper, we define simple-to-</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In ECML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel methods, syntax and semantics for relational text categorization.</title>
<date>2008</date>
<booktitle>In CIKM.</booktitle>
<contexts>
<context position="4640" citStr="Moschitti, 2008" startWordPosition="699" endWordPosition="700">semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into tree structures and rely on tree kernels to automatically generate rich feature spaces. This work extends in several directions our earlier work in question answering, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008), in textual entailment recognition, e.g., (Moschitti and Zanzotto, 2007), and more in general in relational text categorization (Moschitti, 2008; Severyn and Moschitti, 2012). In this section we describe: (i) a kernel framework to combine structural and vector models; (ii) structural kernels to handle feature engineering; and (iii) suitable structural representations for relational learning. 2.1 Structural Kernel Learning In supervised learning, given labeled data {(xi,yi)}ni=1, the goal is to estimate a decision function h(x) = y that maps input examples to their targets. A conventional approach is to represent a pair of texts as a set of similarity features {fi}, s.t. the predictions are computed as h(x) = w · x = Ei wifi, where w i</context>
</contexts>
<marker>Moschitti, 2008</marker>
<rawString>Alessandro Moschitti. 2008. Kernel methods, syntax and semantics for relational text categorization. In CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structural relationships for large-scale learning of answer re-ranking.</title>
<date>2012</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="4670" citStr="Severyn and Moschitti, 2012" startWordPosition="701" endWordPosition="704">4 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of the input text pairs into tree structures and rely on tree kernels to automatically generate rich feature spaces. This work extends in several directions our earlier work in question answering, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008), in textual entailment recognition, e.g., (Moschitti and Zanzotto, 2007), and more in general in relational text categorization (Moschitti, 2008; Severyn and Moschitti, 2012). In this section we describe: (i) a kernel framework to combine structural and vector models; (ii) structural kernels to handle feature engineering; and (iii) suitable structural representations for relational learning. 2.1 Structural Kernel Learning In supervised learning, given labeled data {(xi,yi)}ni=1, the goal is to estimate a decision function h(x) = y that maps input examples to their targets. A conventional approach is to represent a pair of texts as a set of similarity features {fi}, s.t. the predictions are computed as h(x) = w · x = Ei wifi, where w is the model weight vector. Hen</context>
<context position="8568" citStr="Severyn and Moschitti, 2012" startWordPosition="1343" endWordPosition="1347">the production rules and generating an extremely rich feature space, which results in higher generalization ability. 2.3 Structural representations In this paper, we define simple-to-build relational structures based on: (i) a shallow syntactic tree, (ii) constituency, (iii) dependency and (iv) phrasedependency trees. Shallow tree is a two-level syntactic hierarchy built from word lemmas (leaves), part-of-speech tags (preterminals) that are further organized into chunks. It was shown to significantly outperform feature vector baselines for modeling relationships between question answer pairs (Severyn and Moschitti, 2012). Constituency tree. While shallow syntactic parsing is very fast, here we consider using constituency structures as a potentially richer source of syntactic/semantic information. Dependency tree. We propose to use dependency relations between words to derive an alternative structural representation. In particular, dex(2)) = KTK(t(1),t(2)) + 715 Figure 1: A phrase dependency-based structural representation of a text pair (s1, s2): A woman with a knife is slicing a pepper (s1) vs. A women slicing green pepper (s2) with a high semantic similarity (human judgement score 4.0 out of 5.0). Related t</context>
</contexts>
<marker>Severyn, Moschitti, 2012</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2012. Structural relationships for large-scale learning of answer re-ranking. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frane ˇSari´c</author>
<author>Goran Glavaˇs</author>
<author>Mladen Karan</author>
</authors>
<title>Snajder, and Bojana Dalbelo Baˇsi´c.</title>
<date></date>
<booktitle>In SemEval.</booktitle>
<marker>ˇSari´c, Glavaˇs, Karan, </marker>
<rawString>Frane ˇSari´c, Goran Glavaˇs, Mladen Karan, Jan ˇSnajder, and Bojana Dalbelo Baˇsi´c. 2012. Takelab: Systems for measuring semantic text similarity. In SemEval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Probabilistic tree-edit models with structured latent variables for textual entailment and question answering.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="3639" citStr="Wang and Manning, 2010" startWordPosition="552" endWordPosition="555"> (iv) we experiment with four structural representations and show that constituency and dependency trees represent the best source for learning structural relationships; and (v) using a classifier stacking approach, structural models can be easily combined and integrated into existing feature-based STS models. 2 Structural Relational Similarity The approach of relating pairs of input structures by learning predictable syntactic transformations has shown to deliver state-of-the-art results in question answering, recognizing textual entailment, and paraphrase detection, e.g. (Wang et al., 2007; Wang and Manning, 2010; Heilman and Smith, 2010). Previous work relied on fairly complex approaches, e.g. applying quasi-synchronous grammar formalism and variations of tree edit distance alignments, to extract syntactic patterns relating pairs of input structures. Our approach is conceptually simpler, as it regards the problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ties of </context>
</contexts>
<marker>Wang, Manning, 2010</marker>
<rawString>Mengqiu Wang and Christopher D. Manning. 2010. Probabilistic tree-edit models with structured latent variables for textual entailment and question answering. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Noah A Smith</author>
<author>Teruko Mitaura</author>
</authors>
<title>What is the jeopardy model? a quasisynchronous grammar for qa.</title>
<date>2007</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="3615" citStr="Wang et al., 2007" startWordPosition="548" endWordPosition="551">he-shelf NLP tools; (iv) we experiment with four structural representations and show that constituency and dependency trees represent the best source for learning structural relationships; and (v) using a classifier stacking approach, structural models can be easily combined and integrated into existing feature-based STS models. 2 Structural Relational Similarity The approach of relating pairs of input structures by learning predictable syntactic transformations has shown to deliver state-of-the-art results in question answering, recognizing textual entailment, and paraphrase detection, e.g. (Wang et al., 2007; Wang and Manning, 2010; Heilman and Smith, 2010). Previous work relied on fairly complex approaches, e.g. applying quasi-synchronous grammar formalism and variations of tree edit distance alignments, to extract syntactic patterns relating pairs of input structures. Our approach is conceptually simpler, as it regards the problem within the kernel learning framework, where we first encode salient syntactic/semantic proper714 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 714–718, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computatio</context>
</contexts>
<marker>Wang, Smith, Mitaura, 2007</marker>
<rawString>Mengqiu Wang, Noah A. Smith, and Teruko Mitaura. 2007. What is the jeopardy model? a quasisynchronous grammar for qa. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="9671" citStr="Wu et al., 2009" startWordPosition="1528" endWordPosition="1531">women slicing green pepper (s2) with a high semantic similarity (human judgement score 4.0 out of 5.0). Related tree fragments are linked with a REL tag. pendency relations are used to link words in a way that they are always at the leaf level. This reordering of the nodes helps to avoid the situation where nodes with words tend to form long chains. This is essential for PTK to extract meaningful fragments. We also plug part-of-speech tags between the word nodes and nodes carrying their grammatical role. Phrase-dependency tree. We explore a phrasedependency tree similar to the one defined in (Wu et al., 2009). It represents an alternative structure derived from the dependency tree, where the dependency relations between words belonging to the same phrase (chunk) are collapsed in a unified node. Different from (Wu et al., 2009), the collapsed nodes are stored as a shallow subtree rooted at the unified node. This node organization is particularly suitable for PTK that effectively runs a sequence kernel on the tree fragments inside each chunk subtree. Fig 1 gives an example of our variation of a phrase dependency tree. As a final consideration, if a document contains multiple sentences they are merge</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>