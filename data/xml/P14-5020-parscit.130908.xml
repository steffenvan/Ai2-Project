<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003852">
<title confidence="0.999631">
Enhanced Search with Wildcards and Morphological Inflections
in the Google Books Ngram Viewer
</title>
<author confidence="0.999337">
Jason Mann4* David Zhang♦* Lu Yang°* Dipanjan Das&apos; Slav Petrov&apos;
</author>
<affiliation confidence="0.944639">
4Columbia University ♦USC °Cornell University &apos;Google Inc.
</affiliation>
<email confidence="0.991341">
Contact: dipanjand@google.com, slav@google.com
</email>
<sectionHeader confidence="0.993799" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999585">
We present a new version of the Google
Books Ngram Viewer, which plots the fre-
quency of words and phrases over the last
five centuries; its data encompasses 6%
of the world’s published books. The new
Viewer adds three features for more pow-
erful search: wildcards, morphological in-
flections, and capitalization. These addi-
tions allow the discovery of patterns that
were previously difficult to find and fur-
ther facilitate the study of linguistic trends
in printed text.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999925947368421">
The Google Books Ngram project facilitates the
analysis of cultural, social and linguistic trends
through five centuries of written text in eight
languages. The Ngram Corpus (Michel et al.,
2011; Lin et al., 2012) consists of words and
phrases (i.e., ngrams) and their usage frequency
over time.1 The interactive Ngram Viewer2 allows
users to retrieve and plot the frequency of mul-
tiple ngrams on a simple webpage. The Viewer
is widely popular and can be used to efficiently
explore and visualize patterns in the underlying
ngram data. For example, the ngram data has
been used to detect emotion trends in 20th cen-
tury books (Acerbi et al., 2013), to analyze text
focusing on market capitalism throughout the past
century (Schulz and Robinson, 2013), detect so-
cial and cultural impact of historical personalities
(Skiena and Ward, 2013), or to analyze the corre-
lation of economic crises with a literary ‘misery
</bodyText>
<footnote confidence="0.9764008">
∗ The majority of this work was carried out during an
internship at Google.
1The Ngram Corpus is freely available for download at
http://books.google.com/ngrams/datasets.
2Seehttp://books.google.com/ngrams.
</footnote>
<note confidence="0.4704345">
Query: &amp;quot;President Kennedy, President Reagan, President Nixon&amp;quot;
1930 1965 2000
</note>
<figureCaption confidence="0.9939145">
Figure 1: Mention frequencies for three different American
presidents queried one-by-one.
</figureCaption>
<bodyText confidence="0.999614923076923">
index’ reflected in printed text during crises peri-
ods (Bentley et al., 2014).
A limitation of the Viewer, however, is that all
the reasoning has to be done by the user, and
only individual, user-specified ngrams can be re-
trieved and plotted. For example, to compare
the popularity of different presidents, one needs
to come up with a list of presidents and then
search for them one-by-one. The result of the
query ‘President Kennedy, President
Nixon, President Reagan’ is shown in
Figure 1. To determine the most popular president,
one would need to search for all presidents, which
is cumbersome and should ideally be automated.
In this paper, we therefore present an updated
version of the Viewer that enhances its search
functionality. We introduce three new features
that automatically expand a given query and re-
trieve a collection of ngrams, to facilitate the dis-
covery of patterns in the underlying data. First,
users can replace one query term with a place-
holder symbol ‘*’ (wildcard, henceforth), which
will return the ten most frequent expansions of
the wildcard in the corpus for the specified year
range. Second, by adding a specific marker to
any word in a query (‘ INF’), ngrams with all
</bodyText>
<figure confidence="0.99676925">
Relative Frequency
&amp;quot;President Kennedy&amp;quot;
&amp;quot;President Reagan&amp;quot;
&amp;quot;President Nixon&amp;quot;
</figure>
<page confidence="0.98191">
115
</page>
<bodyText confidence="0.984892696969697">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 115–120,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
morphological inflections of that word will be re-
trieved. Finally, the new Viewer supports capi-
talization searches, which return all capitalization
variants of the query ngram. Figure 2 provides ex-
amples for these three new types of queries.
While it is fairly obvious how the above search
features can be implemented via brute-force com-
putation, supporting an interactive application
with low latency necessitates some precomputa-
tion. In particular, the wildcard search feature
poses some challenges because the most frequent
expansions depend on the selected year range
(consider the frequency with which presidents are
mentioned during different decades, for example).
To this end, we provide details of our system ar-
chitecture in §2 and discuss how the new search
features are implemented in §3. In addition, we
present an overhaul of the Ngram Viewer’s user
interface with interactive features that allow for
easier management of the increase in data points
returned.
Detailed analysis and interpretation of trends
uncovered with the new search interface is beyond
the scope of this paper. We highlight some in-
teresting use cases in §4; many of the presented
queries were difficult (or impossible) to execute in
the previous versions of the system. We emphasize
that this demonstration updates only the Viewer,
providing tools for easier analysis of the underly-
ing corpora. The ngram corpora themselves are
not updated.
</bodyText>
<sectionHeader confidence="0.955311" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.9999828">
We first briefly review the two editions of the
Ngram Corpus (Michel et al., 2011; Lin et al.,
2012) and then describe the extensions to the ar-
chitecture of the Viewer that are needed to support
the new search features.
</bodyText>
<subsectionHeader confidence="0.99235">
2.1 The Ngram Corpus
</subsectionHeader>
<bodyText confidence="0.999372181818182">
The Google Books Ngram Corpus provides ngram
counts for eight different languages over more
than 500 years; additionally, the English corpus
is split further into British vs. American English
and Fiction to aid domain-specific analysis. This
corpus is a subset of all books digitized at Google
and represents more than 6% of all publicized texts
(Lin et al., 2012). Two editions of the corpus are
available: the first edition dates from 2009 and is
described in Michel et al. (2011); the second edi-
tion is from 2012 and is described in Lin et al.
</bodyText>
<note confidence="0.474808">
Query: &amp;quot;University of *&amp;quot;
</note>
<figure confidence="0.973274333333333">
1900 1950 2000
Query: &amp;quot;book_INF a hotel&amp;quot;
1800 1900 2000
</figure>
<figureCaption confidence="0.887497714285714">
Figure 2: In the new enhanced search features of the Ngram
Viewer, a single query is automatically expanded to retrieve
multiple related ngrams. From top to bottom, we show ex-
amples of the wildcard operator (‘*’), the ‘ INF’ marker that
results in morphological inflections, and the case insensitive
search functionality. Due to space considerations we show
only a subset of the results returned by the Ngram Viewer.
</figureCaption>
<bodyText confidence="0.999917846153846">
(2012). The new search features presented here
are available for both editions.
Michel et al. (2011) extract ngrams for each
page in isolation. More specifically, they use
whitespace tokenization and extract all ngrams up
to length five. These ngrams include ones that po-
tentially span sentence boundaries, but do not in-
clude ngrams that span across page breaks (even
when they are part of the same sentence). Lin
et al. (2012) on the other hand perform tokeniza-
tion, text normalization and segmentation into sen-
tences. They then add synthetic START and
END tokens to the beginning and end of the sen-
</bodyText>
<figure confidence="0.340613">
Relative Frequency
</figure>
<affiliation confidence="0.93454">
University of California
University of Chicago
University of Wisconsin
University of Michigan
University of Pennsylvania
</affiliation>
<figure confidence="0.998674727272727">
1950 1975 2000
Query: &amp;quot;fitzgerald [case-insensitive]&amp;quot;
Relative Frequency
book a hotel
booked a hotel
booking a hotel
books a hotel
Relative Frequency
Fitzgerald
FitzGerald
FITZGERALD
</figure>
<page confidence="0.99498">
116
</page>
<bodyText confidence="0.9999844">
tences to enable the distinction of sentence me-
dial ngrams from those near sentence boundaries.
They also ensure that sentences that span across
page boundaries are included. Due to these dif-
ferences, as well as the availability of additional
book data, improvements to the optical character
recognition algorithms and metadata extraction for
dating the books, the ngrams counts from the two
editions are not the same.
The edition from Lin et al. (2012) additionally
includes syntactic ngrams. The corpus is tagged
using the universal part-of-speech (POS) tag set
of Petrov et al. (2012): NOUN (nouns), VERB
(verbs), ADJ (adjectives), ADV (adverbs), PRON
(pronouns), DET (determiners and articles), ADP
(prepositions and postpositions), CONJ (conjunc-
tions). Words can be disambiguated by their POS
tag by simply appending the tag to the word with
an underscore (e.g. book NOUN) and can also be
replaced by POS tags in the ngrams, see Lin et
al. (2012) for details. The corpus is parsed with
a dependency parser and head-modifier syntactic
relations between words in the same sentence are
extracted. Dependency relations are represented
as ‘=&gt;’ in the corpus. Our new enhanced search
features for automatic expansions can also be ap-
plied to these syntactic ngrams. In fact, some of
the most interesting queries use expansions to au-
tomatically uncover related ngrams, while using
syntax to focus on particular patterns.
The Viewer supports the composition of ngram
frequencies via arithmetic operators. Addition (+),
subtraction (-) and division (/) of ngrams are car-
ried out on a per year basis, while multiplication
(*) is performed by a scalar that is applied to all
counts in the time series. Where ambiguous, the
wildcard operator takes precedence over the mul-
tiplication operator. Parentheses can be used to
disambiguate and to force the interpretation of a
mathematical operation.
</bodyText>
<subsectionHeader confidence="0.999538">
2.2 Architecture
</subsectionHeader>
<bodyText confidence="0.999781888888889">
The Ngram Viewer provides a lightweight inter-
face to the underlying ngram corpora. In its basic
form, user requests are directed through the server
to a simple lookup table containing the raw ngrams
and their frequencies. This data flow is displayed
in the top part of Figure 3 and is maintained for
queries that do not involve the new expansion fea-
tures introduced in this work.
The expansion queries could in principle be
</bodyText>
<figureCaption confidence="0.998277">
Figure 3: Overview of the Ngram Viewer architecture.
</figureCaption>
<bodyText confidence="0.999938730769231">
implemented by scanning the raw ngrams on
the fly and returning the matching subset: to
answer the query ‘President *’, one would
need to obtain all bigrams starting with the word
President (there are 23,693) and extract the
most frequent ten. Given the large number of
ngrams (especially for larger n), such an approach
turns out to be too slow for an interactive appli-
cation. We therefore pre-compute intermediate re-
sults that can be used to more efficiently retrieve
the results for expansion queries. The intermedi-
ate results are stored in additional lookup tables
(shown at the bottom in Figure 3). When the user
executes an expansion search, the query is first
routed to the appropriate lookup table which stores
all possible expansions (including expansions that
might not appear in the corpus). These expanded
ngrams are then retrieved from the raw ngram ta-
ble, sorted by frequency and returned to he user.
We describe the intermediate results tables and
how they are generated in the next section.
Note that we only support one expansion oper-
ation per query ngram. This is needed in order to
avoid the combinatorial explosion that would re-
sult from mixing multiple expansion operators in
the same query.
</bodyText>
<sectionHeader confidence="0.996292" genericHeader="method">
3 New Features
</sectionHeader>
<bodyText confidence="0.999869">
The three new search features are implemented via
the same two-step approach. As shown in Fig-
ure 3, we add three new lookup tables that store
intermediate results needed for efficiently support-
</bodyText>
<figure confidence="0.99609041509434">
Ngram Viewer System Architecture
User
Ngram
Viewer
Server
Raw Ngrams
‘King James’ :
{(1900, 234),
(1901, 122), ...}
‘Kinged James’:
{(1900, 20),
(1901, 15), ...}
...
Wildcards
‘King *’:
{King James,
King George,
... }
Inflections
‘King_INF’:
{King, Kinged,
Kings,
... }
Capitalizations
‘king james’:
{king James,
King James,
... }
new in this version
117
Query: &amp;quot;President *_NOUN, 1950-2000&amp;quot;
Relative Frequency
President Roosevelt_NOUN
President Truman_NOUN
President Kennedy_NOUN
President Johnson_NOUN
President Eisenhower_NOUN
Query: &amp;quot;President *&amp;quot; Query: &amp;quot;President *_NOUN, 1800-2000&amp;quot;
1800 1900 2000
1800 1900 2000
Relative Frequency
President of
President ‘s
President and
President to
President Roosevelt
Relative Frequency
President Roosevelt_NOUN
President Wilson_NOUN
President Lincoln_NOUN
President Johnson_NOUN
President Truman_NOUN
1950 1975 2000
</figure>
<figureCaption confidence="0.996323">
Figure 4: Different wildcard queries for bigrams starting with President. Specification of a POS tag along with the wildcard
operator results in more specific results, and the results vary depending on the selected yaer range.
</figureCaption>
<bodyText confidence="0.9999385">
ing the new search types. In all cases the lookup
tables provide a set of possible expansions that are
then retrieved in the original raw ngram table. Be-
low we describe how these intermediate results are
generated and how they are used to retrieve the fi-
nal results.
</bodyText>
<subsectionHeader confidence="0.983307">
3.1 Wildcards
</subsectionHeader>
<bodyText confidence="0.999953609756098">
Wildcards provide a convenient way to automat-
ically retrieve and explore related ngrams. Be-
cause of the large number of possibilities that can
fill a wildcard slot, returning anything but the top
few expansions is likely to be overwhelming. We
therefore return only the ten most frequent expan-
sions. Determining the most frequent expansions
is unfortunately computationally very expensive
because of the large number of ngrams; the query
‘the *’ for example has 2,353,960 expansions.
To avoid expensive on-the-fly computations,
we precompute the most frequent expansions for
all possible queries. The problem that arises
is that the ten most frequent expansions depend
on the selected year range. Consider the query
‘President *’; we would like to be able get
the correct result for any year range. Since our
data spans more than 500 years, precomputing the
results for all year ranges is not a possibility. In-
stead, we compute the possible wildcard expan-
sions for each year. The top expansions for the
entire range are then taken from the union of top
expansions for each year. This set is at most of
size lOn (where n is the year range) and in practice
typically a lot smaller. Theoretically it is possible
for this approximation to miss an expansion that is
never among the top ten for a particular year, but
is cumulatively in the top ten for the entire range.
This would happen if there were many spikes in
the data, which is not the case.
To make the wildcard expansions more rele-
vant, we filter expansions that consist entirely of
punctuation symbols. To further narrow down
the expansions and focus on particular patterns,
we allow wildcards to be qualified via POS
tags. Figure 4 shows some example wildcard
queries involving bigrams that start with the word
‘President.’ See also Table 1 for some addi-
tional examples. Note that it is possible to replace
POS tags with wildcards (e.g., cook *) which
will find all POS tags that the query word can take.
</bodyText>
<subsectionHeader confidence="0.996747">
3.2 Morphological Inflections
</subsectionHeader>
<bodyText confidence="0.999988214285714">
When comparing ngram frequencies (especially
across languages, but also for the same language),
it can be useful to examine and potentially aggre-
gate the frequencies of all inflected forms. This
can be accomplished by manually deriving all in-
flected forms and then using arithmetic operations
to aggregate their counts. Our new inflected form
search accomplishes this automatically. By ap-
pending the keyword INF to a word, a set of
ngrams with all inflected forms of the word will
be retrieved. To generate the inflected forms we
make use of Wiktionary3 and supplement it with
automatically generated inflection tables based on
the approach of Durrett and DeNero (2013).
Because there are at most a few dozen inflected
forms for any given word, we can afford to sub-
stitute and retrieve all inflections of the marked
word, even the ones that are not grammatical in a
given ngram context. This has the advantage that
we only need to store inflected forms for individ-
ual words rather than entire ngrams. If a generated
ngram has no support in the corpus, we simply
omit it from the final set of results. We do not per-
form any additional filtering; as a result, an inflec-
tion search can produce many results, especially
for morphologically rich languages like Russian.
We have therefore updated the user interface to
better deal with many data lines (§4).
</bodyText>
<footnote confidence="0.999570333333333">
3See http://www.wiktionary.org/. Because
Wiktionary is an evolving resource, results for a particular
query may change over time.
</footnote>
<page confidence="0.974739">
118
</page>
<table confidence="0.9996524">
Query Possible Replacements
* ’s Theorem Lagrange ’s Theorem, Gauss ’s Theorem,
Euler ’s Theorem, Pascal ’s Theorem
War=&gt;* NOUN War=&gt;World NOUN, War=&gt;Civil NOUN,
War=&gt;Second NOUN, War=&gt;Cold NOUN
lubov~ INF lubil, lublu, lubit, lubit~, lubila, lubimy˘i, lubix~
book INF book, books, booked, booking
book INF NOUN book, books
cook * cook NOUN, cook VERB
the cook (case insensitive) THE COOK, the cook, The Cook, the Cook, The cook
</table>
<tableCaption confidence="0.999939">
Table 1: Examples expansions for wildcard, inflection, and capitalization queries.
</tableCaption>
<subsectionHeader confidence="0.998568">
3.3 Capitalization
</subsectionHeader>
<bodyText confidence="0.999995368421053">
By aggregating different capitalizations of the
same word, one can normalize between sentence-
initial and sentence-medial occurrences of a given
word. A simple way to accomplish this is by
searching for a lowercased, capitalized and all
caps spelling of the query. This however can miss
CamelCase spelling and other capitalization vari-
ants (consider FitzGerald for example). It is
of course not feasible to try all case variants of ev-
ery letter in the query. Instead, we perform an of-
fline precomputation step in which we collect all
ngrams that map to the same lowercased string.
Due to scanning errors and spelling mistakes there
can be many extremely rare capitalization variants
for a given query. We therefore filter out all vari-
ants that have a cumulative count of less than 1%
of the most frequent variant for a given year range.
Capitalization searches are enabled by selecting a
case-insensitive check box on the new interface.
</bodyText>
<sectionHeader confidence="0.984681" genericHeader="method">
4 Use Cases
</sectionHeader>
<bodyText confidence="0.999943762711865">
The three features introduced in this paper repre-
sent a major extension of the capabilities of the
Ngram Viewer. While the second edition of the
Ngram Corpus (Lin et al., 2012) introduced syn-
tactic ngrams, the functionality of the Viewer had
remained largely unchanged since its first launch
five years ago. Together, the updated Corpus and
Viewer enable a much more detailed analysis of
the underlying data. Below we provide some uses
cases highlighting the ways in which sophisticated
queries can be crafted. While the results produce
some intriguing patterns, we leave their analysis to
the experts.
Since we have made no modifications to the un-
derlying raw ngrams, all of the plots in this pa-
per could have also been generated with the pre-
vious version of the Viewer. They would, how-
ever, have required the user to manually generate
and issue all query terms. For example, Figure 1
shows manually created queries searching for spe-
cific presidents; contrarily, Figure 4 shows single
wildcard queries that automatically retrieve the ten
most frequently mentioned presidents and uncover
additional trends that would have required extra
work on behalf of the user.
The wildcard feature used on its own can be a
powerful tool for the analysis of top expansions
for a certain context. Although already useful on
its own, it becomes really powerful when com-
bined with POS tags. The user can attach an un-
derscore and POS tag to either a wildcard-based
or inflection-based query to specify that the ex-
pansions returned should be of a specific part of
speech. Compare the utility of the generic wild-
card and a search with a noun part-of-speech spec-
ification in a query examining president names,
‘President *’ vs. ‘President * NOUN’
shown in Figure 4. The former gives a mixture
of prepositions, particles, and verbs along with
names of presidents, and because the latter spec-
ifies the noun tag, the top expansions turn out to
be names and more in line with the intention of
the search. Also, note in Figure 4 the difference in
expansions that searching over two different time
ranges provides. In Table 2, we compare the com-
bination of the wildcard feature with the existing
dependency link feature to highlight a comparison
of context across several languages.
It is worth noting that the newly introduced fea-
tures could result in many lines in the resulting
chart. Hence, we have updated the Viewer’s user
interface to better handle charts involving many
ngrams. The new interactive functionality allows
the user to highlight a line by hovering over it,
keep that focus by left clicking, and clear all fo-
cused lines by double clicking. A right click on
any of the expansions returned by an issued query
combines them into the year-wise sum total of all
the expansions. We added another feature to the
</bodyText>
<page confidence="0.992177">
119
</page>
<figure confidence="0.988419764705882">
Query: &amp;quot;light_INF&amp;quot; Query: &amp;quot;light_VERB_INF&amp;quot;
Relative Frequency
&amp;quot;light&amp;quot;
&amp;quot;lights&amp;quot;
&amp;quot;lighted&amp;quot;
&amp;quot;lighter&amp;quot;
&amp;quot;lit&amp;quot;
&amp;quot;lighting&amp;quot;
&amp;quot;lightest&amp;quot;
Relative Frequency
&amp;quot;light_VERB&amp;quot;
&amp;quot;lighted_VERB&amp;quot;
&amp;quot;lit_VERB&amp;quot;
&amp;quot;lighting_VERB&amp;quot;
&amp;quot;lights_VERB&amp;quot;
1700 1850 2000
1700 1850 2000
</figure>
<figureCaption confidence="0.999942">
Figure 5: Comparison of specification of POS tag in wildcard search.
</figureCaption>
<table confidence="0.4038665">
English American British German French Russian Italian Chinese Spanish Hebrew
(All) English English (Simplified)
drinks drinks drinks trinkt boit pbeT beve 喝 bebe Inv)
water water water Bier (beer) vin (wine) on (he) vino (wine) 酒 (wine) agua (water) 1)) (wine)
wine wine wine Kaffee (coffee) sang (blood) ma˘i (tea) acqua (water) 茶 (tea) vino (wine) 0))7 (water)
milk coffee tea Wein (wine) eau (water) voAy (water) sangue (blood) 水 (water) sangre (blood) II (the)
coffee beer blood Wasser (water) cafe (coffee) On (He) birra (beer) 咖啡 (coffee) vaso (glass) VII (cup)
beer milk beer Tee (tea) verre (glass) vino (wine) caff´e (coffee) 人 (person) cerveza (beer) In (tea)
</table>
<tableCaption confidence="0.95886">
Table 2: Comparison of the top modifiers of the verb drinks, or its equivalent in translation, in all corpora, retrieved via
the query drinks VERB=&gt;* NOUN and equivalents in the other languages. The modifiers can appear both in subject and in
object position because we have access only to unlabeled dependencies.
</tableCaption>
<bodyText confidence="0.999988761904762">
interface that creates static URLs maintaining all
the raw ngrams retrieved from any query. This pre-
vents statically linked charts from changing over
time, and allowing for backwards compatibility.
One of the primary benefits of the capitalization
feature is the combination of multiple searches
in one, which allows the user to compare case-
insensitive usages of two different phrases. An
alternative use is in Figure 2(c), where capitaliza-
tion search allows the immediate identification of
changing orthographic usage of a word or phrase;
in this case the figure shows the arrival of F. Scott
Fitzgerald in the early to mid 20th century, as well
as the rise in popularity of the CamelCase variety
of his surname at the turn of the 19th century.
Searches using inflections can be useful for the
same reasons as the capitalization feature, and also
be used to compare changes in spelling; it is par-
ticularly useful for the analysis of irregular verbs,
where the query can return both the regular and
irregular forms of a verb.
</bodyText>
<sectionHeader confidence="0.999787" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999972666666667">
We have presented an update to the Ngram Viewer
that introduces new search features. Users can
now perform more powerful searches that auto-
matically uncover trends which were previously
difficult or impossible to extract. We look forward
to seeing what users of the Viewer will discover.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.994072">
We would like to thank John DeNero, Jon Orwant,
Karl Moritz Hermann for many useful discussions.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702464285714">
A. Acerbi, V. Lampos, and R. A. Bentley. 2013. Ro-
bustness of emotion extraction from 20th century en-
glish books. In Proceedings of the IEEE Interna-
tional Conference on Big Data.
A. R. Bentley, A. Acerbi, P. Ormerod, and V. Lampos.
2014. Books average previous decade of economic
misery. PLOS One, 9(1).
G. Durrett and J. DeNero. 2013. Supervised learning
of complete morphological paradigms. In Proceed-
ings of NAACL-HLT.
Y. Lin, J.-B. Michel, E. L. Aiden, J. Orwant, W. Brock-
man, and S. Petrov. 2012. Syntactic annotations for
the Google Books Ngram Corpus. In Proceedings
of the ACL.
J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres,
M. K. Gray, The Google Books Team, J. P. Pick-
ett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant,
S. Pinker, M. A. Nowak, and E. Lieberman Aiden.
2011. Quantitative analysis of culture using millions
of digitized books. Science.
S. Petrov, D. Das, and R. McDonald. 2012. A univer-
sal part-of-speech tagset. In Proc. of LREC.
J. Schulz and L. Robinson. 2013. Shifting grounds and
evolving battlegrounds. American Journal of Cul-
tural Sociology, 1(3):373–402.
S. Skiena and C. Ward. 2013. Who’s Bigger?: Where
Historical Figures Really Rank. Cambridge Univer-
sity Press.
</reference>
<page confidence="0.996253">
120
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959146">
<title confidence="0.989307">Enhanced Search with Wildcards and Morphological in the Google Books Ngram Viewer</title>
<author confidence="0.999877">David Lu Dipanjan</author>
<affiliation confidence="0.999996">University University</affiliation>
<abstract confidence="0.998400230769231">We present a new version of the Google Books Ngram Viewer, which plots the frequency of words and phrases over the last five centuries; its data encompasses 6% of the world’s published books. The new Viewer adds three features for more powerful search: wildcards, morphological inflections, and capitalization. These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Acerbi</author>
<author>V Lampos</author>
<author>R A Bentley</author>
</authors>
<title>Robustness of emotion extraction from 20th century english books.</title>
<date>2013</date>
<booktitle>In Proceedings of the IEEE International Conference on Big Data.</booktitle>
<contexts>
<context position="1403" citStr="Acerbi et al., 2013" startWordPosition="217" endWordPosition="220">ject facilitates the analysis of cultural, social and linguistic trends through five centuries of written text in eight languages. The Ngram Corpus (Michel et al., 2011; Lin et al., 2012) consists of words and phrases (i.e., ngrams) and their usage frequency over time.1 The interactive Ngram Viewer2 allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. For example, the ngram data has been used to detect emotion trends in 20th century books (Acerbi et al., 2013), to analyze text focusing on market capitalism throughout the past century (Schulz and Robinson, 2013), detect social and cultural impact of historical personalities (Skiena and Ward, 2013), or to analyze the correlation of economic crises with a literary ‘misery ∗ The majority of this work was carried out during an internship at Google. 1The Ngram Corpus is freely available for download at http://books.google.com/ngrams/datasets. 2Seehttp://books.google.com/ngrams. Query: &amp;quot;President Kennedy, President Reagan, President Nixon&amp;quot; 1930 1965 2000 Figure 1: Mention frequencies for three different A</context>
</contexts>
<marker>Acerbi, Lampos, Bentley, 2013</marker>
<rawString>A. Acerbi, V. Lampos, and R. A. Bentley. 2013. Robustness of emotion extraction from 20th century english books. In Proceedings of the IEEE International Conference on Big Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Bentley</author>
<author>A Acerbi</author>
<author>P Ormerod</author>
<author>V Lampos</author>
</authors>
<title>Books average previous decade of economic misery.</title>
<date>2014</date>
<journal>PLOS One,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="2119" citStr="Bentley et al., 2014" startWordPosition="317" endWordPosition="320">n, 2013), detect social and cultural impact of historical personalities (Skiena and Ward, 2013), or to analyze the correlation of economic crises with a literary ‘misery ∗ The majority of this work was carried out during an internship at Google. 1The Ngram Corpus is freely available for download at http://books.google.com/ngrams/datasets. 2Seehttp://books.google.com/ngrams. Query: &amp;quot;President Kennedy, President Reagan, President Nixon&amp;quot; 1930 1965 2000 Figure 1: Mention frequencies for three different American presidents queried one-by-one. index’ reflected in printed text during crises periods (Bentley et al., 2014). A limitation of the Viewer, however, is that all the reasoning has to be done by the user, and only individual, user-specified ngrams can be retrieved and plotted. For example, to compare the popularity of different presidents, one needs to come up with a list of presidents and then search for them one-by-one. The result of the query ‘President Kennedy, President Nixon, President Reagan’ is shown in Figure 1. To determine the most popular president, one would need to search for all presidents, which is cumbersome and should ideally be automated. In this paper, we therefore present an updated</context>
</contexts>
<marker>Bentley, Acerbi, Ormerod, Lampos, 2014</marker>
<rawString>A. R. Bentley, A. Acerbi, P. Ormerod, and V. Lampos. 2014. Books average previous decade of economic misery. PLOS One, 9(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Durrett</author>
<author>J DeNero</author>
</authors>
<title>Supervised learning of complete morphological paradigms.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="15025" citStr="Durrett and DeNero (2013)" startWordPosition="2388" endWordPosition="2391"> across languages, but also for the same language), it can be useful to examine and potentially aggregate the frequencies of all inflected forms. This can be accomplished by manually deriving all inflected forms and then using arithmetic operations to aggregate their counts. Our new inflected form search accomplishes this automatically. By appending the keyword INF to a word, a set of ngrams with all inflected forms of the word will be retrieved. To generate the inflected forms we make use of Wiktionary3 and supplement it with automatically generated inflection tables based on the approach of Durrett and DeNero (2013). Because there are at most a few dozen inflected forms for any given word, we can afford to substitute and retrieve all inflections of the marked word, even the ones that are not grammatical in a given ngram context. This has the advantage that we only need to store inflected forms for individual words rather than entire ngrams. If a generated ngram has no support in the corpus, we simply omit it from the final set of results. We do not perform any additional filtering; as a result, an inflection search can produce many results, especially for morphologically rich languages like Russian. We h</context>
</contexts>
<marker>Durrett, DeNero, 2013</marker>
<rawString>G. Durrett and J. DeNero. 2013. Supervised learning of complete morphological paradigms. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lin</author>
<author>J-B Michel</author>
<author>E L Aiden</author>
<author>J Orwant</author>
<author>W Brockman</author>
<author>S Petrov</author>
</authors>
<title>Syntactic annotations for the Google Books Ngram Corpus.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="970" citStr="Lin et al., 2012" startWordPosition="143" endWordPosition="146">ency of words and phrases over the last five centuries; its data encompasses 6% of the world’s published books. The new Viewer adds three features for more powerful search: wildcards, morphological inflections, and capitalization. These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text. 1 Introduction The Google Books Ngram project facilitates the analysis of cultural, social and linguistic trends through five centuries of written text in eight languages. The Ngram Corpus (Michel et al., 2011; Lin et al., 2012) consists of words and phrases (i.e., ngrams) and their usage frequency over time.1 The interactive Ngram Viewer2 allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. For example, the ngram data has been used to detect emotion trends in 20th century books (Acerbi et al., 2013), to analyze text focusing on market capitalism throughout the past century (Schulz and Robinson, 2013), detect social and cultural impact of historical personalities </context>
<context position="5083" citStr="Lin et al., 2012" startWordPosition="785" endWordPosition="788">ement of the increase in data points returned. Detailed analysis and interpretation of trends uncovered with the new search interface is beyond the scope of this paper. We highlight some interesting use cases in §4; many of the presented queries were difficult (or impossible) to execute in the previous versions of the system. We emphasize that this demonstration updates only the Viewer, providing tools for easier analysis of the underlying corpora. The ngram corpora themselves are not updated. 2 System Overview We first briefly review the two editions of the Ngram Corpus (Michel et al., 2011; Lin et al., 2012) and then describe the extensions to the architecture of the Viewer that are needed to support the new search features. 2.1 The Ngram Corpus The Google Books Ngram Corpus provides ngram counts for eight different languages over more than 500 years; additionally, the English corpus is split further into British vs. American English and Fiction to aid domain-specific analysis. This corpus is a subset of all books digitized at Google and represents more than 6% of all publicized texts (Lin et al., 2012). Two editions of the corpus are available: the first edition dates from 2009 and is described </context>
<context position="6696" citStr="Lin et al. (2012)" startWordPosition="1057" endWordPosition="1060">rker that results in morphological inflections, and the case insensitive search functionality. Due to space considerations we show only a subset of the results returned by the Ngram Viewer. (2012). The new search features presented here are available for both editions. Michel et al. (2011) extract ngrams for each page in isolation. More specifically, they use whitespace tokenization and extract all ngrams up to length five. These ngrams include ones that potentially span sentence boundaries, but do not include ngrams that span across page breaks (even when they are part of the same sentence). Lin et al. (2012) on the other hand perform tokenization, text normalization and segmentation into sentences. They then add synthetic START and END tokens to the beginning and end of the senRelative Frequency University of California University of Chicago University of Wisconsin University of Michigan University of Pennsylvania 1950 1975 2000 Query: &amp;quot;fitzgerald [case-insensitive]&amp;quot; Relative Frequency book a hotel booked a hotel booking a hotel books a hotel Relative Frequency Fitzgerald FitzGerald FITZGERALD 116 tences to enable the distinction of sentence medial ngrams from those near sentence boundaries. They</context>
<context position="8147" citStr="Lin et al. (2012)" startWordPosition="1282" endWordPosition="1285">tion for dating the books, the ngrams counts from the two editions are not the same. The edition from Lin et al. (2012) additionally includes syntactic ngrams. The corpus is tagged using the universal part-of-speech (POS) tag set of Petrov et al. (2012): NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners and articles), ADP (prepositions and postpositions), CONJ (conjunctions). Words can be disambiguated by their POS tag by simply appending the tag to the word with an underscore (e.g. book NOUN) and can also be replaced by POS tags in the ngrams, see Lin et al. (2012) for details. The corpus is parsed with a dependency parser and head-modifier syntactic relations between words in the same sentence are extracted. Dependency relations are represented as ‘=&gt;’ in the corpus. Our new enhanced search features for automatic expansions can also be applied to these syntactic ngrams. In fact, some of the most interesting queries use expansions to automatically uncover related ngrams, while using syntax to focus on particular patterns. The Viewer supports the composition of ngram frequencies via arithmetic operators. Addition (+), subtraction (-) and division (/) of </context>
<context position="17497" citStr="Lin et al., 2012" startWordPosition="2795" endWordPosition="2798">p in which we collect all ngrams that map to the same lowercased string. Due to scanning errors and spelling mistakes there can be many extremely rare capitalization variants for a given query. We therefore filter out all variants that have a cumulative count of less than 1% of the most frequent variant for a given year range. Capitalization searches are enabled by selecting a case-insensitive check box on the new interface. 4 Use Cases The three features introduced in this paper represent a major extension of the capabilities of the Ngram Viewer. While the second edition of the Ngram Corpus (Lin et al., 2012) introduced syntactic ngrams, the functionality of the Viewer had remained largely unchanged since its first launch five years ago. Together, the updated Corpus and Viewer enable a much more detailed analysis of the underlying data. Below we provide some uses cases highlighting the ways in which sophisticated queries can be crafted. While the results produce some intriguing patterns, we leave their analysis to the experts. Since we have made no modifications to the underlying raw ngrams, all of the plots in this paper could have also been generated with the previous version of the Viewer. They</context>
</contexts>
<marker>Lin, Michel, Aiden, Orwant, Brockman, Petrov, 2012</marker>
<rawString>Y. Lin, J.-B. Michel, E. L. Aiden, J. Orwant, W. Brockman, and S. Petrov. 2012. Syntactic annotations for the Google Books Ngram Corpus. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-B Michel</author>
<author>Y K Shen</author>
<author>A P Aiden</author>
<author>A Veres</author>
<author>M K Gray</author>
</authors>
<title>The Google Books</title>
<date>2011</date>
<publisher>Science.</publisher>
<contexts>
<context position="951" citStr="Michel et al., 2011" startWordPosition="139" endWordPosition="142">which plots the frequency of words and phrases over the last five centuries; its data encompasses 6% of the world’s published books. The new Viewer adds three features for more powerful search: wildcards, morphological inflections, and capitalization. These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text. 1 Introduction The Google Books Ngram project facilitates the analysis of cultural, social and linguistic trends through five centuries of written text in eight languages. The Ngram Corpus (Michel et al., 2011; Lin et al., 2012) consists of words and phrases (i.e., ngrams) and their usage frequency over time.1 The interactive Ngram Viewer2 allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. For example, the ngram data has been used to detect emotion trends in 20th century books (Acerbi et al., 2013), to analyze text focusing on market capitalism throughout the past century (Schulz and Robinson, 2013), detect social and cultural impact of histor</context>
<context position="5064" citStr="Michel et al., 2011" startWordPosition="781" endWordPosition="784">llow for easier management of the increase in data points returned. Detailed analysis and interpretation of trends uncovered with the new search interface is beyond the scope of this paper. We highlight some interesting use cases in §4; many of the presented queries were difficult (or impossible) to execute in the previous versions of the system. We emphasize that this demonstration updates only the Viewer, providing tools for easier analysis of the underlying corpora. The ngram corpora themselves are not updated. 2 System Overview We first briefly review the two editions of the Ngram Corpus (Michel et al., 2011; Lin et al., 2012) and then describe the extensions to the architecture of the Viewer that are needed to support the new search features. 2.1 The Ngram Corpus The Google Books Ngram Corpus provides ngram counts for eight different languages over more than 500 years; additionally, the English corpus is split further into British vs. American English and Fiction to aid domain-specific analysis. This corpus is a subset of all books digitized at Google and represents more than 6% of all publicized texts (Lin et al., 2012). Two editions of the corpus are available: the first edition dates from 200</context>
<context position="6369" citStr="Michel et al. (2011)" startWordPosition="1002" endWordPosition="1005">scribed in Lin et al. Query: &amp;quot;University of *&amp;quot; 1900 1950 2000 Query: &amp;quot;book_INF a hotel&amp;quot; 1800 1900 2000 Figure 2: In the new enhanced search features of the Ngram Viewer, a single query is automatically expanded to retrieve multiple related ngrams. From top to bottom, we show examples of the wildcard operator (‘*’), the ‘ INF’ marker that results in morphological inflections, and the case insensitive search functionality. Due to space considerations we show only a subset of the results returned by the Ngram Viewer. (2012). The new search features presented here are available for both editions. Michel et al. (2011) extract ngrams for each page in isolation. More specifically, they use whitespace tokenization and extract all ngrams up to length five. These ngrams include ones that potentially span sentence boundaries, but do not include ngrams that span across page breaks (even when they are part of the same sentence). Lin et al. (2012) on the other hand perform tokenization, text normalization and segmentation into sentences. They then add synthetic START and END tokens to the beginning and end of the senRelative Frequency University of California University of Chicago University of Wisconsin University</context>
</contexts>
<marker>Michel, Shen, Aiden, Veres, Gray, 2011</marker>
<rawString>J.-B. Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K. Gray, The Google Books Team, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig, J. Orwant, S. Pinker, M. A. Nowak, and E. Lieberman Aiden. 2011. Quantitative analysis of culture using millions of digitized books. Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="7783" citStr="Petrov et al. (2012)" startWordPosition="1223" endWordPosition="1226">gerald FitzGerald FITZGERALD 116 tences to enable the distinction of sentence medial ngrams from those near sentence boundaries. They also ensure that sentences that span across page boundaries are included. Due to these differences, as well as the availability of additional book data, improvements to the optical character recognition algorithms and metadata extraction for dating the books, the ngrams counts from the two editions are not the same. The edition from Lin et al. (2012) additionally includes syntactic ngrams. The corpus is tagged using the universal part-of-speech (POS) tag set of Petrov et al. (2012): NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners and articles), ADP (prepositions and postpositions), CONJ (conjunctions). Words can be disambiguated by their POS tag by simply appending the tag to the word with an underscore (e.g. book NOUN) and can also be replaced by POS tags in the ngrams, see Lin et al. (2012) for details. The corpus is parsed with a dependency parser and head-modifier syntactic relations between words in the same sentence are extracted. Dependency relations are represented as ‘=&gt;’ in the corpus. Our new enhanced search feat</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2012. A universal part-of-speech tagset. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schulz</author>
<author>L Robinson</author>
</authors>
<title>Shifting grounds and evolving battlegrounds.</title>
<date>2013</date>
<journal>American Journal of Cultural Sociology,</journal>
<volume>1</volume>
<issue>3</issue>
<contexts>
<context position="1506" citStr="Schulz and Robinson, 2013" startWordPosition="232" endWordPosition="235"> written text in eight languages. The Ngram Corpus (Michel et al., 2011; Lin et al., 2012) consists of words and phrases (i.e., ngrams) and their usage frequency over time.1 The interactive Ngram Viewer2 allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. For example, the ngram data has been used to detect emotion trends in 20th century books (Acerbi et al., 2013), to analyze text focusing on market capitalism throughout the past century (Schulz and Robinson, 2013), detect social and cultural impact of historical personalities (Skiena and Ward, 2013), or to analyze the correlation of economic crises with a literary ‘misery ∗ The majority of this work was carried out during an internship at Google. 1The Ngram Corpus is freely available for download at http://books.google.com/ngrams/datasets. 2Seehttp://books.google.com/ngrams. Query: &amp;quot;President Kennedy, President Reagan, President Nixon&amp;quot; 1930 1965 2000 Figure 1: Mention frequencies for three different American presidents queried one-by-one. index’ reflected in printed text during crises periods (Bentley </context>
</contexts>
<marker>Schulz, Robinson, 2013</marker>
<rawString>J. Schulz and L. Robinson. 2013. Shifting grounds and evolving battlegrounds. American Journal of Cultural Sociology, 1(3):373–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Skiena</author>
<author>C Ward</author>
</authors>
<title>Who’s Bigger?: Where Historical Figures Really Rank.</title>
<date>2013</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1593" citStr="Skiena and Ward, 2013" startWordPosition="245" endWordPosition="248">consists of words and phrases (i.e., ngrams) and their usage frequency over time.1 The interactive Ngram Viewer2 allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. For example, the ngram data has been used to detect emotion trends in 20th century books (Acerbi et al., 2013), to analyze text focusing on market capitalism throughout the past century (Schulz and Robinson, 2013), detect social and cultural impact of historical personalities (Skiena and Ward, 2013), or to analyze the correlation of economic crises with a literary ‘misery ∗ The majority of this work was carried out during an internship at Google. 1The Ngram Corpus is freely available for download at http://books.google.com/ngrams/datasets. 2Seehttp://books.google.com/ngrams. Query: &amp;quot;President Kennedy, President Reagan, President Nixon&amp;quot; 1930 1965 2000 Figure 1: Mention frequencies for three different American presidents queried one-by-one. index’ reflected in printed text during crises periods (Bentley et al., 2014). A limitation of the Viewer, however, is that all the reasoning has to be</context>
</contexts>
<marker>Skiena, Ward, 2013</marker>
<rawString>S. Skiena and C. Ward. 2013. Who’s Bigger?: Where Historical Figures Really Rank. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>