<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.994514">
Question-Answering Based on Virtually Integrated Lexical
Knowledge Base
</title>
<author confidence="0.879574">
Key-Sun Choi
</author>
<affiliation confidence="0.7030315">
KAIST,Korterm
Daejeon
</affiliation>
<address confidence="0.913229">
305-701 Korea
</address>
<email confidence="0.743145">
kschoi@cs.ka
ist.ac.kr
</email>
<note confidence="0.587730666666667">
Jae-Ho Kim
KAIST,Korterm
Daejeon
</note>
<address confidence="0.822716">
305-701 Korea
</address>
<email confidence="0.6893805">
jjaeh@world.
kaist.ac.kr
</email>
<note confidence="0.806807333333333">
Masaru
Miyazaki
NHK STRL
</note>
<address confidence="0.590689">
Tokyo 157-8510
Japan
</address>
<email confidence="0.7795695">
miyazaki.m-
fk@nhk.or.jp
</email>
<note confidence="0.887914">
Jun Goto
NHK STRL
Human Science
</note>
<address confidence="0.557821">
Tokyo 157-8510
Japan
</address>
<email confidence="0.751028">
goto.j-
fw@nhk.or.jp
</email>
<note confidence="0.951631">
Yeun-Bae Kim
NHK STRL
Human Science
</note>
<author confidence="0.469468">
Tokyo 157-8510
</author>
<affiliation confidence="0.445225">
Japan
</affiliation>
<email confidence="0.752781">
kimu.y-
go@nhk.or.jp
</email>
<sectionHeader confidence="0.996423" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980307692308">
This paper proposes an algorithm for cau-
sality inference based on a set of lexical
knowledge bases that contain information
about such items as event role, is-a hier-
archy, relevant relation, antonymy, and
other features. These lexical knowledge
bases have mainly made use of lexical
features and symbols in HowNet. Several
types of questions are experimented to
test the effectiveness of the algorithm here
proposed. Particularly in this paper, the
question form of “why” is dealt with to
show how causality inference works.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999886384615384">
A virtually linked knowledge base is designed to
utilize a pre-constructed knowledge base in a dy-
namic mode when it is in actual use.
An open-domain question answering architec-
ture must consist of various components and
processes (Pasça, 2001) that include WordNet-
like resources, part of speech tagging, parsing,
named entity recognition, question processing,
passage retrieval, answer extraction, and answer
justification. Consider a question like the follow-
ing: “Why do doctors cure patients?”
The answer may be obtained by commonsense
knowledge as follows:
</bodyText>
<listItem confidence="0.959319875">
1. A patient suffered from a
disease.
2. A doctor cures the disease.
3. The doctor cures at hospi-
tal.
4. Doctor is an occupation.
5. So the doctor cures the
patient.
</listItem>
<bodyText confidence="0.991745">
These sentences are transformed into proposi-
tional forms, as illustrated below:
</bodyText>
<figure confidence="0.8283936">
6. sufferFrom(patient,disease)
7. cure(doctor,disease)
8. cure(doctor,at-hospital)
9. occupation(doctor)
10. cure(doctor,patient)
</figure>
<bodyText confidence="0.997116740740741">
Linguistic knowledge bases like WordNet
(Miller, 1995), EDR dictionary (Yokoi, 1995) and
HowNet (Dong, 1999) have been used to interpret
these sentences.
Moldovan et al. (2002) generated lexical chains
from WordNet in order to trace these topically re-
lated paths and thereby to search for causal expla-
nations. A conceptual word Cj inside of a gloss
under a synset Ci is linked to the synset Cj.
HowNet (Dong et al. 1999) is a linguistic
knowledge base that is designed to have the defini-
tion of words and concepts as well as event role
and role-filling entities. Commonsense knowledge
like naive physics is also built up through event
role relation like the relation of sufferFrom requir-
ing cure.
HowNet is modularized into separate knowl-
edge spaces for entity hierarchy, event hierarchy,
antonymy, syntax, attributes, etc. Relations be-
tween various concepts (e.g., part-of, relevance,
location) are defined implicitly in the definition of
each concept.
This paper will focus on building an algorithm
that allows for searching for some topical paths in
order to find causal explanations for questions like
“Why do doctors cure patients?” or “Why do pa-
tients pay money?” as illustrated in Figure 1.
</bodyText>
<figureCaption confidence="0.745307666666667">
Figure 1: A Snapshot of a virtually integrated
knowledge base for the question: “Why do patients
pay money to doctors?”
</figureCaption>
<bodyText confidence="0.999006666666667">
In the following sections, issues on the virtual in-
tegration of knowledge bases, their algorithms and
experimentations are presented.
</bodyText>
<sectionHeader confidence="0.8171185" genericHeader="introduction">
2 Underlined Knowledge Bases and Vir-
tual Integration
</sectionHeader>
<bodyText confidence="0.9537175">
In Figure 1, each marked numbering has the fol-
lowing meaning:
</bodyText>
<listItem confidence="0.997692206896551">
(1) Entity hierarchy: entity is the top node in
the hierarchy of entities.
(2) entity is the hypernym of patient, doctor,
occupation, and money in the line (3).
(3) Concepts or word entries are listed in this
line. All concepts and word entries repre-
sent their definition by a list of concepts
and marked pointers.
(4) A concept (or word) in (3) features defini-
tional relations to a list of concepts. For
example, a doctor definition is composed
of two concepts and their marking point-
ers: #occupation and *cure. Pointers in
HowNet represent relations between two
concepts or word entries, e.g., “#” means
“relevant” and “*” does “agent”.
(5) syn refers to the syntactic relation in the
question “Why do patients pay money to
doctors?”
(6) converse refers to the converse relation be-
tween events, e.g., give and take.
(7) Event hierarchy: For example, the hy-
pernym for pay is give and the hypernym
of give is event.
(8) Event role: Now, event roles are partially
filled with entities, e.g., patient and
money.
(9) Event role shift: The agent of give is
equalized to the source of take.
</listItem>
<bodyText confidence="0.999012333333333">
An overview of each component of the knowl-
edge base is in Figure 2, where three word entries
why, patient, and money are in the dictionary.
The four concept facets of entity, role, event, and
converse are described in this example, mainly as
part of linguistic knowledge.
</bodyText>
<figureCaption confidence="0.99496">
Figure 2: HowNet Architecture in Example.
</figureCaption>
<bodyText confidence="0.999642611111111">
Some issues on ontology integration have been
discussed from various points of view. Pinto et al.
(1999) classified the notions of ontology integra-
tion into three types: integration, merging and
use/application. The term virtually integrated
means the view of ontology-based use/application.
This paper presents issues on and arguments for
linguistic knowledge base and commonsense
knowledge in (Lenat, Miller and Yokoi, 1995).
One of the arguments was whether linguistic
knowledge could be separated from commonsense
knowledge, but it was agreed that both types of
knowledge were essentially required for natural
language processing.
This paper was motivated by the desire to make
inferences using a lexical knowledge base, thus
successfully carrying out a kind of commonsense
reasoning.
</bodyText>
<figure confidence="0.972334983606557">
(2) (3)
(1)
entity
agent=patient
possession=money
target=?
patient
$cure *cure earn $earn
(5)syn
*pay $pay
(6)
(7)
(8)
doctor
give
#occupation
converse
event
(9)
occupation
agent=?
possession=money
source=patient
take
(4)
money
patient
dictionary
why
pay
Concept
facets
role
question
cure
cause
human
doctor
#occupation
*cure earn $earn
pay
Alter-possession
give take
agent=
possession=
target=
give take
entity
event
occupation
converse
earn
agent=
possession=
source=
money
3 Interpretation of Lexical Knowledge
Consider the following three sentences:
11. Doctors cure patients.
12. Doctors earn money.
13. Patients pay money.
</figure>
<bodyText confidence="0.989513333333333">
One major concern is finding connectability
among words and concepts. As shown in Figure 2,
the following facts are derived:
</bodyText>
<listItem confidence="0.9794075">
14. Doctor is relevant to oc-
cupation.
15. Occupation allows you to
earn money.
</listItem>
<bodyText confidence="0.984075457142857">
Because there exists a converse relation be-
tween give and take, their hyponyms earn and pay
also fall under converse relation. It is something
like the following social commonsense as shown in
Figure 2: “If someone X pays money to the other Y,
Y earns money from X.”
We humans now understand the reason for
“why patients pay money.” The answer is that
“doctors cure patients as their occupation allowing
them to earn money.”
The following is a valid syllogism where Y is
being instantiated to doctor:
If “X pays money to Y” is
equivalent to “Y earns money
from X”1, and “a doctor earns
money from X”, then “X pays
money to the doctor”.
Consider the next syllogism: If “a doctor
cures X” and “doctor is an occupa-
tion” and Axiom 1, then “the doc-
tor earns money from X”.
Axiom 1 is needed to make such a syllogism
that “If Y cures X and Y is an occu-
pation, then Y earns money from
X.” Then our challenge is to find out this Axiom
1 from the lexical knowledge bases. It is a com-
monsense and thus there is a gap in the lexical
knowledge base.
The following is a list of questions derived
from the three sentences of 11, 12 and 13 which
are designed to discover such axioms (or rules)
from a set of lexical knowledge bases: “Why do
doctors cure patient?”, “Why do doctors earn
money?”, and “Why do patients pay money to doc-
tors?”
</bodyText>
<sectionHeader confidence="0.910427" genericHeader="method">
4 Connectability: Similarity Measure
</sectionHeader>
<bodyText confidence="0.999943857142857">
Consider the query “Why do doctors cure pa-
tients?” Tracing Figure 2 back through Figure 1
leads to obtaining logical forms from 6 through 10.
The best connectable path is planned from the first
word of the question.
For each pair of words, the function called
&amp;quot;similar(*,*)&amp;quot; will be estimated to choose the next
best tracing concepts (or words). similar&apos;s mis-
sions are summarized as (1) checking the connect-
ability between two nodes2, (2) selecting the best
sense of the node,3 (3) selecting the best tracing
candidate node in the next step. Finally, following
the guidance by similar allows us to explain the
question.
</bodyText>
<subsectionHeader confidence="0.98577">
4.1 Observation and Evidence of Topical Re-
latedness
</subsectionHeader>
<bodyText confidence="0.9845848">
Let&apos;s try to follow the steps 6-10 given in the logi-
cal forms. In the question “Why do doctors cure
patient?” that focuses on three words doctor, cure,
and patient, we can trace some key words given in
example sentences as follows: patient — disease —
cure — doctor — occupation — earn — pay — pa-
tient.
What kind of lexical relations are relevant to
each pair of words or concepts? Their observation
can be summarized as follows:
</bodyText>
<listItem confidence="0.924045642857143">
A) The relation between patient — disease is a
role relation of “sufferFrom(patient, dis-
ease)”.
B) A sequence of cure — doctor — occupation
— earn lets us infer the relation among
cure — earn, which are closely linked by
their relevance relation to occupation.
Furthermore, earn and cure shares a
common subject of these two events.
C) The sequence of earn ~ pay is the result of
a converse event relation between earn
and pay.
D) pay — patient: The agent of pay is a ge-
neric human. In other words, pay is a hy-
</listItem>
<footnote confidence="0.883613333333333">
2 A node means either concept or word.
3 It is similar with word sense disambiguation.
1 It is a converse relation.
</footnote>
<bodyText confidence="0.9459598125">
ponym for the act of human, one of whose
hyponym is patient.
Consider again the match between the tracing
sequences of concepts and the knowledge base.
Going into more details, notations with footnotes
will be given to each example. At this point, we
will give names and formalization based on the
observed characteristics.
A) Feature comparison: To find the role re-
lation among patient — disease, search the
definition of entities (referring to patient
and disease) in ways that two entities share
the same event concept (referring to
cure):4
patient ⊃ human $cure *sufferFrom.
disease ⊃ medical $cure undesired.
</bodyText>
<listItem confidence="0.977228454545455">
B) Interrelation: To find the event interrela-
tion among cure — earn, two possible
paths are presented as follows.
• First, inverse interrelation: Two event&apos;s
role entities can be found by searching all of
entities using *earn — *cure that share the
same subject, and using *earn — $cure
where the subject of earn is the object of
cure.
• Second, sister interrelation: The following
logical form can be derived from Figure 2:5
</listItem>
<bodyText confidence="0.988477">
doctor ⊃ *cure #occupation.
occupation ⊃ earn.
Because cure and occupation is in the defi-
nition of doctor, a probable logical implica-
tion can be derived as follows:6
*cure ⊃ ~#occupation.
C) Converse/antonymy: earn and pay have
their respective hypernyms take and give.
There exists a converse relation between
these two hypernyms.
</bodyText>
<footnote confidence="0.722018">
4 According to HowNet convention, “$” represents patient,
target, possession, or content of an event, and “*” represents
agent, experiencer, or instrument. “⊃” means implies or has
features.
5 “#” means “relevant”.
6 “—” means “very probable”.
</footnote>
<figure confidence="0.921115285714286">
D) Inheritance: The relation among pay —
patient is represented as follows:7
pay act
p
human ⊃ *act
patient human
p
</figure>
<subsectionHeader confidence="0.993191">
4.2 Rationale of Connectability
</subsectionHeader>
<bodyText confidence="0.999074785714286">
In the former section, we summarized four charac-
teristics8 of causality (relatedness)-based path find-
ing: feature comparison, interrelation,
converse/antonymy in their hypernym’s level, and
inheritance. Among search spaces available, it is
necessary to find out a measure of guiding the op-
timal9 path tracing.
We will call such a measure similar which will
be defined according to the four characteristics just
mentioned. Further details about the calculation
formula will be presented again later.
A) For “feature comparison”, the measure fea-
ture similar(X,Y) defines the notion of
similarity between the features in X and Y.
</bodyText>
<listItem confidence="0.972375714285714">
B) There are two interrelations in the last sec-
tion.
• For “inverse interrelation”&apos;, inverse simi-
lar(X,Y) calculates how much similarity ex-
ists between X6 and Y6 in a manner that X6
= {Z  |Z c 6X}, where 6X is an abstraction
of role-marked concepts like *X, $X, #X,
etc. Thus inverse similar(X,Y) = simi-
lar(X9,Y9).
• For “sister interrelation”, the measure sister
similar(X,Y) means the following two situa-
tions: First, X and Y are features to define
one concept (say, W). Second, one of them,
say, Y&apos;s definitional feature concepts (refer-
ring to Z) are similar with X such that X and
Z are similar if W ⊃ X Y and Y ⊃ Z.
C) Converse or antonymy: The converse re-
lation converse(X,Y) can be found by the
measure feature similar. converse(X,Y) is
formulated by X c 6Y and Y c 6X where
6 = converse.
</listItem>
<page confidence="0.582134333333333">
7 “ X � Y ” means “Y is hypernym of X”.
8 Their exhaustiveness should be discussed later.
9 “optimal” will not be discussed.
</page>
<bodyText confidence="0.999605588235294">
D) Using inheritance property in the concept
hierarchy, relations between hypernym of
concepts X and Y are inherited to X and Y
in a way that X and Y is similar if there
exist X’ and Z such that X � X&apos;, Z ⊃ θX’,
and Y � Z where θ is a pointer or null.
This inheritance tracing can be determined
by how much similar X and Y are in terms
of their path upward based on the relation
of hypernym. We will define path similar.
But tracing the path upward following hy-
pernym links is to be described later ac-
cording to the algorithm.
A measure called similar will be defined based
on the discussion in this section. Then an algorithm
is introduced through this measure with an exam-
ple.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="method">
5 Measures
</sectionHeader>
<bodyText confidence="0.998902">
In the last section, we discussed four kinds of the
measure similar.
</bodyText>
<listItem confidence="0.99991875">
• path similar,
• feature similar,
• inverse similar,
• sister similar.
</listItem>
<bodyText confidence="0.999963142857143">
For feature, inverse, and sister similar func-
tions, path similar is used as a basis of calculation.
They are different with respect to both their search
method and the depth of expanding features. fea-
ture similar finds similar features by using path
similar. inverse similar(X,Y) searches for entries
that contain X and Y as features and then use the
path similar. In the same way, sister similar finds
sister concepts, expands them, and finally meas-
ures using the path similar.
Since path similar plays a key role in all these
search and measure processes, its role will be ex-
plained in the next subsection. Other measures are
only dealt with as part of the algorithm.
</bodyText>
<subsectionHeader confidence="0.799211">
5.1 Similarity Based on Hierarchy and Fea-
</subsectionHeader>
<bodyText confidence="0.983979647058824">
ture
The mission of the measuring function simi-
lar(X,Y) is to calculate their relevancy between
two concepts or words whether they are of type
entity, event, or of some other type.
If X and Y belong to different types of knowl-
edge plane (e.g., entity and event), it is hard to
compare their hypernym path upward to the top
concept. However, if different types of concepts
have any relevance to (connect) causality, we will
use feature similar or inverse similar after find-
ing the same type of concepts to calculate the path
similar. Now we will explain the above by using
two pairs of concept type: entity-entity and entity-
event, without loss of generality.
First, pathsimilar(entity X, entity Y) is de-
fined as follows:
</bodyText>
<equation confidence="0.995722">
pathsimila r(X , Y)
2× path+(X)
=
path+(X) + path+(Y)
</equation>
<bodyText confidence="0.820542">
where path+(X) is the ordered list of hypernym for
X by descending order from the top concept. For
example,
</bodyText>
<equation confidence="0.948705">
path+(doctor)
= [entity...animate...human.doctor]
path+(patient)
= [entity...animate...human.patient]
</equation>
<bodyText confidence="0.9691842">
Because |path+(X) |counts the number of nodes on
the path, pathsimilar(doctor,patient) = 2×
6/(7+7)=0.857.
Second, pathsimilar(entity N, event V) is de-
fined as follows:
pathsimilar(N,V)
= Max pathsimilar(N.feature,V)
where N.Jeature means the feature list in the defi-
nition of N. The following is an illustrative exam-
ple for the definition:
money ⊃ $earn,*buy,#sell, $setAside,
it is equivalent to the following:
money.feature=[$earn,*buy,#sell,$setAside].
So pathsimilar(money,earn)=pathsimilar(earn,earn)
=1. According to this Max function, the selection
priorities for the path can be specified.
Third, pathsimilar(event V, entity N) is de-
fined by inverse similar as follows: pathsimi-
lar(V,N) = Max pathsimilar(V.inverse, N). For
example, pathsimilar(cure, doctor) = Max path-
similar(cure.inverse, doctor) = Max pathsimi-
lar({doctor, medical worker, medicine, patient},
doctor).
Fourth, pathsimilar(event X, event Y) shares
the same formula with pathsimilar(entity X, en-
</bodyText>
<equation confidence="0.7093505">
+
∩ path (Y)
</equation>
<bodyText confidence="0.947562666666667">
tity Y) shown before. But, we can give another
inverse pathsimilar(event X, event Y) = Max
pathsimilar(X.inverse, Y.inverse).
</bodyText>
<subsectionHeader confidence="0.999203">
5.2 Logical Implication and Expansion Depth
</subsectionHeader>
<bodyText confidence="0.962534428571429">
All of the relations in Figure 2 are translated into
logical form (see below). As shown in “Interpreta-
tion as Abduction” (Hobbs et al. 1988), “abductive
inference is inference to the best explanation”.
These relations showed “the interpretation of a text
is the minimal explanation of why the text would
be true” based on the abductive inference. By the
same token, “the interpretation of a question is the
minimal explanation of why the question would be
true” based on a set of lexical knowledge bases.
Before proceeding to our algorithm, an example
will be applied to abductive inference briefly as a
set of logical forms as well as a diagram in Figure
3.
</bodyText>
<reference confidence="0.8060270625">
16. doctor ⊃ human, #occupation,
*cure, medical.
17. medicine ⊃ *cure.
18. disease ⊃ $cure.
19. cure ⊃ medical,
{agent,patient,content}.
20. medical ⊃ #cure.
21. converse(pay,earn) ⊃
agent=source,
target=agent.
22. patient ⊃ human,$cure.
23. occupation ⊃ affairs, earn.
24. cause(cure,sufferFrom) ⊃
patient=experiencer,
content=content.
25. possibleConsequence(cure,
</reference>
<equation confidence="0.832545">
beRecovered) ⊃
</equation>
<bodyText confidence="0.963475333333333">
patient=experiencer,
content=stateIni.
While pursuing the path tracing enabling mini-
mal explanation, now we are going to propose
a connectability measure similar such as
“weighted abduction” (Hobbs et al. 1988). As
“likelihood estimation” is useful to consider a
“bounded conditioning” (Russell &amp; Norvig, 1995)
in a belief network, the “expansion depth” of simi-
lar will be useful for the explanation path tracing
for the purpose of the minimal explanation of the
question.
</bodyText>
<figureCaption confidence="0.996411">
Figure 3: Virtual Linking for Causality
</figureCaption>
<bodyText confidence="0.994454285714286">
The “expansion depth level” of similar has two
kinds of utilities: one is to find the minimal expla-
nation, and the other is to be dynamically adapt-
able to the level of interaction. This level of
similar is defined as a function simi-
lar(Level)(X,Y) for X and Y, concepts or words in
the following manner:
</bodyText>
<listItem confidence="0.997943625">
• similar(0)=pathsimilar: they use only them-
selves and their hypernym path from X and
Y.
• similar(1)=feature_similar: they use their
features that are expanded one more than
similar(0).
• similar(2)=inverse_similar
• similar(3)=sister_similar
</listItem>
<bodyText confidence="0.937952">
=inverse_similar×feature_similar.
Depending on what level of similar is chosen,
the search paths may be changed. A snapshot up to
similar(2) is given in Figure 4.
</bodyText>
<figureCaption confidence="0.998765">
Figure 4: Snapshot for similar(2).
</figureCaption>
<figure confidence="0.985850961538462">
money
*buy
#sell
$setAside
commercial
agent
content
source
$earn
occupation
affirs
earn
why
patient
human
*sufferFrom
$cure
medical
#occupation
*cure
human
doctor
pay
payer*
money
advanced$
inverse
give
hypernym
converse
take
hypernym
why
human
#occupation
*cure
medical
doctor cure
patient
agent
patient
content
medical
e*
medicine*
d&amp;
disease$
m#
medical#
human
* sufferFrom
$cure
</figure>
<sectionHeader confidence="0.772771" genericHeader="method">
6 Tracing Algorithms
</sectionHeader>
<subsectionHeader confidence="0.993605">
6.1 Algorithm Crossover
</subsectionHeader>
<bodyText confidence="0.9984235">
The overall algorithm 10 flow depends on simi-
lar(Level) as in the next program.
</bodyText>
<table confidence="0.7027684">
Algorithm Crossover
For Level=0...N until stopping
condition is satisfied:
Expand the trace
by similar(Level)
</table>
<bodyText confidence="0.999360315789474">
For example, when Level=1, the algorithm cross-
over finds a very primitive answer to the question
“Why do doctors cure patients?” We will expand
other features of doctor except for cure because
cure has a syntactic relation between doctor and
patient.
As shown in the logical forms (16—24) intro-
duced in the previous section, this algorithm in
Level=1 can find the following concepts as a re-
sult: medical, human, cure ($cure, *cure).
When Level=2, the algorithm crossover will
seek higher-order relations (like the hypothesis)
from the concept (by inverse_similar), con-
verse/antonymy relations (by feature_similar),
and event relations (if any, for use in knowing
the cause or consequence relation). Consider again
our example &amp;quot;Why do doctors cure patients?&amp;quot; by
using the previous section&apos;s logical forms. The re-
sults are as follows:
</bodyText>
<equation confidence="0.97636675">
*cure = {doctor, medicine}
$cure = {patient, disease}
*sufferFrom = {patient}
$sufferFrom = {disease}
</equation>
<bodyText confidence="0.9994174">
Its generated meaning may be “If a doctor cures a
patient, the patient is recovered from disease.
Because patients suffer from diseases, doctors cure
the patients. Patients are recovered after getting
cured.”
</bodyText>
<subsectionHeader confidence="0.999025">
6.2 Stopping Condition
</subsectionHeader>
<bodyText confidence="0.9983195">
Stopping conditions for the algorithm crossover
are as follows:
</bodyText>
<listItem confidence="0.821941">
(1) Event roles are filled up.
(2) If no event is found in the feature defini-
tion, increase similar level.
10 This algorithm will be called “crossover”.
(3) [weak stopping condition] When there is
</listItem>
<bodyText confidence="0.905798">
no event, one of the other features is com-
monly shared between two concepts. For
example, medical is a common feature be-
tween doctor and cure.
</bodyText>
<subsectionHeader confidence="0.997418">
6.3 Hypernym Climbing
</subsectionHeader>
<bodyText confidence="0.9993135">
In section 4.2, inheritance was discussed for the
purpose of finding a relation among pay — patient.
After trying to make Level=2 in section 5.2, we
have been motivated to find the interrelation be-
tween hypernyms. The algorithm crossover is up-
dated.
</bodyText>
<table confidence="0.780643666666667">
Algorithm Crossover+
For Level=0..N until stopping
condition is satisfied:
Expand the trace
by similar(Level)
If Level &gt;= 2, then
repeat climb up hypernym
until it matches with
the higher relation.
</table>
<subsectionHeader confidence="0.868764">
6.4 Algorithm Crossover++
</subsectionHeader>
<bodyText confidence="0.9999844">
Consider again the question &amp;quot;Why do patients pay
money to doctors?&amp;quot; As shown in Figure 1, the best
trace is $cure — *cure — *earn — $pay. It provides
an explanation for the statement that “patients are
cured by doctors — doctors earn money — patients
pay money to doctors”. This minimal explanation
is observed by switching over the role pointers θ
whenever tracing is performed. For example,
$cure was switched over to *cure. This extended
version of algorithm is called Crossover++.
</bodyText>
<sectionHeader confidence="0.998574" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<bodyText confidence="0.993678">
By the algorithm Crossover’s, the behavior of
“why”-type questions are investigated by extract-
ing the answer paths as follows.
Q: Why does patient pay money?
Path: patient — $cure — doctor — #occupation —
$earn — money
Q: Why does researcher read textbook?
Path: researcher — #knowledge — #information —
readings — textbook
Paths between two concepts can now be found
by simply checking the presence of a path among
the concepts reached from an initial concept. Table
1 and Table 2 show examples of the number of
paths as a function of path size.
</bodyText>
<table confidence="0.687278666666667">
Source Reached concepts path size
concept
1 2 3
cure 275 593 24854
eat 268 605 24903
study 276 358 23172
food 532 650 18066
human 6713 3686 51171
money 328 1312 19827
</table>
<tableCaption confidence="0.9892135">
Table 1: Examples of destination concepts reached
starting from one source concept
</tableCaption>
<table confidence="0.990551875">
Concept1 Concept2 Paths number length
1 2 3
cure human 0 78 26
pay money 0 7 3
human money 0 3 7
food human 0 0 28
read write 0 4 6
earn pay 0 0 7
</table>
<tableCaption confidence="0.9425915">
Table 2: The number of paths between pairs of
concepts
</tableCaption>
<sectionHeader confidence="0.998701" genericHeader="discussions">
8 Discussion
</sectionHeader>
<bodyText confidence="0.999838833333333">
HowNet (Dong et al. 1999-2003) has already de-
fined the words and concepts using the features of
concepts. Each event role is also defined under the
notion of feature. On the other hand, WordNet
(Miller, 1995) consists of synsets and their glosses.
Moldovan et al. (2002) showed a lexical chain to
use words in glosses in order to trace the topically
related paths.
Their search boundary is restricted to the
shapes: V, W, VW, and WW. In this paper, cross-
over* is shown to be flexible and search for a more
probable explanation.
</bodyText>
<sectionHeader confidence="0.997916" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999979933333334">
In this paper, we have attempted to show how to
link pre-existing lexical knowledge bases to one
another. The major issue was to generate a path to
give explanation paths for answering the “why”-
type question. While observing the causality path
behavior, we proposed the measure similar and
also the algorithm crossover. It is compared with
the “weighted abduction” (Hobbs et al. 1988) and
“lexical chain” (Moldovan et al. 2002).
With the ability to provide explanations de-
pending on the level of the measure similar, our
proposed algorithm adapts itself to the user knowl-
edge level and well as to the type of interactive
questions to enable more detailed level of ques-
tion-answering.
</bodyText>
<sectionHeader confidence="0.999185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999700756756757">
Zhen Dong and Q. Dong. 1999-2003. Hownet,
http://www.keenage.com/
Jerry R. Hobbs, Mark Stickel, Douglas Appelt and
Paul Martin. 1988. Interpretation as Abduction,
Proceedings of the Conference on 26th Annual
Meeting of the Assocation for Computational Lin-
guistics.
Doug Lenat, George Miller, and Toshio Yokoi. 1995.
CYC, WordNet, and EDR: Critiques and Re-
sponses, Communications of the ACM, 38(11):45-
48.
Bernardo Magnini and Manuela Speranza. 2002.
Merging Global and Specialized Linguistic On-
tologies, Proceedings of Ontolex 2002 (Workshop
held in conjunction with LREC-2002), Las Palmas.
George Miller. 1995. WordNet: a lexical database.
Communications of the ACM, 38(11):39-41.
Dan Moldovan and Adrian Novischi. 2002. Lexical
Chains for Question Answering, Proceedings of
COLING 2002, Taipei.
Takanoa Ogino and Masahiro Kobayashi. 2000. Verb
Patterns extracted from EDR Concept Description,
IPSJ SIGNotes Natural Language Abstract,
No.138 – 006:39-46.
Alexandru Marius Pasça. 2001. High-Performance,
Open-Domain Question Answering from Large
Text Collections. Ph.D Dissertation, Southern
Methodist University.
H. Sofia Pinto, Asunción Gómez-Pérez and João P.
Martins. 1999. Some Issues on Ontology Integra-
tion, Proceedings of the IJCAI-99 workshop on
Ontologies and Problem-Solving Methods (KRR5),
Stockholm.
Stuart Russell and Peter Norvig. 1995. Artificial
Intelligence: A Modern Approach. Prentice-Hall.
Toshio Yokoi. 1995. The EDR Electronic Dictionary.
Communications of the ACM, 38(11).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000308">
<title confidence="0.847844">Question-Answering Based on Virtually Integrated Knowledge Base</title>
<author confidence="0.252476">Key-Sun</author>
<abstract confidence="0.464970181818182">305-701 Korea kschoi@cs.ka ist.ac.kr Jae-Ho 305-701 Korea jjaeh@world. kaist.ac.kr NHK Tokyo Japan miyazaki.m-</abstract>
<email confidence="0.824323">fk@nhk.or.jp</email>
<author confidence="0.513959">Jun</author>
<affiliation confidence="0.508417">NHK Human Tokyo</affiliation>
<address confidence="0.698649">Japan</address>
<email confidence="0.952382">goto.jfw@nhk.or.jp</email>
<author confidence="0.990139">Yeun-Bae Kim</author>
<affiliation confidence="0.986393">NHK STRL Human Science</affiliation>
<address confidence="0.7207025">Tokyo 157-8510 Japan</address>
<email confidence="0.9260975">kimu.ygo@nhk.or.jp</email>
<abstract confidence="0.999723">This paper proposes an algorithm for causality inference based on a set of lexical knowledge bases that contain information such items as event role, hierarchy, relevant relation, antonymy, and other features. These lexical knowledge bases have mainly made use of lexical and symbols in Several types of questions are experimented to test the effectiveness of the algorithm here proposed. Particularly in this paper, the question form of “why” is dealt with to show how causality inference works.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>doctor</author>
</authors>
<note>occupation, *cure, medical.</note>
<marker>16.</marker>
<rawString>doctor ⊃ human, #occupation, *cure, medical.</rawString>
</citation>
<citation valid="false">
<authors>
<author>medicine</author>
</authors>
<marker>17.</marker>
<rawString>medicine ⊃ *cure.</rawString>
</citation>
<citation valid="false">
<note>disease ⊃ $cure.</note>
<marker>18.</marker>
<rawString>disease ⊃ $cure.</rawString>
</citation>
<citation valid="false">
<note>cure ⊃ medical, {agent,patient,content}.</note>
<marker>19.</marker>
<rawString>cure ⊃ medical, {agent,patient,content}.</rawString>
</citation>
<citation valid="false">
<note>medical ⊃ #cure.</note>
<marker>20.</marker>
<rawString>medical ⊃ #cure.</rawString>
</citation>
<citation valid="false">
<note>converse(pay,earn) ⊃ agent=source, target=agent.</note>
<marker>21.</marker>
<rawString>converse(pay,earn) ⊃ agent=source, target=agent.</rawString>
</citation>
<citation valid="false">
<authors>
<author>cure human</author>
</authors>
<marker>22.</marker>
<rawString>patient ⊃ human,$cure.</rawString>
</citation>
<citation valid="false">
<note>occupation ⊃ affairs, earn.</note>
<marker>23.</marker>
<rawString>occupation ⊃ affairs, earn.</rawString>
</citation>
<citation valid="false">
<tech>cause(cure,sufferFrom) ⊃ patient=experiencer, content=content.</tech>
<marker>24.</marker>
<rawString>cause(cure,sufferFrom) ⊃ patient=experiencer, content=content.</rawString>
</citation>
<citation valid="false">
<authors>
<author>http www keenage com Jerry R Hobbs Hownet</author>
<author>Mark Stickel</author>
<author>Douglas Appelt</author>
<author>Paul Martin</author>
</authors>
<title>Interpretation as Abduction,</title>
<date>1988</date>
<journal>Communications of the ACM,</journal>
<booktitle>Proceedings of the Conference on 26th Annual Meeting of the Assocation for Computational Linguistics. Doug Lenat,</booktitle>
<volume>38</volume>
<issue>11</issue>
<location>George</location>
<marker>25.</marker>
<rawString>possibleConsequence(cure, Zhen Dong and Q. Dong. 1999-2003. Hownet, http://www.keenage.com/ Jerry R. Hobbs, Mark Stickel, Douglas Appelt and Paul Martin. 1988. Interpretation as Abduction, Proceedings of the Conference on 26th Annual Meeting of the Assocation for Computational Linguistics. Doug Lenat, George Miller, and Toshio Yokoi. 1995. CYC, WordNet, and EDR: Critiques and Responses, Communications of the ACM, 38(11):45-</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bernardo Magnini</author>
<author>Manuela Speranza</author>
</authors>
<title>Merging Global and Specialized Linguistic Ontologies,</title>
<date>2002</date>
<journal>Communications of the ACM,</journal>
<booktitle>Proceedings of Ontolex</booktitle>
<volume>38</volume>
<issue>11</issue>
<pages>38--11</pages>
<institution>from Large Text Collections. Ph.D Dissertation, Southern Methodist University. H. Sofia Pinto, Asunción Gómez-Pérez</institution>
<location>Stockholm. Stuart Russell</location>
<marker>48.</marker>
<rawString> Bernardo Magnini and Manuela Speranza. 2002. Merging Global and Specialized Linguistic Ontologies, Proceedings of Ontolex 2002 (Workshop held in conjunction with LREC-2002), Las Palmas. George Miller. 1995. WordNet: a lexical database. Communications of the ACM, 38(11):39-41. Dan Moldovan and Adrian Novischi. 2002. Lexical Chains for Question Answering, Proceedings of COLING 2002, Taipei. Takanoa Ogino and Masahiro Kobayashi. 2000. Verb Patterns extracted from EDR Concept Description, IPSJ SIGNotes Natural Language Abstract, No.138 – 006:39-46. Alexandru Marius Pasça. 2001. High-Performance, Open-Domain Question Answering from Large Text Collections. Ph.D Dissertation, Southern Methodist University. H. Sofia Pinto, Asunción Gómez-Pérez and João P. Martins. 1999. Some Issues on Ontology Integration, Proceedings of the IJCAI-99 workshop on Ontologies and Problem-Solving Methods (KRR5), Stockholm. Stuart Russell and Peter Norvig. 1995. Artificial Intelligence: A Modern Approach. Prentice-Hall. Toshio Yokoi. 1995. The EDR Electronic Dictionary. Communications of the ACM, 38(11).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>