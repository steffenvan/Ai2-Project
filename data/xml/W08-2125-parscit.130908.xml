<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000169">
<title confidence="0.992189">
Collective Semantic Role Labelling with Markov Logic
</title>
<author confidence="0.998556">
Sebastian Riedel Ivan Meza-Ruiz
</author>
<affiliation confidence="0.999167">
Institute for Communicating and Collaborative Systems
School of Informatics
University of Edinburgh, Scotland
</affiliation>
<email confidence="0.998886">
{S.R.Riedel,I.V.Meza-Ruiz}@sms.ed.ac.uk
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99959275">
This paper presents our system for the
Open Track of the CoNLL 2008 Shared
Task (Surdeanu et al., 2008) in Joint De-
pendency Parsing&apos; and Semantic Role La-
belling. We use Markov Logic to define
a joint SRL model and achieve a semantic
F-score of 74.59%, the second best in the
Open Track.
</bodyText>
<sectionHeader confidence="0.999391" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999825142857143">
Many SRL systems use a two-stage pipeline that
first extracts possible argument candidates (argu-
ment identification) and then assigns argument
labels to these candidates (argument classifica-
tion) (Xue and Palmer, 2004). If we also con-
sider the necessary previous step of identifying
the predicates and their senses (predicate identi-
fication) this yields a three-stage pipeline: predi-
cate identification, argument identification and ar-
gument classification.
Our system, on the other hand, follows a joint
approach in the spirit of Toutanova et al. (2005)
and performs the above steps collectively . We de-
cided to use Markov Logic (ML, Richardson and
Domingos, 2005), a First Order Probabilistic Lan-
guage, to develop a global probabilistic model of
SRL. By using ML we are able to incorporate the
dependencies between the decisions of different
stages in the pipeline and the well-known global
correlations between the arguments of a predi-
cate (Punyakanok et al., 2005). And since learning
</bodyText>
<footnote confidence="0.860941142857143">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
&apos;Note that in this work we do not consider the parsing
task; instead we use the provided dependencies of the open
track datatsets.
</footnote>
<bodyText confidence="0.999229161290323">
and inference methods were already implemented
in the ML software we use, only minimal engineer-
ing efforts had to be done.
In contrast to the work of Toutanova et al. (2005)
our system applies online learning to train its pa-
rameters and exact inference to predict a collective
role labelling. Moreover, we jointly label the argu-
ments of all predicates in a sentence. This allows
us, for example, to require that certain tokens have
to be an argument of some predicates in the sen-
tence.
In this paper we also investigate the impact of
different levels of interaction between the layers of
the joint SRL model. We find that a probabilis-
tic model which resembles a traditional bottom-up
pipeline (though jointly trained and globally nor-
malised) performs better than the complete joint
model on the WSJ test set and worse on the Brown
test set. The worst performance is observed when
no interaction between SRL stages is allowed.
In terms of semantic F-score (74.59%) our sub-
mitted results are the second best in the Open
Track of the Shared Task. Our error analysis in-
dicates that a) the training regime can be improved
and b) nominalizations are difficult to handle for
the model as it is.
In the next sections we will first briefly intro-
duce Markov Logic. Then we present the Markov
Logic model we used in our final submission. We
present and analyse our results in section 4 before
we conclude in Section 5.
</bodyText>
<sectionHeader confidence="0.946724" genericHeader="method">
2 Markov Logic
</sectionHeader>
<footnote confidence="0.898495333333333">
Markov Logic (ML, Richardson and Domingos,
2005) is a Statistical Relational Learning language
based on First Order Logic and Markov Networks.
It can be seen as a formalism that extends First
Order Logic to allow formulae that can be vi-
olated with some penalty. From an alternative
</footnote>
<page confidence="0.948369">
193
</page>
<reference confidence="0.2459725">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 193–197
Manchester, August 2008
</reference>
<bodyText confidence="0.995685888888889">
point of view, it is an expressive template language
that uses First Order Logic formulae to instantiate
Markov Networks of repetitive structure.
Let us describe Markov Logic by considering
the predicate identification task. In Markov Logic
we can model this task by first introducing a set
of logical predicates2 such as isPredicate(Token)
or word(Token,Word). Then we specify a set of
weighted first order formulae that define a distribu-
tion over sets of ground atoms of these predicates
(or so-called possible worlds).
Ideally, the distribution we define with these
weighted formulae assigns high probability to pos-
sible worlds where SRL predicates are correctly
identified and a low probability to worlds where
this is not the case. For example, a suitable set of
weighted formulae would assign a high probability
to the world3
</bodyText>
<equation confidence="0.8472965">
{word (1, Haag) , word(2, plays),
word(3, Elianti), isPredicate(2)}
</equation>
<bodyText confidence="0.549679">
and a low one to
</bodyText>
<equation confidence="0.804671">
{word (1, Haag) , word(2, plays),
word(3, Elianti), isPredicate(3)}
</equation>
<bodyText confidence="0.994976333333333">
In Markov Logic a set M = {(0,wO)}O of
weighted first order formulae is called a Markov
Logic Network (MLN). It assigns the probability
</bodyText>
<equation confidence="0.9977605">
p(y) = Z exp w E fOc (y) (1)
((O,w)EM cECnφ
</equation>
<bodyText confidence="0.936813666666667">
to the possible world y. Here fOc is a feature func-
tion that returns 1 if in the possible world y the
ground formula we get by replacing the free vari-
ables in 0 by the constants in c is true and 0 oth-
erwise. Cnφ is the set of all tuples of constants we
can replace the free variables in 0 with. Z is a nor-
malisation constant. Note that this distribution cor-
responds to a Markov Network where nodes rep-
resent ground atoms and factors represent ground
formulae.
For example, if M contains the formula 0
word (x,&apos;take&apos;) ⇒ isPredicate (x)
then its corresponding log-linear model has,
among others, a feature fO
t1 for which x in 0 has
</bodyText>
<footnote confidence="0.8433655">
2In the cases were is not obvious whether we refer to SRL
or ML predicates we add the prefix SRL or ML, respectively.
3“Haag plays Elianti” is a segment of a sentence in train-
ing corpus.
</footnote>
<bodyText confidence="0.986423">
been replaced by the constant t1 and that returns 1
if
</bodyText>
<equation confidence="0.9066005">
word (1,&apos;take&apos;) ⇒ isPredicate (1)
is true in y and 0 otherwise.
</equation>
<bodyText confidence="0.99966875">
We will refer predicates such as word as ob-
served because they are known in advance. In con-
trast, isPredicate is hidden because we need to in-
fer it at test time.
</bodyText>
<subsectionHeader confidence="0.997216">
2.1 Learning
</subsectionHeader>
<bodyText confidence="0.99987525">
An MLN we use to model the collective SRL task
is presented in section 3. We learn the weights as-
sociated this MLN using 1-best MIRA (Crammer
and Singer, 2003) Online Learning method.
</bodyText>
<subsectionHeader confidence="0.940749">
2.2 Inference
</subsectionHeader>
<bodyText confidence="0.9993578">
Assuming that we have an MLN, a set of weights
and a given sentence then we need to predict
the choice of predicates, frame types, arguments
and role labels with maximal a posteriori prob-
ability. To this end we apply a method that
is both exact and efficient: Cutting Plane Infer-
ence (CPI, Riedel, 2008) with Integer Linear Pro-
gramming (ILP) as base solver. We use it for infer-
ence at test time as well as during the MIRA online
learning process.
</bodyText>
<sectionHeader confidence="0.993669" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999991555555556">
We define five hidden predicates for the three
stages of the task. For predicate identification, we
use the predicates isPredicate and sense. isPred-
icate(p) indicates that the word in the position p
is an SRL predicate while sense(p,e) signals that
predicate in position p has the sense e.
For argument identification, we use the predi-
cates isArgument and hasRole. The atom isArgu-
ment(a) signals that the word in the position a is
a SRL argument of some (unspecified) SRL predi-
cate while hasRole(p,a) indicates that the token at
position a is an argument of the predicate in posi-
tion p.
Finally, for the argument classification stage we
define the predicate role. Here role(p,a,r) corre-
sponds to the decision that the argument in the po-
sition a has the role r with respect to the predicate
in the position p.
</bodyText>
<subsectionHeader confidence="0.997997">
3.1 Local formulae
</subsectionHeader>
<bodyText confidence="0.99992125">
We define a set of local formulae. A formula is lo-
cal if its groundings relate any number of observed
ground atoms to exactly one hidden ground atom.
For example, a grounding of the local formula
</bodyText>
<equation confidence="0.736869">
lemma(p, +l1)nlemma(a, +l2) ⇒ hasRole(p, a)
</equation>
<page confidence="0.994907">
194
</page>
<figureCaption confidence="0.988453">
Figure 1: Factor graph for the local formula in sec-
tion 3.1.
</figureCaption>
<bodyText confidence="0.999861827586207">
can be seen in the Markov Network of Figure 1. It
connects a hidden hasRole ground atom to two ob-
served lemma ground atoms. Note that the “+” pre-
fix for variables indicates that there is a different
weight for each possible pair of lemmas (l1, l2).
For the hasRole and role predicates we defined
local formulae that aimed to reproduce the stan-
dard features used in previous work (Xue and
Palmer, 2004). This also required us to develop
dependency-based versions of the constituent-
based features such as the syntactic path between
predicate and argument, as proposed by Xue and
Palmer (2004).
The remaining hidden predicates, isPredicate,
isArgument and sense, have local formulae that
relate their ground atoms to properties of a con-
textual window around the token the atom corre-
sponds to. For this we used the information pro-
vided in the closed track training corpus of the
shared task (i.e. both versions of lemma and POS
tags plus a coarse version of the POS tags).
Instead of describing the local feature set in
more detail we refer the reader to our MLN model
files.4 They can be used both as a reference and
as input to our Markov Logic Engine5, and thus al-
low the reader to easily reproduce our results. We
believe that this is another advantage of explicitly
separating model and algorithms by using first or-
der probabilistic logic languages.
</bodyText>
<subsectionHeader confidence="0.997249">
3.2 Global formulae
</subsectionHeader>
<bodyText confidence="0.960421857142857">
Global formulae relate several hidden ground
atoms. We use them for two purposes: to en-
sure consistency between the decisions of all SRL
stages and to capture some of our intuition about
the task. We will refer to formulae that serve the
first purpose as structural constraints.
For example, a structural constraint is given by
</bodyText>
<footnote confidence="0.999563">
4http://thebeast.googlecode.com/svn/
mlns/conll08
5http://thebeast.googlecode.com
</footnote>
<equation confidence="0.6166295">
the (deterministic) formula
role(p, a, r) ⇒ hasRole(p, a)
</equation>
<bodyText confidence="0.999719923076923">
which ensures that, whenever the argument a is
given a label r with respect to the predicate p, this
argument must be an argument of a as denoted by
hasRole(p,a). Note that this formula by itself mod-
els the traditional “bottom-up” argument identifi-
cation and classification pipeline: it is possible to
not assign a role r to an predicate-argument pair
(p, a) proposed by the identification stage; how-
ever, it is impossible to assign a role r to token
pairs (p, a) that have not been proposed as poten-
tial arguments.
One example of another class of structural con-
straints is
</bodyText>
<equation confidence="0.537112">
hasRole(p, a) ⇒ ∃r.role(p, a, r)
</equation>
<bodyText confidence="0.99923425">
which, by itself, models an inverted or “top-down”
pipeline. In this architecture the argument classi-
fication stage can assign roles to tokens that have
not been proposed by the argument identification
stage. However, it must assign a label to any token
pair the previous stage proposes. Figure 2 illus-
trates the structural formulae we use in form of a
Markov Network.
The formulae we use to ensure consistency be-
tween the remaining hidden predicates are omitted
for brevity as they are very similar to the bottom-
up and top-down formulae we presented above.
For the SRL predicates that perform a labelling
task (role and sense) we also need a structural con-
straint which ensures that not more than one label
is assigned. For instance,
</bodyText>
<equation confidence="0.671094">
(role(p, a, r1) ∧ r1 =6 r2 ⇒ ¬role(p, a, r2))
</equation>
<bodyText confidence="0.99891">
forbids two different semantic roles for a pair of
words.
The global formulae that capture our intuition
about the task itself can be further divided into two
classes. The first one uses deterministic or hard
constraints such as
</bodyText>
<equation confidence="0.950202">
role (p, a1, r) ∧ ¬mod (r) ∧ a1 =6 a2 ⇒
¬role (p, a2, r)
</equation>
<bodyText confidence="0.9990734">
which forbids cases where distinct arguments of
a predicate have the same role unless the role de-
scribes a modifier.
The second class of global formulae is soft or
nondeterministic. For instance, the formula
</bodyText>
<equation confidence="0.6722475">
lemma(p, +l) ∧ ppos(a, +p)
∧hasRole(p, a) ⇒ sense(p, +f)
</equation>
<page confidence="0.995529">
195
</page>
<table confidence="0.997084">
Model WSJ Brown Train Test
Time Time
Full 75.72% 65.38% 25h 24m
Up 76.96% 63.86% 11h 14m
Down 73.48% 59.34% 22h 23m
Isolated 60.49% 48.12% 11h 14m
Structural 74.93% 64.23% 22h 33m
</table>
<tableCaption confidence="0.838754">
Table 1: F-scores for different models.
</tableCaption>
<figureCaption confidence="0.966836">
Figure 2: Markov Network that illustrates the
structural constraints we use.
</figureCaption>
<bodyText confidence="0.79593525">
is a soft global formula. It captures the observation
that the sense of a verb or noun depends on the type
of its arguments. Here the type of an argument
token is represented by its POS tag.
</bodyText>
<sectionHeader confidence="0.999928" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.985569291666667">
We only submitted results for the Open Track of
the Shared Task. Moreover, we focused on SRL
and did not infer dependencies; instead we used
the MALT dependencies parses provided in the
Open Track dataset. Our submission was ranked
second out of five with a semantic F1-score of
74.59%.6
After submission we also set up additional ex-
periments to evaluate different types and degrees
of connectivity between the decisions made by our
model. To this end we created four new models:
a model that omits top-down structural constraints
and thus resembles a (globally trained) bottom-
up pipeline (Up); a model that does not contain
bottom-up structural constraints and thus resem-
bles a top-down architecture (Down); a model
in which stages are not connected at all (Iso-
lated); and finally, a model in which additional
global formulae are omitted and the only remain-
ing global formulae are structural (Structural). The
results we submitted were generated using the full
model (Full).
Table 1 summarises the results for each of these
models. We report the F-scores for the WSJ and
Brown test corpora provided for the task. In addi-
tion we show training and test times for each sys-
tem.
There are four findings we take from this. First,
and somewhat surprisingly, the jointly trained
bottom-up model (Up) performs substantially bet-
6While we did use information of the open dataset we do
believe that it is possible to train a stacked parsing-SRL sys-
tem that would perform similarily. If so, our system would
have the 5th best semantic scores among the 20 participants
of the closed track.
ter than the full model on the WSJ test corpus. We
will try to give an explanation for this result in
the next section. Second, the bottom-up model is
twice as fast compared to both the full and the top-
down model. This is due to the removal of formu-
lae with existential quantifiers that would result in
large clique sizes of the ground Markov Network.
Third, the isolated model performs extremely poor,
particularly for argument classification. Here fea-
tures defined for the role predicate can not make
any use of the information in previous stages. Fi-
nally, the additional global formulae do improve
performance, although not substantially.
</bodyText>
<subsectionHeader confidence="0.998338">
4.1 Analysis
</subsectionHeader>
<bodyText confidence="0.999993620689655">
A substantial amount of errors in our submitted re-
sults (Full) can be attributed to the seemingly ran-
dom assignment of the very low frequency label
“R-AA” (appears once in the training set) to token
pairs that should either have a different role or no
role at all. Without these false positives, precision
would increase by about 1%. Interestingly, this
type of error completely disappears for the bottom-
up model (Up) and thus seem to be crucial in order
understand why this model can outperform the full
model.
We believe that this type of error is an artifact of
the training regime. For the full model the weights
of the role predicate only have ensure that the right
(true positive) role is the relative winner among
all roles. In the bottom-up model they also have
to make sure that their cumulative weight is non-
negative – otherwise simply not assigning a role
r for (p, a) would increase the score even if has-
Role(p,a) is predicted with high confidence. Thus
more weight is shifted towards the correct roles.
This helps the right label to win more likely over
the “R-AA” label, whose weights have rarely been
touched and are closer to zero.
Likewise, in the bottom-up model the total
weight of the hasRole features of a wrong (false
positive) candidate token pair must be nonpositive.
Otherwise picking the wrong candidate would in-
crease overall score and no role features can re-
</bodyText>
<page confidence="0.996828">
196
</page>
<bodyText confidence="0.99998737037037">
ject this decision because the corresponding struc-
tural constraints are missing. Thus more weight
is shifted away from false positive candidates, re-
sulting in a higher precision of the hasRole pred-
icate. This also means that less wrong candidates
are proposed, for which the “R-AA” role is more
likely to be picked because its weights have hardly
been touched.
However, it seems that by increasing precision
in this way, we decrease recall for out-of-domain
data. This leads to a lower F1 score for the bottom-
up model on the Brown test set.
Another prominent type of errors appear for
nominal predicates. Our system only recovers only
about 80% of predicates with “NN”, “NNS” and
“NNP” tags (and classifies about 90% of these with
the right predicate sense). Argument identification
and classification performs equally bad. For exam-
ple, for the “A0” argument of “VB” predicates we
get an F-score of 82.00%. For the “A0” of “NN”
predicates F-score is 65.92%. The features of our
system are essentially taken from the work done on
PropBank predicates and we did only little work
to adapt these to the case of nominal predicates.
Putting more effort into designing features specific
to the case of nominal predicates might improve
this situation.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999980608695652">
We presented a Markov Logic Network that jointly
performs predicate identification, argument identi-
fication and argument classification for SRL. This
network achieves the second best semantic F-
scores in the Open Track of the CoNLL shared
task.
Experimentally we show that results can be fur-
ther improved by using an MLN that resembles a
conventional SRL bottom-up pipeline (but is still
jointly trained and globally normalised) instead
of a fully connected model. We hypothesise that
when training this model more weight is shifted
away from wrong argument candidates and more
weight is shifted towards correct role labels. This
results in higher precision for argument identifica-
tion and better accuracy for argument classifica-
tion.
Possible future work includes better treatment
of nominal predicates, for which we perform quite
poorly. We would also like to investigate the im-
pact of linguistically motivated global formulae
more thoroughly. So far our model benefits from
them, albeit not substantially.
</bodyText>
<sectionHeader confidence="0.998151" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997399129032258">
Koby Crammer and Yoram Singer. Ultraconserva-
tive online algorithms for multiclass problems.
Journal of Machine Learning Research, 2003.
V. Punyakanok, D. Roth, and W. Yih. Generalized
inference with multiple semantic role labeling
systems. In Proceedings of the Annual Con-
ference on Computational Natural Language
Learning, 2005.
Matthew Richardson and Pedro Domingos.
Markov logic networks. Technical report,
University of Washington, 2005.
Sebastian Riedel. Improving the accuracy and ef-
ficiency of map inference for markov logic. In
Proceedings of the Annual Conference on Un-
certainty in AI, 2008.
Mihai Surdeanu, Richard Johansson, Adam Mey-
ers, Lluis M`arquez, and Joakim Nivre. The
CoNLL-2008 shared task on joint parsing of
syntactic and semantic dependencies. In Pro-
ceedings of the 12th Conference on Compu-
tational Natural Language Learning (CoNLL-
2008), 2008.
Kristina Toutanova, Aria Haghighi, and Christo-
pher D. Manning. Joint learning improves se-
mantic role labeling. In Proceedings of the 43rd
Annual Meeting on Association for Computa-
tional Linguistics, 2005.
Nianwen Xue and Martha Palmer. Calibrating fea-
tures for semantic role labeling. In Proceedings
of the Annual Conference on Empirical Methods
in Natural Language Processing, 2004.
</reference>
<page confidence="0.998146">
197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.563470">
<title confidence="0.999751">Collective Semantic Role Labelling with Markov Logic</title>
<author confidence="0.99977">Sebastian Riedel Ivan Meza-Ruiz</author>
<affiliation confidence="0.99836">Institute for Communicating and Collaborative School of University of Edinburgh,</affiliation>
<abstract confidence="0.925419333333333">This paper presents our system for the Open Track of the CoNLL 2008 Shared Task (Surdeanu et al., 2008) in Joint De- Semantic Role Labelling. We use Markov Logic to define a joint SRL model and achieve a semantic F-score of 74.59%, the second best in the Open Track.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>CoNLL</author>
</authors>
<date>2008</date>
<booktitle>Proceedings of the 12th Conference on Computational Natural Language Learning,</booktitle>
<pages>193--197</pages>
<location>Manchester,</location>
<marker>CoNLL, 2008</marker>
<rawString>CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 193–197 Manchester, August 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Generalized inference with multiple semantic role labeling systems.</title>
<date>2005</date>
<booktitle>In Proceedings of the Annual Conference on Computational Natural Language Learning,</booktitle>
<contexts>
<context position="1513" citStr="Punyakanok et al., 2005" startWordPosition="227" endWordPosition="230">his yields a three-stage pipeline: predicate identification, argument identification and argument classification. Our system, on the other hand, follows a joint approach in the spirit of Toutanova et al. (2005) and performs the above steps collectively . We decided to use Markov Logic (ML, Richardson and Domingos, 2005), a First Order Probabilistic Language, to develop a global probabilistic model of SRL. By using ML we are able to incorporate the dependencies between the decisions of different stages in the pipeline and the well-known global correlations between the arguments of a predicate (Punyakanok et al., 2005). And since learning © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. &apos;Note that in this work we do not consider the parsing task; instead we use the provided dependencies of the open track datatsets. and inference methods were already implemented in the ML software we use, only minimal engineering efforts had to be done. In contrast to the work of Toutanova et al. (2005) our system applies online learning to train its parameters and exact inference to predict a coll</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>V. Punyakanok, D. Roth, and W. Yih. Generalized inference with multiple semantic role labeling systems. In Proceedings of the Annual Conference on Computational Natural Language Learning, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>University of Washington,</institution>
<contexts>
<context position="1210" citStr="Richardson and Domingos, 2005" startWordPosition="178" endWordPosition="181">ipeline that first extracts possible argument candidates (argument identification) and then assigns argument labels to these candidates (argument classification) (Xue and Palmer, 2004). If we also consider the necessary previous step of identifying the predicates and their senses (predicate identification) this yields a three-stage pipeline: predicate identification, argument identification and argument classification. Our system, on the other hand, follows a joint approach in the spirit of Toutanova et al. (2005) and performs the above steps collectively . We decided to use Markov Logic (ML, Richardson and Domingos, 2005), a First Order Probabilistic Language, to develop a global probabilistic model of SRL. By using ML we are able to incorporate the dependencies between the decisions of different stages in the pipeline and the well-known global correlations between the arguments of a predicate (Punyakanok et al., 2005). And since learning © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. &apos;Note that in this work we do not consider the parsing task; instead we use the provided dependenc</context>
</contexts>
<marker>Richardson, Domingos, 2005</marker>
<rawString>Matthew Richardson and Pedro Domingos. Markov logic networks. Technical report, University of Washington, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
</authors>
<title>Improving the accuracy and efficiency of map inference for markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Conference on Uncertainty in AI,</booktitle>
<marker>Riedel, 2008</marker>
<rawString>Sebastian Riedel. Improving the accuracy and efficiency of map inference for markov logic. In Proceedings of the Annual Conference on Uncertainty in AI, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL2008),</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis M`arquez, and Joakim Nivre. The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL2008), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint learning improves semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<contexts>
<context position="1099" citStr="Toutanova et al. (2005)" startWordPosition="159" endWordPosition="162"> F-score of 74.59%, the second best in the Open Track. 1 Introduction Many SRL systems use a two-stage pipeline that first extracts possible argument candidates (argument identification) and then assigns argument labels to these candidates (argument classification) (Xue and Palmer, 2004). If we also consider the necessary previous step of identifying the predicates and their senses (predicate identification) this yields a three-stage pipeline: predicate identification, argument identification and argument classification. Our system, on the other hand, follows a joint approach in the spirit of Toutanova et al. (2005) and performs the above steps collectively . We decided to use Markov Logic (ML, Richardson and Domingos, 2005), a First Order Probabilistic Language, to develop a global probabilistic model of SRL. By using ML we are able to incorporate the dependencies between the decisions of different stages in the pipeline and the well-known global correlations between the arguments of a predicate (Punyakanok et al., 2005). And since learning © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some righ</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2005</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. Joint learning improves semantic role labeling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Conference on Empirical Methods in Natural Language Processing,</booktitle>
<contexts>
<context position="764" citStr="Xue and Palmer, 2004" startWordPosition="108" endWordPosition="111">ol of Informatics University of Edinburgh, Scotland {S.R.Riedel,I.V.Meza-Ruiz}@sms.ed.ac.uk Abstract This paper presents our system for the Open Track of the CoNLL 2008 Shared Task (Surdeanu et al., 2008) in Joint Dependency Parsing&apos; and Semantic Role Labelling. We use Markov Logic to define a joint SRL model and achieve a semantic F-score of 74.59%, the second best in the Open Track. 1 Introduction Many SRL systems use a two-stage pipeline that first extracts possible argument candidates (argument identification) and then assigns argument labels to these candidates (argument classification) (Xue and Palmer, 2004). If we also consider the necessary previous step of identifying the predicates and their senses (predicate identification) this yields a three-stage pipeline: predicate identification, argument identification and argument classification. Our system, on the other hand, follows a joint approach in the spirit of Toutanova et al. (2005) and performs the above steps collectively . We decided to use Markov Logic (ML, Richardson and Domingos, 2005), a First Order Probabilistic Language, to develop a global probabilistic model of SRL. By using ML we are able to incorporate the dependencies between th</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. Calibrating features for semantic role labeling. In Proceedings of the Annual Conference on Empirical Methods in Natural Language Processing, 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>