<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005239">
<title confidence="0.986853">
Challenges of Cheap Resource Creation for Morphological Tagging
</title>
<author confidence="0.993466">
Jirka Hana Anna Feldman
</author>
<affiliation confidence="0.889841">
Charles University Montclair State University
Prague, Czech Republic Montclair, New Jersey, USA
</affiliation>
<email confidence="0.99386">
first.last@gmail.com first.last@montclair.edu
</email>
<sectionHeader confidence="0.99374" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888444444444">
We describe the challenges of resource
creation for a resource-light system for
morphological tagging of fusional lan-
guages (Feldman and Hana, 2010). The
constraints on resources (time, expertise,
and money) introduce challenges that are
not present in development of morphologi-
cal tools and corpora in the usual, resource
intensive way.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.958371704545455">
Morphological analysis, tagging and lemmatiza-
tion are essential for many Natural Language Pro-
cessing (NLP) applications of both practical and
theoretical nature. Modern taggers and analyz-
ers are very accurate. However, the standard
way to create them for a particular language re-
quires substantial amount of expertise, time and
money. A tagger is usually trained on a large cor-
pus (around 100,000+ words) annotated with the
correct tags. Morphological analyzers usually rely
on large manually created lexicons. For exam-
ple, the Czech analyzer (Hajiˇc, 2004) uses a lex-
icon with 300,000+ entries. As a result, most of
the world languages and dialects have no realis-
tic prospect for morphological taggers or analyz-
ers created in this way.
We have been developing a method for creat-
ing morphological taggers and analyzers of fu-
sional languages1 without the need for large-scale
knowledge- and labor-intensive resources (Hana et
al., 2004; Hana et al., 2006; Feldman and Hana,
2010) for the target language. Instead, we rely
on (i) resources available for a related language
and (ii) a limited amount of high-impact, low-
1Fusional languages are languages in which several fea-
ture values are realized in one morpheme. For example Indo-
European languages, including Czech, German, Romanian
and Farsi, are predominantly fusional.
cost manually created resources. This greatly re-
duces cost, time requirements and the need for
(language-specific) linguistic expertise.
The focus of our paper is on the creation of re-
sources for the system we developed. Even though
we have reduced the manual resource creation to
the minimum, we have encountered a number of
problems, including training language annotators,
documenting the reasoning behind the tagset de-
sign and morphological paradigms for a specific
language as well as creating support tools to facil-
itate and speed up the manual work. While these
problems are analogous to those that arise with
standard resource creation, the approach to their
solution is often different as we discuss in the fol-
lowing sections.
</bodyText>
<sectionHeader confidence="0.996654" genericHeader="method">
2 Resource-light Morphology
</sectionHeader>
<bodyText confidence="0.999936333333333">
The details of our system are provided in (Feld-
man and Hana, 2010). Our main assumption is
that a model for the target language can be approx-
imated by language models from one or more re-
lated source languages and that inclusion of a lim-
ited amount of high-impact and/or low-cost man-
ual resources is greatly beneficial and desirable.
We use TnT (Brants, 2000), a second order
Markov Model tagger. We approximate the target-
language emissions by combining the emissions
from the (modified) source language corpus with
information from the output of our resource-light
analyzer (Hana, 2008). The target-language tran-
sitions are approximated by the source language
(Feldman and Hana, 2010).
</bodyText>
<sectionHeader confidence="0.99548" genericHeader="method">
3 Resource creation
</sectionHeader>
<bodyText confidence="0.9882895">
In this section we address the problem of collec-
tion, selection and creation of resources needed
by our system. The following resources must be
available:
</bodyText>
<listItem confidence="0.995921">
• a reference grammar book for information
</listItem>
<page confidence="0.923369">
197
</page>
<note confidence="0.3717815">
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 197–201,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.962903409090909">
about paradigms and closed class words,
• a large amount of plain text for learning a lex-
icon, e.g. newspapers from the Internet,
• a large annotated training corpus of a related
language,
• optionally, a dictionary (or a native speaker)
to provide analyses of the most frequent
words,
• a non-expert (not a linguist and not a native
speaker) to create the resources listed below,
• limited access to a linguist (to make non-
obvious decisions in the design of the re-
sources),
• limited access to a native speaker (to anno-
tate a development corpus, to answer a lim-
ited number of language specific questions).
and these resources must be created:
• a list of morphological paradigms,
• a list of closed class words with their analy-
ses,
• optionally, a list of the most frequent forms,
• a small annotated development corpus.
</listItem>
<bodyText confidence="0.73864875">
For evaluation, an annotated test corpus must
be also created. As this corpus is not part of the
resource-light system per se, it can (and should)
be as large as possible.
</bodyText>
<subsectionHeader confidence="0.996787">
3.1 Restrictions
</subsectionHeader>
<bodyText confidence="0.999997333333333">
Since our goal is to create resources cheaply and
fast, we intentionally limit (but not completely ex-
clude) the inclusion of any linguist and of anybody
knowing the target language. We also limit the
time of training and encoding of the basic target-
language linguistic information to a minimum.
</bodyText>
<subsectionHeader confidence="0.997545">
3.2 Tagset
</subsectionHeader>
<bodyText confidence="0.999995666666667">
In traditional settings, a tagset is usually designed
by a linguist, moreover a native speaker. The con-
straints of a resource-light system preclude both of
these qualifications. Instead, we have standardized
the process as much as possible to make it possible
to have the tagset designed by a non-expert.
</bodyText>
<subsectionHeader confidence="0.909075">
3.2.1 Positional Tagset
</subsectionHeader>
<bodyText confidence="0.999775571428571">
All languages we work with are morphologically
rich. Naturally, such languages require a large
number of tags to capture their morphological
properties. An obvious way to make it manageable
is to use a structured system. In such a system, a
tag is a composition of tags each coming from a
much smaller and simpler atomic tagset tagging a
particular morpho-syntactic property (e.g. gender
or tense). This system has many benefits, includ-
ing the 1) relative easiness for a human annotator
to remember individual positions rather than sev-
eral thousands of atomic symbols; 2) systematic
morphological description; 3) tag decomposabil-
ity; and 4) systematic evaluation.
</bodyText>
<subsectionHeader confidence="0.666381">
3.2.2 Tagset Design: Procedure
</subsectionHeader>
<bodyText confidence="0.999554333333333">
Instead of starting from scratch each time a tagset
for a new language is created, we have provided
an annotated tagset template. A particular tagset
can deviate from this template, but only if there is
a linguistic reason. The tagset template includes
the following items:
</bodyText>
<listItem confidence="0.9979875">
• order of categories (POS, SubPOS, gender,
animacy, number, case, ...) – not all might
be present in that language; additional cate-
gories might be needed;
• values for each category (N – nouns, C – nu-
merals, M – masculine);
• which categories we do not distinguish, even
though we could (proper vs. common nouns);
• a fully worked out commented example (as
mentioned above).
</listItem>
<bodyText confidence="0.992751375">
Such a template not only provides a general
guidance, but also saves a lot of time, because
many of rather arbitrary decisions involved in any
tagset creation are done just once (e.g. symbols de-
noting basic POS categories, should numerals be
included as separate POS, etc.). As stated, a tagset
may deviate from such a template, but only if there
is a specific reason for it.
</bodyText>
<subsectionHeader confidence="0.90527">
3.3 Resources for the morphological analyzer
</subsectionHeader>
<bodyText confidence="0.999524666666667">
Our morphological analyzer relies on a small set
of morphological paradigms and a list of closed
class and/or most frequent words.
</bodyText>
<page confidence="0.99263">
198
</page>
<subsectionHeader confidence="0.914398">
3.3.1 Morphological paradigms
</subsectionHeader>
<bodyText confidence="0.999965125">
For each target language, we create a list of
morphological paradigms. We just encode basic
facts about the target language morphology from
a standard grammar textbook. On average, the
basic morphology of highly inflected languages,
such as Slavic languages, are captured in 70-80
paradigms. The choices on what to cover involve
a balance between precision, coverage and effort.
</bodyText>
<subsectionHeader confidence="0.921803">
3.3.2 A list of frequent forms
</subsectionHeader>
<bodyText confidence="0.99998647826087">
Entering a lexicon entry is very costly, both in
terms of time and knowledge needed. While it is
usually easy (for a native speaker) to assign a word
to one of the major paradigm groups, it takes con-
siderably more time to select the exact paradigm
variant differing only in one or two forms (in fact,
this may be even idiolect-dependent). For exam-
ple, in Czech, it is easy to see that the word atom
‘atom’ does not decline according to the neuter
paradigm mˇesto ‘town’, but it takes more time to
decide to which of the hard masculine inanimate
paradigms it belongs. On the other hand, enter-
ing possible analyses for individual word forms is
usually very straightforward. Therefore, our sys-
tem uses a list of manually provided analyses for
the most common forms.
Note that the process of providing the list of
forms is not completely manual – the correct anal-
yses are selected from those suggested on the ba-
sis of the words’ endings. This can be done rel-
atively quickly by a native speaker or by a non-
native speaker with the help of a basic grammar
book and a dictionary.
</bodyText>
<subsectionHeader confidence="0.951392">
3.4 Documentation
</subsectionHeader>
<bodyText confidence="0.9999728">
Since the main idea of the project is to create
resources quickly for an arbitrarily selected fu-
sional language, we cannot possibly create anno-
tation and language encoding manuals for each
language. So, we created a manual that explains
the annotation and paradigm encoding procedure
in general and describes the main attributes and
possible values that a language consultant needs
to consider when working on a specific language.
The manual has five parts:
</bodyText>
<listItem confidence="0.999726857142857">
1. How to summarize the basic facts about the
morphosyntax of a language;
2. How to create a tagset
3. How to encode morphosyntactic properties of
the target language in paradigms;
4. How to create a list of closed class words.
5. Corpus annotation manual
</listItem>
<bodyText confidence="0.999953333333333">
The instructions are mostly language indepen-
dent (with some bias toward Indo-European lan-
guages), but contain a lot of examples from lan-
guages we have processed so far. These include
suggestions how to analyze personal pronouns,
what to do with clitics or numerals.
</bodyText>
<subsectionHeader confidence="0.924808">
3.5 Procedure
</subsectionHeader>
<bodyText confidence="0.999972428571429">
The resource creation procedure involves at least
two people: a native speaker who can annotate
a development corpus, and a non-native speaker
who is responsible for the tagset design, morpho-
logical paradigms, and a list of closed class words
or frequent forms. Below we describe our proce-
dure in more detail.
</bodyText>
<subsectionHeader confidence="0.833424">
3.5.1 Tagset and MA resources creation
</subsectionHeader>
<bodyText confidence="0.919426777777778">
We have realized that even though we do not need
a native speaker, some understanding of at least
basic morphological categories the language uses
is helpful. So, based on our experience, it is bet-
ter to hire a person who speaks (natively or not) a
language with some features in common. For ex-
ample, for Polish, somebody knowing Russian is
ideal, but even somebody speaking German (it has
genders and cases) is much better than a person
speaking only English. In addition, a person who
had created resources for one language performs
much better on the next target language. Knowl-
edge comes with practice.
The order of work is as follows:
1. The annotator is given basic training that usu-
ally includes the following: 1) brief explana-
tion of the purpose of the project; 2) tagset
design; 3) paradigm creation.
</bodyText>
<listItem confidence="0.984806166666667">
2. The annotator summarizes the basic facts
about the morphosyntax of a language,
3. The first version of the tagset is created.
4. The list of paradigms and closed-class words
is compiled. During this process, the tagset is
further adjusted.
</listItem>
<page confidence="0.997301">
199
</page>
<subsectionHeader confidence="0.928252">
3.5.2 Corpus annotation
</subsectionHeader>
<bodyText confidence="0.999901833333333">
The annotators do not annotate from scratch.
We first run our morphological analyzer on
the selected corpus; the annotators then dis-
ambiguate the output. We have created a
support tool (http://ufal.mff.cuni.cz/
˜hana/law.html) that displays the word to be
annotated, its context, the lemma and possible tags
suggested by the morphological analyzer. There is
an option to insert a new lemma and a new tag if
none of the suggested items is suitable. The tags
are displayed together with their natural language
translation.
</bodyText>
<sectionHeader confidence="0.914117" genericHeader="method">
4 Case studies
</sectionHeader>
<bodyText confidence="0.999931740740741">
Our case studies include Russian via Czech, Rus-
sian via Polish, Russian via Czech and Polish, Por-
tuguese via Spanish, and Catalan via Spanish.
We use these languages to test our hypotheses
and we do not suggest that morphological tagging
of these languages should be designed in the way
we do. Actually, high precision systems that use
manually created resources already exist for these
languages. The main reason for working with
them is that we can easily evaluate our system on
existing corpora.
We experimented with the direct transfer of
transition probabilities, cognates, modifying tran-
sitions to make them more target-like, training a
battery of subtaggers and combining the results
(Reference omitted). Our best result on Russian
is 81.3% precision (on the full 15-slot tag, on all
POSs), and 92.2% (on the detailed POS). We have
also noticed that the most difficult categories are
nouns and adjectives. If we improve on these in-
dividual categories, we will improve significantly
the overall result. The precision of our model
on Catalan is 87.1% and 91.1% on the full tag
and SubPOS, respectively. The Portuguese perfor-
mance is comparable as well.
The resources our experiments have relied upon
include the following:
</bodyText>
<listItem confidence="0.998417090909091">
1. Russian
• Tagset, paradigms, word-list: speaker of
Czech and linguist, some knowledge of
Russian
• Dev corpus: a native speaker &amp; linguist
2. Catalan
• Tagset: modified existing tagset (de-
signed by native speaking linguists)
• paradigms, word-list: linguist speaking
Russian and English
• Dev corpus: a native speaking linguists
3. Portuguese
• Tagset: modified Spanish tagset (de-
signed by native speaking linguists) by
us
• paradigms, word-list: a native speaking
linguist
• Dev corpus: a native speaking linguist
4. Romanian
• Tagset, paradigms, word-list: designed
by a non-linguist, speaker of English
• Dev corpus – a native speaker
</listItem>
<bodyText confidence="0.999861">
Naturally, we cannot expect the tagging accu-
racy to be 100%. There are many factors that con-
tribute to the performance of the model:
</bodyText>
<listItem confidence="0.9978215">
1. target language morphosyntactic complexity,
2. source-language–target-language proximity,
3. quality of the paradigms,
4. quality of the cognate pairs (that are used for
approximating emissions),
5. time spent on language analysis,
6. expertise of language consultants,
7. supporting tools.
</listItem>
<sectionHeader confidence="0.997536" genericHeader="evaluation">
5 Summary
</sectionHeader>
<bodyText confidence="0.999990333333333">
We have described challenges of resource creation
for resource-light morphological tagging. These
include creating clear guidelines for tagset design
that can be reusable for an arbitrarily selected lan-
guage; precise formatting instructions; providing
basic linguistic training with the emphasis on mor-
phosyntactic properties of fusional languages; cre-
ating an annotation support tool; and giving timely
and constructive feedback on intermediate results.
</bodyText>
<sectionHeader confidence="0.999344" genericHeader="conclusions">
6 Acknowledgement
</sectionHeader>
<bodyText confidence="0.995739666666667">
The development of the tagset was supported by
the GAˇCR grant P406/10/P328 and by the U.S.
NSF grant # 0916280.
</bodyText>
<page confidence="0.990761">
200
</page>
<sectionHeader confidence="0.99588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999753068965517">
Thorsten Brants. 2000. TnT - A Statistical Part-of-
Speech Tagger. In Proceedings of 6th Applied Nat-
ural Language Processing Conference and North
American chapter of the Association for Computa-
tional Linguistics annual meeting (ANLP-NAACL),
pages 224–231.
Anna Feldman and Jirka Hana. 2010. A Resource-light
Approach to Morpho-syntactic Tagging, volume 70
of Language and Computers: Studies in Practical
Linguistics. Rodopi, Amsterdam/New York.
Jan Hajiˇc. 2004. Disambiguation of Rich Inflection:
Computational Morphology of Czech. Karolinum,
Charles University Press, Prague, Czech Republic.
Jirka Hana, Anna Feldman, and Chris Brew. 2004.
A Resource-light Approach to Russian Morphol-
ogy: Tagging Russian Using Czech Resources.
In Proceedings of Empirical Methods for Natural
Language Processing (EMNLP), pages 222–229,
Barcelona, Spain.
Jirka Hana, Anna Feldman, Luiz Amaral, and Chris
Brew. 2006. Tagging Portuguese with a Span-
ish Tagger Using Cognates. In Proceedings of the
Workshop on Cross-language Knowledge Induction
hosted in conjunction with the 11th Conference of
the European Chapter of the Association for Com-
putational Linguistics (EACL), pages 33–40, Trento,
Italy.
Jirka Hana. 2008. Knowledge- and labor-light mor-
phological analysis. OSUWPL, 58:52–84.
</reference>
<page confidence="0.998402">
201
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.976740">
<title confidence="0.998961">Challenges of Cheap Resource Creation for Morphological Tagging</title>
<author confidence="0.99885">Jirka Hana Anna Feldman</author>
<affiliation confidence="0.999934">Charles University Montclair State University</affiliation>
<address confidence="0.995243">Prague, Czech Republic Montclair, New Jersey, USA</address>
<email confidence="0.99987">first.last@gmail.comfirst.last@montclair.edu</email>
<abstract confidence="0.9982492">We describe the challenges of resource creation for a resource-light system for morphological tagging of fusional languages (Feldman and Hana, 2010). The constraints on resources (time, expertise, and money) introduce challenges that are not present in development of morphological tools and corpora in the usual, resource intensive way.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT - A Statistical Part-ofSpeech Tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of 6th Applied Natural Language Processing Conference and North American chapter of the Association for Computational Linguistics annual meeting (ANLP-NAACL),</booktitle>
<pages>224--231</pages>
<contexts>
<context position="3035" citStr="Brants, 2000" startWordPosition="468" endWordPosition="469">ols to facilitate and speed up the manual work. While these problems are analogous to those that arise with standard resource creation, the approach to their solution is often different as we discuss in the following sections. 2 Resource-light Morphology The details of our system are provided in (Feldman and Hana, 2010). Our main assumption is that a model for the target language can be approximated by language models from one or more related source languages and that inclusion of a limited amount of high-impact and/or low-cost manual resources is greatly beneficial and desirable. We use TnT (Brants, 2000), a second order Markov Model tagger. We approximate the targetlanguage emissions by combining the emissions from the (modified) source language corpus with information from the output of our resource-light analyzer (Hana, 2008). The target-language transitions are approximated by the source language (Feldman and Hana, 2010). 3 Resource creation In this section we address the problem of collection, selection and creation of resources needed by our system. The following resources must be available: • a reference grammar book for information 197 Proceedings of the Fourth Linguistic Annotation Wo</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT - A Statistical Part-ofSpeech Tagger. In Proceedings of 6th Applied Natural Language Processing Conference and North American chapter of the Association for Computational Linguistics annual meeting (ANLP-NAACL), pages 224–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Feldman</author>
<author>Jirka Hana</author>
</authors>
<title>A Resource-light Approach to Morpho-syntactic Tagging,</title>
<date>2010</date>
<booktitle>of Language and Computers: Studies in Practical Linguistics.</booktitle>
<volume>70</volume>
<location>Rodopi, Amsterdam/New York.</location>
<contexts>
<context position="1570" citStr="Feldman and Hana, 2010" startWordPosition="230" endWordPosition="233">trained on a large corpus (around 100,000+ words) annotated with the correct tags. Morphological analyzers usually rely on large manually created lexicons. For example, the Czech analyzer (Hajiˇc, 2004) uses a lexicon with 300,000+ entries. As a result, most of the world languages and dialects have no realistic prospect for morphological taggers or analyzers created in this way. We have been developing a method for creating morphological taggers and analyzers of fusional languages1 without the need for large-scale knowledge- and labor-intensive resources (Hana et al., 2004; Hana et al., 2006; Feldman and Hana, 2010) for the target language. Instead, we rely on (i) resources available for a related language and (ii) a limited amount of high-impact, low1Fusional languages are languages in which several feature values are realized in one morpheme. For example IndoEuropean languages, including Czech, German, Romanian and Farsi, are predominantly fusional. cost manually created resources. This greatly reduces cost, time requirements and the need for (language-specific) linguistic expertise. The focus of our paper is on the creation of resources for the system we developed. Even though we have reduced the manu</context>
<context position="3361" citStr="Feldman and Hana, 2010" startWordPosition="513" endWordPosition="516">2010). Our main assumption is that a model for the target language can be approximated by language models from one or more related source languages and that inclusion of a limited amount of high-impact and/or low-cost manual resources is greatly beneficial and desirable. We use TnT (Brants, 2000), a second order Markov Model tagger. We approximate the targetlanguage emissions by combining the emissions from the (modified) source language corpus with information from the output of our resource-light analyzer (Hana, 2008). The target-language transitions are approximated by the source language (Feldman and Hana, 2010). 3 Resource creation In this section we address the problem of collection, selection and creation of resources needed by our system. The following resources must be available: • a reference grammar book for information 197 Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 197–201, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics about paradigms and closed class words, • a large amount of plain text for learning a lexicon, e.g. newspapers from the Internet, • a large annotated training corpus of a related language, • optionally, a dicti</context>
</contexts>
<marker>Feldman, Hana, 2010</marker>
<rawString>Anna Feldman and Jirka Hana. 2010. A Resource-light Approach to Morpho-syntactic Tagging, volume 70 of Language and Computers: Studies in Practical Linguistics. Rodopi, Amsterdam/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Disambiguation of Rich Inflection: Computational Morphology of Czech.</title>
<date>2004</date>
<publisher>Karolinum, Charles University Press,</publisher>
<location>Prague, Czech Republic.</location>
<marker>Hajiˇc, 2004</marker>
<rawString>Jan Hajiˇc. 2004. Disambiguation of Rich Inflection: Computational Morphology of Czech. Karolinum, Charles University Press, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jirka Hana</author>
<author>Anna Feldman</author>
<author>Chris Brew</author>
</authors>
<title>A Resource-light Approach to Russian Morphology: Tagging Russian Using Czech Resources.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>222--229</pages>
<location>Barcelona,</location>
<contexts>
<context position="1526" citStr="Hana et al., 2004" startWordPosition="222" endWordPosition="225">, time and money. A tagger is usually trained on a large corpus (around 100,000+ words) annotated with the correct tags. Morphological analyzers usually rely on large manually created lexicons. For example, the Czech analyzer (Hajiˇc, 2004) uses a lexicon with 300,000+ entries. As a result, most of the world languages and dialects have no realistic prospect for morphological taggers or analyzers created in this way. We have been developing a method for creating morphological taggers and analyzers of fusional languages1 without the need for large-scale knowledge- and labor-intensive resources (Hana et al., 2004; Hana et al., 2006; Feldman and Hana, 2010) for the target language. Instead, we rely on (i) resources available for a related language and (ii) a limited amount of high-impact, low1Fusional languages are languages in which several feature values are realized in one morpheme. For example IndoEuropean languages, including Czech, German, Romanian and Farsi, are predominantly fusional. cost manually created resources. This greatly reduces cost, time requirements and the need for (language-specific) linguistic expertise. The focus of our paper is on the creation of resources for the system we dev</context>
</contexts>
<marker>Hana, Feldman, Brew, 2004</marker>
<rawString>Jirka Hana, Anna Feldman, and Chris Brew. 2004. A Resource-light Approach to Russian Morphology: Tagging Russian Using Czech Resources. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 222–229, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jirka Hana</author>
<author>Anna Feldman</author>
<author>Luiz Amaral</author>
<author>Chris Brew</author>
</authors>
<title>Tagging Portuguese with a Spanish Tagger Using Cognates.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Cross-language Knowledge Induction hosted in conjunction with the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>33--40</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="1545" citStr="Hana et al., 2006" startWordPosition="226" endWordPosition="229"> tagger is usually trained on a large corpus (around 100,000+ words) annotated with the correct tags. Morphological analyzers usually rely on large manually created lexicons. For example, the Czech analyzer (Hajiˇc, 2004) uses a lexicon with 300,000+ entries. As a result, most of the world languages and dialects have no realistic prospect for morphological taggers or analyzers created in this way. We have been developing a method for creating morphological taggers and analyzers of fusional languages1 without the need for large-scale knowledge- and labor-intensive resources (Hana et al., 2004; Hana et al., 2006; Feldman and Hana, 2010) for the target language. Instead, we rely on (i) resources available for a related language and (ii) a limited amount of high-impact, low1Fusional languages are languages in which several feature values are realized in one morpheme. For example IndoEuropean languages, including Czech, German, Romanian and Farsi, are predominantly fusional. cost manually created resources. This greatly reduces cost, time requirements and the need for (language-specific) linguistic expertise. The focus of our paper is on the creation of resources for the system we developed. Even though</context>
</contexts>
<marker>Hana, Feldman, Amaral, Brew, 2006</marker>
<rawString>Jirka Hana, Anna Feldman, Luiz Amaral, and Chris Brew. 2006. Tagging Portuguese with a Spanish Tagger Using Cognates. In Proceedings of the Workshop on Cross-language Knowledge Induction hosted in conjunction with the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 33–40, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jirka Hana</author>
</authors>
<title>Knowledge- and labor-light morphological analysis.</title>
<date>2008</date>
<journal>OSUWPL,</journal>
<pages>58--52</pages>
<contexts>
<context position="3263" citStr="Hana, 2008" startWordPosition="501" endWordPosition="502">esource-light Morphology The details of our system are provided in (Feldman and Hana, 2010). Our main assumption is that a model for the target language can be approximated by language models from one or more related source languages and that inclusion of a limited amount of high-impact and/or low-cost manual resources is greatly beneficial and desirable. We use TnT (Brants, 2000), a second order Markov Model tagger. We approximate the targetlanguage emissions by combining the emissions from the (modified) source language corpus with information from the output of our resource-light analyzer (Hana, 2008). The target-language transitions are approximated by the source language (Feldman and Hana, 2010). 3 Resource creation In this section we address the problem of collection, selection and creation of resources needed by our system. The following resources must be available: • a reference grammar book for information 197 Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 197–201, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics about paradigms and closed class words, • a large amount of plain text for learning a lexicon, e.g. newspapers f</context>
</contexts>
<marker>Hana, 2008</marker>
<rawString>Jirka Hana. 2008. Knowledge- and labor-light morphological analysis. OSUWPL, 58:52–84.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>