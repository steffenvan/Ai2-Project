<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007193">
<note confidence="0.9924675">
Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
Philadelphia, July 2002, pp. 154-161. Association for Computational Linguistics.
</note>
<table confidence="0.960899">
types of context content
situational time, place, etc
discourse what has been said
interlocutionary user/system properties
domain ontological knowledge
</table>
<tableCaption confidence="0.999283">
Table 1: Contexts and content
</tableCaption>
<bodyText confidence="0.999889736842105">
incorporate these contextual factors, resulting
in a context-dependent analysis of the given ut-
terances, thereby increasing the conversational
capabilites of NLP systems.
Our overall goal is to produce reliable nat-
ural language understanding components that
increase user satisfaction measures - measur-
able in an evaluation framework such as PAR-
ADISE, described in Walker et al. (2000), or
the benchmark- and impurity graphs proposed
in Paek (2001) - by applying context sensitive
analysis such as described below. We will intro-
duce our model employing examples from the
domain of spatial information in Section 2 and
give an analysis of the collected data and ex-
periments undertaken so far in Section 3. The
resulting model will be described in Sections 4
through 6 followed by concluding remarks in
Section 7.
</bodyText>
<sectionHeader confidence="0.7887335" genericHeader="abstract">
2 Instructions and Descriptions in
the Tourist Domain
</sectionHeader>
<bodyText confidence="0.999895">
Several NLP research efforts have adopted the
tourism domain as a suitably complex challenge
for an intuitive conversational natural language
processing system. The resulting prototypes -
i.e. mobile tourist information systems that can
guide users through cities by providing detailed
spatial, architectural and historical information
as well as topical information from hotel, en-
tertainment and weather services - have been
demonstrated on various occasions .3 Supply-
ing spatial information, specifically spatial in-
structions and spatial descriptions, constitutes
an integral part of the functionality of a mobile
</bodyText>
<footnote confidence="0.974244">
3For example the SmartKom system,
</footnote>
<note confidence="0.90003625">
Wahlster et al. (2001), and Deep Map system,
Malaka and Zipf (2000), have been demonstrated
at C-STAR II, Eurospeech 2001 and the International
Status Conference &amp;quot;Human Computer Interaction&amp;quot; 2001.
</note>
<bodyText confidence="0.993802787878788">
tourist information system.
A spatial instruction, e.g. In order to get
to the castle you have to turn right and follow
the path until you see the gate tower on you left
hand side, instructs the user how to get from
one location/object to a different location along
a specific path, which can be for example the
shortest, nicest or fastest possible. We regard
such an instruction as a felicitous response to a
corresponding instructional request.
A spatial description, e.g. The Elizabeth Gate
is 200 meters to your right tells the user where
a location/object is situated with respect to a
reference location/object. We consider this type
of response appropriate for a descriptive request.
We can, therefore, say that a spatial instruc-
tion is an appropriate response to an instruc-
tional request and a spatial description, e.g. a
localization, constitutes an appropriate response
to descriptive request. Responding to a descrip-
tive localization request with a spatial instruc-
tion or vice versa, however, does not consti-
tute a felicitous response, but can be deemed a
misunderstanding of the questioner&apos;s intention,
i.e. an intention misrecognition. In all dialogue
systems intention misrecognitions decrease the
overall evaluation scores, since they harm the di-
alogue efficiency metrics, as the user is required
to paraphrase the question, resulting in at least
one additional user- and system turn. Further-
more user satisfaction measures can also be ex-
pected to decrease due to factors as perceived
task ease and expected system behavior.4
</bodyText>
<sectionHeader confidence="0.986678" genericHeader="method">
3 The Data
</sectionHeader>
<bodyText confidence="0.999829">
In an initial data collection for constructing ad-
equate language models for automatic speech
recognition we asked American native speakers
to imagine that they are tourists in Heidelberg,
Germany, equipped with a small, personal com-
puter device that understands them and can an-
swer their questions. Among tasks from hotel
and restaurant domains subjects also had to ask
for directions to specific places. In the corpus we
find 128 instances where the subjects were told
</bodyText>
<footnote confidence="0.952887333333333">
4Unfortunately dialogue quality metrics are not ef-
fected by intention misrecognitions, as they are currently
not taken into account in the PARADISE framework.
</footnote>
<bodyText confidence="0.9817936">
to ask for directions, i.e. to make an instruc-
tional requests, out of a total of roughly 500
tasks from 49 subjects. The types and occur-
rences of these instructional requests from our
data are listed in Table 2.
</bodyText>
<figure confidence="0.5752150625">
Type #
Example %
(A) How interrogatives, e.g., 38
How do I get to the Fischergasse 30%
(B) Where interrogatives, e.g., 37
Where is the Fischergasse 29%
(C) What/which interrogatives, e.g., 18
What is the best way to the castle 14%
(D) Imperatives, e.g., 12
Give me directions to the castle 9.5%
(E) Declaratives, e.g., 12
I want to go to the castle 9.5%
(F) Existential interrogatives, e.g., 8
Are there any toilets here 6%
(G) Others 3
I do not see any bus stops 2%
</figure>
<tableCaption confidence="0.985693">
Table 2: Request types and occurrences
</tableCaption>
<bodyText confidence="0.9998379">
Current parsers that handle both instruc-
tional and descriptive requests for spatial in-
formation (e.g. the Soup Parser described in
Gayalda (1999) within the Deep Map system
and the SPIN parser within the SmartKom sys-
tem (Wahlster et al., 2001)) identify types A, C,
D and E as instructional request. This corre-
sponds to a baseline of recognizing roughly 63%
of the instructional requests contained in our
first data sample as such. Changing the gram-
mars to treat type B and F as instructional re-
quest would consequently raise the coverage to
98%. However, Where interrogatives do not
only occur as requests for spatial instructions
but also as requests for spatial descriptions, i.e.
localizations.5
A problem arises due to the fact that the
current parser grammars can either interpret
all Where interrogatives as descriptive re-
quests or as instructional requests. This implies
</bodyText>
<footnote confidence="0.565593">
5Numerous instances of Where interrogatives re-
questing spatial localizations can be found also in other
corpora such as the HCRC Map Task Corpus.
</footnote>
<bodyText confidence="0.999257928571429">
that each parser can either misinterpret 29% of
the instructional request from our initial data
as descriptive requests or interpret all Where
interrogatives as instructional ones, thereby
misinterpreting all those intended as descriptive
request. In short, they lack a systematic way of
dealing with this kind of pragmatic ambiguity,
which in this case entails finding out which type
of Where interrogative might be at hand.6
Resulting from these observations we con-
ducted an experiment in which we ask peo-
ple on the street always the same Where
interrogative, i.e. Excuse me, can you tell
me where X is. We varied three factors:
</bodyText>
<listItem confidence="0.997362">
• the goal object, i.e. either the castle,
city hall, a specific school, a specific dis-
cotheque, a specific cinema, an ATM ma-
chine and a specific clothing store, all of
which can be either open or closed depend-
ing on the time of day, except for the ATM,
• the time of day (i.e. morning, afternoon,
evening),
• the proximity to the goal object, i.e. near
</listItem>
<bodyText confidence="0.943541363636364">
(less than 5 minutes walk), medium (more
than 5 and less than 30 minutes walk) and
far (more than 30 minutes walk).
Additionally we kept track of the approximate
age group (young, middle, old) and gender of
the subjects. In this initial and by no means ex-
haustive set of contextual features we find that
the results of generating decision trees and rules
applying a c4.5 learning algorithm as described
in Winston (1992), follow our basic intuitions,
i.e.:
</bodyText>
<listItem confidence="0.68859">
• if the object is currently closed, e.g. a
discotheque or cinema in the morning, al-
most 90% of the Where interrogatives are
answered by means of localizations, a few
subjects asked whether we actually wanted
to go there now or not, and one subject gave
instructions (the object was the cinema).
</listItem>
<bodyText confidence="0.9601682">
eAs the data discussed herein show a simple approach
to employ the system&apos;s class-based lexicon to make this
decision hinge on the object-type, e.g. BUILDING or
STREET, will not suffice to solve the problem com-
pletely.
</bodyText>
<listItem confidence="0.968542571428571">
• if the object is currently open, e.g. a store
or ATM machine in the morning, people re-
sponded with instructions, unless - and this
we did not expect - the goal object is near
and can be localized by means of a refer-
ence object that is within line of sight, e.g.
an ATM is in that post office over there
</listItem>
<bodyText confidence="0.999965466666667">
Looking at the problem of analyzing Where
interrogatives correctly, we can conclude al-
ready that, depending on the combination of at
least two contextual features, accessibility and
proximity, responses were either instructions,
localizations or questions. We feel very con-
fident, however, that by means of introducing
additional contextual variations, e.g. dressing
the questioner a craftsperson carrying buckets of
paint, we would get instructions to objects such
as discotheques or cinemas even if they happen
to be closed at present. The following section
will describe how we have chosen to incorporate
findings such as the ones described above into
the natural language understanding process.
</bodyText>
<sectionHeader confidence="0.9816635" genericHeader="method">
4 Requirements for Contextual
Analysis
</sectionHeader>
<bodyText confidence="0.998931033333333">
We have noted above that current natural lan-
guage understanding systems lack a system-
atic way of asking, for example, whether a
given Where interrogative at hand is con-
strued as an instructional or a descriptive re-
quest.7 Speakers habitually rely on situational
and other contextual features to enable their
interlocutor to resolve such construals appro-
priately. This is not at all surprising, since
conversational dialogues - whether in human-
human interaction or human-computer interac-
tion - that occur in a specific context are con-
sequently composed of utterances based upon
specific knowledge of that context.
In order to capture the diverse kinds of con-
textual information, studies and experiments of
the type described above need to be conducted,
so that the individual factors and their influ-
ences for a set of additional construal resolu-
71n our terminology saying that the questioner intends
the question to be an instructional- or descriptive request
is equivalent to it being construed as either one.
tions can be identified and formalized, e.g. via
machine learning algorithms Looking at the
domain of spatial information alone we find a
multitude of additional decisions that need to
be made in order to enable a dialogue system
to produce felicitous responses. Next to the
instruction versus localization decision, we find
construal decisions, such as:
</bodyText>
<listItem confidence="0.9990065">
• does the user want to enter, view or just
approach the goal object
• does the user want to take the shortest,
fastest or nicest path
• does the user intend to walk there, drive or
take public transportation
</listItem>
<bodyText confidence="0.990242266666667">
as relevant to answering instructional request
felicitously. In many cases, e.g. the ones
noted above, construal resolution corresponds
to an automatic context-dependent generation
of non-elliptical paraphrases in the sense of
Ebert et al. (2001). That is, to explicate infor-
mation that was left linguistically implicit, e.g.
to expand an utterance such as How do I get to
the castle depending on the context into How do
a get to the castle by car on a scenic route.
These decisions hinge on a number of contex-
tual features much like the instruction versus
localization decision discussed above.8 In our
minds a model resolving the construal of such
questions has to satisfy the following demands:
</bodyText>
<listItem confidence="0.7277124">
• it has to model the data collected in the ex-
periments, which provide the statistic like-
lihoods of the relevant factors, for example,
the likelihood of a Where interrogative
being construed as a descriptive or instruc-
tional request, given the accessibility of the
goal object,
• it has to be able to combine the probabilis-
tic observations from various heterogenous
knowledge sources, e.g. what if the object
</listItem>
<bodyText confidence="0.912323333333333">
8Here also ontological factors, e.g. object type and
role, additional situational factors, e.g. weather, dis-
course factors, e.g. referential status, as well as user-
related factors, e.g. tourists or business travelers as ques-
tioners and their time constraints, constitute significant
factors.
</bodyText>
<figure confidence="0.996184538461539">
accessible
proximity
open
closed
near
medium
far
decision node
instruct
localize
where_interrogative
true
false
</figure>
<bodyText confidence="0.999892">
interpreted as localizational requests and type F
is not recognized at all and causes the system
to indicate non-understanding. The context-
adaptive enhancement described herein, lowers
the error rate to 8%, which, in our minds, consti-
tutes a significant improvement. If the ongoing
studies indicate that we can treat Existential
Interrogatives in a similar fashion, this would
result in an additional lowering by 6%, leaving
only 2% of the initial data set as unanalyzable
for the system.
</bodyText>
<sectionHeader confidence="0.991198" genericHeader="method">
6 The Extended Model
</sectionHeader>
<bodyText confidence="0.99996">
As the data supplies factors related not only to
the situational context, but also to the other
context stores, such as the discourse, interlocu-
tionary and domain context, we have introduced
a way of integrating diverse knowledge sources
into graphical models by means of establishing
a set of intermediate nodes that form a decision
panel. In such a panel each weighable expert
node votes on a common decision, e.g. the poste-
rior probability of a Where interrogative be-
ing construed as a descriptive or instructional
request, as viewed from:
</bodyText>
<listItem confidence="0.988709">
• a situation expert observing, e.g., time,
date, proximity, accessibility
• a user expert observing, e.g., interests,
transportation, thrift
• a discourse expert observing, e.g., referen-
tial status, discourse accessibility
• an ontological expert observing, e.g., object
types and object roles
</listItem>
<bodyText confidence="0.982705870967742">
These weights and votes of the experts are, then,
combined to achieve resulting posterior proba-
bilities for the decision at had that equal 1 in
their sum.11
In the simple case of a single decision (i.e.
instructive versus descriptive requests) we have
seen that the model is able to capture the data
adequately and behaves accordingly. The full
&amp;quot;This addition also constitutes an novel systematic
way of combining evidences from independent factors in
Bayesian networks and keeps the conditional probability
tables from becoming exponentially big.
blown model features currently a set of 14 ad-
ditional discrete decisions and observes over 20
contextual factors. It has not been integrated
into the system as the individual data collection
for these factors is still ongoing and the inte-
gration of some monitoring capabilities, e.g. for
the current weather conditions, have just begun.
A schematic view of the network with only two
decision nodes is given in Appendix 1.
An additional reason for choosing these net-
works was that even if they become rather com-
plex, they are naturally robust against missing
and uncertain data, by relying on the priors in
the absence of currently available topical data.
This approach, therefore, offers a systematic and
robust way of enabling natural language under-
standing modules to choose among different con-
struals of conversational utterances via context-
dependent analysis.
</bodyText>
<sectionHeader confidence="0.986658" genericHeader="method">
7 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999866627906977">
In this paper we argue that, by representing
and integrating factors from diverse contextual
knowledge sources, natural language interpreta-
tion of interrogatives in the tourist domain can
be enhanced. We show, in this sample case, how
contextual observations can serve as a means of
dealing with this type of construal that is of-
ten called pragmatic ambiguity. In envisioning a
multi-domain conversational dialogue system we
expect the need for this type of construal reso-
lution to increase sharply. This also entails that
the individual domains as an additional context
and their corresponding representations, i.e. the
ontology, will also need to be considered in a
more generic application of our model.
As exemplified above the amount of misinter-
pretations or intention misrecognitions in con-
versational dialogue systems can therefore be
decreased, thereby increasing the systems&apos; per-
formances on user satisfaction evaluations. We
expect measurable increases in PARADISE cri-
teria (Walker et al., 2000) such as task ease, ex-
pected behavior as well as dialogue metrics, due
to a decrease in the number of turns necessary to
achieve task completion. An additional exper-
iment based on the Wizard-of-Oz paradigm is
currently in the transcription and labeling pro-
cess to serve as a gold standard for an evaluation
in the framework of Paek (2001).
Since the approach described herein results in
a ranked list of possible construals for a given
utterance we also defined a threshold for cases
where the posterior probabilities can be consid-
ered too close. If, for example, the difference
of the posterior probabilities of the instruct -
localize decision is between 0.1 and -0.1, then
the system responds by asking the user: Do you
want to go there or know where it is located?,
which incidentally is also a response we found
in our initial experiments. This, in turn, would
result in more mixed initiative of conversational
dialogue systems next to increasing their under-
standing capabilities and robustness.
</bodyText>
<sectionHeader confidence="0.993948" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9981272">
There work described herein was conducted
within the SmartKom and EDU projects partly
funded by the German ministry of Research and
Technology under grant 0111,9517 and by the
Klaus Tschira Foundation.
</bodyText>
<sectionHeader confidence="0.997718" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997501510204081">
James F. Allen, Georga Ferguson, and Amanda
Stent. 2001. An architecture for more realistic
conversational system. In Proceedings of Intelli-
gent User Interfaces, pages 1-8, Santa Fe, NM.
Fabio Cozman. 2000. Generalizing variable elimina-
tion in Bayesian networks. In Proceedings of the
IBERAMIA Workshop on Probabilistic Reasoning
in Artificial Intelligence, Sao Paulo, Brazil.
Christian Ebert, Shalom Lappin, Howard Gregory,
and Nicolas Nicolov. 2001. Generating full para-
phrases out of fragments in a dialogue interpre-
tation system. In Proceeding of the 2nd SIGdial
Workshop on Discourse and Dialogue, pages 58-
67, Aalborg, Denmark.
Marsal Gayalda. 1999. SOUP: A parser for real-
world spontaneous speechgrowing semantic gram-
mars. In Proceedings of the 6th International
Workshop on Parsing Technologies, Trento, Italy.
Rainer Malaka and Alexander Zipf. 2000. Deep Map
- challenging IT research in the framework of a
tourist infromation system. In D.R. Fesenmaier,
S. Klein, and D. Buhalis, editors, Information and
Communication Technologies in Toursim, pages
15-27. Springer.
Srini Narayanan and Daniel Jurafsky. 1998.
Bayesian models of human sentence processing. In
Proc. 20th Cognitive Science Society Conference,
pages 84-90. Lawrence Erlbaum Associates.
Tim Paek. 2001. Empirical methods for evaluating
dialog systems. In Proceeding of the 2nd SIGdial
Workshop on Discourse and Dialogue, pages 100-
107, Aalborg, Denmark.
Robert Porzel and Michael Strube. 2000. Towards
context adaptive natrual language processing sys-
tems. In Manfred Klenner and Henriette Visser,
editors, Proceedings of the International Sympo-
sium: Computional Linguistics for the New Mille-
nium.
Wolfgang Wahlster, Norbert Reithinger, and Jochen
Mueller. 2001. Smartkom: Multimodal communi-
cation with a life-like character. In In Procedings
of the 7th European Conference on Speech Com-
munication and Technology., pages 1547-1550.
Marilyn A. Walker, Candace A. Kamm, and Diane J.
Litman. 2000. Towards developing general model
of usability with PARADISE. Natural Language
Engeneering, 6.
Patrick Henry Winston. 1992. Artificial Intelligence.
Addison-Wesley.
</reference>
<figure confidence="0.995912642857143">
Situation Observation Nodes
User
Discourse
Ontology
D O
S U
location
Decision
Nodes
D O
direction
S U
IM
Nodes
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<affiliation confidence="0.432963">Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,</affiliation>
<address confidence="0.535161">Philadelphia, July 2002, pp. 154-161. Association for Computational Linguistics.</address>
<abstract confidence="0.991769214285715">types of context content situational time, place, etc discourse what has been said interlocutionary user/system properties domain ontological knowledge Table 1: Contexts and content incorporate these contextual factors, resulting in a context-dependent analysis of the given utterances, thereby increasing the conversational capabilites of NLP systems. Our overall goal is to produce reliable natural language understanding components that increase user satisfaction measures measurable in an evaluation framework such as PAR- ADISE, described in Walker et al. (2000), or the benchmarkand impurity graphs proposed in Paek (2001) by applying context sensitive analysis such as described below. We will introduce our model employing examples from the domain of spatial information in Section 2 and give an analysis of the collected data and experiments undertaken so far in Section 3. The resulting model will be described in Sections 4 through 6 followed by concluding remarks in Section 7. 2 Instructions and Descriptions in the Tourist Domain Several NLP research efforts have adopted the tourism domain as a suitably complex challenge for an intuitive conversational natural language processing system. The resulting prototypes i.e. mobile tourist information systems that can guide users through cities by providing detailed spatial, architectural and historical information as well as topical information from hotel, entertainment and weather services have been on various occasions Supplying spatial information, specifically spatial instructions and spatial descriptions, constitutes an integral part of the functionality of a mobile the SmartKom system, Wahlster et al. (2001), and Deep Map Malaka and Zipf (2000), have been demonstrated at C-STAR II, Eurospeech 2001 and the International Status Conference &amp;quot;Human Computer Interaction&amp;quot; 2001. tourist information system. instruction, order to get to the castle you have to turn right and follow the path until you see the gate tower on you left side, the user how to get from one location/object to a different location along a specific path, which can be for example the shortest, nicest or fastest possible. We regard such an instruction as a felicitous response to a description, Elizabeth Gate 200 meters to your right the user where a location/object is situated with respect to a reference location/object. We consider this type response appropriate for a We can, therefore, say that a spatial instruction is an appropriate response to an instructional request and a spatial description, e.g. a localization, constitutes an appropriate response to descriptive request. Responding to a descriptive localization request with a spatial instruction or vice versa, however, does not constitute a felicitous response, but can be deemed a misunderstanding of the questioner&apos;s intention, i.e. an intention misrecognition. In all dialogue systems intention misrecognitions decrease the overall evaluation scores, since they harm the dialogue efficiency metrics, as the user is required to paraphrase the question, resulting in at least one additional userand system turn. Furthermore user satisfaction measures can also be expected to decrease due to factors as perceived ease and expected system 3 The Data In an initial data collection for constructing adequate language models for automatic speech recognition we asked American native speakers to imagine that they are tourists in Heidelberg, Germany, equipped with a small, personal computer device that understands them and can answer their questions. Among tasks from hotel and restaurant domains subjects also had to ask for directions to specific places. In the corpus we find 128 instances where the subjects were told dialogue quality metrics are not effected by intention misrecognitions, as they are currently not taken into account in the PARADISE framework. to ask for directions, i.e. to make an instructional requests, out of a total of roughly 500 tasks from 49 subjects. The types and occurrences of these instructional requests from our data are listed in Table 2. Type Example # %</abstract>
<note confidence="0.896101769230769">(A) How interrogatives, e.g., How do I get to the Fischergasse 38 30% (B) Where interrogatives, e.g., 37 Where is the Fischergasse 29% (C) What/which interrogatives, e.g., 18 What is the best way to the castle 14% (D) Imperatives, e.g., 12 Give me directions to the castle 9.5% (E) Declaratives, e.g., 12 I want to go to the castle 9.5% (F) Existential interrogatives, e.g., 8 Are there any toilets here 6% (G) Others 3</note>
<abstract confidence="0.994079735915494">I do not see any bus stops 2% Table 2: Request types and occurrences Current parsers that handle both instructional and descriptive requests for spatial information (e.g. the Soup Parser described in Gayalda (1999) within the Deep Map system and the SPIN parser within the SmartKom system (Wahlster et al., 2001)) identify types A, C, D and E as instructional request. This corresponds to a baseline of recognizing roughly 63% of the instructional requests contained in our first data sample as such. Changing the grammars to treat type B and F as instructional request would consequently raise the coverage to However, interrogatives not only occur as requests for spatial instructions but also as requests for spatial descriptions, i.e. A problem arises due to the fact that the current parser grammars can either interpret interrogatives descriptive requests or as instructional requests. This implies instances of interrogatives requesting spatial localizations can be found also in other corpora such as the HCRC Map Task Corpus. that each parser can either misinterpret 29% of the instructional request from our initial data descriptive requests or interpret all instructional ones, thereby misinterpreting all those intended as descriptive request. In short, they lack a systematic way of dealing with this kind of pragmatic ambiguity, which in this case entails finding out which type interrogative be at Resulting from these observations we conducted an experiment in which we ask peoon the street always the same me, can you tell where X is. varied three factors: • the goal object, i.e. either the city hall, a specific school, a specific discotheque, a specific cinema, an ATM machine and a specific clothing store, all of which can be either open or closed depending on the time of day, except for the ATM, • the time of day (i.e. morning, afternoon, evening), • the proximity to the goal object, i.e. near (less than 5 minutes walk), medium (more than 5 and less than 30 minutes walk) and far (more than 30 minutes walk). Additionally we kept track of the approximate age group (young, middle, old) and gender of the subjects. In this initial and by no means exhaustive set of contextual features we find that the results of generating decision trees and rules applying a c4.5 learning algorithm as described in Winston (1992), follow our basic intuitions, i.e.: • if the object is currently closed, e.g. a discotheque or cinema in the morning, al- 90% of the interrogatives answered by means of localizations, a few subjects asked whether we actually wanted to go there now or not, and one subject gave instructions (the object was the cinema). the data discussed herein show a simple approach to employ the system&apos;s class-based lexicon to make this decision hinge on the object-type, e.g. BUILDING or STREET, will not suffice to solve the problem completely. • if the object is currently open, e.g. a store or ATM machine in the morning, people responded with instructions, unless and this we did not expect the goal object is near and can be localized by means of a reference object that is within line of sight, e.g. is post office over there at the problem of analyzing we can conclude already that, depending on the combination of at least two contextual features, accessibility and proximity, responses were either instructions, localizations or questions. We feel very confident, however, that by means of introducing additional contextual variations, e.g. dressing the questioner a craftsperson carrying buckets of paint, we would get instructions to objects such as discotheques or cinemas even if they happen to be closed at present. The following section will describe how we have chosen to incorporate findings such as the ones described above into the natural language understanding process. 4 Requirements for Contextual Analysis We have noted above that current natural language understanding systems lack a systematic way of asking, for example, whether a interrogative hand is conan instructional or a descriptive re- Speakers habitually rely on situational and other contextual features to enable their interlocutor to resolve such construals appropriately. This is not at all surprising, since conversational dialogues whether in humanhuman interaction or human-computer interaction that occur in a specific context are consequently composed of utterances based upon specific knowledge of that context. In order to capture the diverse kinds of contextual information, studies and experiments of the type described above need to be conducted, so that the individual factors and their influfor a set of additional construal resoluour terminology saying that the questioner intends the question to be an instructionalor descriptive request is equivalent to it being construed as either one. tions can be identified and formalized, e.g. via machine learning algorithms Looking at the domain of spatial information alone we find a multitude of additional decisions that need to be made in order to enable a dialogue system to produce felicitous responses. Next to the instruction versus localization decision, we find construal decisions, such as: • does the user want to enter, view or just approach the goal object • does the user want to take the shortest, fastest or nicest path • does the user intend to walk there, drive or take public transportation as relevant to answering instructional request felicitously. In many cases, e.g. the noted above, construal resolution corresponds to an automatic context-dependent generation of non-elliptical paraphrases in the sense of Ebert et al. (2001). That is, to explicate information that was left linguistically implicit, e.g. expand an utterance such as do I get to castle on the context into do a get to the castle by car on a scenic route. These decisions hinge on a number of contextual features much like the instruction versus decision discussed In our minds a model resolving the construal of such questions has to satisfy the following demands: • it has to model the data collected in the experiments, which provide the statistic likelihoods of the relevant factors, for example, likelihood of a interrogative being construed as a descriptive or instructional request, given the accessibility of the goal object, • it has to be able to combine the probabilistic observations from various heterogenous knowledge sources, e.g. what if the object also ontological factors, e.g. object type and role, additional situational factors, e.g. weather, discourse factors, e.g. referential status, as well as userrelated factors, e.g. tourists or business travelers as questioners and their time constraints, constitute significant factors. accessible proximity open closed near medium far decision node instruct localize where_interrogative true false interpreted as localizational requests and type F is not recognized at all and causes the system to indicate non-understanding. The contextadaptive enhancement described herein, lowers the error rate to 8%, which, in our minds, constitutes a significant improvement. If the ongoing indicate that we can treat a similar fashion, this would result in an additional lowering by 6%, leaving only 2% of the initial data set as unanalyzable for the system. 6 The Extended Model As the data supplies factors related not only to the situational context, but also to the other context stores, such as the discourse, interlocutionary and domain context, we have introduced a way of integrating diverse knowledge sources into graphical models by means of establishing set of intermediate nodes that form a such a panel each weighable on a common decision, e.g. the posteprobability of a interrogative being construed as a descriptive or instructional request, as viewed from: • a situation expert observing, e.g., time, date, proximity, accessibility • a user expert observing, e.g., interests, transportation, thrift • a discourse expert observing, e.g., referential status, discourse accessibility • an ontological expert observing, e.g., object types and object roles These weights and votes of the experts are, then, combined to achieve resulting posterior probabilities for the decision at had that equal 1 in In the simple case of a single decision (i.e. instructive versus descriptive requests) we have seen that the model is able to capture the data adequately and behaves accordingly. The full &amp;quot;This addition also constitutes an novel systematic way of combining evidences from independent factors in Bayesian networks and keeps the conditional probability tables from becoming exponentially big. blown model features currently a set of 14 additional discrete decisions and observes over 20 contextual factors. It has not been integrated into the system as the individual data collection for these factors is still ongoing and the integration of some monitoring capabilities, e.g. for the current weather conditions, have just begun. A schematic view of the network with only two decision nodes is given in Appendix 1. An additional reason for choosing these networks was that even if they become rather complex, they are naturally robust against missing and uncertain data, by relying on the priors in the absence of currently available topical data. This approach, therefore, offers a systematic and robust way of enabling natural language understanding modules to choose among different construals of conversational utterances via contextdependent analysis. 7 Concluding Remarks In this paper we argue that, by representing and integrating factors from diverse contextual knowledge sources, natural language interpretation of interrogatives in the tourist domain can be enhanced. We show, in this sample case, how contextual observations can serve as a means of dealing with this type of construal that is ofcalled ambiguity. envisioning a multi-domain conversational dialogue system we expect the need for this type of construal resolution to increase sharply. This also entails that the individual domains as an additional context and their corresponding representations, i.e. the ontology, will also need to be considered in a more generic application of our model. As exemplified above the amount of misinterpretations or intention misrecognitions in conversational dialogue systems can therefore be decreased, thereby increasing the systems&apos; performances on user satisfaction evaluations. We expect measurable increases in PARADISE criteria (Walker et al., 2000) such as task ease, expected behavior as well as dialogue metrics, due to a decrease in the number of turns necessary to achieve task completion. An additional experiment based on the Wizard-of-Oz paradigm is currently in the transcription and labeling proto serve as a standard an evaluation in the framework of Paek (2001). Since the approach described herein results in a ranked list of possible construals for a given utterance we also defined a threshold for cases where the posterior probabilities can be considered too close. If, for example, the difference the posterior probabilities of the is between 0.1 and -0.1, then system responds by asking the user: you want to go there or know where it is located?, which incidentally is also a response we found in our initial experiments. This, in turn, would result in more mixed initiative of conversational dialogue systems next to increasing their understanding capabilities and robustness. Acknowledgments There work described herein was conducted within the SmartKom and EDU projects partly funded by the German ministry of Research and</abstract>
<note confidence="0.58875275">Technology under grant 0111,9517 and by the Klaus Tschira Foundation. References James F. Allen, Georga Ferguson, and Amanda An architecture for more realistic system. In of Intelli- User Interfaces, 1-8, Santa Fe, NM. Fabio Cozman. 2000. Generalizing variable elimina-</note>
<title confidence="0.702570666666667">in Bayesian networks. In of the IBERAMIA Workshop on Probabilistic Reasoning Artificial Intelligence, Paulo,</title>
<author confidence="0.976446">Christian Ebert</author>
<author confidence="0.976446">Shalom Lappin</author>
<author confidence="0.976446">Howard Gregory</author>
<abstract confidence="0.597134666666667">and Nicolas Nicolov. 2001. Generating full paraphrases out of fragments in a dialogue interpresystem. In of the 2nd SIGdial on Discourse and Dialogue, 58- 67, Aalborg, Denmark. Marsal Gayalda. 1999. SOUP: A parser for realworld spontaneous speechgrowing semantic gram- In of the 6th International on Parsing Technologies, Italy. Rainer Malaka and Alexander Zipf. 2000. Deep Map challenging IT research in the framework of a tourist infromation system. In D.R. Fesenmaier,</abstract>
<keyword confidence="0.279928">Klein, and D. Buhalis, editors, and</keyword>
<note confidence="0.803317909090909">Technologies in Toursim, 15-27. Springer. Srini Narayanan and Daniel Jurafsky. 1998. Bayesian models of human sentence processing. In Proc. 20th Cognitive Science Society Conference, pages 84-90. Lawrence Erlbaum Associates. Tim Paek. 2001. Empirical methods for evaluating systems. In of the 2nd SIGdial on Discourse and Dialogue, 100- 107, Aalborg, Denmark. Robert Porzel and Michael Strube. 2000. Towards</note>
<title confidence="0.597283">adaptive natrual language processing sys-</title>
<author confidence="0.957158">Manfred Klenner</author>
<author confidence="0.957158">Henriette Visser</author>
<note confidence="0.668959076923077">of the International Symposium: Computional Linguistics for the New Millenium. Wolfgang Wahlster, Norbert Reithinger, and Jochen Mueller. 2001. Smartkom: Multimodal communiwith a life-like character. In Procedings of the 7th European Conference on Speech Comand Technology., Marilyn A. Walker, Candace A. Kamm, and Diane J. Litman. 2000. Towards developing general model usability with PARADISE. Language Henry Winston. 1992. Intelligence. Addison-Wesley.</note>
<title confidence="0.909977076923077">Situation Observation Nodes User Discourse Ontology D O S U location Decision Nodes D O direction S U Nodes</title>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Georga Ferguson</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for more realistic conversational system.</title>
<date>2001</date>
<booktitle>In Proceedings of Intelligent User Interfaces,</booktitle>
<pages>1--8</pages>
<location>Santa Fe, NM.</location>
<marker>Allen, Ferguson, Stent, 2001</marker>
<rawString>James F. Allen, Georga Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational system. In Proceedings of Intelligent User Interfaces, pages 1-8, Santa Fe, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Cozman</author>
</authors>
<title>Generalizing variable elimination in Bayesian networks.</title>
<date>2000</date>
<booktitle>In Proceedings of the IBERAMIA Workshop on Probabilistic Reasoning in Artificial Intelligence,</booktitle>
<location>Sao Paulo, Brazil.</location>
<marker>Cozman, 2000</marker>
<rawString>Fabio Cozman. 2000. Generalizing variable elimination in Bayesian networks. In Proceedings of the IBERAMIA Workshop on Probabilistic Reasoning in Artificial Intelligence, Sao Paulo, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Ebert</author>
<author>Shalom Lappin</author>
<author>Howard Gregory</author>
<author>Nicolas Nicolov</author>
</authors>
<title>Generating full paraphrases out of fragments in a dialogue interpretation system.</title>
<date>2001</date>
<booktitle>In Proceeding of the 2nd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>58--67</pages>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="10789" citStr="Ebert et al. (2001)" startWordPosition="1731" endWordPosition="1734">e in order to enable a dialogue system to produce felicitous responses. Next to the instruction versus localization decision, we find construal decisions, such as: • does the user want to enter, view or just approach the goal object • does the user want to take the shortest, fastest or nicest path • does the user intend to walk there, drive or take public transportation as relevant to answering instructional request felicitously. In many cases, e.g. the ones noted above, construal resolution corresponds to an automatic context-dependent generation of non-elliptical paraphrases in the sense of Ebert et al. (2001). That is, to explicate information that was left linguistically implicit, e.g. to expand an utterance such as How do I get to the castle depending on the context into How do a get to the castle by car on a scenic route. These decisions hinge on a number of contextual features much like the instruction versus localization decision discussed above.8 In our minds a model resolving the construal of such questions has to satisfy the following demands: • it has to model the data collected in the experiments, which provide the statistic likelihoods of the relevant factors, for example, the likelihoo</context>
</contexts>
<marker>Ebert, Lappin, Gregory, Nicolov, 2001</marker>
<rawString>Christian Ebert, Shalom Lappin, Howard Gregory, and Nicolas Nicolov. 2001. Generating full paraphrases out of fragments in a dialogue interpretation system. In Proceeding of the 2nd SIGdial Workshop on Discourse and Dialogue, pages 58-67, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marsal Gayalda</author>
</authors>
<title>SOUP: A parser for realworld spontaneous speechgrowing semantic grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 6th International Workshop on Parsing Technologies,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="5089" citStr="Gayalda (1999)" startWordPosition="795" endWordPosition="796">es, e.g., 38 How do I get to the Fischergasse 30% (B) Where interrogatives, e.g., 37 Where is the Fischergasse 29% (C) What/which interrogatives, e.g., 18 What is the best way to the castle 14% (D) Imperatives, e.g., 12 Give me directions to the castle 9.5% (E) Declaratives, e.g., 12 I want to go to the castle 9.5% (F) Existential interrogatives, e.g., 8 Are there any toilets here 6% (G) Others 3 I do not see any bus stops 2% Table 2: Request types and occurrences Current parsers that handle both instructional and descriptive requests for spatial information (e.g. the Soup Parser described in Gayalda (1999) within the Deep Map system and the SPIN parser within the SmartKom system (Wahlster et al., 2001)) identify types A, C, D and E as instructional request. This corresponds to a baseline of recognizing roughly 63% of the instructional requests contained in our first data sample as such. Changing the grammars to treat type B and F as instructional request would consequently raise the coverage to 98%. However, Where interrogatives do not only occur as requests for spatial instructions but also as requests for spatial descriptions, i.e. localizations.5 A problem arises due to the fact that the cur</context>
</contexts>
<marker>Gayalda, 1999</marker>
<rawString>Marsal Gayalda. 1999. SOUP: A parser for realworld spontaneous speechgrowing semantic grammars. In Proceedings of the 6th International Workshop on Parsing Technologies, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rainer Malaka</author>
<author>Alexander Zipf</author>
</authors>
<title>Deep Map - challenging IT research in the framework of a tourist infromation system.</title>
<date>2000</date>
<booktitle>Information and Communication Technologies in Toursim,</booktitle>
<pages>15--27</pages>
<editor>In D.R. Fesenmaier, S. Klein, and D. Buhalis, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="1915" citStr="Malaka and Zipf (2000)" startWordPosition="278" endWordPosition="281">r an intuitive conversational natural language processing system. The resulting prototypes - i.e. mobile tourist information systems that can guide users through cities by providing detailed spatial, architectural and historical information as well as topical information from hotel, entertainment and weather services - have been demonstrated on various occasions .3 Supplying spatial information, specifically spatial instructions and spatial descriptions, constitutes an integral part of the functionality of a mobile 3For example the SmartKom system, Wahlster et al. (2001), and Deep Map system, Malaka and Zipf (2000), have been demonstrated at C-STAR II, Eurospeech 2001 and the International Status Conference &amp;quot;Human Computer Interaction&amp;quot; 2001. tourist information system. A spatial instruction, e.g. In order to get to the castle you have to turn right and follow the path until you see the gate tower on you left hand side, instructs the user how to get from one location/object to a different location along a specific path, which can be for example the shortest, nicest or fastest possible. We regard such an instruction as a felicitous response to a corresponding instructional request. A spatial description, </context>
</contexts>
<marker>Malaka, Zipf, 2000</marker>
<rawString>Rainer Malaka and Alexander Zipf. 2000. Deep Map - challenging IT research in the framework of a tourist infromation system. In D.R. Fesenmaier, S. Klein, and D. Buhalis, editors, Information and Communication Technologies in Toursim, pages 15-27. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Bayesian models of human sentence processing.</title>
<date>1998</date>
<booktitle>In Proc. 20th Cognitive Science Society Conference,</booktitle>
<pages>84--90</pages>
<marker>Narayanan, Jurafsky, 1998</marker>
<rawString>Srini Narayanan and Daniel Jurafsky. 1998. Bayesian models of human sentence processing. In Proc. 20th Cognitive Science Society Conference, pages 84-90. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Paek</author>
</authors>
<title>Empirical methods for evaluating dialog systems.</title>
<date>2001</date>
<booktitle>In Proceeding of the 2nd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>100--107</pages>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="780" citStr="Paek (2001)" startWordPosition="107" endWordPosition="108">ntent situational time, place, etc discourse what has been said interlocutionary user/system properties domain ontological knowledge Table 1: Contexts and content incorporate these contextual factors, resulting in a context-dependent analysis of the given utterances, thereby increasing the conversational capabilites of NLP systems. Our overall goal is to produce reliable natural language understanding components that increase user satisfaction measures - measurable in an evaluation framework such as PARADISE, described in Walker et al. (2000), or the benchmark- and impurity graphs proposed in Paek (2001) - by applying context sensitive analysis such as described below. We will introduce our model employing examples from the domain of spatial information in Section 2 and give an analysis of the collected data and experiments undertaken so far in Section 3. The resulting model will be described in Sections 4 through 6 followed by concluding remarks in Section 7. 2 Instructions and Descriptions in the Tourist Domain Several NLP research efforts have adopted the tourism domain as a suitably complex challenge for an intuitive conversational natural language processing system. The resulting prototy</context>
<context position="16178" citStr="Paek (2001)" startWordPosition="2583" endWordPosition="2584">amount of misinterpretations or intention misrecognitions in conversational dialogue systems can therefore be decreased, thereby increasing the systems&apos; performances on user satisfaction evaluations. We expect measurable increases in PARADISE criteria (Walker et al., 2000) such as task ease, expected behavior as well as dialogue metrics, due to a decrease in the number of turns necessary to achieve task completion. An additional experiment based on the Wizard-of-Oz paradigm is currently in the transcription and labeling process to serve as a gold standard for an evaluation in the framework of Paek (2001). Since the approach described herein results in a ranked list of possible construals for a given utterance we also defined a threshold for cases where the posterior probabilities can be considered too close. If, for example, the difference of the posterior probabilities of the instruct - localize decision is between 0.1 and -0.1, then the system responds by asking the user: Do you want to go there or know where it is located?, which incidentally is also a response we found in our initial experiments. This, in turn, would result in more mixed initiative of conversational dialogue systems next </context>
</contexts>
<marker>Paek, 2001</marker>
<rawString>Tim Paek. 2001. Empirical methods for evaluating dialog systems. In Proceeding of the 2nd SIGdial Workshop on Discourse and Dialogue, pages 100-107, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Porzel</author>
<author>Michael Strube</author>
</authors>
<title>Towards context adaptive natrual language processing systems.</title>
<date>2000</date>
<booktitle>In Manfred Klenner and Henriette Visser, editors, Proceedings of the International Symposium: Computional Linguistics for the</booktitle>
<location>New Millenium.</location>
<marker>Porzel, Strube, 2000</marker>
<rawString>Robert Porzel and Michael Strube. 2000. Towards context adaptive natrual language processing systems. In Manfred Klenner and Henriette Visser, editors, Proceedings of the International Symposium: Computional Linguistics for the New Millenium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
<author>Norbert Reithinger</author>
<author>Jochen Mueller</author>
</authors>
<title>Smartkom: Multimodal communication with a life-like character. In</title>
<date>2001</date>
<booktitle>In Procedings of the 7th European Conference on Speech Communication and Technology.,</booktitle>
<pages>1547--1550</pages>
<contexts>
<context position="1870" citStr="Wahlster et al. (2001)" startWordPosition="270" endWordPosition="273">ism domain as a suitably complex challenge for an intuitive conversational natural language processing system. The resulting prototypes - i.e. mobile tourist information systems that can guide users through cities by providing detailed spatial, architectural and historical information as well as topical information from hotel, entertainment and weather services - have been demonstrated on various occasions .3 Supplying spatial information, specifically spatial instructions and spatial descriptions, constitutes an integral part of the functionality of a mobile 3For example the SmartKom system, Wahlster et al. (2001), and Deep Map system, Malaka and Zipf (2000), have been demonstrated at C-STAR II, Eurospeech 2001 and the International Status Conference &amp;quot;Human Computer Interaction&amp;quot; 2001. tourist information system. A spatial instruction, e.g. In order to get to the castle you have to turn right and follow the path until you see the gate tower on you left hand side, instructs the user how to get from one location/object to a different location along a specific path, which can be for example the shortest, nicest or fastest possible. We regard such an instruction as a felicitous response to a corresponding i</context>
<context position="5187" citStr="Wahlster et al., 2001" startWordPosition="811" endWordPosition="814"> is the Fischergasse 29% (C) What/which interrogatives, e.g., 18 What is the best way to the castle 14% (D) Imperatives, e.g., 12 Give me directions to the castle 9.5% (E) Declaratives, e.g., 12 I want to go to the castle 9.5% (F) Existential interrogatives, e.g., 8 Are there any toilets here 6% (G) Others 3 I do not see any bus stops 2% Table 2: Request types and occurrences Current parsers that handle both instructional and descriptive requests for spatial information (e.g. the Soup Parser described in Gayalda (1999) within the Deep Map system and the SPIN parser within the SmartKom system (Wahlster et al., 2001)) identify types A, C, D and E as instructional request. This corresponds to a baseline of recognizing roughly 63% of the instructional requests contained in our first data sample as such. Changing the grammars to treat type B and F as instructional request would consequently raise the coverage to 98%. However, Where interrogatives do not only occur as requests for spatial instructions but also as requests for spatial descriptions, i.e. localizations.5 A problem arises due to the fact that the current parser grammars can either interpret all Where interrogatives as descriptive requests or as i</context>
</contexts>
<marker>Wahlster, Reithinger, Mueller, 2001</marker>
<rawString>Wolfgang Wahlster, Norbert Reithinger, and Jochen Mueller. 2001. Smartkom: Multimodal communication with a life-like character. In In Procedings of the 7th European Conference on Speech Communication and Technology., pages 1547-1550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Candace A Kamm</author>
<author>Diane J Litman</author>
</authors>
<title>Towards developing general model of usability with PARADISE.</title>
<date>2000</date>
<journal>Natural Language Engeneering,</journal>
<volume>6</volume>
<contexts>
<context position="717" citStr="Walker et al. (2000)" startWordPosition="95" endWordPosition="98"> 154-161. Association for Computational Linguistics. types of context content situational time, place, etc discourse what has been said interlocutionary user/system properties domain ontological knowledge Table 1: Contexts and content incorporate these contextual factors, resulting in a context-dependent analysis of the given utterances, thereby increasing the conversational capabilites of NLP systems. Our overall goal is to produce reliable natural language understanding components that increase user satisfaction measures - measurable in an evaluation framework such as PARADISE, described in Walker et al. (2000), or the benchmark- and impurity graphs proposed in Paek (2001) - by applying context sensitive analysis such as described below. We will introduce our model employing examples from the domain of spatial information in Section 2 and give an analysis of the collected data and experiments undertaken so far in Section 3. The resulting model will be described in Sections 4 through 6 followed by concluding remarks in Section 7. 2 Instructions and Descriptions in the Tourist Domain Several NLP research efforts have adopted the tourism domain as a suitably complex challenge for an intuitive conversat</context>
<context position="15840" citStr="Walker et al., 2000" startWordPosition="2522" endWordPosition="2525">omain conversational dialogue system we expect the need for this type of construal resolution to increase sharply. This also entails that the individual domains as an additional context and their corresponding representations, i.e. the ontology, will also need to be considered in a more generic application of our model. As exemplified above the amount of misinterpretations or intention misrecognitions in conversational dialogue systems can therefore be decreased, thereby increasing the systems&apos; performances on user satisfaction evaluations. We expect measurable increases in PARADISE criteria (Walker et al., 2000) such as task ease, expected behavior as well as dialogue metrics, due to a decrease in the number of turns necessary to achieve task completion. An additional experiment based on the Wizard-of-Oz paradigm is currently in the transcription and labeling process to serve as a gold standard for an evaluation in the framework of Paek (2001). Since the approach described herein results in a ranked list of possible construals for a given utterance we also defined a threshold for cases where the posterior probabilities can be considered too close. If, for example, the difference of the posterior prob</context>
</contexts>
<marker>Walker, Kamm, Litman, 2000</marker>
<rawString>Marilyn A. Walker, Candace A. Kamm, and Diane J. Litman. 2000. Towards developing general model of usability with PARADISE. Natural Language Engeneering, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Henry Winston</author>
</authors>
<date>1992</date>
<journal>Artificial Intelligence. Addison-Wesley.</journal>
<contexts>
<context position="7374" citStr="Winston (1992)" startWordPosition="1180" endWordPosition="1181">, all of which can be either open or closed depending on the time of day, except for the ATM, • the time of day (i.e. morning, afternoon, evening), • the proximity to the goal object, i.e. near (less than 5 minutes walk), medium (more than 5 and less than 30 minutes walk) and far (more than 30 minutes walk). Additionally we kept track of the approximate age group (young, middle, old) and gender of the subjects. In this initial and by no means exhaustive set of contextual features we find that the results of generating decision trees and rules applying a c4.5 learning algorithm as described in Winston (1992), follow our basic intuitions, i.e.: • if the object is currently closed, e.g. a discotheque or cinema in the morning, almost 90% of the Where interrogatives are answered by means of localizations, a few subjects asked whether we actually wanted to go there now or not, and one subject gave instructions (the object was the cinema). eAs the data discussed herein show a simple approach to employ the system&apos;s class-based lexicon to make this decision hinge on the object-type, e.g. BUILDING or STREET, will not suffice to solve the problem completely. • if the object is currently open, e.g. a store </context>
</contexts>
<marker>Winston, 1992</marker>
<rawString>Patrick Henry Winston. 1992. Artificial Intelligence. Addison-Wesley.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>