<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000238">
<title confidence="0.99371">
Leveraging Compounds to Improve Noun Phrase Translation
from Chinese and German
</title>
<author confidence="0.997105">
Xiao Pu
</author>
<affiliation confidence="0.680154">
Idiap Research Institute
1920 Martigny
Switzerland
</affiliation>
<email confidence="0.993155">
xiao.pu@idiap.ch
</email>
<author confidence="0.998706">
Mark Fishel
</author>
<affiliation confidence="0.8827665">
Institute of Computational
Linguistics, U. of Zurich
</affiliation>
<address confidence="0.71337">
8050 Zurich, Switzerland
</address>
<email confidence="0.985088">
fishel@cl.uzh.ch
</email>
<author confidence="0.978589">
Laura Mascarell
</author>
<affiliation confidence="0.835538">
Institute of Computational
Linguistics, U. of Zurich
</affiliation>
<address confidence="0.847209">
8050 Zurich, Switzerland
</address>
<email confidence="0.99795">
mascarell@cl.uzh.ch
</email>
<author confidence="0.998175">
Ngoc-Quang Luong
</author>
<affiliation confidence="0.791158">
Idiap Research Institute
1920 Martigny
Switzerland
</affiliation>
<email confidence="0.96967">
nluong@idiap.ch
</email>
<author confidence="0.977294">
Andrei Popescu-Belis
</author>
<affiliation confidence="0.675626333333333">
Idiap Research Institute
1920 Martigny
Switzerland
</affiliation>
<email confidence="0.993239">
apbelis@idiap.ch
</email>
<author confidence="0.998656">
Martin Volk
</author>
<affiliation confidence="0.882023">
Institute of Computational
Linguistics, U. of Zurich
</affiliation>
<address confidence="0.718296">
8050 Zurich, Switzerland
</address>
<email confidence="0.992352">
volk@cl.uzh.ch
</email>
<sectionHeader confidence="0.995564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902708333333">
This paper presents a method to improve
the translation of polysemous nouns, when
a previous occurrence of the noun as
the head of a compound noun phrase is
available in a text. The occurrences are
identified through pattern matching rules,
which detect XY compounds followed
closely by a potentially coreferent oc-
currence of Y , such as “Nordwand ...
Wand”. Two strategies are proposed to
improve the translation of the second oc-
currence of Y : re-using the cached trans-
lation of Y from the XY compound, or
post-editing the translation of Y using
the head of the translation of XY . Ex-
periments are performed on Chinese-to-
English and German-to-French statistical
machine translation, over the WIT3 and
Text+Berg corpora respectively, with 261
XY/Y pairs each. The results suggest that
while the overall BLEU scores increase
only slightly, the translations of the tar-
geted polysemous nouns are significantly
improved.
</bodyText>
<sectionHeader confidence="0.999335" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858789473684">
Words tend to be less ambiguous when consid-
ered in context, which partially explains the suc-
cess of phrase-based statistical machine transla-
tion (SMT) systems. In this paper, we take ad-
vantage of this observation, and extend the dis-
ambiguation potential of n-grams to subsequent
occurrences of their individual components. We
assume that the translation of a noun-noun com-
pound, noted XY , displays fewer ambiguities
than the translations of its components X and Y .
Therefore, on a subsequent occurrence of the head
of XY , assumed to refer to the same entity as XY ,
we hypothesize that its previously-found transla-
tion offers a better and more coherent translation
than the one proposed by an SMT system that is
not aware of the compound.
Our claim is supported by results from ex-
periments on Chinese-to-English (ZH/EN) and
German-to-French (DE/FR) translation presented
in this paper. In both source languages, noun-noun
compounds are frequent, and will enable us to dis-
ambiguate subsequent occurrences of their head.
For instance, in the example in Figure 1, the
Chinese compound ASR refers to ‘high heels’,
and the subsequent mention of the referent using
only the third character (�) should be translated
as ‘heels’. However, the character 9 by itself
could also be translated as ‘shoe’ or ‘footwear’, as
observed with a baseline SMT system that is not
aware of the XY/Y coreference.
Although the XY/Y configuration may not be
very frequent in texts, errors in its translation are
particularly detrimental to the understanding of a
text, as they often conceal the coreference link
between two expressions. Moreover, as we will
show, such issues can be quite reliably corrected,
and the proposed approach can later generalize to
other configurations of noun phrase coreference.
</bodyText>
<page confidence="0.978923">
8
</page>
<note confidence="0.9341035">
Proceedings of the ACL-IJCNLP 2015 Student Research Workshop, pages 8–15,
Beijing, China, July 28, 2015. c�2015 Association for Computational Linguistics
</note>
<table confidence="0.975827333333333">
1. CHINESE SOURCE SENTENCE 她以为⾃自⼰己买了双两英⼨寸的⾼高跟鞋,
但实际上那是⼀一双三英⼨寸⾼高的鞋。
2. SEGMENTATION, POS TAGGING, 她#PN 以为#VV ⾃自⼰己#AD 买#VV 了#AS 双#CD 两#CD 英⼨寸
IDENTIFICATION OF COMPOUNDS #NN 的#DEG ⾼高跟鞋#NN ,#PU 但#AD 实际上#AD 那#PN
AND THEIR CO-REFERENCE 是#VC ⼀一#CD 双#M 三#CD 英⼨寸#NN ⾼高#VA 的#DEC 鞋#NN。#PU
3. BASELINE TRANSLATION INTO She thought since bought a pair of two inches high heel,
ENGLISH (STATISTICAL MT) but in fact it was a pair of three inches high shoes.
4. AUTOMATIC POST-EDITING OF She thought since bought a pair of two inches high heel,
THE BASELINE TRANSLATION but in fact it was a pair of three inches high heel.
USING COMPOUNDS
5. COMPARISON WITH A HUMAN She thought she’d gotten a two-inch heel
REFERENCE TRANSLATION but she’d actually bought a three-inch heel. ✓
</table>
<figureCaption confidence="0.723103333333333">
Figure 1: Compound post-editing method illustrated on ZH/EN. The first translation of �FRR into
‘heel’ enables the correct translation of the subsequent occurrence of 9 as ‘heel’, by post-editing the
baseline output ‘shoes’.
</figureCaption>
<bodyText confidence="0.9999795">
The paper is organized as follows. In Section 2
we present the main components of our proposal:
first, the rules for identifying XY/Y pairs, and
then two alternative methods for improving the co-
herence of the translation of a subsequent mention
Y , one based on post-editing and the other one
based on caching, which builds upon initial exper-
iments presented by Mascarell et al. (2014). In
Section 3, we present our experimental setting. In
Section 4, we evaluate our proposal on ZH/EN and
DE/FR translation, demonstrating that the transla-
tion of nouns is indeed improved, mainly by au-
tomatic or human comparisons with the reference
translation. We conclude with a brief discussion
of related studies (Section 5) and with perspectives
for future work (Section 6).
</bodyText>
<sectionHeader confidence="0.591554" genericHeader="method">
2 Description of the Method
</sectionHeader>
<subsectionHeader confidence="0.939467">
2.1 Overview
</subsectionHeader>
<bodyText confidence="0.9983264">
We propose to use the translation of a compound
XY to improve the translation of a subsequent oc-
currence of Y , the head of the XY noun phrase,
in the following way, represented schematically in
Figure 1 (details for each stage are given below).
First, the presence of XY/Y patterns is detected
either by examining whether a compound XY is
followed by an occurrence of Y , or, conversely,
by examining for each Y candidate whether it ap-
pears as part of a previous compound XY . Dis-
tance constraints and additional filtering rules are
implemented to increase the likelihood that XY
and Y are actually co-referent, or at least refer to
entities of the same type.
Second, each sentence is translated by a base-
line SMT system, and the translation of the head Y
of each compound XY is identified using the word
alignment from the SMT decoder. This transla-
tion is used as the translation of a subsequent oc-
currence of Y either by caching the correspond-
ing source/target word pair in the SMT or by post-
editing the baseline SMT output. For instance, if
the Chinese pair (r , ) is identified, where the
first compound can unambiguously be translated
into English by ‘vegetable’, then the translation of
a subsequent occurrence of is enforced to ‘veg-
etable’. This has the potential to improve over the
baseline translation, because when considered in-
dividually, could also be translated as ‘dish’,
‘greens’, ‘wild herbs’, etc.
</bodyText>
<subsectionHeader confidence="0.999565">
2.2 Identifying XY/Y Pairs
</subsectionHeader>
<bodyText confidence="0.99989975">
Chinese and German share a number of similar-
ities regarding compounds. Although Chinese
texts are not word-segmented, once this opera-
tion is performed, multi-character words in which
all characters have individual meanings – such as
the above-mentioned X (‘vegetable’) – are fre-
quent. Similarly, in German, noun-noun com-
pounds such as ‘Bundesamt’ (‘Bund’ + ‘Amt’, for
Federal Bureau) or Nordwand (‘Nord’ + ‘Wand’,
for North face) are frequent as well. While
the identification of XY noun-noun compounds
is straightforward with morpho-syntactic analysis
</bodyText>
<page confidence="0.989603">
9
</page>
<bodyText confidence="0.999991307692308">
tools, the identification of a subsequent mention
of the head noun, Y , and especially the decision
whether this Y refers or not to the same entity
XY , are more challenging issues. In other words,
the main difficulty is to separate true XY/Y pairs
from false positives.
To detect truly coreferent XY/Y pairs we nar-
row down the set of detected cases using hand-
written rules that check the local context of Y .
For example, only the cases where Y is preceded
by demonstrative pronouns (e.g. i�_( or X mean-
ing ‘this’ and ‘that’ in Chinese, or ‘diese’ in Ger-
man), possessive pronouns and determiners (‘der’,
‘die’, ‘das’ in German) are considered. Since
other words can occur between the two parts (like
classifiers in Chinese or adjectives), there are ad-
ditional distance constraints: the pronoun or de-
terminer must be separated by fewer than three
words. Since the rules use morphological infor-
mation and word boundaries, they are preceded by
word segmentation1 and tagging2 for Chinese and
morphological analysis for German.3 For exam-
ple, in the input sentence from Figure 1, we deter-
mine that the noun phrase 9 fits our condition for
extraction as Y because as there are words before
it which fulfill the condition for acceptance.
</bodyText>
<subsectionHeader confidence="0.997182">
2.3 Enforcing the Translation of Y
</subsectionHeader>
<bodyText confidence="0.99944252631579">
Two language-independent methods have been de-
signed to ensure that the translations of XY and
Y are a consistent: post-editing and caching. The
second one builds upon an earlier proposal tested
only on DE/FR with subjective evaluations (Mas-
carell et al., 2014).
In the post-editing method, for each XY/Y
pair, the translations of XY and Y by a baseline
SMT system (see Section 3) are first identified
through word alignment. We verify if the trans-
lations of Y in both noun phrases are identical
or different. Both elements comprising the com-
pound structure XY/Y are identified, for the stan-
dard cases, with only one possible XY referring to
one Y . The translation of both words are provided
by the baseline SMT system, and our system sub-
sequently verifies if the translations of Y in both
noun phrases are identical or different. We keep
them intact in the first case, while in the second
</bodyText>
<footnote confidence="0.99854075">
1Using the Stanford Word Segmenter available from
http://nlp.stanford.edu/software/segmenter.shtml.
2Using the Stanford Log-linear Part-of-speech Tagger,
http://nlp.stanford.edu/software/tagger.shtml.
</footnote>
<subsectionHeader confidence="0.634858">
3Using Gertwol (Koskeniemmi and Haapalainen, 1994).
</subsectionHeader>
<bodyText confidence="0.999986236842105">
case we replace the translation of Y by the transla-
tion of XY or by its head noun only, if it contains
several words. In the example in Figure 1, XY
is translated into ‘high heel’ and Y into ‘shoes’,
which is a wrong translation of 9 in this context.
Using the consistency constraint, our method post-
edits the translation of Y replacing it with ‘heel’,
which is the correct word.
Several differences from the ideal case pre-
sented above must be handled separately. First, it
may occur that several XY are likely co-referent
with the same Y . In this case, if their transla-
tions differ, given that we cannot resolve the co-
reference, we do not post-edit Y .4 If the trans-
lations of the several occurrences of XY are the
same, but consist of one word, we still do not post-
edit Y . We only change it if the translations con-
sist of several words, ensuring that XY is a com-
pound noun phrase. Second, if the compound XY
is not translated (out-of-vocabulary word), we do
not post-edit Y .5 Third, sometimes the alignment
of Y is empty in the target sentence (alignment er-
ror or untranslated word), in which case we apply
post-editing as above on the word preceding Y , if
it is aligned.
In the caching method (Mascarell et al., 2014),
once an XY compound is identified, we obtain
the translation of the Y part of the compound
through the word alignment given by the SMT
decoder. Next, we check that this translation ap-
pears as a translation of Y in the phrase table, and
if so, we cache both Y and the obtained transla-
tion. We then enforce the cached translation every
time a coreference Y to XY is identified. Note
that this is different from the probabilistic caching
proposed by Tiedemann (2010), because in our
case the cached translation is deterministically en-
forced as the translation of Y .
</bodyText>
<sectionHeader confidence="0.998228" genericHeader="method">
3 Experimental Settings
</sectionHeader>
<bodyText confidence="0.9994535">
The experiments are carried out on two differ-
ent parallel corpora: the WIT3 Chinese-English
dataset (Cettolo et al., 2012) with transcripts
of TED lectures and their translations, and the
Text+Berg German-French corpus (Bubenhofer et
al., 2013), a collection of articles from the year-
</bodyText>
<footnote confidence="0.97152">
4Upon manual examination, we found that using the most
recent XY was not a reliable candidate for the antecedent.
5In fact, we can use the translation of Y as a translation
candidate for XY . Our observations show that this helps to
improve BLEU scores, but does not affect the specific scoring
of Y in Section 4.
</footnote>
<page confidence="0.861997">
10
</page>
<table confidence="0.999653571428571">
Sentences Tokens
ZH Training 188’758 19’880’790
Tuning 2’457 260’770
Testing 855 12’344
DE Training 285’877 5’194’622
Tuning 1’557 32’649
Testing 505 12’499
</table>
<tableCaption confidence="0.999848">
Table 1: Sizes of SMT data sets.
</tableCaption>
<bodyText confidence="0.999976511111111">
books of the Swiss Alpine Club. The sizes of the
subsets used for training, tuning and testing the
SMT systems are given in Table 1. The test sets
were constructed by selecting all the sentences or
fragments which contained the XY/Y pairs, iden-
tified as above, to maximize their number in the
test data, given that they are not needed in the
training/tuning sets, as the proposed methods are
not based on machine learning.
The rules for selecting coreferent XY/Y pairs
in Chinese identified 261 pairs among 192k sen-
tences. The rather low rate of occurrence (about
one every 700 sentences) is explained by the strict
conditions of the selection rules, which are de-
signed to maximize the likelihood of coreference.
In German, less restrictive rules selected 7,365
XY/Y pairs (a rate of one every 40 sentences).
Still, in what follows, we randomly selected 261
XY/Y pairs for the DE/FR test data, to match
their number in the ZH/EN test data.
Our baseline SMT system is the Moses phrase-
based decoder (Koehn et al., 2007), trained over
tokenized and true-cased data. The language mod-
els were built using SRILM (Stolcke et al., 2011)
at order 3 (i.e. up to trigrams) using the default
smoothing method (i.e. Good-Turing). Optimiza-
tion was done using Minimum Error Rate Training
(Och, 2003) as provided with Moses.
The effectiveness of proposed systems is mea-
sured in two ways. First, we use BLEU (Pap-
ineni et al., 2002) for overall evaluation, to verify
whether our systems provide better translation for
entire texts. Then, we focus on the XY/Y pairs
and count the number of cases in which the trans-
lations of Y match the reference or not, which can
be computed automatically using the alignments.
However, the automatic comparison of a sys-
tem’s translation with the reference is not entirely
informative, because even if the two differ, the sys-
tem’s translation can still be acceptable. There-
fore, we analyzed these “undecided” situations
manually, with three human annotators (among the
authors of the paper). The annotators rated sepa-
rately the system’s translations of Y and the refer-
ence ones as ‘good’, ‘acceptable’ or ‘wrong’.
</bodyText>
<sectionHeader confidence="0.928943" genericHeader="method">
4 Analysis of Results
</sectionHeader>
<subsectionHeader confidence="0.989989">
4.1 Automatic Comparison with a Reference
</subsectionHeader>
<bodyText confidence="0.9787964">
The BLEU scores obtained by the baseline SMT,
the caching and post-editing methods, and an or-
acle system are given in Table 2. The scores are
in the same range as the baseline scores found by
other teams on these datasets (Cettolo et al., 2012,
Table 7 for ZH/EN), and much higher on DE/FR
than ZH/EN.
Our methods have a small positive effect on
ZH/EN translation, and a small negative effect on
DE/FR one. Given the sparsity of XY/Y pairs
with respect to the total number of words, hence
the small number of changed words, these re-
sults meet our prior expectations. Indeed, we also
computed the oracle BLEU scores for both lan-
guage pairs, i.e. the scores when all Y members of
XY/Y pairs are (manually) translated exactly as
in the reference (last line of Table 2). These val-
ues are only slightly higher than the other scores,
showing that even a perfect translation of the Y
nouns would only have a small effect on BLEU.
</bodyText>
<table confidence="0.9958068">
ZH/EN DE/FR
BASELINE 11.18 27.65
CACHING 11.23 27.26
POST-EDITING 11.27 27.48
ORACLE 11.30 27.80
</table>
<tableCaption confidence="0.999064">
Table 2: BLEU scores of our methods.
</tableCaption>
<bodyText confidence="0.999934125">
We now turn to the reference-based evaluation
of the translations of Y in the 261 XY/Y pairs,
comparing the baseline SMT with each of our
methods. These results are represented as four
contingency tables – two language pairs and two
methods against the baseline – gathered together
as percentages in Table 3. Among these values,
we focus first on the total of pairs where one of our
systems agrees with the reference while the base-
line system does not (i.e., improvements due to
the system), and the converse case (degradations).
The higher the difference between the two values,
the more beneficial our method.
For ZH/EN and the post-editing system, among
the 222 extracted pairs, there were 45 improve-
ments (20.3%) of the system with respect to the
</bodyText>
<page confidence="0.998824">
11
</page>
<table confidence="0.9980395">
CACHING POST-EDITING
= ref 7� ref = ref 7� ref
ZH/EN BASELINE = ref 59.3 4.1 42.3 4.5
7� ref 13.8 22.8 20.3 32.9
DE/FR BASELINE = ref 70.1 10.3 73.9 5.0
7� ref 4.3 15.2 3.5 17.5
</table>
<tableCaption confidence="0.922143">
Table 3: Comparison of each approach with the baseline, for the two language pairs, in terms of Y nouns
which are identical or different from a reference translation (‘ref’). All scores are percentages of the
totals. Numbers in bold are improvements over the baseline, while those in italics are degradations.
</tableCaption>
<bodyText confidence="0.999810290322581">
baseline, and only 10 degradations (4.5%). There
were also 94 pairs (42.3%) for which the baseline
and the post-edited system were equal to the ref-
erence. The remaining 73 pairs (32.9%) will be
analyzed manually in the next section. Therefore,
from a pure reference-based view, the post-edited
system has a net improvement of 15.8% (absolute)
over the baseline in dealing with the XY/Y pairs.
A similar pattern is observed with the other
method, namely caching, again on ZH/EN trans-
lation: 13.8% improvements vs. 4.1% degrada-
tions. The difference (i.e. the net improvement)
is slightly smaller in this case with respect to the
post-editing method.
For DE/FR translation, both methods appear
to score fewer improvements than degradations.
There are more than 70% of the pairs which are
translated correctly by the baseline and by both
systems, which indicates that the potential for im-
provement is much smaller for DE/FR than for
ZH/EN.
While the pattern of improvement between
ZH/EN and DE/FR is similar for post-editing and
for caching, for both language pairs the post-
editing method has a larger difference between
improvements and degradations than the caching
method. This can be explained by a lower cov-
erage of the latter method, since it only enforces
a translation when it appears as one of the trans-
lation candidates for Y in the phrase table (Mas-
carell et al., 2014).
</bodyText>
<subsectionHeader confidence="0.993724">
4.2 Manual Evaluation of Undecided Cases
</subsectionHeader>
<bodyText confidence="0.999983456521739">
When both the baseline and one of our systems
generate translations of Y which differ from the
reference, it is not possible to compare the trans-
lations without having them examined by human
subjects. This was done for the 73 such cases
of the ZH/EN post-editing system. Three of the
authors, working independently, considered each
translation from each system (in separate batches)
with respect to the reference one, and rated its
meaning on a 3-point scale: 2 (good), 1 (accept-
able) or 0 (wrong). To estimate the inter-rater
agreement, we computed the average absolute de-
viation6 and found a value of 0.15, thus denoting
very good agreement. Below, we group ‘2’ and
‘1’ answers into one category, called “acceptable”,
and compare them to ‘0’ answers, i.e. wrong trans-
lations.
When both the baseline and the post-edited
translations of Y differ from the reference, they
can either be identical (49 cases) or different (24).
In the former case, of course, neither of the sys-
tems outperforms the other. The interesting obser-
vation is that the relatively high number of such
cases (49) is due to situations where the reference
translation of noun Y is by a pronoun (40), which
the systems have currently no possibility to gen-
erate from a noun in the source sentence. Manual
evaluation shows that the systems’ translations are
correct in 36 out of 40 cases. This large number
shows that the “quality” of the systems is actu-
ally higher than what can be inferred from Table 3
only. Conversely, in the 9 cases when the refer-
ence translation of Y is not a pronoun, only about
half of the translations are correct.
In the latter case, when baseline and post-edited
translations differ from the reference and among
themselves (24 cases), it is legitimate to ask which
of the two systems is better. Overall, 10 baseline
translations are correct and 14 are wrong, whereas
23 post-edited translations are correct (or at least
acceptable) and only one is wrong. The post-
edited system thus clearly outperforms the base-
line in this case. Similarly to the observation
above, we note that among the 24 cases considered
here, almost all (20) involve a reference translation
of Y by a pronoun. In these cases, the baseline
</bodyText>
<footnote confidence="0.8198">
6Average of s Ei=1 |scorei − mean  |over all ratings .
</footnote>
<page confidence="0.998338">
12
</page>
<bodyText confidence="0.992557666666667">
system translates only about half of them with a
correct noun (9 out of 20), while the post-edited
system translates correctly 19 out of 20.
</bodyText>
<sectionHeader confidence="0.999609" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999957344827586">
We briefly review in this section several previous
studies from which the present one has benefited.
Our idea is built upon the one-sense-per-discourse
hypothesis (Gale et al., 1992) and its application
to machine translation is based on the premise that
consistency in discourse (Carpuat, 2009) is desir-
able. The initial compound idea was first pub-
lished by Mascarell et al. (2014), in which the co-
reference of compound noun phrases in German
(e.g. Nordwand/Wand) was studied and used to
improve DE/FR translation by assuming that the
last constituent of the compound Y should share
the same translation as that of Y in XY .
Several other approaches focused on enforcing
consistent lexical choice. Tiedemann (2010) pro-
posed a cache-model to enforce consistent trans-
lation of phrases across the document. How-
ever, caching is sensitive to error propagation, that
is, when a phrase is incorrectly translated and
cached, the model propagates the error to the fol-
lowing sentences. Gong et al. (2011) later ex-
tended Tiedemann’s proposal by initializing the
cache with phrase pairs from similar documents
at the beginning of the translation and by also ap-
plying a topic cache, which was introduced to deal
with the error propagation issue. Xiao et al. (2011)
defined a three step procedure that enforces the
consistent translation of ambiguous words, achiev-
ing improvements for EN/ZH. Ture et al. (2012)
encouraged consistency for AR/EN MT by intro-
ducing cross-sentence consistency features to the
translation model, while Alexandrescu and Kirch-
hoff (2009) enforced similar translations to sen-
tences having a similar graph representation.
Our work is an instance of a recent trend aim-
ing to go beyond sentence-by-sentence MT, by us-
ing semantic information from previous sentences
to constrain or correct the decoding of the cur-
rent one. In this paper, we compared caching and
post-editing as ways of achieving this goal, but
a document-level decoder such as Docent (Hard-
meier et al., 2012) could be used as well. In other
studies, factored translation models (Koehn and
Hoang, 2007) have been used with the same pur-
pose, by incorporating contextual information into
labels used to indicate the meaning of ambiguous
discourse connectives (Meyer and Popescu-Belis,
2012) or the expected tenses of verb phrase trans-
lations (Loaiciga et al., 2014). Quite naturally,
there are analogies between our work and stud-
ies of pronoun translation (Le Nagard and Koehn,
2010; Hardmeier and Federico, 2010; Guillou,
2012), with the notable difference that pronominal
anaphora resolution remains a challenging task.
Finally, our work and its perspectives contribute
to the general objective of using discourse-level
information to improve MT (Hardmeier, 2014;
Meyer, 2014).
</bodyText>
<sectionHeader confidence="0.989033" genericHeader="conclusions">
6 Conclusion and Perspectives
</sectionHeader>
<bodyText confidence="0.99991695">
We presented a method to enforce the consistent
translation of coreferences to a compound, when
the coreference matches the head noun of the com-
pound. Experimental results showed that baseline
SMT systems often translate coreferences to com-
pounds consistently for DE/FR, but much less so
for ZH/EN. For a significant number of cases in
which the noun phrase Y had multiple meanings,
our system reduced the frequency of mistransla-
tions in comparison to the baseline, and improved
noun phrase translation.
In this work, we considered XY/Y pairs, hy-
pothesizing that when they are coreferent, they
should have consistent translations. In the future,
we will generalize this constraint to complex noun
phrases which are not compounds. More gener-
ally, we will explore the encoding of coreference
constraints into probabilistic models that can be
combined with SMT systems, so that coreference
constraints are considered in the decoding process.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999921666666667">
The authors are grateful for the support of
the Swiss National Science Foundation (SNSF)
through the Sinergia project MODERN: Model-
ing Discourse Entities and Relations for Coher-
ent Machine Translation, grant nr. CRSII2 147653
(www.idiap.ch/project/modern).
</bodyText>
<sectionHeader confidence="0.987942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.525743166666667">
Andrei Alexandrescu and Katrin Kirchhoff. 2009.
Graph-based learning for statistical machine trans-
lation. In Proceedings of the Annual Conference
of the North American Chapter of the Association
for Computational Linguistics (NAACL), pages 119–
127, Boulder, Colorado.
</reference>
<page confidence="0.997028">
13
</page>
<reference confidence="0.995775436363636">
Noah Bubenhofer, Martin Volk, David Klaper,
Manuela Weibel, and Daniel W¨uest. 2013.
Text+Berg-korpus (release 147 v03). Digitale Edi-
tion des Jahrbuch des SAC 1864-1923, Echo des
Alpes 1872-1924 und Die Alpen 1925-2011.
Marine Carpuat. 2009. One Translation per Discourse.
In Proceedings of the Workshop on Semantic Evalu-
ations: Recent Achievements and Future Directions
(SEW), pages 19–27, Singapore.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT3: Web inventory of transcribed
and translated talks. In Proceedings of the 16th Con-
ference of the European Association for Machine
Translation (EAMT), pages 261–268, Trento, Italy.
William A Gale, Kenneth W Church, and David
Yarowsky. 1992. One sense per discourse. In Pro-
ceedings of the Workshop on Speech and Natural
Language, pages 233–237.
Zhengxian Gong, Min Zhang, and Guodong Zhou.
2011. Cache-based document-level statistical ma-
chine translation. In Proceedings of the 2011 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 909–919, Edinburgh.
Liane Guillou. 2012. Improving pronoun translation
for statistical machine translation. In Proceedings of
EACL 2012 Student Research Workshop (13th Con-
ference of the European Chapter of the ACL), pages
1–10, Avignon, France.
Christian Hardmeier and Marcello Federico. 2010.
Modelling Pronominal Anaphora in Statistical Ma-
chine Translation. In Proceedings of Interna-
tional Workshop on Spoken Language Translation
(IWSLT), Paris, France.
Christian Hardmeier, Joakim Nivre, and J¨org Tiede-
mann. 2012. Document-Wide Decoding for Phrase-
Based Statistical Machine Translation. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing and Natural Language
Learning (EMNLP-CoNLL), Jeju, Korea.
Christian Hardmeier. 2014. Discourse in Statistical
Machine Translation. PhD thesis, Uppsala Univer-
sity, Sweden.
Philipp Koehn and Hieu Hoang. 2007. Factored
translation models. In Proceedings of the Joint
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP) and Computational
Natural Language Learning (CONLL), pages 868–
876, Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbs. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In Proceedings of 45th Annual Meeting of the
Association for Computational Linguistics (ACL),
Demonstration Session, pages 177–180, Prague,
Czech Republic.
Kimmo Koskeniemmi and Mariikka Haapalainen.
1994. Gertwol–lingsoft oy. Linguistische Veri-
fikation: Dokumentation zurErsten Morpholympics,
pages 121–140.
Ronan Le Nagard and Philipp Koehn. 2010. Aiding
pronoun translation with co-reference resolution. In
Proceedings of the Joint 5th Workshop on Statisti-
cal Machine Translation and Metrics (MATR), pages
258–267, Uppsala, Sweden.
Sharid Loaiciga, Thomas Meyer, and Andrei Popescu-
Belis. 2014. English-French Verb Phrase Align-
ment in Europarl for Tense Translation Modeling. In
Proceedings of the 9th international conference on
Language Resources and Evaluation (LREC), Reyk-
javik, Iceland.
Laura Mascarell, Mark Fishel, Natalia Korchagina, and
Martin Volk. 2014. Enforcing consistent translation
of German compound coreferences. In Proceedings
of the 12th Konvens Conference, Hildesheim, Ger-
many.
Thomas Meyer and Andrei Popescu-Belis. 2012. Us-
ing sense-labeled discourse connectives for statisti-
cal machine translation. In Proceedings of the EACL
2012 Joint Workshop on Exploiting Synergies be-
tween IR and MT, and Hybrid Approaches to MT
(ESIRMT-HyTra), pages 129–138, Avignon, France.
Thomas Meyer. 2014. Discourse-level Features for
Statistical Machine Translation. PhD thesis, EPFL,
Lausanne.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting of the Association for
Computational Linguistics (ACL), pages 160–167,
Sapporo, Japan.
Kishore Papineni, Salim Roukos, Todd Ard, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL).
Andreas Stolcke, Jing Zheng, Wen Wang, and Victor
Abrash. 2011. SRILM at Sixteen: Update and Out-
look. In Proceedings of the IEEE Automatic Speech
Recognition and Understanding Workshop (ASRU),
Waikoloa, Hawaii.
J¨org Tiedemann. 2010. Context adaptation in statisti-
cal machine translation using models with exponen-
tially decaying cache. In Proceedings of the 2010
Workshop on Domain Adaptation for Natural Lan-
guage Processing, pages 8–15, Uppsala, Sweden.
Ferhan Ture, Douglas W. Oard, and Philip Resnik.
2012. Encouraging consistent translation choices.
In Proceedings of the 2012 Conference of the North
</reference>
<page confidence="0.98464">
14
</page>
<reference confidence="0.9986765">
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), pages 417–426, Montr´eal, Canada.
Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang.
2011. Document-level consistency verification in
machine translation. In Proceedings of the 13th Ma-
chine Translation Summit, pages 131–138, Xiamen,
China.
</reference>
<page confidence="0.997907">
15
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002659">
<title confidence="0.99657">Leveraging Compounds to Improve Noun Phrase</title>
<author confidence="0.6705305">from Chinese</author>
<author confidence="0.6705305">German Xiao</author>
<affiliation confidence="0.951973">Idiap Research</affiliation>
<date confidence="0.62874">1920</date>
<email confidence="0.56537">xiao.pu@idiap.ch</email>
<author confidence="0.99994">Mark Fishel</author>
<affiliation confidence="0.979616">Institute of Computational Linguistics, U. of Zurich</affiliation>
<address confidence="0.999952">8050 Zurich, Switzerland</address>
<email confidence="0.968349">fishel@cl.uzh.ch</email>
<author confidence="0.99211">Laura Mascarell</author>
<affiliation confidence="0.979574">Institute of Computational Linguistics, U. of Zurich</affiliation>
<address confidence="0.999837">8050 Zurich, Switzerland</address>
<email confidence="0.912271">mascarell@cl.uzh.ch</email>
<note confidence="0.5292405">Ngoc-Quang Idiap Research 1920 nluong@idiap.ch Andrei Idiap Research</note>
<date confidence="0.576877">1920</date>
<title confidence="0.346802">apbelis@idiap.ch</title>
<author confidence="0.64997">Martin</author>
<affiliation confidence="0.98626">Institute of</affiliation>
<address confidence="0.892682">Linguistics, U. of 8050 Zurich,</address>
<email confidence="0.977586">volk@cl.uzh.ch</email>
<abstract confidence="0.995466">This paper presents a method to improve the translation of polysemous nouns, when a previous occurrence of the noun as the head of a compound noun phrase is available in a text. The occurrences are identified through pattern matching rules, detect followed closely by a potentially coreferent ocof such as “Nordwand Wand”. Two strategies are proposed to improve the translation of the second ocof re-using the cached transof the or the translation of head of the translation of Experiments are performed on Chinese-to- English and German-to-French statistical machine translation, over the WIT3 and Text+Berg corpora respectively, with 261 each. The results suggest that while the overall BLEU scores increase only slightly, the translations of the targeted polysemous nouns are significantly improved.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrei Alexandrescu</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Graph-based learning for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>119--127</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="22221" citStr="Alexandrescu and Kirchhoff (2009)" startWordPosition="3675" endWordPosition="3679"> the model propagates the error to the following sentences. Gong et al. (2011) later extended Tiedemann’s proposal by initializing the cache with phrase pairs from similar documents at the beginning of the translation and by also applying a topic cache, which was introduced to deal with the error propagation issue. Xiao et al. (2011) defined a three step procedure that enforces the consistent translation of ambiguous words, achieving improvements for EN/ZH. Ture et al. (2012) encouraged consistency for AR/EN MT by introducing cross-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences having a similar graph representation. Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual informa</context>
</contexts>
<marker>Alexandrescu, Kirchhoff, 2009</marker>
<rawString>Andrei Alexandrescu and Katrin Kirchhoff. 2009. Graph-based learning for statistical machine translation. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 119– 127, Boulder, Colorado.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Noah Bubenhofer</author>
</authors>
<location>Martin Volk, David Klaper,</location>
<marker>Bubenhofer, </marker>
<rawString>Noah Bubenhofer, Martin Volk, David Klaper,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuela Weibel</author>
<author>Daniel W¨uest</author>
</authors>
<date>2013</date>
<booktitle>Text+Berg-korpus (release 147 v03). Digitale Edition des Jahrbuch des SAC 1864-1923, Echo des Alpes 1872-1924 und Die</booktitle>
<location>Alpen</location>
<marker>Weibel, W¨uest, 2013</marker>
<rawString>Manuela Weibel, and Daniel W¨uest. 2013. Text+Berg-korpus (release 147 v03). Digitale Edition des Jahrbuch des SAC 1864-1923, Echo des Alpes 1872-1924 und Die Alpen 1925-2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
</authors>
<title>One Translation per Discourse.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW),</booktitle>
<pages>pages</pages>
<contexts>
<context position="20966" citStr="Carpuat, 2009" startWordPosition="3476" endWordPosition="3477">red here, almost all (20) involve a reference translation of Y by a pronoun. In these cases, the baseline 6Average of s Ei=1 |scorei − mean |over all ratings . 12 system translates only about half of them with a correct noun (9 out of 20), while the post-edited system translates correctly 19 out of 20. 5 Related Work We briefly review in this section several previous studies from which the present one has benefited. Our idea is built upon the one-sense-per-discourse hypothesis (Gale et al., 1992) and its application to machine translation is based on the premise that consistency in discourse (Carpuat, 2009) is desirable. The initial compound idea was first published by Mascarell et al. (2014), in which the coreference of compound noun phrases in German (e.g. Nordwand/Wand) was studied and used to improve DE/FR translation by assuming that the last constituent of the compound Y should share the same translation as that of Y in XY . Several other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly </context>
</contexts>
<marker>Carpuat, 2009</marker>
<rawString>Marine Carpuat. 2009. One Translation per Discourse. In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW), pages 19–27, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Christian Girardi</author>
<author>Marcello Federico</author>
</authors>
<title>WIT3: Web inventory of transcribed and translated talks.</title>
<date>2012</date>
<booktitle>In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT),</booktitle>
<pages>261--268</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="11673" citStr="Cettolo et al., 2012" startWordPosition="1899" endWordPosition="1902">d through the word alignment given by the SMT decoder. Next, we check that this translation appears as a translation of Y in the phrase table, and if so, we cache both Y and the obtained translation. We then enforce the cached translation every time a coreference Y to XY is identified. Note that this is different from the probabilistic caching proposed by Tiedemann (2010), because in our case the cached translation is deterministically enforced as the translation of Y . 3 Experimental Settings The experiments are carried out on two different parallel corpora: the WIT3 Chinese-English dataset (Cettolo et al., 2012) with transcripts of TED lectures and their translations, and the Text+Berg German-French corpus (Bubenhofer et al., 2013), a collection of articles from the year4Upon manual examination, we found that using the most recent XY was not a reliable candidate for the antecedent. 5In fact, we can use the translation of Y as a translation candidate for XY . Our observations show that this helps to improve BLEU scores, but does not affect the specific scoring of Y in Section 4. 10 Sentences Tokens ZH Training 188’758 19’880’790 Tuning 2’457 260’770 Testing 855 12’344 DE Training 285’877 5’194’622 Tun</context>
<context position="14779" citStr="Cettolo et al., 2012" startWordPosition="2422" endWordPosition="2425"> the two differ, the system’s translation can still be acceptable. Therefore, we analyzed these “undecided” situations manually, with three human annotators (among the authors of the paper). The annotators rated separately the system’s translations of Y and the reference ones as ‘good’, ‘acceptable’ or ‘wrong’. 4 Analysis of Results 4.1 Automatic Comparison with a Reference The BLEU scores obtained by the baseline SMT, the caching and post-editing methods, and an oracle system are given in Table 2. The scores are in the same range as the baseline scores found by other teams on these datasets (Cettolo et al., 2012, Table 7 for ZH/EN), and much higher on DE/FR than ZH/EN. Our methods have a small positive effect on ZH/EN translation, and a small negative effect on DE/FR one. Given the sparsity of XY/Y pairs with respect to the total number of words, hence the small number of changed words, these results meet our prior expectations. Indeed, we also computed the oracle BLEU scores for both language pairs, i.e. the scores when all Y members of XY/Y pairs are (manually) translated exactly as in the reference (last line of Table 2). These values are only slightly higher than the other scores, showing that ev</context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012. WIT3: Web inventory of transcribed and translated talks. In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT), pages 261–268, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the Workshop on Speech and Natural Language,</booktitle>
<pages>233--237</pages>
<contexts>
<context position="20853" citStr="Gale et al., 1992" startWordPosition="3457" endWordPosition="3460">ly outperforms the baseline in this case. Similarly to the observation above, we note that among the 24 cases considered here, almost all (20) involve a reference translation of Y by a pronoun. In these cases, the baseline 6Average of s Ei=1 |scorei − mean |over all ratings . 12 system translates only about half of them with a correct noun (9 out of 20), while the post-edited system translates correctly 19 out of 20. 5 Related Work We briefly review in this section several previous studies from which the present one has benefited. Our idea is built upon the one-sense-per-discourse hypothesis (Gale et al., 1992) and its application to machine translation is based on the premise that consistency in discourse (Carpuat, 2009) is desirable. The initial compound idea was first published by Mascarell et al. (2014), in which the coreference of compound noun phrases in German (e.g. Nordwand/Wand) was studied and used to improve DE/FR translation by assuming that the last constituent of the compound Y should share the same translation as that of Y in XY . Several other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrase</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A Gale, Kenneth W Church, and David Yarowsky. 1992. One sense per discourse. In Proceedings of the Workshop on Speech and Natural Language, pages 233–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengxian Gong</author>
<author>Min Zhang</author>
<author>Guodong Zhou</author>
</authors>
<title>Cache-based document-level statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>909--919</pages>
<location>Edinburgh.</location>
<contexts>
<context position="21666" citStr="Gong et al. (2011)" startWordPosition="3590" endWordPosition="3593">2014), in which the coreference of compound noun phrases in German (e.g. Nordwand/Wand) was studied and used to improve DE/FR translation by assuming that the last constituent of the compound Y should share the same translation as that of Y in XY . Several other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly translated and cached, the model propagates the error to the following sentences. Gong et al. (2011) later extended Tiedemann’s proposal by initializing the cache with phrase pairs from similar documents at the beginning of the translation and by also applying a topic cache, which was introduced to deal with the error propagation issue. Xiao et al. (2011) defined a three step procedure that enforces the consistent translation of ambiguous words, achieving improvements for EN/ZH. Ture et al. (2012) encouraged consistency for AR/EN MT by introducing cross-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences h</context>
</contexts>
<marker>Gong, Zhang, Zhou, 2011</marker>
<rawString>Zhengxian Gong, Min Zhang, and Guodong Zhou. 2011. Cache-based document-level statistical machine translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 909–919, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liane Guillou</author>
</authors>
<title>Improving pronoun translation for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL 2012 Student Research Workshop (13th Conference of the European Chapter of the ACL),</booktitle>
<pages>1--10</pages>
<location>Avignon, France.</location>
<contexts>
<context position="23171" citStr="Guillou, 2012" startWordPosition="3830" endWordPosition="3831">ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a compound, when the coreference matches the head noun of the compound. Experimental results showed that baseline SMT systems often translate coreferences to compounds consistently for DE/FR, but much less so for ZH/EN. For a significant n</context>
</contexts>
<marker>Guillou, 2012</marker>
<rawString>Liane Guillou. 2012. Improving pronoun translation for statistical machine translation. In Proceedings of EACL 2012 Student Research Workshop (13th Conference of the European Chapter of the ACL), pages 1–10, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
<author>Marcello Federico</author>
</authors>
<title>Modelling Pronominal Anaphora in Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<location>Paris, France.</location>
<contexts>
<context position="23155" citStr="Hardmeier and Federico, 2010" startWordPosition="3826" endWordPosition="3829">d caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a compound, when the coreference matches the head noun of the compound. Experimental results showed that baseline SMT systems often translate coreferences to compounds consistently for DE/FR, but much less so for ZH/EN. For</context>
</contexts>
<marker>Hardmeier, Federico, 2010</marker>
<rawString>Christian Hardmeier and Marcello Federico. 2010. Modelling Pronominal Anaphora in Statistical Machine Translation. In Proceedings of International Workshop on Spoken Language Translation (IWSLT), Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
<author>Joakim Nivre</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Document-Wide Decoding for PhraseBased Statistical Machine Translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL), Jeju,</booktitle>
<contexts>
<context position="22654" citStr="Hardmeier et al., 2012" startWordPosition="3747" endWordPosition="3751">vements for EN/ZH. Ture et al. (2012) encouraged consistency for AR/EN MT by introducing cross-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences having a similar graph representation. Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challen</context>
</contexts>
<marker>Hardmeier, Nivre, Tiedemann, 2012</marker>
<rawString>Christian Hardmeier, Joakim Nivre, and J¨org Tiedemann. 2012. Document-Wide Decoding for PhraseBased Statistical Machine Translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL), Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
</authors>
<date>2014</date>
<booktitle>Discourse in Statistical Machine Translation. PhD thesis,</booktitle>
<institution>Uppsala University, Sweden.</institution>
<contexts>
<context position="23407" citStr="Hardmeier, 2014" startWordPosition="3862" endWordPosition="3863">orporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a compound, when the coreference matches the head noun of the compound. Experimental results showed that baseline SMT systems often translate coreferences to compounds consistently for DE/FR, but much less so for ZH/EN. For a significant number of cases in which the noun phrase Y had multiple meanings, our system reduced the frequency of mistranslations in comparison to the baseline, and improved noun phrase translation. In this work, we considered XY/Y pairs, hypothesiz</context>
</contexts>
<marker>Hardmeier, 2014</marker>
<rawString>Christian Hardmeier. 2014. Discourse in Statistical Machine Translation. PhD thesis, Uppsala University, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing (EMNLP) and Computational Natural Language Learning (CONLL),</booktitle>
<pages>868--876</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="22747" citStr="Koehn and Hoang, 2007" startWordPosition="3763" endWordPosition="3766">-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences having a similar graph representation. Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of usin</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing (EMNLP) and Computational Natural Language Learning (CONLL), pages 868– 876, Prague, Czech Republic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs.</title>
<date>2007</date>
<booktitle>In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics (ACL), Demonstration Session,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13359" citStr="Koehn et al., 2007" startWordPosition="2185" endWordPosition="2188">sed on machine learning. The rules for selecting coreferent XY/Y pairs in Chinese identified 261 pairs among 192k sentences. The rather low rate of occurrence (about one every 700 sentences) is explained by the strict conditions of the selection rules, which are designed to maximize the likelihood of coreference. In German, less restrictive rules selected 7,365 XY/Y pairs (a rate of one every 40 sentences). Still, in what follows, we randomly selected 261 XY/Y pairs for the DE/FR test data, to match their number in the ZH/EN test data. Our baseline SMT system is the Moses phrasebased decoder (Koehn et al., 2007), trained over tokenized and true-cased data. The language models were built using SRILM (Stolcke et al., 2011) at order 3 (i.e. up to trigrams) using the default smoothing method (i.e. Good-Turing). Optimization was done using Minimum Error Rate Training (Och, 2003) as provided with Moses. The effectiveness of proposed systems is measured in two ways. First, we use BLEU (Papineni et al., 2002) for overall evaluation, to verify whether our systems provide better translation for entire texts. Then, we focus on the XY/Y pairs and count the number of cases in which the translations of Y match the</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbs. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics (ACL), Demonstration Session, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskeniemmi</author>
<author>Mariikka Haapalainen</author>
</authors>
<title>Gertwol–lingsoft oy. Linguistische Verifikation: Dokumentation zurErsten Morpholympics,</title>
<date>1994</date>
<pages>121--140</pages>
<contexts>
<context position="9735" citStr="Koskeniemmi and Haapalainen, 1994" startWordPosition="1549" endWordPosition="1552">. Both elements comprising the compound structure XY/Y are identified, for the standard cases, with only one possible XY referring to one Y . The translation of both words are provided by the baseline SMT system, and our system subsequently verifies if the translations of Y in both noun phrases are identical or different. We keep them intact in the first case, while in the second 1Using the Stanford Word Segmenter available from http://nlp.stanford.edu/software/segmenter.shtml. 2Using the Stanford Log-linear Part-of-speech Tagger, http://nlp.stanford.edu/software/tagger.shtml. 3Using Gertwol (Koskeniemmi and Haapalainen, 1994). case we replace the translation of Y by the translation of XY or by its head noun only, if it contains several words. In the example in Figure 1, XY is translated into ‘high heel’ and Y into ‘shoes’, which is a wrong translation of 9 in this context. Using the consistency constraint, our method postedits the translation of Y replacing it with ‘heel’, which is the correct word. Several differences from the ideal case presented above must be handled separately. First, it may occur that several XY are likely co-referent with the same Y . In this case, if their translations differ, given that we</context>
</contexts>
<marker>Koskeniemmi, Haapalainen, 1994</marker>
<rawString>Kimmo Koskeniemmi and Mariikka Haapalainen. 1994. Gertwol–lingsoft oy. Linguistische Verifikation: Dokumentation zurErsten Morpholympics, pages 121–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Le Nagard</author>
<author>Philipp Koehn</author>
</authors>
<title>Aiding pronoun translation with co-reference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint 5th Workshop on Statistical Machine Translation and Metrics (MATR),</booktitle>
<pages>258--267</pages>
<location>Uppsala,</location>
<marker>Le Nagard, Koehn, 2010</marker>
<rawString>Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint 5th Workshop on Statistical Machine Translation and Metrics (MATR), pages 258–267, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharid Loaiciga</author>
<author>Thomas Meyer</author>
<author>Andrei PopescuBelis</author>
</authors>
<title>English-French Verb Phrase Alignment in Europarl for Tense Translation Modeling.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th international conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="23008" citStr="Loaiciga et al., 2014" startWordPosition="3803" endWordPosition="3806"> MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a compound, when the coreference matches the head noun of the compound. Expe</context>
</contexts>
<marker>Loaiciga, Meyer, PopescuBelis, 2014</marker>
<rawString>Sharid Loaiciga, Thomas Meyer, and Andrei PopescuBelis. 2014. English-French Verb Phrase Alignment in Europarl for Tense Translation Modeling. In Proceedings of the 9th international conference on Language Resources and Evaluation (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Mascarell</author>
<author>Mark Fishel</author>
<author>Natalia Korchagina</author>
<author>Martin Volk</author>
</authors>
<title>Enforcing consistent translation of German compound coreferences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 12th Konvens Conference,</booktitle>
<location>Hildesheim, Germany.</location>
<contexts>
<context position="4908" citStr="Mascarell et al. (2014)" startWordPosition="757" endWordPosition="760">inch heel. ✓ Figure 1: Compound post-editing method illustrated on ZH/EN. The first translation of �FRR into ‘heel’ enables the correct translation of the subsequent occurrence of 9 as ‘heel’, by post-editing the baseline output ‘shoes’. The paper is organized as follows. In Section 2 we present the main components of our proposal: first, the rules for identifying XY/Y pairs, and then two alternative methods for improving the coherence of the translation of a subsequent mention Y , one based on post-editing and the other one based on caching, which builds upon initial experiments presented by Mascarell et al. (2014). In Section 3, we present our experimental setting. In Section 4, we evaluate our proposal on ZH/EN and DE/FR translation, demonstrating that the translation of nouns is indeed improved, mainly by automatic or human comparisons with the reference translation. We conclude with a brief discussion of related studies (Section 5) and with perspectives for future work (Section 6). 2 Description of the Method 2.1 Overview We propose to use the translation of a compound XY to improve the translation of a subsequent occurrence of Y , the head of the XY noun phrase, in the following way, represented sc</context>
<context position="8854" citStr="Mascarell et al., 2014" startWordPosition="1415" endWordPosition="1419">word boundaries, they are preceded by word segmentation1 and tagging2 for Chinese and morphological analysis for German.3 For example, in the input sentence from Figure 1, we determine that the noun phrase 9 fits our condition for extraction as Y because as there are words before it which fulfill the condition for acceptance. 2.3 Enforcing the Translation of Y Two language-independent methods have been designed to ensure that the translations of XY and Y are a consistent: post-editing and caching. The second one builds upon an earlier proposal tested only on DE/FR with subjective evaluations (Mascarell et al., 2014). In the post-editing method, for each XY/Y pair, the translations of XY and Y by a baseline SMT system (see Section 3) are first identified through word alignment. We verify if the translations of Y in both noun phrases are identical or different. Both elements comprising the compound structure XY/Y are identified, for the standard cases, with only one possible XY referring to one Y . The translation of both words are provided by the baseline SMT system, and our system subsequently verifies if the translations of Y in both noun phrases are identical or different. We keep them intact in the fi</context>
<context position="10961" citStr="Mascarell et al., 2014" startWordPosition="1777" endWordPosition="1780">nnot resolve the coreference, we do not post-edit Y .4 If the translations of the several occurrences of XY are the same, but consist of one word, we still do not postedit Y . We only change it if the translations consist of several words, ensuring that XY is a compound noun phrase. Second, if the compound XY is not translated (out-of-vocabulary word), we do not post-edit Y .5 Third, sometimes the alignment of Y is empty in the target sentence (alignment error or untranslated word), in which case we apply post-editing as above on the word preceding Y , if it is aligned. In the caching method (Mascarell et al., 2014), once an XY compound is identified, we obtain the translation of the Y part of the compound through the word alignment given by the SMT decoder. Next, we check that this translation appears as a translation of Y in the phrase table, and if so, we cache both Y and the obtained translation. We then enforce the cached translation every time a coreference Y to XY is identified. Note that this is different from the probabilistic caching proposed by Tiedemann (2010), because in our case the cached translation is deterministically enforced as the translation of Y . 3 Experimental Settings The experi</context>
<context position="18211" citStr="Mascarell et al., 2014" startWordPosition="3007" endWordPosition="3011">than 70% of the pairs which are translated correctly by the baseline and by both systems, which indicates that the potential for improvement is much smaller for DE/FR than for ZH/EN. While the pattern of improvement between ZH/EN and DE/FR is similar for post-editing and for caching, for both language pairs the postediting method has a larger difference between improvements and degradations than the caching method. This can be explained by a lower coverage of the latter method, since it only enforces a translation when it appears as one of the translation candidates for Y in the phrase table (Mascarell et al., 2014). 4.2 Manual Evaluation of Undecided Cases When both the baseline and one of our systems generate translations of Y which differ from the reference, it is not possible to compare the translations without having them examined by human subjects. This was done for the 73 such cases of the ZH/EN post-editing system. Three of the authors, working independently, considered each translation from each system (in separate batches) with respect to the reference one, and rated its meaning on a 3-point scale: 2 (good), 1 (acceptable) or 0 (wrong). To estimate the inter-rater agreement, we computed the ave</context>
<context position="21053" citStr="Mascarell et al. (2014)" startWordPosition="3490" endWordPosition="3493">n these cases, the baseline 6Average of s Ei=1 |scorei − mean |over all ratings . 12 system translates only about half of them with a correct noun (9 out of 20), while the post-edited system translates correctly 19 out of 20. 5 Related Work We briefly review in this section several previous studies from which the present one has benefited. Our idea is built upon the one-sense-per-discourse hypothesis (Gale et al., 1992) and its application to machine translation is based on the premise that consistency in discourse (Carpuat, 2009) is desirable. The initial compound idea was first published by Mascarell et al. (2014), in which the coreference of compound noun phrases in German (e.g. Nordwand/Wand) was studied and used to improve DE/FR translation by assuming that the last constituent of the compound Y should share the same translation as that of Y in XY . Several other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly translated and cached, the model propagates the error to the following sentences. Gong </context>
</contexts>
<marker>Mascarell, Fishel, Korchagina, Volk, 2014</marker>
<rawString>Laura Mascarell, Mark Fishel, Natalia Korchagina, and Martin Volk. 2014. Enforcing consistent translation of German compound coreferences. In Proceedings of the 12th Konvens Conference, Hildesheim, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
<author>Andrei Popescu-Belis</author>
</authors>
<title>Using sense-labeled discourse connectives for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the EACL 2012 Joint Workshop on Exploiting Synergies between IR and MT, and Hybrid Approaches to MT (ESIRMT-HyTra),</booktitle>
<pages>129--138</pages>
<location>Avignon, France.</location>
<contexts>
<context position="22933" citStr="Meyer and Popescu-Belis, 2012" startWordPosition="3790" endWordPosition="3793"> Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used as well. In other studies, factored translation models (Koehn and Hoang, 2007) have been used with the same purpose, by incorporating contextual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a</context>
</contexts>
<marker>Meyer, Popescu-Belis, 2012</marker>
<rawString>Thomas Meyer and Andrei Popescu-Belis. 2012. Using sense-labeled discourse connectives for statistical machine translation. In Proceedings of the EACL 2012 Joint Workshop on Exploiting Synergies between IR and MT, and Hybrid Approaches to MT (ESIRMT-HyTra), pages 129–138, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
</authors>
<title>Discourse-level Features for Statistical Machine Translation.</title>
<date>2014</date>
<tech>PhD thesis,</tech>
<institution>EPFL, Lausanne.</institution>
<contexts>
<context position="23421" citStr="Meyer, 2014" startWordPosition="3864" endWordPosition="3865">tual information into labels used to indicate the meaning of ambiguous discourse connectives (Meyer and Popescu-Belis, 2012) or the expected tenses of verb phrase translations (Loaiciga et al., 2014). Quite naturally, there are analogies between our work and studies of pronoun translation (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), with the notable difference that pronominal anaphora resolution remains a challenging task. Finally, our work and its perspectives contribute to the general objective of using discourse-level information to improve MT (Hardmeier, 2014; Meyer, 2014). 6 Conclusion and Perspectives We presented a method to enforce the consistent translation of coreferences to a compound, when the coreference matches the head noun of the compound. Experimental results showed that baseline SMT systems often translate coreferences to compounds consistently for DE/FR, but much less so for ZH/EN. For a significant number of cases in which the noun phrase Y had multiple meanings, our system reduced the frequency of mistranslations in comparison to the baseline, and improved noun phrase translation. In this work, we considered XY/Y pairs, hypothesizing that when </context>
</contexts>
<marker>Meyer, 2014</marker>
<rawString>Thomas Meyer. 2014. Discourse-level Features for Statistical Machine Translation. PhD thesis, EPFL, Lausanne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="13626" citStr="Och, 2003" startWordPosition="2230" endWordPosition="2231">aximize the likelihood of coreference. In German, less restrictive rules selected 7,365 XY/Y pairs (a rate of one every 40 sentences). Still, in what follows, we randomly selected 261 XY/Y pairs for the DE/FR test data, to match their number in the ZH/EN test data. Our baseline SMT system is the Moses phrasebased decoder (Koehn et al., 2007), trained over tokenized and true-cased data. The language models were built using SRILM (Stolcke et al., 2011) at order 3 (i.e. up to trigrams) using the default smoothing method (i.e. Good-Turing). Optimization was done using Minimum Error Rate Training (Och, 2003) as provided with Moses. The effectiveness of proposed systems is measured in two ways. First, we use BLEU (Papineni et al., 2002) for overall evaluation, to verify whether our systems provide better translation for entire texts. Then, we focus on the XY/Y pairs and count the number of cases in which the translations of Y match the reference or not, which can be computed automatically using the alignments. However, the automatic comparison of a system’s translation with the reference is not entirely informative, because even if the two differ, the system’s translation can still be acceptable. </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ard</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="13756" citStr="Papineni et al., 2002" startWordPosition="2251" endWordPosition="2255">y 40 sentences). Still, in what follows, we randomly selected 261 XY/Y pairs for the DE/FR test data, to match their number in the ZH/EN test data. Our baseline SMT system is the Moses phrasebased decoder (Koehn et al., 2007), trained over tokenized and true-cased data. The language models were built using SRILM (Stolcke et al., 2011) at order 3 (i.e. up to trigrams) using the default smoothing method (i.e. Good-Turing). Optimization was done using Minimum Error Rate Training (Och, 2003) as provided with Moses. The effectiveness of proposed systems is measured in two ways. First, we use BLEU (Papineni et al., 2002) for overall evaluation, to verify whether our systems provide better translation for entire texts. Then, we focus on the XY/Y pairs and count the number of cases in which the translations of Y match the reference or not, which can be computed automatically using the alignments. However, the automatic comparison of a system’s translation with the reference is not entirely informative, because even if the two differ, the system’s translation can still be acceptable. Therefore, we analyzed these “undecided” situations manually, with three human annotators (among the authors of the paper). The an</context>
</contexts>
<marker>Papineni, Roukos, Ard, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ard, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
<author>Victor Abrash</author>
</authors>
<title>SRILM at Sixteen: Update and Outlook.</title>
<date>2011</date>
<booktitle>In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), Waikoloa,</booktitle>
<location>Hawaii.</location>
<contexts>
<context position="13470" citStr="Stolcke et al., 2011" startWordPosition="2203" endWordPosition="2206">192k sentences. The rather low rate of occurrence (about one every 700 sentences) is explained by the strict conditions of the selection rules, which are designed to maximize the likelihood of coreference. In German, less restrictive rules selected 7,365 XY/Y pairs (a rate of one every 40 sentences). Still, in what follows, we randomly selected 261 XY/Y pairs for the DE/FR test data, to match their number in the ZH/EN test data. Our baseline SMT system is the Moses phrasebased decoder (Koehn et al., 2007), trained over tokenized and true-cased data. The language models were built using SRILM (Stolcke et al., 2011) at order 3 (i.e. up to trigrams) using the default smoothing method (i.e. Good-Turing). Optimization was done using Minimum Error Rate Training (Och, 2003) as provided with Moses. The effectiveness of proposed systems is measured in two ways. First, we use BLEU (Papineni et al., 2002) for overall evaluation, to verify whether our systems provide better translation for entire texts. Then, we focus on the XY/Y pairs and count the number of cases in which the translations of Y match the reference or not, which can be computed automatically using the alignments. However, the automatic comparison </context>
</contexts>
<marker>Stolcke, Zheng, Wang, Abrash, 2011</marker>
<rawString>Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. SRILM at Sixteen: Update and Outlook. In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), Waikoloa, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Context adaptation in statistical machine translation using models with exponentially decaying cache.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing,</booktitle>
<pages>8--15</pages>
<location>Uppsala,</location>
<contexts>
<context position="11426" citStr="Tiedemann (2010)" startWordPosition="1862" endWordPosition="1863">anslated word), in which case we apply post-editing as above on the word preceding Y , if it is aligned. In the caching method (Mascarell et al., 2014), once an XY compound is identified, we obtain the translation of the Y part of the compound through the word alignment given by the SMT decoder. Next, we check that this translation appears as a translation of Y in the phrase table, and if so, we cache both Y and the obtained translation. We then enforce the cached translation every time a coreference Y to XY is identified. Note that this is different from the probabilistic caching proposed by Tiedemann (2010), because in our case the cached translation is deterministically enforced as the translation of Y . 3 Experimental Settings The experiments are carried out on two different parallel corpora: the WIT3 Chinese-English dataset (Cettolo et al., 2012) with transcripts of TED lectures and their translations, and the Text+Berg German-French corpus (Bubenhofer et al., 2013), a collection of articles from the year4Upon manual examination, we found that using the most recent XY was not a reliable candidate for the antecedent. 5In fact, we can use the translation of Y as a translation candidate for XY .</context>
<context position="21386" citStr="Tiedemann (2010)" startWordPosition="3546" endWordPosition="3547">. Our idea is built upon the one-sense-per-discourse hypothesis (Gale et al., 1992) and its application to machine translation is based on the premise that consistency in discourse (Carpuat, 2009) is desirable. The initial compound idea was first published by Mascarell et al. (2014), in which the coreference of compound noun phrases in German (e.g. Nordwand/Wand) was studied and used to improve DE/FR translation by assuming that the last constituent of the compound Y should share the same translation as that of Y in XY . Several other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly translated and cached, the model propagates the error to the following sentences. Gong et al. (2011) later extended Tiedemann’s proposal by initializing the cache with phrase pairs from similar documents at the beginning of the translation and by also applying a topic cache, which was introduced to deal with the error propagation issue. Xiao et al. (2011) defined a three step procedure that enforces the consistent tr</context>
</contexts>
<marker>Tiedemann, 2010</marker>
<rawString>J¨org Tiedemann. 2010. Context adaptation in statistical machine translation using models with exponentially decaying cache. In Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing, pages 8–15, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferhan Ture</author>
<author>Douglas W Oard</author>
<author>Philip Resnik</author>
</authors>
<title>Encouraging consistent translation choices.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North</booktitle>
<contexts>
<context position="22068" citStr="Ture et al. (2012)" startWordPosition="3655" endWordPosition="3658">ases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly translated and cached, the model propagates the error to the following sentences. Gong et al. (2011) later extended Tiedemann’s proposal by initializing the cache with phrase pairs from similar documents at the beginning of the translation and by also applying a topic cache, which was introduced to deal with the error propagation issue. Xiao et al. (2011) defined a three step procedure that enforces the consistent translation of ambiguous words, achieving improvements for EN/ZH. Ture et al. (2012) encouraged consistency for AR/EN MT by introducing cross-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences having a similar graph representation. Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we compared caching and post-editing as ways of achieving this goal, but a document-level decoder such as Docent (Hardmeier et al., 2012) could be used</context>
</contexts>
<marker>Ture, Oard, Resnik, 2012</marker>
<rawString>Ferhan Ture, Douglas W. Oard, and Philip Resnik. 2012. Encouraging consistent translation choices. In Proceedings of the 2012 Conference of the North</rawString>
</citation>
<citation valid="false">
<title>American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</title>
<pages>417--426</pages>
<location>Montr´eal, Canada.</location>
<marker></marker>
<rawString>American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 417–426, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Xiao</author>
<author>Jingbo Zhu</author>
<author>Shujie Yao</author>
<author>Hao Zhang</author>
</authors>
<title>Document-level consistency verification in machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 13th Machine Translation Summit,</booktitle>
<pages>131--138</pages>
<location>Xiamen, China.</location>
<contexts>
<context position="21923" citStr="Xiao et al. (2011)" startWordPosition="3633" endWordPosition="3636">other approaches focused on enforcing consistent lexical choice. Tiedemann (2010) proposed a cache-model to enforce consistent translation of phrases across the document. However, caching is sensitive to error propagation, that is, when a phrase is incorrectly translated and cached, the model propagates the error to the following sentences. Gong et al. (2011) later extended Tiedemann’s proposal by initializing the cache with phrase pairs from similar documents at the beginning of the translation and by also applying a topic cache, which was introduced to deal with the error propagation issue. Xiao et al. (2011) defined a three step procedure that enforces the consistent translation of ambiguous words, achieving improvements for EN/ZH. Ture et al. (2012) encouraged consistency for AR/EN MT by introducing cross-sentence consistency features to the translation model, while Alexandrescu and Kirchhoff (2009) enforced similar translations to sentences having a similar graph representation. Our work is an instance of a recent trend aiming to go beyond sentence-by-sentence MT, by using semantic information from previous sentences to constrain or correct the decoding of the current one. In this paper, we com</context>
</contexts>
<marker>Xiao, Zhu, Yao, Zhang, 2011</marker>
<rawString>Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang. 2011. Document-level consistency verification in machine translation. In Proceedings of the 13th Machine Translation Summit, pages 131–138, Xiamen, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>