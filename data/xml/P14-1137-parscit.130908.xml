<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000176">
<title confidence="0.995929">
A Sense-Based Translation Model for Statistical Machine Translation
</title>
<author confidence="0.925378">
Deyi Xiong and Min Zhang∗
</author>
<affiliation confidence="0.87496">
Provincial Key Laboratory for Computer Information Processing Technology
</affiliation>
<address confidence="0.813739">
Soochow University, Suzhou, China 215006
</address>
<email confidence="0.98895">
{dyxiong, minzhang}@suda.edu.cn
</email>
<sectionHeader confidence="0.997209" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999887">
The sense in which a word is used deter-
mines the translation of the word. In this
paper, we propose a sense-based transla-
tion model to integrate word senses into
statistical machine translation. We build
a broad-coverage sense tagger based on
a nonparametric Bayesian topic model
that automatically learns sense clusters for
words in the source language. The pro-
posed sense-based translation model en-
ables the decoder to select appropriate
translations for source words according to
the inferred senses for these words us-
ing maximum entropy classifiers. Our
method is significantly different from pre-
vious word sense disambiguation reformu-
lated for machine translation in that the lat-
ter neglects word senses in nature. We test
the effectiveness of the proposed sense-
based translation model on a large-scale
Chinese-to-English translation task. Re-
sults show that the proposed model sub-
stantially outperforms not only the base-
line but also the previous reformulated
word sense disambiguation.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98984884">
One of very common phenomena in language is
that a plenty of words have multiple meanings.
In the context of machine translation, such dif-
ferent meanings normally produce different target
translations. Therefore a natural assumption is that
word sense disambiguation (WSD) may contribute
to statistical machine translation (SMT) by provid-
ing appropriate word senses for target translation
selection with context features (Carpuat and Wu,
2005).
∗Corresponding author
This assumption, however, has not been em-
pirically verified in the early days. Carpuat and
Wu (2005) adopt a standard formulation of WSD:
predicting word senses that are defined on an
ontology for ambiguous words. As they apply
WSD to Chinese-to-English translation, they pre-
dict word senses from a Chinese ontology HowNet
and project the predicted senses to English glosses
provided by HowNet. These glosses, used as the
sense predictions of their WSD system, are inte-
grated into a word-based SMT system either to
substitute for translation candidates of their trans-
lation model or to postedit the output of their SMT
system. They report that WSD degenerates the
translation quality of SMT.
In contrast to the standard WSD formulation,
Vickrey et al. (2005) reformulate the task of WSD
for SMT as predicting possible target translations
rather than senses for ambiguous source words.
They show that such a reformulated WSD can im-
prove the accuracy of a simplified word translation
task.
Following this WSD reformulation for SMT,
Chan et al. (2007) integrate a state-of-the-art
WSD system into a hierarchical phrase-based sys-
tem (Chiang, 2005). Carpuat and Wu (2007) also
use this reformulated WSD and further adapt it to
multi-word phrasal disambiguation. They both re-
port that the redefined WSD can significantly im-
prove SMT.
Although this reformulated WSD has proved
helpful for SMT, one question is not answered
yet: are pure word senses useful for SMT? The
early WSD for SMT (Carpuat and Wu, 2005)
uses projected word senses while the reformu-
lated WSD sidesteps word senses. In this pa-
per we would like to re-investigate this question
by resorting to word sense induction (WSI) that
is related to but different from WSD.1 We use
</bodyText>
<footnote confidence="0.7480265">
&apos;We will discuss the relation and difference between WSI
and WSD in Section 2.
</footnote>
<page confidence="0.920153">
1459
</page>
<note confidence="0.8370325">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1459–1469,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.997209">
WSI to obtain word senses for large-scale data.
With these word senses, we study in particular: 1)
whether word senses can be directly integrated to
SMT to improve translation quality and 2) whether
WSI-based model can outperform the reformu-
lated WSD in the context of SMT.
In order to incorporate word senses into SMT,
we propose a sense-based translation model that
is built on maximum entropy classifiers. We use a
nonparametric Bayesian topic model based WSI to
infer word senses for source words in our training,
development and test set. We collect training in-
stances from the sense-tagged training data to train
the proposed sense-based translation model. Spe-
cially,
</bodyText>
<listItem confidence="0.965581">
• Instead of predicting target translations for
ambiguous source words as the previous re-
formulated WSD does, we first predict word
senses for ambiguous source words. The pre-
dicted word senses together with other con-
text features are then used to predict possible
target translations for these words.
• Instead of using word senses defined by a
prespecified sense inventory as the standard
WSD does, we incorporate word senses that
are automatically learned from data into our
sense-based translation model.
</listItem>
<bodyText confidence="0.9999824">
We integrate the proposed sense-based transla-
tion model into a state-of-the-art SMT system and
conduct experiments on Chines-to-English trans-
lation using large-scale training data. Results
show that automatically learned word senses are
able to improve translation quality and the sense-
based translation model is better than the previous
reformulated WSD.
The remainder of this paper proceeds as fol-
lows. Section 2 introduces how we obtain word
senses for our large-scale training data via a WSI-
based broad-coverage sense tagger. Section 3
presents our sense-based translation model. Sec-
tion 4 describes how we integrate the sense-based
translation model into SMT. Section 5 elaborates
our experiments on the large-scale Chinese-to-
English translation task. Section 6 introduces re-
lated studies and highlights significant differences
from them. Finally, we conclude in Section 7 with
future directions.
</bodyText>
<sectionHeader confidence="0.9177195" genericHeader="introduction">
2 WSI-Based Broad-Coverage Sense
Tagger
</sectionHeader>
<bodyText confidence="0.999916">
In order to obtain word senses for any source
words, we build a broad-coverage sense tagger
that relies on the nonparametric Bayesian model
based word sense induction. We first describe
WSI, especially WSI based on the Hierarchical
Dirichlet Process (HDP) (Teh et al., 2004), a non-
parametric version of Latent Dirichlet Allocation
(LDA) (Blei et al., 2003). We then elaborate how
we use the HDP-based WSI to predict sense clus-
ters and to annotate source words in our train-
ing/development/test sets with these sense clus-
ters.
</bodyText>
<subsectionHeader confidence="0.996134">
2.1 Word Sense Induction
</subsectionHeader>
<bodyText confidence="0.999953228571429">
Before we introduce WSI, we differentiate word
type from word token. A word type refers to a
unique word as a vocabulary entry while a word
token is an occurrence of a word type. Take the
first sentence of this paragraph as an example, it
has 11 word tokens but 9 word types as there are
two word tokens of the word type “we” and two
tokens of the word type “word”.
Word sense induction is a task of automatically
inducing the underlying senses of word tokens
given the surrounding contexts where the word
tokens occur. The biggest difference from word
sense disambiguation lies in that WSI does not
rely on a predefined sense inventory. Such a pre-
specified list of senses is normally assumed by
WSD which predicts senses of word tokens using
this given inventory. From this perspective, WSI
can be treated as a clustering problem while WSD
a classification one.
Various clustering algorithms, such as k-means,
have been previously used for WSI. Recently, we
have also witnessed that WSI is cast as a topic
modeling problem where the sense clusters of a
word type are considered as underlying topics
(Brody and Lapata, 2009; Yao and Durme, 2011;
Lau et al., 2012). We follow this line to tailor a
topic modeling framework to induce word senses
for our large-scale training data.
In the topic-based WSI, surrounding context of
a word token is considered as a pseudo document
of the corresponding word type. A pseudo docu-
ment is composed of either a bag of neighboring
words of a word token, or the Part-to-Speech tags
of neighboring words, or other contextual infor-
mation elements. In this paper, we define a pseudo
</bodyText>
<page confidence="0.982403">
1460
</page>
<bodyText confidence="0.991981941176471">
document as ±N neighboring words centered on
a given word token. Table 1 shows examples of
pseudo documents for a Chinese word “wǎngluò”
(network). These two pseudo documents are ex-
tracted from a sentence listed in the first row of Ta-
ble 1. Here we set N = 5. We can extract as many
pseudo documents as the number of word tokens
of a given word type that occur in training data.
The collection of all these extracted pseudo docu-
ments of the given word type forms a corpus. We
can induce topics on this corpus for each pseudo
document via topic modeling approaches.
Figure 1(a) shows the LDA-based WSI for a
given word type W. The outer plate represents
replicates of pseudo documents which consist of
N neighboring words centered on the tokens of
the given word type W. wj,i is the i-th word of
the j-th pseudo document of the given word type
W. sj,i is the sense assigned to the word wj,i.
The conventional topic distribution θj for the j-
th pseudo document is taken as the the distribu-
tion over senses for the given word type W. The
LDA generative process for sense induction is as
follows: 1) for each pseudo document Dj, draw a
per-document sense distribution θj from a Dirich-
let distribution Dir(α); 2) for each item wj,i in the
pseudo document Dj, 2.1) draw a sense cluster
sj,i ∼ Multinomial(θj); and 2.2) draw a word
wj,i ∼ cpsj,i where cpsj,i is the distribution of
sense sj,i over words drawn from a Dirichlet dis-
tribution Dir(β).
As LDA needs to manually specify the num-
ber of senses (topics), a better idea is to let the
training data automatically determine the number
of senses for each word type. Therefore we re-
sort to the HDP, a natural nonparametric gener-
alization of LDA, for the inference of both sense
clusters and the number of sense clusters follow-
ing Lau et al. (2012) and Yao and Durme (2011).
The HDP for WSI is shown in Figure 1(b). The
HDP generative process for word sense induction
is as follows: 1) sample a base distribution G0
from a Dirichlet process DP(-y, H) with a con-
centration parameter -y and a base distribution H;
2) for each pseudo document Dj, sample a dis-
tribution Gj ∼ DP(α0, G0); 3) for each item
wj,i in the pseudo document Dj, 3.1) sample a
sense cluster sj,i ∼ Gj; and 3.2) sample a word
wj,i ∼ cpsj,i. Here G0 is a global distribution
over sense clusters that are shared by all Gj. Gj is
a per-document sense distribution over these sense
Figure 1: Graphical model representations of (a)
Latent Dirichlet Allocation for WSI, (b) Hierar-
chical Dirichlet Process for WSI.
clusters, which has its own document-specific pro-
portions of these sense clusters. The hyperparam-
eter -y, α0 in the HDP are both concentration pa-
rameters which control the variability of senses in
the global distribution G0 and document-specific
distribution Gj.
The HDP/LDA-based WSI complies with the
distributional hypothesis that states that words oc-
curring in the same contexts tend to have similar
meanings. We want to extend this hypothesis to
machine translation by building sense-based trans-
lation model upon the HDP-based word sense in-
duction: words with the same meanings tend to be
translated in the same way.
</bodyText>
<subsectionHeader confidence="0.999393">
2.2 Word Sense Tagging
</subsectionHeader>
<bodyText confidence="0.999980090909091">
We adopt the HDP-based WSI to automatically
predict word senses and use these predicted senses
to annotate source words. We individually build a
HDP-based WSI model per word type and train
these models on the training data. The sense for a
word token is defined as the most probable sense
according to the per-document sense distribution
Gj estimated for the corresponding pseudo doc-
ument that represents the surrounding context of
the word token. In particular, we take the follow-
ing steps.
</bodyText>
<equation confidence="0.953940421052632">
(a) (b)
i E [1, Nj]
wj,i
ϕk
k E [1, K]
sj,i
Oj
β
α
j E [1, J]
wj,i
i E [1, Nj]
sj,i
Gj
Go
H
j E [1, J]
γ
α0
</equation>
<page confidence="0.901943">
1461
</page>
<bodyText confidence="0.968934">
td tixing w6gu6 wdngluo yunying zh6 zhuyi f6ngf6n h�ike gongji , quebdo wdngluo dnqu6n o
Pseudo Documents for word “wdngluo”
td tixing w6gu6 wdngluo yunying zh6 zhuyi f6ngf6n h�ike
f6ngf6n h�ike gdngji , quebdo wdngluo dnqu6n o
</bodyText>
<tableCaption confidence="0.940254">
Table 1: Examples of pseudo documents extracted from a Chinese sentence (written in Chinese Pinyin).
</tableCaption>
<listItem confidence="0.813753148148148">
• Data preprocessing We preprocess the
source side of our bilingual training data as
well as development and test set by removing
stop words and rare words.
• Training Data Sense Annotation From the
preprocessed training data, we extract all
possible pseudo documents for each source
word type. The collection of these extracted
pseudo documents is used as a corpus to train
a HDP-based WSI model for the source word
type. In this way, we can train as many HDP-
based WSI models as the number of word
types kept after preprocessing. The sense
with the highest probability output by the
HDP-based WSI model for each pseudo doc-
ument is used as the sense cluster to label the
corresponding word token.
• Test/Dev Data Sense Annotation From the
preprocessed test data, we can also extract
pseudo documents for each source word type
that occur in the test/dev set. Using the
trained HDP-based WSI model that corre-
spond to the source word type in question, we
can obtain the best sense assignment for each
pseudo document of the word type, which
in turn is used to annotate the corresponding
word token in the test/dev data.
</listItem>
<sectionHeader confidence="0.982629" genericHeader="method">
3 Sense-Based Translation Model
</sectionHeader>
<bodyText confidence="0.999936333333333">
In this section we present our sense-based transla-
tion model and describe the features that we use as
well as the training process of this model.
</bodyText>
<subsectionHeader confidence="0.997924">
3.1 Model
</subsectionHeader>
<bodyText confidence="0.999629">
The sense-based translation model estimates the
probability that a source word c is translated into a
target phrase e˜ given contextual information, in-
cluding word senses that are obtained using the
HDP-based WSI as described in the last section.
We allow the target phrase e˜ to be either a phrase
of length up to 3 words or NULL so that we can
capture both multi-word and null translations. The
essential component of the model is a maximum
entropy (MaxEnt) based classifier that is used to
predict the translation probability p(˜e|C(c)). The
MaxEnt classifier can be formulated as follows.
</bodyText>
<equation confidence="0.996062666666667">
exp(Ei θihi(˜e,C(c)))
p(˜e|C(c)) = (1)
E&amp; exp(Ei θihi(˜e′, C(c)))
</equation>
<bodyText confidence="0.999957">
where his are binary features, θis are weights of
these features, C(c) is the surrounding context of
c.
We define two groups of binary features: 1) lex-
icon features and 2) sense features. All these fea-
tures take the following form.
</bodyText>
<equation confidence="0.936869666666667">
{ 1, if e˜ = ❑ and C(c).µ = ν
h(˜e, C(c)) =
0, else
</equation>
<bodyText confidence="0.996953137931034">
(2)
where ❑ is a placeholder for a possible target
translation (up to 3 words or NULL), µ is the name
of a contextual (lexicon or sense) feature for the
source word c, and the symbol ν represents the
value of the feature µ.
We extract both the lexicon and sense features
from a ±k-word window centered on the word c.
The lexicon features are defined as the preceding
k words, the succeeding k words and the word c
itself: {c−k, ..., c−1, c, c1, ..., ck}. The sense fea-
tures are defined as the predicted senses for these
words: {sc−k, ..., sc−1, sc, sc1, ..., sck}.
As we also use these neighboring words to pre-
dict word senses in the HDP-based WSI, the infor-
mation provided by the lexicon and sense features
may overlap. This is not a issue for the MaxEnt
classifier as it can deal with arbitrary overlapping
features (Berger et al., 1996). One may also won-
der whether the sense features can contribute to
SMT new information that can NOT be obtained
from the lexicon features. First, we believe that
the senses induced by the HDP-based WSI pro-
vide a different view of data than that of the lex-
icon features. Second, the sense features contain
semantic distributional information learned by the
HDP across contexts where lexical words occur.
Third, we empirically investigate this doubt by
comparing two MaxEnt-based translation models
</bodyText>
<page confidence="0.977751">
1462
</page>
<bodyText confidence="0.99989475">
in Section 5. One model only uses the lexicon fea-
tures while the other integrates both the lexicon
and sense features. The former model can be con-
sidered as a reformulated WSD for SMT as we de-
scribed in Section 1.
Given a source sentence {cz}i, the proposed
sense-based translation model M3 can be denoted
as
</bodyText>
<equation confidence="0.993516">
∏M3 = (ez|C(cz)) (3)
ci∈W
</equation>
<bodyText confidence="0.9998335">
where W is a set of words for which we build
MaxEnt classifiers (see the next subsection for the
discussion on how we build MaxEnt classifiers for
our sense-based translation model).
</bodyText>
<subsectionHeader confidence="0.996671">
3.2 Training
</subsectionHeader>
<bodyText confidence="0.999898964285714">
The training of the proposed sense-based transla-
tion model is a process of estimating the feature
weights Bs in the equation (1). There are two
strategies that we can use to obtain these weights.
We can either build an all-in-one MaxEnt clas-
sifier that integrates all source word types c and
their possible target translations e� or build multi-
ple MaxEnt classifiers. If we train the all-in-one
classifier, we have to predict millions of classes
(target translations of length up to 3 words). This
is normally intractable in practice. Therefore we
take the second strategy: building multiple Max-
Ent classifiers with one classifier per source word
type.
In order to train these classifiers, we have to col-
lect training events from our word-aligned bilin-
gual training data where source words are anno-
tated with their corresponding sense clusters pre-
dicted by the HDP-based WSI as described in
Section 2. A training event for a source word c
consists of all contextual elements in the form of
C(c).µ = v defined in the last subsection and the
target translation e. Using these collected events,
we can train our multiple classifiers. In prac-
tice, we do not build MaxEnt classifiers for source
words that occur less than 10 times in the train-
ing data and run the MaxEnt toolkit in a parallel
manner in order to expedite the training process.
</bodyText>
<sectionHeader confidence="0.864716" genericHeader="method">
4 Decoding with Sense-Based
Translation Model
</sectionHeader>
<bodyText confidence="0.99929425">
The sense-based translation model described
above is integrated into the log-linear translation
model of SMT as a sense-based knowledge source.
The weight of this model is tuned by the minimum
</bodyText>
<figureCaption confidence="0.9931335">
Figure 2: Architecture of SMT system with the
sense-based translation model.
</figureCaption>
<bodyText confidence="0.977715181818182">
error rate training (MERT) (Och, 2003) together
with other models such as the language model.
Figure 2 shows the architecture of the SMT
system enhanced with the sense-based translation
model. Before we translate a source sentence, we
use the HDP-based WSI models trained on the
training data to predict senses for word tokens oc-
curring in the source sentence as discussed in Sec-
tion 2.2. Note that the HDP-based WSI does not
predict senses for all words due to the following
two reasons.
</bodyText>
<listItem confidence="0.950826714285714">
• We do not train HDP-based WSI models for
word types for which we extract more than T
pseudo documents.2
• In the test/dev set, there are some words that
are unseen in the training data. These un-
seen words, of course, do not have their HDP-
based WSI models.
</listItem>
<bodyText confidence="0.999421428571429">
For these words, we set a default sense (i.e. sc =
si).
Sense tagging on test sentences can be done in
a preprocessing step. Once we get sense clus-
ters for word tokens in test sentences, we load
pre-trained MaxEnt classifiers of the correspond-
ing word types. During decoding, we keep word
alignments for each translation rule. Whenever a
new source word c is translated, we find its trans-
lation e� via the kept word alignments. We then
calculate the translation probability p(e|C(c)) ac-
cording to the equation (1) using the correspond-
ing loaded classifier. In this way, we can easily
calculate the sense-based translation model score.
</bodyText>
<figure confidence="0.972730705882353">
2we set T = 20, 000.
source
sentences
HDP-based
WSI
sense-tagged
source
sentences
MaxEnt
classifiers
other
models
decoder
sense-based
translation model
target
sentences
</figure>
<page confidence="0.906084">
1463
</page>
<sectionHeader confidence="0.993737" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999966444444444">
In this section, we carried out a series of ex-
periments on Chinese-to-English translation us-
ing large-scale bilingual training data. In order to
build the proposed sense-based translation model,
we annotated the source part of the bilingual train-
ing data with word senses induced by the HDP-
based WSI. With the trained sense-based transla-
tion model, we would like to investigate the fol-
lowing two questions:
</bodyText>
<listItem confidence="0.997235">
• Do word senses automatically induced by the
HDP-based WSI improve translation quality?
• Does the sense-based translation model out-
perform the reformulated WSD for SMT?
</listItem>
<subsectionHeader confidence="0.974518">
5.1 Setup
</subsectionHeader>
<bodyText confidence="0.99994264516129">
Our baseline system is a state-of-the-art SMT
system which adapts Bracketing Transduction
Grammars (Wu, 1997) to phrasal translation and
equips itself with a maximum entropy based
reordering model (Xiong et al., 2006). We used
LDC corpora LDC2004E12, LDC2004T08,
LDC2005T10, LDC2003E14, LDC2002E18,
LDC2005T06, LDC2003E07, LDC2004T07 as
our bilingual training data which consists of
3.84M bilingual sentences, 109.5M English word
tokens and 96.9M Chinese word tokens. We ran
Giza++ on the training data in two directions
and applied the “grow-diag-final” refinement
rule (Koehn et al., 2003) to obtain word align-
ments. From the word-aligned data, we extracted
weighted phrase pairs to generate our phrase
table. We trained a 5-gram language model on the
Xinhua section of the English Gigaword corpus
(306 million words) using the SRILM toolkit
(Stolcke, 2002) with the modified Kneser-Ney
smoothing (Chen and Goodman, 1996).
We trained our HDP-based WSI models via the
C++ HDP toolkit3 (Wang and Blei, 2012). We
set the hyperparameters γ = 0.1 and α0 = 1.0
following Lau et al. (2012).We extracted pseudo
documents from a ±10-word window centered on
the corresponding word token for each word type
following Brody and Lapata (2009). As described
in Section 2.2, we preprocessed the source part
of our bilingual training data by removing stop
words and infrequent words that occurs less than
</bodyText>
<footnote confidence="0.939349">
3http://www.cs.cmu.edu/˜chongw/
resource.html
</footnote>
<table confidence="0.999824166666667">
Training Test
# Word Types 67,723 4,348
# Total Pseudo Documents 27.73M 11,777
# Avg Pseudo Documents 427.79 2.71
# Total Senses 271,770 24,162
# Avg Senses 4.01 5.56
</table>
<tableCaption confidence="0.914222">
Table 2: Statistics of the HDP-based word sense
induction on the training and test data.
</tableCaption>
<bodyText confidence="0.998121785714286">
10 times in the training data. From the prepro-
cessed data, we extracted pseudo documents for
each word type to train a HDP-based WSI model
per word type. Note that we do not build WSI
models for highly frequent words that occur more
than 20,000 times in order to expedite the HDP
training process.
We trained our MaxEnt classifiers with the off-
the-shelf MaxEnt tool.4 We performed 100 iter-
ations of the L-BFGS algorithm implemented in
the training toolkit on the collected training events
from the sense-annotated data as described in Sec-
tion 3.2. We set the Gaussian prior to 1 to avoid
overfitting. On average, we obtained 346 classes
(target translations) per source word type with the
maximum number of classes being 256,243. It
took an average of 57.5 seconds for training a
Maxent classifier.
We used the NIST MT03 evaluation test data as
our development set, and the NIST MT05 as the
test set. We evaluated translation quality with the
case-insensitive BLEU-4 (Papineni et al., 2002)
and NIST (Doddington, 2002). In order to al-
leviate the impact of MERT (Och, 2003) insta-
bility, we followed the suggestion of Clark et al.
(2011) to run MERT three times and report aver-
age BLEU/NIST scores over the three runs for all
our experiments.
</bodyText>
<subsectionHeader confidence="0.999546">
5.2 Statistics and Examples of Word Senses
</subsectionHeader>
<bodyText confidence="0.999923666666667">
Before we present our experiment results of the
sense-based translation model, we study some
statistics of the HDP-based WSI on the training
and test data. We show these statistics in Table 2.
There are 67,723 and 4,348 unique word types in
the training and test data after the preprocessing
step. For these word types, we extract 27.73M and
11,777 pseudo documents from the training and
test set respectively. On average, there are 427.79
</bodyText>
<footnote confidence="0.994803">
4http://homepages.inf.ed.ac.uk/
lzhang10/maxenttoolkit.html
</footnote>
<page confidence="0.968865">
1464
</page>
<table confidence="0.999401">
System BLEU(%) NIST
STM (±5w) 34.64 9.4346
STM (±10w) 34.76 9.5114
STM (±15w) - -
</table>
<tableCaption confidence="0.986661">
Table 4: Experiment results of the sense-based
</tableCaption>
<bodyText confidence="0.957222904761905">
translation model (STM) with lexicon and sense
features extracted from a window of size varying
from ±5 to ±15 words on the development set.
pseudo documents per word type in the training
data and 2.71 in the test set. The HDP-based
WSI learns 271,770 word senses in total using the
pseudo documents collected from the training data
and infers 24,162 word senses using the pseudo
documents extracted from the test set. There are
4.01 different senses per word type in the training
data and 5.56 in the test set on average.
Table 3 illustrates six different senses of the
word “运营 (operate)” learned by the HDP-based
WSI in the training data. We also show the most
probable 10 words for each sense cluster. Sense s1
represents the operations of company or organi-
zation, sense s2 denotes country/institution/inter-
nation operations, sense s3 refers to market opera-
tions, sense s4 corresponds to business operations,
sense s5 to public facility operations, and finally
s6 to economy operations.
</bodyText>
<subsectionHeader confidence="0.9774835">
5.3 Impact of Window Size k used in MaxEnt
Classifiers
</subsectionHeader>
<bodyText confidence="0.999856833333333">
Our first group of experiments were conducted to
investigate the impact of the window size k on
translation performance in terms of BLEU/NIST
on the development set. We extracted both the lex-
icon and sense features from a ±k-word window
for our MaxEnt classifiers. We varied k from 5
to 15. Experiment results are shown in Table 4.
We achieve the best performance when k = 10.
This suggests that a ±10-word window context is
sufficient for predicting target translations for am-
biguous source words. We therefore set k = 10
for all experiments thereafter.
</bodyText>
<subsectionHeader confidence="0.986452">
5.4 Effect of the Sense-Based Translation
Model
</subsectionHeader>
<bodyText confidence="0.999969833333333">
Our second group of experiments were carried out
to investigate whether the sense-base translation
model is able to improve translation quality by
comparing the system enhanced with our sense-
based translation model against the baseline. We
also studied the impact of word senses induced by
</bodyText>
<table confidence="0.9989565">
System BLEU(%) NIST
Base 33.53 9.0561
STM (sense) 34.15 9.2596
STM (sense+lexicon) 34.73 9.4184
</table>
<tableCaption confidence="0.974556">
Table 5: Experiment results of the sense-based
translation model (STM) against the baseline.
</tableCaption>
<table confidence="0.999815">
System BLEU(%) NIST
Base 33.53 9.0561
Reformulated WSD 34.16 9.3820
STM 34.73 9.4184
</table>
<tableCaption confidence="0.988616">
Table 6: Comparison results of the sense-based
</tableCaption>
<bodyText confidence="0.964430333333334">
translation model vs. the reformulated WSD for
SMT.
the HDP-based WSI on translation performance
by enforcing the sense-based translation model to
use only sense features. Table 5 shows the experi-
ment results. From the table, we can observe that
</bodyText>
<listItem confidence="0.872898">
• Our sense-based translation model achieves
a substantial improvement of 1.2 BLEU
points over the baseline. This indicates that
the sense-based translation model is able to
help select correct translations for ambiguous
source words.
• If we only integrate sense features into
the sense-based translation model, we can
still outperform the baseline by 0.62 BLEU
points. This suggests that automatically in-
duced word senses alone are indeed useful for
machine translation.
</listItem>
<subsectionHeader confidence="0.960313">
5.5 Comparison to Word Sense
Disambiguation
</subsectionHeader>
<bodyText confidence="0.999920733333333">
As we mentioned in Section 3.1, our sense-based
translation model can be degenerated to a reformu-
lated WSD model for SMT if we only use lexicon
features in MaxEnt classifiers. This allows us to
directly compare our method against the reformu-
lated WSD for SMT. Table 6 shows the compari-
son result.
From the table, we can find that the sense-
based translation model outperforms the reformu-
lated WSD by 0.57 BLEU points. This suggests
that the HDP-based word sense induction is bet-
ter than the reformulated WSD in the context of
SMT. Furthermore, as the reformulated WSD is
a degenerated version of our sense-based transla-
tion model which only uses the lexicon features,
</bodyText>
<page confidence="0.970145">
1465
</page>
<table confidence="0.999671636363637">
S1 S2 S3
Lf (operate) Lf (operate) L� (operate)
int (facility) T-M (satellite) r$ (market)
i+IIf (plan) IfVt_ (system) SAL (enterprise)
_44` (foundation) Q*c (country) A-I (competition)
H (project) 1W, (supply) j!kI&apos; (assets)
7 (company) QRT (inter-nation) (profit)
g:7rL,Y1 (structure) #LY1 (institution) (cause)
ER* (service) AIT (proceed) (cost)
¢119/0, (organization) +,b (center) j!k-4�- (capital)
1W, (supply) rlJ&apos;� (cooperate) AL* (business)
S4 S5 S6
�� (cost) JA r$ (city) (lie)
(share price) A91 (process) (photograph)
27000 A*7j, (tap-water) 119
#*, � (Kosovo) Zr (factory) DPRK
OF (extra) (car) fgPA (insurance)
Zj!k (wage) %� (railway) jW___?E (overspend)
XJu (dollar) �57j, (sewage) (position)
1AL (commerce) ),�A (office) (economy)
�� (income) fg* (break-even) (competitor)
%*f (railway administration) ri ft (component) 7 (balance)
</table>
<tableCaption confidence="0.999917">
Table 3: Six different senses learned for the word “Lf” from the training data.
</tableCaption>
<bodyText confidence="0.993626333333333">
the sense features used in our model do provide
new information that can not be obtained by the
lexicon features.
</bodyText>
<sectionHeader confidence="0.999939" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999295892857143">
In this section we introduce previous studies that
are related to our work. For ease of comparison,
we roughly divide them into 4 categories: 1) WSD
for SMT, 2) topic-based WSI, 3) topic model for
SMT and 4) lexical selection.
WSD for SMT As we mentioned in Section
1, WSD has been successfully reformulated and
adapted to SMT (Vickrey et al., 2005; Carpuat and
Wu, 2007; Chan et al., 2007). Rather than predict-
ing word senses for ambiguous words, the refor-
mulated WSD directly predicts target translations
for source words with context information. Our
sense-based translation model also predicts target
translations for SMT. The significant difference is
that we predict word senses automatically learned
from data and incorporate these predicted senses
into SMT. Our experiments show that such word
senses are able to improve translation quality.
Topic-based WSI Topic-based WSI can be
considered as the foundation of our work as we
use it to obtain broad-coverage word senses to an-
notate our large-scale training data. Brody and La-
pata (2009)’s work is the first attempt to approach
WSI via topic modeling. They adapt LDA to word
sense induction by building one topic model per
word type. According to them, there are 3 sig-
nificant differences between topic-based WSI and
generic topic modeling.
</bodyText>
<listItem confidence="0.983432142857143">
• First, the goal of topic-based WSI is to di-
vide contexts of a word type into different
categories, each representing a sense cluster.
However generic topic models aim at topic
distributions of documents.
• Second, generic topic modeling explores
whole documents for topic inference while
topic-based WSI uses much smaller units in
a document (e.g., surrounding words of a tar-
get word) for word sense induction.
• Finally, the number of induced word senses
in WSI is usually less than 10 while the num-
ber of inferred topics in generic topic model-
ing is tens or hundreds.
</listItem>
<bodyText confidence="0.989369333333333">
As LDA-based WSI needs to manually spec-
ify the number of word senses, Yao and Durme
(2011) propose HDP-based WSI that is capable of
</bodyText>
<page confidence="0.974895">
1466
</page>
<bodyText confidence="0.999988972222223">
determining the number of senses for each word
type according to training data. Lau et al. (2012)
adopt the HDP-based WSI for novel sense de-
tection and empirically show that the HDP-based
WSI is better than the LDA-based WSI. We follow
them to set the hyperparameters of HDP for train-
ing and incorporate automatically induced word
senses into SMT in our work.
Topic model for SMT Generic topic models
are also explored for SMT. Zhao and Xing (2007)
propose a bilingual topic model and integrate a
topic-specific lexicon translation model into SMT.
Tam et al. (2007) also explore a bilingual topic
model for translation and language model adapta-
tion. Foster and Kunh (2007) introduce a mixture
model approach for translation model adaptation.
Xiao et al. (2012) propose a topic-based similar-
ity model for rule selection in hierarchical phrase-
based translation. Xiong and Zhang (2013) em-
ploy a sentence-level topic model to capture co-
herence for document-level machine translation.
The difference between our work and these pre-
vious studies on topic model for SMT lies in that
we adopt topic-based WSI to obtain word senses
rather than generic topics and integrate induced
word senses into machine translation.
Lexical selection Our work is also related to
lexical selection in SMT where appropriate target
lexical items for source words are selected by a
statistical model with context information (Banga-
lore et al., 2007; Mauser et al., 2009). The refor-
mulated WSD discussed before can also be con-
sidered as a lexical selection model. The signif-
icant difference from these studies is that we per-
form lexical selection using automatically induced
word senses by the HDP on the source side.
</bodyText>
<sectionHeader confidence="0.998918" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99999465">
We have presented a sense-based translation
model that integrates word senses into machine
translation. We capitalize on the broad-coverage
word sense induction system that is built on the
nonparametric Bayesian HDP to learn sense clus-
ters for words in the source language. We gen-
erate pseudo documents for word tokens in the
training/test data for the HDP-based WSI system
to infer topics. The most probable topic inferred
for a pseudo document is taken as the sense of
the corresponding word token. We incorporate
these learned word senses as translation evidences
into maximum entropy classifiers which form the
foundation of the proposed sense-based translation
model.
We carried out a series of experiments to vali-
date the effectiveness of the sense-based transla-
tion by comparing the model against the baseline
and the previous reformulated WSD. Our experi-
ment results show that
</bodyText>
<listItem confidence="0.983004571428572">
• The sense-based translation model is able to
substantially improve translation quality in
terms of both BLEU and NIST.
• The sense-based translation model is also
better than the previous reformulated WSD
for SMT.
• Word senses automatically induced by the
</listItem>
<bodyText confidence="0.955049">
HDP-based WSI on large-scale training data
are very useful for machine translation. To
the best of our knowledge, this is the first at-
tempt to empirically verify the positive im-
pact of word senses on translation quality.
Comparing with macro topics of documents in-
ferred by LDA with bag of words from the whole
documents, word senses inferred by the HDP-
based WSI can be considered as micro topics. In
the future, we would like to explore both the micro
and macro topics for machine translation. Addi-
tionally, we also want to induce sense clusters for
words in the target language so that we can build
sense-based language model and integrate it into
SMT. We would like to investigate whether auto-
matically learned senses of proceeding words are
helpful for predicting succeeding words.
</bodyText>
<sectionHeader confidence="0.957235" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9998504">
The work was sponsored by the National Natu-
ral Science Foundation of China under projects
61373095 and 61333018. We would like to thank
three anonymous reviewers for their insightful
comments.
</bodyText>
<sectionHeader confidence="0.999316" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993515428571429">
Srinivas Bangalore, Patrick Haffner, and Stephan Kan-
thak. 2007. Statistical Machine Translation through
Global Lexical Selection and Sentence Reconstruc-
tion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
152–159, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
</reference>
<page confidence="0.990165">
1467
</page>
<table confidence="0.7881695">
Adam L. Berger, Stephen A. Della Pietra, and Vincent Technology Research, HLT ’02, pages 138–145, San
J. Della Pietra. 1996. A Maximum Entropy Ap- Francisco, CA, USA. Morgan Kaufmann Publishers
proach to Natural Language Processing. Computa- Inc.
tional Linguistics, 22(1):39–71.
</table>
<reference confidence="0.999169689320389">
David M. Blei, Andrew Y. Ng, Michael I. Jordan,
and John Lafferty. 2003. Latent Dirichlet Al-
location. Journal of Machine Learning Research,
3:993–1022.
Samuel Brody and Mirella Lapata. 2009. Bayesian
Word Sense Induction. In Proceedings of the
12th Conference of the European Chapter of the
ACL (EACL 2009), pages 103–111, Athens, Greece,
March. Association for Computational Linguistics.
Marine Carpuat and Dekai Wu. 2005. Word Sense
Disambiguation vs. Statistical Machine Transla-
tion. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL’05), pages 387–394, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Marine Carpuat and Dekai Wu. 2007. Improving
Statistical Machine Translation Using Word Sense
Disambiguation. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 61–72.
Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007. Word Sense Disambiguation Improves Sta-
tistical Machine Translation. In Proceedings of the
45th Annual Meeting of the Association of Com-
putational Linguistics, pages 33–40, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Stanley F. Chen and Joshua Goodman. 1996. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. In Proceedings of the 34th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’96, pages 310–318, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL’05), pages
263–270, Ann Arbor, Michigan, June. Association
for Computational Linguistics.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better Hypothesis Testing for
Statistical Machine Translation: Controlling for Op-
timizer Instability. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
176–181, Portland, Oregon, USA, June.
George Doddington. 2002. Automatic Evaluation
of Machine Translation Quality Using N-gram Co-
occurrence Statistics. In Proceedings of the Sec-
ond International Conference on Human Language
George Foster and Roland Kuhn. 2007. Mixture-
Model Adaptation for SMT. In Proc. of the Second
Workshop on Statistical Machine Translation, pages
128–135, Prague, Czech Republic, June.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of the 2003 Human Language Technology
Conference of the North American Chapter of the
Association for Computational Linguistics, pages
58–54, Edmonton, Canada, May-June.
Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word Sense
Induction for Novel Sense Detection. In Proceed-
ings of the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 591–601, Avignon, France, April. Association
for Computational Linguistics.
Arne Mauser, Saˇsa Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-Based Lexicon Models. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages
210–218, Singapore, August. Association for Com-
putational Linguistics.
Franz Josef Och. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 160–167, Sap-
poro, Japan, July. Association for Computational
Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311–318, Philadelphia,
Pennsylvania, USA, July.
Yik-Cheung Tam, Ian R. Lane, and Tanja Schultz.
2007. Bilingual LSA-based adaptation for statis-
tical machine translation. Machine Translation,
21(4):187–207.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,
and David M. Blei. 2004. Hierarchical Dirichlet
processes. Journal of the American Statistical Asso-
ciation, 101.
David Vickrey, Luke Biewald, Marc Teyssier, and
Daphne Koller. 2005. Word-Sense Disambiguation
for Machine Translation. In HLT/EMNLP. The As-
sociation for Computational Linguistics.
C. Wang and D. M. Blei. 2012. A Split-Merge MCMC
Algorithm for the Hierarchical Dirichlet Process.
ArXiv e-prints, January.
</reference>
<page confidence="0.834376">
1468
</page>
<reference confidence="0.999891387096774">
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
Xinyan Xiao, Deyi Xiong, Min Zhang, Qun Liu, and
Shouxun Lin. 2012. A Topic Similarity Model for
Hierarchical Phrase-based Translation. In Proceed-
ings of the 50th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 750–758, Jeju Island, Korea, July. As-
sociation for Computational Linguistics.
Deyi Xiong and Min Zhang. 2013. A Topic-Based Co-
herence Model for Statistical Machine Translation.
In Proceedings of the Twenty-Seventh AAAI Confer-
ence on Artificial Intelligence (AAAI-13), Bellevue,
Washington, USA, July.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Max-
imum Entropy Based Phrase Reordering Model for
Statistical Machine Translation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 521–528,
Sydney, Australia, July.
Xuchen Yao and Benjamin Van Durme. 2011. Non-
parametric Bayesian Word Sense Induction. In
Proceedings of TextGraphs-6: Graph-based Meth-
ods for Natural Language Processing, pages 10–14,
Portland, Oregon, June. Association for Computa-
tional Linguistics.
Bin Zhao and Eric P. Xing. 2007. HM-BiTAM:
Bilingual Topic Exploration, Word Alignment, and
Translation. In Proc. NIPS 2007.
</reference>
<page confidence="0.996052">
1469
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.387947">
<title confidence="0.865076666666667">A Sense-Based Translation Model for Statistical Machine Translation Xiong Provincial Key Laboratory for Computer Information Processing</title>
<address confidence="0.514538">Soochow University, Suzhou, China</address>
<abstract confidence="0.999631192307693">The sense in which a word is used determines the translation of the word. In this paper, we propose a sense-based translation model to integrate word senses into statistical machine translation. We build a broad-coverage sense tagger based on a nonparametric Bayesian topic model that automatically learns sense clusters for words in the source language. The proposed sense-based translation model enables the decoder to select appropriate translations for source words according to the inferred senses for these words using maximum entropy classifiers. Our method is significantly different from previous word sense disambiguation reformulated for machine translation in that the latter neglects word senses in nature. We test the effectiveness of the proposed sensebased translation model on a large-scale Chinese-to-English translation task. Results show that the proposed model substantially outperforms not only the baseline but also the previous reformulated word sense disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Patrick Haffner</author>
<author>Stephan Kanthak</author>
</authors>
<title>Statistical Machine Translation through Global Lexical Selection and Sentence Reconstruction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>152--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="31854" citStr="Bangalore et al., 2007" startWordPosition="5248" endWordPosition="5252">l for rule selection in hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic model for SMT lies in that we adopt topic-based WSI to obtain word senses rather than generic topics and integrate induced word senses into machine translation. Lexical selection Our work is also related to lexical selection in SMT where appropriate target lexical items for source words are selected by a statistical model with context information (Bangalore et al., 2007; Mauser et al., 2009). The reformulated WSD discussed before can also be considered as a lexical selection model. The significant difference from these studies is that we perform lexical selection using automatically induced word senses by the HDP on the source side. 7 Conclusion We have presented a sense-based translation model that integrates word senses into machine translation. We capitalize on the broad-coverage word sense induction system that is built on the nonparametric Bayesian HDP to learn sense clusters for words in the source language. We generate pseudo documents for word tokens</context>
</contexts>
<marker>Bangalore, Haffner, Kanthak, 2007</marker>
<rawString>Srinivas Bangalore, Patrick Haffner, and Stephan Kanthak. 2007. Statistical Machine Translation through Global Lexical Selection and Sentence Reconstruction. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 152–159, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
<author>John Lafferty</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="6219" citStr="Blei et al., 2003" startWordPosition="954" endWordPosition="957">rates our experiments on the large-scale Chinese-toEnglish translation task. Section 6 introduces related studies and highlights significant differences from them. Finally, we conclude in Section 7 with future directions. 2 WSI-Based Broad-Coverage Sense Tagger In order to obtain word senses for any source words, we build a broad-coverage sense tagger that relies on the nonparametric Bayesian model based word sense induction. We first describe WSI, especially WSI based on the Hierarchical Dirichlet Process (HDP) (Teh et al., 2004), a nonparametric version of Latent Dirichlet Allocation (LDA) (Blei et al., 2003). We then elaborate how we use the HDP-based WSI to predict sense clusters and to annotate source words in our training/development/test sets with these sense clusters. 2.1 Word Sense Induction Before we introduce WSI, we differentiate word type from word token. A word type refers to a unique word as a vocabulary entry while a word token is an occurrence of a word type. Take the first sentence of this paragraph as an example, it has 11 word tokens but 9 word types as there are two word tokens of the word type “we” and two tokens of the word type “word”. Word sense induction is a task of automa</context>
</contexts>
<marker>Blei, Ng, Jordan, Lafferty, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, Michael I. Jordan, and John Lafferty. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Mirella Lapata</author>
</authors>
<title>Bayesian Word Sense Induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>103--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="7536" citStr="Brody and Lapata, 2009" startWordPosition="1183" endWordPosition="1186">word tokens occur. The biggest difference from word sense disambiguation lies in that WSI does not rely on a predefined sense inventory. Such a prespecified list of senses is normally assumed by WSD which predicts senses of word tokens using this given inventory. From this perspective, WSI can be treated as a clustering problem while WSD a classification one. Various clustering algorithms, such as k-means, have been previously used for WSI. Recently, we have also witnessed that WSI is cast as a topic modeling problem where the sense clusters of a word type are considered as underlying topics (Brody and Lapata, 2009; Yao and Durme, 2011; Lau et al., 2012). We follow this line to tailor a topic modeling framework to induce word senses for our large-scale training data. In the topic-based WSI, surrounding context of a word token is considered as a pseudo document of the corresponding word type. A pseudo document is composed of either a bag of neighboring words of a word token, or the Part-to-Speech tags of neighboring words, or other contextual information elements. In this paper, we define a pseudo 1460 document as ±N neighboring words centered on a given word token. Table 1 shows examples of pseudo docum</context>
<context position="21294" citStr="Brody and Lapata (2009)" startWordPosition="3540" endWordPosition="3543">lignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with the modified Kneser-Ney smoothing (Chen and Goodman, 1996). We trained our HDP-based WSI models via the C++ HDP toolkit3 (Wang and Blei, 2012). We set the hyperparameters γ = 0.1 and α0 = 1.0 following Lau et al. (2012).We extracted pseudo documents from a ±10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009). As described in Section 2.2, we preprocessed the source part of our bilingual training data by removing stop words and infrequent words that occurs less than 3http://www.cs.cmu.edu/˜chongw/ resource.html Training Test # Word Types 67,723 4,348 # Total Pseudo Documents 27.73M 11,777 # Avg Pseudo Documents 427.79 2.71 # Total Senses 271,770 24,162 # Avg Senses 4.01 5.56 Table 2: Statistics of the HDP-based word sense induction on the training and test data. 10 times in the training data. From the preprocessed data, we extracted pseudo documents for each word type to train a HDP-based WSI model</context>
<context position="29471" citStr="Brody and Lapata (2009)" startWordPosition="4853" endWordPosition="4857">ses for ambiguous words, the reformulated WSD directly predicts target translations for source words with context information. Our sense-based translation model also predicts target translations for SMT. The significant difference is that we predict word senses automatically learned from data and incorporate these predicted senses into SMT. Our experiments show that such word senses are able to improve translation quality. Topic-based WSI Topic-based WSI can be considered as the foundation of our work as we use it to obtain broad-coverage word senses to annotate our large-scale training data. Brody and Lapata (2009)’s work is the first attempt to approach WSI via topic modeling. They adapt LDA to word sense induction by building one topic model per word type. According to them, there are 3 significant differences between topic-based WSI and generic topic modeling. • First, the goal of topic-based WSI is to divide contexts of a word type into different categories, each representing a sense cluster. However generic topic models aim at topic distributions of documents. • Second, generic topic modeling explores whole documents for topic inference while topic-based WSI uses much smaller units in a document (e</context>
</contexts>
<marker>Brody, Lapata, 2009</marker>
<rawString>Samuel Brody and Mirella Lapata. 2009. Bayesian Word Sense Induction. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 103–111, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Word Sense Disambiguation vs. Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>387--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="1699" citStr="Carpuat and Wu, 2005" startWordPosition="245" endWordPosition="248">anslation task. Results show that the proposed model substantially outperforms not only the baseline but also the previous reformulated word sense disambiguation. 1 Introduction One of very common phenomena in language is that a plenty of words have multiple meanings. In the context of machine translation, such different meanings normally produce different target translations. Therefore a natural assumption is that word sense disambiguation (WSD) may contribute to statistical machine translation (SMT) by providing appropriate word senses for target translation selection with context features (Carpuat and Wu, 2005). ∗Corresponding author This assumption, however, has not been empirically verified in the early days. Carpuat and Wu (2005) adopt a standard formulation of WSD: predicting word senses that are defined on an ontology for ambiguous words. As they apply WSD to Chinese-to-English translation, they predict word senses from a Chinese ontology HowNet and project the predicted senses to English glosses provided by HowNet. These glosses, used as the sense predictions of their WSD system, are integrated into a word-based SMT system either to substitute for translation candidates of their translation mo</context>
<context position="3225" citStr="Carpuat and Wu, 2005" startWordPosition="491" endWordPosition="494">ds. They show that such a reformulated WSD can improve the accuracy of a simplified word translation task. Following this WSD reformulation for SMT, Chan et al. (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005). Carpuat and Wu (2007) also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation. They both report that the redefined WSD can significantly improve SMT. Although this reformulated WSD has proved helpful for SMT, one question is not answered yet: are pure word senses useful for SMT? The early WSD for SMT (Carpuat and Wu, 2005) uses projected word senses while the reformulated WSD sidesteps word senses. In this paper we would like to re-investigate this question by resorting to word sense induction (WSI) that is related to but different from WSD.1 We use &apos;We will discuss the relation and difference between WSI and WSD in Section 2. 1459 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1459–1469, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics WSI to obtain word senses for large-scale data. With these word senses, we study in pa</context>
</contexts>
<marker>Carpuat, Wu, 2005</marker>
<rawString>Marine Carpuat and Dekai Wu. 2005. Word Sense Disambiguation vs. Statistical Machine Translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 387–394, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving Statistical Machine Translation Using Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>61--72</pages>
<contexts>
<context position="2889" citStr="Carpuat and Wu (2007)" startWordPosition="434" endWordPosition="437">didates of their translation model or to postedit the output of their SMT system. They report that WSD degenerates the translation quality of SMT. In contrast to the standard WSD formulation, Vickrey et al. (2005) reformulate the task of WSD for SMT as predicting possible target translations rather than senses for ambiguous source words. They show that such a reformulated WSD can improve the accuracy of a simplified word translation task. Following this WSD reformulation for SMT, Chan et al. (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005). Carpuat and Wu (2007) also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation. They both report that the redefined WSD can significantly improve SMT. Although this reformulated WSD has proved helpful for SMT, one question is not answered yet: are pure word senses useful for SMT? The early WSD for SMT (Carpuat and Wu, 2005) uses projected word senses while the reformulated WSD sidesteps word senses. In this paper we would like to re-investigate this question by resorting to word sense induction (WSI) that is related to but different from WSD.1 We use &apos;We will discuss the relation an</context>
<context position="28795" citStr="Carpuat and Wu, 2007" startWordPosition="4750" endWordPosition="4753">istration) ri ft (component) 7 (balance) Table 3: Six different senses learned for the word “Lf” from the training data. the sense features used in our model do provide new information that can not be obtained by the lexicon features. 6 Related Work In this section we introduce previous studies that are related to our work. For ease of comparison, we roughly divide them into 4 categories: 1) WSD for SMT, 2) topic-based WSI, 3) topic model for SMT and 4) lexical selection. WSD for SMT As we mentioned in Section 1, WSD has been successfully reformulated and adapted to SMT (Vickrey et al., 2005; Carpuat and Wu, 2007; Chan et al., 2007). Rather than predicting word senses for ambiguous words, the reformulated WSD directly predicts target translations for source words with context information. Our sense-based translation model also predicts target translations for SMT. The significant difference is that we predict word senses automatically learned from data and incorporate these predicted senses into SMT. Our experiments show that such word senses are able to improve translation quality. Topic-based WSI Topic-based WSI can be considered as the foundation of our work as we use it to obtain broad-coverage wo</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving Statistical Machine Translation Using Word Sense Disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word Sense Disambiguation Improves Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2771" citStr="Chan et al. (2007)" startWordPosition="417" endWordPosition="420">edictions of their WSD system, are integrated into a word-based SMT system either to substitute for translation candidates of their translation model or to postedit the output of their SMT system. They report that WSD degenerates the translation quality of SMT. In contrast to the standard WSD formulation, Vickrey et al. (2005) reformulate the task of WSD for SMT as predicting possible target translations rather than senses for ambiguous source words. They show that such a reformulated WSD can improve the accuracy of a simplified word translation task. Following this WSD reformulation for SMT, Chan et al. (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005). Carpuat and Wu (2007) also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation. They both report that the redefined WSD can significantly improve SMT. Although this reformulated WSD has proved helpful for SMT, one question is not answered yet: are pure word senses useful for SMT? The early WSD for SMT (Carpuat and Wu, 2005) uses projected word senses while the reformulated WSD sidesteps word senses. In this paper we would like to re-investigate this question by resor</context>
<context position="28815" citStr="Chan et al., 2007" startWordPosition="4754" endWordPosition="4757">onent) 7 (balance) Table 3: Six different senses learned for the word “Lf” from the training data. the sense features used in our model do provide new information that can not be obtained by the lexicon features. 6 Related Work In this section we introduce previous studies that are related to our work. For ease of comparison, we roughly divide them into 4 categories: 1) WSD for SMT, 2) topic-based WSI, 3) topic model for SMT and 4) lexical selection. WSD for SMT As we mentioned in Section 1, WSD has been successfully reformulated and adapted to SMT (Vickrey et al., 2005; Carpuat and Wu, 2007; Chan et al., 2007). Rather than predicting word senses for ambiguous words, the reformulated WSD directly predicts target translations for source words with context information. Our sense-based translation model also predicts target translations for SMT. The significant difference is that we predict word senses automatically learned from data and incorporate these predicted senses into SMT. Our experiments show that such word senses are able to improve translation quality. Topic-based WSI Topic-based WSI can be considered as the foundation of our work as we use it to obtain broad-coverage word senses to annotat</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007. Word Sense Disambiguation Improves Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 33–40, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, ACL ’96,</booktitle>
<pages>310--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="20986" citStr="Chen and Goodman, 1996" startWordPosition="3487" endWordPosition="3490">DC2005T06, LDC2003E07, LDC2004T07 as our bilingual training data which consists of 3.84M bilingual sentences, 109.5M English word tokens and 96.9M Chinese word tokens. We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with the modified Kneser-Ney smoothing (Chen and Goodman, 1996). We trained our HDP-based WSI models via the C++ HDP toolkit3 (Wang and Blei, 2012). We set the hyperparameters γ = 0.1 and α0 = 1.0 following Lau et al. (2012).We extracted pseudo documents from a ±10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009). As described in Section 2.2, we preprocessed the source part of our bilingual training data by removing stop words and infrequent words that occurs less than 3http://www.cs.cmu.edu/˜chongw/ resource.html Training Test # Word Types 67,723 4,348 # Total Pseudo Documents 27.73M 11,777 # Avg P</context>
</contexts>
<marker>Chen, Goodman, 1996</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1996. An Empirical Study of Smoothing Techniques for Language Modeling. In Proceedings of the 34th Annual Meeting on Association for Computational Linguistics, ACL ’96, pages 310–318, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-Based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2866" citStr="Chiang, 2005" startWordPosition="432" endWordPosition="433">translation candidates of their translation model or to postedit the output of their SMT system. They report that WSD degenerates the translation quality of SMT. In contrast to the standard WSD formulation, Vickrey et al. (2005) reformulate the task of WSD for SMT as predicting possible target translations rather than senses for ambiguous source words. They show that such a reformulated WSD can improve the accuracy of a simplified word translation task. Following this WSD reformulation for SMT, Chan et al. (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005). Carpuat and Wu (2007) also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation. They both report that the redefined WSD can significantly improve SMT. Although this reformulated WSD has proved helpful for SMT, one question is not answered yet: are pure word senses useful for SMT? The early WSD for SMT (Carpuat and Wu, 2005) uses projected word senses while the reformulated WSD sidesteps word senses. In this paper we would like to re-investigate this question by resorting to word sense induction (WSI) that is related to but different from WSD.1 We use &apos;We will </context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 263–270, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>176--181</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="22891" citStr="Clark et al. (2011)" startWordPosition="3806" endWordPosition="3809">ta as described in Section 3.2. We set the Gaussian prior to 1 to avoid overfitting. On average, we obtained 346 classes (target translations) per source word type with the maximum number of classes being 256,243. It took an average of 57.5 seconds for training a Maxent classifier. We used the NIST MT03 evaluation test data as our development set, and the NIST MT05 as the test set. We evaluated translation quality with the case-insensitive BLEU-4 (Papineni et al., 2002) and NIST (Doddington, 2002). In order to alleviate the impact of MERT (Och, 2003) instability, we followed the suggestion of Clark et al. (2011) to run MERT three times and report average BLEU/NIST scores over the three runs for all our experiments. 5.2 Statistics and Examples of Word Senses Before we present our experiment results of the sense-based translation model, we study some statistics of the HDP-based WSI on the training and test data. We show these statistics in Table 2. There are 67,723 and 4,348 unique word types in the training and test data after the preprocessing step. For these word types, we extract 27.73M and 11,777 pseudo documents from the training and test set respectively. On average, there are 427.79 4http://hom</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 176–181, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic Evaluation of Machine Translation Quality Using N-gram Cooccurrence Statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Conference on Human Language</booktitle>
<contexts>
<context position="22774" citStr="Doddington, 2002" startWordPosition="3786" endWordPosition="3787">e L-BFGS algorithm implemented in the training toolkit on the collected training events from the sense-annotated data as described in Section 3.2. We set the Gaussian prior to 1 to avoid overfitting. On average, we obtained 346 classes (target translations) per source word type with the maximum number of classes being 256,243. It took an average of 57.5 seconds for training a Maxent classifier. We used the NIST MT03 evaluation test data as our development set, and the NIST MT05 as the test set. We evaluated translation quality with the case-insensitive BLEU-4 (Papineni et al., 2002) and NIST (Doddington, 2002). In order to alleviate the impact of MERT (Och, 2003) instability, we followed the suggestion of Clark et al. (2011) to run MERT three times and report average BLEU/NIST scores over the three runs for all our experiments. 5.2 Statistics and Examples of Word Senses Before we present our experiment results of the sense-based translation model, we study some statistics of the HDP-based WSI on the training and test data. We show these statistics in Table 2. There are 67,723 and 4,348 unique word types in the training and test data after the preprocessing step. For these word types, we extract 27.</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic Evaluation of Machine Translation Quality Using N-gram Cooccurrence Statistics. In Proceedings of the Second International Conference on Human Language</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>MixtureModel Adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proc. of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<location>Prague, Czech Republic,</location>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. MixtureModel Adaptation for SMT. In Proc. of the Second Workshop on Statistical Machine Translation, pages 128–135, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>58--54</pages>
<location>Edmonton, Canada, May-June.</location>
<contexts>
<context position="20654" citStr="Koehn et al., 2003" startWordPosition="3435" endWordPosition="3438">ated WSD for SMT? 5.1 Setup Our baseline system is a state-of-the-art SMT system which adapts Bracketing Transduction Grammars (Wu, 1997) to phrasal translation and equips itself with a maximum entropy based reordering model (Xiong et al., 2006). We used LDC corpora LDC2004E12, LDC2004T08, LDC2005T10, LDC2003E14, LDC2002E18, LDC2005T06, LDC2003E07, LDC2004T07 as our bilingual training data which consists of 3.84M bilingual sentences, 109.5M English word tokens and 96.9M Chinese word tokens. We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with the modified Kneser-Ney smoothing (Chen and Goodman, 1996). We trained our HDP-based WSI models via the C++ HDP toolkit3 (Wang and Blei, 2012). We set the hyperparameters γ = 0.1 and α0 = 1.0 following Lau et al. (2012).We extracted pseudo documents from a ±10-word window centered on the corresponding word token for each wor</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 58–54, Edmonton, Canada, May-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>Paul Cook</author>
<author>Diana McCarthy</author>
<author>David Newman</author>
<author>Timothy Baldwin</author>
</authors>
<title>Word Sense Induction for Novel Sense Detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>591--601</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Avignon, France,</location>
<contexts>
<context position="7576" citStr="Lau et al., 2012" startWordPosition="1191" endWordPosition="1194">m word sense disambiguation lies in that WSI does not rely on a predefined sense inventory. Such a prespecified list of senses is normally assumed by WSD which predicts senses of word tokens using this given inventory. From this perspective, WSI can be treated as a clustering problem while WSD a classification one. Various clustering algorithms, such as k-means, have been previously used for WSI. Recently, we have also witnessed that WSI is cast as a topic modeling problem where the sense clusters of a word type are considered as underlying topics (Brody and Lapata, 2009; Yao and Durme, 2011; Lau et al., 2012). We follow this line to tailor a topic modeling framework to induce word senses for our large-scale training data. In the topic-based WSI, surrounding context of a word token is considered as a pseudo document of the corresponding word type. A pseudo document is composed of either a bag of neighboring words of a word token, or the Part-to-Speech tags of neighboring words, or other contextual information elements. In this paper, we define a pseudo 1460 document as ±N neighboring words centered on a given word token. Table 1 shows examples of pseudo documents for a Chinese word “wǎngluò” (netwo</context>
<context position="9824" citStr="Lau et al. (2012)" startWordPosition="1595" endWordPosition="1598">irichlet distribution Dir(α); 2) for each item wj,i in the pseudo document Dj, 2.1) draw a sense cluster sj,i ∼ Multinomial(θj); and 2.2) draw a word wj,i ∼ cpsj,i where cpsj,i is the distribution of sense sj,i over words drawn from a Dirichlet distribution Dir(β). As LDA needs to manually specify the number of senses (topics), a better idea is to let the training data automatically determine the number of senses for each word type. Therefore we resort to the HDP, a natural nonparametric generalization of LDA, for the inference of both sense clusters and the number of sense clusters following Lau et al. (2012) and Yao and Durme (2011). The HDP for WSI is shown in Figure 1(b). The HDP generative process for word sense induction is as follows: 1) sample a base distribution G0 from a Dirichlet process DP(-y, H) with a concentration parameter -y and a base distribution H; 2) for each pseudo document Dj, sample a distribution Gj ∼ DP(α0, G0); 3) for each item wj,i in the pseudo document Dj, 3.1) sample a sense cluster sj,i ∼ Gj; and 3.2) sample a word wj,i ∼ cpsj,i. Here G0 is a global distribution over sense clusters that are shared by all Gj. Gj is a per-document sense distribution over these sense Fi</context>
<context position="21147" citStr="Lau et al. (2012)" startWordPosition="3518" endWordPosition="3521"> We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with the modified Kneser-Ney smoothing (Chen and Goodman, 1996). We trained our HDP-based WSI models via the C++ HDP toolkit3 (Wang and Blei, 2012). We set the hyperparameters γ = 0.1 and α0 = 1.0 following Lau et al. (2012).We extracted pseudo documents from a ±10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009). As described in Section 2.2, we preprocessed the source part of our bilingual training data by removing stop words and infrequent words that occurs less than 3http://www.cs.cmu.edu/˜chongw/ resource.html Training Test # Word Types 67,723 4,348 # Total Pseudo Documents 27.73M 11,777 # Avg Pseudo Documents 427.79 2.71 # Total Senses 271,770 24,162 # Avg Senses 4.01 5.56 Table 2: Statistics of the HDP-based word sense induction on the training and te</context>
<context position="30531" citStr="Lau et al. (2012)" startWordPosition="5036" endWordPosition="5039">ns of documents. • Second, generic topic modeling explores whole documents for topic inference while topic-based WSI uses much smaller units in a document (e.g., surrounding words of a target word) for word sense induction. • Finally, the number of induced word senses in WSI is usually less than 10 while the number of inferred topics in generic topic modeling is tens or hundreds. As LDA-based WSI needs to manually specify the number of word senses, Yao and Durme (2011) propose HDP-based WSI that is capable of 1466 determining the number of senses for each word type according to training data. Lau et al. (2012) adopt the HDP-based WSI for novel sense detection and empirically show that the HDP-based WSI is better than the LDA-based WSI. We follow them to set the hyperparameters of HDP for training and incorporate automatically induced word senses into SMT in our work. Topic model for SMT Generic topic models are also explored for SMT. Zhao and Xing (2007) propose a bilingual topic model and integrate a topic-specific lexicon translation model into SMT. Tam et al. (2007) also explore a bilingual topic model for translation and language model adaptation. Foster and Kunh (2007) introduce a mixture mode</context>
</contexts>
<marker>Lau, Cook, McCarthy, Newman, Baldwin, 2012</marker>
<rawString>Jey Han Lau, Paul Cook, Diana McCarthy, David Newman, and Timothy Baldwin. 2012. Word Sense Induction for Novel Sense Detection. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 591–601, Avignon, France, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne Mauser</author>
<author>Saˇsa Hasan</author>
<author>Hermann Ney</author>
</authors>
<title>Extending Statistical Machine Translation with Discriminative and Trigger-Based Lexicon Models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>210--218</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="31876" citStr="Mauser et al., 2009" startWordPosition="5253" endWordPosition="5256">hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic model for SMT lies in that we adopt topic-based WSI to obtain word senses rather than generic topics and integrate induced word senses into machine translation. Lexical selection Our work is also related to lexical selection in SMT where appropriate target lexical items for source words are selected by a statistical model with context information (Bangalore et al., 2007; Mauser et al., 2009). The reformulated WSD discussed before can also be considered as a lexical selection model. The significant difference from these studies is that we perform lexical selection using automatically induced word senses by the HDP on the source side. 7 Conclusion We have presented a sense-based translation model that integrates word senses into machine translation. We capitalize on the broad-coverage word sense induction system that is built on the nonparametric Bayesian HDP to learn sense clusters for words in the source language. We generate pseudo documents for word tokens in the training/test </context>
</contexts>
<marker>Mauser, Hasan, Ney, 2009</marker>
<rawString>Arne Mauser, Saˇsa Hasan, and Hermann Ney. 2009. Extending Statistical Machine Translation with Discriminative and Trigger-Based Lexicon Models. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 210–218, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<contexts>
<context position="17943" citStr="Och, 2003" startWordPosition="2999" endWordPosition="3000">d events, we can train our multiple classifiers. In practice, we do not build MaxEnt classifiers for source words that occur less than 10 times in the training data and run the MaxEnt toolkit in a parallel manner in order to expedite the training process. 4 Decoding with Sense-Based Translation Model The sense-based translation model described above is integrated into the log-linear translation model of SMT as a sense-based knowledge source. The weight of this model is tuned by the minimum Figure 2: Architecture of SMT system with the sense-based translation model. error rate training (MERT) (Och, 2003) together with other models such as the language model. Figure 2 shows the architecture of the SMT system enhanced with the sense-based translation model. Before we translate a source sentence, we use the HDP-based WSI models trained on the training data to predict senses for word tokens occurring in the source sentence as discussed in Section 2.2. Note that the HDP-based WSI does not predict senses for all words due to the following two reasons. • We do not train HDP-based WSI models for word types for which we extract more than T pseudo documents.2 • In the test/dev set, there are some words</context>
<context position="22828" citStr="Och, 2003" startWordPosition="3797" endWordPosition="3798"> collected training events from the sense-annotated data as described in Section 3.2. We set the Gaussian prior to 1 to avoid overfitting. On average, we obtained 346 classes (target translations) per source word type with the maximum number of classes being 256,243. It took an average of 57.5 seconds for training a Maxent classifier. We used the NIST MT03 evaluation test data as our development set, and the NIST MT05 as the test set. We evaluated translation quality with the case-insensitive BLEU-4 (Papineni et al., 2002) and NIST (Doddington, 2002). In order to alleviate the impact of MERT (Och, 2003) instability, we followed the suggestion of Clark et al. (2011) to run MERT three times and report average BLEU/NIST scores over the three runs for all our experiments. 5.2 Statistics and Examples of Word Senses Before we present our experiment results of the sense-based translation model, we study some statistics of the HDP-based WSI on the training and test data. We show these statistics in Table 2. There are 67,723 and 4,348 unique word types in the training and test data after the preprocessing step. For these word types, we extract 27.73M and 11,777 pseudo documents from the training and </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="22746" citStr="Papineni et al., 2002" startWordPosition="3780" endWordPosition="3783">We performed 100 iterations of the L-BFGS algorithm implemented in the training toolkit on the collected training events from the sense-annotated data as described in Section 3.2. We set the Gaussian prior to 1 to avoid overfitting. On average, we obtained 346 classes (target translations) per source word type with the maximum number of classes being 256,243. It took an average of 57.5 seconds for training a Maxent classifier. We used the NIST MT03 evaluation test data as our development set, and the NIST MT05 as the test set. We evaluated translation quality with the case-insensitive BLEU-4 (Papineni et al., 2002) and NIST (Doddington, 2002). In order to alleviate the impact of MERT (Och, 2003) instability, we followed the suggestion of Clark et al. (2011) to run MERT three times and report average BLEU/NIST scores over the three runs for all our experiments. 5.2 Statistics and Examples of Word Senses Before we present our experiment results of the sense-based translation model, we study some statistics of the HDP-based WSI on the training and test data. We show these statistics in Table 2. There are 67,723 and 4,348 unique word types in the training and test data after the preprocessing step. For thes</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yik-Cheung Tam</author>
<author>Ian R Lane</author>
<author>Tanja Schultz</author>
</authors>
<title>Bilingual LSA-based adaptation for statistical machine translation.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="30999" citStr="Tam et al. (2007)" startWordPosition="5115" endWordPosition="5118">2011) propose HDP-based WSI that is capable of 1466 determining the number of senses for each word type according to training data. Lau et al. (2012) adopt the HDP-based WSI for novel sense detection and empirically show that the HDP-based WSI is better than the LDA-based WSI. We follow them to set the hyperparameters of HDP for training and incorporate automatically induced word senses into SMT in our work. Topic model for SMT Generic topic models are also explored for SMT. Zhao and Xing (2007) propose a bilingual topic model and integrate a topic-specific lexicon translation model into SMT. Tam et al. (2007) also explore a bilingual topic model for translation and language model adaptation. Foster and Kunh (2007) introduce a mixture model approach for translation model adaptation. Xiao et al. (2012) propose a topic-based similarity model for rule selection in hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic model for SMT lies in that we adopt topic-based WSI to obtain word senses rather than generic topics and integrate in</context>
</contexts>
<marker>Tam, Lane, Schultz, 2007</marker>
<rawString>Yik-Cheung Tam, Ian R. Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for statistical machine translation. Machine Translation, 21(4):187–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2004</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>101</volume>
<contexts>
<context position="6137" citStr="Teh et al., 2004" startWordPosition="941" endWordPosition="944">ibes how we integrate the sense-based translation model into SMT. Section 5 elaborates our experiments on the large-scale Chinese-toEnglish translation task. Section 6 introduces related studies and highlights significant differences from them. Finally, we conclude in Section 7 with future directions. 2 WSI-Based Broad-Coverage Sense Tagger In order to obtain word senses for any source words, we build a broad-coverage sense tagger that relies on the nonparametric Bayesian model based word sense induction. We first describe WSI, especially WSI based on the Hierarchical Dirichlet Process (HDP) (Teh et al., 2004), a nonparametric version of Latent Dirichlet Allocation (LDA) (Blei et al., 2003). We then elaborate how we use the HDP-based WSI to predict sense clusters and to annotate source words in our training/development/test sets with these sense clusters. 2.1 Word Sense Induction Before we introduce WSI, we differentiate word type from word token. A word type refers to a unique word as a vocabulary entry while a word token is an occurrence of a word type. Take the first sentence of this paragraph as an example, it has 11 word tokens but 9 word types as there are two word tokens of the word type “we</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2004</marker>
<rawString>Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. 2004. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vickrey</author>
<author>Luke Biewald</author>
<author>Marc Teyssier</author>
<author>Daphne Koller</author>
</authors>
<title>Word-Sense Disambiguation for Machine Translation. In HLT/EMNLP. The Association for Computational Linguistics.</title>
<date>2005</date>
<contexts>
<context position="2481" citStr="Vickrey et al. (2005)" startWordPosition="370" endWordPosition="373"> predicting word senses that are defined on an ontology for ambiguous words. As they apply WSD to Chinese-to-English translation, they predict word senses from a Chinese ontology HowNet and project the predicted senses to English glosses provided by HowNet. These glosses, used as the sense predictions of their WSD system, are integrated into a word-based SMT system either to substitute for translation candidates of their translation model or to postedit the output of their SMT system. They report that WSD degenerates the translation quality of SMT. In contrast to the standard WSD formulation, Vickrey et al. (2005) reformulate the task of WSD for SMT as predicting possible target translations rather than senses for ambiguous source words. They show that such a reformulated WSD can improve the accuracy of a simplified word translation task. Following this WSD reformulation for SMT, Chan et al. (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005). Carpuat and Wu (2007) also use this reformulated WSD and further adapt it to multi-word phrasal disambiguation. They both report that the redefined WSD can significantly improve SMT. Although this reformulated WSD</context>
<context position="28773" citStr="Vickrey et al., 2005" startWordPosition="4746" endWordPosition="4749">or) %*f (railway administration) ri ft (component) 7 (balance) Table 3: Six different senses learned for the word “Lf” from the training data. the sense features used in our model do provide new information that can not be obtained by the lexicon features. 6 Related Work In this section we introduce previous studies that are related to our work. For ease of comparison, we roughly divide them into 4 categories: 1) WSD for SMT, 2) topic-based WSI, 3) topic model for SMT and 4) lexical selection. WSD for SMT As we mentioned in Section 1, WSD has been successfully reformulated and adapted to SMT (Vickrey et al., 2005; Carpuat and Wu, 2007; Chan et al., 2007). Rather than predicting word senses for ambiguous words, the reformulated WSD directly predicts target translations for source words with context information. Our sense-based translation model also predicts target translations for SMT. The significant difference is that we predict word senses automatically learned from data and incorporate these predicted senses into SMT. Our experiments show that such word senses are able to improve translation quality. Topic-based WSI Topic-based WSI can be considered as the foundation of our work as we use it to ob</context>
</contexts>
<marker>Vickrey, Biewald, Teyssier, Koller, 2005</marker>
<rawString>David Vickrey, Luke Biewald, Marc Teyssier, and Daphne Koller. 2005. Word-Sense Disambiguation for Machine Translation. In HLT/EMNLP. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>D M Blei</author>
</authors>
<title>A Split-Merge MCMC Algorithm for the Hierarchical Dirichlet Process. ArXiv e-prints,</title>
<date>2012</date>
<contexts>
<context position="21070" citStr="Wang and Blei, 2012" startWordPosition="3502" endWordPosition="3505">M bilingual sentences, 109.5M English word tokens and 96.9M Chinese word tokens. We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million words) using the SRILM toolkit (Stolcke, 2002) with the modified Kneser-Ney smoothing (Chen and Goodman, 1996). We trained our HDP-based WSI models via the C++ HDP toolkit3 (Wang and Blei, 2012). We set the hyperparameters γ = 0.1 and α0 = 1.0 following Lau et al. (2012).We extracted pseudo documents from a ±10-word window centered on the corresponding word token for each word type following Brody and Lapata (2009). As described in Section 2.2, we preprocessed the source part of our bilingual training data by removing stop words and infrequent words that occurs less than 3http://www.cs.cmu.edu/˜chongw/ resource.html Training Test # Word Types 67,723 4,348 # Total Pseudo Documents 27.73M 11,777 # Avg Pseudo Documents 427.79 2.71 # Total Senses 271,770 24,162 # Avg Senses 4.01 5.56 Tab</context>
</contexts>
<marker>Wang, Blei, 2012</marker>
<rawString>C. Wang and D. M. Blei. 2012. A Split-Merge MCMC Algorithm for the Hierarchical Dirichlet Process. ArXiv e-prints, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="20172" citStr="Wu, 1997" startWordPosition="3368" endWordPosition="3369">n using large-scale bilingual training data. In order to build the proposed sense-based translation model, we annotated the source part of the bilingual training data with word senses induced by the HDPbased WSI. With the trained sense-based translation model, we would like to investigate the following two questions: • Do word senses automatically induced by the HDP-based WSI improve translation quality? • Does the sense-based translation model outperform the reformulated WSD for SMT? 5.1 Setup Our baseline system is a state-of-the-art SMT system which adapts Bracketing Transduction Grammars (Wu, 1997) to phrasal translation and equips itself with a maximum entropy based reordering model (Xiong et al., 2006). We used LDC corpora LDC2004E12, LDC2004T08, LDC2005T10, LDC2003E14, LDC2002E18, LDC2005T06, LDC2003E07, LDC2004T07 as our bilingual training data which consists of 3.84M bilingual sentences, 109.5M English word tokens and 96.9M Chinese word tokens. We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase tabl</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinyan Xiao</author>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>A Topic Similarity Model for Hierarchical Phrase-based Translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>750--758</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="31194" citStr="Xiao et al. (2012)" startWordPosition="5145" endWordPosition="5148">ction and empirically show that the HDP-based WSI is better than the LDA-based WSI. We follow them to set the hyperparameters of HDP for training and incorporate automatically induced word senses into SMT in our work. Topic model for SMT Generic topic models are also explored for SMT. Zhao and Xing (2007) propose a bilingual topic model and integrate a topic-specific lexicon translation model into SMT. Tam et al. (2007) also explore a bilingual topic model for translation and language model adaptation. Foster and Kunh (2007) introduce a mixture model approach for translation model adaptation. Xiao et al. (2012) propose a topic-based similarity model for rule selection in hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic model for SMT lies in that we adopt topic-based WSI to obtain word senses rather than generic topics and integrate induced word senses into machine translation. Lexical selection Our work is also related to lexical selection in SMT where appropriate target lexical items for source words are selected by a statis</context>
</contexts>
<marker>Xiao, Xiong, Zhang, Liu, Lin, 2012</marker>
<rawString>Xinyan Xiao, Deyi Xiong, Min Zhang, Qun Liu, and Shouxun Lin. 2012. A Topic Similarity Model for Hierarchical Phrase-based Translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 750–758, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
</authors>
<title>A Topic-Based Coherence Model for Statistical Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13),</booktitle>
<location>Bellevue, Washington, USA,</location>
<contexts>
<context position="31316" citStr="Xiong and Zhang (2013)" startWordPosition="5163" endWordPosition="5166">ameters of HDP for training and incorporate automatically induced word senses into SMT in our work. Topic model for SMT Generic topic models are also explored for SMT. Zhao and Xing (2007) propose a bilingual topic model and integrate a topic-specific lexicon translation model into SMT. Tam et al. (2007) also explore a bilingual topic model for translation and language model adaptation. Foster and Kunh (2007) introduce a mixture model approach for translation model adaptation. Xiao et al. (2012) propose a topic-based similarity model for rule selection in hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic model for SMT lies in that we adopt topic-based WSI to obtain word senses rather than generic topics and integrate induced word senses into machine translation. Lexical selection Our work is also related to lexical selection in SMT where appropriate target lexical items for source words are selected by a statistical model with context information (Bangalore et al., 2007; Mauser et al., 2009). The reformulated WSD discussed before </context>
</contexts>
<marker>Xiong, Zhang, 2013</marker>
<rawString>Deyi Xiong and Min Zhang. 2013. A Topic-Based Coherence Model for Statistical Machine Translation. In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13), Bellevue, Washington, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>521--528</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="20280" citStr="Xiong et al., 2006" startWordPosition="3383" endWordPosition="3386">n model, we annotated the source part of the bilingual training data with word senses induced by the HDPbased WSI. With the trained sense-based translation model, we would like to investigate the following two questions: • Do word senses automatically induced by the HDP-based WSI improve translation quality? • Does the sense-based translation model outperform the reformulated WSD for SMT? 5.1 Setup Our baseline system is a state-of-the-art SMT system which adapts Bracketing Transduction Grammars (Wu, 1997) to phrasal translation and equips itself with a maximum entropy based reordering model (Xiong et al., 2006). We used LDC corpora LDC2004E12, LDC2004T08, LDC2005T10, LDC2003E14, LDC2002E18, LDC2005T06, LDC2003E07, LDC2004T07 as our bilingual training data which consists of 3.84M bilingual sentences, 109.5M English word tokens and 96.9M Chinese word tokens. We ran Giza++ on the training data in two directions and applied the “grow-diag-final” refinement rule (Koehn et al., 2003) to obtain word alignments. From the word-aligned data, we extracted weighted phrase pairs to generate our phrase table. We trained a 5-gram language model on the Xinhua section of the English Gigaword corpus (306 million word</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 521–528, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuchen Yao</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Nonparametric Bayesian Word Sense Induction.</title>
<date>2011</date>
<booktitle>In Proceedings of TextGraphs-6: Graph-based Methods for Natural Language Processing,</booktitle>
<pages>10--14</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon,</location>
<marker>Yao, Van Durme, 2011</marker>
<rawString>Xuchen Yao and Benjamin Van Durme. 2011. Nonparametric Bayesian Word Sense Induction. In Proceedings of TextGraphs-6: Graph-based Methods for Natural Language Processing, pages 10–14, Portland, Oregon, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Zhao</author>
<author>Eric P Xing</author>
</authors>
<title>HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation.</title>
<date>2007</date>
<booktitle>In Proc. NIPS</booktitle>
<contexts>
<context position="30882" citStr="Zhao and Xing (2007)" startWordPosition="5097" endWordPosition="5100">opic modeling is tens or hundreds. As LDA-based WSI needs to manually specify the number of word senses, Yao and Durme (2011) propose HDP-based WSI that is capable of 1466 determining the number of senses for each word type according to training data. Lau et al. (2012) adopt the HDP-based WSI for novel sense detection and empirically show that the HDP-based WSI is better than the LDA-based WSI. We follow them to set the hyperparameters of HDP for training and incorporate automatically induced word senses into SMT in our work. Topic model for SMT Generic topic models are also explored for SMT. Zhao and Xing (2007) propose a bilingual topic model and integrate a topic-specific lexicon translation model into SMT. Tam et al. (2007) also explore a bilingual topic model for translation and language model adaptation. Foster and Kunh (2007) introduce a mixture model approach for translation model adaptation. Xiao et al. (2012) propose a topic-based similarity model for rule selection in hierarchical phrasebased translation. Xiong and Zhang (2013) employ a sentence-level topic model to capture coherence for document-level machine translation. The difference between our work and these previous studies on topic </context>
</contexts>
<marker>Zhao, Xing, 2007</marker>
<rawString>Bin Zhao and Eric P. Xing. 2007. HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation. In Proc. NIPS 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>