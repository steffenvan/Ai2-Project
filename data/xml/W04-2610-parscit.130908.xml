<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000148">
<title confidence="0.9961065">
Support Vector Machines Applied to the Classification of Semantic Relations
in Nominalized Noun Phrases
</title>
<author confidence="0.935877">
Roxana Girju Ana-Maria Giuglea, Marian Olteanu,
</author>
<affiliation confidence="0.9264606">
Computer Science Department Ovidiu Fortu, Orest Bolohan, and
Baylor University Dan Moldovan
Waco, Texas Department of Computing Science
girju@cs.baylor.edu University of Texas at Dallas
Dallas, Texas
</affiliation>
<email confidence="0.997069">
moldovan@utdallas.edu
</email>
<sectionHeader confidence="0.995622" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999694">
The discovery of semantic relations in text
plays an important role in many NLP appli-
cations. This paper presents a method for the
automatic classification of semantic relations
in nominalized noun phrases. Nominalizations
represent a subclass of NP constructions in
which either the head or the modifier noun is
derived from a verb while the other noun is an
argument of this verb. Especially designed fea-
tures are extracted automatically and used in a
Support Vector Machine learning model. The
paper presents preliminary results for the se-
mantic classification of the most representative
NP patterns using four distinct learning mod-
els.
</bodyText>
<sectionHeader confidence="0.999751" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.999153">
1.1 Problem description
</subsectionHeader>
<bodyText confidence="0.999927260869565">
The automatic identification of semantic relations in text
has become increasingly important in Information Ex-
traction, Question Answering, Summarization, Text Un-
derstanding, and other NLP applications. This paper dis-
cusses the automatic labeling of semantic relations in
nominalized noun phrases (NPs) using a support vector
machines learning algorithm.
Based on the classification provided by the New Web-
ster’s Grammar Guide (Semmelmeyer and Bolander
1992) and our observations of noun phrase patterns on
large text collections, the most frequently occurring NP
level constructions are: (1) Compound Nominals consist-
ing of two consecutive nouns (eg pump drainage - an IN-
STRUMENT relation), (2) Adjective Noun constructions
where the adjectival modifier is derived from a noun (eg
parental refusal - AGENT), (3) Genitives (eg tone of con-
versation - a PROPERTY relation), (4) Adjective phrases
in which the modifier noun is expressed by a preposi-
tional phrase which functions as an adjective (eg amuse-
ment in the park - a LOCATION relation), and (5) Adjec-
tive clauses where the head noun is modified by a relative
clause (eg the man who was driving the car - an AGENT
relation between man and driving).
</bodyText>
<sectionHeader confidence="0.8268885" genericHeader="introduction">
1.2 Previous work on the discovery of semantic
relations
</sectionHeader>
<bodyText confidence="0.9999426">
The development of large semantically annotated cor-
pora, such as Penn Treebank2 and, more recently, Prop-
Bank (Kingsbury, et al. 2002), as well as semantic
knowledge bases, such as FrameNet (Baker, Fillmore,
and Lowe 1998), have stimulated a high interest in the
automatic acquisition of semantic relations, and espe-
cially of semantic roles. In the last few years, many re-
searchers (Blaheta and Charniak 2000), (Gildea and Ju-
rafsky 2002), (Gildea and Palmer 2002), (Pradhan et
al. 2003) have focused on the automatic prediction of se-
mantic roles using statistical techniques. These statistical
techniques operate on the output of probabilistic parsers
and take advantage of the characteristic features of the
semantic roles that are then employed in a learning algo-
rithm.
While these systems focus on verb-argument semantic
relations, called semantic roles, in this paper we inves-
tigate predicate-argument semantic relations in nominal-
ized noun phrases and present a method for their auto-
matic detection in open-text.
</bodyText>
<subsectionHeader confidence="0.939168">
1.3 Approach
</subsectionHeader>
<bodyText confidence="0.999913888888889">
We approach the problem top-down, namely identify and
study first the characteristics or feature vectors of each
noun phrase linguistic pattern and then develop models
for their semantic classification. The distribution of the
semantic relations is studied across different NP patterns
and the similarities and differences among resulting se-
mantic spaces are analyzed. A thorough understanding
of the syntactic and semantic characteristics of NPs pro-
vides valuable insights into defining the most representa-
tive feature vectors that ultimately drive the discriminat-
ing learning models.
An important characteristic of this work is that it re-
lies heavily on state-of-the-art natural language process-
ing and machine learning methods. Prior to the discovery
of semantic relations, the text is syntactically parsed with
Charniak’s parser (Charniak 2001) and words are seman-
tically disambiguated and mapped into their appropriate
WordNet senses. The word sense disambiguation is done
manually for training and automatically for testing with
a state-of-the-art WSD module, an improved version of
a system with which we have participated successfully
in Senseval 2 and which has an accuracy of 81% when
disambiguating nouns in open-domain. The discovery of
semantic relations is based on learning lexical, syntactic,
semantic and contextual constraints that effectively iden-
tify the most probable relation for each NP construction
considered.
</bodyText>
<sectionHeader confidence="0.736551" genericHeader="method">
2 Semantic Relations in Nominalized Noun
Phrases
</sectionHeader>
<bodyText confidence="0.9958188">
In this paper we study the behavior of semantic relations
at the noun phrase level when one of the nouns is nom-
inalized. The following NP level constructions are con-
sidered: complex nominals, genitives, adjective phrases,
and adjective clauses.
</bodyText>
<subsectionHeader confidence="0.655074">
Complex Nominals
</subsectionHeader>
<bodyText confidence="0.999956692307692">
Levi (Levi 1979) defines complex nominals (CNs) as ex-
pressions that have a head noun preceded by one or more
modifying nouns, or by adjectives derived from nouns
(usually called denominal adjectives). Each sequence of
nouns, or possibly adjectives and nouns, has a particular
meaning as a whole carrying an implicit semantic rela-
tion; for example, “parental refusal” (AGENT).
The main tasks are the recognition, and the interpre-
tation of complex nominals. The recognition task deals
with the identification of CN constructions in text, while
the interpretation of CNs focuses on the detection and
classification of a comprehensive set of semantic rela-
tions between the noun constituents.
</bodyText>
<subsectionHeader confidence="0.825327">
Genitives
</subsectionHeader>
<bodyText confidence="0.99969528125">
In English there are two kinds of genitives; in one, the
modifier is morphologically linked to the possessive clitic
’s and precedes the head noun (s-genitive e.g. “John’s
conclusion”), and in the second one the modifier is syn-
tactically marked by the preposition of and follows the
head noun (of-genitive, e.g. “declaration of indepen-
dence”).
Adjective Phrases are prepositional phrases attached to
nouns and act as adjectives (cf. (Semmelmeyer and
Bolander 1992)). Prepositions play an important role
both syntactically and semantically ( (Dorr 1997). Prepo-
sitional constructions can encode various semantic re-
lations, their interpretations being provided most of the
time by the underlying context. For instance, the preposi-
tion “with” can encode different semantic relations: (1) It
was the girl with blue eyes (MERONYMY), (2) The baby
with the red ribbon is cute (POSSESSION), (3) The woman
with triplets received a lot of attention (KINSHIP).
The conclusion for us is that in addition to the nouns se-
mantic classes, the preposition and the context play im-
portant roles here.
Adjective Clauses are subordinate clauses attached to
nouns (cf. (Semmelmeyer and Bolander 1992)). Often
they are introduced by a relative pronoun/adverb (ie that,
which, who, whom, whose, where) as in the following ex-
amples: (1) Here is the book which I am reading (book
is the THEME of reading) (2) The man who was driving
the car was a spy (man is the AGENT of driving). Adjec-
tive clauses are inherently verb-argument structures, thus
their interpretation consists of detecting the semantic role
between the head noun and the main verb in the relative
clause. This is addressed below.
</bodyText>
<sectionHeader confidence="0.9728825" genericHeader="method">
3 Nominalizations and Mapping of NPs
into Grammatical Role Structures
</sectionHeader>
<subsectionHeader confidence="0.999271">
3.1 Nominalizations
</subsectionHeader>
<bodyText confidence="0.999889243243243">
A further analysis of various examples of noun - noun
pairs encoded by the first three major types of NP-level
constructions shows the need for a different taxonomy
based on the syntactic and grammatical roles the con-
stituents have in relation to each other. The criterion in
this classification splits the noun - noun examples (re-
spectively, adjective - noun examples in complex nom-
inals) into nominalizations and non-nominalizations.
Nominalizations represent a particular subclass of NP
constructions that in general have “a systematic corre-
spondence with a clause structure” (Quirk et al.1985).
The head or modifier noun is derived from a verb while
the other noun (the modifier, or respectively, the head) is
interpreted as an argument of this verb. For example, the
noun phrase “car owner” corresponds to “he owns a car”.
The head noun owner is morphologically related to the
verb own. Otherwise said, the interpretation of this class
of NPs is reduced to the automatic detection and inter-
pretation of semantic roles mapped on the corresponding
verb-argument structure.
As in (Hull and Gomez 1996), in this paper we use
the term nominalization to refer only to those senses of
the nominalized nouns which are derived from verbs.
For example, the noun “decoration” has three senses in
WordNet 2.0: an ornament (#1), a medal (#2), and the act
of decorating (#3). Only the last sense is a nominaliza-
tion. However, there are more complex situations when
the underlying verb has more than one sense that refers to
an action/event. This is the case of “examination” which
has five senses of which four are action-related. In this
case, the selection of the correct sense is provided by the
context.
We are interested in answering the following ques-
tions: (1) What is the best set offeatures that can capture
the meaning ofnoun - noun nominalization pairs for each
NP-level construction? and (2) What is the semantic be-
havior of nominalization constructions across NP levels?
</bodyText>
<subsectionHeader confidence="0.999817">
3.2 Taxonomy of nominalizations
</subsectionHeader>
<bodyText confidence="0.992049647058823">
Deverbal vs verbal noun.
(Quirk et al.1985) generally classify nominalizations
based on the morphological formation of the nominal-
ized noun. They distinguish between deverbal nouns, i.e.
those derived from the underlying verb through word for-
mation; e.g., “student examination”, and verbal nouns,
i.e. those derived from the verb by adding the gerund
suffix “-ing”; e.g.: “cleaning woman”. Most of the time,
verbal nouns are derived from verbs which don’t have a
deverbal correspondent.
Table 1 shows the mapping of the first three major syn-
tactic NP constructions to the grammatical role level. By
analyzing a large corpus, we have observed that Quirk’s
grammatical roles shown in Table 1 are not uniformly dis-
tributed over the types of NP-constructions. For example,
the “ ” pattern cannot be encoded
by s-genitives (e.g., “language teacher”, “teacher of lan-
guage”).
Some of the non-nominalization NP constructions can
also capture the arguments of a particular verb that is
missing (e.g., subject - object, subject - complement).
The “General” subclass refers to all other types of noun
- noun constructions that cannot be mapped on verb-
argument relations (e.g., “hundreds of dollars”). Adjec-
tive clauses are not part of Table 1 as they describe by
default verb-argument relations (semantic roles). Thus
they cannot be classified as nominalizations or non-
nominalizations.
Two other useful classifications for nominalizations
are: paraphrased vs. non-paraphrased, and the clas-
sification according to the nominalized noun’s verb-
argument underlying structures as provided by the Nom-
Lex dictionary of English nominalizations (Macleod et al.
1998) discussed more later.
</bodyText>
<subsectionHeader confidence="0.750532">
Paraphrased vs non-Paraphrased.
</subsectionHeader>
<bodyText confidence="0.999830176470588">
In most cases, the relation between the nominalized noun
and the other noun argument can be captured from the
subcategorization properties of the underlying verb. Oth-
erwise said, most of the time, there is a systematic cor-
respondence between the nominalized NP construction
and the predicate-argument structure of the correspond-
ing verb in a clausal paraphrase (paraphrased nominal-
ization). The predicate-argument structure can be cap-
tured by three grammatical roles: verb-subject, verb-
object, and verb-complement. We call the arguments of
the verb that appear more frequently or are obligatory
- frame arguments. From this point of view the non-
nominalized noun can be mapped on the verb-argument
frame or not. Thus we can classify paraphrased nom-
inalizations in framed and non-framed according to the
presence or absence of the non-nominalized noun in the
frame of the verb. The semantic classification of nom-
inalizations involves first the detection of a nominaliza-
tion, the selection of the correct sense of the root verb,
and finally the detection of the semantic relationship with
the other noun.
Besides the paraphrase nominalization, there is an-
other type which occurs less frequently. We call this type
non-paraphrased nominalization as its meaning is differ-
ent from its most related paraphrase clause. Examples:
research budget, design contract, preparation booklet,
publishing sub-industry and editing error. An important
observation is that the nominalized noun occurs most of
the time on the first position in an NP construction.
The criteria presented here consider also nominaliza-
tions with adjectival modifiers such as “parental refusal”.
These adjectives are derived from nouns, so the con-
struction is just a special case of nominalization between
nouns.
</bodyText>
<subsectionHeader confidence="0.720654">
NomLex classification
</subsectionHeader>
<bodyText confidence="0.996179666666667">
The NomLex dictionary of nominalizations (Macleod et
al. 1998) contains 1025 lexical entries and lists the verbs
from which the nouns are derived. This dictionary spec-
ifies the complements allowed for a nominalization. The
mapping is done at a syntactic level only. NomLex is
used in the first phase of our algorithm in order to de-
tect a possible nominalization and the corresponding root
verb. The criterion of NomLex classification is based on
the verb-argument correspondence:
</bodyText>
<listItem confidence="0.99176975">
a. Verb-nom: The nominalized noun represents the ac-
tion/state of the verb (e.g., “acquisition challenge”, “de-
positary receipt)”,
b. Subj-nom: The nominalized noun refers to the sub-
ject of the verb (e.g., “auto maker”, “math teacher”).
This type is also called agential nominalization (Quirk
et al.1985) as the nominalized noun captures information
about both the subject and verb.
c. Obj-nom: The nominalized noun refers to the object of
the verb (e.g., “court order”, “company employee”),
d. Verb-part: the nominalized noun is derived from a
compositional verb (e.g., “takeover target”).
</listItem>
<subsectionHeader confidence="0.8601695">
3.3 Corpus Analysis at NP level
The data
</subsectionHeader>
<bodyText confidence="0.994132">
We have assembled a corpus from the Wall Street Journal
articles from TREC-9. Table 2 shows for each syntactic
</bodyText>
<table confidence="0.9998135625">
Syntactic Patterns Grammatical CNs Genitives Adjective Example
Roles Phrase
N N Adj-N ’s of
Nominalization Deverbal “heart massage”
noun
“language teacher”
“smallpox vaccination”
“boy’s application”
Verbal “cleaning woman”
noun
“spending money”
“carving knife”
“horse riding”
Non-nominalization “wind mill”
“pine tree”
General “hundreds of dollars”
</table>
<tableCaption confidence="0.999551">
Table 1: Classification of noun phrase constructions on the types of grammatical roles (cf. (Quirk et al.1985)) needed
</tableCaption>
<bodyText confidence="0.894675444444444">
for semantic roles detection. The classification is the result of our observations of nominalization patterns at noun
phrase level.
category the number of randomly selected sentences, the
number of instances found in these sentences, and finally
the number of nominalized instances our group managed
to annotate by hand. The annotation of each example
consisted of specifying its feature vector and the most ap-
propriate semantic relation as defined in (Moldovan et al.
2004).
</bodyText>
<sectionHeader confidence="0.572612" genericHeader="method">
Inter-annotator Agreement
</sectionHeader>
<bodyText confidence="0.999658076923077">
The annotators, four PhD students in Computational Se-
mantics worked in groups of two, each group focusing on
one half of the corpus to annotate. Besides the type of
relation, the annotators were asked to provide informa-
tion about the order of the modifier and the head nouns
in the syntactic constructions if applicable. For example,
“owner of the car” and “car of the owner”.
The annotators were also asked to indicate if the in-
stance was a nominalization and if yes, which of the
noun constituents was derived from a verb (e.g. the head
noun nominalization “student protest”, or the modifier
noun nominalization “working woman’” cf. (Quirk et
al.1985)).
The annotators’ agreement was measured using the
Kappa statistics (Siegel and Castellan 1988), one of the
most frequently used measure of inter-annotator agree-
ment for classification tasks: , where
is the proportion of times the raters agree and
is the probability of agreement by chance. The
K coefficient is 1 if there is a total agreement among the
annotators, and 0 if there is no agreement other than that
expected to occur by chance.
For each construction, the corpus was split after agree-
ment with an 80/20 training/testing ratio. For each pat-
tern, we computed the K coefficient only for those in-
stances tagged with one of the 35 semantic relations (K
value for: NN (0.64), AdjN (0.70), s-genitive (0.69), of-
genitive (0.73), adjective phrases (0.67), and adjective
clauses (0.71)). For each pattern, we also calculated the
number of pairs that were tagged with OTHERS by both
annotators, over the number of examples classified in this
category by at least one of the judges, averaged by the
number of patterns considered (agreement for OTHERS:
75%).
The K coefficient shows a good level of agreement for
the training and testing data on the set of 35 relations, tak-
ing into consideration the task difficulty. This can be ex-
plained by the instructions the annotators received prior
to annotation and by their expertise in lexical semantics.
</bodyText>
<subsectionHeader confidence="0.997757">
3.4 Distribution of Semantic Relations
</subsectionHeader>
<bodyText confidence="0.997140793103448">
Even noun phrase constructions are very productive al-
lowing for a large number of possible interpretations, Ta-
ble 3 shows that a relatively small set of 35 semantic re-
lations covers a significant part of the semantic distribu-
tion of these constructions on a large open-domain cor-
pus. Moreover, the distribution of these relations is de-
pendent on the type of NP construction, each type en-
coding a particular subset. For example, in the case of
s-genitives, there were 13 relations found from the total
of 35 relations considered. The most frequently occur-
ring relations were AGENT, TEMPORAL, LOCATION, and
THEME. By comparing the subsets of semantic relations
in each column we can notice that these semantic spaces
(the set of semantic relations an NP construction can en-
code) are not identical, proving our initial intuition that
the NP constructions cannot be alternative ways of pack-
ing the same information. Table 3 also shows that there is
a subset of semantic relations that can be fully encoded by
all types of NP constructions. The statistics about the an-
notated nominalized examples are as follows (lines 3 and
4 in Table 2): N-N (32.30%), Adj-N (30.80%), s-genitive
(21.09%), of-genitive (21.8%), adjective phrase (40.5%).
80% of the examples in adjective phrases (respectively in
94% in s-genitives) had the nominalized noun on the head
position.
This simple analysis leads to the important conclusion
that the NP constructions must be treated separately as
their semantic content is different. We can draw from
here the following conclusions:
</bodyText>
<listItem confidence="0.641331">
1. Not all semantic relations can be encoded by all NP
</listItem>
<table confidence="0.998315">
Wall Street Journal
CNs Genitives Adjective Adjective
Phrases Clauses
NN AdjN ’s of
No. of sentences 7067 5381 50291 27067 14582 31568
No. of instances 5557 500 2990 4185 3502 6520 2
No. of annotated instances 2315 383 1816 3404 1341 563
No. of annotated nominalized instances 747 118 383 742 543 563
No. of annotated nominalized instances used in the learning task 312 118 383 344 297 563
</table>
<tableCaption confidence="0.998612">
Table 2: Corpus statistics.
</tableCaption>
<bodyText confidence="0.652312">
syntactic constructions.
</bodyText>
<listItem confidence="0.919868">
2. There are semantic relations that have preferences over
particular syntactic constructions.
</listItem>
<subsectionHeader confidence="0.8988245">
3.5 Model
3.6 Support Vector Machines
</subsectionHeader>
<bodyText confidence="0.996203961538462">
Support Vector Machines (SVM) have a strong mathe-
matical foundation (Vapnik 1982) and have been applied
successfully to text classification (Tong and Koller 2001),
speech recognition, and other applications. We applied
SVM to the semantic classification problem and obtained
encouraging results.
SVM algorithms are a special class of hyperplane
classifiers that use the information encoded in the dot-
products of the transformed feature vectors as a simi-
larity measure. The similarity between two instances
and is given as a function ,
. The Kernel function is the
inner product of the non-linear function that
maps the original feature vectors into real feature space.
The function that provides the best classification is of
the form: . The vec-
tors for which the Lagrange multipliers are
called support vectors. Intuitively, they are the closest to
the separating hyperplane. SVM provide good classifiers
with few, well chosen training examples.
In order to achieve classification in classes, ,
a binary classifier is built for each pair of classes (a total
of classifiers). A voting procedure is then used to es-
tablish the class of a new example. For the experiments
with semantic relations, the simplest voting scheme has
been chosen; each binary classifier has one vote which is
assigned to the class it chooses when it is run. Then the
class with the largest number of votes is considered to be
the answer. Using the specific nature of the semantic re-
lation detection problem, new voting schemes can be de-
signed, with good perspectives of improving the overall
precision.
The software used in these experiments is the pack-
age LIBSVM, http://www.csie.ntu.edu.tw/ cjlin/libsvm/
which implements the SVM algorithm described above.
The choice of the kernel is the most difficult part of
applying SVM algorithms as the performance of the clas-
sifier might be enhanced with a judicious choice of the
kernel. We used in our experiments 4 types of general
kernels (linear, polynomial, radial-based and sigmoid),
with good results. All of them had nearly the same per-
formance, with slight deviations between 2% and 4% on
a reduced testing set. However, remarkable is the fact
that all classifiers, regardless of the kernel used, made the
same mistakes (misclassified the same examples - eg, a
classifier with 58% precision makes the same mistakes as
one with 62% precision, plus some of its own, and this
situation occurred even when the two classifiers had dif-
ferent kernels), while the overall precision seems to be
around to the same value during the coefficient tuning.
This shows that the limitation is rather imposed by the
classification task than by the kernel type.
</bodyText>
<subsectionHeader confidence="0.991796">
3.7 Feature space
</subsectionHeader>
<bodyText confidence="0.999943533333333">
The key to a successful semantic classification of NP con-
structions is the identification of their most specific lexi-
cal, syntactic, semantic and contextual features. We de-
veloped algorithms for finding their values automatically.
The values of these features are determined with the help
of some important resources mentioned below.
ComLex (Grishman et al.1994) is a computational lexi-
con providing syntactic information for more than 38,000
English headwords. It contains detailed syntactic infor-
mation about the attributes of each lexical item and the
subcategorization frames when words have arguments.
This last feature is the most useful for our task as the
senses of verbs are clustered by the syntactic frames. We
will use ComLex in combination with VerbLeX to map
the syntactic behaviors to verb semantic classes.
VerbLeX is an in-house verb lexicon built by enrich-
ing VerbNet (Kipper et al. 2000) with verb synsets
from WordNet and verbs extracted from the semantic
frames of FrameNet. It contains information about the
semantic roles that can appear within a class of verbs to-
gether with the selectional restrictions for their lexical re-
alizations, syntactic subcategorization and WordNet verb
senses. The syntactic information is less detailed than
in ComLex, but a mapping between these two resources
will provide both the semantic and syntactic information
needed for the task. From the total of 13,213 verbs in
the extended VerbNet, 6,077 were distinct. It also pro-
vides a mapping from the FrameNet deep semantic roles
to general thematic roles (list defined in (Moldovan et al.
2004)), and use cases for VerbNet.
</bodyText>
<table confidence="0.999920761904762">
No. Semantic Frequency Examples
Relations
CNs Genitives Adjective Adjective
Phrases Clauses
NN AdjN ’s of
1 POSSESSION 0.46 1.16 1.06 0.37 0 0.23 “stock holders”
2 KINSHIP 0 0 0 0 0 0
3 ATTRIBUTE-HOLDER 1.37 6.97 1.41 8.24 1.82 0 “intensity of intervention”
4 AGENT 15.13 23.25 33.68 1.87 11.41 25.81 “trading companies”
5 TEMPORAL 0.92 0 26.24 1.50 11.87 6.27 “date ofpurchase”
6 DEPICTION-DEPICTED 0 0 0 0.75 0 0 “evidence of cheating”
7 PART-WHOLE 0 8.13 1.41 3.37 1.82 0 “world consumer”
8 IS-A (HYPERNYMY) 0 0 0 0 0 0
9 ENTAIL 0 0 0 0 0 0
10 CAUSE 0.46 0 0.35 1.12 0.91 0 “fire destruction”
11 MAKE/PRODUCE 0 3.48 0.35 3.00 0.91 0 “computer’s maker”
12 INSTRUMENT 0 0 0 0.75 0.45 0.46 “oven cooking”
13 LOCATION/SPACE 2.75 16.27 3.19 0.75 8.67 4.65 “meeting in Philadelphia”
14 PURPOSE 10.09 3.48 0 1.50 5.93 0 “research budget”
15 SOURCE 0 13.95 0 0.37 3.19 0.46 “Japanese buyer”
16 TOPIC 24.77 3.48 0 9.73 5.02 6.51 “price discussion”
17 MANNER 4.13 0 0 0 1.37 2.32 “shock reaction”
18 MEANS 0 0 0 0 0 0
19 ACCOMPANIMENT 0 0 0 0 0 0
20 EXPERIENCER 0 1.16 0.35 0 1.37 2.79 “riskfor the investor”
21 RECIPIENT 0 0 0.35 0.37 0.45 0.23 “ovations for the champions”
22 FREQUENCY 0 8.13 0 0 0 0 “daily jogging”
23 INFLUENCE 0 0 0 0 0 0
24 ASSOCIATED WITH 0 1.16 0.71 1.12 1.82 0 “designer’s attorney”
25 MEASURE 0 0 0 5.24 0.45 0 “5-mile running”
26 SYNONYMY 0 0 0 0 0 0
27 ANTONYMY 0 0 0 0 0 0
28 PROBABILITY 0 0 0 0 0 0.46 “chance that he is single”
29 POSSIBILITY 0 0 0 0 0 0
30 CERTAINTY 0 0 0 0 0 0
31 THEME 25.22 4.65 22.34 43.82 32.87 38.14 “use ofcards”
32 RESULT 5.04 0 0.35 3.00 0.45 1.62 “ship construction”
33 STIMULUS 0 0 0 0 0 2.32 “the beautiful painting he saw”
34 EXTENT 0 0 0 0 0 0
35 PREDICATE 0.46 0 0 0 0.45 0.70 “sun king, as Louis XVI is called”
OTHERS 4.58 4.65 8.15 13.11 8.67 6.98 “editing error”
Total no. of examples 100 (218) 100 (86) 100 (282) 100 (267) 100 (219) 100 (430)
</table>
<tableCaption confidence="0.998306">
Table 3: The distribution of the semantic relations on the annotated corpus after agreement. The list of 35 semantic
</tableCaption>
<bodyText confidence="0.980376928571429">
relations was presented in (Moldovan et al. 2004). The percentages represent the number of examples that encode a
semantic relation for a particular pattern. The last row shows the number of examples covered by each pattern in the
entire annotated corpus (1502 pairs).
An essential aspect of our approach below is the
word sense disambiguation (WSD) of the content words
(nouns, verbs, adjectives and adverbs). Using a state-
of-the-art open-text WSD system, each word is mapped
into its corresponding WordNet 2.0 sense. When dis-
ambiguating each word, the WSD algorithm takes into
account the surrounding words, and this is one important
way through which context gets to play a role in the se-
mantic classification of NPs.
So far, we have identified and experimented with the
following NP features:
</bodyText>
<listItem confidence="0.75906">
1. Semantic class of the
</listItem>
<bodyText confidence="0.9962232">
non-nominalized noun. The non-nominalized
noun is classified into one of the 39 EuroWordNet noun
semantic classes. VerbNet classes extended in VerbLeX
contain selectional restrictions for different semantic
roles inside the verb frame. These restrictions are pro-
vided based on the EuroWordNet noun semantic classes.
Example: “computer maker”, where “computer” is
mapped to the ABSTRACT noun category in EuroWord-
Net. We intend to map the EuroWordNet top noun
semantic classes into their WordNet correspondents.
</bodyText>
<listItem confidence="0.924585583333334">
2. Verb class for nominalized noun,
or verb in adjective clauses maps the
nominalizing verb into its VerbLeX class. The intuition
behind this feature is that semantic relations cluster
around specific VerbLeX verb classes.
3. Type of nominalization indicates the
NomLex nominalization class. For this experiment
we considered only examples that could be found
in NomLex. By specifying subj-nom, obj-nom, and
verb-nom types of nominalization, we reduce the list of
possible semantic relations the verb can have with the
non-nominalized noun. Example: “computer maker”,
</listItem>
<bodyText confidence="0.8947985">
where “maker” is an agential deverbal noun that captures
both the subject (respectively, AGENT) and the verb.
Thus, the noun “computer” can only map to object
(respectively, THEME).
</bodyText>
<listItem confidence="0.437480714285714">
4. Verbal nominalization is a binary feature
indicating whether the nominalized noun is gerundive or
not. Chomsky (Chomsky 1970) showed that gerundive
nominalizations have different behavior than derived
nominalizations. Example: ”woman worker” vs “work-
ing woman”; here “working” is a verbal nominal.
5. Semantic class of the
</listItem>
<bodyText confidence="0.988298297297297">
coordinating word. This is a contextual fea-
ture and can be either a noun (if the phrase that contains
the nominalization is attached to a noun) or a verb (if
the phrase is an argument of the verb in the sentence).
The feature value is either the VerbLeX class of the verb
or the root of the noun in the WordNet hierarchy. The
coordinating word captures some properties present in
the noun phrase, properties that help to discriminate
between various competing semantic relations. Example:
“Foreigners complain that they have limited access to
[government procurement] in Japan.” -the coordinating
word is “access” which is a psychological feature.
6. Position of the nominalized noun
depicts the position of the nominalizing verb in the com-
pound; ie, either head or modifier. Example: “working
woman”, where the nominalized noun is the modifier,
and “computer maker” where the nominalized noun is
the head noun.
7. In frame is a three-value feature indicating
whether the compound has a paraphrase or if the peer
in the compound is framed or not. If the peer in the
NP noun-noun pair is in the corresponding VerbLeX
predicate-argument frame, than the relation is captured
in the predicate-argument structure. If it is not in the
VerbLeX frame, but is an external argument (eg, LOCA-
TION, TEMPORAL, MANNER, etc.), then it is no-frame.
Otherwise, there is no paraphrase that keeps the meaning,
so the relation is not defined by the predicate-argument
frame. Example: “computer maker” is framed where
as “backyard composting” is non-framed, and “editing
error” is no-paraphrase (has no paraphrase of type
verb-argument).
8. Relative pronoun/adverb applies only
to adjective clauses and embeds information about the
grammatical and/or semantic role of the head noun in
the subordinate clause. Example: “the room where the
meeting took place” - the word where implies location.
</bodyText>
<sectionHeader confidence="0.718997" genericHeader="method">
9. Grammatical role of relative
</sectionHeader>
<bodyText confidence="0.998485952380953">
pronoun/adverb applies only to adjective clauses
and specifies the grammatical role of the relative pro-
noun/adverb, if one exists. This feature depicts better
the grammatical role played in the sentence by the head
noun. We used for this purpose an in-house rule-based
grammatical role detection module, which annotates the
following roles (cf. (Quirk et al.1985): subject, direct
object, indirect object, subject complement (argument
for copular verbs), object complement (second argument
for complex transitive verbs), object oblique, free pred-
icative, and approximates extent and temporal semantic
roles. Example: “the man who gave Mary the book” -
Mary and the book are indirect object and, respectively
direct object, so man cannot be THEME or RECIPIENT.
10. Voice. This feature applies only to adjective
clauses and indicates the voice of the verb in the relative
clause. The voice plays an important role in the correla-
tion between grammatical roles and semantic roles in a
sentence. Example: “the child that was taken to the zoo”
- passive voice, so the child is in a THEME relation with
the verb take.
Let’s consider an example of nominalization with its
features.
“Several candidates have withdrawn their names from
consideration after administration officials asked them
for their views on abortion and fetal-tissue transplants.”
The noun compound “fetal-tissue#1 transplant#1” is
detected as a nominalization as the noun “transplant” is
derived from the verb “to transplant#3”. The features and
their values are: Feature 1: semantic class for fetal-tissue:
body-part; Feature 2: verb class for transplant: fill-9.8;
Feature 3: type of nominalization: verb-nom; Feature 4:
gerundive: no (0); Feature 5: semantic class for coordi-
nating word (“view”) = psychological feature#1; Feature
6: position of the nominalized noun = second; Feature 7:
in frame = yes.
The in-house extended verb lexicon VerbLeX shows
the following semantic frame for the verb class fill-
9.8: Agent[+animate] Destination[+location -region]
Theme[+concrete] Body-part is a subcategory of con-
crete. Thus, for this example the semantic relation is
THEME.
</bodyText>
<sectionHeader confidence="0.98638" genericHeader="conclusions">
4 Overview of Results
</sectionHeader>
<bodyText confidence="0.99923485">
The f-measure results obtained so far are summarized in
Table 4. They are divided in two categories, nominaliza-
tions, and adjective clauses since the feature vectors differ
from one category to another. We have compared the per-
formance of SVM with three other learning algorithms:
(1) semantic scattering (Moldovan et al. 2004), (2) deci-
sion trees (a C4.5 implementation), and (3) Naive Bayes.
We considered as baseline semantic scattering which is
a new learning model (Moldovan et al. 2004) devel-
oped in-house for the semantic classification of noun-
noun pairs in NP constructions. The semantic relation
derives from the WordNet semantic classes of the two
nouns participating in those constructions, as well as the
surrounding context provided by the WSD module.
As expected, the results vary from pattern to pattern.
SVM and Naive Bayes seem to perform better than other
models for the nominalizations and adjective clauses.
Overall, these results are very encouraging given the
complexity of the problem. By comparison with the base-
line, the feature vector presented here gives better results.
</bodyText>
<table confidence="0.998885666666667">
Syntactic Semantic Scattering Decision Naive Support Vector
Pattern (Baseline) Tree Bayes Machines
Complex NN
Nominals
AdjN NA NA NA
Genitives ’S
Of
Adjective Phrases
Adjective Clauses NA
</table>
<tableCaption confidence="0.9914575">
Table 4: F-measure results for the semantic classification of NP patterns obtained with four learning models on a
corpora with an 80/20 training/testing ratio. “NA” means not available.
Table 5: The impact of each feature on the overall performance; H-high (over 8%), M-medium(between 2% and
8%), and L-low (below 2%). Empty boxes indicate the absence of features.
</tableCaption>
<figure confidence="0.994552125">
Nominalized
Adjective Clauses
f1 f2 f3
f4 f5 f6 f7 f8 f9 f10
H M M
M L H H
M H
H L H
</figure>
<bodyText confidence="0.99955275">
This explains in part our initial intuition that nominaliza-
tion constructions at NP level have a different semantic
behavior than the NP non-nominalization patterns.
We studied the influence of each feature on the per-
formance, and since there are too many cases to discuss
we only show in Table 5 the average impact as High,
Medium, or Low. This table also shows the features used
in each case.
</bodyText>
<sectionHeader confidence="0.999251" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999939677966101">
C. Baker, C. Fillmore, and J. Lowe. 1998. The Berkeley
FrameNet Project. In Proceedings of COLLING/ACL.
D. Blaheta and E. Charniak. 2000. Assigning function
tags to parsed text. In Proceedings of the NAACL.
E. Charniak. 2001. Immediate-head parsing for language
models. In Proceedings ofACL, Toulouse, France.
N. Chomsky. 1970. Remarks on Nominalization. In
Readings in English Transformational Grammar. Ja-
cobs, R. A., and Rosenbaum, P.S. (eds), Ginn and
Company.
B. Dorr. 1997. Large-scale dictionary construction for
foreign language tutoring and interlingual machine
translation. In Machine Translation, 12(4).
D. Gildea and D. Jurafsky. 2002. Automatic Labeling of
Semantic Roles. In Computational Linguistics, 28(3).
D. Gildea and M. Palmer. 2002. The Necessity of Parsing
for Predicate Argument Recognition. In ACL.
R. Grishman, C. Macleod, and A. Meyers. 1994. Comlex
syntax: Building a computational lexicon. In Proceed-
ings of COLING, Kyoto, Japan.
R. Hull and F. Gomez. 1996. Semantic interpretation of
nominalizations. In AAAI conference, Oregon.
K. Kipper, H. T. Dang, and M. Palmer. 2000. Class-based
construction of a verb lexicon. In AAAI, Austin, Texas.
P. Kingsbury, M. Palmer, and M. Marcus. 2002. Adding
Semantic Annotation to the Penn TreeBank. In Pro-
ceedings ofHLT, California.
P. Kingsbury and M. Palmer. 2002. From Treebank to
Propbank. In Third International Conference on Lan-
guage Resources and Evaluation, LREC-02, Las Pal-
mas, Canary Islands.
Judith Levi. 1979. The Syntax and Semantics of Com-
plex Nominals. New York: Academic Press.
C. Macleod, R. Grishman, A. Meyers, L. Barrett, and R.
Reeves. 1998. Nomlex: A lexicon of nominalizations.
In Proceedings of the 8th International Congress of the
European Association for Lexicography, Belgium.
D. Moldovan, A. Badulescu, M. Tatu, D. Antohe,
and R. Girju. 2004. Semantic Classification of
Non-nominalized Noun Phrases. In Proceedings of
HLT/NAACL 2004 - Computational Lexical Semantics
workshop, Boston, MA.
S. Pradhan, K. Hacioglu, V. Krugler, W. Ward, J. Mar-
tin, and D. Jurafsky. 2003. Semantic role parsing:
Adding semantic structure to unstructured text. In
ICDM, Florida.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985.
A comprehensive grammar of English language, Long-
man, Harlow.
S. Siegel and N.J. Castellan. 1988. Non Paramet-
ric Statistics for the behavioral science. New York:
McGraw-Hill.
M. Semmelmeyer and D. Bolander. 1992. The New Web-
ster’s Grammar Guide. Lexicon Publications, Inc.
S. Tong and D. Koller. 2001. Support Vector Machine
Active Learning with Applications to Text Classifica-
tion. In Journal ofMachine Learning Research.
V. Vapnik. 1982. Estimation of Dependences Based on
Empirical Data. In Springer Verlag.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.328612">
<title confidence="0.9964045">Support Vector Machines Applied to the Classification of Semantic Relations in Nominalized Noun Phrases</title>
<author confidence="0.982529">Roxana Ana-Maria Giuglea</author>
<author confidence="0.982529">Marian</author>
<affiliation confidence="0.583053">Computer Science Fortu, Orest</affiliation>
<author confidence="0.854152">Baylor Dan</author>
<affiliation confidence="0.971058666666667">Waco, Department of Computing girju@cs.baylor.edu University of Texas at Dallas,</affiliation>
<email confidence="0.999913">moldovan@utdallas.edu</email>
<abstract confidence="0.9838374375">The discovery of semantic relations in text plays an important role in many NLP applications. This paper presents a method for the automatic classification of semantic relations in nominalized noun phrases. Nominalizations represent a subclass of NP constructions in which either the head or the modifier noun is derived from a verb while the other noun is an argument of this verb. Especially designed features are extracted automatically and used in a Support Vector Machine learning model. The paper presents preliminary results for the semantic classification of the most representative NP patterns using four distinct learning models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>C Fillmore</author>
<author>J Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLLING/ACL.</booktitle>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. Baker, C. Fillmore, and J. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of COLLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blaheta</author>
<author>E Charniak</author>
</authors>
<title>Assigning function tags to parsed text.</title>
<date>2000</date>
<booktitle>In Proceedings of the NAACL.</booktitle>
<contexts>
<context position="2730" citStr="Blaheta and Charniak 2000" startWordPosition="414" endWordPosition="417">and (5) Adjective clauses where the head noun is modified by a relative clause (eg the man who was driving the car - an AGENT relation between man and driving). 1.2 Previous work on the discovery of semantic relations The development of large semantically annotated corpora, such as Penn Treebank2 and, more recently, PropBank (Kingsbury, et al. 2002), as well as semantic knowledge bases, such as FrameNet (Baker, Fillmore, and Lowe 1998), have stimulated a high interest in the automatic acquisition of semantic relations, and especially of semantic roles. In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques. These statistical techniques operate on the output of probabilistic parsers and take advantage of the characteristic features of the semantic roles that are then employed in a learning algorithm. While these systems focus on verb-argument semantic relations, called semantic roles, in this paper we investigate predicate-argument semantic relations in nominalized noun phrases and present a method for their automatic detection in op</context>
</contexts>
<marker>Blaheta, Charniak, 2000</marker>
<rawString>D. Blaheta and E. Charniak. 2000. Assigning function tags to parsed text. In Proceedings of the NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Immediate-head parsing for language models.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="4200" citStr="Charniak 2001" startWordPosition="633" endWordPosition="634">c relations is studied across different NP patterns and the similarities and differences among resulting semantic spaces are analyzed. A thorough understanding of the syntactic and semantic characteristics of NPs provides valuable insights into defining the most representative feature vectors that ultimately drive the discriminating learning models. An important characteristic of this work is that it relies heavily on state-of-the-art natural language processing and machine learning methods. Prior to the discovery of semantic relations, the text is syntactically parsed with Charniak’s parser (Charniak 2001) and words are semantically disambiguated and mapped into their appropriate WordNet senses. The word sense disambiguation is done manually for training and automatically for testing with a state-of-the-art WSD module, an improved version of a system with which we have participated successfully in Senseval 2 and which has an accuracy of 81% when disambiguating nouns in open-domain. The discovery of semantic relations is based on learning lexical, syntactic, semantic and contextual constraints that effectively identify the most probable relation for each NP construction considered. 2 Semantic Re</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>E. Charniak. 2001. Immediate-head parsing for language models. In Proceedings ofACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Remarks on Nominalization.</title>
<date>1970</date>
<booktitle>In Readings in English Transformational</booktitle>
<institution>Ginn and Company.</institution>
<contexts>
<context position="28023" citStr="Chomsky 1970" startWordPosition="4474" endWordPosition="4475">mLex nominalization class. For this experiment we considered only examples that could be found in NomLex. By specifying subj-nom, obj-nom, and verb-nom types of nominalization, we reduce the list of possible semantic relations the verb can have with the non-nominalized noun. Example: “computer maker”, where “maker” is an agential deverbal noun that captures both the subject (respectively, AGENT) and the verb. Thus, the noun “computer” can only map to object (respectively, THEME). 4. Verbal nominalization is a binary feature indicating whether the nominalized noun is gerundive or not. Chomsky (Chomsky 1970) showed that gerundive nominalizations have different behavior than derived nominalizations. Example: ”woman worker” vs “working woman”; here “working” is a verbal nominal. 5. Semantic class of the coordinating word. This is a contextual feature and can be either a noun (if the phrase that contains the nominalization is attached to a noun) or a verb (if the phrase is an argument of the verb in the sentence). The feature value is either the VerbLeX class of the verb or the root of the noun in the WordNet hierarchy. The coordinating word captures some properties present in the noun phrase, prope</context>
</contexts>
<marker>Chomsky, 1970</marker>
<rawString>N. Chomsky. 1970. Remarks on Nominalization. In Readings in English Transformational Grammar. Jacobs, R. A., and Rosenbaum, P.S. (eds), Ginn and Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
</authors>
<title>Large-scale dictionary construction for foreign language tutoring and interlingual machine translation.</title>
<date>1997</date>
<booktitle>In Machine Translation,</booktitle>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="6348" citStr="Dorr 1997" startWordPosition="959" endWordPosition="960">mantic relations between the noun constituents. Genitives In English there are two kinds of genitives; in one, the modifier is morphologically linked to the possessive clitic ’s and precedes the head noun (s-genitive e.g. “John’s conclusion”), and in the second one the modifier is syntactically marked by the preposition of and follows the head noun (of-genitive, e.g. “declaration of independence”). Adjective Phrases are prepositional phrases attached to nouns and act as adjectives (cf. (Semmelmeyer and Bolander 1992)). Prepositions play an important role both syntactically and semantically ( (Dorr 1997). Prepositional constructions can encode various semantic relations, their interpretations being provided most of the time by the underlying context. For instance, the preposition “with” can encode different semantic relations: (1) It was the girl with blue eyes (MERONYMY), (2) The baby with the red ribbon is cute (POSSESSION), (3) The woman with triplets received a lot of attention (KINSHIP). The conclusion for us is that in addition to the nouns semantic classes, the preposition and the context play important roles here. Adjective Clauses are subordinate clauses attached to nouns (cf. (Semme</context>
</contexts>
<marker>Dorr, 1997</marker>
<rawString>B. Dorr. 1997. Large-scale dictionary construction for foreign language tutoring and interlingual machine translation. In Machine Translation, 12(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="2758" citStr="Gildea and Jurafsky 2002" startWordPosition="418" endWordPosition="422">re the head noun is modified by a relative clause (eg the man who was driving the car - an AGENT relation between man and driving). 1.2 Previous work on the discovery of semantic relations The development of large semantically annotated corpora, such as Penn Treebank2 and, more recently, PropBank (Kingsbury, et al. 2002), as well as semantic knowledge bases, such as FrameNet (Baker, Fillmore, and Lowe 1998), have stimulated a high interest in the automatic acquisition of semantic relations, and especially of semantic roles. In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques. These statistical techniques operate on the output of probabilistic parsers and take advantage of the characteristic features of the semantic roles that are then employed in a learning algorithm. While these systems focus on verb-argument semantic relations, called semantic roles, in this paper we investigate predicate-argument semantic relations in nominalized noun phrases and present a method for their automatic detection in open-text. 1.3 Approach We app</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic Labeling of Semantic Roles. In Computational Linguistics, 28(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>M Palmer</author>
</authors>
<title>The Necessity of Parsing for Predicate Argument Recognition.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2784" citStr="Gildea and Palmer 2002" startWordPosition="423" endWordPosition="426"> by a relative clause (eg the man who was driving the car - an AGENT relation between man and driving). 1.2 Previous work on the discovery of semantic relations The development of large semantically annotated corpora, such as Penn Treebank2 and, more recently, PropBank (Kingsbury, et al. 2002), as well as semantic knowledge bases, such as FrameNet (Baker, Fillmore, and Lowe 1998), have stimulated a high interest in the automatic acquisition of semantic relations, and especially of semantic roles. In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques. These statistical techniques operate on the output of probabilistic parsers and take advantage of the characteristic features of the semantic roles that are then employed in a learning algorithm. While these systems focus on verb-argument semantic relations, called semantic roles, in this paper we investigate predicate-argument semantic relations in nominalized noun phrases and present a method for their automatic detection in open-text. 1.3 Approach We approach the problem top-down</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>D. Gildea and M. Palmer. 2002. The Necessity of Parsing for Predicate Argument Recognition. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>C Macleod</author>
<author>A Meyers</author>
</authors>
<title>Comlex syntax: Building a computational lexicon.</title>
<date>1994</date>
<booktitle>In Proceedings of COLING, Kyoto,</booktitle>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>R. Grishman, C. Macleod, and A. Meyers. 1994. Comlex syntax: Building a computational lexicon. In Proceedings of COLING, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hull</author>
<author>F Gomez</author>
</authors>
<title>Semantic interpretation of nominalizations.</title>
<date>1996</date>
<booktitle>In AAAI conference,</booktitle>
<location>Oregon.</location>
<contexts>
<context position="8658" citStr="Hull and Gomez 1996" startWordPosition="1330" endWordPosition="1333"> of NP constructions that in general have “a systematic correspondence with a clause structure” (Quirk et al.1985). The head or modifier noun is derived from a verb while the other noun (the modifier, or respectively, the head) is interpreted as an argument of this verb. For example, the noun phrase “car owner” corresponds to “he owns a car”. The head noun owner is morphologically related to the verb own. Otherwise said, the interpretation of this class of NPs is reduced to the automatic detection and interpretation of semantic roles mapped on the corresponding verb-argument structure. As in (Hull and Gomez 1996), in this paper we use the term nominalization to refer only to those senses of the nominalized nouns which are derived from verbs. For example, the noun “decoration” has three senses in WordNet 2.0: an ornament (#1), a medal (#2), and the act of decorating (#3). Only the last sense is a nominalization. However, there are more complex situations when the underlying verb has more than one sense that refers to an action/event. This is the case of “examination” which has five senses of which four are action-related. In this case, the selection of the correct sense is provided by the context. We a</context>
</contexts>
<marker>Hull, Gomez, 1996</marker>
<rawString>R. Hull and F. Gomez. 1996. Semantic interpretation of nominalizations. In AAAI conference, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kipper</author>
<author>H T Dang</author>
<author>M Palmer</author>
</authors>
<title>Class-based construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In AAAI,</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="23068" citStr="Kipper et al. 2000" startWordPosition="3613" endWordPosition="3616">p of some important resources mentioned below. ComLex (Grishman et al.1994) is a computational lexicon providing syntactic information for more than 38,000 English headwords. It contains detailed syntactic information about the attributes of each lexical item and the subcategorization frames when words have arguments. This last feature is the most useful for our task as the senses of verbs are clustered by the syntactic frames. We will use ComLex in combination with VerbLeX to map the syntactic behaviors to verb semantic classes. VerbLeX is an in-house verb lexicon built by enriching VerbNet (Kipper et al. 2000) with verb synsets from WordNet and verbs extracted from the semantic frames of FrameNet. It contains information about the semantic roles that can appear within a class of verbs together with the selectional restrictions for their lexical realizations, syntactic subcategorization and WordNet verb senses. The syntactic information is less detailed than in ComLex, but a mapping between these two resources will provide both the semantic and syntactic information needed for the task. From the total of 13,213 verbs in the extended VerbNet, 6,077 were distinct. It also provides a mapping from the F</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>K. Kipper, H. T. Dang, and M. Palmer. 2000. Class-based construction of a verb lexicon. In AAAI, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
<author>M Marcus</author>
</authors>
<title>Adding Semantic Annotation to the Penn TreeBank.</title>
<date>2002</date>
<booktitle>In Proceedings ofHLT,</booktitle>
<location>California.</location>
<contexts>
<context position="2455" citStr="Kingsbury, et al. 2002" startWordPosition="370" endWordPosition="373"> a noun (eg parental refusal - AGENT), (3) Genitives (eg tone of conversation - a PROPERTY relation), (4) Adjective phrases in which the modifier noun is expressed by a prepositional phrase which functions as an adjective (eg amusement in the park - a LOCATION relation), and (5) Adjective clauses where the head noun is modified by a relative clause (eg the man who was driving the car - an AGENT relation between man and driving). 1.2 Previous work on the discovery of semantic relations The development of large semantically annotated corpora, such as Penn Treebank2 and, more recently, PropBank (Kingsbury, et al. 2002), as well as semantic knowledge bases, such as FrameNet (Baker, Fillmore, and Lowe 1998), have stimulated a high interest in the automatic acquisition of semantic relations, and especially of semantic roles. In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques. These statistical techniques operate on the output of probabilistic parsers and take advantage of the characteristic features of the semantic roles that are t</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>P. Kingsbury, M. Palmer, and M. Marcus. 2002. Adding Semantic Annotation to the Penn TreeBank. In Proceedings ofHLT, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
</authors>
<title>From Treebank to Propbank.</title>
<date>2002</date>
<booktitle>In Third International Conference on Language Resources and Evaluation, LREC-02,</booktitle>
<location>Las Palmas, Canary Islands.</location>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>P. Kingsbury and M. Palmer. 2002. From Treebank to Propbank. In Third International Conference on Language Resources and Evaluation, LREC-02, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1979</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="5114" citStr="Levi 1979" startWordPosition="770" endWordPosition="771">al 2 and which has an accuracy of 81% when disambiguating nouns in open-domain. The discovery of semantic relations is based on learning lexical, syntactic, semantic and contextual constraints that effectively identify the most probable relation for each NP construction considered. 2 Semantic Relations in Nominalized Noun Phrases In this paper we study the behavior of semantic relations at the noun phrase level when one of the nouns is nominalized. The following NP level constructions are considered: complex nominals, genitives, adjective phrases, and adjective clauses. Complex Nominals Levi (Levi 1979) defines complex nominals (CNs) as expressions that have a head noun preceded by one or more modifying nouns, or by adjectives derived from nouns (usually called denominal adjectives). Each sequence of nouns, or possibly adjectives and nouns, has a particular meaning as a whole carrying an implicit semantic relation; for example, “parental refusal” (AGENT). The main tasks are the recognition, and the interpretation of complex nominals. The recognition task deals with the identification of CN constructions in text, while the interpretation of CNs focuses on the detection and classification of a</context>
</contexts>
<marker>Levi, 1979</marker>
<rawString>Judith Levi. 1979. The Syntax and Semantics of Complex Nominals. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Macleod</author>
<author>R Grishman</author>
<author>A Meyers</author>
<author>L Barrett</author>
<author>R Reeves</author>
</authors>
<title>Nomlex: A lexicon of nominalizations.</title>
<date>1998</date>
<booktitle>In Proceedings of the 8th International Congress of the European Association</booktitle>
<institution>for Lexicography, Belgium.</institution>
<contexts>
<context position="11207" citStr="Macleod et al. 1998" startWordPosition="1732" endWordPosition="1735">ement). The “General” subclass refers to all other types of noun - noun constructions that cannot be mapped on verbargument relations (e.g., “hundreds of dollars”). Adjective clauses are not part of Table 1 as they describe by default verb-argument relations (semantic roles). Thus they cannot be classified as nominalizations or nonnominalizations. Two other useful classifications for nominalizations are: paraphrased vs. non-paraphrased, and the classification according to the nominalized noun’s verbargument underlying structures as provided by the NomLex dictionary of English nominalizations (Macleod et al. 1998) discussed more later. Paraphrased vs non-Paraphrased. In most cases, the relation between the nominalized noun and the other noun argument can be captured from the subcategorization properties of the underlying verb. Otherwise said, most of the time, there is a systematic correspondence between the nominalized NP construction and the predicate-argument structure of the corresponding verb in a clausal paraphrase (paraphrased nominalization). The predicate-argument structure can be captured by three grammatical roles: verb-subject, verbobject, and verb-complement. We call the arguments of the v</context>
<context position="13117" citStr="Macleod et al. 1998" startWordPosition="2020" endWordPosition="2023">zation as its meaning is different from its most related paraphrase clause. Examples: research budget, design contract, preparation booklet, publishing sub-industry and editing error. An important observation is that the nominalized noun occurs most of the time on the first position in an NP construction. The criteria presented here consider also nominalizations with adjectival modifiers such as “parental refusal”. These adjectives are derived from nouns, so the construction is just a special case of nominalization between nouns. NomLex classification The NomLex dictionary of nominalizations (Macleod et al. 1998) contains 1025 lexical entries and lists the verbs from which the nouns are derived. This dictionary specifies the complements allowed for a nominalization. The mapping is done at a syntactic level only. NomLex is used in the first phase of our algorithm in order to detect a possible nominalization and the corresponding root verb. The criterion of NomLex classification is based on the verb-argument correspondence: a. Verb-nom: The nominalized noun represents the action/state of the verb (e.g., “acquisition challenge”, “depositary receipt)”, b. Subj-nom: The nominalized noun refers to the subje</context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>C. Macleod, R. Grishman, A. Meyers, L. Barrett, and R. Reeves. 1998. Nomlex: A lexicon of nominalizations. In Proceedings of the 8th International Congress of the European Association for Lexicography, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>A Badulescu</author>
<author>M Tatu</author>
<author>D Antohe</author>
<author>R Girju</author>
</authors>
<title>Semantic Classification of Non-nominalized Noun Phrases.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL 2004 - Computational Lexical Semantics workshop,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="15218" citStr="Moldovan et al. 2004" startWordPosition="2338" endWordPosition="2341">neral “hundreds of dollars” Table 1: Classification of noun phrase constructions on the types of grammatical roles (cf. (Quirk et al.1985)) needed for semantic roles detection. The classification is the result of our observations of nominalization patterns at noun phrase level. category the number of randomly selected sentences, the number of instances found in these sentences, and finally the number of nominalized instances our group managed to annotate by hand. The annotation of each example consisted of specifying its feature vector and the most appropriate semantic relation as defined in (Moldovan et al. 2004). Inter-annotator Agreement The annotators, four PhD students in Computational Semantics worked in groups of two, each group focusing on one half of the corpus to annotate. Besides the type of relation, the annotators were asked to provide information about the order of the modifier and the head nouns in the syntactic constructions if applicable. For example, “owner of the car” and “car of the owner”. The annotators were also asked to indicate if the instance was a nominalization and if yes, which of the noun constituents was derived from a verb (e.g. the head noun nominalization “student prot</context>
<context position="23761" citStr="Moldovan et al. 2004" startWordPosition="3723" endWordPosition="3726">ames of FrameNet. It contains information about the semantic roles that can appear within a class of verbs together with the selectional restrictions for their lexical realizations, syntactic subcategorization and WordNet verb senses. The syntactic information is less detailed than in ComLex, but a mapping between these two resources will provide both the semantic and syntactic information needed for the task. From the total of 13,213 verbs in the extended VerbNet, 6,077 were distinct. It also provides a mapping from the FrameNet deep semantic roles to general thematic roles (list defined in (Moldovan et al. 2004)), and use cases for VerbNet. No. Semantic Frequency Examples Relations CNs Genitives Adjective Adjective Phrases Clauses NN AdjN ’s of 1 POSSESSION 0.46 1.16 1.06 0.37 0 0.23 “stock holders” 2 KINSHIP 0 0 0 0 0 0 3 ATTRIBUTE-HOLDER 1.37 6.97 1.41 8.24 1.82 0 “intensity of intervention” 4 AGENT 15.13 23.25 33.68 1.87 11.41 25.81 “trading companies” 5 TEMPORAL 0.92 0 26.24 1.50 11.87 6.27 “date ofpurchase” 6 DEPICTION-DEPICTED 0 0 0 0.75 0 0 “evidence of cheating” 7 PART-WHOLE 0 8.13 1.41 3.37 1.82 0 “world consumer” 8 IS-A (HYPERNYMY) 0 0 0 0 0 0 9 ENTAIL 0 0 0 0 0 0 10 CAUSE 0.46 0 0.35 1.12 </context>
<context position="25862" citStr="Moldovan et al. 2004" startWordPosition="4142" endWordPosition="4145">e” 29 POSSIBILITY 0 0 0 0 0 0 30 CERTAINTY 0 0 0 0 0 0 31 THEME 25.22 4.65 22.34 43.82 32.87 38.14 “use ofcards” 32 RESULT 5.04 0 0.35 3.00 0.45 1.62 “ship construction” 33 STIMULUS 0 0 0 0 0 2.32 “the beautiful painting he saw” 34 EXTENT 0 0 0 0 0 0 35 PREDICATE 0.46 0 0 0 0.45 0.70 “sun king, as Louis XVI is called” OTHERS 4.58 4.65 8.15 13.11 8.67 6.98 “editing error” Total no. of examples 100 (218) 100 (86) 100 (282) 100 (267) 100 (219) 100 (430) Table 3: The distribution of the semantic relations on the annotated corpus after agreement. The list of 35 semantic relations was presented in (Moldovan et al. 2004). The percentages represent the number of examples that encode a semantic relation for a particular pattern. The last row shows the number of examples covered by each pattern in the entire annotated corpus (1502 pairs). An essential aspect of our approach below is the word sense disambiguation (WSD) of the content words (nouns, verbs, adjectives and adverbs). Using a stateof-the-art open-text WSD system, each word is mapped into its corresponding WordNet 2.0 sense. When disambiguating each word, the WSD algorithm takes into account the surrounding words, and this is one important way through w</context>
<context position="32607" citStr="Moldovan et al. 2004" startWordPosition="5184" endWordPosition="5187">= yes. The in-house extended verb lexicon VerbLeX shows the following semantic frame for the verb class fill9.8: Agent[+animate] Destination[+location -region] Theme[+concrete] Body-part is a subcategory of concrete. Thus, for this example the semantic relation is THEME. 4 Overview of Results The f-measure results obtained so far are summarized in Table 4. They are divided in two categories, nominalizations, and adjective clauses since the feature vectors differ from one category to another. We have compared the performance of SVM with three other learning algorithms: (1) semantic scattering (Moldovan et al. 2004), (2) decision trees (a C4.5 implementation), and (3) Naive Bayes. We considered as baseline semantic scattering which is a new learning model (Moldovan et al. 2004) developed in-house for the semantic classification of nounnoun pairs in NP constructions. The semantic relation derives from the WordNet semantic classes of the two nouns participating in those constructions, as well as the surrounding context provided by the WSD module. As expected, the results vary from pattern to pattern. SVM and Naive Bayes seem to perform better than other models for the nominalizations and adjective clauses.</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Girju, 2004</marker>
<rawString>D. Moldovan, A. Badulescu, M. Tatu, D. Antohe, and R. Girju. 2004. Semantic Classification of Non-nominalized Noun Phrases. In Proceedings of HLT/NAACL 2004 - Computational Lexical Semantics workshop, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>K Hacioglu</author>
<author>V Krugler</author>
<author>W Ward</author>
<author>J Martin</author>
<author>D Jurafsky</author>
</authors>
<title>Semantic role parsing: Adding semantic structure to unstructured text.</title>
<date>2003</date>
<booktitle>In ICDM,</booktitle>
<location>Florida.</location>
<contexts>
<context position="2807" citStr="Pradhan et al. 2003" startWordPosition="427" endWordPosition="430">the man who was driving the car - an AGENT relation between man and driving). 1.2 Previous work on the discovery of semantic relations The development of large semantically annotated corpora, such as Penn Treebank2 and, more recently, PropBank (Kingsbury, et al. 2002), as well as semantic knowledge bases, such as FrameNet (Baker, Fillmore, and Lowe 1998), have stimulated a high interest in the automatic acquisition of semantic relations, and especially of semantic roles. In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques. These statistical techniques operate on the output of probabilistic parsers and take advantage of the characteristic features of the semantic roles that are then employed in a learning algorithm. While these systems focus on verb-argument semantic relations, called semantic roles, in this paper we investigate predicate-argument semantic relations in nominalized noun phrases and present a method for their automatic detection in open-text. 1.3 Approach We approach the problem top-down, namely identify and s</context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2003</marker>
<rawString>S. Pradhan, K. Hacioglu, V. Krugler, W. Ward, J. Martin, and D. Jurafsky. 2003. Semantic role parsing: Adding semantic structure to unstructured text. In ICDM, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A comprehensive grammar of English language,</title>
<date>1985</date>
<location>Longman, Harlow.</location>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A comprehensive grammar of English language, Longman, Harlow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Non Parametric Statistics for the behavioral science.</title>
<date>1988</date>
<publisher>McGraw-Hill.</publisher>
<location>New York:</location>
<contexts>
<context position="15995" citStr="Siegel and Castellan 1988" startWordPosition="2463" endWordPosition="2466">e corpus to annotate. Besides the type of relation, the annotators were asked to provide information about the order of the modifier and the head nouns in the syntactic constructions if applicable. For example, “owner of the car” and “car of the owner”. The annotators were also asked to indicate if the instance was a nominalization and if yes, which of the noun constituents was derived from a verb (e.g. the head noun nominalization “student protest”, or the modifier noun nominalization “working woman’” cf. (Quirk et al.1985)). The annotators’ agreement was measured using the Kappa statistics (Siegel and Castellan 1988), one of the most frequently used measure of inter-annotator agreement for classification tasks: , where is the proportion of times the raters agree and is the probability of agreement by chance. The K coefficient is 1 if there is a total agreement among the annotators, and 0 if there is no agreement other than that expected to occur by chance. For each construction, the corpus was split after agreement with an 80/20 training/testing ratio. For each pattern, we computed the K coefficient only for those instances tagged with one of the 35 semantic relations (K value for: NN (0.64), AdjN (0.70),</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and N.J. Castellan. 1988. Non Parametric Statistics for the behavioral science. New York: McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Semmelmeyer</author>
<author>D Bolander</author>
</authors>
<title>The New Webster’s Grammar Guide.</title>
<date>1992</date>
<publisher>Lexicon Publications, Inc.</publisher>
<contexts>
<context position="1520" citStr="Semmelmeyer and Bolander 1992" startWordPosition="214" endWordPosition="217">ents preliminary results for the semantic classification of the most representative NP patterns using four distinct learning models. 1 Introduction 1.1 Problem description The automatic identification of semantic relations in text has become increasingly important in Information Extraction, Question Answering, Summarization, Text Understanding, and other NLP applications. This paper discusses the automatic labeling of semantic relations in nominalized noun phrases (NPs) using a support vector machines learning algorithm. Based on the classification provided by the New Webster’s Grammar Guide (Semmelmeyer and Bolander 1992) and our observations of noun phrase patterns on large text collections, the most frequently occurring NP level constructions are: (1) Compound Nominals consisting of two consecutive nouns (eg pump drainage - an INSTRUMENT relation), (2) Adjective Noun constructions where the adjectival modifier is derived from a noun (eg parental refusal - AGENT), (3) Genitives (eg tone of conversation - a PROPERTY relation), (4) Adjective phrases in which the modifier noun is expressed by a prepositional phrase which functions as an adjective (eg amusement in the park - a LOCATION relation), and (5) Adjectiv</context>
<context position="6260" citStr="Semmelmeyer and Bolander 1992" startWordPosition="945" endWordPosition="948">xt, while the interpretation of CNs focuses on the detection and classification of a comprehensive set of semantic relations between the noun constituents. Genitives In English there are two kinds of genitives; in one, the modifier is morphologically linked to the possessive clitic ’s and precedes the head noun (s-genitive e.g. “John’s conclusion”), and in the second one the modifier is syntactically marked by the preposition of and follows the head noun (of-genitive, e.g. “declaration of independence”). Adjective Phrases are prepositional phrases attached to nouns and act as adjectives (cf. (Semmelmeyer and Bolander 1992)). Prepositions play an important role both syntactically and semantically ( (Dorr 1997). Prepositional constructions can encode various semantic relations, their interpretations being provided most of the time by the underlying context. For instance, the preposition “with” can encode different semantic relations: (1) It was the girl with blue eyes (MERONYMY), (2) The baby with the red ribbon is cute (POSSESSION), (3) The woman with triplets received a lot of attention (KINSHIP). The conclusion for us is that in addition to the nouns semantic classes, the preposition and the context play impor</context>
</contexts>
<marker>Semmelmeyer, Bolander, 1992</marker>
<rawString>M. Semmelmeyer and D. Bolander. 1992. The New Webster’s Grammar Guide. Lexicon Publications, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tong</author>
<author>D Koller</author>
</authors>
<title>Support Vector Machine Active Learning with Applications to Text Classification.</title>
<date>2001</date>
<journal>In Journal ofMachine Learning Research.</journal>
<contexts>
<context position="19636" citStr="Tong and Koller 2001" startWordPosition="3059" endWordPosition="3062">27067 14582 31568 No. of instances 5557 500 2990 4185 3502 6520 2 No. of annotated instances 2315 383 1816 3404 1341 563 No. of annotated nominalized instances 747 118 383 742 543 563 No. of annotated nominalized instances used in the learning task 312 118 383 344 297 563 Table 2: Corpus statistics. syntactic constructions. 2. There are semantic relations that have preferences over particular syntactic constructions. 3.5 Model 3.6 Support Vector Machines Support Vector Machines (SVM) have a strong mathematical foundation (Vapnik 1982) and have been applied successfully to text classification (Tong and Koller 2001), speech recognition, and other applications. We applied SVM to the semantic classification problem and obtained encouraging results. SVM algorithms are a special class of hyperplane classifiers that use the information encoded in the dotproducts of the transformed feature vectors as a similarity measure. The similarity between two instances and is given as a function , . The Kernel function is the inner product of the non-linear function that maps the original feature vectors into real feature space. The function that provides the best classification is of the form: . The vectors for which th</context>
</contexts>
<marker>Tong, Koller, 2001</marker>
<rawString>S. Tong and D. Koller. 2001. Support Vector Machine Active Learning with Applications to Text Classification. In Journal ofMachine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>Estimation of Dependences Based on Empirical Data. In</title>
<date>1982</date>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="19555" citStr="Vapnik 1982" startWordPosition="3049" endWordPosition="3050">djective Phrases Clauses NN AdjN ’s of No. of sentences 7067 5381 50291 27067 14582 31568 No. of instances 5557 500 2990 4185 3502 6520 2 No. of annotated instances 2315 383 1816 3404 1341 563 No. of annotated nominalized instances 747 118 383 742 543 563 No. of annotated nominalized instances used in the learning task 312 118 383 344 297 563 Table 2: Corpus statistics. syntactic constructions. 2. There are semantic relations that have preferences over particular syntactic constructions. 3.5 Model 3.6 Support Vector Machines Support Vector Machines (SVM) have a strong mathematical foundation (Vapnik 1982) and have been applied successfully to text classification (Tong and Koller 2001), speech recognition, and other applications. We applied SVM to the semantic classification problem and obtained encouraging results. SVM algorithms are a special class of hyperplane classifiers that use the information encoded in the dotproducts of the transformed feature vectors as a similarity measure. The similarity between two instances and is given as a function , . The Kernel function is the inner product of the non-linear function that maps the original feature vectors into real feature space. The function</context>
</contexts>
<marker>Vapnik, 1982</marker>
<rawString>V. Vapnik. 1982. Estimation of Dependences Based on Empirical Data. In Springer Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>