<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.9983265">
A Combined Phonetic-Phonological Approach to Estimating Cross-
Language Phoneme Similarity in an ASR Environment
</title>
<author confidence="0.940984">
Lynette Melnar Chen Liu
</author>
<email confidence="0.966143">
lynette.melnar@motorola.com chen.liu@motorola.com
</email>
<sectionHeader confidence="0.999099" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999875081081081">
Speech technologists typically use acoustic meas-
urements to determine similarity among acoustic
speech models (phone(me) HMMs) and there are a
variety of distance metrics available that prove the
effectiveness of this method (see Sooful and Botha
2002). Additionally, HMM similarity can be
evaluated indirectly through comparison of HMM
performances in ASR experiments.
For acoustic measurements, speech data must
be accessible for model training. However, speech
data unavailability is a practical concern in that
most commercially available speech databases are
restricted to widely spoken languages in large
business markets. The vast majority of languages
have not been exposed to intense data collection
and resources for these languages are subsequently
either limited or completely unavailable. Hence a
knowledge-based phoneme distance metric poten-
tially has great value in acoustic modeling for re-
source-limited languages in that it can predict
cross-language HMM similarity in the absence of
target-language speech data.
Knowledge-based approaches to HMM similar-
ity generally attempt to identify articulatory simi-
larity between phonemes across languages. The
typical strategy is subjective and label-based,
where two phonemes are judged to be more or less
similar depending on their transcription labels
(Köhler 1996; Schultz and Waibel 1997, 2000).
A label-based approach suffers for two obvious
reasons. First, phone inventories designed for
speech technology applications are predominantly
phonemic in orientation. Thus, transcription labels
do not transfer with the same phonetic value to
other languages, even where international phonetic
transcription labels are employed. In a phonemic
transcription strategy, transcription labels are gen-
</bodyText>
<sectionHeader confidence="0.648848" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.99995384375">
This paper presents a fully automated lin-
guistic approach to measuring distance
between phonemes across languages. In
this approach, a phoneme is represented
by a feature matrix where feature catego-
ries are fixed, hierarchically related and
binary-valued; feature categorization ex-
plicitly addresses allophonic variation and
feature values are weighted based on their
relative prominence derived from lexical
frequency measurements. The relative
weight of feature values is factored into
phonetic distance calculation. Two pho-
nological distances are statistically de-
rived from lexical frequency
measurements. The phonetic distance is
combined with the phonological distances
to produce a single metric that quantifies
cross-language phoneme distance.
The performances of target-language
phoneme HMMs constructed solely with
source language HMMs, first selected by
the combined phonetic and phonological
metric and then by a data-driven, acous-
tics distance-based method, are compared
in context-independent automatic speech
recognition (ASR) experiments. Results
show that this approach consistently per-
forms equivalently to the acoustics-based
approach, confirming its effectiveness in
estimating cross-language similarity be-
tween phonemes in an ASR environment.
</bodyText>
<page confidence="0.82598">
1
</page>
<note confidence="0.867774">
Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 1–10,
New York City, USA, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999780411764707">
erally restricted to only the most basic symbols,
usually unmodified letters of the Roman alphabet
(IPA 1999). Second, phoneme transcription labels
fail to capture allophony. The best phonetic defini-
tion that a phoneme transcription label can offer is
the most typical phonetic realization of that pho-
neme. Not surprisingly, label-based cross-language
transfer experiments have produced poor perform-
ance results.
In contrast to the subjective, label-based strat-
egy, researchers in such fields as language recon-
struction, dialectometry, and child language
development, commonly use automatic feature-
based approaches to articulatory similarity between
phonemes. In these methods, phonemes are repre-
sented by a distinctive feature vector and a pho-
netic distance or similarity algorithm is used to
align phoneme strings between related words
(Connolly 1997; Kessler 1995, 2005; Kondrak
2002; Nerbonne and Heeringa 1997; Somers
1998). Significantly, in these approaches, phono-
logical similarity is generally assumed.
In principle, the feature-based approach to pho-
netic distance admits more precise specification of
phonemes because it supports allophonic variance.
For example, a standard feature-based approach to
allophony representation restricts feature inclusion
to only those features relevant to all realizations of
the phoneme. Another common approach retains
features that are relevant to all allophonic variants,
but leaves their values underspecified (Archangeli
1988). However, it is unclear from the literature
whether allophony is explicitly addressed in the
current feature-based approaches to phoneme simi-
larity.
A strategy for specifying allophony and charac-
terizing phonetic distance between phonemes is
only one component in predicting phoneme simi-
larity among diverse languages without acoustic
data in an ASR environment. Because HMMs rep-
resent phonemes and significant allophones in a
language-dependent context, it is necessary to con-
sider the overall constructed target-language HMM
system. Thus phonological distance quantities that
regulate the priority of source languages for pho-
neme selection in accordance to their phonological
similarity to the target language are also in order.
In this paper, we describe an automated, com-
bined phonetic-phonological (CPP) approach to
estimating phoneme similarity across languages in
ASR. Elsewhere, we provide the phonetic and
phonological distance algorithms (Liu and Melnar
2005, 2006), though offer little linguistic justifica-
tion of the approach or evaluation of the experi-
ment results due to space limitations. Here, we
focus on explaining the linguistic principles behind
the algorithms and analyzing the results.
The CPP approach is fundamentally based on
articulatory phonetic features and is designed to
handle allophonic variation. Feature salience and
phonetic distance are automatically calculated and
phoneme distance is constrained by statistically-
derived phonological similarity biases. Unlike
other distinctive feature-based approaches to pho-
neme similarity, phonological distance is not as-
sumed. In testing this approach in cross-language
transfer experiments, target-language resources are
restricted to lexica and phonology descriptions and
do not include speech data.
In the next section, we describe our feature-
based phoneme specification method. In section
three, we show how our phoneme specification
approach is used in calculating phonetic distance
between phonemes. Section four describes two
other distance metrics that predict phonological
similarity between languages. We explain how the
three distance metrics combine to quantify cross-
language phoneme distance and select target-
language phoneme HMM inventories. In section
five, we describe the experiments that we con-
ducted to evaluate our approach to phoneme simi-
larity prediction. Here, the CPP method is
compared with an acoustic distance method in con-
text-independent speech recognition. We offer our
evaluation and conclusions in section 6.
</bodyText>
<sectionHeader confidence="0.918726" genericHeader="introduction">
2 Phoneme specification
</sectionHeader>
<bodyText confidence="0.999878222222222">
In the CPP approach to estimating cross-language
phoneme similarity, each phoneme in our multilin-
gual ASR dataset is associated with a distinctive
feature matrix. Feature categories are fixed for all
phonemes, hierarchically related, and binary-
valued. Feature-contradiction, associated with al-
lophonic variance, is explicitly addressed through
the introduction of a small set of special corollary
features.
</bodyText>
<subsectionHeader confidence="0.983589">
2.1 The phoneme feature matrix
</subsectionHeader>
<bodyText confidence="0.999061">
As noted in the introduction, cross-language pho-
neme comparison requires accurate feature specifi-
cation. Because a phoneme comprises one or more
</bodyText>
<page confidence="0.988284">
2
</page>
<bodyText confidence="0.999795766666667">
allophones which may contrast in particular fea-
tures, a distinctive feature strategy that allows for
feature contradiction is preferred. Omitting contra-
dictory features and underspecifying contradictory
values are two well-known methods.
However, cross-language phoneme comparison
in a computational environment is greatly facili-
tated by agreeing on a fixed set of binary-valued
features for all phonemes. A fixed set of distinctive
features is favored as this enables cross-class pho-
neme comparison. A binary-valued system is easy
to manipulate and naturally lends itself to mathe-
matical formulation. However, strict binary-valued
feature systems only indicate the presence or ab-
sence of a feature, and feature contradiction must
then be indicated by feature omission - which is
not possible in a fixed distinctive feature set.
The phoneme specification method that we em-
ploy indicates feature contradiction associated with
allophony in a strict binary-valued, fixed set of
distinctive features through the introduction of
special feature categories. Specifically, we utilize a
small set of corollary features to mark the occa-
sional, allophonic realizations of some primary
features. A corollary feature is defined as a feature
that supplements a primary feature in the system.
The corollary features mark “occasionality” (asso-
ciated with context dependency, dialectal variation,
speech style variation, etc.) in the primary feature
as either present or absent.
</bodyText>
<subsectionHeader confidence="0.979228">
2.2 Primary and corollary features
</subsectionHeader>
<bodyText confidence="0.999878">
Our feature set includes twenty-six primary articu-
latory features and six corollary features. The se-
lected primary features conform to a typical set of
hierarchically-related distinctive features (e.g. syl-
labic, sonorant, consonantal, labial, coronal, nasal,
continuant, high, low, back, etc.) (Ladefoged
1975). In this hierarchical system, the presence of
one feature presupposes the presence of those hier-
archically dominant features. For example, the
presence of the feature [alveolar] requires the pres-
ence of the feature [coronal], and the presence of
the feature [nasal] requires the presence of the fea-
ture [sonorant]. Significantly, the reverse of these
relations is not true. As is explained later in the
next section, this feature structure allows for a lin-
guistically-principled determination of feature sali-
ence in phonetic distance calculation.
Corollary features are restricted to specifying
those primary features that are judged to be most
significant to cross-language phoneme comparison
in an ASR environment. Phoneme inventories de-
signed for ASR comprise both phonemes and sig-
nificant allophones, where a significant allophone
is characteristically both acoustically distinct from
the primary allophone and associated with a suffi-
ciently high count of occurrence in the associated
speech database. Thus American English ASR
inventories regularly include an alveolar tap, a con-
textually-realized allophonic variant of both /t/ and
/d/. Furthermore, pronunciation transcriptions in
ASR lexica are typically phonetic - within the con-
text of the phoneme-based inventory. So, word-
final voice neutralization in German is overtly in-
dicated throughout the lexicon (e.g. hund : h U n t).
A typical ASR phoneme then does not represent a
true phoneme; rather it encompasses only that
phonemic variation that is not explicitly captured
by its existing significant allophones in the inven-
tory.
Corollary features specify variance that is not
usually overtly indicated in ASR inventories and
lexica but that is important to cross-language pho-
neme comparison in an acoustic, ASR environ-
ment. Internal phoneme recognition experiments
indicate that generally major class features (syl-
labic, sonorant, etc.), manner features (nasal, con-
tinuant, etc.) and laryngeal features (voice, spread
glottis, etc.) are more robustly identified than place
features (labial, coronal, etc.); accordingly, the set
of corollary features, provided in Table 1, pre-
dominantly targets particular major class, manner,
and laryngeal features.
</bodyText>
<tableCaption confidence="0.988524">
Table 1: Corollary features
</tableCaption>
<bodyText confidence="0.997045352941177">
Corollary Description
Feature
syllabic-occ positive value marks the occasional
realization of the phoneme as a syl-
labic consonant or glide
voice-occ positive value marks the occasional
voicing of phonemes
labial-occ positive value marks the occasional
rounding of vowels
nasal-occ positive value marks the occasional
nasalization of vowels and glides
rhotic-occ positive value marks the occasional
rhotization of liquids and vowels
spread-occ positive value marks the occasional
aspiration of obstruents
It should be pointed out that allophones that ex-
press a place contrast or difference in continuance
</bodyText>
<page confidence="0.994961">
3
</page>
<bodyText confidence="0.999482333333333">
with the primary realization of a phoneme are typi-
cally considered significant allophones in the ASR
phoneme system and are therefore overtly repre-
sented.
As an illustration of the usefulness of corollary
features in cross-language phoneme comparison,
consider Table 2 which includes a partial feature
matrix for the phoneme /k/ associated with 17 lan-
guages and dialects:
</bodyText>
<tableCaption confidence="0.994988">
Table 2: Partial distinctive feature table
</tableCaption>
<table confidence="0.998414631578947">
Languages phoneme spread spread
glottis -occ
Arabic k 0 0
Danish k 1 1
German k 1 1
British English k 1 1
U.S. English k 1 1
Lat. Spanish k 0 0
Can. French k 0 0
Parisian French k 0 0
Italian k 0 0
Japanese k 1 1
Dutch k 0 0
Brz. Portuguese k 0 0
Eur. Portuguese k 0 0
Swedish k 1 1
Korean k 1 0
Cantonese k 1 0
Mandarin k 1 0
</table>
<bodyText confidence="0.999069090909091">
Note that the realization of the phoneme /k/ differs
across the seventeen languages and dialects in the
two features provided: [spread glottis] and [spread-
occ]. The presence of the feature [spread glottis],
marked by 1, and the non-presence of the corollary
feature [spread-occ], marked by 0, indicates that
the glottis is always open during the articulation of
the phoneme; i.e. this phoneme is consistently as-
sociated with aspiration. The precise IPA transcrip-
tion of this segment is /kh/. A positive value for the
corollary feature [spread-occ] means that the pho-
neme is only sometimes associated with aspiration.
This phoneme has two principle phonetic realiza-
tions, marked [k] and [kh] in IPA notation. A 0
value for the feature [spread glottis] and corollary
feature [spread-occ] indicates that the segment is
never aspirated. Thus this phoneme is most accu-
rately labeled /k/ in IPA labeling.
Because this methodology incorporates pho-
neme feature contradiction, overall phonological
similarity among languages and dialects is more
precisely predicted:
</bodyText>
<tableCaption confidence="0.999253">
Table 3: Phoneme similarity across languages
</tableCaption>
<table confidence="0.999141555555556">
phoneme allophone(s) language lang. family
k kh, k Danish Germanic
German Germanic
Br. Eng. Germanic
Amer. Eng. Germanic
Japanese Altaic
Swedish Germanic
kh Korean Altaic
Mandarin Sinitic
Cantonese Sinitic
k Arabic Afro-Asiatic
Lat. Span. Romance
Parisian Fr. Romance
Canadian Fr. Romance
Italian Romance
Dutch Germanic
Brz. Port. Romance
Eur. Port. Romance
</table>
<tableCaption confidence="0.59812">
Table 3 reveals that Germanic languages tend to
</tableCaption>
<bodyText confidence="0.980948">
only occasionally aspirate /k/, Romance languages
avoid aspirating /k/, and Sinitic languages typically
aspirate /k/. Of course, closely related languages
tend to be phonologically similar.
</bodyText>
<sectionHeader confidence="0.985736" genericHeader="method">
3 Phonetic distance
</sectionHeader>
<bodyText confidence="0.999944769230769">
Most techniques for measuring phonetic distance
between phonemes that do not assume speech data
availability are based on articulatory features,
though perceptual distance, judged (subjective)
distance, and historical distance are also attested
(Kessler 2005). We base our phonetic distance
measurement on articulatory features because of
their cross-linguistic consistency and general
availability.
As Kessler notes, standard phonological theory
provides no guidance in comparing phonetic dis-
tance between phonemes across multiple features
(Kessler 2005). In our experiments to date, we use
the Manhattan distance where the distance between
phonemes equals the sum of the absolute values of
individual feature distances. This approach is fairly
standard in the literature, though the Euclidean
distance has also been reported to attain good re-
sults (Kessler 2005).
Because features are known to differ in relative
importance (Ladefoged 1969), some researchers
apply weights or saliencies to the individual fea-
tures for distance calculation. Nerbonne and Heer-
inga (1997), for example, weighted each feature by
information gain, or entropy reduction. Kondrak
(2002) expressed weights as coefficients that could
</bodyText>
<page confidence="0.987941">
4
</page>
<bodyText confidence="0.997692193548387">
be changed to any numeric value. He adjusted the
coefficients until he achieved optimal performance
on aligning cognate words.
In our approach, weights are derived from the
lexica of all the considered languages. Specifically,
the value of a weight for a feature is derived from
the frequency of the feature in the lexica. Each lan-
guage is treated equally in this approach; thus, the
weights are not subject to the relative size of a lan-
guage’s lexicon.
Because our phoneme specification method in-
corporates hierarchical relations between features,
feature weights are necessarily interdependent.
Hierarchically dominant features are more fre-
quently attested than their subordinate features and
thus receive more weight. Further, hierarchically
superior features tend to correspond to major pho-
netic categories (sonorant, consonantal, syllabic,
etc.), which are expected to be more contrastive or
distant to each other than sister subordinate catego-
ries. Thus, in a hierarchical feature system, lexical
frequency of features is a reasonable indication of
feature importance in phonetic contrast or distance.
In the following two subsections the phonetic
distance algorithm is described.
Quantitative representation of phonemes
A phoneme is denoted by pl(i), where l (=1,...,L)
represents the language that includes the phoneme,
and i (=1,...,Il) represents the index of the pho-
neme in language l. Thus, the phoneme inventory
of language l is
</bodyText>
<equation confidence="0.8115135">
(1) {pl(i)  |i
= 1, K , I l } .
</equation>
<bodyText confidence="0.979362875">
A phoneme pl (i) is represented by a vector of J
features
(2) f[pl(i)] = [vl(i,j)]T = [vl(i,1),K,vl(ij),K,vl(ij)]T
where each vl (i, j) is a binary feature, i =1, L, Il ,
j =1, L,J , l=1, L,L , and the superscript T denotes
vector transposition.
Weighted phonetic distance
As mentioned, the value of a weight for a feature
in the present phonetic distance approach is de-
rived from the frequency of the feature in the
lexica of all the considered languages. Let cl[pl(i)]
denote the occurrence count of a phoneme pl (i) in
a lexicon of language l, then the frequency of each
feature j contributed by the phoneme pl (i) is
cl [pl (i)]vl (i, j) , and the frequency of each feature j
contributed by all the phonemes in language l is
</bodyText>
<equation confidence="0.9893665">
∑Il =
icl pl i vl i j
1 [ ( )] ( , ) . The global weights derived from
all the phonemes in all the languages are
(3) W j =diag w L w j L w J
( ) { (1), , ( ), , ( ) }
</equation>
<bodyText confidence="0.707266">
where
</bodyText>
<equation confidence="0.997696727272727">
1 L 1
w j
( ) = ∑ w j =
l ( )
L L
l=1
l=1 c p i v i j
l l
[ ( )] ( , )
l
j=1i=1
</equation>
<bodyText confidence="0.9693334">
where diag(vector) gives a diagonal matrix with
elements of the vector as the diagonal entries. We
define the phonetic distance between phonemes
pl (i) and pt (k) in the form of a Manhattan dis-
tance, which is expressed as
</bodyText>
<equation confidence="0.992472333333333">
J
dlt(i,k)= W(j)(f[pl(i)]−f[pt(k)]) 1 =∑w(j)vl(i,j)−vt(k,j)
j=1
</equation>
<bodyText confidence="0.995245666666667">
where i =1, L ,Il , k =1, L , It , and the weights, given
in a diagonal matrix W(j), are dependent upon the
feature identity j.
</bodyText>
<sectionHeader confidence="0.99165" genericHeader="method">
4 Phonological distance metrics
</sectionHeader>
<bodyText confidence="0.999960173913044">
Although our phoneme specification approach is
designed to account for allophonic variance, not all
variation is captured. Because of this, the effec-
tiveness of measuring phonetic distance as a stand-
alone strategy to predicting cross-language pho-
neme similarity is compromised. Furthermore,
phonetic distance does not determine relative pho-
neme similarity in the not atypical scenario where
two or more phonemes share the same phonetic
distance to some target phoneme. In order to ad-
dress these problems, phonological distance met-
rics are used to bias cross-language phoneme
similarity predictions toward languages that have
similar phoneme inventories and phoneme fre-
quency distributions. The general idea is that the
more similar the phoneme inventory and relative
importance of each corresponding phoneme be-
tween languages, the more likely it is that the cor-
responding phonemes will be more similar.
Phonological distance consideration is espe-
cially desirable in an ASR environment because
ultimately HMMs corresponding to those source-
language phonemes predicted to be most similar to
</bodyText>
<figure confidence="0.995627090909091">
L
i=1
∑ j =1, L ,J
J I l
∑∑
Il
∑
c p i v i j
l l
[ ( )] ( , )
l
</figure>
<page confidence="0.94541">
5
</page>
<bodyText confidence="0.999956846153846">
target-language phonemes must interact in a sys-
tem that is intended to reflect a single target lan-
guage. Use of phonological metrics then ensures
that the overall model pool will have a bias toward
a reduced set of phonologically similar languages,
and it is reasonable to expect that similarity in lan-
guages of the model pool provides consistency in
the target HMM system (see Schultz and Waibel
2000).
In this section, we define two distance metrics
to characterize cross-language phonological simi-
larity. One is based on monophoneme inventories
while the other is based on biphoneme inventories.
</bodyText>
<subsectionHeader confidence="0.967268">
4.1 Monophoneme distribution distance
</subsectionHeader>
<bodyText confidence="0.99990895">
Monophoneme distribution distance characterizes
the difference in lexical phoneme distribution be-
tween two languages. Specifically, the distribution,
or normalized histogram, of the phonemes is ob-
tained from a large lexicon of a language, with the
probability in the distribution corresponding to the
frequency of a phoneme in the lexicon. We derive
the distribution from a lexicon as we consider it
more representative of a language’s phonology
than a particular database.
The monophoneme distribution metric is a ty-
pological comparison that is based on two princi-
pal classes of information: (1) types of sounds and
(2) frequencies of these sounds in the lexicon. The
former class is directly associated with phoneme
inventory correspondence while the latter concerns
relative phoneme importance.
Because the phoneme inventories of the two
languages to be compared may not be identical, we
first need to define a combined inventory for them
</bodyText>
<equation confidence="0.900965">
{plt (m)  |m=1,...,Ilt}={pl(i)  |i=1,...,Il}∪ {pt (k)  |k=1,...,It
</equation>
<bodyText confidence="0.99992025">
where plt (m) is a phoneme in the combined inven-
tory where there are total Ilt phonemes.
The frequency of the phoneme plt (m) in lan-
guage l can be expressed as
</bodyText>
<equation confidence="0.91657975">
(7) ρl [plt (m)] = Ill [plt (m)] , m=1, , Ilt
∑ i = 1 c p i
l l
[ ( )]
</equation>
<bodyText confidence="0.9949439">
where cl [plt (m)] is the occurrence count of pho-
neme plt (m) in a lexicon of language l. If a pho-
neme plt (m) does not exist in the language, its
frequency would be zero. The difference of pho-
neme frequencies between the two languages can
be calculated as
(8) dρlt [plt (m)] = ρl [plt (m)] − ρt [plt (m)] m =1, , Ilt
Then the monophoneme distribution distance
between the target language t and source language
l is
</bodyText>
<equation confidence="0.9691195">
Ilt
(9) D lt
ρ = ∑
m=
</equation>
<bodyText confidence="0.992792666666667">
The distance is calculated between the target lan-
guage and every one of the source languages.
In view of the known differences in phonologi-
cal characteristics between vowels and consonants,
we make separate calculations for the vowel and
consonant categories. Thus Eq. (9) becomes
</bodyText>
<figure confidence="0.8240605">
g
(10) Dρ = ∑
lt
d lt p lt m
ρ [ (
1
.
)]
dρlt [plt (m)]
plt (m )∈g
where g=Vowels or Consonants.
4.2 Biphoneme distribution distance
</figure>
<figureCaption confidence="0.530715714285714">
The biphoneme distribution distance metric char-
acterizes the difference in lexical distribution of
phoneme pairs, or biphonemes, between two lan-
guages. Similar to the monophoneme distribution
distance, the distribution of biphonemes in a lan-
guage is obtained based on the frequency of bipho-
nemes in a large lexicon.
</figureCaption>
<bodyText confidence="0.999807708333333">
The biphoneme metric indicates how phonemes
can combine in a language and how important
these combinations are. Though the phonotactics
provided in this approach is limited to only a se-
quence of two, the overall biphoneme inventory
and distribution provides important phonological
information. For example, it indicates if and to
what extent consonants can cluster. Some lan-
guages tend to disfavor consonant clustering, like
} the Romance languages, while others allow for
broad clustering, like the Germanic languages. It
also indicates if and to what extent vowels may co-
occur. Many languages require an onset consonant
so vowels will never co-occur; other languages
have no such restriction.
The biphoneme metric then yields types of in-
formation that are distinct from the monophoneme
metric. It explicitly provides a biphoneme inven-
tory, permissible phonotactic sequences, and pho-
notactic sequence importance. It also implicitly
incorporates phoneme inventory and phonological
complexity information.
Similar to the monophoneme distribution dis-
tance, the distribution of biphonemes in a language
</bodyText>
<page confidence="0.998296">
6
</page>
<bodyText confidence="0.998450666666667">
is obtained based on the frequency of a biphoneme
in a large lexicon. The biphoneme inventory for
the target language t is expressed as
</bodyText>
<equation confidence="0.52852575">
(11) {qt (k) |k=1,K,It′}
while the biphoneme inventory for a source lan-
guage l is
(12) {ql(i)  |i = 1, K , I l ′ }
</equation>
<bodyText confidence="0.9971185">
Then the combined biphoneme inventory for the
two languages to be compared is
</bodyText>
<equation confidence="0.966154">
{qlt(n) |n= 1,K,rrt}={ql(i)  |i=1,K,Il′}∪{qt(k)  |k=1,K,r
</equation>
<bodyText confidence="0.99984096">
where qlt (n) is a biphoneme in the combined in-
ventory where there are total Ilt′ biphonemes. For a
phoneme at the beginning or end of a word, qlt (n)
takes the format of “void+phoneme” or “pho-
neme+void”, respectively.
The frequency of a biphoneme qlt (n) in lan-
guage l can be expressed as
ranking between source phonemes and languages,
is a linear processing that scales the score range
from each domain into the range [0 1].
We equate the overall importance of phonetics
with that of phonology by providing a weight of 2
to the phonetic score and 1 to each of the phono-
logical scores. By doing this, a source-language
phoneme can have a greater phonetic distance to
some target-language phoneme than other source-
language phonemes but a lower phonological dis-
} tance and receive a lower overall phoneme dis-
tance score. It is because phonological distance is
considered as important as phonetic distance that
the overall constructed target-language model pool
will tend to be restricted to a subset of phonologi-
cally similar languages.
The feature-based phoneme distance metric is
defined as
</bodyText>
<equation confidence="0.975983111111111">
(18)
c q n
l lt
[ ( )]
(14) γ [ ( )] = Il , n = 1, L , Ilt ′
l lt
q n
′
cl [ql (i)]
</equation>
<bodyText confidence="0.930436">
where cl [qlt (n)] is the occurrence count of bipho-
neme qlt (n) in a lexicon of language l. The differ-
ence of biphoneme frequencies between the two
languages is
(15) dγlt [qlt (n)]= γl [qlt (n)]− γt [qlt (n)] n = 1, L , Ilt′
Then the biphoneme distribution distance between
the target language t and source language l is
</bodyText>
<equation confidence="0.966792">
Ilt′
(16) D lt
γ = ∑
=1
</equation>
<bodyText confidence="0.999475">
Similarly, the distance is better characterized
within the categories of vowels and consonants
separately. In our algorithm we count each bipho-
neme twice, the first time as a left-contact bipho-
neme and second time as a right-contact
biphoneme. Thus
</bodyText>
<equation confidence="0.9903348">
g
(17) Dγ = ∑ d q n
γ [ ( )]+
lt lt ∑
lt
</equation>
<bodyText confidence="0.983643">
where g=Vowels or Consonants.
</bodyText>
<subsectionHeader confidence="0.67379">
4.3 CPP phoneme distance
</subsectionHeader>
<bodyText confidence="0.999982">
For phoneme similarity prediction, we unite the
phonetic and phonological distance metrics to ar-
rive at the CPP phoneme distance measurement.
Since the three distances are from different do-
mains and provide distinct types of information,
normalization is necessary before combination.
The normalization, aimed at extracting the relative
</bodyText>
<equation confidence="0.995564636363636">
g g
CPP i k
( , ) = ⋅
α N + γ ⋅
d lt
[ ( , )]
d i k α
N + ρ ⋅ [ ]
D ρ α [ ]
D γ
lt lt
</equation>
<bodyText confidence="0.999031444444444">
where CPP(i,k) represents the distance between
phoneme pl (i) from language l and phoneme pt (k)
from language t, and both phonemes belong to the
same phonological category g (vowels or conso-
nants). The weights αd, αρ, and αγ represent the
relative importance of each quantity. As men-
tioned, ( αd , αρ , αγ )=(2,1,1). The symbol [·]N de-
notes that the quantity inside is linearly scaled into
the range [0 1]. For g
</bodyText>
<subsectionHeader confidence="0.572791">
Dρ and g
</subsectionHeader>
<bodyText confidence="0.960127">
Dγ , the original
lt lt
range is determined by scores of all the source lan-
guages. Their scaling is done once for a target lan-
guage t. While for dlt(i,k) , we found that it is better
to do scaling once for each target phoneme pt(k) ,
and the original range is determined by scores of a
group of candidate phonemes that includes at least
one phoneme from any source language.
</bodyText>
<sectionHeader confidence="0.99743" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999814111111111">
To test our CPP approach to phoneme similarity
prediction, we compared it to an acoustic distance
approach in ASR experiments. Because native lan-
guage speech data is used in measuring model dis-
tance in the acoustic approach, it is expected to
work better than the knowledge-based approach,
which only estimates acoustic similarity indirectly
through articulatory phonetic distance and overall
phonological distance.
</bodyText>
<figure confidence="0.98857252631579">
right of
( )
q n g
left of
( )
q n g
∈
∈
lt
lt
∑
i=1
d lt qlt n .
γ [ ( )]
n
dγlt [ ( )]
q n
lt
N
</figure>
<page confidence="0.984106">
7
</page>
<subsectionHeader confidence="0.922897">
5.1 Model construction
</subsectionHeader>
<bodyText confidence="0.999993578947369">
We employ the regular 3-state, left-right, mul-
timixture, continuous-Gaussian HMMs as the
acoustic models and assume that the models from
all the source and target languages have the same
topology except that the number of mixtures in a
state may vary. Once the top source phonemes are
determined from our feature-based phoneme dis-
tance metric for each target phoneme, the target
HMM is constructed by gathering all the mixtures
for a corresponding state from the source candi-
dates. The original mean and variance values are
maintained while the mixture weights are uni-
formly scaled down so that the new weights add up
to one for each state. It is possible to weigh mix-
tures according to the relative importance of the
candidates if the importance as reflected by the
phoneme distance metric has a significantly large
difference. The transition probabilities are adopted
from the top one candidate model.
</bodyText>
<subsectionHeader confidence="0.97529">
5.2 CPP phoneme model construction
</subsectionHeader>
<bodyText confidence="0.9999705">
We used the 17 languages and dialects provided in
Table 2 in the experiments testing our CPP pho-
neme distance approach to phoneme HMM simi-
larity. For each language, a native monolingual
model set had been built by training with native
speech data. The acoustic features are 39 regular
MFCC features including cepstral, delta, and delta-
delta. The individual ASR databases derive from a
variety of projects and protocols, including, but not
limited to, CallHome, EUROM, SpeechDat, Poly-
phone, and GlobalPhone. In each of the following
experiments, we select one language as the target
language, and construct its acoustic models by us-
ing all the other languages as source languages. A
phoneme distance score is calculated for each tar-
get phoneme and the top two candidate source-
language phonemes are chosen for HMM model
construction. We conducted experiments with Ital-
ian, Latin American Spanish, European Portu-
guese, Japanese, and Danish as target languages.
</bodyText>
<subsectionHeader confidence="0.951563">
5.3 Acoustic model construction
</subsectionHeader>
<bodyText confidence="0.999991454545455">
In the acoustics distance approach, models are built
with the top two models chosen from source lan-
guages based on their acoustic distance from the
corresponding native target model. For these ex-
periments, we adopt the widely used Bhat-
tacharyya metric for the distance measurement
(Mak and Barnard 1996). It should be noted that
the recognition performance of the acoustics-
constructed models is not a theoretically strict up-
per bound for HMM similarity because the meas-
urement in the acoustic space is probabilistic.
</bodyText>
<sectionHeader confidence="0.834447" genericHeader="evaluation">
5.4 Results
</sectionHeader>
<bodyText confidence="0.999943">
Each recognition task includes about 3000 utter-
ances of digit strings, command words, and sen-
tences. The word accuracy results in Table 4
include the native baseline performance, i.e. the
performance of the native monolingual, context-
independent models from each target language, as
well as the acoustics-based and feature-based per-
formances. These results show that the perform-
ance of models selected by the CPP phoneme
distance approach is equivalent overall to that of
models selected by acoustic distance.
</bodyText>
<tableCaption confidence="0.99782">
Table 4: Model performance
</tableCaption>
<table confidence="0.999299">
Target Native Acoustic CPP
Language Baseline Distance Distance
Lat. Spanish 94.49 88.61 93.06
Italian 98.42 98.27 98.52
Japanese 95.36 76.72 78.76
Danish 94.36 72.95 70.15
Eur. Portuguese 96.31 77.91 72.74
</table>
<bodyText confidence="0.998808571428571">
The performance of models selected by the CPP
approach nearly matches the performance of the
native models for Latin American Spanish and
surpasses those for Italian. This approach performs
better than the acoustic distance approach for Latin
American Spanish, Italian, and Japanese and not as
well for Danish and European Portuguese.
</bodyText>
<sectionHeader confidence="0.974163" genericHeader="conclusions">
6 Evaluation and conclusion
</sectionHeader>
<bodyText confidence="0.999972785714286">
We suggest four principal performance factors to
explain the results provided in Table 4: (1) rare
phonemes in the target-language inventory; (2)
target-language inventory complexity; (3) degree
of source-language phonological distance to the
target language; (4) reliability of source-language
models. Because the CPP approach has only been
tested on five languages, we consider this analysis
preliminary.
Regarding the first factor, rare phonemes in the
target-language inventory, it is worth noting that
neither Latin American Spanish nor Italian has
phonemes whose exact feature specifications are
unattested in phonemes from other languages in
</bodyText>
<page confidence="0.991745">
8
</page>
<bodyText confidence="0.999989608695652">
our dataset. For these languages, all phonemes
have exact source-language matches. In contrast,
Japanese, Danish, and European Portuguese each
contain phonemes with feature specifications
unique to their language. Based on this analysis,
we propose that, all other factors being equal, the
greater the overall phoneme correspondence be-
tween the target language and the source lan-
guages, the better the target-language HMM
performance.
In general, it appears that target languages as-
sociated with inventories that are greater in size
than their least phonologically distant source lan-
guages perform worse than target languages asso-
ciated with smaller inventories relative to their
closest source languages. For example, the vowel
systems of Danish, European Portuguese, and
Japanese are the most complex of the five target
languages, with Danish having 26 vowels, Euro-
pean Portuguese having 14 vowels, and Japanese
having ten vowels. In sharp contrast, Latin Ameri-
can Spanish has only five vowels and Italian has
seven. Both Latin American Spanish and Italian
are phonologically similar to other Romance lan-
guages in the dataset that have greater vowel con-
trasts: Brazilian Portuguese (13 vowels), European
Portuguese (14 vowels), Parisian French (17 vow-
els) and Canadian French (19 vowels). Here, we
suggest that target languages that have a similar or
lesser number of phoneme contrasts compared to
the source languages are more likely to achieve
higher recognition performances, all other factors
being equal.
Relative phonological distance of the source
languages to the target language and reliability of
source language models additionally impact target-
language ASR performance. Consider Table 5
where the difference in these factors for Italian and
European Portuguese are given. First, Italian and
European Portuguese are both Romance languages
and our dataset includes a total of six, presumably
phonologically similar, Romance languages and
dialects. However, the recognition results of the
models selected by both the feature-based and
acoustics-based phoneme distance method are very
different for the two languages.
</bodyText>
<tableCaption confidence="0.961505">
Table 5: Phonological distance and native baseline per-
formance factors in target-language recognition
</tableCaption>
<figureCaption confidence="0.613380785714286">
Target Language Italian Eur. Portuguese
Top 3 least distant (1) Lat. Spanish (1) Brz. Port.
langs. (2) Parisian Fr. (2) Lat. Spanish
(3) Brz. Port. (3) Canadian Fr.
Avg. phonolog. 0.7399 0.8945
distance of top 3
langs.
Avg. phonolog. 0.5757 0.8248
distance of top 1
lang.
Avg. native base- 89 91.94
line of top 3 langs.
Native baseline of 94.49 84.25
top 1 lang.
</figureCaption>
<bodyText confidence="0.99999165625">
If we compare the phonological distances between
the least distant source languages to Italian and
European Portuguese, we observe that Italian’s
closest languages are less distant overall than
European Portuguese’s closest languages.
Because the phonologically least distant source
languages contribute the majority of target-
language HMMs, it is reasonable to expect that
lesser phonological distance to the target language
by a greater number of source languages is likely
to result in a better target-language HMM per-
formance, all other factors being equal.
Finally, note the substantial discrepancy in na-
tive baseline performance between the phonologi-
cally least distant source languages for Italian and
European Portuguese. The majority of selected
models for Italian derive from Latin American
Spanish which is associated with a high native rec-
ognition baseline. European Portuguese models,
on the other hand, largely come from Brazilian
Portuguese which has a much lower native base-
line. This suggests that the most reliable source-
language HMMs, as judged from their native rec-
ognition performance, contribute to better target-
language recognition performance, all other fac-
tors being equal.
In future work, we intend to test our CPP pho-
neme similarity approach on new target languages
and expand the preliminary evaluation provided
here. In particular, we are interested to what extent
this method can predict recognition performance
for new target languages.
</bodyText>
<page confidence="0.997311">
9
</page>
<sectionHeader confidence="0.988842" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998869959183673">
Archangeli, D., “Aspects of Underspecification The-
ory”. Phonology 5:183-207, 1988.
Connolly, J. H., “Quantifying target-realization differ-
ences,” Clinical Linguistics &amp; Phonetics, 11:267–
298, 1997.
IPA, Handbook of the International Phonetic Associa-
tion, Oxford University Press, 1999.
Kessler, B., “Computational dialectology in Irish
Gaelic,” Proc. 6th Conf. European Chapter of ACL,
60–67, 1995.
Kessler, B., “Phonetic comparison algorithms,” Trans-
actions of the Philological Society, 2005
Köhler J., “Multilingual phoneme recognition exploiting
acoustic-phonetic similarities of sounds,” ICSLP’96,
2195-2198, Philadelphia, 1996.
Kondrak, G., Algorithms for Language Reconstruction,
Ph.D. thesis, University of Toronto, 2002.
Ladefoged P., “The measurement of phonetic similar-
ity,” Int Conf on Comp Linguistics, Stockholm, Swe-
den, 1969.
Ladefoged P. A Course in Phonetics. Harcourt Brace
Jovanovich, New York, 1975.
Liu, C. and Melnar, L., “An automated linguistic
knowledge-based cross-language transfer method for
building acoustic models for a language without na-
tive training data,” Interspeech’05, 1365-1368, Lis-
bon, 2005.
Liu, C. and Melnar, L., “Training acoustic models with
speech data from different languages,”
MULTILING’06, Stellenbosch, 2006.
Mak, B. and Barnard, E., “Phone clustering using the
Bhattacharyya distance,” ICSLP’96, 2005-2008,
1996.
Nerbonne, J. and Heeringa, W., “Measuring dialect dis-
tance phonetically,” Proc. 3rd Meeting ACL Special
Interest Group in Comp. Phonology, 1997.
Schultz, T. and Waibel, A., “Fast bootstrapping of
LVCSR systems with multilingual phoneme sets,”
Eurospeech 97, 1:371-373, 1997.
Schultz, T. and Waibel, A.., “Polyphone Decision Tree
Specialization for Language Adaptation”, In Proc. of
ICASSP 2000. Istanbul, 2000.
Somers, H. L., “Similarity metrics for aligning chil-
dren’s articulation data,” Proc. 36th Annual Meeting
ACL and 17th Int. Conf. Comp. Ling., 1227–1231,
1998.
Sooful, J. J. and Botha, E. C., “Comparison of acoustic
distance measures for automatic cross-language pho-
neme mapping,” ICSLP’02, 521-524, 2002.
</reference>
<page confidence="0.997726">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.899806">
<title confidence="0.9853545">Combined Phonetic-Phonological Approach to Estimating Language Phoneme Similarity in an ASR Environment</title>
<author confidence="0.911822">Lynette Melnar Chen Liu</author>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Archangeli</author>
</authors>
<title>Aspects of Underspecification Theory”.</title>
<date>1988</date>
<pages>5--183</pages>
<publisher>Phonology</publisher>
<contexts>
<context position="4909" citStr="Archangeli 1988" startWordPosition="670" endWordPosition="671">er 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspecified (Archangeli 1988). However, it is unclear from the literature whether allophony is explicitly addressed in the current feature-based approaches to phoneme similarity. A strategy for specifying allophony and characterizing phonetic distance between phonemes is only one component in predicting phoneme similarity among diverse languages without acoustic data in an ASR environment. Because HMMs represent phonemes and significant allophones in a language-dependent context, it is necessary to consider the overall constructed target-language HMM system. Thus phonological distance quantities that regulate the priority</context>
</contexts>
<marker>Archangeli, 1988</marker>
<rawString>Archangeli, D., “Aspects of Underspecification Theory”. Phonology 5:183-207, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Connolly</author>
</authors>
<title>Quantifying target-realization differences,”</title>
<date>1997</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<volume>11</volume>
<pages>298</pages>
<contexts>
<context position="4286" citStr="Connolly 1997" startWordPosition="587" endWordPosition="588">can offer is the most typical phonetic realization of that phoneme. Not surprisingly, label-based cross-language transfer experiments have produced poor performance results. In contrast to the subjective, label-based strategy, researchers in such fields as language reconstruction, dialectometry, and child language development, commonly use automatic featurebased approaches to articulatory similarity between phonemes. In these methods, phonemes are represented by a distinctive feature vector and a phonetic distance or similarity algorithm is used to align phoneme strings between related words (Connolly 1997; Kessler 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspec</context>
</contexts>
<marker>Connolly, 1997</marker>
<rawString>Connolly, J. H., “Quantifying target-realization differences,” Clinical Linguistics &amp; Phonetics, 11:267– 298, 1997.</rawString>
</citation>
<citation valid="true">
<date>1999</date>
<booktitle>IPA, Handbook of the International Phonetic Association,</booktitle>
<publisher>University Press,</publisher>
<location>Oxford</location>
<marker>1999</marker>
<rawString>IPA, Handbook of the International Phonetic Association, Oxford University Press, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kessler</author>
</authors>
<title>Computational dialectology in Irish Gaelic,”</title>
<date>1995</date>
<booktitle>Proc. 6th Conf. European Chapter of ACL,</booktitle>
<pages>60--67</pages>
<contexts>
<context position="4300" citStr="Kessler 1995" startWordPosition="589" endWordPosition="590">e most typical phonetic realization of that phoneme. Not surprisingly, label-based cross-language transfer experiments have produced poor performance results. In contrast to the subjective, label-based strategy, researchers in such fields as language reconstruction, dialectometry, and child language development, commonly use automatic featurebased approaches to articulatory similarity between phonemes. In these methods, phonemes are represented by a distinctive feature vector and a phonetic distance or similarity algorithm is used to align phoneme strings between related words (Connolly 1997; Kessler 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspecified (Archang</context>
</contexts>
<marker>Kessler, 1995</marker>
<rawString>Kessler, B., “Computational dialectology in Irish Gaelic,” Proc. 6th Conf. European Chapter of ACL, 60–67, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kessler</author>
</authors>
<title>Phonetic comparison algorithms,”</title>
<date>2005</date>
<journal>Transactions of the Philological Society,</journal>
<contexts>
<context position="15408" citStr="Kessler 2005" startWordPosition="2222" endWordPosition="2223">mance Canadian Fr. Romance Italian Romance Dutch Germanic Brz. Port. Romance Eur. Port. Romance Table 3 reveals that Germanic languages tend to only occasionally aspirate /k/, Romance languages avoid aspirating /k/, and Sinitic languages typically aspirate /k/. Of course, closely related languages tend to be phonologically similar. 3 Phonetic distance Most techniques for measuring phonetic distance between phonemes that do not assume speech data availability are based on articulatory features, though perceptual distance, judged (subjective) distance, and historical distance are also attested (Kessler 2005). We base our phonetic distance measurement on articulatory features because of their cross-linguistic consistency and general availability. As Kessler notes, standard phonological theory provides no guidance in comparing phonetic distance between phonemes across multiple features (Kessler 2005). In our experiments to date, we use the Manhattan distance where the distance between phonemes equals the sum of the absolute values of individual feature distances. This approach is fairly standard in the literature, though the Euclidean distance has also been reported to attain good results (Kessler </context>
</contexts>
<marker>Kessler, 2005</marker>
<rawString>Kessler, B., “Phonetic comparison algorithms,” Transactions of the Philological Society, 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Köhler</author>
</authors>
<title>Multilingual phoneme recognition exploiting acoustic-phonetic similarities of sounds,”</title>
<date>1996</date>
<booktitle>ICSLP’96,</booktitle>
<pages>2195--2198</pages>
<location>Philadelphia,</location>
<contexts>
<context position="1525" citStr="Köhler 1996" startWordPosition="208" endWordPosition="209">esources for these languages are subsequently either limited or completely unavailable. Hence a knowledge-based phoneme distance metric potentially has great value in acoustic modeling for resource-limited languages in that it can predict cross-language HMM similarity in the absence of target-language speech data. Knowledge-based approaches to HMM similarity generally attempt to identify articulatory similarity between phonemes across languages. The typical strategy is subjective and label-based, where two phonemes are judged to be more or less similar depending on their transcription labels (Köhler 1996; Schultz and Waibel 1997, 2000). A label-based approach suffers for two obvious reasons. First, phone inventories designed for speech technology applications are predominantly phonemic in orientation. Thus, transcription labels do not transfer with the same phonetic value to other languages, even where international phonetic transcription labels are employed. In a phonemic transcription strategy, transcription labels are genAbstract This paper presents a fully automated linguistic approach to measuring distance between phonemes across languages. In this approach, a phoneme is represented by a</context>
</contexts>
<marker>Köhler, 1996</marker>
<rawString>Köhler J., “Multilingual phoneme recognition exploiting acoustic-phonetic similarities of sounds,” ICSLP’96, 2195-2198, Philadelphia, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kondrak</author>
</authors>
<title>Algorithms for Language Reconstruction,</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Toronto,</institution>
<contexts>
<context position="4320" citStr="Kondrak 2002" startWordPosition="592" endWordPosition="593">tic realization of that phoneme. Not surprisingly, label-based cross-language transfer experiments have produced poor performance results. In contrast to the subjective, label-based strategy, researchers in such fields as language reconstruction, dialectometry, and child language development, commonly use automatic featurebased approaches to articulatory similarity between phonemes. In these methods, phonemes are represented by a distinctive feature vector and a phonetic distance or similarity algorithm is used to align phoneme strings between related words (Connolly 1997; Kessler 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspecified (Archangeli 1988). However, </context>
<context position="16313" citStr="Kondrak (2002)" startWordPosition="2352" endWordPosition="2353">2005). In our experiments to date, we use the Manhattan distance where the distance between phonemes equals the sum of the absolute values of individual feature distances. This approach is fairly standard in the literature, though the Euclidean distance has also been reported to attain good results (Kessler 2005). Because features are known to differ in relative importance (Ladefoged 1969), some researchers apply weights or saliencies to the individual features for distance calculation. Nerbonne and Heeringa (1997), for example, weighted each feature by information gain, or entropy reduction. Kondrak (2002) expressed weights as coefficients that could 4 be changed to any numeric value. He adjusted the coefficients until he achieved optimal performance on aligning cognate words. In our approach, weights are derived from the lexica of all the considered languages. Specifically, the value of a weight for a feature is derived from the frequency of the feature in the lexica. Each language is treated equally in this approach; thus, the weights are not subject to the relative size of a language’s lexicon. Because our phoneme specification method incorporates hierarchical relations between features, fea</context>
</contexts>
<marker>Kondrak, 2002</marker>
<rawString>Kondrak, G., Algorithms for Language Reconstruction, Ph.D. thesis, University of Toronto, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ladefoged</author>
</authors>
<title>The measurement of phonetic similarity,”</title>
<date>1969</date>
<booktitle>Int Conf on Comp Linguistics,</booktitle>
<location>Stockholm, Sweden,</location>
<contexts>
<context position="16091" citStr="Ladefoged 1969" startWordPosition="2320" endWordPosition="2321"> because of their cross-linguistic consistency and general availability. As Kessler notes, standard phonological theory provides no guidance in comparing phonetic distance between phonemes across multiple features (Kessler 2005). In our experiments to date, we use the Manhattan distance where the distance between phonemes equals the sum of the absolute values of individual feature distances. This approach is fairly standard in the literature, though the Euclidean distance has also been reported to attain good results (Kessler 2005). Because features are known to differ in relative importance (Ladefoged 1969), some researchers apply weights or saliencies to the individual features for distance calculation. Nerbonne and Heeringa (1997), for example, weighted each feature by information gain, or entropy reduction. Kondrak (2002) expressed weights as coefficients that could 4 be changed to any numeric value. He adjusted the coefficients until he achieved optimal performance on aligning cognate words. In our approach, weights are derived from the lexica of all the considered languages. Specifically, the value of a weight for a feature is derived from the frequency of the feature in the lexica. Each la</context>
</contexts>
<marker>Ladefoged, 1969</marker>
<rawString>Ladefoged P., “The measurement of phonetic similarity,” Int Conf on Comp Linguistics, Stockholm, Sweden, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ladefoged</author>
</authors>
<title>A Course in Phonetics.</title>
<date>1975</date>
<publisher>Harcourt Brace Jovanovich,</publisher>
<location>New York,</location>
<contexts>
<context position="9842" citStr="Ladefoged 1975" startWordPosition="1372" endWordPosition="1373">ary feature is defined as a feature that supplements a primary feature in the system. The corollary features mark “occasionality” (associated with context dependency, dialectal variation, speech style variation, etc.) in the primary feature as either present or absent. 2.2 Primary and corollary features Our feature set includes twenty-six primary articulatory features and six corollary features. The selected primary features conform to a typical set of hierarchically-related distinctive features (e.g. syllabic, sonorant, consonantal, labial, coronal, nasal, continuant, high, low, back, etc.) (Ladefoged 1975). In this hierarchical system, the presence of one feature presupposes the presence of those hierarchically dominant features. For example, the presence of the feature [alveolar] requires the presence of the feature [coronal], and the presence of the feature [nasal] requires the presence of the feature [sonorant]. Significantly, the reverse of these relations is not true. As is explained later in the next section, this feature structure allows for a linguistically-principled determination of feature salience in phonetic distance calculation. Corollary features are restricted to specifying thos</context>
</contexts>
<marker>Ladefoged, 1975</marker>
<rawString>Ladefoged P. A Course in Phonetics. Harcourt Brace Jovanovich, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Liu</author>
<author>L Melnar</author>
</authors>
<title>An automated linguistic knowledge-based cross-language transfer method for building acoustic models for a language without native training data,”</title>
<date>2005</date>
<booktitle>Interspeech’05,</booktitle>
<pages>1365--1368</pages>
<location>Lisbon,</location>
<contexts>
<context position="5878" citStr="Liu and Melnar 2005" startWordPosition="806" endWordPosition="809"> environment. Because HMMs represent phonemes and significant allophones in a language-dependent context, it is necessary to consider the overall constructed target-language HMM system. Thus phonological distance quantities that regulate the priority of source languages for phoneme selection in accordance to their phonological similarity to the target language are also in order. In this paper, we describe an automated, combined phonetic-phonological (CPP) approach to estimating phoneme similarity across languages in ASR. Elsewhere, we provide the phonetic and phonological distance algorithms (Liu and Melnar 2005, 2006), though offer little linguistic justification of the approach or evaluation of the experiment results due to space limitations. Here, we focus on explaining the linguistic principles behind the algorithms and analyzing the results. The CPP approach is fundamentally based on articulatory phonetic features and is designed to handle allophonic variation. Feature salience and phonetic distance are automatically calculated and phoneme distance is constrained by statisticallyderived phonological similarity biases. Unlike other distinctive feature-based approaches to phoneme similarity, phono</context>
</contexts>
<marker>Liu, Melnar, 2005</marker>
<rawString>Liu, C. and Melnar, L., “An automated linguistic knowledge-based cross-language transfer method for building acoustic models for a language without native training data,” Interspeech’05, 1365-1368, Lisbon, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Liu</author>
<author>L Melnar</author>
</authors>
<title>Training acoustic models with speech data from different languages,” MULTILING’06,</title>
<date>2006</date>
<location>Stellenbosch,</location>
<marker>Liu, Melnar, 2006</marker>
<rawString>Liu, C. and Melnar, L., “Training acoustic models with speech data from different languages,” MULTILING’06, Stellenbosch, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mak</author>
<author>E Barnard</author>
</authors>
<title>Phone clustering using the Bhattacharyya distance,”</title>
<date>1996</date>
<booktitle>ICSLP’96,</booktitle>
<pages>2005--2008</pages>
<contexts>
<context position="30817" citStr="Mak and Barnard 1996" startWordPosition="4874" endWordPosition="4877">guages. A phoneme distance score is calculated for each target phoneme and the top two candidate sourcelanguage phonemes are chosen for HMM model construction. We conducted experiments with Italian, Latin American Spanish, European Portuguese, Japanese, and Danish as target languages. 5.3 Acoustic model construction In the acoustics distance approach, models are built with the top two models chosen from source languages based on their acoustic distance from the corresponding native target model. For these experiments, we adopt the widely used Bhattacharyya metric for the distance measurement (Mak and Barnard 1996). It should be noted that the recognition performance of the acousticsconstructed models is not a theoretically strict upper bound for HMM similarity because the measurement in the acoustic space is probabilistic. 5.4 Results Each recognition task includes about 3000 utterances of digit strings, command words, and sentences. The word accuracy results in Table 4 include the native baseline performance, i.e. the performance of the native monolingual, contextindependent models from each target language, as well as the acoustics-based and feature-based performances. These results show that the per</context>
</contexts>
<marker>Mak, Barnard, 1996</marker>
<rawString>Mak, B. and Barnard, E., “Phone clustering using the Bhattacharyya distance,” ICSLP’96, 2005-2008, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nerbonne</author>
<author>W Heeringa</author>
</authors>
<title>Measuring dialect distance phonetically,”</title>
<date>1997</date>
<booktitle>Proc. 3rd Meeting ACL Special Interest Group in Comp. Phonology,</booktitle>
<contexts>
<context position="4348" citStr="Nerbonne and Heeringa 1997" startWordPosition="594" endWordPosition="597">n of that phoneme. Not surprisingly, label-based cross-language transfer experiments have produced poor performance results. In contrast to the subjective, label-based strategy, researchers in such fields as language reconstruction, dialectometry, and child language development, commonly use automatic featurebased approaches to articulatory similarity between phonemes. In these methods, phonemes are represented by a distinctive feature vector and a phonetic distance or similarity algorithm is used to align phoneme strings between related words (Connolly 1997; Kessler 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspecified (Archangeli 1988). However, it is unclear from the liter</context>
<context position="16219" citStr="Nerbonne and Heeringa (1997)" startWordPosition="2336" endWordPosition="2340">eory provides no guidance in comparing phonetic distance between phonemes across multiple features (Kessler 2005). In our experiments to date, we use the Manhattan distance where the distance between phonemes equals the sum of the absolute values of individual feature distances. This approach is fairly standard in the literature, though the Euclidean distance has also been reported to attain good results (Kessler 2005). Because features are known to differ in relative importance (Ladefoged 1969), some researchers apply weights or saliencies to the individual features for distance calculation. Nerbonne and Heeringa (1997), for example, weighted each feature by information gain, or entropy reduction. Kondrak (2002) expressed weights as coefficients that could 4 be changed to any numeric value. He adjusted the coefficients until he achieved optimal performance on aligning cognate words. In our approach, weights are derived from the lexica of all the considered languages. Specifically, the value of a weight for a feature is derived from the frequency of the feature in the lexica. Each language is treated equally in this approach; thus, the weights are not subject to the relative size of a language’s lexicon. Beca</context>
</contexts>
<marker>Nerbonne, Heeringa, 1997</marker>
<rawString>Nerbonne, J. and Heeringa, W., “Measuring dialect distance phonetically,” Proc. 3rd Meeting ACL Special Interest Group in Comp. Phonology, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schultz</author>
<author>A Waibel</author>
</authors>
<title>Fast bootstrapping of LVCSR systems with multilingual phoneme sets,”</title>
<date>1997</date>
<journal>Eurospeech</journal>
<volume>97</volume>
<pages>1--371</pages>
<contexts>
<context position="1550" citStr="Schultz and Waibel 1997" startWordPosition="210" endWordPosition="213">these languages are subsequently either limited or completely unavailable. Hence a knowledge-based phoneme distance metric potentially has great value in acoustic modeling for resource-limited languages in that it can predict cross-language HMM similarity in the absence of target-language speech data. Knowledge-based approaches to HMM similarity generally attempt to identify articulatory similarity between phonemes across languages. The typical strategy is subjective and label-based, where two phonemes are judged to be more or less similar depending on their transcription labels (Köhler 1996; Schultz and Waibel 1997, 2000). A label-based approach suffers for two obvious reasons. First, phone inventories designed for speech technology applications are predominantly phonemic in orientation. Thus, transcription labels do not transfer with the same phonetic value to other languages, even where international phonetic transcription labels are employed. In a phonemic transcription strategy, transcription labels are genAbstract This paper presents a fully automated linguistic approach to measuring distance between phonemes across languages. In this approach, a phoneme is represented by a feature matrix where fea</context>
</contexts>
<marker>Schultz, Waibel, 1997</marker>
<rawString>Schultz, T. and Waibel, A., “Fast bootstrapping of LVCSR systems with multilingual phoneme sets,” Eurospeech 97, 1:371-373, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schultz</author>
<author>A Waibel</author>
</authors>
<title>Polyphone Decision Tree Specialization for Language Adaptation”,</title>
<date>2000</date>
<booktitle>In Proc. of ICASSP</booktitle>
<location>Istanbul,</location>
<contexts>
<context position="20818" citStr="Schultz and Waibel 2000" startWordPosition="3142" endWordPosition="3145">ration is especially desirable in an ASR environment because ultimately HMMs corresponding to those sourcelanguage phonemes predicted to be most similar to L i=1 ∑ j =1, L ,J J I l ∑∑ Il ∑ c p i v i j l l [ ( )] ( , ) l 5 target-language phonemes must interact in a system that is intended to reflect a single target language. Use of phonological metrics then ensures that the overall model pool will have a bias toward a reduced set of phonologically similar languages, and it is reasonable to expect that similarity in languages of the model pool provides consistency in the target HMM system (see Schultz and Waibel 2000). In this section, we define two distance metrics to characterize cross-language phonological similarity. One is based on monophoneme inventories while the other is based on biphoneme inventories. 4.1 Monophoneme distribution distance Monophoneme distribution distance characterizes the difference in lexical phoneme distribution between two languages. Specifically, the distribution, or normalized histogram, of the phonemes is obtained from a large lexicon of a language, with the probability in the distribution corresponding to the frequency of a phoneme in the lexicon. We derive the distributio</context>
</contexts>
<marker>Schultz, Waibel, 2000</marker>
<rawString>Schultz, T. and Waibel, A.., “Polyphone Decision Tree Specialization for Language Adaptation”, In Proc. of ICASSP 2000. Istanbul, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H L Somers</author>
</authors>
<title>Similarity metrics for aligning children’s articulation data,”</title>
<date>1998</date>
<booktitle>Proc. 36th Annual Meeting ACL and 17th Int. Conf. Comp.</booktitle>
<location>Ling., 1227–1231,</location>
<contexts>
<context position="4362" citStr="Somers 1998" startWordPosition="598" endWordPosition="599">isingly, label-based cross-language transfer experiments have produced poor performance results. In contrast to the subjective, label-based strategy, researchers in such fields as language reconstruction, dialectometry, and child language development, commonly use automatic featurebased approaches to articulatory similarity between phonemes. In these methods, phonemes are represented by a distinctive feature vector and a phonetic distance or similarity algorithm is used to align phoneme strings between related words (Connolly 1997; Kessler 1995, 2005; Kondrak 2002; Nerbonne and Heeringa 1997; Somers 1998). Significantly, in these approaches, phonological similarity is generally assumed. In principle, the feature-based approach to phonetic distance admits more precise specification of phonemes because it supports allophonic variance. For example, a standard feature-based approach to allophony representation restricts feature inclusion to only those features relevant to all realizations of the phoneme. Another common approach retains features that are relevant to all allophonic variants, but leaves their values underspecified (Archangeli 1988). However, it is unclear from the literature whether </context>
</contexts>
<marker>Somers, 1998</marker>
<rawString>Somers, H. L., “Similarity metrics for aligning children’s articulation data,” Proc. 36th Annual Meeting ACL and 17th Int. Conf. Comp. Ling., 1227–1231, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Sooful</author>
<author>E C Botha</author>
</authors>
<title>Comparison of acoustic distance measures for automatic cross-language phoneme mapping,” ICSLP’02,</title>
<date>2002</date>
<pages>521--524</pages>
<marker>Sooful, Botha, 2002</marker>
<rawString>Sooful, J. J. and Botha, E. C., “Comparison of acoustic distance measures for automatic cross-language phoneme mapping,” ICSLP’02, 521-524, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>