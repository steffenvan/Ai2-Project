<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020405">
<title confidence="0.9883475">
Machine learning and features selection for
semi-automatic ICD-9-CM encoding
</title>
<author confidence="0.873565">
Julia Medori Cédrick Fairon
</author>
<affiliation confidence="0.56711">
CENTAL CENTAL
</affiliation>
<address confidence="0.756525">
Université catholique de Louvain Université catholique de Louvain
Place Blaise Pascal, 1 Place Blaise Pascal, 1
1348 Louvain-la-neuve 1348 Louvain-la-neuve
</address>
<email confidence="0.997552">
julia.medori@uclouvain.be cedrick.fairon@uclouvain.be
</email>
<sectionHeader confidence="0.996631" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969">
This paper describes the architecture of an
encoding system which aim is to be implemented
as a coding help at the Cliniques universtaires
Saint-Luc, a hospital in Brussels. This paper
focuses on machine learning methods, more
specifically, on the appropriate set of attributes to
be chosen in order to optimize the results of these
methods. A series of four experiments was
conducted on a baseline method: Naïve Bayes
with varying sets of attributes. These experiments
showed that a first step consisting in the extraction
of information to be coded (such as diseases,
procedures, aggravating factors, etc.) is essential.
It also demonstrated the importance of stemming
features. Restraining the classes to categories
resulted in a recall of 81.1 %.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.956386272727273">
This paper describes a series of experiments
carried out within the framework of the CAPADIS
project.1 This project is the product of a
collaboration between the UCL (Université
catholique de Louvain, Belgium) and the
Cliniques universitaires Saint-Luc. Saint-Luc is
one of the major hospitals in Belgium. Each year,
a team of file clerks processes more than 85,000
patient discharge summaries and assigns to each
of them classification codes taken from the ICD-
9-CM (International Classification of Diseases –
</bodyText>
<footnote confidence="0.867452">
1http://www.iwoib.irisnet.be/PRFB/t10/t10_medori_fr.html
</footnote>
<bodyText confidence="0.99535640625">
Ninth Revision – Clinical modification ) (PMIC,
2005).
The encoding of clinical notes (or patient
discharge summaries) into nomenclatures such as
the International Classification of Diseases (ICD)
is a time-consuming, yet necessary task in
hospitals. This essential process aims at evaluating
the costs and budget in each medical unit. In
Belgium, these data are sent to the National
Health Department so as to compute part of the
hospital’s funding.
Our aim is to help coders with their ever-
growing workload. More and more patients’ stays
need to be encoded while the number of coders
remains the same. Our goal is therefore to develop
an semi-automatic encoding system where the role
of the coders would be to check and complete the
codes provided by the system.
This paper focuses on machine learning
methods as automatic encoding techniques. More
specifically, it focuses on the appropriate set of
attributes to be chosen in order to optimize the
results of these methods.
It will therefore present the structure of the
system and compare the results of different inputs
to the machine learning approach. Section 2 gives
a more detailed description of the objectives of
this project. Section 3 gives an overview of the
architecture of the system: first, the extraction part
will be described, and then, the automatic
encoding stage will be discussed. Section 4 will
focus on the machine learning experiments that
</bodyText>
<page confidence="0.983401">
84
</page>
<note confidence="0.7551555">
Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 84–89,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9989215">
were conducted. The results will be presented and
discussed in sections 5 and 6.
</bodyText>
<sectionHeader confidence="0.993671" genericHeader="introduction">
2 Objectives
</sectionHeader>
<bodyText confidence="0.999853023255814">
Since the early 1990s and the rise of the
computational linguistics field, many scientists
have looked into the possible automation of the
encoding process (Ananiadou and McNaught,
2006; Ceusters et al., 1994; Deville etal., 1996;
Friedman et al., 2004; Sager et al., 1995;
Zweigenbaum et al., 1995). Two different
approaches distinguish themselves from one
another: a symbolic approach as in (Pereira et al.,
2006) and a statistical one. Both methods scored
highly in the “Computational Medicine
Challenge” (CMC) organized by the “National
Library of Medicine” in 2007 (Pestian et al.,
2007): among the best three systems, two
combined a statistic and a symbolic approach and
only one relies only on a symbolic approach. Most
systems participating took a hybrid approach as in
(Farkas and Szarvas, 2008).
During ACL 2007, Aronson (2007) presented
within the framework of the same challenge, four
different approaches, symbolic, statistical and
hybrid. His conclusion was that combining
different methods and approaches performed
better and were more stable than their contributing
methods. Pakhomov (2006) describes Autocoder,
an automatic encoding system implemented at
Mayo Clinic that combines example-based rules
and a machine learning module using Naïve
Bayes.
Within the scope of this challenge, only a
limited number of codes were involved.
The objective of our work is to build such a tool to
help the team of coders from the Cliniques
Universitaires Saint-Luc. Three facts are
noteworthy: the clinical notes we work on are
written in French; they originate from all medical
units; and all the codes from the ICD are used in
the process (around 15,000). Most studies are
limited on at least one of these criteria: most
systems are developed on English as more
language resources are available, and they often
focus on specific types of notes, e.g. the CMC
focused on radiology reports.
</bodyText>
<sectionHeader confidence="0.97799" genericHeader="method">
3 System description
</sectionHeader>
<bodyText confidence="0.9995622">
The system is divided into two units: an extraction
unit which aims at marking up information
considered as relevant in the encoding process,
and an encoding unit which, from extracted
information generates a list of codes.
</bodyText>
<figure confidence="0.649763">
clinical
notes
</figure>
<figureCaption confidence="0.999727">
Figure 1. System structure
</figureCaption>
<bodyText confidence="0.999937916666667">
Extraction: The system aims at reproducing
the work of human coders. Coders first read the
text, extract all the pieces of information that have
to be encoded, and ‘translate’ information into
codes of the ICD-9-CM. The idea behind our tool
is to recreate this process. The main source of
information coders use are the patient discharge
summaries written by doctors summarizing all that
happened during the patient’s stay: diagnoses,
procedures, as well as the aggravating factors, the
patient’s medical history, etc. These files are
electronic documents written in free text with no
specific structure.
We developed a tool which aims at extracting
the necessary information from these texts: terms
referring to diseases but also anatomical terms, the
degree of seriousness or probability of a disease,
aggravating factors such as smoking, allergies, or
other types of information that may influence the
choice of a code.
There are many ways of referring to the same
diagnosis or procedure, we therefore needed to
build specialized dictionaries that would comprise
as many of these wordings as possible. The
</bodyText>
<figure confidence="0.996790142857143">
extraction
Preprocessing
Dictionaries and
linguistic structures
encoding
Matching lists
Code selection
according to
context and
probabilities
Machine learning
module
ICD-9-CM
Morphological
processing
Context analysis
clinical notes
+
ordered list
of codes
Manual checking
</figure>
<page confidence="0.996532">
85
</page>
<bodyText confidence="0.999918">
dictionaries of diseases and procedures were
mainly built automatically using the UMLS and
the classifications in French it comprises. Other
specialized dictionaries (anatomical terms,
medical departments, medications, etc.) were
developed from existing lists. These then were
gradually completed manually as the development
of the extraction tool went on.
However, the plain detection of terms is not
sufficient. It is important to detect in which
context these terms occur. For instance, a
diagnosis that is negated will not be encoded. The
identification of contexts required the use of
finite-state automata and transducers. These
transducers are represented by graphs that
describe the linguistic structures indicating
specific contexts. These graphs were hand crafted
using the UNITEX software tool2 (Paumier,
2003). An example of a graph matching fractures
and sprains is presented in figure 2.3 Each path of
the graph describes a recognized linguistic
structure.
Graphs were also used to broaden the scope of
the terms detected by dictionaries. For instance,
not only do diseases need to be extracted but, to
code, one also needs to know which part of the
body is affected.
Certain types of diagnoses also have to be
described via graphs such as smoking as there are
many ways in which to say that someone smokes
or not. Ex: “he smokes 3 cigarettes a day.” “He
used to smoke.” “Occasionally smokes.” “Heavy
smoker.” “Does not smoke.”
</bodyText>
<footnote confidence="0.962354">
2 http://www-igm.univ-mlv.fr/~unitex/
3 The grey boxes indicate calls to other graphs. Here,
d_localisation is a graph matching anatomical terms.
</footnote>
<bodyText confidence="0.999885872340426">
Our aim was to develop a wide-coverage
system. We therefore focused mainly on the
General Internal Medicine service in order to
develop the grammars and dictionaries. It is a very
diverse department where physicians have to face
all kinds of diseases.
The graphs and dictionaries on which is based
our extraction system were built during the first
phase of the project. A more detailed description
and evaluation of the extraction process can be
found in (Medori, 2008).
Encoding: As was said above, two main
approaches to the encoding problem coexist: the
symbolic approach and the statistical approach.
Both have their benefits and drawbacks. The
symbolic approach is a time-consuming approach
as it involves describing linguistic rules linking
text to diseases. The statistical approach has the
advantage of being fast to compute but the need
for a large amount of data often hampers the use
of these methods. However, both methods give
reliable results, and a combination of both is the
option generally favored. In our context, we chose
to combine both approaches as a large corpus of
clinical notes is at our disposal.
Saint-Luc provided us with a corpus of
166,670 clinical notes. The codes that were
assigned to them by the coders were also
provided. This corpus gives us the chance to
develop and test statistical methods in a ‘real life’
experiment.4
However, whatever the results, we will need to
combine these methods with linguistic rules.
There are two main reasons for this : in the near
future, we will have to face the problem of having
to switch to another classification. The change to
ICD-10-CM is planned for 2015. Therefore, at
that time, we will not have enough learning data to
be able to generate the list of codes in a statistical
manner. The second reason is that there are codes
that are seldom assigned and for which we will
not have enough occurrences in our corpus to be
able to extract them statistically.
This paper focuses on the statistical tests that
were conducted on our corpus. An insight into a
symbolic method using the matching of
morphemes can be found in (Medori, 2008).
</bodyText>
<footnote confidence="0.988266333333333">
4 In this paper, the experiments were conducted on a smaller
corpus. At a later stage, the methods chosen for the final
system will need to be trained on the full corpus.
</footnote>
<figureCaption confidence="0.9952935">
Figure 2. Example of a UNITEX graph matching
patterns such as fractures and sprains.
</figureCaption>
<page confidence="0.990372">
86
</page>
<sectionHeader confidence="0.998608" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.998183382978723">
As a first encoding experiment, we chose to focus
on a baseline machine learning method: Naïve
Bayes. This method has often been used and
proves to be robust.
To conduct this experiment, we used Weka, a
data mining software5 developed at the University
of Waikato. For more information on this tool, see
(Witten, 2004).
In order to test this method we took a sub-set
of 19,994 discharge summaries from the General
Internal Medicine department. In order to test how
necessary the extraction step is, we chose the texts
from the department on which the development of
the extraction rules were based.
These notes were assigned 102,855 codes
which makes up 4,039 distinct codes.
This corpus was then divided into two subsets:
90% of the 19,994 patient discharge summaries
were used as the training corpus and 10% as the
test set.
As with any machine learning method, enough
data for each class is needed in the training set in
order to be able to classify correctly. Therefore,
we built a classifier for each code that was
manually assigned at least 6 times in our corpus.
This resulted in 1,497 classifiers, which means
that we did not have enough data to be able to
assign 2,542 codes which make up 5% of all the
assigned codes.
Four experiments were conducted:
Experiment 1. In our first experiment, the
selected attributes were the terms that were
highlighted as diagnoses by the extraction step.
The diagnoses identified in a negative context
were removed from the features list. These
resulting list of extracted terms went through a
normalization process: accents and stop words
were removed; words were decapitalized.
Experiment 2. The second experiment aimed
at proving the relevance of the stemming of these
terms. The attributes in this experiment were
therefore the terms that were extracted, then
normalized and stemmed using Snowball
Stemmer6 which is an implementation of the
Porter algorithm.
Experiment 3. In this third experiment, we
wanted to check the relevance of the extraction
</bodyText>
<footnote confidence="0.9912555">
5 http://www.cs.waikato.ac.nz/~ml/weka/
6 http://snowball.tartarus.org/
</footnote>
<bodyText confidence="0.999075068181818">
process (see experiments 1 and 2). Therefore, the
attributes comprised all the words contained in the
clinical notes apart from stop words. The words
were stemmed in the same way as the extracted
terms in experiment 2.
Experiment 4. In all the previous experiments,
the classes to be assigned consisted in codes. In
this experiment, classes are reduced to categories
of codes: represented by the first three digits of a
code. The attributes are the same as in experiment
1: extracted terms (non-stemmed). As the system
is designed as a coding help i.e. its aim is to
generate a list of suggested codes, and not as a
fully automated encoding system, one could
imagine listing categories of codes instead of
codes themselves and then let the coders look up
in the hierarchy for the appropriate code within
the selected category.
At the end of each experiment, we end up with
a list of the 1,497 codes from ICD-9-CM ordered
by their Naïve Bayes score for each letter.
The measure that is most interesting here is the
recall. The list of suggested codes needs to
comprise most of the codes the coder will need so
that he/she does not have to go elsewhere to find
the appropriate code. Therefore, we kept three
measures of recall. It is important to keep the list
of codes to be presented to the user short and
manageable. Larkey and Croft (1995) used the
same measures and set the limit number of codes
to 20. This choice is arbitrary but seems like a
sensible limit. In Saint-Luc, the maximum number
of codes a file clerk can assign to a patient
discharge summary is 26 (the principal diagnosis
is assigned the letter A and all the other codes are
ordered according to the other letters of the
alphabet). However, few reports are actually
assigned 26 codes (15 out of 19,994). The average
number of codes assigned by the file clerks in our
set of 19,994 discharge summaries is 6.2.
The three measures of recall are Recall10,
Recall15 and Recall20 which are the measures of
micro averaged recall if we show the first 10, 15
and 20 most likely codes respectively.7
</bodyText>
<footnote confidence="0.668530666666667">
7 It should be noted that we keep in the list of suggested codes
all the codes that tie last with the 10th, 15th and 20th position
respectively.
</footnote>
<page confidence="0.99928">
87
</page>
<sectionHeader confidence="0.999835" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.9905815">
The results of the experiments described above are
detailed in figure 3.
</bodyText>
<table confidence="0.9971165">
Rec10 Rec15 Rec20
1(att: extracted terms) 50.4 56.4 60.5
2 (att: stemmed 56.1 64.1 69.1
extracted terms)
3 (att: all words, 39.1 40.3 41.4
stemmed)
4 (att: extracted terms 64.0 75.1 81.1
classes : categories)
</table>
<figureCaption confidence="0.978512">
Figure 3. Recall for each experiment (in %)
</figureCaption>
<bodyText confidence="0.996694111111111">
Experiment 1. From the results of this baseline
experiment, considering the extracted terms and
retaining the 20 most likely codes according to the
Naïve Bayesian statistics, more than 60% of the
codes manually assigned to the test notes can be
found in this list.
Experiment 2. The stemming of the extracted
terms increased the recall by 8.6%.
Experiment 3. If considering all the words as
attributes, the recall when retaining 20 possible
candidates is around 40% while when attributes
are selected through the extraction process, the
recall increases to 69% which is an increase of
about 28%. This result proves that the extraction
process is an essential step in the system and
clearly improves the performance of the statistical
encoding unit.
Experiment 4. When classes are limited to
categories, Recall20 jumps to 81.1% which is
20.6% more than in experiment 1 which was
conducted with the same attributes but where
classes were codes. This supports our idea that
showing a list of categories instead of codes could
be an interesting alternative for coders: they
would be shown more codes while keeping the list
manageable, and then could browse easily into the
sub-structure of the classification.
</bodyText>
<sectionHeader confidence="0.999151" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999942561403509">
The choice of attributes is important when testing
machine learning methods. In the framework of
the development of an encoding system, we
proved that a first step consisting in selecting the
terms carrying the information that needs to be
encoded is essential. We also showed that the use
of a simple stemming algorithm clearly improves
the performance of the method.
In the last experiment, classifying the clinical
notes by categories of codes resulted in a recall of
81.1%. This reinforces our opinion that, to make
sure that all the needed codes are present for the
coder, we could list categories and let him/her
browse through the codes from there.
It is important to put these results in light of
where the codes originate. Most of the information
that needs to be encoded is present in these
clinical notes. However, even though efforts are
made in order for this to change, many physicians
still do not compile all the information into these
notes. Coders therefore still have to look up into
the whole patient record in order to find additional
codes. The proportion of codes that cannot be
inferred from the clinical notes can be very high.
A study conducted by Sabine Regout, a patient
discharge summary specialist in Saint-Luc, on 250
clinical notes from 25 medical units, showed that
in most departments, 15 to 20% of the codes
assigned by the clerks cannot be inferred from the
notes. This proportion can increase up to 80% in
some surgery departments. This evaluation proves
that without a change of mind-set from the
physicians, our system can only aim to be a
coding help for file clerks. Analyzing all the
different types of documents contained in patient
records would be a difficult task as they comprise
a variety of documents with different structures
and formats, and some of them are hand-written
documents. For our experiments, this also means
that the maximal recall value we will be able to
get is around 80%.
In these experiments, we were not able to
check the inter-annotator agreement but we must
keep in mind that, as in any classification task
where humans set the gold-standard, one must
expect some degree of errors and variation in the
coding.
Another observation influences the maximal
number of codes we will be able to retrieve is that
we built classifiers for all the codes for which we
had enough data. This lead to the building of 1497
classifiers. This represents 95% of all the codes
assigned to our test notes. This decreases our
maximal recall value by 5%.
The codes that are seldom assigned will
therefore never show up in our list of suggested
codes. This is rather problematic and other non-
</bodyText>
<page confidence="0.996121">
88
</page>
<bodyText confidence="0.997443">
statistical methods will be needed to make up for
this.
</bodyText>
<sectionHeader confidence="0.998376" genericHeader="discussions">
7 Future work
</sectionHeader>
<bodyText confidence="0.999983433333333">
In the light of these results, the next step will be to
conduct an experiment on categories as classes
using stemmed extracted terms as features. This
should improve further the 81.1% recall from the
results of experiment 4.
These experiments were conducted in order to
select the right features to be used as attributes for
our machine learning module. We chose Naïve
Bayes as a baseline method. However, other
methods have been tested in previous works
(Larkey and Croft, 1995) and have proved to give
good results as well, such as k-nearest neighbors
or Support Vector Machines.
We saw, at the end of section 6, that symbolic
methods need to be developed in order to assist
machine learning methods. Machine learning
techniques have their limitations: they cannot
assign codes for which they did not have enough
data, and they cannot face the change to a new
nomenclature. Therefore, in the near future we
will have to develop a symbolic module
comprising a series of linguistic rules in order to
do the matching on all codes. A prototype based
on the matching of morphemes has already been
developed but will need to be experimented
further.
The results of the experiments we conducted
on a machine learning method were promising.
Now, combining these two different approaches is
the next challenging task in our project.
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999942111111111">
The CAPADIS project was funded by the
government of the Brussels-Capital Region
(Institute for the encouragement of
Scientific Research and Innovation of Brussels)
within the framework of the &amp;quot;Prospective
research for Brussels 2006&amp;quot; program. I would also
like to thank Benoît Debande, Claire Beguin,
Sabine Regout and the Saint-Luc hospital team of
coders.
</bodyText>
<sectionHeader confidence="0.996456" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999887050847458">
Ananiadou S., McNaught J.: Introduction to Text Mining in
Biology. In Ananiadou S., McNaught J. (eds.) Text
Mining for Biology and Biomedicine, pp 1--12, Artech
House Books (2006).
Aronson A. R.: MetaMap: Mapping Text to the UMLS
Metathesaurus (2006).
Ceusters W., Michel C., Penson D., Mauclet E.: Semi-
automated encoding of diagnoses and medical procedures
combining ICD-9-CM with computational-linguistic tools.
Ann Med Milit Belg;8(2):53—58 (1994).
Deville G., Herbigniaux E., Mousel P., Thienpont G., Wéry
M.: ANTHEM: Advanced Natural Language Interface for
Multilingual Text Generation in Healthcare (1996).
Farkas R., Szarvas G. Automatic construction of rule-based
ICD-9-CM coding systems’, BMC Bioinformatics, 9
(2008).
Friedman C., Shagina L., Lussier Y.A., Hripcsak G.:
Automated encoding of clinical documents based on
natural language processing. J Am Med Inform Assoc.
2004 Sep-Oct;11(5):392--402. Epub 2004 Jun 7 (2004).
Larkey L. S, Croft W. B. Automatic assignment of icd9 codes
to discharge summaries. Technical report, University of
Massachusetts at Amherst, Amherst, MA (1995).
Medori J. From Free Text to ICD: Development of a Coding
Help, In: Proceedings of Louhi 08, Turku, 3-4 sept 2008
(2008).
Pakhomov S. V. S., Buntrock J. D., Chute C. G.: Automating
the Assignment of Diagnosis Codes to Patient Encounters
Using Example-based and Machine Learning Techniques
(2006).
Paumier S. De la reconnaissance de formes linguistiques à
l&apos;analyse syntaxique. PhD thesis. Université de Marne-la-
Vallée (2003).
Practice Management Information Corporation. ICD-9-CM
Hospital Edition, International Classification of Diseases
9th Revision, Clinical Modification (Color-Coded,
Volumes 1-3, Thumb-Indexed) (2005).
Pereira S., Névéol A., Massari P., Joubert M., Darmoni S.J. :
Construction of a semi-automated ICD-10 coding help
system to optimize medical and economic coding. Proc.
MIE. (2006).
Pestian J. P., Brew C., Matykiewicz P.M., Hovermale D.J.,
Johnson N., Cohen K.B., Duch W.: A shared task
involving multi-label classification of clinical free text.
Proceedings of ACL BioNLP; 2007 Jun; Prague (2007).
Sager N., Lyman M., Nhán N., Tick L.: Medical language
processing: Applications to patient data representation and
automatic encoding. Methods of Information in Medicine,
(34):140 -- 146 (1995).
Witten I.H., Frank E. Data Mining: Practical Machine
Learning Tools and Techniques. San Francisco: Morgan
Kaufmann Publishers. 2nd edition. 560 pp. ISBN 0-12-
088407-0 (2005).
Zweigenbaum P. and Consortium MENELAS: MENELAS:
coding and information retrieval from natural language
patient discharge summaries. In Laires M. F., Ladeira M.
J., Christensen J. P., (eds.), Advances in Health
Telematics, pages 82-89. IOS Press, Amsterdam, 1995.
MENELAS Final Edited Progress Report (1995).
</reference>
<page confidence="0.999752">
89
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.261594">
<title confidence="0.9854355">Machine learning and features selection semi-automatic ICD-9-CM encoding</title>
<author confidence="0.995068">Julia Medori Cédrick Fairon</author>
<affiliation confidence="0.9795035">CENTAL CENTAL Université catholique de Louvain Université catholique de Louvain</affiliation>
<address confidence="0.711828">Place Blaise Pascal, 1 Place Blaise Pascal, 1</address>
<abstract confidence="0.947622789473684">1348 Louvain-la-neuve 1348 Louvain-la-neuve julia.medori@uclouvain.be cedrick.fairon@uclouvain.be Abstract This paper describes the architecture of an encoding system which aim is to be implemented a coding help at the universtaires a hospital in Brussels. This paper focuses on machine learning methods, more specifically, on the appropriate set of attributes to be chosen in order to optimize the results of these methods. A series of four experiments was conducted on a baseline method: Naïve Bayes with varying sets of attributes. These experiments showed that a first step consisting in the extraction of information to be coded (such as diseases, procedures, aggravating factors, etc.) is essential. It also demonstrated the importance of stemming features. Restraining the classes to categories resulted in a recall of 81.1 %.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Ananiadou</author>
<author>J McNaught</author>
</authors>
<title>Introduction to Text Mining</title>
<date>2006</date>
<booktitle>Text Mining for Biology and Biomedicine,</booktitle>
<pages>1--12</pages>
<editor>in Biology. In Ananiadou S., McNaught J. (eds.)</editor>
<publisher>Artech House Books</publisher>
<contexts>
<context position="3569" citStr="Ananiadou and McNaught, 2006" startWordPosition="536" endWordPosition="539">on part will be described, and then, the automatic encoding stage will be discussed. Section 4 will focus on the machine learning experiments that 84 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 84–89, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics were conducted. The results will be presented and discussed in sections 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas</context>
</contexts>
<marker>Ananiadou, McNaught, 2006</marker>
<rawString>Ananiadou S., McNaught J.: Introduction to Text Mining in Biology. In Ananiadou S., McNaught J. (eds.) Text Mining for Biology and Biomedicine, pp 1--12, Artech House Books (2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Aronson</author>
</authors>
<title>MetaMap: Mapping Text to the UMLS Metathesaurus</title>
<date>2006</date>
<marker>Aronson, 2006</marker>
<rawString>Aronson A. R.: MetaMap: Mapping Text to the UMLS Metathesaurus (2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ceusters</author>
<author>C Michel</author>
<author>D Penson</author>
</authors>
<title>Mauclet E.: Semiautomated encoding of diagnoses and medical procedures combining ICD-9-CM with computational-linguistic tools.</title>
<date>1994</date>
<journal>Ann Med Milit</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="3592" citStr="Ceusters et al., 1994" startWordPosition="540" endWordPosition="543"> then, the automatic encoding stage will be discussed. Section 4 will focus on the machine learning experiments that 84 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 84–89, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics were conducted. The results will be presented and discussed in sections 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). Du</context>
</contexts>
<marker>Ceusters, Michel, Penson, 1994</marker>
<rawString>Ceusters W., Michel C., Penson D., Mauclet E.: Semiautomated encoding of diagnoses and medical procedures combining ICD-9-CM with computational-linguistic tools. Ann Med Milit Belg;8(2):53—58 (1994).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Deville</author>
<author>E Herbigniaux</author>
<author>P Mousel</author>
<author>G Thienpont</author>
<author>M Wéry</author>
</authors>
<title>ANTHEM: Advanced Natural Language Interface for Multilingual Text Generation in Healthcare</title>
<date>1996</date>
<marker>Deville, Herbigniaux, Mousel, Thienpont, Wéry, 1996</marker>
<rawString>Deville G., Herbigniaux E., Mousel P., Thienpont G., Wéry M.: ANTHEM: Advanced Natural Language Interface for Multilingual Text Generation in Healthcare (1996).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Farkas</author>
<author>G Szarvas</author>
</authors>
<title>Automatic construction of rule-based ICD-9-CM coding systems’,</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="4188" citStr="Farkas and Szarvas, 2008" startWordPosition="634" endWordPosition="637">, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). During ACL 2007, Aronson (2007) presented within the framework of the same challenge, four different approaches, symbolic, statistical and hybrid. His conclusion was that combining different methods and approaches performed better and were more stable than their contributing methods. Pakhomov (2006) describes Autocoder, an automatic encoding system implemented at Mayo Clinic that combines example-based rules and a machine learning module using Naïve Bayes. Within the scope of this challenge, only a limited number of codes were involved. The objective of our work is to build such a tool to he</context>
</contexts>
<marker>Farkas, Szarvas, 2008</marker>
<rawString>Farkas R., Szarvas G. Automatic construction of rule-based ICD-9-CM coding systems’, BMC Bioinformatics, 9 (2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>L Shagina</author>
<author>Y A Lussier</author>
</authors>
<title>Hripcsak G.: Automated encoding of clinical documents based on natural language processing.</title>
<date>2004</date>
<journal>J Am Med Inform Assoc.</journal>
<contexts>
<context position="3636" citStr="Friedman et al., 2004" startWordPosition="547" endWordPosition="550">discussed. Section 4 will focus on the machine learning experiments that 84 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 84–89, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics were conducted. The results will be presented and discussed in sections 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). During ACL 2007, Aronson (2007) presented with</context>
</contexts>
<marker>Friedman, Shagina, Lussier, 2004</marker>
<rawString>Friedman C., Shagina L., Lussier Y.A., Hripcsak G.: Automated encoding of clinical documents based on natural language processing. J Am Med Inform Assoc. 2004 Sep-Oct;11(5):392--402. Epub 2004 Jun 7 (2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Larkey</author>
<author>W B Croft</author>
</authors>
<title>Automatic assignment of icd9 codes to discharge summaries.</title>
<date>1995</date>
<tech>Technical report,</tech>
<institution>University of Massachusetts at Amherst,</institution>
<location>Amherst, MA</location>
<contexts>
<context position="14335" citStr="Larkey and Croft (1995)" startWordPosition="2279" endWordPosition="2282">lves and then let the coders look up in the hierarchy for the appropriate code within the selected category. At the end of each experiment, we end up with a list of the 1,497 codes from ICD-9-CM ordered by their Naïve Bayes score for each letter. The measure that is most interesting here is the recall. The list of suggested codes needs to comprise most of the codes the coder will need so that he/she does not have to go elsewhere to find the appropriate code. Therefore, we kept three measures of recall. It is important to keep the list of codes to be presented to the user short and manageable. Larkey and Croft (1995) used the same measures and set the limit number of codes to 20. This choice is arbitrary but seems like a sensible limit. In Saint-Luc, the maximum number of codes a file clerk can assign to a patient discharge summary is 26 (the principal diagnosis is assigned the letter A and all the other codes are ordered according to the other letters of the alphabet). However, few reports are actually assigned 26 codes (15 out of 19,994). The average number of codes assigned by the file clerks in our set of 19,994 discharge summaries is 6.2. The three measures of recall are Recall10, Recall15 and Recall</context>
<context position="19949" citStr="Larkey and Croft, 1995" startWordPosition="3234" endWordPosition="3237">n our list of suggested codes. This is rather problematic and other non88 statistical methods will be needed to make up for this. 7 Future work In the light of these results, the next step will be to conduct an experiment on categories as classes using stemmed extracted terms as features. This should improve further the 81.1% recall from the results of experiment 4. These experiments were conducted in order to select the right features to be used as attributes for our machine learning module. We chose Naïve Bayes as a baseline method. However, other methods have been tested in previous works (Larkey and Croft, 1995) and have proved to give good results as well, such as k-nearest neighbors or Support Vector Machines. We saw, at the end of section 6, that symbolic methods need to be developed in order to assist machine learning methods. Machine learning techniques have their limitations: they cannot assign codes for which they did not have enough data, and they cannot face the change to a new nomenclature. Therefore, in the near future we will have to develop a symbolic module comprising a series of linguistic rules in order to do the matching on all codes. A prototype based on the matching of morphemes ha</context>
</contexts>
<marker>Larkey, Croft, 1995</marker>
<rawString>Larkey L. S, Croft W. B. Automatic assignment of icd9 codes to discharge summaries. Technical report, University of Massachusetts at Amherst, Amherst, MA (1995).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Medori</author>
</authors>
<title>From Free Text to ICD: Development of a Coding Help, In:</title>
<date>2008</date>
<booktitle>Proceedings of Louhi 08,</booktitle>
<location>Turku,</location>
<contexts>
<context position="9007" citStr="Medori, 2008" startWordPosition="1383" endWordPosition="1384">http://www-igm.univ-mlv.fr/~unitex/ 3 The grey boxes indicate calls to other graphs. Here, d_localisation is a graph matching anatomical terms. Our aim was to develop a wide-coverage system. We therefore focused mainly on the General Internal Medicine service in order to develop the grammars and dictionaries. It is a very diverse department where physicians have to face all kinds of diseases. The graphs and dictionaries on which is based our extraction system were built during the first phase of the project. A more detailed description and evaluation of the extraction process can be found in (Medori, 2008). Encoding: As was said above, two main approaches to the encoding problem coexist: the symbolic approach and the statistical approach. Both have their benefits and drawbacks. The symbolic approach is a time-consuming approach as it involves describing linguistic rules linking text to diseases. The statistical approach has the advantage of being fast to compute but the need for a large amount of data often hampers the use of these methods. However, both methods give reliable results, and a combination of both is the option generally favored. In our context, we chose to combine both approaches </context>
<context position="10651" citStr="Medori, 2008" startWordPosition="1662" endWordPosition="1663">ar future, we will have to face the problem of having to switch to another classification. The change to ICD-10-CM is planned for 2015. Therefore, at that time, we will not have enough learning data to be able to generate the list of codes in a statistical manner. The second reason is that there are codes that are seldom assigned and for which we will not have enough occurrences in our corpus to be able to extract them statistically. This paper focuses on the statistical tests that were conducted on our corpus. An insight into a symbolic method using the matching of morphemes can be found in (Medori, 2008). 4 In this paper, the experiments were conducted on a smaller corpus. At a later stage, the methods chosen for the final system will need to be trained on the full corpus. Figure 2. Example of a UNITEX graph matching patterns such as fractures and sprains. 86 4 Experiment As a first encoding experiment, we chose to focus on a baseline machine learning method: Naïve Bayes. This method has often been used and proves to be robust. To conduct this experiment, we used Weka, a data mining software5 developed at the University of Waikato. For more information on this tool, see (Witten, 2004). In ord</context>
</contexts>
<marker>Medori, 2008</marker>
<rawString>Medori J. From Free Text to ICD: Development of a Coding Help, In: Proceedings of Louhi 08, Turku, 3-4 sept 2008 (2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V S Pakhomov</author>
<author>J D Buntrock</author>
<author>C G Chute</author>
</authors>
<title>Automating the Assignment of Diagnosis Codes to Patient Encounters Using Example-based and Machine Learning Techniques</title>
<date>2006</date>
<marker>Pakhomov, Buntrock, Chute, 2006</marker>
<rawString>Pakhomov S. V. S., Buntrock J. D., Chute C. G.: Automating the Assignment of Diagnosis Codes to Patient Encounters Using Example-based and Machine Learning Techniques (2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Paumier</author>
</authors>
<title>De la reconnaissance de formes linguistiques à l&apos;analyse syntaxique. PhD thesis. Université de Marne-laVallée</title>
<date>2003</date>
<contexts>
<context position="7771" citStr="Paumier, 2003" startWordPosition="1178" endWordPosition="1179">edications, etc.) were developed from existing lists. These then were gradually completed manually as the development of the extraction tool went on. However, the plain detection of terms is not sufficient. It is important to detect in which context these terms occur. For instance, a diagnosis that is negated will not be encoded. The identification of contexts required the use of finite-state automata and transducers. These transducers are represented by graphs that describe the linguistic structures indicating specific contexts. These graphs were hand crafted using the UNITEX software tool2 (Paumier, 2003). An example of a graph matching fractures and sprains is presented in figure 2.3 Each path of the graph describes a recognized linguistic structure. Graphs were also used to broaden the scope of the terms detected by dictionaries. For instance, not only do diseases need to be extracted but, to code, one also needs to know which part of the body is affected. Certain types of diagnoses also have to be described via graphs such as smoking as there are many ways in which to say that someone smokes or not. Ex: “he smokes 3 cigarettes a day.” “He used to smoke.” “Occasionally smokes.” “Heavy smoker</context>
</contexts>
<marker>Paumier, 2003</marker>
<rawString>Paumier S. De la reconnaissance de formes linguistiques à l&apos;analyse syntaxique. PhD thesis. Université de Marne-laVallée (2003).</rawString>
</citation>
<citation valid="true">
<title>Information Corporation. ICD-9-CM Hospital Edition, International Classification of Diseases 9th Revision, Clinical Modification (Color-Coded, Volumes 1-3,</title>
<date>2005</date>
<institution>Practice Management</institution>
<location>Thumb-Indexed</location>
<marker>2005</marker>
<rawString>Practice Management Information Corporation. ICD-9-CM Hospital Edition, International Classification of Diseases 9th Revision, Clinical Modification (Color-Coded, Volumes 1-3, Thumb-Indexed) (2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pereira</author>
<author>A Névéol</author>
<author>P Massari</author>
<author>M Joubert</author>
<author>S J Darmoni</author>
</authors>
<title>Construction of a semi-automated ICD-10 coding help system to optimize medical and economic coding.</title>
<date>2006</date>
<booktitle>Proc.</booktitle>
<location>MIE.</location>
<contexts>
<context position="3799" citStr="Pereira et al., 2006" startWordPosition="572" endWordPosition="575">th Documents, pages 84–89, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics were conducted. The results will be presented and discussed in sections 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). During ACL 2007, Aronson (2007) presented within the framework of the same challenge, four different approaches, symbolic, statistical and hybrid. His conclusion was that combining different methods and approa</context>
</contexts>
<marker>Pereira, Névéol, Massari, Joubert, Darmoni, 2006</marker>
<rawString>Pereira S., Névéol A., Massari P., Joubert M., Darmoni S.J. : Construction of a semi-automated ICD-10 coding help system to optimize medical and economic coding. Proc. MIE. (2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Pestian</author>
<author>C Brew</author>
<author>P M Matykiewicz</author>
<author>D J Hovermale</author>
<author>N Johnson</author>
<author>K B Cohen</author>
<author>W Duch</author>
</authors>
<title>A shared task involving multi-label classification of clinical free text.</title>
<date>2007</date>
<booktitle>Proceedings of ACL BioNLP;</booktitle>
<location>Prague</location>
<contexts>
<context position="3976" citStr="Pestian et al., 2007" startWordPosition="599" endWordPosition="602">ctions 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). During ACL 2007, Aronson (2007) presented within the framework of the same challenge, four different approaches, symbolic, statistical and hybrid. His conclusion was that combining different methods and approaches performed better and were more stable than their contributing methods. Pakhomov (2006) describes Autocoder, an automatic encoding system implemented at Mayo Clinic that com</context>
</contexts>
<marker>Pestian, Brew, Matykiewicz, Hovermale, Johnson, Cohen, Duch, 2007</marker>
<rawString>Pestian J. P., Brew C., Matykiewicz P.M., Hovermale D.J., Johnson N., Cohen K.B., Duch W.: A shared task involving multi-label classification of clinical free text. Proceedings of ACL BioNLP; 2007 Jun; Prague (2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sager</author>
<author>M Lyman</author>
<author>N Nhán</author>
<author>L Tick</author>
</authors>
<title>Medical language processing: Applications to patient data representation and automatic encoding.</title>
<date>1995</date>
<journal>Methods of Information in Medicine,</journal>
<volume>34</volume>
<pages>146</pages>
<contexts>
<context position="3656" citStr="Sager et al., 1995" startWordPosition="551" endWordPosition="554">ll focus on the machine learning experiments that 84 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 84–89, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics were conducted. The results will be presented and discussed in sections 5 and 6. 2 Objectives Since the early 1990s and the rise of the computational linguistics field, many scientists have looked into the possible automation of the encoding process (Ananiadou and McNaught, 2006; Ceusters et al., 1994; Deville etal., 1996; Friedman et al., 2004; Sager et al., 1995; Zweigenbaum et al., 1995). Two different approaches distinguish themselves from one another: a symbolic approach as in (Pereira et al., 2006) and a statistical one. Both methods scored highly in the “Computational Medicine Challenge” (CMC) organized by the “National Library of Medicine” in 2007 (Pestian et al., 2007): among the best three systems, two combined a statistic and a symbolic approach and only one relies only on a symbolic approach. Most systems participating took a hybrid approach as in (Farkas and Szarvas, 2008). During ACL 2007, Aronson (2007) presented within the framework of </context>
</contexts>
<marker>Sager, Lyman, Nhán, Tick, 1995</marker>
<rawString>Sager N., Lyman M., Nhán N., Tick L.: Medical language processing: Applications to patient data representation and automatic encoding. Methods of Information in Medicine, (34):140 -- 146 (1995).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical Machine Learning Tools and Techniques.</title>
<date>2005</date>
<volume>560</volume>
<pages>0--12</pages>
<publisher>Morgan Kaufmann</publisher>
<location>San Francisco:</location>
<marker>Witten, Frank, 2005</marker>
<rawString>Witten I.H., Frank E. Data Mining: Practical Machine Learning Tools and Techniques. San Francisco: Morgan Kaufmann Publishers. 2nd edition. 560 pp. ISBN 0-12-088407-0 (2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Zweigenbaum</author>
</authors>
<title>and Consortium MENELAS: MENELAS: coding and information retrieval from natural language patient discharge summaries.</title>
<date>1995</date>
<booktitle>Advances in Health Telematics,</booktitle>
<pages>82--89</pages>
<editor>In Laires M. F., Ladeira M. J., Christensen J. P., (eds.),</editor>
<publisher>IOS Press,</publisher>
<location>Amsterdam,</location>
<marker>Zweigenbaum, 1995</marker>
<rawString>Zweigenbaum P. and Consortium MENELAS: MENELAS: coding and information retrieval from natural language patient discharge summaries. In Laires M. F., Ladeira M. J., Christensen J. P., (eds.), Advances in Health Telematics, pages 82-89. IOS Press, Amsterdam, 1995. MENELAS Final Edited Progress Report (1995).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>