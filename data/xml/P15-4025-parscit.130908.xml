<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017239">
<title confidence="0.984361">
NiuParser: A Chinese Syntactic and Semantic Parsing Toolkit
</title>
<author confidence="0.764532">
Jingbo Zhu Muhua Zhu ∗ Qiang Wang Tong Xiao
Natural Language Processing Lab.
</author>
<affiliation confidence="0.912596">
Northeastern University
</affiliation>
<email confidence="0.989979">
zhujingbo@mail.neu.edu.cn zhumuhua@gmail.com
wangqiangneu@gmail.com xiaotong@mail.neu.edu.cn
</email>
<sectionHeader confidence="0.993804" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998390625">
We present a new toolkit - NiuParser -
for Chinese syntactic and semantic anal-
ysis. It can handle a wide range of Natural
Language Processing (NLP) tasks in Chi-
nese, including word segmentation, part-
of-speech tagging, named entity recogni-
tion, chunking, constituent parsing, depen-
dency parsing, and semantic role label-
ing. The NiuParser system runs fast and
shows state-of-the-art performance on sev-
eral benchmarks. Moreover, it is very easy
to use for both research and industrial pur-
poses. Advanced features include the Soft-
ware Development Kit (SDK) interfaces
and a multi-thread implementation for sys-
tem speed-up.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994272066666667">
Chinese has been one of the most popular world
languages for years. Due to its complexity and
diverse underlying structures, processing this lan-
guage is a challenging issue and has been clearly
an important part of Natural Language Processing
(NLP). Many tasks are proposed to analyze and
understand Chinese, ranging from word segmen-
tation to syntactic and/or semantic parsing, which
can benefit a wide range of natural language ap-
plications. To date, several systems have been
developed for Chinese word segmentation, part-
of-speech tagging and syntactic parsing (exam-
ples include Stanford CoreNLP1, FudanNLP2, LT-
P3 and etc.) though some of them are not opti-
mized for Chinese.
</bodyText>
<footnote confidence="0.8343055">
∗ This work was done during his Ph.D. study in North-
eastern University.
1http://nlp.stanford.edu/software/
corenlp.shtml
2http://fudannlp.googlecode.com
3http://www.ltp-cloud.com/intro/en/
</footnote>
<bodyText confidence="0.99941">
In this paper we present a new toolkit for
Chinese syntactic and semantic analysis (cal-
l it NiuParser4). Unlike previous systems, the
NiuParser toolkit can handle most of Chinese
parsing-related tasks, including word segmenta-
tion, part-of-speech tagging, named entity recog-
nition, chunking, constituent parsing, dependency
parsing, and semantic role labeling. To the best
of our knowledge we are the first to report that all
seven of these functions are supported in a single
NLP package.
All subsystems in NiuParser are based on sta-
tistical models and are learned automatically from
data. Also, we optimize these systems for Chinese
in several ways, including handcrafted rules used
in pre/post-processing, heuristics used in various
algorithms, and a number of tuned features. The
systems are implemented with C++ and run fast.
On several benchmarks, we demonstrate state-of-
the-art performance in both accuracy/F1 score and
speed.
In addition, NiuParser can be fit into large-scale
tasks which are common in both research-oriented
experiments and industrial applications. Several
useful utilities are distributed with NiuParser, such
as the Software Development Kit (SDK) inter-
faces and a multi-thread implementation for sys-
tem speed-up.
The rest of the demonstration is organized as
follows. Section 2 describes the implementation
details of each subsystem, including statistical ap-
proaches and some enhancements with handcraft-
ed rules and dictionaries. Section 3 represents the
ways to use the toolkit. We also show the perfor-
mance of the system in Section 4 and finally we
conclude the demonstration and point out the fu-
ture work of NiuParser in Section 5.
</bodyText>
<footnote confidence="0.9955735">
4http://www.niuparser.com/index.en.
html
</footnote>
<page confidence="0.936898">
145
</page>
<note confidence="0.720233">
Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 145–150,
Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP
</note>
<figure confidence="0.999619782608695">
Word
Segmentation
Conditional
Random Fields
POS
Tagging
Averaged
Perceptron
Machine Learning Models
NiuParser Subsystems
Named Entity
Recognition
Dependency
Parsing
Constituent
Parsing
Chunking
Maximum
Entropy
Recurrent
Neural Networks
Semantic Role
Labeling
</figure>
<figureCaption confidence="0.999989">
Figure 1: The system architecture of NiuParser.
</figureCaption>
<sectionHeader confidence="0.699158" genericHeader="method">
2 The NiuParser System
</sectionHeader>
<subsectionHeader confidence="0.984502">
2.1 What is NiuParser
</subsectionHeader>
<bodyText confidence="0.99997255">
The NiuParser system is a sentence-level syntactic
and semantic parsing toolkit developed by Natu-
ral Language Processing Laboratory in Northeast-
ern University of China. The system is designed
specifically to process the Chinese language. Sub-
systems of NiuParser include word segmentation,
POS tagging, named entity recognition, shallow
syntactic parsing (chunking), constituent parsing,
dependency parsing, and constituent parse-based
semantic role labeling. Figure 1 shows the archi-
tecture of the NiuParser system. As we can see
from the figure, subsystems in NiuParser are orga-
nized in a pipeline structure. A given sentence is
first segmented into a word sequence, each word
in which is assigned a POS tag by the POS tag-
ging subsystem. Based on the POS tagging result,
we can choose to do named entity recognition or
syntactic parsing. Finally, shallow semantic struc-
tures are generated by semantic role labeling on
the base of constituent parsing.
</bodyText>
<subsectionHeader confidence="0.9978415">
2.2 Statistical Approaches to Subsystems
2.2.1 Sequence Labeling
</subsectionHeader>
<bodyText confidence="0.990473888888889">
The subsystems of word segmentation, POS tag-
ging, named entity recognition, and chunking in
NiuParser are based on statistical sequence label-
ing models. Specifically, we adopt linear-chain
Conditional Random Fields (CRF) (Lafferty et al.,
2001) as the method for sequence labeling. Given
an input sample X = x1, x2, ... , xL and its cor-
responding sequence Y = y1, y2, ... , yL, Condi-
tional Random Fields are defined as follows.
</bodyText>
<equation confidence="0.998555">
Pw(Y |X) = Zw(X)exp(WTΦ(X, Y ))) (1)
1
</equation>
<bodyText confidence="0.999975222222222">
where Zw(X) denotes the normalization constant
and Φ(X, Y ) are manually defined feature func-
tions. In the testing phase, the Viterbi algorithm
is applied to find an optimal label sequence or a
k-best list for a testing instance.
With Conditional Random Fields, Chinese
word segmentation is regarded as a character-
based sequence labeling problem. We adopt the
scheme of six tags (B, B2, B3, I, E, O) to translate
</bodyText>
<page confidence="0.995286">
146
</page>
<bodyText confidence="0.99986496875">
between a segmented sentence and its correspond-
ing label sequence (Zhao et al., 2005). Specifical-
ly, B, B2, B3 denotes the first, the second, and the
third character in a word, respectively. I means
that the character is inside in a word, and E means
that the character is at the end of a word. Finally,
O denotes a single-character word. Features in-
clude the characters (and their combinations) in a
sliding window.
As mentioned above, the NiuParser system uti-
lizes the pipeline method to integrate all the sub-
systems. That is, POS tagging, named enti-
ty recognition, and chunking take the output of
the preceding subsystem as input. For POS tag-
ging, we obtain training data from Penn Chinese
Treebank (CTB) (Xue et al., 2005), which has 32
POS tags. The named entity recognition subsys-
tem takes the guideline of OntoNotes (Pradhan et
al., 2007). Named entities annotated in OntoNotes
have 18 entity types in total, including person
names, organization names, and events, etc. Ta-
ble 1 presents a complete list of the entity types in
OntoNotes. Chunking uses training data derived
from constituent parse trees in CTB. In NiuParser,
we consider phrase types including noun phrase
(NP), verbal phrase (VP), quantifier phrase (QP),
prepositional phrase (PP), adjective phrase (AD-
JP), and classifier phrase (CLP), etc. Features for
the three subsystems are words (and their combi-
nations) in a sliding window. Prefix and suffix of
words are also used as features for better system
generalization.
</bodyText>
<subsubsectionHeader confidence="0.891776">
2.2.2 Transition-based Parsing
</subsubsectionHeader>
<bodyText confidence="0.999985575757576">
Syntactic parsers can be grouped into two cate-
gories according to decoding algorithms: dynam-
ic programming-based and transition-based. For
the purpose of efficiency, we implement the con-
stituent and two versions of dependency parsers in
the NiuParser system with transition-based meth-
ods (Zhu et al., 2013; Zhang and Nivre, 2011;
Chen and Manning, 2014). Specifically, parser-
s are variants of shift-reduce parsers, which start
from an initial state and reach a final state by per-
forming an action in each stage transition. Fig-
ure 2 and Figure 3 present an example parse of the
two parsers, respectively.
One version of the dependency parsers follows
the work in (Chen and Manning, 2014), regarding
the state transition process as a sequence of clas-
sification decisions. In each transition, a best ac-
tion is chosen by a Neural Network classifier. The
other parses (the constituent parser and the other
version of dependency parser) utilize exactly the
same framework, where both training and decod-
ing phases are formalized as a beam search pro-
cess. In the decoding phase, the candidate parse
with the highest score in the beam will be picked
as the parsing result once the beam search process
terminates. In the training phase, a beam search-
based global online training method is adopted.
The training process iterates through the whole
training data by decoding the sentences sequent-
ly. On each sentence, parameters will be updated
immediately once the gold parse is pruned off the
beam. In the NiuParser system, we utilize aver-
aged perceptron to learn parameters.
</bodyText>
<subsubsectionHeader confidence="0.724396">
2.2.3 Two-Stage Classification
</subsubsectionHeader>
<bodyText confidence="0.999943115384615">
Researchers in semantic role labeling have ex-
plored diverse syntactic structures (chunks, con-
stituent parses, and dependency parses) as input.
The semantic role labeling subsystem in NiuPars-
er considers constituent parse trees as input. The
subsystem can recognize constituents in a parse
tree as arguments with respect to a specified pred-
icate (See Figure 4). Here, semantic role labeling
is formalized as a two-stage classification prob-
lem. The first stage (called identification) conduct-
s a binary classification to decide whether a con-
stituent in a parse tree is an argument. After the
first stage, a set of constituents is fed to the sec-
ond stage (called classification) classifier which is
a multi-class classifier, used for assigning each ar-
gument an appropriate semantic label.
The statistical model used in the semantic role
labeling subsystem is Maximum Entropy (Berg-
er et al., 1996), which provides classification de-
cisions with corresponding probabilities. With
such probabilities, the identification stage applies
the algorithm of enforcing non-overlapping argu-
ments (Jiang and Ng, 2006) to maximize the log-
probability of the entire labeled parse tree. In the
classification stage, the classifier assigns labels to
arguments independently.
</bodyText>
<subsectionHeader confidence="0.996232">
2.3 Improvements and Advanced Features
2.3.1 Word Segmentation
</subsectionHeader>
<bodyText confidence="0.999871833333333">
In Chinese sentences, words like dates, email
addresses, and web page URLs are pervasive but
training data for statistical methods is limited
in size to cover enough such words. A purely
statistical approach often fails to recognize such
words once the words do not appear in the training
</bodyText>
<page confidence="0.993674">
147
</page>
<table confidence="0.975835666666667">
PERSON peopel, including fictional NORP nationalities or religious or political groups
FACILITY building, airports, highways, etc. ORGANIZATION companies, agencies, etc.
GPE countries, cities, states LOCATION non-GPE, mountain ranges, bodies of water
PRODUCT vehicles, weapons, foods, etc. EVENT named hurricanes, battles, wars, sports events
WORD OF ART titles or books, songs, etc. LAW named documents made into laws
LANGUAGE named language DATE absolute or relative dates or periods
TIME times smaller than a day PERCENT percentage *including ”%”
MONEY monetary values, including unit QUANTITY measurements, as of weight or distances
ORDINAL ”first”, ”second” CARDINAL numerals that do not fall under another type
</table>
<tableCaption confidence="0.999899">
Table 1: Named entity types in OntoNotes
</tableCaption>
<figure confidence="0.960786333333333">
IP
VP
PP VP
NP VV
%_J:� M to a fT 7(E V_L� ff
OD M NN NN NN P NR VV
</figure>
<figureCaption confidence="0.972898333333333">
Figure 3: Example of dependency parsing in NiuParser.
IP
Figure 4: Example of semantic role labeling in NiuParser.
</figureCaption>
<figure confidence="0.994794571428571">
NMOD
NMOD
M
NMOD
POBJ
SBJ
VMOD
ROOT
NP VP
%4� A, t-A ing&amp;quot;fTTIIF
PP
r± V
VP
VV
</figure>
<bodyText confidence="0.9745801">
be used are specified as command line arguments.
Second, all the functionalities in NiuParser can
be integrated into users’ own applications or busi-
ness process by using the toolkit’s SDK interfaces.
The SDK supports both Windows and Linux plat-
forms. In contrast to web services, SDK is more
suitable to be deployed in the server side.
Third, a demo web page is provided for users
to view the analysis results intuitively.5 All the
analysis results are presented graphically.
</bodyText>
<sectionHeader confidence="0.999112" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9987745">
We ran our system on several benchmarks. Specif-
ically, we trained and tested word segmentation,
POS tagging, chunking, and constituent parsing on
CTB5.1: articles 001-270 and 440-1151 were used
for training and articles 271-300 were used for
testing. The performance of named entity recog-
nition was reported on OntoNotes, where 49,011
sentences were used for training and 1,340 sen-
tences were used for testing. For semantic role
labeling, we adopted the same data set and split-
ting as in (Xue, 2008). Finally, the data set and
splitting in (Zhang and Clark, 2011) were used to
evaluate the performance of dependency parsing.
All results were reported on a machine with a
</bodyText>
<footnote confidence="0.8596095">
5http://demo.niuparser.com/index.en.
html
</footnote>
<bodyText confidence="0.999236769230769">
800MHz CPU and 4GB memory. See Table 2 for
results of acurracy/F1 scores, memory use, mod-
el sizes and speed. Note that we evaluated the
speed with a single thread and the accuracies were
achieved with statistical models only.
From the results we can see that most of the sub-
systems achieve state-of-the-art performance, (the
chunking subsystem is an exception, whose accu-
racy still have some room left for further improve-
ments.). In addition, the memory use of dependen-
cy parsing is extremely heavy. We will optimize
the implementation of dependency parsing in our
future work.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="evaluation">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999865384615385">
We have presented the NiuParser Chinese syntac-
tic and semantic analysis toolkit. It can handle
several parsing tasks for Chinese, including word
segmentation, part-of-speech tagging, named enti-
ty recognition, chunking, constituent parsing, de-
pendency parsing, and constituent parser-based se-
mantic role labeling. The NiuParser system is fast
and shows state-of-the-art performance on sever-
al benchmarks. Moreover, it supports several ad-
vanced features, such as the Software Develop-
ment Kit (SDK) interfaces and the multi-thread
implementation for system speed-up.
In our future work, we will add more function-
</bodyText>
<page confidence="0.997152">
149
</page>
<table confidence="0.999237777777778">
Task Acurrary/F1 Memory Used Model Size Speed*
word segmentation 97.3% 68M 57M 45K
POS tagging 93.5% 93M 185M 38.8K
named entity recognition 88.1% 687M 708M 1.87K
chunking 81.1% 71.9MG 90M 18.8K
constituent parsing 83.2% 0.98G 243M 583.3
dependency parsing† 82.4% 2.9G 116M 402.4
dependency parsing$ 82.1% 597M 22M 13.5K
semantic role labeling 68.4% 1.2M/0.9M 30M 494*
</table>
<tableCaption confidence="0.9534995">
Table 2: Evaluation of NiuParser on various tasks. †beam search-based global training method.
$classification-based method with Neural Networks. *characters per second. * predicates per second.
</tableCaption>
<bodyText confidence="0.9985846">
alities to NiuParser. First of all, we will integrate a
new subsystem which conducts dependency-based
semantic role labeling. In addition, we will de-
velop a faster constituent parsers by using Recur-
rent Neural Network. According to the previous
work (Chen and Manning, 2014) (and its clone
in the NiuParser system), this method reduces the
cost of feature extraction and thus shows the ad-
vantage in speed. We expect the same approach
can be adapted to constituent parsing.
</bodyText>
<sectionHeader confidence="0.982586" genericHeader="conclusions">
Acknowledges
</sectionHeader>
<bodyText confidence="0.987807333333333">
This work was supported in part by the National
Science Foundation of China (Grants 61272376,
61300097, and 61432013).
</bodyText>
<sectionHeader confidence="0.998249" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999851447368421">
Adam L. Berger, Stephen A. Della Pietra, and Vincent
J. Dealla Pietra. 1996. A maximum entropy ap-
proach to natural language processing. Computa-
tional Linguics, 22:39–71.
Danqi Chen and Christopher D. Manning. 2014. A fast
and accurate dependency parser using neural net-
works. Proc. of EMNLP 2014, pages 740–750.
Zheng Ping Jiang and Hwee Tou Ng. 2006. Seman-
tic role labeling of nombank: a maximum entropy
approach. Proc. of EMNLP 2006, pages 138–145.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. Proc. of ICML 2001.
Sameer S. Pradhan, Hovy Eduard, Mitch Mar-
cus, Martha Palmer, Lance Ramshaw, and Ralph
Weischedel. 2007. Ontonotes: A unified relation-
al semantic representation. Proc. of ICSC 2007.
Nianwen Xue, Fei Xia, Chiou Fu-Dong, and Palmer
Martha. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11:207–238.
Nianwen Xue. 2008. Labeling chinese predicates with
semantic roles. Computational Linguistics, 32:225–
255.
Yue Zhang and Stephen Clark. 2011. Syntactic pro-
cessing using the generalized perceptron and beam
search. Computational Linguistics, 37:105–151.
Yue Zhang and Joakim Nivre. 2011. Transition-
based dependency parsing with rich non-local fea-
tures. Proc. of ACL 2011, pages 188–193.
Hai. Zhao, Chang-Ning Huang, and Mu Li. 2005. An
improved chinese word segmentation system with
conditional randome fileds. Proc. of SIGHAN 2006,
pages 162–165.
Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. A fast and accurate con-
stituent parsing. Proc. of ACL 2013.
</reference>
<page confidence="0.998319">
150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.343014">
<title confidence="0.999863">NiuParser: A Chinese Syntactic and Semantic Parsing Toolkit</title>
<author confidence="0.83157">Zhu Muhua Zhu Wang Tong Xiao</author>
<affiliation confidence="0.8910245">Natural Language Processing Northeastern University</affiliation>
<email confidence="0.6074955">zhujingbo@mail.neu.edu.cnzhumuhua@gmail.comwangqiangneu@gmail.comxiaotong@mail.neu.edu.cn</email>
<abstract confidence="0.994511882352941">We present a new toolkit - NiuParser for Chinese syntactic and semantic analysis. It can handle a wide range of Natural Language Processing (NLP) tasks in Chinese, including word segmentation, partof-speech tagging, named entity recognition, chunking, constituent parsing, dependency parsing, and semantic role labeling. The NiuParser system runs fast and shows state-of-the-art performance on several benchmarks. Moreover, it is very easy to use for both research and industrial purposes. Advanced features include the Software Development Kit (SDK) interfaces and a multi-thread implementation for system speed-up.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Dealla Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguics,</journal>
<pages>22--39</pages>
<contexts>
<context position="9858" citStr="Berger et al., 1996" startWordPosition="1517" endWordPosition="1521">ents in a parse tree as arguments with respect to a specified predicate (See Figure 4). Here, semantic role labeling is formalized as a two-stage classification problem. The first stage (called identification) conducts a binary classification to decide whether a constituent in a parse tree is an argument. After the first stage, a set of constituents is fed to the second stage (called classification) classifier which is a multi-class classifier, used for assigning each argument an appropriate semantic label. The statistical model used in the semantic role labeling subsystem is Maximum Entropy (Berger et al., 1996), which provides classification decisions with corresponding probabilities. With such probabilities, the identification stage applies the algorithm of enforcing non-overlapping arguments (Jiang and Ng, 2006) to maximize the logprobability of the entire labeled parse tree. In the classification stage, the classifier assigns labels to arguments independently. 2.3 Improvements and Advanced Features 2.3.1 Word Segmentation In Chinese sentences, words like dates, email addresses, and web page URLs are pervasive but training data for statistical methods is limited in size to cover enough such words.</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Dealla Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguics, 22:39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danqi Chen</author>
<author>Christopher D Manning</author>
</authors>
<title>A fast and accurate dependency parser using neural networks.</title>
<date>2014</date>
<booktitle>Proc. of EMNLP</booktitle>
<pages>740--750</pages>
<contexts>
<context position="7722" citStr="Chen and Manning, 2014" startWordPosition="1173" endWordPosition="1176">), adjective phrase (ADJP), and classifier phrase (CLP), etc. Features for the three subsystems are words (and their combinations) in a sliding window. Prefix and suffix of words are also used as features for better system generalization. 2.2.2 Transition-based Parsing Syntactic parsers can be grouped into two categories according to decoding algorithms: dynamic programming-based and transition-based. For the purpose of efficiency, we implement the constituent and two versions of dependency parsers in the NiuParser system with transition-based methods (Zhu et al., 2013; Zhang and Nivre, 2011; Chen and Manning, 2014). Specifically, parsers are variants of shift-reduce parsers, which start from an initial state and reach a final state by performing an action in each stage transition. Figure 2 and Figure 3 present an example parse of the two parsers, respectively. One version of the dependency parsers follows the work in (Chen and Manning, 2014), regarding the state transition process as a sequence of classification decisions. In each transition, a best action is chosen by a Neural Network classifier. The other parses (the constituent parser and the other version of dependency parser) utilize exactly the sa</context>
</contexts>
<marker>Chen, Manning, 2014</marker>
<rawString>Danqi Chen and Christopher D. Manning. 2014. A fast and accurate dependency parser using neural networks. Proc. of EMNLP 2014, pages 740–750.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Ping Jiang</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Semantic role labeling of nombank: a maximum entropy approach.</title>
<date>2006</date>
<booktitle>Proc. of EMNLP</booktitle>
<pages>138--145</pages>
<contexts>
<context position="10065" citStr="Jiang and Ng, 2006" startWordPosition="1544" endWordPosition="1547">) conducts a binary classification to decide whether a constituent in a parse tree is an argument. After the first stage, a set of constituents is fed to the second stage (called classification) classifier which is a multi-class classifier, used for assigning each argument an appropriate semantic label. The statistical model used in the semantic role labeling subsystem is Maximum Entropy (Berger et al., 1996), which provides classification decisions with corresponding probabilities. With such probabilities, the identification stage applies the algorithm of enforcing non-overlapping arguments (Jiang and Ng, 2006) to maximize the logprobability of the entire labeled parse tree. In the classification stage, the classifier assigns labels to arguments independently. 2.3 Improvements and Advanced Features 2.3.1 Word Segmentation In Chinese sentences, words like dates, email addresses, and web page URLs are pervasive but training data for statistical methods is limited in size to cover enough such words. A purely statistical approach often fails to recognize such words once the words do not appear in the training 147 PERSON peopel, including fictional NORP nationalities or religious or political groups FACI</context>
</contexts>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic role labeling of nombank: a maximum entropy approach. Proc. of EMNLP 2006, pages 138–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>Proc. of ICML</booktitle>
<contexts>
<context position="5207" citStr="Lafferty et al., 2001" startWordPosition="754" endWordPosition="757">mented into a word sequence, each word in which is assigned a POS tag by the POS tagging subsystem. Based on the POS tagging result, we can choose to do named entity recognition or syntactic parsing. Finally, shallow semantic structures are generated by semantic role labeling on the base of constituent parsing. 2.2 Statistical Approaches to Subsystems 2.2.1 Sequence Labeling The subsystems of word segmentation, POS tagging, named entity recognition, and chunking in NiuParser are based on statistical sequence labeling models. Specifically, we adopt linear-chain Conditional Random Fields (CRF) (Lafferty et al., 2001) as the method for sequence labeling. Given an input sample X = x1, x2, ... , xL and its corresponding sequence Y = y1, y2, ... , yL, Conditional Random Fields are defined as follows. Pw(Y |X) = Zw(X)exp(WTΦ(X, Y ))) (1) 1 where Zw(X) denotes the normalization constant and Φ(X, Y ) are manually defined feature functions. In the testing phase, the Viterbi algorithm is applied to find an optimal label sequence or a k-best list for a testing instance. With Conditional Random Fields, Chinese word segmentation is regarded as a characterbased sequence labeling problem. We adopt the scheme of six tag</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. Proc. of ICML 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer S Pradhan</author>
<author>Hovy Eduard</author>
<author>Mitch Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>Ontonotes: A unified relational semantic representation.</title>
<date>2007</date>
<booktitle>Proc. of ICSC</booktitle>
<contexts>
<context position="6692" citStr="Pradhan et al., 2007" startWordPosition="1016" endWordPosition="1019">ide in a word, and E means that the character is at the end of a word. Finally, O denotes a single-character word. Features include the characters (and their combinations) in a sliding window. As mentioned above, the NiuParser system utilizes the pipeline method to integrate all the subsystems. That is, POS tagging, named entity recognition, and chunking take the output of the preceding subsystem as input. For POS tagging, we obtain training data from Penn Chinese Treebank (CTB) (Xue et al., 2005), which has 32 POS tags. The named entity recognition subsystem takes the guideline of OntoNotes (Pradhan et al., 2007). Named entities annotated in OntoNotes have 18 entity types in total, including person names, organization names, and events, etc. Table 1 presents a complete list of the entity types in OntoNotes. Chunking uses training data derived from constituent parse trees in CTB. In NiuParser, we consider phrase types including noun phrase (NP), verbal phrase (VP), quantifier phrase (QP), prepositional phrase (PP), adjective phrase (ADJP), and classifier phrase (CLP), etc. Features for the three subsystems are words (and their combinations) in a sliding window. Prefix and suffix of words are also used </context>
</contexts>
<marker>Pradhan, Eduard, Marcus, Palmer, Ramshaw, Weischedel, 2007</marker>
<rawString>Sameer S. Pradhan, Hovy Eduard, Mitch Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2007. Ontonotes: A unified relational semantic representation. Proc. of ICSC 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Chiou Fu-Dong</author>
<author>Palmer Martha</author>
</authors>
<title>The penn chinese treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<pages>11--207</pages>
<contexts>
<context position="6573" citStr="Xue et al., 2005" startWordPosition="996" endWordPosition="999">3 denotes the first, the second, and the third character in a word, respectively. I means that the character is inside in a word, and E means that the character is at the end of a word. Finally, O denotes a single-character word. Features include the characters (and their combinations) in a sliding window. As mentioned above, the NiuParser system utilizes the pipeline method to integrate all the subsystems. That is, POS tagging, named entity recognition, and chunking take the output of the preceding subsystem as input. For POS tagging, we obtain training data from Penn Chinese Treebank (CTB) (Xue et al., 2005), which has 32 POS tags. The named entity recognition subsystem takes the guideline of OntoNotes (Pradhan et al., 2007). Named entities annotated in OntoNotes have 18 entity types in total, including person names, organization names, and events, etc. Table 1 presents a complete list of the entity types in OntoNotes. Chunking uses training data derived from constituent parse trees in CTB. In NiuParser, we consider phrase types including noun phrase (NP), verbal phrase (VP), quantifier phrase (QP), prepositional phrase (PP), adjective phrase (ADJP), and classifier phrase (CLP), etc. Features for</context>
</contexts>
<marker>Xue, Xia, Fu-Dong, Martha, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Chiou Fu-Dong, and Palmer Martha. 2005. The penn chinese treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11:207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<pages>255</pages>
<contexts>
<context position="12582" citStr="Xue, 2008" startWordPosition="1953" endWordPosition="1954">s to view the analysis results intuitively.5 All the analysis results are presented graphically. 3 Experiments We ran our system on several benchmarks. Specifically, we trained and tested word segmentation, POS tagging, chunking, and constituent parsing on CTB5.1: articles 001-270 and 440-1151 were used for training and articles 271-300 were used for testing. The performance of named entity recognition was reported on OntoNotes, where 49,011 sentences were used for training and 1,340 sentences were used for testing. For semantic role labeling, we adopted the same data set and splitting as in (Xue, 2008). Finally, the data set and splitting in (Zhang and Clark, 2011) were used to evaluate the performance of dependency parsing. All results were reported on a machine with a 5http://demo.niuparser.com/index.en. html 800MHz CPU and 4GB memory. See Table 2 for results of acurracy/F1 scores, memory use, model sizes and speed. Note that we evaluated the speed with a single thread and the accuracies were achieved with statistical models only. From the results we can see that most of the subsystems achieve state-of-the-art performance, (the chunking subsystem is an exception, whose accuracy still have</context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling chinese predicates with semantic roles. Computational Linguistics, 32:225– 255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Syntactic processing using the generalized perceptron and beam search.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<pages>37--105</pages>
<contexts>
<context position="12646" citStr="Zhang and Clark, 2011" startWordPosition="1962" endWordPosition="1965"> analysis results are presented graphically. 3 Experiments We ran our system on several benchmarks. Specifically, we trained and tested word segmentation, POS tagging, chunking, and constituent parsing on CTB5.1: articles 001-270 and 440-1151 were used for training and articles 271-300 were used for testing. The performance of named entity recognition was reported on OntoNotes, where 49,011 sentences were used for training and 1,340 sentences were used for testing. For semantic role labeling, we adopted the same data set and splitting as in (Xue, 2008). Finally, the data set and splitting in (Zhang and Clark, 2011) were used to evaluate the performance of dependency parsing. All results were reported on a machine with a 5http://demo.niuparser.com/index.en. html 800MHz CPU and 4GB memory. See Table 2 for results of acurracy/F1 scores, memory use, model sizes and speed. Note that we evaluated the speed with a single thread and the accuracies were achieved with statistical models only. From the results we can see that most of the subsystems achieve state-of-the-art performance, (the chunking subsystem is an exception, whose accuracy still have some room left for further improvements.). In addition, the mem</context>
</contexts>
<marker>Zhang, Clark, 2011</marker>
<rawString>Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search. Computational Linguistics, 37:105–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transitionbased dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>Proc. of ACL</booktitle>
<pages>188--193</pages>
<contexts>
<context position="7697" citStr="Zhang and Nivre, 2011" startWordPosition="1169" endWordPosition="1172">repositional phrase (PP), adjective phrase (ADJP), and classifier phrase (CLP), etc. Features for the three subsystems are words (and their combinations) in a sliding window. Prefix and suffix of words are also used as features for better system generalization. 2.2.2 Transition-based Parsing Syntactic parsers can be grouped into two categories according to decoding algorithms: dynamic programming-based and transition-based. For the purpose of efficiency, we implement the constituent and two versions of dependency parsers in the NiuParser system with transition-based methods (Zhu et al., 2013; Zhang and Nivre, 2011; Chen and Manning, 2014). Specifically, parsers are variants of shift-reduce parsers, which start from an initial state and reach a final state by performing an action in each stage transition. Figure 2 and Figure 3 present an example parse of the two parsers, respectively. One version of the dependency parsers follows the work in (Chen and Manning, 2014), regarding the state transition process as a sequence of classification decisions. In each transition, a best action is chosen by a Neural Network classifier. The other parses (the constituent parser and the other version of dependency parse</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transitionbased dependency parsing with rich non-local features. Proc. of ACL 2011, pages 188–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang-Ning Huang Zhao</author>
<author>Mu Li</author>
</authors>
<title>An improved chinese word segmentation system with conditional randome fileds.</title>
<date>2005</date>
<booktitle>Proc. of SIGHAN</booktitle>
<pages>162--165</pages>
<marker>Zhao, Li, 2005</marker>
<rawString>Hai. Zhao, Chang-Ning Huang, and Mu Li. 2005. An improved chinese word segmentation system with conditional randome fileds. Proc. of SIGHAN 2006, pages 162–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Muhua Zhu</author>
<author>Yue Zhang</author>
<author>Wenliang Chen</author>
<author>Min Zhang</author>
<author>Jingbo Zhu</author>
</authors>
<title>A fast and accurate constituent parsing.</title>
<date>2013</date>
<booktitle>Proc. of ACL</booktitle>
<contexts>
<context position="7674" citStr="Zhu et al., 2013" startWordPosition="1165" endWordPosition="1168">ier phrase (QP), prepositional phrase (PP), adjective phrase (ADJP), and classifier phrase (CLP), etc. Features for the three subsystems are words (and their combinations) in a sliding window. Prefix and suffix of words are also used as features for better system generalization. 2.2.2 Transition-based Parsing Syntactic parsers can be grouped into two categories according to decoding algorithms: dynamic programming-based and transition-based. For the purpose of efficiency, we implement the constituent and two versions of dependency parsers in the NiuParser system with transition-based methods (Zhu et al., 2013; Zhang and Nivre, 2011; Chen and Manning, 2014). Specifically, parsers are variants of shift-reduce parsers, which start from an initial state and reach a final state by performing an action in each stage transition. Figure 2 and Figure 3 present an example parse of the two parsers, respectively. One version of the dependency parsers follows the work in (Chen and Manning, 2014), regarding the state transition process as a sequence of classification decisions. In each transition, a best action is chosen by a Neural Network classifier. The other parses (the constituent parser and the other vers</context>
</contexts>
<marker>Zhu, Zhang, Chen, Zhang, Zhu, 2013</marker>
<rawString>Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. 2013. A fast and accurate constituent parsing. Proc. of ACL 2013.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>