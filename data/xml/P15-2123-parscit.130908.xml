<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.990261">
Lifelong Learning for Sentiment Classification
</title>
<author confidence="0.998179">
Zhiyuan Chen, Nianzu Ma, Bing Liu
</author>
<affiliation confidence="0.99904">
Department of Computer Science
University of Illinois at Chicago
</affiliation>
<email confidence="0.993964">
{czyuanacm,jingyima005}@gmail.com,liub@cs.uic.edu
</email>
<sectionHeader confidence="0.997317" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999332">
This paper proposes a novel lifelong learn-
ing (LL) approach to sentiment classifica-
tion. LL mimics the human continuous
learning process, i.e., retaining the knowl-
edge learned from past tasks and use it
to help future learning. In this paper, we
first discuss LL in general and then LL for
sentiment classification in particular. The
proposed LL approach adopts a Bayesian
optimization framework based on stochas-
tic gradient descent. Our experimental re-
sults show that the proposed method out-
performs baseline methods significantly,
which demonstrates that lifelong learning
is a promising research direction.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999291869565218">
Sentiment classification is the task of classifying
an opinion document as expressing a positive or
negative sentiment. Liu (2012) and Pang and Lee
(2008) provided good surveys of the existing re-
search. In this paper, we tackle sentiment clas-
sification from a novel angle, lifelong learning
(LL), or lifelong machine learning. This learn-
ing paradigm aims to learn as humans do: re-
taining the learned knowledge from the past and
use the knowledge to help future learning (Thrun,
1998, Chen and Liu, 2014b, Silver et al., 2013).
Although many machine learning topics and
techniques are related to LL, e.g., lifelong learn-
ing (Thrun, 1998, Chen and Liu, 2014b, Silver et
al., 2013), transfer learning (Jiang, 2008, Pan and
Yang, 2010), multi-task learning (Caruana, 1997),
never-ending learning (Carlson et al., 2010), self-
taught learning (Raina et al., 2007), and online
learning (Bottou, 1998), there is still no unified
definition for LL.
Based on the prior work and our research, to
build an LL system, we believe that we need to
answer the following key questions:
</bodyText>
<listItem confidence="0.956770285714286">
1. What information should be retained from the
past learning tasks?
2. What forms of knowledge will be used to help
future learning?
3. How does the system obtain the knowledge?
4. How does the system use the knowledge to help
future learning?
</listItem>
<bodyText confidence="0.990163125">
Motivated by these questions, we present the
following definition of lifelong learning (LL).
Definition (Lifelong Learning): A learner has
performed learning on a sequence of tasks, from
1 to N − 1. When faced with the Nth task, it uses
the knowledge gained in the past N − 1 tasks to
help learning for the Nth task. An LL system thus
needs the following four general components:
</bodyText>
<listItem confidence="0.980449695652174">
1. Past Information Store (PIS): It stores the in-
formation resulted from the past learning. This
may involve sub-stores for information such as
(1) the original data used in each past task, (2)
intermediate results from the learning of each
past task, and (3) the final model or patterns
learned from the past task, respectively.
2. Knowledge Base (KB): It stores the knowledge
mined or consolidated from PIS (Past Informa-
tion Store). This requires a knowledge repre-
sentation scheme suitable for the application.
3. Knowledge Miner (KM). It mines knowledge
from PIS (Past Information Store). This min-
ing can be regarded as a meta-learning process
because it learns knowledge from information
resulted from learning of the past tasks. The
knowledge is stored to KB (Knowledge Base).
4. Knowledge-Based Learner (KBL): Given the
knowledge in KB, this learner is able to lever-
age the knowledge and/or some information in
PIS for the new task.
Based on this, we can define lifelong sentiment
classification (LSC):
</listItem>
<subsectionHeader confidence="0.450864">
Definition (Lifelong Sentiment Classification):
</subsectionHeader>
<bodyText confidence="0.805009">
A learner has performed a sequence of supervised
</bodyText>
<page confidence="0.837036">
750
</page>
<bodyText confidence="0.966422872727272">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 750–756,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
sentiment classification tasks, from 1 to N − 1,
where each task consists of a set of training doc-
uments with positive and negative polarity labels.
Given the Nth task, it uses the knowledge gained
in the past N − 1 tasks to learn a better classifier
for the Nth task.
It is useful to note that although many re-
searchers have used transfer learning for super-
vised sentiment classification, LL is different from
the classic transfer learning or domain adapta-
tion (Pan and Yang, 2010). Transfer learning typi-
cally uses labeled training data from one (or more)
source domain(s) to help learning in the target do-
main that has little or no labeled data (Aue and
Gamon, 2005, Bollegala et al., 2011). It does not
use the results of the past learning or knowledge
mined from the results of the past learning. Fur-
ther, transfer learning is usually inferior to tradi-
tional supervised learning when the target domain
already has good training data. In contrast, our
target (or future) domain/task has good training
data and we aim to further improve the learning
using both the target domain training data and the
knowledge gained in past learning. To be consis-
tent with prior research, we treat the classification
of one domain as one learning task.
One question is why the past learning tasks can
contribute to the target domain classification given
that the target domain already has labeled training
data. The key reason is that the training data may
not be fully representative of the test data due to
the sample selection bias (Heckman, 1979, Shi-
modaira, 2000, Zadrozny, 2004). In few real-life
applications, the training data are fully represen-
tative of the test data. For example, in a senti-
ment classification application, the test data may
contain some sentiment words that are absent in
the training data of the target domain, while these
sentiment words have appeared in some past do-
mains. So the past domain knowledge can provide
the prior polarity information in this situation.
Like most existing sentiment classification pa-
pers (Liu, 2012), this paper focuses on binary clas-
sification, i.e., positive (+) and negative (−) polar-
ities. But the proposed method is also applicable
to multi-class classification. To embed and use the
knowledge in building the target domain classifier,
we propose a novel optimization method based on
the Naive Bayesian (NB) framework and stochas-
tic gradient descent. The knowledge is incorpo-
rated using penalty terms in the optimization for-
mulation. This paper makes three contributions:
</bodyText>
<listItem confidence="0.97349925">
1. It proposes a novel lifelong learning approach
to sentiment classification, called lifelong sen-
timent classification (LSC).
2. It proposes an optimization method that uses
penalty terms to embed the knowledge gained
in the past and to deal with domain dependent
sentiment words to build a better classifier.
3. It creates a large corpus containing reviews
</listItem>
<bodyText confidence="0.58626">
from 20 diverse product domains for extensive
evaluation. The experimental results demon-
strate the superiority of the proposed method.
</bodyText>
<sectionHeader confidence="0.999755" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999985621621622">
Our work is mainly related to lifelong learning
and multi-task learning (Thrun, 1998, Caruana,
1997, Chen and Liu, 2014b, Silver et al., 2013).
Existing lifelong learning approaches focused on
exploiting invariances (Thrun, 1998) and other
types of knowledge (Chen and Liu, 2014b, Chen
and Liu, 2014a, Ruvolo and Eaton, 2013) across
multiple tasks. Multi-task learning optimizes the
learning of multiple related tasks at the same
time (Caruana, 1997, Chen et al., 2011, Saha et al.,
2011, Zhang et al., 2008). However, these meth-
ods are not for sentiment analysis. Also, our naive
Bayesian optimization based LL method is quite
different from all these existing techniques.
Our work is also related to transfer learning or
domain adaptation (Pan and Yang, 2010). In the
sentiment classification context, Aue and Gamon
(2005) trained sentiment classifiers for the target
domain using various mixes of labeled and un-
labeled reviews. Blitzer et al. (2007) proposed to
first find some common or pivot features from the
source and the target, and then identify correlated
features with the pivot features. The final classifier
is built using the combined features. Li and Zong
(2008) built a meta-classifier (called CLF) using
the outputs of each base classifier constructed in
each domain. Other works along similar lines
include (Andreevskaia and Bergler, 2008, Bol-
legala et al., 2011, He et al., 2011, Ku et al.,
2009, Li et al., 2012, Li et al., 2013, Pan and Yang,
2010, Tan et al., 2007, Wu et al., 2009, Xia and
Zong, 2011, Yoshida et al., 2011). Additional de-
tails about these and other related works can be
found in (Liu, 2012). However, as we discussed
in the introduction, these methods do not focus on
the ability to accumulate learned knowledge and
leverage it in new learning in a lifelong manner.
</bodyText>
<page confidence="0.996315">
751
</page>
<sectionHeader confidence="0.996803" genericHeader="method">
3 Proposed LSC Technique
</sectionHeader>
<subsectionHeader confidence="0.999337">
3.1 Naive Bayesian Text Classification
</subsectionHeader>
<bodyText confidence="0.992752666666667">
Before presenting the proposed method, we briefly
review the Naive Bayesian (NB) text classification
as our method uses it as the foundation.
NB text classification (McCallum and Nigam,
1998) basically computes the conditional proba-
bility of each word w given each class cj (i.e.,
P (w|cj)) and the prior probability of each class
cj (i.e., P(cj)), which are used to calculate the
posterior probability of each class cj given a test
document d (i.e., P(cj|d)). cj is either positive
(+) or negative (−) in our case.
The key parameter P(w|cj) is computed as:
</bodyText>
<equation confidence="0.989998333333333">
(1)
A|V  |+ E|V |
v=1 Ncj,v
</equation>
<bodyText confidence="0.999329333333333">
where Ncj,w is the frequency of word w in docu-
ments of class cj. |V  |is the size of vocabulary V
and A (0 ≤ A ≤ 1) is used for smoothing.
</bodyText>
<subsectionHeader confidence="0.998821">
3.2 Components in LSC
</subsectionHeader>
<bodyText confidence="0.9999335">
This subsection describes our proposed method
corresponding to the proposed LL components.
</bodyText>
<listItem confidence="0.574952">
1. Past Information Store (PIS): In this work, we
</listItem>
<bodyText confidence="0.9517379">
do not store the original data used in the past
learning tasks, but only their results. For each
past learning task ˆt, we store a) Pˆt(w|+) and
Pˆt(w|−) for each word w which are from task
ˆt’s NB classifier (see Eq 1); and b) the number
of times that w appears in a positive (+) doc-
ument Nˆt+,w and the number of times that w
appears in a negative documents Nˆt−,w.
2. Knowledge Base (KB): Our knowledge base
contains two types of knowledge:
</bodyText>
<listItem confidence="0.971775809523809">
(a) Document-level knowledge NKB
+,w (and
NKB
−,w): number of occurrences of w in
the documents of the positive (and nega-
tive) class in the past tasks, i.e., NKB
+,w =
Etˆ Nˆt+,w and NKB
−,w = Etˆ Nˆt−,w.
(b) Domain-level knowledge MKB
+,w (and
MKB
−,w): number of past tasks in
which P(w|+) &gt; P(w|−) (and
P(w|+) &lt; P(w|−)).
3. Knowledge Miner (KM). Knowledge miner is
straightforward as it just performs counting and
aggregation of information in PIS to generate
knowledge (see 2(a) and 2(b) above).
4. Knowledge-Based Learner (KBL): This learner
incorporates knowledge using regularization as
</listItem>
<bodyText confidence="0.8960695">
penalty terms in our optimization. See the de-
tails in 3.4.
</bodyText>
<subsectionHeader confidence="0.994361">
3.3 Objective Function
</subsectionHeader>
<bodyText confidence="0.999334">
In this subsection, we introduce the objective func-
tion used in our method. The key parameters that
affect NB classification results are P(w|cj) which
are computed using empirical counts of word w
with class cj, i.e., Ncj,w (Eq. 1). In binary classifi-
cation, they are N+,w and N−,w. This suggests
that we can revise these counts appropriately to
improve classification. In our optimization, we
denote the optimized variables X+,w and X−,w
as the number of times that a word w appears in
the positive and negative class. We called them
virtual counts to distinguish them from empirical
counts N+,w and N−,w. For correct classification,
ideally, we should have the posterior probability
P(cj|di) = 1 for labeled class cj, and for the other
class cf, we should have P(cf|di) = 0. Formally,
given a new domain training data Dt, our objective
function is:
</bodyText>
<equation confidence="0.706421">
(P (cj|di) − P (cf|di)) (2)
</equation>
<bodyText confidence="0.997850125">
Here cj is the actual labeled class of di ∈ Dt.
In this paper, we use stochastic gradient descent
(SGD) to optimize on the classification of each
document di ∈ Dt. Due to the space limit, we
only show the optimization process for a positive
document (the process for a negative document is
similar). The objective function under SGD for a
positive document is:
</bodyText>
<equation confidence="0.998294">
F+,i = P (+|di) − P(−|di) (3)
</equation>
<bodyText confidence="0.998488">
To further save space, we omit the derivation
steps and give the final derivatives below (See the
detailed derivation steps in the separate supple-
mentary note):
</bodyText>
<equation confidence="0.977616777777778">
λ |V  |+ P|V  |!|di|
v=1 X+,v
g (X) = (4)
λ |V  |+ P|V |
v=1 X−,v
nu,di Q �λ+X−,w �nw,di × ∂g
λ+X+,u + P(−)
P(+) w∈di λ+X+,w ∂X+,u
Q �λ+X−,w
1 + P (−) �nw,di × g(X)
P(+) w∈di λ+X+,w
nu,di
λ + X+,u
(5)
u,di∂g
λ+X−,u × g(X) + ∂X−,u
= ( λ+X+,w ) nw,di
P(+) Q+ g(X) (6) w∈di λ+X−,w
A + Nc, w
P (w|cj) =
j
� |Dt|
i=1
∂F+,i =
∂X+,u
∂F+,i
∂X−,u
</equation>
<page confidence="0.977173">
752
</page>
<table confidence="0.9997448">
Alarm Clock 30.51 Flashlight 11.69 Home Theater System 28.84 Projector 20.24
Baby 16.45 GPS 19.50 Jewelry 12.21 Rice Cooker 18.64
Bag 11.97 Gloves 13.76 Keyboard 22.66 Sandal 12.11
Cable Modem 12.53 Graphics Card 14.58 Magazine Subscriptions 26.88 Vacuum 22.07
Dumbbell 16.04 Headphone 20.99 Movies TV 10.86 Video Games 20.93
</table>
<tableCaption confidence="0.99984">
Table 1: Names of the 20 product domains and the proportion of negative reviews in each domain.
</tableCaption>
<bodyText confidence="0.976944857142857">
where nu,di is the term frequency of word u in
document di. X denotes all the variables consist-
ing of X+,w and X−,w for each word w. The par-
tial derivatives for a word u, i.e., ∂g ∂X+,u and∂g
∂X−,u,
are quite straightforward and thus not shown here.
X0+,w = Nt+,w+NKB
+,w and X0 −,w = Nt −,w+NKB
−,w
are served as a reasonable starting point for SGD,
where Nt+,w and Nt−,w are the empirical counts of
word w and classes + and − from domain Dt, and
NKB
+,w and NKB
−,w are from knowledge KB (Sec-
tion 3.2). The SGD runs iteratively using the fol-
lowing rules for the positive document di until
convergence, i.e., when the difference of Eq. 2 for
two consecutive iterations is less than 1e−3 (same
for the negative document), where γ is the learning
rate:
</bodyText>
<equation confidence="0.56884">
Xl Xl−1− ∂F+,iXl Xl−1−γ ∂F+,i
+,u+,uγ 7_U_−,uaX+&apos;� ∂X−,u
</equation>
<subsectionHeader confidence="0.890821">
3.4 Exploiting Knowledge via Penalty Terms
</subsectionHeader>
<bodyText confidence="0.997524555555556">
The above optimization is able to update the vir-
tual counts for a better classification in the target
domain. However, it does not deal with the issue
of domain dependent sentiment words, i.e., some
words may change the polarity across different do-
mains. Nor does it utilize the domain-level knowl-
edge in the knowledge base KB (Section 3.2). We
thus propose to add penalty terms into the opti-
mization to accomplish these.
The intuition here is that if a word w can dis-
tinguish classes very well from the target domain
training data, we should rely more on the target
domain training data in computing counts related
to w. So we define a set of words VT that consists
of distinguishable target domain dependent words.
A word w belongs to VT if P(w|+) is much larger
or much smaller than P(w|−) in the target do-
main, i.e., P (w|+)
</bodyText>
<equation confidence="0.727496">
P (w|−) ≥ Q or P (w|−)
P (w|+) ≥ Q, where Q
</equation>
<bodyText confidence="0.998396142857143">
is a parameter. Such words are already effective
in classification for the target domain, so the vir-
tual counts in optimization should follow the em-
pirical counts (Nt+,w and Nt− w) in the target do-
main, which are reflected in the L2 regularization
penalty term below (α is the regularization coeffi-
cient):
</bodyText>
<equation confidence="0.995705">
1 X 2α t 2 t 2
wEVT (X+,w − N+,w~ + (X−,w − N−,w~ (7)
</equation>
<bodyText confidence="0.9579575">
To leverage domain-level knowledge (the sec-
ond type of knowledge in KB in Section 3.2), we
want to utilize only those reliable parts of knowl-
edge. The rationale here is that if a word only
appears in one or two past domains, the knowl-
edge associated with it is probably not reliable or
it is highly specific to those domains. Based on
it, we use domain frequency to define the relia-
bility of the domain-level knowledge. For w, if
MKB
</bodyText>
<equation confidence="0.740251">
+,w ≥ T or MKB
</equation>
<bodyText confidence="0.939514166666667">
−,w ≥ T (T is a parameter), we
regard it as appearing in a reasonable number of
domains, making its knowledge reliable. We de-
note the set of such words as VS. Then we add the
second penalty term as follows:
where the ratio Rw is defined as MKB
</bodyText>
<equation confidence="0.449247666666667">
+,w/(MKB
+,w +
MKB
</equation>
<bodyText confidence="0.9998005">
−,w). X0+,w and X0 −,w are the starting points for
SGD (Section 3.3). Finally, we revise the partial
derivatives in Eqs. 4-6 by adding the correspond-
ing partial derivatives of Eqs. 7 and 8 to them.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999854857142857">
Datasets. We created a large corpus contain-
ing reviews from 20 types of diverse products
or domains crawled from Amazon.com (i.e., 20
datasets). The names of product domains are
listed in Table 1. Each domain contains 1,000 re-
views. Following the existing work of other re-
searchers (Blitzer et al., 2007, Pang et al., 2002),
we treat reviews with rating &gt; 3 as positive and
reviews with rating &lt; 3 as negative. The datasets
are publically available at the authors websites.
Natural class distribution: We keep the natural
(or skewed) distribution of the positive and nega-
tive reviews to experiment with the real-life situa-
tion. F1-score is used due to the imbalance.
</bodyText>
<equation confidence="0.8341903">
1 � 2α
w∈VS
1 �
+ 2α
w∈VS
0 2
(X+,w − Rw × X+,w)
(X−,w − (1 − Rw) × X0 )2
−,w
(8)
</equation>
<page confidence="0.9964">
753
</page>
<table confidence="0.9953295">
NB-T NB-S NB-ST SVM-T SVM-S SVM-ST CLF LSC
56.21 57.04 60.61 57.82 57.64 61.05 12.87 67.00
</table>
<tableCaption confidence="0.9876745">
Table 2: Natural class distribution: Average F1-score of the negative class over 20 domains. Negative
class is the minority class and thus harder to classify.
</tableCaption>
<table confidence="0.9985725">
NB-T NB-S NB-ST SVM-T SVM-S SVM-ST CLF LSC
80.15 77.35 80.85 78.45 78.20 79.40 80.49 83.34
</table>
<tableCaption confidence="0.999555">
Table 3: Balanced class distribution: Average accuracy over 20 domains for each system.
</tableCaption>
<bodyText confidence="0.9567416">
Balanced class distribution: We also created a
balance dataset with 200 reviews (100 positive and
100 negative) in each domain dataset. This set is
smaller because of the small number of negative
reviews in each domain. Accuracy is used for eval-
uation in this balanced setting.
We used unigram features with no feature se-
lection in classification. We followed (Pang et al.,
2002) to deal with negation words. For evalua-
tion, each domain is treated as the target domain
with the rest 19 domains as the past domains. All
the models are evaluated using 5-fold cross vali-
dation.
Baselines. We compare our proposed LSC
model with Naive Bayes (NB), SVM1, and
CLF (Li and Zong, 2008). Note that NB and SVM
can only work on a single domain data. To have
a comprehensive comparison, they are fed with
three types of training data:
a) labeled training data from the target domain
only, denoted by NB-T and SVM-T;
b) labeled training data from all past source do-
mains only, denoted by NB-S and SVM-S;
c) merged (labeled) training data from all past do-
mains and the target domain, referred to as NB-
ST and SVM-ST.
For LSC, we empirically set σ = 6 and T = 6.
The learning rate A and regularization coefficient
α are set to 0.1 empirically. A is set to 1 for
(Laplace) smoothing.
Table 2 shows the average F1-scores for the
negative class in the natural class distribution, and
Table 3 shows the average accuracies in the bal-
anced class distribution. We can clearly see that
our proposed model LSC achieves the best perfor-
mance in both cases. In general, NB-S (and SVM-
S) are worse than NB-T (and SVM-T), both of
which are worse than NB-ST (and SVM-ST). This
shows that simply merging both past domains and
the target domain data is slightly beneficial. Note
</bodyText>
<footnote confidence="0.981576">
1http://www.csie.ntu.edu.tw/˜cjlin/libsvm/
</footnote>
<figureCaption confidence="0.9170595">
Figure 1: (Left): Negative class F1-score of LSC
with #past domains in natural class distribution.
(Right): Accuracy of LSC with #past domains in
balanced class distribution.
</figureCaption>
<bodyText confidence="0.999788263157895">
that the average F1-score for the positive class is
not shown as all classifiers perform very well be-
cause the positive class is the majority class (while
our model performs slightly better than the base-
lines). The improvements of the proposed LSC
model over all baselines in both cases are statisti-
cally significant using paired t-test (p &lt; 0.01 com-
pared to NB-ST and CLF, p &lt; 0.0001 compared
to the others). In the balanced class setting (Ta-
ble 3), CLF performs better than NB-T and SVM-
T, which is consistent with the results in (Li and
Zong, 2008). However, it is still worse than our
LSC model.
Effects of #Past Domains. Figure 1 shows the
effects of our model using different number of past
domains. We clearly see that LSC performs bet-
ter with more past domains, showing it indeed has
the ability to accumulate knowledge and use the
knowledge to build better classifiers.
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999508">
In this paper, we proposed a lifelong learning ap-
proach to sentiment classification using optimiza-
tion, which is based on stochastic gradient de-
scent in the framework of Bayesian probabilities.
Penalty terms are introduced to effectively exploit
the knowledge gained from past learning. Our
experimental results using 20 diverse product re-
view domains demonstrate the effectiveness of the
method. We believe that lifelong learning is a
promising direction for building better classifiers.
</bodyText>
<figure confidence="0.9984539">
0.7
0.85
0.65
0.6
0.81
0.55
0.79
NB-T 5 10 15 19
NB-T 5 10 15 19
0.83
</figure>
<page confidence="0.99617">
754
</page>
<sectionHeader confidence="0.996095" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99984477">
Alina Andreevskaia and Sabine Bergler. 2008. When
Specialists and Generalists Work Together: Over-
coming Domain Dependence in Sentiment Tagging.
In ACL, pages 290–298.
Anthony Aue and Michael Gamon. 2005. Customiz-
ing Sentiment Classifiers to New Domains: A Case
Study. In RANLP.
John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, Bollywood, Boom-boxes and
Blenders: Domain Adaptation for Sentiment Clas-
sification. In ACL, pages 440–447.
Danushka Bollegala, David J Weir, and John Carroll.
2011. Using Multiple Sources to Construct a Sen-
timent Sensitive Thesaurus for Cross-Domain Senti-
ment Classification. In ACL HLT, pages 132–141.
L´eon Bottou. 1998. Online algorithms and stochas-
tic approximations. In David Saad, editor, Online
Learning and Neural Networks. Cambridge Univer-
sity Press, Cambridge, UK. Oct 2012.
Andrew Carlson, Justin Betteridge, and Bryan Kisiel.
2010. Toward an Architecture for Never-Ending
Language Learning. In AAAI, pages 1306–1313.
Rich Caruana. 1997. Multitask Learning. Machine
learning, 28(1):41–75.
Zhiyuan Chen and Bing Liu. 2014a. Mining Topics in
Documents: Standing on the Shoulders of Big Data.
In KDD, pages 1116–1125.
Zhiyuan Chen and Bing Liu. 2014b. Topic Modeling
using Topics from Many Domains, Lifelong Learn-
ing and Big Data. In ICML, pages 703–711.
Jianhui Chen, Jiayu Zhou, and Jieping Ye. 2011. Inte-
grating low-rank and group-sparse structures for ro-
bust multi-task learning. In KDD, pages 42–50.
Yulan He, Chenghua Lin, and Harith Alani. 2011. Au-
tomatically Extracting Polarity-Bearing Topics for
Cross-Domain Sentiment Classification. In ACL,
pages 123–131.
James J Heckman. 1979. Sample selection bias as a
specification error. Econometrica: Journal of the
econometric society, pages 153–161.
Jing Jiang. 2008. A literature survey on domain adap-
tation of statistical classifiers. Technical report.
Lun-Wei Ku, Ting-Hao Huang, and Hsin-Hsi Chen.
2009. Using morphological and syntactic structures
for Chinese opinion analysis. In EMNLP, pages
1260–1269.
Shoushan Li and Chengqing Zong. 2008. Multi-
domain sentiment classification. In ACL HLT, pages
257–260.
Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and
Xiaoyan Zhu. 2012. Cross-domain Co-extraction of
Sentiment and Topic Lexicons. In ACL, pages 410–
419.
Shoushan Li, Yunxia Xue, Zhongqing Wang, and
Guodong Zhou. 2013. Active learning for cross-
domain sentiment classification. In AAAI, pages
2127–2133.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Sinno Jialin Pan and Qiang Yang. 2010. A Survey on
Transfer Learning. IEEE Trans. Knowl. Data Eng.,
22(10):1345–1359.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classification using
Machine Learning Techniques. In EMNLP, pages
79–86.
Rajat Raina, Alexis Battle, Honglak Lee, Benjamin
Packer, and Andrew Y Ng. 2007. Self-taught Learn-
ing : Transfer Learning from Unlabeled Data. In
ICML, pages 759–766.
Paul Ruvolo and Eric Eaton. 2013. ELLA: An efficient
lifelong learning algorithm. In ICML, pages 507–
515.
Avishek Saha, Piyush Rai, Suresh Venkatasubrama-
nian, and Hal Daume. 2011. Online learning of
multiple tasks and their relationships. In AISTATS,
pages 643–651.
Hidetoshi Shimodaira. 2000. Improving predictive in-
ference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning
and inference, 90(2):227–244.
Daniel L Silver, Qiang Yang, and Lianghao Li.
2013. Lifelong Machine Learning Systems: Beyond
Learning Algorithms. In AAAI Spring Symposium:
Lifelong Machine Learning, pages 49–55.
Songbo Tan, Gaowei Wu, Huifeng Tang, and Xueqi
Cheng. 2007. A novel scheme for domain-transfer
problem in the context of sentiment analysis. In
CIKM, pages 979–982.
Sebastian Thrun. 1998. Lifelong Learning Algo-
rithms. In S Thrun and L Pratt, editors, Learning
To Learn, pages 181–209. Kluwer Academic Pub-
lishers.
Qiong Wu, Songbo Tan, and Xueqi Cheng. 2009.
Graph Ranking for Sentiment Transfer. In ACL-
IJCNLP, pages 317–320.
</reference>
<page confidence="0.982528">
755
</page>
<reference confidence="0.99967">
Rui Xia and Chengqing Zong. 2011. A POS-based
Ensemble Model for Cross-domain Sentiment Clas-
sification. In IJCNLP, pages 614–622. Citeseer.
Yasuhisa Yoshida, Tsutomu Hirao, Tomoharu Iwata,
Masaaki Nagata, and Yuji Matsumoto. 2011.
Transfer Learning for Multiple-Domain Sen-
timent Analysis-Identifying Domain Depen-
dent/Independent Word Polarity. In AAAI, pages
1286–1291.
Bianca Zadrozny. 2004. Learning and evaluating clas-
sifiers under sample selection bias. In ICML, page
114. ACM.
Jian Zhang, Zoubin Ghahramani, and Yiming Yang.
2008. Flexible latent variable models for multi-task
learning. Machine Learning, 73(3):221–242.
</reference>
<page confidence="0.998718">
756
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.964164">
<title confidence="0.999962">Lifelong Learning for Sentiment Classification</title>
<author confidence="0.999053">Zhiyuan Chen</author>
<author confidence="0.999053">Nianzu Ma</author>
<author confidence="0.999053">Bing</author>
<affiliation confidence="0.98617">Department of Computer University of Illinois at</affiliation>
<abstract confidence="0.9995184375">This paper proposes a novel lifelong learning (LL) approach to sentiment classification. LL mimics the human continuous learning process, i.e., retaining the knowledge learned from past tasks and use it to help future learning. In this paper, we first discuss LL in general and then LL for sentiment classification in particular. The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent. Our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging. In</title>
<date>2008</date>
<booktitle>ACL,</booktitle>
<pages>290--298</pages>
<contexts>
<context position="8297" citStr="Andreevskaia and Bergler, 2008" startWordPosition="1318" endWordPosition="1321">in adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) t</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2008. When Specialists and Generalists Work Together: Overcoming Domain Dependence in Sentiment Tagging. In ACL, pages 290–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Aue</author>
<author>Michael Gamon</author>
</authors>
<title>Customizing Sentiment Classifiers to New Domains: A Case Study.</title>
<date>2005</date>
<booktitle>In RANLP.</booktitle>
<contexts>
<context position="4576" citStr="Aue and Gamon, 2005" startWordPosition="728" endWordPosition="731">where each task consists of a set of training documents with positive and negative polarity labels. Given the Nth task, it uses the knowledge gained in the past N − 1 tasks to learn a better classifier for the Nth task. It is useful to note that although many researchers have used transfer learning for supervised sentiment classification, LL is different from the classic transfer learning or domain adaptation (Pan and Yang, 2010). Transfer learning typically uses labeled training data from one (or more) source domain(s) to help learning in the target domain that has little or no labeled data (Aue and Gamon, 2005, Bollegala et al., 2011). It does not use the results of the past learning or knowledge mined from the results of the past learning. Further, transfer learning is usually inferior to traditional supervised learning when the target domain already has good training data. In contrast, our target (or future) domain/task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning. To be consistent with prior research, we treat the classification of one domain as one learning task. One question is why the pas</context>
<context position="7764" citStr="Aue and Gamon (2005)" startWordPosition="1235" endWordPosition="1238">invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et a</context>
</contexts>
<marker>Aue, Gamon, 2005</marker>
<rawString>Anthony Aue and Michael Gamon. 2005. Customizing Sentiment Classifiers to New Domains: A Case Study. In RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. In</title>
<date>2007</date>
<booktitle>ACL,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="7892" citStr="Blitzer et al. (2007)" startWordPosition="1255" endWordPosition="1258">s multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Add</context>
<context position="16325" citStr="Blitzer et al., 2007" startWordPosition="2771" endWordPosition="2774"> Then we add the second penalty term as follows: where the ratio Rw is defined as MKB +,w/(MKB +,w + MKB −,w). X0+,w and X0 −,w are the starting points for SGD (Section 3.3). Finally, we revise the partial derivatives in Eqs. 4-6 by adding the corresponding partial derivatives of Eqs. 7 and 8 to them. 4 Experiments Datasets. We created a large corpus containing reviews from 20 types of diverse products or domains crawled from Amazon.com (i.e., 20 datasets). The names of product domains are listed in Table 1. Each domain contains 1,000 reviews. Following the existing work of other researchers (Blitzer et al., 2007, Pang et al., 2002), we treat reviews with rating &gt; 3 as positive and reviews with rating &lt; 3 as negative. The datasets are publically available at the authors websites. Natural class distribution: We keep the natural (or skewed) distribution of the positive and negative reviews to experiment with the real-life situation. F1-score is used due to the imbalance. 1 � 2α w∈VS 1 � + 2α w∈VS 0 2 (X+,w − Rw × X+,w) (X−,w − (1 − Rw) × X0 )2 −,w (8) 753 NB-T NB-S NB-ST SVM-T SVM-S SVM-ST CLF LSC 56.21 57.04 60.61 57.82 57.64 61.05 12.87 67.00 Table 2: Natural class distribution: Average F1-score of th</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. In ACL, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>David J Weir</author>
<author>John Carroll</author>
</authors>
<title>Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification.</title>
<date>2011</date>
<booktitle>In ACL HLT,</booktitle>
<pages>132--141</pages>
<contexts>
<context position="4601" citStr="Bollegala et al., 2011" startWordPosition="732" endWordPosition="735">sts of a set of training documents with positive and negative polarity labels. Given the Nth task, it uses the knowledge gained in the past N − 1 tasks to learn a better classifier for the Nth task. It is useful to note that although many researchers have used transfer learning for supervised sentiment classification, LL is different from the classic transfer learning or domain adaptation (Pan and Yang, 2010). Transfer learning typically uses labeled training data from one (or more) source domain(s) to help learning in the target domain that has little or no labeled data (Aue and Gamon, 2005, Bollegala et al., 2011). It does not use the results of the past learning or knowledge mined from the results of the past learning. Further, transfer learning is usually inferior to traditional supervised learning when the target domain already has good training data. In contrast, our target (or future) domain/task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning. To be consistent with prior research, we treat the classification of one domain as one learning task. One question is why the past learning tasks can cont</context>
<context position="8321" citStr="Bollegala et al., 2011" startWordPosition="1322" endWordPosition="1326">0). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as ou</context>
</contexts>
<marker>Bollegala, Weir, Carroll, 2011</marker>
<rawString>Danushka Bollegala, David J Weir, and John Carroll. 2011. Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification. In ACL HLT, pages 132–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L´eon Bottou</author>
</authors>
<title>Online algorithms and stochastic approximations.</title>
<date>1998</date>
<booktitle>Online Learning and Neural Networks.</booktitle>
<editor>In David Saad, editor,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="1722" citStr="Bottou, 1998" startWordPosition="257" endWordPosition="258">ng learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning? Motivated by these questions, we present the following definition of lifelong learning (LL). Definition (Lifelong Learning): A learner has performed learning on a sequence of tasks</context>
</contexts>
<marker>Bottou, 1998</marker>
<rawString>L´eon Bottou. 1998. Online algorithms and stochastic approximations. In David Saad, editor, Online Learning and Neural Networks. Cambridge University Press, Cambridge, UK. Oct 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
</authors>
<title>Toward an Architecture for Never-Ending Language Learning. In</title>
<date>2010</date>
<booktitle>AAAI,</booktitle>
<pages>1306--1313</pages>
<contexts>
<context position="1644" citStr="Carlson et al., 2010" startWordPosition="243" endWordPosition="246">research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning? Motivated by these questions, we present the following definition of lifelong learning (LL). Definitio</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, and Bryan Kisiel. 2010. Toward an Architecture for Never-Ending Language Learning. In AAAI, pages 1306–1313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich Caruana</author>
</authors>
<date>1997</date>
<booktitle>Multitask Learning. Machine learning,</booktitle>
<pages>28--1</pages>
<contexts>
<context position="1598" citStr="Caruana, 1997" startWordPosition="239" endWordPosition="240"> provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning? Motivated by these questions, we present the following d</context>
<context position="7039" citStr="Caruana, 1997" startWordPosition="1123" endWordPosition="1124">ons: 1. It proposes a novel lifelong learning approach to sentiment classification, called lifelong sentiment classification (LSC). 2. It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related </context>
</contexts>
<marker>Caruana, 1997</marker>
<rawString>Rich Caruana. 1997. Multitask Learning. Machine learning, 28(1):41–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Bing Liu</author>
</authors>
<title>Mining Topics in Documents: Standing on the Shoulders of Big Data. In</title>
<date>2014</date>
<booktitle>KDD,</booktitle>
<pages>1116--1125</pages>
<contexts>
<context position="1332" citStr="Chen and Liu, 2014" startWordPosition="196" endWordPosition="199"> methods significantly, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retai</context>
<context position="7059" citStr="Chen and Liu, 2014" startWordPosition="1125" endWordPosition="1128">oses a novel lifelong learning approach to sentiment classification, called lifelong sentiment classification (LSC). 2. It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning</context>
</contexts>
<marker>Chen, Liu, 2014</marker>
<rawString>Zhiyuan Chen and Bing Liu. 2014a. Mining Topics in Documents: Standing on the Shoulders of Big Data. In KDD, pages 1116–1125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Bing Liu</author>
</authors>
<title>Topic Modeling using Topics from Many Domains, Lifelong Learning and Big Data. In</title>
<date>2014</date>
<booktitle>ICML,</booktitle>
<pages>703--711</pages>
<contexts>
<context position="1332" citStr="Chen and Liu, 2014" startWordPosition="196" endWordPosition="199"> methods significantly, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retai</context>
<context position="7059" citStr="Chen and Liu, 2014" startWordPosition="1125" endWordPosition="1128">oses a novel lifelong learning approach to sentiment classification, called lifelong sentiment classification (LSC). 2. It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning</context>
</contexts>
<marker>Chen, Liu, 2014</marker>
<rawString>Zhiyuan Chen and Bing Liu. 2014b. Topic Modeling using Topics from Many Domains, Lifelong Learning and Big Data. In ICML, pages 703–711.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianhui Chen</author>
<author>Jiayu Zhou</author>
<author>Jieping Ye</author>
</authors>
<title>Integrating low-rank and group-sparse structures for robust multi-task learning.</title>
<date>2011</date>
<booktitle>In KDD,</booktitle>
<pages>42--50</pages>
<contexts>
<context position="7408" citStr="Chen et al., 2011" startWordPosition="1178" endWordPosition="1181">rom 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated f</context>
</contexts>
<marker>Chen, Zhou, Ye, 2011</marker>
<rawString>Jianhui Chen, Jiayu Zhou, and Jieping Ye. 2011. Integrating low-rank and group-sparse structures for robust multi-task learning. In KDD, pages 42–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Chenghua Lin</author>
<author>Harith Alani</author>
</authors>
<title>Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification. In</title>
<date>2011</date>
<booktitle>ACL,</booktitle>
<pages>123--131</pages>
<contexts>
<context position="8338" citStr="He et al., 2011" startWordPosition="1327" endWordPosition="1330">ssification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it </context>
</contexts>
<marker>He, Lin, Alani, 2011</marker>
<rawString>Yulan He, Chenghua Lin, and Harith Alani. 2011. Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification. In ACL, pages 123–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James J Heckman</author>
</authors>
<title>Sample selection bias as a specification error.</title>
<date>1979</date>
<journal>Econometrica: Journal of the econometric society,</journal>
<pages>153--161</pages>
<contexts>
<context position="5445" citStr="Heckman, 1979" startWordPosition="876" endWordPosition="877">training data. In contrast, our target (or future) domain/task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning. To be consistent with prior research, we treat the classification of one domain as one learning task. One question is why the past learning tasks can contribute to the target domain classification given that the target domain already has labeled training data. The key reason is that the training data may not be fully representative of the test data due to the sample selection bias (Heckman, 1979, Shimodaira, 2000, Zadrozny, 2004). In few real-life applications, the training data are fully representative of the test data. For example, in a sentiment classification application, the test data may contain some sentiment words that are absent in the training data of the target domain, while these sentiment words have appeared in some past domains. So the past domain knowledge can provide the prior polarity information in this situation. Like most existing sentiment classification papers (Liu, 2012), this paper focuses on binary classification, i.e., positive (+) and negative (−) polaritie</context>
</contexts>
<marker>Heckman, 1979</marker>
<rawString>James J Heckman. 1979. Sample selection bias as a specification error. Econometrica: Journal of the econometric society, pages 153–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
</authors>
<title>A literature survey on domain adaptation of statistical classifiers.</title>
<date>2008</date>
<tech>Technical report.</tech>
<contexts>
<context position="1540" citStr="Jiang, 2008" startWordPosition="231" endWordPosition="232"> negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning</context>
</contexts>
<marker>Jiang, 2008</marker>
<rawString>Jing Jiang. 2008. A literature survey on domain adaptation of statistical classifiers. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Ting-Hao Huang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Using morphological and syntactic structures for Chinese opinion analysis.</title>
<date>2009</date>
<booktitle>In EMNLP,</booktitle>
<pages>1260--1269</pages>
<contexts>
<context position="8355" citStr="Ku et al., 2009" startWordPosition="1331" endWordPosition="1334">xt, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation</context>
</contexts>
<marker>Ku, Huang, Chen, 2009</marker>
<rawString>Lun-Wei Ku, Ting-Hao Huang, and Hsin-Hsi Chen. 2009. Using morphological and syntactic structures for Chinese opinion analysis. In EMNLP, pages 1260–1269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shoushan Li</author>
<author>Chengqing Zong</author>
</authors>
<title>Multidomain sentiment classification.</title>
<date>2008</date>
<booktitle>In ACL HLT,</booktitle>
<pages>257--260</pages>
<contexts>
<context position="8118" citStr="Li and Zong (2008)" startWordPosition="1292" endWordPosition="1295">sis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new le</context>
<context position="17880" citStr="Li and Zong, 2008" startWordPosition="3045" endWordPosition="3048">aset with 200 reviews (100 positive and 100 negative) in each domain dataset. This set is smaller because of the small number of negative reviews in each domain. Accuracy is used for evaluation in this balanced setting. We used unigram features with no feature selection in classification. We followed (Pang et al., 2002) to deal with negation words. For evaluation, each domain is treated as the target domain with the rest 19 domains as the past domains. All the models are evaluated using 5-fold cross validation. Baselines. We compare our proposed LSC model with Naive Bayes (NB), SVM1, and CLF (Li and Zong, 2008). Note that NB and SVM can only work on a single domain data. To have a comprehensive comparison, they are fed with three types of training data: a) labeled training data from the target domain only, denoted by NB-T and SVM-T; b) labeled training data from all past source domains only, denoted by NB-S and SVM-S; c) merged (labeled) training data from all past domains and the target domain, referred to as NBST and SVM-ST. For LSC, we empirically set σ = 6 and T = 6. The learning rate A and regularization coefficient α are set to 0.1 empirically. A is set to 1 for (Laplace) smoothing. Table 2 sh</context>
<context position="19716" citStr="Li and Zong, 2008" startWordPosition="3365" endWordPosition="3368"> Accuracy of LSC with #past domains in balanced class distribution. that the average F1-score for the positive class is not shown as all classifiers perform very well because the positive class is the majority class (while our model performs slightly better than the baselines). The improvements of the proposed LSC model over all baselines in both cases are statistically significant using paired t-test (p &lt; 0.01 compared to NB-ST and CLF, p &lt; 0.0001 compared to the others). In the balanced class setting (Table 3), CLF performs better than NB-T and SVMT, which is consistent with the results in (Li and Zong, 2008). However, it is still worse than our LSC model. Effects of #Past Domains. Figure 1 shows the effects of our model using different number of past domains. We clearly see that LSC performs better with more past domains, showing it indeed has the ability to accumulate knowledge and use the knowledge to build better classifiers. 5 Conclusions In this paper, we proposed a lifelong learning approach to sentiment classification using optimization, which is based on stochastic gradient descent in the framework of Bayesian probabilities. Penalty terms are introduced to effectively exploit the knowledg</context>
</contexts>
<marker>Li, Zong, 2008</marker>
<rawString>Shoushan Li and Chengqing Zong. 2008. Multidomain sentiment classification. In ACL HLT, pages 257–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Sinno Jialin Pan</author>
<author>Ou Jin</author>
<author>Qiang Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Cross-domain Co-extraction of Sentiment and Topic Lexicons. In</title>
<date>2012</date>
<booktitle>ACL,</booktitle>
<pages>410--419</pages>
<contexts>
<context position="8372" citStr="Li et al., 2012" startWordPosition="1335" endWordPosition="1338"> (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classif</context>
</contexts>
<marker>Li, Pan, Jin, Yang, Zhu, 2012</marker>
<rawString>Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and Xiaoyan Zhu. 2012. Cross-domain Co-extraction of Sentiment and Topic Lexicons. In ACL, pages 410– 419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shoushan Li</author>
<author>Yunxia Xue</author>
<author>Zhongqing Wang</author>
<author>Guodong Zhou</author>
</authors>
<title>Active learning for crossdomain sentiment classification.</title>
<date>2013</date>
<booktitle>In AAAI,</booktitle>
<pages>2127--2133</pages>
<contexts>
<context position="8389" citStr="Li et al., 2013" startWordPosition="1339" endWordPosition="1342">entiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum</context>
</contexts>
<marker>Li, Xue, Wang, Zhou, 2013</marker>
<rawString>Shoushan Li, Yunxia Xue, Zhongqing Wang, and Guodong Zhou. 2013. Active learning for crossdomain sentiment classification. In AAAI, pages 2127–2133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="960" citStr="Liu (2012)" startWordPosition="134" endWordPosition="135">etaining the knowledge learned from past tasks and use it to help future learning. In this paper, we first discuss LL in general and then LL for sentiment classification in particular. The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent. Our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010</context>
<context position="5953" citStr="Liu, 2012" startWordPosition="957" endWordPosition="958"> data may not be fully representative of the test data due to the sample selection bias (Heckman, 1979, Shimodaira, 2000, Zadrozny, 2004). In few real-life applications, the training data are fully representative of the test data. For example, in a sentiment classification application, the test data may contain some sentiment words that are absent in the training data of the target domain, while these sentiment words have appeared in some past domains. So the past domain knowledge can provide the prior polarity information in this situation. Like most existing sentiment classification papers (Liu, 2012), this paper focuses on binary classification, i.e., positive (+) and negative (−) polarities. But the proposed method is also applicable to multi-class classification. To embed and use the knowledge in building the target domain classifier, we propose a novel optimization method based on the Naive Bayesian (NB) framework and stochastic gradient descent. The knowledge is incorporated using penalty terms in the optimization formulation. This paper makes three contributions: 1. It proposes a novel lifelong learning approach to sentiment classification, called lifelong sentiment classification (L</context>
<context position="8571" citStr="Liu, 2012" startWordPosition="1376" endWordPosition="1377"> and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum and Nigam, 1998) basically computes the conditional probability of each word w given each class cj (i.e., P (w|cj)) and the prior probability of each class cj (i.e., P(cj)), which a</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Jialin Pan</author>
<author>Qiang Yang</author>
</authors>
<title>A Survey on Transfer Learning.</title>
<date>2010</date>
<journal>IEEE Trans. Knowl. Data Eng.,</journal>
<volume>22</volume>
<issue>10</issue>
<contexts>
<context position="1561" citStr="Pan and Yang, 2010" startWordPosition="233" endWordPosition="236">timent. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning? Motivated by these </context>
<context position="4390" citStr="Pan and Yang, 2010" startWordPosition="695" endWordPosition="698">al Language Processing (Short Papers), pages 750–756, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics sentiment classification tasks, from 1 to N − 1, where each task consists of a set of training documents with positive and negative polarity labels. Given the Nth task, it uses the knowledge gained in the past N − 1 tasks to learn a better classifier for the Nth task. It is useful to note that although many researchers have used transfer learning for supervised sentiment classification, LL is different from the classic transfer learning or domain adaptation (Pan and Yang, 2010). Transfer learning typically uses labeled training data from one (or more) source domain(s) to help learning in the target domain that has little or no labeled data (Aue and Gamon, 2005, Bollegala et al., 2011). It does not use the results of the past learning or knowledge mined from the results of the past learning. Further, transfer learning is usually inferior to traditional supervised learning when the target domain already has good training data. In contrast, our target (or future) domain/task has good training data and we aim to further improve the learning using both the target domain </context>
<context position="7701" citStr="Pan and Yang, 2010" startWordPosition="1226" endWordPosition="1229">. Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bo</context>
</contexts>
<marker>Pan, Yang, 2010</marker>
<rawString>Sinno Jialin Pan and Qiang Yang. 2010. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="984" citStr="Pang and Lee (2008)" startWordPosition="137" endWordPosition="140">owledge learned from past tasks and use it to help future learning. In this paper, we first discuss LL in general and then LL for sentiment classification in particular. The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent. Our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques. In</title>
<date>2002</date>
<booktitle>EMNLP,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="16345" citStr="Pang et al., 2002" startWordPosition="2775" endWordPosition="2778">d penalty term as follows: where the ratio Rw is defined as MKB +,w/(MKB +,w + MKB −,w). X0+,w and X0 −,w are the starting points for SGD (Section 3.3). Finally, we revise the partial derivatives in Eqs. 4-6 by adding the corresponding partial derivatives of Eqs. 7 and 8 to them. 4 Experiments Datasets. We created a large corpus containing reviews from 20 types of diverse products or domains crawled from Amazon.com (i.e., 20 datasets). The names of product domains are listed in Table 1. Each domain contains 1,000 reviews. Following the existing work of other researchers (Blitzer et al., 2007, Pang et al., 2002), we treat reviews with rating &gt; 3 as positive and reviews with rating &lt; 3 as negative. The datasets are publically available at the authors websites. Natural class distribution: We keep the natural (or skewed) distribution of the positive and negative reviews to experiment with the real-life situation. F1-score is used due to the imbalance. 1 � 2α w∈VS 1 � + 2α w∈VS 0 2 (X+,w − Rw × X+,w) (X−,w − (1 − Rw) × X0 )2 −,w (8) 753 NB-T NB-S NB-ST SVM-T SVM-S SVM-ST CLF LSC 56.21 57.04 60.61 57.82 57.64 61.05 12.87 67.00 Table 2: Natural class distribution: Average F1-score of the negative class ove</context>
<context position="17583" citStr="Pang et al., 2002" startWordPosition="2992" endWordPosition="2995">ve class is the minority class and thus harder to classify. NB-T NB-S NB-ST SVM-T SVM-S SVM-ST CLF LSC 80.15 77.35 80.85 78.45 78.20 79.40 80.49 83.34 Table 3: Balanced class distribution: Average accuracy over 20 domains for each system. Balanced class distribution: We also created a balance dataset with 200 reviews (100 positive and 100 negative) in each domain dataset. This set is smaller because of the small number of negative reviews in each domain. Accuracy is used for evaluation in this balanced setting. We used unigram features with no feature selection in classification. We followed (Pang et al., 2002) to deal with negation words. For evaluation, each domain is treated as the target domain with the rest 19 domains as the past domains. All the models are evaluated using 5-fold cross validation. Baselines. We compare our proposed LSC model with Naive Bayes (NB), SVM1, and CLF (Li and Zong, 2008). Note that NB and SVM can only work on a single domain data. To have a comprehensive comparison, they are fed with three types of training data: a) labeled training data from the target domain only, denoted by NB-T and SVM-T; b) labeled training data from all past source domains only, denoted by NB-S </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. In EMNLP, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajat Raina</author>
<author>Alexis Battle</author>
<author>Honglak Lee</author>
<author>Benjamin Packer</author>
<author>Andrew Y Ng</author>
</authors>
<title>Self-taught Learning : Transfer Learning from Unlabeled Data. In</title>
<date>2007</date>
<booktitle>ICML,</booktitle>
<pages>759--766</pages>
<contexts>
<context position="1686" citStr="Raina et al., 2007" startWordPosition="250" endWordPosition="253"> classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learning tasks? 2. What forms of knowledge will be used to help future learning? 3. How does the system obtain the knowledge? 4. How does the system use the knowledge to help future learning? Motivated by these questions, we present the following definition of lifelong learning (LL). Definition (Lifelong Learning): A learner has perfo</context>
</contexts>
<marker>Raina, Battle, Lee, Packer, Ng, 2007</marker>
<rawString>Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer, and Andrew Y Ng. 2007. Self-taught Learning : Transfer Learning from Unlabeled Data. In ICML, pages 759–766.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ruvolo</author>
<author>Eric Eaton</author>
</authors>
<title>ELLA: An efficient lifelong learning algorithm.</title>
<date>2013</date>
<booktitle>In ICML,</booktitle>
<pages>507--515</pages>
<contexts>
<context position="7265" citStr="Ruvolo and Eaton, 2013" startWordPosition="1156" endWordPosition="1159"> gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled rev</context>
</contexts>
<marker>Ruvolo, Eaton, 2013</marker>
<rawString>Paul Ruvolo and Eric Eaton. 2013. ELLA: An efficient lifelong learning algorithm. In ICML, pages 507– 515.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avishek Saha</author>
<author>Piyush Rai</author>
<author>Suresh Venkatasubramanian</author>
<author>Hal Daume</author>
</authors>
<title>Online learning of multiple tasks and their relationships.</title>
<date>2011</date>
<booktitle>In AISTATS,</booktitle>
<pages>643--651</pages>
<contexts>
<context position="7427" citStr="Saha et al., 2011" startWordPosition="1182" endWordPosition="1185">uct domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pi</context>
</contexts>
<marker>Saha, Rai, Venkatasubramanian, Daume, 2011</marker>
<rawString>Avishek Saha, Piyush Rai, Suresh Venkatasubramanian, and Hal Daume. 2011. Online learning of multiple tasks and their relationships. In AISTATS, pages 643–651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hidetoshi Shimodaira</author>
</authors>
<title>Improving predictive inference under covariate shift by weighting the loglikelihood function. Journal of statistical planning and inference,</title>
<date>2000</date>
<pages>90--2</pages>
<contexts>
<context position="5463" citStr="Shimodaira, 2000" startWordPosition="878" endWordPosition="880">In contrast, our target (or future) domain/task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning. To be consistent with prior research, we treat the classification of one domain as one learning task. One question is why the past learning tasks can contribute to the target domain classification given that the target domain already has labeled training data. The key reason is that the training data may not be fully representative of the test data due to the sample selection bias (Heckman, 1979, Shimodaira, 2000, Zadrozny, 2004). In few real-life applications, the training data are fully representative of the test data. For example, in a sentiment classification application, the test data may contain some sentiment words that are absent in the training data of the target domain, while these sentiment words have appeared in some past domains. So the past domain knowledge can provide the prior polarity information in this situation. Like most existing sentiment classification papers (Liu, 2012), this paper focuses on binary classification, i.e., positive (+) and negative (−) polarities. But the propose</context>
</contexts>
<marker>Shimodaira, 2000</marker>
<rawString>Hidetoshi Shimodaira. 2000. Improving predictive inference under covariate shift by weighting the loglikelihood function. Journal of statistical planning and inference, 90(2):227–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel L Silver</author>
<author>Qiang Yang</author>
<author>Lianghao Li</author>
</authors>
<title>Lifelong Machine Learning Systems: Beyond Learning Algorithms.</title>
<date>2013</date>
<booktitle>In AAAI Spring Symposium: Lifelong Machine Learning,</booktitle>
<pages>49--55</pages>
<contexts>
<context position="1355" citStr="Silver et al., 2013" startWordPosition="200" endWordPosition="203">y, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What information should be retained from the past learn</context>
<context position="7082" citStr="Silver et al., 2013" startWordPosition="1129" endWordPosition="1132"> learning approach to sentiment classification, called lifelong sentiment classification (LSC). 2. It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (</context>
</contexts>
<marker>Silver, Yang, Li, 2013</marker>
<rawString>Daniel L Silver, Qiang Yang, and Lianghao Li. 2013. Lifelong Machine Learning Systems: Beyond Learning Algorithms. In AAAI Spring Symposium: Lifelong Machine Learning, pages 49–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songbo Tan</author>
<author>Gaowei Wu</author>
<author>Huifeng Tang</author>
<author>Xueqi Cheng</author>
</authors>
<title>A novel scheme for domain-transfer problem in the context of sentiment analysis.</title>
<date>2007</date>
<booktitle>In CIKM,</booktitle>
<pages>979--982</pages>
<contexts>
<context position="8427" citStr="Tan et al., 2007" startWordPosition="1347" endWordPosition="1350">omain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum and Nigam, 1998) basically computes t</context>
</contexts>
<marker>Tan, Wu, Tang, Cheng, 2007</marker>
<rawString>Songbo Tan, Gaowei Wu, Huifeng Tang, and Xueqi Cheng. 2007. A novel scheme for domain-transfer problem in the context of sentiment analysis. In CIKM, pages 979–982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Thrun</author>
</authors>
<title>Lifelong Learning Algorithms.</title>
<date>1998</date>
<booktitle>Learning To Learn,</booktitle>
<pages>181--209</pages>
<editor>In S Thrun and L Pratt, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1312" citStr="Thrun, 1998" startWordPosition="194" endWordPosition="195">orms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction. 1 Introduction Sentiment classification is the task of classifying an opinion document as expressing a positive or negative sentiment. Liu (2012) and Pang and Lee (2008) provided good surveys of the existing research. In this paper, we tackle sentiment classification from a novel angle, lifelong learning (LL), or lifelong machine learning. This learning paradigm aims to learn as humans do: retaining the learned knowledge from the past and use the knowledge to help future learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013). Although many machine learning topics and techniques are related to LL, e.g., lifelong learning (Thrun, 1998, Chen and Liu, 2014b, Silver et al., 2013), transfer learning (Jiang, 2008, Pan and Yang, 2010), multi-task learning (Caruana, 1997), never-ending learning (Carlson et al., 2010), selftaught learning (Raina et al., 2007), and online learning (Bottou, 1998), there is still no unified definition for LL. Based on the prior work and our research, to build an LL system, we believe that we need to answer the following key questions: 1. What informa</context>
<context position="7024" citStr="Thrun, 1998" startWordPosition="1121" endWordPosition="1122">ee contributions: 1. It proposes a novel lifelong learning approach to sentiment classification, called lifelong sentiment classification (LSC). 2. It proposes an optimization method that uses penalty terms to embed the knowledge gained in the past and to deal with domain dependent sentiment words to build a better classifier. 3. It creates a large corpus containing reviews from 20 diverse product domains for extensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work i</context>
</contexts>
<marker>Thrun, 1998</marker>
<rawString>Sebastian Thrun. 1998. Lifelong Learning Algorithms. In S Thrun and L Pratt, editors, Learning To Learn, pages 181–209. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiong Wu</author>
<author>Songbo Tan</author>
<author>Xueqi Cheng</author>
</authors>
<title>Graph Ranking for Sentiment Transfer. In</title>
<date>2009</date>
<booktitle>ACLIJCNLP,</booktitle>
<pages>317--320</pages>
<contexts>
<context position="8444" citStr="Wu et al., 2009" startWordPosition="1351" endWordPosition="1354">s mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum and Nigam, 1998) basically computes the conditional pr</context>
</contexts>
<marker>Wu, Tan, Cheng, 2009</marker>
<rawString>Qiong Wu, Songbo Tan, and Xueqi Cheng. 2009. Graph Ranking for Sentiment Transfer. In ACLIJCNLP, pages 317–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Xia</author>
<author>Chengqing Zong</author>
</authors>
<title>A POS-based Ensemble Model for Cross-domain Sentiment Classification. In</title>
<date>2011</date>
<booktitle>IJCNLP,</booktitle>
<pages>614--622</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="8464" citStr="Xia and Zong, 2011" startWordPosition="1355" endWordPosition="1358">d and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum and Nigam, 1998) basically computes the conditional probability of each wo</context>
</contexts>
<marker>Xia, Zong, 2011</marker>
<rawString>Rui Xia and Chengqing Zong. 2011. A POS-based Ensemble Model for Cross-domain Sentiment Classification. In IJCNLP, pages 614–622. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhisa Yoshida</author>
<author>Tsutomu Hirao</author>
<author>Tomoharu Iwata</author>
<author>Masaaki Nagata</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Transfer Learning for Multiple-Domain Sentiment Analysis-Identifying Domain Dependent/Independent Word Polarity. In</title>
<date>2011</date>
<booktitle>AAAI,</booktitle>
<pages>1286--1291</pages>
<contexts>
<context position="8487" citStr="Yoshida et al., 2011" startWordPosition="1359" endWordPosition="1362">ews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The final classifier is built using the combined features. Li and Zong (2008) built a meta-classifier (called CLF) using the outputs of each base classifier constructed in each domain. Other works along similar lines include (Andreevskaia and Bergler, 2008, Bollegala et al., 2011, He et al., 2011, Ku et al., 2009, Li et al., 2012, Li et al., 2013, Pan and Yang, 2010, Tan et al., 2007, Wu et al., 2009, Xia and Zong, 2011, Yoshida et al., 2011). Additional details about these and other related works can be found in (Liu, 2012). However, as we discussed in the introduction, these methods do not focus on the ability to accumulate learned knowledge and leverage it in new learning in a lifelong manner. 751 3 Proposed LSC Technique 3.1 Naive Bayesian Text Classification Before presenting the proposed method, we briefly review the Naive Bayesian (NB) text classification as our method uses it as the foundation. NB text classification (McCallum and Nigam, 1998) basically computes the conditional probability of each word w given each class c</context>
</contexts>
<marker>Yoshida, Hirao, Iwata, Nagata, Matsumoto, 2011</marker>
<rawString>Yasuhisa Yoshida, Tsutomu Hirao, Tomoharu Iwata, Masaaki Nagata, and Yuji Matsumoto. 2011. Transfer Learning for Multiple-Domain Sentiment Analysis-Identifying Domain Dependent/Independent Word Polarity. In AAAI, pages 1286–1291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bianca Zadrozny</author>
</authors>
<title>Learning and evaluating classifiers under sample selection bias.</title>
<date>2004</date>
<booktitle>In ICML,</booktitle>
<pages>114</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5480" citStr="Zadrozny, 2004" startWordPosition="881" endWordPosition="882">arget (or future) domain/task has good training data and we aim to further improve the learning using both the target domain training data and the knowledge gained in past learning. To be consistent with prior research, we treat the classification of one domain as one learning task. One question is why the past learning tasks can contribute to the target domain classification given that the target domain already has labeled training data. The key reason is that the training data may not be fully representative of the test data due to the sample selection bias (Heckman, 1979, Shimodaira, 2000, Zadrozny, 2004). In few real-life applications, the training data are fully representative of the test data. For example, in a sentiment classification application, the test data may contain some sentiment words that are absent in the training data of the target domain, while these sentiment words have appeared in some past domains. So the past domain knowledge can provide the prior polarity information in this situation. Like most existing sentiment classification papers (Liu, 2012), this paper focuses on binary classification, i.e., positive (+) and negative (−) polarities. But the proposed method is also </context>
</contexts>
<marker>Zadrozny, 2004</marker>
<rawString>Bianca Zadrozny. 2004. Learning and evaluating classifiers under sample selection bias. In ICML, page 114. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Zhang</author>
<author>Zoubin Ghahramani</author>
<author>Yiming Yang</author>
</authors>
<title>Flexible latent variable models for multi-task learning.</title>
<date>2008</date>
<booktitle>Machine Learning,</booktitle>
<volume>73</volume>
<issue>3</issue>
<contexts>
<context position="7448" citStr="Zhang et al., 2008" startWordPosition="1186" endWordPosition="1189">ensive evaluation. The experimental results demonstrate the superiority of the proposed method. 2 Related Work Our work is mainly related to lifelong learning and multi-task learning (Thrun, 1998, Caruana, 1997, Chen and Liu, 2014b, Silver et al., 2013). Existing lifelong learning approaches focused on exploiting invariances (Thrun, 1998) and other types of knowledge (Chen and Liu, 2014b, Chen and Liu, 2014a, Ruvolo and Eaton, 2013) across multiple tasks. Multi-task learning optimizes the learning of multiple related tasks at the same time (Caruana, 1997, Chen et al., 2011, Saha et al., 2011, Zhang et al., 2008). However, these methods are not for sentiment analysis. Also, our naive Bayesian optimization based LL method is quite different from all these existing techniques. Our work is also related to transfer learning or domain adaptation (Pan and Yang, 2010). In the sentiment classification context, Aue and Gamon (2005) trained sentiment classifiers for the target domain using various mixes of labeled and unlabeled reviews. Blitzer et al. (2007) proposed to first find some common or pivot features from the source and the target, and then identify correlated features with the pivot features. The fin</context>
</contexts>
<marker>Zhang, Ghahramani, Yang, 2008</marker>
<rawString>Jian Zhang, Zoubin Ghahramani, and Yiming Yang. 2008. Flexible latent variable models for multi-task learning. Machine Learning, 73(3):221–242.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>