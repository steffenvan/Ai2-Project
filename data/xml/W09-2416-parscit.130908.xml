<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002811">
<title confidence="0.995121">
SemEval-2010 Task 9: The Interpretation of Noun Compounds
Using Paraphrasing Verbs and Prepositions
</title>
<author confidence="0.997183">
Cristina Butnariu Su Nam Kim Preslav Nakov
</author>
<affiliation confidence="0.999134">
University College Dublin University of Melbourne National University of Singapore
</affiliation>
<email confidence="0.928903">
ioana.butnariu@ucd.ie nkim@csse.unimelb.edu.au nakov@comp.nus.edu.sg
</email>
<author confidence="0.994915">
Diarmuid O´ S´eaghdha Stan Szpakowicz Tony Veale
</author>
<affiliation confidence="0.999801">
University of Cambridge University of Ottawa University College Dublin
</affiliation>
<address confidence="0.523992">
do242@cam.ac.uk Polish Academy of Sciences tony.veale@ucd.ie
</address>
<email confidence="0.994107">
szpak@site.uottawa.ca
</email>
<sectionHeader confidence="0.99857" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999284090909091">
We present a brief overview of the main
challenges in understanding the semantics of
noun compounds and consider some known
methods. We introduce a new task to be
part of SemEval-2010: the interpretation of
noun compounds using paraphrasing verbs
and prepositions. The task is meant to provide
a standard testbed for future research on noun
compound semantics. It should also promote
paraphrase-based approaches to the problem,
which can benefit many NLP applications.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999626052631579">
Noun compounds (NCs) – sequences of two or more
nouns acting as a single noun,1 e.g., colon cancer
tumor suppressor protein – are abundant in English
and pose a major challenge to the automatic anal-
ysis of written text. Baldwin and Tanaka (2004)
calculated that 3.9% and 2.6% of the tokens in
the Reuters corpus and the British National Corpus
(BNC), respectively, are part of a noun compound.
Compounding is also an extremely productive pro-
cess in English. The frequency spectrum of com-
pound types follows a Zipfian or power-law distribu-
tion ( O´ S´eaghdha, 2008), so in practice many com-
pound tokens encountered belong to a “long tail”
of low-frequency types. For example, over half of
the two-noun NC types in the BNC occur just once
(Lapata and Lascarides, 2003). Even for relatively
frequent NCs that occur ten or more times in the
BNC, static English dictionaries give only 27% cov-
erage (Tanaka and Baldwin, 2003). Taken together,
</bodyText>
<footnote confidence="0.797722">
1We follow the definition in (Downing, 1977).
</footnote>
<bodyText confidence="0.998677294117647">
the factors of high frequency and high productiv-
ity mean that achieving robust NC interpretation is
an important goal for broad-coverage semantic pro-
cessing. NCs provide a concise means of evoking a
relationship between two or more nouns, and natu-
ral language processing (NLP) systems that do not
try to recover these implicit relations from NCs are
effectively discarding valuable semantic informa-
tion. Broad coverage should therefore be achieved
by post-hoc interpretation rather than pre-hoc enu-
meration, since it is impossible to build a lexicon of
all NCs likely to be encountered.
The challenges presented by NCs and their se-
mantics have generated significant ongoing interest
in NC interpretation in the NLP community. Repre-
sentative publications include (Butnariu and Veale,
2008; Girju, 2007; Kim and Baldwin, 2006; Nakov,
2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha
and Copestake, 2007). Applications that have been
suggested include Question Answering, Machine
Translation, Information Retrieval and Information
Extraction. For example, a question-answering sys-
tem may need to determine whether headaches in-
duced by caffeine withdrawal is a good paraphrase
for caffeine headaches when answering questions
about the causes of headaches, while an information
extraction system may need to decide whether caf-
feine withdrawal headache and caffeine headache
refer to the same concept when used in the same
document. Similarly, a machine translation system
facing the unknown NC WTO Geneva headquarters
might benefit from the ability to paraphrase it as
Geneva headquarters of the WTO or as WTO head-
quarters located in Geneva. Given a query like can-
</bodyText>
<page confidence="0.903083">
100
</page>
<note confidence="0.7955995">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 100–105,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999942111111111">
cer treatment, an information retrieval system could
use suitable paraphrasing verbs like relieve and pre-
vent for page ranking and query refinement.
In this paper, we introduce a new task, which will
be part of the SemEval-2010 competition: NC inter-
pretation using paraphrasing verbs and prepositions.
The task is intended to provide a standard testbed
for future research on noun compound semantics.
We also hope that it will promote paraphrase-based
approaches to the problem, which can benefit many
NLP applications.
The remainder of the paper is organized as fol-
lows: Section 2 presents a brief overview of the
existing approaches to NC semantic interpretation
and introduces the one we will adopt for SemEval-
2010 Task 9; Section 3 provides a general descrip-
tion of the task, the data collection, and the evalua-
tion methodology; Section 4 offers a conclusion.
</bodyText>
<sectionHeader confidence="0.657806" genericHeader="method">
2 Models of Relational Semantics in NCs
</sectionHeader>
<subsectionHeader confidence="0.815311">
2.1 Inventory-Based Semantics
</subsectionHeader>
<bodyText confidence="0.998580857142857">
The prevalent view in theoretical and computational
linguistics holds that the semantic relations that im-
plicitly link the nouns of an NC can be adequately
enumerated via a small inventory of abstract re-
lational categories. In this view, mountain hut,
field mouse and village feast all express ‘location
in space’, while the relation implicit in history book
and nativity play can be characterized as ‘topicality’
or ‘aboutness’. A sample of some of the most influ-
ential relation inventories appears in Table 1.
Levi (1978) proposes that complex nominals –
a general concept grouping together nominal com-
pounds (e.g., peanut butter), nominalizations (e.g.,
dream analysis) and non-predicative noun phrases
(e.g., electric shock) – are derived through the com-
plementary processes of recoverable predicate dele-
tion and nominalization; each process is associated
with its own inventory of semantic categories. Table
1 lists the categories for the former.
Warren (1978) posits a hierarchical classifica-
tion scheme derived from a large-scale corpus study
of NCs. The top-level relations in her hierar-
chy are listed in Table 1, while the next level
subdivides CONSTITUTE into SOURCE-RESULT,
RESULT-SOURCE and COPULA; COPULA is then
further subdivided at two additional levels.
In computational linguistics, popular invento-
ries of semantic relations have been proposed by
Nastase and Szpakowicz (2003) and Girju et al.
(2005), among others. The former groups 30 fine-
grained relations into five coarse-grained super-
categories, while the latter is a flat list of 21 re-
lations. Both schemes are intended to be suit-
able for broad-coverage analysis of text. For spe-
cialized applications, however, it is often useful
to use domain-specific relations. For example,
Rosario and Hearst (2001) propose 18 abstract rela-
tions for interpreting NCs in biomedical text, e.g.,
DEFECT, MATERIAL, PERSON AFFILIATED,
ATTRIBUTE OF CLINICAL STUDY.
Inventory-based analyses offer significant advan-
tages. Abstract relations such as ‘location’ and ‘pos-
session’ capture valuable generalizations about NC
semantics in a parsimonious framework. Unlike
paraphrase-based analyses (Section 2.2), they are
not tied to specific lexical items, which may them-
selves be semantically ambiguous. They also lend
themselves particularly well to automatic interpreta-
tion methods based on multi-class classification.
On the other hand, relation inventories have been
criticized on a number of fronts, most influentially
by Downing (1977). She argues that the great vari-
ety of NC relations makes listing them all impos-
sible; creative NCs like plate length (‘what your
hair is when it drags in your food’) are intuitively
compositional, but cannot be assigned to any stan-
dard inventory category. A second criticism is that
restricted inventories are too impoverished a repre-
sentation scheme for NC semantics, e.g., headache
pills and sleeping pills would both be analyzed as
FOR in Levi’s classification, but express very differ-
ent (indeed, contrary) relationships. Downing writes
(p. 826): “These interpretations are at best reducible
to underlying relationships..., but only with the loss
of much of the semantic material considered by sub-
jects to be relevant or essential to the definitions.”
A further drawback associated with sets of abstract
relations is that it is difficult to identify the “correct”
inventory or to decide whether one proposed classi-
fication scheme should be favored over another.
</bodyText>
<subsectionHeader confidence="0.992748">
2.2 Interpretation Using Verbal Paraphrases
</subsectionHeader>
<bodyText confidence="0.9993395">
An alternative approach to NC interpretation asso-
ciates each compound with an explanatory para-
</bodyText>
<page confidence="0.982698">
101
</page>
<figure confidence="0.680371833333333">
Author(s) Relation Inventory
Levi (1978) CAUSE, HAVE, MAKE, USE, BE, IN, FOR, FROM, ABOUT
Warren (1978) POSSESSION, LOCATION, PURPOSE, ACTIVITY-ACTOR, RESEMBLANCE, CONSTITUTE
Nastase and CAUSALITY (cause, effect, detraction, purpose),
Szpakowicz PARTICIPANT (agent, beneficiary, instrument, object property,
(2003) object, part, possessor, property, product, source, whole, stative),
</figure>
<tableCaption confidence="0.752972">
QUALITY(container, content, equative, material, measure, topic, type),
SPATIAL (direction, location at, location from, location),
TEMPORALITY (frequency, time at, time through)
Girju et al. (2005) POSSESSION, ATTRIBUTE-HOLDER, AGENT, TEMPORAL, PART-WHOLE, IS-A, CAUSE,
MAKE/PRODUCE, INSTRUMENT, LOCATION/SPACE, PURPOSE, SOURCE, TOPIC, MANNER,
MEANS,THEME,ACCOMPANIMENT,EXPERIENCER,RECIPIENT,MEASURE,RESULT
Lauer(1995) OF, FOR, IN, AT, ON, FROM, WITH, ABOUT
Table 1: Previously proposed inventories of semantic relations for noun compound interpretation. The first two come
from linguistic theories; the rest have been proposed in computational linguistics.
</tableCaption>
<bodyText confidence="0.999964954545455">
phrase. Thus, cheese knife and kitchen knife can be
expanded as a knife for cutting cheese and a knife
used in a kitchen, respectively. In the paraphrase-
based paradigm, semantic relations need not come
from a small set; it is possible to have many sub-
tle distinctions afforded by the vocabulary of the
paraphrasing language (in our case, English). This
paradigm avoids the problems of coverage and rep-
resentational poverty, which Downing (1977) ob-
served in inventory-based approaches. It also re-
flects cognitive-linguistic theories of NC semantics,
in which compounds are held to express underlying
event frames and whose constituents are held to de-
note event participants (Ryder, 1994).
Lauer (1995) associates NC semantics with
prepositional paraphrases. As Lauer only consid-
ers a handful of prepositions (about, at, for,
from, in, of, on, with), his model is es-
sentially inventory-based. On the other hand, noun-
preposition co-occurrences can easily be identified
in a corpus, so an automatic interpretation can be
implemented through simple unsupervised methods.
The disadvantage of this approach is the absence of a
one-to-one mapping from prepositions to meanings;
prepositions can be ambiguous (of indicates many
different relations) or synonymous (at, in and on
all express ‘location’). This concern arises with all
paraphrasing models, but it is exacerbated by the re-
stricted nature of prepositions. Furthermore, many
NCs cannot be paraphrased adequately with prepo-
sitions, e.g., woman driver, honey bee.
A richer, more flexible paraphrasing model is af-
forded by the use of verbs. In such a model, a honey
bee is a bee that produces honey, a sleeping pill
is a pill that induces sleeping and a headache pill
is a pill that relieves headaches. In some previous
computational work on NC interpretation, manually
constructed dictionaries provided typical activities
or functions associated with nouns (Finin, 1980; Is-
abelle, 1984; Johnston and Busa, 1996). It is, how-
ever, impractical to build large structured lexicons
for broad-coverage systems; these methods can only
be applied to specialized domains. On the other
hand, we expect that the ready availability of large
text corpora should facilitate the automatic mining
of rich paraphrase information.
The SemEval-2010 task we present here builds on
the work of Nakov (Nakov and Hearst, 2006; Nakov,
2007; Nakov, 2008b), where NCs are paraphrased
by combinations of verbs and prepositions. Given
the problem of synonymy, we do not provide a sin-
gle correct paraphrase for a given NC but a prob-
ability distribution over a range of candidates. For
example, highly probable paraphrases for chocolate
bar are bar made of chocolate and bar that tastes
like chocolate, while bar that eats chocolate is very
unlikely. As described in Section 3.3, a set of gold-
standard paraphrase distributions can be constructed
by collating responses from a large number of hu-
man subjects.
In this framework, the task of interpretation be-
comes one of identifying the most likely paraphrases
for an NC. Nakov (2008b) and Butnariu and Veale
(2008) have demonstrated that paraphrasing infor-
mation can be collected from corpora in an un-
supervised fashion; we expect that participants in
</bodyText>
<page confidence="0.995285">
102
</page>
<bodyText confidence="0.999421625">
SemEval-2010 Task 9 will further develop suitable
techniques for this problem. Paraphrases of this kind
have been shown to be useful in applications such as
machine translation (Nakov, 2008a) and as an inter-
mediate step in inventory-based classification of ab-
stract relations (Kim and Baldwin, 2006; Nakov and
Hearst, 2008). Progress in paraphrasing is therefore
likely to have follow-on benefits in many areas.
</bodyText>
<sectionHeader confidence="0.996842" genericHeader="method">
3 Task Description
</sectionHeader>
<bodyText confidence="0.999891">
The description of the task we present below is pre-
liminary. We invite the interested reader to visit the
official Website of SemEval-2010 Task 9, where up-
to-date information will be published; there is also a
discussion group and a mailing list.2
</bodyText>
<subsectionHeader confidence="0.998957">
3.1 Preliminary Study
</subsectionHeader>
<bodyText confidence="0.998199368421052">
In a preliminary study, we asked 25-30 human sub-
jects to paraphrase 250 noun-noun compounds us-
ing suitable paraphrasing verbs. This is the Levi-
250 dataset (Levi, 1978); see (Nakov, 2008b) for de-
tails.3 The most popular paraphrases tend to be quite
apt, while some less frequent choices are question-
able. For example, for chocolate bar we obtained
the following paraphrases (the number of subjects
who proposed each one is shown in parentheses):
contain (17); be made of (16); be made
from (10); taste like (7); be composed
of (7); consist of (5); be (3); have (2);
smell of (2); be manufactured from (2);
be formed from (2); melt into (2); serve
(1); sell (1); incorporate (1); be made with
(1); be comprised of (1); be constituted
by (1); be solidified from (1); be flavored
with (1); store (1); be flavored with (1); be
created from (1); taste of (1)
</bodyText>
<subsectionHeader confidence="0.995561">
3.2 Objective
</subsectionHeader>
<bodyText confidence="0.9999734">
We propose a task in which participating systems
must estimate the quality of paraphrases for a test
set of NCs. A list of verb/preposition paraphrases
will be provided for each NC, and for each list a
participating system will be asked to provide aptness
</bodyText>
<footnote confidence="0.98195075">
2Please follow the Task #9 link at the SemEval-2010 home-
page http://semeval2.fbk.eu
3This dataset is available from http://sourceforge.
net/projects/multiword/
</footnote>
<bodyText confidence="0.986629">
scores that correlate well (in terms of frequency dis-
tribution) with the human judgments collated from
our test subjects.
</bodyText>
<subsectionHeader confidence="0.991386">
3.3 Datasets
</subsectionHeader>
<bodyText confidence="0.997769705882353">
Trial/Development Data. As trial/development
data, we will release the previously collected para-
phrase sets for the Levi-250 dataset (after further
review and cleaning). This dataset consists of 250
noun-noun compounds, each paraphrased by 25-30
human subjects (Nakov, 2008b).
Test Data. The test data will consist of approx-
imately 300 NCs, each accompanied by a set of
paraphrasing verbs and prepositions. Following the
methodology of Nakov (2008b), we will use the
Amazon Mechanical Turk Web service4 to recruit
human subjects. This service offers an inexpensive
way to recruit subjects for tasks that require human
intelligence, and provides an API which allows a
computer program to easily run tasks and collate
the responses from human subjects. The Mechanical
Turk is becoming a popular means to elicit and col-
lect linguistic intuitions for NLP research; see Snow
et al. (2008) for an overview and a discussion of is-
sues that arise.
We intend to recruit 100 annotators for each NC,
and we will require each annotator to paraphrase
at least five NCs. Annotators will be given clear
instructions and will be asked to produce one or
more paraphrases for a given NC. To help us filter
out subjects with an insufficient grasp of English or
an insufficient interest in the task, annotators will
be asked to complete a short and simple multiple-
choice pretest on NC comprehension before pro-
ceeding to the paraphrasing step.
Post-processing. We will manually check the
trial/development data and the test data. Depending
on the quality of the paraphrases, we may decide to
drop the least frequent verbs.
</bodyText>
<listItem confidence="0.4558315">
License. All data will be released under the Cre-
ative Commons Attribution 3.0 Unported license5.
</listItem>
<subsectionHeader confidence="0.919093">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.966298333333333">
Single-NC Scores. For each NC, we will compare
human scores (our gold standard) with those pro-
posed by each participating system. We have con-
</bodyText>
<footnote confidence="0.999792">
4http://www.mturk.com
5http://creativecommons.org/licenses/by/3.0/
</footnote>
<page confidence="0.998992">
103
</page>
<bodyText confidence="0.9980585">
sidered three scores: (1) Pearson’s correlation, (2)
cosine similarity, and (3) Spearman’s rank correla-
tion.
Pearson’s correlation coef�cient is a standard
measure of the correlation strength between two dis-
tributions; it can be calculated as follows:
</bodyText>
<equation confidence="0.993781">
E(XY ) − E(X)E(Y)
pE(X2) − [E(X)]2pE(Y 2) − [E(Y )]2
(1)
</equation>
<bodyText confidence="0.976821888888889">
where X = (x1, ... , xn) and Y = (y1, ... , yn) are
vectors of numerical scores for each paraphrase pro-
vided by the humans and the competing systems, re-
spectively, n is the number of paraphrases to score,
and E(X) is the expectation of X.
Cosine correlation coef�cient is another popu-
lar alternative and was used by Nakov and Hearst
(2008); it can be seen as an uncentered version of
Pearson’s correlation coefficient:
</bodyText>
<equation confidence="0.8713165">
X.Y (2)
IIXII IIY II
</equation>
<bodyText confidence="0.998782">
Spearman’s rank correlation coef�cient is suit-
able for comparing rankings of sets of items; it is
a special case of Pearson’s correlation, derived by
considering rank indices (1,2,...) as item scores . It
is defined as follows:
</bodyText>
<equation confidence="0.8341535">
n P xiyi − (P xi)(P yi) q q
n P x2 i − (P xi)2 n P y2 i − (P yi)2 (3)
</equation>
<bodyText confidence="0.992937580645161">
One problem with using Spearman’s rank coef-
ficient for the current task is the assumption that
swapping any two ranks has the same effect. The
often-skewed nature of paraphrase frequency distri-
butions means that swapping some ranks is intu-
itively less “wrong” than swapping others. Consider,
for example, the following list of human-proposed
paraphrasing verbs for child actor, which is given in
Nakov (2007):
be (22); look like (4); portray (3); start as
(1); include (1); play (1); have (1); involve
(1); act like (1); star as (1); work as (1);
mimic (1); pass as (1); resemble (1); be
classified as (1); substitute for (1); qualify
as (1); act as (1)
Clearly, a system that swaps the positions for
be (22) and look like (4) for child actor will
have made a significant error, while swapping con-
tain (17) and be made of (16) for chocolate bar (see
Section 3.1) would be less inappropriate. However,
Spearman’s coefficient treats both alterations iden-
tically since it only looks at ranks; thus, we do not
plan to use it for official evaluation, though it may
be useful for post-hoc analysis.
Final Score. A participating system’s final score
will be the average of the scores it achieves over all
test examples.
Scoring Tool. We will provide an automatic eval-
uation tool that participants can use when train-
ing/tuning/testing their systems. We will use the
same tool for the official evaluation.
</bodyText>
<sectionHeader confidence="0.998369" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999971586206897">
We have presented a noun compound paraphrasing
task that will run as part of SemEval-2010. The goal
of the task is to promote and explore the feasibility
of paraphrase-based methods for compound inter-
pretation. We believe paraphrasing holds some key
advantages over more traditional inventory-based
approaches, such as the ability of paraphrases to rep-
resent fine-grained and overlapping meanings, and
the utility of the resulting paraphrases for other ap-
plications such as Question Answering, Information
Extraction/Retrieval and Machine Translation.
The proposed paraphrasing task is predicated on
two important assumptions: first, that paraphrasing
via a combination of verbs and prepositions pro-
vides a powerful framework for representing and in-
terpreting the meaning of compositional nonlexical-
ized noun compounds; and second, that humans can
agree amongst themselves about what constitutes a
good paraphrase for any given NC. As researchers in
this area and as proponents of this task, we believe
that both assumptions are valid, but if the analysis
of the task were to raise doubts about either assump-
tion (e.g., by showing poor agreement amongst hu-
man annotators), then this in itself would be a mean-
ingful and successful output of the task. As such,
we anticipate that the task and its associated dataset
will inspire further research, both on the theory and
development of paraphrase-based compound inter-
pretation and on its practical applications.
</bodyText>
<equation confidence="0.848076666666667">
P=
P=
P=
</equation>
<page confidence="0.997979">
104
</page>
<sectionHeader confidence="0.996223" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999582171428571">
Timothy Baldwin and Takaaki Tanaka. 2004. Transla-
tion by machine of compound nominals: Getting it
right. In Proceedings of the ACL 2004 Workshop on
Multiword Expressions: Integrating Processing, pages
24–31.
Cristina Butnariu and Tony Veale. 2008. A concept-
centered approach to noun-compound interpretation.
In Proceedings of the 22nd International Conference
on Computational Linguistics (COLING 2008), pages
81–88.
Pamela Downing. 1977. On the creation and use of En-
glish compound nouns. Language, 53(4):810–842.
Timothy Finin. 1980. The Semantic Interpretation of
Compound Nominals. Ph.D. Dissertation, University
of Illinois, Urbana, Illinois.
Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel
Antohe. 2005. On the semantics of noun compounds.
Journal of Computer Speech and Language - Special
Issue on Multiword Expressions, 4(19):479–496.
Roxana Girju. 2007. Improving the interpretation of
noun phrases with cross-linguistic information. In
Proceedings of the 45th Annual Meeting of the Associ-
ation of Computational Linguistics (ACL 2007), pages
568–575.
Pierre Isabelle. 1984. Another look at nominal com-
pounds. In Proceedings of the 10th International Con-
ference on Computational Linguistics, pages 509–516.
Michael Johnston and Frederica Busa. 1996. Qualia
structure and the compositional interpretation of com-
pounds. In Proceedings of the ACL 1996 Workshop on
Breadth and Depth of Semantic Lexicons, pages 77–
88.
Su Nam Kim and Timothy Baldwin. 2006. Interpret-
ing semantic relations in noun compounds via verb
semantics. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics
(COLING/ACL 2006) Main Conference Poster Ses-
sions, pages 491–498.
Mirella Lapata and Alex Lascarides. 2003. Detecting
novel compounds: the role of distributional evidence.
In Proceedings of the 10th conference of the European
chapter of the Association for Computational Linguis-
tics (EACL 2003), pages 235–242.
Mark Lauer. 1995. Designing Statistical Language
Learners: Experiments on Noun Compounds. Ph.D.
thesis, Dept. of Computing, Macquarie University,
Australia.
Judith Levi. 1978. The Syntax and Semantics of Complex
Nominals. Academic Press, New York.
Preslav Nakov and Marti A. Hearst. 2006. Using verbs to
characterize noun-noun relations. In LNCS vol. 4183:
Proceedings of the 12th international conference on
Artificial Intelligence: Methodology, Systems and Ap-
plications (AIMSA 2006), pages 233–244. Springer.
Preslav Nakov and Marti A. Hearst. 2008. Solving re-
lational similarity problems using the web as a cor-
pus. In Proceedings of the 46th Annual Meeting of the
Association of Computational Linguistics (ACL 2008),
pages 452–460.
Preslav Nakov. 2007. Using the Web as an Implicit
Training Set: Application to Noun Compound Syntax
and Semantics. Ph.D. thesis, EECS Department, Uni-
versity of California, Berkeley, UCB/EECS-2007-173.
Preslav Nakov. 2008a. Improved statistical machine
translation using monolingual paraphrases. In Pro-
ceedings of the 18th European Conference on Artificial
Intelligence (ECAI’2008), pages 338–342.
Preslav Nakov. 2008b. Noun compound interpretation
using paraphrasing verbs: Feasibility study. In LNAI
vol. 5253: Proceedings of the 13th international con-
ference on Artificial Intelligence: Methodology, Sys-
tems and Applications (AIMSA 2008), pages 103–117.
Springer.
Vivi Nastase and Stan Szpakowicz. 2003. Exploring
noun-modifier semantic relations. In Proceedings of
the 5th International Workshop on Computational Se-
mantics, pages 285–301.
Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Co-
occurrence contexts for noun compound interpreta-
tion. In Proceedings of the Workshop on A Broader
Perspective on Multiword Expressions, pages 57–64.
Diarmuid O´ S´eaghdha. 2008. Learning Compound Noun
Semantics. Ph.D. thesis, University of Cambridge.
Barbara Rosario and Marti Hearst. 2001. Classify-
ing the semantic relations in noun compounds via a
domain-specific lexical hierarchy. In Proceedings of
the 2001 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2005), pages 82–90.
Mary Ellen Ryder. 1994. Ordered Chaos: The Interpre-
tation of English Noun-Noun Compounds. University
of California Press, Berkeley, CA.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and An-
drew Ng. 2008. Cheap and fast – but is it good?
evaluating non-expert annotations for natural language
tasks. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2008), pages 254–263.
Takaaki Tanaka and Timothy Baldwin. 2003. Noun-
noun compound machine translation: a feasibility
study on shallow processing. In Proceedings of the
ACL 2003 workshop on Multiword expressions, pages
17–24.
Beatrice Warren. 1978. Semantic patterns of noun-noun
compounds. In Gothenburg Studies in English 41,
Goteburg, Acta Universtatis Gothoburgensis.
</reference>
<page confidence="0.999016">
105
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.435866">
<title confidence="0.8622755">SemEval-2010 Task 9: The Interpretation of Noun Using Paraphrasing Verbs and Prepositions</title>
<author confidence="0.999227">Cristina Butnariu Su Nam Kim Preslav Nakov</author>
<affiliation confidence="0.996515">University College Dublin University of Melbourne National University of Singapore</affiliation>
<email confidence="0.641731">ioana.butnariu@ucd.ienkim@csse.unimelb.edu.aunakov@comp.nus.edu.sg</email>
<author confidence="0.99645">O´S´eaghdha Stan Szpakowicz Tony Veale</author>
<affiliation confidence="0.995572">University of Cambridge University of Ottawa University College Dublin Academy of Sciences</affiliation>
<email confidence="0.966095">szpak@site.uottawa.ca</email>
<abstract confidence="0.998252916666667">We present a brief overview of the main challenges in understanding the semantics of noun compounds and consider some known methods. We introduce a new task to be part of SemEval-2010: the interpretation of noun compounds using paraphrasing verbs and prepositions. The task is meant to provide a standard testbed for future research on noun compound semantics. It should also promote paraphrase-based approaches to the problem, which can benefit many NLP applications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Takaaki Tanaka</author>
</authors>
<title>Translation by machine of compound nominals: Getting it right.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL 2004 Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="1236" citStr="Baldwin and Tanaka (2004)" startWordPosition="170" endWordPosition="173">consider some known methods. We introduce a new task to be part of SemEval-2010: the interpretation of noun compounds using paraphrasing verbs and prepositions. The task is meant to provide a standard testbed for future research on noun compound semantics. It should also promote paraphrase-based approaches to the problem, which can benefit many NLP applications. 1 Introduction Noun compounds (NCs) – sequences of two or more nouns acting as a single noun,1 e.g., colon cancer tumor suppressor protein – are abundant in English and pose a major challenge to the automatic analysis of written text. Baldwin and Tanaka (2004) calculated that 3.9% and 2.6% of the tokens in the Reuters corpus and the British National Corpus (BNC), respectively, are part of a noun compound. Compounding is also an extremely productive process in English. The frequency spectrum of compound types follows a Zipfian or power-law distribution ( O´ S´eaghdha, 2008), so in practice many compound tokens encountered belong to a “long tail” of low-frequency types. For example, over half of the two-noun NC types in the BNC occur just once (Lapata and Lascarides, 2003). Even for relatively frequent NCs that occur ten or more times in the BNC, sta</context>
</contexts>
<marker>Baldwin, Tanaka, 2004</marker>
<rawString>Timothy Baldwin and Takaaki Tanaka. 2004. Translation by machine of compound nominals: Getting it right. In Proceedings of the ACL 2004 Workshop on Multiword Expressions: Integrating Processing, pages 24–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Butnariu</author>
<author>Tony Veale</author>
</authors>
<title>A conceptcentered approach to noun-compound interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>81--88</pages>
<contexts>
<context position="2761" citStr="Butnariu and Veale, 2008" startWordPosition="414" endWordPosition="417">rovide a concise means of evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same</context>
<context position="12492" citStr="Butnariu and Veale (2008)" startWordPosition="1871" endWordPosition="1874">he problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability distribution over a range of candidates. For example, highly probable paraphrases for chocolate bar are bar made of chocolate and bar that tastes like chocolate, while bar that eats chocolate is very unlikely. As described in Section 3.3, a set of goldstandard paraphrase distributions can be constructed by collating responses from a large number of human subjects. In this framework, the task of interpretation becomes one of identifying the most likely paraphrases for an NC. Nakov (2008b) and Butnariu and Veale (2008) have demonstrated that paraphrasing information can be collected from corpora in an unsupervised fashion; we expect that participants in 102 SemEval-2010 Task 9 will further develop suitable techniques for this problem. Paraphrases of this kind have been shown to be useful in applications such as machine translation (Nakov, 2008a) and as an intermediate step in inventory-based classification of abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task</context>
</contexts>
<marker>Butnariu, Veale, 2008</marker>
<rawString>Cristina Butnariu and Tony Veale. 2008. A conceptcentered approach to noun-compound interpretation. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Downing</author>
</authors>
<title>On the creation and use of English compound nouns.</title>
<date>1977</date>
<journal>Language,</journal>
<volume>53</volume>
<issue>4</issue>
<contexts>
<context position="1972" citStr="Downing, 1977" startWordPosition="295" endWordPosition="296">e part of a noun compound. Compounding is also an extremely productive process in English. The frequency spectrum of compound types follows a Zipfian or power-law distribution ( O´ S´eaghdha, 2008), so in practice many compound tokens encountered belong to a “long tail” of low-frequency types. For example, over half of the two-noun NC types in the BNC occur just once (Lapata and Lascarides, 2003). Even for relatively frequent NCs that occur ten or more times in the BNC, static English dictionaries give only 27% coverage (Tanaka and Baldwin, 2003). Taken together, 1We follow the definition in (Downing, 1977). the factors of high frequency and high productivity mean that achieving robust NC interpretation is an important goal for broad-coverage semantic processing. NCs provide a concise means of evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challen</context>
<context position="7261" citStr="Downing (1977)" startWordPosition="1092" endWordPosition="1093">SON AFFILIATED, ATTRIBUTE OF CLINICAL STUDY. Inventory-based analyses offer significant advantages. Abstract relations such as ‘location’ and ‘possession’ capture valuable generalizations about NC semantics in a parsimonious framework. Unlike paraphrase-based analyses (Section 2.2), they are not tied to specific lexical items, which may themselves be semantically ambiguous. They also lend themselves particularly well to automatic interpretation methods based on multi-class classification. On the other hand, relation inventories have been criticized on a number of fronts, most influentially by Downing (1977). She argues that the great variety of NC relations makes listing them all impossible; creative NCs like plate length (‘what your hair is when it drags in your food’) are intuitively compositional, but cannot be assigned to any standard inventory category. A second criticism is that restricted inventories are too impoverished a representation scheme for NC semantics, e.g., headache pills and sleeping pills would both be analyzed as FOR in Levi’s classification, but express very different (indeed, contrary) relationships. Downing writes (p. 826): “These interpretations are at best reducible to </context>
<context position="9855" citStr="Downing (1977)" startWordPosition="1458" endWordPosition="1459">nventories of semantic relations for noun compound interpretation. The first two come from linguistic theories; the rest have been proposed in computational linguistics. phrase. Thus, cheese knife and kitchen knife can be expanded as a knife for cutting cheese and a knife used in a kitchen, respectively. In the paraphrasebased paradigm, semantic relations need not come from a small set; it is possible to have many subtle distinctions afforded by the vocabulary of the paraphrasing language (in our case, English). This paradigm avoids the problems of coverage and representational poverty, which Downing (1977) observed in inventory-based approaches. It also reflects cognitive-linguistic theories of NC semantics, in which compounds are held to express underlying event frames and whose constituents are held to denote event participants (Ryder, 1994). Lauer (1995) associates NC semantics with prepositional paraphrases. As Lauer only considers a handful of prepositions (about, at, for, from, in, of, on, with), his model is essentially inventory-based. On the other hand, nounpreposition co-occurrences can easily be identified in a corpus, so an automatic interpretation can be implemented through simple </context>
</contexts>
<marker>Downing, 1977</marker>
<rawString>Pamela Downing. 1977. On the creation and use of English compound nouns. Language, 53(4):810–842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Finin</author>
</authors>
<title>The Semantic Interpretation of Compound Nominals.</title>
<date>1980</date>
<tech>Ph.D.</tech>
<institution>Dissertation, University of Illinois,</institution>
<location>Urbana, Illinois.</location>
<contexts>
<context position="11329" citStr="Finin, 1980" startWordPosition="1684" endWordPosition="1685">arises with all paraphrasing models, but it is exacerbated by the restricted nature of prepositions. Furthermore, many NCs cannot be paraphrased adequately with prepositions, e.g., woman driver, honey bee. A richer, more flexible paraphrasing model is afforded by the use of verbs. In such a model, a honey bee is a bee that produces honey, a sleeping pill is a pill that induces sleeping and a headache pill is a pill that relieves headaches. In some previous computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct par</context>
</contexts>
<marker>Finin, 1980</marker>
<rawString>Timothy Finin. 1980. The Semantic Interpretation of Compound Nominals. Ph.D. Dissertation, University of Illinois, Urbana, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Dan Moldovan</author>
<author>Marta Tatu</author>
<author>Daniel Antohe</author>
</authors>
<title>On the semantics of noun compounds.</title>
<date>2005</date>
<journal>Journal of Computer Speech and Language - Special Issue on Multiword Expressions,</journal>
<volume>4</volume>
<issue>19</issue>
<contexts>
<context position="6190" citStr="Girju et al. (2005)" startWordPosition="935" endWordPosition="938">cate deletion and nominalization; each process is associated with its own inventory of semantic categories. Table 1 lists the categories for the former. Warren (1978) posits a hierarchical classification scheme derived from a large-scale corpus study of NCs. The top-level relations in her hierarchy are listed in Table 1, while the next level subdivides CONSTITUTE into SOURCE-RESULT, RESULT-SOURCE and COPULA; COPULA is then further subdivided at two additional levels. In computational linguistics, popular inventories of semantic relations have been proposed by Nastase and Szpakowicz (2003) and Girju et al. (2005), among others. The former groups 30 finegrained relations into five coarse-grained supercategories, while the latter is a flat list of 21 relations. Both schemes are intended to be suitable for broad-coverage analysis of text. For specialized applications, however, it is often useful to use domain-specific relations. For example, Rosario and Hearst (2001) propose 18 abstract relations for interpreting NCs in biomedical text, e.g., DEFECT, MATERIAL, PERSON AFFILIATED, ATTRIBUTE OF CLINICAL STUDY. Inventory-based analyses offer significant advantages. Abstract relations such as ‘location’ and ‘</context>
<context position="8950" citStr="Girju et al. (2005)" startWordPosition="1332" endWordPosition="1335">h compound with an explanatory para101 Author(s) Relation Inventory Levi (1978) CAUSE, HAVE, MAKE, USE, BE, IN, FOR, FROM, ABOUT Warren (1978) POSSESSION, LOCATION, PURPOSE, ACTIVITY-ACTOR, RESEMBLANCE, CONSTITUTE Nastase and CAUSALITY (cause, effect, detraction, purpose), Szpakowicz PARTICIPANT (agent, beneficiary, instrument, object property, (2003) object, part, possessor, property, product, source, whole, stative), QUALITY(container, content, equative, material, measure, topic, type), SPATIAL (direction, location at, location from, location), TEMPORALITY (frequency, time at, time through) Girju et al. (2005) POSSESSION, ATTRIBUTE-HOLDER, AGENT, TEMPORAL, PART-WHOLE, IS-A, CAUSE, MAKE/PRODUCE, INSTRUMENT, LOCATION/SPACE, PURPOSE, SOURCE, TOPIC, MANNER, MEANS,THEME,ACCOMPANIMENT,EXPERIENCER,RECIPIENT,MEASURE,RESULT Lauer(1995) OF, FOR, IN, AT, ON, FROM, WITH, ABOUT Table 1: Previously proposed inventories of semantic relations for noun compound interpretation. The first two come from linguistic theories; the rest have been proposed in computational linguistics. phrase. Thus, cheese knife and kitchen knife can be expanded as a knife for cutting cheese and a knife used in a kitchen, respectively. In </context>
</contexts>
<marker>Girju, Moldovan, Tatu, Antohe, 2005</marker>
<rawString>Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel Antohe. 2005. On the semantics of noun compounds. Journal of Computer Speech and Language - Special Issue on Multiword Expressions, 4(19):479–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
</authors>
<title>Improving the interpretation of noun phrases with cross-linguistic information.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL</booktitle>
<pages>568--575</pages>
<contexts>
<context position="2774" citStr="Girju, 2007" startWordPosition="418" endWordPosition="419">evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when</context>
</contexts>
<marker>Girju, 2007</marker>
<rawString>Roxana Girju. 2007. Improving the interpretation of noun phrases with cross-linguistic information. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL 2007), pages 568–575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
</authors>
<title>Another look at nominal compounds.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics,</booktitle>
<pages>509--516</pages>
<contexts>
<context position="11345" citStr="Isabelle, 1984" startWordPosition="1686" endWordPosition="1688">ll paraphrasing models, but it is exacerbated by the restricted nature of prepositions. Furthermore, many NCs cannot be paraphrased adequately with prepositions, e.g., woman driver, honey bee. A richer, more flexible paraphrasing model is afforded by the use of verbs. In such a model, a honey bee is a bee that produces honey, a sleeping pill is a pill that induces sleeping and a headache pill is a pill that relieves headaches. In some previous computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a gi</context>
</contexts>
<marker>Isabelle, 1984</marker>
<rawString>Pierre Isabelle. 1984. Another look at nominal compounds. In Proceedings of the 10th International Conference on Computational Linguistics, pages 509–516.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Johnston</author>
<author>Frederica Busa</author>
</authors>
<title>Qualia structure and the compositional interpretation of compounds.</title>
<date>1996</date>
<booktitle>In Proceedings of the ACL 1996 Workshop on Breadth and Depth of Semantic Lexicons,</booktitle>
<pages>77--88</pages>
<contexts>
<context position="11371" citStr="Johnston and Busa, 1996" startWordPosition="1689" endWordPosition="1692">models, but it is exacerbated by the restricted nature of prepositions. Furthermore, many NCs cannot be paraphrased adequately with prepositions, e.g., woman driver, honey bee. A richer, more flexible paraphrasing model is afforded by the use of verbs. In such a model, a honey bee is a bee that produces honey, a sleeping pill is a pill that induces sleeping and a headache pill is a pill that relieves headaches. In some previous computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability d</context>
</contexts>
<marker>Johnston, Busa, 1996</marker>
<rawString>Michael Johnston and Frederica Busa. 1996. Qualia structure and the compositional interpretation of compounds. In Proceedings of the ACL 1996 Workshop on Breadth and Depth of Semantic Lexicons, pages 77– 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Interpreting semantic relations in noun compounds via verb semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (COLING/ACL 2006) Main Conference Poster Sessions,</booktitle>
<pages>491--498</pages>
<contexts>
<context position="2797" citStr="Kim and Baldwin, 2006" startWordPosition="420" endWordPosition="423">ationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when used in the same docum</context>
<context position="12932" citStr="Kim and Baldwin, 2006" startWordPosition="1939" endWordPosition="1942">number of human subjects. In this framework, the task of interpretation becomes one of identifying the most likely paraphrases for an NC. Nakov (2008b) and Butnariu and Veale (2008) have demonstrated that paraphrasing information can be collected from corpora in an unsupervised fashion; we expect that participants in 102 SemEval-2010 Task 9 will further develop suitable techniques for this problem. Paraphrases of this kind have been shown to be useful in applications such as machine translation (Nakov, 2008a) and as an intermediate step in inventory-based classification of abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task we present below is preliminary. We invite the interested reader to visit the official Website of SemEval-2010 Task 9, where upto-date information will be published; there is also a discussion group and a mailing list.2 3.1 Preliminary Study In a preliminary study, we asked 25-30 human subjects to paraphrase 250 noun-noun compounds using suitable paraphrasing verbs. This is the Levi250 dataset (Levi, 1978); see (Nakov, 2008b) for detai</context>
</contexts>
<marker>Kim, Baldwin, 2006</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2006. Interpreting semantic relations in noun compounds via verb semantics. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (COLING/ACL 2006) Main Conference Poster Sessions, pages 491–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Detecting novel compounds: the role of distributional evidence.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th conference of the European chapter of the Association for Computational Linguistics (EACL</booktitle>
<pages>235--242</pages>
<contexts>
<context position="1757" citStr="Lapata and Lascarides, 2003" startWordPosition="258" endWordPosition="261"> in English and pose a major challenge to the automatic analysis of written text. Baldwin and Tanaka (2004) calculated that 3.9% and 2.6% of the tokens in the Reuters corpus and the British National Corpus (BNC), respectively, are part of a noun compound. Compounding is also an extremely productive process in English. The frequency spectrum of compound types follows a Zipfian or power-law distribution ( O´ S´eaghdha, 2008), so in practice many compound tokens encountered belong to a “long tail” of low-frequency types. For example, over half of the two-noun NC types in the BNC occur just once (Lapata and Lascarides, 2003). Even for relatively frequent NCs that occur ten or more times in the BNC, static English dictionaries give only 27% coverage (Tanaka and Baldwin, 2003). Taken together, 1We follow the definition in (Downing, 1977). the factors of high frequency and high productivity mean that achieving robust NC interpretation is an important goal for broad-coverage semantic processing. NCs provide a concise means of evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable s</context>
</contexts>
<marker>Lapata, Lascarides, 2003</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2003. Detecting novel compounds: the role of distributional evidence. In Proceedings of the 10th conference of the European chapter of the Association for Computational Linguistics (EACL 2003), pages 235–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Lauer</author>
</authors>
<title>Designing Statistical Language Learners: Experiments on Noun Compounds.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. of Computing, Macquarie University, Australia.</institution>
<contexts>
<context position="10111" citStr="Lauer (1995)" startWordPosition="1496" endWordPosition="1497">se and a knife used in a kitchen, respectively. In the paraphrasebased paradigm, semantic relations need not come from a small set; it is possible to have many subtle distinctions afforded by the vocabulary of the paraphrasing language (in our case, English). This paradigm avoids the problems of coverage and representational poverty, which Downing (1977) observed in inventory-based approaches. It also reflects cognitive-linguistic theories of NC semantics, in which compounds are held to express underlying event frames and whose constituents are held to denote event participants (Ryder, 1994). Lauer (1995) associates NC semantics with prepositional paraphrases. As Lauer only considers a handful of prepositions (about, at, for, from, in, of, on, with), his model is essentially inventory-based. On the other hand, nounpreposition co-occurrences can easily be identified in a corpus, so an automatic interpretation can be implemented through simple unsupervised methods. The disadvantage of this approach is the absence of a one-to-one mapping from prepositions to meanings; prepositions can be ambiguous (of indicates many different relations) or synonymous (at, in and on all express ‘location’). This c</context>
</contexts>
<marker>Lauer, 1995</marker>
<rawString>Mark Lauer. 1995. Designing Statistical Language Learners: Experiments on Noun Compounds. Ph.D. thesis, Dept. of Computing, Macquarie University, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="5295" citStr="Levi (1978)" startWordPosition="806" endWordPosition="807">ers a conclusion. 2 Models of Relational Semantics in NCs 2.1 Inventory-Based Semantics The prevalent view in theoretical and computational linguistics holds that the semantic relations that implicitly link the nouns of an NC can be adequately enumerated via a small inventory of abstract relational categories. In this view, mountain hut, field mouse and village feast all express ‘location in space’, while the relation implicit in history book and nativity play can be characterized as ‘topicality’ or ‘aboutness’. A sample of some of the most influential relation inventories appears in Table 1. Levi (1978) proposes that complex nominals – a general concept grouping together nominal compounds (e.g., peanut butter), nominalizations (e.g., dream analysis) and non-predicative noun phrases (e.g., electric shock) – are derived through the complementary processes of recoverable predicate deletion and nominalization; each process is associated with its own inventory of semantic categories. Table 1 lists the categories for the former. Warren (1978) posits a hierarchical classification scheme derived from a large-scale corpus study of NCs. The top-level relations in her hierarchy are listed in Table 1, w</context>
<context position="8410" citStr="Levi (1978)" startWordPosition="1270" endWordPosition="1271">tes (p. 826): “These interpretations are at best reducible to underlying relationships..., but only with the loss of much of the semantic material considered by subjects to be relevant or essential to the definitions.” A further drawback associated with sets of abstract relations is that it is difficult to identify the “correct” inventory or to decide whether one proposed classification scheme should be favored over another. 2.2 Interpretation Using Verbal Paraphrases An alternative approach to NC interpretation associates each compound with an explanatory para101 Author(s) Relation Inventory Levi (1978) CAUSE, HAVE, MAKE, USE, BE, IN, FOR, FROM, ABOUT Warren (1978) POSSESSION, LOCATION, PURPOSE, ACTIVITY-ACTOR, RESEMBLANCE, CONSTITUTE Nastase and CAUSALITY (cause, effect, detraction, purpose), Szpakowicz PARTICIPANT (agent, beneficiary, instrument, object property, (2003) object, part, possessor, property, product, source, whole, stative), QUALITY(container, content, equative, material, measure, topic, type), SPATIAL (direction, location at, location from, location), TEMPORALITY (frequency, time at, time through) Girju et al. (2005) POSSESSION, ATTRIBUTE-HOLDER, AGENT, TEMPORAL, PART-WHOLE, </context>
<context position="13502" citStr="Levi, 1978" startWordPosition="2034" endWordPosition="2035">abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task we present below is preliminary. We invite the interested reader to visit the official Website of SemEval-2010 Task 9, where upto-date information will be published; there is also a discussion group and a mailing list.2 3.1 Preliminary Study In a preliminary study, we asked 25-30 human subjects to paraphrase 250 noun-noun compounds using suitable paraphrasing verbs. This is the Levi250 dataset (Levi, 1978); see (Nakov, 2008b) for details.3 The most popular paraphrases tend to be quite apt, while some less frequent choices are questionable. For example, for chocolate bar we obtained the following paraphrases (the number of subjects who proposed each one is shown in parentheses): contain (17); be made of (16); be made from (10); taste like (7); be composed of (7); consist of (5); be (3); have (2); smell of (2); be manufactured from (2); be formed from (2); melt into (2); serve (1); sell (1); incorporate (1); be made with (1); be comprised of (1); be constituted by (1); be solidified from (1); be </context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Judith Levi. 1978. The Syntax and Semantics of Complex Nominals. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti A Hearst</author>
</authors>
<title>Using verbs to characterize noun-noun relations.</title>
<date>2006</date>
<booktitle>In LNCS vol. 4183: Proceedings of the 12th international conference on Artificial Intelligence: Methodology, Systems and Applications (AIMSA</booktitle>
<pages>233--244</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="11761" citStr="Nakov and Hearst, 2006" startWordPosition="1750" endWordPosition="1753">at relieves headaches. In some previous computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability distribution over a range of candidates. For example, highly probable paraphrases for chocolate bar are bar made of chocolate and bar that tastes like chocolate, while bar that eats chocolate is very unlikely. As described in Section 3.3, a set of goldstandard paraphrase distributions can be constructed by collating responses from a large number of human subjects. In this framework, the t</context>
</contexts>
<marker>Nakov, Hearst, 2006</marker>
<rawString>Preslav Nakov and Marti A. Hearst. 2006. Using verbs to characterize noun-noun relations. In LNCS vol. 4183: Proceedings of the 12th international conference on Artificial Intelligence: Methodology, Systems and Applications (AIMSA 2006), pages 233–244. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti A Hearst</author>
</authors>
<title>Solving relational similarity problems using the web as a corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association of Computational Linguistics (ACL</booktitle>
<pages>452--460</pages>
<contexts>
<context position="12957" citStr="Nakov and Hearst, 2008" startWordPosition="1943" endWordPosition="1946">s. In this framework, the task of interpretation becomes one of identifying the most likely paraphrases for an NC. Nakov (2008b) and Butnariu and Veale (2008) have demonstrated that paraphrasing information can be collected from corpora in an unsupervised fashion; we expect that participants in 102 SemEval-2010 Task 9 will further develop suitable techniques for this problem. Paraphrases of this kind have been shown to be useful in applications such as machine translation (Nakov, 2008a) and as an intermediate step in inventory-based classification of abstract relations (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task we present below is preliminary. We invite the interested reader to visit the official Website of SemEval-2010 Task 9, where upto-date information will be published; there is also a discussion group and a mailing list.2 3.1 Preliminary Study In a preliminary study, we asked 25-30 human subjects to paraphrase 250 noun-noun compounds using suitable paraphrasing verbs. This is the Levi250 dataset (Levi, 1978); see (Nakov, 2008b) for details.3 The most popular par</context>
<context position="17326" citStr="Nakov and Hearst (2008)" startWordPosition="2655" endWordPosition="2658"> Pearson’s correlation, (2) cosine similarity, and (3) Spearman’s rank correlation. Pearson’s correlation coef�cient is a standard measure of the correlation strength between two distributions; it can be calculated as follows: E(XY ) − E(X)E(Y) pE(X2) − [E(X)]2pE(Y 2) − [E(Y )]2 (1) where X = (x1, ... , xn) and Y = (y1, ... , yn) are vectors of numerical scores for each paraphrase provided by the humans and the competing systems, respectively, n is the number of paraphrases to score, and E(X) is the expectation of X. Cosine correlation coef�cient is another popular alternative and was used by Nakov and Hearst (2008); it can be seen as an uncentered version of Pearson’s correlation coefficient: X.Y (2) IIXII IIY II Spearman’s rank correlation coef�cient is suitable for comparing rankings of sets of items; it is a special case of Pearson’s correlation, derived by considering rank indices (1,2,...) as item scores . It is defined as follows: n P xiyi − (P xi)(P yi) q q n P x2 i − (P xi)2 n P y2 i − (P yi)2 (3) One problem with using Spearman’s rank coefficient for the current task is the assumption that swapping any two ranks has the same effect. The often-skewed nature of paraphrase frequency distributions </context>
</contexts>
<marker>Nakov, Hearst, 2008</marker>
<rawString>Preslav Nakov and Marti A. Hearst. 2008. Solving relational similarity problems using the web as a corpus. In Proceedings of the 46th Annual Meeting of the Association of Computational Linguistics (ACL 2008), pages 452–460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
</authors>
<title>Using the Web as an Implicit Training Set: Application to Noun Compound Syntax and Semantics.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<pages>2007--173</pages>
<institution>EECS Department, University of California, Berkeley,</institution>
<contexts>
<context position="11774" citStr="Nakov, 2007" startWordPosition="1754" endWordPosition="1755">n some previous computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability distribution over a range of candidates. For example, highly probable paraphrases for chocolate bar are bar made of chocolate and bar that tastes like chocolate, while bar that eats chocolate is very unlikely. As described in Section 3.3, a set of goldstandard paraphrase distributions can be constructed by collating responses from a large number of human subjects. In this framework, the task of interp</context>
<context position="18133" citStr="Nakov (2007)" startWordPosition="2799" endWordPosition="2800"> is a special case of Pearson’s correlation, derived by considering rank indices (1,2,...) as item scores . It is defined as follows: n P xiyi − (P xi)(P yi) q q n P x2 i − (P xi)2 n P y2 i − (P yi)2 (3) One problem with using Spearman’s rank coefficient for the current task is the assumption that swapping any two ranks has the same effect. The often-skewed nature of paraphrase frequency distributions means that swapping some ranks is intuitively less “wrong” than swapping others. Consider, for example, the following list of human-proposed paraphrasing verbs for child actor, which is given in Nakov (2007): be (22); look like (4); portray (3); start as (1); include (1); play (1); have (1); involve (1); act like (1); star as (1); work as (1); mimic (1); pass as (1); resemble (1); be classified as (1); substitute for (1); qualify as (1); act as (1) Clearly, a system that swaps the positions for be (22) and look like (4) for child actor will have made a significant error, while swapping contain (17) and be made of (16) for chocolate bar (see Section 3.1) would be less inappropriate. However, Spearman’s coefficient treats both alterations identically since it only looks at ranks; thus, we do not pl</context>
</contexts>
<marker>Nakov, 2007</marker>
<rawString>Preslav Nakov. 2007. Using the Web as an Implicit Training Set: Application to Noun Compound Syntax and Semantics. Ph.D. thesis, EECS Department, University of California, Berkeley, UCB/EECS-2007-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
</authors>
<title>Improved statistical machine translation using monolingual paraphrases.</title>
<date>2008</date>
<booktitle>In Proceedings of the 18th European Conference on Artificial Intelligence (ECAI’2008),</booktitle>
<pages>338--342</pages>
<contexts>
<context position="2810" citStr="Nakov, 2008" startWordPosition="424" endWordPosition="425">r more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when used in the same document. Similarl</context>
<context position="11787" citStr="Nakov, 2008" startWordPosition="1756" endWordPosition="1757">us computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability distribution over a range of candidates. For example, highly probable paraphrases for chocolate bar are bar made of chocolate and bar that tastes like chocolate, while bar that eats chocolate is very unlikely. As described in Section 3.3, a set of goldstandard paraphrase distributions can be constructed by collating responses from a large number of human subjects. In this framework, the task of interpretation beco</context>
<context position="13520" citStr="Nakov, 2008" startWordPosition="2037" endWordPosition="2038"> (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task we present below is preliminary. We invite the interested reader to visit the official Website of SemEval-2010 Task 9, where upto-date information will be published; there is also a discussion group and a mailing list.2 3.1 Preliminary Study In a preliminary study, we asked 25-30 human subjects to paraphrase 250 noun-noun compounds using suitable paraphrasing verbs. This is the Levi250 dataset (Levi, 1978); see (Nakov, 2008b) for details.3 The most popular paraphrases tend to be quite apt, while some less frequent choices are questionable. For example, for chocolate bar we obtained the following paraphrases (the number of subjects who proposed each one is shown in parentheses): contain (17); be made of (16); be made from (10); taste like (7); be composed of (7); consist of (5); be (3); have (2); smell of (2); be manufactured from (2); be formed from (2); melt into (2); serve (1); sell (1); incorporate (1); be made with (1); be comprised of (1); be constituted by (1); be solidified from (1); be flavored with (1);</context>
<context position="15026" citStr="Nakov, 2008" startWordPosition="2280" endWordPosition="2281">ng system will be asked to provide aptness 2Please follow the Task #9 link at the SemEval-2010 homepage http://semeval2.fbk.eu 3This dataset is available from http://sourceforge. net/projects/multiword/ scores that correlate well (in terms of frequency distribution) with the human judgments collated from our test subjects. 3.3 Datasets Trial/Development Data. As trial/development data, we will release the previously collected paraphrase sets for the Levi-250 dataset (after further review and cleaning). This dataset consists of 250 noun-noun compounds, each paraphrased by 25-30 human subjects (Nakov, 2008b). Test Data. The test data will consist of approximately 300 NCs, each accompanied by a set of paraphrasing verbs and prepositions. Following the methodology of Nakov (2008b), we will use the Amazon Mechanical Turk Web service4 to recruit human subjects. This service offers an inexpensive way to recruit subjects for tasks that require human intelligence, and provides an API which allows a computer program to easily run tasks and collate the responses from human subjects. The Mechanical Turk is becoming a popular means to elicit and collect linguistic intuitions for NLP research; see Snow et </context>
</contexts>
<marker>Nakov, 2008</marker>
<rawString>Preslav Nakov. 2008a. Improved statistical machine translation using monolingual paraphrases. In Proceedings of the 18th European Conference on Artificial Intelligence (ECAI’2008), pages 338–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
</authors>
<title>Noun compound interpretation using paraphrasing verbs: Feasibility study.</title>
<date>2008</date>
<booktitle>In LNAI vol. 5253: Proceedings of the 13th international conference on Artificial Intelligence: Methodology, Systems and Applications (AIMSA</booktitle>
<pages>103--117</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2810" citStr="Nakov, 2008" startWordPosition="424" endWordPosition="425">r more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when used in the same document. Similarl</context>
<context position="11787" citStr="Nakov, 2008" startWordPosition="1756" endWordPosition="1757">us computational work on NC interpretation, manually constructed dictionaries provided typical activities or functions associated with nouns (Finin, 1980; Isabelle, 1984; Johnston and Busa, 1996). It is, however, impractical to build large structured lexicons for broad-coverage systems; these methods can only be applied to specialized domains. On the other hand, we expect that the ready availability of large text corpora should facilitate the automatic mining of rich paraphrase information. The SemEval-2010 task we present here builds on the work of Nakov (Nakov and Hearst, 2006; Nakov, 2007; Nakov, 2008b), where NCs are paraphrased by combinations of verbs and prepositions. Given the problem of synonymy, we do not provide a single correct paraphrase for a given NC but a probability distribution over a range of candidates. For example, highly probable paraphrases for chocolate bar are bar made of chocolate and bar that tastes like chocolate, while bar that eats chocolate is very unlikely. As described in Section 3.3, a set of goldstandard paraphrase distributions can be constructed by collating responses from a large number of human subjects. In this framework, the task of interpretation beco</context>
<context position="13520" citStr="Nakov, 2008" startWordPosition="2037" endWordPosition="2038"> (Kim and Baldwin, 2006; Nakov and Hearst, 2008). Progress in paraphrasing is therefore likely to have follow-on benefits in many areas. 3 Task Description The description of the task we present below is preliminary. We invite the interested reader to visit the official Website of SemEval-2010 Task 9, where upto-date information will be published; there is also a discussion group and a mailing list.2 3.1 Preliminary Study In a preliminary study, we asked 25-30 human subjects to paraphrase 250 noun-noun compounds using suitable paraphrasing verbs. This is the Levi250 dataset (Levi, 1978); see (Nakov, 2008b) for details.3 The most popular paraphrases tend to be quite apt, while some less frequent choices are questionable. For example, for chocolate bar we obtained the following paraphrases (the number of subjects who proposed each one is shown in parentheses): contain (17); be made of (16); be made from (10); taste like (7); be composed of (7); consist of (5); be (3); have (2); smell of (2); be manufactured from (2); be formed from (2); melt into (2); serve (1); sell (1); incorporate (1); be made with (1); be comprised of (1); be constituted by (1); be solidified from (1); be flavored with (1);</context>
<context position="15026" citStr="Nakov, 2008" startWordPosition="2280" endWordPosition="2281">ng system will be asked to provide aptness 2Please follow the Task #9 link at the SemEval-2010 homepage http://semeval2.fbk.eu 3This dataset is available from http://sourceforge. net/projects/multiword/ scores that correlate well (in terms of frequency distribution) with the human judgments collated from our test subjects. 3.3 Datasets Trial/Development Data. As trial/development data, we will release the previously collected paraphrase sets for the Levi-250 dataset (after further review and cleaning). This dataset consists of 250 noun-noun compounds, each paraphrased by 25-30 human subjects (Nakov, 2008b). Test Data. The test data will consist of approximately 300 NCs, each accompanied by a set of paraphrasing verbs and prepositions. Following the methodology of Nakov (2008b), we will use the Amazon Mechanical Turk Web service4 to recruit human subjects. This service offers an inexpensive way to recruit subjects for tasks that require human intelligence, and provides an API which allows a computer program to easily run tasks and collate the responses from human subjects. The Mechanical Turk is becoming a popular means to elicit and collect linguistic intuitions for NLP research; see Snow et </context>
</contexts>
<marker>Nakov, 2008</marker>
<rawString>Preslav Nakov. 2008b. Noun compound interpretation using paraphrasing verbs: Feasibility study. In LNAI vol. 5253: Proceedings of the 13th international conference on Artificial Intelligence: Methodology, Systems and Applications (AIMSA 2008), pages 103–117. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Exploring noun-modifier semantic relations.</title>
<date>2003</date>
<booktitle>In Proceedings of the 5th International Workshop on Computational Semantics,</booktitle>
<pages>285--301</pages>
<contexts>
<context position="2841" citStr="Nastase and Szpakowicz, 2003" startWordPosition="426" endWordPosition="429">and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to build a lexicon of all NCs likely to be encountered. The challenges presented by NCs and their semantics have generated significant ongoing interest in NC interpretation in the NLP community. Representative publications include (Butnariu and Veale, 2008; Girju, 2007; Kim and Baldwin, 2006; Nakov, 2008b; Nastase and Szpakowicz, 2003; O´ S´eaghdha and Copestake, 2007). Applications that have been suggested include Question Answering, Machine Translation, Information Retrieval and Information Extraction. For example, a question-answering system may need to determine whether headaches induced by caffeine withdrawal is a good paraphrase for caffeine headaches when answering questions about the causes of headaches, while an information extraction system may need to decide whether caffeine withdrawal headache and caffeine headache refer to the same concept when used in the same document. Similarly, a machine translation system</context>
<context position="6166" citStr="Nastase and Szpakowicz (2003)" startWordPosition="930" endWordPosition="933">ary processes of recoverable predicate deletion and nominalization; each process is associated with its own inventory of semantic categories. Table 1 lists the categories for the former. Warren (1978) posits a hierarchical classification scheme derived from a large-scale corpus study of NCs. The top-level relations in her hierarchy are listed in Table 1, while the next level subdivides CONSTITUTE into SOURCE-RESULT, RESULT-SOURCE and COPULA; COPULA is then further subdivided at two additional levels. In computational linguistics, popular inventories of semantic relations have been proposed by Nastase and Szpakowicz (2003) and Girju et al. (2005), among others. The former groups 30 finegrained relations into five coarse-grained supercategories, while the latter is a flat list of 21 relations. Both schemes are intended to be suitable for broad-coverage analysis of text. For specialized applications, however, it is often useful to use domain-specific relations. For example, Rosario and Hearst (2001) propose 18 abstract relations for interpreting NCs in biomedical text, e.g., DEFECT, MATERIAL, PERSON AFFILIATED, ATTRIBUTE OF CLINICAL STUDY. Inventory-based analyses offer significant advantages. Abstract relations </context>
</contexts>
<marker>Nastase, Szpakowicz, 2003</marker>
<rawString>Vivi Nastase and Stan Szpakowicz. 2003. Exploring noun-modifier semantic relations. In Proceedings of the 5th International Workshop on Computational Semantics, pages 285–301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Cooccurrence contexts for noun compound interpretation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions,</booktitle>
<pages>57--64</pages>
<marker>S´eaghdha, Copestake, 2007</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. 2007. Cooccurrence contexts for noun compound interpretation. In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
</authors>
<title>Learning Compound Noun Semantics.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<marker>S´eaghdha, 2008</marker>
<rawString>Diarmuid O´ S´eaghdha. 2008. Learning Compound Noun Semantics. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti Hearst</author>
</authors>
<title>Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>82--90</pages>
<contexts>
<context position="6548" citStr="Rosario and Hearst (2001)" startWordPosition="992" endWordPosition="995">es CONSTITUTE into SOURCE-RESULT, RESULT-SOURCE and COPULA; COPULA is then further subdivided at two additional levels. In computational linguistics, popular inventories of semantic relations have been proposed by Nastase and Szpakowicz (2003) and Girju et al. (2005), among others. The former groups 30 finegrained relations into five coarse-grained supercategories, while the latter is a flat list of 21 relations. Both schemes are intended to be suitable for broad-coverage analysis of text. For specialized applications, however, it is often useful to use domain-specific relations. For example, Rosario and Hearst (2001) propose 18 abstract relations for interpreting NCs in biomedical text, e.g., DEFECT, MATERIAL, PERSON AFFILIATED, ATTRIBUTE OF CLINICAL STUDY. Inventory-based analyses offer significant advantages. Abstract relations such as ‘location’ and ‘possession’ capture valuable generalizations about NC semantics in a parsimonious framework. Unlike paraphrase-based analyses (Section 2.2), they are not tied to specific lexical items, which may themselves be semantically ambiguous. They also lend themselves particularly well to automatic interpretation methods based on multi-class classification. On the </context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>Barbara Rosario and Marti Hearst. 2001. Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP 2005), pages 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Ryder</author>
</authors>
<title>Ordered Chaos: The Interpretation of English Noun-Noun Compounds.</title>
<date>1994</date>
<publisher>University of California Press,</publisher>
<location>Berkeley, CA.</location>
<contexts>
<context position="10097" citStr="Ryder, 1994" startWordPosition="1494" endWordPosition="1495">r cutting cheese and a knife used in a kitchen, respectively. In the paraphrasebased paradigm, semantic relations need not come from a small set; it is possible to have many subtle distinctions afforded by the vocabulary of the paraphrasing language (in our case, English). This paradigm avoids the problems of coverage and representational poverty, which Downing (1977) observed in inventory-based approaches. It also reflects cognitive-linguistic theories of NC semantics, in which compounds are held to express underlying event frames and whose constituents are held to denote event participants (Ryder, 1994). Lauer (1995) associates NC semantics with prepositional paraphrases. As Lauer only considers a handful of prepositions (about, at, for, from, in, of, on, with), his model is essentially inventory-based. On the other hand, nounpreposition co-occurrences can easily be identified in a corpus, so an automatic interpretation can be implemented through simple unsupervised methods. The disadvantage of this approach is the absence of a one-to-one mapping from prepositions to meanings; prepositions can be ambiguous (of indicates many different relations) or synonymous (at, in and on all express ‘loca</context>
</contexts>
<marker>Ryder, 1994</marker>
<rawString>Mary Ellen Ryder. 1994. Ordered Chaos: The Interpretation of English Noun-Noun Compounds. University of California Press, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Ng</author>
</authors>
<title>Cheap and fast – but is it good? evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>254--263</pages>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Ng. 2008. Cheap and fast – but is it good? evaluating non-expert annotations for natural language tasks. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 254–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Tanaka</author>
<author>Timothy Baldwin</author>
</authors>
<title>Nounnoun compound machine translation: a feasibility study on shallow processing.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 workshop on Multiword expressions,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="1910" citStr="Tanaka and Baldwin, 2003" startWordPosition="284" endWordPosition="287">he Reuters corpus and the British National Corpus (BNC), respectively, are part of a noun compound. Compounding is also an extremely productive process in English. The frequency spectrum of compound types follows a Zipfian or power-law distribution ( O´ S´eaghdha, 2008), so in practice many compound tokens encountered belong to a “long tail” of low-frequency types. For example, over half of the two-noun NC types in the BNC occur just once (Lapata and Lascarides, 2003). Even for relatively frequent NCs that occur ten or more times in the BNC, static English dictionaries give only 27% coverage (Tanaka and Baldwin, 2003). Taken together, 1We follow the definition in (Downing, 1977). the factors of high frequency and high productivity mean that achieving robust NC interpretation is an important goal for broad-coverage semantic processing. NCs provide a concise means of evoking a relationship between two or more nouns, and natural language processing (NLP) systems that do not try to recover these implicit relations from NCs are effectively discarding valuable semantic information. Broad coverage should therefore be achieved by post-hoc interpretation rather than pre-hoc enumeration, since it is impossible to bu</context>
</contexts>
<marker>Tanaka, Baldwin, 2003</marker>
<rawString>Takaaki Tanaka and Timothy Baldwin. 2003. Nounnoun compound machine translation: a feasibility study on shallow processing. In Proceedings of the ACL 2003 workshop on Multiword expressions, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Warren</author>
</authors>
<title>Semantic patterns of noun-noun compounds.</title>
<date>1978</date>
<booktitle>In Gothenburg Studies in English 41, Goteburg, Acta Universtatis Gothoburgensis.</booktitle>
<contexts>
<context position="5737" citStr="Warren (1978)" startWordPosition="869" endWordPosition="870">y book and nativity play can be characterized as ‘topicality’ or ‘aboutness’. A sample of some of the most influential relation inventories appears in Table 1. Levi (1978) proposes that complex nominals – a general concept grouping together nominal compounds (e.g., peanut butter), nominalizations (e.g., dream analysis) and non-predicative noun phrases (e.g., electric shock) – are derived through the complementary processes of recoverable predicate deletion and nominalization; each process is associated with its own inventory of semantic categories. Table 1 lists the categories for the former. Warren (1978) posits a hierarchical classification scheme derived from a large-scale corpus study of NCs. The top-level relations in her hierarchy are listed in Table 1, while the next level subdivides CONSTITUTE into SOURCE-RESULT, RESULT-SOURCE and COPULA; COPULA is then further subdivided at two additional levels. In computational linguistics, popular inventories of semantic relations have been proposed by Nastase and Szpakowicz (2003) and Girju et al. (2005), among others. The former groups 30 finegrained relations into five coarse-grained supercategories, while the latter is a flat list of 21 relation</context>
<context position="8473" citStr="Warren (1978)" startWordPosition="1281" endWordPosition="1282"> underlying relationships..., but only with the loss of much of the semantic material considered by subjects to be relevant or essential to the definitions.” A further drawback associated with sets of abstract relations is that it is difficult to identify the “correct” inventory or to decide whether one proposed classification scheme should be favored over another. 2.2 Interpretation Using Verbal Paraphrases An alternative approach to NC interpretation associates each compound with an explanatory para101 Author(s) Relation Inventory Levi (1978) CAUSE, HAVE, MAKE, USE, BE, IN, FOR, FROM, ABOUT Warren (1978) POSSESSION, LOCATION, PURPOSE, ACTIVITY-ACTOR, RESEMBLANCE, CONSTITUTE Nastase and CAUSALITY (cause, effect, detraction, purpose), Szpakowicz PARTICIPANT (agent, beneficiary, instrument, object property, (2003) object, part, possessor, property, product, source, whole, stative), QUALITY(container, content, equative, material, measure, topic, type), SPATIAL (direction, location at, location from, location), TEMPORALITY (frequency, time at, time through) Girju et al. (2005) POSSESSION, ATTRIBUTE-HOLDER, AGENT, TEMPORAL, PART-WHOLE, IS-A, CAUSE, MAKE/PRODUCE, INSTRUMENT, LOCATION/SPACE, PURPOSE,</context>
</contexts>
<marker>Warren, 1978</marker>
<rawString>Beatrice Warren. 1978. Semantic patterns of noun-noun compounds. In Gothenburg Studies in English 41, Goteburg, Acta Universtatis Gothoburgensis.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>