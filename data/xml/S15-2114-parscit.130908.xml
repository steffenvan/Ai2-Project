<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000218">
<title confidence="0.9983955">
KELabTeam: A Statistical Approach on Figurative Language Sentiment
Analysis in Twitter
</title>
<author confidence="0.997447">
Hoang Long Nguyen, Trung Duc Nguyen and Dosam Hwang
</author>
<affiliation confidence="0.899611">
Department of Computer Engineering
Yeungnam University, Korea
</affiliation>
<email confidence="0.986636">
{longnh238, duc.nguyentrung, dosamhwang}@gmail.com
</email>
<author confidence="0.99783">
Jason J. Jung∗
</author>
<affiliation confidence="0.958491">
Department of Computer Engineering
Chung-Ang University, Korea
</affiliation>
<email confidence="0.98977">
j2jung@gmail.com
</email>
<sectionHeader confidence="0.99657" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999783941176471">
In this paper, we propose a new statistical
method for sentiment analysis of figurative
language within short texts collected from
Twitter (called tweets) as a part of SemEval-
2015 Task 11. Particularly, the proposed
model focuses on classifying the tweets into
three categories (i.e., sarcastic, ironic, and
metaphorical tweet) by extracting two main
features (i.e., term features and emotion pat-
terns). Our experiments have been conducted
with two datasets, which are Trial set (1000
tweets) and Test set (4000 tweets). Perfor-
mance is evaluated by cosine similarity to gold
annotations. Using this evaluation methodol-
ogy, the proposed method achieves 0.74 on the
Trial set. On the Test set, we achieve 0.90 on
sarcastic tweets and 0.89 on ironic tweets.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989658020408163">
Sentiment analysis in computer science is a diffi-
cult task which aims to identify the emotion from a
given data source. The goal of sentiment analysis is
to dissect a given document and determine whether
its opinion represent positive, negative, or neutral.
There have been many studies (which use lexicon-
based methods and machine learning-based meth-
ods) to extract and identify the sentiment (Medhat et
al., 2014). In case of figurative language, the task
becomes more challenging because the document
can have secondary or extended meanings. Hence,
exactly finding the truth meaning of figurative lan-
guage is an interesting problem for researchers due
to its importance.
∗Corresponding author
The first work that we want to mention here
is contributed by Reyes and Rosso (2013a). The
authors captured ironic sentences from low-level
to high-level of irony according to three con-
ceptual layers and their eight textual features.
With customer reviews on Amazon, Reyes and
Rosso (2012a) contributed an approach for distin-
guishing irony and non-irony based on six mod-
els. Also focusing on detecting irony, Hao and
Veale (2010) classifies irony and non-irony by ana-
lyzing the large quantity of simile forms with 9-steps
sequence. By considering short texts with case-
study is Twitter, Reyes et al. (2013b) introduced
a model to detect verbal irony by combining four
types of conceptual features and their dimensions.
Focusing on comprehending metaphor, Shutova et
al. (2010) used unsupervised methods to find the
associate from a small set of metaphorical expres-
sions by verb and noun clustering processing to de-
tect similarity structure of metaphor. Finally, Reyes
et al. (2012b) analyzed humor and irony by adding
more features to express the favorable and unfavor-
able ironic contexts using the theory of textual.
These above studies tried to solve the problem by
focusing on lexical level. Therefore, the goal of
our research is to find a new way to identify fig-
urative meaning. In this work, we focus on ana-
lyzing three types of figurative languages (i.e., sar-
casm, irony, and metaphor) on tweets collected from
Twitter. With FLASA Model (Figurative Language
Analysis using Statistical Approach) to detect multi-
ple types of figurative language, we believe that this
is a general model to solve the problem and easy-
extending for characterizing other types.
</bodyText>
<page confidence="0.987995">
679
</page>
<note confidence="0.6124965">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 679–683,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.939527" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999101">
The Training set includes 8000 tweets collected
from Twitter. All the tweets are presented in English
with three main types of tweets: sarcasm, irony, and
metaphor with the respective ratio: 5000 sarcastic
tweets, 1000 ironic tweets and 2000 metaphorical
tweets.
</bodyText>
<equation confidence="0.999711">
Z = {&lt; t, s &gt;  |s ∈ [−5,5]} (1)
</equation>
<bodyText confidence="0.999775">
where Z is a set of tweets in the Training set; t is a
tweet, and s is the score of that tweet.
Tweets are extracted into the set of terms. All
the tweets are pre-processed by: i) considering in
lower-case mode, ii) removing unnecessary infor-
mation such as: the tagged persons, pronouns, iii)
formalizing words (e.g., remove redundancy charac-
ters which repeat more than three times, and correct
the typos). The hash-tags and symbol in the tweets
are kept because of the sentiment expressing prop-
erty. The set of terms which is extracted from Z:
</bodyText>
<equation confidence="0.934387">
{wj  |wj ∈ ti}m j=1 (2)
</equation>
<bodyText confidence="0.9995435">
where TZ is a set of terms that are extracted from Z;
n is the number of tweets in the Training set; wj is a
term; and m is the number of terms that are extracted
from Z.
</bodyText>
<subsectionHeader confidence="0.644764">
2.1 FLASA Model
</subsectionHeader>
<bodyText confidence="0.9780234">
FLASA Model includes two main modules which
are: i) Content-based Approach Module, and ii)
Emotion Pattern-based Approach Module. The final
score of a tweet is calculated by using the following
formula:
</bodyText>
<equation confidence="0.994909">
S = α × SC + β × SE (3)
</equation>
<bodyText confidence="0.999685">
where S is the final score of a tweet; SC is the
score that is calculated by Content-based Approach
module; SE is the score that is calculated by Emo-
tion Pattern-based Approach Module; and α, and β
are coefficients identified based on the training error
score of the classification model of each approach,
with α + β = 1.
</bodyText>
<subsectionHeader confidence="0.616822">
2.1.1 Content-based Approach Module
</subsectionHeader>
<bodyText confidence="0.999207285714286">
Content-based approach module evaluate the sen-
timent of a tweet based on the co-occurrence of
terms which are extracted from a tweet using the
Training set. This method basically use statistics on
the Training set to predict the score of a tweet.
With a tweet tk that is needed to be annotated.
First, it is extracted into set of terms:
</bodyText>
<equation confidence="0.997290666666667">
U
Tk = {wi  |wi ∈ tk}mk (4)
i=1
</equation>
<bodyText confidence="0.999794083333333">
where Tk is the set of terms extracted from tweet
tk; wi is a term belongs to tweet tk; and mk is the
number of terms which are extracted from tweet tk.
From Tk, we build all the possible combinations
from the set of terms to consider all the possible
co-occurrence of terms because terms can express
different meaning when they appear together. With
this step, we can achieve all these aspects: i) all the
meaning of the tweet tk when terms co-exist, and ii)
some main terms that affect the score of the tweet
tk. We can consider each of combination is a cluster
which can respective as a feature vector:
</bodyText>
<equation confidence="0.993854333333334">
�Ck = (δk)i � 1 ��γk = E mk mk)
j (5)
j=1
</equation>
<bodyText confidence="0.9974607">
where Ck is the set of all possible clusters extract
from the given tweet; δk is a cluster, each cluster
can be represented as a feature vector; and γk is the
number of all combinations which are created from
terms in Tk.
Each cluster in Ck is represented as a feature vec-
tor, with the dimension equals with the number of
terms in Tk. From the set of tweets Z in the Train-
ing set, we cluster every tweet into the set of cluster
Ck. A tweet is assigned into a cluster in the case:
</bodyText>
<listItem confidence="0.918332">
i) the distance between a vector to a cluster is mini-
mum comparing to its distance to other clusters, and
ii) the distance has to smaller than a defined thresh-
old. This has a significant meaning in expressing the
co-occurrence of terms in a tweet. The distance be-
tween a tweet and a cluster is calculated by using the
following formula:
</listItem>
<equation confidence="0.673990333333333">
AT B
dis(A, B) = 1 − (6)
|A||B|
</equation>
<bodyText confidence="0.9992028">
where dis(A, B) is the distance between a term and
a cluster.
Each cluster has a cluster coefficient which is cal-
culated from the number of feature terms of a clus-
ter. If a cluster has more terms, its coefficient will
</bodyText>
<equation confidence="0.9966135">
n
U
i=1
TZ =
ti =
n
U
i=1
</equation>
<page confidence="0.989599">
680
</page>
<figure confidence="0.8804587">
Total coefficient 16 score. Assuming that all the tweets have equatable
14 meaning, the score of a term is calculated by the fol-
12 lowing formula:
10 �l i=1 Swi
8 Sw = (7)
6 l
4
2
0
Tweet score
</figure>
<figureCaption confidence="0.999986">
Figure 1: Histogram of score distribution.
</figureCaption>
<bodyText confidence="0.996905714285714">
be higher. The cluster coefficient can expresses how
important it affects the final score of a tweet. Then,
from tweets in clusters with their scores and coeffi-
cient, the histogram is built to represent the distribu-
tion of score in the Training set. Finally, the score
of a tweet is annotated by selecting the peak of the
histogram.
</bodyText>
<construct confidence="0.905991333333333">
Example 1. We have 3 clusters: cluster {A, B, C}:
includes 3 tweets (&lt; t1, −2.5 &gt;; &lt; t2, −3.5 &gt;;
&lt; t3, −3.5 &gt;); cluster {B, C}: includes 3 tweets
(&lt; t4, 0.0 &gt;; &lt; t5, −2.0 &gt;; &lt; t6, −2.0 &gt;);
cluster {C}: includes 4 tweets (&lt; t7, −4.5 &gt;;
&lt; t8, −3.0 &gt;; &lt; t9, −0.5 &gt;; &lt; t10, −1.5 &gt;).
</construct>
<figureCaption confidence="0.960105333333333">
Figure 1 expresses the above data as histogram. In
this case, the score of tweet which is calculated by
Content-based Approach Module is −3.5.
</figureCaption>
<subsectionHeader confidence="0.668573">
2.1.2 Emotion Pattern-based Approach
Module
</subsectionHeader>
<bodyText confidence="0.994055962962963">
The Emotion Pattern-based Approach Module de-
termine the score of a given tweet based on the emo-
tion change pattern in the content. This approach
consists in calculating the sentiment score for each
term, then construct the emotion distribution pattern
using the termss score in the tweet corresponding to
its occurrence positions.
Each term has a score which is calculated based
on tweets in the Training set. By finding the score
of term and the pattern of tweet, we can understand
about how important a term contributes to the final
score of a tweet, and about the sentiment degree of a
term, whether it’s positive, negative, or neutral. The
score of a tweet is decided by the pattern of terms in
a sentence. Our goal is try to find the real score of
a term. In the Traning set, a term belongs to many
tweets, and in each tweet, it represents a different
where Sw is the score of a term; and l is the number
of tweets which contain this term.
From the set of tweets Z and the set of terms T,
we can find the distribution of a term by using the
score of tweets which contain it. The peak of his-
togram is the point at that a term has highest distri-
bution with a score. At the beginning (i0 step), each
term has the score which is selected from the peak
of its respective histogram. Then, the score in the
step i + 1 is calculated by using the formula:
</bodyText>
<equation confidence="0.996995">
Si — Sw 1 ∗ P(St |w) ∗ St (8)
w 1(Swjl ∗ P (St |wj))
</equation>
<bodyText confidence="0.996804074074074">
where Siw is the score of a term at step ith; St is the
score of tweet that contains this term; and P(St|w)
is the probability that a term has the score with given
tweet score.
This step is conducted repeatably until the score
of term at step ith greater than the score of term at
step (i−1)th a value of defined epsilon, with epsilon
is extremely small.
With each tweet in the Training set, it is extracted
into the list of terms and then create a pattern based
on its term scores as we mentioned above. Due to
the different of the number of terms in a tweet, the
signal of pattern is needed to be scaled by using an
interpolation function. The pattern is scaled to the
maximum possible terms that a tweet in the Training
set contain in order to be able to map all the tweets
into vectors with same dimension.
Example 2. We have a tweet: @SamySam-
son wow you’re soooo funny #sarcasm it
actually hurts a bunch!. From this tweet,
we have list of terms and their scores:
(&lt; wow, −0.2057831 &gt;; &lt; soo, −0.1552674 &gt;; &lt;
funny,−0.19274 &gt;; &lt; #sarcasm, −2.34994 &gt;;
&lt; actually, −0.03287 &gt;; &lt; hurts,−0.16091 &gt;;
&lt; bunch,−0.02096 &gt;). Figure 2 expresses the
pattern of the above data after the term scores are
scaled down by the size of largest terms in a tweet
</bodyText>
<figure confidence="0.955402666666666">
−5.0
−4.5
−4.0
−3.5
−3.0
−2.5
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
</figure>
<page confidence="0.986661">
681
</page>
<bodyText confidence="0.97042">
found in the Training set. Here, the maximum num-
ber of terms that a tweet contains in the Training set
is 24.
</bodyText>
<figure confidence="0.7922575">
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Terms extracted from a tweet
</figure>
<figureCaption confidence="0.985451">
Figure 2: Sequential pattern of tweet term scores
after length normalization.
</figureCaption>
<bodyText confidence="0.998960625">
Using the set of patterns from the Training set,
we construct a vector space representation whereby
each dimension signifies a match to one of the ex-
tracted patterns. We then train a decision tree based
classifier to predict from these vectors the inte-
ger sentiment labels [−5..5] of the corresponding
tweets. And that is the score which is annotated by
using Emotion Pattern-based Approach Module.
</bodyText>
<sectionHeader confidence="0.989809" genericHeader="method">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.999868473684211">
The test data comprises 4000 tweets with both fig-
urative and non-figurative tweets with 70% of them
are sarcasm, irony, or metaphor; and 30% of the data
are other. We evaluate the test with: i) Content-
based Approach Module, ii) Emotion Pattern-based
Approach Module, and iii) Combined Module.
FLASA Model works well with figurative tweets.
Using cosine similarity to gold annotations to evalu-
ate the system, the highest performance that we got
is 0.90 with irony type, and the next is sarcastic type
with 0.89. With metaphor type, we achieve 0.34
with annotated tweets. About non-figurative tweets,
the performance is still low due to the tweets in the
Training set. The root cause is that there are no non-
figurative tweets in the Training set. If we add more
non-figurative tweets to the Training set in order to
learn, the result will be improved. Fig. 3 shows the
performance that we got from testing our approach
on the Test set.
</bodyText>
<subsectionHeader confidence="0.299078">
Sarcasm Irony Metaphor Other Overall
</subsectionHeader>
<figureCaption confidence="0.933128">
Figure 3: The performance of FLASA Model on
Test set using cosine similarity.
</figureCaption>
<sectionHeader confidence="0.998668" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99974424137931">
In this paper, we proposed a new approach for ana-
lyzing the sentiment of figurative language based-
on the statistics with two main approaches: con-
tent and emotional pattern. By combining all these
features, we enhanced the performance of our algo-
rithm. However, the result of FLASA Model is af-
fected by these following reasons:
i) Almost all the tweets in the Training set are
sarcastic tweets, and irony tweets. Due to this rea-
son, the performance on metaphor tweets, and non-
figurative tweets are still low.
ii) Is this work, we only consider unigram model
when calculating the score for terms in Emotion
Pattern-based Approach. This leads to the miss-
expressing meaning of terms if they are co-showing
an specific sense in a phrase.
iii) Our training data has a little noise be-
cause some tweets are written in an unstandardized
way(e.g. abbreviation word, and repeated word).
In the next work, we will improve the perfor-
mance by increasing the number of tweets in the
Training set, especially the metaphor tweets, and
non-figurative tweets. Bigram or trigram model will
be used to clearly comprehend the sentiment of a
tweet. Moreover, we will add more heuristic to com-
pletely formalize tweets. Finally, we will extend
FLASA Model to analyze the data from the other
social network, such as Facebook, Instagram, Flick,
and Google Plus also.
</bodyText>
<sectionHeader confidence="0.951403" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.484526">
This work was supported by the National
Research Foundation of Korea (NRF) grant
</bodyText>
<figure confidence="0.999102545454545">
Term score
-1
-2
-3
-4
-5
4
3
2
0
5
1
Term Score
1
0.8
0.6
0.4
0.2
0
Content-based
Emotion-Pattern-based
Combined
</figure>
<page confidence="0.991575">
682
</page>
<bodyText confidence="0.99917">
funded by the Korea government (MSIP) (NRF-
2014R1A2A2A05007154). Also, this research
was supported by the MSIP (Ministry of Science,
ICT &amp; Future Planning), Korea, under the ITRC
(Information Technology Research Cetner) support
program (NIPA-2014-H0301-14-1044) supervised
by the NIPA (National ICT Industry Promotion
Agency).
</bodyText>
<sectionHeader confidence="0.99883" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999773285714286">
Hao, Y., &amp; Veale, T. 2010. An Ironic Fist in a Velvet
Glove: Creative Mis-Representation in the Construc-
tion of Ironic Similes. Minds and Machines, 20(4),
635-650.
Kaur, A., &amp; Gupta, V. 2013. A Survey on Sentiment
Analysis and Opinion Mining Techniques. Ain Journal
of Emerging Technologies in Web Intelligence, 5(4),
367-371.
Kumon-Nakamura, S., Glucksberg, S., &amp; Brown, M.
1995. How about Another Piece of Pie: The Allu-
sional Pretense Theory of Discourse Irony. Journal
of Experimental Psychology General, 124(1), 3-21.
Medhat, W., Hassan, A., &amp; Korashy, H. 2014. Sentiment
Analysis Algorithms and Applications: A Survey. Ain
Shams Engineering Journal, 5(4), 1093-1113.
Reyes, A., &amp; Rosso, P. 2013a. On the Difficulty of Au-
tomatically Detecting Irony: Beyond a Simple Case
of Negation. Knowledge and Information Systems,
40(3), 595-614.
Reyes, A., Rosso, P., &amp; Veale, T. 2013b. A Multidimen-
sional Approach for Detecting Irony in Twitter. Lan-
guages Resources and Evaluation, 47(1), 239-268.
Reyes, A., &amp; Rosso, P. 2012a. Making Objective Deci-
sions from Subjective Data: Detecting Irony in Cus-
tomers Reviews. Journal on Decision Support Sys-
tems, 53(4), 754-760.
Reyes, A., Rosso, P., &amp; Buscaldi, D. 2012b. From Hu-
mor Recognition to Irony Detection: The Figurative
Language of Social Media. Data &amp; Knowledge Engi-
neering, 74(0), 1-12.
Shutova, E., Sun, L., &amp; Korhonen, A. 2010. Metaphor
Identification Using Verb and Noun Clustering. Pro-
ceedings of the 23rd International Conference on
Computational Linguistics (COLING 2010), Beijing,
China, August 23-27, pp. 1002-1010.
</reference>
<page confidence="0.999156">
683
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.488963">
<title confidence="0.946416">KELabTeam: A Statistical Approach on Figurative Language Analysis in Twitter</title>
<author confidence="0.923221">Hoang Long Nguyen</author>
<author confidence="0.923221">Trung Duc Nguyen</author>
<author confidence="0.923221">Dosam</author>
<affiliation confidence="0.9992875">Department of Computer Yeungnam University,</affiliation>
<email confidence="0.886184">duc.nguyentrung,</email>
<author confidence="0.655932">J</author>
<affiliation confidence="0.999739">Department of Computer Chung-Ang University,</affiliation>
<email confidence="0.998595">j2jung@gmail.com</email>
<abstract confidence="0.998384611111111">In this paper, we propose a new statistical method for sentiment analysis of figurative language within short texts collected from Twitter (called tweets) as a part of SemEval- 2015 Task 11. Particularly, the proposed model focuses on classifying the tweets into three categories (i.e., sarcastic, ironic, and metaphorical tweet) by extracting two main features (i.e., term features and emotion patterns). Our experiments have been conducted with two datasets, which are Trial set (1000 tweets) and Test set (4000 tweets). Performance is evaluated by cosine similarity to gold annotations. Using this evaluation methodology, the proposed method achieves 0.74 on the Trial set. On the Test set, we achieve 0.90 on sarcastic tweets and 0.89 on ironic tweets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Hao</author>
<author>T Veale</author>
</authors>
<title>An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the Construction of Ironic Similes.</title>
<date>2010</date>
<journal>Minds and Machines,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>635--650</pages>
<contexts>
<context position="2250" citStr="Hao and Veale (2010)" startWordPosition="337" endWordPosition="340">an have secondary or extended meanings. Hence, exactly finding the truth meaning of figurative language is an interesting problem for researchers due to its importance. ∗Corresponding author The first work that we want to mention here is contributed by Reyes and Rosso (2013a). The authors captured ironic sentences from low-level to high-level of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for distinguishing irony and non-irony based on six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of conceptual features and their dimensions. Focusing on comprehending metaphor, Shutova et al. (2010) used unsupervised methods to find the associate from a small set of metaphorical expressions by verb and noun clustering processing to detect similarity structure of metaphor. Finally, Reyes et al. (2012b) analyzed humor and irony by adding more feature</context>
</contexts>
<marker>Hao, Veale, 2010</marker>
<rawString>Hao, Y., &amp; Veale, T. 2010. An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the Construction of Ironic Similes. Minds and Machines, 20(4), 635-650.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kaur</author>
<author>V Gupta</author>
</authors>
<title>A Survey on Sentiment Analysis and Opinion Mining Techniques.</title>
<date>2013</date>
<journal>Ain Journal of Emerging Technologies in Web Intelligence,</journal>
<volume>5</volume>
<issue>4</issue>
<pages>367--371</pages>
<marker>Kaur, Gupta, 2013</marker>
<rawString>Kaur, A., &amp; Gupta, V. 2013. A Survey on Sentiment Analysis and Opinion Mining Techniques. Ain Journal of Emerging Technologies in Web Intelligence, 5(4), 367-371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumon-Nakamura</author>
<author>S Glucksberg</author>
<author>M Brown</author>
</authors>
<title>How about Another Piece of Pie: The Allusional Pretense Theory of Discourse Irony.</title>
<date>1995</date>
<journal>Journal of Experimental Psychology General,</journal>
<volume>124</volume>
<issue>1</issue>
<pages>3--21</pages>
<marker>Kumon-Nakamura, Glucksberg, Brown, 1995</marker>
<rawString>Kumon-Nakamura, S., Glucksberg, S., &amp; Brown, M. 1995. How about Another Piece of Pie: The Allusional Pretense Theory of Discourse Irony. Journal of Experimental Psychology General, 124(1), 3-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Medhat</author>
<author>A Hassan</author>
<author>H Korashy</author>
</authors>
<title>Sentiment Analysis Algorithms and Applications: A Survey.</title>
<date>2014</date>
<journal>Ain Shams Engineering Journal,</journal>
<volume>5</volume>
<issue>4</issue>
<pages>1093--1113</pages>
<contexts>
<context position="1540" citStr="Medhat et al., 2014" startWordPosition="226" endWordPosition="229">ty to gold annotations. Using this evaluation methodology, the proposed method achieves 0.74 on the Trial set. On the Test set, we achieve 0.90 on sarcastic tweets and 0.89 on ironic tweets. 1 Introduction Sentiment analysis in computer science is a difficult task which aims to identify the emotion from a given data source. The goal of sentiment analysis is to dissect a given document and determine whether its opinion represent positive, negative, or neutral. There have been many studies (which use lexiconbased methods and machine learning-based methods) to extract and identify the sentiment (Medhat et al., 2014). In case of figurative language, the task becomes more challenging because the document can have secondary or extended meanings. Hence, exactly finding the truth meaning of figurative language is an interesting problem for researchers due to its importance. ∗Corresponding author The first work that we want to mention here is contributed by Reyes and Rosso (2013a). The authors captured ironic sentences from low-level to high-level of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for </context>
</contexts>
<marker>Medhat, Hassan, Korashy, 2014</marker>
<rawString>Medhat, W., Hassan, A., &amp; Korashy, H. 2014. Sentiment Analysis Algorithms and Applications: A Survey. Ain Shams Engineering Journal, 5(4), 1093-1113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reyes</author>
<author>P Rosso</author>
</authors>
<title>On the Difficulty of Automatically Detecting Irony: Beyond a Simple Case of Negation.</title>
<date>2013</date>
<journal>Knowledge and Information Systems,</journal>
<volume>40</volume>
<issue>3</issue>
<pages>595--614</pages>
<contexts>
<context position="1904" citStr="Reyes and Rosso (2013" startWordPosition="283" endWordPosition="286">dissect a given document and determine whether its opinion represent positive, negative, or neutral. There have been many studies (which use lexiconbased methods and machine learning-based methods) to extract and identify the sentiment (Medhat et al., 2014). In case of figurative language, the task becomes more challenging because the document can have secondary or extended meanings. Hence, exactly finding the truth meaning of figurative language is an interesting problem for researchers due to its importance. ∗Corresponding author The first work that we want to mention here is contributed by Reyes and Rosso (2013a). The authors captured ironic sentences from low-level to high-level of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for distinguishing irony and non-irony based on six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of concept</context>
</contexts>
<marker>Reyes, Rosso, 2013</marker>
<rawString>Reyes, A., &amp; Rosso, P. 2013a. On the Difficulty of Automatically Detecting Irony: Beyond a Simple Case of Negation. Knowledge and Information Systems, 40(3), 595-614.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reyes</author>
<author>P Rosso</author>
<author>T Veale</author>
</authors>
<title>A Multidimensional Approach for Detecting Irony in Twitter. Languages Resources and Evaluation,</title>
<date>2013</date>
<volume>47</volume>
<issue>1</issue>
<pages>239--268</pages>
<contexts>
<context position="2425" citStr="Reyes et al. (2013" startWordPosition="366" endWordPosition="369">onding author The first work that we want to mention here is contributed by Reyes and Rosso (2013a). The authors captured ironic sentences from low-level to high-level of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for distinguishing irony and non-irony based on six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of conceptual features and their dimensions. Focusing on comprehending metaphor, Shutova et al. (2010) used unsupervised methods to find the associate from a small set of metaphorical expressions by verb and noun clustering processing to detect similarity structure of metaphor. Finally, Reyes et al. (2012b) analyzed humor and irony by adding more features to express the favorable and unfavorable ironic contexts using the theory of textual. These above studies tried to solve the problem by focusing on lexical level. Therefore,</context>
</contexts>
<marker>Reyes, Rosso, Veale, 2013</marker>
<rawString>Reyes, A., Rosso, P., &amp; Veale, T. 2013b. A Multidimensional Approach for Detecting Irony in Twitter. Languages Resources and Evaluation, 47(1), 239-268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reyes</author>
<author>P Rosso</author>
</authors>
<title>Making Objective Decisions from Subjective Data: Detecting Irony in Customers Reviews.</title>
<date>2012</date>
<journal>Journal on Decision Support Systems,</journal>
<volume>53</volume>
<issue>4</issue>
<pages>754--760</pages>
<contexts>
<context position="2109" citStr="Reyes and Rosso (2012" startWordPosition="314" endWordPosition="317">act and identify the sentiment (Medhat et al., 2014). In case of figurative language, the task becomes more challenging because the document can have secondary or extended meanings. Hence, exactly finding the truth meaning of figurative language is an interesting problem for researchers due to its importance. ∗Corresponding author The first work that we want to mention here is contributed by Reyes and Rosso (2013a). The authors captured ironic sentences from low-level to high-level of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for distinguishing irony and non-irony based on six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of conceptual features and their dimensions. Focusing on comprehending metaphor, Shutova et al. (2010) used unsupervised methods to find the associate from a small set of metaphorical expressions by verb and noun cl</context>
</contexts>
<marker>Reyes, Rosso, 2012</marker>
<rawString>Reyes, A., &amp; Rosso, P. 2012a. Making Objective Decisions from Subjective Data: Detecting Irony in Customers Reviews. Journal on Decision Support Systems, 53(4), 754-760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Reyes</author>
<author>P Rosso</author>
<author>D Buscaldi</author>
</authors>
<title>From Humor Recognition to Irony Detection: The Figurative Language of Social Media.</title>
<date>2012</date>
<journal>Data &amp; Knowledge Engineering,</journal>
<volume>74</volume>
<issue>0</issue>
<pages>1--12</pages>
<contexts>
<context position="2800" citStr="Reyes et al. (2012" startWordPosition="424" endWordPosition="427">n six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of conceptual features and their dimensions. Focusing on comprehending metaphor, Shutova et al. (2010) used unsupervised methods to find the associate from a small set of metaphorical expressions by verb and noun clustering processing to detect similarity structure of metaphor. Finally, Reyes et al. (2012b) analyzed humor and irony by adding more features to express the favorable and unfavorable ironic contexts using the theory of textual. These above studies tried to solve the problem by focusing on lexical level. Therefore, the goal of our research is to find a new way to identify figurative meaning. In this work, we focus on analyzing three types of figurative languages (i.e., sarcasm, irony, and metaphor) on tweets collected from Twitter. With FLASA Model (Figurative Language Analysis using Statistical Approach) to detect multiple types of figurative language, we believe that this is a gen</context>
</contexts>
<marker>Reyes, Rosso, Buscaldi, 2012</marker>
<rawString>Reyes, A., Rosso, P., &amp; Buscaldi, D. 2012b. From Humor Recognition to Irony Detection: The Figurative Language of Social Media. Data &amp; Knowledge Engineering, 74(0), 1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shutova</author>
<author>L Sun</author>
<author>A Korhonen</author>
</authors>
<title>Metaphor Identification Using Verb and Noun Clustering.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010),</booktitle>
<pages>1002--1010</pages>
<location>Beijing, China,</location>
<contexts>
<context position="2596" citStr="Shutova et al. (2010)" startWordPosition="391" endWordPosition="394">of irony according to three conceptual layers and their eight textual features. With customer reviews on Amazon, Reyes and Rosso (2012a) contributed an approach for distinguishing irony and non-irony based on six models. Also focusing on detecting irony, Hao and Veale (2010) classifies irony and non-irony by analyzing the large quantity of simile forms with 9-steps sequence. By considering short texts with casestudy is Twitter, Reyes et al. (2013b) introduced a model to detect verbal irony by combining four types of conceptual features and their dimensions. Focusing on comprehending metaphor, Shutova et al. (2010) used unsupervised methods to find the associate from a small set of metaphorical expressions by verb and noun clustering processing to detect similarity structure of metaphor. Finally, Reyes et al. (2012b) analyzed humor and irony by adding more features to express the favorable and unfavorable ironic contexts using the theory of textual. These above studies tried to solve the problem by focusing on lexical level. Therefore, the goal of our research is to find a new way to identify figurative meaning. In this work, we focus on analyzing three types of figurative languages (i.e., sarcasm, iron</context>
</contexts>
<marker>Shutova, Sun, Korhonen, 2010</marker>
<rawString>Shutova, E., Sun, L., &amp; Korhonen, A. 2010. Metaphor Identification Using Verb and Noun Clustering. Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), Beijing, China, August 23-27, pp. 1002-1010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>