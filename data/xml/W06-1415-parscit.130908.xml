<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.9988825">
Generating Intelligent Numerical Answers
in a Question-Answering System
</title>
<author confidence="0.930524">
V´eronique Moriceau
</author>
<affiliation confidence="0.633543">
Institut de Recherche en Informatique de Toulouse
118, route de Narbonne, 31062 Toulouse, France
</affiliation>
<email confidence="0.963431">
moriceau@irit.fr
</email>
<sectionHeader confidence="0.99241" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900090909091">
In this paper, we present a question-
answering system on the Web which aims
at generating intelligent answers to numer-
ical questions. These answers are gener-
ated in a cooperative way: besides a direct
answer, comments are generated to ex-
plain to the user the variation of numerical
data extracted from the Web. We present
the content determination and realisation
tasks. We also present some elements of
evaluation with respect to end-users.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999717181818182">
Search engines on the Web and most existing
question-answering (QA) systems provide the user
with a set of hyperlinks and/or Web page extracts
containing answer(s) to a question. These answers
may be incoherent to a certain degree: they may be
equivalent, complementary, contradictory, at dif-
ferent levels of precision or specificity, etc. It is
then quite difficult for the user to know which an-
swer is the correct one. Thus, an analysis of rel-
evance and coherence of candidate answers is es-
sential.
</bodyText>
<sectionHeader confidence="0.875172" genericHeader="introduction">
1.1 Related work
</sectionHeader>
<bodyText confidence="0.999898516129032">
Search engines on the Web produce a set of an-
swers to a question in the form of hyperlinks or
page extracts, ranked according to content or pop-
ularity criteria (Salton, 1989; Page et al., 1998).
Some QA systems on the Web use other tech-
niques: candidate answers are ranked according
to a score which takes into account lexical re-
lations between questions and answers, semantic
categories of concepts, distance between words,
etc. (Moldovan et al., 2003), (Narayanan and
Harabagiu, 2004), (Radev and McKeown, 1998).
Recently, advanced QA systems defined rela-
tionships (equivalence, contradiction, ...) between
Web page extracts or texts containing possible an-
swers in order to combine them and to produce
a single answer (Radev and McKeown, 1998),
(Harabagiu and Lacatusu, 2004), (Webber et al.,
2002).
Most systems provide the user with either a set
of potential answers (ranked or not), or the ”best”
answer according to some relevance criteria. They
do not provide answers which take into account
information from a set of candidate answers or
answer inconsistencies. As for logical approaches
used for database query, they are based on major-
ity approach or on source reliability. But, contrary
to the assumption of (Motro et al., 2004), we noted
that reliability information (information about the
author, date of Web pages, ...) is rather difficult
to obtain, so we assume that all Web pages are
equally reliable.
</bodyText>
<subsectionHeader confidence="0.986819">
1.2 Motivations and goals
</subsectionHeader>
<bodyText confidence="0.99983925">
Our framework is advanced QA systems over open
domains. Our main goals are to model and to eval-
uate a system which, from a factoid question in
natural language (in French), selects a set of can-
didate answers on the Web and generates cooper-
ative answers in natural language. Our challenge
is (1) to generate a synthetic answer instead of a
list of potential answers (in order to avoid provid-
ing the user with too much information), and (2) to
generate relevant comments which explain the va-
riety of answers extracted from the Web (in order
to avoid misleading the user) (Grice, 1975). In a
cooperative perspective, we propose an approach
for answer generation which uses answer integra-
tion. When several possible answers are extracted
from the Web, the goal is to define a coherent core
</bodyText>
<page confidence="0.991553">
103
</page>
<note confidence="0.689494">
Proceedings of the Fourth International Natural Language Generation Conference, pages 103–110,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999094909090909">
from candidate answers and to generate a cooper-
ative answer, i.e. an answer with explanations.
In this paper, we focus on the integration of nu-
merical data in order to generate natural language
cooperative answers to numerical questions. We
first present some motivational problems for the
generation of numerical answers in a QA system.
Then, we present the content determination and
realization processes. Finally, we give some el-
ements of evaluation of our system outputs, with
respect to end-users.
</bodyText>
<sectionHeader confidence="0.579503" genericHeader="method">
2 On numerical data
</sectionHeader>
<bodyText confidence="0.999592">
We focus on the integration of numerical data
for the generation of natural language coopera-
tive numerical answers. We first present some re-
lated work on generation from numerical data sets.
Then we propose a model for the generation of co-
operative numerical answers.
</bodyText>
<sectionHeader confidence="0.956706" genericHeader="method">
2.1 Related work
</sectionHeader>
<bodyText confidence="0.999616416666667">
The generation of summaries from numerical data
has been developed in some NLG systems. For ex-
ample, the system ANA (Kukich, 1983) generates
stock market reports by computing fluctuations
for a day. FoG (Goldberg et al, 1994) produces
weather forecasts from forecast data. More re-
cently, StockReporter (Dale, 2003) was developed
to generate summaries describing how a stock per-
forms over a period. Yu et al. (2005) propose a
system which generates summaries of sensor data
from gas turbines.
Those systems have input data analysis compo-
nents which are more or less efficient and describe
numerical time-series data. In the framework of
QA systems, there are other major problems that
the previous systems do not deal with. When a
numerical question is submitted to a QA system,
a set of numerical data is extracted from the Web.
Then, the goal is not to describe the whole data set
but to find an appropriate answer, dealing with the
user expectations (for example, contraints in the
question) or data inconsistencies. Another impor-
tant point is the analysis of numerical input data in
order to identify causes (besides time) of variation.
</bodyText>
<subsectionHeader confidence="0.999273">
2.2 A typology of numerical answers
</subsectionHeader>
<bodyText confidence="0.999309866666667">
Our challenge is to develop a formal framework
for the integration of numerical data extracted
from Web pages in order to produce cooperative
numerical answers.
To define the different types of numerical
answers, we collected a set of 80 question-answer
pairs about prices, quantities, age, time, weight,
temperature, speed and distance. The goal is
to identify for each question-answer pair why
extracted numerical values are different (is this an
inconsistency? an evolution?).
A numerical question may accept several
answers when numerical values vary according
to some criteria. Let us consider the following
examples.
</bodyText>
<equation confidence="0.4789988">
Example 1 :
How many inhabitants are there in France?
- Population census in France (1999): 60184186.
- 61.7: number of inhabitants in France in 2004.
Example 2 :
</equation>
<bodyText confidence="0.616318166666667">
What is the average age of marriage of women in
2004?
- In Iran, the average age of marriage of women
was 21 years in 2004.
- In 2004, Moroccan women get married at the
age of 27.
</bodyText>
<equation confidence="0.40405">
Example 3 :
</equation>
<bodyText confidence="0.605494">
At what temperature should I serve wine?
</bodyText>
<listItem confidence="0.946817666666667">
- Red wine must be served at room temperature.
- Champagne: between 8 and 10 ˚C.
- White wine: between 8 and 11 ˚C.
</listItem>
<bodyText confidence="0.99426825">
The corpus analysis allows us to identify 3 main
variation criteria, namely time (ex.1), place (ex.2)
and restriction (ex.3: restriction on the focus, for
example: Champagne/wine). These criteria can be
combined: some numerical values vary according
to time and place, to time and restrictions, etc. (for
example, the average age of marriage vary accord-
ing to time, place and restrictions on men/women).
</bodyText>
<subsectionHeader confidence="0.998268">
2.3 A model for cooperative numerical
answer generation
</subsectionHeader>
<bodyText confidence="0.9984444">
The system has to generate an answer from a set
of numerical data. In order to identify the different
problems, let us consider the following example :
What is the average age of marriage in France?
- In 1972, the average age of marriage was 24.5
for men and 22.4 for women. In 2005, it is 30 for
men and 28 for women.
- The average age ofmarriage in France increased
from 24.5 to 26.9 for women and from 26.5 to 29
for men between 1986 and 1995.
</bodyText>
<page confidence="0.995101">
104
</page>
<bodyText confidence="0.9978543">
This set of potential answers may seem incoher-
ent but their internal coherence can be made ap-
parent once a variation criterion is identified. In a
cooperative perspective, an answer can be for ex-
ample:
In 2005, the average age of marriage in France
was 30 for men and 28 for women.
It increased by about 5.5 years between 1972 and
2005.
This answer is composed of:
</bodyText>
<listItem confidence="0.990229333333333">
1. a direct answer to the question,
2. an explanation characterizing the variation
mode of the numerical value.
</listItem>
<bodyText confidence="0.999160057142857">
To generate this kind of answer, it is necessary (1)
to integrate candidate answers in order to elabo-
rate a direct answer (for example by solving incon-
sistencies), and (2) to integrate candidate answers
characteristics in order to generate an explanation.
Figure 1 presents the general architecture of our
system which allows us to generate answers and
explanations from several different numerical an-
swers. Questions are submitted in natural lan-
guage to QRISTAL1 which analyses them and se-
lects potential answers from the Web. Then, a
grammar is applied to extract information needed
for the generation of an appropriate cooperative
answer. This information is mainly:
- the searched numerical value (val),
- the unit of measure,
- the question focus,
- the date and place of the information,
- the restriction(s) on the question focus ,
- the precision of the numerical value (for example
adverbs or prepositions such as in about 700, ...),
- linguistic clues indicating a variation of the value
(temporal adverbs, verbs of change/movement as
in the price increased to 200 euro).
For the extraction of restrictions, a set of basic
properties is defined (colors, form, material, etc.).
Ontologies are also necessary. For example, for
the question how many inhabitants are there
in France?, population of overseas regions and
metropolitan population are restrictions of France
because they are daughters of the concept France
in the ontology. On the contrary, prison popula-
tion of France is not a restriction because prison is
not a daughter of France. Several ontologies are
available2 but the lack of available knowledge for
</bodyText>
<footnote confidence="0.9998995">
1www.qristal.fr, Synapse D´eveloppement
2http://www.daml.org/ontologies/
</footnote>
<figureCaption confidence="0.999769">
Figure 1: Architecture
</figureCaption>
<bodyText confidence="0.9981136">
some domains obviously influences the quality of
answers.
We define the set A = jai, ..., aNI, with ai a
frame which gathers all this information for a nu-
merical value. Figure 2 shows an extraction result.
</bodyText>
<figureCaption confidence="0.993668">
Figure 2: Extraction results
</figureCaption>
<bodyText confidence="0.999934166666667">
From the frame set, the variation criteria and
mode of the searched numerical value are iden-
tified: these components perform content deter-
mination. Finally, a natural language answer is
generated explaining those characteristics. Each
of these stages is presented in the next sections.
</bodyText>
<sectionHeader confidence="0.965414" genericHeader="method">
3 Content determination for
explanations
</sectionHeader>
<bodyText confidence="0.9984645">
In order to produce explanations for data variation,
the system must have a data analysis component
</bodyText>
<page confidence="0.996105">
105
</page>
<bodyText confidence="0.995293">
which can infer, from extracted information, the
variation phenomena, criteria and mode.
</bodyText>
<subsectionHeader confidence="0.999609">
3.1 Variation criteria
</subsectionHeader>
<bodyText confidence="0.999674666666667">
Once we have the frames representing the different
numerical values, the goal is to determine if there
is a variation and to identify the variation criteria
of the value. We assume that there is a variation if
there is at least k different numerical values with
different criteria (time, place, restriction) among
the N frames (for the moment, we arbitrarily set
k = N/4, but this has to be evaluated). Thus, a
numerical value varies according to:
</bodyText>
<figure confidence="0.961103533333333">
1. time if T = jai(V al), I aj E A,
such as ai(V al) =� aj(V al)
A ai(Unit) = aj(Unit)
A ai(Date) =� aj(Date) }
A card(T) &gt; k
2. place if P = jai(V al), I aj E A,
such as ai(V al) =� aj(V al)
A ai(Unit) = aj(Unit)
A ai(Place) =� aj(Place) }
A card(P) &gt; k
3. restriction if Rt = jai(V al), I aj E A,
such as ai(V al) =� aj(V al)
A ai(Unit) = aj(Unit)
A ai(Restriction) =� aj(Restriction) }
A card(Rt) &gt; k
</figure>
<listItem confidence="0.99624775">
4. time and place if (1) A (2)
5. time and restriction if (1) A (3)
6. place and restriction if (2) A (3)
7. time, place and restriction if (1) A (2) A (3)
</listItem>
<bodyText confidence="0.7583525">
Numerical values can be compared only if they
have the same unit of measure. If not, they have to
be converted. More details about comparison rules
are presented in (Moriceau, 2006).
</bodyText>
<subsectionHeader confidence="0.99893">
3.2 Variation mode
</subsectionHeader>
<bodyText confidence="0.999949470588235">
In the case of numerical values varying over time,
it is possible to characterize more precisely the
variation. The idea is to draw a trend (increase,
decrease, ...) of variaton over time so that a precise
explanation can be generated. For this purpose, we
draw a regression line which determines the rela-
tionship between the two extracted variables value
and date.
In particular, Pearson’s correlation coefficient (r),
related to the line slope, reflects the degree of lin-
ear relationship between two variables. It ranges
from +1 to −1. For example, figure 3 shows that a
positive Pearson’s correlation implies a general in-
crease of values whereas a negative Pearson’s cor-
relation implies a general decrease. On the con-
trary, if r is low (−0.6 &lt; r &lt; 0.6), then we con-
sider that the variation is random (Fisher, 1925).
</bodyText>
<figureCaption confidence="0.977749111111111">
Figure 3: Variation mode
Figure 4 shows the results for the question How
many inhabitants are there in France? Differ-
ent numerical values and associated dates are ex-
tracted from Web pages. The Pearson’s correlation
is 0.694 meaning that the number of inhabitants
increases over time (between 1999 and 2005).
Figure 4: Variation mode: How many inhabitants
are there in France?
</figureCaption>
<sectionHeader confidence="0.98611" genericHeader="method">
4 Answer generation
</sectionHeader>
<bodyText confidence="0.986695333333333">
Once the searched numerical values have been ex-
tracted and characterized by their variation crite-
ria and mode, a cooperative answer is generated in
natural language. It is composed of two parts:
- a direct answer if available,
- an explanation of the value variation.
</bodyText>
<subsectionHeader confidence="0.993519">
4.1 Direct answer generation
4.1.1 Question constraints
</subsectionHeader>
<bodyText confidence="0.999263">
The content determination process for the di-
rect answer generation is mainly guided by con-
straints which may be explicit or implicit in the
question. For example, in the question how many
inhabitants are there in France in 2006?, there
</bodyText>
<page confidence="0.993019">
106
</page>
<bodyText confidence="0.94711065625">
are explicit constraints on time and place. On
the contrary, in how many inhabitants are there in
France?, there is no constraint on time. Let C be
the set of question constraints: C = {Ct, Cp, Cr}
with:
- Ct: constraint on time (Ct E {exp time, 0}),
- Cp: constraint on place (Cp E {exp place, 0}),
- Cr: constraint on restrictions (Cr E {exp restr,
0}).
For example, in the question what is the average
age ofmarriage in France?: Ct = 0, Cp = France
and Cr = 0.
When there is no explicit constraint in the ques-
tion, we distinguish several cases:
- if there is no explicit constraint on time in the
question and if a numerical variation over time has
been infered from the data set, then we assume that
the user wants to have the most recent information:
Ct = max({ai(date), ai E A}),
- if there is no explicit constraint on place in the
question and if a numerical variation according to
place has been infered from the data set, then we
assume that the user wants to have the information
for the closest place to him (the system can have
this information for example via a user model),
- if there is no explicit constraint on restrictions in
the question and if a numerical variation accord-
ing to restrictions has been infered from the data
set, then we assume that the user wants to have the
information for any restrictions.
For example, on figure 5: Ct = 2000 (the most
recent information), Cp = France and Cr = 0.
</bodyText>
<subsectionHeader confidence="0.638783">
4.1.2 Candidate answers
</subsectionHeader>
<bodyText confidence="0.99882775">
Candidate frames for direct answers are those
which satisfy the set of constraints C. Let AC be
the set of frames which satisfy C (via subsump-
tion):
</bodyText>
<equation confidence="0.98163725">
AC = {ai E A, such as
ai(date) = (Ct V 0) n ai(place) = (Cp V 0) n
f Cr V 0 if Cr 7�0
l exp rest V 0 if Cr = 0
</equation>
<bodyText confidence="0.33634">
For figure 5: AC = {a1, a2, a3, a4, a5, a6}.
</bodyText>
<subsectionHeader confidence="0.917089">
4.1.3 Choosing a direct answer
</subsectionHeader>
<bodyText confidence="0.97311">
A direct answer has to be generated from
the set AC. We define subsets of AC which
contain frames having the same restrictions: a
direct answer will be generated for each relevant
restriction. Let 9/ be the subsets of frames
satisfying the question constraints and having the
same restrictions: 9/ = {AC1, ..., ACM} with:
</bodyText>
<equation confidence="0.9490783">
ACi = {aj, such as V aj, ak E AC,
aj(restriction) = ak(restriction)
V aj(restriction) = 0},
and AC1, ..., ACM are disjoint.
For figure 5: 9/ = {AC1, AC2} with:
AC1 = {a1, a3, a5}, subset for restriction women,
AC2 = {a2, a4, a6}, subset for restriction men.
Then, for each element in 9 /, an answer is
generated :
V ACi E 9 /, answer = generate answer(ACi).
</equation>
<bodyText confidence="0.9999805">
Each element of 9/ may contain one or sev-
eral frames, i.e. one or several numerical data.
Some of these values may be aberrant (for exam-
ple, How high is the Eiffel Tower? 300m, 324m,
18cm): they are filtered out via classical statistical
methods (use of the standard deviation). Among
the remaining frames, values may be equal or not
at different degrees (rounded values, for example).
Those values have to be integrated so that a syn-
thetic answer can be generated.
There are many operators used in logical ap-
proaches for fusion: conjunction, disjunction, av-
erage, etc. But, they may produce an answer
which is not cooperative: a conjunction or disjunc-
tion of all candidates may mislead users; the aver-
age of candidates is an ”artificial” answer since it
has been computed and not extracted from Web
pages.
Our approach allows the system to choose a
value among the set of possible values, dealing
with the problem of rounded or approximative
data. Candidate values are represented by an ori-
ented graph whose arcs are weighted with the cost
between the two linked values and the weight (w)
of the departure value (its number of occurrences).
A graph 9 of numerical values is defined by ✓V
the set of nodes (set of values) and 9/ rc the set of
arcs. The cost c(x, y) of arc(x, y) is:
</bodyText>
<equation confidence="0.84237575">
n n
X (w(x) + w(xi)) + c(xi, x).
i=1 i=1
with (x1, ..., xn, x) a path from x1 to x.
</equation>
<bodyText confidence="0.9999382">
Finally, we define a fusion operator which
selects the value which is used for the direct
answer. This value is the one which maximizes
the difference (cost(x)) between the cost to leave
this value and the cost to arrive to this value:
</bodyText>
<equation confidence="0.956745333333333">
ai(restriction) =
|x − y|
y
</equation>
<page confidence="0.995159">
107
</page>
<figureCaption confidence="0.998786">
Figure 5: Data set for What is the average age of marriage in France?
</figureCaption>
<equation confidence="0.933592">
answer = y E _4&apos;, such as
cost(y) = max({ cost(n), V n E _ /V,
cost(n) = cost leave(n) − cost arrive(n)j)
with: cost leave(x) = Ei c(x, xi) and,
cost arrive(x) = Ei c(xi, x).
</equation>
<bodyText confidence="0.999783192307692">
Let us consider an example. The following val-
ues are candidate for the direct answer to the ques-
tion How high is the Mont-Blanc?: 4800, 4807
(2 occurrences), 4808 (2 occurrences), 4808.75,
4810 (8 occurrences) and 4813. Figure 6 shows
the graph of values: in this example, the value
which maximizes the costs is 4810.
From the selected value, the system generates
a direct answer in natural language in the form
of Focus Verb (Precision) Value. For example,
the generated answer for How high is the Mont-
Blanc? is The Mont-Blanc is about 4810 meters
high. Here the preposition about indicates to the
user that the given value is an approximation.
For the question what is the average age of mar-
riage in France?, a direct answer has to be gen-
erated for each restriction. For the restriction men
(AC2), there are 3 candidate values: 29.8, 30 and
30.6, the value which minimizes the costs being
30. For the restriction women (AC1), there are
also 3 candidate values: 27.7, 28 and 28.5, the
value which minimizes the costs being 28. Af-
ter aggregation process, the generated direct an-
swer is: In 2000, the average age of marriage in
France was about 30 years for men and 28 years
for women.
</bodyText>
<subsectionHeader confidence="0.995114">
4.2 Explanation generation
</subsectionHeader>
<bodyText confidence="0.999442386363636">
The generation of the cooperative part of the an-
swer is complex because it requires lexical knowl-
edge. This part of the answer has to explain to
the user variation phenomena of search values:
when a variation of values is identified and char-
acterised, an explanation is generated in the form
of X varies according to Criteria. In the case of
variation according to restrictions or properties of
the focus, a generalizer is generated. For exam-
ple, the average age of marriage varies for men and
women: the explanation is in the form the average
age of marriage varies according to sex. The gen-
eralizer is the mother concept in the ontology or a
property of the mother concept (Benamara, 2004).
For numerical value varying over time, if the vari-
ation mode (increase or decrease) is identified,
a more precise explanation is generated: X in-
creased/decreased between... and... instead of X
varies over time.
Here, verbs are used to express precisely numer-
ical variations. The lexicalisation process needs
deep lexical descriptions. We use for that pur-
pose a classification of French verbs (Saint-Dizier,
1999) based on the main classes defined by Word-
Net. The classes we are interested in for our
task are mainly those of verbs of state (have,
be, weight, etc.), verbs of change (increase, de-
crease, etc.) and verbs of movement (climb,
move forward/backward, etc.) used metaphori-
cally (Moriceau et al, 2003). From these classes,
we selected a set of about 100 verbs which can be
applied to numerical values.
From these classes, we characterized sub-classes
of growth, decrease, etc., so that the lexicalisation
task is constrained by the type of verbs which has
to be used according to the variation mode.
A deep semantics of verbs is necessary to gen-
erate an answer which takes into account the char-
acteristics of numerical variation as well as pos-
sible: for example, the variation mode but also
the speed and range of the variation. Thus, for
each sub-class of verbs and its associated varia-
tion mode, we need a refined description of onto-
logical domains and selectional restrictions so that
</bodyText>
<page confidence="0.997695">
108
</page>
<figureCaption confidence="0.999495">
Figure 6: Graph of candidate values for How high is the Mont-Blanc?
</figureCaption>
<bodyText confidence="0.9982868">
an appropriate verb lexicalisation can be chosen:
which verb can be applied to prices, to age, etc.?
(Moriceau et al, 2003). We propose to use propor-
tional series representing verb sub-classes accord-
ing to the speed and amplitude of variation. For
example, the use of climb (resp. drop) indicates
a faster growth (resp. decrease) than go up (resp.
go down): the verb climb is prefered for the gener-
ation of Gas prices climb 20.3% in october 2005
whereas go up is prefered in Gas prices went up
7.2% in september 2005.
Verbs can possibly be associated with a preposi-
tion that refines the information (The average age
of marriage increased by about 5.5 years between
1972 and 2005).
</bodyText>
<subsectionHeader confidence="0.996298">
4.3 Answer justification
</subsectionHeader>
<bodyText confidence="0.999848619047619">
Our system generates a cooperative answer com-
posed of a direct answer to the question and an ex-
planation for the possible variation of the searched
numerical value. But the answer may not be sure
because of a too high/low number of candidate
values to the direct answer. In this case, it may be
useful to add some additional information for the
user in order to justify or complete the generated
answer.
We propose to add a know-how component to
our system, which provides the user with one or
two relevant Web page extracts besides the gen-
erated answer whenever it is necessary. These ex-
tracts must contain information about the searched
numerical values, and for example some explana-
tions of the causes of numerical variation. Some
linguistic clues can be used to select page extracts:
number of numerical values concerning the ques-
tion focus, causal marks (because of, due to, ...),
etc. Figure 7 shows an output example of our sys-
tem.
</bodyText>
<figureCaption confidence="0.994837">
Figure 7: An ouput example
</figureCaption>
<sectionHeader confidence="0.99796" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999929833333333">
In this section, we present some elements of eval-
uation of our system with respect to 15 end-users3.
We first evaluated how users behave when they
are faced with different candidate answers to a
question. To each user, we presented 5 numeri-
cal questions and their candidate answers which
vary according to time or restrictions and ask them
to produce their own answer from candidate an-
swers. For numerical answers varying according
to restrictions, 93% of subjects produce answers
explaining the different numerical values for each
restriction. For numerical answers varying over
time, 80% of subjects produce answers giving the
most recent information (20% of subjects produce
an answer which a summary of all candidate val-
ues). This validates our hypothesis presented in
section 4.1.1.
The second point we evaluated is the answer or-
der. Our system produces answers in the form of
a direct answer, then an explanation and a justi-
fication (page extract) if necessary. We proposed
to users answers with these three parts arranged
randomly. Contrary to (Yu et al, 2005) which pro-
pose first an overview and then a zoom on inter-
</bodyText>
<footnote confidence="0.9708905">
3Subjects are between 20 and 35 years old and are accus-
tomed to using search engines.
</footnote>
<page confidence="0.998315">
109
</page>
<bodyText confidence="0.999976846153846">
esting phenomena, 73% of subjects prefered the
order proposed by our system, perhaps because, in
QA systems, users wants to have a direct answer
to their question before having explanations.
The last point we evaluated is the quality of the
system answers. For this purpose, we asked sub-
jects to choose, for 5 questions, which answer they
prefer among: the system answer, an average, an
interval and a disjunction of all candidate answers.
91% of subjects prefered the system answer. 75%
of subjects found that the explanation produced is
useful and only 31% of subjects consulted the Web
page extract (28% of these found it useful).
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999992105263158">
We proposed a question-answering system which
generates intelligent answers to numerical ques-
tions. Candidate answers are first extracted from
the Web. Generated answers are composed of
three parts: (1) a direct answer: the content
determination process ”chooses” a direct answer
among candidates, dealing with data inconsisten-
cies and approximations, (2) an explanation: the
content determination process allows to identify,
from data sets, the possible value variations and
to infer their variation criteria (time, place or re-
strictions on the question focus), and (3) a possi-
ble Web page extract. This work has several future
directions among which we plan:
- to define precisely in which cases it is useful to
propose a Web page extract as a justification and,
- to measure the relevance of restrictions on the
question focus to avoid generating an enumeration
of values corresponding to irrelevant restrictions.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999480125">
F. Benamara. 2004. Generating Intensional Answers
in Intelligent Question Answering Systems. LNAI
Series, volume 3123, Springer.
R. Dale. 2003. http://www.ics.mq.edu.au/ lgt-
demo/StockReporter/.
R. A. Fisher 1925. Statistical Methods for Research
Workers, originally published in London by Oliver
and Boyd.
E. Goldberg, N. Driedger, R. Kittredge. 1994. Us-
ing natural language processing to produce weather
forecasts. IEEE Expert 9(2).
H.P. Grice. 1975. Logic and conversation. In P. Cole
and J.L. Morgan, (eds.): Syntax and Semantics, Vol.
3, Speech Acts, New York, Academic Press.
S. Harabagiu and F. Lacatusu. 2004. Strategies for
Advanced Question Answering. Proceedings of the
Workshop on Pragmatics of Question Answering at
HLT-NAACL 2004.
K. Kukich. 1983. Knowledge-based report genera-
tion: a knowledge engineering approach to natural
language report generation. Ph.D. Thesis, Informa-
tion Science Department, University of Pittsburgh.
D. Moldovan, C. Clark, S. Harabagiu and S. Maiorano.
2003. COGEX: A Logic Prover for Question An-
swering. Proceedings of HLT-NAACL 2003.
V. Moriceau and P. Saint-Dizier. 2003. A Conceptual
Treatment of Metaphors for NLP. Proceedings of
ICON, Mysore, India.
V. Moriceau. 2006. Numerical Data Integration
for Question-Answering. Proceedings of EACL-
KRAQ’06, Trento, Italy.
A. Motro, P. Anokhin. 2004. Fusionplex: resolution
of data inconsistencies in the integration of hetero-
geneous information sources. Information Fusion,
Elsevier.
S. Narayanan, S. Harabagiu. 2004. Answering Ques-
tions Using Adcanced Semantics and Probabilis-
tic Inference. Proceedings of the Workshop on
Pragmatics of Question Answering, HLT-NAACL,
Boston, USA, 2004.
L. Page, S. Brin, R. Motwani, T. Winograd. 1998. The
PageRank Citation Ranking: Bringing Ordre to the
Web. Technical Report, Computer Science Depart-
ment, Stanford University.
D.R. Radev and K.R. McKeown. 1998. Generat-
ing Natural Language Summaries from Multiple On-
Line Sources. Computational Linguistics, vol. 24,
issue 3 - Natural Language Generation.
P. Saint-Dizier. 1999. Alternations and Verb Semantic
Classes for French. Predicative Forms for NL and
LKB, Kluwer Academic.
P. Saint-Dizier. 2005. PrepNet: a Framework for
Describing Prepositions: preliminary investigation
results. Proceedings of IWCS’05, Tilburg, The
Netherlands.
G. Salton. 2002. Automatic Text Processing. The
Transformation, Analysis and Retrieval of Informa-
tion by Computer, Addison-Wesley.
B. Webber, C. Gardent and J. Bos. 2002. Position
statement: Inference in Question Answering. Pro-
ceedings of LREC, Las Palmas, Spain.
J. Yu, E. Reiter, J. Hunter, C. Mellish. 2005. Choosing
the content of textual summaries of large time-series
data sets. Natural Language Engineering, 11.
</reference>
<page confidence="0.998376">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.831566">
<title confidence="0.9997965">Generating Intelligent Numerical in a Question-Answering System</title>
<author confidence="0.93079">V´eronique</author>
<affiliation confidence="0.992351">Institut de Recherche en Informatique de</affiliation>
<address confidence="0.904644">118, route de Narbonne, 31062 Toulouse,</address>
<email confidence="0.998388">moriceau@irit.fr</email>
<abstract confidence="0.998837916666667">In this paper, we present a questionanswering system on the Web which aims at generating intelligent answers to numerical questions. These answers are generated in a cooperative way: besides a direct answer, comments are generated to explain to the user the variation of numerical data extracted from the Web. We present the content determination and realisation tasks. We also present some elements of evaluation with respect to end-users.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Benamara</author>
</authors>
<title>Generating Intensional Answers in Intelligent Question Answering Systems.</title>
<date>2004</date>
<booktitle>LNAI Series,</booktitle>
<volume>volume</volume>
<pages>3123</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="19827" citStr="Benamara, 2004" startWordPosition="3415" endWordPosition="3416">equires lexical knowledge. This part of the answer has to explain to the user variation phenomena of search values: when a variation of values is identified and characterised, an explanation is generated in the form of X varies according to Criteria. In the case of variation according to restrictions or properties of the focus, a generalizer is generated. For example, the average age of marriage varies for men and women: the explanation is in the form the average age of marriage varies according to sex. The generalizer is the mother concept in the ontology or a property of the mother concept (Benamara, 2004). For numerical value varying over time, if the variation mode (increase or decrease) is identified, a more precise explanation is generated: X increased/decreased between... and... instead of X varies over time. Here, verbs are used to express precisely numerical variations. The lexicalisation process needs deep lexical descriptions. We use for that purpose a classification of French verbs (Saint-Dizier, 1999) based on the main classes defined by WordNet. The classes we are interested in for our task are mainly those of verbs of state (have, be, weight, etc.), verbs of change (increase, decre</context>
</contexts>
<marker>Benamara, 2004</marker>
<rawString>F. Benamara. 2004. Generating Intensional Answers in Intelligent Question Answering Systems. LNAI Series, volume 3123, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<date>2003</date>
<note>http://www.ics.mq.edu.au/ lgtdemo/StockReporter/.</note>
<contexts>
<context position="4708" citStr="Dale, 2003" startWordPosition="752" endWordPosition="753">erical data We focus on the integration of numerical data for the generation of natural language cooperative numerical answers. We first present some related work on generation from numerical data sets. Then we propose a model for the generation of cooperative numerical answers. 2.1 Related work The generation of summaries from numerical data has been developed in some NLG systems. For example, the system ANA (Kukich, 1983) generates stock market reports by computing fluctuations for a day. FoG (Goldberg et al, 1994) produces weather forecasts from forecast data. More recently, StockReporter (Dale, 2003) was developed to generate summaries describing how a stock performs over a period. Yu et al. (2005) propose a system which generates summaries of sensor data from gas turbines. Those systems have input data analysis components which are more or less efficient and describe numerical time-series data. In the framework of QA systems, there are other major problems that the previous systems do not deal with. When a numerical question is submitted to a QA system, a set of numerical data is extracted from the Web. Then, the goal is not to describe the whole data set but to find an appropriate answe</context>
</contexts>
<marker>Dale, 2003</marker>
<rawString>R. Dale. 2003. http://www.ics.mq.edu.au/ lgtdemo/StockReporter/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Fisher</author>
</authors>
<title>Statistical Methods for Research Workers, originally published in London by Oliver and Boyd.</title>
<date>1925</date>
<contexts>
<context position="12621" citStr="Fisher, 1925" startWordPosition="2102" endWordPosition="2103">e explanation can be generated. For this purpose, we draw a regression line which determines the relationship between the two extracted variables value and date. In particular, Pearson’s correlation coefficient (r), related to the line slope, reflects the degree of linear relationship between two variables. It ranges from +1 to −1. For example, figure 3 shows that a positive Pearson’s correlation implies a general increase of values whereas a negative Pearson’s correlation implies a general decrease. On the contrary, if r is low (−0.6 &lt; r &lt; 0.6), then we consider that the variation is random (Fisher, 1925). Figure 3: Variation mode Figure 4 shows the results for the question How many inhabitants are there in France? Different numerical values and associated dates are extracted from Web pages. The Pearson’s correlation is 0.694 meaning that the number of inhabitants increases over time (between 1999 and 2005). Figure 4: Variation mode: How many inhabitants are there in France? 4 Answer generation Once the searched numerical values have been extracted and characterized by their variation criteria and mode, a cooperative answer is generated in natural language. It is composed of two parts: - a dir</context>
</contexts>
<marker>Fisher, 1925</marker>
<rawString>R. A. Fisher 1925. Statistical Methods for Research Workers, originally published in London by Oliver and Boyd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Goldberg</author>
<author>N Driedger</author>
<author>R Kittredge</author>
</authors>
<title>Using natural language processing to produce weather forecasts.</title>
<date>1994</date>
<journal>IEEE Expert</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="4619" citStr="Goldberg et al, 1994" startWordPosition="738" endWordPosition="741">lly, we give some elements of evaluation of our system outputs, with respect to end-users. 2 On numerical data We focus on the integration of numerical data for the generation of natural language cooperative numerical answers. We first present some related work on generation from numerical data sets. Then we propose a model for the generation of cooperative numerical answers. 2.1 Related work The generation of summaries from numerical data has been developed in some NLG systems. For example, the system ANA (Kukich, 1983) generates stock market reports by computing fluctuations for a day. FoG (Goldberg et al, 1994) produces weather forecasts from forecast data. More recently, StockReporter (Dale, 2003) was developed to generate summaries describing how a stock performs over a period. Yu et al. (2005) propose a system which generates summaries of sensor data from gas turbines. Those systems have input data analysis components which are more or less efficient and describe numerical time-series data. In the framework of QA systems, there are other major problems that the previous systems do not deal with. When a numerical question is submitted to a QA system, a set of numerical data is extracted from the W</context>
</contexts>
<marker>Goldberg, Driedger, Kittredge, 1994</marker>
<rawString>E. Goldberg, N. Driedger, R. Kittredge. 1994. Using natural language processing to produce weather forecasts. IEEE Expert 9(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>3</volume>
<editor>In P. Cole and J.L. Morgan, (eds.):</editor>
<publisher>Academic Press.</publisher>
<location>New York,</location>
<contexts>
<context position="3215" citStr="Grice, 1975" startWordPosition="520" endWordPosition="521">le. 1.2 Motivations and goals Our framework is advanced QA systems over open domains. Our main goals are to model and to evaluate a system which, from a factoid question in natural language (in French), selects a set of candidate answers on the Web and generates cooperative answers in natural language. Our challenge is (1) to generate a synthetic answer instead of a list of potential answers (in order to avoid providing the user with too much information), and (2) to generate relevant comments which explain the variety of answers extracted from the Web (in order to avoid misleading the user) (Grice, 1975). In a cooperative perspective, we propose an approach for answer generation which uses answer integration. When several possible answers are extracted from the Web, the goal is to define a coherent core 103 Proceedings of the Fourth International Natural Language Generation Conference, pages 103–110, Sydney, July 2006. c�2006 Association for Computational Linguistics from candidate answers and to generate a cooperative answer, i.e. an answer with explanations. In this paper, we focus on the integration of numerical data in order to generate natural language cooperative answers to numerical qu</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>H.P. Grice. 1975. Logic and conversation. In P. Cole and J.L. Morgan, (eds.): Syntax and Semantics, Vol. 3, Speech Acts, New York, Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>F Lacatusu</author>
</authors>
<title>Strategies for Advanced Question Answering.</title>
<date>2004</date>
<booktitle>Proceedings of the Workshop on Pragmatics of Question Answering at HLT-NAACL</booktitle>
<contexts>
<context position="1966" citStr="Harabagiu and Lacatusu, 2004" startWordPosition="306" endWordPosition="309">ty criteria (Salton, 1989; Page et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). Most systems provide the user with either a set of potential answers (ranked or not), or the ”best” answer according to some relevance criteria. They do not provide answers which take into account information from a set of candidate answers or answer inconsistencies. As for logical approaches used for database query, they are based on majority approach or on source reliability. But, contrary to the assumption of (Motro et al., 2004), we noted that reliability information (information about the author, date of Web pages, ...) is rather difficult to obtain, so we assume </context>
</contexts>
<marker>Harabagiu, Lacatusu, 2004</marker>
<rawString>S. Harabagiu and F. Lacatusu. 2004. Strategies for Advanced Question Answering. Proceedings of the Workshop on Pragmatics of Question Answering at HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Knowledge-based report generation: a knowledge engineering approach to natural language report generation.</title>
<date>1983</date>
<tech>Ph.D. Thesis,</tech>
<institution>Information Science Department, University of Pittsburgh.</institution>
<contexts>
<context position="4524" citStr="Kukich, 1983" startWordPosition="725" endWordPosition="726">a QA system. Then, we present the content determination and realization processes. Finally, we give some elements of evaluation of our system outputs, with respect to end-users. 2 On numerical data We focus on the integration of numerical data for the generation of natural language cooperative numerical answers. We first present some related work on generation from numerical data sets. Then we propose a model for the generation of cooperative numerical answers. 2.1 Related work The generation of summaries from numerical data has been developed in some NLG systems. For example, the system ANA (Kukich, 1983) generates stock market reports by computing fluctuations for a day. FoG (Goldberg et al, 1994) produces weather forecasts from forecast data. More recently, StockReporter (Dale, 2003) was developed to generate summaries describing how a stock performs over a period. Yu et al. (2005) propose a system which generates summaries of sensor data from gas turbines. Those systems have input data analysis components which are more or less efficient and describe numerical time-series data. In the framework of QA systems, there are other major problems that the previous systems do not deal with. When a </context>
</contexts>
<marker>Kukich, 1983</marker>
<rawString>K. Kukich. 1983. Knowledge-based report generation: a knowledge engineering approach to natural language report generation. Ph.D. Thesis, Information Science Department, University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>C Clark</author>
<author>S Harabagiu</author>
<author>S Maiorano</author>
</authors>
<title>COGEX: A Logic Prover for Question Answering.</title>
<date>2003</date>
<booktitle>Proceedings of HLT-NAACL</booktitle>
<contexts>
<context position="1642" citStr="Moldovan et al., 2003" startWordPosition="259" endWordPosition="262">n quite difficult for the user to know which answer is the correct one. Thus, an analysis of relevance and coherence of candidate answers is essential. 1.1 Related work Search engines on the Web produce a set of answers to a question in the form of hyperlinks or page extracts, ranked according to content or popularity criteria (Salton, 1989; Page et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). Most systems provide the user with either a set of potential answers (ranked or not), or the ”best” answer according to some relevance criteria. They do not provide answers which take into account information from a set of candidate answers or answer </context>
</contexts>
<marker>Moldovan, Clark, Harabagiu, Maiorano, 2003</marker>
<rawString>D. Moldovan, C. Clark, S. Harabagiu and S. Maiorano. 2003. COGEX: A Logic Prover for Question Answering. Proceedings of HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Moriceau</author>
<author>P Saint-Dizier</author>
</authors>
<title>A Conceptual Treatment of Metaphors for NLP.</title>
<date>2003</date>
<booktitle>Proceedings of ICON, Mysore,</booktitle>
<marker>Moriceau, Saint-Dizier, 2003</marker>
<rawString>V. Moriceau and P. Saint-Dizier. 2003. A Conceptual Treatment of Metaphors for NLP. Proceedings of ICON, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Moriceau</author>
</authors>
<title>Numerical Data Integration for Question-Answering.</title>
<date>2006</date>
<booktitle>Proceedings of EACLKRAQ’06,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="11783" citStr="Moriceau, 2006" startWordPosition="1960" endWordPosition="1961">2. place if P = jai(V al), I aj E A, such as ai(V al) =� aj(V al) A ai(Unit) = aj(Unit) A ai(Place) =� aj(Place) } A card(P) &gt; k 3. restriction if Rt = jai(V al), I aj E A, such as ai(V al) =� aj(V al) A ai(Unit) = aj(Unit) A ai(Restriction) =� aj(Restriction) } A card(Rt) &gt; k 4. time and place if (1) A (2) 5. time and restriction if (1) A (3) 6. place and restriction if (2) A (3) 7. time, place and restriction if (1) A (2) A (3) Numerical values can be compared only if they have the same unit of measure. If not, they have to be converted. More details about comparison rules are presented in (Moriceau, 2006). 3.2 Variation mode In the case of numerical values varying over time, it is possible to characterize more precisely the variation. The idea is to draw a trend (increase, decrease, ...) of variaton over time so that a precise explanation can be generated. For this purpose, we draw a regression line which determines the relationship between the two extracted variables value and date. In particular, Pearson’s correlation coefficient (r), related to the line slope, reflects the degree of linear relationship between two variables. It ranges from +1 to −1. For example, figure 3 shows that a positi</context>
</contexts>
<marker>Moriceau, 2006</marker>
<rawString>V. Moriceau. 2006. Numerical Data Integration for Question-Answering. Proceedings of EACLKRAQ’06, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Motro</author>
<author>P Anokhin</author>
</authors>
<title>Fusionplex: resolution of data inconsistencies in the integration of heterogeneous information sources. Information Fusion,</title>
<date>2004</date>
<publisher>Elsevier.</publisher>
<marker>Motro, Anokhin, 2004</marker>
<rawString>A. Motro, P. Anokhin. 2004. Fusionplex: resolution of data inconsistencies in the integration of heterogeneous information sources. Information Fusion, Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
<author>S Harabagiu</author>
</authors>
<title>Answering Questions Using Adcanced Semantics and Probabilistic Inference.</title>
<date>2004</date>
<booktitle>Proceedings of the Workshop on Pragmatics of Question Answering, HLT-NAACL,</booktitle>
<location>Boston, USA,</location>
<contexts>
<context position="1675" citStr="Narayanan and Harabagiu, 2004" startWordPosition="263" endWordPosition="266"> user to know which answer is the correct one. Thus, an analysis of relevance and coherence of candidate answers is essential. 1.1 Related work Search engines on the Web produce a set of answers to a question in the form of hyperlinks or page extracts, ranked according to content or popularity criteria (Salton, 1989; Page et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). Most systems provide the user with either a set of potential answers (ranked or not), or the ”best” answer according to some relevance criteria. They do not provide answers which take into account information from a set of candidate answers or answer inconsistencies. As for logical a</context>
</contexts>
<marker>Narayanan, Harabagiu, 2004</marker>
<rawString>S. Narayanan, S. Harabagiu. 2004. Answering Questions Using Adcanced Semantics and Probabilistic Inference. Proceedings of the Workshop on Pragmatics of Question Answering, HLT-NAACL, Boston, USA, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Page</author>
<author>S Brin</author>
<author>R Motwani</author>
<author>T Winograd</author>
</authors>
<title>The PageRank Citation Ranking: Bringing Ordre to the Web.</title>
<date>1998</date>
<tech>Technical Report,</tech>
<institution>Computer Science Department, Stanford University.</institution>
<contexts>
<context position="1382" citStr="Page et al., 1998" startWordPosition="218" endWordPosition="221">with a set of hyperlinks and/or Web page extracts containing answer(s) to a question. These answers may be incoherent to a certain degree: they may be equivalent, complementary, contradictory, at different levels of precision or specificity, etc. It is then quite difficult for the user to know which answer is the correct one. Thus, an analysis of relevance and coherence of candidate answers is essential. 1.1 Related work Search engines on the Web produce a set of answers to a question in the form of hyperlinks or page extracts, ranked according to content or popularity criteria (Salton, 1989; Page et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al.</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>L. Page, S. Brin, R. Motwani, T. Winograd. 1998. The PageRank Citation Ranking: Bringing Ordre to the Web. Technical Report, Computer Science Department, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Radev</author>
<author>K R McKeown</author>
</authors>
<title>Generating Natural Language Summaries from Multiple OnLine Sources.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<contexts>
<context position="1702" citStr="Radev and McKeown, 1998" startWordPosition="267" endWordPosition="270"> correct one. Thus, an analysis of relevance and coherence of candidate answers is essential. 1.1 Related work Search engines on the Web produce a set of answers to a question in the form of hyperlinks or page extracts, ranked according to content or popularity criteria (Salton, 1989; Page et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). Most systems provide the user with either a set of potential answers (ranked or not), or the ”best” answer according to some relevance criteria. They do not provide answers which take into account information from a set of candidate answers or answer inconsistencies. As for logical approaches used for database</context>
</contexts>
<marker>Radev, McKeown, 1998</marker>
<rawString>D.R. Radev and K.R. McKeown. 1998. Generating Natural Language Summaries from Multiple OnLine Sources. Computational Linguistics, vol. 24, issue 3 - Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Saint-Dizier</author>
</authors>
<title>Alternations and Verb Semantic Classes for French. Predicative Forms for NL and LKB,</title>
<date>1999</date>
<publisher>Kluwer Academic.</publisher>
<contexts>
<context position="20241" citStr="Saint-Dizier, 1999" startWordPosition="3478" endWordPosition="3479">men and women: the explanation is in the form the average age of marriage varies according to sex. The generalizer is the mother concept in the ontology or a property of the mother concept (Benamara, 2004). For numerical value varying over time, if the variation mode (increase or decrease) is identified, a more precise explanation is generated: X increased/decreased between... and... instead of X varies over time. Here, verbs are used to express precisely numerical variations. The lexicalisation process needs deep lexical descriptions. We use for that purpose a classification of French verbs (Saint-Dizier, 1999) based on the main classes defined by WordNet. The classes we are interested in for our task are mainly those of verbs of state (have, be, weight, etc.), verbs of change (increase, decrease, etc.) and verbs of movement (climb, move forward/backward, etc.) used metaphorically (Moriceau et al, 2003). From these classes, we selected a set of about 100 verbs which can be applied to numerical values. From these classes, we characterized sub-classes of growth, decrease, etc., so that the lexicalisation task is constrained by the type of verbs which has to be used according to the variation mode. A d</context>
</contexts>
<marker>Saint-Dizier, 1999</marker>
<rawString>P. Saint-Dizier. 1999. Alternations and Verb Semantic Classes for French. Predicative Forms for NL and LKB, Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Saint-Dizier</author>
</authors>
<title>PrepNet: a Framework for Describing Prepositions: preliminary investigation results.</title>
<date>2005</date>
<booktitle>Proceedings of IWCS’05,</booktitle>
<location>Tilburg, The Netherlands.</location>
<marker>Saint-Dizier, 2005</marker>
<rawString>P. Saint-Dizier. 2005. PrepNet: a Framework for Describing Prepositions: preliminary investigation results. Proceedings of IWCS’05, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
</authors>
<title>Automatic Text Processing. The Transformation, Analysis and Retrieval of Information by Computer,</title>
<date>2002</date>
<publisher>Addison-Wesley.</publisher>
<marker>Salton, 2002</marker>
<rawString>G. Salton. 2002. Automatic Text Processing. The Transformation, Analysis and Retrieval of Information by Computer, Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>C Gardent</author>
<author>J Bos</author>
</authors>
<title>Position statement: Inference in Question Answering.</title>
<date>2002</date>
<booktitle>Proceedings of LREC, Las</booktitle>
<location>Palmas,</location>
<contexts>
<context position="1989" citStr="Webber et al., 2002" startWordPosition="310" endWordPosition="313">et al., 1998). Some QA systems on the Web use other techniques: candidate answers are ranked according to a score which takes into account lexical relations between questions and answers, semantic categories of concepts, distance between words, etc. (Moldovan et al., 2003), (Narayanan and Harabagiu, 2004), (Radev and McKeown, 1998). Recently, advanced QA systems defined relationships (equivalence, contradiction, ...) between Web page extracts or texts containing possible answers in order to combine them and to produce a single answer (Radev and McKeown, 1998), (Harabagiu and Lacatusu, 2004), (Webber et al., 2002). Most systems provide the user with either a set of potential answers (ranked or not), or the ”best” answer according to some relevance criteria. They do not provide answers which take into account information from a set of candidate answers or answer inconsistencies. As for logical approaches used for database query, they are based on majority approach or on source reliability. But, contrary to the assumption of (Motro et al., 2004), we noted that reliability information (information about the author, date of Web pages, ...) is rather difficult to obtain, so we assume that all Web pages are </context>
</contexts>
<marker>Webber, Gardent, Bos, 2002</marker>
<rawString>B. Webber, C. Gardent and J. Bos. 2002. Position statement: Inference in Question Answering. Proceedings of LREC, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yu</author>
<author>E Reiter</author>
<author>J Hunter</author>
<author>C Mellish</author>
</authors>
<title>Choosing the content of textual summaries of large time-series data sets.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<contexts>
<context position="4808" citStr="Yu et al. (2005)" startWordPosition="768" endWordPosition="771">e cooperative numerical answers. We first present some related work on generation from numerical data sets. Then we propose a model for the generation of cooperative numerical answers. 2.1 Related work The generation of summaries from numerical data has been developed in some NLG systems. For example, the system ANA (Kukich, 1983) generates stock market reports by computing fluctuations for a day. FoG (Goldberg et al, 1994) produces weather forecasts from forecast data. More recently, StockReporter (Dale, 2003) was developed to generate summaries describing how a stock performs over a period. Yu et al. (2005) propose a system which generates summaries of sensor data from gas turbines. Those systems have input data analysis components which are more or less efficient and describe numerical time-series data. In the framework of QA systems, there are other major problems that the previous systems do not deal with. When a numerical question is submitted to a QA system, a set of numerical data is extracted from the Web. Then, the goal is not to describe the whole data set but to find an appropriate answer, dealing with the user expectations (for example, contraints in the question) or data inconsistenc</context>
<context position="24050" citStr="Yu et al, 2005" startWordPosition="4122" endWordPosition="4125"> of subjects produce answers explaining the different numerical values for each restriction. For numerical answers varying over time, 80% of subjects produce answers giving the most recent information (20% of subjects produce an answer which a summary of all candidate values). This validates our hypothesis presented in section 4.1.1. The second point we evaluated is the answer order. Our system produces answers in the form of a direct answer, then an explanation and a justification (page extract) if necessary. We proposed to users answers with these three parts arranged randomly. Contrary to (Yu et al, 2005) which propose first an overview and then a zoom on inter3Subjects are between 20 and 35 years old and are accustomed to using search engines. 109 esting phenomena, 73% of subjects prefered the order proposed by our system, perhaps because, in QA systems, users wants to have a direct answer to their question before having explanations. The last point we evaluated is the quality of the system answers. For this purpose, we asked subjects to choose, for 5 questions, which answer they prefer among: the system answer, an average, an interval and a disjunction of all candidate answers. 91% of subjec</context>
</contexts>
<marker>Yu, Reiter, Hunter, Mellish, 2005</marker>
<rawString>J. Yu, E. Reiter, J. Hunter, C. Mellish. 2005. Choosing the content of textual summaries of large time-series data sets. Natural Language Engineering, 11.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>