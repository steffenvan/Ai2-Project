<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000499">
<title confidence="0.977858">
Expectations in Incremental Discourse Processing
</title>
<author confidence="0.998503">
Dan Cristea
</author>
<affiliation confidence="0.813353">
Faculty of Computer Science
University &amp;quot;AI Cuza&amp;quot;
</affiliation>
<address confidence="0.9611755">
16, Berthelot Street
6600 - Iasi, Romania
</address>
<email confidence="0.924011">
dcristeainfoiasi.ro
</email>
<author confidence="0.987264">
Bonnie Webber
</author>
<affiliation confidence="0.9976225">
Dept. of Computer &amp; Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.941913">
200 South 33rd Street
Philadelphia PA 19104-6389 USA
</address>
<email confidence="0.976097">
bonnieOcentral.cis.upenn.edu
</email>
<sectionHeader confidence="0.996977" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999884142857143">
The way in which discourse features ex-
press connections back to the previous dis-
course has been described in the literature
in terms of adjoining at the right frontier
of discourse structure. But this does not
allow for discourse features that express ex-
pectations about what is to come in the
subsequent discourse. After characterizing
these expectations and their distribution in
text, we show how an approach that makes
use of substitution as well as adjoining on a
suitably defined right frontier, can be used
to both process expectations and constrain
discouse processing in general.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999857884615385">
Discourse processing subsumes several distinguish-
able but interlinked processes. These include refer-
ence and ellipsis resolution, inference (e.g., inferen-
tial processes associated with focus particles such as,
in English, &amp;quot;even&amp;quot; and &amp;quot;only&amp;quot;), and identification of
those structures underlying a discourse that are as-
sociated with coherence relations between its units.
In the course of developing an incremental approach
to the latter, we noticed a variety of constructions
in discourse that raise expectations about its future
structural features. We found that we could rep-
resent such expectations by adopting a lexical vari-
ant of TAG — LTAG (Schabes, 1990) — and using
its substitution operation as a complement to ad-
joining. Perhaps more interesting was that these
expectations appeared to constrain the subsequent
discourse until they were resolved. This we found
we could model in terms of constraints on adjoining
and substitution with respect to a suitably defined
Right Frontier. This short paper focuesses on the
phenomenon of these expectations in discourse and
their expression in a discourse-level LTAG. We con-
clude the paper with some thoughts on incremental
discourse processing in light of these expectations.
The following examples illustrate the creation of
expectations through discourse markers:
</bodyText>
<figure confidence="0.95346725">
Example 1
a. On the one hand, John is very generous.
b. On the other, he is extremely difficult to find.
Example 2
a. On the one hand, John is very generous.
b. On the other, suppose you needed some money.
c. You&apos;d see that he&apos;s very difficult to find.
Example 3
</figure>
<listItem confidence="0.86198775">
a. On the one hand, John is very generous.
b. For example, suppose you needed some money.
c. You would just have to ask him for it.
b. On the other hand, he is very difficult to find.
</listItem>
<bodyText confidence="0.983814238095238">
Example 1 illustrates the expectation that, follow-
ing a clause marked &amp;quot;on the one hand&amp;quot;, the discourse
will express a constrasting situation (here marked
by &amp;quot;on the other&amp;quot;). Examples 2 and 3 illustrate
that such an expectation need not be satisfied im-
mediately by the next clause: In Example 2, clause
(b) partially resolves the expectation set up in (a),
but introduces an expectation that the subsequent
discourse will indicate what happens in such cases.
That expectation is then resolved in clause (c). In
Example 3, the next two clauses do nothing to sat-
isfy the expectation raised in clause (a): rather, they
give evidence for the claim made in (a). The expec-
tation raised in (a) is not resolved until clause (d).
These examples show expectations raised by sen-
tential adverbs and the imperative use of the verb
&amp;quot;suppose&amp;quot;. Subordinate conjunctions (e.g., &amp;quot;just
as&amp;quot;, &amp;quot;although&amp;quot;, &amp;quot;when&amp;quot;, etc.) can lead to similar
expectations when they appear in a preposed subor-
dinate clause - eg.
Example 4
</bodyText>
<listItem confidence="0.513052333333333">
a. Although John is very generous,
b. if you should need some money,
c. you&apos;d see that he&apos;s difficult to find.
</listItem>
<bodyText confidence="0.998707">
As in Example 2, clause 4(a) raises the expectation
of learning what is nevertheless the case. Clause 4(b)
partially satisfies that expectation by raising a hy-
</bodyText>
<page confidence="0.998059">
88
</page>
<bodyText confidence="0.99994346875">
pothetical situation, along with the expectation of
learning what is true in such a situation. This latter
expectation is then satisfied in clause 4(c).
In summary, these expectations can be charac-
terized as follows: (1) once raised, an expectation
must be resolved, but its resolvant can be a clause
that raises its own expectations; (2) a clause rais-
ing an expectation can itelf be elaborated before
that expectation is resolved, including elaboration
by clauses that raise their own expectations; and (3)
the most deeply &amp;quot;embedded&amp;quot; expectations must al-
ways be resolved first.
Now these are very likely not the only kinds of
expectations to be found in discourse: Whenever
events or behavior follow fairly regular patterns over
time, observers develop expectations about what will
come next or at least eventually. For example, a di-
alogue model may embody the expectation that a
suggestion made by one dialogue participant would
eventually be followed by an explicit or implicit re-
jection, acceptance or tabling by the other. Other di-
alogue actions such as clarifications or justifications
may intervene, but there is a sense of an expectation
being resolved when the suggestion is responded to.
Here we are focussed on discourse at the level of
individual monologue or turn within a larger dis-
course: what we show is that discourse manifests cer-
tain forward-looking patterns that have similar con-
straints to those of sentence-level syntax and can be
handled by similar means. One possible reason that
these particualr kinds of expressions may not have
been noticed before is that in non-incremental ap-
proaches to discourse processing (Mann and Thomp-
son, 1988; Marcu, 1996), they don&apos;t stand out as
obviously different.
The labels for discourse coherence relations used
here are similar to those of RST (Mann and Thomp-
son, 1988), but for simplicity, are treated as binary.
Since any multi-branching tree can be converted to a
binary tree, no representational power is lost. In do-
ing this, we follow several recent converging compu-
tational approaches to discourse analysis, which are
also couched in binary terms (Gardent, 1997; Marcu,
1996; Polanyi and van den Berg, 1996; Schilder,
1997; van den Berg, 1996).
Implicit in our discussion is the view that in
processing a discourse incrementally, its semantics
and pragmatics are computed compositionally from
the structure reflected in the coherence relations
between its units. In the figures presented here,
non-terminal nodes in a discourse structure are la-
belled with coherence relations merely to indicate
the functions that project appropriate content, be-
liefs and other side effects into the recipient&apos;s dis-
course model. This view is, we believe, consistent
with the more detailed formal interfaces to discourse
semantics/pragmatics presented in (Gardent, 1997;
Schilder, 1997; van den Berg, 1996), and also allows
for multiple discourse relations (intentional and in-
formational) to hold between discourse units (Moore
and Pollack, 1992; Moser and Moore, 1995; Moser
and Moore, 1996) and contribute to the seman-
tic/pragmatics effects on the recipient&apos;s discourse
model.
</bodyText>
<sectionHeader confidence="0.905909" genericHeader="method">
2 Expectations in Corpora
</sectionHeader>
<bodyText confidence="0.997587265306122">
The examples given in the Introduction were all
&amp;quot;minimal pairs&amp;quot; created to illustrate the relevant
phenomenon as succinctly as possible. Empirical
questions thus include: (1) the range of lexico-
syntactic constructions that raise expectations with
the specific properties mentioned above; (2) the fre-
quency of expectation-raising constructions in text;
(3) the frequency with which expectations are sat-
isfied immediately, as opposed to being delayed by
material that elaborates the unit raising the expec-
tation; (4) the frequency of embedded expectations;
and (5) features that provide evidence for an expec-
tation being satisfied.
While we do not have answers to all these ques-
tions, a very preliminary analysis of the Brown Cor-
pus, a corpus of approximately 1600 email messages,
and a short Romanian text by T. Vianu (approx.
5000 words) has yielded some interesting results.
First, reviewing the 270 constructions that Knott
has identified as potential cue phrases in the Brown
Corpus 1, one finds 15 adverbial phrases (such as
&amp;quot;initially&amp;quot;, &amp;quot;at first&amp;quot;, &amp;quot;to start with&amp;quot;, etc.) whose
presence in a clause would lead to an expectation
being raised. All left-extraposed clauses in English
raise expectations (as in Example 4) so all the sub-
ordinate conjunctions in Knott&apos;s list would be in-
cluded as well. Outside of cue phrases, we have iden-
tified imperative forms of &amp;quot;suppose&amp;quot; and &amp;quot;consider&amp;quot;
as raising expectations, but currently lack a more
systematic procedure for identifying expectation-
raising constructions in text than hand-combing text
for them.
With respect to how often expectation-raising
constructions appear in text, we have Brown Cor-
pus data on two specific types — imperative &amp;quot;sup-
pose&amp;quot; and adverbial &amp;quot;on the one hand&amp;quot; — as well as
a detailed analysis of the Romanian text by Vianu
mentioned earlier.
There are approximately 54K sentences in the
Brown Corpus. Of these, 37 contain imperative
&amp;quot;suppose&amp;quot; or &amp;quot;let us suppose&amp;quot;. Twelve of these cor-
respond to &amp;quot;what if&amp;quot; questions or negotiation moves
which do not raise expectations:
Suppose — just suppose this guy was really
what he said he was! A retired professional
killer If he was just a nut, no harm was
done. But if he was the real thing, he could
do something about Lolly. (c123)
&apos;Personal communication, but also see (Knott, 1996)
</bodyText>
<page confidence="0.998896">
89
</page>
<bodyText confidence="0.989791594594595">
Alec leaned on the desk, holding the clerk&apos;s
eyes with his. &amp;quot;Suppose you tell me the
real reason&amp;quot;, he drawled. &amp;quot;There might be
a story in it&amp;quot;. (c121)
The remaining 25 sentences constitute only about
0.05% of the Brown Corpus. Of these, 22 have their
expectations satisfied immediately (88%) — for ex-
ample,
Suppose John Jones, who, for 1960, filed
on the basis of a calendar year, died June
20, 1961. His return for the period January
1 to June 20, 1961, is due April 16, 1962.
One is followed by a single sentence elaborating the
original supposition (also flagged by &amp;quot;suppose&amp;quot;) —
&amp;quot;Suppose it was not us that killed these
aliens. Suppose it is something right on the
planet, native to it. I just hope it doesn&apos;t
work on Earthmen too. These critters went
real sudden&amp;quot;. (cm04)
while the remaining two contain multi-sentence elab-
orations of the original supposition. None of the ex-
amples in the Brown Corpus contains an embedded
expectation.
The adverbial &amp;quot;on the one hand&amp;quot; is used to pose
a contrast either phrasally —
Both plans also prohibited common direc-
tors, officers, or employees between Du
Pont, Christiana, and Delaware, on the one
hand, and General Motors on the other.
(chi 6)
You couldn&apos;t on the one hand decry the
arts and at the same time practice them,
could you? (ck08)
or clausally. It is only the latter that are of interest
from the point of discourse expectations.
The Brown Corpus contains only 7 examples of
adverbial &amp;quot;on the one hand&amp;quot;. In three cases, the
expectation is satisfied immediately by a clause cued
by &amp;quot;but&amp;quot; or &amp;quot;or&amp;quot; — e.g.
On the one hand, the Public Health Ser-
vice declared as recently as October 26 that
present radiation levels resulting from the
Soviet shots &amp;quot;do not warrant undue public
concern&amp;quot; or any action to limit the intake
of radioactive substances by individuals or
large population groups anywhere in the
Aj. But the PH conceded that the new
radioactive particles &amp;quot;will add to the risk
of genetic effects in succeeding generations,
and possibly to the risk of health damage to
some people in the United States&amp;quot; .(cb2/)
In the remaining four cases, satisfaction of the ex-
pectation (the &amp;quot;target&amp;quot; contrast item) is delayed by
2-3 sentences elaborating the &amp;quot;source&amp;quot; contrast item
— e.g.
Brooklyn College students have an ambiva-
lent attitude toward their school. On the
one hand, there is a sense of not having
moved beyond the ambiance of their high
school. This is particularly acute for those
who attended Midwood High School di-
rectly across the street from Brooklyn Col-
lege. They have a sense of marginality at
being denied that special badge of status,
the out-of-town school. At the same time,
there is a good deal of self-congratulation
at attending a good college ...(cf25)
In these cases, the target contrast item is cued by
&amp;quot;on the other hand&amp;quot; in three cases and &amp;quot;at the same
time&amp;quot; in the case given above. Again, none of the
examples contains an embedded expectation.
(The much smaller email corpus contained six ex-
amples of clausal &amp;quot;on the one hand&amp;quot;, with the target
contrast cued by &amp;quot;on the other hand&amp;quot; ,&amp;quot;on the other&amp;quot;
or &amp;quot;at the other extreme&amp;quot;. In one case, there was no
explicit target contrast and the expectation raised
by &amp;quot;on the one hand&amp;quot; was never satisfied. We will
continue to monitor for such examples.)
Before concluding with a close analysis of the Ro-
manian text, we should note that in both the Brown
Corpus and the email corpus, clausal adverbial &amp;quot;on
the other hand&amp;quot; occurs more frequently without an
expectation-raising &amp;quot;on the one hand&amp;quot; than it does
with one. (Our attention was called to this by a
frequency analysis of potential cue phrase instances
in the Brown Corpus compiled for us by Alistair
Knott and Andrei Mikheev, HCRC, University of
Edinburgh.) We found 53 instances of clausal &amp;quot;on
the other hand&amp;quot; occuring without an explicit source
contrast cued earlier. Although one can only specu-
late now on the reason for this phenomenon, it does
make a difference to incremental analysis, as we try
to show in Section 3.3.
The Romanian text that has been closely anal-
ysed for explicit expectation-raising constructions is
T. Vianu&apos;s Aesthetics. It contains 5160 words and
382 discourse units (primarily clauses). Counting
preposed gerunds as raising expectations as well as
counting the constructions noted previously, 39 in-
stances of expectation-raising discourse units were
identified (10.2%). In 11 of these cases, 1-16 dis-
course units intervened before the raised expectation
was satisfied. One example follows:
Dar deli trebuie parcurgem in
intregime, pentru a orienta cercetarea este
nevoie s5, inceream 1nc5, de pe acum o pre-
cizare a obiectului lui.
(But although we must cover it entirely, in
order to guide the research we need to try
already an explanation of its subject mat-
ter.)
</bodyText>
<page confidence="0.995691">
90
</page>
<sectionHeader confidence="0.977579" genericHeader="method">
3 A Grammar for Discourse
</sectionHeader>
<bodyText confidence="0.999933">
The intuitive appeal of Tree-adjoining Grammar
(TAG) (Joshi, 1987) for discourse processing (Gar-
dent, 1997; Polanyi and van den Berg, 1996;
Schilder, 1997; van den Berg, 1996; Webber, 1991)
follows from the fact that TAG&apos;s adjoining operation
allows one to directly analyse the current discourse
unit as a sister to previous discourse material that
it stands in a particular relation to. The new in-
tuition presented here — that expectations convey a
dependency between the current discourse unit and
future discourse material, a dependency that can
be &amp;quot;stretched&amp;quot; long-distance by intervening mate-
rial — more fully exploits TAG&apos;s ability to express
dependencies. By expressing in an elementary TAG
tree, a dependency betwen the current discourse unit
and future discourse material and using substitu-
tion (Schabes, 1990) when the expected material is
found, our TAG-based approach to discourse pro-
cessing allows expectations to be both raised and
resolved.
</bodyText>
<subsectionHeader confidence="0.991054">
3.1 Categories and Operations
</subsectionHeader>
<bodyText confidence="0.999787711864407">
The categories of our TAG-based approach consist
of nodes and binary trees. We follow (Gardent,
1997) in associating nodes with feature structures
that may hold various sorts of information, including
information about the semantic interpretations pro-
jected through the nodes, constraints on the specific
operations a node may participate in, etc. A non-
terminal node represents a discourse relation holding
between its two daughter nodes. A terminal node
can be either non-empty (Figure la), corresponding
to a basic discourse unit (usually a clause), or empty.
A node is &amp;quot;empty&amp;quot; only in not having an associated
discourse unit or relation: it can still have an asso-
ciated feature structure. Empty nodes play a role
in adjoining and substitution, as explained below,
and hence in building the derived binary tree that
represents the structure of the discourse.
Adjoining adds to the discourse structure an aux-
iliary tree consisting of a root labelled with a dis-
course relation, an empty foot node (labelled *), and
at least one non-empty node (Figures lc and 1d). In
our approach, the foot node of an auxiliary tree must
be its leftmost terminal because all adjoining oper-
ations take place on a suitably defined right frontier
(i.e., the path from the root of a tree to its rightmost
leaf node) — such that all newly introduced mate-
rial lies to the right of the adjunction site. (This is
discussed in Section 3.2 in more detail.) Adjoining
corresponds to identifying a discourse relation be-
tween the new material and material in the previous
discourse that is still open for elaboration.
Figure 2(a) illustrates adjoining midway down the
RF of tree a, while Figure 2(b) illustrates adjoining
at the root of CK&apos;S RF. Figure 2(c) shows adjoining
at the &amp;quot;degenerate&amp;quot; case of a tree that consists only
of its root. Figure 2(d) will be explained shortly.
Substitution unifies the root of a substitution
structure with an empty node in the discourse tree
that serves as a substitution site. We currently
use two kinds of substitution structures: non-empty
nodes (Figure la) and elementary trees with substi-
tution sites (Figure lb). The latter are one way by
which a substitution site may be introduced into a
tree. As will be argued shortly, substitution sites can
only appear on the right of an elementary tree, al-
though any number of them may appear there (Fig-
ure lb). Figure 2(e) illustrates substitution of a non-
empty node at 1, and Figure 2(f) illustrates substitu-
tion of an elementary tree with its own substitution
site at
Since in a clause with two discourse markers (as
in Example 3b) one may look backwards (&amp;quot;for exam-
ple&amp;quot;) while the other looks forwards (&amp;quot;suppose&amp;quot;), we
also need a way of introducing expectations in the
context of adjoining. This we do by allowing an aux-
iliary tree to contain substitution sites (Figure 1d)
which, as above, can only appear on its right.&apos; An-
other term we use for auxiliary trees is adjoining
structures.
</bodyText>
<subsectionHeader confidence="0.997834">
3.2 Constraints
</subsectionHeader>
<bodyText confidence="0.99149775862069">
Earlier we noted that in a discourse structure with
no substitution sites, adjoining is limited to the right
frontier (RF). This is true of all existing TAG-based
approaches to discourse processing (Gardent, 1997;
Hinrichs and Polanyi, 1986; Polanyi and van den
Berg, 1996; Schilder, 1997; Webber, 1991), whose
structures correspond to trees that lack substitution
sites. One reason for this RF restriction is to main-
tain a strict correspondence between a left-to-right
reading of the terminal nodes of a discourse struc-
ture and the text it analyses - i.e.,
Principle of Sequentiality: A left-to-
right reading of the terminal frontier of the
tree associated with a discourse must cor-
respond to the span of text it analyses in
that same left-to-right order.
Formal proof that this principle leads to the restric-
tion of adjoining to the right frontier is given in
(Cristea and Webber, June 1997).
The Principle of Sequentiality leads to additional
constraints on where adjoining and substitution can
occur in trees with substitution sites. Consider the
tree in Figure 3(i), which has two such sites, and an
adjoining operation on the right frontier at node It,
or above. Figure 3(ii) shows that this would intro-
duce a non-empty node (uk) above and to the right
of the substitution sites. This would mean that later
substitution at either of them would lead to a viola-
tion of the Principle of Sequentiality, since the newly
</bodyText>
<footnote confidence="0.591839666666667">
2We currently have no linguistic evidence for the
structure labelled in Figure id, but are open to its
possibility.
</footnote>
<page confidence="0.99542">
91
</page>
<figure confidence="0.9979735">
A•
U ,k21)
d. Aux trees with
substitution sites
a. One-node tree
(Non-empty node)
b. Elementary trees c. Auxiliary trees
with substitution sites
</figure>
<figureCaption confidence="0.999175">
Figure 1: Grammatical Categories. (* marks the foot of an auxiliary tree, and 1, a substitution site.)
</figureCaption>
<figure confidence="0.970538947368421">
(e) Substituting a material node at
Ri Rk
Ri+2
R i+3
a
(a) Adjoining at Ri+2 on the RF of a
a
(b) Adjoining at the root (R1) of a
•
*
a
(c) Adjoining at root of single node tree a (d) Adjoining at R3 on the right frontier of
RI RI RI R1
A?\, •
u
R2 R2
1
(f) Substituting at tin elementary
tree with substitution site 2
</figure>
<figureCaption confidence="0.99479">
Figure 2: Examples of Adjoining and Substitution
</figureCaption>
<figure confidence="0.863438">
92
R.
(i) U k+1
</figure>
<figureCaption confidence="0.999872">
Figure 3: Adjoining is constrained to nodes the inner_RF, indicated by the dashed arrow.
</figureCaption>
<bodyText confidence="0.999954115384616">
substituted node uk.f., would then appear to the left
of uk in the terminal frontier, but to the right of
it in the original discourse. Adjoining at any node
above R5+2 - the left sister of the most deeply em-
bedded substitution site — leads to the same problem
(Figure 3iii). Thus in a tree with substitution sites,
adjoining must be limited to nodes on the path from
the left sister of the most embedded site to that sis-
ter&apos;s rightmost descendent. But this is just a right
frontier (RF) rooted at that left sister. Thus, ad-
joining is always limited to a RF: the presence of a
substitution site just changes what node that RF is
rooted at. We can call a RF rooted at the left sister
of the most embedded substitution site, the inner
right frontier or &amp;quot;inner_RF&amp;quot;. (In Figure 3(i), the in-
ner_RF is indicated by a dashed arrow.) In contrast,
we sometimes call the RF of a tree without substi-
tution sites, the outer right frontier or &amp;quot;outer_RF&amp;quot;
Figure 2(d) illustrates adjoining on the inner_RF of
a, a tree with a substitution site labelled 11.
Another consequence of the Principle of Sequen-
tiality is that the only node at which substitution
is allowed in a tree with substitution sites is at the
most embedded one. Any other substitution would
violate the principle. (Formal proof of these claims
are given in (Cristea and Webber, June 1997).
</bodyText>
<subsectionHeader confidence="0.998477">
3.3 Examples
</subsectionHeader>
<bodyText confidence="0.958393371428571">
Because we have not yet implemented a parser that
embodies the ideas presented so far, we give here
an idealized analysis of Examples 2 and 3, to show
how an ideal incremental monotonic algorithm that
admitted expectations would work.
Figure 4A illustrates the incremental analysis of
Example 2. Figure 4A(i) shows the elementary tree
corresponding to sentence 2a (&amp;quot;On the one hand
...&amp;quot;): the interpretation of &amp;quot;John is very generous&amp;quot;
corresponds to the left daughter labelled &amp;quot;a&amp;quot;. The
adverbial &amp;quot;On the one hand&amp;quot; is taken as signalling a
coherence relation of Contrast with something ex-
pected later in the discourse.
In sentence 2b (&amp;quot;On the other hand, suppose
...&amp;quot;), the adverbial &amp;quot;On the other hand&amp;quot; signals
the expected contrast item. Because it is al-
ready expected, the adverbial does not lead to the
creation of a separate elementary tree (but see
the next example). The imperative verb &amp;quot;sup-
pose&amp;quot;, however, signals a coherence relation of an-
tecedent/consequent (A/C) with a consequence
expected later in the discourse. The elementary
tree corresponding to &amp;quot;suppose ...&amp;quot; is shown in
Figure 4A(ii), with the interpretation of &amp;quot;you need
money&amp;quot; corresponding to the left daughter labelled
&amp;quot;b&amp;quot;. Figure 4A(iii) shows this elementary tree sub-
stituted at 1 , satisfying that expectation. Fig-
ure 4A(iv) shows the interpretation of sentence 2c
(&amp;quot;You&apos;d see he&apos;s very difficult to find&amp;quot;) substituted
at 12, satisfying that remaining expectation.
Before moving on to Example 3, notice that if Sen-
tence 2a were not explicitly cued with &amp;quot;On the other
hand&amp;quot;, the analysis would proceed somewhat differ-
ently.
Example 5
</bodyText>
<listItem confidence="0.917343">
a. John is very generous.
b. On the other hand, suppose you needed money.
c. You&apos;d see that he&apos;s very difficult to find.
</listItem>
<bodyText confidence="0.999834">
Here, the interpretation of sentence 5(a) would cor-
respond to the degenerate case of a tree consisting of
a single non-empty node shown in Figure 4B(i). The
contrast introduced by &amp;quot;On the other hand&amp;quot; in sen-
tence 5(b) leads to the auxiliary tree shown in Fig-
ure 4B(ii), where T stands for the elementary tree
corresponding to the interpretation of &amp;quot;suppose ...&amp;quot; .
</bodyText>
<page confidence="0.998185">
93
</page>
<figureCaption confidence="0.999822">
Figure 4: Analyses of Examples 2, 3 and 4.
</figureCaption>
<figure confidence="0.99941828125">
Contrast Contrast
A/C A/C
b i2
(ii) (iii) (iv)
A. Example 2
Contrast
1\j.
a T
Contrast
Evid
Contrast Contrast
--&gt;--
Evid
A/C
b c
(iv)
C. Example 3
Contrast
4/\I
a T
(i)
Contrast
b
(ii) (iii)
Contrast
A/C
Contrast
Contrast
---&gt;-
(v)
B. Example 5
A/C
</figure>
<bodyText confidence="0.999532105263158">
The entire structure associated with sentence 5(b)
is shown in Figure 4B(iii). This is adjoined to the
single node tree in Figure 4B(i), yielding the tree
shown in Figure 4B(iv). The analysis then contin-
ues exactly as in that of Example 2 above.
Moving on to Example 3, Figure 4C(i) shows the
same elementary tree as in Figure 4A(i) correspond-
ing to clause 3a. Next, Figure 4C(ii) shows the aux-
iliary tree with substitution site 12 corresponding to
clause 3b being adjoined as a sister to the interpre-
tation of clause 3a, as evidence for the claim made
there. The right daughter of the node labelled &amp;quot;Ev-
idence&amp;quot; is, as in Example 2b, an elementary tree
expecting the consequence of the supposition &amp;quot;you
need money&amp;quot;. Figure 4C(iii) shows the interpreta-
tion of clause 3c substituted at 12, satisfying that
expectation. Finally, Figure 4C(iv) shows the inter-
pretation of clause 3d substituted at 11, satisfying
the remaining expectation.
</bodyText>
<sectionHeader confidence="0.98779" genericHeader="method">
4 Sources of Uncertainty
</sectionHeader>
<bodyText confidence="0.999909833333333">
The idealized analysis presented above could lead
to a simple deterministic incremental algorithm, if
there were no uncertainty due to local or global am-
biguity. But there is. We can identify three separate
sources of uncertainty that would affect incremental
processing according to the grammar just presented:
</bodyText>
<listItem confidence="0.968794833333333">
• the identity of the discourse relation that is
meant to hold between two discourse units;
• the operation (adjoining or substitution) to be
used in adding one discourse unit onto another;
• if that operation is adjoining, the site in the
target unit at which the operation should take
</listItem>
<bodyText confidence="0.967431173913044">
place — that is, the other argument to the dis-
course relation associated with the root of the
auxiliary tree.
It may not be obvious that there could be uncer-
tainty as to whether the current discourse unit sat-
isfies an expectation and therefore substitutes into
the discourse structure, or elaborates something in
the previous discourse, and therefore adjoins into
it.&apos; But the evidence clarifying this local ambiguity
may not be available until later in the discourse. In
the following variation of Example 4, the fact that
clause (b) participates in elaborating the interpreta-
tion of clause (a) rather than in satisfying the expec-
tation it raises (which it does in Example 4) may not
be unambiguously clear until the discourse marker
&amp;quot;for example&amp;quot; in clause (c) is processed.
Example 6
a. Because John is such a generous man —
b. whenever he is asked for money,
c. he will give whatever he has, for example —
d. he deserves the &amp;quot;Citizen of the Year&amp;quot; award.
The other point is that, even if a forward-looking
cue phrase signals only a substitution structure as
</bodyText>
<footnote confidence="0.622289">
&apos;This is not the same as shift-reduce uncertainty.
</footnote>
<page confidence="0.998571">
94
</page>
<bodyText confidence="0.999609428571428">
in Figure 4A(i) and 4A(ii), if there are no pending
subsitution sites such as in 4A(i) against which to
unify such a structure, then the substitution struc-
ture must be coerced to an auxiliary tree as in Fig-
ure id (with some as yet unspecified cohesion rela-
tion) in order to adjoin it somewhere in the current
discourse structure.
</bodyText>
<sectionHeader confidence="0.989426" genericHeader="evaluation">
5 Speculations and Conclusions
</sectionHeader>
<bodyText confidence="0.999956684210526">
In this paper, we have focussed on discourse expec-
tations associated with forward-looking clausal con-
nectives, sentential adverbs and the imperative verbs
(&amp;quot;suppose&amp;quot; and &amp;quot;consider&amp;quot;). There is clearly more
to be done, including a more complete characteri-
zation of the phenomenon and development of an
incremental discourse processor based on the ideas
presented above. The latter would, we believe, have
to be coupled with incremental sentence-level pro-
cessing. As the previous examples have shown, the
same phenomenon that occurs inter-sententially in
Examples 1-3 occurs intra-sententially in Examples 4
and 6, suggesting that the two processors may be
based on identical principles. In addition, carrying
out sentence-level processing in parallel with dis-
course processing and allowing each to inform the
other would allow co-reference interpretation to fol-
low from decisions about discourse relations and vice
versa.
</bodyText>
<sectionHeader confidence="0.999123" genericHeader="conclusions">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9984814">
Support for this work has come from the De-
partment of Computer Science, Universiti Sains
Malaysia (Penang, Malaysia), the Department of
Computer Science, University &amp;quot;A.I.Cuza&amp;quot; (Iasi, Ro-
mania) and the Advanced Research Project Agency
(ARPA) under grant N6600194C6-043 and the
Army Research Organization (ARO) under grant
DAAH0494G0426. Thanks go to both the anony-
mous reviewers and the following colleagues for their
helpful comments: Michael Collins, Claire Gardent,
Udo Hahn, Joseph Rosenzweig, Donia Scott, Mark
Steedman, Matthew Stone, Michael Strube, and
Michael Zock. Thanks also to Alistair Knott and
Andrei Mikheev for giving us a rough count of cue
phrases in the Brown Corpus.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999307737704918">
Cristea, Dan and Bonnie Webber. June 1997. Ex-
pectations in incremental discourse processing.
Technical report, University A.I. Cuza, Iasi, Ro-
mania.
Gardent, Claire. 1997. Discourse tree adjoining
grammars. Claus report nr.89, University of the
Saarland, Saarbriicken.
Hinrichs, Erhard and Livia Polanyi. 1986. Pointing
the way: A unified treatment of referential ges-
ture in interactive discourse. In CLS 22, Part
2: Papers from the Parasession on Pragmatics
and Grammatical Theory, pages 298-314, Chicago
Linguistic Society.
Joshi, Aravind. 1987. An introduction to Tree Ad-
joining Grammar. In Alexis Manaster-Ramer, ed-
itor, Mathematics of Language. John Benjamins,
Amsterdam.
Knott, Alistair. 1996. A Data-driven Methodol-
ogy for Motivating a Set of Coherence Relations.
Ph.D. thesis, Department of Artificial Intelligence,
University of Edinburgh.
Mann, William and Sandra Thompson. 1988.
Rhetorical structure theory: Toward a functional
theory of text organization. Text, 8(3):243-281.
Marcu, Daniel. 1996. Building up rhetorical struc-
ture trees. In Proceedings of AAAI-96, pages
1069-1074, Portland OR.
Moore, Johanna and Martha Pollack. 1992. A prob-
lem for rst: The need for multi-level discouse anal-
ysis. Computational Linguistics, 18(4):537-544.
Moser, Megan and Johanna Moore. 1995. Inves-
tigating cue selection and placement in tutorial
discourse. In Proc. 33rd Annual Meeting, Asso-
ciation for Computational Linguistics, pages 130-
135, MIT, Boston MA.
Moser, Megan and Johanna Moore. 1996. Toward
a synthesis of two accounts of discourse structure.
Computational Linguistics, 22(2):TBA.
Polanyi, Livia and Martin H. van den Berg. 1996.
Discourse structure and discourse interpretation.
In P. Dekker and M. Stokhof, editors, Proceedings
of the Tenth Amsterdam Colloquium, pages 113-
131, ILLC/Department of Philosophy, University
of Amsterdam.
Schabes, Yves. 1990. Mathematical and Compu-
tational Aspects of Lexicalized Grammars. Ph.D.
thesis, Department of Computer and Information
Science, University of Pennsylvania. Technical
Report MS-CIS-90-48, LINC Lab 179.
Schilder, Frank. 1997. Tree discourse grammar, or
how to get attached to a discourse. In Proceedings
of the Tilburg Conference on Formal Semantics,
Tilburg, Netherlands, January.
van den Berg, Martin H. 1996. Discourse grammar
and dynamic logic. In P. Dekker and M. Stokhof,
editors, Proceedings of the Tenth Amsterdam Col-
loquium, pages 93-111, ILLC/Department of Phi-
losophy, University of Amsterdam.
Webber, Bonnie. 1991. Structure and ostension
in the interpretation of discourse deixis. Natural
Language and Cognitive Processes, 6(2):107-135.
</reference>
<page confidence="0.999064">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.865816">
<title confidence="0.999787">Expectations in Incremental Discourse Processing</title>
<author confidence="0.999685">Dan Cristea</author>
<affiliation confidence="0.989789">Faculty of Computer Science University &amp;quot;AI Cuza&amp;quot;</affiliation>
<address confidence="0.9997375">16, Berthelot Street 6600 - Iasi, Romania</address>
<email confidence="0.941549">dcristeainfoiasi.ro</email>
<author confidence="0.998704">Bonnie Webber</author>
<affiliation confidence="0.999625">Dept. of Computer &amp; Information Science University of Pennsylvania</affiliation>
<address confidence="0.973923">200 South 33rd Street Philadelphia PA 19104-6389 USA</address>
<email confidence="0.999766">bonnieOcentral.cis.upenn.edu</email>
<abstract confidence="0.999481466666667">The way in which discourse features express connections back to the previous discourse has been described in the literature terms of the frontier of discourse structure. But this does not for discourse features that express exwhat is to come in the subsequent discourse. After characterizing these expectations and their distribution in text, we show how an approach that makes of well adjoining a suitably defined right frontier, can be used to both process expectations and constrain discouse processing in general.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Cristea</author>
<author>Bonnie Webber</author>
</authors>
<title>Expectations in incremental discourse processing.</title>
<date>1997</date>
<tech>Technical report,</tech>
<location>University A.I. Cuza, Iasi, Romania.</location>
<marker>Cristea, Webber, 1997</marker>
<rawString>Cristea, Dan and Bonnie Webber. June 1997. Expectations in incremental discourse processing. Technical report, University A.I. Cuza, Iasi, Romania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
</authors>
<title>Discourse tree adjoining grammars. Claus report nr.89,</title>
<date>1997</date>
<institution>University of the Saarland, Saarbriicken.</institution>
<contexts>
<context position="6107" citStr="Gardent, 1997" startWordPosition="981" endWordPosition="982">cualr kinds of expressions may not have been noticed before is that in non-incremental approaches to discourse processing (Mann and Thompson, 1988; Marcu, 1996), they don&apos;t stand out as obviously different. The labels for discourse coherence relations used here are similar to those of RST (Mann and Thompson, 1988), but for simplicity, are treated as binary. Since any multi-branching tree can be converted to a binary tree, no representational power is lost. In doing this, we follow several recent converging computational approaches to discourse analysis, which are also couched in binary terms (Gardent, 1997; Marcu, 1996; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996). Implicit in our discussion is the view that in processing a discourse incrementally, its semantics and pragmatics are computed compositionally from the structure reflected in the coherence relations between its units. In the figures presented here, non-terminal nodes in a discourse structure are labelled with coherence relations merely to indicate the functions that project appropriate content, beliefs and other side effects into the recipient&apos;s discourse model. This view is, we believe, consistent with the mor</context>
<context position="14332" citStr="Gardent, 1997" startWordPosition="2334" endWordPosition="2336">usly, 39 instances of expectation-raising discourse units were identified (10.2%). In 11 of these cases, 1-16 discourse units intervened before the raised expectation was satisfied. One example follows: Dar deli trebuie parcurgem in intregime, pentru a orienta cercetarea este nevoie s5, inceream 1nc5, de pe acum o precizare a obiectului lui. (But although we must cover it entirely, in order to guide the research we need to try already an explanation of its subject matter.) 90 3 A Grammar for Discourse The intuitive appeal of Tree-adjoining Grammar (TAG) (Joshi, 1987) for discourse processing (Gardent, 1997; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996; Webber, 1991) follows from the fact that TAG&apos;s adjoining operation allows one to directly analyse the current discourse unit as a sister to previous discourse material that it stands in a particular relation to. The new intuition presented here — that expectations convey a dependency between the current discourse unit and future discourse material, a dependency that can be &amp;quot;stretched&amp;quot; long-distance by intervening material — more fully exploits TAG&apos;s ability to express dependencies. By expressing in an elementary TAG tree, a </context>
<context position="18383" citStr="Gardent, 1997" startWordPosition="3001" endWordPosition="3002">se markers (as in Example 3b) one may look backwards (&amp;quot;for example&amp;quot;) while the other looks forwards (&amp;quot;suppose&amp;quot;), we also need a way of introducing expectations in the context of adjoining. This we do by allowing an auxiliary tree to contain substitution sites (Figure 1d) which, as above, can only appear on its right.&apos; Another term we use for auxiliary trees is adjoining structures. 3.2 Constraints Earlier we noted that in a discourse structure with no substitution sites, adjoining is limited to the right frontier (RF). This is true of all existing TAG-based approaches to discourse processing (Gardent, 1997; Hinrichs and Polanyi, 1986; Polanyi and van den Berg, 1996; Schilder, 1997; Webber, 1991), whose structures correspond to trees that lack substitution sites. One reason for this RF restriction is to maintain a strict correspondence between a left-to-right reading of the terminal nodes of a discourse structure and the text it analyses - i.e., Principle of Sequentiality: A left-toright reading of the terminal frontier of the tree associated with a discourse must correspond to the span of text it analyses in that same left-to-right order. Formal proof that this principle leads to the restrictio</context>
</contexts>
<marker>Gardent, 1997</marker>
<rawString>Gardent, Claire. 1997. Discourse tree adjoining grammars. Claus report nr.89, University of the Saarland, Saarbriicken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard Hinrichs</author>
<author>Livia Polanyi</author>
</authors>
<title>Pointing the way: A unified treatment of referential gesture in interactive discourse.</title>
<date>1986</date>
<booktitle>In CLS 22, Part 2: Papers from the Parasession on Pragmatics and Grammatical Theory,</booktitle>
<pages>298--314</pages>
<publisher>Chicago Linguistic Society.</publisher>
<contexts>
<context position="18411" citStr="Hinrichs and Polanyi, 1986" startWordPosition="3003" endWordPosition="3006">in Example 3b) one may look backwards (&amp;quot;for example&amp;quot;) while the other looks forwards (&amp;quot;suppose&amp;quot;), we also need a way of introducing expectations in the context of adjoining. This we do by allowing an auxiliary tree to contain substitution sites (Figure 1d) which, as above, can only appear on its right.&apos; Another term we use for auxiliary trees is adjoining structures. 3.2 Constraints Earlier we noted that in a discourse structure with no substitution sites, adjoining is limited to the right frontier (RF). This is true of all existing TAG-based approaches to discourse processing (Gardent, 1997; Hinrichs and Polanyi, 1986; Polanyi and van den Berg, 1996; Schilder, 1997; Webber, 1991), whose structures correspond to trees that lack substitution sites. One reason for this RF restriction is to maintain a strict correspondence between a left-to-right reading of the terminal nodes of a discourse structure and the text it analyses - i.e., Principle of Sequentiality: A left-toright reading of the terminal frontier of the tree associated with a discourse must correspond to the span of text it analyses in that same left-to-right order. Formal proof that this principle leads to the restriction of adjoining to the right </context>
</contexts>
<marker>Hinrichs, Polanyi, 1986</marker>
<rawString>Hinrichs, Erhard and Livia Polanyi. 1986. Pointing the way: A unified treatment of referential gesture in interactive discourse. In CLS 22, Part 2: Papers from the Parasession on Pragmatics and Grammatical Theory, pages 298-314, Chicago Linguistic Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
</authors>
<title>An introduction to Tree Adjoining Grammar.</title>
<date>1987</date>
<booktitle>Mathematics of Language. John Benjamins,</booktitle>
<editor>In Alexis Manaster-Ramer, editor,</editor>
<location>Amsterdam.</location>
<contexts>
<context position="14292" citStr="Joshi, 1987" startWordPosition="2329" endWordPosition="2330">counting the constructions noted previously, 39 instances of expectation-raising discourse units were identified (10.2%). In 11 of these cases, 1-16 discourse units intervened before the raised expectation was satisfied. One example follows: Dar deli trebuie parcurgem in intregime, pentru a orienta cercetarea este nevoie s5, inceream 1nc5, de pe acum o precizare a obiectului lui. (But although we must cover it entirely, in order to guide the research we need to try already an explanation of its subject matter.) 90 3 A Grammar for Discourse The intuitive appeal of Tree-adjoining Grammar (TAG) (Joshi, 1987) for discourse processing (Gardent, 1997; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996; Webber, 1991) follows from the fact that TAG&apos;s adjoining operation allows one to directly analyse the current discourse unit as a sister to previous discourse material that it stands in a particular relation to. The new intuition presented here — that expectations convey a dependency between the current discourse unit and future discourse material, a dependency that can be &amp;quot;stretched&amp;quot; long-distance by intervening material — more fully exploits TAG&apos;s ability to express dependencies. By </context>
</contexts>
<marker>Joshi, 1987</marker>
<rawString>Joshi, Aravind. 1987. An introduction to Tree Adjoining Grammar. In Alexis Manaster-Ramer, editor, Mathematics of Language. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
</authors>
<title>A Data-driven Methodology for Motivating a Set of Coherence Relations.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Artificial Intelligence, University of Edinburgh.</institution>
<contexts>
<context position="9429" citStr="Knott, 1996" startWordPosition="1503" endWordPosition="1504">tive &amp;quot;suppose&amp;quot; and adverbial &amp;quot;on the one hand&amp;quot; — as well as a detailed analysis of the Romanian text by Vianu mentioned earlier. There are approximately 54K sentences in the Brown Corpus. Of these, 37 contain imperative &amp;quot;suppose&amp;quot; or &amp;quot;let us suppose&amp;quot;. Twelve of these correspond to &amp;quot;what if&amp;quot; questions or negotiation moves which do not raise expectations: Suppose — just suppose this guy was really what he said he was! A retired professional killer If he was just a nut, no harm was done. But if he was the real thing, he could do something about Lolly. (c123) &apos;Personal communication, but also see (Knott, 1996) 89 Alec leaned on the desk, holding the clerk&apos;s eyes with his. &amp;quot;Suppose you tell me the real reason&amp;quot;, he drawled. &amp;quot;There might be a story in it&amp;quot;. (c121) The remaining 25 sentences constitute only about 0.05% of the Brown Corpus. Of these, 22 have their expectations satisfied immediately (88%) — for example, Suppose John Jones, who, for 1960, filed on the basis of a calendar year, died June 20, 1961. His return for the period January 1 to June 20, 1961, is due April 16, 1962. One is followed by a single sentence elaborating the original supposition (also flagged by &amp;quot;suppose&amp;quot;) — &amp;quot;Suppose it was</context>
</contexts>
<marker>Knott, 1996</marker>
<rawString>Knott, Alistair. 1996. A Data-driven Methodology for Motivating a Set of Coherence Relations. Ph.D. thesis, Department of Artificial Intelligence, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
<author>Sandra Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text,</tech>
<pages>8--3</pages>
<contexts>
<context position="5640" citStr="Mann and Thompson, 1988" startWordPosition="903" endWordPosition="907">ogue actions such as clarifications or justifications may intervene, but there is a sense of an expectation being resolved when the suggestion is responded to. Here we are focussed on discourse at the level of individual monologue or turn within a larger discourse: what we show is that discourse manifests certain forward-looking patterns that have similar constraints to those of sentence-level syntax and can be handled by similar means. One possible reason that these particualr kinds of expressions may not have been noticed before is that in non-incremental approaches to discourse processing (Mann and Thompson, 1988; Marcu, 1996), they don&apos;t stand out as obviously different. The labels for discourse coherence relations used here are similar to those of RST (Mann and Thompson, 1988), but for simplicity, are treated as binary. Since any multi-branching tree can be converted to a binary tree, no representational power is lost. In doing this, we follow several recent converging computational approaches to discourse analysis, which are also couched in binary terms (Gardent, 1997; Marcu, 1996; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996). Implicit in our discussion is the view that in pr</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann, William and Sandra Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Building up rhetorical structure trees.</title>
<date>1996</date>
<booktitle>In Proceedings of AAAI-96,</booktitle>
<pages>1069--1074</pages>
<location>Portland OR.</location>
<contexts>
<context position="5654" citStr="Marcu, 1996" startWordPosition="908" endWordPosition="909">ifications or justifications may intervene, but there is a sense of an expectation being resolved when the suggestion is responded to. Here we are focussed on discourse at the level of individual monologue or turn within a larger discourse: what we show is that discourse manifests certain forward-looking patterns that have similar constraints to those of sentence-level syntax and can be handled by similar means. One possible reason that these particualr kinds of expressions may not have been noticed before is that in non-incremental approaches to discourse processing (Mann and Thompson, 1988; Marcu, 1996), they don&apos;t stand out as obviously different. The labels for discourse coherence relations used here are similar to those of RST (Mann and Thompson, 1988), but for simplicity, are treated as binary. Since any multi-branching tree can be converted to a binary tree, no representational power is lost. In doing this, we follow several recent converging computational approaches to discourse analysis, which are also couched in binary terms (Gardent, 1997; Marcu, 1996; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996). Implicit in our discussion is the view that in processing a dis</context>
</contexts>
<marker>Marcu, 1996</marker>
<rawString>Marcu, Daniel. 1996. Building up rhetorical structure trees. In Proceedings of AAAI-96, pages 1069-1074, Portland OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanna Moore</author>
<author>Martha Pollack</author>
</authors>
<title>A problem for rst: The need for multi-level discouse analysis.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--4</pages>
<contexts>
<context position="6973" citStr="Moore and Pollack, 1992" startWordPosition="1107" endWordPosition="1110">re reflected in the coherence relations between its units. In the figures presented here, non-terminal nodes in a discourse structure are labelled with coherence relations merely to indicate the functions that project appropriate content, beliefs and other side effects into the recipient&apos;s discourse model. This view is, we believe, consistent with the more detailed formal interfaces to discourse semantics/pragmatics presented in (Gardent, 1997; Schilder, 1997; van den Berg, 1996), and also allows for multiple discourse relations (intentional and informational) to hold between discourse units (Moore and Pollack, 1992; Moser and Moore, 1995; Moser and Moore, 1996) and contribute to the semantic/pragmatics effects on the recipient&apos;s discourse model. 2 Expectations in Corpora The examples given in the Introduction were all &amp;quot;minimal pairs&amp;quot; created to illustrate the relevant phenomenon as succinctly as possible. Empirical questions thus include: (1) the range of lexicosyntactic constructions that raise expectations with the specific properties mentioned above; (2) the frequency of expectation-raising constructions in text; (3) the frequency with which expectations are satisfied immediately, as opposed to being</context>
</contexts>
<marker>Moore, Pollack, 1992</marker>
<rawString>Moore, Johanna and Martha Pollack. 1992. A problem for rst: The need for multi-level discouse analysis. Computational Linguistics, 18(4):537-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megan Moser</author>
<author>Johanna Moore</author>
</authors>
<title>Investigating cue selection and placement in tutorial discourse.</title>
<date>1995</date>
<booktitle>In Proc. 33rd Annual Meeting, Association for Computational Linguistics,</booktitle>
<pages>130--135</pages>
<location>MIT, Boston MA.</location>
<contexts>
<context position="6996" citStr="Moser and Moore, 1995" startWordPosition="1111" endWordPosition="1114">ence relations between its units. In the figures presented here, non-terminal nodes in a discourse structure are labelled with coherence relations merely to indicate the functions that project appropriate content, beliefs and other side effects into the recipient&apos;s discourse model. This view is, we believe, consistent with the more detailed formal interfaces to discourse semantics/pragmatics presented in (Gardent, 1997; Schilder, 1997; van den Berg, 1996), and also allows for multiple discourse relations (intentional and informational) to hold between discourse units (Moore and Pollack, 1992; Moser and Moore, 1995; Moser and Moore, 1996) and contribute to the semantic/pragmatics effects on the recipient&apos;s discourse model. 2 Expectations in Corpora The examples given in the Introduction were all &amp;quot;minimal pairs&amp;quot; created to illustrate the relevant phenomenon as succinctly as possible. Empirical questions thus include: (1) the range of lexicosyntactic constructions that raise expectations with the specific properties mentioned above; (2) the frequency of expectation-raising constructions in text; (3) the frequency with which expectations are satisfied immediately, as opposed to being delayed by material th</context>
</contexts>
<marker>Moser, Moore, 1995</marker>
<rawString>Moser, Megan and Johanna Moore. 1995. Investigating cue selection and placement in tutorial discourse. In Proc. 33rd Annual Meeting, Association for Computational Linguistics, pages 130-135, MIT, Boston MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megan Moser</author>
<author>Johanna Moore</author>
</authors>
<title>Toward a synthesis of two accounts of discourse structure.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="7020" citStr="Moser and Moore, 1996" startWordPosition="1115" endWordPosition="1118">its units. In the figures presented here, non-terminal nodes in a discourse structure are labelled with coherence relations merely to indicate the functions that project appropriate content, beliefs and other side effects into the recipient&apos;s discourse model. This view is, we believe, consistent with the more detailed formal interfaces to discourse semantics/pragmatics presented in (Gardent, 1997; Schilder, 1997; van den Berg, 1996), and also allows for multiple discourse relations (intentional and informational) to hold between discourse units (Moore and Pollack, 1992; Moser and Moore, 1995; Moser and Moore, 1996) and contribute to the semantic/pragmatics effects on the recipient&apos;s discourse model. 2 Expectations in Corpora The examples given in the Introduction were all &amp;quot;minimal pairs&amp;quot; created to illustrate the relevant phenomenon as succinctly as possible. Empirical questions thus include: (1) the range of lexicosyntactic constructions that raise expectations with the specific properties mentioned above; (2) the frequency of expectation-raising constructions in text; (3) the frequency with which expectations are satisfied immediately, as opposed to being delayed by material that elaborates the unit r</context>
</contexts>
<marker>Moser, Moore, 1996</marker>
<rawString>Moser, Megan and Johanna Moore. 1996. Toward a synthesis of two accounts of discourse structure. Computational Linguistics, 22(2):TBA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Martin H van den Berg</author>
</authors>
<title>Discourse structure and discourse interpretation.</title>
<date>1996</date>
<booktitle>Proceedings of the Tenth Amsterdam Colloquium,</booktitle>
<pages>113--131</pages>
<editor>In P. Dekker and M. Stokhof, editors,</editor>
<institution>ILLC/Department of Philosophy, University of Amsterdam.</institution>
<marker>Polanyi, van den Berg, 1996</marker>
<rawString>Polanyi, Livia and Martin H. van den Berg. 1996. Discourse structure and discourse interpretation. In P. Dekker and M. Stokhof, editors, Proceedings of the Tenth Amsterdam Colloquium, pages 113-131, ILLC/Department of Philosophy, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Mathematical and Computational Aspects of Lexicalized Grammars.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="1606" citStr="Schabes, 1990" startWordPosition="236" endWordPosition="237">guishable but interlinked processes. These include reference and ellipsis resolution, inference (e.g., inferential processes associated with focus particles such as, in English, &amp;quot;even&amp;quot; and &amp;quot;only&amp;quot;), and identification of those structures underlying a discourse that are associated with coherence relations between its units. In the course of developing an incremental approach to the latter, we noticed a variety of constructions in discourse that raise expectations about its future structural features. We found that we could represent such expectations by adopting a lexical variant of TAG — LTAG (Schabes, 1990) — and using its substitution operation as a complement to adjoining. Perhaps more interesting was that these expectations appeared to constrain the subsequent discourse until they were resolved. This we found we could model in terms of constraints on adjoining and substitution with respect to a suitably defined Right Frontier. This short paper focuesses on the phenomenon of these expectations in discourse and their expression in a discourse-level LTAG. We conclude the paper with some thoughts on incremental discourse processing in light of these expectations. The following examples illustrate</context>
<context position="15045" citStr="Schabes, 1990" startWordPosition="2446" endWordPosition="2447">e fact that TAG&apos;s adjoining operation allows one to directly analyse the current discourse unit as a sister to previous discourse material that it stands in a particular relation to. The new intuition presented here — that expectations convey a dependency between the current discourse unit and future discourse material, a dependency that can be &amp;quot;stretched&amp;quot; long-distance by intervening material — more fully exploits TAG&apos;s ability to express dependencies. By expressing in an elementary TAG tree, a dependency betwen the current discourse unit and future discourse material and using substitution (Schabes, 1990) when the expected material is found, our TAG-based approach to discourse processing allows expectations to be both raised and resolved. 3.1 Categories and Operations The categories of our TAG-based approach consist of nodes and binary trees. We follow (Gardent, 1997) in associating nodes with feature structures that may hold various sorts of information, including information about the semantic interpretations projected through the nodes, constraints on the specific operations a node may participate in, etc. A nonterminal node represents a discourse relation holding between its two daughter n</context>
</contexts>
<marker>Schabes, 1990</marker>
<rawString>Schabes, Yves. 1990. Mathematical and Computational Aspects of Lexicalized Grammars. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania. Technical Report MS-CIS-90-48, LINC Lab 179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Schilder</author>
</authors>
<title>Tree discourse grammar, or how to get attached to a discourse.</title>
<date>1997</date>
<booktitle>In Proceedings of the Tilburg Conference on Formal Semantics,</booktitle>
<location>Tilburg, Netherlands,</location>
<contexts>
<context position="6168" citStr="Schilder, 1997" startWordPosition="991" endWordPosition="992">is that in non-incremental approaches to discourse processing (Mann and Thompson, 1988; Marcu, 1996), they don&apos;t stand out as obviously different. The labels for discourse coherence relations used here are similar to those of RST (Mann and Thompson, 1988), but for simplicity, are treated as binary. Since any multi-branching tree can be converted to a binary tree, no representational power is lost. In doing this, we follow several recent converging computational approaches to discourse analysis, which are also couched in binary terms (Gardent, 1997; Marcu, 1996; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996). Implicit in our discussion is the view that in processing a discourse incrementally, its semantics and pragmatics are computed compositionally from the structure reflected in the coherence relations between its units. In the figures presented here, non-terminal nodes in a discourse structure are labelled with coherence relations merely to indicate the functions that project appropriate content, beliefs and other side effects into the recipient&apos;s discourse model. This view is, we believe, consistent with the more detailed formal interfaces to discourse semantics/pragmatic</context>
<context position="14380" citStr="Schilder, 1997" startWordPosition="2343" endWordPosition="2344">urse units were identified (10.2%). In 11 of these cases, 1-16 discourse units intervened before the raised expectation was satisfied. One example follows: Dar deli trebuie parcurgem in intregime, pentru a orienta cercetarea este nevoie s5, inceream 1nc5, de pe acum o precizare a obiectului lui. (But although we must cover it entirely, in order to guide the research we need to try already an explanation of its subject matter.) 90 3 A Grammar for Discourse The intuitive appeal of Tree-adjoining Grammar (TAG) (Joshi, 1987) for discourse processing (Gardent, 1997; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996; Webber, 1991) follows from the fact that TAG&apos;s adjoining operation allows one to directly analyse the current discourse unit as a sister to previous discourse material that it stands in a particular relation to. The new intuition presented here — that expectations convey a dependency between the current discourse unit and future discourse material, a dependency that can be &amp;quot;stretched&amp;quot; long-distance by intervening material — more fully exploits TAG&apos;s ability to express dependencies. By expressing in an elementary TAG tree, a dependency betwen the current discourse unit and</context>
<context position="18459" citStr="Schilder, 1997" startWordPosition="3013" endWordPosition="3014">the other looks forwards (&amp;quot;suppose&amp;quot;), we also need a way of introducing expectations in the context of adjoining. This we do by allowing an auxiliary tree to contain substitution sites (Figure 1d) which, as above, can only appear on its right.&apos; Another term we use for auxiliary trees is adjoining structures. 3.2 Constraints Earlier we noted that in a discourse structure with no substitution sites, adjoining is limited to the right frontier (RF). This is true of all existing TAG-based approaches to discourse processing (Gardent, 1997; Hinrichs and Polanyi, 1986; Polanyi and van den Berg, 1996; Schilder, 1997; Webber, 1991), whose structures correspond to trees that lack substitution sites. One reason for this RF restriction is to maintain a strict correspondence between a left-to-right reading of the terminal nodes of a discourse structure and the text it analyses - i.e., Principle of Sequentiality: A left-toright reading of the terminal frontier of the tree associated with a discourse must correspond to the span of text it analyses in that same left-to-right order. Formal proof that this principle leads to the restriction of adjoining to the right frontier is given in (Cristea and Webber, June 1</context>
</contexts>
<marker>Schilder, 1997</marker>
<rawString>Schilder, Frank. 1997. Tree discourse grammar, or how to get attached to a discourse. In Proceedings of the Tilburg Conference on Formal Semantics, Tilburg, Netherlands, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin H van den Berg</author>
</authors>
<title>Discourse grammar and dynamic logic.</title>
<date>1996</date>
<booktitle>Proceedings of the Tenth Amsterdam Colloquium,</booktitle>
<pages>93--111</pages>
<editor>In P. Dekker and M. Stokhof, editors,</editor>
<institution>ILLC/Department of Philosophy, University of Amsterdam.</institution>
<marker>van den Berg, 1996</marker>
<rawString>van den Berg, Martin H. 1996. Discourse grammar and dynamic logic. In P. Dekker and M. Stokhof, editors, Proceedings of the Tenth Amsterdam Colloquium, pages 93-111, ILLC/Department of Philosophy, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
</authors>
<title>Structure and ostension in the interpretation of discourse deixis.</title>
<date>1991</date>
<booktitle>Natural Language and Cognitive Processes,</booktitle>
<pages>6--2</pages>
<contexts>
<context position="14415" citStr="Webber, 1991" startWordPosition="2349" endWordPosition="2350">In 11 of these cases, 1-16 discourse units intervened before the raised expectation was satisfied. One example follows: Dar deli trebuie parcurgem in intregime, pentru a orienta cercetarea este nevoie s5, inceream 1nc5, de pe acum o precizare a obiectului lui. (But although we must cover it entirely, in order to guide the research we need to try already an explanation of its subject matter.) 90 3 A Grammar for Discourse The intuitive appeal of Tree-adjoining Grammar (TAG) (Joshi, 1987) for discourse processing (Gardent, 1997; Polanyi and van den Berg, 1996; Schilder, 1997; van den Berg, 1996; Webber, 1991) follows from the fact that TAG&apos;s adjoining operation allows one to directly analyse the current discourse unit as a sister to previous discourse material that it stands in a particular relation to. The new intuition presented here — that expectations convey a dependency between the current discourse unit and future discourse material, a dependency that can be &amp;quot;stretched&amp;quot; long-distance by intervening material — more fully exploits TAG&apos;s ability to express dependencies. By expressing in an elementary TAG tree, a dependency betwen the current discourse unit and future discourse material and usin</context>
<context position="18474" citStr="Webber, 1991" startWordPosition="3015" endWordPosition="3016">forwards (&amp;quot;suppose&amp;quot;), we also need a way of introducing expectations in the context of adjoining. This we do by allowing an auxiliary tree to contain substitution sites (Figure 1d) which, as above, can only appear on its right.&apos; Another term we use for auxiliary trees is adjoining structures. 3.2 Constraints Earlier we noted that in a discourse structure with no substitution sites, adjoining is limited to the right frontier (RF). This is true of all existing TAG-based approaches to discourse processing (Gardent, 1997; Hinrichs and Polanyi, 1986; Polanyi and van den Berg, 1996; Schilder, 1997; Webber, 1991), whose structures correspond to trees that lack substitution sites. One reason for this RF restriction is to maintain a strict correspondence between a left-to-right reading of the terminal nodes of a discourse structure and the text it analyses - i.e., Principle of Sequentiality: A left-toright reading of the terminal frontier of the tree associated with a discourse must correspond to the span of text it analyses in that same left-to-right order. Formal proof that this principle leads to the restriction of adjoining to the right frontier is given in (Cristea and Webber, June 1997). The Princ</context>
</contexts>
<marker>Webber, 1991</marker>
<rawString>Webber, Bonnie. 1991. Structure and ostension in the interpretation of discourse deixis. Natural Language and Cognitive Processes, 6(2):107-135.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>