<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002482">
<title confidence="0.993584">
Confidence-based Adaptivity in Response Generation
for a Spoken Dialogue System
</title>
<author confidence="0.998475">
Kristiina Jokinen Graham Wilcock
</author>
<affiliation confidence="0.998201">
University of Art and Design Helsinki University of Helsinki
</affiliation>
<address confidence="0.90018">
00560 Helsinki, Finland 00014 Helsinki, Finland
</address>
<email confidence="0.996677">
kjokinen@uiah.fi Graham.Wilcock@helsinki.fi
</email>
<sectionHeader confidence="0.979807" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992117647059">
The paper addresses the issue of how to increase
adaptivity in response generation for a spoken
dialogue system. Realization strategies for dia-
logue responses depend on communicative confi-
dence levels and interaction management goals.
We first describe a Java/XML-based generator
which produces different realizations of system
responses based on agendas specified by the di-
alogue manager. We then discuss how greater
adaptivity can be achieved by using a set of dis-
tinct generator agents, each of which is special-
ized in its realization strategy (e.g. highly ellip-
tical or highly explicit). This allows a simpler
design of each generator agent, while increas-
ing the overall system adaptivity to meet the
requirements for flexible cooperation in incre-
mental and immediate interactive situations.
</bodyText>
<sectionHeader confidence="0.996304" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943057142858">
When describing the desired characteristics of
human-computer interaction, the common key-
words are cooperation and naturalness. Coop-
eration is used to refer to the participants&apos; abil-
ity to collaborate with each other on a given
task and to provide informative and helpful con-
tributions in a given task context. Naturalness,
however, describes the participants&apos; reaction
which is appropriate in the current communica-
tive context, and usually presupposes reasoning
through which the participants can adapt them-
selves to the requirements of the situation and
to the knowledge level of their partner.
Naturalness in spoken interaction can be
characterised by features such as incrementality
and immediacy (Jokinen et al., 1998). Speak-
ers exchange information and present the new
information in a stepwise manner, constructing
a common ground by providing new pieces of
relevant information to complete the task that
the interaction was initiated for. They mon-
itor their own presentations and react to the
partner&apos;s contributions immediately, often si-
multaneously, to prevent potential misunder-
standings growing and causing problems to the
interaction. Spoken dialogue systems that aim
at natural interaction with the user should thus
have capabilities for incremental and immedi-
ate management of interaction. In other words,
they should be able to produce responses that
take into account the requirements of an incre-
mental and immediate interactive situation. In
this paper we discuss how various types of sys-
tem responses can be generated taking into ac-
count the special requirements of incremental
and immediate interaction situations.
The paper is structured as follows. In Sec-
tion 2 we discuss concrete examples from a spo-
ken dialogue system, in which different forms
of surface realization are required in order to
achieve interaction management goals. This
may involve, for example, deliberate repetition
of old information to get implicit confirmation
of speech recognition accuracy. When there is
a high level of confidence in the effectiveness of
the communication channel, however, the pre-
ferred form of response realization is to include
only the new information in the response.
Section 3 describes an implementation of dia-
logue response generation based on Java, XML
and XSL transformations. The implementation
can generate the different realizations discussed
in Section 2. The way in which the genera-
tor chooses between the different realizations
is based on detailed specifications of the infor-
mation status of different concepts, given in an
agenda by the dialogue manager component.
In Section 4 we then discuss an alternative
approach to the choice of realization, in which
a set of distinct generation agents are used, each
agent being specialized in its realization strat-
egy (e.g. highly elliptical or highly explicit).
The design of the individual generation agents
is therefore simpler, but the system as a whole
increases in adaptivity by choosing which agent
to use according to the wider dialogue context.
We describe a Java and XML-based framework
which supports this architecture, and discuss a
strategy for adaptivity based on communicative
confidence.
</bodyText>
<sectionHeader confidence="0.982665" genericHeader="method">
2 Interaction Management
</sectionHeader>
<bodyText confidence="0.998735333333333">
In this section we discuss concrete examples
from a spoken dialogue system. The domain
is public transportation in Helsinki.
</bodyText>
<subsectionHeader confidence="0.987344">
2.1 Agenda, NewInfo and Topic
</subsectionHeader>
<bodyText confidence="0.998785942857143">
To enable incremental presentation and imme-
diate reaction, Jokinen et al. (1998) structure
the context with the help of NewInfo and Topic,
so that the generator can distinguish the new in-
formation that is meant to be put across in the
current dialogue situation, and the background
information that the new information is linked
to. The pool of contextual information includes
an agenda, a set of concepts marked with the
help of &apos;topic&apos; and &apos;newinfo&apos; tags, the tags be-
ing determined by the dialogue manager which
decides how the system is to react next.
The generator can freely use the tagged pieces
of information in order to realise the system&apos;s
intention as a surface string, but it is not forced
to include in the response all the concepts that
the dialogue manager has designated as rele-
vant in the agenda. Thus the dialogue manager
and the generator communicate via the specif-
ically marked conceptual items in the shared
knowledge-base, but they both make their own
decisions on the basis of their own reasoning and
task management. The dialogue manager need
not know about particular rules of surface real-
isation while the generator need not know how
to decide the information status of the concepts
in the current dialogue situation.
While the notions of NewInfo and Topic are
often used to illustrate the characteristics of
word-order variation, their importance in spo-
ken dialogue systems can be mostly shown in
the planning process that lies at the border
of dialogue processing and tactical generation.
Consider first the following questions by the
user:
</bodyText>
<listItem confidence="0.9973475">
(1) Which bus goes to Malmi?
(2) How do I get to Malmi?
</listItem>
<bodyText confidence="0.998131230769231">
The dialogue manager has analysed them as
timetable requests related to the user&apos;s going to
Malmi. It has also recognized that NewInfo in
(1) is the information concerning bus numbers
while NewInfo in (2) concerns means of trans-
portation.
In the case of (1), the information that the
dialogue manager gets from the task manager
which consults the timetable database, is that
there is bus 74 that goes to Malmi. The dialogue
manager decides to put the following concepts
into the agenda in the shared knowledge pool
(using XML as discussed in Section 3):
</bodyText>
<figure confidence="0.994663944444444">
&lt;agenda&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;means-of-transportation&lt;/type&gt;
&lt;value&gt;bus&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;destination&lt;/type&gt;
&lt;value&gt;malmi&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;bus&lt;/type&gt;
&lt;value&gt;exists&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;busnumber&lt;/type&gt;
&lt;value&gt;74&lt;/value&gt;
&lt;/concept&gt;
&lt;/agenda&gt;
</figure>
<bodyText confidence="0.999892545454545">
The dialogue manager also tags the concepts
as NewInfo or Topic, reflecting its knowledge of
how the concepts relate to the current dialogue
situation. The concept &apos;busnumber&apos; is tagged
as NewInfo, and the other three as Topic, since
this is a match with the new information asked
in the previous utterance, and the user will be
likely to link the response correctly.
The generator can then select the concepts
and decide the surface realisation as described
in Section 4. The simplest realisation is:
</bodyText>
<listItem confidence="0.670623">
(1a) Number 74.
</listItem>
<subsectionHeader confidence="0.978034">
2.2 Indirect Requests
</subsectionHeader>
<bodyText confidence="0.9903679">
For example (2), however, the situation is some-
what more complicated since the user question
can be understood either as a literal question
about public transportation to Malmi, or as an
indirect request for buses that go to Malmi. In-
formation about the previous dialogue situation
must thus be used, and we relate the difference
to the Topic of the conversation: in the &apos;literal&apos;
case, the Topic is Malmi, the destination where
the speaker wants to find out transportation
for, whereas in the indirect request, the Topic is
the bus as a means of transportation to Malmi.
Consequently, in the &apos;literal&apos; case, the dialogue
manager consults the task manager by request-
ing a value for the concept &apos;means of trans-
portation&apos;, while in the indirect request, the di-
alogue manager requests task manager to give
a value for the busnumber. In both cases, how-
ever, the information that the dialogue man-
ager gets from the task manager is the same:
that there exists a means of transportation to
Malmi, namely a bus and the busnumber is 74.1
When deciding on the response to the &apos;lit-
eral&apos; case, the dialogue manager regards the
means of transportation as NewInfo and the
destination to Malmi as Topic, continuing the
information structure of the previous question.
The two other concepts, &apos;bus&apos; and &apos;busnumber&apos;,
are also tagged as new but since the NewInfo
that matches the dialogue situation concerns
the public transportation to Malmi, the piece of
information of the bus number is extra informa-
tion that can be seen as a sign of cooperation on
the system&apos;s side, rather than a necessary new
information to be told to the user, i.e. they
can be added in the response if the time con-
straints allow this and the level of cooperation
so requests.
The agenda in the shared knowledge pool in
case (2a) is as follows:
</bodyText>
<figure confidence="0.729414833333333">
&lt;agenda&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;means-of-transportation&lt;/type&gt;
&lt;value&gt;bus&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
</figure>
<footnote confidence="0.738731">
&apos;The dialogue manager and task manager commu-
nicate with each other via a particular task-form which
has as its parameters the concepts important for the task
manager to fetch information from the database. If the
form is filled in so that a database query can be per-
formed, the task manager returns the form with all the
appropriate parameters filled in, and thus lets the dia-
logue manager decide on the status of the parameters
and their values with respect to the dialogue situation.
</footnote>
<figure confidence="0.995580666666667">
&lt;type&gt;destination&lt;/type&gt;
&lt;value&gt;malmi&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;bus&lt;/type&gt;
&lt;value&gt;exists&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;busnumber&lt;/type&gt;
&lt;value&gt;74&lt;/value&gt;
&lt;/concept&gt;
&lt;/agenda&gt;
</figure>
<bodyText confidence="0.999631125">
In the case of an indirect request, the dia-
logue manager again relies on the dialogue con-
text when tagging the concepts for the agenda.
The Topic is the means of transportation to
Malmi, whereas the NewInfo concerns the bus-
number, and so only the &apos;bus&apos; and &apos;busnumber&apos;
are tagged as new. For (2b), the shared knowl-
edge is thus as follows:
</bodyText>
<figure confidence="0.995384222222222">
&lt;agenda&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;means-of-transportation&lt;/type&gt;
&lt;value&gt;bus&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;destination&lt;/type&gt;
&lt;value&gt;malmi&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;bus&lt;/type&gt;
&lt;value&gt;exists&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;busnumber&lt;/type&gt;
&lt;value&gt;74&lt;/value&gt;
&lt;/concept&gt;
&lt;/agenda&gt;
</figure>
<bodyText confidence="0.9983925">
The difference in the system responses is re-
flected in the alternatives (2a) and (2b):
</bodyText>
<listItem confidence="0.9212705">
(2a) By bus - number 74.
(2b) Bus 74 goes there.
</listItem>
<subsectionHeader confidence="0.997654">
2.3 Confidence Levels
</subsectionHeader>
<bodyText confidence="0.999926857142857">
The next example is related to a different as-
pect of spoken dialogue systems: confidence in
speech recognition results. The dialogue man-
ager gets the recognized words together with
their recognition scores, and decides on the ap-
propriate action depending on the confidence
levels.
</bodyText>
<listItem confidence="0.9830026">
(3) When will the next bus leave for Malmi?
(a) 2.20pm
(b) It will leave at 2.20pm
(c) The next bus to Malmi leaves at
2.20pm
</listItem>
<bodyText confidence="0.999446666666666">
As is common, we assume that if recognition
is above a certain confidence level, the system
will use the simplest and most straightforward
answer, while if the recognition error becomes
bigger, a confirmation strategy has to be used.
Thus response (3a) is used when the system has
confidence that the user has indeed asked about
new information concerning the next bus leav-
ing for Malmi (cf. 1a). Response (3b) is also
used in the similar situation where the system is
confident about its recognition, but the dialogue
situation differs from the one in (3a) in that
now the system assumes that the user expects a
polite full response, instead of an elliptical an-
swer as in (3a) where the user has talked about
the buses to Malmi and just wants to check the
next one leaving. The alternative (3c) is used
when the system explicitly wants to confirm the
Topic (= next bus to Malmi), so as not to allow
user to draw false implicatures about which bus
timetable the answer concerns.
The agendas for the alternatives (3a) and (3b)
are similar, and the difference in the surface re-
alizations is due to the different interaction his-
tory: in the former case the Topic continues and
the dialogue history contains the concepts des-
tination and bus as previous Topics, whereas in
the latter case, the previous Topics may be dif-
ferent concepts or there may me no previous
Topic at all (beginning of the dialogue).
</bodyText>
<figure confidence="0.991249263157895">
(3a,b)
&lt;agenda&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;means-of-transportation&lt;/type&gt;
&lt;value&gt;bus&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;destination&lt;/type&gt;
&lt;value&gt;malmi&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;bus&lt;/type&gt;
&lt;value&gt;exists&lt;/value&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;bustime&lt;/type&gt;
&lt;value&gt;2.20pm&lt;/value&gt;
&lt;/concept&gt;
&lt;/agenda&gt;
</figure>
<bodyText confidence="0.998905545454545">
Also the agenda for the alternative (3c) looks
the same, except for the feature &lt;confidence&gt;
which characterizes the system&apos;s own evaluation
of how confident it is of the correctness of the
recognized concepts. The value 1 marks cer-
tainty as in the case of bustime whose value is
retrieved from the database. This feature has
been left out in the other representations for
the sake of clarity: if the confidence is above
the threshold, the concept is treated according
to its information status in the shared pool.
</bodyText>
<figure confidence="0.988301956521739">
(3c)
&lt;agenda&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;means-of-transportation&lt;/type&gt;
&lt;value&gt;bus&lt;/value&gt;
&lt;confidence&gt;0.6&lt;/confidence&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;destination&lt;/type&gt;
&lt;value&gt;malmi&lt;/value&gt;
&lt;confidence&gt;0.2&lt;/confidence&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;Topic&amp;quot;&gt;
&lt;type&gt;bus&lt;/type&gt;
&lt;value&gt;exists&lt;/value&gt;
&lt;confidence&gt;0.6&lt;/confidence&gt;
&lt;/concept&gt;
&lt;concept info=&amp;quot;NewInfo&amp;quot;&gt;
&lt;type&gt;bustime&lt;/type&gt;
&lt;value&gt;2.20pm&lt;/value&gt;
&lt;confidence&gt;1.0&lt;/confidence&gt;
&lt;/concept&gt;
&lt;/agenda&gt;
</figure>
<sectionHeader confidence="0.822427" genericHeader="method">
3 Dialogue Response Generation
</sectionHeader>
<bodyText confidence="0.999982033333333">
The system&apos;s competence in dialogue manage-
ment is shown in the two tasks that the sys-
tem must perform: evaluating the user goal,
and response generation. The former results
in strategic decision about operationally appro-
priate goals, while the latter concerns how the
same goal can be realised in different ways in
different contexts.
We now describe the framework which per-
forms the dialogue response generation. The
content determination has been done by the di-
alogue manager, which has selected the relevant
concepts to put on the agenda. The discourse
planning is based closely on the specification of
Topic and NewInfo by the dialogue manager,
but also includes specific decisions by the gener-
ator described in Section 3.2. The response gen-
eration continues with an aggregation stage, de-
scribed in Section 3.3, followed by a stage which
combines lexicalization and generation of refer-
ring expressions, described in Section 3.4. Mor-
phological generation, which is very important
for one of the languages generated (Finnish), is
done in a separate stage.
The framework is based on Java, XML and
XSL transformations. The implemented system
can generate the responses which we have dis-
cussed. In the next section, we will describe an
extension to this framework, suitable for adap-
tive and flexible response generation.
</bodyText>
<subsectionHeader confidence="0.990379">
3.1 A Pipeline Architecture
</subsectionHeader>
<bodyText confidence="0.999981974358975">
The generator starts from an agenda of con-
cepts specified in XML, set up by the dialogue
manager as shown in the examples in Section 2.
The generator produces linguistic output which
is also specified in XML, to be passed to the
speech synthesizer. We are therefore generating
XML from XML. The simplest way to do this
is to apply a set of XML transformations spec-
ified in XSL (XML Stylesheet Language). We
do this using the Xalan XSL Processor (Apache
XML Project, 2001) which is open-source soft-
ware written entirely in Java.
With the Xalan XSL Processor it is easy to
set up a sequence of transformations, in which
the output of one transformation becomes the
input to the next transformation. This kind of
&amp;quot;piping&amp;quot; is a natural way to implement the stan-
dard pipeline architecture regularly used in nat-
ural language generation systems (Reiter and
Dale, 2000).
The ease of setting up a pipeline architecture
with XSL raises the general question of whether
XSL transformations are suitable for wider use
in NLG systems. This is discussed by Cawsey
(2000), who concludes that relatively simple
XSL transformations can be used for generation
when the input is fairly constrained, but XSL is
not suitable for less constrained input, when we
need to turn to general purpose programming
languages or NLG tools.
However, XSL can be combined with gen-
eral purpose programming languages by embed-
ding extension functions in the XSL templates.
These functions can be written in Java (Apache
XML Project, 2001). This means that even
where general purpose programming languages
are required for specific purposes, such as com-
plex morphology, a pipeline of XSL transforma-
tions can still be used as a general framework.
</bodyText>
<subsectionHeader confidence="0.98154">
3.2 Focus-based Generation
</subsectionHeader>
<bodyText confidence="0.999971912280702">
The model of dialogue response generation
which we use is based on generation from the
new information focus, as proposed by Jokinen
et al. (1998). In this model, response planning
starts from the new information focus, called
NewInfo. One of the tasks of the generator is
to decide how to present the NewInfo to the
user: whether it should be presented by itself
or whether it should be wrapped in appropriate
linking information.
The wrapping of the NewInfo depends on
the pragmatic requirements of the dynamic dia-
logue context. When the context permits a flu-
ent exchange of contributions, wrapping will be
avoided and the response will be based on new
information only. When the context requires
more clarity and explicitness, the new informa-
tion will be wrapped by Topic information in
order to avoid ambiguity and misunderstand-
ing. When the communication channel is work-
ing well, wrapping will be reduced, and when
there are uncertainties about what was actually
said, wrapping will be increased to provide im-
plicit confirmation.
Typically, XSL transformations are used
to convert information content represented in
XML into a desired presentation format, for ex-
ample in HTML. There is usually no need for
complex re-ordering of the content. Here how-
ever, the generator must convert the unordered
bag of concepts in the agenda into a syntacti-
cally correct ordered sequence of words to be
passed to the speech synthesizer. Also, the new
information focus tends to come last in surface
order, so the linking information (if any) will
generally precede the new information in the
surface realization.
Simple reordering can be performed in XSL,
for example by using XSL modes. We have ex-
perimented with applying XSL templates first
with a Topic mode (if required), followed by a
NewInfo mode. The usefulness of XSL modes
for such purposes is noted by Cawsey (2000).
However, as we must also handle detailed syn-
tactic ordering, we use aggregation templates as
described in Section 3.3.
If the real-time requirements of the system al-
low sufficient time, the generator can decide on
the optimum way to wrap the new information,
but if there is extreme urgency to produce a re-
sponse, the generator can simply give the new
information without wrapping it. If this leads
to misunderstanding, the system can attempt
to repair this in subsequent turns. In this sense,
the model offers an any-time algorithm, impor-
tant for providing incremental and immediate
responses for spoken interactive situations.
</bodyText>
<subsectionHeader confidence="0.993689">
3.3 Aggregation
</subsectionHeader>
<bodyText confidence="0.998631454545454">
The aggregation stage selects those concepts
marked as NewInfo as the basis for generation,
and also decides whether NewInfo will be the
only output, or whether it will be preceded by
the Topic linking concepts.
In order to implement detailed syntactic or-
dering, we use aggregation templates as a form
of sentence plan specification. The aggregation
templates are implemented by means of XSL
named templates, as in the following simplified
example:
</bodyText>
<figure confidence="0.965147">
&lt;xsl:template name=&amp;quot;NUM-DEST-TIME&amp;quot;&gt;
&lt;aggregation&gt;
&lt;tree&gt;&lt;node&gt;S&lt;/node&gt;
&lt;tree&gt;&lt;node&gt;NP&lt;/node&gt;
&lt;xsl:copy-of select=&amp;quot;.
/concept[type=&apos;busnumber&apos;]&amp;quot;/&gt;
&lt;/tree&gt;
&lt;tree&gt;&lt;node&gt;V&lt;/node&gt;
&lt;xsl:copy-of select=&amp;quot;.
/concept[type=&apos;bus&apos;]&amp;quot;/&gt;
&lt;/tree&gt;
&lt;tree&gt;&lt;node&gt;PP&lt;/node&gt;
&lt;xsl:copy-of select=&amp;quot;.
/concept[type=&apos;destination&apos;]&amp;quot;/&gt;
&lt;/tree&gt;
&lt;tree&gt;&lt;node&gt;PP&lt;/node&gt;
&lt;xsl:copy-of select=&amp;quot;.
/concept[type=&apos;bustime&apos;]&amp;quot;/&gt;
&lt;/tree&gt;
&lt;/tree&gt;
&lt;/aggregation&gt;
&lt;/xsl:template&gt;
</figure>
<bodyText confidence="0.998789090909091">
The selected aggregation template creates a
new XML document instance, with root node
&lt;aggregation&gt;. Its child nodes are one or more
&lt;tree&gt; nodes, containing syntactic categories
and other features. The trees contain variable
slots, which will be filled in later by the lexical-
ization and referring expression stages. In the
aggregation stage, the concepts from the agenda
are copied directly into the appropriate slots by
means of &lt;xsl:copy-of&gt; statements.
Our aggregation templates are quite similar
to the syntactic templates described by Theune
(2000). As argued by van Deemter et al. (1999),
this kind of syntactic template-based approach,
which rather resembles TAG-based generation,
is fundamentally well-founded.
The selection of an appropriate aggregation
template is based on which concept types are in
the agenda and on their information status as
Topic or NewInfo. The logic is implemented by
means of nested &lt;xsl:choose&gt; statements, as
in the following example:
</bodyText>
<figure confidence="0.995412708333333">
&lt;!-- CHOOSE TEMPLATE BASED ON AGENDA --&gt;
&lt;xsl:template match=&amp;quot;agenda&amp;quot;&gt;
&lt;xsl:choose&gt;
&lt;xsl:when test=&amp;quot;concept[@info=&apos;NewInfo&apos;]
/type=&apos;means-of-transportation&apos;&amp;quot;&gt;
&lt;xsl:call-template name=&amp;quot;BY-TRANSPORT&amp;quot;/&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;concept[@info=&apos;NewInfo&apos;]
/type=&apos;bus&apos;&amp;quot;&gt;
&lt;xsl:choose&gt;
&lt;xsl:when test=&amp;quot;concept[@info=&apos;NewInfo&apos;]
/type=&apos;busnumber&apos;&amp;quot;&gt;
&lt;xsl:call-template name=&amp;quot;NUM-DEST-TIME&amp;quot;/&gt;
&lt;/xsl:when&gt;
...
&lt;/xsl:choose&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;concept[@info=&apos;NewInfo&apos;]
/type=&apos;busnumber&apos;&amp;quot;&gt;
&lt;xsl:call-template name=&amp;quot;NUMBER-ONLY&amp;quot;/&gt;
&lt;/xsl:when&gt;
...
&lt;/xsl:choose&gt;
&lt;/xsl:template&gt;
</figure>
<bodyText confidence="0.998277">
Here, if means-of-transportation is NewInfo
as in (2a), the template named BY-TRANSPORT
is selected. If means-of-transportation is not
NewInfo, but bus and busnumber are NewInfo
as in (2b), template NUM-DEST-TIME is selected.
If only busnumber is NewInfo, as in (1a), the
template NUMBER-ONLY is selected.
</bodyText>
<subsectionHeader confidence="0.986046">
3.4 Referring Expressions
</subsectionHeader>
<bodyText confidence="0.997167571428571">
In the lexicalization and referring expression
stages of the response generation pipeline, the
concepts in the aggregation templates are re-
placed by lexical items and referring expres-
sions. In general, concepts which are marked
as Topic are realized as pronouns, as shown by
the following simplified examples:
</bodyText>
<figure confidence="0.972343875">
&lt;!-- REFERRING EXPRESSIONS: PRONOUNS --&gt;
&lt;xsl:template
match=&amp;quot;concept[@info=&apos;Topic&apos;]&amp;quot;
mode=&amp;quot;referring-expression&amp;quot;&gt;
&lt;xsl:choose&gt;
&lt;xsl:when test=&amp;quot;type=&apos;busnumber&apos;&amp;quot;&gt;
&lt;xsl:text&gt; it &lt;/xsl:text&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;type=&apos;destination&apos;&amp;quot;&gt;
&lt;xsl:text&gt; there &lt;/xsl:text&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;type=&apos;bustime&apos;&amp;quot;&gt;
&lt;xsl:text&gt; then &lt;/xsl:text&gt;
&lt;/xsl:when&gt;
&lt;/xsl:choose&gt;
&lt;/xsl:template&gt;
</figure>
<bodyText confidence="0.9438421">
Here, a destination concept marked as Topic
is pronominalized as there, as in (2b). By con-
trast, concepts which are marked as NewInfo
are realized as full descriptions. In the following
template, the destination concept is realized by
a prepositional phrase, to followed by the text
value of the destination placename, obtained by
the &lt;xsl:value-of&gt; statement.
&lt;!-- REFERRING EXPRESSIONS: DESCRIPTIONS --&gt;
&lt;xsl:template
</bodyText>
<figure confidence="0.857478333333333">
match=&amp;quot;concept[@info=&apos;NewInfo&apos;]&amp;quot;
mode=&amp;quot;referring-expression&amp;quot;&gt;
&lt;xsl:choose&gt;
&lt;xsl:when test=&amp;quot;type=&apos;busnumber&apos;&amp;quot;&gt;
&lt;xsl:text&gt; number &lt;/xsl:text&gt;
&lt;xsl:value-of select=&amp;quot;value/text()&amp;quot;/&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;type=&apos;destination&apos;&amp;quot;&gt;
&lt;xsl:text&gt; to &lt;/xsl:text&gt;
&lt;xsl:value-of select=&amp;quot;value/text()&amp;quot;/&gt;
&lt;/xsl:when&gt;
&lt;xsl:when test=&amp;quot;type=&apos;bustime&apos;&amp;quot;&gt;
&lt;xsl:text&gt; at &lt;/xsl:text&gt;
&lt;xsl:value-of select=&amp;quot;value/text()&amp;quot;/&gt;
&lt;/xsl:when&gt;
</figure>
<page confidence="0.3689935">
&lt;/xsl:choose&gt;
&lt;/xsl:template&gt;
</page>
<bodyText confidence="0.9999005">
The above examples are simplified to show
simple text output. The final stages of response
generation actually perform syntactic and mor-
phological realization producing XML output
(SABLE or VoiceXML) which is passed to the
speech synthesizer.
</bodyText>
<sectionHeader confidence="0.985229" genericHeader="method">
4 Confidence-based Adaptivity
</sectionHeader>
<bodyText confidence="0.999952545454545">
In general, when confidence in speech recog-
nition accuracy goes down, the dialogue sys-
tem needs to adapt by increasing the repetition
of old information to check that it is correct.
When confidence in speech recognition accuracy
is high, the system should adapt by reducing the
repetition of old information, given the dialogue
context itself does not require this. Normally,
with high speech recognition confidence, a flu-
ent dialogue will be made up of responses with
only new information.
</bodyText>
<subsectionHeader confidence="0.990879">
4.1 A Development Framework
</subsectionHeader>
<bodyText confidence="0.99958929032258">
In order to allow this kind of variation in the re-
sponses produced, the framework in which the
dialogue management is embedded must itself
be designed specifically to support adaptivity.
One such system is the Jaspis adaptive speech
application framework (Turunen and Hakuli-
nen, 2000). Jaspis is a general agent-based de-
velopment architecture, and on the most general
level it contains managers which handle general
coordination between the system components
and functional modules (such as the Input Man-
ager, the Dialogue Manager and the Presenta-
tion Manager). Within each manager there are
several agents which handle various interaction
situations, as well as a set of evaluators which
try to choose the best possible agent to handle
each situation. The architecture also exploits
a shared knowledge-base called the Information
Storage, where the information about the cur-
rent state of the system is kept and which each
of the agents can read and update.
The adaptivity-oriented architecture of our
dialogue system is shown in Figure 1 (the In-
put Manager is left out). The Dialogue Man-
ager consists of a number of dialogue agents that
are experts on one specific aspect of dialogue
management and whose activities are controlled
and coordinated by a particualr dialogue con-
troller (which thus currently acts as the central
evaluator for all the dialogue agents). The Di-
alogue Manager decides what to say next on
</bodyText>
<figureCaption confidence="0.999406">
Figure 1: Part of the system architecture
</figureCaption>
<bodyText confidence="0.999979836734694">
the basis of the dialogue context recorded in
the Information Storage by the various agents,
and by consulting the Task Manager, whenever
the requested information requires factual in-
formation about the task itself. The output of
this reasoning is expressed in terms of concepts
marked as NewInfo and Topic, and stored in the
shared Information Storage in the XML format
as shown in the examples in Section 2.
The response generation takes place in the
presentation management module, which con-
tains several generator agents, each of which
specialized in one particular type of generation.
The agents may, for example, generate in differ-
ent languages (we are developing generators for
English and Finnish). In the current implemen-
tation, we mainly consider agents for pronomi-
nalization, explicitness and politeness.
We are developing generation agents at three
distinct explicitness levels. The first agent gen-
erates NewInfo only, and is suitable for quick in-
formal interactions with high speech recognition
confidence like example (3a). The second agent
generates NewInfo wrapped by Topic, where
Topic is normally realized as a minimal refer-
ring expression such as a pronoun. This agent
is suitable for more polite interactions with good
speech recognition, as in example (3b). The
third agent generates a fully explicit Topic, and
is suitable for situations where speech recogni-
tion confidence is low, and confirmation of the
topic is required, as in example (3c). One ad-
vantage of this approach is that the design of
the individual generators is simplified, as they
can follow a fixed realization strategy, but the
overall adaptivity of the system is increased.
The selection of the appropriate generator
agent is the task of the component called the
Adapter in Figure 1. The Adapter is a particu-
lar kind of evaluator based on a neural network
implementation. Input consists of a number of
features which are encoded as binary features,
and output consists of categories that represent
the different generators. The features are ex-
tracted from the shared information storage and
concern e.g. the content of the planned utter-
ance (Topic, NewInfo), recognition confidence
of the previous user utterance, and general re-
quirements for cooperative, natural responses.
</bodyText>
<subsectionHeader confidence="0.937097">
4.2 Adaptivity
</subsectionHeader>
<bodyText confidence="0.999994907407407">
Adaptivity is one of the desirable properties for
learning dialogue systems (Jokinen, 2000). It
is linked to the system&apos;s cooperation with the
user, i.e. its capability to provide informative
and helpful responses but also its capability to
tailor responses according to various situations
the users find themselves in.
In the above framework, one approach to pro-
viding the desired adaptivity is to have gen-
erator agents with different levels of explicit-
ness. Changing levels of confidence in speech
recognition accuracy can then lead to selecting
generator agents with more or less explicitness.
The detailed mechanisms for switching between
these different agents by means of the evalua-
tors in the Jaspis framework, including a soft
computing approach based on neural networks,
are being evaluated.
Related research has studied adaptivity with
respect to system strategies, and identified con-
firmation as one of the helpful strategies that
spoken dialogue systems can use in order to
show cooperation and allow the user to cor-
rect misrecognized words (Danieli and Gerbino,
1995). The use of system initiative also helps re-
duce misrecognition errors and thus contributes
to user satisfaction (Walker et al., 1998). How-
ever, a fixed dialogue strategy may not suit all
users, whose knowledge of the system&apos;s capabil-
ities may differ. Adaptivity can thus be related
to the system&apos;s ability to change from a user ini-
tiative strategy to a system initiative one, or to
use varied confirmation strategies, in response
to circumstances and the user model. Empiri-
cal evaluation of one such system shows that an
adaptable system outperforms a non-adaptable
one (Litman and Pan, 2000).
We have widened the notion of adaptivity
to concern also the system&apos;s generation strate-
gies in maintaining natural interaction with the
user. The dialogue manager can be said to select
among dialogue strategies, such as confirmation
or initiative, and the choice is implicitly shown
in the selection of the concepts in the agenda.
The presentation manager then selects a gener-
ator agent to realise the agenda, and can be said
to further extend the system&apos;s adaptivity as an
aspect of the realization possibilities available
for the system. The same agenda can be re-
alised differently (as in examples 3a and 3b) by
different generator agents, and thus the system
can adapt on different levels. The selection of
confirmation or non-confirmation strategy can
also depend on the system&apos;s other capabilities.
</bodyText>
<subsectionHeader confidence="0.980317">
4.3 Confidence
</subsectionHeader>
<bodyText confidence="0.99999754">
The aim of the adaptivity-oriented architecture
is to enable the spoken dialogue system to adapt
its responses to the changing confidence lev-
els concerning the system&apos;s knowledge of the
current dialogue situation. At the start of a
new dialogue, when there is no previous history
on which to establish any general communica-
tive confidence, the system should start with a
highly explicit response generator, and gradu-
ally, if some level of confidence is established,
switch to a less explicit generator.
The high level of explicitness in the system
responses has several aspects. Simply by pro-
viding a quantity of words to be recognised and
acknowledged, the system can verify its under-
standing of the relevant concepts. Explicitness
thus enables speech recognition confidence to be
established, and is related to the system&apos;s con-
firmation strategy as in example (3c).
It is also associated with politeness: a high
level of explicitness is more polite, and a high
level of elliptical expression is more friendly.
Since politeness is expected with strangers,
more explicitness is therefore appropriate at the
start of a dialogue and less appropriate as the
dialogue proceeds: it is thus inversely related
to the confidence of the partner which gets es-
tablished in the shared situation. This pattern
of gradual change from a more formal initial
register to a more informal register as the di-
alogue progresses is well known, at least in cul-
tures in which register is not dictated strictly
by social hierarchy. Differences between En-
glish dialogues (dynamic register adaptivity)
and Japanese dialogues (fixed register through-
out) have been studied (Kume et al., 1989).
Generation of referring expressions is mainly
concerned with enabling successful discrimina-
tion of the correct referent. However, referring
expressions in dialogue systems are also strongly
affected by the level of confidence. When there
is some doubt, it is safer to use highly explicit
referring expressions. When there is a high level
of confidence, it is normal to take certain risks
for the sake of fluent interaction. In fact the
difference between definite descriptions and pro-
nouns is based on confidence: if an entity has
not been mentioned previously, it has no history
on which any confidence can be established, so
a high level of explicitness is required.
</bodyText>
<subsectionHeader confidence="0.944133">
4.4 Communicative Obligations
</subsectionHeader>
<bodyText confidence="0.999998392857143">
As argued by Allwood (1976), communication
creates normative social obligations which con-
cern the speaker&apos;s rational coordinated interac-
tion. Obligations are connected to a particular
activity and a role in the activity, varying also
according to the speakers&apos; familiarity and rela-
tive status with each other.
In dialogue systems, communicative obliga-
tions are usually part of the system&apos;s control
structure. The system can take the initiative,
give helpful information in anticipation of the
user&apos;s questions or to resolve problematic sit-
uations (misheard words, ambiguous referents,
etc.), or simply react to the user input as best
as it can. Obligations are thus used as a basic
motivation for action (Traum and Allen, 1994).
In our framework communicative obligations
are dispersed among the agents and evaluator
control. This allows us to make the obligations
overt, since they can be implemented as simple
dialogue agents. However, as their application
order is not fixed, the overall architecture sup-
ports flexible interaction where the basic com-
municative ability of the system is shown in the
functioning of the system itself. The systems&apos;s
cooperation is not only a pre-assigned disposi-
tion to act in a helpful way, but involves reason-
ing about the appropriate act in the context.
</bodyText>
<sectionHeader confidence="0.996747" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999871">
We have described our work on adaptivity in re-
sponse generation for a spoken dialogue system,
and have argued in favour of a system architec-
ture using highly specialized agents. The sys-
tem adapts its responses to dialogue situations
by means of the detailed agendas specified by
the dialogue manager and the selection of the
generator agent by the presentation manager.
Further evaluation of a larger demonstrator sys-
tem is planned.
</bodyText>
<sectionHeader confidence="0.998815" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998785173913044">
Jens Allwood. 1976. Linguistic Communication
as Action and Cooperation. Department of
Linguistics, University of Goteborg. Gothen-
burg Monographs in Linguistics 2.
Apache XML Project. 2001. Xalan-Java
version 2.1.0. http://xml.apache.org/xalan-
j/index.html.
Alison Cawsey. 2000. Presenting tailored re-
source descriptions: Will XSLT do the job?
In 9th International Conference on the World
Wide Web.
Morena Danieli and Elisabetta Gerbino. 1995.
Metrics for evaluating dialogue strategies in
a spoken language system. In Proceedings
of the AAAI Spring Symposium on Empiri-
cal Methods in Discourse Interpretation and
Generation, pages 34{39.
Kristiina Jokinen, Hideki Tanaka, and Akio
Yokoo. 1998. Planning dialogue contribu-
tions with new information. In Proceedings
of the Ninth International Workshop on Nat-
ural Language Generation, pages 158{167,
Niagara-on-the-Lake, Ontario.
Kristiina Jokinen. 2000. Learning dialogue sys-
tems. In L. Dybkjaer, editor, LREC 2000
Workshop: From Spoken Dialogue to Full
Natural Interactive Dialogue - Theory, Em-
pirical Analysis and Evaluation, pages 13{17,
Athens.
Masako Kume, Gayle K. Sato, and Kei Yoshi-
moto. 1989. A descriptive framework for
translating speaker&apos;s meaning: Towards a di-
alogue translation system between Japanese
and English. In Fourth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 264{271,
Manchester.
Diane Litman and Shimei Pan. 2000. Predict-
ing and adapting to poor speech recognition
in a spoken dialogue system. In Proceed-
ings of the Seventeenth National Conference
on Artificial Intelligence (AAAI-2000), pages
722{728, Austin, TX.
Ehud Reiter and Robert Dale. 2000. Building
Natural Language Generation Systems. Cam-
bridge University Press.
Mariet Theune. 2000. From Data to Speech:
Language Generation in Context. Ph.D. the-
sis, Eindhoven University of Technology.
David Traum and James F. Allen. 1994. Dis-
course obligations in dialogue processing. In
32nd Annual Meeting of the Association for
Computational Linguistics, pages 1-8, Las
Cruces.
Markku Turunen and Jaakko Hakulinen. 2000.
Jaspis - a framework for multilingual adaptive
speech applications. In Proceedings of 6th In-
ternational Conference on Spoken Language
Processing, Beijing.
Kees van Deemter, Emiel Krahmer, and Mariet
Theune. 1999. Plan-based vs. template-
based NLG: A false opposition? In Proceed-
ings of the KI&apos;99 Workshop: May I Speak
Freely?, pages 1-5, Saarbrucken.
Marilyn Walker, Diane Litman, Candace
Kamm, and Alicia Abella. 1998. Evaluat-
ing spoken dialogue agents with PARADISE:
Two case studies. Computer Speech and Lan-
guage, 12-3.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.620835">
<title confidence="0.9998445">Confidence-based Adaptivity in Response Generation for a Spoken Dialogue System</title>
<author confidence="0.999987">Kristiina Jokinen Graham Wilcock</author>
<affiliation confidence="0.999915">University of Art and Design Helsinki University of Helsinki</affiliation>
<address confidence="0.999959">00560 Helsinki, Finland 00014 Helsinki, Finland</address>
<email confidence="0.634444">kjokinen@uiah.fiGraham.Wilcock@helsinki.fi</email>
<abstract confidence="0.998822166666667">The paper addresses the issue of how to increase adaptivity in response generation for a spoken dialogue system. Realization strategies for dialogue responses depend on communicative confidence levels and interaction management goals. We first describe a Java/XML-based generator which produces different realizations of system responses based on agendas specified by the dialogue manager. We then discuss how greater adaptivity can be achieved by using a set of distinct generator agents, each of which is specialized in its realization strategy (e.g. highly elliptical or highly explicit). This allows a simpler design of each generator agent, while increasing the overall system adaptivity to meet the requirements for flexible cooperation in incremental and immediate interactive situations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jens Allwood</author>
</authors>
<title>Linguistic Communication as Action and Cooperation. Department of Linguistics,</title>
<date>1976</date>
<journal>University of Goteborg. Gothenburg Monographs in Linguistics</journal>
<volume>2</volume>
<contexts>
<context position="33459" citStr="Allwood (1976)" startWordPosition="5032" endWordPosition="5033">eferent. However, referring expressions in dialogue systems are also strongly affected by the level of confidence. When there is some doubt, it is safer to use highly explicit referring expressions. When there is a high level of confidence, it is normal to take certain risks for the sake of fluent interaction. In fact the difference between definite descriptions and pronouns is based on confidence: if an entity has not been mentioned previously, it has no history on which any confidence can be established, so a high level of explicitness is required. 4.4 Communicative Obligations As argued by Allwood (1976), communication creates normative social obligations which concern the speaker&apos;s rational coordinated interaction. Obligations are connected to a particular activity and a role in the activity, varying also according to the speakers&apos; familiarity and relative status with each other. In dialogue systems, communicative obligations are usually part of the system&apos;s control structure. The system can take the initiative, give helpful information in anticipation of the user&apos;s questions or to resolve problematic situations (misheard words, ambiguous referents, etc.), or simply react to the user input a</context>
</contexts>
<marker>Allwood, 1976</marker>
<rawString>Jens Allwood. 1976. Linguistic Communication as Action and Cooperation. Department of Linguistics, University of Goteborg. Gothenburg Monographs in Linguistics 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apache XML Project</author>
</authors>
<title>Xalan-Java version 2.1.0.</title>
<date>2001</date>
<note>http://xml.apache.org/xalanj/index.html.</note>
<contexts>
<context position="15954" citStr="Project, 2001" startWordPosition="2428" endWordPosition="2429"> section, we will describe an extension to this framework, suitable for adaptive and flexible response generation. 3.1 A Pipeline Architecture The generator starts from an agenda of concepts specified in XML, set up by the dialogue manager as shown in the examples in Section 2. The generator produces linguistic output which is also specified in XML, to be passed to the speech synthesizer. We are therefore generating XML from XML. The simplest way to do this is to apply a set of XML transformations specified in XSL (XML Stylesheet Language). We do this using the Xalan XSL Processor (Apache XML Project, 2001) which is open-source software written entirely in Java. With the Xalan XSL Processor it is easy to set up a sequence of transformations, in which the output of one transformation becomes the input to the next transformation. This kind of &amp;quot;piping&amp;quot; is a natural way to implement the standard pipeline architecture regularly used in natural language generation systems (Reiter and Dale, 2000). The ease of setting up a pipeline architecture with XSL raises the general question of whether XSL transformations are suitable for wider use in NLG systems. This is discussed by Cawsey (2000), who concludes </context>
</contexts>
<marker>Project, 2001</marker>
<rawString>Apache XML Project. 2001. Xalan-Java version 2.1.0. http://xml.apache.org/xalanj/index.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alison Cawsey</author>
</authors>
<title>Presenting tailored resource descriptions: Will XSLT do the job?</title>
<date>2000</date>
<booktitle>In 9th International Conference on the World Wide Web.</booktitle>
<contexts>
<context position="16538" citStr="Cawsey (2000)" startWordPosition="2525" endWordPosition="2526">or (Apache XML Project, 2001) which is open-source software written entirely in Java. With the Xalan XSL Processor it is easy to set up a sequence of transformations, in which the output of one transformation becomes the input to the next transformation. This kind of &amp;quot;piping&amp;quot; is a natural way to implement the standard pipeline architecture regularly used in natural language generation systems (Reiter and Dale, 2000). The ease of setting up a pipeline architecture with XSL raises the general question of whether XSL transformations are suitable for wider use in NLG systems. This is discussed by Cawsey (2000), who concludes that relatively simple XSL transformations can be used for generation when the input is fairly constrained, but XSL is not suitable for less constrained input, when we need to turn to general purpose programming languages or NLG tools. However, XSL can be combined with general purpose programming languages by embedding extension functions in the XSL templates. These functions can be written in Java (Apache XML Project, 2001). This means that even where general purpose programming languages are required for specific purposes, such as complex morphology, a pipeline of XSL transfo</context>
<context position="19081" citStr="Cawsey (2000)" startWordPosition="2940" endWordPosition="2941">however, the generator must convert the unordered bag of concepts in the agenda into a syntactically correct ordered sequence of words to be passed to the speech synthesizer. Also, the new information focus tends to come last in surface order, so the linking information (if any) will generally precede the new information in the surface realization. Simple reordering can be performed in XSL, for example by using XSL modes. We have experimented with applying XSL templates first with a Topic mode (if required), followed by a NewInfo mode. The usefulness of XSL modes for such purposes is noted by Cawsey (2000). However, as we must also handle detailed syntactic ordering, we use aggregation templates as described in Section 3.3. If the real-time requirements of the system allow sufficient time, the generator can decide on the optimum way to wrap the new information, but if there is extreme urgency to produce a response, the generator can simply give the new information without wrapping it. If this leads to misunderstanding, the system can attempt to repair this in subsequent turns. In this sense, the model offers an any-time algorithm, important for providing incremental and immediate responses for </context>
</contexts>
<marker>Cawsey, 2000</marker>
<rawString>Alison Cawsey. 2000. Presenting tailored resource descriptions: Will XSLT do the job? In 9th International Conference on the World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morena Danieli</author>
<author>Elisabetta Gerbino</author>
</authors>
<title>Metrics for evaluating dialogue strategies in a spoken language system.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation,</booktitle>
<pages>34--39</pages>
<contexts>
<context position="29655" citStr="Danieli and Gerbino, 1995" startWordPosition="4421" endWordPosition="4424">ness. Changing levels of confidence in speech recognition accuracy can then lead to selecting generator agents with more or less explicitness. The detailed mechanisms for switching between these different agents by means of the evaluators in the Jaspis framework, including a soft computing approach based on neural networks, are being evaluated. Related research has studied adaptivity with respect to system strategies, and identified confirmation as one of the helpful strategies that spoken dialogue systems can use in order to show cooperation and allow the user to correct misrecognized words (Danieli and Gerbino, 1995). The use of system initiative also helps reduce misrecognition errors and thus contributes to user satisfaction (Walker et al., 1998). However, a fixed dialogue strategy may not suit all users, whose knowledge of the system&apos;s capabilities may differ. Adaptivity can thus be related to the system&apos;s ability to change from a user initiative strategy to a system initiative one, or to use varied confirmation strategies, in response to circumstances and the user model. Empirical evaluation of one such system shows that an adaptable system outperforms a non-adaptable one (Litman and Pan, 2000). We ha</context>
</contexts>
<marker>Danieli, Gerbino, 1995</marker>
<rawString>Morena Danieli and Elisabetta Gerbino. 1995. Metrics for evaluating dialogue strategies in a spoken language system. In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, pages 34{39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristiina Jokinen</author>
<author>Hideki Tanaka</author>
<author>Akio Yokoo</author>
</authors>
<title>Planning dialogue contributions with new information.</title>
<date>1998</date>
<booktitle>In Proceedings of the Ninth International Workshop on Natural Language Generation,</booktitle>
<pages>158--167</pages>
<location>Niagara-on-the-Lake, Ontario.</location>
<contexts>
<context position="1809" citStr="Jokinen et al., 1998" startWordPosition="259" endWordPosition="262">peration and naturalness. Cooperation is used to refer to the participants&apos; ability to collaborate with each other on a given task and to provide informative and helpful contributions in a given task context. Naturalness, however, describes the participants&apos; reaction which is appropriate in the current communicative context, and usually presupposes reasoning through which the participants can adapt themselves to the requirements of the situation and to the knowledge level of their partner. Naturalness in spoken interaction can be characterised by features such as incrementality and immediacy (Jokinen et al., 1998). Speakers exchange information and present the new information in a stepwise manner, constructing a common ground by providing new pieces of relevant information to complete the task that the interaction was initiated for. They monitor their own presentations and react to the partner&apos;s contributions immediately, often simultaneously, to prevent potential misunderstandings growing and causing problems to the interaction. Spoken dialogue systems that aim at natural interaction with the user should thus have capabilities for incremental and immediate management of interaction. In other words, th</context>
<context position="4525" citStr="Jokinen et al. (1998)" startWordPosition="675" endWordPosition="678">r highly explicit). The design of the individual generation agents is therefore simpler, but the system as a whole increases in adaptivity by choosing which agent to use according to the wider dialogue context. We describe a Java and XML-based framework which supports this architecture, and discuss a strategy for adaptivity based on communicative confidence. 2 Interaction Management In this section we discuss concrete examples from a spoken dialogue system. The domain is public transportation in Helsinki. 2.1 Agenda, NewInfo and Topic To enable incremental presentation and immediate reaction, Jokinen et al. (1998) structure the context with the help of NewInfo and Topic, so that the generator can distinguish the new information that is meant to be put across in the current dialogue situation, and the background information that the new information is linked to. The pool of contextual information includes an agenda, a set of concepts marked with the help of &apos;topic&apos; and &apos;newinfo&apos; tags, the tags being determined by the dialogue manager which decides how the system is to react next. The generator can freely use the tagged pieces of information in order to realise the system&apos;s intention as a surface string,</context>
<context position="17362" citStr="Jokinen et al. (1998)" startWordPosition="2655" endWordPosition="2658">eral purpose programming languages or NLG tools. However, XSL can be combined with general purpose programming languages by embedding extension functions in the XSL templates. These functions can be written in Java (Apache XML Project, 2001). This means that even where general purpose programming languages are required for specific purposes, such as complex morphology, a pipeline of XSL transformations can still be used as a general framework. 3.2 Focus-based Generation The model of dialogue response generation which we use is based on generation from the new information focus, as proposed by Jokinen et al. (1998). In this model, response planning starts from the new information focus, called NewInfo. One of the tasks of the generator is to decide how to present the NewInfo to the user: whether it should be presented by itself or whether it should be wrapped in appropriate linking information. The wrapping of the NewInfo depends on the pragmatic requirements of the dynamic dialogue context. When the context permits a fluent exchange of contributions, wrapping will be avoided and the response will be based on new information only. When the context requires more clarity and explicitness, the new informat</context>
</contexts>
<marker>Jokinen, Tanaka, Yokoo, 1998</marker>
<rawString>Kristiina Jokinen, Hideki Tanaka, and Akio Yokoo. 1998. Planning dialogue contributions with new information. In Proceedings of the Ninth International Workshop on Natural Language Generation, pages 158{167, Niagara-on-the-Lake, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristiina Jokinen</author>
</authors>
<title>Learning dialogue systems.</title>
<date>2000</date>
<booktitle>LREC 2000 Workshop: From Spoken Dialogue to Full Natural Interactive Dialogue - Theory, Empirical Analysis and Evaluation,</booktitle>
<pages>13--17</pages>
<editor>In L. Dybkjaer, editor,</editor>
<location>Athens.</location>
<contexts>
<context position="28666" citStr="Jokinen, 2000" startWordPosition="4269" endWordPosition="4270">ter in Figure 1. The Adapter is a particular kind of evaluator based on a neural network implementation. Input consists of a number of features which are encoded as binary features, and output consists of categories that represent the different generators. The features are extracted from the shared information storage and concern e.g. the content of the planned utterance (Topic, NewInfo), recognition confidence of the previous user utterance, and general requirements for cooperative, natural responses. 4.2 Adaptivity Adaptivity is one of the desirable properties for learning dialogue systems (Jokinen, 2000). It is linked to the system&apos;s cooperation with the user, i.e. its capability to provide informative and helpful responses but also its capability to tailor responses according to various situations the users find themselves in. In the above framework, one approach to providing the desired adaptivity is to have generator agents with different levels of explicitness. Changing levels of confidence in speech recognition accuracy can then lead to selecting generator agents with more or less explicitness. The detailed mechanisms for switching between these different agents by means of the evaluator</context>
</contexts>
<marker>Jokinen, 2000</marker>
<rawString>Kristiina Jokinen. 2000. Learning dialogue systems. In L. Dybkjaer, editor, LREC 2000 Workshop: From Spoken Dialogue to Full Natural Interactive Dialogue - Theory, Empirical Analysis and Evaluation, pages 13{17, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masako Kume</author>
<author>Gayle K Sato</author>
<author>Kei Yoshimoto</author>
</authors>
<title>A descriptive framework for translating speaker&apos;s meaning: Towards a dialogue translation system between Japanese and English.</title>
<date>1989</date>
<booktitle>In Fourth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>264--271</pages>
<location>Manchester.</location>
<contexts>
<context position="32731" citStr="Kume et al., 1989" startWordPosition="4915" endWordPosition="4918">h strangers, more explicitness is therefore appropriate at the start of a dialogue and less appropriate as the dialogue proceeds: it is thus inversely related to the confidence of the partner which gets established in the shared situation. This pattern of gradual change from a more formal initial register to a more informal register as the dialogue progresses is well known, at least in cultures in which register is not dictated strictly by social hierarchy. Differences between English dialogues (dynamic register adaptivity) and Japanese dialogues (fixed register throughout) have been studied (Kume et al., 1989). Generation of referring expressions is mainly concerned with enabling successful discrimination of the correct referent. However, referring expressions in dialogue systems are also strongly affected by the level of confidence. When there is some doubt, it is safer to use highly explicit referring expressions. When there is a high level of confidence, it is normal to take certain risks for the sake of fluent interaction. In fact the difference between definite descriptions and pronouns is based on confidence: if an entity has not been mentioned previously, it has no history on which any confi</context>
</contexts>
<marker>Kume, Sato, Yoshimoto, 1989</marker>
<rawString>Masako Kume, Gayle K. Sato, and Kei Yoshimoto. 1989. A descriptive framework for translating speaker&apos;s meaning: Towards a dialogue translation system between Japanese and English. In Fourth Conference of the European Chapter of the Association for Computational Linguistics, pages 264{271, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane Litman</author>
<author>Shimei Pan</author>
</authors>
<title>Predicting and adapting to poor speech recognition in a spoken dialogue system.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth National Conference on Artificial Intelligence (AAAI-2000),</booktitle>
<pages>722--728</pages>
<location>Austin, TX.</location>
<contexts>
<context position="30248" citStr="Litman and Pan, 2000" startWordPosition="4518" endWordPosition="4521"> (Danieli and Gerbino, 1995). The use of system initiative also helps reduce misrecognition errors and thus contributes to user satisfaction (Walker et al., 1998). However, a fixed dialogue strategy may not suit all users, whose knowledge of the system&apos;s capabilities may differ. Adaptivity can thus be related to the system&apos;s ability to change from a user initiative strategy to a system initiative one, or to use varied confirmation strategies, in response to circumstances and the user model. Empirical evaluation of one such system shows that an adaptable system outperforms a non-adaptable one (Litman and Pan, 2000). We have widened the notion of adaptivity to concern also the system&apos;s generation strategies in maintaining natural interaction with the user. The dialogue manager can be said to select among dialogue strategies, such as confirmation or initiative, and the choice is implicitly shown in the selection of the concepts in the agenda. The presentation manager then selects a generator agent to realise the agenda, and can be said to further extend the system&apos;s adaptivity as an aspect of the realization possibilities available for the system. The same agenda can be realised differently (as in example</context>
</contexts>
<marker>Litman, Pan, 2000</marker>
<rawString>Diane Litman and Shimei Pan. 2000. Predicting and adapting to poor speech recognition in a spoken dialogue system. In Proceedings of the Seventeenth National Conference on Artificial Intelligence (AAAI-2000), pages 722{728, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="16344" citStr="Reiter and Dale, 2000" startWordPosition="2491" endWordPosition="2494">thesizer. We are therefore generating XML from XML. The simplest way to do this is to apply a set of XML transformations specified in XSL (XML Stylesheet Language). We do this using the Xalan XSL Processor (Apache XML Project, 2001) which is open-source software written entirely in Java. With the Xalan XSL Processor it is easy to set up a sequence of transformations, in which the output of one transformation becomes the input to the next transformation. This kind of &amp;quot;piping&amp;quot; is a natural way to implement the standard pipeline architecture regularly used in natural language generation systems (Reiter and Dale, 2000). The ease of setting up a pipeline architecture with XSL raises the general question of whether XSL transformations are suitable for wider use in NLG systems. This is discussed by Cawsey (2000), who concludes that relatively simple XSL transformations can be used for generation when the input is fairly constrained, but XSL is not suitable for less constrained input, when we need to turn to general purpose programming languages or NLG tools. However, XSL can be combined with general purpose programming languages by embedding extension functions in the XSL templates. These functions can be writ</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building Natural Language Generation Systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariet Theune</author>
</authors>
<title>From Data to Speech: Language Generation in Context.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Eindhoven University of Technology.</institution>
<contexts>
<context position="21167" citStr="Theune (2000)" startWordPosition="3224" endWordPosition="3225">stime&apos;]&amp;quot;/&gt; &lt;/tree&gt; &lt;/tree&gt; &lt;/aggregation&gt; &lt;/xsl:template&gt; The selected aggregation template creates a new XML document instance, with root node &lt;aggregation&gt;. Its child nodes are one or more &lt;tree&gt; nodes, containing syntactic categories and other features. The trees contain variable slots, which will be filled in later by the lexicalization and referring expression stages. In the aggregation stage, the concepts from the agenda are copied directly into the appropriate slots by means of &lt;xsl:copy-of&gt; statements. Our aggregation templates are quite similar to the syntactic templates described by Theune (2000). As argued by van Deemter et al. (1999), this kind of syntactic template-based approach, which rather resembles TAG-based generation, is fundamentally well-founded. The selection of an appropriate aggregation template is based on which concept types are in the agenda and on their information status as Topic or NewInfo. The logic is implemented by means of nested &lt;xsl:choose&gt; statements, as in the following example: &lt;!-- CHOOSE TEMPLATE BASED ON AGENDA --&gt; &lt;xsl:template match=&amp;quot;agenda&amp;quot;&gt; &lt;xsl:choose&gt; &lt;xsl:when test=&amp;quot;concept[@info=&apos;NewInfo&apos;] /type=&apos;means-of-transportation&apos;&amp;quot;&gt; &lt;xsl:call-template na</context>
</contexts>
<marker>Theune, 2000</marker>
<rawString>Mariet Theune. 2000. From Data to Speech: Language Generation in Context. Ph.D. thesis, Eindhoven University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>James F Allen</author>
</authors>
<title>Discourse obligations in dialogue processing.</title>
<date>1994</date>
<booktitle>In 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<location>Las Cruces.</location>
<contexts>
<context position="34159" citStr="Traum and Allen, 1994" startWordPosition="5137" endWordPosition="5140">&apos;s rational coordinated interaction. Obligations are connected to a particular activity and a role in the activity, varying also according to the speakers&apos; familiarity and relative status with each other. In dialogue systems, communicative obligations are usually part of the system&apos;s control structure. The system can take the initiative, give helpful information in anticipation of the user&apos;s questions or to resolve problematic situations (misheard words, ambiguous referents, etc.), or simply react to the user input as best as it can. Obligations are thus used as a basic motivation for action (Traum and Allen, 1994). In our framework communicative obligations are dispersed among the agents and evaluator control. This allows us to make the obligations overt, since they can be implemented as simple dialogue agents. However, as their application order is not fixed, the overall architecture supports flexible interaction where the basic communicative ability of the system is shown in the functioning of the system itself. The systems&apos;s cooperation is not only a pre-assigned disposition to act in a helpful way, but involves reasoning about the appropriate act in the context. 5 Conclusion We have described our w</context>
</contexts>
<marker>Traum, Allen, 1994</marker>
<rawString>David Traum and James F. Allen. 1994. Discourse obligations in dialogue processing. In 32nd Annual Meeting of the Association for Computational Linguistics, pages 1-8, Las Cruces.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markku Turunen</author>
<author>Jaakko Hakulinen</author>
</authors>
<title>Jaspis - a framework for multilingual adaptive speech applications.</title>
<date>2000</date>
<booktitle>In Proceedings of 6th International Conference on Spoken Language Processing,</booktitle>
<location>Beijing.</location>
<contexts>
<context position="25121" citStr="Turunen and Hakulinen, 2000" startWordPosition="3704" endWordPosition="3708">rrect. When confidence in speech recognition accuracy is high, the system should adapt by reducing the repetition of old information, given the dialogue context itself does not require this. Normally, with high speech recognition confidence, a fluent dialogue will be made up of responses with only new information. 4.1 A Development Framework In order to allow this kind of variation in the responses produced, the framework in which the dialogue management is embedded must itself be designed specifically to support adaptivity. One such system is the Jaspis adaptive speech application framework (Turunen and Hakulinen, 2000). Jaspis is a general agent-based development architecture, and on the most general level it contains managers which handle general coordination between the system components and functional modules (such as the Input Manager, the Dialogue Manager and the Presentation Manager). Within each manager there are several agents which handle various interaction situations, as well as a set of evaluators which try to choose the best possible agent to handle each situation. The architecture also exploits a shared knowledge-base called the Information Storage, where the information about the current stat</context>
</contexts>
<marker>Turunen, Hakulinen, 2000</marker>
<rawString>Markku Turunen and Jaakko Hakulinen. 2000. Jaspis - a framework for multilingual adaptive speech applications. In Proceedings of 6th International Conference on Spoken Language Processing, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Emiel Krahmer</author>
<author>Mariet Theune</author>
</authors>
<title>Plan-based vs. templatebased NLG: A false opposition?</title>
<date>1999</date>
<booktitle>In Proceedings of the KI&apos;99 Workshop: May I Speak Freely?,</booktitle>
<pages>1--5</pages>
<location>Saarbrucken.</location>
<marker>van Deemter, Krahmer, Theune, 1999</marker>
<rawString>Kees van Deemter, Emiel Krahmer, and Mariet Theune. 1999. Plan-based vs. templatebased NLG: A false opposition? In Proceedings of the KI&apos;99 Workshop: May I Speak Freely?, pages 1-5, Saarbrucken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Diane Litman</author>
<author>Candace Kamm</author>
<author>Alicia Abella</author>
</authors>
<title>Evaluating spoken dialogue agents with PARADISE: Two case studies.</title>
<date>1998</date>
<journal>Computer Speech and Language,</journal>
<pages>12--3</pages>
<contexts>
<context position="29789" citStr="Walker et al., 1998" startWordPosition="4442" endWordPosition="4445">s. The detailed mechanisms for switching between these different agents by means of the evaluators in the Jaspis framework, including a soft computing approach based on neural networks, are being evaluated. Related research has studied adaptivity with respect to system strategies, and identified confirmation as one of the helpful strategies that spoken dialogue systems can use in order to show cooperation and allow the user to correct misrecognized words (Danieli and Gerbino, 1995). The use of system initiative also helps reduce misrecognition errors and thus contributes to user satisfaction (Walker et al., 1998). However, a fixed dialogue strategy may not suit all users, whose knowledge of the system&apos;s capabilities may differ. Adaptivity can thus be related to the system&apos;s ability to change from a user initiative strategy to a system initiative one, or to use varied confirmation strategies, in response to circumstances and the user model. Empirical evaluation of one such system shows that an adaptable system outperforms a non-adaptable one (Litman and Pan, 2000). We have widened the notion of adaptivity to concern also the system&apos;s generation strategies in maintaining natural interaction with the use</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1998</marker>
<rawString>Marilyn Walker, Diane Litman, Candace Kamm, and Alicia Abella. 1998. Evaluating spoken dialogue agents with PARADISE: Two case studies. Computer Speech and Language, 12-3.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>