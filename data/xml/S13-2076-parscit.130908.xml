<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.037805">
<title confidence="0.9952305">
OPTWIMA: Comparing Knowledge-rich and Knowledge-poor Approaches
for Sentiment Analysis in Short Informal Texts
</title>
<author confidence="0.952831">
Alexandra Balahur
</author>
<affiliation confidence="0.922652">
European Commission Joint Research Centre
</affiliation>
<address confidence="0.977168">
Via E. Fermi 2749
21027 Ispra (VA), Italy
</address>
<email confidence="0.999664">
{alexandra.balahur}@jrc.ec.europa.eu
</email>
<sectionHeader confidence="0.998605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912">
The fast development of Social Media made it
possible for people to no loger remain mere
spectators to the events that happen in the
world, but become part of them, comment-
ing on their developments and the entities in-
volved, sharing their opinions and distribut-
ing related content. This phenomenon is of
high importance to news monitoring systems,
whose aim is to obtain an informative snap-
shot of media events and related comments.
This paper presents the strategies employed in
the OPTWIMA participation to SemEval 2013
Task 2-Sentiment Analysis in Twitter. The
main goal was to evaluate the best settings for
a sentiment analysis component to be added to
the online news monitoring system.
We describe the approaches used in the com-
petition and the additional experiments per-
formed combining different datasets for train-
ing, using or not slang replacement and gener-
alizing sentiment-bearing terms by replacing
them with unique labels.
The results regarding tweet classification are
promising and show that sentiment generaliza-
tion can be an effective approach for tweets
and that SMS language is difficult to tackle,
even when specific normalization resources
are employed.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985473684211">
Sentiment analysis is the Natural Language Process-
ing (NLP) task dealing with the detection and clas-
sification of sentiments in texts. Usually, the classes
considered are “positive”, “negative” and “neutral”,
although in some cases finer-grained categories are
added (e.g. “very positive” and “very negative”) or
only the “positive” and “negative” classes are taken
into account.
This task has received a lot of interest from the re-
search community in the past years. The work done
regarded the manner in which sentiment can be clas-
sified from texts pertaining to different genres and
distinct languages, in the context of various applica-
tions, using knowledge-based, semi-supervised and
supervised methods [Pang and Lee, 2008]. The re-
sult of the analyses performed have shown that the
different types of text require specialized methods
for sentiment analysis, as, for example, sentiments
are not conveyed in the same manner in newspaper
articles and in blogs, reviews, forums or other types
of user-generated contents [Balahur et al., 2010].
In the light of these findings, dealing with senti-
ment analysis in tweets and SMS (that we can gener-
ally call “short informal texts”) requires an analysis
of the characteristics of such texts and the design of
adapted methods.
Our participation in the SemEval 2013 Task 2
[Wilson et al., 2013] had as objective to test how
well our proposed methods for sentiment analysis
for short informal texts (especially tweets) would
perform. The two subtasks proposed in this com-
petition were: a) the classification of sentiment from
snippets from tweets and SMS marked as start and
end position and b) the classification of sentiment
from entire tweets and SMS. Each team could sub-
mit 2 runs for each dataset and task, one employ-
ing as training data only the data provided within
the competition (“constrained”) and the second em-
</bodyText>
<page confidence="0.981336">
460
</page>
<bodyText confidence="0.986525636363636">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 460–465, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
ploying any additional data (“unconstrained”). We
submitted 2 of such runs for each of the subtasks
and datasets.
The main requirements for the system we imple-
mented were: a) not to use language-specific NLP
processing tools (since our final goal is to make the
present system work for many more languages); and
b) to work fast, so that it can be integrated in a near
real time media monitoring system.
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="related work">
2 Related Work and Contribution
</sectionHeader>
<bodyText confidence="0.999884633333333">
One of the first studies on the classification of polar-
ity in tweets was Go et al. [2009]. The authors con-
ducted a supervised classification study on tweets
in English, using the emoticons (e.g. “:)”, “:(”,
etc.) as markers of positive and negative tweets.
Read [2005] employed this method to generate a
corpus of positive tweets, with positive emoticons
“:)”, and negative tweets with negative emoticons
“:(”. Subsequently, they employ different supervised
approaches (SVM, Naive Bayes and Maximum En-
tropy) and various sets of features and conclude that
the simple use of unigrams leads to good results, but
it can be slightly improved by the combination of
unigrams and bigrams.
In the same line of thinking, Pak and Paroubek
[2010] also generated a corpus of tweets for sen-
timent analysis, by selecting positive and negative
tweets based on the presence of specific emoticons.
Subsequently, they compare different supervised ap-
proaches with n-gram features and obtain the best
results using Naive Bayes with unigrams and part-
of-speech tags.
Another approach on sentiment analysis in tweet
is that of Zhang et al. [2011]. Here, the authors em-
ploy a hybrid approach, combining supervised learn-
ing with the knowledge on sentiment-bearing words,
which they extract from the DAL sentiment dictio-
nary [Whissell, 1989]. Their pre-processing stage
includes the removal of retweets, translation of ab-
breviations into original terms and deleting of links,
a tokenization process, and part-of-speech tagging.
They employ various supervised learning algorithms
to classify tweets into positive and negative, using n-
gram features with SVM and syntactic features with
Partial Tree Kernels, combined with the knowledge
on the polarity of the words appearing in the tweets.
The authors conclude that the most important fea-
tures are those corresponding to sentiment-bearing
words. Finally, Jiang et al. [2011] classify sentiment
expressed on previously-given “targets” in tweets.
They add information on the context of the tweet to
its text (e.g. the event that it is related to). Subse-
quently, they employ SVM and General Inquirer and
perform a three-way classification (positive, nega-
tive, neutral).
The main contributions of the approaches con-
sidered for the competition reside in the evaluation
of different strategies to adapt sentiment analysis
methods to the language employed in short informal
texts.
The methods employed in our system are simple,
work fast and efficient and can be easily adapted
to other languages. The main adaptations we con-
sider are part of a pre-processing step, in which the
language in these short informal texts is normalized
(brought to a dictionary form).
Finally, the methods presented are compared on
different configurations and training sets, so that the
conclusions drawn are relevant to the phenomena
found in this type of informal texts.
</bodyText>
<sectionHeader confidence="0.737162" genericHeader="method">
3 Methods Employed by OPTWIMA in
SemEval 2013 Task 2
</sectionHeader>
<bodyText confidence="0.999897222222222">
We employ two different approaches: a) one
based on supervised learning using Support Vector
Machines Sequential Minimal Optimization (SVM
SMO) using unigram and bigram features; and b) a
hybrid approach, based on supervised learning with
a SVM SMO linear kernel, on unigram and bigram
features, but exploiting as features sentiment dictio-
naries, emoticon lists, slang lists and other social
media-specific features. SVM SMO was preferred
due to the computation speed. We do not employ
any specific language analysis software. The aim
is to be able to apply, in a straightforward manner,
the same approach to as many languages as possible.
The approach can be extended to other languages by
using similar dictionaries that have been created in
our team Steinberger et al. [2011].
The sentiment analysis process contains two
stages: preprocessing and sentiment classification.
</bodyText>
<page confidence="0.997069">
461
</page>
<subsectionHeader confidence="0.999606">
3.1 Preprocessing of Short Informal Texts
</subsectionHeader>
<bodyText confidence="0.999911964285714">
The language employed in short informal texts such
as tweets and SMS is different from the one found
in other types of texts, such as newspaper articles
and the form of the words employed is sometimes
not the one we may find in a dictionary. Further
on, users writing on Twitter or SMS-ing on their
cell phone employ a special “slang” (i.e. informal
language, with special expressions, such as “lol”,
“omg”), emoticons, and often emphasize words by
repeating some of their letters. Additionally, the lan-
guage employed in Twitter has specific characteris-
tics, such as the markup of tweets that were reposted
by other users with “RT”, the markup of topics us-
ing the “#” (hash sign) and of the users using the
“@” sign.
All these aspects must be considered at the time
of processing tweets and, to some extent, SMS.
As such, before applying supervised learning to
classify the sentiment of the short informal texts
considered, we preprocess them, to normalize the
language they contain and try to abstract on the con-
cepts that are sentiment-bearing, by replacing them
with labels, according to their polarity&apos;. In case of
SMS messages, the slang employed, the short forms
of words and the acronyms make these texts non pro-
cessable without prior replacement and normaliza-
tion of the slang. The preprocessing stage contains
the following steps:
</bodyText>
<listItem confidence="0.9392585">
• Repeated punctuation sign normalization
(RPSN).
</listItem>
<bodyText confidence="0.994337571428571">
In the first step of the preprocessing, we detect
repetitions of punctuation signs (“.”, “!” and
“?”). Multiple consecutive punctuation signs
are replaced with the labels “multistop”, for
the fullstops, “multiexclamation” in the case of
exclamation sign and “multiquestion” for the
question mark and spaces before and after.
</bodyText>
<listItem confidence="0.92707">
• Emoticon replacement (ER).
</listItem>
<bodyText confidence="0.936548333333333">
In the second step of the preprocessing, we em-
ploy the annotated list of emoticons from Sen-
tiStrength2 and match the content of the tweets
</bodyText>
<footnote confidence="0.72264925">
&apos;The preprocessing steps involving the use of affect dictio-
naries and modifier replacement are used only in one of the two
methods considered
2http://sentistrength.wlv.ac.uk/
</footnote>
<bodyText confidence="0.970778">
against this list. The emoticons found are re-
placed with their polarity (“positive” or “nega-
tive”) and the “neutral” ones are deleted.
</bodyText>
<listItem confidence="0.986251">
• Lower casing and tokenization (LCN).
</listItem>
<bodyText confidence="0.968245333333333">
Subsequently, the tweets are lower cased and
split into tokens, based on spaces and punctua-
tion signs.
</bodyText>
<listItem confidence="0.980638">
• Slang replacement (SR).
</listItem>
<bodyText confidence="0.999864">
The next step involves the normalization of the
language employed. In order to be able to
include the semantics of the expressions fre-
quently used in Social Media, we employed the
list of slang expressions from dedicated sites 3.
This step is especially relevant to SMS texts,
whose language in their original form has little
to do with language employed in ordinary texts.
</bodyText>
<listItem confidence="0.996425">
• Word normalization (WN).
</listItem>
<bodyText confidence="0.967827875">
At this stage, the tokens are compared to entries
in Roget’s Thesaurus. If no match is found, re-
peated letters are sequentially reduced to two or
one until a match is found in the dictionary (e.g.
“perrrrrrrrrrrrrrrrrrfeeect” becomes “perrfeect”,
“perfeect”, “perrfect” and subsequently “per-
fect”). The words used in this form are maked
as “stressed”.
</bodyText>
<listItem confidence="0.915731">
• Affect word matching (AWM).
</listItem>
<bodyText confidence="0.99955675">
Further on, the tokens in the tweet are matched
against three different sentiment lexicons: Gen-
eral Inquirer, LIWC and MicroWNOp, which
were previously split into four different cate-
gories (“positive”, “high positive”, “negative”
and “high negative”). Matched words are re-
placed with their sentiment label - i.e. “posi-
tive”, “negative”, “hpositive” and “hnegative”.
</bodyText>
<listItem confidence="0.792324">
• Modifier word matching (MWM).
</listItem>
<bodyText confidence="0.999856">
Similar to the previous step, we employ a list
of expressions that negate, intensify or dimin-
ish the intensity of the sentiment expressed to
detect such words in the tweets. If such a word
is matched, it is replaced with “negator”, “in-
tensifier” or “diminisher”, respectively.
</bodyText>
<footnote confidence="0.982424">
3www.noslang.com/dictionary, www.smsslang.com
</footnote>
<page confidence="0.997697">
462
</page>
<listItem confidence="0.978884">
• User and topic labeling (UTL).
</listItem>
<bodyText confidence="0.99994925">
Finally, the users mentioned in the tweet, which
are marked with “@”, are replaced with “PER-
SON” and the topics which the tweet refers to
(marked with “#”) are replaced with “TOPIC”.
</bodyText>
<subsectionHeader confidence="0.9916215">
3.2 Sentiment Classification of Short Informal
Texts
</subsectionHeader>
<bodyText confidence="0.999941578947368">
Once the texts are preprocessed, they are passed on
to the sentiment classification module.
We employed supervised learning using Support
Vector Machines Sequential Minimal Optimization
(SVM SMO) [Platt, 1998] with a linear kernel, em-
ploying boolean features - the presence or absence
of unigrams and bigrams determined from the train-
ing data (tweets that were previousely preprocessed
as described above) that appeared at least twice. Bi-
grams are used especially to spot the influence of
modifiers (negations, intensifiers, diminishers) on
the polarity of the sentiment-bearing words. We
tested different parameters for the kernel and modi-
fied only the C constant to the best value determined
on the training data (5.0)/
We tested the approach on different datasets and
dataset splits, using the Weka data mining software
4. The training models are built on a cluster of com-
puters (4 cores, 5000MB of memory each).
</bodyText>
<sectionHeader confidence="0.996061" genericHeader="evaluation">
4 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.978140117647059">
We participated in SemEval 2013 in Task 2 with
two versions of the system, for each of the two sub-
tasks (A and B). The main difference among them is
the use of dictionaries for affect and modifier word
matching and replacement. As such, in the first
method (denoted as “Dict”), we perform all the pre-
processing steps mentioned above, while the second
method is applied on the data on which the AWM
and MWM are not performed (i.e. words that are
associated with a sentiment in a lexicon are not re-
placed with labels). This second method will be de-
noted “NoDict”.
Another difference between the different evalu-
ations we performed are the datasets employed for
training. We created different models, employing:
1) For both the “Constrained” and “Uncon-
strained” submissions, the development and train-
</bodyText>
<footnote confidence="0.83717">
4http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<bodyText confidence="0.997708285714286">
ing data from the corresponding subtask (i.e. using
as training the data in subtask A - the sets given as
training and development together - to train a classi-
fier for the test data in task A; the same for subtask
B). In this case, the training data is marked with the
corresponding subtask (i.e. training data “A”, train-
ing data “B”);
</bodyText>
<listItem confidence="0.914981428571429">
2) For both the “Constrained” and “Uncon-
strained” submissions, the development and training
data from both subtasks - both training and develop-
ment sets - to train one classifier which is used for
both subtasks. This training set is denoted as “A+B”;
3) For the “Unconstrained” submissions, we
added to the joint training and development data
from both subtasks the set of MySpace comments
provided by [Thelwall et al., 2010]. This small set
contains 1300 short texts from the MySpace social
network5. The motivation behind this choice is that
texts from this source are very similar in language
and structure to tweets and (after slang replacement)
SMS.
</listItem>
<bodyText confidence="0.99996212">
Finally, we trained different classifiers on the
training sets described, with and without replacing
the affective and modifier words and with and with-
out employing the slang replacement pre-processing
step.
The results are presented in Tables 1, 2, 3, 4, in
terms of average F-measure of the positive and neg-
ative classes (as used by the organizers). The runs
submitted in the competition are marked with an as-
terisk (“*”). We did not perform all the experiments
for the sets of SMS without slang replacement, as
the first results were very low.
As we can see from the results, our approach per-
formed better in classifying the overall sentiment of
texts than small snippets. The results were signifi-
cantly better for the classification of tweets in com-
parison to SMS, whose language (even with slang
replacement) made them difficult to tackle. We can
also see that the joint use of slang replacement and
dictionaries for tweets leads to significantly lower
results, meaning that this step (at least with the re-
sources we employed for slang treatment), is not
necessary for the treatment of tweets. Instead, for
these texts, the use of affect dictionaries and mod-
ifier lists and their generalizaton lead to better re-
</bodyText>
<footnote confidence="0.982757">
5http://www.myspace.com/
</footnote>
<page confidence="0.997961">
463
</page>
<table confidence="0.9991245">
Trained on A+B with slang replacement (Constrained)
Test set Dict NoDict
Task A Tweets 0.35 0.37
Task A SMS 0.35 0.37*
Task B Tweets 0.45* 0.54
Task B SMS 0.40* 0.47
</table>
<tableCaption confidence="0.999001">
Table 1: Results obtained using A+B (train and developement data) as training set and replacing the slang.
</tableCaption>
<table confidence="0.9981955">
Trained on A+B+MySpace with slang replacement (Unconstrained)
Test Set Dict NoDict
Task A Tweets 0.36 0.39*
Task A SMS 0.37* 0.37
Task B Tweets 0.46 0.54*
Task B SMS 0.40 0.37*
</table>
<tableCaption confidence="0.99985">
Table 2: Results obtained using A+B+MySpace (train and developement data) as training set and replacing the slang.
</tableCaption>
<bodyText confidence="0.999939142857143">
sults. This proves that such a generalization, in the
context of “legible” texts, is a useful tool for senti-
ment analysis. Further on, the results showed that
adding a small quantity of training data led to no
significant growth in performance (for the data in
which slang was replaced). Additional evaluations
could be made to quantify the effect of this data
when other methods to generalize are not applied.
As an observation, our results were balanced for all
three classes, with even higher scores for the neutral
class. We believe this class should have been con-
sidered as well, since in real-world settings systems
for sentiment analysis must also be able to classify
texts pertaining to this category.
Finally, we can see that in the case of SMS, the
difference between the use of slang with or without
affect label generalizations is insignificant. We be-
lieve this is due to the fact that the expressions with
which the slang is replaced are very infrequent in
traditional sentiment dictionaries (such as the ones
we employed). Even by replacing the short forms
and slang with their equivalents, the texts obtained
contain words that are infrequent in other types of
texts, even tweets. However, we will perform addi-
tional experiments with other lists of slang and add,
as much as it is possible, the informal sentiment-
bearing expressions to create new affect resources
for this types of texts.
</bodyText>
<sectionHeader confidence="0.999324" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999961857142857">
In this article, we presented and evaluated the ap-
proaches considered for our participation in the Se-
mEval 2013 Task 2. We evaluated different com-
binations of features, resources and training sets
and applied different methods to tackle the issues
brought by the informal language used in tweets and
SMS.
As future work, we would like to extend the sys-
tem to more languages, using the dictionaries cre-
ated by Steinberger et al. [2011] and analyze and in-
clude new features that are particular to social media
- especially tweets - to improve the performance of
the sentiment analysis component. Further on, we
would like to quantify the influence of using linguis-
tic processing tools to perform lemmatizing, POS-
tagging and the inclusion of corresponding features
on the final performance of the system. Finally, we
would like to explore additional resources to deal
with the issue of language informality in tweets and
further explore the problems posed by the peculiar
language employed in SMS.
</bodyText>
<sectionHeader confidence="0.995515" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.77625975">
Alexandra Balahur, Ralf Steinberger, Mijail Kabad-
jov, Vanni Zavarella, Erik van der Goot, Matina
Halkia, Bruno Pouliquen, and Jenya Belyaeva.
Sentiment analysis in the news. In Proceedings
</reference>
<page confidence="0.998476">
464
</page>
<table confidence="0.999337">
Trained on data of subtask (A or B) with slang replacement
Test Set Dict NoDict
Task A Tweets 0.36 0.37
Task A SMS 0.36 0.37
Task B Tweets 0.5 0.55
Task B SMS 0.49 0.53
</table>
<tableCaption confidence="0.974076">
Table 3: Results obtained using A (train and developement data) or B (train and developement data) as training set and
replacing the slang.
</tableCaption>
<table confidence="0.99896625">
Trained on data of subtask (A or B), no slang replacement Trained on A+B, no slang replacement
Test Set Dict NoDict Dict NoDict
Task A Tweets 0.69* 0.59 0.6 0.69
Task B Tweets 0.59 0.51 0.62 0.44
</table>
<tableCaption confidence="0.999601">
Table 4: Results obtained for tweet classification using A+B or A or B as training set and not replacing the slang.
</tableCaption>
<reference confidence="0.999123620689655">
of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC’10), Val-
letta, Malta, may 2010.
Alec Go, Richa Bhayani, and Lei Huang. Twitter
sentiment classification using distant supervision.
Processing, pages 1–6, 2009.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. Target-dependent twitter sentiment
classification. In Proceedings of the 49th An-
nual Meeting of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies, HLT ’11, pages 151–160. ACL, 2011. ISBN
978-1-932432-87-9.
Alexander Pak and Patrick Paroubek. Twitter as a
corpus for sentiment analysis and opinion min-
ing. In Proceedings of the Seventh conference
on International Language Resources and Eval-
uation (LREC’10), Valletta, Malta; ELRA, may
2010. ELRA. ISBN 2-9517408-6-7. 19-21.
Bo Pang and Lillian Lee. Opinion mining and sen-
timent analysis. Found. Trends Inf. Retr., 2(1-2):
1–135, January 2008. ISSN 1554-0669.
John C. Platt. Sequential minimal optimization:
A fast algorithm for training support vector ma-
chines. Technical report, Advances in Kernel
Methods - Support Vector Learning, 1998.
Jonathon Read. Using emoticons to reduce depen-
dency in machine learning techniques for senti-
ment classification. In Proceedings of the ACL
Student Research Workshop, ACLstudent ’05,
pages 43–48, Stroudsburg, PA, USA, 2005.
J. Steinberger, P. Lenkova, M. Ebrahim,
M. Ehrmann, A. Hurriyetoglu, M. Kabad-
jov, R. Steinberger, H. Tanev, V. Zavarella, and
S. V´azquez. Creating sentiment dictionaries via
triangulation. In Proceedings of WASSA 2011,
WASSA ’11, pages 28–36. ACL, 2011.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
Di Cai, and Arvid Kappas. Sentiment in short
strength detection informal text. Journal of the
American Society for Information Science and
Technology, 61(12):2544–2558, December 2010.
Cynthia Whissell. The Dictionary of Affect in Lan-
guage. In Robert Plutchik and Henry Kellerman,
editors, Emotion: theory, research and experi-
ence, volume 4, The measurement of emotions.
Academic Press, London, 1989.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,
Sara Rosenthal, Veselin Stoyanov, and Alan Rit-
ter. SemEval-2013 task 2: Sentiment analysis in
twitter. In Proceedings of the International Work-
shop on Semantic Evaluation, SemEval ’13, June
2013.
Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil,
Meichun Hsu, and Bing Liu. Combining lexicon-
based and learning-based methods for twitter sen-
timent analysis. Technical Report HPL-2011-89,
HP, 21/06/2011 2011.
</reference>
<page confidence="0.999592">
465
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.204324">
<title confidence="0.77062575">OPTWIMA: Comparing Knowledge-rich and Knowledge-poor Approaches for Sentiment Analysis in Short Informal Texts Alexandra European Commission Joint Research</title>
<author confidence="0.974624">Via E Fermi</author>
<address confidence="0.479863">21027 Ispra (VA),</address>
<abstract confidence="0.992050448275862">The fast development of Social Media made it possible for people to no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This phenomenon is of high importance to news monitoring systems, whose aim is to obtain an informative snapshot of media events and related comments. This paper presents the strategies employed in the OPTWIMA participation to SemEval 2013 Task 2-Sentiment Analysis in Twitter. The main goal was to evaluate the best settings for a sentiment analysis component to be added to the online news monitoring system. We describe the approaches used in the competition and the additional experiments performed combining different datasets for training, using or not slang replacement and generalizing sentiment-bearing terms by replacing them with unique labels. The results regarding tweet classification are promising and show that sentiment generalization can be an effective approach for tweets and that SMS language is difficult to tackle, even when specific normalization resources are employed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandra Balahur</author>
<author>Ralf Steinberger</author>
<author>Mijail Kabadjov</author>
<author>Vanni Zavarella</author>
<author>Erik van der Goot</author>
<author>Matina Halkia</author>
<author>Bruno Pouliquen</author>
<author>Jenya Belyaeva</author>
</authors>
<title>Sentiment analysis in the news.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta, Malta,</location>
<marker>Balahur, Steinberger, Kabadjov, Zavarella, van der Goot, Halkia, Pouliquen, Belyaeva, 2010</marker>
<rawString>Alexandra Balahur, Ralf Steinberger, Mijail Kabadjov, Vanni Zavarella, Erik van der Goot, Matina Halkia, Bruno Pouliquen, and Jenya Belyaeva. Sentiment analysis in the news. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta, may 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>Processing,</booktitle>
<pages>1--6</pages>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. Twitter sentiment classification using distant supervision. Processing, pages 1–6, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11,</booktitle>
<pages>151--160</pages>
<publisher>ACL,</publisher>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, HLT ’11, pages 151–160. ACL, 2011. ISBN 978-1-932432-87-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a corpus for sentiment analysis and opinion mining.</title>
<date>2010</date>
<journal>ELRA. ISBN</journal>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>2--9517408</pages>
<location>Valletta, Malta; ELRA,</location>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta; ELRA, may 2010. ELRA. ISBN 2-9517408-6-7. 19-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--135</pages>
<contexts>
<context position="2177" citStr="Pang and Lee, 2008" startWordPosition="325" endWordPosition="328">on of sentiments in texts. Usually, the classes considered are “positive”, “negative” and “neutral”, although in some cases finer-grained categories are added (e.g. “very positive” and “very negative”) or only the “positive” and “negative” classes are taken into account. This task has received a lot of interest from the research community in the past years. The work done regarded the manner in which sentiment can be classified from texts pertaining to different genres and distinct languages, in the context of various applications, using knowledge-based, semi-supervised and supervised methods [Pang and Lee, 2008]. The result of the analyses performed have shown that the different types of text require specialized methods for sentiment analysis, as, for example, sentiments are not conveyed in the same manner in newspaper articles and in blogs, reviews, forums or other types of user-generated contents [Balahur et al., 2010]. In the light of these findings, dealing with sentiment analysis in tweets and SMS (that we can generally call “short informal texts”) requires an analysis of the characteristics of such texts and the design of adapted methods. Our participation in the SemEval 2013 Task 2 [Wilson et</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2): 1–135, January 2008. ISSN 1554-0669.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Sequential minimal optimization: A fast algorithm for training support vector machines.</title>
<date>1998</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning,</booktitle>
<tech>Technical report,</tech>
<contexts>
<context position="12193" citStr="Platt, 1998" startWordPosition="1911" endWordPosition="1912">atched, it is replaced with “negator”, “intensifier” or “diminisher”, respectively. 3www.noslang.com/dictionary, www.smsslang.com 462 • User and topic labeling (UTL). Finally, the users mentioned in the tweet, which are marked with “@”, are replaced with “PERSON” and the topics which the tweet refers to (marked with “#”) are replaced with “TOPIC”. 3.2 Sentiment Classification of Short Informal Texts Once the texts are preprocessed, they are passed on to the sentiment classification module. We employed supervised learning using Support Vector Machines Sequential Minimal Optimization (SVM SMO) [Platt, 1998] with a linear kernel, employing boolean features - the presence or absence of unigrams and bigrams determined from the training data (tweets that were previousely preprocessed as described above) that appeared at least twice. Bigrams are used especially to spot the influence of modifiers (negations, intensifiers, diminishers) on the polarity of the sentiment-bearing words. We tested different parameters for the kernel and modified only the C constant to the best value determined on the training data (5.0)/ We tested the approach on different datasets and dataset splits, using the Weka data m</context>
</contexts>
<marker>Platt, 1998</marker>
<rawString>John C. Platt. Sequential minimal optimization: A fast algorithm for training support vector machines. Technical report, Advances in Kernel Methods - Support Vector Learning, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathon Read</author>
</authors>
<title>Using emoticons to reduce dependency in machine learning techniques for sentiment classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Student Research Workshop, ACLstudent ’05,</booktitle>
<pages>43--48</pages>
<location>Stroudsburg, PA, USA,</location>
<marker>Read, 2005</marker>
<rawString>Jonathon Read. Using emoticons to reduce dependency in machine learning techniques for sentiment classification. In Proceedings of the ACL Student Research Workshop, ACLstudent ’05, pages 43–48, Stroudsburg, PA, USA, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>P Lenkova</author>
<author>M Ebrahim</author>
<author>M Ehrmann</author>
<author>A Hurriyetoglu</author>
<author>M Kabadjov</author>
<author>R Steinberger</author>
<author>H Tanev</author>
<author>V Zavarella</author>
<author>S V´azquez</author>
</authors>
<title>Creating sentiment dictionaries via triangulation.</title>
<date>2011</date>
<booktitle>In Proceedings of WASSA 2011, WASSA ’11,</booktitle>
<pages>28--36</pages>
<publisher>ACL,</publisher>
<marker>Steinberger, Lenkova, Ebrahim, Ehrmann, Hurriyetoglu, Kabadjov, Steinberger, Tanev, Zavarella, V´azquez, 2011</marker>
<rawString>J. Steinberger, P. Lenkova, M. Ebrahim, M. Ehrmann, A. Hurriyetoglu, M. Kabadjov, R. Steinberger, H. Tanev, V. Zavarella, and S. V´azquez. Creating sentiment dictionaries via triangulation. In Proceedings of WASSA 2011, WASSA ’11, pages 28–36. ACL, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
<author>Arvid Kappas</author>
</authors>
<title>Sentiment in short strength detection informal text.</title>
<date>2010</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, Kappas, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, Di Cai, and Arvid Kappas. Sentiment in short strength detection informal text. Journal of the American Society for Information Science and Technology, 61(12):2544–2558, December 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Whissell</author>
</authors>
<title>The Dictionary of Affect in Language.</title>
<date>1989</date>
<volume>volume</volume>
<editor>In Robert Plutchik and Henry Kellerman, editors, Emotion: theory, research and experience,</editor>
<publisher>Academic Press,</publisher>
<location>London,</location>
<contexts>
<context position="5318" citStr="Whissell, 1989" startWordPosition="833" endWordPosition="834">f thinking, Pak and Paroubek [2010] also generated a corpus of tweets for sentiment analysis, by selecting positive and negative tweets based on the presence of specific emoticons. Subsequently, they compare different supervised approaches with n-gram features and obtain the best results using Naive Bayes with unigrams and partof-speech tags. Another approach on sentiment analysis in tweet is that of Zhang et al. [2011]. Here, the authors employ a hybrid approach, combining supervised learning with the knowledge on sentiment-bearing words, which they extract from the DAL sentiment dictionary [Whissell, 1989]. Their pre-processing stage includes the removal of retweets, translation of abbreviations into original terms and deleting of links, a tokenization process, and part-of-speech tagging. They employ various supervised learning algorithms to classify tweets into positive and negative, using ngram features with SVM and syntactic features with Partial Tree Kernels, combined with the knowledge on the polarity of the words appearing in the tweets. The authors conclude that the most important features are those corresponding to sentiment-bearing words. Finally, Jiang et al. [2011] classify sentimen</context>
</contexts>
<marker>Whissell, 1989</marker>
<rawString>Cynthia Whissell. The Dictionary of Affect in Language. In Robert Plutchik and Henry Kellerman, editors, Emotion: theory, research and experience, volume 4, The measurement of emotions. Academic Press, London, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
</authors>
<title>SemEval-2013 task 2: Sentiment analysis in twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<contexts>
<context position="2787" citStr="Wilson et al., 2013" startWordPosition="426" endWordPosition="429">Lee, 2008]. The result of the analyses performed have shown that the different types of text require specialized methods for sentiment analysis, as, for example, sentiments are not conveyed in the same manner in newspaper articles and in blogs, reviews, forums or other types of user-generated contents [Balahur et al., 2010]. In the light of these findings, dealing with sentiment analysis in tweets and SMS (that we can generally call “short informal texts”) requires an analysis of the characteristics of such texts and the design of adapted methods. Our participation in the SemEval 2013 Task 2 [Wilson et al., 2013] had as objective to test how well our proposed methods for sentiment analysis for short informal texts (especially tweets) would perform. The two subtasks proposed in this competition were: a) the classification of sentiment from snippets from tweets and SMS marked as start and end position and b) the classification of sentiment from entire tweets and SMS. Each team could submit 2 runs for each dataset and task, one employing as training data only the data provided within the competition (“constrained”) and the second em460 Second Joint Conference on Lexical and Computational Semantics (*SEM</context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Rosenthal, Stoyanov, Ritter, 2013</marker>
<rawString>Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter. SemEval-2013 task 2: Sentiment analysis in twitter. In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13, June 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ley Zhang</author>
<author>Riddhiman Ghosh</author>
<author>Mohamed Dekhil</author>
<author>Meichun Hsu</author>
<author>Bing Liu</author>
</authors>
<title>Combining lexiconbased and learning-based methods for twitter sentiment analysis.</title>
<date>2011</date>
<tech>Technical Report HPL-2011-89, HP,</tech>
<pages>21--06</pages>
<marker>Zhang, Ghosh, Dekhil, Hsu, Liu, 2011</marker>
<rawString>Ley Zhang, Riddhiman Ghosh, Mohamed Dekhil, Meichun Hsu, and Bing Liu. Combining lexiconbased and learning-based methods for twitter sentiment analysis. Technical Report HPL-2011-89, HP, 21/06/2011 2011.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>