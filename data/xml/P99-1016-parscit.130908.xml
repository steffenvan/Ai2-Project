<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.084857">
<title confidence="0.871788333333333">
Automatic construction of a hypernym-labeled noun hierarchy
from text
Sharon A. Caraballo
</title>
<affiliation confidence="0.9650835">
Dept. of Computer Science
Brown University
</affiliation>
<address confidence="0.909966">
Providence, RI 02912
</address>
<email confidence="0.999191">
sc@cs.brown.edu
</email>
<sectionHeader confidence="0.993995" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999637571428572">
Previous work has shown that automatic
methods can be used in building semantic
lexicons. This work goes a step further by
automatically creating not just clusters of
related words, but a hierarchy of nouns and
their hypernyms, akin to the hand-built hi-
erarchy in WordNet.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997515">
The purpose of this work is to build some-
thing like the hypernym-labeled noun hierar-
chy of WordNet (Fellbaum, 1998) automat-
ically from text using no other lexical re-
sources. WordNet has been an important re-
search tool, but it is insufficient for domain-
specific text, such as that encountered in
the MUCs (Message Understanding Confer-
ences). Our work develops a labeled hierar-
chy based on a text corpus.
In this project, nouns are clustered into a
hierarchy using data on conjunctions and ap-
positives appearing in the Wall Street Jour-
nal. The internal nodes of the resulting
tree are then labeled with hypernyms for the
nouns clustered underneath them, also based
on data extracted from the Wall Street Jour-
nal. The resulting hierarchy is evaluated by
human judges, and future research directions
are discussed.
</bodyText>
<sectionHeader confidence="0.821413" genericHeader="introduction">
2 Building the noun hierarchy
</sectionHeader>
<bodyText confidence="0.992159243902439">
The first stage in constructing our hierar-
chy is to build an unlabeled hierarchy of
nouns using bottom-up clustering methods
(see, e.g., Brown et al. (1992)). Nouns are
clustered based on conjunction and apposi-
tive data collected from the Wall Street Jour-
nal corpus. Some of the data comes from the
parsed files 2-21 of the Wall Street Journal
Penn Treebank corpus (Marcus et al., 1993),
and additional parsed text was obtained by
parsing the 1987 Wall Street Journal text us-
ing the parser described in Charniak et al.
(1998).
From this parsed text, we identified all
conjunctions of noun phrases (e.g., &amp;quot;execu-
tive vice-president and treasurer&amp;quot; or &amp;quot;scien-
tific equipment, apparatus and disposables&amp;quot;)
and all appositives (e.g., &amp;quot;James H. Rosen-
field, a former CBS Inc. executive&amp;quot; or &amp;quot;Boe-
ing, a defense contractor&amp;quot;). The idea here
is that nouns in conjunctions or appositives
tend to be semantically related, as discussed
in Riloff and Shepherd (1997) and Roark and
Charniak (1998). Taking the head words of
each NP and stemming them results in data
for about 50,000 distinct nouns.
A vector is created for each noun contain-
ing counts for how many times each other
noun appears in a conjunction or appositive
with it. We can then measure the similarity
of the vectors for two nouns by computing
the cosine of the angle between these vec-
tors, as
11&apos;1iWr
To compare the similarity of two groups of
nouns, we define similarity as the average of
the cosines between each pair of nouns made
up of one noun from each of the two groups.
Ev cos (v, w)
size(A)size(B)
where v ranges over all vectors for nouns
</bodyText>
<equation confidence="0.996607333333333">
V • W
cos (v, w) =
sim(A, B) =
</equation>
<page confidence="0.932166">
120
</page>
<bodyText confidence="0.99889335">
in group A, w ranges over the vectors for
group B, and size(x) represents the number
of nouns which are descendants of node x.
We want to create a tree of all of the nouns
in this data using standard bottom-up clus-
tering techniques as follows: Put each noun
into its own node. Compute the similarity
between each pair of nodes using the cosine
method. Find the two most similar nouns
and combine them by giving them a common
parent (and removing the child nodes from
future consideration). We can then compute
the new node&apos;s similarity to each other node
by computing a weighted average of the sim-
ilarities between each of its children and the
other node.
In other words, assuming nodes A and B
have been combined under a new parent C,
the similarity between C and any other node
i can be computed as
</bodyText>
<equation confidence="0.999636333333333">
sim(C , i) =
sim(A, i)size(A) + sim(B , i)size(B)
size(A) + size(B)
</equation>
<bodyText confidence="0.999331785714286">
Once again, we combine the two most sim-
ilar nodes under a common parent. Repeat
until all nouns have been placed under a
common ancestor.
Nouns which have a cosine of 0 with every
other noun are not included in the final tree.
In practice, we cannot follow exactly that
algorithm, because maintaining a list of the
cosines between every pair of nodes requires
a tremendous amount of memory. With
50,000 nouns, we would initially require a
50,000 x 50,000 array of values (or a trian-
gular array of about half this size). With
our current hardware, the largest array we
</bodyText>
<listItem confidence="0.625149666666667">
• can comfortably handle is about 100 times
smaller; that is, we can build a tree starting
from approximately 5,000 nouns.
</listItem>
<bodyText confidence="0.999893857142857">
The way we handled this limitation is to
process the nouns in batches. Initially 5,000
nouns are read in. We cluster these until we
have 2,500 nodes. Then 2,500 more nouns
are read in, to bring the total to 5,000 again,
and once again we cluster until 2,500 nodes
remain. This process is repeated until all
nouns have been processed.
Since the lowest-frequency nouns are clus-
tered based on very little information and
have a greater tendency to be clustered
badly, we chose to filter some of these out.
By reducing the number of nouns to be read,
a much nicer structure is obtained. We now
only consider nouns with a vector of length
at least 2.
There are approximately 20,000 nouns as
the leaves in our final binary tree structure.
Our next step is to try to label each of the
internal nodes with a hypernym describing
its descendant nouns.
</bodyText>
<sectionHeader confidence="0.953748" genericHeader="method">
3 Assigning hypernyms
</sectionHeader>
<bodyText confidence="0.9999318125">
Following WordNet, a word A is said to be
a hypernym of a word B if native speakers of
English accept the sentence &amp;quot;B is a (kind of)
A.&amp;quot;
To determine possible hypernyms for a
particular noun, we use the same parsed text
described in the previous section. As sug-
gested in Hearst (1992), we can find some
hypernym data in the text by looking for
conjunctions involving the word &amp;quot;other&amp;quot;, as
in &amp;quot;X, Y, and other Zs&amp;quot; (patterns 3 and 4
in Hearst). From this phrase we can extract
that Z is likely a hypernym for both X and
Y.
This data is extracted from the parsed
text, and for each noun we construct a vector
of hypernyms, with a value of 1 if a word has
been seen as a hypernym for this noun and 0
otherwise. These vectors are associated with
the leaves of the binary tree constructed in
the previous section.
For each internal node of the tree, we con-
struct a vector of hypernyms by adding to-
gether the vectors of its children. We then
assign a hypernym to this node by sim-
ply choosing the hypernym with the largest
value in this vector; that is, the hypernym
which appeared with the largest number of
the node&apos;s descendant nouns. (In case of
ties, the hypernyms are ordered arbitrarily.)
We also list the second- and third-best hy-
pernyms, to account for cases where a sin-
</bodyText>
<page confidence="0.990289">
121
</page>
<bodyText confidence="0.999958823529412">
gle word does not describe the cluster ad-
equately, or cases where there are a few
good hypernyms which tend to alternate,
such as &amp;quot;country&amp;quot; and &amp;quot;nation&amp;quot;. (There
may or may not be any kind of seman-
tic relationship among the hypernyms listed.
Because of the method of selecting hyper-
nyms, the hypernyms may be synonyms of
each other, have hypernym-hyponym rela-
tionships of their own, or be completely un-
related.) If a hypernym has occurred with
only one of the descendant nouns, it is not
listed as one of the best hypernyms, since
we have insufficient evidence that the word
could describe this class of nouns. Not ev-
ery node has sufficient data to be assigned a
hypernym.
</bodyText>
<sectionHeader confidence="0.972668" genericHeader="method">
4 Compressing the tree
</sectionHeader>
<bodyText confidence="0.999883633333334">
The labeled tree constructed in the previ-
ous section tends to be extremely redundant.
Recall that the tree is binary. In many cases,
a group of nouns really do not have an in-
herent tree structure, for example, a cluster
of countries. Although it is possible that a
reasonable tree structure could be created
with subtrees of, say, European countries,
Asian countries, etc., recall that we are us-
ing single-word hypernyms. A large binary
tree of countries would ideally have &amp;quot;coun-
try&amp;quot; (or &amp;quot;nation&amp;quot;) as the best hypernym at
every level. We would like to combine these
subtrees into a single parent labeled &amp;quot;coun-
try&amp;quot; or &amp;quot;nation&amp;quot;, with each country appear-
ing as a leaf directly beneath this parent.
(Obviously, the tree will no longer be bi-
nary).
Another type of redundancy can occur
when an internal node is unlabeled, meaning
a hypernym could not be found to describe
its descendant nouns. Since the tree&apos;s root is
labeled, somewhere above this node there is
necessarily a node labeled with a hypernym
which applies to its descendant nouns, in-
cluding those which are a descendant of this
node. We want to move this node&apos;s children
directly under the nearest labeled ancestor.
We compress the tree using the following
very simple algorithm: in depth-first order,
</bodyText>
<table confidence="0.99879225">
Hypernyms # nouns
vision 22
bank/group/bond 95
conductor 51
problem 151
apparel/clothing/knitwear 113
item/paraphernalia/car 226
felony/charge/activity 109
system 47
official/product/right 88
official/company/product 10,266
product/factor/service 6,056
agency/area 60
event/item 135
animal/group/people 188
country/nation/producer 348
product/item/crop 300
diversion 130
problem/drug/disorder 306
wildlife 35
</table>
<tableCaption confidence="0.999905">
Table 1: The children of the root node.
</tableCaption>
<bodyText confidence="0.999910666666667">
examine the children of each internal node.
If the child is itself an internal node, and
it either has no best hypernym or the same
three best hypernyms as its parent, delete
this child and make its children into children
of the parent instead.
</bodyText>
<sectionHeader confidence="0.997011" genericHeader="method">
5 Results and evaluation
</sectionHeader>
<bodyText confidence="0.999953210526316">
There are 20,014 leaves (nouns) and 654 in-
ternal nodes in the final tree (reduced from
20,013 internal nodes in the uncompressed
tree). The top-level node in our learned tree
is labeled &amp;quot;product/analyst/official&amp;quot; . (Re-
call from the previous discussion that we do
not assume any kind of semantic relation-
ship among the hypernyms listed for a par-
ticular cluster.) Since these hypernyms are
learned from the Wall Street Journal, they
are domain-specific labels rather than the
more general &amp;quot;thing/person&amp;quot;. However, if
the hierarchy were to be used for text from
the financial domain, these labels may be
preferred.
The next level of the hierarchy, the chil-
dren of the root, is as shown in Table 1.
(&amp;quot;Conductor&amp;quot; seems out-of-place on this list;
see the next section for discussion.) These
</bodyText>
<page confidence="0.990212">
122
</page>
<bodyText confidence="0.999358847058824">
numbers do not add up to 20,014 because
1,288 nouns are attached directly to the root,
meaning that they couldn&apos;t be clustered to
any greater level of detail. These tend to
be nouns for which little data was avail-
able, generally proper nouns (e.g., Reindel,
Yaghoubi, Igoe).
To evaluate the hierarchy, 10 internal
nodes dominating at least 20 nouns were se-
lected at random. For each of these nodes,
we randomly selected 20 of the nouns from
the cluster under that node. Three human
judges were asked to evaluate for each noun
and each of the (up to) three hypernyms
listed as &amp;quot;best&amp;quot; for that cluster, whether
they were actually in a hyponym-hypernym
relation. The judges were students working
in natural language processing or computa-
tional linguistics at our institution who were
not directly involved in the research for this
project. 5 &amp;quot;noise&amp;quot; nouns randomly selected
from elsewhere in the tree were also added
to each cluster without the judges&apos; knowl-
edge to verify that the judges were not overly
generous.
Some nouns, especially proper nouns, were
not recognized by the judges. For any
noun that was not evaluated by at least two
judges, we evaluated the noun/hypernym
pair by examining the appearances of that
noun in the source text and verifying that
the hypernym was correct for the predomi-
nant sense of the noun.
Table 2 presents the results of this eval-
uation. The table lists only results for the
actual candidate hyponym nouns, not the
noise words. The &amp;quot;Hypernym 1&amp;quot; column in-
dicates whether the &amp;quot;best&amp;quot; hypernym was
considered correct, while the &amp;quot;Any hyper-
nym&amp;quot; column indicates whether any of the
listed hypernyms were accepted. Within
those columns, &amp;quot;majority&amp;quot; lists the opinion
of the majority of judges, and &amp;quot;any&amp;quot; indi-
cates the hypernyms that were accepted by
even one of the judges.
The &amp;quot;Hypernym 1/any&amp;quot; column can be
used to compare results to Riloff and Shep-
herd (1997). For five hand-selected cate-
gories, each with a single hypernym, and the
20 nouns their algorithm scored as the best
members of each category, at least one judge
marked on average about 31% of the nouns
as correct. Using randomly-selected cate-
gories and randomly-selected category mem-
bers we achieved 39%.
By the strictest criteria, our algorithm
produces correct hyponyms for a randomly-
selected hypernym 33% of the time. Roark
and Charniak (1998) report that for a hand-
selected category, their algorithm generally
produces 20% to 40% correct entries.
Furthermore, if we loosen our criteria to
consider also the second- and third-best hy-
pernyms, 60% of the nouns evaluated were
assigned to at least one correct hypernym
according to at least one judge.
The &amp;quot;bank/firm/station&amp;quot; cluster consists
largely of investment firms, which were
marked as incorrect for &amp;quot;bank&amp;quot;, resulting in
the poor performance on the Hypernym 1
measures for this cluster. The last cluster
in the list, labeled &amp;quot;company&amp;quot;, is actually a
very good cluster of cities that because of
sparse data was assigned a poor hypernym.
Some of the suggestions in the following sec-
tion might correct this problem.
Of the 50 noise words, a few of them were
actually rated as correct as well, as shown in
Table 3.
This is largely because the noise words
were selected truly at random, so that a
noise word for the &amp;quot;company&amp;quot; cluster may
not have been in that particular cluster but
may still have appeared under a &amp;quot;company&amp;quot;
hypernym elsewhere in the hierarchy.
</bodyText>
<sectionHeader confidence="0.98718" genericHeader="method">
6 Discussion and future
directions
</sectionHeader>
<bodyText confidence="0.999642909090909">
Future work should benefit greatly by using
data on the hypernyms of hypernyms. In our
current tree, the best hypernym for the en-
tire tree is &amp;quot;product&amp;quot;; however, many times
nodes deeper in the tree are given this la-
bel also. For example, we have a cluster
including many forms of currency, but be-
cause there is little data for these partic-
ular words, the only hypernym found was
&amp;quot;product&amp;quot;. However, the parent of this node
has the best hypernym of &amp;quot;currency&amp;quot;. If
</bodyText>
<page confidence="0.997145">
123
</page>
<table confidence="0.999566538461538">
Three best hypernyms Hypernym 1 Any hypernym
majority any majority any
worker/craftsmen/personnel 13 13 13 13
cost/expense/area 7 10 9 10
cost/operation/problem 6 8 11 17
legislation/measure/proposal 3 5 9 18
benefit/business/factor 2 2 2 5
factor 2 7 2 7
lawyer 14 14 14 14
firm/investor/analyst 13 13 14 14
bank/firm/station 0 0 15 17
company 6 6 6 6
AVERAGE 6.6 / 33.0% 7.8 / 39.0% 9.5 / 47.5% 12.1 / 60.5%
</table>
<tableCaption confidence="0.986352">
Table 2: The results of the judges&apos; evaluation.
</tableCaption>
<table confidence="0.946691">
Three best hypernyms Hypernym 1 Any hypernym
majority any majority any
noise words 1 / 2.0% 4 / 8.0% 2 / 4.0% 4 / 8.0%
</table>
<tableCaption confidence="0.999225">
Table 3: The results of the judges&apos; evaluation of noise words.
</tableCaption>
<bodyText confidence="0.999905535714286">
we knew that &amp;quot;product&amp;quot; was a hypernym of
&amp;quot;currency&amp;quot;, we could detect that the parent
node&apos;s label is more specific and simply ab-
sorb the child node into the parent. Fur-
thermore, we may be able to use data on
the hypernyms of hypernyms to give bet-
ter labels to some nodes that are currently
labeled simply with the best hypernyms of
their subtrees, such as a node labeled &amp;quot;prod-
uct/analyst&amp;quot; which has two subtrees, one la-
beled &amp;quot;product&amp;quot; and containing words for
things, the other labeled &amp;quot;analyst&amp;quot; and con-
taining names of people. We would like to
instead label this node something like &amp;quot;en-
tity&amp;quot;. It is not yet clear whether corpus data
will provide sufficient data for hypernyms at
such a high level of the tree, but depending
on the intended application for the hierarchy,
this level of generality might not be required.
As noted in the previous section, one ma-
jor spurious result is a cluster of 51 nouns,
mainly people, which is given the hypernym
&amp;quot;conductor&amp;quot;. The reason for this is that few
of the nouns appear with hypernyms, and
two of them (Giulini and Ozawa) appear in
the same phrase listing conductors, thus giv-
ing &amp;quot;conductor&amp;quot; a count of two, sufficient to
be listed as the only hypernym for the clus-
ter. It might be useful to have some stricter
criterion for hypernyms, say, that they oc-
cur with a certain percentage of the nouns
below them in the tree. Additional hyper-
nym data would also be helpful in this case,
and should be easily obtainable by looking
for other patterns in the text as suggested
by Hearst (1992).
Because the tree is built in a binary
fashion, when, e.g., three clusters should
all be distinct children of a common par-
ent, two of them must merge first, giving
an artificial intermediate level in the tree.
For example, in the current tree a cluster
with best hypernym &amp;quot;agency&amp;quot; and one with
best hypernym &amp;quot;exchange&amp;quot; (as in &amp;quot;stock ex-
change&amp;quot;) have a parent with two best hyper-
nyms &amp;quot;agency/exchange&amp;quot; , rather than both
of these nodes simply being attached to the
next level up with best hypernym &amp;quot;group&amp;quot;.
It might be possible to correct for this situa-
tion by comparing the hypernyms for the two
clusters and if there is little overlap, delet-
ing their parent node and attaching them to
their grandparent instead.
It would be useful to try to identify terms
made up of multiple words, rather than just
using the head nouns of the noun phrases.
</bodyText>
<page confidence="0.996556">
124
</page>
<bodyText confidence="0.999964542857143">
Not only would this provide a more Use-
ful hierarchy, or at least perhaps one that
is more useful for certain applications, but
it would also help to prevent some er-
rors. Hearst (1992) gives an example of
a potential hyponym-hypernym pair &amp;quot;bro-
ken bone/injury&amp;quot; . Using our algorithm, we
would learn that &amp;quot;injury&amp;quot; is a hypernym of
&amp;quot;bone&amp;quot;. Ideally, this would not appear in our
hierarchy since a more common hypernym
would be chosen instead, but it is possible
that in some cases a bad hypernym would
be found based on multiple word phrases. A
discussion of the difficulties in deciding how
much of a noun phrase to use can be found
in Hearst.
Ideally, a useful hierarchy should allow for
multiple senses of a word, and this is an area
which can be explored in future work. How-
ever, domain-specific text tends to greatly
constrain which senses of a word will appear,
and if the learned hierarchy is intended for
use with the same type of text from which it
was learned, it is possible that this would be
of limited benefit.
We used parsed text for these experiments
because we believed we would get better re-
sults and the parsed data was readily avail-
able. However, it would be interesting to
see if parsing is necessary or if we can get
equivalent or nearly-equivalent results doing
some simpler text processing, as suggested
in Ahlswede and Evens (1988). Both Hearst
(1992) and Riloff and Shepherd (1997) use
unparsed text.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="method">
7 Related work
</sectionHeader>
<bodyText confidence="0.99998882">
Pereira et al. (1993) used clustering to build
an unlabeled hierarchy of nouns. Their hier-
archy is constructed top-down, rather than
bottom-up, with nouns being allowed mem-
bership in multiple clusters. Their cluster-
ing is based on verb-object relations rather
than on the noun-noun relations that we use.
Future work on our project will include an
attempt to incorporate verb-object data as
well in the clustering process. The tree they
construct is also binary with some internal
nodes which seem to be &amp;quot;artificial&amp;quot;, but for
evaluation purposes they disregard the tree
structure and consider only the leaf nodes.
Unfortunately it is difficult to compare their
results to ours since their evaluation is based
on the verb-object relations.
Riloff and Shepherd (1997) suggested us-
ing conjunction and appositive data to clus-
ter nouns; however, they approximated this
data by just looking at the nearest NP on
each side of a particular NP. Roark and
Charniak (1998) built on that work by actu-
ally using conjunction and appositive data
for noun clustering, as we do here. (They
also use noun compound data, but in a sep-
arate stage of processing.) Both of these
projects have the goal of building a single
cluster of, e.g., vehicles, and both use seed
words to initialize a cluster with nouns be-
longing to it.
Hearst (1992) introduced the idea of learn-
ing hypernym-hyponym relationships from
text and gives several examples of patterns
that can be used to detect these relation-
ships including those used here, along with
an algorithm for identifying new patterns.
This work shares with ours the feature that
it does not need large amounts of data to
learn a hypernym; unlike in much statistical
work, a single occurrence is sufficient.
The hyponym-hypernym pairs found by
Hearst&apos;s algorithm include some that Hearst
describes as &amp;quot;context and point-of-view de-
pendent,&amp;quot; such as &amp;quot;Washington/nationalist&amp;quot;
and &amp;quot;aircraft/target&amp;quot; . Our work is some-
what less sensitive to this kind of problem
since only the most common hypernym of an
entire cluster of nouns is reported, so much
of the noise is filtered.
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.99994">
We have shown that hypernym hierarchies
of nouns can be constructed automati-
cally from text with similar performance
to semantic lexicons built automatically for
hand-selected hypernyms. With the addi-
tion of some improvements we have identi-
fied, we believe that these automatic meth-
ods can be used to construct truly useful hi-
erarchies. Since the hierarchy is learned from
</bodyText>
<page confidence="0.995005">
125
</page>
<bodyText confidence="0.999857">
sample text, it could be trained on domain-
specific text to create a hierarchy that is
more applicable to a particular domain than
a general-purpose resource such as WordNet.
</bodyText>
<sectionHeader confidence="0.996849" genericHeader="acknowledgments">
9 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999272142857143">
Thanks to Eugene Charniak for helpful dis-
cussions and for the data used in this project.
Thanks also to Brian Roark, Heidi J. Fox,
and Keith Hall for acting as judges in the
project evaluation. This research is sup-
ported in part by NSF grant IRI-9319516
and by ONR grant N0014-96-1-0549.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999569196078432">
Thomas Ahlswede and Martha Evens. 1988.
Parsing vs. text processing in the analysis
of dictionary definitions. In Proceedings of
the 29th Annual Meeting of the Associa-
tion for Computational Linguistics, pages
217-224.
Peter F. Brown, Vincent J. Della Pietra,
Peter V. DeSouza, Jennifer C. Lai, and
Robert L. Mercer. 1992. Class-based n-
gram models of natural language. Com-
putational Linguistics, 18:467-479.
Eugene Charniak, Sharon Goldwater, and
Mark Johnson. 1998. Edge-based best-
first chart parsing. In Proceedings of the
Sixth Workshop on Very Large Corpora,
pages 127-133. Association for Computa-
tional Linguistics.
Christiane Fellbaum, editor. 1998. Word-
Net: An Electronic Lexical Database. MIT
Press.
Marti A. Hearst. 1992. Automatic acquisi-
tion of hyponyms from large text corpora.
In Proceedings of the Fourteenth Interna-
tional Conference on Computational Lin-
guistics.
Mitchell P. Marcus, Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building
a large annotated corpus of English: the
Penn Treebank. Computational Linguis-
tics, 19:313-330.
Fernando Pereira, Naftali Tishby, and Lil-
lian Lee. 1993. Distributional clustering
of English words. In Proceedings of the
31st Annual Meeting of the Association
for Computational Linguistics, pages 183-
190.
Ellen Riloff and Jessica Shepherd. 1997.
A corpus-based approach for building se-
mantic lexicons. In Proceedings of the Sec-
ond Conference on Empirical Methods in
Natural Language Processing, pages 117-
124.
Brian Roark and Eugene Charniak. 1998.
Noun-phrase co-occurrence statistics for
semi-automatic semantic lexicon construc-
tion. In COLING-ACL &apos;98: 36th An-
nual Meeting of the Association for Com-
putational Linguistics and 17th Interna-
tional Conference on Computational Lin-
guistics: Proceedings of the Conference,
pages 1110-1116.
</reference>
<page confidence="0.998518">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.647195">
<title confidence="0.90843">Automatic construction of a hypernym-labeled noun hierarchy from text</title>
<author confidence="0.999897">Sharon A Caraballo</author>
<affiliation confidence="0.9999495">Dept. of Computer Science Brown University</affiliation>
<address confidence="0.970716">02912</address>
<email confidence="0.999794">sc@cs.brown.edu</email>
<abstract confidence="0.9729045">Previous work has shown that automatic methods can be used in building semantic lexicons. This work goes a step further by automatically creating not just clusters of related words, but a hierarchy of nouns and their hypernyms, akin to the hand-built hierarchy in WordNet.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thomas Ahlswede</author>
<author>Martha Evens</author>
</authors>
<title>Parsing vs. text processing in the analysis of dictionary definitions.</title>
<date>1988</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>217--224</pages>
<contexts>
<context position="18373" citStr="Ahlswede and Evens (1988)" startWordPosition="3175" endWordPosition="3178"> area which can be explored in future work. However, domain-specific text tends to greatly constrain which senses of a word will appear, and if the learned hierarchy is intended for use with the same type of text from which it was learned, it is possible that this would be of limited benefit. We used parsed text for these experiments because we believed we would get better results and the parsed data was readily available. However, it would be interesting to see if parsing is necessary or if we can get equivalent or nearly-equivalent results doing some simpler text processing, as suggested in Ahlswede and Evens (1988). Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. 7 Related work Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns. Their hierarchy is constructed top-down, rather than bottom-up, with nouns being allowed membership in multiple clusters. Their clustering is based on verb-object relations rather than on the noun-noun relations that we use. Future work on our project will include an attempt to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificia</context>
</contexts>
<marker>Ahlswede, Evens, 1988</marker>
<rawString>Thomas Ahlswede and Martha Evens. 1988. Parsing vs. text processing in the analysis of dictionary definitions. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 217-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V DeSouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Class-based ngram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--467</pages>
<contexts>
<context position="1464" citStr="Brown et al. (1992)" startWordPosition="232" endWordPosition="235"> based on a text corpus. In this project, nouns are clustered into a hierarchy using data on conjunctions and appositives appearing in the Wall Street Journal. The internal nodes of the resulting tree are then labeled with hypernyms for the nouns clustered underneath them, also based on data extracted from the Wall Street Journal. The resulting hierarchy is evaluated by human judges, and future research directions are discussed. 2 Building the noun hierarchy The first stage in constructing our hierarchy is to build an unlabeled hierarchy of nouns using bottom-up clustering methods (see, e.g., Brown et al. (1992)). Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus. Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former</context>
</contexts>
<marker>Brown, Pietra, DeSouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Peter V. DeSouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based ngram models of natural language. Computational Linguistics, 18:467-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Sharon Goldwater</author>
<author>Mark Johnson</author>
</authors>
<title>Edge-based bestfirst chart parsing.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>127--133</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1833" citStr="Charniak et al. (1998)" startWordPosition="296" endWordPosition="299">ted by human judges, and future research directions are discussed. 2 Building the noun hierarchy The first stage in constructing our hierarchy is to build an unlabeled hierarchy of nouns using bottom-up clustering methods (see, e.g., Brown et al. (1992)). Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus. Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former CBS Inc. executive&amp;quot; or &amp;quot;Boeing, a defense contractor&amp;quot;). The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). Taking the head words of each NP and stemming them results in data for about 50,000 distinct nouns. A vector is created for each noun containing c</context>
</contexts>
<marker>Charniak, Goldwater, Johnson, 1998</marker>
<rawString>Eugene Charniak, Sharon Goldwater, and Mark Johnson. 1998. Edge-based bestfirst chart parsing. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 127-133. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1833" citStr="(1998)" startWordPosition="299" endWordPosition="299">ges, and future research directions are discussed. 2 Building the noun hierarchy The first stage in constructing our hierarchy is to build an unlabeled hierarchy of nouns using bottom-up clustering methods (see, e.g., Brown et al. (1992)). Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus. Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former CBS Inc. executive&amp;quot; or &amp;quot;Boeing, a defense contractor&amp;quot;). The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). Taking the head words of each NP and stemming them results in data for about 50,000 distinct nouns. A vector is created for each noun containing c</context>
<context position="12437" citStr="(1998)" startWordPosition="2127" endWordPosition="2127">indicates the hypernyms that were accepted by even one of the judges. The &amp;quot;Hypernym 1/any&amp;quot; column can be used to compare results to Riloff and Shepherd (1997). For five hand-selected categories, each with a single hypernym, and the 20 nouns their algorithm scored as the best members of each category, at least one judge marked on average about 31% of the nouns as correct. Using randomly-selected categories and randomly-selected category members we achieved 39%. By the strictest criteria, our algorithm produces correct hyponyms for a randomlyselected hypernym 33% of the time. Roark and Charniak (1998) report that for a handselected category, their algorithm generally produces 20% to 40% correct entries. Furthermore, if we loosen our criteria to consider also the second- and third-best hypernyms, 60% of the nouns evaluated were assigned to at least one correct hypernym according to at least one judge. The &amp;quot;bank/firm/station&amp;quot; cluster consists largely of investment firms, which were marked as incorrect for &amp;quot;bank&amp;quot;, resulting in the poor performance on the Hypernym 1 measures for this cluster. The last cluster in the list, labeled &amp;quot;company&amp;quot;, is actually a very good cluster of cities that becaus</context>
<context position="19420" citStr="(1998)" startWordPosition="3347" endWordPosition="3347"> to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificial&amp;quot;, but for evaluation purposes they disregard the tree structure and consider only the leaf nodes. Unfortunately it is difficult to compare their results to ours since their evaluation is based on the verb-object relations. Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP. Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here. (They also use noun compound data, but in a separate stage of processing.) Both of these projects have the goal of building a single cluster of, e.g., vehicles, and both use seed words to initialize a cluster with nouns belonging to it. Hearst (1992) introduced the idea of learning hypernym-hyponym relationships from text and gives several examples of patterns that can be used to detect these relationships including those used here, along with an algorithm for identifying new patterns. Thi</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5648" citStr="Hearst (1992)" startWordPosition="984" endWordPosition="985">to be read, a much nicer structure is obtained. We now only consider nouns with a vector of length at least 2. There are approximately 20,000 nouns as the leaves in our final binary tree structure. Our next step is to try to label each of the internal nodes with a hypernym describing its descendant nouns. 3 Assigning hypernyms Following WordNet, a word A is said to be a hypernym of a word B if native speakers of English accept the sentence &amp;quot;B is a (kind of) A.&amp;quot; To determine possible hypernyms for a particular noun, we use the same parsed text described in the previous section. As suggested in Hearst (1992), we can find some hypernym data in the text by looking for conjunctions involving the word &amp;quot;other&amp;quot;, as in &amp;quot;X, Y, and other Zs&amp;quot; (patterns 3 and 4 in Hearst). From this phrase we can extract that Z is likely a hypernym for both X and Y. This data is extracted from the parsed text, and for each noun we construct a vector of hypernyms, with a value of 1 if a word has been seen as a hypernym for this noun and 0 otherwise. These vectors are associated with the leaves of the binary tree constructed in the previous section. For each internal node of the tree, we construct a vector of hypernyms by add</context>
<context position="16175" citStr="Hearst (1992)" startWordPosition="2787" endWordPosition="2788">ople, which is given the hypernym &amp;quot;conductor&amp;quot;. The reason for this is that few of the nouns appear with hypernyms, and two of them (Giulini and Ozawa) appear in the same phrase listing conductors, thus giving &amp;quot;conductor&amp;quot; a count of two, sufficient to be listed as the only hypernym for the cluster. It might be useful to have some stricter criterion for hypernyms, say, that they occur with a certain percentage of the nouns below them in the tree. Additional hypernym data would also be helpful in this case, and should be easily obtainable by looking for other patterns in the text as suggested by Hearst (1992). Because the tree is built in a binary fashion, when, e.g., three clusters should all be distinct children of a common parent, two of them must merge first, giving an artificial intermediate level in the tree. For example, in the current tree a cluster with best hypernym &amp;quot;agency&amp;quot; and one with best hypernym &amp;quot;exchange&amp;quot; (as in &amp;quot;stock exchange&amp;quot;) have a parent with two best hypernyms &amp;quot;agency/exchange&amp;quot; , rather than both of these nodes simply being attached to the next level up with best hypernym &amp;quot;group&amp;quot;. It might be possible to correct for this situation by comparing the hypernyms for the two clus</context>
<context position="18393" citStr="Hearst (1992)" startWordPosition="3180" endWordPosition="3181">uture work. However, domain-specific text tends to greatly constrain which senses of a word will appear, and if the learned hierarchy is intended for use with the same type of text from which it was learned, it is possible that this would be of limited benefit. We used parsed text for these experiments because we believed we would get better results and the parsed data was readily available. However, it would be interesting to see if parsing is necessary or if we can get equivalent or nearly-equivalent results doing some simpler text processing, as suggested in Ahlswede and Evens (1988). Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. 7 Related work Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns. Their hierarchy is constructed top-down, rather than bottom-up, with nouns being allowed membership in multiple clusters. Their clustering is based on verb-object relations rather than on the noun-noun relations that we use. Future work on our project will include an attempt to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificial&amp;quot;, but for evaluati</context>
<context position="19776" citStr="Hearst (1992)" startWordPosition="3411" endWordPosition="3412">ased on the verb-object relations. Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP. Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here. (They also use noun compound data, but in a separate stage of processing.) Both of these projects have the goal of building a single cluster of, e.g., vehicles, and both use seed words to initialize a cluster with nouns belonging to it. Hearst (1992) introduced the idea of learning hypernym-hyponym relationships from text and gives several examples of patterns that can be used to detect these relationships including those used here, along with an algorithm for identifying new patterns. This work shares with ours the feature that it does not need large amounts of data to learn a hypernym; unlike in much statistical work, a single occurrence is sufficient. The hyponym-hypernym pairs found by Hearst&apos;s algorithm include some that Hearst describes as &amp;quot;context and point-of-view dependent,&amp;quot; such as &amp;quot;Washington/nationalist&amp;quot; and &amp;quot;aircraft/target&amp;quot; </context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the Fourteenth International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--313</pages>
<contexts>
<context position="1694" citStr="Marcus et al., 1993" startWordPosition="272" endWordPosition="275">yms for the nouns clustered underneath them, also based on data extracted from the Wall Street Journal. The resulting hierarchy is evaluated by human judges, and future research directions are discussed. 2 Building the noun hierarchy The first stage in constructing our hierarchy is to build an unlabeled hierarchy of nouns using bottom-up clustering methods (see, e.g., Brown et al. (1992)). Nouns are clustered based on conjunction and appositive data collected from the Wall Street Journal corpus. Some of the data comes from the parsed files 2-21 of the Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former CBS Inc. executive&amp;quot; or &amp;quot;Boeing, a defense contractor&amp;quot;). The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). Taking </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19:313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<contexts>
<context position="18480" citStr="Pereira et al. (1993)" startWordPosition="3193" endWordPosition="3196">es of a word will appear, and if the learned hierarchy is intended for use with the same type of text from which it was learned, it is possible that this would be of limited benefit. We used parsed text for these experiments because we believed we would get better results and the parsed data was readily available. However, it would be interesting to see if parsing is necessary or if we can get equivalent or nearly-equivalent results doing some simpler text processing, as suggested in Ahlswede and Evens (1988). Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. 7 Related work Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns. Their hierarchy is constructed top-down, rather than bottom-up, with nouns being allowed membership in multiple clusters. Their clustering is based on verb-object relations rather than on the noun-noun relations that we use. Future work on our project will include an attempt to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificial&amp;quot;, but for evaluation purposes they disregard the tree structure and consider only the leaf nodes. Unfortu</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pages 183-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A corpus-based approach for building semantic lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>117--124</pages>
<contexts>
<context position="2255" citStr="Riloff and Shepherd (1997)" startWordPosition="361" endWordPosition="364">he Wall Street Journal Penn Treebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former CBS Inc. executive&amp;quot; or &amp;quot;Boeing, a defense contractor&amp;quot;). The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). Taking the head words of each NP and stemming them results in data for about 50,000 distinct nouns. A vector is created for each noun containing counts for how many times each other noun appears in a conjunction or appositive with it. We can then measure the similarity of the vectors for two nouns by computing the cosine of the angle between these vectors, as 11&apos;1iWr To compare the similarity of two groups of nouns, we define similarity as the average of the cosines between each pair of nouns made up of one noun from each of the two groups. Ev cos (v, w) size(A)</context>
<context position="11989" citStr="Riloff and Shepherd (1997)" startWordPosition="2051" endWordPosition="2055">e hypernym was correct for the predominant sense of the noun. Table 2 presents the results of this evaluation. The table lists only results for the actual candidate hyponym nouns, not the noise words. The &amp;quot;Hypernym 1&amp;quot; column indicates whether the &amp;quot;best&amp;quot; hypernym was considered correct, while the &amp;quot;Any hypernym&amp;quot; column indicates whether any of the listed hypernyms were accepted. Within those columns, &amp;quot;majority&amp;quot; lists the opinion of the majority of judges, and &amp;quot;any&amp;quot; indicates the hypernyms that were accepted by even one of the judges. The &amp;quot;Hypernym 1/any&amp;quot; column can be used to compare results to Riloff and Shepherd (1997). For five hand-selected categories, each with a single hypernym, and the 20 nouns their algorithm scored as the best members of each category, at least one judge marked on average about 31% of the nouns as correct. Using randomly-selected categories and randomly-selected category members we achieved 39%. By the strictest criteria, our algorithm produces correct hyponyms for a randomlyselected hypernym 33% of the time. Roark and Charniak (1998) report that for a handselected category, their algorithm generally produces 20% to 40% correct entries. Furthermore, if we loosen our criteria to consi</context>
<context position="18424" citStr="Riloff and Shepherd (1997)" startWordPosition="3183" endWordPosition="3186">r, domain-specific text tends to greatly constrain which senses of a word will appear, and if the learned hierarchy is intended for use with the same type of text from which it was learned, it is possible that this would be of limited benefit. We used parsed text for these experiments because we believed we would get better results and the parsed data was readily available. However, it would be interesting to see if parsing is necessary or if we can get equivalent or nearly-equivalent results doing some simpler text processing, as suggested in Ahlswede and Evens (1988). Both Hearst (1992) and Riloff and Shepherd (1997) use unparsed text. 7 Related work Pereira et al. (1993) used clustering to build an unlabeled hierarchy of nouns. Their hierarchy is constructed top-down, rather than bottom-up, with nouns being allowed membership in multiple clusters. Their clustering is based on verb-object relations rather than on the noun-noun relations that we use. Future work on our project will include an attempt to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificial&amp;quot;, but for evaluation purposes they disregard the </context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Ellen Riloff and Jessica Shepherd. 1997. A corpus-based approach for building semantic lexicons. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 117-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Eugene Charniak</author>
</authors>
<title>Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics: Proceedings of the Conference,</booktitle>
<pages>1110--1116</pages>
<contexts>
<context position="2285" citStr="Roark and Charniak (1998)" startWordPosition="366" endWordPosition="369">ebank corpus (Marcus et al., 1993), and additional parsed text was obtained by parsing the 1987 Wall Street Journal text using the parser described in Charniak et al. (1998). From this parsed text, we identified all conjunctions of noun phrases (e.g., &amp;quot;executive vice-president and treasurer&amp;quot; or &amp;quot;scientific equipment, apparatus and disposables&amp;quot;) and all appositives (e.g., &amp;quot;James H. Rosenfield, a former CBS Inc. executive&amp;quot; or &amp;quot;Boeing, a defense contractor&amp;quot;). The idea here is that nouns in conjunctions or appositives tend to be semantically related, as discussed in Riloff and Shepherd (1997) and Roark and Charniak (1998). Taking the head words of each NP and stemming them results in data for about 50,000 distinct nouns. A vector is created for each noun containing counts for how many times each other noun appears in a conjunction or appositive with it. We can then measure the similarity of the vectors for two nouns by computing the cosine of the angle between these vectors, as 11&apos;1iWr To compare the similarity of two groups of nouns, we define similarity as the average of the cosines between each pair of nouns made up of one noun from each of the two groups. Ev cos (v, w) size(A)size(B) where v ranges over al</context>
<context position="12437" citStr="Roark and Charniak (1998)" startWordPosition="2124" endWordPosition="2127"> judges, and &amp;quot;any&amp;quot; indicates the hypernyms that were accepted by even one of the judges. The &amp;quot;Hypernym 1/any&amp;quot; column can be used to compare results to Riloff and Shepherd (1997). For five hand-selected categories, each with a single hypernym, and the 20 nouns their algorithm scored as the best members of each category, at least one judge marked on average about 31% of the nouns as correct. Using randomly-selected categories and randomly-selected category members we achieved 39%. By the strictest criteria, our algorithm produces correct hyponyms for a randomlyselected hypernym 33% of the time. Roark and Charniak (1998) report that for a handselected category, their algorithm generally produces 20% to 40% correct entries. Furthermore, if we loosen our criteria to consider also the second- and third-best hypernyms, 60% of the nouns evaluated were assigned to at least one correct hypernym according to at least one judge. The &amp;quot;bank/firm/station&amp;quot; cluster consists largely of investment firms, which were marked as incorrect for &amp;quot;bank&amp;quot;, resulting in the poor performance on the Hypernym 1 measures for this cluster. The last cluster in the list, labeled &amp;quot;company&amp;quot;, is actually a very good cluster of cities that becaus</context>
<context position="19420" citStr="Roark and Charniak (1998)" startWordPosition="3344" endWordPosition="3347"> include an attempt to incorporate verb-object data as well in the clustering process. The tree they construct is also binary with some internal nodes which seem to be &amp;quot;artificial&amp;quot;, but for evaluation purposes they disregard the tree structure and consider only the leaf nodes. Unfortunately it is difficult to compare their results to ours since their evaluation is based on the verb-object relations. Riloff and Shepherd (1997) suggested using conjunction and appositive data to cluster nouns; however, they approximated this data by just looking at the nearest NP on each side of a particular NP. Roark and Charniak (1998) built on that work by actually using conjunction and appositive data for noun clustering, as we do here. (They also use noun compound data, but in a separate stage of processing.) Both of these projects have the goal of building a single cluster of, e.g., vehicles, and both use seed words to initialize a cluster with nouns belonging to it. Hearst (1992) introduced the idea of learning hypernym-hyponym relationships from text and gives several examples of patterns that can be used to detect these relationships including those used here, along with an algorithm for identifying new patterns. Thi</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>Brian Roark and Eugene Charniak. 1998. Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon construction. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics: Proceedings of the Conference, pages 1110-1116.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>