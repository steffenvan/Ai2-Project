<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.94546">
Machine Transliteration of Names in Arabic Text
</title>
<author confidence="0.959639">
Yaser Al-Onaizan and Kevin Knight
</author>
<affiliation confidence="0.898375333333333">
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001
</affiliation>
<address confidence="0.604009">
Marina del Rey, CA 90292
</address>
<email confidence="0.918615">
{yaser,knight}Aisi.edu
</email>
<sectionHeader confidence="0.983583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966625">
We present a transliteration algorithm
based on sound and spelling mappings us-
ing finite state machines. The transliter-
ation models can be trained on relatively
small lists of names. We introduce a new
spelling-based model that is much more ac-
curate than state-of-the-art phonetic-based
models and can be trained on easier-to-
obtain training data. We apply our translit-
eration algorithm to the transliteration of
names from Arabic into English. We re-
port on the accuracy of our algorithm based
on exact-matching criterion and based on
human-subjective evaluation. We also com-
pare the accuracy of our system to the ac-
curacy of human translators.
</bodyText>
<sectionHeader confidence="0.995592" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998858">
Human translators and machine translation sys-
tems are often faced with the task of transliterating
phrases like person names and locations. Transliter-
ation is the process of replacing words in the source
language with their approximate phonetic or spelling
equivalents in the target language. Transliterat-
ing names between languages that use similar al-
phabets and sound systems is often very simple,
since the phrase mostly remains the same. However,
the transliteration becomes far more difficult when
transliterating between languages with very different
sound and writing systems.
When transliterating a name from Arabic into En-
glish, there are two types of transliterations:
</bodyText>
<listItem confidence="0.911373">
• Forward Transliteration: This refers to the
</listItem>
<bodyText confidence="0.891484666666667">
transliteration of an Arab name into English.
Typically, many variations of the transliter-
ated name are acceptable. This is especially
true when transliterating between two languages
with many phonetic incompatibilities, such as
Arabic and English. For example, the Arab
name &amp;quot;_.A ycisr&amp;quot;1 can reasonably be transliter-
ated in any of the following ways: Yasir, Yassir,
Yaser, Yasser, etc.
</bodyText>
<listItem confidence="0.885692444444445">
• Back-Transliteration: This refers to the re-
verse transliteration process in order to obtain
the original of an English name that has al-
ready been transliterated into Arabic. In this
case, typically, only one transliteration is accept-
able. For example, when encountering the name
rwbrt&amp;quot; while translating Arabic text
into English, the name should only be translit-
erated as Robert, not as Robirt.
</listItem>
<bodyText confidence="0.998545">
Transliterating names from Arabic into English in
either direction is a difficult task, mainly due to the
differences in their sound and writing systems. For
instance, vowels in Arabic come in two varieties, long
and short. Short vowels are rarely written in Arabic
in newspaper text, which makes pronunciation highly
ambiguous. Also, because of the differences in their
sound inventory, there is no one-to-one correspon-
dence between Arabic sounds and English sounds.
For example, English P and B are both mapped into
Arabic &amp;quot;,_.) b&amp;quot;; Arabic &amp;quot;c and &amp;quot;A h-&amp;quot; into English
H; and so on.
In this paper, we describe Arabic-to-English name
transliteration system using probabilistic finite state
machines2 that address both the transliteration of
Arab and foreign names into English.
</bodyText>
<sectionHeader confidence="0.997918" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.953399">
Kawtrakul et al. (1998) present a back translitera-
tion system from Thai into English in the context
</bodyText>
<footnote confidence="0.514291">
&apos;Arabic text will be presented throughout this pa-
per using the Arabic script and a romanization based
on Lagally (1999).
2We use Carmel, a finite-state toolkit available at
http://www.isi.eduilicensed-swicarmeliindex.html
</footnote>
<bodyText confidence="0.99973297260274">
of document retrieval. In their approach, loan words
are first segmented into syllables using a combination
of rules and statistical techniques. Then, syllables
are mapped to phonemes based on some transcrip-
tion rules. The phoneme sequence of the loan word is
compared to the phonetic sequence of a set of English
words found in a phonetic dictionary and the word
with the most similar phonetic sequence is selected
as the transliteration.
The approach described by Kawtrakul et al.
(1998) requires a phonetic dictionary of English in or-
der to match phonetic sequences. Only those words
with known phonetic sequences in the dictionary can
be mapped by the transliteration system. Also, ap-
plying such technique to Arabic will most likely fail
because without short vowels, the pronunciation is
highly ambiguous, and so is its corresponding pho-
netic sequence.
Arbabi et al. (1994) describe an algorithm for the
forward-transliteration of Arab names into a number
of Romance and Germanic languages including En-
glish, French, and Spanish. The transliteration pro-
cess starts by vowelizing the given Arab name by in-
serting the appropriate short vowels which originally
are not written but necessary for the correct pronun-
ciation of the names. Then, the vowelized Arab name
is converted into its phonetic Roman representation
using a parser and table lookup. The phonetic rep-
resentation is then used in a table lookup to produce
the spelling in the desired language.
The vowelization rules described by
Arbabi et al. (1994) apply only to Arab names
that conform to strict Arabic morphological rules.
Any name that does not conform to the morpho-
logical rules is ignored and hence no transliteration
will be attempted. This restriction limits the
applicability of this approach since many person and
organization names do not conform to morphological
rules, especially loan words and foreign names.
Stalls and Knight (1998) present an Arabic-to-
English back-transliteration system based on the
source-channel framework. The transliteration pro-
cess is based on a generative model of how an En-
glish name is transliterated into Arabic. It consists
of several steps, each defined as a probabilistic model
represented as a finite state machine. First, an En-
glish word w is generated according to its unigram
probabilities Pe). Then, the English word w is pro-
nounced (i.e., converted to sound sequence c) with
probability P (61w) which is collected directly from
an English pronunciation dictionary. Finally, the
English phoneme sequence is converted into Arabic
writing with probability P (a lc), which we discuss in
details in Section 4.
The pronunciation model P(e I w) converts English
letter sequences into English sound sequences. The
model proposed by Stalls and Knight (1998) uses
a pronunciation dictionary to do this conversion.
Therefore, only words with known pronunciations in
the dictionary can be transliterated.
One way to overcome this limitation is to train
a model that can map any given English letter
sequence into its corresponding English sound se-
quence. This mapping is a complex task because
of the mismatch between English spelling and En-
glish pronunciation. This difficulty, coupled with the
difficulty of mapping Arabic letter sequences to En-
glish sound sequences, renders this choice unattrac-
tive. Instead we propose a spelling-based model that
maps directly into Arabic letter sequences, which can
be trained on an English/Arabic name list as we de-
scribe in Section 5. But before we present any further
details, we describe our evaluation data next.
</bodyText>
<sectionHeader confidence="0.993782" genericHeader="method">
3 Evaluation Data
</sectionHeader>
<bodyText confidence="0.998085346153846">
Our evaluation corpora consist of two data sets, a de-
velopment test set and a blind one. The two sets con-
sist of a list of person names extracted from Arabic
newspaper articles. The development test set con-
tains 854 names (377 unique names) and the blind
test set contains 218 (85 unique names). The per-
son names are then manually transliterated into En-
glish. The transliterations are then thoroughly re-
viewed and any obvious mistakes corrected.3 The
corrected transliterations form the gold-standard we
will compare our results with.
We would like to investigate the suitability of
the models proposed here for back- and forward-
transliteration. Therefore, each name in the list is
classified in one of three categories ARABIC, for
names of Arabic origin; ENGLISH, for names of
English origin; and OTHER, for names of other
origins including Chinese, Russian, Indian, etc. The
names were classified by a bilingual speaker (a native
speaker of Arabic). The classification is not always
clear cut. In some cases, the first name of a person
might be of one category and the last name of an-
other (e.g.,&amp;quot;jn....4.. j..c.&amp;quot; Ali Rodriguez). In such
cases, the category is chosen based on the identity of
the person if it is known, otherwise the category of
the last name is chosen. The distribution of person
</bodyText>
<footnote confidence="0.912649142857143">
3Possible transliterations for a name were researched
using the context in which the person name was men-
tioned in the original Arabic document using Web re-
sources to determine the correct transliteration. For ex-
ample, if the person is a US Senator, the official US Sen-
ate Web pages are used to determine the correct spelling
of the Senator&apos;s name.
</footnote>
<figure confidence="0.938788388888889">
AH /
AH / NULL
AH /
AH-F /
AH-F /
AH-S /
AH-S /
(a) Original Model
AH / NULL
AH /
AH /
AH /
AH /
AH /
Initial Medial Final
AH /
AH /
(b) Adapted Model
</figure>
<table confidence="0.99307575">
Data Set Distribution (%)
ARABIC ENGLISH OTHER
Dev. Test Set 21.78 30.09 48.13
Blind Test Set 48.62 30.28 21.10
</table>
<tableCaption confidence="0.647409666666667">
Table 1: The distribution in the two data sets of the names into the three categories ARABIC, ENGLISH,
and OTHER. ARABIC refers to names of Arabic origin, ENGLISH is of English origin, and OTHER
is for names of other origins including Russian, Chinese, and Indian.
</tableCaption>
<figure confidence="0.6682024">
phoneme AH in the modified model after training&apos;:
a e Position P (a le, Position)
1 )a AH Initial 0.43
L € AH Initial 0.24
L.51 ãy AH Initial 0.05
NULL AH Medial 0.37
I a AH Medial 0.36
i w AH Medial 0.27
I a AH Final 0.93
S t AH Final 0.06
</figure>
<bodyText confidence="0.998398333333333">
According to this model, the probability of
transliterating Arabic word a into English word w
is given by the following equation:
</bodyText>
<equation confidence="0.943994">
P(1a) P(wl)P(e1t0P(a H (1)
</equation>
<bodyText confidence="0.989565">
The actual transliteration process is a graph-
search problem through millions of possible
mappings to find the best path with English
word sequence w that maximizes Pp(&apos;
Wia for a
given Arabic word sequence a, as described by
Knight and Graehl (1997).
</bodyText>
<sectionHeader confidence="0.999245" genericHeader="method">
5 Spelling-Based Model
</sectionHeader>
<bodyText confidence="0.999734266666667">
One serious limitation of the phonetic-based model
described above is that only English words with
known pronunciations can be produced. For back-
transliterating person names of English origin, this
is not a big problem because many of such names are
typically found in the dictionary. However, applying
this technique to transliterate names of origins other
than English is not going to work, because many such
names are not likely to be in the dictionary despite
the fact that the dictionary has more than 100,100
entries in it, as shown in Table 2. Moreover, if we
want to apply this technique to transliterate a name
into a language other than English, a large pronun-
ciation dictionary is needed for that language, which
is not easily obtainable.
</bodyText>
<footnote confidence="0.812458">
5NULL is the empty string.
</footnote>
<bodyText confidence="0.998708918918919">
Also, human translators often transliterate words
based on how they are spelled in the source language.
For example, Graham is typically transliterated by
humans into Arabic as &amp;quot;r .Orciham&amp;quot; and not as
jrcim&amp;quot; . Also, both &amp;quot; hwjz&amp;quot; and 13...4
hywzn occur in our corpus as possible transliterations
for Hughes (both occurred as a transliteration for
Karen Hughes). To back-transliterate such instances,
one would need to consider spelling-based mappings
not just sound mappings.
To address these limitations, we propose a new
spelling-based model that can be used alone or in
conjunction with the phonetic-based model. The
new model outperforms the phonetic-based model,
even when evaluated on names found in the pho-
netic dictionary as we will discuss in more detail in
Section 8.
The spelling-based model we propose directly
maps English letter sequences into Arabic letter se-
quences with probability P(alw), which is trained
on an English/Arabic name list without the need for
English pronunciations. Since no pronunciations are
needed, this list is easily obtainable for many lan-
guage pairs. We also extend the model P(w) to in-
clude a letter trigram model in addition to the word
unigram model. This makes it possible to generate
words that are not already defined in the word un-
igram model but obey English patterns. The word
unigram model can be trained on any list of words.
When trained on a list of person names, the translit-
erations will be most accurate for person names. For
the experiments reported in this paper, the unigram
model was trained on the list of names (without their
pronunciations) from the CMU dictionary. The let-
ter trigram is also trained on the same list.
The transliteration score according to this model
is given by:
</bodyText>
<equation confidence="0.986645">
Ps(wia) P(w)P(alw) (2)
</equation>
<bodyText confidence="0.9999378">
For a given Arabic name a, the actual translit-
eration process is carried out by searching for the
English word sequence that maximizes Ps (w la ) -
In our spelling-based model, a sequence of one or
more English letters is mapped to a sequence of zero
</bodyText>
<table confidence="0.99972975">
Data Set Dictionary Coverage (Vo)
ARABIC ENGLISH OTHER OVERALL
Dev. Test Set 29.03 89.10 59.12 61.59
Blind Test Set 55.66 100 47.82 67.43
</table>
<tableCaption confidence="0.992524">
Table 2: The percentages of names in development and blind test sets that are found in the CMU Pronouncing
</tableCaption>
<bodyText confidence="0.959154181818182">
Dictionary presented by the category of each name. OVERALL is a weighted average of the three categories.
or more Arabic letters.&apos; English letter sequences
are typically longer than their Arabic equivalents for
many reasons. First, because Arabic short vowels
are not written and need to be &amp;quot;guessed&amp;quot; by the
model. Second, English names often have silent let-
ters that mostly are not reflected in the Arabic equiv-
alent (e.g., Knight is transliterated as uclyt&amp;quot; ).
This phenomenon was also reflected in the learned
model. Here is an example of some of the parame-
ters learned during training:
</bodyText>
<table confidence="0.958218125">
a w Position P (a lw, Position)
I )i I Initial 0.87
L.51, )iy I Initial 0.10
L.51 ãy I Initial 0.03
L.5 y I Medial 0.56
1 ci I Medial 0.38
NULL I Medial 0.06
L5 y I Final 0.99
</table>
<bodyText confidence="0.969788166666667">
Here are some examples of the letter sequence
alignments for pairs of Arabic name/top translitera-
tion as provided by our system.
Example I: Given the name &amp;quot;r Luc sdam,&amp;quot; its
top transliteration was SADDAM, and the letter
sequence alignment was:
</bodyText>
<table confidence="0.981677181818182">
SA L7&amp;quot;
DD d
A I ci
M r in
Example II: Given the name &amp;quot;Ljli.1 )iyrciu,&amp;quot; its
top transliteration was IRAN, and the letter se-
quence alignment was:
I L5i &apos;iY
R J r
A I ci
N Lj u
</table>
<bodyText confidence="0.71157725">
6To reduce the parameters to be estimated and pre-
vent data sparseness without loss of any practical mod-
eling power, English letter sequences were restricted to a
maximum of 3 letters, while Arabic ones were restricted
to a maximum of 2 letters.
Example III: Given the name &amp;quot; )wbuhci-
ymr,&amp;quot; its top transliteration was OPPEN-
HEIMER, and the letter sequence alignment was:
</bodyText>
<table confidence="0.980625111111111">
0
PP y b
E
N
H A h-
E
I 41 ciY
M r m
R J r
</table>
<sectionHeader confidence="0.7766045" genericHeader="method">
6 Combining The Phonetic-Based
and Spelling-Based Models
</sectionHeader>
<bodyText confidence="0.999901666666667">
The phonetic-based and spelling-based models can
be linearly combined into a single transliteration
model. The transliteration score for an English word
w given an Arabic word a is a linear combination of
the phonetic-based and the spelling-based transliter-
ation scores as follows:7
</bodyText>
<equation confidence="0.999737">
P(w1a) = APs(wla)+ (1 )t)Pp(wia) (3)
</equation>
<sectionHeader confidence="0.939112" genericHeader="method">
7 Improving Transliterations
</sectionHeader>
<bodyText confidence="0.999983727272727">
In this section we discuss two different techniques
that were used to improve the transliteration accu-
racy. In the first technique, the given word to be
transliterated is pre-processed to correct any typos
and spelling errors. The spelling correction model
described in Section 7.1 is also implemented using
a finite state machine which can be easily added to
the transliteration composition pipeline. In the sec-
ond technique to improve transliterations, translit-
erations are post-processed to filter any unlikely
transliterations as described in Section 7.2.
</bodyText>
<subsectionHeader confidence="0.973294">
7.1 Spelling Corrections
</subsectionHeader>
<bodyText confidence="0.99820775">
Typos and misspellings are very common in Arabic
newspapers, especially in on-line editions. Typical
Tor the experiments reported in this paper, we used
A = 0.5.
</bodyText>
<table confidence="0.987090214285714">
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Without Spell Corr. (Topl) 15.59 59.53 23.44 32.52
With Spell Corr. (Topl) 15.59 59.53 28.95 35.20
Without Spell Corr. (Top20) 18.28 86.00 49.52 53.66
With Spell Corr. (Top20) 19.89 87.16 50.48 54.82
(a) Accuracy on the Development Test Set.
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Without Spell Corr. (Topl) 40.57 48.48 6.52 35.78
With Spell Corr. (Topl) 43.40 48.49 6.52 37.16
Without Spell Corr. (Top20) 42.46 100 47.82 61.00
With Spell Corr. (Top20) 46.23 100 47.82 62.85
(b) Accuracy on the Blind Test Set.
</table>
<tableCaption confidence="0.984142">
Table 3: A comparison of the transliteration accuracy on the development and blind test sets by category,
</tableCaption>
<bodyText confidence="0.811614">
with and without spelling correction. The results shown here are for the phonetic-based model. The Topl
results considers whether the correct answer is the top candidate or not, while the Top20 results considers
whether the correct answer is among the top-20 candidates.
</bodyText>
<table confidence="0.673572785714286">
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Without Web Filtering (Topl) 18.28 64.98 40.91 43.21
With Web Filtering (Topl) 19.89 63.42 42.34 43.79
Without Web Filtering (Top20) 26.88 84.82 53.83 57.26
With Web Filtering (Top20) 31.72 85.21 56.69 59.82
(a) Accuracy on the Development Test Set.
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Without Web Filtering (Topl) 45.28 59.10 54.35 50.92
With Web Filtering (Topl) 48.11 59.10 54.35 52.75
Without Web Filtering (Top20) 60.38 98.50 56.52 70.19
With Web Filtering (Top20) 70.75 98.50 56.52 76.15
(b) Accuracy on the Blind Test Set.
</table>
<tableCaption confidence="0.8920355">
Table 4: A comparison of the transliteration accuracy on the development and blind test sets by category,
with and without Web filtering. The results shown here are for the spelling-based model.
</tableCaption>
<table confidence="0.9996725">
Data Set Accuracy (Vo)
ARABIC ENGLISH OTHER OVERALL
Dev. Test Set 55.91 77.04 42.58 55.85
Blind Test Set 60.38 92.42 50.00 67.89
</table>
<tableCaption confidence="0.999767">
Table 5: The transliteration accuracy for a human translator.
</tableCaption>
<bodyText confidence="0.9902925">
typos stem from replacing a letter with another that
has a similar shape, especially when they are mapped
to adjacent keys on the keyboard layout (e.g., &amp;quot;t..&amp;quot;
and &amp;quot;c&apos;; &amp;quot;cj,&amp;quot; and &amp;quot;3&apos;; and so on). These letters
have very different sounds and without being cor-
rected, names with those typos will most likely be
transliterated incorrectly. For example, the name
€wuzcilys&amp;quot; is a misspelled version of the
name &amp;quot;Ly4).;:c. jwuzcilys&amp;quot; (Gonzalez).
Spaces are reliably used in Arabic to separate
words, with very few exceptions. Arabic employs
a cursive writing system, so typically letters in the
same word are connected to each other. Most letters
can be connected from both sides, but some (such as
&amp;quot; , , &amp;quot; J&amp;quot;, and &amp;quot; j&apos; )&apos; can be connected only from
the right side. After any of these letters, a space
might be incorrectly deleted (e.g., &amp;quot;,:y3_,J.,ti...a:jit,&amp;quot; in-
stead of &amp;quot;,:y3_,J.,ti...a) bytr mndlswn&amp;quot;) or inserted
(e.g., &amp;quot;Alfl Ats b d allh&amp;quot; instead of &amp;quot;ABlats. €bdcillh&amp;quot;).
Additionally, there are common misspellings that
can be found even in the most respected Arabic news-
papers, e.g., interchanging one form of an alif (&amp;quot;i&amp;quot;,
&amp;quot;p&apos;, &amp;quot;p&apos;, or &amp;quot;p&apos;) with another, especially at the begin-
ning of a word; or interchanging &amp;quot;a&amp;quot; and &amp;quot;s&amp;quot; at the
end of a word; etc.
These kinds of typos and misspellings are more
common than we expected. For example, 5% of the
names in our development test set were misspelled.
Human translators seem to be able to recover from
name misspellings when transliterating a name they
are familiar with. Our human subject was able to
transliterate the name &amp;quot;,..).4 bwrys&amp;quot; (Boris) cor-
rectly, even though it was misspelled as &amp;quot;Lty, br-
wys.&amp;quot; Therefore, we believe that we need to model
misspellings explicitly rather than hope that they
will not cause wrong transliterations.
We model misspellings by using an additional
finite-state machine at the end of the cascade of finite
state machines. We would like to estimate the pa-
rameters in this model empirically. But since we do
not have enough misspellings/correct spelling pairs
to train this model, the weights were set manually.
The use of this spelling correction model slightly
improves our transliterations, as shown in Table 3.
</bodyText>
<subsectionHeader confidence="0.966168">
7.2 Web-Based Filtering
</subsectionHeader>
<bodyText confidence="0.999900933333333">
As we have described in Section 5, the P(w) model
is a combination of a word unigram model and a let-
ter trigram model. The latter is needed in order to
be able to generate words that are not in the word
unigram model. However, despite being trained on
a long list of names, the letter trigram model occa-
sionally produce unlikely candidates. Unlikely can-
didates can be eliminated by filtering out candidates
with zero Web counts.
The Web-based filtering is useful only for our
spelling-based model since all candidates generated
by the phonetic-based model are in the pronuncia-
tion dictionary and all have non-zero Web counts. A
comparison of the transliteration accuracy with and
without the Web-based filtering is shown in Table 4.
</bodyText>
<sectionHeader confidence="0.9969655" genericHeader="evaluation">
8 Evaluation and Experimental
Results
</sectionHeader>
<bodyText confidence="0.999973">
In this section, we present a comparison of the accu-
racy of the phonetic-based model, the spelling-based
model, and the linear combination in transliterat-
ing names from Arabic into English on the develop-
ment and test sets. We also, present the translit-
eration accuracy of human translators on the same
task. The results presented in Section 8.1 and Sec-
tion 8.2 are based on the exact-matching criterion
(i.e., a transliteration is considered correct only if it
exactly matches the one in the gold-standard). We
also show the accuracy based on human-subjective
evaluation in Section 8.3.
</bodyText>
<subsectionHeader confidence="0.978011">
8.1 Evaluating Human Transliterations
</subsectionHeader>
<bodyText confidence="0.964975636363636">
We wanted to know how well human translators do in
this task. So, we asked a bilingual speaker (a native
speaker of Arabic) to transliterate the names in both
data sets given the context they appear within in the
Arabic document. Then, the transliterations pro-
vided by the human subject are compared with those
in the gold-standard. The accuracy of the transliter-
ations provided by the human translator is shown in
Table 5.
Examples of the transliteration errors made by the
human subject are shown in Table 6.
</bodyText>
<table confidence="0.999868428571429">
Correct Human Subject Arabic
Jon Kyl John Keele
Barak Baraq J .
Karen Hughes Karen Meuz
Karen Hughes Karen Hoggs
Condoleezza Rice Condolisa Rice Lt71:1J
Ariel Sharon Arial Sharon
Yehuda Wilk Yuhuda Welleck
Gilead Sher Jelaad Shir A...t A..i.
Hubert Vedrine Ubair Federene
Richard Boucher Richard Bautcher _.A3iL&apos;
Ronald Reagan Ronald Regan
Ovadia Yosef Ufadia Joseph L.:o....p.? Li
Stephen Miles Stephan Miles _A:La -
John George Bolton
John Bolton
Jean Chretien Jan Kretaine
Vladimir Voronin Vladimir Vlaronin *
Rudolf Scharping Rudolph Sharping 4 4.3 L&apos;Ii j
Emile Lahoud Amil Lahud .i..4.3...„al
Eduard Drumont Edward Dremon
Fyodor Dostoevsky Vieord Dyestoyavsky *
Dostoevsky Dyestoyavsky
Boris Pasternak Boris Bastranak *
Ivan Aksakov Ivan Aksasov cj5L,1
Jacques Chirac Jack Sherak
Walter Shipley Walter Shibly
Dick Cheney Dick Chaney
Lawrence Lindsey Lawrance Linzi
Slade Gorton Slid Gorotn
Pete Laney Bet Lenny
Kenneth Lay Kenneth Lai L5&apos;t Lt-Li
Tony Garza Tony Jaroza l_i_)L j_95
Bulent Ecevit Boland Ajaweed
Francis Okello Francis Akopolo
</table>
<tableCaption confidence="0.884847">
Table 6: Examples of the transliteration errors made by the human subject. Names marked with &amp;quot;*&amp;quot; were
misspelled in the Arabic document.
</tableCaption>
<subsectionHeader confidence="0.967465">
8.2 Evaluating Our Transliteration System
</subsectionHeader>
<bodyText confidence="0.99986925">
We first show in Section 8.2.1 the overall accuracy of
the phonetic-based model, the spelling-based model,
and the linear combination of them. Then, in Sec-
tion 8.2.2 we show how the presence of names in the
pronunciation dictionary affects the transliterations
obtained using our models. We also present some
transliteration errors made by our algorithm in Sec-
tion 8.2.3.
</bodyText>
<listItem confidence="0.1510495">
8.2.1 Transliteration Accuracy of Our
Algorithm
</listItem>
<bodyText confidence="0.996564769230769">
Table 7 shows the transliteration accuracy of the
spelling-based model, the phonetic-based model, and
the linear combination on the development and blind
test set. The spelling-based model was by far more
accurate than the phonetic-based model in all three
categories and on both data sets. Because it com-
bines the transliterations of the two models, we ex-
pected the linear combination to be the most accu-
rate. However, this was not the case. The linear
combination was slightly worse than the spelling-
based model when considering only the top candi-
date, and slightly better when considering the top-
20 candidates. We believe that the reason is that
equal weights were given to the phonetic-based and
spelling-based models in the combination. Weight-
ing the spelling-based model higher will most likely
give more accurate transliterations.
8.2.2 Phonetic-Based vs. Spelling Based on
Names in the Dictionary
As we have described in Section 4, the phonetic-
based model uses a pronunciation dictionary to con-
vert an English phoneme sequence to an English
word sequence. Consequently, only words with
known pronunciations (from the dictionary) can be
generated using this model. Therefore, the spelling-
based model generally has a higher transliteration
accuracy. But, does the spelling-based model gen-
erate more accurate transliterations for words with
known pronunciations? We expected the answer to
this question to be no. But much to our surprise,
the spelling-based model produced more accurate
transliterations on all categories, as shown in Ta-
ble 8. When top-20 transliterations were considered,
the spelling-based model was slightly less accurate.
As expected, the transliterations for names in the
pronunciation dictionary are much more accurate
than those that are not in it. This is because the
word unigram model P(w) was trained on names in
the dictionary.
</bodyText>
<subsectionHeader confidence="0.47946">
8.2.3 Examples of Transliteration Errors
</subsectionHeader>
<bodyText confidence="0.998961857142857">
Table 9 shows some examples of the transliteration
errors made by our transliteration algorithm. Some
of the errors occurred were in fact not errors but
rather acceptable alternative transliterations. How-
ever, many were true errors. The human-subjective
evaluation described in Section 8.3 helps distinguish
between these two cases.
</bodyText>
<subsectionHeader confidence="0.874658">
8.3 Human-Subjective Evaluation
</subsectionHeader>
<bodyText confidence="0.99998525">
The evaluation results presented so far consider a
transliteration correct only if it matches the gold-
standard. In some cases where more than one possi-
ble transliteration is acceptable, this criterion is too
rigid. To address such cases, we must ask a human
subject to determine the correctness of translitera-
tions. We asked a native speaker of English with
good knowledge of Arabic to decide whether any
given transliteration is correct or not. This human-
based evaluation is done for both the translitera-
tions provided by the human translators and by our
transliteration system.
The human subject was presented with the names
in the Arabic script, their gold-standard translitera-
tions, and the transliteration that we are evaluating.
For our transliteration algorithm, the human subject
was provided with the top 20 transliteration candi-
dates as well.
The accuracy of the human translator based on the
human-subjective evaluation is shown in Table 10.
The accuracy of our transliteration models based
on the human-subjective evaluation is shown in Ta-
ble 11.
The human translator&apos;s accuracy based on the
human-subjective evaluation was higher than the
exact-matching accuracy by about 11%. Most of
the increase came from the forward-transliteration
of Arab names. This was expected because for Arab
names, typically many variant transliterations are
acceptable. This was also reflected on the human-
subjective evaluation of our spelling-based model.
However, the accuracy of our phonetic-based model
remains almost the same as in the case of the exact-
matching evaluation. This is because names that can
be found in the dictionary have only a single spelling
that for the most part agrees with our gold-standard.
Also, most of the names in the dictionary are English
names and with English names the human evaluator
was rigid, mostly accepting only the exact-matching
spelling.
</bodyText>
<sectionHeader confidence="0.9977" genericHeader="conclusions">
9 Discussion
</sectionHeader>
<bodyText confidence="0.991886">
We have presented and evaluated a transliteration
algorithm using phonetic-based and spelling-based
</bodyText>
<table confidence="0.9927635">
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 15.59 59.53 28.95 35.20
Spelling-Based (Topl) 19.89 63.42 42.34 43.79
Combination (Topl) 17.20 61.87 42.11 42.62
Phonetic-Based (Top20) 19.89 87.16 50.48 54.82
Spelling-Based (Top20) 31.72 85.21 56.69 59.82
Combination (Top20) 28.49 87.94 57.90 60.51
(a) Accuracy on the Development Test Set.
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 43.40 48.49 6.52 37.16
Spelling-Based (Topl) 48.11 59.10 54.35 52.75
Combination (Topl) 47.17 48.48 54.35 49.08
Phonetic-Based (Top20) 46.23 100 47.82 62.85
Spelling-Based (Top20) 70.75 98.50 56.52 76.15
Combination (Top20) 70.75 100 58.70 77.06
(b) Accuracy on the Blind Test Set.
</table>
<tableCaption confidence="0.9512765">
Table 7: A comparison between the spelling-based model, phonetic-based model, and their linear combination
on the development and blind test sets by category.
</tableCaption>
<table confidence="0.983514071428572">
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 53.70 66.81 48.40 56.85
Spelling-Based (Topl) 59.26 71.18 63.60 66.42
Phonetic-Based (Top20) 68.51 97.81 84.40 88.56
Spelling-Based (Top20) 77.78 95.20 80.80 86.68
(a) Accuracy on the Development Test Set.
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 77.97 48.49 13.64 55.10
Spelling-Based (Topl) 86.44 59.10 90.90 74.83
Phonetic-Based (Top20) 83.07 100 100 93.20
Spelling-Based (Top20) 93.22 98.50 90.90 95.24
(b) Accuracy on the Blind Test Set.
</table>
<tableCaption confidence="0.9917235">
Table 8: A comparison between the spelling-based and phonetic-based models on names in the pronunciation
dictionary for the development and blind test sets by category.
</tableCaption>
<table confidence="0.999287">
Correct Our Transliterations Arabic
Abdel Maqsud Abd Al Maksoud *5-211&apos; .1
Mahmud Salameh Mahmoud Slama k.a)t., ._,......4.
Amid Khuli Amid Julie ii--4- j%:-`r&amp;quot;
Massoud Barzani Miss Awad Barsanti
Mikhail Kasyanov Mikhail Casanova
Boris Gryzlov Boris Grise Love
Ayman Khairy Amen Kerrey
Giora Eiland Guerra Island
Ann Veneman Ann Feinman L.-..t:9
Francois Rivasseau Francois Revco 9-4—)
Voronin Vernon
Yisrael Hasson Israel Hassan
George W. Bush George Deblois Bush L.)±&apos;,&apos; 9:t4= CJJ--&apos;:
Carl Rove Carl Rough c-)JJ JJ&apos;r
Shalom Yerushalmi Shalom Euro Salmi L3-11&amp;quot;.97: rin-t
Fawzi Abu Samrah Fauci Abu Samara °J-c&amp;quot; 9-114i93
Sovirene Sovereign
Morarji Desai Margie Desai * L5L&amp;quot;:1= J1_9-4
Getachew Tefera Jetta Cho Tavera
Kofi Annan Coffee Annan L:A&amp;quot;s&apos; Li_95
</table>
<tableCaption confidence="0.9809055">
Table 9: Examples of the transliteration errors made by our transliteration algorithm. Names marked with
were misspelled in the Arabic document.
</tableCaption>
<table confidence="0.99588875">
Data Set Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Dev. Test Set 79.03 77.43 54.31 66.85
Blind Test Set 83.96 92.42 52.17 79.82
</table>
<tableCaption confidence="0.730815">
Table 10: The transliteration accuracy for a human translator based on the human-subjective evaluation.
</tableCaption>
<table confidence="0.982378055555556">
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 15.59 59.53 28.95 35.20
Spelling-Based (Topl) 27.96 63.42 44.74 46.69
Combination (Topl) 23.12 61.87 45.22 45.41
Phonetic-Based (Top20) 20.43 87.16 50.48 54.93
Spelling-Based (Top20) 43.55 85.21 59.81 63.88
Combination (Top20) 44.63 87.94 61.25 65.62
(a) Accuracy on the Development Test Set.
Experiment Accuracy (%)
ARABIC ENGLISH OTHER OVERALL
Phonetic-Based (Topl) 43.40 48.49 6.52 37.16
Spelling-Based (Topl) 54.72 59.09 58.70 56.88
Combination (Topl) 56.60 48.48 54.35 53.67
Phonetic-Based (Top20) 46.23 100 47.82 62.85
Spelling-Based (Top20) 75.47 98.48 63.05 79.82
Combination (Top20) 79.24 100 63.05 82.11
(b) Accuracy on the Blind Test Set.
</table>
<tableCaption confidence="0.938576">
Table 11: A comparison between the spelling-based model, phonetic-based model, and their linear combi-
</tableCaption>
<bodyText confidence="0.990974588235294">
nation on the development and blind test sets by category. The evaluation is based on human-subjective
evaluation.
models. This algorithm is most accurate on back-
transliterating English names. The reason for this is
that most names in the dictionary are of English ori-
gin. Hence, the language model was mostly trained
on English names. One way to improve translitera-
tions of non-English names is to train the language
model on a list of non-English names in addition to
the dictionary names.
Our current models do not deal with the issue
of metathesis (e.g., metathesis of v and r between
the spelling and the pronunciation of the name
Favre) in person names across languages. Metathe-
sis in person names into Arabic is often a result of
wrong transliterations by the person who transliter-
ated in the original name in Arabic. For example,
the name Dostoevsky was found in our Arabic cor-
pus transliterated as dystwyfsky&amp;quot; and
dystwyfksy&amp;quot; (a metathesis of k and s);
the name Ordzhonikidze was found transliterated as
cirdjion ykydzy&amp;quot; and &amp;quot; Si ..Ati;.‹.; ci-
rdjyk yrt ydzt&amp;quot; (a metathesis of k and n). This causes
incorrect transliterations of theses names by our sys-
tem.
The transliteration accuracy on the blind test set
for both our system and the human translator is sig-
nificantly higher than the development test set. This
is because the blind set is mostly of highly frequent,
prominent politicians; whereas the development set
contains also names of writers and less common po-
litical figures and hence are less likely to be in our
unigram language model (and our pronunciation dic-
tionary in the case of the phonetic-based model).
</bodyText>
<sectionHeader confidence="0.999413" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999564826086957">
Mansur Arbabi, Scott M. Fischthal, Vincent C.
Cheng, and Elizabeth Bart. 1994. Algorithms
for Arabic Names Transliteration. IBM Journal
of Research and Development, 38(2).
Asanee Kawtrakul, Amarin Deemagarn, Chalathip
Thumkanon, Navapat Khantonthong, and Paul
McFetridge. 1998. Backward Transliteration for
Thai Document Retrieval. In Proceedings of the
1998 IEEE Asia-Pacific Conference on Circuits
and Systems (APCCAS), pages 563-566.
Kevin Knight and Jonathan Graehl. 1997. Machine
Transliteration. In Proceedings of the 35th Annual
Meeting of the Association for Computational Lin-
guistics, pages 128-135. Morgan Kaufmann.
Klaus Lagally. 1999. ArabTEX: A System
for Typesetting Arabic, User Manual Version
3.09. Technical Report 1998/09, Universitat
Stuttgart, Fakultat Informatik, Breitwiesenstrafie
20-22, 70565 Stuttgart, Germany.
Bonnie G. Stalls and Kevin Knight. 1998. Translat-
ing Names and Technical Terms in Arabic Text.
In Proceedings of the COLING/ACL Workshop on
Computational Approaches to Semitic Languages.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.880069">
<title confidence="0.999391">Machine Transliteration of Names in Arabic Text</title>
<author confidence="0.970717">Yaser Al-Onaizan</author>
<author confidence="0.970717">Kevin</author>
<affiliation confidence="0.9992525">Information Sciences University of Southern</affiliation>
<address confidence="0.994689">4676 Admiralty Way, Suite</address>
<author confidence="0.923264">Marina del Rey</author>
<author confidence="0.923264">CA</author>
<email confidence="0.998979">yaserAisi.edu</email>
<email confidence="0.998979">knightAisi.edu</email>
<abstract confidence="0.999376">We present a transliteration algorithm based on sound and spelling mappings using finite state machines. The transliteration models can be trained on relatively small lists of names. We introduce a new spelling-based model that is much more accurate than state-of-the-art phonetic-based models and can be trained on easier-toobtain training data. We apply our transliteration algorithm to the transliteration of names from Arabic into English. We report on the accuracy of our algorithm based on exact-matching criterion and based on human-subjective evaluation. We also compare the accuracy of our system to the accuracy of human translators.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mansur Arbabi</author>
<author>Scott M Fischthal</author>
<author>Vincent C Cheng</author>
<author>Elizabeth Bart</author>
</authors>
<title>Algorithms for Arabic Names Transliteration.</title>
<date>1994</date>
<journal>IBM Journal of Research and Development,</journal>
<volume>38</volume>
<issue>2</issue>
<contexts>
<context position="4395" citStr="Arbabi et al. (1994)" startWordPosition="673" endWordPosition="676">s compared to the phonetic sequence of a set of English words found in a phonetic dictionary and the word with the most similar phonetic sequence is selected as the transliteration. The approach described by Kawtrakul et al. (1998) requires a phonetic dictionary of English in order to match phonetic sequences. Only those words with known phonetic sequences in the dictionary can be mapped by the transliteration system. Also, applying such technique to Arabic will most likely fail because without short vowels, the pronunciation is highly ambiguous, and so is its corresponding phonetic sequence. Arbabi et al. (1994) describe an algorithm for the forward-transliteration of Arab names into a number of Romance and Germanic languages including English, French, and Spanish. The transliteration process starts by vowelizing the given Arab name by inserting the appropriate short vowels which originally are not written but necessary for the correct pronunciation of the names. Then, the vowelized Arab name is converted into its phonetic Roman representation using a parser and table lookup. The phonetic representation is then used in a table lookup to produce the spelling in the desired language. The vowelization r</context>
</contexts>
<marker>Arbabi, Fischthal, Cheng, Bart, 1994</marker>
<rawString>Mansur Arbabi, Scott M. Fischthal, Vincent C. Cheng, and Elizabeth Bart. 1994. Algorithms for Arabic Names Transliteration. IBM Journal of Research and Development, 38(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asanee Kawtrakul</author>
<author>Amarin Deemagarn</author>
<author>Chalathip Thumkanon</author>
<author>Navapat Khantonthong</author>
<author>Paul McFetridge</author>
</authors>
<title>Backward Transliteration for Thai Document Retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1998 IEEE Asia-Pacific Conference on Circuits and Systems (APCCAS),</booktitle>
<pages>563--566</pages>
<contexts>
<context position="3218" citStr="Kawtrakul et al. (1998)" startWordPosition="490" endWordPosition="493"> two varieties, long and short. Short vowels are rarely written in Arabic in newspaper text, which makes pronunciation highly ambiguous. Also, because of the differences in their sound inventory, there is no one-to-one correspondence between Arabic sounds and English sounds. For example, English P and B are both mapped into Arabic &amp;quot;,_.) b&amp;quot;; Arabic &amp;quot;c and &amp;quot;A h-&amp;quot; into English H; and so on. In this paper, we describe Arabic-to-English name transliteration system using probabilistic finite state machines2 that address both the transliteration of Arab and foreign names into English. 2 Related Work Kawtrakul et al. (1998) present a back transliteration system from Thai into English in the context &apos;Arabic text will be presented throughout this paper using the Arabic script and a romanization based on Lagally (1999). 2We use Carmel, a finite-state toolkit available at http://www.isi.eduilicensed-swicarmeliindex.html of document retrieval. In their approach, loan words are first segmented into syllables using a combination of rules and statistical techniques. Then, syllables are mapped to phonemes based on some transcription rules. The phoneme sequence of the loan word is compared to the phonetic sequence of a se</context>
</contexts>
<marker>Kawtrakul, Deemagarn, Thumkanon, Khantonthong, McFetridge, 1998</marker>
<rawString>Asanee Kawtrakul, Amarin Deemagarn, Chalathip Thumkanon, Navapat Khantonthong, and Paul McFetridge. 1998. Backward Transliteration for Thai Document Retrieval. In Proceedings of the 1998 IEEE Asia-Pacific Conference on Circuits and Systems (APCCAS), pages 563-566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine Transliteration.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>128--135</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="9922" citStr="Knight and Graehl (1997)" startWordPosition="1605" endWordPosition="1608">ied model after training&apos;: a e Position P (a le, Position) 1 )a AH Initial 0.43 L € AH Initial 0.24 L.51 ãy AH Initial 0.05 NULL AH Medial 0.37 I a AH Medial 0.36 i w AH Medial 0.27 I a AH Final 0.93 S t AH Final 0.06 According to this model, the probability of transliterating Arabic word a into English word w is given by the following equation: P(1a) P(wl)P(e1t0P(a H (1) The actual transliteration process is a graphsearch problem through millions of possible mappings to find the best path with English word sequence w that maximizes Pp(&apos; Wia for a given Arabic word sequence a, as described by Knight and Graehl (1997). 5 Spelling-Based Model One serious limitation of the phonetic-based model described above is that only English words with known pronunciations can be produced. For backtransliterating person names of English origin, this is not a big problem because many of such names are typically found in the dictionary. However, applying this technique to transliterate names of origins other than English is not going to work, because many such names are not likely to be in the dictionary despite the fact that the dictionary has more than 100,100 entries in it, as shown in Table 2. Moreover, if we want to </context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1997. Machine Transliteration. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 128-135. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Lagally</author>
</authors>
<title>ArabTEX: A System for Typesetting Arabic, User Manual Version 3.09.</title>
<date>1999</date>
<tech>Technical Report 1998/09,</tech>
<pages>70565</pages>
<institution>Universitat Stuttgart, Fakultat Informatik, Breitwiesenstrafie</institution>
<location>Stuttgart, Germany.</location>
<contexts>
<context position="3414" citStr="Lagally (1999)" startWordPosition="525" endWordPosition="526">no one-to-one correspondence between Arabic sounds and English sounds. For example, English P and B are both mapped into Arabic &amp;quot;,_.) b&amp;quot;; Arabic &amp;quot;c and &amp;quot;A h-&amp;quot; into English H; and so on. In this paper, we describe Arabic-to-English name transliteration system using probabilistic finite state machines2 that address both the transliteration of Arab and foreign names into English. 2 Related Work Kawtrakul et al. (1998) present a back transliteration system from Thai into English in the context &apos;Arabic text will be presented throughout this paper using the Arabic script and a romanization based on Lagally (1999). 2We use Carmel, a finite-state toolkit available at http://www.isi.eduilicensed-swicarmeliindex.html of document retrieval. In their approach, loan words are first segmented into syllables using a combination of rules and statistical techniques. Then, syllables are mapped to phonemes based on some transcription rules. The phoneme sequence of the loan word is compared to the phonetic sequence of a set of English words found in a phonetic dictionary and the word with the most similar phonetic sequence is selected as the transliteration. The approach described by Kawtrakul et al. (1998) require</context>
</contexts>
<marker>Lagally, 1999</marker>
<rawString>Klaus Lagally. 1999. ArabTEX: A System for Typesetting Arabic, User Manual Version 3.09. Technical Report 1998/09, Universitat Stuttgart, Fakultat Informatik, Breitwiesenstrafie 20-22, 70565 Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie G Stalls</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Names and Technical Terms in Arabic Text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="5431" citStr="Stalls and Knight (1998)" startWordPosition="837" endWordPosition="840">honetic Roman representation using a parser and table lookup. The phonetic representation is then used in a table lookup to produce the spelling in the desired language. The vowelization rules described by Arbabi et al. (1994) apply only to Arab names that conform to strict Arabic morphological rules. Any name that does not conform to the morphological rules is ignored and hence no transliteration will be attempted. This restriction limits the applicability of this approach since many person and organization names do not conform to morphological rules, especially loan words and foreign names. Stalls and Knight (1998) present an Arabic-toEnglish back-transliteration system based on the source-channel framework. The transliteration process is based on a generative model of how an English name is transliterated into Arabic. It consists of several steps, each defined as a probabilistic model represented as a finite state machine. First, an English word w is generated according to its unigram probabilities Pe). Then, the English word w is pronounced (i.e., converted to sound sequence c) with probability P (61w) which is collected directly from an English pronunciation dictionary. Finally, the English phoneme s</context>
</contexts>
<marker>Stalls, Knight, 1998</marker>
<rawString>Bonnie G. Stalls and Kevin Knight. 1998. Translating Names and Technical Terms in Arabic Text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>