<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.211931">
<title confidence="0.625092857142857">
Current Research in the Development of a Spoken Language
Understanding System using PARSEC*
Carla B. Zoltowski
School of Electrical Engineering
Purdue University
West Lafayette, IN 47907
February 28, 1991
</title>
<sectionHeader confidence="0.99655" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999997230769231">
We are developing a spoken language system
which would more effectively merge natural lan-
guage and speech recognition technology by us-
ing a more flexible parsing strategy and utiliz-
ing prosody, the suprasegmental information in
speech such as stress, rhythm, and intonation.
There is a considerable amount of evidence which
indicates that prosodic information impacts hu-
man speech perception at many different levels
[5]. Therefore, it is generally agreed that spoken
language systems would benefit from its addi-
tion to the traditional knowledge sources such
as acoustic-phonetic, syntactic, and semantic in-
formation. A recent and novel approach to incor-
porating prosodic information, specifically the
relative duration of phonetic segments, was de-
veloped by Patti Price and John Bear [1, 4].
They have developed an algorithm for computing
break indices using a hidden Markov model, and
have modified the context-free grammar rules to
incorporate links between non-terminals which
corresponded to the break indices. Although in-
corporation of this information reduced the num-
ber of possible parses, the processing time in-
creased because of the addition of the link nodes
in the grammar.
</bodyText>
<sectionHeader confidence="0.986874" genericHeader="method">
2 Constraint Dependency
</sectionHeader>
<subsectionHeader confidence="0.908408">
Grammar
</subsectionHeader>
<bodyText confidence="0.9995875">
Instead of using context-free grammars, we are
using a natural language framework based on the
</bodyText>
<subsectionHeader confidence="0.990556">
*Parallel Architecture Sentence Constrainer
</subsectionHeader>
<bodyText confidence="0.999948947368421">
Constraint Dependency Grammar (CDG) for-
malism developed by Maruyama [3]. This frame-
work allows us to handle prosodic information
quite easily. Rather than coordinating lexical,
syntactic, semantic, and contextual modules to
develop the meaning of a sentence, we apply
sets of lexical, syntactic, prosodic, semantic, and
pragmatic rules to a packed structure containing
a developing picture of the structure and mean-
ing of a sentence. The CDG grammar has a weak
generative capacity which is strictly greater than
that of context-free grammars and has the added
advantage of benefiting significantly from a par-
allel architecture [2]. PARSEC is our system
based on the CDG formalism.
To develop a syntactic and semantic analysis
using this framework, a network of the words for
a given sentence is constructed. Each word is
given some number indicating its position rela-
tive to the other words in the sentence. Once
a word is entered in the network, the system
assigns all of the possible roles the words can
have by applying the lexical constraints (which
specify legal word categories) and allowing the
word to modify all the remaining words in the
sentence or no words at all. Each of the arcs
in the network has associated with it a matrix
whose row and column indices are the roles that
the words can play in the sentence. Initially, all
entries in the matrices are set to one, indicat-
ing that there is nothing about one word&apos;s func-
tion which prohibits another word&apos;s right to fill
a certain role in the sentence. Once the net-
work is constructed, additional constraints are
introduced to limit the role of each word in the
sentence to a single function. In a spoken lan-
guage system which may contain several possible
candidates for each word, constraints would also
</bodyText>
<page confidence="0.996592">
353
</page>
<bodyText confidence="0.9999705">
provide feedback about impossible word candi-
dates.
We have been able to incorporate the dura-
tional information from Bear and Price quite
easily into our framework. An advantage of
our approach is that the prosodic information
is added as constraints instead of incorporat-
ing it into a parsing grammar. •Because CDG
is more expressive than context-free grammars,
we can produce prosodic rules that are more ex-
pressive than Bear and Price are able to pro-
vide by augmenting context-free grammars. Also
by formulating prosodic rules as constraints, we
avoid the need to clutter our rules with nonter-
minals required by context-free grammars when
they are augmented to handle prosody. Assum-
ing 0(n4/log(n)) processors, the cost of apply-
ing each constraint is 0(log (n)) [2]. Whenever
we apply a constraint to the network, our pro-
cessing time is incremented by this amount. In
contrast, Bear and Price, by doubling the size of
the grammar are multiplying the processing time
by a factor of 8 when no prosodic information is
available (assuming (2n)3 = 8n3 time).
</bodyText>
<sectionHeader confidence="0.921548" genericHeader="method">
3 Current Research
</sectionHeader>
<bodyText confidence="0.999990172413793">
Our current research effort consists of the devel-
opment of algorithms for extracting the prosodic
information from the speech signal and incor-
poration of this information into the PARSEC
framework. In addition, we will be working to
interface PARSEC with the speech recognition
system being developed at Purdue by Mitchell
and Jamieson.
We have selected a corpus of 14 syntactically
ambiguous sentences for our initial experimen-
tation. We have predicted what prosodic fea-
tures humans use to disambiguate the sentences
and are attempting to develop algorithms to ex-
tract those features from the speech. We are
hoping to build upon those algorithms presented
in [1, 4, 5]. Initially we are using a professional
speaker trained in prosodics in our experiments,
but eventually we will test our results with an
untrained speaker.
Although our current system allows multiple
word candidates, it assumes that each of the pos-
sible words begin and end at the same time. It
currently does not allow for non-aligned word
boundaries, lit addition, the output of the speech
recognition system which we will be utilizing will
consist of the most likely sequence of phonemes
for a given utterance, so additional work will be
required to extract the most likely word candi-
dates for use in our system.
</bodyText>
<sectionHeader confidence="0.998664" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999631">
The CDG formalism provides a very promis-
ing framework for our spoken language system.
We believe its flexibility will allow it to over-
come many of the limitations imposed by natural
language systems developed primarily for text-
based applications, such as repeated words and
false starts of phrases. In addition, we believe
that prosody will help to resolve the ambigu-
ity introduced by the speech recognition system
which is not present in text-based systems.
</bodyText>
<sectionHeader confidence="0.999324" genericHeader="method">
5 Acknowledgement
</sectionHeader>
<bodyText confidence="0.997847333333333">
This research was supported in part by NSF IRI-
9011179 under the guidance of Profs. Mary P.
Harper and Leah H. Jamieson.
</bodyText>
<sectionHeader confidence="0.999033" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999914571428571">
[1] J. Bear and P. Price. Prosody, syntax, and parsing.
In Proceedings of the 28th annual ACL, 1990.
[2] R. Helzerman and M.P. Harper. Parsec: An archi-
tecture for parallel parsing of constraint dependency
grammars. In Submitted to The Proceedings of the
29th Annual Meeting of ACL, June 1991.
[3] H. Maruyama. Constraint dependency grammar.
Technical Report #RT0044, IBM, Tokyo, Japan,
1990.
[4] P. Price, C. Wightman, M. Ostendorf, and J. Bear.
The use of relative duration in syntactic disambigua-
tion. In Proceedings of ICSLP, 1990.
[5] A. Waibel. Prosody and Speech Recognition. Morgan
Kaufmann Publishers, Los Altos, CA, 1988.
</reference>
<page confidence="0.999149">
354
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902393">
<title confidence="0.991112">Current Research in the Development of a Spoken Language Understanding System using PARSEC*</title>
<author confidence="0.999982">Carla B Zoltowski</author>
<affiliation confidence="0.9698975">School of Electrical Engineering University</affiliation>
<address confidence="0.999312">West Lafayette, IN 47907</address>
<date confidence="0.977496">February 28, 1991</date>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bear</author>
<author>P Price</author>
</authors>
<title>Prosody, syntax, and parsing.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th annual ACL,</booktitle>
<contexts>
<context position="1011" citStr="[1, 4]" startWordPosition="149" endWordPosition="150">prosody, the suprasegmental information in speech such as stress, rhythm, and intonation. There is a considerable amount of evidence which indicates that prosodic information impacts human speech perception at many different levels [5]. Therefore, it is generally agreed that spoken language systems would benefit from its addition to the traditional knowledge sources such as acoustic-phonetic, syntactic, and semantic information. A recent and novel approach to incorporating prosodic information, specifically the relative duration of phonetic segments, was developed by Patti Price and John Bear [1, 4]. They have developed an algorithm for computing break indices using a hidden Markov model, and have modified the context-free grammar rules to incorporate links between non-terminals which corresponded to the break indices. Although incorporation of this information reduced the number of possible parses, the processing time increased because of the addition of the link nodes in the grammar. 2 Constraint Dependency Grammar Instead of using context-free grammars, we are using a natural language framework based on the *Parallel Architecture Sentence Constrainer Constraint Dependency Grammar (CDG</context>
<context position="5093" citStr="[1, 4, 5]" startWordPosition="814" endWordPosition="816">lgorithms for extracting the prosodic information from the speech signal and incorporation of this information into the PARSEC framework. In addition, we will be working to interface PARSEC with the speech recognition system being developed at Purdue by Mitchell and Jamieson. We have selected a corpus of 14 syntactically ambiguous sentences for our initial experimentation. We have predicted what prosodic features humans use to disambiguate the sentences and are attempting to develop algorithms to extract those features from the speech. We are hoping to build upon those algorithms presented in [1, 4, 5]. Initially we are using a professional speaker trained in prosodics in our experiments, but eventually we will test our results with an untrained speaker. Although our current system allows multiple word candidates, it assumes that each of the possible words begin and end at the same time. It currently does not allow for non-aligned word boundaries, lit addition, the output of the speech recognition system which we will be utilizing will consist of the most likely sequence of phonemes for a given utterance, so additional work will be required to extract the most likely word candidates for use</context>
</contexts>
<marker>[1]</marker>
<rawString>J. Bear and P. Price. Prosody, syntax, and parsing. In Proceedings of the 28th annual ACL, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Helzerman</author>
<author>M P Harper</author>
</authors>
<title>Parsec: An architecture for parallel parsing of constraint dependency grammars.</title>
<date>1991</date>
<booktitle>In Submitted to The Proceedings of the 29th Annual Meeting of ACL,</booktitle>
<contexts>
<context position="2207" citStr="[2]" startWordPosition="330" endWordPosition="330">ar (CDG) formalism developed by Maruyama [3]. This framework allows us to handle prosodic information quite easily. Rather than coordinating lexical, syntactic, semantic, and contextual modules to develop the meaning of a sentence, we apply sets of lexical, syntactic, prosodic, semantic, and pragmatic rules to a packed structure containing a developing picture of the structure and meaning of a sentence. The CDG grammar has a weak generative capacity which is strictly greater than that of context-free grammars and has the added advantage of benefiting significantly from a parallel architecture [2]. PARSEC is our system based on the CDG formalism. To develop a syntactic and semantic analysis using this framework, a network of the words for a given sentence is constructed. Each word is given some number indicating its position relative to the other words in the sentence. Once a word is entered in the network, the system assigns all of the possible roles the words can have by applying the lexical constraints (which specify legal word categories) and allowing the word to modify all the remaining words in the sentence or no words at all. Each of the arcs in the network has associated with i</context>
<context position="4116" citStr="[2]" startWordPosition="656" endWordPosition="656">An advantage of our approach is that the prosodic information is added as constraints instead of incorporating it into a parsing grammar. •Because CDG is more expressive than context-free grammars, we can produce prosodic rules that are more expressive than Bear and Price are able to provide by augmenting context-free grammars. Also by formulating prosodic rules as constraints, we avoid the need to clutter our rules with nonterminals required by context-free grammars when they are augmented to handle prosody. Assuming 0(n4/log(n)) processors, the cost of applying each constraint is 0(log (n)) [2]. Whenever we apply a constraint to the network, our processing time is incremented by this amount. In contrast, Bear and Price, by doubling the size of the grammar are multiplying the processing time by a factor of 8 when no prosodic information is available (assuming (2n)3 = 8n3 time). 3 Current Research Our current research effort consists of the development of algorithms for extracting the prosodic information from the speech signal and incorporation of this information into the PARSEC framework. In addition, we will be working to interface PARSEC with the speech recognition system being d</context>
</contexts>
<marker>[2]</marker>
<rawString>R. Helzerman and M.P. Harper. Parsec: An architecture for parallel parsing of constraint dependency grammars. In Submitted to The Proceedings of the 29th Annual Meeting of ACL, June 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Maruyama</author>
</authors>
<title>Constraint dependency grammar.</title>
<date>1990</date>
<tech>Technical Report #RT0044,</tech>
<location>IBM, Tokyo, Japan,</location>
<contexts>
<context position="1648" citStr="[3]" startWordPosition="244" endWordPosition="244"> for computing break indices using a hidden Markov model, and have modified the context-free grammar rules to incorporate links between non-terminals which corresponded to the break indices. Although incorporation of this information reduced the number of possible parses, the processing time increased because of the addition of the link nodes in the grammar. 2 Constraint Dependency Grammar Instead of using context-free grammars, we are using a natural language framework based on the *Parallel Architecture Sentence Constrainer Constraint Dependency Grammar (CDG) formalism developed by Maruyama [3]. This framework allows us to handle prosodic information quite easily. Rather than coordinating lexical, syntactic, semantic, and contextual modules to develop the meaning of a sentence, we apply sets of lexical, syntactic, prosodic, semantic, and pragmatic rules to a packed structure containing a developing picture of the structure and meaning of a sentence. The CDG grammar has a weak generative capacity which is strictly greater than that of context-free grammars and has the added advantage of benefiting significantly from a parallel architecture [2]. PARSEC is our system based on the CDG f</context>
</contexts>
<marker>[3]</marker>
<rawString>H. Maruyama. Constraint dependency grammar. Technical Report #RT0044, IBM, Tokyo, Japan, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Price</author>
<author>C Wightman</author>
<author>M Ostendorf</author>
<author>J Bear</author>
</authors>
<title>The use of relative duration in syntactic disambiguation.</title>
<date>1990</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<contexts>
<context position="1011" citStr="[1, 4]" startWordPosition="149" endWordPosition="150">prosody, the suprasegmental information in speech such as stress, rhythm, and intonation. There is a considerable amount of evidence which indicates that prosodic information impacts human speech perception at many different levels [5]. Therefore, it is generally agreed that spoken language systems would benefit from its addition to the traditional knowledge sources such as acoustic-phonetic, syntactic, and semantic information. A recent and novel approach to incorporating prosodic information, specifically the relative duration of phonetic segments, was developed by Patti Price and John Bear [1, 4]. They have developed an algorithm for computing break indices using a hidden Markov model, and have modified the context-free grammar rules to incorporate links between non-terminals which corresponded to the break indices. Although incorporation of this information reduced the number of possible parses, the processing time increased because of the addition of the link nodes in the grammar. 2 Constraint Dependency Grammar Instead of using context-free grammars, we are using a natural language framework based on the *Parallel Architecture Sentence Constrainer Constraint Dependency Grammar (CDG</context>
<context position="5093" citStr="[1, 4, 5]" startWordPosition="814" endWordPosition="816">lgorithms for extracting the prosodic information from the speech signal and incorporation of this information into the PARSEC framework. In addition, we will be working to interface PARSEC with the speech recognition system being developed at Purdue by Mitchell and Jamieson. We have selected a corpus of 14 syntactically ambiguous sentences for our initial experimentation. We have predicted what prosodic features humans use to disambiguate the sentences and are attempting to develop algorithms to extract those features from the speech. We are hoping to build upon those algorithms presented in [1, 4, 5]. Initially we are using a professional speaker trained in prosodics in our experiments, but eventually we will test our results with an untrained speaker. Although our current system allows multiple word candidates, it assumes that each of the possible words begin and end at the same time. It currently does not allow for non-aligned word boundaries, lit addition, the output of the speech recognition system which we will be utilizing will consist of the most likely sequence of phonemes for a given utterance, so additional work will be required to extract the most likely word candidates for use</context>
</contexts>
<marker>[4]</marker>
<rawString>P. Price, C. Wightman, M. Ostendorf, and J. Bear. The use of relative duration in syntactic disambiguation. In Proceedings of ICSLP, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Waibel</author>
</authors>
<title>Prosody and Speech Recognition.</title>
<date>1988</date>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>Los Altos, CA,</location>
<contexts>
<context position="640" citStr="[5]" startWordPosition="94" endWordPosition="94">f a Spoken Language Understanding System using PARSEC* Carla B. Zoltowski School of Electrical Engineering Purdue University West Lafayette, IN 47907 February 28, 1991 1 Introduction We are developing a spoken language system which would more effectively merge natural language and speech recognition technology by using a more flexible parsing strategy and utilizing prosody, the suprasegmental information in speech such as stress, rhythm, and intonation. There is a considerable amount of evidence which indicates that prosodic information impacts human speech perception at many different levels [5]. Therefore, it is generally agreed that spoken language systems would benefit from its addition to the traditional knowledge sources such as acoustic-phonetic, syntactic, and semantic information. A recent and novel approach to incorporating prosodic information, specifically the relative duration of phonetic segments, was developed by Patti Price and John Bear [1, 4]. They have developed an algorithm for computing break indices using a hidden Markov model, and have modified the context-free grammar rules to incorporate links between non-terminals which corresponded to the break indices. Alth</context>
<context position="5093" citStr="[1, 4, 5]" startWordPosition="814" endWordPosition="816">lgorithms for extracting the prosodic information from the speech signal and incorporation of this information into the PARSEC framework. In addition, we will be working to interface PARSEC with the speech recognition system being developed at Purdue by Mitchell and Jamieson. We have selected a corpus of 14 syntactically ambiguous sentences for our initial experimentation. We have predicted what prosodic features humans use to disambiguate the sentences and are attempting to develop algorithms to extract those features from the speech. We are hoping to build upon those algorithms presented in [1, 4, 5]. Initially we are using a professional speaker trained in prosodics in our experiments, but eventually we will test our results with an untrained speaker. Although our current system allows multiple word candidates, it assumes that each of the possible words begin and end at the same time. It currently does not allow for non-aligned word boundaries, lit addition, the output of the speech recognition system which we will be utilizing will consist of the most likely sequence of phonemes for a given utterance, so additional work will be required to extract the most likely word candidates for use</context>
</contexts>
<marker>[5]</marker>
<rawString>A. Waibel. Prosody and Speech Recognition. Morgan Kaufmann Publishers, Los Altos, CA, 1988.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>