<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.260346">
<title confidence="0.482483">
A MODEL OF SPEECH ACT PLANNER ADAPTED TO MULTIAGENT UNIVERSES
</title>
<author confidence="0.92945">
Daniel Rousseau, Guy Lapalme
</author>
<affiliation confidence="0.99975">
Department of Computer Science and Operational Research
University of Montreal, Montreal, Canada
</affiliation>
<email confidence="0.97924">
E-mail: roussead@iro.umontreal.ca, lapalme@iro.umontreal.ca
</email>
<author confidence="0.791479">
Bernard Moulin
</author>
<affiliation confidence="0.9990325">
Department of Computer Science
Laval University, Quebec, Canada
</affiliation>
<email confidence="0.997684">
E-mail: moulin@vm.ulaval.ca
</email>
<bodyText confidence="0.999829206896552">
A multiagent universe is characterized by many agents who cooperate (i.e. share a
common goal) or compete (i.e. have conflictual goals). With cooperation, an agent may take
advantage of other agent&apos;s abilities and increase her chance to reach her goals. But
competition between agents decreases the opportunities to reach her own goals, because one
agent&apos;s action might interfere with the ones of the other agent. So, it is very important to
cooperate when it is possible and to negotiate when there are conflictual goals.
Conversation is a form of cooperation by means of interrelated speech acts, also called
illocutionary or linguistic acts, between two or more agents. Each speech act is not executed
immediately, but is planned by an agent in order to reach some goal in the conversation
context. In fact, a speech act is for an agent the best mean to transmit her mental states to
other agents, to try to change their mental states and to affect their behavior in the same
direction that she wants. A minimal level of cooperation is necessary to achieve a coherent
and satisfying conversation between all participants. Before executing a speech act, an agent
must take into consideration many factors such as the context of utterance, including previous
speech acts of the current conversation and the participants&apos; mental states, and shared rules of
communication such as Grice&apos;s (1975) conversational maxims. During a conversation, it is
also possible for an agent to execute non-linguistic speech acts.
In this context, we propose a model of speech act planner to be used in a cooperative
responses generation system. The model can explain an agent&apos;s general behavior during a
conversation involving two agents or more. It deals with the reasoning process between the
perception of a situation and with the execution of a linguistic or non-linguistic action. It
reasons about mental states belonging to herself or to other agents such as goals, intentions,
beliefs, low-level actions and plans containing linguistic and non-linguistic actions. It
integrates ideas from the following domains: intention in speech acts, structure of
conversation and planning.
Some people (Searle and Vanderveken 1985, Cohen and Levesque 1990) have assumed
that the recognition of the speaker&apos;s intention and other mental states in producing an utterance
is extremely important to understand its meaning, but have limited their work on one single
speech act. Because a conversation is a temporal sequence of connected illocutionary acts
</bodyText>
<page confidence="0.996001">
110
</page>
<bodyText confidence="0.999701736842106">
(Moulin, Rousseau and Vanderveken 1991) where each speech act plays a precise role in the
context of other speech acts, some researchers have studied the structure of a conversation and
they all agreed that there are several interrelated components in it and many subconversations
of different types (Grosz and Sidner 1986, Litman and Allen 1987). The planning approach
has been used by some scientists to produce speech acts in the context of a dialogue (Allen
1983, Appelt 1985, Litman and Allen 1987, Lambert and Carberry 1992).
Starting from the approaches mentioned above, the model of speech act planner we
propose takes into consideration the following problems: multiagent planning, reasoning on
other agents&apos; mental states and on one&apos;s own mental states, recognition of intentions behind
direct and indirect speech acts, use of plans integrating linguistic and non-linguistic actions,
coherence of the conversation between two or more agents, handling of subconversations and
modeling of the conversational context.
We assume that a conversation is a task shared by many agents that is the result of
&amp;quot;reactive distributed planning&amp;quot; A conversational participant cannot control all the content of a
conversation, but adapts its behavior by reacting to what has just been said. An agent that
cannot reach a goal without communicating with another agent initiates a conversation by
executing a planned speech act. In reaction to a speech act, at any time during a conversation,
a participant must process it in many steps before executing an action, usually a speech act. It
must interprete it by recognizing the intention of the speaker and update its beliefs. It must
revise its goals, particularly when it must take turn according to the conversational state. In
this case, it has a new communication goal, like answering a question or clarifying the last
speech act, for which it constructs a plan to reach it. This plan generally specify one or more
speech acts to execute. The conversation is ended when there is no more reason to continue it,
i. e. when the goal for which it was initiated has been reached or cannot be reached anymore.
We will illustrate the planning process during a conversation in the context of a
multiagent universe with the following example. Four cooperative robots, that can
communicate with another robot and execute a particular task, are in a working shop. One
robot can lift and move an object, including another robot, unless it weights too much. In that
case, two robots can join forces to lift and move it. When there is a breakdown, a robot has to
go to the repair station.
Suppose that a robot, called Dartagnan, cannot move anymore. So, Dartagnan must go
to the repair station after taking an appointment, but it cannot move. It has to ask another
robot for help to reach the repair station. A sollicited robot that cannot lift and move
Dartagnan will have to ask for help before declining assistance, unless it is already too busy.
Taking an appointment and asking help take the form of speech acts in the context of a
conversation. For each conversation, there is a goal that an initiator conversational agent tries
to satisfy. For example, suppose that Dartagnan already has an appointment with the repair
station. A conversation between Dartagnan and another robot, Portos, may look like this:
</bodyText>
<table confidence="0.789395666666667">
Dartagnan: Portos, please carry me to the repair station by 10 o&apos;clock.
Portos: Sorry, I cannot help you.
Dartagnan: OK, I will ask another robot to help me.
</table>
<page confidence="0.996732">
111
</page>
<bodyText confidence="0.999986928571428">
This quite simple conversation involves a lot of problems to be solved by the two
conversational agents. Before initiating the conversation, Dartagnan has to decide which robot
to talk to. Then, it has to choose what to say to initiate the conversation in order to allow
Portos to recognize its intentions. After receiving the request, Portos must recognize
Dartagnan&apos;s intention and update its knowledge base. Then, it has to decide if it can help
Dartagnan or if not. In the example, Portos is too busy. Dartagnan, after receiving the
response from Portos, must identify Portos&apos; mental states and decide if it accepts this response
or if it proposes a compromise. Here Dartagnan accepts the response and therefore ends the
conversation.
So, before and after each speech act, a lot of reasoning about mental states is necessary
for all the conversational agents involved in a conversation. The speech act planner we
propose tries to model all this necessary reasoning to get a conversation such as the above.
We assume that we must take into account in our planner the general script of a
conversation to generate coherent ones. A conversation is an evolving object. At a global
level, each conversation follows the same conversational script that describes the possible
states of a conversation and the possible transitions between them. A transition is insured by
the application of a private plan by an agent. According to DeVito (1992), there are five
possible states for a conversation: opening, feedforward (the general goal of the conversation
is given), business (the substance of the conversation), feedback (synthesis of the discussion)
and closing. Note that the feedback state is not always present in an instance of conversation.
At these five basic states, we add two other ones, interruption and reopening, because we
consider the cases when a conversation is interrupted by an agent. For instance, an agent may
interrupt a conversation before answering a request.
Each state can be considered as a conversational goal and be focalised into lower level
conversational states during the conversation. These states may be different, depending of the
conversation. A question is asked or a promise is done are examples of states. We cannot
find these states in any order to have a coherent conversation. So, we assume that there are
some rules to respect when we are in some conversational state. These rules precise the
possible and necessary transitions between conversational states, the agent that is responsible
of the transitions and the conditions, expressed in terms of mental states, associated with
them. For example, when a question has just been asked to an agent, it has to answer it if it
knows the answer and has no reason to hide it. If the question is not clear for it, it can initiate
a clarification subdialogue by asking for some clarification. But it was not very conventional
to give an order to the other agent at this time. Therefore, a conversation is like a construction
made of LEG0114 blocks, where you can put a block of a certain type at a few places only.
Each conversation has global parameters that respond to the following questions: who?
(the conversational participants), why? (the goal behind the conversation), when? (the time),
where? (the place) and how? (the type of the conversation). The answer to the question &apos;what?&apos;
is composed of the surface linguistic acts themselves and the corresponding speech acts. All
these information is part of the conversational context, like all the knowledge and mentals
states of the conversational participants. In fact, the conversational context contains all the
information that is important for a speech act planner to participate to a conversation.
</bodyText>
<page confidence="0.994422">
112
</page>
<bodyText confidence="0.996288818181818">
So the model of speech act planner we propose deals with two aspects of a
conversation: its planning and its structure. Up to now, we have established the global
framework of the theoretical model and tested it on dialogues like the one between Dartagnan
and Portos. In the future, we will describe in more detail the different steps of the planning
process, the necessary data structures and the acceptable transitions between conversational
states. To handle conversations involving more than two agents, we expect to reduce them to
many partially ordered dialogues (conversations between two agents only), where one agent
participating to the conversation is conscious of all the dialogues. Finally, we will test our
model by integrating it in a prototype that will simulate the behavior of many agents that will
participate to a conversation in a given situation by producing speech acts from their mental
states and their knowledge.
</bodyText>
<sectionHeader confidence="0.998701" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.99804488">
ALLEN J. F. (1983), &amp;quot;Recognizing Intentions from Natural Language Utterances&amp;quot;, in M.
Bradie ad R. C. Berwick editors, Computational Models of Discourse, MIT Press, Cambridge,
Massachusetts, chap. 2 pp. 108-166.
APPELT D. E. (1985), &amp;quot;Planning English Sentences&amp;quot;, Cambridge University Press,
Cambridge, Great Britain.
COHEN P. R., LEVESQUE H. J. (1990), &amp;quot;Rational Interaction as the Basis for
Comuunication&amp;quot;, in P. R. Cohen, J. Morgan and M. E. Pollack editors, Intentions in
Communication, MIT Press, Cambridge, Massachustetts, Chap. 12, pp. 221-255.
DEVITO J. A. (1992), &amp;quot;The Interpersonal Book&amp;quot;, Sixth edition, HarperCollins Publishers,
New York.
GRICE H. P. (1975), &amp;quot;Logic and Conversation&amp;quot;, in P. Cole and J. L. Morgan editors, &amp;quot;Syntax
and Semantics, vol. III: Speech Acts&amp;quot;, Academic Press, New York, pp. 41-58.
GROSZ B. J., SIDNER C. L. (1986), &amp;quot;Attention, Intentions and the Structure of Discourse&amp;quot;, in
Computational Linguistics, Vol. 12, No 3, July-September 1986, pp. 175-204.
LAMBERT L., CARBERRY S. (1992), &amp;quot;Modeling Negotiation Subdialogues&amp;quot;, in
Proceedings of the Conference of the 30th Annual Meeting of the Association for
Computational Linguistics, Newark, Delaware, pp. 193-200, June 1992.
LITMAN D. J., ALLEN J. F. (1987), &amp;quot;A Plan Recognition Model for Subdialogues in
Conversations&amp;quot;, in Cognitive Science, Vol. 11, pp. 163-200.
MOULIN B., ROUSSEAU D., VANDERVEKEN D. (1991), &amp;quot;Speech Acts in a Connected
Discourse: A Computational Representation Based on Conceptual Graph Theory&amp;quot;, in
Proceedings of the Sixth Annual Workshop on Conceptual Graphs, July 1991, Binghamton,
New York, pp. 269-282.
SEARLE J. R., VANDERVEKEN D. (1985), &amp;quot;Foundations of Illocutionary Logic&amp;quot;,
Cambridge University Press, Cambridge, Great Britain.
</reference>
<page confidence="0.999334">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.059937">
<title confidence="0.999703">A MODEL OF SPEECH ACT PLANNER ADAPTED TO MULTIAGENT UNIVERSES</title>
<author confidence="0.999987">Daniel Rousseau</author>
<author confidence="0.999987">Guy</author>
<affiliation confidence="0.9820105">Department of Computer Science and Operational University of Montreal, Montreal,</affiliation>
<email confidence="0.994708">E-mail:roussead@iro.umontreal.ca,lapalme@iro.umontreal.ca</email>
<author confidence="0.908311">Bernard</author>
<affiliation confidence="0.9960545">Department of Computer Laval University, Quebec,</affiliation>
<email confidence="0.993064">E-mail:moulin@vm.ulaval.ca</email>
<abstract confidence="0.999604285714286">A multiagent universe is characterized by many agents who cooperate (i.e. share a common goal) or compete (i.e. have conflictual goals). With cooperation, an agent may take advantage of other agent&apos;s abilities and increase her chance to reach her goals. But competition between agents decreases the opportunities to reach her own goals, because one agent&apos;s action might interfere with the ones of the other agent. So, it is very important to cooperate when it is possible and to negotiate when there are conflictual goals. Conversation is a form of cooperation by means of interrelated speech acts, also called illocutionary or linguistic acts, between two or more agents. Each speech act is not executed immediately, but is planned by an agent in order to reach some goal in the conversation context. In fact, a speech act is for an agent the best mean to transmit her mental states to other agents, to try to change their mental states and to affect their behavior in the same that wants. minimal level of cooperation is necessary to achieve a coherent and satisfying conversation between all participants. Before executing a speech act, an agent must take into consideration many factors such as the context of utterance, including previous speech acts of the current conversation and the participants&apos; mental states, and shared rules of communication such as Grice&apos;s (1975) conversational maxims. During a conversation, it is also possible for an agent to execute non-linguistic speech acts. In this context, we propose a model of speech act planner to be used in a cooperative responses generation system. The model can explain an agent&apos;s general behavior during a conversation involving two agents or more. It deals with the reasoning process between the perception of a situation and with the execution of a linguistic or non-linguistic action. It reasons about mental states belonging to herself or to other agents such as goals, intentions, beliefs, low-level actions and plans containing linguistic and non-linguistic actions. It integrates ideas from the following domains: intention in speech acts, structure of conversation and planning. Some people (Searle and Vanderveken 1985, Cohen and Levesque 1990) have assumed that the recognition of the speaker&apos;s intention and other mental states in producing an utterance is extremely important to understand its meaning, but have limited their work on one single speech act. Because a conversation is a temporal sequence of connected illocutionary acts 110 (Moulin, Rousseau and Vanderveken 1991) where each speech act plays a precise role in the context of other speech acts, some researchers have studied the structure of a conversation and they all agreed that there are several interrelated components in it and many subconversations of different types (Grosz and Sidner 1986, Litman and Allen 1987). The planning approach has been used by some scientists to produce speech acts in the context of a dialogue (Allen 1983, Appelt 1985, Litman and Allen 1987, Lambert and Carberry 1992). Starting from the approaches mentioned above, the model of speech act planner we propose takes into consideration the following problems: multiagent planning, reasoning on other agents&apos; mental states and on one&apos;s own mental states, recognition of intentions behind direct and indirect speech acts, use of plans integrating linguistic and non-linguistic actions, coherence of the conversation between two or more agents, handling of subconversations and modeling of the conversational context. We assume that a conversation is a task shared by many agents that is the result of &amp;quot;reactive distributed planning&amp;quot; A conversational participant cannot control all the content of a conversation, but adapts its behavior by reacting to what has just been said. An agent that cannot reach a goal without communicating with another agent initiates a conversation by executing a planned speech act. In reaction to a speech act, at any time during a conversation, a participant must process it in many steps before executing an action, usually a speech act. It must interprete it by recognizing the intention of the speaker and update its beliefs. It must revise its goals, particularly when it must take turn according to the conversational state. In this case, it has a new communication goal, like answering a question or clarifying the last speech act, for which it constructs a plan to reach it. This plan generally specify one or more speech acts to execute. The conversation is ended when there is no more reason to continue it, when the goal for which it was initiated has been reached or cannot be reached anymore. We will illustrate the planning process during a conversation in the context of a multiagent universe with the following example. Four cooperative robots, that can communicate with another robot and execute a particular task, are in a working shop. One robot can lift and move an object, including another robot, unless it weights too much. In that case, two robots can join forces to lift and move it. When there is a breakdown, a robot has to go to the repair station. Suppose that a robot, called Dartagnan, cannot move anymore. So, Dartagnan must go to the repair station after taking an appointment, but it cannot move. It has to ask another robot for help to reach the repair station. A sollicited robot that cannot lift and move Dartagnan will have to ask for help before declining assistance, unless it is already too busy. Taking an appointment and asking help take the form of speech acts in the context of a conversation. For each conversation, there is a goal that an initiator conversational agent tries to satisfy. For example, suppose that Dartagnan already has an appointment with the repair station. A conversation between Dartagnan and another robot, Portos, may look like this: please carry me to the repair station by 10 o&apos;clock. I cannot help you. I will ask another robot to help me. 111 This quite simple conversation involves a lot of problems to be solved by the two conversational agents. Before initiating the conversation, Dartagnan has to decide which robot to talk to. Then, it has to choose what to say to initiate the conversation in order to allow Portos to recognize its intentions. After receiving the request, Portos must recognize Dartagnan&apos;s intention and update its knowledge base. Then, it has to decide if it can help Dartagnan or if not. In the example, Portos is too busy. Dartagnan, after receiving the response from Portos, must identify Portos&apos; mental states and decide if it accepts this response or if it proposes a compromise. Here Dartagnan accepts the response and therefore ends the conversation. So, before and after each speech act, a lot of reasoning about mental states is necessary for all the conversational agents involved in a conversation. The speech act planner we propose tries to model all this necessary reasoning to get a conversation such as the above. We assume that we must take into account in our planner the general script of a conversation to generate coherent ones. A conversation is an evolving object. At a global level, each conversation follows the same conversational script that describes the possible states of a conversation and the possible transitions between them. A transition is insured by the application of a private plan by an agent. According to DeVito (1992), there are five states for a conversation: feedforward general goal of the conversation given), substance of the conversation), of the discussion) that the state not always present in an instance of conversation. these five basic states, we add two other ones, we consider the cases when a conversation is interrupted by an agent. For instance, an agent may interrupt a conversation before answering a request. Each state can be considered as a conversational goal and be focalised into lower level conversational states during the conversation. These states may be different, depending of the A is asked promise is done examples of states. We cannot find these states in any order to have a coherent conversation. So, we assume that there are some rules to respect when we are in some conversational state. These rules precise the possible and necessary transitions between conversational states, the agent that is responsible of the transitions and the conditions, expressed in terms of mental states, associated with them. For example, when a question has just been asked to an agent, it has to answer it if it knows the answer and has no reason to hide it. If the question is not clear for it, it can initiate a clarification subdialogue by asking for some clarification. But it was not very conventional to give an order to the other agent at this time. Therefore, a conversation is like a construction of blocks, where you can put a block of a certain type at a few places only. Each conversation has global parameters that respond to the following questions: who? (the conversational participants), why? (the goal behind the conversation), when? (the time), where? (the place) and how? (the type of the conversation). The answer to the question &apos;what?&apos; is composed of the surface linguistic acts themselves and the corresponding speech acts. All these information is part of the conversational context, like all the knowledge and mentals states of the conversational participants. In fact, the conversational context contains all the information that is important for a speech act planner to participate to a conversation. 112 So the model of speech act planner we propose deals with two aspects of a conversation: its planning and its structure. Up to now, we have established the global framework of the theoretical model and tested it on dialogues like the one between Dartagnan and Portos. In the future, we will describe in more detail the different steps of the planning process, the necessary data structures and the acceptable transitions between conversational states. To handle conversations involving more than two agents, we expect to reduce them to many partially ordered dialogues (conversations between two agents only), where one agent participating to the conversation is conscious of all the dialogues. Finally, we will test our model by integrating it in a prototype that will simulate the behavior of many agents that will participate to a conversation in a given situation by producing speech acts from their mental states and their knowledge.</abstract>
<note confidence="0.86246268">REFERENCES ALLEN J. F. (1983), &amp;quot;Recognizing Intentions from Natural Language Utterances&amp;quot;, in M. ad R. C. Berwick editors, Models of Discourse, Press, Cambridge, Massachusetts, chap. 2 pp. 108-166. APPELT D. E. (1985), &amp;quot;Planning English Sentences&amp;quot;, Cambridge University Press, Cambridge, Great Britain. COHEN P. R., LEVESQUE H. J. (1990), &amp;quot;Rational Interaction as the Basis for in P. R. Cohen, J. Morgan and M. E. Pollack editors, in Press, Cambridge, Massachustetts, Chap. 12, pp. 221-255. DEVITO J. A. (1992), &amp;quot;The Interpersonal Book&amp;quot;, Sixth edition, HarperCollins Publishers, New York. GRICE H. P. (1975), &amp;quot;Logic and Conversation&amp;quot;, in P. Cole and J. L. Morgan editors, &amp;quot;Syntax and Semantics, vol. III: Speech Acts&amp;quot;, Academic Press, New York, pp. 41-58. B. J., SIDNER C. L. (1986), &amp;quot;Attention, Intentions and the Structure of Discourse&amp;quot;, Linguistics, 12, No 3, July-September 1986, pp. 175-204. L., CARBERRY S. (1992), &amp;quot;Modeling Negotiation Subdialogues&amp;quot;, Proceedings of the Conference of the 30th Annual Meeting of the Association for Linguistics, Delaware, pp. 193-200, June 1992. LITMAN D. J., ALLEN J. F. (1987), &amp;quot;A Plan Recognition Model for Subdialogues in in Science, 11, pp. 163-200. MOULIN B., ROUSSEAU D., VANDERVEKEN D. (1991), &amp;quot;Speech Acts in a Connected A Computational Representation Based on Conceptual Graph Theory&amp;quot;, of the Sixth Annual Workshop on Conceptual Graphs, 1991, Binghamton, New York, pp. 269-282. SEARLE J. R., VANDERVEKEN D. (1985), &amp;quot;Foundations of Illocutionary Logic&amp;quot;,</note>
<affiliation confidence="0.762715">Cambridge University Press, Cambridge, Great Britain.</affiliation>
<address confidence="0.60999">113</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F ALLEN</author>
</authors>
<title>Recognizing Intentions from Natural Language Utterances&amp;quot;,</title>
<date>1983</date>
<booktitle>Computational Models of Discourse,</booktitle>
<volume>2</volume>
<pages>108--166</pages>
<editor>in M. Bradie ad R. C. Berwick editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts,</location>
<marker>ALLEN, 1983</marker>
<rawString>ALLEN J. F. (1983), &amp;quot;Recognizing Intentions from Natural Language Utterances&amp;quot;, in M. Bradie ad R. C. Berwick editors, Computational Models of Discourse, MIT Press, Cambridge, Massachusetts, chap. 2 pp. 108-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E APPELT</author>
</authors>
<title>Planning English Sentences&amp;quot;,</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, Great Britain.</location>
<marker>APPELT, 1985</marker>
<rawString>APPELT D. E. (1985), &amp;quot;Planning English Sentences&amp;quot;, Cambridge University Press, Cambridge, Great Britain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R COHEN</author>
<author>H J LEVESQUE</author>
</authors>
<title>Rational Interaction as the Basis for Comuunication&amp;quot;,</title>
<date>1990</date>
<booktitle>Intentions in Communication,</booktitle>
<volume>12</volume>
<pages>221--255</pages>
<editor>in P. R. Cohen, J. Morgan and M. E. Pollack editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachustetts, Chap.</location>
<marker>COHEN, LEVESQUE, 1990</marker>
<rawString>COHEN P. R., LEVESQUE H. J. (1990), &amp;quot;Rational Interaction as the Basis for Comuunication&amp;quot;, in P. R. Cohen, J. Morgan and M. E. Pollack editors, Intentions in Communication, MIT Press, Cambridge, Massachustetts, Chap. 12, pp. 221-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A DEVITO</author>
</authors>
<title>The Interpersonal Book&amp;quot;, Sixth edition,</title>
<date>1992</date>
<publisher>HarperCollins Publishers,</publisher>
<location>New York.</location>
<marker>DEVITO, 1992</marker>
<rawString>DEVITO J. A. (1992), &amp;quot;The Interpersonal Book&amp;quot;, Sixth edition, HarperCollins Publishers, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P GRICE</author>
</authors>
<title>Logic and Conversation&amp;quot;,</title>
<date>1975</date>
<pages>41--58</pages>
<editor>in P. Cole and J. L. Morgan editors, &amp;quot;Syntax and Semantics, vol. III:</editor>
<publisher>Speech Acts&amp;quot;, Academic Press,</publisher>
<location>New York,</location>
<marker>GRICE, 1975</marker>
<rawString>GRICE H. P. (1975), &amp;quot;Logic and Conversation&amp;quot;, in P. Cole and J. L. Morgan editors, &amp;quot;Syntax and Semantics, vol. III: Speech Acts&amp;quot;, Academic Press, New York, pp. 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J GROSZ</author>
<author>C L SIDNER</author>
</authors>
<title>Attention, Intentions and the Structure of Discourse&amp;quot;,</title>
<date>1986</date>
<journal>in Computational Linguistics,</journal>
<volume>12</volume>
<pages>175--204</pages>
<marker>GROSZ, SIDNER, 1986</marker>
<rawString>GROSZ B. J., SIDNER C. L. (1986), &amp;quot;Attention, Intentions and the Structure of Discourse&amp;quot;, in Computational Linguistics, Vol. 12, No 3, July-September 1986, pp. 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L LAMBERT</author>
<author>S CARBERRY</author>
</authors>
<title>Modeling Negotiation Subdialogues&amp;quot;,</title>
<date>1992</date>
<booktitle>in Proceedings of the Conference of the 30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>193--200</pages>
<location>Newark, Delaware,</location>
<marker>LAMBERT, CARBERRY, 1992</marker>
<rawString>LAMBERT L., CARBERRY S. (1992), &amp;quot;Modeling Negotiation Subdialogues&amp;quot;, in Proceedings of the Conference of the 30th Annual Meeting of the Association for Computational Linguistics, Newark, Delaware, pp. 193-200, June 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J LITMAN</author>
<author>J F ALLEN</author>
</authors>
<title>A Plan Recognition Model for Subdialogues in Conversations&amp;quot;,</title>
<date>1987</date>
<journal>in Cognitive Science,</journal>
<volume>11</volume>
<pages>163--200</pages>
<marker>LITMAN, ALLEN, 1987</marker>
<rawString>LITMAN D. J., ALLEN J. F. (1987), &amp;quot;A Plan Recognition Model for Subdialogues in Conversations&amp;quot;, in Cognitive Science, Vol. 11, pp. 163-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B MOULIN</author>
<author>D ROUSSEAU</author>
<author>D VANDERVEKEN</author>
</authors>
<title>Speech Acts in a Connected Discourse: A Computational Representation Based on Conceptual Graph Theory&amp;quot;,</title>
<date>1991</date>
<booktitle>in Proceedings of the Sixth Annual Workshop on Conceptual Graphs,</booktitle>
<pages>269--282</pages>
<location>Binghamton, New York,</location>
<marker>MOULIN, ROUSSEAU, VANDERVEKEN, 1991</marker>
<rawString>MOULIN B., ROUSSEAU D., VANDERVEKEN D. (1991), &amp;quot;Speech Acts in a Connected Discourse: A Computational Representation Based on Conceptual Graph Theory&amp;quot;, in Proceedings of the Sixth Annual Workshop on Conceptual Graphs, July 1991, Binghamton, New York, pp. 269-282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R SEARLE</author>
<author>D VANDERVEKEN</author>
</authors>
<title>Foundations of Illocutionary Logic&amp;quot;,</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, Great Britain.</location>
<marker>SEARLE, VANDERVEKEN, 1985</marker>
<rawString>SEARLE J. R., VANDERVEKEN D. (1985), &amp;quot;Foundations of Illocutionary Logic&amp;quot;, Cambridge University Press, Cambridge, Great Britain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>