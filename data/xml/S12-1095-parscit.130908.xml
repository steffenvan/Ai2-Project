<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001909">
<title confidence="0.9966665">
DERI&amp;UPM: Pushing Corpus Based Relatedness to Similarity: Shared
Task System Description
</title>
<author confidence="0.995088">
Nitish Aggarwal* Kartik Asooja° Paul Buitelaar*
</author>
<affiliation confidence="0.998169">
*Unit for Natural Language Processing
Digital Enterprise Research Institute
National University of Ireland, Galway, Ireland
</affiliation>
<email confidence="0.821368">
firstname.lastname@deri.org
</email>
<author confidence="0.368554">
&apos;Ontology Engineering Group
Universidad Politecnica de Madrid
</author>
<address confidence="0.765267">
Madrid, Spain
</address>
<email confidence="0.997785">
asooja@gmail.com
</email>
<sectionHeader confidence="0.995632" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999746925925926">
In this paper, we describe our system submit-
ted for the semantic textual similarity (STS)
task at SemEval 2012. We implemented two
approaches to calculate the degree of simi-
larity between two sentences. First approach
combines corpus-based semantic relatedness
measure over the whole sentence with the
knowledge-based semantic similarity scores
obtained for the words falling under the same
syntactic roles in both the sentences. We fed
all these scores as features to machine learn-
ing models to obtain a single score giving the
degree of similarity of the sentences. Lin-
ear Regression and Bagging models were used
for this purpose. We used Explicit Semantic
Analysis (ESA) as the corpus-based seman-
tic relatedness measure. For the knowledge-
based semantic similarity between words, a
modified WordNet based Lin measure was
used. Second approach uses a bipartite based
method over the WordNet based Lin measure,
without any modification. This paper shows
a significant improvement in calculating the
semantic similarity between sentences by the
fusion of the knowledge-based similarity mea-
sure and the corpus-based relatedness measure
against corpus based measure taken alone.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967894736842">
Similarity between sentences is a central concept
of text analysis, however previous studies about
semantic similarities have mainly focused either
on single word similarity or complete document
similarity. Sentence similarity can be defined by the
degree of semantic equivalence of two given sen-
tences, where sentences are typically 10-20 words
long. The role of sentence semantic similarity mea-
sures in text-related research is increasing due to
potential number of applications such as document
summarization, question answering, information
extraction &amp; retrieval and machine translation.
One plausible limitation of existing methods for
sentence similarity is their adaptation from long text
(e.g. documents) similarity methods, where word
co-occurrence plays a significant role. However,
sentences are too short, thats why taking syntac-
tic role of each word with its narrow semantic
meaning into account, can be highly relevant to
reflect the semantic equivalence of two sentences.
These narrow semantics can be reflected from any
existing large lexicons [(Wu and Palmer, 1994)
and (Lin, 1998)]; nevertheless, these lexicons can
not provide the semantics of words which are out
of lexicon (e.g. guy) or multiword expressions.
These semantics can be represented by a large
distributed semantic space such as Wikipedia and
similarity can be reflected by relatedness of these
extracted semantics. However, relatedness covers
broader space than similarity, which forced us to
tune the Wikipedia based relatedness with lexical
structure (e.g. WordNet) based similarities driven
by linguistic syntactic structure, in reflecting more
sophisticated similarity of two given sentences.
In this work, we present a sentence similarity using
ESA and syntactic similarities. The rest of this
paper is organized as follows. Section 2 explores the
related work. Section 3 describes our approaches
</bodyText>
<page confidence="0.988734">
643
</page>
<note confidence="0.528374">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 643–647,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998599333333333">
in detail. Section 4 explains our three different
submitted runs for STS task. Section 5 shows the
results and finally we conclude in section 6.
</bodyText>
<sectionHeader confidence="0.999344" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999961117647059">
In recent years, there have been a variety of efforts
in improving semantic similarity measures, however
most of these approaches address this problem from
the viewpoint of large document similarity based on
word co-occurrence using string pattern or corpus
statistics. Corpus based approaches such as Latent
Semantic Analysis (LSA) [(Landauer et. al, 1998)
and (Foltz et. al, 1998)] and ESA (Gabrilovich and
Markovitch, 2007) use corpus statistics information
about all words and reflect their semantics in
distributional high semantic space. However, these
approaches perform quite well for long texts as they
use word co-occurrence and relying on the principle
that words which are used in the same contexts
tend to have related meanings. In case of short text
similarities, syntactic role of each word with its
meaning plays an important role.
There are several linguistic measures [( Achananu-
parp et. al, 2008) and (Islam and Inkpen, 2008)],
which can account for pseudo-syntactic information
by analyzing their word order using n-gram. To do
this, Islam and Inkpen defined a syntactic measure,
which considers the word order between two
strings by computing the maximal ordered word
overlapping. (Oliva et. al, 2011) present a similarity
measure for sentences and short text that takes
syntactic information, such as morphology and
parsing tree, into account and calculate similarities
between words with same syntactic role, by using
WordNet.
Our work takes inspiration from existing approaches
that exploit a combination of Wikipedia based re-
latedness with lexical structure based similarities
driven by linguistic syntactic structure.
</bodyText>
<sectionHeader confidence="0.998559" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999991311111111">
We implemented two approaches for the STS
task [(Agirre et. al, 2012)]. First approach is a
fusion of corpus-based semantic relatedness and
knowledge-based semantic similarity measures.
The core of this combination is the corpus-based
measure because the combination includes the
corpus-based semantic relatedness score over the
whole sentences and the knowledge-based semantic
similarity scores for the words falling under the
same syntactic roles in both the sentences. Machine
learning models are trained by taking all these
scores as different features. For the submission,
we used Linear regression and Bagging models.
Also, the equation obtained after training the linear
regression model shows more weightage to the score
obtained by the corpus-based relatedness measure
as this is the only score (feature), which reflects the
semantic relatedness/similarity score over the full
sentences, out of all the considered features for the
model. We used ESA as the corpus based semantic
relatedness measure and modified WordNet-based
Lin measure as the knowledge-based similarity.
The WordNet-based Lin relatedness measure was
modified to reflect better the similarity between
the words. For the knowledge-based similarity,
currently we considered only the words lying in the
three major syntactic role categories i.e. subjects,
actions and the objects. We see the first approach
as the corpus-based measure ESA tuned with the
knowledge-based measure. Thus, it is referred as
TunedESA later in the paper.
Our second approach is based on the bipartite
method over the WordNet based semantic relat-
edness measures. WordNet-based Lin measure
(without any modification) was used for calcu-
lating the relatedness scores for all the possible
corresponding pair of words appearing in both the
sentences. Then, the similarity/relatedness score
for the sentences is calculated by perceiving the
problem as the computation of a maximum total
matching weight of a bipartite graph having the
words as nodes and the relatedness scores as the
weight of the edges between the nodes. To solve
this, we used Hungarian method. Later, we refer
this method as WordNet-Bipartite.
</bodyText>
<subsectionHeader confidence="0.963738">
3.1 TunedESA
</subsectionHeader>
<bodyText confidence="0.9993852">
In this approach, the ESA based relatedness score
for the full sentences is combined with the modified
WordNet-based Lin similarity scores calculated for
the words falling under the corresponding syntactic
role category in both the sentences.
</bodyText>
<page confidence="0.991453">
644
</page>
<table confidence="0.999548">
ALL Rank-ALL ALLnrm RankNrm Mean RankMean
Baseline 0.3110 87 0.6732 85 0.4356 70
Run1 0.5777 52 0.8158 20 0.5466 52
Run2 0.5833 51 0.8183 17 0.5683 42
Run3 0.4911 67 0.7696 57 0.5377 53
</table>
<tableCaption confidence="0.991917">
Table 1: Overall Rank and Pearson Correlation of all runs
</tableCaption>
<table confidence="0.998999333333333">
MSRpar MSRvid SMTeuro OnWN SMTnews
Baseline 0.4334 0.2996 0.4542 0.5864 0.3908
ESA* 0.2778 0.8178 0.3914 0.6541 0.4366
Run1 0.3675 0.8427 0.3534 0.6030 0.4430
Run2 0.3720 0.8330 0.4238 0.6513 0.4489
Run3 0.5320 0.6874 0.4514 0.5827 0.2818
</table>
<tableCaption confidence="0.999339">
Table 2: Pearson Correlation of all runs with all five STS test datasets
</tableCaption>
<bodyText confidence="0.7928685">
TunedESA could be summarized as these four
basic steps:
</bodyText>
<listItem confidence="0.942091538461538">
• Calculate the ESA relatedness score between
the sentences.
• Find the words corresponding to the linguistic
syntactical categories like subject, action and
object of both the sentences.
• Calculate the semantic similarity between the
words falling in the corresponding subjects, ac-
tions and objects in both the sentences using
modified WordNet-based measure Lin.
• Combine these four scores for ESA, Subject,
Action and Object to get the final similarity
score on the basis of an already learned ma-
chine learning model with the training data.
</listItem>
<bodyText confidence="0.987457375">
ESA is a promising technique to find the relatedness
between documents. The texts which need to be
compared are represented as high dimensional vec-
tors containing the TF-IDF weight between the term
and the Wikipedia article. The semantic relatedness
measure is calculated by taking the cosine measure
between these vectors. In this implementation of
ESA 1, the score was calculated by considering the
</bodyText>
<footnote confidence="0.6758005">
1ESA* considering full sentence at a time to make the vector
i.e. different from standard ESA
</footnote>
<bodyText confidence="0.999551333333333">
full sentence at a time for making the Wikipedia
article vector while in the standard ESA, vectors
are made for each word of the text followed by the
addition of all these vectors to represent the final
vector for the text/sentence. It was done just to
reduce the time complexity.
To calculate the lexical similarity between the
words, we implemented WordNet-based semantic
relatedness measure Lin. This score was modified to
reflect a better similarity between the words. In the
current system, basic linguistic syntactic categories
i.e. subjects, actions and objects were used. For
instance, below is a sentences pair from the training
MSRvid dataset with the gold standard score and
the syntactic roles.
</bodyText>
<listItem confidence="0.902129">
Sentence 1: A man is playing a guitar.
Subject: Man, Action: play, Object: guitar
Sentence 2: A man is playing a flute.
Subject: Man, Action: play, Object: flute
</listItem>
<bodyText confidence="0.87368375">
Gold Standard Score (0-5): 2.2
As the modification, the scores given by Lin
measure were used only for the cases where sub-
sumption relation or hypernymy/hyponymy exists
</bodyText>
<page confidence="0.99815">
645
</page>
<bodyText confidence="0.9944308">
this category. Then the built models were used for
calculating the similarity scores for the test data.
between the words. This modification was done
only for the words falling under the category of
subjects and objects.
</bodyText>
<subsectionHeader confidence="0.999758">
3.2 WordNet Bipartite
</subsectionHeader>
<bodyText confidence="0.978028333333333">
WordNet-based semantic relatedness measure was
used for the second approach.
Following steps are performed:
</bodyText>
<listItem confidence="0.992859166666667">
• Each sentence is tokenized to obtain the words.
• Semantic relatedness between every possible
pair of words in both the sentences is calculated
using WordNet-based measure e.g. Lin.
• Using the scores obtained in the second step,
the semantic similarity/relatedness between the
</listItem>
<bodyText confidence="0.59097075">
sentences is calculated by transforming the
problem as that of computing the maximum to-
tal matching weight of a bipartite graph, which
can be done by using Hungarian method.
</bodyText>
<sectionHeader confidence="0.971697" genericHeader="method">
4 System Description
</sectionHeader>
<bodyText confidence="0.999990384615385">
We submitted three runs in the semantic textual
similarity task. The first two runs are based on the
first approach i.e. TunedESA and they differ only in
the machine learning algorithm used for obtaining
the final similarity score based on all the considered
scores/features.
ESA was implemented on the current Wikipedia
dump. WordNet based relatedness measure Lin
was modified to give a better semantic similarity
degree. Stanford Core-NLP library was used for
obtaining the words with their syntactic roles.
All the required scores/feature i.e. ESA based
relatedness for the complete sentences and mod-
ified WordNet-based Lin similarity scores were
calculated for the corresponding words lying in
the same syntactic categories. Bagging and Linear
Regression models were built using the training data
for the first and second runs respectively. Based on
the category of the test dataset, model was trained
on the corresponding training dataset.
For the surprise test datasets, we trained our
model with the training dataset of the MSRvid data
based on the fact that we obtained good results with
For the third run, WordNet Bipartite method
was used to calculate the similarity scores. It didn’t
require any training.
</bodyText>
<sectionHeader confidence="0.999716" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999963230769231">
All above described runs are evaluated on STS
test dataset. Table 1 shows the overall results2 of
our three runs against the baseline system which
follows the bag of words approach. Table 2 shows
the Pearson correlation on different test datasets for
all the three runs. It provides a comparison between
corpus based relatedness measure ESA and our
system TunedESA (Run 1 &amp; Run 2).
The results show significant improvement against
ESA. Although, it can be seen that the baseline
results are even better than of the ESA in the cases
of MSRpar and SMTeuro. It may be because this
implementation of ESA is not the standard one.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999558">
We presented a method to calculate the degree of
sentence similarity based on tuning the corpus based
relatedness measure with the knowledge-based sim-
ilarity measure over the syntactic roles. The results
show a definite improvement by the fusion. As
future work, we plan to improve the syntactic role
handling and considering more syntactical cate-
gories. Also, experimentation3 with standard ESA
and other semantic similarity/relatedness measures
needs to be performed.
</bodyText>
<sectionHeader confidence="0.997478" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.941643">
This work is supported in part by the European
Union under Grant No. 248458 for the Monnet
project as well as by the Science Foundation Ireland
under Grant No. SFI/08/CE/I1380 (Lion-2).
</bodyText>
<footnote confidence="0.9984182">
2results can also be found at http://www.cs.york.
ac.uk/semeval-2012/task6/index.php?id=
results-update with the name nitish aggarwal
3We plan to provide the further results and information at
http://www.itssimilar.com/
</footnote>
<page confidence="0.998309">
646
</page>
<sectionHeader confidence="0.995822" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998308105263158">
Achananuparp Palakorn and Xiaohua Hu and Xiajiong
Shen 2008 The Evaluation of Sentence Similarity
Measures, In: DaWaK. pp. 305-316
Agirre Eneko , Cer Daniel, Diab Mona and Gonzalez-
Agirre Aitor 2012 SemEval-2012 Task 6: A Pilot on
Semantic Textual Similarity. In: Proceedings of the
6th International Workshop on Semantic Evaluation
(SemEval 2012), in conjunction with the First Joint
Conference on Lexical and Computational Semantics
(*SEM 2012).
Foltz P. W., Kintsch W. and Landauer T. K. 1998. In:
journal of the Discourse Processes. pp. 285-307, The
measurement of textual Coherence with Latent Se-
mantic Analysis,
Gabrilovich Evgeniy and Markovitch Shaul 2007 Com-
puting Semantic Relatedness using Wikipedia-based
Explicit Semantic Analysis, In: Proceedings of The
Twentieth International Joint Conference for Artificial
Intelligence. pp. 1606–1611,
Islam, Aminul and Inkpen, Diana 2008 Semantic
text similarity using corpus-based word similarity and
string similarity, In: journal of ACM Trans. Knowl.
Discov. Data. pp. 10:1–10:25
Landauer Thomas K. ,Foltz Peter W. and Laham Darrell
1998. An Introduction to Latent Semantic Analysis,
In: Journal of the Discourse Processes. pp. 259-284,
Lin Dekang 1998 Proceeding of the 15th International
Conference on Machine Learning. pp. 296–304 An
information-theoretic definition of similarity
Oliva, Jes´us and Serrano, Jos´e Ignacio and del Castillo,
Mar´ıa Dolores and Iglesias, ´Angel April, 2011
SyMSS: A syntax-based measure for short-text seman-
tic similarity In: journal of Data Knowledge Engineer-
ing. pp. 390–405
Wu, Zhibiao and Palmer, Martha 1994 Verbs seman-
tics and lexical selection, In: Proceedings of the 32nd
annual meeting on Association for Computational Lin-
guistics,
</reference>
<page confidence="0.998162">
647
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.390089">
<title confidence="0.9980845">DERI&amp;UPM: Pushing Corpus Based Relatedness to Similarity: Task System Description</title>
<author confidence="0.976077">Kartik Paul</author>
<affiliation confidence="0.959633">for Natural Language Digital Enterprise Research National University of Ireland, Galway,</affiliation>
<email confidence="0.995345">firstname.lastname@deri.org</email>
<affiliation confidence="0.789315">Engineering Universidad Politecnica de Madrid,</affiliation>
<email confidence="0.999815">asooja@gmail.com</email>
<abstract confidence="0.999497607142857">In this paper, we describe our system submitted for the semantic textual similarity (STS) task at SemEval 2012. We implemented two approaches to calculate the degree of similarity between two sentences. First approach combines corpus-based semantic relatedness measure over the whole sentence with the knowledge-based semantic similarity scores obtained for the words falling under the same syntactic roles in both the sentences. We fed all these scores as features to machine learning models to obtain a single score giving the degree of similarity of the sentences. Linear Regression and Bagging models were used for this purpose. We used Explicit Semantic Analysis (ESA) as the corpus-based semantic relatedness measure. For the knowledgebased semantic similarity between words, a modified WordNet based Lin measure was used. Second approach uses a bipartite based method over the WordNet based Lin measure, without any modification. This paper shows a significant improvement in calculating the semantic similarity between sentences by the fusion of the knowledge-based similarity measure and the corpus-based relatedness measure against corpus based measure taken alone.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Achananuparp Palakorn and Xiaohua Hu and Xiajiong Shen</title>
<date>2008</date>
<pages>305--316</pages>
<marker>2008</marker>
<rawString>Achananuparp Palakorn and Xiaohua Hu and Xiajiong Shen 2008 The Evaluation of Sentence Similarity Measures, In: DaWaK. pp. 305-316</rawString>
</citation>
<citation valid="true">
<authors>
<author>Agirre Eneko</author>
</authors>
<title>Diab Mona and GonzalezAgirre Aitor 2012 SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In:</title>
<date>2012</date>
<booktitle>Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<marker>Eneko, 2012</marker>
<rawString>Agirre Eneko , Cer Daniel, Diab Mona and GonzalezAgirre Aitor 2012 SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In: Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Foltz</author>
<author>W Kintsch</author>
<author>T K Landauer</author>
</authors>
<title>The measurement of textual Coherence with Latent Semantic Analysis,</title>
<date>1998</date>
<booktitle>In: journal of the Discourse Processes.</booktitle>
<pages>285--307</pages>
<marker>Foltz, Kintsch, Landauer, 1998</marker>
<rawString>Foltz P. W., Kintsch W. and Landauer T. K. 1998. In: journal of the Discourse Processes. pp. 285-307, The measurement of textual Coherence with Latent Semantic Analysis,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabrilovich Evgeniy</author>
<author>Markovitch Shaul</author>
</authors>
<title>Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis, In:</title>
<date>2007</date>
<booktitle>Proceedings of The Twentieth International Joint Conference for Artificial Intelligence.</booktitle>
<pages>1606--1611</pages>
<marker>Evgeniy, Shaul, 2007</marker>
<rawString>Gabrilovich Evgeniy and Markovitch Shaul 2007 Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis, In: Proceedings of The Twentieth International Joint Conference for Artificial Intelligence. pp. 1606–1611,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Semantic text similarity using corpus-based word similarity and string similarity, In:</title>
<date>2008</date>
<journal>journal of ACM Trans. Knowl. Discov. Data.</journal>
<pages>10--1</pages>
<contexts>
<context position="4746" citStr="Islam and Inkpen, 2008" startWordPosition="692" endWordPosition="695">lysis (LSA) [(Landauer et. al, 1998) and (Foltz et. al, 1998)] and ESA (Gabrilovich and Markovitch, 2007) use corpus statistics information about all words and reflect their semantics in distributional high semantic space. However, these approaches perform quite well for long texts as they use word co-occurrence and relying on the principle that words which are used in the same contexts tend to have related meanings. In case of short text similarities, syntactic role of each word with its meaning plays an important role. There are several linguistic measures [( Achananuparp et. al, 2008) and (Islam and Inkpen, 2008)], which can account for pseudo-syntactic information by analyzing their word order using n-gram. To do this, Islam and Inkpen defined a syntactic measure, which considers the word order between two strings by computing the maximal ordered word overlapping. (Oliva et. al, 2011) present a similarity measure for sentences and short text that takes syntactic information, such as morphology and parsing tree, into account and calculate similarities between words with same syntactic role, by using WordNet. Our work takes inspiration from existing approaches that exploit a combination of Wikipedia ba</context>
</contexts>
<marker>Islam, Inkpen, 2008</marker>
<rawString>Islam, Aminul and Inkpen, Diana 2008 Semantic text similarity using corpus-based word similarity and string similarity, In: journal of ACM Trans. Knowl. Discov. Data. pp. 10:1–10:25</rawString>
</citation>
<citation valid="true">
<authors>
<author>Foltz Peter W</author>
<author>Laham Darrell</author>
</authors>
<title>An Introduction to Latent Semantic Analysis, In:</title>
<date>1998</date>
<booktitle>Journal of the Discourse Processes.</booktitle>
<pages>259--284</pages>
<marker>W, Darrell, 1998</marker>
<rawString>Landauer Thomas K. ,Foltz Peter W. and Laham Darrell 1998. An Introduction to Latent Semantic Analysis, In: Journal of the Discourse Processes. pp. 259-284,</rawString>
</citation>
<citation valid="true">
<title>An information-theoretic definition of similarity</title>
<date>1998</date>
<booktitle>Proceeding of the 15th International Conference on Machine Learning.</booktitle>
<pages>296--304</pages>
<institution>Lin Dekang</institution>
<marker>1998</marker>
<rawString>Lin Dekang 1998 Proceeding of the 15th International Conference on Machine Learning. pp. 296–304 An information-theoretic definition of similarity</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Oliva</author>
<author>Jos´e Ignacio Serrano</author>
<author>del Castillo</author>
<author>Mar´ıa Dolores</author>
<author>´Angel April Iglesias</author>
</authors>
<title>SyMSS: A syntax-based measure for short-text semantic similarity In:</title>
<date>2011</date>
<journal>journal of Data Knowledge Engineering.</journal>
<pages>390--405</pages>
<marker>Oliva, Serrano, Castillo, Dolores, Iglesias, 2011</marker>
<rawString>Oliva, Jes´us and Serrano, Jos´e Ignacio and del Castillo, Mar´ıa Dolores and Iglesias, ´Angel April, 2011 SyMSS: A syntax-based measure for short-text semantic similarity In: journal of Data Knowledge Engineering. pp. 390–405</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Palmer</author>
</authors>
<title>Verbs semantics and lexical selection, In:</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<contexts>
<context position="2665" citStr="Wu and Palmer, 1994" startWordPosition="377" endWordPosition="380">r of applications such as document summarization, question answering, information extraction &amp; retrieval and machine translation. One plausible limitation of existing methods for sentence similarity is their adaptation from long text (e.g. documents) similarity methods, where word co-occurrence plays a significant role. However, sentences are too short, thats why taking syntactic role of each word with its narrow semantic meaning into account, can be highly relevant to reflect the semantic equivalence of two sentences. These narrow semantics can be reflected from any existing large lexicons [(Wu and Palmer, 1994) and (Lin, 1998)]; nevertheless, these lexicons can not provide the semantics of words which are out of lexicon (e.g. guy) or multiword expressions. These semantics can be represented by a large distributed semantic space such as Wikipedia and similarity can be reflected by relatedness of these extracted semantics. However, relatedness covers broader space than similarity, which forced us to tune the Wikipedia based relatedness with lexical structure (e.g. WordNet) based similarities driven by linguistic syntactic structure, in reflecting more sophisticated similarity of two given sentences. I</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Zhibiao and Palmer, Martha 1994 Verbs semantics and lexical selection, In: Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>