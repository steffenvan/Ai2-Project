<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006804">
<title confidence="0.956692">
The Hinoki Treebank: Working Toward Text Understanding
</title>
<author confidence="0.872601">
Francis Bond, Sanae Fujita, Chikara Hashimoto,*
Kaname Kasahara, Shigeko Nariyama,† Eric Nichols,†
Akira Ohtani,$ Takaaki Tanaka, Shigeaki Amano
</author>
<affiliation confidence="0.807121">
NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation
*Kobe Shoin Women’s University †NAIST $Osaka Gakuin University
</affiliation>
<email confidence="0.9265045">
{bond, sanae, kaname, takaaki, amano}@cslab.kecl.ntt.co.jp * chashi@sils.shoin.ac.jp,
†{eric-n, shigeko}@is.naist.jp ‡ohtani@utc.osaka-gu.ac.jp
</email>
<sectionHeader confidence="0.994385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.987584111111111">
In this paper we describe the construction of a
new Japanese lexical resource: the Hinoki treebank.
The treebank is built from dictionary definition sen-
tences, and uses an HPSG based Japanese grammar
to encode the syntactic and semantic information.
We show how this treebank can be used to extract
thesaurus information from definition sentences in
a language-neutral way using minimal recursion se-
mantics.
</bodyText>
<sectionHeader confidence="0.998847" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99853858">
In this paper we describe the current state of a new
lexical resource: the Hinoki treebank. The motiva-
tion and initial construction was described in detail
in Bond et al. (2004a). The ultimate goal of our re-
search is natural language understanding — we aim
to create a system that can parse text into some use-
ful semantic representation. Ideally this would be
such that the output can be used to actually update
our semantic models. This is an ambitious goal, and
this paper does not present a completed solution,
but rather a road-map to the solution, with some
progress along the way.
The mid-term goal is to build a thesaurus from
dictionary definition sentences and use it to enhance
a stochastic parse ranking model that combines syn-
tactic and semantic information. In order to do this
the Hinoki project is combining syntactic annotation
with word sense tagging. This will make it possible
to test the use of similarity and/or class based ap-
proaches together with symbolic grammars and sta-
tistical models. Our aim in this is to alleviate data
sparseness. In the Penn Wall Street Journal tree-
bank (Taylor et al., 2003), for example, the words
stocks and skyrocket never appear together. How-
ever, the superordinate concepts capital (D stocks)
and move upward (D skyrocket) often do.
We are constructing the ontology from the ma-
chine readable dictionary Lexeed (Kasahara et al.,
2004). This is a hand built self-contained lexicon:
it consists of headwords and their definitions for the
most familiar 28,000 words of Japanese. This set
is large enough to include most basic level words
and covers over 75% of the common word tokens
in a sample of Japanese newspaper text. In order
to make the system self sustaining we base the first
growth of our treebank on the dictionary definition
sentences themselves. We then train a statistical
model on the treebank and parse the entire lexicon.
From this we induce a thesaurus. We are currently
tagging the definition sentences with senses. We will
then use this information and the thesaurus to build
a model that combines syntactic and semantic in-
formation. We will also produce a richer ontology
— for example extracting selectional preferences. In
the last phase, we will look at ways of extending our
lexicon and ontology to less familiar words.
In this paper we present the results from treebank-
ing 38,900 dictionary sentences. We also highlight
two uses of the treebank: building the statistical
models and inducing the thesaurus.
</bodyText>
<sectionHeader confidence="0.835863" genericHeader="method">
2 The Lexeed Semantic Database of
Japanese
</sectionHeader>
<bodyText confidence="0.997972916666667">
The Lexeed Semantic Database of Japanese consists
of all Japanese words with a familiarity greater than
or equal to five on a seven point scale (Kasahara et
al., 2004). This gives 28,000 words in all, with 46,347
different senses. Definition sentences for these sen-
tences were rewritten to use only the 28,000 familiar
words (and some function words). The defining vo-
cabulary is actually 16,900 different words (60% of
all possible words). An example entry for first two
senses of the word doraib¯a “driver” is
given in Figure 1, with English glosses added (un-
derlined features are those added by Hinoki).
</bodyText>
<sectionHeader confidence="0.991232" genericHeader="method">
3 The Hinoki Treebank
</sectionHeader>
<bodyText confidence="0.999751111111111">
The structure of our treebank is inspired by the Red-
woods treebank of English in which utterances are
parsed and the annotator selects the best parse from
the full analyses derived by the grammar (Oepen et
al., 2002). We had four main reasons for selecting
this approach. The first was that we wanted to de-
velop a precise broad-coverage grammar in tandem
with the treebank, as part of our research into nat-
ural language understanding. Treebanking the out-
</bodyText>
<equation confidence="0.879116230769231">
1
1
�INDEX doraib¯a
� POS noun Lexical-type noun-lex
� �FAMILIARITY 6.5 [1–7]
� �
�DEFINITION / / / / / / / / “A tool for inserting and removing screws .”
� �SENSE 1 �HYPERNYM 1 equipment “tool”
� �SEM. CLASS (942:tool) (C 893:equipment)
� � �
� �DEFINITION / / / / / “Someone who drives a car .”
� SENSE 2 �HYPERNYM 1 hito “person” �
SEM. CLASS (292:driver) (C 4:person)
</equation>
<figureCaption confidence="0.998807">
Figure 1: Entry for the Word doraib¯a “driver” (with English glosses)
</figureCaption>
<bodyText confidence="0.9998971">
put of the parser allows us to immediately identify
problems in the grammar, and improving the gram-
mar directly improves the quality of the treebank in
a mutually beneficial feedback loop (Oepen et al.,
2004).
The second reason is that we wanted to anno-
tate to a high level of detail, marking not only
dependency and constituent structure but also de-
tailed semantic relations. By using a Japanese gram-
mar (JACY: Siegel and Bender (2002)) based on a
monostratal theory of grammar (HPSG: Pollard and
Sag (1994)) we could simultaneously annotate syn-
tactic and semantic structure without overburdening
the annotator. The treebank records the complete
syntacto-semantic analysis provided by the HPSG
grammar, along with an annotator’s choice of the
most appropriate parse. From this record, all kinds
of information can be extracted at various levels
of granularity. In particular, traditional syntactic
structure (e.g., in the form of labeled trees), de-
pendency relations between words and full meaning
representations using minimal recursion semantics
(MRS: Copestake et al. (1999)). A simplified exam-
ple of the labeled tree, MRS and dependency views
for the definition of 2 doraib¯a “driver” is
given in Figure 2.
The third reason was that we expect the use of the
grammar as a base to aid in enforcing consistency —
all sentences annotated are guaranteed to have well-
formed parses. Experience with semi-automatically
constructed grammars, such as the Penn Treebank,
shows many inconsistencies remain (around 4,500
types estimated by Dickinson and Meurers (2003))
and the treebank does not allow them to be identi-
fied automatically.
The last reason was the availability of a reason-
ably robust existing HPSG of Japanese (JACY), and
a wide range of open source tools for developing
the grammars. We made extensive use of the LKB
(Copestake, 2002), a grammar development environ-
ment, in order to extend JACY to the domain of
defining sentences. We also used the extremely effi-
cient PET parser (Callmeier, 2000), which handles
grammars developed using the LKB, to parse large
test sets for regression testing, treebanking and fi-
nally knowledge acquisition. Most of our develop-
ment was done within the [incr tsdb()] profiling en-
vironment (Oepen and Carroll, 2000). The existing
resources enabled us to rapidly develop and test our
approach.
</bodyText>
<subsectionHeader confidence="0.999603">
3.1 Creating and Maintaining the Treebank
</subsectionHeader>
<bodyText confidence="0.999847194444445">
The construction of the treebank is a two stage pro-
cess. First, the corpus is parsed (in our case using
JACY with the PET parser), and then the annotator
selects the correct analysis (or occasionally rejects
all analyses). Selection is done through a choice of
discriminants. The system selects features that dis-
tinguish between different parses, and the annotator
selects or rejects the features until only one parse
is left. The number of decisions for each sentence
is proportional to log2 of the number of parses, al-
though sometimes a single decision can reduce the
number of remaining parses by more or less than
half. In general, even a sentence with 5,000 parses
only requires around 12 decisions.
Because the disambiguating choices made by the
annotators are saved, it is possible to update the
treebank when the grammar changes (Oepen et al.,
2004). Although the trees depend on the grammar,
re-annotation is only necessary in cases where either
the parse has become more ambiguous, so new de-
cisions have to be made, or existing rules or lexical
items have changed so much that the system cannot
reconstruct the parse.
One concern that has been raised with Redwoods
style treebanking is the fact that the treebank is tied
to a particular implementation of a grammar. The
ability to update the treebank alleviates this concern
to a large extent. A more serious concern is that it is
only possible to annotate those trees that the gram-
mar can parse. Sentences for which no analysis had
been implemented in the grammar or which fail to
parse due to processing constraints are left unan-
notated. This makes grammar coverage an urgent
issue. However, dictionary definition sentences are
more repetitive than newspaper text. In addition,
there is little reference to outside context, and Lex-
</bodyText>
<table confidence="0.696246625">
UTTERANCE
NP
VP N
PP V
N CASE-P V V
jid¯osha o unten suru hito
car ACC drive do person
Parse Tree
</table>
<equation confidence="0.945346727272727">
(h0,x1{h0 :proposition rel(h1)
h1 :hito(x1) “person”
h2 :u def(x1, h1, hs)
h3:jidosha(x2) “car”
h4 :u def(x2, h3, h7)
h5 :unten(e1, x1, x2)}) “drive”
MRS
{x1 :
e1 :unten(ARG1 x1 : hito, ARG2 x2 : jidosha)
r1 :proposition(MARG e1 : unten)
Dependency
</equation>
<figureCaption confidence="0.997544">
Figure 2: Parse Tree, Simplified MRS and Dependency Views for 2 doraib¯a “driver”
</figureCaption>
<bodyText confidence="0.999717125">
eed has a fixed defining vocabulary. This makes it a
relatively easy domain to work with.
We extended JACY by adding the defining vo-
cabulary, and added some new rules and lexical-
types (more detail is given in Bond et al. (2004a)).1
Almost none of the rules are specific to the dic-
tionary domain. The grammatical coverage over
all sentences when we began to treebank was 84%,
and it is currently being increased further as we
work on the grammar. We have now treebanked
all definition sentences for words with a familiar-
ity greater than or equal to 6.0. This came to
38,900 sentences with an average length of 6.7
words/sentence. The extended JACY grammar is
available for download from www.dfki.uni-sb.de/
~siegel/grammar-download/JACY-grammar.html.
</bodyText>
<sectionHeader confidence="0.998026" genericHeader="evaluation">
4 Applications
</sectionHeader>
<bodyText confidence="0.9972585">
The treebanked data and grammar have been tested
in two ways. The first is in training a stochastic
model for parse selection. The second is in building
a thesaurus from the parsed data.
</bodyText>
<subsectionHeader confidence="0.99674">
4.1 Stochastic Parse Ranking
</subsectionHeader>
<bodyText confidence="0.9399633125">
Using the treebanked data, we built a stochastic
parse ranking model with [incr tsdb()]. The ranker
uses a maximum entropy learner to train a PCFG
over the parse derivation trees, with the current node
as a conditioning feature. The correct parse is se-
lected 61.7% of the time (training on 4,000 sentences
and testing on another 1,000; evaluated per sen-
tence). More feature-rich models using parent and
grandparent nodes along with models trained on the
MRS representations have been proposed and imple-
mented with an English grammar and the Redwoods
treebank (Oepen et al., 2002). We intend to include
such features, as well as adding our own extensions
to train on constituent weight and semantic class.
&apos;We benefited greatly from advice from the main JACY
developers: Melanie Siegel and Emily Bender.
</bodyText>
<subsectionHeader confidence="0.98119">
4.2 Knowledge Acquisition
</subsectionHeader>
<bodyText confidence="0.999883973684211">
We selected dictionary definitions as our first corpus
in order to use them to acquire lexical and ontolog-
ical knowledge. Currently we are classifying hyper-
nym, hyponym, synonym and domain relationships
in addition to linking senses to an existing ontol-
ogy. Our approach is described in more detail in
Bond et al. (2004b). The main difference between
our research and earlier approaches, such as Tsu-
rumaru et al. (1991), is that we are fully parsing
the input, not just using regular expressions. Pars-
ing sentences to a semantic representation (Minimal
Recursion Semantics, Copestake et al. (1999)) has
three advantages. The first is that it makes our
knowledge acquisition somewhat language indepen-
dent: if we have a parser for some language that
can produce MRS, and a dictionary, the algorithm
can easily be ported. The second reason is that we
can go on to use the same system to acquire knowl-
edge from non-dictionary sources, which will not be
as regular as dictionaries and thus harder to parse
using only regular expressions. Third, we can more
easily acquire knowledge beyond simple hypernyms,
for example, identifying synonyms through common
definition patterns (Tsuchiya et al., 2001).
To extract hypernyms, we parse the first defini-
tion sentence for each sense. The parser uses the
stochastic parse ranking model learned from the Hi-
noki treebank, and returns the MRS of the first
ranked parse. Currently, 84% of the sentences can
be parsed. In most cases, the word with the highest
scope in the MRS representation will be the hyper-
nym. For example, for doraib¯a1 the hypernym is
d¯ogu “tool” and for doraib¯a2 the hypernym is
hito “person” (see Figure 1). Although the ac-
tual hypernym is in very different positions in the
Japanese and English definition sentences, it takes
the highest scope in both their semantic representa-
tions.
</bodyText>
<subsectionHeader confidence="0.7171895">
For some definition sentences (around 20%), fur-
ther parsing of the semantic representation is nec-
</subsectionHeader>
<bodyText confidence="0.989675095238095">
essary. For example, 1 ana is defined as ana:
The abbreviation of “announcer” (translated to En-
glish). In this case abbreviation has the highest
scope but is an explicit relation. We therefore parse
to find its complement and extract the relationship
abbreviation(anal,announcer,). The semantic repre-
sentation is largely language independent. In order
to port the extraction to another language, we only
have to know the semantic relation for abbreviation.
We evaluate the extracted pairs by comparison
with an existing thesaurus: Goi-Taikei (Ikehara et
al., 1997). Currently 58.5% of the pairs extracted
for nouns are linked to nodes in the Goi-Taikei on-
tology (Bond et al., 2004b). In general, we are ex-
tracting pairs with more information than the Goi-
Taikei hierarchy of 2,710 classes. In particular, many
classes contain a mixture of class names and instance
names: buta niku “pork” and niku “meat”
are in the same class, as are percussion in-
strument “drum” and dagakki “percussion
instrument”, which we can now distinguish.
</bodyText>
<sectionHeader confidence="0.994198" genericHeader="conclusions">
5 Conclusion and Further Work
</sectionHeader>
<subsectionHeader confidence="0.564176">
In this paper we have described the current state of
</subsectionHeader>
<bodyText confidence="0.995841157894737">
the Hinoki treebank. We have further showed how
it is being used to develop a language-independent
system for acquiring thesauruses from machine-
readable dictionaries.
We are currently concentrating on three tasks.
The first is improving the coverage of the grammar,
so that we can parse more sentences to a correct
parse. The second is improving the knowledge ac-
quisition and learning other information from the
parsed defining sentences — in particular lexical-
types, semantic association scores, meronyms, and
antonyms. The third task is adding the knowledge
of hypernyms into the stochastic model.
With the improved the grammar and ontology, we
will use the knowledge learned to extend our model
to words not in Lexeed, using definition sentences
from machine-readable dictionaries or where they
appear within normal text. In this way, we can grow
an extensible lexicon and thesaurus from Lexeed.
</bodyText>
<sectionHeader confidence="0.998974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999338136986301">
Francis Bond, Sanae Fujita, Chikara Hashimoto,
Kaname Kasahara, Shigeko Nariyama, Eric Nichols,
Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano.
2004a. The Hinoki treebank: A treebank for text
understanding. In Proceedings of the First Interna-
tional Joint Conference on Natural Language Process-
ing (IJCNLP-04). Springer Verlag. (in press).
Francis Bond, Eric Nichols, Sanae Fujita, and Takaaki
Tanaka. 2004b. Acquiring an ontology for a funda-
mental vocabulary. In COLING 2004, Geneva. (to
appear).
Ulrich Callmeier. 2000. PET - a platform for experi-
mentation with efficient HPSG processing techniques.
Natural Language Engineering, 6(1):99–108.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 1999. Minimal recursion semantics:
An introduction. (manuscript http://www-csli.
stanford.edu/~aac/papers/newmrs.ps).
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications.
Markus Dickinson and W. Detmar Meurers. 2003. De-
tecting inconsistencies in treebanks. In Proceedings
of the Second Workshop on Treebanks and Linguistic
Theories, V¨axj¨o, Sweeden.
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio
Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi
Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei
— A Japanese Lexicon. Iwanami Shoten, Tokyo. 5
volumes/CDROM.
Kaname Kasahara, Hiroshi Sato, Francis Bond, Takaaki
Tanaka, Sanae Fujita, Tomoko Kanasugi, and
Shigeaki Amano. 2004. Construction of a Japanese se-
mantic lexicon: Lexeed. SIG NLC-159, IPSJ, Tokyo.
(in Japanese).
Stephan Oepen and John Carroll. 2000. Performance
profiling for grammar engineering. Natural Language
Engineering, 6(1):81–97.
Stephan Oepen, Kristina Toutanova, Stuart Shieber,
Christoper D. Manning, Dan Flickinger, and Thorsten
Brant. 2002. The LinGO redwoods treebank: Mo-
tivation and preliminary applications. In 19th In-
ternational Conference on Computational Linguistics:
COLING-2002, pages 1253–7, Taipei, Taiwan.
Stephan Oepen, Dan Flickinger, and Francis Bond.
2004. Towards holistic grammar engineering and test-
ing — grafting treebank maintenance into the gram-
mar revision cycle. In Beyond Shallow Analyses —
Formalisms and Satitistical Modelling for Deep Anal-
ysis (Workshop at IJCNLP-2004), Hainan Island.
(http://www-tsujii.is.s.u-tokyo.ac.jp/bsa/).
Carl Pollard and Ivan A. Sag. 1994. Head Driven Phrase
Structure Grammar. University of Chicago Press,
Chicago.
Melanie Siegel and Emily M. Bender. 2002. Efficient
deep processing of Japanese. In Procedings of the 3rd
Workshop on Asian Language Resources and Interna-
tional Standardization at the 19th International Con-
ference on Computational Linguistics, Taipei.
Ann Taylor, Mitchel Marcus, and Beatrice Santorini.
2003. The Penn treebank: an overview. In Anne
Abeill´e, editor, Treebanks: Building and Using Parsed
Corpora, chapter 1, pages 5–22. Kluwer Academic
Publishers.
Masatoshi Tsuchiya, Sadao Kurohashi, and Satoshi Sato.
2001. Discovery of definition patterns by compressing
dictionary sentences. In Proceedings of the 6th Natu-
ral Language Processing Pacific Rim Symposium, NL-
PRS2001, pages 411–418, Tokyo.
Hiroaki Tsurumaru, Katsunori Takesita, Itami Katsuki,
Toshihide Yanagawa, and Sho Yoshida. 1991. An ap-
proach to thesaurus construction from Japanese lan-
guage dictionary. In IPSJ SIGNotes Natural Lan-
guage, volume 83-16, pages 121–128. (in Japanese).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.630602">
<title confidence="0.999337">The Hinoki Treebank: Working Toward Text Understanding</title>
<author confidence="0.928965">Sanae Fujita Bond</author>
<author confidence="0.928965">Chikara Kasahara</author>
<author confidence="0.928965">Shigeko Tanaka</author>
<author confidence="0.928965">Shigeaki</author>
<affiliation confidence="0.979023">NTT Communication Science Laboratories, Nippon Telegraph and Telephone Shoin Women’s University Gakuin University</affiliation>
<email confidence="0.939592">sanae,kaname,takaaki,</email>
<abstract confidence="0.9828237">In this paper we describe the construction of a new Japanese lexical resource: the Hinoki treebank. The treebank is built from dictionary definition sentences, and uses an HPSG based Japanese grammar to encode the syntactic and semantic information. We show how this treebank can be used to extract thesaurus information from definition sentences in a language-neutral way using minimal recursion semantics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Francis Bond</author>
<author>Sanae Fujita</author>
</authors>
<title>Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004a. The Hinoki treebank: A treebank for text understanding.</title>
<booktitle>In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04).</booktitle>
<publisher>Springer Verlag. (in press).</publisher>
<marker>Bond, Fujita, </marker>
<rawString>Francis Bond, Sanae Fujita, Chikara Hashimoto, Kaname Kasahara, Shigeko Nariyama, Eric Nichols, Akira Ohtani, Takaaki Tanaka, and Shigeaki Amano. 2004a. The Hinoki treebank: A treebank for text understanding. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04). Springer Verlag. (in press).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Francis Bond</author>
</authors>
<title>Eric Nichols, Sanae Fujita, and Takaaki Tanaka. 2004b. Acquiring an ontology for a fundamental vocabulary.</title>
<booktitle>In COLING 2004,</booktitle>
<location>Geneva.</location>
<note>(to appear).</note>
<marker>Bond, </marker>
<rawString>Francis Bond, Eric Nichols, Sanae Fujita, and Takaaki Tanaka. 2004b. Acquiring an ontology for a fundamental vocabulary. In COLING 2004, Geneva. (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>PET - a platform for experimentation with efficient HPSG processing techniques.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="6977" citStr="Callmeier, 2000" startWordPosition="1127" endWordPosition="1128">ce with semi-automatically constructed grammars, such as the Penn Treebank, shows many inconsistencies remain (around 4,500 types estimated by Dickinson and Meurers (2003)) and the treebank does not allow them to be identified automatically. The last reason was the availability of a reasonably robust existing HPSG of Japanese (JACY), and a wide range of open source tools for developing the grammars. We made extensive use of the LKB (Copestake, 2002), a grammar development environment, in order to extend JACY to the domain of defining sentences. We also used the extremely efficient PET parser (Callmeier, 2000), which handles grammars developed using the LKB, to parse large test sets for regression testing, treebanking and finally knowledge acquisition. Most of our development was done within the [incr tsdb()] profiling environment (Oepen and Carroll, 2000). The existing resources enabled us to rapidly develop and test our approach. 3.1 Creating and Maintaining the Treebank The construction of the treebank is a two stage process. First, the corpus is parsed (in our case using JACY with the PET parser), and then the annotator selects the correct analysis (or occasionally rejects all analyses). Select</context>
</contexts>
<marker>Callmeier, 2000</marker>
<rawString>Ulrich Callmeier. 2000. PET - a platform for experimentation with efficient HPSG processing techniques. Natural Language Engineering, 6(1):99–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal recursion semantics: An introduction.</title>
<date>1999</date>
<note>(manuscript http://www-csli. stanford.edu/~aac/papers/newmrs.ps).</note>
<contexts>
<context position="6050" citStr="Copestake et al. (1999)" startWordPosition="971" endWordPosition="974">ratal theory of grammar (HPSG: Pollard and Sag (1994)) we could simultaneously annotate syntactic and semantic structure without overburdening the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of information can be extracted at various levels of granularity. In particular, traditional syntactic structure (e.g., in the form of labeled trees), dependency relations between words and full meaning representations using minimal recursion semantics (MRS: Copestake et al. (1999)). A simplified example of the labeled tree, MRS and dependency views for the definition of 2 doraib¯a “driver” is given in Figure 2. The third reason was that we expect the use of the grammar as a base to aid in enforcing consistency — all sentences annotated are guaranteed to have wellformed parses. Experience with semi-automatically constructed grammars, such as the Penn Treebank, shows many inconsistencies remain (around 4,500 types estimated by Dickinson and Meurers (2003)) and the treebank does not allow them to be identified automatically. The last reason was the availability of a reaso</context>
<context position="11977" citStr="Copestake et al. (1999)" startWordPosition="1948" endWordPosition="1951">4.2 Knowledge Acquisition We selected dictionary definitions as our first corpus in order to use them to acquire lexical and ontological knowledge. Currently we are classifying hypernym, hyponym, synonym and domain relationships in addition to linking senses to an existing ontology. Our approach is described in more detail in Bond et al. (2004b). The main difference between our research and earlier approaches, such as Tsurumaru et al. (1991), is that we are fully parsing the input, not just using regular expressions. Parsing sentences to a semantic representation (Minimal Recursion Semantics, Copestake et al. (1999)) has three advantages. The first is that it makes our knowledge acquisition somewhat language independent: if we have a parser for some language that can produce MRS, and a dictionary, the algorithm can easily be ported. The second reason is that we can go on to use the same system to acquire knowledge from non-dictionary sources, which will not be as regular as dictionaries and thus harder to parse using only regular expressions. Third, we can more easily acquire knowledge beyond simple hypernyms, for example, identifying synonyms through common definition patterns (Tsuchiya et al., 2001). T</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 1999</marker>
<rawString>Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag. 1999. Minimal recursion semantics: An introduction. (manuscript http://www-csli. stanford.edu/~aac/papers/newmrs.ps).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="6814" citStr="Copestake, 2002" startWordPosition="1100" endWordPosition="1101">on was that we expect the use of the grammar as a base to aid in enforcing consistency — all sentences annotated are guaranteed to have wellformed parses. Experience with semi-automatically constructed grammars, such as the Penn Treebank, shows many inconsistencies remain (around 4,500 types estimated by Dickinson and Meurers (2003)) and the treebank does not allow them to be identified automatically. The last reason was the availability of a reasonably robust existing HPSG of Japanese (JACY), and a wide range of open source tools for developing the grammars. We made extensive use of the LKB (Copestake, 2002), a grammar development environment, in order to extend JACY to the domain of defining sentences. We also used the extremely efficient PET parser (Callmeier, 2000), which handles grammars developed using the LKB, to parse large test sets for regression testing, treebanking and finally knowledge acquisition. Most of our development was done within the [incr tsdb()] profiling environment (Oepen and Carroll, 2000). The existing resources enabled us to rapidly develop and test our approach. 3.1 Creating and Maintaining the Treebank The construction of the treebank is a two stage process. First, th</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dickinson</author>
<author>W Detmar Meurers</author>
</authors>
<title>Detecting inconsistencies in treebanks.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>V¨axj¨o, Sweeden.</location>
<contexts>
<context position="6532" citStr="Dickinson and Meurers (2003)" startWordPosition="1049" endWordPosition="1052">abeled trees), dependency relations between words and full meaning representations using minimal recursion semantics (MRS: Copestake et al. (1999)). A simplified example of the labeled tree, MRS and dependency views for the definition of 2 doraib¯a “driver” is given in Figure 2. The third reason was that we expect the use of the grammar as a base to aid in enforcing consistency — all sentences annotated are guaranteed to have wellformed parses. Experience with semi-automatically constructed grammars, such as the Penn Treebank, shows many inconsistencies remain (around 4,500 types estimated by Dickinson and Meurers (2003)) and the treebank does not allow them to be identified automatically. The last reason was the availability of a reasonably robust existing HPSG of Japanese (JACY), and a wide range of open source tools for developing the grammars. We made extensive use of the LKB (Copestake, 2002), a grammar development environment, in order to extend JACY to the domain of defining sentences. We also used the extremely efficient PET parser (Callmeier, 2000), which handles grammars developed using the LKB, to parse large test sets for regression testing, treebanking and finally knowledge acquisition. Most of o</context>
</contexts>
<marker>Dickinson, Meurers, 2003</marker>
<rawString>Markus Dickinson and W. Detmar Meurers. 2003. Detecting inconsistencies in treebanks. In Proceedings of the Second Workshop on Treebanks and Linguistic Theories, V¨axj¨o, Sweeden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
<author>Masahiro Miyazaki</author>
<author>Satoshi Shirai</author>
</authors>
<title>Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi.</title>
<date>1997</date>
<booktitle>Goi-Taikei — A Japanese Lexicon. Iwanami Shoten,</booktitle>
<volume>5</volume>
<pages>volumes/CDROM.</pages>
<location>Tokyo.</location>
<contexts>
<context position="13885" citStr="Ikehara et al., 1997" startWordPosition="2255" endWordPosition="2258">%), further parsing of the semantic representation is necessary. For example, 1 ana is defined as ana: The abbreviation of “announcer” (translated to English). In this case abbreviation has the highest scope but is an explicit relation. We therefore parse to find its complement and extract the relationship abbreviation(anal,announcer,). The semantic representation is largely language independent. In order to port the extraction to another language, we only have to know the semantic relation for abbreviation. We evaluate the extracted pairs by comparison with an existing thesaurus: Goi-Taikei (Ikehara et al., 1997). Currently 58.5% of the pairs extracted for nouns are linked to nodes in the Goi-Taikei ontology (Bond et al., 2004b). In general, we are extracting pairs with more information than the GoiTaikei hierarchy of 2,710 classes. In particular, many classes contain a mixture of class names and instance names: buta niku “pork” and niku “meat” are in the same class, as are percussion instrument “drum” and dagakki “percussion instrument”, which we can now distinguish. 5 Conclusion and Further Work In this paper we have described the current state of the Hinoki treebank. We have further showed how it i</context>
</contexts>
<marker>Ikehara, Miyazaki, Shirai, 1997</marker>
<rawString>Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Goi-Taikei — A Japanese Lexicon. Iwanami Shoten, Tokyo. 5 volumes/CDROM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaname Kasahara</author>
<author>Hiroshi Sato</author>
<author>Francis Bond</author>
</authors>
<title>Takaaki Tanaka, Sanae Fujita, Tomoko Kanasugi, and Shigeaki Amano.</title>
<date>2004</date>
<booktitle>Construction of a Japanese semantic lexicon: Lexeed. SIG NLC-159, IPSJ,</booktitle>
<location>Tokyo.</location>
<note>(in Japanese).</note>
<contexts>
<context position="2309" citStr="Kasahara et al., 2004" startWordPosition="348" endWordPosition="351">tion. In order to do this the Hinoki project is combining syntactic annotation with word sense tagging. This will make it possible to test the use of similarity and/or class based approaches together with symbolic grammars and statistical models. Our aim in this is to alleviate data sparseness. In the Penn Wall Street Journal treebank (Taylor et al., 2003), for example, the words stocks and skyrocket never appear together. However, the superordinate concepts capital (D stocks) and move upward (D skyrocket) often do. We are constructing the ontology from the machine readable dictionary Lexeed (Kasahara et al., 2004). This is a hand built self-contained lexicon: it consists of headwords and their definitions for the most familiar 28,000 words of Japanese. This set is large enough to include most basic level words and covers over 75% of the common word tokens in a sample of Japanese newspaper text. In order to make the system self sustaining we base the first growth of our treebank on the dictionary definition sentences themselves. We then train a statistical model on the treebank and parse the entire lexicon. From this we induce a thesaurus. We are currently tagging the definition sentences with senses. W</context>
<context position="3615" citStr="Kasahara et al., 2004" startWordPosition="565" endWordPosition="568">ntactic and semantic information. We will also produce a richer ontology — for example extracting selectional preferences. In the last phase, we will look at ways of extending our lexicon and ontology to less familiar words. In this paper we present the results from treebanking 38,900 dictionary sentences. We also highlight two uses of the treebank: building the statistical models and inducing the thesaurus. 2 The Lexeed Semantic Database of Japanese The Lexeed Semantic Database of Japanese consists of all Japanese words with a familiarity greater than or equal to five on a seven point scale (Kasahara et al., 2004). This gives 28,000 words in all, with 46,347 different senses. Definition sentences for these sentences were rewritten to use only the 28,000 familiar words (and some function words). The defining vocabulary is actually 16,900 different words (60% of all possible words). An example entry for first two senses of the word doraib¯a “driver” is given in Figure 1, with English glosses added (underlined features are those added by Hinoki). 3 The Hinoki Treebank The structure of our treebank is inspired by the Redwoods treebank of English in which utterances are parsed and the annotator selects the </context>
</contexts>
<marker>Kasahara, Sato, Bond, 2004</marker>
<rawString>Kaname Kasahara, Hiroshi Sato, Francis Bond, Takaaki Tanaka, Sanae Fujita, Tomoko Kanasugi, and Shigeaki Amano. 2004. Construction of a Japanese semantic lexicon: Lexeed. SIG NLC-159, IPSJ, Tokyo. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>John Carroll</author>
</authors>
<title>Performance profiling for grammar engineering.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="7228" citStr="Oepen and Carroll, 2000" startWordPosition="1164" endWordPosition="1167">he last reason was the availability of a reasonably robust existing HPSG of Japanese (JACY), and a wide range of open source tools for developing the grammars. We made extensive use of the LKB (Copestake, 2002), a grammar development environment, in order to extend JACY to the domain of defining sentences. We also used the extremely efficient PET parser (Callmeier, 2000), which handles grammars developed using the LKB, to parse large test sets for regression testing, treebanking and finally knowledge acquisition. Most of our development was done within the [incr tsdb()] profiling environment (Oepen and Carroll, 2000). The existing resources enabled us to rapidly develop and test our approach. 3.1 Creating and Maintaining the Treebank The construction of the treebank is a two stage process. First, the corpus is parsed (in our case using JACY with the PET parser), and then the annotator selects the correct analysis (or occasionally rejects all analyses). Selection is done through a choice of discriminants. The system selects features that distinguish between different parses, and the annotator selects or rejects the features until only one parse is left. The number of decisions for each sentence is proporti</context>
</contexts>
<marker>Oepen, Carroll, 2000</marker>
<rawString>Stephan Oepen and John Carroll. 2000. Performance profiling for grammar engineering. Natural Language Engineering, 6(1):81–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Kristina Toutanova</author>
<author>Stuart Shieber</author>
<author>Christoper D Manning</author>
<author>Dan Flickinger</author>
<author>Thorsten Brant</author>
</authors>
<title>The LinGO redwoods treebank: Motivation and preliminary applications.</title>
<date>2002</date>
<booktitle>In 19th International Conference on Computational Linguistics: COLING-2002,</booktitle>
<pages>1253--7</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="4292" citStr="Oepen et al., 2002" startWordPosition="679" endWordPosition="682">nses. Definition sentences for these sentences were rewritten to use only the 28,000 familiar words (and some function words). The defining vocabulary is actually 16,900 different words (60% of all possible words). An example entry for first two senses of the word doraib¯a “driver” is given in Figure 1, with English glosses added (underlined features are those added by Hinoki). 3 The Hinoki Treebank The structure of our treebank is inspired by the Redwoods treebank of English in which utterances are parsed and the annotator selects the best parse from the full analyses derived by the grammar (Oepen et al., 2002). We had four main reasons for selecting this approach. The first was that we wanted to develop a precise broad-coverage grammar in tandem with the treebank, as part of our research into natural language understanding. Treebanking the out1 1 �INDEX doraib¯a � POS noun Lexical-type noun-lex � �FAMILIARITY 6.5 [1–7] � � �DEFINITION / / / / / / / / “A tool for inserting and removing screws .” � �SENSE 1 �HYPERNYM 1 equipment “tool” � �SEM. CLASS (942:tool) (C 893:equipment) � � � � �DEFINITION / / / / / “Someone who drives a car .” � SENSE 2 �HYPERNYM 1 hito “person” � SEM. CLASS (292:driver) (C </context>
<context position="11130" citStr="Oepen et al., 2002" startWordPosition="1813" endWordPosition="1816">rsed data. 4.1 Stochastic Parse Ranking Using the treebanked data, we built a stochastic parse ranking model with [incr tsdb()]. The ranker uses a maximum entropy learner to train a PCFG over the parse derivation trees, with the current node as a conditioning feature. The correct parse is selected 61.7% of the time (training on 4,000 sentences and testing on another 1,000; evaluated per sentence). More feature-rich models using parent and grandparent nodes along with models trained on the MRS representations have been proposed and implemented with an English grammar and the Redwoods treebank (Oepen et al., 2002). We intend to include such features, as well as adding our own extensions to train on constituent weight and semantic class. &apos;We benefited greatly from advice from the main JACY developers: Melanie Siegel and Emily Bender. 4.2 Knowledge Acquisition We selected dictionary definitions as our first corpus in order to use them to acquire lexical and ontological knowledge. Currently we are classifying hypernym, hyponym, synonym and domain relationships in addition to linking senses to an existing ontology. Our approach is described in more detail in Bond et al. (2004b). The main difference between</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brant, 2002</marker>
<rawString>Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christoper D. Manning, Dan Flickinger, and Thorsten Brant. 2002. The LinGO redwoods treebank: Motivation and preliminary applications. In 19th International Conference on Computational Linguistics: COLING-2002, pages 1253–7, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Dan Flickinger</author>
<author>Francis Bond</author>
</authors>
<title>Towards holistic grammar engineering and testing — grafting treebank maintenance into the grammar revision cycle. In Beyond Shallow Analyses — Formalisms and Satitistical Modelling for Deep Analysis (Workshop at IJCNLP-2004),</title>
<date>2004</date>
<location>Hainan Island. (http://www-tsujii.is.s.u-tokyo.ac.jp/bsa/).</location>
<contexts>
<context position="5180" citStr="Oepen et al., 2004" startWordPosition="839" endWordPosition="842">Lexical-type noun-lex � �FAMILIARITY 6.5 [1–7] � � �DEFINITION / / / / / / / / “A tool for inserting and removing screws .” � �SENSE 1 �HYPERNYM 1 equipment “tool” � �SEM. CLASS (942:tool) (C 893:equipment) � � � � �DEFINITION / / / / / “Someone who drives a car .” � SENSE 2 �HYPERNYM 1 hito “person” � SEM. CLASS (292:driver) (C 4:person) Figure 1: Entry for the Word doraib¯a “driver” (with English glosses) put of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel and Bender (2002)) based on a monostratal theory of grammar (HPSG: Pollard and Sag (1994)) we could simultaneously annotate syntactic and semantic structure without overburdening the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of informati</context>
<context position="8205" citStr="Oepen et al., 2004" startWordPosition="1325" endWordPosition="1328">ne through a choice of discriminants. The system selects features that distinguish between different parses, and the annotator selects or rejects the features until only one parse is left. The number of decisions for each sentence is proportional to log2 of the number of parses, although sometimes a single decision can reduce the number of remaining parses by more or less than half. In general, even a sentence with 5,000 parses only requires around 12 decisions. Because the disambiguating choices made by the annotators are saved, it is possible to update the treebank when the grammar changes (Oepen et al., 2004). Although the trees depend on the grammar, re-annotation is only necessary in cases where either the parse has become more ambiguous, so new decisions have to be made, or existing rules or lexical items have changed so much that the system cannot reconstruct the parse. One concern that has been raised with Redwoods style treebanking is the fact that the treebank is tied to a particular implementation of a grammar. The ability to update the treebank alleviates this concern to a large extent. A more serious concern is that it is only possible to annotate those trees that the grammar can parse. </context>
</contexts>
<marker>Oepen, Flickinger, Bond, 2004</marker>
<rawString>Stephan Oepen, Dan Flickinger, and Francis Bond. 2004. Towards holistic grammar engineering and testing — grafting treebank maintenance into the grammar revision cycle. In Beyond Shallow Analyses — Formalisms and Satitistical Modelling for Deep Analysis (Workshop at IJCNLP-2004), Hainan Island. (http://www-tsujii.is.s.u-tokyo.ac.jp/bsa/).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="5480" citStr="Pollard and Sag (1994)" startWordPosition="891" endWordPosition="894">son” � SEM. CLASS (292:driver) (C 4:person) Figure 1: Entry for the Word doraib¯a “driver” (with English glosses) put of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel and Bender (2002)) based on a monostratal theory of grammar (HPSG: Pollard and Sag (1994)) we could simultaneously annotate syntactic and semantic structure without overburdening the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of information can be extracted at various levels of granularity. In particular, traditional syntactic structure (e.g., in the form of labeled trees), dependency relations between words and full meaning representations using minimal recursion semantics (MRS: Copestake et al. (1999)). A simplified example of the</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melanie Siegel</author>
<author>Emily M Bender</author>
</authors>
<title>Efficient deep processing of Japanese.</title>
<date>2002</date>
<booktitle>In Procedings of the 3rd Workshop on Asian Language Resources and International Standardization at the 19th International Conference on Computational Linguistics,</booktitle>
<location>Taipei.</location>
<contexts>
<context position="5408" citStr="Siegel and Bender (2002)" startWordPosition="879" endWordPosition="882">ION / / / / / “Someone who drives a car .” � SENSE 2 �HYPERNYM 1 hito “person” � SEM. CLASS (292:driver) (C 4:person) Figure 1: Entry for the Word doraib¯a “driver” (with English glosses) put of the parser allows us to immediately identify problems in the grammar, and improving the grammar directly improves the quality of the treebank in a mutually beneficial feedback loop (Oepen et al., 2004). The second reason is that we wanted to annotate to a high level of detail, marking not only dependency and constituent structure but also detailed semantic relations. By using a Japanese grammar (JACY: Siegel and Bender (2002)) based on a monostratal theory of grammar (HPSG: Pollard and Sag (1994)) we could simultaneously annotate syntactic and semantic structure without overburdening the annotator. The treebank records the complete syntacto-semantic analysis provided by the HPSG grammar, along with an annotator’s choice of the most appropriate parse. From this record, all kinds of information can be extracted at various levels of granularity. In particular, traditional syntactic structure (e.g., in the form of labeled trees), dependency relations between words and full meaning representations using minimal recursi</context>
</contexts>
<marker>Siegel, Bender, 2002</marker>
<rawString>Melanie Siegel and Emily M. Bender. 2002. Efficient deep processing of Japanese. In Procedings of the 3rd Workshop on Asian Language Resources and International Standardization at the 19th International Conference on Computational Linguistics, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Taylor</author>
<author>Mitchel Marcus</author>
<author>Beatrice Santorini</author>
</authors>
<title>The Penn treebank: an overview.</title>
<date>2003</date>
<booktitle>In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 1,</booktitle>
<pages>5--22</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="2045" citStr="Taylor et al., 2003" startWordPosition="307" endWordPosition="310"> solution, but rather a road-map to the solution, with some progress along the way. The mid-term goal is to build a thesaurus from dictionary definition sentences and use it to enhance a stochastic parse ranking model that combines syntactic and semantic information. In order to do this the Hinoki project is combining syntactic annotation with word sense tagging. This will make it possible to test the use of similarity and/or class based approaches together with symbolic grammars and statistical models. Our aim in this is to alleviate data sparseness. In the Penn Wall Street Journal treebank (Taylor et al., 2003), for example, the words stocks and skyrocket never appear together. However, the superordinate concepts capital (D stocks) and move upward (D skyrocket) often do. We are constructing the ontology from the machine readable dictionary Lexeed (Kasahara et al., 2004). This is a hand built self-contained lexicon: it consists of headwords and their definitions for the most familiar 28,000 words of Japanese. This set is large enough to include most basic level words and covers over 75% of the common word tokens in a sample of Japanese newspaper text. In order to make the system self sustaining we ba</context>
</contexts>
<marker>Taylor, Marcus, Santorini, 2003</marker>
<rawString>Ann Taylor, Mitchel Marcus, and Beatrice Santorini. 2003. The Penn treebank: an overview. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 1, pages 5–22. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masatoshi Tsuchiya</author>
<author>Sadao Kurohashi</author>
<author>Satoshi Sato</author>
</authors>
<title>Discovery of definition patterns by compressing dictionary sentences.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium, NLPRS2001,</booktitle>
<pages>411--418</pages>
<location>Tokyo.</location>
<contexts>
<context position="12574" citStr="Tsuchiya et al., 2001" startWordPosition="2045" endWordPosition="2048">, Copestake et al. (1999)) has three advantages. The first is that it makes our knowledge acquisition somewhat language independent: if we have a parser for some language that can produce MRS, and a dictionary, the algorithm can easily be ported. The second reason is that we can go on to use the same system to acquire knowledge from non-dictionary sources, which will not be as regular as dictionaries and thus harder to parse using only regular expressions. Third, we can more easily acquire knowledge beyond simple hypernyms, for example, identifying synonyms through common definition patterns (Tsuchiya et al., 2001). To extract hypernyms, we parse the first definition sentence for each sense. The parser uses the stochastic parse ranking model learned from the Hinoki treebank, and returns the MRS of the first ranked parse. Currently, 84% of the sentences can be parsed. In most cases, the word with the highest scope in the MRS representation will be the hypernym. For example, for doraib¯a1 the hypernym is d¯ogu “tool” and for doraib¯a2 the hypernym is hito “person” (see Figure 1). Although the actual hypernym is in very different positions in the Japanese and English definition sentences, it takes the high</context>
</contexts>
<marker>Tsuchiya, Kurohashi, Sato, 2001</marker>
<rawString>Masatoshi Tsuchiya, Sadao Kurohashi, and Satoshi Sato. 2001. Discovery of definition patterns by compressing dictionary sentences. In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium, NLPRS2001, pages 411–418, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroaki Tsurumaru</author>
<author>Katsunori Takesita</author>
<author>Itami Katsuki</author>
<author>Toshihide Yanagawa</author>
<author>Sho Yoshida</author>
</authors>
<title>An approach to thesaurus construction from Japanese language dictionary.</title>
<date>1991</date>
<booktitle>In IPSJ SIGNotes Natural Language,</booktitle>
<volume>volume</volume>
<pages>83--16</pages>
<note>(in Japanese).</note>
<contexts>
<context position="11799" citStr="Tsurumaru et al. (1991)" startWordPosition="1920" endWordPosition="1924">as adding our own extensions to train on constituent weight and semantic class. &apos;We benefited greatly from advice from the main JACY developers: Melanie Siegel and Emily Bender. 4.2 Knowledge Acquisition We selected dictionary definitions as our first corpus in order to use them to acquire lexical and ontological knowledge. Currently we are classifying hypernym, hyponym, synonym and domain relationships in addition to linking senses to an existing ontology. Our approach is described in more detail in Bond et al. (2004b). The main difference between our research and earlier approaches, such as Tsurumaru et al. (1991), is that we are fully parsing the input, not just using regular expressions. Parsing sentences to a semantic representation (Minimal Recursion Semantics, Copestake et al. (1999)) has three advantages. The first is that it makes our knowledge acquisition somewhat language independent: if we have a parser for some language that can produce MRS, and a dictionary, the algorithm can easily be ported. The second reason is that we can go on to use the same system to acquire knowledge from non-dictionary sources, which will not be as regular as dictionaries and thus harder to parse using only regular</context>
</contexts>
<marker>Tsurumaru, Takesita, Katsuki, Yanagawa, Yoshida, 1991</marker>
<rawString>Hiroaki Tsurumaru, Katsunori Takesita, Itami Katsuki, Toshihide Yanagawa, and Sho Yoshida. 1991. An approach to thesaurus construction from Japanese language dictionary. In IPSJ SIGNotes Natural Language, volume 83-16, pages 121–128. (in Japanese).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>