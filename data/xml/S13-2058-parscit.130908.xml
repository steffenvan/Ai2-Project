<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000129">
<title confidence="0.9710145">
WBI-NER: The impact of domain-specific features on the performance of
identifying and classifying mentions of drugs
</title>
<author confidence="0.888647">
Tim Rockt¨aschel Torsten Huber Michael Weidlich Ulf Leser
</author>
<affiliation confidence="0.6468565">
Humboldt-Universit¨at zu Berlin
Knowledge Management in Bioinformatics
</affiliation>
<address confidence="0.8686405">
Unter den Linden 6
Berlin, 10099, Germany
</address>
<email confidence="0.99875">
{trocktae,thuber,weidlich,leser}@informatik.hu-berlin.de
</email>
<sectionHeader confidence="0.99557" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9968635">
Named entity recognition (NER) systems
are often based on machine learning tech-
niques to reduce the labor-intensive devel-
opment of hand-crafted extraction rules and
domain-dependent dictionaries. Nevertheless,
time-consuming feature engineering is often
needed to achieve state-of-the-art performance.
In this study, we investigate the impact of such
domain-specific features on the performance
of recognizing and classifying mentions of
pharmacological substances. We compare the
performance of a system based on general fea-
tures, which have been successfully applied
to a wide range of NER tasks, with a system
that additionally uses features generated from
the output of an existing chemical NER tool
and a collection of domain-specific resources.
We demonstrate that acceptable results can be
achieved with the former system. Still, our ex-
periments show that using domain-specific fea-
tures outperforms this general approach. Our
system ranked first in the SemEval-2013 Task
9.1: Recognition and classification of pharma-
cological substances.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999722970588235">
The accurate identification of drug mentions in text
is an important prerequisite for many applications, in-
cluding the retrieval of information about substances
in drug development (e.g. Roberts and Hayes (2008)),
the identification of adverse drug effects (e.g. Lea-
man et al. (2010)) and the recognition of drug-drug
interactions (e.g. Thomas et al. (2011)). Given that
most of the information related to drug research is
covered by medical reports and pharmacological pub-
lications, computational methods for information ex-
traction should be used to support this task.
The SemEval-2013 Task 9.1 competition1 (Segura-
Bedmar et al., 2013) aims at a fair assessment on the
state-of-the-art of tools that recognize and classify
mentions of pharmacological substances in natural
language texts – a task referred to as drug named
entity recognition (NER). The goal of participating
teams is to recreate the gold annotation on a held-
out part of an annotated corpus. Four classes of en-
tities have to be identified: Drug, DrugN, Group
and Brand. Entities of class Drug denote any kind
of drug that is approved for use in humans, whereas
DrugN denotes substances that are not approved.
Group are terms describing a group of drugs and
Brand stands for drug names introduced by a phar-
maceutical company.
The aim of this study is to examine whether it is
worthwhile to implement domain-specific features
for supporting drug NER. The question we attempt
to answer is whether such features really help in iden-
tifying and classifying mentions of drugs or whether
a mostly domain-independent feature set, which can
be applied to many other tasks, achieves a compara-
ble performance.
</bodyText>
<sectionHeader confidence="0.999717" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9944255">
Various NER systems for identifying different
classes of chemical entities, including mentions of
drugs, trivial names and IUPAC terms, have been pro-
posed.
</bodyText>
<footnote confidence="0.999115">
1http://www.cs.york.ac.uk/semeval-2013/task9/
(accessed 2013-04-29)
</footnote>
<page confidence="0.983177">
356
</page>
<bodyText confidence="0.960740022222222">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 356–363, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
Klinger et al. (2008) trained a conditional random
field (CRF) (Lafferty et al., 2001) for extracting men-
tions of IUPAC and IUPAC-like entities. They report
an F1 measure of 85.6% on a hand-annotated corpus
consisting of MEDLINE abstracts.
Segura-Bedmar et al. (2008) introduced Drug-
NER, which is based on UMLS MetaMap Trans-
fer (MMTx) and nomenclature rules by the World
Health Organization International Nonproprietary
Names (INNs). Their system extracts and classifies
mentions of drugs and achieves a precision of 99.1%
and a recall of 99.8% on a silver-standard corpus.
OSCAR (Open-Source Chemistry Analysis Rou-
tines) (Corbett and Murray-Rust, 2006; Jessop et al.,
2011) extracts mentions of a wide range of chemi-
cals using a maximum entropy Markov model (Mc-
Callum et al., 2000). It achieves an F1 of 83.2% on
a corpus consisting of PubMed abstracts and 80.7%
on a corpus consisting of chemistry papers (Corbett
and Copestake, 2008).
Hettne et al. (2009) compiled Jochem (the joint
chemical dictionary) from ChemIDplus, ChEBI,
DrugBank, PubChem, HMDB, KEGG, MeSH and
CAS Registry IDs. Jochem was used with Peregrine
(Schuemie et al., 2007), a dictionary-based NER tool,
achieving an F1 of 50% on the SCAI corpus (Kol´arik
et al., 2008).
We developed ChemSpot (Rockt¨aschel et al.,
2012), a system for extracting mentions of various
kinds of chemicals from text. We applied a CRF
for extracting mentions of IUPAC entities based on
the work of Klinger et al. (2008) and used Jochem
(Hettne et al., 2009) with an adapted matching-
mechanism for identifying trivial names, drugs and
brands. ChemSpot v1.0 achieved an overall F1 of
68.1% on the SCAI corpus. In the meantime, we have
worked on several enhancements (see Section 3.1).
The SemEval-2013 Task 9.1 poses new challenges
on NER tools. Instead of targeting all kinds of chem-
icals, it focuses on drugs, i.e., pharmacological sub-
stances that affect humans and are used for adminis-
tration. Moreover, entities need to be classified into
the four categories mentioned above.
</bodyText>
<sectionHeader confidence="0.998482" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999034538461538">
Our approach is based on a linear-chain CRF with
mostly domain-independent features commonly ap-
plied to NER tasks. In addition, we employ vari-
ous domain-specific features derived from the out-
put of ChemSpot’s components, as well as Jochem,
the PHARE ontology (Coulet et al., 2011) and the
ChEBI ontology (De Matos et al., 2010). In the
following, we first explain extensions to ChemSpot.
Subsequently, we give a brief introduction to linear-
chain CRFs before describing the general and
domain-specific features used by our system. Finally,
we explain the experimental setup and discuss our
results.
</bodyText>
<subsectionHeader confidence="0.999833">
3.1 Improvements of ChemSpot
</subsectionHeader>
<bodyText confidence="0.988791970588235">
To improve ChemSpot’s chemical NER performance,
we extend it by two components and modify its
match-expansion mechanism.
The first addition is a pattern-based tagger
for chemical formulae. In its basic form it ex-
tracts mentions matching the regular expression
(S N?(\+|-)?)+ where S denotes a chemical
symbol and N a natural number greater one.2 This
pattern is augmented by filters to comply with other
naming conventions, such as correct grouping of
compounds with parentheses.
The second extension targets ambiguous ab-
breviations. For example, the abbreviation “DAG”
could denote “diacylglycerol” or “directed acyclic
graph”. We use ABBREV, an algorithm proposed
by Schwartz and Hearst (2003), for extracting such
abbreviations and their definitions (e.g. “diacylglyc-
erol (DAG)”). Note that the position of the long form
(LF) and short form (SF) is interchangeable. To dis-
ambiguate between chemical and non-chemical ab-
breviations, we apply the following two rules to the
mentions extracted by ChemSpot: (1) For a given
pair of LF and SF, we check whether the LF was
found to be a chemical but the SF was not. In this
case we add a new annotation for every occurrence
of the SF in the document. (2) Contrary to that, if
only the SF was tagged as a chemical but the LF was
not, we assume that the abbreviation does not refer
to a chemical and remove all annotations of the SF
in the document.
ChemSpot’s match-expansion often leads to the
extraction of non-chemical suffixes corresponding to
verbs, e.g., “-induced”, “-enriched” or “-mediated”.
2By convention, 1 is ommited (e.g. CO2 instead of C1O2).
</bodyText>
<page confidence="0.994132">
357
</page>
<figureCaption confidence="0.7038092">
Figure 1: A factor graph for a 1st-order linear-chain
CRF (2nd-order with dashed edges). Note that for
each feature function fj in the factor T, the same
weight θj is used at all other positions (gray) in the
sequence (parameter tying).
</figureCaption>
<bodyText confidence="0.999968875">
To tackle this issue we stop the expansion at tokens
whose part-of-speech tag refers to a verb form. Fur-
thermore, we integrated OPSIN (Lowe et al., 2011)
to normalize entity mentions to InChI strings.
The current v1.5 release of ChemSpot achieves an
overall F1 of 74.2% on the SCAI corpus, improving
the performance by 6.1 percentage points (pp) F1
compared to ChemSpot v1.0.
</bodyText>
<subsectionHeader confidence="0.999851">
3.2 Linear-chain conditional random fields
</subsectionHeader>
<bodyText confidence="0.999979863636364">
Contrary to the hybrid strategy used in ChemSpot,
we follow a purely machine learning based approach
for drug NER in this work. NER can be formulated
as a sequence labeling task where the goal is to find
a sequence of labels y = fy1, ... , yn} given a se-
quence x = fx1, ... , xn} of observed input tokens.
Labels commonly follow the IOB format, where B
denotes a token at the beginning of an entity men-
tion, I denotes the continuation of a mention and O
corresponds to tokens that are not part of a mention.
Extracting entity mentions from a tokenized text x
then amounts to finding y∗ = arg maxy p(y  |x).
Linear-chain CRFs are well-known discriminative
undirected graphical models that encode the condi-
tional probability p(y  |x) of a set of input variables
x and a sequence of output variables y (see Wallach
(2004) or Klinger and Tomanek (2007) for an intro-
duction). In the case of NER, x is a sequence of n
tokens and y a sequence of n corresponding labels.
Linear-chain CRFs of order k factorize p(y  |x) into
a product of factors T, globally normalized by an
input-dependent partition function Z(x):
</bodyText>
<equation confidence="0.9329635">
1 n
p(y  |x) = Z(x) H T (yi−k, ... , yi−1, yi, x, i)
</equation>
<bodyText confidence="0.855869666666667">
A factor T is commonly defined as the exponen-
tial function of a sum of weighted feature functions
ff1, ... , fm} :
</bodyText>
<equation confidence="0.976333666666667">
m
� exp �E θj fj (yi−k, ... , yi− 1, yi, x, i) I .
/1
</equation>
<bodyText confidence="0.999774825">
The feature function weights fθj} can be learned
from training data and are shared across all positions
i (parameter tying).
The factorization of a CRF can be illustrated by
a factor graph (Kschischang et al., 2001). A factor
graph is a bipartite graph, where one set of nodes
corresponds to random variables and the other to fac-
tors. Each factor is connected to the variables of its
domain, making the factorization of the model ap-
parent. Figure 1 shows a factor graph for a segment
of a linear-chain CRF of order one and two respec-
tively. In a linear-chain CRF of order k, the label of
a token at position i is connected via feature func-
tions of a factor to the input sequence x as well as
the previous k labels. For example, in a first-order
linear-chain CRF, one of the feature functions could
be f[O→B,capital](yi−1, yi, x, i), which evaluates to 1 if
yi−1 = O, yi = B and xi starts with a capital letter
(otherwise it yields 0). Multiplication with the weight
θ[O→B,capital] yields an unnormalized local score that
indicates how favorable a transition from O to B is
provided that the token at position i starts with a capi-
tal letter. Note that the terms feature function and fea-
ture are often used synonymously and the case differ-
entiation for different labels is implicit. In this work
a feature fcapital denotes its corresponding set of first-
order feature functions ff[s→t,capital](yi−1,yi, x, i) |
(s, t) C f(B, B), (B, I), (B, O), (I, B), (I, I), (I, O),
(O, B), (O, O)}}3 (similarly for second-order).
We employ MALLET (McCallum, 2002) as under-
lying CRF implementation and use a second-order
linear-chain CRF with offset conjunctions of order
two. Offset conjunctions of order k adds features
around a window of k to the features at a partic-
ular position, providing more contextual informa-
tion. Akin to Klinger et al. (2008), we perform fine-
grained tokenization, splitting at special characters
and transitions from alphanumeric characters to dig-
its. An exemplary tagging sequence is shown in Ta-
ble 1.
</bodyText>
<footnote confidence="0.777476">
3Transitions from O to I are invalid.
</footnote>
<equation confidence="0.9987061">
yi−2 yi−1 yi yi+1 yi+2
T T
x
T T T
i=1
1
n
H
i=1
Z(x)
</equation>
<page confidence="0.981716">
358
</page>
<table confidence="0.702042333333333">
i 0 1 2 3 4 5 6 7 8 9 10
y O B-DrugN O B-DrugN I-DrugN I-DrugN O B-Group O O O
x Both ibogaine and 18 - MC ameliorate opioid withdrawal signs .
</table>
<tableCaption confidence="0.996785">
Table 1: Example label sequence for the tokenized sentence MedLine.d110.s4 of the training corpus.
</tableCaption>
<table confidence="0.654441">
Feature Class Description
</table>
<tableCaption confidence="0.9898496">
fCHEMSPOT part of a prediction by ChemSpot
fIUPAC part of an IUPAC entity
FC fFORMULA part of a chemical formula
fDICTIONARY part of a dictionary match
fABBREV part of a chemical abbreviation
</tableCaption>
<table confidence="0.966226222222222">
fJOCHEM dictionaries in Jochem
FJ fPREFIX frequent chemical prefix
fSUFFIX frequent chemical suffix
fPHARE PHARE ontology
FO fCHEBDESCS #descendants in ChEBI ontology
fCHEBDEPTH average depth in ChEBI ontology
fKLINGER see Klinger et al. (2008)
FG fBANNER see Leaman and Gonzalez (2008)
fABNER see Settles (2005)
</table>
<tableCaption confidence="0.6944875">
fUPPERCASESENT. part of an upper-case sentence
FF fPREVWINDOW text of preceding four tokens
fNEXTWINDOW text of succeeding four tokens
Table 2: Overview of features used for identifying
</tableCaption>
<bodyText confidence="0.973522428571428">
and classifying mentions of pharmacological sub-
stances.
Note that the sequence-labeling approach in the
described form cannot cope with discontinuous en-
tity mentions. Since only a tiny fraction (� 0.3%) of
entities in the training corpus are discontinuous, we
simply neglect these for training and tagging.
</bodyText>
<subsectionHeader confidence="0.997546">
3.3 Feature sets
</subsectionHeader>
<bodyText confidence="0.999918625">
An overview of the features used by our system is
shown in Table 2. Our first two submissions for the
SemEval-2013 Task 9.1 differ only in that they use
different subsets of these features. Run 1 employs a
feature set assembled from common general features
used for biomedical NER (FG U FF), whereas Run
2 additionally uses features tailored for extracting
mentions of chemicals (FC U FJ U FO).
</bodyText>
<subsubsectionHeader confidence="0.493435">
3.3.1 Run 1: general features FG and FF
</subsubsectionHeader>
<bodyText confidence="0.999982909090909">
We employ a union of common, rather domain-
independent features published by Klinger et al.
(2008), Settles (2005) and Leaman and Gonzalez
(2008). Note that these feature sets have been suc-
cessfully applied to a wide range of different biomed-
ical NER tasks, e.g., identifying mentions of DNA
sequences, genes, diseases, mutations, IUPAC terms,
cell lines and cell types. They encompass morpho-
logical, syntactic and orthographic features, such as
the text of the token itself, token character n-grams
of length 2 and 3, prefixes and suffixes of length 2, 3,
and 4, characters left and right to a token and part-of-
speech tags. Furthermore, they contain various regu-
lar expressions that capture, for instance, whether a
token starts with a capital letter or contains digits.
In addition, we employ features based on NER
examples in FACTORIE (McCallum et al., 2009).
Specifically, we use the text of the four preceding
and succeeding tokens and whether a token is part of
a sentence that contains only upper-case characters.
The latter is commonly the case for headlines, which
likely contain an entity mention.
</bodyText>
<subsectionHeader confidence="0.892078">
3.3.2 Run 2: domain-specific features
</subsectionHeader>
<bodyText confidence="0.999958263157895">
In addition to the features of Run 1, we use pre-
dictions of our improved version of ChemSpot, as
well as features derived from Jochem, PHARE and
ChEBI.
ChemSpot-based features FC: When a token is
part of a mention extracted by one of ChemSpot’s
components (i.e. IUPAC entity, chemical formula,
dictionary match or chemical abbreviation), we use
the name of the respective component as feature. In
addition, we determine whether a token is part of an
entity predicted by ChemSpot after match-expansion,
boundary-correction and resolution of overlapping
entities. Using the output of ChemSpot as features
for our system could be framed as stacking (see
Wolpert (1992)).
Jochem-based features FJ: For every dictionary
contained in Jochem, we check whether a token is
part of an entity in that dictionary and use the name of
the dictionary as feature. Furthermore, we compile
</bodyText>
<page confidence="0.998565">
359
</page>
<bodyText confidence="0.943490388888889">
a list of frequent chemical suffixes and prefixes of
length three from Jochem.
Ontology-based features FO: It is often hard to
determine whether a mention refers to a specific
chemical entity or rather an abstract term denoting
a group of chemicals. To distinguish between these
two cases, we calculate the average depth and the
number of descendants of a term in the ChEBI on-
tology and use the binned count as feature. The idea
behind these features is that the specificity of an en-
tity correlates positively with its depth in the ontol-
ogy (e.g. leaf nodes are likely specific chemicals)
and negatively with the number of descendants (i.e.
having few descendants indicates a specific entity).
Further ontology-based features are derived from
PHARE, which consists of 200 curated relations. If
possible, we map a token to a term in that ontology
and use its label as feature.
</bodyText>
<sectionHeader confidence="0.502555" genericHeader="method">
3.4 Experiments
</sectionHeader>
<bodyText confidence="0.999917933333333">
We perform document-level 10-fold cross-validation
(CV) on the training corpus to measure the impact
of domain-specific features. To ensure comparability
between Run 1 and Run 2, we use the same splits for
evaluation. Furthermore, we train models on the com-
plete training corpus and evaluate on the test corpus
of DDI Task 9.1 for each run respectively. In addi-
tion, we train a third model based on the best feature
set determined with CV and use the entity mentions
of the Task 9.2 test corpus, which also contains anno-
tations of drug-drug interactions, as additional train-
ing data (Run 3). Following the SemEval-2013 Task
9.1 metrics, we evaluate exact matching performance
(correct entity boundaries) and strict matching per-
formance (correct boundaries and correct type).
</bodyText>
<sectionHeader confidence="0.99995" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.9617621">
Table 3 shows micro-average CV results for identi-
fying and classifying mentions of pharmacological
substances in the training corpus. The performance
varies drastically between different entity classes re-
gardless of the feature set, e.g., Run 1 achieves an F1
of 91.0% for Drug, but only 15.9% F1 for DrugN.
Run 2 outperforms Run 1 for entities of class
Drug (+1.2 pp F1) and DrugN (+4.9 pp F1), but
yields a lower performance for Brand (−0.9 pp
F1) and no change for Group entities. Overall, the
</bodyText>
<table confidence="0.99915175">
Run 1 Run 2 OF1
P R F1 P R F1
Drug 92.1 89.9 91.0 92.0 92.3 92.2 +1.2
DrugN 54.7 9.3 15.9 62.4 12.5 20.8 +4.9
Group 87.2 82.5 84.8 87.3 82.3 84.8 0.0
Brand 87.8 70.8 78.4 87.1 69.8 77.5 −0.9
Exact 93.9 86.9 90.3 94.5 89.0 91.7 +1.4
Strict 90.3 83.6 86.8 90.3 85.1 87.6 +0.8
</table>
<tableCaption confidence="0.955126">
Table 3: Document-level 10-fold cross-validation
micro-average results on the training corpus.
</tableCaption>
<bodyText confidence="0.951597846153846">
micro-average F1 measure increases by 0.8 pp for
strict matching and 1.4 pp F1 for exact matching.
The performance on the test corpus (see Table 4)
is drastically lower compared to CV results (e.g. 17.6
pp F1 for strict evaluation of Run 1). Except for enti-
ties of class Group, using domain-specific features
leads to a superior performance for identifying and
classifying mentions of pharmacological substances.
Run 2 outperforms Run 1 by 1.6 pp F1 for strict eval-
uation and 5.9 pp F1 for exact evaluation. Using en-
tity mentions of the Task 9.2 test corpus as additional
training data (Run 3) further boosts the performance
by 0.7 pp F1 for strict evaluation.
</bodyText>
<sectionHeader confidence="0.998001" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99981785">
Our results show a clear performance advantage
when using domain-specific features tailored for
identifying mentions of chemicals. CV results and
results on the test corpus show an increase in preci-
sion and recall for exact matching and an increase
in recall for strict matching. The considerably higher
recall for exact matching can be attributed to a higher
coverage of chemical entities by features that exploit
domain-knowledge.
It is striking that the performance for DrugN enti-
ties is extremely low compared to the other classes.
We believe that this might be due to two reasons.
First, entities of this class are underrepresented in
the training corpus (Pt� 3%). Since machine learning
based methods tend to favor the majority class, it is
likely that many DrugN entities were classified as
mentions of one of the much larger classes Drug (�
64%) or Group (� 23%). This can be confirmed by
the large differences between strict and exact match-
ing results shown in Table 3 and Table 4.
</bodyText>
<page confidence="0.991958">
360
</page>
<table confidence="0.9999843">
# Run 1 Run 2 OF1 Run 3 OF1
P R F1 P R F1 P R F1
Drug 351 74.2 79.5 76.8 72.9 85.2 78.6 +1.8 73.6 85.2 79.0 +0.4
DrugN 121 25.0 4.1 7.1 35.7 8.3 13.4 +6.3 31.4 9.1 14.1 +0.7
Group 155 77.3 74.8 76.1 78.1 73.5 75.7 −0.4 79.2 76.1 77.6 +1.9
Brand 59 76.2 81.4 78.7 77.8 83.1 80.3 +1.6 81.0 86.4 83.6 +3.3
Exact 686 82.1 72.9 77.2 85.6 80.8 83.1 +5.9 85.5 81.3 83.3 +0.2
Strict 686 73.6 65.3 69.2 73.0 68.8 70.8 +1.6 73.4 69.8 71.5 +0.7
DrugBank (Strict) 304 86.9 85.2 86.0 87.3 86.2 86.8 +0.8 88.1 87.5 87.8 +1.0
MEDLINE (Strict) 382 60.8 49.5 54.5 60.5 55.0 57.6 +3.1 60.7 55.8 58.1 +0.5
</table>
<tableCaption confidence="0.682642571428571">
Table 4: Results on the test corpus. OF1 denotes the F1 pp difference to the preceding Run and # the number
of annotated mentions
Second, DrugN denotes substances that have an ef-
fect on humans, but are not approved for medical use
– a property that is rarely stated along with the entity
mention and can thus often only be determined with
domain-knowledge.
</tableCaption>
<bodyText confidence="0.999718">
We think it is also important to point to the large
difference between results obtained by 10-fold CV
on the training corpus and test results (e.g. up to 17.6
pp F1 for Run 1). One reason might be the large frac-
tion (Pt� 83%) of entity mentions that appear more
than once in the training corpus compared to pre-
sumably many unseen entities in the test corpus. For
10-fold CV this means that an entity in the evaluation
fold has already been seen with a high probability in
one of the nine training folds, yielding results that
overestimate the generalization performance. More-
over, our results indicate that identifying and clas-
sifying pharmacological substances is much harder
for MEDLINE documents than for DrugBank docu-
ments with a difference of up to 31.5 pp F1 (cf. the
last two rows of Table 4). Hence, another apparent
reason for the performance differences is the sub-
stantial skew in the ratio of DrugBank to MEDLINE
documents in the training corpus (roughly 4:1) com-
pared to the test corpus (roughly 1:1). Since both sets
of documents stem from different resources, this can
be referred to as domain-adaptation problem.
In additional experiments we found that the
general-purpose chemical NER tool ChemSpot
achieves an F1 of 65.5% for exact matching on the
test corpus. This is 17.8 pp F1 below our best results
obtained with a machine learning based system (cf.
Run 3) that is able to exploit properties of the task-
specific annotations of the corpora.
</bodyText>
<sectionHeader confidence="0.999557" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99795072">
We described our contribution to the SemEval-2013
Task 9.1: Recognition and classification of pharma-
cological substances. We found that a system based
on rather general features commonly used for a wide
range of biomedical NER tasks yields competetive
results. Implementing this system needed no domain-
adaptation and its performance could be sufficient for
applications building upon drug NER. Nevertheless,
adding domain-specific features boosts the perfor-
mance considerably. Further improvements can be
achieved by using entity annotations of the Task 9.2
test corpus as additional training data.
We identified two limitations of our approach.
First, we found that entities of the minority class
(DrugN) are very hard to classify correctly. Second,
differences between DrugBank and MEDLINE docu-
ments probably cause a domain-adaptation problem.
For future work, one could investigate whether the
latter can be addressed by domain-adaptation tech-
niques (e.g. Satpal and Sarawagi (2007)). To cope
with DrugN entities, one could implement features
derived from those resources that were used by the
annotators for deciding whether a substance is ap-
proved for use in humans, e.g., Drugs@FDA4 and
the WHO ATC5 classification system.
</bodyText>
<footnote confidence="0.99315825">
4http://www.accessdata.fda.gov/scripts/cder/
drugsatfda/ (accessed 2013-04-29)
5http://www.whocc.no/atc_ddd_index/ (accessed
2013-04-29)
</footnote>
<page confidence="0.997065">
361
</page>
<sectionHeader confidence="0.996534" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99870075">
We thank Philippe Thomas for preparing a simplified for-
mat of the corpora. We thank him and Roman Klinger for
fruitful discussions.
Funding: Tim Rockt¨aschel is funded by the German Fed-
eral Ministry of Economics and Technology (BMWi)
[KF2205209MS2], Torsten Huber and Michael Weidlich
are funded by the German Federal Ministry of Education
and Research (BMBF) [0315746].
</bodyText>
<sectionHeader confidence="0.99851" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99985832631579">
Peter Corbett and Ann Copestake. 2008. Cascaded classi-
fiers for confidence-based chemical named entity recog-
nition. BMC Bioinf., 9(Suppl 11):S4.
Peter Corbett and Peter Murray-Rust. 2006. High-
throughput identification of chemistry in life science
texts. In Proc. of CompLife 2006, pages 107–118.
Adrien Coulet, Yael Garten, Michel Dumontier, Russ B.
Altman, Mark A. Musen, and Nigam H. Shah. 2011. In-
tegration and publication of heterogeneous text-mined
relationships on the Semantic Web. J. Biomed. Seman-
tics, 2(Suppl 2):S10.
Paula De Matos, Rafael Alc´antara, Adriano Dekker, Mar-
cus Ennis, Janna Hastings, Kenneth Haug, Inmaculada
Spiteri, Steve Turner, and Christoph Steinbeck. 2010.
Chemical Entities of Biological Interest: an update. Nu-
cleic Acids Res., 38:D249–D254.
Kristina M. Hettne, Rob H. Stierum, Martijn J. Schuemie,
Peter J.M. Hendriksen, Bob J.A. Schijvenaars, Erik
M. Van Mulligen, Jos Kleinjans, and Jan A. Kors. 2009.
A dictionary to identify small molecules and drugs in
free text. Bioinformatics, 25(22):2983–2991.
David M. Jessop, Sam E. Adams, Egon L. Willighagen,
Lezan Hawizy, and Peter Murray-Rust. 2011. OS-
CAR4: a flexible architecture for chemical text-mining.
J. Cheminf., 3(1):41.
Roman Klinger, Corinna Kol´arik, Juliane Fluck, Martin
Hofmann-Apitius, and Christoph M. Friedrich. 2008.
Detection of IUPAC and IUPAC-like chemical names.
In Proc. of ISMB. Bioinformatics, volume 24, pages
i268–i276.
Roman Klinger and Katrin Tomanek. 2007. Classical
Probabilistic Models and Conditional Random Fields.
Algorithm Engineering Report TR07-2-013. Depart-
ment of Computer Science, Dortmund University of
Technology. ISSN 1864-4503.
Corinna Kol´arik, Roman Klinger, Christoph M. Friedrich,
Martin Hofmann-Apitius, and Juliane Fluck. 2008.
Chemical names: terminological resources and corpora
annotation. In Proc. of the Workshop on Building and
evaluating resources for biomedical text mining, pages
51–58.
Frank R. Kschischang, Brendan J. Frey, and Hans-Andrea
Loeliger. 2001. Factor graphs and the sum-product
algorithm. IEEE Trans. Inf. Theory, 47(2):498–519.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional Random Fields: Probabilistic Mod-
els for Segmenting and Labeling Sequence Data. In
Proc. of ICML-2001, pages 282–289.
Robert Leaman and Graciela Gonzalez. 2008. BANNER:
an executable survey of advances in biomedical named
entity recognition. In Proc. of Pac Symp Biocomput,
pages 652–663.
Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, An-
nie Skariah, Jian Yang, and Graciela Gonzalez. 2010.
Towards internet-age pharmacovigilance: extracting ad-
verse drug reactions from user posts to health-related
social networks. In Proc. of Workshop BioNLP, pages
117–125. ACL.
Daniel M. Lowe, Peter T. Corbett, Peter Murray-Rust, and
Robert C. Glen. 2011. Chemical name to structure:
Opsin, an open source solution. J. Chem. Inf. Model.,
51(3):739–753.
Andrew K. McCallum. 2002. MALLET: A
Machine Learning for Language Toolkit.
http://mallet.cs.umass.edu.
Andrew K. McCallum, Dayne Freitag, and Fernando.
Pereira. 2000. Maximum entropy Markov models for
information extraction and segmentation. In Proc. of
ICML-2000, pages 591–598.
Andrew K. McCallum, Karl Schultz, and Sameer Singh.
2009. FACTORIE: Probabilistic programming via im-
peratively defined factor graphs. In Proc. of Neural
Information Processing Systems (NIPS).
Phoebe M. Roberts and William S. Hayes. 2008. Infor-
mation needs and the role of text mining in drug de-
velopment. In Proc. of Pac Symp Biocomput, pages
592–603.
Tim Rockt¨aschel, Michael Weidlich, and Ulf Leser. 2012.
ChemSpot: A Hybrid System for Chemical Named En-
tity Recognition. Bioinformatics, 28(12):1633–1640.
Sandeepkumar Satpal and Sunita Sarawagi. 2007. Do-
main adaptation of conditional probability models
via feature subsetting. In Knowledge Discovery in
Databases: PKDD 2007, pages 224–235. Springer.
Martijn J. Schuemie, Rob Jelier, and Jan A. Kors. 2007.
Peregrine: Lightweight gene name normalization by
dictionary lookup. In Proc. of the Second BioCreative
Challenge, volume 2, pages 131–133.
Ariel S. Schwartz and Marti A. Hearst. 2003. A sim-
ple algorithm for identifying abbreviation definitions
in biomedical text. In Proc. of Pac Symp Biocomput,
volume 8, pages 451–462.
Isabel Segura-Bedmar, Paloma Martinez, and Maria
Herrero-Zazo. 2013. Semeval-2013 task 9: Extraction
of drug-drug interactions from biomedical texts. In
</reference>
<page confidence="0.978848">
362
</page>
<reference confidence="0.999380714285714">
Proc. of the 7th International Workshop on Semantic
Evaluation (SemEval 2013).
Isabel Segura-Bedmar, Paloma Martinez, and Maria
Segura-Bedmar. 2008. Drug name recognition and clas-
sification in biomedical texts. A case study outlining
approaches underpinning automated systems. Drug
Discovery Today, 13(17-18):816–823.
Burr Settles. 2005. ABNER: an open source tool for
automatically tagging genes, proteins and other entity
names in text. Bioinformatics, 21(14):3191–3192.
Philippe Thomas, Mariana Neves, Ill´es Solt, Domonkos
Tikk, and Ulf Leser. 2011. Relation extraction for drug-
drug interactions using ensemble learning. In Proc.
of the 1st Challenge Task on Drug-Drug Interaction
Extraction 2011, pages 11–18.
Hanna M. Wallach. 2004. Conditional Random Fields: An
Introduction. Technical Report MS-CIS-04-21. Depart-
ment of Computer and Information Science, University
of Pennsylvania.
David H. Wolpert. 1992. Stacked generalization. Neural
Networks, 5(2):241–259.
</reference>
<page confidence="0.999367">
363
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.520072">
<title confidence="0.9771545">WBI-NER: The impact of domain-specific features on the performance of identifying and classifying mentions of drugs</title>
<author confidence="0.955991">Tim Rockt¨aschel Torsten Huber Michael Weidlich Ulf Leser</author>
<affiliation confidence="0.780981333333333">Humboldt-Universit¨at zu Knowledge Management in Unter den Linden</affiliation>
<address confidence="0.990537">Berlin, 10099,</address>
<abstract confidence="0.99855692">Named entity recognition (NER) systems are often based on machine learning techniques to reduce the labor-intensive development of hand-crafted extraction rules and domain-dependent dictionaries. Nevertheless, time-consuming feature engineering is often needed to achieve state-of-the-art performance. In this study, we investigate the impact of such domain-specific features on the performance of recognizing and classifying mentions of pharmacological substances. We compare the performance of a system based on general features, which have been successfully applied to a wide range of NER tasks, with a system that additionally uses features generated from the output of an existing chemical NER tool and a collection of domain-specific resources. We demonstrate that acceptable results can be achieved with the former system. Still, our experiments show that using domain-specific features outperforms this general approach. Our system ranked first in the SemEval-2013 Task 9.1: Recognition and classification of pharmacological substances.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter Corbett</author>
<author>Ann Copestake</author>
</authors>
<title>Cascaded classifiers for confidence-based chemical named entity recognition.</title>
<date>2008</date>
<journal>BMC Bioinf.,</journal>
<volume>9</volume>
<pages>11--4</pages>
<contexts>
<context position="4508" citStr="Corbett and Copestake, 2008" startWordPosition="663" endWordPosition="666">LS MetaMap Transfer (MMTx) and nomenclature rules by the World Health Organization International Nonproprietary Names (INNs). Their system extracts and classifies mentions of drugs and achieves a precision of 99.1% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts mentions of a wide range of chemicals using a maximum entropy Markov model (McCallum et al., 2000). It achieves an F1 of 83.2% on a corpus consisting of PubMed abstracts and 80.7% on a corpus consisting of chemistry papers (Corbett and Copestake, 2008). Hettne et al. (2009) compiled Jochem (the joint chemical dictionary) from ChemIDplus, ChEBI, DrugBank, PubChem, HMDB, KEGG, MeSH and CAS Registry IDs. Jochem was used with Peregrine (Schuemie et al., 2007), a dictionary-based NER tool, achieving an F1 of 50% on the SCAI corpus (Kol´arik et al., 2008). We developed ChemSpot (Rockt¨aschel et al., 2012), a system for extracting mentions of various kinds of chemicals from text. We applied a CRF for extracting mentions of IUPAC entities based on the work of Klinger et al. (2008) and used Jochem (Hettne et al., 2009) with an adapted matchingmechan</context>
</contexts>
<marker>Corbett, Copestake, 2008</marker>
<rawString>Peter Corbett and Ann Copestake. 2008. Cascaded classifiers for confidence-based chemical named entity recognition. BMC Bioinf., 9(Suppl 11):S4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Corbett</author>
<author>Peter Murray-Rust</author>
</authors>
<title>Highthroughput identification of chemistry in life science texts.</title>
<date>2006</date>
<booktitle>In Proc. of CompLife</booktitle>
<pages>107--118</pages>
<contexts>
<context position="4224" citStr="Corbett and Murray-Rust, 2006" startWordPosition="613" endWordPosition="616">rained a conditional random field (CRF) (Lafferty et al., 2001) for extracting mentions of IUPAC and IUPAC-like entities. They report an F1 measure of 85.6% on a hand-annotated corpus consisting of MEDLINE abstracts. Segura-Bedmar et al. (2008) introduced DrugNER, which is based on UMLS MetaMap Transfer (MMTx) and nomenclature rules by the World Health Organization International Nonproprietary Names (INNs). Their system extracts and classifies mentions of drugs and achieves a precision of 99.1% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts mentions of a wide range of chemicals using a maximum entropy Markov model (McCallum et al., 2000). It achieves an F1 of 83.2% on a corpus consisting of PubMed abstracts and 80.7% on a corpus consisting of chemistry papers (Corbett and Copestake, 2008). Hettne et al. (2009) compiled Jochem (the joint chemical dictionary) from ChemIDplus, ChEBI, DrugBank, PubChem, HMDB, KEGG, MeSH and CAS Registry IDs. Jochem was used with Peregrine (Schuemie et al., 2007), a dictionary-based NER tool, achieving an F1 of 50% on the SCAI corpus (Kol´arik et al., 2008). We develope</context>
</contexts>
<marker>Corbett, Murray-Rust, 2006</marker>
<rawString>Peter Corbett and Peter Murray-Rust. 2006. Highthroughput identification of chemistry in life science texts. In Proc. of CompLife 2006, pages 107–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrien Coulet</author>
<author>Yael Garten</author>
<author>Michel Dumontier</author>
<author>Russ B Altman</author>
<author>Mark A Musen</author>
<author>Nigam H Shah</author>
</authors>
<title>Integration and publication of heterogeneous text-mined relationships on the Semantic Web.</title>
<date>2011</date>
<journal>J. Biomed. Semantics,</journal>
<volume>2</volume>
<pages>2--10</pages>
<contexts>
<context position="5887" citStr="Coulet et al., 2011" startWordPosition="886" endWordPosition="889">al enhancements (see Section 3.1). The SemEval-2013 Task 9.1 poses new challenges on NER tools. Instead of targeting all kinds of chemicals, it focuses on drugs, i.e., pharmacological substances that affect humans and are used for administration. Moreover, entities need to be classified into the four categories mentioned above. 3 Methods Our approach is based on a linear-chain CRF with mostly domain-independent features commonly applied to NER tasks. In addition, we employ various domain-specific features derived from the output of ChemSpot’s components, as well as Jochem, the PHARE ontology (Coulet et al., 2011) and the ChEBI ontology (De Matos et al., 2010). In the following, we first explain extensions to ChemSpot. Subsequently, we give a brief introduction to linearchain CRFs before describing the general and domain-specific features used by our system. Finally, we explain the experimental setup and discuss our results. 3.1 Improvements of ChemSpot To improve ChemSpot’s chemical NER performance, we extend it by two components and modify its match-expansion mechanism. The first addition is a pattern-based tagger for chemical formulae. In its basic form it extracts mentions matching the regular expr</context>
</contexts>
<marker>Coulet, Garten, Dumontier, Altman, Musen, Shah, 2011</marker>
<rawString>Adrien Coulet, Yael Garten, Michel Dumontier, Russ B. Altman, Mark A. Musen, and Nigam H. Shah. 2011. Integration and publication of heterogeneous text-mined relationships on the Semantic Web. J. Biomed. Semantics, 2(Suppl 2):S10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula De Matos</author>
<author>Rafael Alc´antara</author>
<author>Adriano Dekker</author>
<author>Marcus Ennis</author>
<author>Janna Hastings</author>
<author>Kenneth Haug</author>
<author>Inmaculada Spiteri</author>
<author>Steve Turner</author>
<author>Christoph Steinbeck</author>
</authors>
<title>Chemical Entities of Biological Interest: an update. Nucleic Acids Res.,</title>
<date>2010</date>
<marker>De Matos, Alc´antara, Dekker, Ennis, Hastings, Haug, Spiteri, Turner, Steinbeck, 2010</marker>
<rawString>Paula De Matos, Rafael Alc´antara, Adriano Dekker, Marcus Ennis, Janna Hastings, Kenneth Haug, Inmaculada Spiteri, Steve Turner, and Christoph Steinbeck. 2010. Chemical Entities of Biological Interest: an update. Nucleic Acids Res., 38:D249–D254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina M Hettne</author>
<author>Rob H Stierum</author>
<author>Martijn J Schuemie</author>
<author>Peter J M Hendriksen</author>
<author>Bob J A Schijvenaars</author>
<author>Erik M Van Mulligen</author>
<author>Jos Kleinjans</author>
<author>Jan A Kors</author>
</authors>
<title>A dictionary to identify small molecules and drugs in free text.</title>
<date>2009</date>
<journal>Bioinformatics,</journal>
<volume>25</volume>
<issue>22</issue>
<marker>Hettne, Stierum, Schuemie, Hendriksen, Schijvenaars, Van Mulligen, Kleinjans, Kors, 2009</marker>
<rawString>Kristina M. Hettne, Rob H. Stierum, Martijn J. Schuemie, Peter J.M. Hendriksen, Bob J.A. Schijvenaars, Erik M. Van Mulligen, Jos Kleinjans, and Jan A. Kors. 2009. A dictionary to identify small molecules and drugs in free text. Bioinformatics, 25(22):2983–2991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Jessop</author>
<author>Sam E Adams</author>
<author>Egon L Willighagen</author>
<author>Lezan Hawizy</author>
<author>Peter Murray-Rust</author>
</authors>
<title>OSCAR4: a flexible architecture for chemical text-mining.</title>
<date>2011</date>
<journal>J. Cheminf.,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="4246" citStr="Jessop et al., 2011" startWordPosition="617" endWordPosition="620">ld (CRF) (Lafferty et al., 2001) for extracting mentions of IUPAC and IUPAC-like entities. They report an F1 measure of 85.6% on a hand-annotated corpus consisting of MEDLINE abstracts. Segura-Bedmar et al. (2008) introduced DrugNER, which is based on UMLS MetaMap Transfer (MMTx) and nomenclature rules by the World Health Organization International Nonproprietary Names (INNs). Their system extracts and classifies mentions of drugs and achieves a precision of 99.1% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts mentions of a wide range of chemicals using a maximum entropy Markov model (McCallum et al., 2000). It achieves an F1 of 83.2% on a corpus consisting of PubMed abstracts and 80.7% on a corpus consisting of chemistry papers (Corbett and Copestake, 2008). Hettne et al. (2009) compiled Jochem (the joint chemical dictionary) from ChemIDplus, ChEBI, DrugBank, PubChem, HMDB, KEGG, MeSH and CAS Registry IDs. Jochem was used with Peregrine (Schuemie et al., 2007), a dictionary-based NER tool, achieving an F1 of 50% on the SCAI corpus (Kol´arik et al., 2008). We developed ChemSpot (Rockt¨asch</context>
</contexts>
<marker>Jessop, Adams, Willighagen, Hawizy, Murray-Rust, 2011</marker>
<rawString>David M. Jessop, Sam E. Adams, Egon L. Willighagen, Lezan Hawizy, and Peter Murray-Rust. 2011. OSCAR4: a flexible architecture for chemical text-mining. J. Cheminf., 3(1):41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Klinger</author>
<author>Corinna Kol´arik</author>
<author>Juliane Fluck</author>
<author>Martin Hofmann-Apitius</author>
<author>Christoph M Friedrich</author>
</authors>
<title>Detection of IUPAC and IUPAC-like chemical names.</title>
<date>2008</date>
<booktitle>In Proc. of ISMB. Bioinformatics,</booktitle>
<volume>24</volume>
<pages>268--276</pages>
<marker>Klinger, Kol´arik, Fluck, Hofmann-Apitius, Friedrich, 2008</marker>
<rawString>Roman Klinger, Corinna Kol´arik, Juliane Fluck, Martin Hofmann-Apitius, and Christoph M. Friedrich. 2008. Detection of IUPAC and IUPAC-like chemical names. In Proc. of ISMB. Bioinformatics, volume 24, pages i268–i276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Klinger</author>
<author>Katrin Tomanek</author>
</authors>
<title>Classical Probabilistic Models and Conditional Random Fields. Algorithm Engineering</title>
<date>2007</date>
<journal>ISSN</journal>
<tech>Report TR07-2-013.</tech>
<pages>1864--4503</pages>
<institution>Department of Computer Science, Dortmund University of Technology.</institution>
<contexts>
<context position="9343" citStr="Klinger and Tomanek (2007)" startWordPosition="1464" endWordPosition="1467">bels y = fy1, ... , yn} given a sequence x = fx1, ... , xn} of observed input tokens. Labels commonly follow the IOB format, where B denotes a token at the beginning of an entity mention, I denotes the continuation of a mention and O corresponds to tokens that are not part of a mention. Extracting entity mentions from a tokenized text x then amounts to finding y∗ = arg maxy p(y |x). Linear-chain CRFs are well-known discriminative undirected graphical models that encode the conditional probability p(y |x) of a set of input variables x and a sequence of output variables y (see Wallach (2004) or Klinger and Tomanek (2007) for an introduction). In the case of NER, x is a sequence of n tokens and y a sequence of n corresponding labels. Linear-chain CRFs of order k factorize p(y |x) into a product of factors T, globally normalized by an input-dependent partition function Z(x): 1 n p(y |x) = Z(x) H T (yi−k, ... , yi−1, yi, x, i) A factor T is commonly defined as the exponential function of a sum of weighted feature functions ff1, ... , fm} : m � exp �E θj fj (yi−k, ... , yi− 1, yi, x, i) I . /1 The feature function weights fθj} can be learned from training data and are shared across all positions i (parameter tyin</context>
</contexts>
<marker>Klinger, Tomanek, 2007</marker>
<rawString>Roman Klinger and Katrin Tomanek. 2007. Classical Probabilistic Models and Conditional Random Fields. Algorithm Engineering Report TR07-2-013. Department of Computer Science, Dortmund University of Technology. ISSN 1864-4503.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Kol´arik</author>
<author>Roman Klinger</author>
<author>Christoph M Friedrich</author>
<author>Martin Hofmann-Apitius</author>
<author>Juliane Fluck</author>
</authors>
<title>Chemical names: terminological resources and corpora annotation.</title>
<date>2008</date>
<booktitle>In Proc. of the Workshop on Building and</booktitle>
<pages>51--58</pages>
<marker>Kol´arik, Klinger, Friedrich, Hofmann-Apitius, Fluck, 2008</marker>
<rawString>Corinna Kol´arik, Roman Klinger, Christoph M. Friedrich, Martin Hofmann-Apitius, and Juliane Fluck. 2008. Chemical names: terminological resources and corpora annotation. In Proc. of the Workshop on Building and evaluating resources for biomedical text mining, pages 51–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank R Kschischang</author>
<author>Brendan J Frey</author>
<author>Hans-Andrea Loeliger</author>
</authors>
<title>Factor graphs and the sum-product algorithm.</title>
<date>2001</date>
<journal>IEEE Trans. Inf. Theory,</journal>
<volume>47</volume>
<issue>2</issue>
<contexts>
<context position="10037" citStr="Kschischang et al., 2001" startWordPosition="1601" endWordPosition="1604">s and y a sequence of n corresponding labels. Linear-chain CRFs of order k factorize p(y |x) into a product of factors T, globally normalized by an input-dependent partition function Z(x): 1 n p(y |x) = Z(x) H T (yi−k, ... , yi−1, yi, x, i) A factor T is commonly defined as the exponential function of a sum of weighted feature functions ff1, ... , fm} : m � exp �E θj fj (yi−k, ... , yi− 1, yi, x, i) I . /1 The feature function weights fθj} can be learned from training data and are shared across all positions i (parameter tying). The factorization of a CRF can be illustrated by a factor graph (Kschischang et al., 2001). A factor graph is a bipartite graph, where one set of nodes corresponds to random variables and the other to factors. Each factor is connected to the variables of its domain, making the factorization of the model apparent. Figure 1 shows a factor graph for a segment of a linear-chain CRF of order one and two respectively. In a linear-chain CRF of order k, the label of a token at position i is connected via feature functions of a factor to the input sequence x as well as the previous k labels. For example, in a first-order linear-chain CRF, one of the feature functions could be f[O→B,capital]</context>
</contexts>
<marker>Kschischang, Frey, Loeliger, 2001</marker>
<rawString>Frank R. Kschischang, Brendan J. Frey, and Hans-Andrea Loeliger. 2001. Factor graphs and the sum-product algorithm. IEEE Trans. Inf. Theory, 47(2):498–519.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proc. of ICML-2001,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="3658" citStr="Lafferty et al., 2001" startWordPosition="528" endWordPosition="531">tasks, achieves a comparable performance. 2 Related work Various NER systems for identifying different classes of chemical entities, including mentions of drugs, trivial names and IUPAC terms, have been proposed. 1http://www.cs.york.ac.uk/semeval-2013/task9/ (accessed 2013-04-29) 356 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 356–363, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics Klinger et al. (2008) trained a conditional random field (CRF) (Lafferty et al., 2001) for extracting mentions of IUPAC and IUPAC-like entities. They report an F1 measure of 85.6% on a hand-annotated corpus consisting of MEDLINE abstracts. Segura-Bedmar et al. (2008) introduced DrugNER, which is based on UMLS MetaMap Transfer (MMTx) and nomenclature rules by the World Health Organization International Nonproprietary Names (INNs). Their system extracts and classifies mentions of drugs and achieves a precision of 99.1% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts me</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proc. of ICML-2001, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Graciela Gonzalez</author>
</authors>
<title>BANNER: an executable survey of advances in biomedical named entity recognition.</title>
<date>2008</date>
<booktitle>In Proc. of Pac Symp Biocomput,</booktitle>
<pages>652--663</pages>
<contexts>
<context position="12679" citStr="Leaman and Gonzalez (2008)" startWordPosition="2066" endWordPosition="2069">oid withdrawal signs . Table 1: Example label sequence for the tokenized sentence MedLine.d110.s4 of the training corpus. Feature Class Description fCHEMSPOT part of a prediction by ChemSpot fIUPAC part of an IUPAC entity FC fFORMULA part of a chemical formula fDICTIONARY part of a dictionary match fABBREV part of a chemical abbreviation fJOCHEM dictionaries in Jochem FJ fPREFIX frequent chemical prefix fSUFFIX frequent chemical suffix fPHARE PHARE ontology FO fCHEBDESCS #descendants in ChEBI ontology fCHEBDEPTH average depth in ChEBI ontology fKLINGER see Klinger et al. (2008) FG fBANNER see Leaman and Gonzalez (2008) fABNER see Settles (2005) fUPPERCASESENT. part of an upper-case sentence FF fPREVWINDOW text of preceding four tokens fNEXTWINDOW text of succeeding four tokens Table 2: Overview of features used for identifying and classifying mentions of pharmacological substances. Note that the sequence-labeling approach in the described form cannot cope with discontinuous entity mentions. Since only a tiny fraction (� 0.3%) of entities in the training corpus are discontinuous, we simply neglect these for training and tagging. 3.3 Feature sets An overview of the features used by our system is shown in Tabl</context>
</contexts>
<marker>Leaman, Gonzalez, 2008</marker>
<rawString>Robert Leaman and Graciela Gonzalez. 2008. BANNER: an executable survey of advances in biomedical named entity recognition. In Proc. of Pac Symp Biocomput, pages 652–663.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Laura Wojtulewicz</author>
<author>Ryan Sullivan</author>
<author>Annie Skariah</author>
<author>Jian Yang</author>
<author>Graciela Gonzalez</author>
</authors>
<title>Towards internet-age pharmacovigilance: extracting adverse drug reactions from user posts to health-related social networks.</title>
<date>2010</date>
<booktitle>In Proc. of Workshop BioNLP,</booktitle>
<pages>117--125</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1696" citStr="Leaman et al. (2010)" startWordPosition="228" endWordPosition="232"> domain-specific resources. We demonstrate that acceptable results can be achieved with the former system. Still, our experiments show that using domain-specific features outperforms this general approach. Our system ranked first in the SemEval-2013 Task 9.1: Recognition and classification of pharmacological substances. 1 Introduction The accurate identification of drug mentions in text is an important prerequisite for many applications, including the retrieval of information about substances in drug development (e.g. Roberts and Hayes (2008)), the identification of adverse drug effects (e.g. Leaman et al. (2010)) and the recognition of drug-drug interactions (e.g. Thomas et al. (2011)). Given that most of the information related to drug research is covered by medical reports and pharmacological publications, computational methods for information extraction should be used to support this task. The SemEval-2013 Task 9.1 competition1 (SeguraBedmar et al., 2013) aims at a fair assessment on the state-of-the-art of tools that recognize and classify mentions of pharmacological substances in natural language texts – a task referred to as drug named entity recognition (NER). The goal of participating teams i</context>
</contexts>
<marker>Leaman, Wojtulewicz, Sullivan, Skariah, Yang, Gonzalez, 2010</marker>
<rawString>Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, Annie Skariah, Jian Yang, and Graciela Gonzalez. 2010. Towards internet-age pharmacovigilance: extracting adverse drug reactions from user posts to health-related social networks. In Proc. of Workshop BioNLP, pages 117–125. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Lowe</author>
<author>Peter T Corbett</author>
<author>Peter Murray-Rust</author>
<author>Robert C Glen</author>
</authors>
<title>Chemical name to structure: Opsin, an open source solution.</title>
<date>2011</date>
<journal>J. Chem. Inf. Model.,</journal>
<volume>51</volume>
<issue>3</issue>
<contexts>
<context position="8231" citStr="Lowe et al., 2011" startWordPosition="1268" endWordPosition="1271"> the document. ChemSpot’s match-expansion often leads to the extraction of non-chemical suffixes corresponding to verbs, e.g., “-induced”, “-enriched” or “-mediated”. 2By convention, 1 is ommited (e.g. CO2 instead of C1O2). 357 Figure 1: A factor graph for a 1st-order linear-chain CRF (2nd-order with dashed edges). Note that for each feature function fj in the factor T, the same weight θj is used at all other positions (gray) in the sequence (parameter tying). To tackle this issue we stop the expansion at tokens whose part-of-speech tag refers to a verb form. Furthermore, we integrated OPSIN (Lowe et al., 2011) to normalize entity mentions to InChI strings. The current v1.5 release of ChemSpot achieves an overall F1 of 74.2% on the SCAI corpus, improving the performance by 6.1 percentage points (pp) F1 compared to ChemSpot v1.0. 3.2 Linear-chain conditional random fields Contrary to the hybrid strategy used in ChemSpot, we follow a purely machine learning based approach for drug NER in this work. NER can be formulated as a sequence labeling task where the goal is to find a sequence of labels y = fy1, ... , yn} given a sequence x = fx1, ... , xn} of observed input tokens. Labels commonly follow the I</context>
</contexts>
<marker>Lowe, Corbett, Murray-Rust, Glen, 2011</marker>
<rawString>Daniel M. Lowe, Peter T. Corbett, Peter Murray-Rust, and Robert C. Glen. 2011. Chemical name to structure: Opsin, an open source solution. J. Chem. Inf. Model., 51(3):739–753.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew K McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<location>http://mallet.cs.umass.edu.</location>
<contexts>
<context position="11369" citStr="McCallum, 2002" startWordPosition="1842" endWordPosition="1843">). Multiplication with the weight θ[O→B,capital] yields an unnormalized local score that indicates how favorable a transition from O to B is provided that the token at position i starts with a capital letter. Note that the terms feature function and feature are often used synonymously and the case differentiation for different labels is implicit. In this work a feature fcapital denotes its corresponding set of firstorder feature functions ff[s→t,capital](yi−1,yi, x, i) | (s, t) C f(B, B), (B, I), (B, O), (I, B), (I, I), (I, O), (O, B), (O, O)}}3 (similarly for second-order). We employ MALLET (McCallum, 2002) as underlying CRF implementation and use a second-order linear-chain CRF with offset conjunctions of order two. Offset conjunctions of order k adds features around a window of k to the features at a particular position, providing more contextual information. Akin to Klinger et al. (2008), we perform finegrained tokenization, splitting at special characters and transitions from alphanumeric characters to digits. An exemplary tagging sequence is shown in Table 1. 3Transitions from O to I are invalid. yi−2 yi−1 yi yi+1 yi+2 T T x T T T i=1 1 n H i=1 Z(x) 358 i 0 1 2 3 4 5 6 7 8 9 10 y O B-DrugN </context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew K. McCallum. 2002. MALLET: A Machine Learning for Language Toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pereira</author>
</authors>
<title>Maximum entropy Markov models for information extraction and segmentation.</title>
<date>2000</date>
<booktitle>In Proc. of ICML-2000,</booktitle>
<pages>591--598</pages>
<marker>Pereira, 2000</marker>
<rawString>Andrew K. McCallum, Dayne Freitag, and Fernando. Pereira. 2000. Maximum entropy Markov models for information extraction and segmentation. In Proc. of ICML-2000, pages 591–598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew K McCallum</author>
<author>Karl Schultz</author>
<author>Sameer Singh</author>
</authors>
<title>FACTORIE: Probabilistic programming via imperatively defined factor graphs.</title>
<date>2009</date>
<booktitle>In Proc. of Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="14511" citStr="McCallum et al., 2009" startWordPosition="2363" endWordPosition="2366">medical NER tasks, e.g., identifying mentions of DNA sequences, genes, diseases, mutations, IUPAC terms, cell lines and cell types. They encompass morphological, syntactic and orthographic features, such as the text of the token itself, token character n-grams of length 2 and 3, prefixes and suffixes of length 2, 3, and 4, characters left and right to a token and part-ofspeech tags. Furthermore, they contain various regular expressions that capture, for instance, whether a token starts with a capital letter or contains digits. In addition, we employ features based on NER examples in FACTORIE (McCallum et al., 2009). Specifically, we use the text of the four preceding and succeeding tokens and whether a token is part of a sentence that contains only upper-case characters. The latter is commonly the case for headlines, which likely contain an entity mention. 3.3.2 Run 2: domain-specific features In addition to the features of Run 1, we use predictions of our improved version of ChemSpot, as well as features derived from Jochem, PHARE and ChEBI. ChemSpot-based features FC: When a token is part of a mention extracted by one of ChemSpot’s components (i.e. IUPAC entity, chemical formula, dictionary match or c</context>
</contexts>
<marker>McCallum, Schultz, Singh, 2009</marker>
<rawString>Andrew K. McCallum, Karl Schultz, and Sameer Singh. 2009. FACTORIE: Probabilistic programming via imperatively defined factor graphs. In Proc. of Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phoebe M Roberts</author>
<author>William S Hayes</author>
</authors>
<title>Information needs and the role of text mining in drug development.</title>
<date>2008</date>
<booktitle>In Proc. of Pac Symp Biocomput,</booktitle>
<pages>592--603</pages>
<contexts>
<context position="1624" citStr="Roberts and Hayes (2008)" startWordPosition="217" endWordPosition="220">nerated from the output of an existing chemical NER tool and a collection of domain-specific resources. We demonstrate that acceptable results can be achieved with the former system. Still, our experiments show that using domain-specific features outperforms this general approach. Our system ranked first in the SemEval-2013 Task 9.1: Recognition and classification of pharmacological substances. 1 Introduction The accurate identification of drug mentions in text is an important prerequisite for many applications, including the retrieval of information about substances in drug development (e.g. Roberts and Hayes (2008)), the identification of adverse drug effects (e.g. Leaman et al. (2010)) and the recognition of drug-drug interactions (e.g. Thomas et al. (2011)). Given that most of the information related to drug research is covered by medical reports and pharmacological publications, computational methods for information extraction should be used to support this task. The SemEval-2013 Task 9.1 competition1 (SeguraBedmar et al., 2013) aims at a fair assessment on the state-of-the-art of tools that recognize and classify mentions of pharmacological substances in natural language texts – a task referred to a</context>
</contexts>
<marker>Roberts, Hayes, 2008</marker>
<rawString>Phoebe M. Roberts and William S. Hayes. 2008. Information needs and the role of text mining in drug development. In Proc. of Pac Symp Biocomput, pages 592–603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Rockt¨aschel</author>
<author>Michael Weidlich</author>
<author>Ulf Leser</author>
</authors>
<title>ChemSpot: A Hybrid System for Chemical Named Entity Recognition.</title>
<date>2012</date>
<journal>Bioinformatics,</journal>
<volume>28</volume>
<issue>12</issue>
<marker>Rockt¨aschel, Weidlich, Leser, 2012</marker>
<rawString>Tim Rockt¨aschel, Michael Weidlich, and Ulf Leser. 2012. ChemSpot: A Hybrid System for Chemical Named Entity Recognition. Bioinformatics, 28(12):1633–1640.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandeepkumar Satpal</author>
<author>Sunita Sarawagi</author>
</authors>
<title>Domain adaptation of conditional probability models via feature subsetting.</title>
<date>2007</date>
<booktitle>In Knowledge Discovery in Databases: PKDD</booktitle>
<pages>224--235</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="23287" citStr="Satpal and Sarawagi (2007)" startWordPosition="3842" endWordPosition="3845">plications building upon drug NER. Nevertheless, adding domain-specific features boosts the performance considerably. Further improvements can be achieved by using entity annotations of the Task 9.2 test corpus as additional training data. We identified two limitations of our approach. First, we found that entities of the minority class (DrugN) are very hard to classify correctly. Second, differences between DrugBank and MEDLINE documents probably cause a domain-adaptation problem. For future work, one could investigate whether the latter can be addressed by domain-adaptation techniques (e.g. Satpal and Sarawagi (2007)). To cope with DrugN entities, one could implement features derived from those resources that were used by the annotators for deciding whether a substance is approved for use in humans, e.g., Drugs@FDA4 and the WHO ATC5 classification system. 4http://www.accessdata.fda.gov/scripts/cder/ drugsatfda/ (accessed 2013-04-29) 5http://www.whocc.no/atc_ddd_index/ (accessed 2013-04-29) 361 Acknowledgements We thank Philippe Thomas for preparing a simplified format of the corpora. We thank him and Roman Klinger for fruitful discussions. Funding: Tim Rockt¨aschel is funded by the German Federal Ministry</context>
</contexts>
<marker>Satpal, Sarawagi, 2007</marker>
<rawString>Sandeepkumar Satpal and Sunita Sarawagi. 2007. Domain adaptation of conditional probability models via feature subsetting. In Knowledge Discovery in Databases: PKDD 2007, pages 224–235. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martijn J Schuemie</author>
<author>Rob Jelier</author>
<author>Jan A Kors</author>
</authors>
<title>Peregrine: Lightweight gene name normalization by dictionary lookup.</title>
<date>2007</date>
<booktitle>In Proc. of the Second BioCreative Challenge,</booktitle>
<volume>2</volume>
<pages>131--133</pages>
<contexts>
<context position="4715" citStr="Schuemie et al., 2007" startWordPosition="694" endWordPosition="697">% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts mentions of a wide range of chemicals using a maximum entropy Markov model (McCallum et al., 2000). It achieves an F1 of 83.2% on a corpus consisting of PubMed abstracts and 80.7% on a corpus consisting of chemistry papers (Corbett and Copestake, 2008). Hettne et al. (2009) compiled Jochem (the joint chemical dictionary) from ChemIDplus, ChEBI, DrugBank, PubChem, HMDB, KEGG, MeSH and CAS Registry IDs. Jochem was used with Peregrine (Schuemie et al., 2007), a dictionary-based NER tool, achieving an F1 of 50% on the SCAI corpus (Kol´arik et al., 2008). We developed ChemSpot (Rockt¨aschel et al., 2012), a system for extracting mentions of various kinds of chemicals from text. We applied a CRF for extracting mentions of IUPAC entities based on the work of Klinger et al. (2008) and used Jochem (Hettne et al., 2009) with an adapted matchingmechanism for identifying trivial names, drugs and brands. ChemSpot v1.0 achieved an overall F1 of 68.1% on the SCAI corpus. In the meantime, we have worked on several enhancements (see Section 3.1). The SemEval-2</context>
</contexts>
<marker>Schuemie, Jelier, Kors, 2007</marker>
<rawString>Martijn J. Schuemie, Rob Jelier, and Jan A. Kors. 2007. Peregrine: Lightweight gene name normalization by dictionary lookup. In Proc. of the Second BioCreative Challenge, volume 2, pages 131–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariel S Schwartz</author>
<author>Marti A Hearst</author>
</authors>
<title>A simple algorithm for identifying abbreviation definitions in biomedical text.</title>
<date>2003</date>
<booktitle>In Proc. of Pac Symp Biocomput,</booktitle>
<volume>8</volume>
<pages>451--462</pages>
<contexts>
<context position="6929" citStr="Schwartz and Hearst (2003)" startWordPosition="1043" endWordPosition="1046">omponents and modify its match-expansion mechanism. The first addition is a pattern-based tagger for chemical formulae. In its basic form it extracts mentions matching the regular expression (S N?(\+|-)?)+ where S denotes a chemical symbol and N a natural number greater one.2 This pattern is augmented by filters to comply with other naming conventions, such as correct grouping of compounds with parentheses. The second extension targets ambiguous abbreviations. For example, the abbreviation “DAG” could denote “diacylglycerol” or “directed acyclic graph”. We use ABBREV, an algorithm proposed by Schwartz and Hearst (2003), for extracting such abbreviations and their definitions (e.g. “diacylglycerol (DAG)”). Note that the position of the long form (LF) and short form (SF) is interchangeable. To disambiguate between chemical and non-chemical abbreviations, we apply the following two rules to the mentions extracted by ChemSpot: (1) For a given pair of LF and SF, we check whether the LF was found to be a chemical but the SF was not. In this case we add a new annotation for every occurrence of the SF in the document. (2) Contrary to that, if only the SF was tagged as a chemical but the LF was not, we assume that t</context>
</contexts>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>Ariel S. Schwartz and Marti A. Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical text. In Proc. of Pac Symp Biocomput, volume 8, pages 451–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Segura-Bedmar</author>
<author>Paloma Martinez</author>
<author>Maria Herrero-Zazo</author>
</authors>
<title>Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts.</title>
<date>2013</date>
<booktitle>In Proc. of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Segura-Bedmar, Martinez, Herrero-Zazo, 2013</marker>
<rawString>Isabel Segura-Bedmar, Paloma Martinez, and Maria Herrero-Zazo. 2013. Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts. In Proc. of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Segura-Bedmar</author>
<author>Paloma Martinez</author>
<author>Maria Segura-Bedmar</author>
</authors>
<title>Drug name recognition and classification in biomedical texts. A case study outlining approaches underpinning automated systems. Drug Discovery Today,</title>
<date>2008</date>
<pages>13--17</pages>
<contexts>
<context position="3839" citStr="Segura-Bedmar et al. (2008)" startWordPosition="556" endWordPosition="559">and IUPAC terms, have been proposed. 1http://www.cs.york.ac.uk/semeval-2013/task9/ (accessed 2013-04-29) 356 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 356–363, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics Klinger et al. (2008) trained a conditional random field (CRF) (Lafferty et al., 2001) for extracting mentions of IUPAC and IUPAC-like entities. They report an F1 measure of 85.6% on a hand-annotated corpus consisting of MEDLINE abstracts. Segura-Bedmar et al. (2008) introduced DrugNER, which is based on UMLS MetaMap Transfer (MMTx) and nomenclature rules by the World Health Organization International Nonproprietary Names (INNs). Their system extracts and classifies mentions of drugs and achieves a precision of 99.1% and a recall of 99.8% on a silver-standard corpus. OSCAR (Open-Source Chemistry Analysis Routines) (Corbett and Murray-Rust, 2006; Jessop et al., 2011) extracts mentions of a wide range of chemicals using a maximum entropy Markov model (McCallum et al., 2000). It achieves an F1 of 83.2% on a corpus consisting of PubMed abstracts and 80.7% on </context>
</contexts>
<marker>Segura-Bedmar, Martinez, Segura-Bedmar, 2008</marker>
<rawString>Isabel Segura-Bedmar, Paloma Martinez, and Maria Segura-Bedmar. 2008. Drug name recognition and classification in biomedical texts. A case study outlining approaches underpinning automated systems. Drug Discovery Today, 13(17-18):816–823.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>ABNER: an open source tool for automatically tagging genes, proteins and other entity names in text.</title>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<issue>14</issue>
<contexts>
<context position="12705" citStr="Settles (2005)" startWordPosition="2072" endWordPosition="2073">e label sequence for the tokenized sentence MedLine.d110.s4 of the training corpus. Feature Class Description fCHEMSPOT part of a prediction by ChemSpot fIUPAC part of an IUPAC entity FC fFORMULA part of a chemical formula fDICTIONARY part of a dictionary match fABBREV part of a chemical abbreviation fJOCHEM dictionaries in Jochem FJ fPREFIX frequent chemical prefix fSUFFIX frequent chemical suffix fPHARE PHARE ontology FO fCHEBDESCS #descendants in ChEBI ontology fCHEBDEPTH average depth in ChEBI ontology fKLINGER see Klinger et al. (2008) FG fBANNER see Leaman and Gonzalez (2008) fABNER see Settles (2005) fUPPERCASESENT. part of an upper-case sentence FF fPREVWINDOW text of preceding four tokens fNEXTWINDOW text of succeeding four tokens Table 2: Overview of features used for identifying and classifying mentions of pharmacological substances. Note that the sequence-labeling approach in the described form cannot cope with discontinuous entity mentions. Since only a tiny fraction (� 0.3%) of entities in the training corpus are discontinuous, we simply neglect these for training and tagging. 3.3 Feature sets An overview of the features used by our system is shown in Table 2. Our first two submiss</context>
</contexts>
<marker>Settles, 2005</marker>
<rawString>Burr Settles. 2005. ABNER: an open source tool for automatically tagging genes, proteins and other entity names in text. Bioinformatics, 21(14):3191–3192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Thomas</author>
<author>Mariana Neves</author>
<author>Ill´es Solt</author>
<author>Domonkos Tikk</author>
<author>Ulf Leser</author>
</authors>
<title>Relation extraction for drugdrug interactions using ensemble learning.</title>
<date>2011</date>
<booktitle>In Proc. of the 1st Challenge Task on Drug-Drug Interaction Extraction</booktitle>
<pages>11--18</pages>
<contexts>
<context position="1770" citStr="Thomas et al. (2011)" startWordPosition="240" endWordPosition="243">achieved with the former system. Still, our experiments show that using domain-specific features outperforms this general approach. Our system ranked first in the SemEval-2013 Task 9.1: Recognition and classification of pharmacological substances. 1 Introduction The accurate identification of drug mentions in text is an important prerequisite for many applications, including the retrieval of information about substances in drug development (e.g. Roberts and Hayes (2008)), the identification of adverse drug effects (e.g. Leaman et al. (2010)) and the recognition of drug-drug interactions (e.g. Thomas et al. (2011)). Given that most of the information related to drug research is covered by medical reports and pharmacological publications, computational methods for information extraction should be used to support this task. The SemEval-2013 Task 9.1 competition1 (SeguraBedmar et al., 2013) aims at a fair assessment on the state-of-the-art of tools that recognize and classify mentions of pharmacological substances in natural language texts – a task referred to as drug named entity recognition (NER). The goal of participating teams is to recreate the gold annotation on a heldout part of an annotated corpus</context>
</contexts>
<marker>Thomas, Neves, Solt, Tikk, Leser, 2011</marker>
<rawString>Philippe Thomas, Mariana Neves, Ill´es Solt, Domonkos Tikk, and Ulf Leser. 2011. Relation extraction for drugdrug interactions using ensemble learning. In Proc. of the 1st Challenge Task on Drug-Drug Interaction Extraction 2011, pages 11–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna M Wallach</author>
</authors>
<title>Conditional Random Fields: An Introduction.</title>
<date>2004</date>
<tech>Technical Report MS-CIS-04-21.</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="9313" citStr="Wallach (2004)" startWordPosition="1461" endWordPosition="1462">d a sequence of labels y = fy1, ... , yn} given a sequence x = fx1, ... , xn} of observed input tokens. Labels commonly follow the IOB format, where B denotes a token at the beginning of an entity mention, I denotes the continuation of a mention and O corresponds to tokens that are not part of a mention. Extracting entity mentions from a tokenized text x then amounts to finding y∗ = arg maxy p(y |x). Linear-chain CRFs are well-known discriminative undirected graphical models that encode the conditional probability p(y |x) of a set of input variables x and a sequence of output variables y (see Wallach (2004) or Klinger and Tomanek (2007) for an introduction). In the case of NER, x is a sequence of n tokens and y a sequence of n corresponding labels. Linear-chain CRFs of order k factorize p(y |x) into a product of factors T, globally normalized by an input-dependent partition function Z(x): 1 n p(y |x) = Z(x) H T (yi−k, ... , yi−1, yi, x, i) A factor T is commonly defined as the exponential function of a sum of weighted feature functions ff1, ... , fm} : m � exp �E θj fj (yi−k, ... , yi− 1, yi, x, i) I . /1 The feature function weights fθj} can be learned from training data and are shared across a</context>
</contexts>
<marker>Wallach, 2004</marker>
<rawString>Hanna M. Wallach. 2004. Conditional Random Fields: An Introduction. Technical Report MS-CIS-04-21. Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David H Wolpert</author>
</authors>
<title>Stacked generalization.</title>
<date>1992</date>
<journal>Neural Networks,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="15461" citStr="Wolpert (1992)" startWordPosition="2516" endWordPosition="2517">tions of our improved version of ChemSpot, as well as features derived from Jochem, PHARE and ChEBI. ChemSpot-based features FC: When a token is part of a mention extracted by one of ChemSpot’s components (i.e. IUPAC entity, chemical formula, dictionary match or chemical abbreviation), we use the name of the respective component as feature. In addition, we determine whether a token is part of an entity predicted by ChemSpot after match-expansion, boundary-correction and resolution of overlapping entities. Using the output of ChemSpot as features for our system could be framed as stacking (see Wolpert (1992)). Jochem-based features FJ: For every dictionary contained in Jochem, we check whether a token is part of an entity in that dictionary and use the name of the dictionary as feature. Furthermore, we compile 359 a list of frequent chemical suffixes and prefixes of length three from Jochem. Ontology-based features FO: It is often hard to determine whether a mention refers to a specific chemical entity or rather an abstract term denoting a group of chemicals. To distinguish between these two cases, we calculate the average depth and the number of descendants of a term in the ChEBI ontology and us</context>
</contexts>
<marker>Wolpert, 1992</marker>
<rawString>David H. Wolpert. 1992. Stacked generalization. Neural Networks, 5(2):241–259.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>