<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015647">
<title confidence="0.990632">
A Toolkit to Assist L2 Learners Become Independent Writers
</title>
<author confidence="0.858892">
John Milton and Vivying S. Y. Cheng
</author>
<affiliation confidence="0.6654985">
Language Center
HKUST, Clear Water Bay
</affiliation>
<address confidence="0.296668">
Hong Kong
</address>
<email confidence="0.927487">
{lcjohn,vivying}@ust.hk
</email>
<sectionHeader confidence="0.994148" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997869909090909">
This paper describes a resource-rich toolkit
that assists EFL writers take a discovery-
based approach to writing accurate and fluent
English. The system helps learners identify
lexico-grammatical errors by matching pat-
terns gleaned from a very large corpus of
learners’ texts. Users are guided to appropri-
ate language patterns as they write and revise
through online declarative and procedural re-
sources. Even as more robust and fully auto-
matic feedback technologies evolve,
comprehensive resource-rich support will re-
main necessary for second-language (L2)
writers who must develop practical life-long
language learning strategies. To assist lan-
guage tutors support novice L2 writers, we
have also produced tools that help tutors rein-
force their students’ independent writing and
proofreading strategies. The operation and ra-
tionale of this approach have been imple-
mented and evaluated in several Hong Kong
universities and secondary schools.
</bodyText>
<sectionHeader confidence="0.999122" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954365853658">
Proofing technologies for L2 writers have been of
interest to the NLP community since the 1970s,
and have been subject to critical evaluation since
the early 80s (e.g., Frase et al, 1981, Dobrin,
1985). In spite of continued interest in this area
(e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et
al, 2008; Bender, 2009), computational linguists
themselves remain disappointed with the lack of
ongoing development of commercially available
systems (Wampler, 2002). A more serious prob-
lem, from the view of applied linguists, is that en-
thusiasm for the technology has often resulted in a
purely operational approach. The focus on algo-
rithmic solutions to the correction of ill-formed
input has frequently overlooked the long-term
pedagogical needs of L2 novice writers. The pars-
ing techniques of grammar checkers may reliably
flag a subset of L2 errors; however, there is some
question as to whether automatically generated
prescriptive advice, even when it is reliable, actu-
ally helps learner language evolve (Bolt, 1992;
Chen, 1997). While machine-generated error iden-
tification and correction may be a desirable con-
venience for casual writers, explicit correction by a
machine, or for that matter, a human tutor, appears
to be counterproductive in the development of an
L2 writer’s proficiency (Truscott, 1996; Ferris and
Hedgcock, 2005).
The goal of the project described here is to de-
velop a suite of tools that will help novice writers
who are learning to write in academic or profes-
sional contexts improve the accuracy and fluency
of their texts, while also becoming more confident
in their long-term command of English. We have
developed companion tools to help teachers of
writing improve the efficiency and reliability of
their feedback, and move L2 novice writers toward
life-long independence. The following section out-
lines some of the limitations of currently available
grammar checking software in accomplishing these
goals.
</bodyText>
<sectionHeader confidence="0.853884" genericHeader="method">
2 Limitations of Parsing Technology
</sectionHeader>
<bodyText confidence="0.9998626">
Most grammar checking programs use some form
of parsing to identify errors. Typically, if a sen-
tence is ungrammatical according to a set of pars-
ing rules, the programs attempt alternate analysis.
However, the unconstrained text of L2 learners is
</bodyText>
<page confidence="0.995914">
33
</page>
<note confidence="0.9667765">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 33–41,
Los Angeles, California, June 2010. @2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999442575757576">
difficult to parse. Even more demanding is the
ability of software (or, very often, human tutors) to
suggest a ‘correct’ version that reflects the writer’s
intention. This requires semantic disambiguation
well beyond our current ontology or technology.
The difficulties in parsing natural language are
compounded in the case of interlanguage (Schnei-
der and McCoy, 1998). Parsers generally are
based on theoretical models of how grammatical
sentences of the target language should be con-
structed. This approach is especially ineffective
for cases where the speakers’ first language is lin-
guistically remote from the target language. For
example, the current version of the parser-based
grammar checker in Microsoft Word sacrifices a
low rate of recall for a relatively high rate of preci-
sion in the analysis of Chinese speakers’ English
texts. That is, it displays few flagged errors com-
pared to the total number of errors actually occur-
ring in a text, a necessary trade-off resulting from
the need to reduce distracting false positives. This
is understandable since the rates of recall and pre-
cision for various grammatical constituents are
inconsistent, and the numbers of false positives are
not easily reduced across all types of grammatical
constructions.
The insufficient, but nevertheless often still in-
accurate, and frequently non-existent, advice of
these programs is easily demonstrated. Following
are a few common sentence-level errors produced
by Chinese-speaking novice writers, and the com-
ments generated by the Microsoft Word grammar
checker:
</bodyText>
<listItem confidence="0.850956142857143">
1. It worth studying hard.
[Advice: Fragment (consider revising)]
2. I born in Hong Kong.
[Advice: substitute I bore / I had born / I have
born]
3. There have three students there.
[Error not flagged]
</listItem>
<bodyText confidence="0.99949">
These errors are typical examples of learners’ at-
tempts to map Chinese syntax on English construc-
tions (treating ‘worth’, which functions here as a
preposition1, as a verb, forcing the passive verb
‘born’ into an active construction, and blending the
verbs ‘be’ and ‘have’ into one form, as their
</bodyText>
<footnote confidence="0.96551375">
1 The tendency of most dictionaries to label ‘worth’ as an ad-
jective, regardless of its function in the sentence, may com-
pound the confusion for speakers of Chinese, who often
confuse adjective and noun forms and functions.
</footnote>
<bodyText confidence="0.999650178571429">
equivalents are in Chinese). The first comment is
unhelpful; all options in the second set of sugges-
tions are, bizarrely, further from Standard English
than the student’s original text, and the third sen-
tence passes without comment.
In addition to its general unreliability for L2
writers, grammar/style-checking software has been
censured for giving overly narrow and prescriptive
advice (Pennington, 1992), for compounding the
already constrained nature of L2 production
(Chapelle, 2001) and for otherwise abusing the
tenets of good pedagogy (McGee and Ericsson,
2002). Even if the reliability of parsing technology
can be significantly enhanced, much of the compo-
sition research of the last fifty years has argued
against imposing corrections on the texts of novice
writers. Current theories of language pedagogy
promote learner independence and discourage di-
rect correction by tutors. In light of the limitations
of writing software, reliance on a deus ex machina
for correction is hardly a desirable alternative to
dependence on a language tutor.
A more principled, and ultimately more valid,
role for language tools in supporting L2 novice
writers is to enable them to test their evolving hy-
potheses of the L2. This should free the human
tutor in an academic context to act as a guide, en-
suring that these hypotheses evolve.
</bodyText>
<sectionHeader confidence="0.9227915" genericHeader="method">
3 Assisting L2 Writers become Independ-
ent
</sectionHeader>
<bodyText confidence="0.999970352941177">
Our objective has been to develop a program that
avoids machine-generated prescription, while still
helping L2 writers identify common grammatical,
lexical and style errors. Instead of proscribing us-
age and preempting users’ choices, we expose L2
writers to authentic language and help them be-
come aware of the differences between their inter-
language and the particular L2 genre they are
attempting to produce.
Unlike typical grammar checkers, our program
does not appropriate the embryonic text of novice
writers. Many of these learners will spend much of
their professional life writing in the L2, and they
need to develop independence. While not explic-
itly correcting lexico-grammatical errors, we aim
to sensitize learners to common errors, without
relying on a generic parser.
</bodyText>
<page confidence="0.997631">
34
</page>
<figureCaption confidence="0.997855">
Figure 1: A discovery-based model of the writing proc-
ess.
</figureCaption>
<bodyText confidence="0.997905582089553">
Figure 1 illustrates our model of a discovery-
based approach for L2 writers. During the writing
process, learners can consult resources that provide
information on problematic L2 grammatical struc-
tures, as well as the semantic and collocational
properties of L2 lexis. Users are guided through a
discovery process that helps them become respon-
sible for their own writing, thus reducing the bur-
den on both software and human tutors to identify
and correct errors. The role of the software, and of
the human tutor, is to assist the writer express
meaning in an acceptable manner, rather than ex-
plicitly to interpret the writer’s text.
Our approach allows L2 writers to improve in
two fundamentally different ways: through didactic
explanations and via an inductive/procedural ap-
proach. They can choose either method or a com-
bination, depending on the nature of the language
problem and each user’s learning style (e.g., their
extent of ‘field dependence’, see Witkin et al.,
1977).
The program ‘Check My Words’ (Figure 2)
gives L2 novice writers access to interactive ex-
planations of common structural and lexical errors
from an Internet grammar as they write. These
explanations are based on an analysis of a large L2
corpus consisting of millions of words of the writ-
ing of Chinese speakers, from which a typology of
misused, and blatantly underused or overused lexi-
cal and structural patterns, was extracted (e.g., Mil-
ton, 2001). Hundreds of problematic words and
patterns in a learner’s text are explained. This is
the kind of didactic, deductive advice that a good
textbook might provide, except that there are few
textbooks targeted directly at the EFL learning dif-
ficulties of speakers of particular L1s, and this in-
ternet grammar is embellished with interactive
multimedia: it is fun to use.
Secondly, the program enables learners to dis-
cover how the language they are struggling to use
is formulated in relevant, professionally written
texts. They have a choice of search engines that
they can use to look up words in context. To-
gether, these search engines address many of the
problems learners encounter in choosing words,
forms and constructions. This inductive, proce-
dural access to writing models, combined with the
feedback tutors can provide via companion tools,
greatly increases the amount of positive and nega-
tive evidence about the L2 available to the novice
writer—support that researchers of applied linguis-
tics believe promotes language acquisition (e.g.,
Trahey and White, 1993, Doughty and Varela,
1998).
In addition to helping learners become more
confident, responsible, and independent in select-
ing language that is both accurate and appropriate
to their purposes, this approach helps relieve lan-
guage tutors of the need to act as proofreading
slaves. When learners are given the tools to attend
to form, taught how to use the tools, and held ac-
countable for their own progress, teachers can
share more of the burden of responsibility for
learning with their students. This approach re-
duces the need to impose corrections, either by
human or machine intervention. The next section
explains this procedure in more detail.
</bodyText>
<sectionHeader confidence="0.875174" genericHeader="method">
4 Promoting language awareness
</sectionHeader>
<bodyText confidence="0.999470888888889">
‘Check My Words’ is designed to encourage learn-
ers of English become aware of the role of lexis,
forms, and functions in the L2, and to self-correct.
Errors in the L2 writing of Chinese speakers have
been analyzed and compiled into an online gram-
mar guide mapped to the user’s word processor so
that problematic words and structures can be que-
ried during the writing process to determine if they
are misused in the writer’s document.
An example is one of the interlanguage patterns
we noted earlier: ‘It worth studying hard.’ In such
cases, where the error is easily captured as a lexical
pattern (‘worth’ occurring without the verb ‘be’),
the program highlights the pattern, and the user
then presses a ‘Check’ button to see possible er-
rors, with the most probable error highlighted
(Figure 3). The user selects a link to consult the
English Grammar Guide (EGG).
</bodyText>
<page confidence="0.997488">
35
36
</page>
<figureCaption confidence="0.999301785714286">
Figure 5: An explanatory fragment of the word ‘con-
cern’ from the English Grammar Guide.
Figure 2: The Check My Words toolbar for EFL learners.
Figure 3: The type of prompt that appears when a
learner ‘checks’ a highlighted expression.
Explanations in the EGG are accompanied by
examples and a mini-test. Interesting multimedia
resources are also used to illustrate the explanation.
For example, in Figure 4, the use of the word
‘worth’ is exemplified in an advertisement that
sells its products with the rationalization that
‘you’re worth it’.
Figure 4: An explanatory fragment of the word ‘worth’
from the English Grammar Guide.
</figureCaption>
<bodyText confidence="0.989813692307692">
Over 500 lexico-grammatical errors are indexed,
based on a comprehensive analysis of a corpus of
the learners’ texts. Figure 5 illustrates a cartoon
conversation addressing another common error in
this interlanguage—the blending of the verb and
adjective functions of ‘concern’ (e.g., ‘I concern
about...’).
In addition to an online descriptive grammar, the
program points users to procedural/inductive re-
sources—online lookup engines—where they can
explore the contextual properties of difficult L2
patterns and retrieve collocates of any word or pat-
tern.
</bodyText>
<figureCaption confidence="0.9465265">
Figure 6: The pull-down list of resources on the Check
My Words toolbar.
Users choose one of these resources from the
Check My Words toolbar (Figure 6), and the pro-
gram generates appropriate search syntax for each
lookup resource (a Google search of the web, news
or scholarly articles, or via our own lookup engine,
‘Word Neighbors’). These resources provide
</figureCaption>
<bodyText confidence="0.9943691">
‘snapshots’ of the word or structure in context,
which is especially useful for learners who have
not read widely in the L2. Word Neighbors dis-
plays the collocational properties of words and
phrases in selected, professionally written texts,
and provides learners the opportunity to explore
the relationship between their own output and L2
target forms. Users are guided in looking up words
and expressions in Word Neighbors via the dia-
logue shown in Figure 7.
</bodyText>
<figureCaption confidence="0.999766">
Figure 7: The dialogue prompt for Word Neighbors.
</figureCaption>
<bodyText confidence="0.9999486">
The features of Word Neighbors’ can be demon-
strated by again exploring the sample error: It
worth studying hard. Figure 8 displays the word
worth as the target word. The search parameters
are set by default to display missing words and to
suggest alternatives for malformed words. Word
Neighbors also displays patterns as they occur in
various genres. The parameters Show X words
before/after allow users to select the number of
words to be shown before or after the target word.
The Span X word(s) drop-down enables the user to
investigate possible missing or redundant words in
a phrase, and the Show all word forms checkbox
enables users to display all forms of a word.
The first screen from the Word Neighbors
search result (Figure 8) shows all classes2 of the
target word and, in this case, the classes that nor-
mally precede that word. The user has empirical
evidence that worth is usually a preposition pre-
ceded by a copula verb. Clicking Show results
displays specific instances of this pattern (Figure
9). Clicking See contexts then displays sentences
and paragraphs containing the words (Figure 10).
The difference between our approach to error
correction and that of systems that rely on auto-
matic detection is well illustrated by preposition
errors. Chodorow et al (2007), for example, dis-
cuss a method for detecting preposition errors that
they report achieves a precision of 0.8 and a recall
of 0.3.
</bodyText>
<page confidence="0.72017">
2 Texts are tagged with CLAWS (Garside and Smith, 1997).
</page>
<figureCaption confidence="0.996781">
Figure 8: Word Neighbors displays search result of the
word ‘worth’ in different word class patterns
Figure 9: Word Neighbors displays the search result for
the pattern VERB + PREP.
Figure 10: Word Neighbors displays sentences contain-
ing the pattern ‘is worth’.
</figureCaption>
<page confidence="0.990597">
37
</page>
<figureCaption confidence="0.996711">
Figure 11: Word Neighbors displays the patterns of
‘demanded * more’.
</figureCaption>
<bodyText confidence="0.99997665">
While this type of ambitious scientific research
is important and interesting, it is still of limited use
by non-native writers. We have not attempted to
flag preposition errors unless they are invariable
associated with a frequently misused lexical pat-
tern (e.g., ‘They demanded for more time.’). In-
stead, the novice writer is encouraged to use a
resource such as Word Neighbors to look up the
typical patterns of prepositions. These errors lend
themselves well to such a pattern-matching ap-
proach. If we take this error as an example, the
user has only to highlight the words surrounding
the preposition, and look up the pattern ‘demanded
* more’. The program ellipts the preposition and
looks for a span of three words, resulting in the
display in Figure 11.
Concordance-type tools such as Word Neigh-
bors provide authentic information about the pat-
terns of language, but the L2 writer must often
decide which context is appropriate for a particular
case. Dialogue boxes and tutorials give learners
guidance with this discovery-based learning ap-
proach. Supporting pedagogical materials that
teachers using these tools have developed allow
learners to practice correcting sentence level er-
rors. The materials are aimed particularly at in-
creasing the learners’ awareness of collocational
restrictions and at encouraging them to look up
collocational properties. The materials have been
integrated into EFL courses at several Hong Kong
universities and secondary schools.
We have found that in institutional contexts
where novice writers may have learned to rely
completely on teacher feedback for correction,
simply putting tools in students’ hands is not
enough. In the next section, we describe compan-
ion tools that enable teachers to prompt their stu-
dents to notice particular errors and reformulate
their sentences without the teacher’s explicit cor-
rection.
</bodyText>
<sectionHeader confidence="0.998945" genericHeader="method">
5 Resource-rich Feedback
</sectionHeader>
<bodyText confidence="0.999765846153846">
Teachers of academic written English face enor-
mous problems when they, rather than the learners
themselves, bear the burden for improving the ac-
curacy and fluency of their students’ texts. Teach-
ers are typically called upon to provide individual
support to large numbers of students who are often
at various levels of acquisition and who have a
wide range of motivational drives and individual
needs. These quantitative demands, together with
the complexity of understanding and reformulating
the texts of novice writers, limit the effectiveness
of any feedback a teacher can provide. In addition,
teachers often find themselves repeatedly identify-
ing and correcting errors that they have pointed out
many times before. This is especially discouraging
when the errors reoccur in the same student’s texts.
This was the impetus for the design of Mark My
Words, a companion to the students’ version,
Check My Words. Like Check My Words, it in-
stalls as a toolbar in Microsoft Word (Figure 12).
Teachers can use this tool to insert ‘resource rich’
comments in students’ texts (e.g., Milton, 2006).
These comments include links to the resources
available from the students’ Check My Words
toolbar. Students can be held accountable for re-
formulating their own texts using the same re-
sources they themselves have available during the
writing process.
The following steps illustrate the process a
teacher might use when responding to a student’s
text. This procedure is ideally employed after the
student has completed at least one draft and fol-
lowed a revision process similar to that outlined in
the previous section. Let’s assume that a student
has submitted a text containing the error illustrated
previously (‘It worth studying.’).
Teachers have a variety of options in comment-
ing on a text, depending on how explicit they want
to be. When the teacher wants to bring an error to
</bodyText>
<page confidence="0.998618">
38
</page>
<figureCaption confidence="0.99505">
Figure 12: The Mark My Words toolbar for tutors of English.
</figureCaption>
<bodyText confidence="0.999869304347826">
the student’s attention, the teacher puts the cursor
on the word or highlights a phrase and clicks a
Mark button. The program attempts to identify the
error based on simple heuristics (e.g., identifying
the POS and any pattern that matches a mal-rule),
and dialogues such as the following one presented
in figure 13 are available.
The ‘Topic’ and ‘Hint’ text boxes contain boi-
lerplate comments that the teacher customizes as
desired. The teacher can accept the default sugges-
tions or select a resource or search engine and set
parameters to display the Standard English lexical
pattern. The English Grammar Guide link, online
dictionary, and Word Neighbors are selected in this
example. These links then appear in the student’s
text. These links reinforce the student’s familiarity
with the resources, encouraging students to use the
resources to revise their texts.
The student has only to ‘mouse over’ the
teacher’s initials to see each ‘resource rich’ com-
ment, and can click to open the resource. In the
example illustrated in Figure 14, three resources
are available: usage explanations (the ‘Click here
for more advice and practice’ link points to the
relevant page of the online English Grammar
Guide), definitions (Cambridge Dictionary), and
collocational patterns (Word Neighbors).
Teachers can comment on repeated errors of the
same type by clicking a ‘Copy Comment’ button,
although usually it is not necessary (nor advisable)
to highlight every error. Current feedback peda-
gogy suggests that, rather than highlighting all er-
rors, it is more effective to draw students’ attention
to a subset of errors. In addition to comments cov-
ering the most distracting and disruptive types of
sentence level errors, the Mark My Words program
lists many other comments covering formatting,
organization, style, content, and logic. Teachers
can easily add more comments, and customize and
associate these with any concept or pattern in a
student’s text, and these in turn with any online
resources. By having students concentrate on
structures and lexis that are particularly difficult
for each individual, we can more reasonably expect
L2 novice writers to learn to identify and revise
these problems themselves.
</bodyText>
<figureCaption confidence="0.993336333333333">
Figure 13: dialogue boxes that allow teachers to custom-
ize comments.
Figure 14: a comment from Mark My Words.
</figureCaption>
<bodyText confidence="0.999534333333333">
The Mark My Words program retains a database
of comments made on previous assignments so that
a teacher knows whether a student has had atten-
tion drawn to particular lexical and structural prob-
lems. At the bottom of each text, teachers can
generate a ‘Comments Table’ that summarizes the
comments (Figure 15). This allows teachers to
maintain a record of comments given to particular
students. These comments and error logs are per-
manently available for students and teachers to
refer to as prompts for each subsequent draft and
revision.
</bodyText>
<page confidence="0.998583">
39
</page>
<bodyText confidence="0.999865125">
This procedure does not necessarily replace
classroom instruction or individual consultation.
However, by encouraging EFL learners to use such
resources, and demonstrating their usefulness
through instruction and as part of the feedback
process, we can equip learners to proofread for
themselves, and help them assume responsibility
for becoming independent writers.
</bodyText>
<figureCaption confidence="0.556404">
Figure 15: a summary of comments from Mark My
Words.
</figureCaption>
<sectionHeader confidence="0.977823" genericHeader="evaluation">
6 Implementation and Assessment
</sectionHeader>
<bodyText confidence="0.999977324675325">
The tools and techniques described above have
been designed with the needs of intermediate and
advanced EFL learners in mind—especially Chi-
nese-speaking secondary and tertiary students.
This approach meets many of the requirements laid
out for corpus-based language learning tools (e.g.,
Ghadessy et al, 2001 and Romer, 2006). Other
work in this area (e.g., Gaskell and Cobb, 2004)
has illustrated the promise that such methods have
for enabling teachers to guide students in accessing
and understanding the discrepancy between their
language patterns and those of Standard English.
The programs have been integrated into EFL
courses at several Hong Kong universities and sec-
ondary schools and continue to undergo refine-
ments based on user feedback. A comprehensive
evaluation of students’ and teachers’ reactions to
the programs emphasizes the need for training and
pedagogical materials that support teachers and
students: a number of genre-specific writing sylla-
buses (e.g., lab-report writing) are being built
around the use of the programs.
Although our main aim is not to identify all er-
rors or prescribe correction, the ability of the
Check My Words program to identify the lexico-
grammatical errors of a specific cohort of L2 writ-
ers (Chinese speakers of English) is steadily im-
proving. We maintain an ‘Assignment
Management System’, through which students and
teachers exchange electronic documents. This sys-
tem enables us to collect user-generated knowledge
in the form of common errors in the L2 writing of
this cohort of users, as well as errors tagged by
their language teachers. Students who use the
Check My Words program currently submit ap-
proximately 1 million words per month, and teach-
ers tag about 15,000 errors in these texts monthly,
using the Mark My Words program. We are able
to mine these texts for mal-rules and for the usage
marked by their teachers, and we can use the cor-
pus as an iterative test bed for error checking.
A quantitative analysis of about a million words
of the re-drafted texts of students who have used
the program, and another million words of those
who did not use the program during composition
show significant improvements in accuracy and
fluency of those who used the program. Students
who follow this process tend to use a wider range
of language formulae and, as well as gaining con-
fidence in using the tools to check lexis and struc-
tures, they more successfully attempt grammatical
structures normally avoided in the novice L2 writ-
ing of speakers of Chinese (such as modality and
subordination). In surveys, the L2 novice writers
report that they find the programs ‘very useful’.
Teachers report that students who used the pro-
gram as a proofreading aid were able to self-
correct more reliably than students who did not use
the program.
However, although the technical infrastructure
of Hong Kong schools and universities can easily
accommodate these programs (students and teach-
ers generally have access to good computer facili-
ties), the adoption of this method of feedback by
teachers has been slow. Examination-driven teach-
ing practices emphasize teacher-centered methods,
and teachers have little incentive to encourage stu-
dents in independent learning and discovery-based
writing. Nevertheless, most teachers who try this
method quickly become proficient and embrace it,
recognizing that it can help transfer the burden for
proofreading to their students. They appreciate
being able to customize and share comments, and
avoid explicit correction, while still assisting stu-
dents and holding them accountable for conveying
meaning in an acceptable manner and in their own
words.
</bodyText>
<page confidence="0.99786">
40
</page>
<sectionHeader confidence="0.997967" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999527083333334">
The programs described in this paper demonstrate
techniques that can help L2 writers acquire accu-
racy and fluency in written English and develop
life-long writing habits in the L2. The approach
takes advantage of online resources to help stu-
dents and teachers shift from a machine- or
teacher-centered pedagogy to one that puts the L2
writer at the center of the writing process by mak-
ing the learner accountable, and ultimately more
confident and independent. The Check My Words
and Mark My Words programs described in this
paper are available from http://mywords.ust.hk/.
</bodyText>
<sectionHeader confidence="0.998944" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999874302325581">
E. M. Bender. 2009. Linguistically Na•ve!=Language
Independent: Why NLP Needs Linguistic Typology.
Proceedings of the EACL 2009 Workshop on the In-
teraction between Linguistics and Computational
Linguistics: Virtuous, Vicious or Vacuous? Athens,
Greece, 26–32.
P. Bolt. 1992. An evaluation of grammar-checking pro-
grams as self-help learning aids for learners of Eng-
lish as a foreign language. Computer Assisted
Learning, 5(1–2):49–9.
C. Chapelle. 2001. Computer Applications in Second
Language Acquisition: Foundations for Teaching,
Testing, and Research. Cambridge, UK: Cambridge
University Press.
J. F. Chen. 1997. Computer generated error feedback
and the writing process. TESL-EJ Teaching English
as a second Foreign Language, 2(3).
M. Chodorow, J. Tetreault, and N.-R. Han. 2007. Detec-
tion of grammatical errors involving prepositions.
Proceedings of the Fourth ACL-SIGSEM Workshop
on Prepositions, Prague, Czech Republic: Associa-
tion for Computational Linguistics, 25–30.
D. N. Dobrin. 1985. Style analyzers once more. Com-
puters and Composition, 3:22–32.
D. Ferris. and J. S. Hedgcock. 2005. Teaching ESL
Composition: Purpose, Process, and Practice (2nd
ed.) Mahwah: Lawrence Erlbaum Associates.
J. Foster. and J. Vogel. 2004. Parsing Ill-Formed Text
Using an Error Grammar. Artificial Intelligence Re-
view, 21(3-4):269–291.
L. T. Frase, N. H. Macdonald, P. S. Gingrich, S. A.
Keenan and J. L. Collymore, 1981. Computer aids
for text assessment and writing instruction, NSPI
Journal, 21.
D. Gaskell, and T. Cobb. 2004. Can learners use con-
cordance feedback for writing errors? System, 32(3):
301–319.
M. Ghadessy, A. Henry, and R. Roseberry, (eds.). 2001.
Small Corpus Studies and ELT: Theory and Practice,
John Benjamins.
R. Garside, and N. Smith. 1997. A hybrid grammatical
tagger: CLAWS4, In R. Garside, G. Leech and A.
McEnery. (eds.) Corpus Annotation: Linguistic In-
formation from Computer Text Corpora. Longman,
London, 102–121.
T. McGee and P. Ericsson. 2002. The Politics of the
Program: MS Word as the Invisible Grammarian,
Computers and Composition, 19:453–470.
J. Milton. 2001. Elements of a Written Interlanguage: a
computational and corpus-based study of institu-
tional influences on the acquisition of English by
Hong Kong Chinese students. HKUST, Hong Kong.
J. Milton. 2006. Resource-Rich Web-Based Feedback:
helping learners become independent writers, In Hy-
land, K. and Hyland F. (eds.) Feedback in Second
Language Writing: Contexts and Issues, Cambridge
University Press, 123–137.
M. C. Pennington. 1992. Beyond off-the-shelf computer
remedies for student writers: Alternatives to canned
feedback. System, 20(4):423–447.
D. Schneider. and K. F. McCoy. 1998. Recognizing
syntactic errors in the writing of second language
learners. Proceedings of the 36th conference on As-
sociation for Computational Linguistics volume 2.
Montreal, Quebec, Canada.
M. Trahey. and L. White. 1993. Positive evidence and
preemption in the L2 classroom. Studies in Second
Language Acquisition, 15:181–204.
J. Truscott. 1996. The case against grammar correction
in L2 writing classes. Language Learning, 46(2):
327-369.
A. Vernon. 2000. Computerized grammar checkers
2000: capabilities, limitations, and pedagogical pos-
sibilities. Computers and Composition, 17:329–349.
B. Wampler. 2002. A computer scientist&apos;s lament:
grammar has lost its technological edge. The New
York Times.
H. A. Witkin, C. Moore, D. Goodenough, and P. Cox.
1977. Field Dependent and Field Independent Cogni-
tive Styles and their Educational Implications, Re-
view of Educational Research, 47:1–64.
X. Yi, J. Gao and W. B. Dolan. 2008. A Web-based
English Proofing System for English as a Second
Language Users Proceedings of the Third Interna-
tional Joint Conference on Natural Language Proc-
essing volume 1.
</reference>
<page confidence="0.999445">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.372806">
<title confidence="0.998621">A Toolkit to Assist L2 Learners Become Independent Writers</title>
<author confidence="0.996668">S Y Milton</author>
<title confidence="0.726218">Language HKUST, Clear Water</title>
<author confidence="0.653909">Hong</author>
<email confidence="0.965567">lcjohn@ust.hk</email>
<email confidence="0.965567">vivying@ust.hk</email>
<abstract confidence="0.999655304347826">This paper describes a resource-rich toolkit that assists EFL writers take a discoverybased approach to writing accurate and fluent English. The system helps learners identify lexico-grammatical errors by matching patterns gleaned from a very large corpus of learners’ texts. Users are guided to appropriate language patterns as they write and revise through online declarative and procedural resources. Even as more robust and fully automatic feedback technologies evolve, comprehensive resource-rich support will remain necessary for second-language (L2) writers who must develop practical life-long language learning strategies. To assist language tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E M Bender</author>
</authors>
<title>Linguistically Na•ve!=Language Independent: Why NLP Needs Linguistic Typology.</title>
<date>2009</date>
<booktitle>Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?</booktitle>
<pages>26--32</pages>
<location>Athens, Greece,</location>
<contexts>
<context position="1455" citStr="Bender, 2009" startWordPosition="220" endWordPosition="221"> novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generat</context>
</contexts>
<marker>Bender, 2009</marker>
<rawString>E. M. Bender. 2009. Linguistically Na•ve!=Language Independent: Why NLP Needs Linguistic Typology. Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous? Athens, Greece, 26–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bolt</author>
</authors>
<title>An evaluation of grammar-checking programs as self-help learning aids for learners of English as a foreign language. Computer Assisted Learning,</title>
<date>1992</date>
<pages>5--1</pages>
<contexts>
<context position="2155" citStr="Bolt, 1992" startWordPosition="326" endWordPosition="327">ent of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generated prescriptive advice, even when it is reliable, actually helps learner language evolve (Bolt, 1992; Chen, 1997). While machine-generated error identification and correction may be a desirable convenience for casual writers, explicit correction by a machine, or for that matter, a human tutor, appears to be counterproductive in the development of an L2 writer’s proficiency (Truscott, 1996; Ferris and Hedgcock, 2005). The goal of the project described here is to develop a suite of tools that will help novice writers who are learning to write in academic or professional contexts improve the accuracy and fluency of their texts, while also becoming more confident in their long-term command of En</context>
</contexts>
<marker>Bolt, 1992</marker>
<rawString>P. Bolt. 1992. An evaluation of grammar-checking programs as self-help learning aids for learners of English as a foreign language. Computer Assisted Learning, 5(1–2):49–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chapelle</author>
</authors>
<title>Computer Applications in Second Language Acquisition: Foundations for Teaching, Testing, and Research.</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, UK:</location>
<contexts>
<context position="6309" citStr="Chapelle, 2001" startWordPosition="969" endWordPosition="970">n the sentence, may compound the confusion for speakers of Chinese, who often confuse adjective and noun forms and functions. equivalents are in Chinese). The first comment is unhelpful; all options in the second set of suggestions are, bizarrely, further from Standard English than the student’s original text, and the third sentence passes without comment. In addition to its general unreliability for L2 writers, grammar/style-checking software has been censured for giving overly narrow and prescriptive advice (Pennington, 1992), for compounding the already constrained nature of L2 production (Chapelle, 2001) and for otherwise abusing the tenets of good pedagogy (McGee and Ericsson, 2002). Even if the reliability of parsing technology can be significantly enhanced, much of the composition research of the last fifty years has argued against imposing corrections on the texts of novice writers. Current theories of language pedagogy promote learner independence and discourage direct correction by tutors. In light of the limitations of writing software, reliance on a deus ex machina for correction is hardly a desirable alternative to dependence on a language tutor. A more principled, and ultimately mor</context>
</contexts>
<marker>Chapelle, 2001</marker>
<rawString>C. Chapelle. 2001. Computer Applications in Second Language Acquisition: Foundations for Teaching, Testing, and Research. Cambridge, UK: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Chen</author>
</authors>
<title>Computer generated error feedback and the writing process. TESL-EJ Teaching English as a second Foreign Language,</title>
<date>1997</date>
<contexts>
<context position="2168" citStr="Chen, 1997" startWordPosition="328" endWordPosition="329">rcially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generated prescriptive advice, even when it is reliable, actually helps learner language evolve (Bolt, 1992; Chen, 1997). While machine-generated error identification and correction may be a desirable convenience for casual writers, explicit correction by a machine, or for that matter, a human tutor, appears to be counterproductive in the development of an L2 writer’s proficiency (Truscott, 1996; Ferris and Hedgcock, 2005). The goal of the project described here is to develop a suite of tools that will help novice writers who are learning to write in academic or professional contexts improve the accuracy and fluency of their texts, while also becoming more confident in their long-term command of English. We hav</context>
</contexts>
<marker>Chen, 1997</marker>
<rawString>J. F. Chen. 1997. Computer generated error feedback and the writing process. TESL-EJ Teaching English as a second Foreign Language, 2(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chodorow</author>
<author>J Tetreault</author>
<author>N-R Han</author>
</authors>
<title>Detection of grammatical errors involving prepositions.</title>
<date>2007</date>
<booktitle>Proceedings of the Fourth ACL-SIGSEM Workshop on Prepositions, Prague, Czech Republic: Association for Computational Linguistics,</booktitle>
<pages>25--30</pages>
<contexts>
<context position="15423" citStr="Chodorow et al (2007)" startWordPosition="2443" endWordPosition="2446"> of a word. The first screen from the Word Neighbors search result (Figure 8) shows all classes2 of the target word and, in this case, the classes that normally precede that word. The user has empirical evidence that worth is usually a preposition preceded by a copula verb. Clicking Show results displays specific instances of this pattern (Figure 9). Clicking See contexts then displays sentences and paragraphs containing the words (Figure 10). The difference between our approach to error correction and that of systems that rely on automatic detection is well illustrated by preposition errors. Chodorow et al (2007), for example, discuss a method for detecting preposition errors that they report achieves a precision of 0.8 and a recall of 0.3. 2 Texts are tagged with CLAWS (Garside and Smith, 1997). Figure 8: Word Neighbors displays search result of the word ‘worth’ in different word class patterns Figure 9: Word Neighbors displays the search result for the pattern VERB + PREP. Figure 10: Word Neighbors displays sentences containing the pattern ‘is worth’. 37 Figure 11: Word Neighbors displays the patterns of ‘demanded * more’. While this type of ambitious scientific research is important and interesting</context>
</contexts>
<marker>Chodorow, Tetreault, Han, 2007</marker>
<rawString>M. Chodorow, J. Tetreault, and N.-R. Han. 2007. Detection of grammatical errors involving prepositions. Proceedings of the Fourth ACL-SIGSEM Workshop on Prepositions, Prague, Czech Republic: Association for Computational Linguistics, 25–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D N Dobrin</author>
</authors>
<title>Style analyzers once more.</title>
<date>1985</date>
<journal>Computers and Composition,</journal>
<pages>3--22</pages>
<contexts>
<context position="1336" citStr="Dobrin, 1985" startWordPosition="199" endWordPosition="200">guage (L2) writers who must develop practical life-long language learning strategies. To assist language tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of gramma</context>
</contexts>
<marker>Dobrin, 1985</marker>
<rawString>D. N. Dobrin. 1985. Style analyzers once more. Computers and Composition, 3:22–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Hedgcock</author>
</authors>
<date>2005</date>
<booktitle>Teaching ESL Composition: Purpose, Process, and Practice (2nd ed.) Mahwah: Lawrence Erlbaum Associates.</booktitle>
<contexts>
<context position="2474" citStr="Hedgcock, 2005" startWordPosition="374" endWordPosition="375">term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generated prescriptive advice, even when it is reliable, actually helps learner language evolve (Bolt, 1992; Chen, 1997). While machine-generated error identification and correction may be a desirable convenience for casual writers, explicit correction by a machine, or for that matter, a human tutor, appears to be counterproductive in the development of an L2 writer’s proficiency (Truscott, 1996; Ferris and Hedgcock, 2005). The goal of the project described here is to develop a suite of tools that will help novice writers who are learning to write in academic or professional contexts improve the accuracy and fluency of their texts, while also becoming more confident in their long-term command of English. We have developed companion tools to help teachers of writing improve the efficiency and reliability of their feedback, and move L2 novice writers toward life-long independence. The following section outlines some of the limitations of currently available grammar checking software in accomplishing these goals. </context>
</contexts>
<marker>Hedgcock, 2005</marker>
<rawString>D. Ferris. and J. S. Hedgcock. 2005. Teaching ESL Composition: Purpose, Process, and Practice (2nd ed.) Mahwah: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Vogel</author>
</authors>
<title>Parsing Ill-Formed Text Using an Error Grammar.</title>
<date>2004</date>
<journal>Artificial Intelligence Review,</journal>
<pages>21--3</pages>
<contexts>
<context position="1424" citStr="Vogel, 2004" startWordPosition="214" endWordPosition="215">ssist language tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as t</context>
</contexts>
<marker>Vogel, 2004</marker>
<rawString>J. Foster. and J. Vogel. 2004. Parsing Ill-Formed Text Using an Error Grammar. Artificial Intelligence Review, 21(3-4):269–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L T Frase</author>
<author>N H Macdonald</author>
<author>P S Gingrich</author>
<author>S A Keenan</author>
<author>J L Collymore</author>
</authors>
<title>Computer aids for text assessment and writing instruction,</title>
<date>1981</date>
<journal>NSPI Journal,</journal>
<volume>21</volume>
<contexts>
<context position="1321" citStr="Frase et al, 1981" startWordPosition="195" endWordPosition="198">sary for second-language (L2) writers who must develop practical life-long language learning strategies. To assist language tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techn</context>
</contexts>
<marker>Frase, Macdonald, Gingrich, Keenan, Collymore, 1981</marker>
<rawString>L. T. Frase, N. H. Macdonald, P. S. Gingrich, S. A. Keenan and J. L. Collymore, 1981. Computer aids for text assessment and writing instruction, NSPI Journal, 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gaskell</author>
<author>T Cobb</author>
</authors>
<title>Can learners use concordance feedback for writing errors?</title>
<date>2004</date>
<journal>System,</journal>
<volume>32</volume>
<issue>3</issue>
<pages>301--319</pages>
<contexts>
<context position="23466" citStr="Gaskell and Cobb, 2004" startWordPosition="3718" endWordPosition="3721">nd as part of the feedback process, we can equip learners to proofread for themselves, and help them assume responsibility for becoming independent writers. Figure 15: a summary of comments from Mark My Words. 6 Implementation and Assessment The tools and techniques described above have been designed with the needs of intermediate and advanced EFL learners in mind—especially Chinese-speaking secondary and tertiary students. This approach meets many of the requirements laid out for corpus-based language learning tools (e.g., Ghadessy et al, 2001 and Romer, 2006). Other work in this area (e.g., Gaskell and Cobb, 2004) has illustrated the promise that such methods have for enabling teachers to guide students in accessing and understanding the discrepancy between their language patterns and those of Standard English. The programs have been integrated into EFL courses at several Hong Kong universities and secondary schools and continue to undergo refinements based on user feedback. A comprehensive evaluation of students’ and teachers’ reactions to the programs emphasizes the need for training and pedagogical materials that support teachers and students: a number of genre-specific writing syllabuses (e.g., lab</context>
</contexts>
<marker>Gaskell, Cobb, 2004</marker>
<rawString>D. Gaskell, and T. Cobb. 2004. Can learners use concordance feedback for writing errors? System, 32(3): 301–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ghadessy</author>
<author>A Henry</author>
<author>R Roseberry</author>
</authors>
<date>2001</date>
<booktitle>Small Corpus Studies and ELT: Theory and Practice,</booktitle>
<location>John Benjamins.</location>
<contexts>
<context position="23393" citStr="Ghadessy et al, 2001" startWordPosition="3705" endWordPosition="3708">ch resources, and demonstrating their usefulness through instruction and as part of the feedback process, we can equip learners to proofread for themselves, and help them assume responsibility for becoming independent writers. Figure 15: a summary of comments from Mark My Words. 6 Implementation and Assessment The tools and techniques described above have been designed with the needs of intermediate and advanced EFL learners in mind—especially Chinese-speaking secondary and tertiary students. This approach meets many of the requirements laid out for corpus-based language learning tools (e.g., Ghadessy et al, 2001 and Romer, 2006). Other work in this area (e.g., Gaskell and Cobb, 2004) has illustrated the promise that such methods have for enabling teachers to guide students in accessing and understanding the discrepancy between their language patterns and those of Standard English. The programs have been integrated into EFL courses at several Hong Kong universities and secondary schools and continue to undergo refinements based on user feedback. A comprehensive evaluation of students’ and teachers’ reactions to the programs emphasizes the need for training and pedagogical materials that support teache</context>
</contexts>
<marker>Ghadessy, Henry, Roseberry, 2001</marker>
<rawString>M. Ghadessy, A. Henry, and R. Roseberry, (eds.). 2001. Small Corpus Studies and ELT: Theory and Practice, John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
<author>N Smith</author>
</authors>
<title>A hybrid grammatical tagger: CLAWS4, In</title>
<date>1997</date>
<booktitle>Corpus Annotation: Linguistic Information from Computer Text Corpora.</booktitle>
<pages>102--121</pages>
<editor>R. Garside, G. Leech and A. McEnery. (eds.)</editor>
<publisher>Longman,</publisher>
<location>London,</location>
<contexts>
<context position="15609" citStr="Garside and Smith, 1997" startWordPosition="2476" endWordPosition="2479"> user has empirical evidence that worth is usually a preposition preceded by a copula verb. Clicking Show results displays specific instances of this pattern (Figure 9). Clicking See contexts then displays sentences and paragraphs containing the words (Figure 10). The difference between our approach to error correction and that of systems that rely on automatic detection is well illustrated by preposition errors. Chodorow et al (2007), for example, discuss a method for detecting preposition errors that they report achieves a precision of 0.8 and a recall of 0.3. 2 Texts are tagged with CLAWS (Garside and Smith, 1997). Figure 8: Word Neighbors displays search result of the word ‘worth’ in different word class patterns Figure 9: Word Neighbors displays the search result for the pattern VERB + PREP. Figure 10: Word Neighbors displays sentences containing the pattern ‘is worth’. 37 Figure 11: Word Neighbors displays the patterns of ‘demanded * more’. While this type of ambitious scientific research is important and interesting, it is still of limited use by non-native writers. We have not attempted to flag preposition errors unless they are invariable associated with a frequently misused lexical pattern (e.g.</context>
</contexts>
<marker>Garside, Smith, 1997</marker>
<rawString>R. Garside, and N. Smith. 1997. A hybrid grammatical tagger: CLAWS4, In R. Garside, G. Leech and A. McEnery. (eds.) Corpus Annotation: Linguistic Information from Computer Text Corpora. Longman, London, 102–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McGee</author>
<author>P Ericsson</author>
</authors>
<date>2002</date>
<booktitle>The Politics of the Program: MS Word as the Invisible Grammarian, Computers and Composition,</booktitle>
<pages>19--453</pages>
<contexts>
<context position="6390" citStr="McGee and Ericsson, 2002" startWordPosition="980" endWordPosition="983"> often confuse adjective and noun forms and functions. equivalents are in Chinese). The first comment is unhelpful; all options in the second set of suggestions are, bizarrely, further from Standard English than the student’s original text, and the third sentence passes without comment. In addition to its general unreliability for L2 writers, grammar/style-checking software has been censured for giving overly narrow and prescriptive advice (Pennington, 1992), for compounding the already constrained nature of L2 production (Chapelle, 2001) and for otherwise abusing the tenets of good pedagogy (McGee and Ericsson, 2002). Even if the reliability of parsing technology can be significantly enhanced, much of the composition research of the last fifty years has argued against imposing corrections on the texts of novice writers. Current theories of language pedagogy promote learner independence and discourage direct correction by tutors. In light of the limitations of writing software, reliance on a deus ex machina for correction is hardly a desirable alternative to dependence on a language tutor. A more principled, and ultimately more valid, role for language tools in supporting L2 novice writers is to enable the</context>
</contexts>
<marker>McGee, Ericsson, 2002</marker>
<rawString>T. McGee and P. Ericsson. 2002. The Politics of the Program: MS Word as the Invisible Grammarian, Computers and Composition, 19:453–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Milton</author>
</authors>
<title>Elements of a Written Interlanguage: a computational and corpus-based study of institutional influences on the acquisition of English by Hong Kong Chinese students. HKUST, Hong Kong.</title>
<date>2001</date>
<contexts>
<context position="9464" citStr="Milton, 2001" startWordPosition="1477" endWordPosition="1479"> a combination, depending on the nature of the language problem and each user’s learning style (e.g., their extent of ‘field dependence’, see Witkin et al., 1977). The program ‘Check My Words’ (Figure 2) gives L2 novice writers access to interactive explanations of common structural and lexical errors from an Internet grammar as they write. These explanations are based on an analysis of a large L2 corpus consisting of millions of words of the writing of Chinese speakers, from which a typology of misused, and blatantly underused or overused lexical and structural patterns, was extracted (e.g., Milton, 2001). Hundreds of problematic words and patterns in a learner’s text are explained. This is the kind of didactic, deductive advice that a good textbook might provide, except that there are few textbooks targeted directly at the EFL learning difficulties of speakers of particular L1s, and this internet grammar is embellished with interactive multimedia: it is fun to use. Secondly, the program enables learners to discover how the language they are struggling to use is formulated in relevant, professionally written texts. They have a choice of search engines that they can use to look up words in cont</context>
</contexts>
<marker>Milton, 2001</marker>
<rawString>J. Milton. 2001. Elements of a Written Interlanguage: a computational and corpus-based study of institutional influences on the acquisition of English by Hong Kong Chinese students. HKUST, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Milton</author>
</authors>
<title>Resource-Rich Web-Based Feedback: helping learners become independent writers,</title>
<date>2006</date>
<booktitle>Feedback in Second Language Writing: Contexts and Issues,</booktitle>
<pages>123--137</pages>
<editor>In Hyland, K. and Hyland F. (eds.)</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="18924" citStr="Milton, 2006" startWordPosition="3000" endWordPosition="3001"> reformulating the texts of novice writers, limit the effectiveness of any feedback a teacher can provide. In addition, teachers often find themselves repeatedly identifying and correcting errors that they have pointed out many times before. This is especially discouraging when the errors reoccur in the same student’s texts. This was the impetus for the design of Mark My Words, a companion to the students’ version, Check My Words. Like Check My Words, it installs as a toolbar in Microsoft Word (Figure 12). Teachers can use this tool to insert ‘resource rich’ comments in students’ texts (e.g., Milton, 2006). These comments include links to the resources available from the students’ Check My Words toolbar. Students can be held accountable for reformulating their own texts using the same resources they themselves have available during the writing process. The following steps illustrate the process a teacher might use when responding to a student’s text. This procedure is ideally employed after the student has completed at least one draft and followed a revision process similar to that outlined in the previous section. Let’s assume that a student has submitted a text containing the error illustrate</context>
</contexts>
<marker>Milton, 2006</marker>
<rawString>J. Milton. 2006. Resource-Rich Web-Based Feedback: helping learners become independent writers, In Hyland, K. and Hyland F. (eds.) Feedback in Second Language Writing: Contexts and Issues, Cambridge University Press, 123–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Pennington</author>
</authors>
<title>Beyond off-the-shelf computer remedies for student writers: Alternatives to canned feedback.</title>
<date>1992</date>
<journal>System,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="6227" citStr="Pennington, 1992" startWordPosition="958" endWordPosition="959"> of most dictionaries to label ‘worth’ as an adjective, regardless of its function in the sentence, may compound the confusion for speakers of Chinese, who often confuse adjective and noun forms and functions. equivalents are in Chinese). The first comment is unhelpful; all options in the second set of suggestions are, bizarrely, further from Standard English than the student’s original text, and the third sentence passes without comment. In addition to its general unreliability for L2 writers, grammar/style-checking software has been censured for giving overly narrow and prescriptive advice (Pennington, 1992), for compounding the already constrained nature of L2 production (Chapelle, 2001) and for otherwise abusing the tenets of good pedagogy (McGee and Ericsson, 2002). Even if the reliability of parsing technology can be significantly enhanced, much of the composition research of the last fifty years has argued against imposing corrections on the texts of novice writers. Current theories of language pedagogy promote learner independence and discourage direct correction by tutors. In light of the limitations of writing software, reliance on a deus ex machina for correction is hardly a desirable al</context>
</contexts>
<marker>Pennington, 1992</marker>
<rawString>M. C. Pennington. 1992. Beyond off-the-shelf computer remedies for student writers: Alternatives to canned feedback. System, 20(4):423–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K F McCoy</author>
</authors>
<title>Recognizing syntactic errors in the writing of second language learners.</title>
<date>1998</date>
<booktitle>Proceedings of the 36th conference on Association for Computational Linguistics</booktitle>
<volume>2</volume>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="3910" citStr="McCoy, 1998" startWordPosition="594" endWordPosition="595">alysis. However, the unconstrained text of L2 learners is 33 Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 33–41, Los Angeles, California, June 2010. @2010 Association for Computational Linguistics difficult to parse. Even more demanding is the ability of software (or, very often, human tutors) to suggest a ‘correct’ version that reflects the writer’s intention. This requires semantic disambiguation well beyond our current ontology or technology. The difficulties in parsing natural language are compounded in the case of interlanguage (Schneider and McCoy, 1998). Parsers generally are based on theoretical models of how grammatical sentences of the target language should be constructed. This approach is especially ineffective for cases where the speakers’ first language is linguistically remote from the target language. For example, the current version of the parser-based grammar checker in Microsoft Word sacrifices a low rate of recall for a relatively high rate of precision in the analysis of Chinese speakers’ English texts. That is, it displays few flagged errors compared to the total number of errors actually occurring in a text, a necessary trade</context>
</contexts>
<marker>McCoy, 1998</marker>
<rawString>D. Schneider. and K. F. McCoy. 1998. Recognizing syntactic errors in the writing of second language learners. Proceedings of the 36th conference on Association for Computational Linguistics volume 2. Montreal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L White</author>
</authors>
<title>Positive evidence and preemption</title>
<date>1993</date>
<booktitle>in the L2 classroom. Studies in Second Language Acquisition,</booktitle>
<pages>15--181</pages>
<contexts>
<context position="10534" citStr="White, 1993" startWordPosition="1647" endWordPosition="1648"> use is formulated in relevant, professionally written texts. They have a choice of search engines that they can use to look up words in context. Together, these search engines address many of the problems learners encounter in choosing words, forms and constructions. This inductive, procedural access to writing models, combined with the feedback tutors can provide via companion tools, greatly increases the amount of positive and negative evidence about the L2 available to the novice writer—support that researchers of applied linguistics believe promotes language acquisition (e.g., Trahey and White, 1993, Doughty and Varela, 1998). In addition to helping learners become more confident, responsible, and independent in selecting language that is both accurate and appropriate to their purposes, this approach helps relieve language tutors of the need to act as proofreading slaves. When learners are given the tools to attend to form, taught how to use the tools, and held accountable for their own progress, teachers can share more of the burden of responsibility for learning with their students. This approach reduces the need to impose corrections, either by human or machine intervention. The next </context>
</contexts>
<marker>White, 1993</marker>
<rawString>M. Trahey. and L. White. 1993. Positive evidence and preemption in the L2 classroom. Studies in Second Language Acquisition, 15:181–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Truscott</author>
</authors>
<title>The case against grammar correction in L2 writing classes.</title>
<date>1996</date>
<journal>Language Learning,</journal>
<volume>46</volume>
<issue>2</issue>
<pages>327--369</pages>
<contexts>
<context position="2446" citStr="Truscott, 1996" startWordPosition="370" endWordPosition="371">uently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generated prescriptive advice, even when it is reliable, actually helps learner language evolve (Bolt, 1992; Chen, 1997). While machine-generated error identification and correction may be a desirable convenience for casual writers, explicit correction by a machine, or for that matter, a human tutor, appears to be counterproductive in the development of an L2 writer’s proficiency (Truscott, 1996; Ferris and Hedgcock, 2005). The goal of the project described here is to develop a suite of tools that will help novice writers who are learning to write in academic or professional contexts improve the accuracy and fluency of their texts, while also becoming more confident in their long-term command of English. We have developed companion tools to help teachers of writing improve the efficiency and reliability of their feedback, and move L2 novice writers toward life-long independence. The following section outlines some of the limitations of currently available grammar checking software in</context>
</contexts>
<marker>Truscott, 1996</marker>
<rawString>J. Truscott. 1996. The case against grammar correction in L2 writing classes. Language Learning, 46(2): 327-369.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vernon</author>
</authors>
<title>Computerized grammar checkers 2000: capabilities, limitations, and pedagogical possibilities.</title>
<date>2000</date>
<journal>Computers and Composition,</journal>
<pages>17--329</pages>
<contexts>
<context position="1400" citStr="Vernon, 2000" startWordPosition="210" endWordPosition="211">learning strategies. To assist language tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, the</context>
</contexts>
<marker>Vernon, 2000</marker>
<rawString>A. Vernon. 2000. Computerized grammar checkers 2000: capabilities, limitations, and pedagogical possibilities. Computers and Composition, 17:329–349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wampler</author>
</authors>
<title>A computer scientist&apos;s lament: grammar has lost its technological edge.</title>
<date>2002</date>
<publisher>The</publisher>
<location>New York Times.</location>
<contexts>
<context position="1598" citStr="Wampler, 2002" startWordPosition="237" endWordPosition="238">e operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automatically generated prescriptive advice, even when it is reliable, actually helps learner language evolve (Bolt, 1992; Chen, 1997). While machine-generated erro</context>
</contexts>
<marker>Wampler, 2002</marker>
<rawString>B. Wampler. 2002. A computer scientist&apos;s lament: grammar has lost its technological edge. The New York Times.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A Witkin</author>
<author>C Moore</author>
<author>D Goodenough</author>
<author>P Cox</author>
</authors>
<date>1977</date>
<booktitle>Field Dependent and Field Independent Cognitive Styles and their Educational Implications, Review of Educational Research,</booktitle>
<pages>47--1</pages>
<contexts>
<context position="9013" citStr="Witkin et al., 1977" startWordPosition="1401" endWordPosition="1404"> own writing, thus reducing the burden on both software and human tutors to identify and correct errors. The role of the software, and of the human tutor, is to assist the writer express meaning in an acceptable manner, rather than explicitly to interpret the writer’s text. Our approach allows L2 writers to improve in two fundamentally different ways: through didactic explanations and via an inductive/procedural approach. They can choose either method or a combination, depending on the nature of the language problem and each user’s learning style (e.g., their extent of ‘field dependence’, see Witkin et al., 1977). The program ‘Check My Words’ (Figure 2) gives L2 novice writers access to interactive explanations of common structural and lexical errors from an Internet grammar as they write. These explanations are based on an analysis of a large L2 corpus consisting of millions of words of the writing of Chinese speakers, from which a typology of misused, and blatantly underused or overused lexical and structural patterns, was extracted (e.g., Milton, 2001). Hundreds of problematic words and patterns in a learner’s text are explained. This is the kind of didactic, deductive advice that a good textbook m</context>
</contexts>
<marker>Witkin, Moore, Goodenough, Cox, 1977</marker>
<rawString>H. A. Witkin, C. Moore, D. Goodenough, and P. Cox. 1977. Field Dependent and Field Independent Cognitive Styles and their Educational Implications, Review of Educational Research, 47:1–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yi</author>
<author>J Gao</author>
<author>W B Dolan</author>
</authors>
<title>A Web-based English Proofing System for English as a Second Language Users</title>
<date>2008</date>
<booktitle>Proceedings of the Third International Joint Conference on Natural Language Processing</booktitle>
<volume>1</volume>
<contexts>
<context position="1440" citStr="Yi et al, 2008" startWordPosition="216" endWordPosition="219">e tutors support novice L2 writers, we have also produced tools that help tutors reinforce their students’ independent writing and proofreading strategies. The operation and rationale of this approach have been implemented and evaluated in several Hong Kong universities and secondary schools. 1 Introduction Proofing technologies for L2 writers have been of interest to the NLP community since the 1970s, and have been subject to critical evaluation since the early 80s (e.g., Frase et al, 1981, Dobrin, 1985). In spite of continued interest in this area (e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et al, 2008; Bender, 2009), computational linguists themselves remain disappointed with the lack of ongoing development of commercially available systems (Wampler, 2002). A more serious problem, from the view of applied linguists, is that enthusiasm for the technology has often resulted in a purely operational approach. The focus on algorithmic solutions to the correction of ill-formed input has frequently overlooked the long-term pedagogical needs of L2 novice writers. The parsing techniques of grammar checkers may reliably flag a subset of L2 errors; however, there is some question as to whether automa</context>
</contexts>
<marker>Yi, Gao, Dolan, 2008</marker>
<rawString>X. Yi, J. Gao and W. B. Dolan. 2008. A Web-based English Proofing System for English as a Second Language Users Proceedings of the Third International Joint Conference on Natural Language Processing volume 1.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>