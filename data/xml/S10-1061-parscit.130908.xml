<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002974">
<title confidence="0.834818">
MARS: A Specialized RTE System for Parser Evaluation
</title>
<author confidence="0.902389">
Rui Wang† Yi Zhang†‡
</author>
<affiliation confidence="0.867316">
† Department of Computational Linguistics, Saarland University
</affiliation>
<address confidence="0.681047">
‡ LT-Lab, German Research Center for Artificial Intelligence
Im Stadtwald, 66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.998249">
{rwang,yzhang}@coli.uni-sb.de
</email>
<sectionHeader confidence="0.997378" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999338357142857">
This paper describes our participation
in the the SemEval-2010 Task #12,
Parser Evaluation using Textual Entail-
ment. Our system incorporated two depen-
dency parsers, one semantic role labeler,
and a deep parser based on hand-crafted
grammars. The shortest path algorithm
is applied on the graph representation of
the parser outputs. Then, different types
of features are extracted and the entail-
ment recognition is casted into a machine-
learning-based classification task. The
best setting of the system achieves 66.78%
of accuracy, which ranks the 3rd place.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918028571429">
The SemEval-2010 Task #12, Parser Evaluation
using Textual Entailment (PETE) (Yuret et al.,
2010), is an interesting task connecting two areas
of research, parsing and recognizing textual entail-
ment (RTE) (Dagan et al., 2005). The former is
usually concerned with syntactic analysis in spe-
cific linguistic frameworks, while the latter is be-
lieved to involve more semantic aspects of the hu-
man languages. However, no clear-cut boundary
can be drawn between syntax and semantics for
both tasks. In recent years, the parsing commu-
nity has been reaching beyond what was usually
accepted as syntactic structures. Many deep lin-
guistic frameworks allow the construction of se-
mantic representations in parallel to the syntactic
structure. Meanwhile, data-driven shallow seman-
tic parsers (or semantic role labelers) are another
popular type of extension to enrich the information
in the parser outputs.
Although entailment is described as a semantic
relation, RTE, in practice, covers linguistic phe-
nomena at various levels, from surface text to the
meaning, even to the context and discourse. One
proposal of solving the problem is to deal with dif-
ferent cases of entailment using different special-
ized RTE modules (Wang and Neumann, 2009).
Then, the PETE data can be naturally classified
into the syntactic and shallow semantic categories.
By participating in this shared task, we aim to
investigate whether different parsing outputs leads
to different RTE accuracy, and on the contrary,
whether the “application”-based evaluation pro-
vides insights to the parser comparison. Further,
we investigate if strict grammaticality checking
with a linguistic grammar is helpful in this task.
</bodyText>
<sectionHeader confidence="0.980138" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.994513666666667">
The workflow of the system is shown in Figure
1 and the details of the three components will be
elaborated on in the following sections.
</bodyText>
<subsectionHeader confidence="0.989536">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.998464333333333">
In this paper, we generally refer all the linguistic
analyses on the text as preprocessing. The output
of this procedure is a graph representation, which
approximates the meaning of the input text. In par-
ticular, after tokenization and POS tagging, we did
dependency parsing and semantic role labeling. In
addition, HPSG parsing is a filter for ungrammat-
ical hypotheses.
Tokenization and POS Tagging We use the
Penn Treebank style tokenization throughout the
various processing stages. TnT, an HMM-based
POS tagger trained with Wall Street Journal sec-
tions of the PTB, was used to automatically pre-
dict the part-of-speech of each token in the texts
and hypotheses.
Dependency Parsing For obtaining the syntac-
tic dependencies, we use two dependency parsers,
MSTParser (McDonald et al., 2005) and Malt-
Parser (Nivre et al., 2007). MSTParser is a graph-
based dependency parser where the best parse
tree is acquired by searching for a spanning tree
</bodyText>
<page confidence="0.962499">
272
</page>
<note confidence="0.5552915">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 272–275,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.998922791666667">
T
H
Preprocessing
HPSG
Parsing
Dependency
Parsing
Semantic
Role
Labeling
Dependency Path
Extraction
Dependency
Triple
Extraction
Path
Extraction
Feature-based Classification
Feature
Extraction
SVM-based
Classification
Yes/No
No
</figure>
<figureCaption confidence="0.999986">
Figure 1: Workflow of the System
</figureCaption>
<bodyText confidence="0.999928222222222">
which maximize the score on an either partially or
fully connected dependency graph. MaltParser is
a transition-based incremental dependency parser,
which is language-independent and data-driven. It
contains a deterministic algorithm, which can be
viewed as a variant of the basic shift-reduce al-
gorithm. Both parsers can achieve state-of-the-art
performance and Figure 2 shows the resulting syn-
tactic dependency trees of the following T-H pair,
</bodyText>
<construct confidence="0.6041625">
ID: 2036; Entailment: YES
T: Devotees of the market question the value of
the work national service would perform.
H: Value is questioned.
</construct>
<bodyText confidence="0.999569535714286">
Semantic Role Labeling The statistical depen-
dency parsers provide shallow syntactic analyses
of the entailment pairs through the limited vocab-
ulary of the dependency relations. In our case, the
CoNLL shared task dataset from 2008 were used
to train the statistical dependency parsing mod-
els. While such dependencies capture interesting
syntactic relations, when compared to the parsing
systems with deeper representations, the contained
information is not as detailed. To compensate for
this, we used a shallow semantic parser to predict
the semantic role relations in the T and H of en-
tailment pairs. The shallow semantic parser was
also trained with CoNLL 2008 shared task dataset,
with semantic roles extracted from the Propbank
and Nombank annotations (Zhang et al., 2008).
Figure 3 shows the resulting semantic dependency
graphs of the T-H pair.
HPSG Parsing We employ the English Re-
source Grammar (Flickinger, 2000), a hand-
written linguistic grammar in the framework of
HPSG, and the PET HPSG parser (Callmeier,
2001) to check the grammaticality of each hy-
pothesis sentence. As the hypotheses in this
PETE shared task were automatically generated,
some ungrammatical hypotheses occur in non-
entailment pairs. the grammaticality checking al-
lows us to quickly identify these instances.
</bodyText>
<subsectionHeader confidence="0.994904">
2.2 Dependency Path Extraction
</subsectionHeader>
<bodyText confidence="0.9997852">
According to the task definition, we need to ver-
ify whether those dependency relations in H also
appear in T. We firstly find out all the impor-
tant dependency triples in H, like &lt;word, depen-
dency relation, word&gt;, excluding those having
stop words. The extracted syntactic dependency
triples of the example T-H pair would be none,
since the only content words “value” and “ques-
tioned” have no direct syntactic dependency in-
between (Figure 2). The extracted semantic de-
pendency triples would be &lt;“questioned”, “A1”,
“value”&gt; (Figure 3).
After that, we use the word pairs contained in
the extracted dependency triples as anchors to find
out the corresponding dependency relations in T.
Notice that it is not necessarily that we can al-
ways find a direct dependency relation in T be-
tween the same word pair, so we need to traverse
the dependency tree or graph to find the depen-
dency paths. In general, we treat all the depen-
dency trees and graphs as undirected graphs with
loops, but keep records for the directions of the
edges we traverse. For the following three repre-
sentations, we apply slightly different algorithms
to find the dependency path between two words,
Syntactic Dependency Tree We simply traverse
the tree and find the corresponding depen-
dency path connecting the two words;
Semantic Dependency Graph We apply Dijk-
stra’s algorithm (Dijkstra, 1959) to find the
shortest path between the two words;
Joint Dependency Graph We assign different
weights to syntactic and semantic dependen-
cies and apply Dijkstra’s algorithm to find the
shortest path (with the lowest cost)1.
</bodyText>
<subsectionHeader confidence="0.92185">
2.3 Feature-based Classification
</subsectionHeader>
<bodyText confidence="0.994138">
Based on the meaning representation we have dis-
cussed above (Section 2.1 and Section 2.2), we ex-
</bodyText>
<footnote confidence="0.978696333333333">
1In practice, we simply give semantic dependencies 0.5
cost and syntactic dependencies 1.0 cost, to show the prefer-
ences on the former when both exist.
</footnote>
<page confidence="0.997431">
273
</page>
<figure confidence="0.5020055">
T:
H:
</figure>
<figureCaption confidence="0.970897">
Figure 2: Syntactic dependency of the example T-H pair by MaltParser.
</figureCaption>
<figure confidence="0.875566">
T:
H:
</figure>
<figureCaption confidence="0.999743">
Figure 3: Semantic dependency of the example T-H pair by MaltParser and our SRL system.
</figureCaption>
<bodyText confidence="0.99995836">
tract features for the machine-learning-based clas-
sifier. First of all, we should check whether there
are dependency triples extracted from H, other-
wise for our system, there is no meaning repre-
sentation for that sentence. Then we also need to
check whether the same words can be found in T
as well. Only if the corresponding dependency
paths are successfully located in T, we could ex-
tract the following features.
The direction of each dependency relation or
path could be interesting. The direction of the
H-path is clear, so we only need to check the
direction of the T-path. In practice, we simply
use a boolean value to represent whether T-path
contains dependency relations with different di-
rections. For instance, in Figure 3, if we extract
the path from “market” to “value”, the directions
of the dependency relations contained in the path
would be ← and →, one of which would be incon-
sistent with the dependency relation in H.
Notice that all the dependency paths from H
have length 12, but the lengths of the dependency
paths from T are varied. If the latter length is also
1, we can simply compare the two dependency re-
lations; otherwise, we compare each of the depen-
</bodyText>
<footnote confidence="0.762546">
2The length of one dependency path is defined as the num-
ber of dependency relations contained in the path.
</footnote>
<bodyText confidence="0.9996398">
dency relation contained the T-path with H-path
one by one3. By comparison, we mainly focus on
two values, the category of the dependency rela-
tion (e.g. syntactic dependency vs. semantic de-
pendency) and the content of the dependency rela-
tion (e.g. A1 vs. AM-LOC).
We also incorporate the string value of the de-
pendency relation pair and make it boolean ac-
cording to whether it occurs or not. Table 1 shows
the feature types we extract from each T-H pair.
</bodyText>
<sectionHeader confidence="0.999044" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999599142857143">
As we mentioned in the preprocessing section
(Section 2.1), we utilize the open source depen-
dency parsers, MSTParser4 and MaltParser5, our
own semantic role labeler (Zhang et al., 2008), and
the PET HPSG parser6. For the shortest path algo-
rithm, we use the jGraphT package7; and for the
machine learning toolkit, we use the UniverSVM
</bodyText>
<footnote confidence="0.999295">
3Enlightened by Wang and Neumann (2007), we ex-
clude some dependency relations like “CONJ”, “COORD”,
“APPO”, etc., heuristically, since in most of the cases, they
will not change the relationship between the two words at
both ends of the path.
4http://sourceforge.net/projects/
mstparser/
5http://maltparser.org/
6http://heartofgold.dfki.de/PET.html
7http://jgrapht.sourceforge.net/
</footnote>
<page confidence="0.989078">
274
</page>
<table confidence="0.99504025">
H Null? T Null? Dir Multi? Dep Same? Rel Sim? Rel Same? Rel Pair
Joint + + + + + + + +
No Sem + + + + +
No Syn + + + + + + +
</table>
<tableCaption confidence="0.76143325">
Table 1: Feature types of different settings of the
system. H Null? means whether H has dependencies;
T Null? means whether T has the corresponding paths (us-
ing the same word pairs found in H); Dir is whether the di-
</tableCaption>
<bodyText confidence="0.500321066666667">
rection of the path T the same as H; Multi? adds a prefix,
m , to the Rel Pair features, if the T-path is longer than one
dependency relation; Dep Same? checks whether the two de-
pendency types are the same, i.e. syntactic and semantic de-
pendencies; Rel Sim? only occurs when two semantic depen-
dencies are compared, meaning whether they have the same
prefixes, e.g. C-, AM-, etc.; Rel Same? checks whether the
two dependency relations are the same; and Rel Pair simple
concatenates the two relation labels together. Notice that, the
first seven feature types all contain boolean values, and for the
last one, we make it boolean as well, by observing whether
that pair of dependency labels appear or not.
package8. We test different dependency graphs
and feature sets as mentioned before (Table 1), and
the results are shown in Table 2.
</bodyText>
<table confidence="0.9970306">
MSTParser+SRL MaltParser+SRL
Joint No Sem No Syn Joint No Sem No Syn
+GC 0.5249 0.5116 0.5050 0.6678 0.5282 0.6346
(-1.3%) (-2.0%) (-14.0%) (-3.3%)
-GC 0.5216 0.5050 0.4950 0.6545 0.5282 0.6179
</table>
<tableCaption confidence="0.918925">
Table 2: Experiment results of our system with
different settings.
</tableCaption>
<bodyText confidence="0.998944571428572">
First of all, in almost all the cases, the grammat-
icality checking based on HPSG parsing is help-
ful, if we compare each pair of results at the two
rows, +GC and -GC. In all cases, the joint graph
representation achieves better results. This in-
dicates that features extracted from both syntac-
tic dependency and shallow semantic dependency
are useful for the entailment recognition. For the
MaltParser case, the semantic features show great
importance. Notice that the performance of the
whole system does not necessarily reflect the per-
formance of the parser itself, since it also depends
on our entailment modules. In all, the best setting
of our system ranks the 3rd place in the evaluation.
</bodyText>
<sectionHeader confidence="0.999666" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99866475">
In this paper, we present our system used in the
PETE task, which consists of preprocessing, de-
pendency path extraction, and feature-based clas-
sification. We use MSTParser and MaltParser as
</bodyText>
<footnote confidence="0.814395">
8http://www.kyb.mpg.de/bs/people/
fabee/universvm.html
</footnote>
<bodyText confidence="0.9998243">
dependency parsers, our SRL system as a shallow
semantic parser, and a deep parser based on hand-
crafted grammars for grammaticality checking.
The entailment recognition is done by an SVM-
based classifier using features extracted from the
graph representation of the parser outputs. Based
on the results, we tentatively conclude that both
the syntactic and the shallow semantic features are
useful. A detailed error analysis would be our on-
going work in the near future.
</bodyText>
<sectionHeader confidence="0.96831" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999895666666667">
The authors thank the PIRE PhD scholarship and
the German Excellence Cluster of MMCI for the
support of the work.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999799837837838">
Ulrich Callmeier. 2001. Efficient parsing with large-scale
unification grammars. Master’s thesis, Universit¨at des
Saarlandes, Saarbr¨ucken, Germany.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005.
The pascal recognising textual entailment challenge. In
Qui˜nonero-Candela et al., editor, MLCW 2005, volume
LNAI Volume 3944, pages 177–190. Springer-Verlag.
E. W. Dijkstra. 1959. A note on two problems in connexion
with graphs. Numerische Mathematik, 1:269–271.
Dan Flickinger. 2000. On building a more efficient gram-
mar by exploiting types. Natural Language Engineering,
6(1):15–28.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan
Hajic. 2005. Non-Projective Dependency Parsing us-
ing Spanning Tree Algorithms. In Proceedings of HLT-
EMNLP 2005, pages 523–530, Vancouver, Canada.
Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev,
G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and
Erwin Marsi. 2007. Maltparser: A language-independent
system for data-driven dependency parsing. Natural Lan-
guage Engineering, 13(1):1–41.
Rui Wang and G¨unter Neumann. 2007. Recognizing textual
entailment using a subsequence kernel method. In Pro-
ceedings of AAAI-07, Vancouver, Canada, July.
Rui Wang and G¨unter Neumann. 2009. An accuracy-
oriented divide-and-conquer strategy for recognizing tex-
tual entailment. In Proceedings of TAC 2008, Gaithers-
burg, Maryland, USA.
Deniz Yuret, Aydın Han, and Zehra Turgut. 2010. Semeval-
2010 task 12: Parser evaluation using textual entailments.
In Proceedings of the SemEval-2010 Evaluation Exercises
on Semantic Evaluation.
Yi Zhang, Rui Wang, and Hans Uszkoreit. 2008. Hybrid
learning of dependency structures from heterogeneous lin-
guistic resources. In Proceedings of the Twelfth Con-
ference on Computational Natural Language Learning
(CoNLL 2008), pages 198–202, Manchester, UK.
</reference>
<page confidence="0.998435">
275
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.335174">
<title confidence="0.959504">MARS: A Specialized RTE System for Parser Evaluation</title>
<affiliation confidence="0.6790735">of Computational Linguistics, Saarland University German Research Center for Artificial Intelligence</affiliation>
<address confidence="0.587315">Im Stadtwald, 66123 Saarbr¨ucken, Germany</address>
<abstract confidence="0.964218933333333">This paper describes our participation in the the SemEval-2010 Task #12, Parser Evaluation using Textual Entail- Our system incorporated two dependency parsers, one semantic role labeler, and a deep parser based on hand-crafted grammars. The shortest path algorithm is applied on the graph representation of the parser outputs. Then, different types of features are extracted and the entailment recognition is casted into a machinelearning-based classification task. The best setting of the system achieves 66.78% of accuracy, which ranks the 3rd place.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>Efficient parsing with large-scale unification grammars.</title>
<date>2001</date>
<booktitle>Master’s thesis, Universit¨at des Saarlandes,</booktitle>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="5699" citStr="Callmeier, 2001" startWordPosition="860" endWordPosition="861">epresentations, the contained information is not as detailed. To compensate for this, we used a shallow semantic parser to predict the semantic role relations in the T and H of entailment pairs. The shallow semantic parser was also trained with CoNLL 2008 shared task dataset, with semantic roles extracted from the Propbank and Nombank annotations (Zhang et al., 2008). Figure 3 shows the resulting semantic dependency graphs of the T-H pair. HPSG Parsing We employ the English Resource Grammar (Flickinger, 2000), a handwritten linguistic grammar in the framework of HPSG, and the PET HPSG parser (Callmeier, 2001) to check the grammaticality of each hypothesis sentence. As the hypotheses in this PETE shared task were automatically generated, some ungrammatical hypotheses occur in nonentailment pairs. the grammaticality checking allows us to quickly identify these instances. 2.2 Dependency Path Extraction According to the task definition, we need to verify whether those dependency relations in H also appear in T. We firstly find out all the important dependency triples in H, like &lt;word, dependency relation, word&gt;, excluding those having stop words. The extracted syntactic dependency triples of the examp</context>
</contexts>
<marker>Callmeier, 2001</marker>
<rawString>Ulrich Callmeier. 2001. Efficient parsing with large-scale unification grammars. Master’s thesis, Universit¨at des Saarlandes, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<volume>3944</volume>
<pages>177--190</pages>
<editor>In Qui˜nonero-Candela et al., editor, MLCW</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="1077" citStr="Dagan et al., 2005" startWordPosition="151" endWordPosition="154">ole labeler, and a deep parser based on hand-crafted grammars. The shortest path algorithm is applied on the graph representation of the parser outputs. Then, different types of features are extracted and the entailment recognition is casted into a machinelearning-based classification task. The best setting of the system achieves 66.78% of accuracy, which ranks the 3rd place. 1 Introduction The SemEval-2010 Task #12, Parser Evaluation using Textual Entailment (PETE) (Yuret et al., 2010), is an interesting task connecting two areas of research, parsing and recognizing textual entailment (RTE) (Dagan et al., 2005). The former is usually concerned with syntactic analysis in specific linguistic frameworks, while the latter is believed to involve more semantic aspects of the human languages. However, no clear-cut boundary can be drawn between syntax and semantics for both tasks. In recent years, the parsing community has been reaching beyond what was usually accepted as syntactic structures. Many deep linguistic frameworks allow the construction of semantic representations in parallel to the syntactic structure. Meanwhile, data-driven shallow semantic parsers (or semantic role labelers) are another popula</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In Qui˜nonero-Candela et al., editor, MLCW 2005, volume LNAI Volume 3944, pages 177–190. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E W Dijkstra</author>
</authors>
<title>A note on two problems in connexion with graphs.</title>
<date>1959</date>
<journal>Numerische Mathematik,</journal>
<pages>1--269</pages>
<contexts>
<context position="7355" citStr="Dijkstra, 1959" startWordPosition="1129" endWordPosition="1130">irect dependency relation in T between the same word pair, so we need to traverse the dependency tree or graph to find the dependency paths. In general, we treat all the dependency trees and graphs as undirected graphs with loops, but keep records for the directions of the edges we traverse. For the following three representations, we apply slightly different algorithms to find the dependency path between two words, Syntactic Dependency Tree We simply traverse the tree and find the corresponding dependency path connecting the two words; Semantic Dependency Graph We apply Dijkstra’s algorithm (Dijkstra, 1959) to find the shortest path between the two words; Joint Dependency Graph We assign different weights to syntactic and semantic dependencies and apply Dijkstra’s algorithm to find the shortest path (with the lowest cost)1. 2.3 Feature-based Classification Based on the meaning representation we have discussed above (Section 2.1 and Section 2.2), we ex1In practice, we simply give semantic dependencies 0.5 cost and syntactic dependencies 1.0 cost, to show the preferences on the former when both exist. 273 T: H: Figure 2: Syntactic dependency of the example T-H pair by MaltParser. T: H: Figure 3: S</context>
</contexts>
<marker>Dijkstra, 1959</marker>
<rawString>E. W. Dijkstra. 1959. A note on two problems in connexion with graphs. Numerische Mathematik, 1:269–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="5597" citStr="Flickinger, 2000" startWordPosition="843" endWordPosition="844">ependencies capture interesting syntactic relations, when compared to the parsing systems with deeper representations, the contained information is not as detailed. To compensate for this, we used a shallow semantic parser to predict the semantic role relations in the T and H of entailment pairs. The shallow semantic parser was also trained with CoNLL 2008 shared task dataset, with semantic roles extracted from the Propbank and Nombank annotations (Zhang et al., 2008). Figure 3 shows the resulting semantic dependency graphs of the T-H pair. HPSG Parsing We employ the English Resource Grammar (Flickinger, 2000), a handwritten linguistic grammar in the framework of HPSG, and the PET HPSG parser (Callmeier, 2001) to check the grammaticality of each hypothesis sentence. As the hypotheses in this PETE shared task were automatically generated, some ungrammatical hypotheses occur in nonentailment pairs. the grammaticality checking allows us to quickly identify these instances. 2.2 Dependency Path Extraction According to the task definition, we need to verify whether those dependency relations in H also appear in T. We firstly find out all the important dependency triples in H, like &lt;word, dependency relat</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-Projective Dependency Parsing using Spanning Tree Algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of HLTEMNLP</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="3495" citStr="McDonald et al., 2005" startWordPosition="528" endWordPosition="531">he meaning of the input text. In particular, after tokenization and POS tagging, we did dependency parsing and semantic role labeling. In addition, HPSG parsing is a filter for ungrammatical hypotheses. Tokenization and POS Tagging We use the Penn Treebank style tokenization throughout the various processing stages. TnT, an HMM-based POS tagger trained with Wall Street Journal sections of the PTB, was used to automatically predict the part-of-speech of each token in the texts and hypotheses. Dependency Parsing For obtaining the syntactic dependencies, we use two dependency parsers, MSTParser (McDonald et al., 2005) and MaltParser (Nivre et al., 2007). MSTParser is a graphbased dependency parser where the best parse tree is acquired by searching for a spanning tree 272 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 272–275, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics T H Preprocessing HPSG Parsing Dependency Parsing Semantic Role Labeling Dependency Path Extraction Dependency Triple Extraction Path Extraction Feature-based Classification Feature Extraction SVM-based Classification Yes/No No Figure 1: Workflow of the System whic</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005. Non-Projective Dependency Parsing using Spanning Tree Algorithms. In Proceedings of HLTEMNLP 2005, pages 523–530, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="3531" citStr="Nivre et al., 2007" startWordPosition="535" endWordPosition="538">ular, after tokenization and POS tagging, we did dependency parsing and semantic role labeling. In addition, HPSG parsing is a filter for ungrammatical hypotheses. Tokenization and POS Tagging We use the Penn Treebank style tokenization throughout the various processing stages. TnT, an HMM-based POS tagger trained with Wall Street Journal sections of the PTB, was used to automatically predict the part-of-speech of each token in the texts and hypotheses. Dependency Parsing For obtaining the syntactic dependencies, we use two dependency parsers, MSTParser (McDonald et al., 2005) and MaltParser (Nivre et al., 2007). MSTParser is a graphbased dependency parser where the best parse tree is acquired by searching for a spanning tree 272 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 272–275, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics T H Preprocessing HPSG Parsing Dependency Parsing Semantic Role Labeling Dependency Path Extraction Dependency Triple Extraction Path Extraction Feature-based Classification Feature Extraction SVM-based Classification Yes/No No Figure 1: Workflow of the System which maximize the score on an either pa</context>
</contexts>
<marker>Nivre, Nilsson, Hall, 2007</marker>
<rawString>Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007. Maltparser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(1):1–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Wang</author>
<author>G¨unter Neumann</author>
</authors>
<title>Recognizing textual entailment using a subsequence kernel method.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI-07,</booktitle>
<location>Vancouver, Canada,</location>
<contexts>
<context position="10159" citStr="Wang and Neumann (2007)" startWordPosition="1605" endWordPosition="1608">he dependency relation (e.g. A1 vs. AM-LOC). We also incorporate the string value of the dependency relation pair and make it boolean according to whether it occurs or not. Table 1 shows the feature types we extract from each T-H pair. 3 Experiments As we mentioned in the preprocessing section (Section 2.1), we utilize the open source dependency parsers, MSTParser4 and MaltParser5, our own semantic role labeler (Zhang et al., 2008), and the PET HPSG parser6. For the shortest path algorithm, we use the jGraphT package7; and for the machine learning toolkit, we use the UniverSVM 3Enlightened by Wang and Neumann (2007), we exclude some dependency relations like “CONJ”, “COORD”, “APPO”, etc., heuristically, since in most of the cases, they will not change the relationship between the two words at both ends of the path. 4http://sourceforge.net/projects/ mstparser/ 5http://maltparser.org/ 6http://heartofgold.dfki.de/PET.html 7http://jgrapht.sourceforge.net/ 274 H Null? T Null? Dir Multi? Dep Same? Rel Sim? Rel Same? Rel Pair Joint + + + + + + + + No Sem + + + + + No Syn + + + + + + + Table 1: Feature types of different settings of the system. H Null? means whether H has dependencies; T Null? means whether T ha</context>
</contexts>
<marker>Wang, Neumann, 2007</marker>
<rawString>Rui Wang and G¨unter Neumann. 2007. Recognizing textual entailment using a subsequence kernel method. In Proceedings of AAAI-07, Vancouver, Canada, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Wang</author>
<author>G¨unter Neumann</author>
</authors>
<title>An accuracyoriented divide-and-conquer strategy for recognizing textual entailment.</title>
<date>2009</date>
<booktitle>In Proceedings of TAC 2008,</booktitle>
<location>Gaithersburg, Maryland, USA.</location>
<contexts>
<context position="2083" citStr="Wang and Neumann, 2009" startWordPosition="309" endWordPosition="312">Many deep linguistic frameworks allow the construction of semantic representations in parallel to the syntactic structure. Meanwhile, data-driven shallow semantic parsers (or semantic role labelers) are another popular type of extension to enrich the information in the parser outputs. Although entailment is described as a semantic relation, RTE, in practice, covers linguistic phenomena at various levels, from surface text to the meaning, even to the context and discourse. One proposal of solving the problem is to deal with different cases of entailment using different specialized RTE modules (Wang and Neumann, 2009). Then, the PETE data can be naturally classified into the syntactic and shallow semantic categories. By participating in this shared task, we aim to investigate whether different parsing outputs leads to different RTE accuracy, and on the contrary, whether the “application”-based evaluation provides insights to the parser comparison. Further, we investigate if strict grammaticality checking with a linguistic grammar is helpful in this task. 2 System Description The workflow of the system is shown in Figure 1 and the details of the three components will be elaborated on in the following sectio</context>
</contexts>
<marker>Wang, Neumann, 2009</marker>
<rawString>Rui Wang and G¨unter Neumann. 2009. An accuracyoriented divide-and-conquer strategy for recognizing textual entailment. In Proceedings of TAC 2008, Gaithersburg, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deniz Yuret</author>
<author>Aydın Han</author>
<author>Zehra Turgut</author>
</authors>
<title>Semeval2010 task 12: Parser evaluation using textual entailments.</title>
<date>2010</date>
<booktitle>In Proceedings of the SemEval-2010 Evaluation Exercises on Semantic Evaluation.</booktitle>
<contexts>
<context position="949" citStr="Yuret et al., 2010" startWordPosition="131" endWordPosition="134">emEval-2010 Task #12, Parser Evaluation using Textual Entailment. Our system incorporated two dependency parsers, one semantic role labeler, and a deep parser based on hand-crafted grammars. The shortest path algorithm is applied on the graph representation of the parser outputs. Then, different types of features are extracted and the entailment recognition is casted into a machinelearning-based classification task. The best setting of the system achieves 66.78% of accuracy, which ranks the 3rd place. 1 Introduction The SemEval-2010 Task #12, Parser Evaluation using Textual Entailment (PETE) (Yuret et al., 2010), is an interesting task connecting two areas of research, parsing and recognizing textual entailment (RTE) (Dagan et al., 2005). The former is usually concerned with syntactic analysis in specific linguistic frameworks, while the latter is believed to involve more semantic aspects of the human languages. However, no clear-cut boundary can be drawn between syntax and semantics for both tasks. In recent years, the parsing community has been reaching beyond what was usually accepted as syntactic structures. Many deep linguistic frameworks allow the construction of semantic representations in par</context>
</contexts>
<marker>Yuret, Han, Turgut, 2010</marker>
<rawString>Deniz Yuret, Aydın Han, and Zehra Turgut. 2010. Semeval2010 task 12: Parser evaluation using textual entailments. In Proceedings of the SemEval-2010 Evaluation Exercises on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Rui Wang</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Hybrid learning of dependency structures from heterogeneous linguistic resources.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>198--202</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="5452" citStr="Zhang et al., 2008" startWordPosition="818" endWordPosition="821">pendency relations. In our case, the CoNLL shared task dataset from 2008 were used to train the statistical dependency parsing models. While such dependencies capture interesting syntactic relations, when compared to the parsing systems with deeper representations, the contained information is not as detailed. To compensate for this, we used a shallow semantic parser to predict the semantic role relations in the T and H of entailment pairs. The shallow semantic parser was also trained with CoNLL 2008 shared task dataset, with semantic roles extracted from the Propbank and Nombank annotations (Zhang et al., 2008). Figure 3 shows the resulting semantic dependency graphs of the T-H pair. HPSG Parsing We employ the English Resource Grammar (Flickinger, 2000), a handwritten linguistic grammar in the framework of HPSG, and the PET HPSG parser (Callmeier, 2001) to check the grammaticality of each hypothesis sentence. As the hypotheses in this PETE shared task were automatically generated, some ungrammatical hypotheses occur in nonentailment pairs. the grammaticality checking allows us to quickly identify these instances. 2.2 Dependency Path Extraction According to the task definition, we need to verify whet</context>
<context position="9971" citStr="Zhang et al., 2008" startWordPosition="1573" endWordPosition="1576"> with H-path one by one3. By comparison, we mainly focus on two values, the category of the dependency relation (e.g. syntactic dependency vs. semantic dependency) and the content of the dependency relation (e.g. A1 vs. AM-LOC). We also incorporate the string value of the dependency relation pair and make it boolean according to whether it occurs or not. Table 1 shows the feature types we extract from each T-H pair. 3 Experiments As we mentioned in the preprocessing section (Section 2.1), we utilize the open source dependency parsers, MSTParser4 and MaltParser5, our own semantic role labeler (Zhang et al., 2008), and the PET HPSG parser6. For the shortest path algorithm, we use the jGraphT package7; and for the machine learning toolkit, we use the UniverSVM 3Enlightened by Wang and Neumann (2007), we exclude some dependency relations like “CONJ”, “COORD”, “APPO”, etc., heuristically, since in most of the cases, they will not change the relationship between the two words at both ends of the path. 4http://sourceforge.net/projects/ mstparser/ 5http://maltparser.org/ 6http://heartofgold.dfki.de/PET.html 7http://jgrapht.sourceforge.net/ 274 H Null? T Null? Dir Multi? Dep Same? Rel Sim? Rel Same? Rel Pair </context>
</contexts>
<marker>Zhang, Wang, Uszkoreit, 2008</marker>
<rawString>Yi Zhang, Rui Wang, and Hans Uszkoreit. 2008. Hybrid learning of dependency structures from heterogeneous linguistic resources. In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL 2008), pages 198–202, Manchester, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>