<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.969229">
Learning to Extract International Relations from Political Context
</title>
<author confidence="0.928495">
Brendan O’Connor Brandon M. Stewart Noah A. Smith
</author>
<affiliation confidence="0.917291">
School of Computer Science Department of Government School of Computer Science
Carnegie Mellon University Harvard University Carnegie Mellon University
Pittsburgh, PA 15213, USA Cambridge, MA 02139, USA Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998279">
brenocon@cs.cmu.edu bstewart@fas.harvard.edu nasmith@cs.cmu.edu
</email>
<sectionHeader confidence="0.99479" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999181777777778">
We describe a new probabilistic model
for extracting events between major polit-
ical actors from news corpora. Our un-
supervised model brings together famil-
iar components in natural language pro-
cessing (like parsers and topic models)
with contextual political information—
temporal and dyad dependence—to in-
fer latent event classes. We quantita-
tively evaluate the model’s performance
on political science benchmarks: recover-
ing expert-assigned event class valences,
and detecting real-world conflict. We also
conduct a small case study based on our
model’s inferences.
A supplementary appendix, and replica-
tion software/data are available online, at:
http://brenocon.com/irevents
</bodyText>
<sectionHeader confidence="0.998775" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978869565217">
The digitization of large news corpora has pro-
vided an unparalleled opportunity for the system-
atic study of international relations. Since the mid-
1960s political scientists have used political events
data, records of public micro-level interactions be-
tween major political actors of the form “someone
does something to someone else” as reported in
the open press (Schrodt, 2012), to study the pat-
terns of interactions between political actors and
how they evolve over time. Scaling this data effort
to modern corpora presents an information extrac-
tion challenge: can a structured collection of ac-
curate, politically relevant events between major
political actors be extracted automatically and ef-
ficiently? And can they be grouped into meaning-
ful event types with a low-dimensional structure
useful for further analysis?
We present an unsupervised approach to event
extraction, in which political structure and linguis-
tic evidence are combined. A political context
model of the relationship between a pair of polit-
ical actors imposes a prior distribution over types
of linguistic events. Our probabilistic model in-
fers latent frames, each a distribution over textual
expressions of a kind of event, as well as a repre-
sentation of the relationship between each political
actor pair at each point in time. We use syntactic
preprocessing and a logistic normal topic model,
including latent temporal smoothing on the politi-
cal context prior.
We apply the model in a series of compar-
isons to benchmark datasets in political science.
First, we compare the automatically learned verb
classes to a pre-existing ontology and hand-crafted
verb patterns from TABARI,1 an open-source and
widely used rule-based event extraction system for
this domain. Second, we demonstrate correlation
to a database of real-world international conflict
events, the Militarized Interstate Dispute (MID)
dataset (Jones et al., 1996). Third, we qualitatively
examine a prominent case not included in the MID
dataset, Israeli-Palestinian relations, and compare
the recovered trends to the historical record.
We outline the data used for event discovery
(§2), describe our model (§3), inference (§4), eval-
uation (§5), and comment on related work (§6).
</bodyText>
<sectionHeader confidence="0.995434" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.996613">
The model we describe in §3 is learned from a
corpus of 6.5 million newswire articles from the
English Gigaword 4th edition (1994–2008, Parker
et al., 2009). We also supplement it with a sam-
ple of data from the New York Times Annotated
Corpus (1987–2007, Sandhaus, 2008).2 The Stan-
</bodyText>
<footnote confidence="0.8951875">
1Available from the Penn State Event Data Project:
http://eventdata.psu.edu/
2For arbitrary reasons this portion of the data is much
smaller (we only parse the first five sentences of each arti-
cle, while Gigaword has all sentences parsed), resulting in
less than 2% as many tuples as from the Gigaword data.
</footnote>
<page confidence="0.912558">
1094
</page>
<note confidence="0.916654">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1094–1104,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.977969333333333">
ford CoreNLP system,3 under default settings, was
used to POS-tag and parse the articles, to eventu-
ally produce event tuples of the form
</bodyText>
<equation confidence="0.619104">
(s, r, t, wpredpath)
</equation>
<bodyText confidence="0.999960159090909">
where s and r denote “source” and “receiver” ar-
guments, which are political actor entities in a pre-
defined set £, t is a timestep (i.e., a 7-day pe-
riod) derived from the article’s published date, and
wpredpath is a textual predicate expressed as a de-
pendency path that typically includes a verb (we
use the terms “predicate-path” and “verb-path” in-
terchangeably). For example, on January 1, 2000,
the AP reported “Pakistan promptly accused In-
dia,” from which our preprocessing extracts the tu-
ple (PAK, IND, 678, accuse dobj �−−). (The path ex-
cludes the first source-side arc.) Entities and verb
paths are identified through the following sets of
rules.
Named entity recognition and resolution is done
deterministically by finding instances of country
names from the CountryInfo.txt dictionary from
TABARI,4 which contains proper noun and adjec-
tival forms for countries and administrative units.
We supplement these with a few entries for in-
ternational organizations from another dictionary
provided by the same project, and clean up a few
ambiguous names, resulting in a final actor dictio-
nary of 235 entities and 2,500 names.
Whenever a name is found, we identify its en-
tity’s mention as the minimal noun phrase that
contains it; if the name is an adjectival or noun-
noun compound modifier, we traverse any such
amod and nn dependencies to the noun phrase
head. Thus NATO bombing, British view, and
Palestinian militant resolve to the entity codes IG-
ONAT, GBR, and PSE respectively.
We are interested in identifying actions initi-
ated by agents of one country targeted towards an-
other, and hence concentrate on verbs, analyzing
the “CCprocessed” version of the Stanford Depen-
dencies (de Marneffe and Manning, 2008). Verb
paths are identified by looking at the shortest de-
pendency path between two mentions in a sen-
tence. If one of the mentions is immediately dom-
inated by a nsubj or agent relation, we consider
that the Source actor, and the other mention is the
Receiver. The most common cases are simple di-
rect objects and prepositional arguments like talk
</bodyText>
<footnote confidence="0.977462">
3http://nlp.stanford.edu/software/
corenlp.shtml
4http://eventdata.psu.edu/software.
dir/dictionaries.html.
</footnote>
<bodyText confidence="0.979228796296296">
�−−−− and fight prep alongside
prep with �−−−−−− (“talk with R,” “fight
alongside R”) but many interesting multiword con-
structions also result, such as reject dobj
�−− allegation
poss
�−−(“rejected R’s allegation”) or verb chains as
in offer xcomp
�−− help dobj
�−− (“offer to help R”).
We wish to focus on instances of directly re-
ported events, so attempt to remove factively com-
plicated cases such as indirect reporting and hy-
potheticals by discarding all predicate paths for
which any verb on the path has an off-path gov-
erning verb with a non-conj relation. (For exam-
ple, the verb at the root of a sentence always sur-
vives this filter.) Without this filter, the (s, r, w)
tuple (USA, CUB, want xcomp
�−− seize dobj �−−) is ex-
tracted from the sentence “Parliament Speaker Ri-
cardo Alarcon said the United States wants to seize
Cuba and take over its lands”; the filter removes
it since wants is dominated by an off-path verb
through say ccomp
�−− wants. The filter was iteratively
developed by inspecting dozens of output exam-
ples and their labelings under successive changes
to the rules.
Finally, only paths length 4 or less are allowed,
the final dependency relation for the receiver may
not be nsubj or agent, and the path may not contain
any of the dependency relations conj, parataxis,
det, or dep. We use lemmatized word forms in
defining the paths.
Several document filters are applied before tu-
ple extraction. Deduplication removes 8.5% of ar-
ticles.5 For topic filtering, we apply a series of
keyword filters to remove sports and finance news,
and also apply a text classifier for diplomatic and
military news, trained on several hundred man-
ually labeled news articles (using `1-regularized
logistic regression with unigram and bigram fea-
tures). Other filters remove non-textual junk and
non-standard punctuation likely to cause parse er-
rors.
For experiments we remove tuples where the
source and receiver entities are the same, and re-
strict to tuples with dyads that occur at least 500
times, and predicate paths that occur at least 10
times. This yields 365,623 event tuples from
235,830 documents, for 421 dyads and 10,457
unique predicate paths. We define timesteps
to be 7-day periods, resulting in 1,149 discrete
</bodyText>
<footnote confidence="0.998462333333333">
5We use a simple form of shingling (ch. 3, Rajaraman and
Ullman, 2011): represent a document signature as its J = 5
lowercased bigrams with the lowest hash values, and reject a
document with a signature that has been seen before within
the same month. J was manually tuned, as it affects the pre-
cision/recall tradeoff.
</footnote>
<page confidence="0.993238">
1095
</page>
<figureCaption confidence="0.997774">
Figure 1: Directed probabilistic diagram of the model for one
(s, r, t) dyad-time context, for the smoothed model.
</figureCaption>
<bodyText confidence="0.980924">
timesteps (1987 through 2008, though the vast ma-
jority of data starts in 1994).
</bodyText>
<sectionHeader confidence="0.990356" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.99965845">
We design two models to learn linguistic event
classes over predicate paths by conditioning on
real-world contextual information about interna-
tional politics, p(wpredpath  |s, r, t), leveraging the
fact there tends to be dyadic and temporal coher-
ence in international relations: the types of actions
that are likely to occur between nations tend to be
similar within the same dyad, and usually their dis-
tribution changes smoothly over time.
Our model decomposes into two submodels:
a Context submodel, which encodes how politi-
cal context affects the probability distribution over
event types, and a Language submodel, for how
those events are manifested as textual predicate
paths (Figure 1). The overall generative process is
as follows. We color global parameters for a frame
blue, and local context parameters red, and use
the term “frame” as a synonym for “event type.”
The fixed hyperparameter K denotes the number
of frames.
</bodyText>
<listItem confidence="0.988377615384615">
• The context model generates a frame prior Bs,r,t
for every context (s, r, t).
• Language model:
• Draw lexical sparsity parameter b from a dif-
fuse prior (see §4).
• For each frame k, draw a multinomial distri-
bution of dependency paths, Ok — Dir(b/V)
(where V is the number of dependency path
types).
• For each (s, r, t), for every event tuple i in
that context,
• Sample its frame z(i) — Mult(Bs,r,t).
• Sample its predicate realization
</listItem>
<equation confidence="0.9903155">
i
wpredpath — Mult(Oz(i)).
</equation>
<bodyText confidence="0.9892698">
Thus the language model is very similar to a topic
model’s generation of token topics and wordtypes.
We use structured logistic normal distributions
to represent contextual effects. The simplest is the
vanilla (V) context model,
</bodyText>
<listItem confidence="0.9998934">
• For each frame k, draw global parameters from
diffuse priors: prevalence αk and variability σ2k.
• For each (s, r, t),
• Draw ηk,s,r,t — N(αk, σ2k) for each frame k.
• Apply a softmax transform,
</listItem>
<equation confidence="0.883432">
exp ηk,s,r,t
Bk,s,r,t = K
�k&apos;=1 exp ηk&apos;,s,r,t
</equation>
<bodyText confidence="0.9996326">
Thus the vector η∗,s,r,t encodes the relative log-
odds of the different frames for events appearing
in the context (s, r, t). This simple logistic nor-
mal prior is, in terms of topic models, analogous
to the asymmetric Dirichlet prior version of LDA
in Wallach et al. (2009), since the αk parameter
can learn that some frames tend to be more likely
than others. The variance parameters σ2k control
admixture sparsity, and are analogous to a Dirich-
let’s concentration parameter.
</bodyText>
<subsectionHeader confidence="0.983928">
Smoothing Frames Across Time
</subsectionHeader>
<bodyText confidence="0.9999372">
The vanilla model is capable of inducing frames
through dependency path co-occurences, when
multiple events occur in a given context. How-
ever, many dyad-time slices are very sparse; for
example, most dyads (all but 18) have events in
fewer than half the time slices in the dataset. One
solution is to increase the bucket size (e.g., to
months); however, previous work in political sci-
ence has demonstrated that answering questions
of interest about reciprocity dynamics requires re-
covering the events at weekly or even daily gran-
ularity (Shellman, 2004), and in any case wide
buckets help only so much for dyads with fewer
events or less media attention. Therefore we pro-
pose a smoothed frames (SF) model, in which the
</bodyText>
<figure confidence="0.99950104">
s &amp;quot;Source&amp;quot;
entity
r &amp;quot;Receiver&amp;quot;
entity
t Timestep
i Event tuple
k Frame
⌧2
Language Model
P(Text  |Event Type)
Context Model
P(Event Type  |Context)
A,s,r,t—]k
4,s,r,t
k
�2
k
↵k
⌘k,s,r,t
k
✓s,r,t
r
wpredpath
i
b
</figure>
<page confidence="0.982651">
1096
</page>
<bodyText confidence="0.9858438">
frame distribution for a given dyad comes from a
latent parameter β*,s,r,t that smoothly varies over
time. For each (s, r), draw the first timestep’s val-
ues as βk,s,r,1 — N(0,100), and for each context
(s, r, t &gt; 1),
</bodyText>
<listItem confidence="0.9999245">
• Draw βk,s,r,t — N(βk,s,r,t−1, T2)
• Draw qk,s,r,t — N(αk + βk,s,r,t, Q2k)
</listItem>
<bodyText confidence="0.9999270625">
Other parameters (αk, Q2k) are same as the vanilla
model. This model assumes a random walk pro-
cess on β, a variable which exists even for contexts
that contain no events. Thus inferences about q
will be smoothed according to event data at nearby
timesteps. This is an instance of a linear Gaussian
state-space model (also known as a linear dynami-
cal system or dynamic linear model), and is a con-
venient formulation because it has well-known ex-
act inference algorithms. Dynamic linear models
have been used elsewhere in machine learning and
political science to allow latent topic frequencies
(Blei and Lafferty, 2006; Quinn et al., 2010) and
ideological positions (Martin and Quinn, 2002) to
smoothly change over time, and thus share statis-
tical strength between timesteps.
</bodyText>
<sectionHeader confidence="0.999547" genericHeader="method">
4 Inference
</sectionHeader>
<bodyText confidence="0.999983933333333">
After randomly initializing all qk,s,r,t, inference is
performed by a blocked Gibbs sampler, alternat-
ing resamplings for three major groups of vari-
ables: the language model (z,φ), context model
(α, ry, β, p), and the q, θ variables, which bottle-
neck between the submodels.
The language model sampler sequentially up-
dates every z(i) (and implicitly φ via collapsing)
in the manner of Griffiths and Steyvers (2004):
p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + b/V)/(nz + b),
where counts n are for all event tuples besides i.
For the context model, α is conjugate resam-
pled as a normal mean. The random walk vari-
ables β are sampled with the forward-filtering-
backward-sampling algorithm (FFBS; Harrison
and West, 1997; Carter and Kohn, 1994); there is
one slight modification of the standard dynamic
linear model that the zero-count weeks have no q
observation; the Kalman filter implementation is
appropriately modified to handle this.
The q update step is challenging since it is a
nonconjugate prior to the z counts. Logistic nor-
mal distributions were introduced to text mod-
eling by Blei and Lafferty (2007), who devel-
oped a variational approximation; however, we
find that experimenting with different models is
easier in the Gibbs sampling framework. While
Gibbs sampling for logistic normal priors is pos-
sible using auxiliary variable methods (Mimno
et al., 2008; Holmes and Held, 2006; Polson et al.,
2012), it can be slow to converge. We opt for
the more computationally efficient approach of
Zeger and Karim (1991) and Hoff (2003), using
a Laplace approximation to p(q  |¯q, E, z), which
is a mode-centered Gaussian having inverse co-
variance equal to the unnormalized log-posterior’s
negative Hessian (§8.4 in Murphy, 2012). We find
the mode with the linear-time Newton algorithm
from Eisenstein et al. (2011), and sample in linear
time by only using the Hessian’s diagonal as the
inverse covariance (i.e., an axis-aligned normal),
since a full multivariate normal sample requires
a cubic-time-to-compute Cholesky root of the co-
variance matrix. This q* sample is a proposal for a
Metropolis-within-Gibbs step, which is moved to
according to the standard Metropolis-Hastings ac-
ceptance rule. Acceptance rates differ by K, rang-
ing approximately from 30% (K = 100) to nearly
100% (small K).
Finally, we use diffuse priors on all global pa-
rameters, conjugate resampling variances T2, Qk
once per iteration, and slice sampling (Neal, 2003)
the Dirichlet concentration b every 100 iterations.
Automatically learning these was extremely con-
venient for model-fitting; the only hyperparameter
we set manually was K. It also allowed us to mon-
itor the convergence of dispersion parameters to
help debug and assess MCMC mixing. For other
modeling and implementation details, see the on-
line appendix and software.
</bodyText>
<sectionHeader confidence="0.998739" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999943625">
We fit the two models on the dataset described in
§2, varying the number of frames K, with 8 or
more separate runs for each setting. Posteriors are
saved and averaged from 11 Gibbs samples (every
100 iterations from 9,000 to 10,000) for analysis.
We present intrinsic (§5.1) and extrinsic (§5.2)
quantitative evaluations, and a qualitative case
study (§5.4).
</bodyText>
<subsectionHeader confidence="0.993666">
5.1 Lexical Scale Impurity
</subsectionHeader>
<bodyText confidence="0.9999216">
In the international relations literature, much of
the analysis of text-based events data makes use of
a unidimensional conflict to cooperation scale. A
popular event ontology in this domain, CAMEO,
consists of around 300 different event types, each
</bodyText>
<page confidence="0.974369">
1097
</page>
<bodyText confidence="0.999988210526316">
given an expert-assigned scale in the range from
—10 to +10 (Gerner et al., 2002), derived from
a judgement collection experiment in Goldstein
(1992). The TABARI pattern-based event extrac-
tion program comes with a list of almost 16,000
manually engineered verb patterns, each assigned
to one CAMEO event type.
It is interesting to consider the extent to which
our unsupervised model is able to recover the
expert-designed ontology. Given that many of
the categories are very fine-grained (e.g. “Express
intent to de-escalate military engagement”), we
elect to measure model quality as lexical scale pu-
rity: whether all the predicate paths within one
automatically learned frame tend to have similar
gold-standard scale scores. (This measures clus-
ter cohesiveness against a one-dimensional con-
tinuous scale, instead of measuring cluster cohe-
siveness against a gold-standard clustering as in
VI, Rand index, or purity.) To calculate this, we
construct a mapping between our corpus-derived
verb path vocabulary and the TABARI verb pat-
terns, many of which contain one to several word
stems that are intended to be matched in surface
order. Many of our dependency paths, when tra-
versed from the source to receiver direction, also
follow surface order, due to English’s SVO word
order.6 Therefore we convert each path to a
word sequence and match against the TABARI
lexicon—plus a few modifications for differences
in infinitives and stemming—and find 528 depen-
dency path matches. We assign each path w a
gold-standard scale g(w) by resolving through its
matching pattern’s CAMEO code.
We formalize lexical scale impurity as the av-
erage absolute difference of scale values between
two predicate paths under the same frame. Specif-
ically, we want a token-level posterior expectation
</bodyText>
<equation confidence="0.990092">
E(|g(wi) - g(wj)  ||zi = zj, wi =� wj) (1)
</equation>
<bodyText confidence="0.999687">
which is taken over pairs of path instances (i, j)
where both paths wi, wj are in M, the set of verb
paths that were matched between the lexicons.
This can be reformulated at the type level as:7
</bodyText>
<equation confidence="0.656235">
1 N � nw,k nv,k |g(w) — g(v) |(2)
k w,v∈M
w=,4v
</equation>
<footnote confidence="0.9895206">
6There are plenty of exceptions where a Source-to-
Receiver path traversal can have a right-to-left move, such
as dependency edges for posessives. This approach can not
match them.
7Derivation in supplementary appendix.
</footnote>
<bodyText confidence="0.999992588235294">
where n refers to the averaged Gibbs samples’
counts of event tuples having frame k and a par-
ticular verb path,8 and N is the number of to-
ken comparisons (i.e. the same sum, but with a
1 replacing the distance). The worst possible im-
purity is upper bounded at 20 (= max(g(w)) —
min(g(w))) and the best possible is 0. We also
compute a randomized null hypothesis to see how
low impurity can be by chance: each of —1000
simulations randomly assigns each path in M to
one of K frames (all its instances are exclusively
assigned to that frame), and computes the impu-
rity. On average the impurity is same at all K,
but variance increases with K (since small clus-
ters might by chance get a highly similar paths in
them), necessitating this null hypothesis analysis.
We report the 5th percentile over simulations.
</bodyText>
<subsectionHeader confidence="0.992858">
5.2 Conflict Detection
</subsectionHeader>
<bodyText confidence="0.9999535">
Political events data has shown considerable
promise as a tool for crisis early warning systems
(O’Brien, 2010; Brandt et al., 2011). While con-
flict forecasting is a potential application of our
model, we conduct a simpler prediction task to
validate whether the model is learning something
useful: based on news text, tell whether or not an
armed conflict is currently happening. For a gold
standard, we use the Militarized Interstate Dispute
(MID) dataset (Jones et al., 1996; Ghosn et al.,
2004), which documents historical international
disputes. While not without critics, the MID data
is the most prominent dataset in the field of in-
ternational relations. We use the Dyadic MIDs,
each of which ranks hostility levels between pairs
of actors on a five point scale over a date inter-
val; we define conflict to be the top two categories
“Use of Force” (4) and “War” (5). We convert
the data into a variable ys,r,t, the highest hostility
level reached by actor s directed towards receiver
r in the dispute that overlaps with our 7-day in-
terval t, and want to predict the binary indicator
1{ys,r,t &gt;— 41. For the illustrative examples (USA
to Iraq, and the Israel-Palestine example below)
we use results from a smaller but more internally
comparable dataset consisting of the 2 million As-
sociated Press articles within the Gigaword cor-
pus.
For an example of the MID data, see Figure 2,
which depicts three disputes between the US and
</bodyText>
<footnote confidence="0.99710925">
8Results are nearly identical whether we use counts av-
eraged across samples (thus giving posterior marginals),
or simply use counts from a single sample (i.e., iteration
10,000).
</footnote>
<page confidence="0.989291">
1098
</page>
<figureCaption confidence="0.552586222222222">
Figure 2: The USA→Iraq directed dyad, analyzed by
smoothed (above) and vanilla (below) models, showing (1)
gold-standard MID values (red intervals along top), (2) weeks
with non-zero event counts (vertical lines along x-axis), (3)
posterior E[θk,USA,IRQ,t] inferences for two frames chosen
from two different K = 5 models, and (4) most common
verb paths for each frame (right). Frames corresponding to
material and verbal conflict were chosen for display. Vertical
line indicates Operation Desert Fox (see §5.2).
</figureCaption>
<bodyText confidence="0.998706842105263">
Iraq in this time period. The MID labels are
marked in red.
The first dispute is a “display of force” (level
3), cataloguing the U.S. response to a series of
troop movements along the border with Kuwait.
The third dispute (10/7/1997 to 10/10/2001) be-
gins with increasing Iraqi violations of the no-
fly zone, resulting in U.S. and U.K. retaliation,
reaching a high intensity with Operation Desert
Fox, a four-day bombing campaign from Decem-
ber 16 to 19, 1998—which is not shown in MID.
These cases highlight MID’s limitations—while it
is well regarded in the political science literature,
its coarse level of aggregation can fail to capture
variation in conflict intensity.
Figure 2 also shows model inferences. Our
smoothed model captures some of these phenom-
ena here, showing clear trends for two relevant
frames, including a dramatic change in Decem-
ber 1998. The vanilla model has a harder time,
since it cannot combine evidence between differ-
ent timesteps.
The MID dataset overlaps with our data for 470
weeks, from 1993 through 2001. After excluding
dyads with actors that the MID data does not in-
tend to include—Kosovo, Tibet, Palestine, and in-
ternational organizations—we have 267 directed
dyads for evaluation, 117 of which have at least
one dispute in the MID data. (Dyads with no dis-
pute in the MID data, such as Germany-France,
are assumed to have y = 0 throughout the time
period.) About 7% of the dyad-time contexts have
a dispute under these definitions.
We split the dataset by time, training on the first
half of the data and testing on the second half, and
measure area under the receiver operating charac-
teristic curve (AUC).9 For each model, we train an
`1-regularized logistic regression10 with the K el-
ements of 0∗,s,r,t as input features, tuning the reg-
ularization parameter within the training set (by
splitting it in half again) to optimize held-out like-
lihood. We weight instances to balance positive
and negative examples. Training is on all individ-
ual 0 samples at once (thus accounting for pos-
terior uncertainty in learning), and final predicted
probabilities are averaged from individual proba-
bilities from each 0 test set sample, thus propa-
gating posterior uncertainty into the predictions.
We also create a baseline `1-regularized logistic
regression that uses normalized dependency path
counts as the features (10,457 features). For both
the baseline and vanilla model, contexts with no
events are given a feature vector of all zeros.11
(We also explored an alternative evaluation setup,
to hold out by dyad; however, the performance
variance is quite high between different random
dyad splits.)
</bodyText>
<subsectionHeader confidence="0.528408">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.977970090909091">
Results are shown in Figure 3.12
The verb-path logistic regression performs
strongly at AUC 0.62; it outperforms all of
the vanilla frame models. This is an exam-
ple of individual lexical features outperforming a
topic model for predictive task, because the topic
model’s dimension reduction obscures important
indicators from individual words. Similarly, Ger-
rish and Blei (2011) found that word-based regres-
sion outperformed a customized topic model when
predicting Congressional bill passage, and Eisen-
</bodyText>
<footnote confidence="0.597391">
9AUC can be interpreted as follows: given a positive and
negative example, what is the probability that the classifier’s
confidences order them correctly? Random noise or predict-
ing all the same class both give AUC 0.5.
10Using the R glmnet package (Friedman et al., 2010).
</footnote>
<bodyText confidence="0.82131">
11For the vanilla model, this performed better than linear
interpolation (about 0.03 AUC), and with less variance be-
tween runs.
12Due to an implementation bug, the model put the vast
majority of the probability mass only on K − 1 frames,
so these settings might be better thought of as K =
1, 2, 3, 4, 9, ...; see the appendix for details.
</bodyText>
<figure confidence="0.989549705882353">
1995 1996 1997 1998 1999 2000 2001 2002
0.0 0.4 0.8 0.0 0.4 0.8
1995 1996 1997 1998 1999 2000 2001 2002
kill, fire at,
seal, invade,
enter
accuse,
criticize, warn,
reject, urge
accuse,
reject, blame,
kill, take
criticize, call,
ask, condemn
denounce
USA to Iraq (Smoothed Frames)
USA to Iraq (Vanilla Model)
</figure>
<page confidence="0.890658">
1099
</page>
<figureCaption confidence="0.996396">
Figure 3: Evaluation results. Each point indicates one model
</figureCaption>
<bodyText confidence="0.978881871794872">
run. Lines show the average per K, with vertical lines indi-
cating the 95% bootstrapped interval. Top: Conflict detection
AUC for different models (§5.2). Green line is the verb-path
logistic regression baseline. Bottom: Lexical scale impurity
(§5.1). Top green line indicates the simple random baseline
E(|g(wi) − g(wj)|) = 5.33; the second green line is from
the random assignment baseline.
stein et al. (2010) found word-based regression
outperformed Supervised LDA for geolocation,13
and we have noticed this phenomenon for other
text-based prediction problems.
However, adding smoothing to the model sub-
stantially increases performance, and in fact out-
performs the verb-path regression at K = 100.
It is unclear why the vanilla model fails to in-
crease performance in K. Note also, the vanilla
model exhibits very little variability in prediction
performance between model runs, in comparison
to the smoothed model which is much more vari-
able (presumably due to the higher number of pa-
rameters in the model); at small values of K, the
smoothed model can perform poorly. It would also
be interesting to analyze the smoothed model with
higher values of K and find where it peaks.
We view the conflict detection task only as one
of several validations, and thus turn to lexical eval-
uation of the induced frames. For lexical scale
purity (bottom of Figure 3), the models perform
about the same, with the smoothed model a lit-
tle bit worse at some values of K (though some-
times with better stability of the fits—opposite of
the conflict detection task). This suggests that se-
mantic coherence does not benefit from the longer-
13In the latter, a problem-specific topic model did best.
range temporal dependencies.
In general, performance improves with higher
K, but not beyond K = 50. This suggests the
model reaches a limit for how fine-grained of se-
mantics it can learn.
</bodyText>
<subsectionHeader confidence="0.996084">
5.4 Case study
</subsectionHeader>
<bodyText confidence="0.9980664">
Here we qualitatively examine the narrative story
between the dyad with the highest frequency of
events in our dataset, the Israeli-Palestinian rela-
tionship, finding qualitative agreement with other
case studies of this conflict (Brandt et al., 2012;
Goldstein et al., 2001; Schrodt and Gerner, 2004).
(The MID dataset does not include this conflict be-
cause the Palestinians are not considered a state
actor.) Using the Associated Press subset, we plot
the highest incidence frames from one run of the
K = 20 smoothed frame models, for the two di-
rected dyads, and highlight some of the interesting
relationships.
Figure 4(a) shows that tradeoffs in the use of
military vs. police action by Israel towards the
Palestinians tracks with major historical events.
The first period in the data where police actions
(‘impose, seal, capture, seize, arrest’) exceed mil-
itary actions (‘kill, fire, enter, attack, raid’) is
with the signing of the “Interim Agreement on the
West Bank and the Gaza Strip,” also known as the
Oslo II agreement. This balance persists until the
abrupt breakdown in relations that followed the
unsuccessful Camp David Summit in July of 2000,
which generally marks the starting point of the
wave of violence known as the Second Intifada.
In Figure 4(b) we show that our model produces
a frame which captures the legal aftermath of par-
ticular events (‘accuse, criticize,’ but also ‘detain,
release, extradite, charge’). Each of the major
spikes in the data coincides with a particular event
which either involves the investigation of a par-
ticular attack or series of attacks (as in A,B,E) or
a discussion about prisoner swaps or mass arrests
(as in events D, F, J).
Our model also picks up positive diplomatic
events, as seen in Figure 4(c), a frame describ-
ing Israeli diplomatic actions towards Palestine
(‘meet with, sign with, praise, say with, arrive
in’). Not only do the spikes coincide with major
peace treaties and negotiations, but the model cor-
rectly characterizes the relative lack of positively
valenced action from the beginning of the Second
Intifada until its end around 2005–2006.
In Figure 4(d) we show the relevant frames de-
</bodyText>
<figure confidence="0.997486441558442">
4 5 10 20 50 100
Number of frames (K)
2 3 4 5 10 20 50 100
Number of frames (K)
model
Log. Reg
Vanilla
Smoothed
Conflict prediction AUC
(higher is better)
0.7
0.6
0.5
0.4
●
●
model
Null
Vanilla
Smoothed
Scale impurity
(lower is better)
4.5
2.5
5.5
3.5
1.5
●
●
●
●
●
1100
a.
0.0 0.4 0.8
0.0 0.4 0.8 1.2
Israeli Use of Force Tradeoff
Oslo II Signed Second Intifada Begins
Police Actions and Crime Response
A: Series of Suicide Attacks
in Jerusalem
B: Island of Peace Massacre
C: Arrests over Protests
D: Tensions over Treatment
of Pal. Prisoners
A
D
E: Passover Massacre
F: 400-Person Prisoner Swap
G: Gaza Street Bus Bombing
H: Stage Club Bombing
I: House to House Sweep for 7
militant leaders
J: Major Prisoner Release
G
C
B
E
F H I J
1994 1997 2000 2002 2005 2007
b.
1994 1997 2000 2002 2005 2007
0.0 0.4 0.8
A: Israel-Jordan Peace
Treaty
B: Hebron Protocol
C: U.S. Calls for West Bank
Withdrawal
D: Deadlines for Wye River Peace
Accord
E: Negotiations in Mecca
F: Annapolis Conference
A B C D E F
Israeli−Palestinian Diplomacy
0.0 0.4 0.8
Palestinian Use of Force
c. 1994 1997 2000 2002 2005 2007 d. 1994 1997 2000 2002 2005 2007
</figure>
<figureCaption confidence="0.99188875">
Figure 4: For Israel-Palestinian directed dyads, plots of E[θ] (proportion of weekly events in a frame) over time, annotated with
historical events. (a): Words are ‘kill, fire at, enter, kill, attack, raid, strike, move, pound, bomb’ and ‘impose, seal, capture,
seize, arrest, ease, close, deport, close, release’ (b): ‘accuse, criticize, reject, tell, hand to, warn, ask, detain, release, order’ (c):
‘meet with, sign with, praise, say with, arrive in, host, tell, welcome, join, thank’ (d): again the same ‘kill, fire at’ frame in (a),
</figureCaption>
<bodyText confidence="0.943524933333333">
appos
plus the erroneous frame (see text) ‘include, join, fly to, have relation with, protest to, call, include bomber *��� informer
for’. Figures (b) and (c) use linear interpolation for zero-count weeks (thus relying exclusively on the model for smoothing);
(a) and (d) apply a lowess smoother. (a-c) are for the ISR-+PSE direction; (d) is PSE-+ISR.
picting use of force from the Palestinians towards
the Israelis (brown trend line). At first, the drop
in the use of force frame immediately following
the start of the Second Intifada seems inconsis-
tent with the historical record. However, there is a
concucrrent rise in a different frame driven by the
word ‘include’, which actually appears here due
to an NLP error compounded with an artifact of
the data source. A casualties report article, con-
taining variants of the text “The Palestinian fig-
ure includes... 13 Israeli Arabs...”, is repeated 27
times over two years. “Palestinian figure” is er-
roneously identified as the PSE entity, and several
noun phrases in a list are identified as separate re-
ceivers. This issue causes 39 of all 86 PSE→ISR
events during this period to use the word ‘in-
clude’, accounting for the rise in that frame. (This
highlights how better natural language processing
could help the model, and the dangers of false
positives for this type of data analysis, especially
in small-sample drilldowns.) Discounting this er-
roneous inference, the results are consistent with
heightened violence during this period.
We conclude the frame extractions for the
Israeli-Palestinian case are consistent with the his-
torical record over the period of study.
</bodyText>
<sectionHeader confidence="0.999948" genericHeader="method">
6 Related Work
</sectionHeader>
<subsectionHeader confidence="0.99992">
6.1 Events Data in Political Science
</subsectionHeader>
<bodyText confidence="0.999891458333333">
Projects using hand-collected events data repre-
sent some of the earliest efforts in the statisti-
cal study of international relations, dating back to
the 1960s (Rummel, 1968; Azar and Sloan, 1975;
McClelland, 1970). Beginning in the mid-1980s,
political scientists began experimenting with au-
tomated rule-based extraction systems (Schrodt
and Gerner, 1994). These efforts culminated in
the open-source program, TABARI, which uses
pattern matching from extensive hand-developed
phrase dictionaries, combined with basic part of
speech tagging (Schrodt, 2001); a rough analogue
in the information extraction literature might be
the rule-based, finite-state FASTUS system for
MUC IE (Hobbs et al., 1997), though TABARI is
restricted to single sentence analysis. Later pro-
prietary work has apparently incorporated more
extensive NLP (e.g., sentence parsing) though
few details are available (King and Lowe, 2003).
The most recent published work we know of, by
Boschee et al. (2013), uses a proprietary parsing
and coreference system (BBN SERIF, Ramshaw
et al., 2011), and directly compares to TABARI,
finding significantly higher accuracy. The origi-
</bodyText>
<page confidence="0.985267">
1101
</page>
<bodyText confidence="0.999984833333333">
nal TABARI system is still actively being devel-
oped, including just-released work on a new 200
million event dataset, GDELT (Schrodt and Lee-
taru, 2013).14 All these systems crucially rely on
hand-built pattern dictionaries.
It is extremely labor intensive to develop these
dictionaries. Schrodt (2006) estimates 4,000
trained person-hours were required to create dic-
tionaries of political actors in the Middle East, and
the phrase dictionary took dramatically longer; the
comments in TABARI’s phrase dictionary indicate
some of its 15,789 entries were created as early as
1991. Ideally, any new events data solution would
incorporate the extensive work already completed
by political scientists in this area while minimiz-
ing the need for further dictionary development. In
this work we use the actor dictionaries, and hope
to incorporate the verb patterns in future work.
</bodyText>
<subsectionHeader confidence="0.997563">
6.2 Events in Natural Language Processing
</subsectionHeader>
<bodyText confidence="0.987736766666667">
Political event extraction from news has also re-
ceived considerable attention within natural lan-
guage processing in part due to government-
funded challenges such as MUC-3 and MUC-4
(Lehnert, 1994), which focused on the extraction
of terrorist events, as well as the more recent
ACE program. The work in this paper is inspired
by unsupervised approaches that seek to discover
types of relations and events, instead of assuming
them to be pre-specified; this includes research un-
der various headings such as template/frame/event
learning (Cheung et al., 2013; Modi et al., 2012;
Chambers and Jurafsky, 2011; Li et al., 2010; Be-
jan, 2008), script learning (Regneri et al., 2010;
Chambers and Jurafsky, 2009), relation learning
(Yao et al., 2011), open information extraction
(Banko et al., 2007; Carlson et al., 2010), verb
caseframe learning (Rooth et al., 1999; Gildea,
2002; Grenager and Manning, 2006; Lang and La-
pata, 2010; O´ S´eaghdha, 2010; Titov and Klemen-
tiev, 2012), and a version of frame learning called
“unsupervised semantic parsing” (Titov and Kle-
mentiev, 2011; Poon and Domingos, 2009). Un-
like much of the previous literature, we do not
learn latent roles/slots. Event extraction is also
a large literature, including supervised systems
targeting problems similar to MUC and political
events (Piskorski and Atkinson, 2011; Piskorski
et al., 2011; Sanfilippo et al., 2008).
One can also see this work as a relational ex-
</bodyText>
<footnote confidence="0.7167415">
14http://eventdata.psu.edu/data.dir/
GDELT.html
</footnote>
<bodyText confidence="0.9999029">
tension of co-occurence-based methods such as
Gerrish (2013; ch. 4), Diesner and Carley (2005),
Chang et al. (2009), or Newman et al. (2006),
which perform bag-of-words-style analysis of text
fragments containing co-occurring entities. (Ger-
rish also analyzed the international relations do-
main, using supervised bag-of-words regression
to assess the expressed valence between a pair
of actors in a news paragraph, using the predic-
tions as observations in a latent temporal model,
and compared to MID.) We instead use parsing to
get a much more focused and interpretable repre-
sentation of the relationship between textually co-
occurring entities; namely, that they are the source
and target of an action event. This is more in line
with work in relation extraction on biomedical sci-
entific articles (Friedman et al., 2001; Rzhetsky
et al., 2004) which uses parsing to extracting a net-
work of how different entities, like drugs or pro-
teins, interact.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999929444444445">
Large-scale information extraction can dramati-
cally enhance the study of political behavior. Here
we present a novel unsupervised approach to an
important data collection effort in the social sci-
ences. We see international relations as a rich
and practically useful domain for the development
of text analysis methods that jointly infer events,
relations, and sociopolitical context. There are
numerous areas for future work, such as: using
verb dictionaries as semi-supervised seeds or pri-
ors; interactive learning between political science
researchers and unsupervised algorithms; build-
ing low-dimensional scaling, or hierarchical struc-
ture, into the model; and learning the actor lists
to handle changing real-world situations and new
domains. In particular, adding more supervision
to the model will be crucial to improve semantic
quality and make it useful for researchers.
</bodyText>
<sectionHeader confidence="0.996996" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9969005">
Thanks to Justin Betteridge for providing the parsed Giga-
word corpus, Erin Baggott for help in developing the doc-
ument filter, and the anonymous reviewers for helpful com-
ments. This research was supported in part by NSF grant IIS-
1211277, and was made possible through the use of comput-
ing resources made available by the Pittsburgh Supercomput-
ing Center. Brandon Stewart gratefully acknowledges fund-
ing from an NSF Graduate Research Fellowship.
</bodyText>
<sectionHeader confidence="0.983087" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.310839">
Azar, E. E. and Sloan, T. (1975). Dimensions of interactions.
</bodyText>
<affiliation confidence="0.9684905">
Technical report, University Center of International Stud-
ies, University of Pittsburgh, Pittsburgh.
</affiliation>
<page confidence="0.998776">
1102
</page>
<reference confidence="0.995506159090909">
Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M.,
and Etzioni, O. (2007). Open Information Extraction from
the Web. IJCAI.
Bejan, C. A. (2008). Unsupervised discovery of event sce-
narios from texts. In Proceedings of the 21st Florida Arti-
ficial Intelligence Research Society International Confer-
ence (FLAIRS), Coconut Grove, FL, USA.
Blei, D. M. and Lafferty, J. D. (2006). Dynamic topic models.
In Proceedings of ICML.
Blei, D. M. and Lafferty, J. D. (2007). A correlated topic
model of science. Annals of Applied Statistics, 1(1), 17–
35.
Boschee, E., Natarajan, P., and Weischedel, R. (2013). Au-
tomatic extraction of events from open source text for
predictive forecasting. Handbook of Computational Ap-
proaches to Counterterrorism, page 51.
Brandt, P. T., Freeman, J. R., and Schrodt, P. A. (2011). Real
time, time series forecasting of inter-and intra-state po-
litical conflict. Conflict Management and Peace Science,
28(1), 41–64.
Brandt, P. T., Freeman, J. R., Lin, T.-m., and Schrodt, P. A.
(2012). A Bayesian time series approach to the compari-
son of conflict dynamics. In APSA 2012 Annual Meeting
Paper.
Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka,
E. R., and Mitchell, T. M. (2010). Toward an architecture
for never-ending language learning. In Proceedings of the
Conference on Artificial Intelligence (AAAI), pages 1306–
1313.
Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for
state space models. Biometrika, 81(3), 541–553.
Chambers, N. and Jurafsky, D. (2009). Unsupervised learn-
ing of narrative schemas and their participants. In Pro-
ceedings of ACL-IJCNLP. Association for Computational
Linguistics.
Chambers, N. and Jurafsky, D. (2011). Template-based infor-
mation extraction without the templates. In Proceedings
of ACL.
Chang, J., Boyd-Graber, J., and Blei, D. M. (2009). Con-
nections between the lines: augmenting social networks
with text. In Proceedings of the 15th ACM SIGKDD in-
ternational conference on Knowledge discovery and data
mining, pages 169–178. ACM.
Cheung, J. C. K., Poon, H., and Vanderwende, L. (2013).
Probabilistic frame induction. In Proceedings of NAACL.
arXiv preprint arXiv:1302.4813.
de Marneffe, M.-C. and Manning, C. D. (2008). Stanford
typed dependencies manual. Technical report, Stanford
University.
Diesner, J. and Carley, K. M. (2005). Revealing social
structure from texts: meta-matrix text analysis as a novel
method for network text analysis. In Causal mapping for
information systems and technology research, pages 81–
108. Harrisburg, PA: Idea Group Publishing.
Eisenstein, J., O’Connor, B., Smith, N. A., and Xing, E. P.
(2010). A latent variable model for geographic lexical
variation. In Proceedings of the 2010 Conference on Em-
pirical Methods in Natural Language Processing, pages
1277—1287.
Eisenstein, J., Ahmed, A., and Xing, E. (2011). Sparse ad-
ditive generative models of text. In Proceedings of ICML,
pages 1041–1048.
Friedman, C., Kra, P., Yu, H., Krauthammer, M., and Rzhet-
sky, A. (2001). GENIES: a natural-language process-
ing system for the extraction of molecular pathways from
journal articles. Bioinformatics, 17(suppl 1), S74–S82.
Friedman, J., Hastie, T., and Tibshirani, R. (2010). Regular-
ization paths for generalized linear models via coordinate
descent. Journal of Statistical Software, 33(1).
Gerner, D. J., Schrodt, P. A., Yilmaz, O., and Abu-Jabr, R.
(2002). The Creation of CAMEO (Conflict and Media-
tion Event Observations): An Event Data Framework for
a Post Cold War World. Annual Meeting of the American
Political Science Association.
Gerrish, S. M. (2013). Applications of Latent Variable Mod-
els in Modeling Influence and Decision Making. Ph.D.
thesis, Princeton University.
Gerrish, S. M. and Blei, D. M. (2011). Predicting legislative
roll calls from text. In Proceedings of ICML.
Ghosn, F., Palmer, G., and Bremer, S. A. (2004). The MID3
data set, 1993–2001: Procedures, coding rules, and de-
scription. Conflict Management and Peace Science, 21(2),
133–154.
Gildea, D. (2002). Probabilistic models of verb-argument
structure. In Proceedings of COLING.
Goldstein, J. S. (1992). A conflict-cooperation scale for
WEIS events data. Journal of Conflict Resolution, 36,
369–385.
Goldstein, J. S., Pevehouse, J. C., Gerner, D. J., and Telhami,
S. (2001). Reciprocity, triangularity, and cooperation in
the middle east, 1979-97. Journal of Conflict Resolution,
45(5), 594–620.
Grenager, T. and Manning, C. D. (2006). Unsupervised dis-
covery of a statistical verb lexicon. In Proceedings of the
2006 Conference on Empirical Methods in Natural Lan-
guage Processing, page 18.
Griffiths, T. L. and Steyvers, M. (2004). Finding scientific
topics. PNAS,101(suppl. 1), 5228–5235.
Harrison, J. and West, M. (1997). Bayesian forecasting and
dynamic models. Springer Verlag, New York.
Hobbs, J. R., Appelt, D., Bear, J., Israel, D., Kameyama,
M., Stickel, M., and Tyson, M. (1997). FASTUS: A
cascaded finite-state transducer for extracting information
from natural-language text. Finite-State Language Pro-
cessing, page 383.
Hoff, P. D. (2003). Nonparametric modeling of hierarchi-
cally exchangeable data. University of Washington Statis-
tics Department, Technical Report, 421.
Holmes, C. C. and Held, L. (2006). Bayesian auxiliary
variable models for binary and multinomial regression.
Bayesian Analysis, 1(1), 145–168.
Jones, D., Bremer, S., and Singer, J. (1996). Militarized in-
terstate disputes, 1816–1992: Rationale, coding rules, and
empirical patterns. Conflict Management and Peace Sci-
ence,15(2), 163–213.
King, G. and Lowe, W. (2003). An automated information
extraction tool for international conflict data with perfor-
mance as good as human coders: A rare events evaluation
design. International Organization, 57(3), 617–642.
Lang, J. and Lapata, M. (2010). Unsupervised induction of
semantic roles. In Human Language Technologies: The
2010 Annual Conference of the North American Chapter
of the Association for Computational Linguistics, pages
939–947. Association for Computational Linguistics.
Lehnert, W. G. (1994). Cognition, computers, and car bombs:
How Yale prepared me for the 1990s. In Beliefs, Reason-
ing, and Decision-Making. Psycho-Logic in Honor of Bob
Abelson, pages 143–173, Hillsdale, NJ, Hove, UK. Erl-
baum.http://ciir.cs.umass.edu/pubfiles/
cognition3.pdf.
Li, H., Li, X., Ji, H., and Marton, Y. (2010). Domain-
independent novel event discovery and semi-automatic
</reference>
<page confidence="0.681289">
1103
</page>
<reference confidence="0.999882198347107">
event annotation. In Proceedings of the 24th Pacific Asia
Conference on Language, Information and Computation,
Sendai, Japan, November.
Martin, A. D. and Quinn, K. M. (2002). Dynamic ideal point
estimation via Markov chain Monte Carlo for the U.S.
Supreme Court, 1953–1999. Political Analysis, 10(2),
134–153.
McClelland, C. (1970). Some effects on theory from the in-
ternational event analysis movement. Mimeo, University
of Southern California.
Mimno, D., Wallach, H., and McCallum, A. (2008). Gibbs
sampling for logistic normal topic models with graph-
based priors. In NIPS Workshop on Analyzing Graphs.
Modi, A., Titov, I., and Klementiev, A. (2012). Unsuper-
vised induction of frame-semantic representations. In Pro-
ceedings of the NAACL-HLT Workshop on the Induction of
Linguistic Structure, pages 1–7. Association for Computa-
tional Linguistics.
Murphy, K. P. (2012). Machine Learning: a Probabilistic
Perspective. MIT Press.
Neal, R. M. (2003). Slice sampling. Annals of Statistics,
pages 705–741.
Newman, D., Chemudugunta, C., and Smyth, P. (2006). Sta-
tistical entity-topic models. In Proceedings of the 12th
ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 680–686. ACM.
O´ S´eaghdha, D. (2010). Latent variable models of selectional
preference. In Proceedings of the 48th Annual Meeting
of the Association for Computational Linguistics, pages
435–444. Association for Computational Linguistics.
O’Brien, S. P. (2010). Crisis early warning and decision sup-
port: Contemporary approaches and thoughts on future re-
search. International Studies Review, 12(1), 87–104.
Parker, R., Graff, D., Kong, J., Chen, K., and Maeda, K.
(2009). English Gigaword Fourth Edition. Linguistic Data
Consortium. LDC2009T13.
Piskorski, J. and Atkinson, M. (2011). Frontex real-time
news event extraction framework. In Proceedings of the
17th ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 749–752. ACM.
Piskorski, J., Tanev, H., Atkinson, M., van der Goot, E., and
Zavarella, V. (2011). Online news event extraction for
global crisis surveillance. Transactions on computational
collective intelligence V, pages 182–212.
Polson, N. G., Scott, J. G., and Windle, J. (2012). Bayesian
inference for logistic models using Polya-Gamma latent
variables. arXiv preprint arXiv:1205.0310.
Poon, H. and Domingos, P. (2009). Unsupervised semantic
parsing. In Proceedings of EMNLP, pages 1–10. Associa-
tion for Computational Linguistics.
Quinn, K. M., Monroe, B. L., Colaresi, M., Crespin, M. H.,
and Radev, D. R. (2010). How to analyze political atten-
tion with minimal assumptions and costs. American Jour-
nal of Political Science, 54(1), 209228.
Rajaraman, A. and Ullman, J. D. (2011). Mining of mas-
sive datasets. Cambridge University Press; http://
infolab.stanford.edu/˜ullman/mmds.html.
Ramshaw, L., Boschee, E., Freedman, M., MacBride, J.,
Weischedel, R., , and Zamanian, A. (2011). SERIF lan-
guage processing effective trainable language understand-
ing. Handbook of Natural Language Processing and Ma-
chine Translation, pages 636–644.
Regneri, M., Koller, A., and Pinkal, M. (2010). Learning
script knowledge with web experiments. In Proceedings
of the 48th Annual Meeting of the Association for Compu-
tational Linguistics, ACL ’10, pages 979–988.
Rooth, M., Riezler, S., Prescher, D., Carroll, G., and Beil,
F. (1999). Inducing a semantically annotated lexicon via
EM-based clustering. In Proceedings of the 37th annual
meeting of the Association for Computational Linguistics
on Computational Linguistics, page 104111.
Rummel, R. (1968). The Dimensionality of Nations project.
Rzhetsky, A., Iossifov, I., Koike, T., Krauthammer, M., Kra,
P., Morris, M., Yu, H., Dubou´e, P. A., Weng, W., Wilbur,
W. J., Hatzivassiloglou, V., and Friedman, C. (2004).
GeneWays: a system for extracting, analyzing, visualiz-
ing, and integrating molecular pathway data. Journal of
Biomedical Informatics, 37(1), 43–53.
Sandhaus, E. (2008). The New York Times Annotated Cor-
pus. Linguistic Data Consortium. LDC2008T19.
Sanfilippo, A., Franklin, L., Tratz, S., Danielson, G., Mile-
son, N., Riensche, R., and McGrath, L. (2008). Automat-
ing frame analysis. Social computing, behavioral model-
ing, and prediction, pages 239–248.
Schrodt, P. (2012). Precedents, progress, and prospects in po-
litical event data. International Interactions, 38(4), 546–
569.
Schrodt, P. and Leetaru, K. (2013). GDELT: Global data
on events, location and tone, 1979-2012. In International
Studies Association Conference.
Schrodt, P. A. (2001). Automated coding of international
event data using sparse parsing techniques. International
Studies Association Conference.
Schrodt, P. A. (2006). Twenty Years of the Kansas Event
Data System Project. Political Methodologist.
Schrodt, P. A. and Gerner, D. J. (1994). Validity assessment
of a machine-coded event data set for the Middle East,
1982-1992. American Journal of Political Science.
Schrodt, P. A. and Gerner, D. J. (2004). An event data analy-
sis of third-party mediation in the middle east and balkans.
Journal of Conflict Resolution, 48(3), 310–330.
Shellman, S. M. (2004). Time series intervals and statistical
inference: The effects of temporal aggregation on event
data analysis. Political Analysis, 12(1), 97–104.
Titov, I. and Klementiev, A. (2011). A Bayesian model for
unsupervised semantic parsing. In Proceedings of ACL.
Titov, I. and Klementiev, A. (2012). A Bayesian approach
to unsupervised semantic role induction. Proceedings of
EACL.
Wallach, H., Mimno, D., and McCallum, A. (2009). Rethink-
ing lda: Why priors matter. Advances in Neural Informa-
tion Processing Systems, 22, 1973–1981.
Yao, L., Haghighi, A., Riedel, S., and McCallum, A. (2011).
Structured relation discovery using generative models. In
Proceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 1456–1466. Associ-
ation for Computational Linguistics.
Zeger, S. L. and Karim, M. R. (1991). Generalized linear
models with random effects; a Gibbs sampling approach.
Journal of the American Statistical Association, 86(413),
79–86.
</reference>
<page confidence="0.997828">
1104
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.435933">
<title confidence="0.999631">Learning to Extract International Relations from Political Context</title>
<author confidence="0.999967">Brendan O’Connor Brandon M Stewart Noah A Smith</author>
<affiliation confidence="0.999823">School of Computer Science Department of Government School of Computer Science Carnegie Mellon University Harvard University Carnegie Mellon</affiliation>
<address confidence="0.973839">Pittsburgh, PA 15213, USA Cambridge, MA 02139, USA Pittsburgh, PA 15213, USA</address>
<email confidence="0.999647">brenocon@cs.cmu.edubstewart@fas.harvard.edunasmith@cs.cmu.edu</email>
<abstract confidence="0.965915111111111">We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at:</abstract>
<web confidence="0.672938">http://brenocon.com/irevents</web>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Banko</author>
<author>M J Cafarella</author>
<author>S Soderland</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open Information Extraction from the Web. IJCAI.</booktitle>
<contexts>
<context position="36647" citStr="Banko et al., 2007" startWordPosition="5943" endWordPosition="5946">d MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One </context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., and Etzioni, O. (2007). Open Information Extraction from the Web. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C A Bejan</author>
</authors>
<title>Unsupervised discovery of event scenarios from texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the 21st Florida Artificial Intelligence Research Society International Conference (FLAIRS), Coconut</booktitle>
<location>Grove, FL, USA.</location>
<contexts>
<context position="36491" citStr="Bejan, 2008" startWordPosition="5921" endWordPosition="5923">tion from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including sup</context>
</contexts>
<marker>Bejan, 2008</marker>
<rawString>Bejan, C. A. (2008). Unsupervised discovery of event scenarios from texts. In Proceedings of the 21st Florida Artificial Intelligence Research Society International Conference (FLAIRS), Coconut Grove, FL, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>J D Lafferty</author>
</authors>
<title>Dynamic topic models.</title>
<date>2006</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="13419" citStr="Blei and Lafferty, 2006" startWordPosition="2158" endWordPosition="2161">, Q2k) Other parameters (αk, Q2k) are same as the vanilla model. This model assumes a random walk process on β, a variable which exists even for contexts that contain no events. Thus inferences about q will be smoothed according to event data at nearby timesteps. This is an instance of a linear Gaussian state-space model (also known as a linear dynamical system or dynamic linear model), and is a convenient formulation because it has well-known exact inference algorithms. Dynamic linear models have been used elsewhere in machine learning and political science to allow latent topic frequencies (Blei and Lafferty, 2006; Quinn et al., 2010) and ideological positions (Martin and Quinn, 2002) to smoothly change over time, and thus share statistical strength between timesteps. 4 Inference After randomly initializing all qk,s,r,t, inference is performed by a blocked Gibbs sampler, alternating resamplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), </context>
</contexts>
<marker>Blei, Lafferty, 2006</marker>
<rawString>Blei, D. M. and Lafferty, J. D. (2006). Dynamic topic models. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>J D Lafferty</author>
</authors>
<title>A correlated topic model of science.</title>
<date>2007</date>
<journal>Annals of Applied Statistics,</journal>
<volume>1</volume>
<issue>1</issue>
<pages>35</pages>
<contexts>
<context position="14689" citStr="Blei and Lafferty (2007)" startWordPosition="2364" endWordPosition="2367">ts n are for all event tuples besides i. For the context model, α is conjugate resampled as a normal mean. The random walk variables β are sampled with the forward-filteringbackward-sampling algorithm (FFBS; Harrison and West, 1997; Carter and Kohn, 1994); there is one slight modification of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (</context>
</contexts>
<marker>Blei, Lafferty, 2007</marker>
<rawString>Blei, D. M. and Lafferty, J. D. (2007). A correlated topic model of science. Annals of Applied Statistics, 1(1), 17– 35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Boschee</author>
<author>P Natarajan</author>
<author>R Weischedel</author>
</authors>
<title>Automatic extraction of events from open source text for predictive forecasting. Handbook of Computational Approaches to Counterterrorism,</title>
<date>2013</date>
<pages>51</pages>
<contexts>
<context position="34770" citStr="Boschee et al. (2013)" startWordPosition="5654" endWordPosition="5657">). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013).14 All these systems crucially rely on hand-built pattern dictionaries. It is extremely labor intensive to develop these dictionaries. Schrodt (2006) estimates 4,000 trained person-hours were required to create dictionaries of political actors in the Middle East, and the phr</context>
</contexts>
<marker>Boschee, Natarajan, Weischedel, 2013</marker>
<rawString>Boschee, E., Natarajan, P., and Weischedel, R. (2013). Automatic extraction of events from open source text for predictive forecasting. Handbook of Computational Approaches to Counterterrorism, page 51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P T Brandt</author>
<author>J R Freeman</author>
<author>P A Schrodt</author>
</authors>
<title>Real time, time series forecasting of inter-and intra-state political conflict.</title>
<date>2011</date>
<journal>Conflict Management and Peace Science,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>41--64</pages>
<contexts>
<context position="20283" citStr="Brandt et al., 2011" startWordPosition="3274" endWordPosition="3277">zed null hypothesis to see how low impurity can be by chance: each of —1000 simulations randomly assigns each path in M to one of K frames (all its instances are exclusively assigned to that frame), and computes the impurity. On average the impurity is same at all K, but variance increases with K (since small clusters might by chance get a highly similar paths in them), necessitating this null hypothesis analysis. We report the 5th percentile over simulations. 5.2 Conflict Detection Political events data has shown considerable promise as a tool for crisis early warning systems (O’Brien, 2010; Brandt et al., 2011). While conflict forecasting is a potential application of our model, we conduct a simpler prediction task to validate whether the model is learning something useful: based on news text, tell whether or not an armed conflict is currently happening. For a gold standard, we use the Militarized Interstate Dispute (MID) dataset (Jones et al., 1996; Ghosn et al., 2004), which documents historical international disputes. While not without critics, the MID data is the most prominent dataset in the field of international relations. We use the Dyadic MIDs, each of which ranks hostility levels between p</context>
</contexts>
<marker>Brandt, Freeman, Schrodt, 2011</marker>
<rawString>Brandt, P. T., Freeman, J. R., and Schrodt, P. A. (2011). Real time, time series forecasting of inter-and intra-state political conflict. Conflict Management and Peace Science, 28(1), 41–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P T Brandt</author>
<author>J R Freeman</author>
<author>T-m Lin</author>
<author>P A Schrodt</author>
</authors>
<title>A Bayesian time series approach to the comparison of conflict dynamics.</title>
<date>2012</date>
<booktitle>In APSA 2012 Annual Meeting Paper.</booktitle>
<contexts>
<context position="28542" citStr="Brandt et al., 2012" startWordPosition="4623" endWordPosition="4626">osite of the conflict detection task). This suggests that semantic coherence does not benefit from the longer13In the latter, a problem-specific topic model did best. range temporal dependencies. In general, performance improves with higher K, but not beyond K = 50. This suggests the model reaches a limit for how fine-grained of semantics it can learn. 5.4 Case study Here we qualitatively examine the narrative story between the dyad with the highest frequency of events in our dataset, the Israeli-Palestinian relationship, finding qualitative agreement with other case studies of this conflict (Brandt et al., 2012; Goldstein et al., 2001; Schrodt and Gerner, 2004). (The MID dataset does not include this conflict because the Palestinians are not considered a state actor.) Using the Associated Press subset, we plot the highest incidence frames from one run of the K = 20 smoothed frame models, for the two directed dyads, and highlight some of the interesting relationships. Figure 4(a) shows that tradeoffs in the use of military vs. police action by Israel towards the Palestinians tracks with major historical events. The first period in the data where police actions (‘impose, seal, capture, seize, arrest’)</context>
</contexts>
<marker>Brandt, Freeman, Lin, Schrodt, 2012</marker>
<rawString>Brandt, P. T., Freeman, J. R., Lin, T.-m., and Schrodt, P. A. (2012). A Bayesian time series approach to the comparison of conflict dynamics. In APSA 2012 Annual Meeting Paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>J Betteridge</author>
<author>B Kisiel</author>
<author>B Settles</author>
<author>E R Hruschka</author>
<author>T M Mitchell</author>
</authors>
<title>Toward an architecture for never-ending language learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>1306--1313</pages>
<contexts>
<context position="36670" citStr="Carlson et al., 2010" startWordPosition="5947" endWordPosition="5950">94), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work </context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Hruschka, Mitchell, 2010</marker>
<rawString>Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka, E. R., and Mitchell, T. M. (2010). Toward an architecture for never-ending language learning. In Proceedings of the Conference on Artificial Intelligence (AAAI), pages 1306– 1313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K Carter</author>
<author>R Kohn</author>
</authors>
<title>On Gibbs sampling for state space models.</title>
<date>1994</date>
<journal>Biometrika,</journal>
<volume>81</volume>
<issue>3</issue>
<pages>541--553</pages>
<contexts>
<context position="14320" citStr="Carter and Kohn, 1994" startWordPosition="2304" endWordPosition="2307">mplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + b/V)/(nz + b), where counts n are for all event tuples besides i. For the context model, α is conjugate resampled as a normal mean. The random walk variables β are sampled with the forward-filteringbackward-sampling algorithm (FFBS; Harrison and West, 1997; Carter and Kohn, 1994); there is one slight modification of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable </context>
</contexts>
<marker>Carter, Kohn, 1994</marker>
<rawString>Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika, 81(3), 541–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>D Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="36560" citStr="Chambers and Jurafsky, 2009" startWordPosition="5930" endWordPosition="5933">on within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political event</context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Chambers, N. and Jurafsky, D. (2009). Unsupervised learning of narrative schemas and their participants. In Proceedings of ACL-IJCNLP. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>D Jurafsky</author>
</authors>
<title>Template-based information extraction without the templates.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="36460" citStr="Chambers and Jurafsky, 2011" startWordPosition="5913" endWordPosition="5916">ral Language Processing Political event extraction from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a </context>
</contexts>
<marker>Chambers, Jurafsky, 2011</marker>
<rawString>Chambers, N. and Jurafsky, D. (2011). Template-based information extraction without the templates. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chang</author>
<author>J Boyd-Graber</author>
<author>D M Blei</author>
</authors>
<title>Connections between the lines: augmenting social networks with text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>169--178</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="37451" citStr="Chang et al. (2009)" startWordPosition="6065" endWordPosition="6068">nd a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We instead use parsing to get a much more focused and interpretable representation of the relationship between textually cooccurring entities; namely, that they are the source and target of an action event. This i</context>
</contexts>
<marker>Chang, Boyd-Graber, Blei, 2009</marker>
<rawString>Chang, J., Boyd-Graber, J., and Blei, D. M. (2009). Connections between the lines: augmenting social networks with text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 169–178. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C K Cheung</author>
<author>H Poon</author>
<author>L Vanderwende</author>
</authors>
<title>Probabilistic frame induction.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL. arXiv preprint arXiv:1302.4813.</booktitle>
<contexts>
<context position="36412" citStr="Cheung et al., 2013" startWordPosition="5905" endWordPosition="5908">terns in future work. 6.2 Events in Natural Language Processing Political event extraction from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn</context>
</contexts>
<marker>Cheung, Poon, Vanderwende, 2013</marker>
<rawString>Cheung, J. C. K., Poon, H., and Vanderwende, L. (2013). Probabilistic frame induction. In Proceedings of NAACL. arXiv preprint arXiv:1302.4813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C de Marneffe</author>
<author>C D Manning</author>
</authors>
<title>Stanford typed dependencies manual.</title>
<date>2008</date>
<tech>Technical report,</tech>
<institution>Stanford University.</institution>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>de Marneffe, M.-C. and Manning, C. D. (2008). Stanford typed dependencies manual. Technical report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Diesner</author>
<author>K M Carley</author>
</authors>
<title>Revealing social structure from texts: meta-matrix text analysis as a novel method for network text analysis. In Causal mapping for information systems and technology research,</title>
<date>2005</date>
<pages>81--108</pages>
<publisher>Idea Group Publishing.</publisher>
<location>Harrisburg, PA:</location>
<contexts>
<context position="37430" citStr="Diesner and Carley (2005)" startWordPosition="6061" endWordPosition="6064">ov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We instead use parsing to get a much more focused and interpretable representation of the relationship between textually cooccurring entities; namely, that they are the source and target of an</context>
</contexts>
<marker>Diesner, Carley, 2005</marker>
<rawString>Diesner, J. and Carley, K. M. (2005). Revealing social structure from texts: meta-matrix text analysis as a novel method for network text analysis. In Causal mapping for information systems and technology research, pages 81– 108. Harrisburg, PA: Idea Group Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisenstein</author>
<author>B O’Connor</author>
<author>N A Smith</author>
<author>E P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1277--1287</pages>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Eisenstein, J., O’Connor, B., Smith, N. A., and Xing, E. P. (2010). A latent variable model for geographic lexical variation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1277—1287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisenstein</author>
<author>A Ahmed</author>
<author>E Xing</author>
</authors>
<title>Sparse additive generative models of text.</title>
<date>2011</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>1041--1048</pages>
<contexts>
<context position="15396" citStr="Eisenstein et al. (2011)" startWordPosition="2476" endWordPosition="2479">th different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute Cholesky root of the covariance matrix. This q* sample is a proposal for a Metropolis-within-Gibbs step, which is moved to according to the standard Metropolis-Hastings acceptance rule. Acceptance rates differ by K, ranging approximately from 30% (K = 100) to nearly 100% (small K). Finally, we use diffuse priors on all global parameters, conjugate resampling variances T2, Qk once per iteration, and sl</context>
</contexts>
<marker>Eisenstein, Ahmed, Xing, 2011</marker>
<rawString>Eisenstein, J., Ahmed, A., and Xing, E. (2011). Sparse additive generative models of text. In Proceedings of ICML, pages 1041–1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>P Kra</author>
<author>H Yu</author>
<author>M Krauthammer</author>
<author>A Rzhetsky</author>
</authors>
<title>GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles.</title>
<date>2001</date>
<journal>Bioinformatics,</journal>
<volume>17</volume>
<pages>74--82</pages>
<contexts>
<context position="38155" citStr="Friedman et al., 2001" startWordPosition="6175" endWordPosition="6178">nts containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We instead use parsing to get a much more focused and interpretable representation of the relationship between textually cooccurring entities; namely, that they are the source and target of an action event. This is more in line with work in relation extraction on biomedical scientific articles (Friedman et al., 2001; Rzhetsky et al., 2004) which uses parsing to extracting a network of how different entities, like drugs or proteins, interact. 7 Conclusion Large-scale information extraction can dramatically enhance the study of political behavior. Here we present a novel unsupervised approach to an important data collection effort in the social sciences. We see international relations as a rich and practically useful domain for the development of text analysis methods that jointly infer events, relations, and sociopolitical context. There are numerous areas for future work, such as: using verb dictionaries</context>
</contexts>
<marker>Friedman, Kra, Yu, Krauthammer, Rzhetsky, 2001</marker>
<rawString>Friedman, C., Kra, P., Yu, H., Krauthammer, M., and Rzhetsky, A. (2001). GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles. Bioinformatics, 17(suppl 1), S74–S82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Friedman</author>
<author>T Hastie</author>
<author>R Tibshirani</author>
</authors>
<title>Regularization paths for generalized linear models via coordinate descent.</title>
<date>2010</date>
<journal>Journal of Statistical Software,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="25695" citStr="Friedman et al., 2010" startWordPosition="4150" endWordPosition="4153"> an example of individual lexical features outperforming a topic model for predictive task, because the topic model’s dimension reduction obscures important indicators from individual words. Similarly, Gerrish and Blei (2011) found that word-based regression outperformed a customized topic model when predicting Congressional bill passage, and Eisen9AUC can be interpreted as follows: given a positive and negative example, what is the probability that the classifier’s confidences order them correctly? Random noise or predicting all the same class both give AUC 0.5. 10Using the R glmnet package (Friedman et al., 2010). 11For the vanilla model, this performed better than linear interpolation (about 0.03 AUC), and with less variance between runs. 12Due to an implementation bug, the model put the vast majority of the probability mass only on K − 1 frames, so these settings might be better thought of as K = 1, 2, 3, 4, 9, ...; see the appendix for details. 1995 1996 1997 1998 1999 2000 2001 2002 0.0 0.4 0.8 0.0 0.4 0.8 1995 1996 1997 1998 1999 2000 2001 2002 kill, fire at, seal, invade, enter accuse, criticize, warn, reject, urge accuse, reject, blame, kill, take criticize, call, ask, condemn denounce USA to I</context>
</contexts>
<marker>Friedman, Hastie, Tibshirani, 2010</marker>
<rawString>Friedman, J., Hastie, T., and Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. Journal of Statistical Software, 33(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Gerner</author>
<author>P A Schrodt</author>
<author>O Yilmaz</author>
<author>R Abu-Jabr</author>
</authors>
<title>The Creation of CAMEO (Conflict and Mediation Event Observations): An Event Data Framework for a Post Cold War World. Annual Meeting of the American Political Science Association.</title>
<date>2002</date>
<contexts>
<context position="17124" citStr="Gerner et al., 2002" startWordPosition="2749" endWordPosition="2752">eparate runs for each setting. Posteriors are saved and averaged from 11 Gibbs samples (every 100 iterations from 9,000 to 10,000) for analysis. We present intrinsic (§5.1) and extrinsic (§5.2) quantitative evaluations, and a qualitative case study (§5.4). 5.1 Lexical Scale Impurity In the international relations literature, much of the analysis of text-based events data makes use of a unidimensional conflict to cooperation scale. A popular event ontology in this domain, CAMEO, consists of around 300 different event types, each 1097 given an expert-assigned scale in the range from —10 to +10 (Gerner et al., 2002), derived from a judgement collection experiment in Goldstein (1992). The TABARI pattern-based event extraction program comes with a list of almost 16,000 manually engineered verb patterns, each assigned to one CAMEO event type. It is interesting to consider the extent to which our unsupervised model is able to recover the expert-designed ontology. Given that many of the categories are very fine-grained (e.g. “Express intent to de-escalate military engagement”), we elect to measure model quality as lexical scale purity: whether all the predicate paths within one automatically learned frame ten</context>
</contexts>
<marker>Gerner, Schrodt, Yilmaz, Abu-Jabr, 2002</marker>
<rawString>Gerner, D. J., Schrodt, P. A., Yilmaz, O., and Abu-Jabr, R. (2002). The Creation of CAMEO (Conflict and Mediation Event Observations): An Event Data Framework for a Post Cold War World. Annual Meeting of the American Political Science Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Gerrish</author>
</authors>
<title>Applications of Latent Variable Models in Modeling Influence and Decision Making.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>Princeton University.</institution>
<contexts>
<context position="37395" citStr="Gerrish (2013" startWordPosition="6057" endWordPosition="6058">O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We instead use parsing to get a much more focused and interpretable representation of the relationship between textually cooccurring entities; namely, that t</context>
</contexts>
<marker>Gerrish, 2013</marker>
<rawString>Gerrish, S. M. (2013). Applications of Latent Variable Models in Modeling Influence and Decision Making. Ph.D. thesis, Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Gerrish</author>
<author>D M Blei</author>
</authors>
<title>Predicting legislative roll calls from text.</title>
<date>2011</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="25298" citStr="Gerrish and Blei (2011)" startWordPosition="4087" endWordPosition="4091">model, contexts with no events are given a feature vector of all zeros.11 (We also explored an alternative evaluation setup, to hold out by dyad; however, the performance variance is quite high between different random dyad splits.) 5.3 Results Results are shown in Figure 3.12 The verb-path logistic regression performs strongly at AUC 0.62; it outperforms all of the vanilla frame models. This is an example of individual lexical features outperforming a topic model for predictive task, because the topic model’s dimension reduction obscures important indicators from individual words. Similarly, Gerrish and Blei (2011) found that word-based regression outperformed a customized topic model when predicting Congressional bill passage, and Eisen9AUC can be interpreted as follows: given a positive and negative example, what is the probability that the classifier’s confidences order them correctly? Random noise or predicting all the same class both give AUC 0.5. 10Using the R glmnet package (Friedman et al., 2010). 11For the vanilla model, this performed better than linear interpolation (about 0.03 AUC), and with less variance between runs. 12Due to an implementation bug, the model put the vast majority of the pr</context>
</contexts>
<marker>Gerrish, Blei, 2011</marker>
<rawString>Gerrish, S. M. and Blei, D. M. (2011). Predicting legislative roll calls from text. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ghosn</author>
<author>G Palmer</author>
<author>S A Bremer</author>
</authors>
<title>The MID3 data set, 1993–2001: Procedures, coding rules, and description.</title>
<date>2004</date>
<journal>Conflict Management and Peace Science,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>133--154</pages>
<contexts>
<context position="20649" citStr="Ghosn et al., 2004" startWordPosition="3334" endWordPosition="3337">hem), necessitating this null hypothesis analysis. We report the 5th percentile over simulations. 5.2 Conflict Detection Political events data has shown considerable promise as a tool for crisis early warning systems (O’Brien, 2010; Brandt et al., 2011). While conflict forecasting is a potential application of our model, we conduct a simpler prediction task to validate whether the model is learning something useful: based on news text, tell whether or not an armed conflict is currently happening. For a gold standard, we use the Militarized Interstate Dispute (MID) dataset (Jones et al., 1996; Ghosn et al., 2004), which documents historical international disputes. While not without critics, the MID data is the most prominent dataset in the field of international relations. We use the Dyadic MIDs, each of which ranks hostility levels between pairs of actors on a five point scale over a date interval; we define conflict to be the top two categories “Use of Force” (4) and “War” (5). We convert the data into a variable ys,r,t, the highest hostility level reached by actor s directed towards receiver r in the dispute that overlaps with our 7-day interval t, and want to predict the binary indicator 1{ys,r,t </context>
</contexts>
<marker>Ghosn, Palmer, Bremer, 2004</marker>
<rawString>Ghosn, F., Palmer, G., and Bremer, S. A. (2004). The MID3 data set, 1993–2001: Procedures, coding rules, and description. Conflict Management and Peace Science, 21(2), 133–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
</authors>
<title>Probabilistic models of verb-argument structure.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="36729" citStr="Gildea, 2002" startWordPosition="5958" endWordPosition="5959"> the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDEL</context>
</contexts>
<marker>Gildea, 2002</marker>
<rawString>Gildea, D. (2002). Probabilistic models of verb-argument structure. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Goldstein</author>
</authors>
<title>A conflict-cooperation scale for WEIS events data.</title>
<date>1992</date>
<journal>Journal of Conflict Resolution,</journal>
<volume>36</volume>
<pages>369--385</pages>
<contexts>
<context position="17192" citStr="Goldstein (1992)" startWordPosition="2760" endWordPosition="2761"> Gibbs samples (every 100 iterations from 9,000 to 10,000) for analysis. We present intrinsic (§5.1) and extrinsic (§5.2) quantitative evaluations, and a qualitative case study (§5.4). 5.1 Lexical Scale Impurity In the international relations literature, much of the analysis of text-based events data makes use of a unidimensional conflict to cooperation scale. A popular event ontology in this domain, CAMEO, consists of around 300 different event types, each 1097 given an expert-assigned scale in the range from —10 to +10 (Gerner et al., 2002), derived from a judgement collection experiment in Goldstein (1992). The TABARI pattern-based event extraction program comes with a list of almost 16,000 manually engineered verb patterns, each assigned to one CAMEO event type. It is interesting to consider the extent to which our unsupervised model is able to recover the expert-designed ontology. Given that many of the categories are very fine-grained (e.g. “Express intent to de-escalate military engagement”), we elect to measure model quality as lexical scale purity: whether all the predicate paths within one automatically learned frame tend to have similar gold-standard scale scores. (This measures cluster</context>
</contexts>
<marker>Goldstein, 1992</marker>
<rawString>Goldstein, J. S. (1992). A conflict-cooperation scale for WEIS events data. Journal of Conflict Resolution, 36, 369–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Goldstein</author>
<author>J C Pevehouse</author>
<author>D J Gerner</author>
<author>S Telhami</author>
</authors>
<title>Reciprocity, triangularity, and cooperation in the middle east,</title>
<date>2001</date>
<journal>Journal of Conflict Resolution,</journal>
<volume>45</volume>
<issue>5</issue>
<pages>594--620</pages>
<contexts>
<context position="28566" citStr="Goldstein et al., 2001" startWordPosition="4627" endWordPosition="4630"> detection task). This suggests that semantic coherence does not benefit from the longer13In the latter, a problem-specific topic model did best. range temporal dependencies. In general, performance improves with higher K, but not beyond K = 50. This suggests the model reaches a limit for how fine-grained of semantics it can learn. 5.4 Case study Here we qualitatively examine the narrative story between the dyad with the highest frequency of events in our dataset, the Israeli-Palestinian relationship, finding qualitative agreement with other case studies of this conflict (Brandt et al., 2012; Goldstein et al., 2001; Schrodt and Gerner, 2004). (The MID dataset does not include this conflict because the Palestinians are not considered a state actor.) Using the Associated Press subset, we plot the highest incidence frames from one run of the K = 20 smoothed frame models, for the two directed dyads, and highlight some of the interesting relationships. Figure 4(a) shows that tradeoffs in the use of military vs. police action by Israel towards the Palestinians tracks with major historical events. The first period in the data where police actions (‘impose, seal, capture, seize, arrest’) exceed military actions</context>
</contexts>
<marker>Goldstein, Pevehouse, Gerner, Telhami, 2001</marker>
<rawString>Goldstein, J. S., Pevehouse, J. C., Gerner, D. J., and Telhami, S. (2001). Reciprocity, triangularity, and cooperation in the middle east, 1979-97. Journal of Conflict Resolution, 45(5), 594–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Grenager</author>
<author>C D Manning</author>
</authors>
<title>Unsupervised discovery of a statistical verb lexicon.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>18</pages>
<contexts>
<context position="36757" citStr="Grenager and Manning, 2006" startWordPosition="5960" endWordPosition="5963">nt ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occuren</context>
</contexts>
<marker>Grenager, Manning, 2006</marker>
<rawString>Grenager, T. and Manning, C. D. (2006). Unsupervised discovery of a statistical verb lexicon. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, page 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Griffiths</author>
<author>M Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<volume>101</volume>
<pages>5228--5235</pages>
<contexts>
<context position="14001" citStr="Griffiths and Steyvers (2004)" startWordPosition="2250" endWordPosition="2253">tent topic frequencies (Blei and Lafferty, 2006; Quinn et al., 2010) and ideological positions (Martin and Quinn, 2002) to smoothly change over time, and thus share statistical strength between timesteps. 4 Inference After randomly initializing all qk,s,r,t, inference is performed by a blocked Gibbs sampler, alternating resamplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + b/V)/(nz + b), where counts n are for all event tuples besides i. For the context model, α is conjugate resampled as a normal mean. The random walk variables β are sampled with the forward-filteringbackward-sampling algorithm (FFBS; Harrison and West, 1997; Carter and Kohn, 1994); there is one slight modification of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Lo</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Griffiths, T. L. and Steyvers, M. (2004). Finding scientific topics. PNAS,101(suppl. 1), 5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Harrison</author>
<author>M West</author>
</authors>
<title>Bayesian forecasting and dynamic models.</title>
<date>1997</date>
<publisher>Springer Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="14296" citStr="Harrison and West, 1997" startWordPosition="2300" endWordPosition="2303">sampler, alternating resamplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + b/V)/(nz + b), where counts n are for all event tuples besides i. For the context model, α is conjugate resampled as a normal mean. The random walk variables β are sampled with the forward-filteringbackward-sampling algorithm (FFBS; Harrison and West, 1997; Carter and Kohn, 1994); there is one slight modification of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible u</context>
</contexts>
<marker>Harrison, West, 1997</marker>
<rawString>Harrison, J. and West, M. (1997). Bayesian forecasting and dynamic models. Springer Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
<author>D Appelt</author>
<author>J Bear</author>
<author>D Israel</author>
<author>M Kameyama</author>
<author>M Stickel</author>
<author>M Tyson</author>
</authors>
<title>FASTUS: A cascaded finite-state transducer for extracting information from natural-language text. Finite-State Language Processing,</title>
<date>1997</date>
<pages>383</pages>
<contexts>
<context position="34493" citStr="Hobbs et al., 1997" startWordPosition="5611" endWordPosition="5614">s in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975; McClelland, 1970). Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Israel, Kameyama, Stickel, Tyson, 1997</marker>
<rawString>Hobbs, J. R., Appelt, D., Bear, J., Israel, D., Kameyama, M., Stickel, M., and Tyson, M. (1997). FASTUS: A cascaded finite-state transducer for extracting information from natural-language text. Finite-State Language Processing, page 383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Hoff</author>
</authors>
<title>Nonparametric modeling of hierarchically exchangeable data.</title>
<date>2003</date>
<tech>Technical Report, 421.</tech>
<institution>University of Washington Statistics Department,</institution>
<contexts>
<context position="15118" citStr="Hoff (2003)" startWordPosition="2435" endWordPosition="2436">le this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute Cholesky root of the covariance matrix. This q* sample is a proposal for a Metropolis-within-Gibbs step, which is moved to acc</context>
</contexts>
<marker>Hoff, 2003</marker>
<rawString>Hoff, P. D. (2003). Nonparametric modeling of hierarchically exchangeable data. University of Washington Statistics Department, Technical Report, 421.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Holmes</author>
<author>L Held</author>
</authors>
<title>Bayesian auxiliary variable models for binary and multinomial regression.</title>
<date>2006</date>
<journal>Bayesian Analysis,</journal>
<volume>1</volume>
<issue>1</issue>
<pages>145--168</pages>
<contexts>
<context position="14970" citStr="Holmes and Held, 2006" startWordPosition="2407" endWordPosition="2410">ation of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a </context>
</contexts>
<marker>Holmes, Held, 2006</marker>
<rawString>Holmes, C. C. and Held, L. (2006). Bayesian auxiliary variable models for binary and multinomial regression. Bayesian Analysis, 1(1), 145–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jones</author>
<author>S Bremer</author>
<author>J Singer</author>
</authors>
<title>Militarized interstate disputes, 1816–1992: Rationale, coding rules, and empirical patterns.</title>
<date>1996</date>
<booktitle>Conflict Management and Peace Science,15(2),</booktitle>
<pages>163--213</pages>
<contexts>
<context position="3015" citStr="Jones et al., 1996" startWordPosition="434" endWordPosition="437">each point in time. We use syntactic preprocessing and a logistic normal topic model, including latent temporal smoothing on the political context prior. We apply the model in a series of comparisons to benchmark datasets in political science. First, we compare the automatically learned verb classes to a pre-existing ontology and hand-crafted verb patterns from TABARI,1 an open-source and widely used rule-based event extraction system for this domain. Second, we demonstrate correlation to a database of real-world international conflict events, the Militarized Interstate Dispute (MID) dataset (Jones et al., 1996). Third, we qualitatively examine a prominent case not included in the MID dataset, Israeli-Palestinian relations, and compare the recovered trends to the historical record. We outline the data used for event discovery (§2), describe our model (§3), inference (§4), evaluation (§5), and comment on related work (§6). 2 Data The model we describe in §3 is learned from a corpus of 6.5 million newswire articles from the English Gigaword 4th edition (1994–2008, Parker et al., 2009). We also supplement it with a sample of data from the New York Times Annotated Corpus (1987–2007, Sandhaus, 2008).2 The</context>
<context position="20628" citStr="Jones et al., 1996" startWordPosition="3330" endWordPosition="3333">y similar paths in them), necessitating this null hypothesis analysis. We report the 5th percentile over simulations. 5.2 Conflict Detection Political events data has shown considerable promise as a tool for crisis early warning systems (O’Brien, 2010; Brandt et al., 2011). While conflict forecasting is a potential application of our model, we conduct a simpler prediction task to validate whether the model is learning something useful: based on news text, tell whether or not an armed conflict is currently happening. For a gold standard, we use the Militarized Interstate Dispute (MID) dataset (Jones et al., 1996; Ghosn et al., 2004), which documents historical international disputes. While not without critics, the MID data is the most prominent dataset in the field of international relations. We use the Dyadic MIDs, each of which ranks hostility levels between pairs of actors on a five point scale over a date interval; we define conflict to be the top two categories “Use of Force” (4) and “War” (5). We convert the data into a variable ys,r,t, the highest hostility level reached by actor s directed towards receiver r in the dispute that overlaps with our 7-day interval t, and want to predict the binar</context>
</contexts>
<marker>Jones, Bremer, Singer, 1996</marker>
<rawString>Jones, D., Bremer, S., and Singer, J. (1996). Militarized interstate disputes, 1816–1992: Rationale, coding rules, and empirical patterns. Conflict Management and Peace Science,15(2), 163–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G King</author>
<author>W Lowe</author>
</authors>
<title>An automated information extraction tool for international conflict data with performance as good as human coders: A rare events evaluation design.</title>
<date>2003</date>
<journal>International Organization,</journal>
<volume>57</volume>
<issue>3</issue>
<pages>617--642</pages>
<contexts>
<context position="34701" citStr="King and Lowe, 2003" startWordPosition="5641" endWordPosition="5644">th automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013).14 All these systems crucially rely on hand-built pattern dictionaries. It is extremely labor intensive to develop these dictionaries. Schrodt (2006) estimates 4,000 trained person-hours were required to cr</context>
</contexts>
<marker>King, Lowe, 2003</marker>
<rawString>King, G. and Lowe, W. (2003). An automated information extraction tool for international conflict data with performance as good as human coders: A rare events evaluation design. International Organization, 57(3), 617–642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lang</author>
<author>M Lapata</author>
</authors>
<title>Unsupervised induction of semantic roles.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>939--947</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36780" citStr="Lang and Lapata, 2010" startWordPosition="5964" endWordPosition="5968">this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such a</context>
</contexts>
<marker>Lang, Lapata, 2010</marker>
<rawString>Lang, J. and Lapata, M. (2010). Unsupervised induction of semantic roles. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 939–947. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Lehnert</author>
</authors>
<title>Cognition, computers, and car bombs: How Yale prepared me for the 1990s.</title>
<date>1994</date>
<booktitle>In Beliefs, Reasoning, and Decision-Making. Psycho-Logic in Honor of Bob Abelson,</booktitle>
<pages>143--173</pages>
<location>Hillsdale, NJ, Hove, UK.</location>
<note>Erlbaum.http://ciir.cs.umass.edu/pubfiles/ cognition3.pdf.</note>
<contexts>
<context position="36052" citStr="Lehnert, 1994" startWordPosition="5850" endWordPosition="5851">rase dictionary indicate some of its 15,789 entries were created as early as 1991. Ideally, any new events data solution would incorporate the extensive work already completed by political scientists in this area while minimizing the need for further dictionary development. In this work we use the actor dictionaries, and hope to incorporate the verb patterns in future work. 6.2 Events in Natural Language Processing Political event extraction from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Car</context>
</contexts>
<marker>Lehnert, 1994</marker>
<rawString>Lehnert, W. G. (1994). Cognition, computers, and car bombs: How Yale prepared me for the 1990s. In Beliefs, Reasoning, and Decision-Making. Psycho-Logic in Honor of Bob Abelson, pages 143–173, Hillsdale, NJ, Hove, UK. Erlbaum.http://ciir.cs.umass.edu/pubfiles/ cognition3.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>X Li</author>
<author>H Ji</author>
<author>Y Marton</author>
</authors>
<title>Domainindependent novel event discovery and semi-automatic event annotation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation,</booktitle>
<location>Sendai, Japan,</location>
<contexts>
<context position="36477" citStr="Li et al., 2010" startWordPosition="5917" endWordPosition="5920">ical event extraction from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature,</context>
</contexts>
<marker>Li, Li, Ji, Marton, 2010</marker>
<rawString>Li, H., Li, X., Ji, H., and Marton, Y. (2010). Domainindependent novel event discovery and semi-automatic event annotation. In Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation, Sendai, Japan, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A D Martin</author>
<author>K M Quinn</author>
</authors>
<title>Dynamic ideal point estimation via Markov chain Monte Carlo for the U.S. Supreme Court, 1953–1999. Political Analysis,</title>
<date>2002</date>
<volume>10</volume>
<issue>2</issue>
<pages>134--153</pages>
<contexts>
<context position="13491" citStr="Martin and Quinn, 2002" startWordPosition="2169" endWordPosition="2172">del assumes a random walk process on β, a variable which exists even for contexts that contain no events. Thus inferences about q will be smoothed according to event data at nearby timesteps. This is an instance of a linear Gaussian state-space model (also known as a linear dynamical system or dynamic linear model), and is a convenient formulation because it has well-known exact inference algorithms. Dynamic linear models have been used elsewhere in machine learning and political science to allow latent topic frequencies (Blei and Lafferty, 2006; Quinn et al., 2010) and ideological positions (Martin and Quinn, 2002) to smoothly change over time, and thus share statistical strength between timesteps. 4 Inference After randomly initializing all qk,s,r,t, inference is performed by a blocked Gibbs sampler, alternating resamplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + b/V)/(nz + b), where counts n are for all event tup</context>
</contexts>
<marker>Martin, Quinn, 2002</marker>
<rawString>Martin, A. D. and Quinn, K. M. (2002). Dynamic ideal point estimation via Markov chain Monte Carlo for the U.S. Supreme Court, 1953–1999. Political Analysis, 10(2), 134–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C McClelland</author>
</authors>
<title>Some effects on theory from the international event analysis movement.</title>
<date>1970</date>
<institution>Mimeo, University of Southern California.</institution>
<contexts>
<context position="34008" citStr="McClelland, 1970" startWordPosition="5547" endWordPosition="5548">and the dangers of false positives for this type of data analysis, especially in small-sample drilldowns.) Discounting this erroneous inference, the results are consistent with heightened violence during this period. We conclude the frame extractions for the Israeli-Palestinian case are consistent with the historical record over the period of study. 6 Related Work 6.1 Events Data in Political Science Projects using hand-collected events data represent some of the earliest efforts in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975; McClelland, 1970). Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more </context>
</contexts>
<marker>McClelland, 1970</marker>
<rawString>McClelland, C. (1970). Some effects on theory from the international event analysis movement. Mimeo, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mimno</author>
<author>H Wallach</author>
<author>A McCallum</author>
</authors>
<title>Gibbs sampling for logistic normal topic models with graphbased priors.</title>
<date>2008</date>
<booktitle>In NIPS Workshop on Analyzing Graphs.</booktitle>
<contexts>
<context position="14947" citStr="Mimno et al., 2008" startWordPosition="2403" endWordPosition="2406">s one slight modification of the standard dynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate no</context>
</contexts>
<marker>Mimno, Wallach, McCallum, 2008</marker>
<rawString>Mimno, D., Wallach, H., and McCallum, A. (2008). Gibbs sampling for logistic normal topic models with graphbased priors. In NIPS Workshop on Analyzing Graphs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Modi</author>
<author>I Titov</author>
<author>A Klementiev</author>
</authors>
<title>Unsupervised induction of frame-semantic representations.</title>
<date>2012</date>
<booktitle>In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36431" citStr="Modi et al., 2012" startWordPosition="5909" endWordPosition="5912"> 6.2 Events in Natural Language Processing Political event extraction from news has also received considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots</context>
</contexts>
<marker>Modi, Titov, Klementiev, 2012</marker>
<rawString>Modi, A., Titov, I., and Klementiev, A. (2012). Unsupervised induction of frame-semantic representations. In Proceedings of the NAACL-HLT Workshop on the Induction of Linguistic Structure, pages 1–7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K P Murphy</author>
</authors>
<title>Machine Learning: a Probabilistic Perspective.</title>
<date>2012</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="15310" citStr="Murphy, 2012" startWordPosition="2464" endWordPosition="2465">veloped a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute Cholesky root of the covariance matrix. This q* sample is a proposal for a Metropolis-within-Gibbs step, which is moved to according to the standard Metropolis-Hastings acceptance rule. Acceptance rates differ by K, ranging approximately from 30% (K = 100) to nearly 100% (small K). Finally, we use diffuse priors on a</context>
</contexts>
<marker>Murphy, 2012</marker>
<rawString>Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Neal</author>
</authors>
<title>Slice sampling. Annals of Statistics,</title>
<date>2003</date>
<pages>705--741</pages>
<contexts>
<context position="16021" citStr="Neal, 2003" startWordPosition="2576" endWordPosition="2577">n linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute Cholesky root of the covariance matrix. This q* sample is a proposal for a Metropolis-within-Gibbs step, which is moved to according to the standard Metropolis-Hastings acceptance rule. Acceptance rates differ by K, ranging approximately from 30% (K = 100) to nearly 100% (small K). Finally, we use diffuse priors on all global parameters, conjugate resampling variances T2, Qk once per iteration, and slice sampling (Neal, 2003) the Dirichlet concentration b every 100 iterations. Automatically learning these was extremely convenient for model-fitting; the only hyperparameter we set manually was K. It also allowed us to monitor the convergence of dispersion parameters to help debug and assess MCMC mixing. For other modeling and implementation details, see the online appendix and software. 5 Experiments We fit the two models on the dataset described in §2, varying the number of frames K, with 8 or more separate runs for each setting. Posteriors are saved and averaged from 11 Gibbs samples (every 100 iterations from 9,0</context>
</contexts>
<marker>Neal, 2003</marker>
<rawString>Neal, R. M. (2003). Slice sampling. Annals of Statistics, pages 705–741.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Newman</author>
<author>C Chemudugunta</author>
<author>P Smyth</author>
</authors>
<title>Statistical entity-topic models.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>680--686</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="37476" citStr="Newman et al. (2006)" startWordPosition="6070" endWordPosition="6073">arning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We instead use parsing to get a much more focused and interpretable representation of the relationship between textually cooccurring entities; namely, that they are the source and target of an action event. This is more in line with work </context>
</contexts>
<marker>Newman, Chemudugunta, Smyth, 2006</marker>
<rawString>Newman, D., Chemudugunta, C., and Smyth, P. (2006). Statistical entity-topic models. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 680–686. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O´ S´eaghdha</author>
<author>D</author>
</authors>
<title>Latent variable models of selectional preference.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>435--444</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>S´eaghdha, D, 2010</marker>
<rawString>O´ S´eaghdha, D. (2010). Latent variable models of selectional preference. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 435–444. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P O’Brien</author>
</authors>
<title>Crisis early warning and decision support: Contemporary approaches and thoughts on future research.</title>
<date>2010</date>
<journal>International Studies Review,</journal>
<volume>12</volume>
<issue>1</issue>
<pages>87--104</pages>
<marker>O’Brien, 2010</marker>
<rawString>O’Brien, S. P. (2010). Crisis early warning and decision support: Contemporary approaches and thoughts on future research. International Studies Review, 12(1), 87–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parker</author>
<author>D Graff</author>
<author>J Kong</author>
<author>K Chen</author>
<author>K Maeda</author>
</authors>
<title>English Gigaword Fourth Edition. Linguistic Data Consortium.</title>
<date>2009</date>
<tech>LDC2009T13.</tech>
<contexts>
<context position="3495" citStr="Parker et al., 2009" startWordPosition="511" endWordPosition="514">correlation to a database of real-world international conflict events, the Militarized Interstate Dispute (MID) dataset (Jones et al., 1996). Third, we qualitatively examine a prominent case not included in the MID dataset, Israeli-Palestinian relations, and compare the recovered trends to the historical record. We outline the data used for event discovery (§2), describe our model (§3), inference (§4), evaluation (§5), and comment on related work (§6). 2 Data The model we describe in §3 is learned from a corpus of 6.5 million newswire articles from the English Gigaword 4th edition (1994–2008, Parker et al., 2009). We also supplement it with a sample of data from the New York Times Annotated Corpus (1987–2007, Sandhaus, 2008).2 The Stan1Available from the Penn State Event Data Project: http://eventdata.psu.edu/ 2For arbitrary reasons this portion of the data is much smaller (we only parse the first five sentences of each article, while Gigaword has all sentences parsed), resulting in less than 2% as many tuples as from the Gigaword data. 1094 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1094–1104, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2009</marker>
<rawString>Parker, R., Graff, D., Kong, J., Chen, K., and Maeda, K. (2009). English Gigaword Fourth Edition. Linguistic Data Consortium. LDC2009T13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>M Atkinson</author>
</authors>
<title>Frontex real-time news event extraction framework.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>749--752</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="37191" citStr="Piskorski and Atkinson, 2011" startWordPosition="6027" endWordPosition="6030">elation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in </context>
</contexts>
<marker>Piskorski, Atkinson, 2011</marker>
<rawString>Piskorski, J. and Atkinson, M. (2011). Frontex real-time news event extraction framework. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 749–752. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>H Tanev</author>
<author>M Atkinson</author>
<author>E van der Goot</author>
<author>V Zavarella</author>
</authors>
<title>Online news event extraction for global crisis surveillance. Transactions on computational collective intelligence V,</title>
<date>2011</date>
<pages>182--212</pages>
<marker>Piskorski, Tanev, Atkinson, van der Goot, Zavarella, 2011</marker>
<rawString>Piskorski, J., Tanev, H., Atkinson, M., van der Goot, E., and Zavarella, V. (2011). Online news event extraction for global crisis surveillance. Transactions on computational collective intelligence V, pages 182–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N G Polson</author>
<author>J G Scott</author>
<author>J Windle</author>
</authors>
<title>Bayesian inference for logistic models using Polya-Gamma latent variables. arXiv preprint arXiv:1205.0310.</title>
<date>2012</date>
<contexts>
<context position="14992" citStr="Polson et al., 2012" startWordPosition="2411" endWordPosition="2414">ynamic linear model that the zero-count weeks have no q observation; the Kalman filter implementation is appropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute </context>
</contexts>
<marker>Polson, Scott, Windle, 2012</marker>
<rawString>Polson, N. G., Scott, J. G., and Windle, J. (2012). Bayesian inference for logistic models using Polya-Gamma latent variables. arXiv preprint arXiv:1205.0310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
<author>P Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36955" citStr="Poon and Domingos, 2009" startWordPosition="5992" endWordPosition="5995">under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occ</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Poon, H. and Domingos, P. (2009). Unsupervised semantic parsing. In Proceedings of EMNLP, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K M Quinn</author>
<author>B L Monroe</author>
<author>M Colaresi</author>
<author>M H Crespin</author>
<author>D R Radev</author>
</authors>
<title>How to analyze political attention with minimal assumptions and costs.</title>
<date>2010</date>
<journal>American Journal of Political Science,</journal>
<volume>54</volume>
<issue>1</issue>
<pages>209228</pages>
<contexts>
<context position="13440" citStr="Quinn et al., 2010" startWordPosition="2162" endWordPosition="2165">αk, Q2k) are same as the vanilla model. This model assumes a random walk process on β, a variable which exists even for contexts that contain no events. Thus inferences about q will be smoothed according to event data at nearby timesteps. This is an instance of a linear Gaussian state-space model (also known as a linear dynamical system or dynamic linear model), and is a convenient formulation because it has well-known exact inference algorithms. Dynamic linear models have been used elsewhere in machine learning and political science to allow latent topic frequencies (Blei and Lafferty, 2006; Quinn et al., 2010) and ideological positions (Martin and Quinn, 2002) to smoothly change over time, and thus share statistical strength between timesteps. 4 Inference After randomly initializing all qk,s,r,t, inference is performed by a blocked Gibbs sampler, alternating resamplings for three major groups of variables: the language model (z,φ), context model (α, ry, β, p), and the q, θ variables, which bottleneck between the submodels. The language model sampler sequentially updates every z(i) (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): p(z(i)|θ, w(i), b) a θs,r,t,z(nw,z + </context>
</contexts>
<marker>Quinn, Monroe, Colaresi, Crespin, Radev, 2010</marker>
<rawString>Quinn, K. M., Monroe, B. L., Colaresi, M., Crespin, M. H., and Radev, D. R. (2010). How to analyze political attention with minimal assumptions and costs. American Journal of Political Science, 54(1), 209228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rajaraman</author>
<author>J D Ullman</author>
</authors>
<title>Mining of massive datasets.</title>
<date>2011</date>
<publisher>Cambridge University Press;</publisher>
<note>http:// infolab.stanford.edu/˜ullman/mmds.html.</note>
<contexts>
<context position="8746" citStr="Rajaraman and Ullman, 2011" startWordPosition="1367" endWordPosition="1370">ticles (using `1-regularized logistic regression with unigram and bigram features). Other filters remove non-textual junk and non-standard punctuation likely to cause parse errors. For experiments we remove tuples where the source and receiver entities are the same, and restrict to tuples with dyads that occur at least 500 times, and predicate paths that occur at least 10 times. This yields 365,623 event tuples from 235,830 documents, for 421 dyads and 10,457 unique predicate paths. We define timesteps to be 7-day periods, resulting in 1,149 discrete 5We use a simple form of shingling (ch. 3, Rajaraman and Ullman, 2011): represent a document signature as its J = 5 lowercased bigrams with the lowest hash values, and reject a document with a signature that has been seen before within the same month. J was manually tuned, as it affects the precision/recall tradeoff. 1095 Figure 1: Directed probabilistic diagram of the model for one (s, r, t) dyad-time context, for the smoothed model. timesteps (1987 through 2008, though the vast majority of data starts in 1994). 3 Model We design two models to learn linguistic event classes over predicate paths by conditioning on real-world contextual information about internat</context>
</contexts>
<marker>Rajaraman, Ullman, 2011</marker>
<rawString>Rajaraman, A. and Ullman, J. D. (2011). Mining of massive datasets. Cambridge University Press; http:// infolab.stanford.edu/˜ullman/mmds.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ramshaw</author>
<author>E Boschee</author>
<author>M Freedman</author>
<author>J MacBride</author>
<author>R Weischedel</author>
</authors>
<title>SERIF language processing effective trainable language understanding.</title>
<date>2011</date>
<booktitle>Handbook of Natural Language Processing and Machine Translation,</booktitle>
<pages>636--644</pages>
<contexts>
<context position="34855" citStr="Ramshaw et al., 2011" startWordPosition="5667" endWordPosition="5670">tching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013).14 All these systems crucially rely on hand-built pattern dictionaries. It is extremely labor intensive to develop these dictionaries. Schrodt (2006) estimates 4,000 trained person-hours were required to create dictionaries of political actors in the Middle East, and the phrase dictionary took dramatically longer; the comments in TABARI’s phrase dictionary i</context>
</contexts>
<marker>Ramshaw, Boschee, Freedman, MacBride, Weischedel, 2011</marker>
<rawString>Ramshaw, L., Boschee, E., Freedman, M., MacBride, J., Weischedel, R., , and Zamanian, A. (2011). SERIF language processing effective trainable language understanding. Handbook of Natural Language Processing and Machine Translation, pages 636–644.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Regneri</author>
<author>A Koller</author>
<author>M Pinkal</author>
</authors>
<title>Learning script knowledge with web experiments.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>979--988</pages>
<contexts>
<context position="36530" citStr="Regneri et al., 2010" startWordPosition="5926" endWordPosition="5929">d considerable attention within natural language processing in part due to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems simi</context>
</contexts>
<marker>Regneri, Koller, Pinkal, 2010</marker>
<rawString>Regneri, M., Koller, A., and Pinkal, M. (2010). Learning script knowledge with web experiments. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 979–988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rooth</author>
<author>S Riezler</author>
<author>D Prescher</author>
<author>G Carroll</author>
<author>F Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>104111</pages>
<contexts>
<context position="36715" citStr="Rooth et al., 1999" startWordPosition="5954" endWordPosition="5957">t events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Rooth, M., Riezler, S., Prescher, D., Carroll, G., and Beil, F. (1999). Inducing a semantically annotated lexicon via EM-based clustering. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, page 104111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rummel</author>
</authors>
<title>The Dimensionality of Nations project.</title>
<date>1968</date>
<contexts>
<context position="33967" citStr="Rummel, 1968" startWordPosition="5541" endWordPosition="5542">ge processing could help the model, and the dangers of false positives for this type of data analysis, especially in small-sample drilldowns.) Discounting this erroneous inference, the results are consistent with heightened violence during this period. We conclude the frame extractions for the Israeli-Palestinian case are consistent with the historical record over the period of study. 6 Related Work 6.1 Events Data in Political Science Projects using hand-collected events data represent some of the earliest efforts in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975; McClelland, 1970). Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprieta</context>
</contexts>
<marker>Rummel, 1968</marker>
<rawString>Rummel, R. (1968). The Dimensionality of Nations project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rzhetsky</author>
<author>I Iossifov</author>
<author>T Koike</author>
<author>M Krauthammer</author>
<author>P Kra</author>
<author>M Morris</author>
<author>H Yu</author>
<author>P A Dubou´e</author>
<author>W Weng</author>
<author>W J Wilbur</author>
<author>V Hatzivassiloglou</author>
<author>C Friedman</author>
</authors>
<title>GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data.</title>
<date>2004</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>37</volume>
<issue>1</issue>
<pages>43--53</pages>
<marker>Rzhetsky, Iossifov, Koike, Krauthammer, Kra, Morris, Yu, Dubou´e, Weng, Wilbur, Hatzivassiloglou, Friedman, 2004</marker>
<rawString>Rzhetsky, A., Iossifov, I., Koike, T., Krauthammer, M., Kra, P., Morris, M., Yu, H., Dubou´e, P. A., Weng, W., Wilbur, W. J., Hatzivassiloglou, V., and Friedman, C. (2004). GeneWays: a system for extracting, analyzing, visualizing, and integrating molecular pathway data. Journal of Biomedical Informatics, 37(1), 43–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sandhaus</author>
</authors>
<title>The New York Times Annotated Corpus. Linguistic Data Consortium.</title>
<date>2008</date>
<contexts>
<context position="3609" citStr="Sandhaus, 2008" startWordPosition="533" endWordPosition="534"> (Jones et al., 1996). Third, we qualitatively examine a prominent case not included in the MID dataset, Israeli-Palestinian relations, and compare the recovered trends to the historical record. We outline the data used for event discovery (§2), describe our model (§3), inference (§4), evaluation (§5), and comment on related work (§6). 2 Data The model we describe in §3 is learned from a corpus of 6.5 million newswire articles from the English Gigaword 4th edition (1994–2008, Parker et al., 2009). We also supplement it with a sample of data from the New York Times Annotated Corpus (1987–2007, Sandhaus, 2008).2 The Stan1Available from the Penn State Event Data Project: http://eventdata.psu.edu/ 2For arbitrary reasons this portion of the data is much smaller (we only parse the first five sentences of each article, while Gigaword has all sentences parsed), resulting in less than 2% as many tuples as from the Gigaword data. 1094 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1094–1104, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ford CoreNLP system,3 under default settings, was used to POS-tag and parse the article</context>
</contexts>
<marker>Sandhaus, 2008</marker>
<rawString>Sandhaus, E. (2008). The New York Times Annotated Corpus. Linguistic Data Consortium. LDC2008T19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sanfilippo</author>
<author>L Franklin</author>
<author>S Tratz</author>
<author>G Danielson</author>
<author>N Mileson</author>
<author>R Riensche</author>
<author>L McGrath</author>
</authors>
<title>Automating frame analysis. Social computing, behavioral modeling, and prediction,</title>
<date>2008</date>
<pages>239--248</pages>
<contexts>
<context position="37241" citStr="Sanfilippo et al., 2008" startWordPosition="6035" endWordPosition="6038">extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text fragments containing co-occurring entities. (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID.) We </context>
</contexts>
<marker>Sanfilippo, Franklin, Tratz, Danielson, Mileson, Riensche, McGrath, 2008</marker>
<rawString>Sanfilippo, A., Franklin, L., Tratz, S., Danielson, G., Mileson, N., Riensche, R., and McGrath, L. (2008). Automating frame analysis. Social computing, behavioral modeling, and prediction, pages 239–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schrodt</author>
</authors>
<title>Precedents, progress, and prospects in political event data.</title>
<date>2012</date>
<journal>International Interactions,</journal>
<volume>38</volume>
<issue>4</issue>
<pages>546--569</pages>
<contexts>
<context position="1490" citStr="Schrodt, 2012" startWordPosition="203" endWordPosition="204">ences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents 1 Introduction The digitization of large news corpora has provided an unparalleled opportunity for the systematic study of international relations. Since the mid1960s political scientists have used political events data, records of public micro-level interactions between major political actors of the form “someone does something to someone else” as reported in the open press (Schrodt, 2012), to study the patterns of interactions between political actors and how they evolve over time. Scaling this data effort to modern corpora presents an information extraction challenge: can a structured collection of accurate, politically relevant events between major political actors be extracted automatically and efficiently? And can they be grouped into meaningful event types with a low-dimensional structure useful for further analysis? We present an unsupervised approach to event extraction, in which political structure and linguistic evidence are combined. A political context model of the </context>
</contexts>
<marker>Schrodt, 2012</marker>
<rawString>Schrodt, P. (2012). Precedents, progress, and prospects in political event data. International Interactions, 38(4), 546– 569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schrodt</author>
<author>K Leetaru</author>
</authors>
<title>GDELT: Global data on events, location and tone,</title>
<date>2013</date>
<booktitle>In International Studies Association Conference.</booktitle>
<pages>1979--2012</pages>
<contexts>
<context position="35094" citStr="Schrodt and Leetaru, 2013" startWordPosition="5703" endWordPosition="5707">C IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013).14 All these systems crucially rely on hand-built pattern dictionaries. It is extremely labor intensive to develop these dictionaries. Schrodt (2006) estimates 4,000 trained person-hours were required to create dictionaries of political actors in the Middle East, and the phrase dictionary took dramatically longer; the comments in TABARI’s phrase dictionary indicate some of its 15,789 entries were created as early as 1991. Ideally, any new events data solution would incorporate the extensive work already completed by political scientists in this area while minimizing the need for further dicti</context>
</contexts>
<marker>Schrodt, Leetaru, 2013</marker>
<rawString>Schrodt, P. and Leetaru, K. (2013). GDELT: Global data on events, location and tone, 1979-2012. In International Studies Association Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Schrodt</author>
</authors>
<title>Automated coding of international event data using sparse parsing techniques.</title>
<date>2001</date>
<booktitle>International Studies Association Conference.</booktitle>
<contexts>
<context position="34350" citStr="Schrodt, 2001" startWordPosition="5591" endWordPosition="5592">study. 6 Related Work 6.1 Events Data in Political Science Projects using hand-collected events data represent some of the earliest efforts in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975; McClelland, 1970). Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TAB</context>
</contexts>
<marker>Schrodt, 2001</marker>
<rawString>Schrodt, P. A. (2001). Automated coding of international event data using sparse parsing techniques. International Studies Association Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Schrodt</author>
</authors>
<title>Twenty Years of the Kansas Event Data System Project.</title>
<date>2006</date>
<tech>Political Methodologist.</tech>
<contexts>
<context position="35244" citStr="Schrodt (2006)" startWordPosition="5726" endWordPosition="5727">entence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by Boschee et al. (2013), uses a proprietary parsing and coreference system (BBN SERIF, Ramshaw et al., 2011), and directly compares to TABARI, finding significantly higher accuracy. The origi1101 nal TABARI system is still actively being developed, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013).14 All these systems crucially rely on hand-built pattern dictionaries. It is extremely labor intensive to develop these dictionaries. Schrodt (2006) estimates 4,000 trained person-hours were required to create dictionaries of political actors in the Middle East, and the phrase dictionary took dramatically longer; the comments in TABARI’s phrase dictionary indicate some of its 15,789 entries were created as early as 1991. Ideally, any new events data solution would incorporate the extensive work already completed by political scientists in this area while minimizing the need for further dictionary development. In this work we use the actor dictionaries, and hope to incorporate the verb patterns in future work. 6.2 Events in Natural Languag</context>
</contexts>
<marker>Schrodt, 2006</marker>
<rawString>Schrodt, P. A. (2006). Twenty Years of the Kansas Event Data System Project. Political Methodologist.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Schrodt</author>
<author>D J Gerner</author>
</authors>
<title>Validity assessment of a machine-coded event data set for the Middle East,</title>
<date>1994</date>
<journal>American Journal of Political Science.</journal>
<contexts>
<context position="34150" citStr="Schrodt and Gerner, 1994" startWordPosition="5563" endWordPosition="5566">inference, the results are consistent with heightened violence during this period. We conclude the frame extractions for the Israeli-Palestinian case are consistent with the historical record over the period of study. 6 Related Work 6.1 Events Data in Political Science Projects using hand-collected events data represent some of the earliest efforts in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975; McClelland, 1970). Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). These efforts culminated in the open-source program, TABARI, which uses pattern matching from extensive hand-developed phrase dictionaries, combined with basic part of speech tagging (Schrodt, 2001); a rough analogue in the information extraction literature might be the rule-based, finite-state FASTUS system for MUC IE (Hobbs et al., 1997), though TABARI is restricted to single sentence analysis. Later proprietary work has apparently incorporated more extensive NLP (e.g., sentence parsing) though few details are available (King and Lowe, 2003). The most recent published work we know of, by B</context>
</contexts>
<marker>Schrodt, Gerner, 1994</marker>
<rawString>Schrodt, P. A. and Gerner, D. J. (1994). Validity assessment of a machine-coded event data set for the Middle East, 1982-1992. American Journal of Political Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Schrodt</author>
<author>D J Gerner</author>
</authors>
<title>An event data analysis of third-party mediation in the middle east and balkans.</title>
<date>2004</date>
<journal>Journal of Conflict Resolution,</journal>
<volume>48</volume>
<issue>3</issue>
<pages>310--330</pages>
<contexts>
<context position="28593" citStr="Schrodt and Gerner, 2004" startWordPosition="4631" endWordPosition="4634">uggests that semantic coherence does not benefit from the longer13In the latter, a problem-specific topic model did best. range temporal dependencies. In general, performance improves with higher K, but not beyond K = 50. This suggests the model reaches a limit for how fine-grained of semantics it can learn. 5.4 Case study Here we qualitatively examine the narrative story between the dyad with the highest frequency of events in our dataset, the Israeli-Palestinian relationship, finding qualitative agreement with other case studies of this conflict (Brandt et al., 2012; Goldstein et al., 2001; Schrodt and Gerner, 2004). (The MID dataset does not include this conflict because the Palestinians are not considered a state actor.) Using the Associated Press subset, we plot the highest incidence frames from one run of the K = 20 smoothed frame models, for the two directed dyads, and highlight some of the interesting relationships. Figure 4(a) shows that tradeoffs in the use of military vs. police action by Israel towards the Palestinians tracks with major historical events. The first period in the data where police actions (‘impose, seal, capture, seize, arrest’) exceed military actions (‘kill, fire, enter, attac</context>
</contexts>
<marker>Schrodt, Gerner, 2004</marker>
<rawString>Schrodt, P. A. and Gerner, D. J. (2004). An event data analysis of third-party mediation in the middle east and balkans. Journal of Conflict Resolution, 48(3), 310–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shellman</author>
</authors>
<title>Time series intervals and statistical inference: The effects of temporal aggregation on event data analysis.</title>
<date>2004</date>
<journal>Political Analysis,</journal>
<volume>12</volume>
<issue>1</issue>
<pages>97--104</pages>
<contexts>
<context position="12130" citStr="Shellman, 2004" startWordPosition="1934" endWordPosition="1935">chlet’s concentration parameter. Smoothing Frames Across Time The vanilla model is capable of inducing frames through dependency path co-occurences, when multiple events occur in a given context. However, many dyad-time slices are very sparse; for example, most dyads (all but 18) have events in fewer than half the time slices in the dataset. One solution is to increase the bucket size (e.g., to months); however, previous work in political science has demonstrated that answering questions of interest about reciprocity dynamics requires recovering the events at weekly or even daily granularity (Shellman, 2004), and in any case wide buckets help only so much for dyads with fewer events or less media attention. Therefore we propose a smoothed frames (SF) model, in which the s &amp;quot;Source&amp;quot; entity r &amp;quot;Receiver&amp;quot; entity t Timestep i Event tuple k Frame ⌧2 Language Model P(Text |Event Type) Context Model P(Event Type |Context) A,s,r,t—]k 4,s,r,t k �2 k ↵k ⌘k,s,r,t k ✓s,r,t r wpredpath i b 1096 frame distribution for a given dyad comes from a latent parameter β*,s,r,t that smoothly varies over time. For each (s, r), draw the first timestep’s values as βk,s,r,1 — N(0,100), and for each context (s, r, t &gt; 1), • D</context>
</contexts>
<marker>Shellman, 2004</marker>
<rawString>Shellman, S. M. (2004). Time series intervals and statistical inference: The effects of temporal aggregation on event data analysis. Political Analysis, 12(1), 97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>A Klementiev</author>
</authors>
<title>A Bayesian model for unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="36929" citStr="Titov and Klementiev, 2011" startWordPosition="5987" endWordPosition="5991">ied; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005), Chang et al. (2009), or Newman et al. (2006), which perform bag-of-words-style analysis of text f</context>
</contexts>
<marker>Titov, Klementiev, 2011</marker>
<rawString>Titov, I. and Klementiev, A. (2011). A Bayesian model for unsupervised semantic parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>A Klementiev</author>
</authors>
<title>A Bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>Proceedings of EACL.</booktitle>
<contexts>
<context position="36829" citStr="Titov and Klementiev, 2012" startWordPosition="5972" endWordPosition="5976">oaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski et al., 2011; Sanfilippo et al., 2008). One can also see this work as a relational ex14http://eventdata.psu.edu/data.dir/ GDELT.html tension of co-occurence-based methods such as Gerrish (2013; ch. 4), Diesner and Carley (2005</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Titov, I. and Klementiev, A. (2012). A Bayesian approach to unsupervised semantic role induction. Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wallach</author>
<author>D Mimno</author>
<author>A McCallum</author>
</authors>
<title>Rethinking lda: Why priors matter.</title>
<date>2009</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<volume>22</volume>
<pages>1973--1981</pages>
<contexts>
<context position="11344" citStr="Wallach et al. (2009)" startWordPosition="1807" endWordPosition="1810">stic normal distributions to represent contextual effects. The simplest is the vanilla (V) context model, • For each frame k, draw global parameters from diffuse priors: prevalence αk and variability σ2k. • For each (s, r, t), • Draw ηk,s,r,t — N(αk, σ2k) for each frame k. • Apply a softmax transform, exp ηk,s,r,t Bk,s,r,t = K �k&apos;=1 exp ηk&apos;,s,r,t Thus the vector η∗,s,r,t encodes the relative logodds of the different frames for events appearing in the context (s, r, t). This simple logistic normal prior is, in terms of topic models, analogous to the asymmetric Dirichlet prior version of LDA in Wallach et al. (2009), since the αk parameter can learn that some frames tend to be more likely than others. The variance parameters σ2k control admixture sparsity, and are analogous to a Dirichlet’s concentration parameter. Smoothing Frames Across Time The vanilla model is capable of inducing frames through dependency path co-occurences, when multiple events occur in a given context. However, many dyad-time slices are very sparse; for example, most dyads (all but 18) have events in fewer than half the time slices in the dataset. One solution is to increase the bucket size (e.g., to months); however, previous work</context>
</contexts>
<marker>Wallach, Mimno, McCallum, 2009</marker>
<rawString>Wallach, H., Mimno, D., and McCallum, A. (2009). Rethinking lda: Why priors matter. Advances in Neural Information Processing Systems, 22, 1973–1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Yao</author>
<author>A Haghighi</author>
<author>S Riedel</author>
<author>A McCallum</author>
</authors>
<title>Structured relation discovery using generative models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1456--1466</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36598" citStr="Yao et al., 2011" startWordPosition="5936" endWordPosition="5939"> to governmentfunded challenges such as MUC-3 and MUC-4 (Lehnert, 1994), which focused on the extraction of terrorist events, as well as the more recent ACE program. The work in this paper is inspired by unsupervised approaches that seek to discover types of relations and events, instead of assuming them to be pre-specified; this includes research under various headings such as template/frame/event learning (Cheung et al., 2013; Modi et al., 2012; Chambers and Jurafsky, 2011; Li et al., 2010; Bejan, 2008), script learning (Regneri et al., 2010; Chambers and Jurafsky, 2009), relation learning (Yao et al., 2011), open information extraction (Banko et al., 2007; Carlson et al., 2010), verb caseframe learning (Rooth et al., 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). Unlike much of the previous literature, we do not learn latent roles/slots. Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Pisko</context>
</contexts>
<marker>Yao, Haghighi, Riedel, McCallum, 2011</marker>
<rawString>Yao, L., Haghighi, A., Riedel, S., and McCallum, A. (2011). Structured relation discovery using generative models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1456–1466. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Zeger</author>
<author>M R Karim</author>
</authors>
<title>Generalized linear models with random effects; a Gibbs sampling approach.</title>
<date>1991</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>86</volume>
<issue>413</issue>
<pages>79--86</pages>
<contexts>
<context position="15102" citStr="Zeger and Karim (1991)" startWordPosition="2430" endWordPosition="2433">ropriately modified to handle this. The q update step is challenging since it is a nonconjugate prior to the z counts. Logistic normal distributions were introduced to text modeling by Blei and Lafferty (2007), who developed a variational approximation; however, we find that experimenting with different models is easier in the Gibbs sampling framework. While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al., 2008; Holmes and Held, 2006; Polson et al., 2012), it can be slow to converge. We opt for the more computationally efficient approach of Zeger and Karim (1991) and Hoff (2003), using a Laplace approximation to p(q |¯q, E, z), which is a mode-centered Gaussian having inverse covariance equal to the unnormalized log-posterior’s negative Hessian (§8.4 in Murphy, 2012). We find the mode with the linear-time Newton algorithm from Eisenstein et al. (2011), and sample in linear time by only using the Hessian’s diagonal as the inverse covariance (i.e., an axis-aligned normal), since a full multivariate normal sample requires a cubic-time-to-compute Cholesky root of the covariance matrix. This q* sample is a proposal for a Metropolis-within-Gibbs step, which</context>
</contexts>
<marker>Zeger, Karim, 1991</marker>
<rawString>Zeger, S. L. and Karim, M. R. (1991). Generalized linear models with random effects; a Gibbs sampling approach. Journal of the American Statistical Association, 86(413), 79–86.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>