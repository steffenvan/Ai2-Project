<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.995447">
Design and validation of ECA gestures to improve
dialogue system robustness
</title>
<author confidence="0.964729">
Beatriz Lopez, Alvaro Hernandez, David Diaz,
Ruben Fernandez, Luis Hernandez
</author>
<title confidence="0.26521225">
GAPS, Signal, Systems and Radiocommunications
Department
Universidad Polit6cnica de Madrid
Ciudad Universitaria s/n, 2 8040 Madrid, Spain
</title>
<email confidence="0.979604">
alvaro@gaps.ssr.upm.es
</email>
<note confidence="0.6999425">
Doroteo Torre
ATVS, Escuela Polit6cnica Superior
</note>
<address confidence="0.789106">
Universidad Aut6noma de Madrid
Ciudad Universitaria de Cantoblanco,
2 8049 Madrid, Spain
</address>
<email confidence="0.982185">
Doroteo.torre@uam.es
</email>
<sectionHeader confidence="0.999564" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992921875">
Spoken language dialogue systems and embodied
conversational agents are being introduced in a
rapidly increasing number of Human-Computer
Interaction (HCI) applications. The technologies
involved in SLDSs (speech recognition, dialogue
design, etc.) are mature enough to allow the crea-
tion of trustworthy applications. However, robust-
ness problems still arise in concrete limited dia-
logue systems because there are many error
sources that may cause the system to perform
poorly. A common example is that users tend to
repeat their previous utterance with some frustra-
tion when error recovery mechanisms come into
play, which does not help the recognition process,
and as a result using the system seems slow and
unnatural (Boyce, 1999).
At the same time, embodied conversational
agents (ECAs) are gaining prominence in HCI sys-
tems, since they make for more user-friendly ap-
plications while increasing communication effec-
tiveness. There are many studies on the effects —
from psychological to efficiency in goal achieve-
ment— ECAs have on users of a variety of applica-
tions, see Bickmore et al. (2004) and Brave et al.
(2005), but still very few (Bell and Gustafson,
2003) on the impact of ECAs in directed dialogue
situations where robustness is a problem.
Our research explores the potential of ECAs to
assist in, or resolve, certain difficult dialogue situa-
tions that have been identified by various leading
authors in the field (Cassell and Thorisson, 1999;
Cassell and Stone, 1999), as well as a few we our-
</bodyText>
<sectionHeader confidence="0.667566" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999818344827586">
In this paper we present validation tests
that we have carried out on gestures that
we have designed for an embodied conver-
sational agent (ECAs), to assess their
soundness with a view to applying said
gestures in a forthcoming experiment to
explore the possibilities ECAs can offer to
overcome typical robustness problems in
spoken language dialogue systems
(SLDSs). The paper is divided into two
parts: First we carry our a literature review
to acquire a sense of the extent to which
ECAs can help overcome user frustration
during human-machine interaction. Then
we associate tentative, yet specific, ECA
gestural behaviour with each of the main
dialogue stages, with special emphasis on
problem situations. In the second part we
describe the tests we have carried out to
validate our ECA&apos;s gestural repertoire. The
results obtained show that users generally
understand and naturally accept the ges-
tures, to a reasonable degree. This encour-
ages us to proceed with the next stage of
research: evaluating the gestural strategy in
real dialogue situations with the aim of
learning about how to favour a more effi-
cient and pleasant dialogue flow for the us-
ers.
</bodyText>
<page confidence="0.997857">
67
</page>
<note confidence="0.8798545">
Proceedings of the Workshop on Embodied Language Processing, pages 67–74,
Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.998974090909091">
selves suggest. After identifying the problematic
situations of the dialogue we suggest a gestural
strategy for the ECA to respond to such problem
situations. Then we propose an experimental
framework, for forthcoming tests, to study the po-
tential benefits of adding nonverbal communica-
tion in complex dialogue situations. In the study
we present here we focus on preliminary validation
of our gestural repertoire through user tests. We
conclude by presenting our results and suggesting
the direction our research will take from this point.
</bodyText>
<sectionHeader confidence="0.523283" genericHeader="introduction">
2 How ECA technology can improve in-
teraction with SLDSs
</sectionHeader>
<bodyText confidence="0.999941419354839">
There are many nonverbal elements of communi-
cation in everyday life that are important because
they convey a considerable amount of information
and qualify the spoken message, sometimes even
to the extent that what is meant is actually the op-
posite of what is said (Krauss et al., 1996). ECAs
offer the possibility to combine several communi-
cation modes such as speech and gestures, making
it possible, in theory, to create interfaces with
which human-machine interaction is much more
natural and comfortable. In fact, they are already
being employed to improve interaction (Massaro et
al., 2000).
These are some common situations with SLDSs
in which an ECA could have a positive effect:
Efficient turn management: The body language
and expressiveness of agents are important not
only to reinforce the spoken message, but also to
regulate the flow of the dialogue, as Cassell points
out (in Bickmore et al., 2004).
Improving error recovery: The process of rec-
ognition error recovery usually leads to a certain
degree of user frustration (see Oviatt and VanGent,
1996). Indeed, it is common, once an error occurs,
to enter into an error spiral in which the system is
trying to recover, the user gets ever more frustrated,
and this frustration interferes in the recognition
process making the situation worse (Oviatt et al.,
199 8). ECAs may help reduce frustration, and by
doing so make error recovery more effective (Hone,
2005).
</bodyText>
<subsectionHeader confidence="0.808072">
Correct understanding of the state of the dia-
</subsectionHeader>
<bodyText confidence="0.9981105">
logue: Sometimes the user doesn&apos;t know whether
or not things are going normally (Oviatt, 1994).
This sometimes leads the dialogue to error states
that could be avoided. The expressive capacity of
ECAs could be used to reflect with greater clarity
the state the system takes the dialogue to be in.
</bodyText>
<sectionHeader confidence="0.6320605" genericHeader="method">
3 Suggesting ECA behaviour for each
dialogue situation
</sectionHeader>
<bodyText confidence="0.999860913043478">
A variety of studies have been carried out on be-
havioural strategies for embodied conversational
agents (Poggi, 2001; Cassell et al., 2000; Cassell et
al., 2001; Chovil, 1992; Kendon, 1990), which deal
with behaviour in hypothetical situations and in
terms of the informational goals of each particular
interaction (be it human-human or human-
machine). We direct our attention to the overall
dialogue systems dynamics, focussing specifically
on typical robustness problems and how to favour
smooth sailing through the different stages of the
dialogue. We draw from existing research under-
taken to try to understand the effects different ges-
tures displayed by ECAs have on people, and we
apply this knowledge to a real dialogue system. In
Table 1 we show the basic set of gestures we are
using as a starting point. They are based mainly on
descriptions in Bickmore (et al., 2004) and Cassell
(et al., 2000), and on recommendations in Cassell
and Thorisson (1999), Cassell (et al., 2001), Chovil
(1992), Kendon (1990) and San-Segundo (et al.,
2001), to which we have added a few suggestions
of our own.
</bodyText>
<figureCaption confidence="0.7597148">
Dialogue stage ECA behaviour
(movements, gestures and other cues)
Initiation 1. Welcome message: look at the camera,
(welcoming the smile, wave hand
user) 2. Explanation of the task: zoom in
</figureCaption>
<table confidence="0.941621705882353">
3. Zoom out, lights dim
Give turn Look directly at the user, raise eyebrows.
Camera zooms out. Lights dim.
Take turn Look directly at the user, raise hands into ges-
ture space. Camera zooms in. Light gets
brighter.
Wait Slight leaning back, one arm crossed and the
other touching the cheek shift of body weight
Help Beat gesture with the hands. Change of posture
Error recovery Lean towards the camera, beat gesture
with correction
Confirmation Nod, smile, eyes fully open
(high
confidence)
Confirmation Slight leaning of the head to one side, stop
(low smiling, mildly squint
confidence)
</table>
<tableCaption confidence="0.980918">
Table 1: Gesture repertoire for the main dialogue
stages
</tableCaption>
<page confidence="0.997998">
68
</page>
<subsectionHeader confidence="0.980295">
3.1 Initiation
</subsectionHeader>
<bodyText confidence="0.999990185185185">
The inclusion of an ECA at this stage &amp;quot;humanises&amp;quot;
the system (Oviatt and Adams, 2000). This is a
problem, first because once a user has such high
expectations the system can only end up disap-
pointing her, and secondly because the user will
tend to use more natural (and thus complex) com-
munication, which the system is unable to handle,
and the experience will ultimately be frustrating.
On the other hand, especially in the case of new
users, contact with a dialoguing animated character
may have the effect that the user&apos;s level of atten-
tion to the actual information that is being given is
reduced (Schaumburg, 2001; Catrambone, 2002).
Thus the goal is to present a human-like interface
that is, at the same time, less striking and thus less
distracting at first contact, and one that clearly
&amp;quot;sets the rules&amp;quot; of the interaction and makes sure
that the user keeps it framed within the capability
of the system.
We have designed a welcome gesture for our
ECA based on the recommendations in Kendon
(1990), to test whether or not it fosters a sense of
ease in the user and helps her concentrate on the
task at hand. Playing with the zoom, the size and
the position of the ECA on the screen may also
prove to be useful to frame the communication bet-
ter (see Table 1).
</bodyText>
<subsectionHeader confidence="0.998499">
3.2 Turn Management
</subsectionHeader>
<bodyText confidence="0.9942045">
Turn management involves two basic actions:
taking turn and giving turn. Again, in Table 1 we
show the corresponding ECA gestures we will start
testing with. Note that apart from the ECA gestures,
we also play with zoom and light intensity: when
it&apos;s the ECA&apos;s turn to speak the camera zooms-in
slightly and the light becomes brighter, and when
it&apos;s the user&apos;s turn the camera zooms out and the
lights dim. The idea is that, hopefully, the user will
associate each camera shot and level of light inten-
sity with each of the turn modes, and so know
when she is expected to speak.
The following are some typical examples of
problem situations together with further considera-
tions about ECA behaviour that could help avoid
or recover from them:
• The user tries to interrupt at a point at
which the barge-in feature is not active. If
this happens the system does not process
what the user has said, and when the system
finally returns to listening mode there is si-
lence from both parts: the system expects
input from the user, and the user expects an
answer. Often both finally break the silence
at the same time and the cycle begins again,
or, if the system caught part of the user&apos;s ut-
terance, a recognition error will most likely
occur and the system will fall into a recogni-
tion error recovery subdialogue that the user
does not expect. To help avoid such faulty
events the ECAs demeanour should indicate
as clearly as possible that the user is not be-
ing listened to at that particular moment.
Speaking while looking away, perhaps at
some object, and absence of attention cues
(such as nodding) are possible ways to show
that the user is not expected to interrupt the
ECA. Since our present dialogue system
produces fairly short utterances for the ECA,
we are somewhat limited as to the active
strategies to build into the ECA&apos;s behaviour.
However, there are at least three cues the
user could read to realise that the system
didn&apos;t listen to what she said. The first is the
fact that the system carries on speaking, ig-
noring the user&apos;s utterance. Second, at the
end of the system&apos;s turn the ECA will per-
form a specific give-turn gesture. And third,
after giving the turn the ECA will remain
still and silent for a few seconds before per-
forming a waiting gesture (leaning back
slightly with her arms crossed, shifting the
body weight from one leg to another; see
Table 1). In addition, if the user still remains
silent after yet another brief waiting period
the system will offer help. It will be interest-
ing to see at which point users realise that
the system didn&apos;t register their utterance.
</bodyText>
<listItem confidence="0.800326666666667">
• A similar situation occurs if the Voice Ac-
tivity Detector (VAD) fails and the system
doesn&apos;t capture the user&apos;s entire utterance,
</listItem>
<bodyText confidence="0.965365833333333">
or when the user simply doesn&apos;t say any-
thing when she is expected to (&amp;quot;no input&amp;quot;).
Again, both system and user end up waiting
for each other to say something. And again,
the strategy we use is to have the ECA dis-
play a waiting posture.
</bodyText>
<listItem confidence="0.925888">
• It can also happen that the user doesn&apos;t
speak but the VAD &amp;quot;thinks&amp;quot; she did, per-
haps after detecting some background noise
</listItem>
<page confidence="0.996735">
69
</page>
<bodyText confidence="0.999611428571429">
(a &amp;quot;phantom input&amp;quot;). The dialogue system&apos;s
reaction to something the user didn&apos;t say can
cause surprise and confusion in the user.
Here the visible reactions of an ECA might
help the user understand what has happened
and allow her to steer the dialogue back on
track.
</bodyText>
<subsectionHeader confidence="0.998664">
3.3 Recognition Confidence Scheme
</subsectionHeader>
<bodyText confidence="0.999748857142857">
Once the user utterance has been recognised, in-
formation confirmation strategies are commonly
used in dialogue systems. Different strategies are
taken depending on the level of confidence in the
correctness of the user locution as captured by the
speech recognition unit (San-Segundo et al., 2001).
Our scheme is as follows:
</bodyText>
<listItem confidence="0.916665538461538">
• High confidence: if recognition confidence
is high enough to safely assume that no error
has occurred, the dialogue strategy is made
more fluent, with no confirmations being
sought by the system.
• Intermediate confidence: the result is re-
garded as uncertain and the system tries im-
plicit confirmation (by including the uncer-
tain piece of information in a question about
something else.) This, combined with a
mixed initiative approach, allows the user to
correct the system if an error did occur.
• Low confidence: in this case recognition
</listItem>
<bodyText confidence="0.984642651162791">
has probably failed. When this happens the
dialogue switches to a more guided strategy,
with explicit confirmation of the collected
information and no mixed initiative. The
user&apos;s reply may confirm that the system
understood correctly, in which case the dia-
logue continues to flow normally, or, on the
other hand, it may show that there was a
recognition error. In this case an error re-
covery mechanism begins.
In addition to the dialogue strategies, ECAs
could also be used to reflect in their manner the
level of confidence that the system has understood
the user, in accordance with the confirmation dia-
logue strategies. While the user speaks, our ECA
will, if the recognition confidence level is high,
nod her head (Cassell et al., 2000), smile and have
her eyes fully open to give the user feedback that
everything is going well and the system is under-
standing. If, on the other hand, confidence is low,
in order to make it clearer to the user that there
might be some problem with recognition and that
extra care should be taken, an option might be for
the ECA to gesture in such a way as to show that
she isn&apos;t quite sure she&apos;s understood but is making
an effort to. We have attempted to create this effect
by having the ECA lean her head slightly to one
side, stop smiling and mildly squint. Our goal,
once again, is to find out whether these cues do
indeed help users realise what the situation is. This
is especially important if it helps to avoid the well-
known problem of falling into error spirals when a
recognition error occurs in a spoken dialogue sys-
tem (Bulyko et al., 2005). In the case of intermedi-
ate recognition confidence followed by a mixed
initiative strategy involving implicit confirmation,
specific gestures could also be envisaged. We have
chosen not to include specific gestures for these
situations in our first trials, however, so as not to
obscure our observations for the high and low con-
fidence cases. A neutral stance for the intermediate
confidence level should be a useful reference
against which to compare the other two cases.
</bodyText>
<subsectionHeader confidence="0.982501">
3.4 Recognition Problems
</subsectionHeader>
<bodyText confidence="0.999941346153846">
We will consider those situations in which the sys-
tem finds the user&apos;s utterance incomprehensible
(no-match situations) and those in which the sys-
tem gets the user&apos;s message wrong (recognitions
errors). When a no-match occurs there are two
ways in which an ECA can be useful. First, what
the character should say must be carefully pon-
dered to ensure that the user is aware that the sys-
tem didn&apos;t understand what she said and that the
immediate objective is to solve this particular
problem. This knowledge can make the user more
patient with the system and tolerate better the un-
expected lengthening of the interaction (Goldberg,
2003). Second, the ECAs manner should try to
keep the user in a positive attitude. A common
problem in no-match and error recovery situations
is that the user becomes irritated or hyperarticu-
lates in an attempt to make herself understood,
which in fact increases the probability of yet an-
other no-match or a recognition error. This we
should obviously try to avoid.
The ECA behaviour strategy we will test in no-
match situations is to have the character lean to-
wards the camera and raise her eyebrows (the idea
being to convey a sense of surprise coupled with
friendly interest). We have based our gesture on
</bodyText>
<page confidence="0.995359">
70
</page>
<bodyText confidence="0.99843775">
one given in (Fagerberg et al., 2003). If the user
points out to the system that there has been a rec-
ognition error in a way that gives the correct in-
formation at the same time, then the ECA will con-
firm the corrected information with special empha-
sis in speech and gesture. For this purpose we have
designed a beat gesture with both hands (see Table
1).
</bodyText>
<subsectionHeader confidence="0.998209">
3.5 Help offers and request
</subsectionHeader>
<bodyText confidence="0.9997415">
It will be interesting to see whether the fact that
help is offered by an animated character (the ECA)
is regarded by users to be more user-friendly than
otherwise. If users feel more comfortable with the
ECA, perhaps they will show greater initiative in
requesting help from the system; and when it is
offered by the system (when a problem situation
occurs), the presence of a friendly ECA might help
control user frustration. While the ECA is giving
the requested information, she will perform a beat
gesture with both hands for emphasis, and she will
also change posture. The idea is to see whether this
captures the interest of the user, makes her more
confident and the experience more pleasant or, on
the contrary, it distracts the user and makes help
delivery less effective.
Figure 1 illustrates a dialogue sequence includ-
ing the association between the different dialogue
strategies and the ECA gesture sequences after a
user&apos;s utterance.
</bodyText>
<sectionHeader confidence="0.985701" genericHeader="method">
4 Experimental set up
</sectionHeader>
<bodyText confidence="0.998201333333333">
Gestures and nonverbal communication are cul-
ture-dependent. This is an important fact to take
into account because a single gesture might be in-
terpreted in different ways depending on the user&apos;s
culture (Kleinsmith et al., 2006). Therefore, a nec-
essary step prior to the evaluation of the various
hypotheses put forward in the previous section is to
test the gestures we have implemented for our
ECA, within the framework designed for our study.
This implies validating the gestures for Spanish
users, since we have based them on studies within
the Anglo-Saxon culture.
</bodyText>
<subsectionHeader confidence="0.987408">
4.1 Procedure
</subsectionHeader>
<bodyText confidence="0.999871130434783">
For the purpose of testing the gesture repertoire
developed for our ECA we have conceived an
evaluation environment that simulates a realistic
mobile videotelephony application that allows us-
ers to remotely check the state (e.g., on/off) of sev-
eral household devices (lights, heating, etc.). Our
dialogue system incorporates mixed initiative, er-
ror recovery subdialogues, context-dependent help
and the production of guided or flexible dialogues
according to the confidence levels of the speech
recogniser. Our environment uses Nuance Com-
munications&apos; speech recognition technology
(www.nuance.com). The ECA character has been
designed by Haptek (www.haptek.com).
During the gesture validation tests users didn&apos;t
interact directly with the dialogue system. We first
asked the users to watch a system simulator (a
video recording of a user interacting with the sys-
tem), so that they could see the ECA performing
the gestures in the context of a real dialogue.
After watching the simulation the users were
asked to fill out a questionnaire. The questionnaire
allowed users to view isolated clips of each
</bodyText>
<figureCaption confidence="0.993328">
Figure 1: Dialogue strategies and related gesture sequence
</figureCaption>
<page confidence="0.992019">
71
</page>
<bodyText confidence="0.966552833333333">
of the dialogue gestures (the eight that had ap-
peared in the video). To each gesture clip were as-
sociated questions basically covering the following
three aspects:
• Gesture interpretation: Users are asked to
interpret each gesture, choosing one from
among several given options (the same op-
tions for all gestures). The aim is to see
whether the meaning and intention of each
gesture are clear. In addition users told us
whether they thought they had seen the ges-
ture in the previous dialogue sample.
</bodyText>
<listItem confidence="0.720288538461538">
• Gesture design: Do users think the gesture
is well made and does it look natural? To
answer this question we asked users to rate
the quality, expressiveness and clarity of the
ECAs gesture (on a 9-point Likert scale).
• User expectations: Users rated how useful
they thought each gesture was (on a 9-point
Likert scale). The idea is to juxtapose the
utility function of the gestures in the users&apos;
mental model to our own when we designed
them, and evaluate the similarity. In addition
we collected suggestions as to how the users
thought the gestures could be improved.
</listItem>
<subsectionHeader confidence="0.623796">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999974144927536">
We recruited 17 test users (most of them students
between 20 and 25 years of age) for our trial. The
results concerning the three previously mentioned
aspects are shown in Table 2. In the case of the
gesture interpretation, we present the percentage
of the users who interpreted each gesture &amp;quot;cor-
rectly&amp;quot; (i.e., as we had intended when we designed
them). Depending on this percentage we label each
gesture as &amp;quot;Good&amp;quot;, &amp;quot;Average&amp;quot;, or &amp;quot;Bad&amp;quot;. For each
of the parameters for gesture design and user ex-
pectations we give the mean and the standard de-
viation of the Likert scale scores. We label the av-
erage scores as &amp;quot;Low&amp;quot; (Likert score between 1 and
3), Medium (4-6) or &amp;quot;High&amp;quot; (7-9).
We now discuss the results separately for each
of the dimensions:
Regarding user expectations, the values for each
gesture are High except for two of them, valued as
Medium. These two gestures are the welcome ges-
ture and the gesture for offering help. In the case of
the welcome gesture, users probably believe the
beginning of the dialogue is already well enough
defined when the ECA starts to speak. If so, users
might see an element of redundancy in the wel-
come gesture, lowering its perceived utility in the
dialogue process. On the other hand, the help ges-
ture utility might be valued lower than the rest be-
cause many users didn&apos;t seem to understand its
purpose (the clarity of the Help gesture was the
least valued of all, µ=5.117). Nevertheless, the
general user impressions of the utility of the evalu-
ated gesture repertoire fairly high.
In relation to gesture design, we can see that,
overall, the marks for quality and expressiveness
are high. This implies our gesture design is, on the
whole, adequate. Regarding the clarity of the ges-
tures, three of them are valued as Medium. These
are the gestures expressing Give Turn, Error Re-
covery and Help offer. This could be related to the
prevailing opinion among users that there are a few
confusing gestures, although they are better under-
stood in the context of the application, when you
listen to what the ECA says.
Only half of the gestures were properly inter-
preted by the users. Those that weren&apos;t (Give Turn,
Take Turn, Error Recovery and the Help gesture)
are, we realize, the subtlest in the repertoire, so we
asked ourselves if there could be relation between
a bad interpretation of the gesture and the whether
that user didn&apos;t remember seeing the gesture in the
dialogue. In Figure 2 we show the number of users
who claimed they hadn&apos;t seen the ECA gestures
during the dialogue sample. The coloured bars rep-
resent the overall accuracy in the interpretation of
the gesture. We may observe that the gestures that
a larger number of users hadn&apos;t seen in the dia-
logue, and therefore, hadn&apos;t an image of in proper
context, tended also to be considered more unclear.
We may conclude that some gestures need to be
evaluated in context. In any case, and in spite of
the uncertainty we have found regarding the inter-
pretation of certain gestures, we believe the posi-
tive evaluation by the users for the expressiveness
and the quality of the gestures justifies us in vali-
dating our gestural repertoire for the next research
stage where we will evaluate how well our ECA
gestures function under real interaction conditions
(taking into account objective data related to dia-
logue efficiency).
</bodyText>
<page confidence="0.993338">
72
</page>
<table confidence="0.987111476190476">
INTERPRETATION DESIGN EXPECTATIONS
Good Interpretation Quality Clarity Expressiveness Usefulness
���
G1 88.23 7.117 (0.927) 7.5 88 (1.277) 6.764 (1.147) 5.647 (2.119)
Wellcome Good High High High Medium
G2 35.29 6.647 (1.057) 5. 823 (1.333) 6.470 (1.007) 6.5 88 (1.543)
Give Turn Average High Medium High High
G3 23.53 7.117 (1.166) 6.705 (1.447) 6.941 (1.444) 6.647 (1.271)
Take Turn Bad High High High High
G4 82.35 7.05 8 (1.0 88) 7.176 (1.1 85) 7.176 (0.727) 6.5 88 (1.622)
Wait Good High High High High
G5 76.47 8.294 (0.5 87) 8.05 8 (1.02 8) 8.05 8 (1.02 8) 7.941 (1.02 8)
Confirmation Good High High High High
(Low confidence)
G6 94.11 7.529 (1.124) 7.529 (1.124) 7.705(1.263) 7.5 88 (1.175)
Confirmation (High Good High High High High
confidence)
G7 41.17 6.941 (1.0 88) 5.5 88 (2.032) 6.529 (1.462) 6.05 8 (1.390)
Error Recovery Average High Medium High High
G8 35.29 6. 823 (1.1 85) 5.117 (1.932) 6.05 8(1.560) 5.529 (1.771)
Help Average High Medium High Medium
</table>
<tableCaption confidence="0.999377">
Table 2: Results of the gesture validation tests.
</tableCaption>
<figureCaption confidence="0.9651285">
Figure 2: Interpretation vs. `visibility&apos; of the ges-
tures.
</figureCaption>
<sectionHeader confidence="0.974509" genericHeader="conclusions">
5 Conclusions and future lines of work
</sectionHeader>
<bodyText confidence="0.999857681818182">
In this article we have identified a range of prob-
lem situations that may arise in dialogue systems,
and defined various strategies for using an ECA to
improve user-machine interaction throughout the
whole dialogue. We have developed an experimen-
tal set up for a user validation of ECA gestures in
the dialogue system and have obtained quantitative
results and user opinions to improve the design of
the gestures. The results of this validation allow us
to be in a position to begin testing our dialogue
system and evaluate our ECA gestures in the con-
text of a real dialogue.
In future experiments we will attempt to go one
step further and analyse how empathic emotions vs.
self-oriented behaviour (see Brave et al., 2005)
may affect the resolution of a variety of dialogue
situations. To this end we plan to design ECA pro-
totypes that incorporate specific emotions, hoping
to learn how best to connect empathically with the
user, and what effects this may have on dialogue
dynamics and the overall user perception of the
system.
</bodyText>
<sectionHeader confidence="0.997803" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.928780647058823">
Linda Bell and Joakim Gustafson, 2003. Child and
Adult SpeakerAdaptation during Error Resolution in
a Publicly Available Spoken Dialogue System. Pro-
ceedings of Eurospeech 03, Geneve, Schweiz.
Timothy W. Bickmore, Justine Cassell, Jan van Kup-
pevelt, Laila Dybkjaer and Niels Ole Bernsen, 2004.
Natural, Intelligent and Effective Interaction with
Multimodal Dialogue Systems, chapter Social Dia-
logue with Embodied Conversational Agents. Kluwer
Academic.
Susan J. Boyce, 1999. Spoken natural language dia-
logue systems: user interface issues for the future. In
Human Factors and Voice Interactive Systems. D.
Gardner-Bonneau Ed. Norwell, Massachusetts, Klu-
wer Academic Publishers: 37-62.
Scott Brave, Clifford Nass, Kevin Hutchinson, 2005.
Computers that care: investigating the effects of ori-
</reference>
<page confidence="0.993852">
73
</page>
<reference confidence="0.999001946236559">
entation of emotion exhibited by an embodied com-
puter agent. Int. J. Human-Computer Studies, Nr. 62,
Issue 2, pp. 161-17 8.
Ivan Bulyko, Katrin Kirchhoff, Mari Ostendorf, Julie
Goldberg, 2005 Error correction detection and re-
sponse generation in a spoken dialogue system.
Speech Communication 45, 271-2 88.
Justine Cassell, Kristinn R. Thorisson, 1999. The power
of a nod and aglance: envelope vs. emotional feed-
back in animated conversational agents. Applied Ar-
tificial Intelligence, vol.13, pp.519-53 8.
Justine Cassell and Matthew Stone, 1999. Living Hand
to Mouth: Psychological Theories about Speech and
Gesture in Interactive Dialogue Systems. Proceed-
ings of the AAAI 1999 Fall Symposium on Psycho-
logical Models of Communication in Collaborative
Systems, pp. 34-42. November 5-7, North Falmouth,
MA, 1999.
Justine Cassell, Timothy W. Bickmore, Hannes
Vilhjalmsson and Hao Yan, 2000. More than just a
pretty face: affordances of embodiment. In Proceed-
ings of the 5th international Conference on intelligent
User interfaces.
Justine Cassell, Yukiko I. Nakano, Timothy W. Bick-
more, Candace L. Sidner and Charles Rich, 2001.
Non-verbal cues for discourse structure. In Proceed-
ings of the 39th Annual Meeting on Association For
Computational Linguistics.
Richard Catrambone, 2002 Anthropomorphic agents as
a user interface paradigm: Experimental findings
and a framework for research. In: Proceedings of the
24th Annual Conference of the Cognitive Science
Society (pp. 166-171), Fairfax, VA, August.
Nicole Chovil, 1992. Discourse-Oriented Facial Dis-
plays in Conversation. Research on Language and
Social Interaction, 25, 163-194.
Petra Fagerberg, Anna Stahl, Kristina Hook, 2003. De-
signing Gestures for Afective Input: an Analysis of
Shape, Effort and Valence. In Proceedings of Mobile
Ubiquitious and Multimedia, Norrkoping, Sweden.
Julie Goldberg, Mari Ostendorf, Katrin Kirchhoff, 2003.
The impact of response wording in error correction
subdialogs, In EHSD-2003, 101-106.
Kate Hone, 2005. Animated Agents to reduce user frus-
tration, in The 19th British HCI Group Annual Con-
ference, Edinburgh, UK.
Adam Kendon, 1990. Conducting interaction: patterns
of behaviour in focused encounters, Cambridge Uni-
versity Press.
Andrea Kleinsmith, P. Ravindra De Silva, Nadia Bian-
chi-Berthouze, 2006 Cross-cultural differences in
recognizing affect from body posture Interacting with
computers 10 1371-13 89
Robert M. Krauss, Yihsiu Chen and Purnima Chawla,
1996 Nonverbal behavior and nonverbal communica-
tion: What do conversational hand gestures tell us?
In M. Zanna (Ed.), Advances in experimental social
psychology (pp. 3 89 450).San Diego, CA: Academic
Press.
Dominic W. Massaro, Michael M. Cohen, Jonas
Beskow and Ronald A. Cole, 2000.Developing and
evaluating conversational agents. In Embodied Con-
versational Agents MIT Press, Cambridge, MA, 2 87-
31 8.
Sharon Oviatt. 1994. Interface techniques for minimiz-
ing disfluent input to spoken language systems. In
Proc. CHI&apos;94 (pp. 205-210) Boston, ACM Press,
1994
Sharon Oviatt and Robert VanGent, 1996, Error resolu-
tion duringmultimodal humancomputer interaction.
Proc. International Conference on Spoken Language
Processing, 1 204-207.
Sharon Oviatt, Margaret MacEachern, and Gina-Anne
Levow, G.,199 8. Predicting hyperarticulate speech
during human-computer error resolution. Speech
Communication, vol.24, 2, 1-23.
Sharon Oviatt, and Bridget Adams, 2000. Designing
and evaluating conversational interfaces with ani-
mated characters. Embodied conversational agents,
MIT Press: 319-345.
Isabella Poggi, 2001. How to decide which gesture to
make according to our goals and our contextual
knowledge. Paper presented at Gesture Workshop
2001 London 18th-20th April, 2001
Ruben San-Segundo, Juan M. Montero, Javier Ferreiros,
Ricardo C6rdoba, Jose M. Pardo, 2001 Designing
Confirmation Mechanisms and Error Recover Tech-
niques in a Railway Information System for Spanish.
SIGDIAL. Septiembre 1-2, Aalborg (Dinamarca).
Heike Schaumburg, 2001. Computers as tools or as
social actors?the users&apos; perspective on anthropomor-
phic agents.International Journal of Cooperative In-
formation Systems.10, 1, 2, 217-234.
</reference>
<page confidence="0.999135">
74
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.195709">
<title confidence="0.992061">Design and validation of ECA gestures to improve dialogue system robustness</title>
<author confidence="0.9365815">Beatriz Lopez</author>
<author confidence="0.9365815">Alvaro Hernandez</author>
<author confidence="0.9365815">David Ruben Fernandez</author>
<author confidence="0.9365815">Luis</author>
<affiliation confidence="0.895544333333333">GAPS, Signal, Systems and Department Universidad Polit6cnica de</affiliation>
<address confidence="0.44105">Ciudad Universitaria s/n, 2 8040 Madrid, Spain</address>
<email confidence="0.833404">alvaro@gaps.ssr.upm.es</email>
<author confidence="0.960348">Doroteo Torre</author>
<affiliation confidence="0.854217333333333">ATVS, Escuela Polit6cnica Universidad Aut6noma de Ciudad Universitaria de</affiliation>
<address confidence="0.860943">2 8049 Madrid, Spain</address>
<intro confidence="0.86255">Doroteo.torre@uam.es</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Linda Bell</author>
<author>Joakim Gustafson</author>
</authors>
<title>Child and Adult SpeakerAdaptation during Error Resolution in a Publicly Available Spoken Dialogue System.</title>
<date>2003</date>
<booktitle>Proceedings of Eurospeech 03,</booktitle>
<location>Geneve, Schweiz.</location>
<contexts>
<context position="1657" citStr="Bell and Gustafson, 2003" startWordPosition="239" endWordPosition="242">ance with some frustration when error recovery mechanisms come into play, which does not help the recognition process, and as a result using the system seems slow and unnatural (Boyce, 1999). At the same time, embodied conversational agents (ECAs) are gaining prominence in HCI systems, since they make for more user-friendly applications while increasing communication effectiveness. There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al. (2004) and Brave et al. (2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem. Our research explores the potential of ECAs to assist in, or resolve, certain difficult dialogue situations that have been identified by various leading authors in the field (Cassell and Thorisson, 1999; Cassell and Stone, 1999), as well as a few we ourAbstract In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conversational agent (ECAs), to assess their soundness with a view to applying said gestures in a forthcoming experiment to explore the</context>
</contexts>
<marker>Bell, Gustafson, 2003</marker>
<rawString>Linda Bell and Joakim Gustafson, 2003. Child and Adult SpeakerAdaptation during Error Resolution in a Publicly Available Spoken Dialogue System. Proceedings of Eurospeech 03, Geneve, Schweiz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy W Bickmore</author>
<author>Justine Cassell</author>
<author>Jan van Kuppevelt</author>
<author>Laila Dybkjaer</author>
<author>Niels Ole Bernsen</author>
</authors>
<title>Natural, Intelligent and Effective Interaction with Multimodal Dialogue Systems, chapter Social Dialogue with Embodied Conversational Agents.</title>
<date>2004</date>
<publisher>Kluwer Academic.</publisher>
<marker>Bickmore, Cassell, van Kuppevelt, Dybkjaer, Bernsen, 2004</marker>
<rawString>Timothy W. Bickmore, Justine Cassell, Jan van Kuppevelt, Laila Dybkjaer and Niels Ole Bernsen, 2004. Natural, Intelligent and Effective Interaction with Multimodal Dialogue Systems, chapter Social Dialogue with Embodied Conversational Agents. Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan J Boyce</author>
</authors>
<title>Spoken natural language dialogue systems: user interface issues for the future.</title>
<date>1999</date>
<booktitle>In Human Factors and Voice Interactive Systems. D. Gardner-Bonneau Ed.</booktitle>
<pages>37--62</pages>
<publisher>Kluwer Academic Publishers:</publisher>
<location>Norwell, Massachusetts,</location>
<contexts>
<context position="1222" citStr="Boyce, 1999" startWordPosition="169" endWordPosition="170"> Human-Computer Interaction (HCI) applications. The technologies involved in SLDSs (speech recognition, dialogue design, etc.) are mature enough to allow the creation of trustworthy applications. However, robustness problems still arise in concrete limited dialogue systems because there are many error sources that may cause the system to perform poorly. A common example is that users tend to repeat their previous utterance with some frustration when error recovery mechanisms come into play, which does not help the recognition process, and as a result using the system seems slow and unnatural (Boyce, 1999). At the same time, embodied conversational agents (ECAs) are gaining prominence in HCI systems, since they make for more user-friendly applications while increasing communication effectiveness. There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al. (2004) and Brave et al. (2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem. Our research explores the potential of ECAs to assist in, or resolve, certain d</context>
</contexts>
<marker>Boyce, 1999</marker>
<rawString>Susan J. Boyce, 1999. Spoken natural language dialogue systems: user interface issues for the future. In Human Factors and Voice Interactive Systems. D. Gardner-Bonneau Ed. Norwell, Massachusetts, Kluwer Academic Publishers: 37-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Brave</author>
<author>Clifford Nass</author>
<author>Kevin Hutchinson</author>
</authors>
<title>Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent.</title>
<date>2005</date>
<journal>Int. J. Human-Computer Studies, Nr. 62, Issue</journal>
<volume>2</volume>
<pages>161--17</pages>
<contexts>
<context position="1610" citStr="Brave et al. (2005)" startWordPosition="231" endWordPosition="234">users tend to repeat their previous utterance with some frustration when error recovery mechanisms come into play, which does not help the recognition process, and as a result using the system seems slow and unnatural (Boyce, 1999). At the same time, embodied conversational agents (ECAs) are gaining prominence in HCI systems, since they make for more user-friendly applications while increasing communication effectiveness. There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al. (2004) and Brave et al. (2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem. Our research explores the potential of ECAs to assist in, or resolve, certain difficult dialogue situations that have been identified by various leading authors in the field (Cassell and Thorisson, 1999; Cassell and Stone, 1999), as well as a few we ourAbstract In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conversational agent (ECAs), to assess their soundness with a view to applying said gest</context>
</contexts>
<marker>Brave, Nass, Hutchinson, 2005</marker>
<rawString>Scott Brave, Clifford Nass, Kevin Hutchinson, 2005. Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent. Int. J. Human-Computer Studies, Nr. 62, Issue 2, pp. 161-17 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Bulyko</author>
<author>Katrin Kirchhoff</author>
<author>Mari Ostendorf</author>
<author>Julie Goldberg</author>
</authors>
<title>Error correction detection and response generation in a spoken dialogue system.</title>
<date>2005</date>
<journal>Speech Communication</journal>
<volume>45</volume>
<pages>271--2</pages>
<contexts>
<context position="14845" citStr="Bulyko et al., 2005" startWordPosition="2475" endWordPosition="2478">me problem with recognition and that extra care should be taken, an option might be for the ECA to gesture in such a way as to show that she isn&apos;t quite sure she&apos;s understood but is making an effort to. We have attempted to create this effect by having the ECA lean her head slightly to one side, stop smiling and mildly squint. Our goal, once again, is to find out whether these cues do indeed help users realise what the situation is. This is especially important if it helps to avoid the wellknown problem of falling into error spirals when a recognition error occurs in a spoken dialogue system (Bulyko et al., 2005). In the case of intermediate recognition confidence followed by a mixed initiative strategy involving implicit confirmation, specific gestures could also be envisaged. We have chosen not to include specific gestures for these situations in our first trials, however, so as not to obscure our observations for the high and low confidence cases. A neutral stance for the intermediate confidence level should be a useful reference against which to compare the other two cases. 3.4 Recognition Problems We will consider those situations in which the system finds the user&apos;s utterance incomprehensible (n</context>
</contexts>
<marker>Bulyko, Kirchhoff, Ostendorf, Goldberg, 2005</marker>
<rawString>Ivan Bulyko, Katrin Kirchhoff, Mari Ostendorf, Julie Goldberg, 2005 Error correction detection and response generation in a spoken dialogue system. Speech Communication 45, 271-2 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Kristinn R Thorisson</author>
</authors>
<title>The power of a nod and aglance: envelope vs. emotional feedback in animated conversational agents.</title>
<date>1999</date>
<journal>Applied Artificial Intelligence,</journal>
<volume>13</volume>
<pages>519--53</pages>
<contexts>
<context position="1945" citStr="Cassell and Thorisson, 1999" startWordPosition="285" endWordPosition="288"> since they make for more user-friendly applications while increasing communication effectiveness. There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al. (2004) and Brave et al. (2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem. Our research explores the potential of ECAs to assist in, or resolve, certain difficult dialogue situations that have been identified by various leading authors in the field (Cassell and Thorisson, 1999; Cassell and Stone, 1999), as well as a few we ourAbstract In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conversational agent (ECAs), to assess their soundness with a view to applying said gestures in a forthcoming experiment to explore the possibilities ECAs can offer to overcome typical robustness problems in spoken language dialogue systems (SLDSs). The paper is divided into two parts: First we carry our a literature review to acquire a sense of the extent to which ECAs can help overcome user frustration during human-ma</context>
<context position="6712" citStr="Cassell and Thorisson (1999)" startWordPosition="1057" endWordPosition="1060">n or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real dialogue system. In Table 1 we show the basic set of gestures we are using as a starting point. They are based mainly on descriptions in Bickmore (et al., 2004) and Cassell (et al., 2000), and on recommendations in Cassell and Thorisson (1999), Cassell (et al., 2001), Chovil (1992), Kendon (1990) and San-Segundo (et al., 2001), to which we have added a few suggestions of our own. Dialogue stage ECA behaviour (movements, gestures and other cues) Initiation 1. Welcome message: look at the camera, (welcoming the smile, wave hand user) 2. Explanation of the task: zoom in 3. Zoom out, lights dim Give turn Look directly at the user, raise eyebrows. Camera zooms out. Lights dim. Take turn Look directly at the user, raise hands into gesture space. Camera zooms in. Light gets brighter. Wait Slight leaning back, one arm crossed and the other</context>
</contexts>
<marker>Cassell, Thorisson, 1999</marker>
<rawString>Justine Cassell, Kristinn R. Thorisson, 1999. The power of a nod and aglance: envelope vs. emotional feedback in animated conversational agents. Applied Artificial Intelligence, vol.13, pp.519-53 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Matthew Stone</author>
</authors>
<title>Living Hand to Mouth: Psychological Theories about Speech and Gesture in Interactive Dialogue Systems.</title>
<date>1999</date>
<booktitle>Proceedings of the AAAI 1999 Fall Symposium on Psychological Models of Communication in Collaborative Systems,</booktitle>
<pages>34--42</pages>
<location>North Falmouth, MA,</location>
<contexts>
<context position="1971" citStr="Cassell and Stone, 1999" startWordPosition="289" endWordPosition="292">r-friendly applications while increasing communication effectiveness. There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al. (2004) and Brave et al. (2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem. Our research explores the potential of ECAs to assist in, or resolve, certain difficult dialogue situations that have been identified by various leading authors in the field (Cassell and Thorisson, 1999; Cassell and Stone, 1999), as well as a few we ourAbstract In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conversational agent (ECAs), to assess their soundness with a view to applying said gestures in a forthcoming experiment to explore the possibilities ECAs can offer to overcome typical robustness problems in spoken language dialogue systems (SLDSs). The paper is divided into two parts: First we carry our a literature review to acquire a sense of the extent to which ECAs can help overcome user frustration during human-machine interaction. Then we</context>
</contexts>
<marker>Cassell, Stone, 1999</marker>
<rawString>Justine Cassell and Matthew Stone, 1999. Living Hand to Mouth: Psychological Theories about Speech and Gesture in Interactive Dialogue Systems. Proceedings of the AAAI 1999 Fall Symposium on Psychological Models of Communication in Collaborative Systems, pp. 34-42. November 5-7, North Falmouth, MA, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Timothy W Bickmore</author>
<author>Hannes Vilhjalmsson</author>
<author>Hao Yan</author>
</authors>
<title>More than just a pretty face: affordances of embodiment.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th international Conference on intelligent User interfaces.</booktitle>
<contexts>
<context position="5890" citStr="Cassell et al., 2000" startWordPosition="923" endWordPosition="926">reduce frustration, and by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real dialogue system. In T</context>
<context position="13995" citStr="Cassell et al., 2000" startWordPosition="2315" endWordPosition="2318">e collected information and no mixed initiative. The user&apos;s reply may confirm that the system understood correctly, in which case the dialogue continues to flow normally, or, on the other hand, it may show that there was a recognition error. In this case an error recovery mechanism begins. In addition to the dialogue strategies, ECAs could also be used to reflect in their manner the level of confidence that the system has understood the user, in accordance with the confirmation dialogue strategies. While the user speaks, our ECA will, if the recognition confidence level is high, nod her head (Cassell et al., 2000), smile and have her eyes fully open to give the user feedback that everything is going well and the system is understanding. If, on the other hand, confidence is low, in order to make it clearer to the user that there might be some problem with recognition and that extra care should be taken, an option might be for the ECA to gesture in such a way as to show that she isn&apos;t quite sure she&apos;s understood but is making an effort to. We have attempted to create this effect by having the ECA lean her head slightly to one side, stop smiling and mildly squint. Our goal, once again, is to find out whet</context>
</contexts>
<marker>Cassell, Bickmore, Vilhjalmsson, Yan, 2000</marker>
<rawString>Justine Cassell, Timothy W. Bickmore, Hannes Vilhjalmsson and Hao Yan, 2000. More than just a pretty face: affordances of embodiment. In Proceedings of the 5th international Conference on intelligent User interfaces.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Yukiko I Nakano</author>
<author>Timothy W Bickmore</author>
<author>Candace L Sidner</author>
<author>Charles Rich</author>
</authors>
<title>Non-verbal cues for discourse structure.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting on Association For Computational Linguistics.</booktitle>
<contexts>
<context position="5912" citStr="Cassell et al., 2001" startWordPosition="927" endWordPosition="930">d by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real dialogue system. In Table 1 we show the bas</context>
</contexts>
<marker>Cassell, Nakano, Bickmore, Sidner, Rich, 2001</marker>
<rawString>Justine Cassell, Yukiko I. Nakano, Timothy W. Bickmore, Candace L. Sidner and Charles Rich, 2001. Non-verbal cues for discourse structure. In Proceedings of the 39th Annual Meeting on Association For Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Catrambone</author>
</authors>
<title>Anthropomorphic agents as a user interface paradigm: Experimental findings and a framework for research. In:</title>
<date>2002</date>
<booktitle>Proceedings of the 24th Annual Conference of the Cognitive Science Society</booktitle>
<pages>166--171</pages>
<location>Fairfax, VA,</location>
<contexts>
<context position="8343" citStr="Catrambone, 2002" startWordPosition="1331" endWordPosition="1332">ECA at this stage &amp;quot;humanises&amp;quot; the system (Oviatt and Adams, 2000). This is a problem, first because once a user has such high expectations the system can only end up disappointing her, and secondly because the user will tend to use more natural (and thus complex) communication, which the system is unable to handle, and the experience will ultimately be frustrating. On the other hand, especially in the case of new users, contact with a dialoguing animated character may have the effect that the user&apos;s level of attention to the actual information that is being given is reduced (Schaumburg, 2001; Catrambone, 2002). Thus the goal is to present a human-like interface that is, at the same time, less striking and thus less distracting at first contact, and one that clearly &amp;quot;sets the rules&amp;quot; of the interaction and makes sure that the user keeps it framed within the capability of the system. We have designed a welcome gesture for our ECA based on the recommendations in Kendon (1990), to test whether or not it fosters a sense of ease in the user and helps her concentrate on the task at hand. Playing with the zoom, the size and the position of the ECA on the screen may also prove to be useful to frame the commu</context>
</contexts>
<marker>Catrambone, 2002</marker>
<rawString>Richard Catrambone, 2002 Anthropomorphic agents as a user interface paradigm: Experimental findings and a framework for research. In: Proceedings of the 24th Annual Conference of the Cognitive Science Society (pp. 166-171), Fairfax, VA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Chovil</author>
</authors>
<title>Discourse-Oriented Facial Displays in Conversation.</title>
<date>1992</date>
<journal>Research on Language and Social Interaction,</journal>
<volume>25</volume>
<pages>163--194</pages>
<contexts>
<context position="5926" citStr="Chovil, 1992" startWordPosition="931" endWordPosition="932">or recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real dialogue system. In Table 1 we show the basic set of gest</context>
</contexts>
<marker>Chovil, 1992</marker>
<rawString>Nicole Chovil, 1992. Discourse-Oriented Facial Displays in Conversation. Research on Language and Social Interaction, 25, 163-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petra Fagerberg</author>
<author>Anna Stahl</author>
<author>Kristina Hook</author>
</authors>
<title>Designing Gestures for Afective Input: an Analysis of Shape, Effort and Valence.</title>
<date>2003</date>
<booktitle>In Proceedings of Mobile Ubiquitious and Multimedia, Norrkoping,</booktitle>
<contexts>
<context position="16623" citStr="Fagerberg et al., 2003" startWordPosition="2773" endWordPosition="2776">anner should try to keep the user in a positive attitude. A common problem in no-match and error recovery situations is that the user becomes irritated or hyperarticulates in an attempt to make herself understood, which in fact increases the probability of yet another no-match or a recognition error. This we should obviously try to avoid. The ECA behaviour strategy we will test in nomatch situations is to have the character lean towards the camera and raise her eyebrows (the idea being to convey a sense of surprise coupled with friendly interest). We have based our gesture on 70 one given in (Fagerberg et al., 2003). If the user points out to the system that there has been a recognition error in a way that gives the correct information at the same time, then the ECA will confirm the corrected information with special emphasis in speech and gesture. For this purpose we have designed a beat gesture with both hands (see Table 1). 3.5 Help offers and request It will be interesting to see whether the fact that help is offered by an animated character (the ECA) is regarded by users to be more user-friendly than otherwise. If users feel more comfortable with the ECA, perhaps they will show greater initiative in</context>
</contexts>
<marker>Fagerberg, Stahl, Hook, 2003</marker>
<rawString>Petra Fagerberg, Anna Stahl, Kristina Hook, 2003. Designing Gestures for Afective Input: an Analysis of Shape, Effort and Valence. In Proceedings of Mobile Ubiquitious and Multimedia, Norrkoping, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Goldberg</author>
<author>Mari Ostendorf</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>The impact of response wording in error correction subdialogs,</title>
<date>2003</date>
<booktitle>In EHSD-2003,</booktitle>
<pages>101--106</pages>
<marker>Goldberg, Ostendorf, Kirchhoff, 2003</marker>
<rawString>Julie Goldberg, Mari Ostendorf, Katrin Kirchhoff, 2003. The impact of response wording in error correction subdialogs, In EHSD-2003, 101-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kate Hone</author>
</authors>
<title>Animated Agents to reduce user frustration,</title>
<date>2005</date>
<booktitle>in The 19th British HCI Group Annual Conference,</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="5353" citStr="Hone, 2005" startWordPosition="837" endWordPosition="838"> but also to regulate the flow of the dialogue, as Cassell points out (in Bickmore et al., 2004). Improving error recovery: The process of recognition error recovery usually leads to a certain degree of user frustration (see Oviatt and VanGent, 1996). Indeed, it is common, once an error occurs, to enter into an error spiral in which the system is trying to recover, the user gets ever more frustrated, and this frustration interferes in the recognition process making the situation worse (Oviatt et al., 199 8). ECAs may help reduce frustration, and by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal</context>
</contexts>
<marker>Hone, 2005</marker>
<rawString>Kate Hone, 2005. Animated Agents to reduce user frustration, in The 19th British HCI Group Annual Conference, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kendon</author>
</authors>
<title>Conducting interaction: patterns of behaviour in focused encounters,</title>
<date>1990</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5941" citStr="Kendon, 1990" startWordPosition="933" endWordPosition="934">re effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real dialogue system. In Table 1 we show the basic set of gestures we are usi</context>
<context position="8712" citStr="Kendon (1990)" startWordPosition="1396" endWordPosition="1397">e other hand, especially in the case of new users, contact with a dialoguing animated character may have the effect that the user&apos;s level of attention to the actual information that is being given is reduced (Schaumburg, 2001; Catrambone, 2002). Thus the goal is to present a human-like interface that is, at the same time, less striking and thus less distracting at first contact, and one that clearly &amp;quot;sets the rules&amp;quot; of the interaction and makes sure that the user keeps it framed within the capability of the system. We have designed a welcome gesture for our ECA based on the recommendations in Kendon (1990), to test whether or not it fosters a sense of ease in the user and helps her concentrate on the task at hand. Playing with the zoom, the size and the position of the ECA on the screen may also prove to be useful to frame the communication better (see Table 1). 3.2 Turn Management Turn management involves two basic actions: taking turn and giving turn. Again, in Table 1 we show the corresponding ECA gestures we will start testing with. Note that apart from the ECA gestures, we also play with zoom and light intensity: when it&apos;s the ECA&apos;s turn to speak the camera zooms-in slightly and the light </context>
</contexts>
<marker>Kendon, 1990</marker>
<rawString>Adam Kendon, 1990. Conducting interaction: patterns of behaviour in focused encounters, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Kleinsmith</author>
<author>P Ravindra De Silva</author>
<author>Nadia Bianchi-Berthouze</author>
</authors>
<title>Cross-cultural differences in recognizing affect from body posture Interacting with computers</title>
<date>2006</date>
<volume>10</volume>
<pages>1371--13</pages>
<marker>Kleinsmith, De Silva, Bianchi-Berthouze, 2006</marker>
<rawString>Andrea Kleinsmith, P. Ravindra De Silva, Nadia Bianchi-Berthouze, 2006 Cross-cultural differences in recognizing affect from body posture Interacting with computers 10 1371-13 89</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Krauss</author>
<author>Yihsiu Chen</author>
<author>Purnima Chawla</author>
</authors>
<title>Nonverbal behavior and nonverbal communication: What do conversational hand gestures tell us?</title>
<date>1996</date>
<booktitle>In M. Zanna (Ed.), Advances in experimental social psychology (pp. 3 89 450).San</booktitle>
<publisher>Academic Press.</publisher>
<location>Diego, CA:</location>
<contexts>
<context position="4211" citStr="Krauss et al., 1996" startWordPosition="650" endWordPosition="653">ing nonverbal communication in complex dialogue situations. In the study we present here we focus on preliminary validation of our gestural repertoire through user tests. We conclude by presenting our results and suggesting the direction our research will take from this point. 2 How ECA technology can improve interaction with SLDSs There are many nonverbal elements of communication in everyday life that are important because they convey a considerable amount of information and qualify the spoken message, sometimes even to the extent that what is meant is actually the opposite of what is said (Krauss et al., 1996). ECAs offer the possibility to combine several communication modes such as speech and gestures, making it possible, in theory, to create interfaces with which human-machine interaction is much more natural and comfortable. In fact, they are already being employed to improve interaction (Massaro et al., 2000). These are some common situations with SLDSs in which an ECA could have a positive effect: Efficient turn management: The body language and expressiveness of agents are important not only to reinforce the spoken message, but also to regulate the flow of the dialogue, as Cassell points out</context>
</contexts>
<marker>Krauss, Chen, Chawla, 1996</marker>
<rawString>Robert M. Krauss, Yihsiu Chen and Purnima Chawla, 1996 Nonverbal behavior and nonverbal communication: What do conversational hand gestures tell us? In M. Zanna (Ed.), Advances in experimental social psychology (pp. 3 89 450).San Diego, CA: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic W Massaro</author>
<author>Michael M Cohen</author>
<author>Jonas Beskow</author>
<author>Ronald A Cole</author>
</authors>
<title>and evaluating conversational agents.</title>
<date>2000</date>
<booktitle>In Embodied Conversational Agents</booktitle>
<volume>2</volume>
<pages>87--31</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="4521" citStr="Massaro et al., 2000" startWordPosition="697" endWordPosition="700">e interaction with SLDSs There are many nonverbal elements of communication in everyday life that are important because they convey a considerable amount of information and qualify the spoken message, sometimes even to the extent that what is meant is actually the opposite of what is said (Krauss et al., 1996). ECAs offer the possibility to combine several communication modes such as speech and gestures, making it possible, in theory, to create interfaces with which human-machine interaction is much more natural and comfortable. In fact, they are already being employed to improve interaction (Massaro et al., 2000). These are some common situations with SLDSs in which an ECA could have a positive effect: Efficient turn management: The body language and expressiveness of agents are important not only to reinforce the spoken message, but also to regulate the flow of the dialogue, as Cassell points out (in Bickmore et al., 2004). Improving error recovery: The process of recognition error recovery usually leads to a certain degree of user frustration (see Oviatt and VanGent, 1996). Indeed, it is common, once an error occurs, to enter into an error spiral in which the system is trying to recover, the user ge</context>
</contexts>
<marker>Massaro, Cohen, Beskow, Cole, 2000</marker>
<rawString>Dominic W. Massaro, Michael M. Cohen, Jonas Beskow and Ronald A. Cole, 2000.Developing and evaluating conversational agents. In Embodied Conversational Agents MIT Press, Cambridge, MA, 2 87-31 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Oviatt</author>
</authors>
<title>Interface techniques for minimizing disfluent input to spoken language systems.</title>
<date>1994</date>
<booktitle>In Proc. CHI&apos;94</booktitle>
<pages>205--210</pages>
<publisher>ACM Press,</publisher>
<location>Boston,</location>
<contexts>
<context position="5494" citStr="Oviatt, 1994" startWordPosition="860" endWordPosition="861">recognition error recovery usually leads to a certain degree of user frustration (see Oviatt and VanGent, 1996). Indeed, it is common, once an error occurs, to enter into an error spiral in which the system is trying to recover, the user gets ever more frustrated, and this frustration interferes in the recognition process making the situation worse (Oviatt et al., 199 8). ECAs may help reduce frustration, and by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or human</context>
</contexts>
<marker>Oviatt, 1994</marker>
<rawString>Sharon Oviatt. 1994. Interface techniques for minimizing disfluent input to spoken language systems. In Proc. CHI&apos;94 (pp. 205-210) Boston, ACM Press, 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Oviatt</author>
<author>Robert VanGent</author>
</authors>
<title>Error resolution duringmultimodal humancomputer interaction.</title>
<date>1996</date>
<booktitle>Proc. International Conference on Spoken Language Processing,</booktitle>
<volume>1</volume>
<pages>204--207</pages>
<contexts>
<context position="4992" citStr="Oviatt and VanGent, 1996" startWordPosition="774" endWordPosition="777">ich human-machine interaction is much more natural and comfortable. In fact, they are already being employed to improve interaction (Massaro et al., 2000). These are some common situations with SLDSs in which an ECA could have a positive effect: Efficient turn management: The body language and expressiveness of agents are important not only to reinforce the spoken message, but also to regulate the flow of the dialogue, as Cassell points out (in Bickmore et al., 2004). Improving error recovery: The process of recognition error recovery usually leads to a certain degree of user frustration (see Oviatt and VanGent, 1996). Indeed, it is common, once an error occurs, to enter into an error spiral in which the system is trying to recover, the user gets ever more frustrated, and this frustration interferes in the recognition process making the situation worse (Oviatt et al., 199 8). ECAs may help reduce frustration, and by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity</context>
</contexts>
<marker>Oviatt, VanGent, 1996</marker>
<rawString>Sharon Oviatt and Robert VanGent, 1996, Error resolution duringmultimodal humancomputer interaction. Proc. International Conference on Spoken Language Processing, 1 204-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Oviatt</author>
<author>Margaret MacEachern</author>
<author>Gina-Anne Levow</author>
</authors>
<title>8. Predicting hyperarticulate speech during human-computer error resolution.</title>
<date></date>
<journal>Speech Communication,</journal>
<volume>24</volume>
<pages>1--23</pages>
<marker>Oviatt, MacEachern, Levow, </marker>
<rawString>Sharon Oviatt, Margaret MacEachern, and Gina-Anne Levow, G.,199 8. Predicting hyperarticulate speech during human-computer error resolution. Speech Communication, vol.24, 2, 1-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Oviatt</author>
<author>Bridget Adams</author>
</authors>
<title>Designing and evaluating conversational interfaces with animated characters. Embodied conversational agents,</title>
<date>2000</date>
<pages>319--345</pages>
<publisher>MIT Press:</publisher>
<contexts>
<context position="7791" citStr="Oviatt and Adams, 2000" startWordPosition="1235" endWordPosition="1238">ectly at the user, raise hands into gesture space. Camera zooms in. Light gets brighter. Wait Slight leaning back, one arm crossed and the other touching the cheek shift of body weight Help Beat gesture with the hands. Change of posture Error recovery Lean towards the camera, beat gesture with correction Confirmation Nod, smile, eyes fully open (high confidence) Confirmation Slight leaning of the head to one side, stop (low smiling, mildly squint confidence) Table 1: Gesture repertoire for the main dialogue stages 68 3.1 Initiation The inclusion of an ECA at this stage &amp;quot;humanises&amp;quot; the system (Oviatt and Adams, 2000). This is a problem, first because once a user has such high expectations the system can only end up disappointing her, and secondly because the user will tend to use more natural (and thus complex) communication, which the system is unable to handle, and the experience will ultimately be frustrating. On the other hand, especially in the case of new users, contact with a dialoguing animated character may have the effect that the user&apos;s level of attention to the actual information that is being given is reduced (Schaumburg, 2001; Catrambone, 2002). Thus the goal is to present a human-like inter</context>
</contexts>
<marker>Oviatt, Adams, 2000</marker>
<rawString>Sharon Oviatt, and Bridget Adams, 2000. Designing and evaluating conversational interfaces with animated characters. Embodied conversational agents, MIT Press: 319-345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabella Poggi</author>
</authors>
<title>How to decide which gesture to make according to our goals and our contextual knowledge. Paper presented at Gesture Workshop</title>
<date>2001</date>
<location>London</location>
<contexts>
<context position="5868" citStr="Poggi, 2001" startWordPosition="921" endWordPosition="922">CAs may help reduce frustration, and by doing so make error recovery more effective (Hone, 2005). Correct understanding of the state of the dialogue: Sometimes the user doesn&apos;t know whether or not things are going normally (Oviatt, 1994). This sometimes leads the dialogue to error states that could be avoided. The expressive capacity of ECAs could be used to reflect with greater clarity the state the system takes the dialogue to be in. 3 Suggesting ECA behaviour for each dialogue situation A variety of studies have been carried out on behavioural strategies for embodied conversational agents (Poggi, 2001; Cassell et al., 2000; Cassell et al., 2001; Chovil, 1992; Kendon, 1990), which deal with behaviour in hypothetical situations and in terms of the informational goals of each particular interaction (be it human-human or humanmachine). We direct our attention to the overall dialogue systems dynamics, focussing specifically on typical robustness problems and how to favour smooth sailing through the different stages of the dialogue. We draw from existing research undertaken to try to understand the effects different gestures displayed by ECAs have on people, and we apply this knowledge to a real</context>
</contexts>
<marker>Poggi, 2001</marker>
<rawString>Isabella Poggi, 2001. How to decide which gesture to make according to our goals and our contextual knowledge. Paper presented at Gesture Workshop 2001 London 18th-20th April, 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruben San-Segundo</author>
<author>Juan M Montero</author>
<author>Javier Ferreiros</author>
<author>Ricardo C6rdoba</author>
<author>Jose M Pardo</author>
</authors>
<title>Designing Confirmation Mechanisms and Error Recover Techniques in a Railway Information System for Spanish. SIGDIAL. Septiembre 1-2,</title>
<date>2001</date>
<location>Aalborg (Dinamarca).</location>
<marker>San-Segundo, Montero, Ferreiros, C6rdoba, Pardo, 2001</marker>
<rawString>Ruben San-Segundo, Juan M. Montero, Javier Ferreiros, Ricardo C6rdoba, Jose M. Pardo, 2001 Designing Confirmation Mechanisms and Error Recover Techniques in a Railway Information System for Spanish. SIGDIAL. Septiembre 1-2, Aalborg (Dinamarca).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Schaumburg</author>
</authors>
<title>Computers as tools or as social actors?the users&apos; perspective on anthropomorphic agents.International</title>
<date>2001</date>
<journal>Journal of Cooperative Information Systems.10,</journal>
<volume>1</volume>
<pages>217--234</pages>
<contexts>
<context position="8324" citStr="Schaumburg, 2001" startWordPosition="1329" endWordPosition="1330">e inclusion of an ECA at this stage &amp;quot;humanises&amp;quot; the system (Oviatt and Adams, 2000). This is a problem, first because once a user has such high expectations the system can only end up disappointing her, and secondly because the user will tend to use more natural (and thus complex) communication, which the system is unable to handle, and the experience will ultimately be frustrating. On the other hand, especially in the case of new users, contact with a dialoguing animated character may have the effect that the user&apos;s level of attention to the actual information that is being given is reduced (Schaumburg, 2001; Catrambone, 2002). Thus the goal is to present a human-like interface that is, at the same time, less striking and thus less distracting at first contact, and one that clearly &amp;quot;sets the rules&amp;quot; of the interaction and makes sure that the user keeps it framed within the capability of the system. We have designed a welcome gesture for our ECA based on the recommendations in Kendon (1990), to test whether or not it fosters a sense of ease in the user and helps her concentrate on the task at hand. Playing with the zoom, the size and the position of the ECA on the screen may also prove to be useful</context>
</contexts>
<marker>Schaumburg, 2001</marker>
<rawString>Heike Schaumburg, 2001. Computers as tools or as social actors?the users&apos; perspective on anthropomorphic agents.International Journal of Cooperative Information Systems.10, 1, 2, 217-234.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>