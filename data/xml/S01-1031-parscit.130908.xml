<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004900">
<title confidence="0.992928">
Pattern Learning and Active Feature Selection
for Word Sense Disambiguation
</title>
<author confidence="0.997617">
Rada F. MIHALCEA Dan I. MOLDOVAN
</author>
<affiliation confidence="0.7802195">
Southern Methodist University University of Texas at Dallas
Dallas, Texas, 75275-0122 Richardson, Texas, 75083-0688
</affiliation>
<email confidence="0.998673">
rada©seas.smu.edu rnoldovan@utdallas.edu
</email>
<sectionHeader confidence="0.980104" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999953909090909">
We present here the main ideas of the algo-
rithm employed in the SMU/s and SMUaw sys-
tems. These systems have participated in the
SENSEVAL-2 competition attaining the best per-
formance for both English all words and En-
glish lexical sample tasksl. The algorithm has
two main components (1) pattern learning from
available sense tagged corpora (SemCor) and dic-
tionary definitions (WordNet), and (2) instance
based learning with active feature selection, when
training data is available for a particular word.
</bodyText>
<sectionHeader confidence="0.995511" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999222041666667">
It is well known that WSD constitutes one of
the hardest problems in Natural Language Pro-
cessing, yet is a necessary step in a large range
of applications including machine translation,
knowledge acquisition, coreference, information
retrieval and others. This motivates a continu-
ously increasing number of researchers to develop
WSD systems and devote time to finding solu-
tions for this challenging problem.
The system presented here was initially de-
signed for the semantic disambiguation of all
words in open text. The SENSEVAL competitions
created a good environment for supervised sys-
tems and this encouraged us to improve our sys-
tem with the capability of incorporating larger
training data sets when provided.
There are two important modules in this sys-
tem. The first one uses pattern learning relying
on large sense tagged corpora to tag all words in
open text. The second module is triggered only
for the words with large training data, as was the
case with the words from the lexical sample tasks.
It uses an instance based learning algorithm with
active feature selection.
</bodyText>
<footnote confidence="0.56137">
&apos;This is in conformity with the original ranking, fol-
lowing the evaluation of systems answers submitted before
deadline.
</footnote>
<bodyText confidence="0.9998075">
To our knowledge, both pattern learning and
active feature selection are novel approaches in
the WSD field, and they led to very good results
during the SENSEVAL-2 evaluation exercise.
</bodyText>
<sectionHeader confidence="0.809244" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999615966666667">
The WSD algorithm used in this system has the
capability of tagging words when no specific sense
tagged corpora is available, automatically scaling
up to larger training data2 when provided.
Due to space constraints, we will not be able to
give a detailed description of the system. How-
ever we try to gain space and replace one thou-
sand words with a picture: Figure 1 shows an
overview of the system architecture. It illustrates
the two main components, namely pattern learn-
ing from available sense tagged corpora and dic-
tionary definitions and instance based learning
with active feature selection. The two modules
are preceded by a preprocessing phase which in-
cludes compound concept identification, and fol-
lowed by a default phase that assigns the most
frequent sense as a last resort, when no other
previous methods could be applied. The shaded
areas in Figure 1 are specific for the case when
larger training data sets are available.
During the preprocessing stage, SGML tags are
eliminated, the text is tokenized, part of speech
tags are assigned using Brill tagger (Brill, 1995),
and Named Entities (NE) are identified with an
in-house implementation of an NE recognizer. To
identify collocations, we determine sequences of
words that form compound concepts defined in
WordNet.
In the second step, patterns3 are learned from
WordNet, SemCor and GenCor, which is a large
</bodyText>
<footnote confidence="0.9993024">
21.e. in addition to the publicly available sense tagged
corpora
3We alternatively call them rules as they basically spec-
ify the sense triggered by a given local context, using rules
like &amp;quot;if the word before is X then sense is Y&amp;quot;
</footnote>
<page confidence="0.993355">
127
</page>
<figureCaption confidence="0.999586">
Figure 1: System architecture
</figureCaption>
<figure confidence="0.8246646">
- eliminate SGMLtags
- tokenization
- part of speech tagging
- Named Entity recognitior.
- learn patterns from
- SemCor and WordNe
- GenCor
additional sense tagged
corpora
- identify compound
concepts
- identify proper nouns
with a semantic role (NE
No
if additional training data
available: validate patterns
keep only error free
instance: based learning
wiih active feature sClectioi
- assign the most frequent
sense
(e.g. first sense in WordNet,
onosemou
word 9
SENSE TAGGED TEXT
</figure>
<bodyText confidence="0.999395727272727">
sense tagged corpus automatically built via a set
of heuristics. If additional training data is avail-
able, patterns are filtered through a validation
process. Practically, the patterns are applied on
the sense tagged data and we keep only those with
no counter-examples found in the training sets.
The third step consists of a learning mecha-
nism with active feature selection. This step is
initiated only for those words with a sufficiently
large number of examples, as was the case with
the words in the SENSEVAL lexical sample tasks.
</bodyText>
<sectionHeader confidence="0.992402" genericHeader="method">
3 Pattern learning
</sectionHeader>
<bodyText confidence="0.999793166666666">
This module is intended for solving the semantic
ambiguity of all words in open text. To this end,
we build disambiguation patterns using SemCor,
WordNet and GenCor. Several processing steps
were required to transform the first two resources
into a useful corpus for our task. Moreover, these
lexical resources coupled with a set of heuristics
were used as seeds for generating a new sense
tagged corpus called GenCor.
SemCor The SENSEVAL-2 English tasks have de-
cided to use the WordNet 1.7 sense inventory, and
therefore we had to deal with the task of map-
ping SemCor senses, which were assigned using
an earlier version of WordNet, to the correspond-
ing senses in WordNet 1.7. When a word sense
from WordNet 1.6 is missing we assign a default
sense of 0.4
WordNet The main idea in generating a sense
tagged corpus out of WordNet is very simple. It is
based on the underlying assumption that each ex-
ample pertains to a word belonging to the current
synset, thereby allowing us to assign the correct
sense to at least one word in each example. For
instance, the example given for mother#4 is &amp;quot;ne-
cessity is the mother of invention&amp;quot;, and the word
mother can be tagged with its appropriate sense.
GenCor is a generated sense tagged corpus, con-
taining at the moment about 160,000 tagged
words, which uses as seeds the sense tagged ex-
amples from SemCor and WordNet, as well as
some of the principles for generating sense tagged
corpora presented in (Mihalcea and Moldovan,
1999). Due to space limitations we cannot
present here the methodology for creating this
corpus. A thorough description is provided in
(Mihalcea, 2001).
</bodyText>
<footnote confidence="0.999198">
4SemCor 1.7a is available for download at
http://www.seas.smu.edurrada/semcor
</footnote>
<page confidence="0.991439">
128
</page>
<bodyText confidence="0.991964490384616">
Once we have created this large corpus with
examples of word meanings, we can start to learn
patterns. A pattern basically consists of the local
context for each semantically tagged word found
in the corpus. The local context is formed by a
window of N words to the left and M words to the
right of each word considered. Additionally, a set
of constraints is applied to filter out meaningless
patterns.
Patterns are formed following the rules for reg-
ular expressions. Each word in the corpus is rep-
resented by its base form, its part of speech, its
sense, if there is any provided, and its hypernym,
again if the sense is known. Any of these word
components can be unspecified, and therefore de-
noted with the symbol *. A count is also asso-
ciated with every pattern, indicating the number
of times it occurred in the corpus.
When trying to disambiguate a word, first we
search for all available patterns that match the
current context. In doing so, we use the current
word as a pivot to perform matching. If there
are several patterns available, then the decision
of which pattern to apply is based on the pattern
strength. The strength of a pattern is evaluated
in terms of (1) number of specified components,
(2) number of occurrences and (3) pattern length.
&lt;the/DT modal/JJ/1 age/NN at/IN&gt; is consid-
ered to be stronger than &lt;modal/NN/1 age/NN&gt;.
Also, &lt;clear/JJ/4 water/NN/1&gt; is stronger than
&lt;clear/JJ water/NN/1&gt;. Moreover, the inclusion
of the hypernym among the word components
gives us the means for generalization. For
instance, &lt;*/NN/*/room/1 door/NN/l&gt; matches
&amp;quot;kitchen door&amp;quot; as well as &amp;quot;bedroom door&amp;quot;.
Another important step performed during the
all words disambiguation task is sense propaga-
tion. The patterns do not guarantee a complete
coverage of all words in input text, and therefore
additional methods are required. We use a cache-
like procedure which assigns to each ambiguous
word the sense of its closest occurrence, if any
can be found. The words still ambiguous at this
point are assigned by default the first sense in
WordNet.
Words with a significant number of seman-
tic tagged examples constitute a special case in
our system. There is a second module designed
to handle the semantic disambiguation of these
words. This module, described in the follow-
ing section, exploits the benefits of having larger
training data available for a particular word.
4 Learning with active feature
selection
Learning mechanisms for disambiguating word
senses have a long tradition in the WSD field. For
our system, we have decided for an instance based
algorithm with information gain feature weight-
ing. The reasons for this decision are three fold:
first, it has been advocated that forgetting ex-
ceptions is harmful for language learning applica-
tions (Daelemans et al., 1999), and instance based
algorithms are known for their property of taking
into consideration every single training example
when making a classification decision; secondly,
instance based learning algorithms have been suc-
cessfully used in WSD applications (Veenstra et
al., 2000); finally, this type of algorithms are ef-
ficient in terms of training and testing time. We
have initially used the MLC++ implementation,
and later on switched to Timbl (Daelemans et al.,
2001).
Even more important than the choice of learn-
ing methodology is the selection of features em-
ployed during the learning process. There are
several features recognized as good indicators of
word sense, including the word itself (CW) and
its part of speech (CP), surrounding words and
their parts of speech (CF), collocations (COL),
syntactic roles, keywords in contexts (SK). More
recently, other possible features have been inves-
tigated: bigrams in context (B), named entities
(NE), the semantic relation with the other words
in context, etc.
Our intuition was that different sets of features
have different effects depending on the ambiguous
word considered. Feature weighting was clearly
proven to be an advantageous approach for a
large range of applications, including WSD. Still,
weights are computed independently for each fea-
ture and therefore this strategy does not always
guarantee to provide the best results.
For our system, we actively select features us-
ing a forward search algorithm. In this way,
we practically generate meta word experts. Each
word will have a different set of features that will
eventually lead to the best disambiguation accu-
racy.
Using this approach, we combine the advan-
tages of instance based learning mechanisms that
have the nice property of &amp;quot;not forgetting ex-
ceptions&amp;quot;, with an optimized feature selection
scheme. One could argue that decision trees have
the capability of selecting relevant features, but
</bodyText>
<page confidence="0.997144">
129
</page>
<bodyText confidence="0.9984915">
it has been shown (Almuallim and Dietterich,
1991) that irrelevant features significantly affect
the performance of decision trees as well.
The algorithm for active feature selection is
sketched in Figure 2. It is worth mentioning that
in step 2, the training and testing corpora are ex-
tracted for each ambiguous word. This means
that examples pertaining to the word &amp;quot;dress
down&amp;quot; are separated from the examples for the
single word &amp;quot;dress&amp;quot;.
</bodyText>
<reference confidence="0.651949333333333">
1. Generate pool of features PF = {F,}. Initialize
the set of selected features with the empty set
SF=--{0}.
2. Extract training and testing corpora for the given
target ambiguous word.
3. For each feature F, in the pool PF:
3.1. Run a 10-fold cross validation on the training
set; each example in the training set contains
the features in SF and the feature Fi.
</reference>
<figure confidence="0.7696426">
3.2. Determine the feature F, leading to the best
accuracy.
3.3. Remove Fi from PF and add it to SF.
4. Repeat step 3 until no improvements are ob-
tained.
</figure>
<figureCaption confidence="0.99879">
Figure 2: Algorithm for active feature selection
</figureCaption>
<bodyText confidence="0.999892666666667">
The pool PF contains a large number of fea-
tures, including those previously mentioned CW,
CP, CF, COL, SK, B, NE, as well as other fea-
tures like the noun before and after (NB, NA),
head of the noun phrase, surrounding verbs, and
others.
</bodyText>
<sectionHeader confidence="0.998309" genericHeader="evaluation">
5 Results in SENSEVAL-2
</sectionHeader>
<bodyText confidence="0.986559473684211">
The overall performance of the system in the En-
glish all words task was 69% for fine-grained scor-
ing, respectively 69.8% for coarse-grained scoring
(SMUaw). In the English lexical sample task, we
obtained 63.8% for fine-grained scoring, respec-
tively 71.2% for coarse-grained scoring (SMU/s).
These results ranked our system before deadline
as the best performing for both tasks.
Discussion
There were several interesting cases encoun-
tered in the SENSEVAL-2 data, justifying our ap-
proach of using active feature selection. The in-
fluence of a feature greatly depends on the tar-
get word: a feature can increase the precision for
a word, while making things worse for another
word. For example, a word such as free does not
benefit from the surrounding keywords (SK) fea-
ture, whereas colourless gains almost 7% in pre-
cision when this feature is used.
</bodyText>
<equation confidence="0.9887085">
free.a[CW CP CF SKI 57.85%
free.a[CW CP CF ] 63.57%
colourless.a[CW CP CF] -4 78.57%
colourless.a[CW CP CF SKI -4 85.71%
</equation>
<bodyText confidence="0.999920894736842">
Another interesting example is constituted by
the noun chair, which was disambiguated with
high precision by simply using the current word
(CW) feature. This is explained by the fact
that the most frequent senses are Chair meaning
person and chair meaning furniture, and there-
fore the distinction between lower and upper case
spellings makes the distinction among the differ-
ent meanings of this word.
We have also tested the system on the
SENSEVAL-1 data, and performed the disam-
biguation task in respect with Hector definitions,
as required by the first disambiguation exercise.
The overall result achieved on this data was
higher than the one reported by the best per-
forming system. Besides proving the validity of
our approach, this fact also proved that our sys-
tem is not tight in any ways to the sense inventory
or data format employed.
</bodyText>
<sectionHeader confidence="0.99929" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999448333333333">
Pattern learning and active feature selection are
new approaches in the WSD field. They have
been implemented in a system that participated
in the SENSEVAL-2 competition, with an excel-
lent performance in both English all words and
English lexical sample tasks.
</bodyText>
<sectionHeader confidence="0.999216" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999571217391304">
H. Almuallim and T.G. Dietterich. 1991. Learning with
many irrelevant features. In Proceedings of AAAI-91,
volume 2, pages 547-552, Anaheim, California.
E. Brill. 1995. Transformation-based error driven learn-
ing and natural language processing: A case study
in part-of-speech tagging. Computational Linguistics,
21(4):543-566, December.
W. Daelemans, A. van den Bosch, and J. Zavrel. 1999.
Forgetting exceptions is harmful in language learning.
Machine Learning, 34(1-3):11-34.
W. Daelemans, J. Zavrel, K. van der Sloot, and A. van den
Bosch. 2001. Timbl: Tilburg memory based learner,
version 4.0, reference guide. Technical report, Univer-
sity of Antwerp.
R. Mihalcea and D.I. Moldovan. 1999. An automatic
method for generating sense tagged corpora. In Pro-
ceedings of AAAI-99, Orlando, FL, July.
R. Mihalcea. 2001. GenCor: a large semantically tagged
corpus. (in preparation).
J. Yeenstra, A. van den Bosch, S. Buchholz, W. Daele-
mans, and J. Zavrel. 2000. Memory-based word
sense disambiguation. Computers and the Humanities,
34:171-177.
</reference>
<page confidence="0.997612">
130
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.979096">
<title confidence="0.9997865">Pattern Learning and Active Feature Selection for Word Sense Disambiguation</title>
<author confidence="0.999146">Rada F MIHALCEA Dan I MOLDOVAN</author>
<affiliation confidence="0.994176">Southern Methodist University University of Texas at Dallas</affiliation>
<address confidence="0.996375">Dallas, Texas, 75275-0122 Richardson, Texas, 75083-0688</address>
<email confidence="0.99981">rada©seas.smu.edurnoldovan@utdallas.edu</email>
<abstract confidence="0.999076583333333">We present here the main ideas of the algoemployed in the systems. These systems have participated in the attaining the best performance for both English all words and Enlexical sample The algorithm has two main components (1) pattern learning from available sense tagged corpora (SemCor) and dictionary definitions (WordNet), and (2) instance based learning with active feature selection, when training data is available for a particular word.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Generate pool of features PF = {F,}. Initialize the set of selected features with the empty set SF=--{0}.</title>
<marker></marker>
<rawString>1. Generate pool of features PF = {F,}. Initialize the set of selected features with the empty set SF=--{0}.</rawString>
</citation>
<citation valid="false">
<title>Extract training and testing corpora for the given target ambiguous word. 3. For each feature F, in the pool PF:</title>
<marker></marker>
<rawString>2. Extract training and testing corpora for the given target ambiguous word. 3. For each feature F, in the pool PF:</rawString>
</citation>
<citation valid="false">
<title>Run a 10-fold cross validation on the training set; each example in the training set contains the features in SF and the feature Fi.</title>
<marker></marker>
<rawString>3.1. Run a 10-fold cross validation on the training set; each example in the training set contains the features in SF and the feature Fi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Almuallim</author>
<author>T G Dietterich</author>
</authors>
<title>Learning with many irrelevant features.</title>
<date>1991</date>
<booktitle>In Proceedings of AAAI-91,</booktitle>
<volume>2</volume>
<pages>547--552</pages>
<location>Anaheim, California.</location>
<marker>Almuallim, Dietterich, 1991</marker>
<rawString>H. Almuallim and T.G. Dietterich. 1991. Learning with many irrelevant features. In Proceedings of AAAI-91, volume 2, pages 547-552, Anaheim, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based error driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--4</pages>
<contexts>
<context position="3289" citStr="Brill, 1995" startWordPosition="518" endWordPosition="519">ning from available sense tagged corpora and dictionary definitions and instance based learning with active feature selection. The two modules are preceded by a preprocessing phase which includes compound concept identification, and followed by a default phase that assigns the most frequent sense as a last resort, when no other previous methods could be applied. The shaded areas in Figure 1 are specific for the case when larger training data sets are available. During the preprocessing stage, SGML tags are eliminated, the text is tokenized, part of speech tags are assigned using Brill tagger (Brill, 1995), and Named Entities (NE) are identified with an in-house implementation of an NE recognizer. To identify collocations, we determine sequences of words that form compound concepts defined in WordNet. In the second step, patterns3 are learned from WordNet, SemCor and GenCor, which is a large 21.e. in addition to the publicly available sense tagged corpora 3We alternatively call them rules as they basically specify the sense triggered by a given local context, using rules like &amp;quot;if the word before is X then sense is Y&amp;quot; 127 Figure 1: System architecture - eliminate SGMLtags - tokenization - part o</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Transformation-based error driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543-566, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A van den Bosch</author>
<author>J Zavrel</author>
</authors>
<title>Forgetting exceptions is harmful in language learning.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<marker>Daelemans, van den Bosch, Zavrel, 1999</marker>
<rawString>W. Daelemans, A. van den Bosch, and J. Zavrel. 1999. Forgetting exceptions is harmful in language learning. Machine Learning, 34(1-3):11-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>K van der Sloot</author>
<author>A van den Bosch</author>
</authors>
<title>Timbl: Tilburg memory based learner, version 4.0, reference guide.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>University of Antwerp.</institution>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2001</marker>
<rawString>W. Daelemans, J. Zavrel, K. van der Sloot, and A. van den Bosch. 2001. Timbl: Tilburg memory based learner, version 4.0, reference guide. Technical report, University of Antwerp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D I Moldovan</author>
</authors>
<title>An automatic method for generating sense tagged corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI-99,</booktitle>
<location>Orlando, FL,</location>
<note>(in preparation).</note>
<contexts>
<context position="6355" citStr="Mihalcea and Moldovan, 1999" startWordPosition="1030" endWordPosition="1033">. It is based on the underlying assumption that each example pertains to a word belonging to the current synset, thereby allowing us to assign the correct sense to at least one word in each example. For instance, the example given for mother#4 is &amp;quot;necessity is the mother of invention&amp;quot;, and the word mother can be tagged with its appropriate sense. GenCor is a generated sense tagged corpus, containing at the moment about 160,000 tagged words, which uses as seeds the sense tagged examples from SemCor and WordNet, as well as some of the principles for generating sense tagged corpora presented in (Mihalcea and Moldovan, 1999). Due to space limitations we cannot present here the methodology for creating this corpus. A thorough description is provided in (Mihalcea, 2001). 4SemCor 1.7a is available for download at http://www.seas.smu.edurrada/semcor 128 Once we have created this large corpus with examples of word meanings, we can start to learn patterns. A pattern basically consists of the local context for each semantically tagged word found in the corpus. The local context is formed by a window of N words to the left and M words to the right of each word considered. Additionally, a set of constraints is applied to </context>
</contexts>
<marker>Mihalcea, Moldovan, 1999</marker>
<rawString>R. Mihalcea and D.I. Moldovan. 1999. An automatic method for generating sense tagged corpora. In Proceedings of AAAI-99, Orlando, FL, July. R. Mihalcea. 2001. GenCor: a large semantically tagged corpus. (in preparation).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yeenstra</author>
<author>A van den Bosch</author>
<author>S Buchholz</author>
<author>W Daelemans</author>
<author>J Zavrel</author>
</authors>
<title>Memory-based word sense disambiguation. Computers and the Humanities,</title>
<date>2000</date>
<pages>34--171</pages>
<marker>Yeenstra, van den Bosch, Buchholz, Daelemans, Zavrel, 2000</marker>
<rawString>J. Yeenstra, A. van den Bosch, S. Buchholz, W. Daelemans, and J. Zavrel. 2000. Memory-based word sense disambiguation. Computers and the Humanities, 34:171-177.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>