<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.045829">
<note confidence="0.855164">
GRAMMATICAL ANALYSIS BY COMPUTER OF THE LANCASTER-OSLO/BERGEN
(LOB) CORPUS OF BRITISH ENGLISH TEXTS.
</note>
<author confidence="0.918729">
Andrew David Beale
</author>
<affiliation confidence="0.948053">
Unit for Computer Research on the English Language
Bowland College, University of Lancaster
</affiliation>
<address confidence="0.504013">
Bailrigg, Lancaster; England LA1 4YT.
</address>
<sectionHeader confidence="0.799168" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999835272727273">
Research has been under way at the
Unit for Computer Research on the English
Language at the University of Lancaster,
England, to develop a suite of computer
programs which provide a detailed
grammatical analysis of the LOB corpus,
a collection of about 1 million words of.
British English texts available in
machine readable form.
The first phrase of the project,
completed in September 1983, produced a
grammatically annotated version of the
corpus giving a tag showing the word
class of each word token. Over 93 per
cent of the word tags were correctly
selected by using a matrix of tag pair
probabilities and this figure was upgraded
by a further 3 per cent by retagging
problematic strings of words prior to
disambiguation and by altering the
probability weightings for sequences of
three tags. The remaining 3 to 4 per
cent were corrected by a human post-editor.
The system was originally designed to
run in batch mode over the corpus but we
have recently modified procedures to run
interactively for sample sentences typed
in by a user at a terminal. We are
currently extending the word tag set and
improving the word tagging procedures to
further reduce manual intervention. A
similar probabilistic system is being
developed for phrase and clause tagging.
</bodyText>
<sectionHeader confidence="0.9784345" genericHeader="method">
THE STRUCTURE AND PURPOSE
OF THE LOB OORPUS.
</sectionHeader>
<bodyText confidence="0.994819724137931">
The LOB Corpus (Johansson, Leech and
Goodluck, 1978), like its American
English counterpart, the Brown Corpus
(Kura and Francis, 1964; Hauge and
Hofland, 1978), is a collection of 300
samples of British English texts, each
containing about 2,000 word tokens. The
samples are representations of 15
different text categories: A. Press
(Reportage); B. Press (Editorial);
C. Press cReviews); D. Religion; E.
Skills and Hobbies; F. Popular Lore;
G. Belles Lettres, Biography, Memoirs,
etc.; H. Miscellaneous; J.
Learned and Scientific; K. General
Fiction; L. Mystery and Detective
Fiction; M. Science Fiction; N.
Adventure and Western Fiction, Romance
and Love Story; R. Humour. There are
two main sections, informative prose and
imaginative prose, and all the texts
contained in the corpus were printed in
a single year (1961).
The structure of the LOB corpus was
designed to resemble that of the Brown
corpus as closely as possible so that
a systematic comparison of British and
American written English could be made.
Both corpora contain samples of texts
published in the same year (1961) so
that comparisons are not distorted by
diachronic factors.
The LOB corpus is used as a database
for linguistic research and language
description. Historically, different
linguists have been concerned to a
greater or lesser extent with the use of
corpus citations, to some degree, at
least, because of differences in the
perceived view of the descriptive
requirements of grammar. Jespersen
(1909-49), Kruisinga and Erades (1911)
gave frequent examples of citations from
assembled corpora of written texts to
illustrate grammatical rules. Work on
text corpora is, of course, very much
alive today. Storage, retrieval and
processing of natural language text is a
more efficient and less laborious task
with modern computer hardware than it
was with hand-written card files but
data capture is still a significant
problem (Francis, 1980). The forthcoming
work, A Comprehensive Grammar of the
aglish Language (quirk, Greenbaum,
leech, and Svartvik, 1985) contains many
citations from both LOB and Brown
Corpora.
</bodyText>
<page confidence="0.998438">
293
</page>
<sectionHeader confidence="0.672182" genericHeader="method">
A GRAMMATICALLY ANNOTATZD VERSION
OF THE OORPUS
</sectionHeader>
<bodyText confidence="0.999943665338646">
Since 1981, research has been directed
towards writing programs to grammatically
annotate the LOB corpus. From 1981-83,
the research effort produced a version of
the corpus with every word token labelled
by a grammatical tag showing the word
class of each word form. Subsequent
research has attempted to build on the
techniques used for automatic word
tagging by using the output from the word
tagging programs as input to phrase and
clause tagging and by using probabilistic
methods to provide a constituent analysis
of the LOB corpus.
The programs and data files used for
word tagging were developed from work done
at Brown University (Greene and Rubin,
1971). Staff and research associates at
Lancaster undertook the programming in
PASCAL while colleagues in Oslo revised
and extended the lists used by Greene and
Rubin (op.cit.) for word tag assignment.
Half of the corpus was post-edited at
Lancaster and the other half at the
Norwegian Computing Centre for the
Humanities.
How word tagging works.
The major difficulties to be
encountered with word tagging of written
English are the lack of distinctive
inflectional or derivational endings and
the large proportion of word forms that
belong to more than one word class.
Endings such as -able, -1.z. and -ness are
graphic realizations of morphological
units indicating word class, but they
occur infrequently for the purposes of
automatic word tag assignment; the
reader will be able to establish
exceptions to rules assigning word classes
to words with these suffixes, because the
characters do not invariably represent
the same morphemes.
The solution we have adopted is to use
a look up procedure to assign one or more
potential tags to each input word. The
appropriate word tag is then selected for
words with more than one potential tag
by calculating the probability of the
tag&apos;s occurrence given neighbouring
potential tags.
â€žPotential word tag assignment.
In cases where more than one potential
tag is assigned to the input word, the
tags represent word classes of the word
without taking the syntactic environment
into account. A list of one to five word
final characters, known as the
&apos;suffixlist&apos;, is used for assignment of
appropriate word class tags to as many
word types as possible. A list of full
word forms, known as the &apos;wordlist&apos;,
used for exceptions to the suffixlist,
and, in addition, word forms that occur
more than 50 times in the corpus are
included in the wordlist, for speed of
processing. The term &apos;suffixlist&apos; is
used as a convenient name, and the reader
is warned that the list does not
necessarily contain word final morphs;
strings of between one and five word
final characters are included if their
occurrence as a tagged form in the Brown
corpus merits it.
The &apos;suffixlist&apos; used by Greene and
Rubin (op.cit.) was substantially revised
and extended by Johansson and Jahr (1982)
using reverse alphabetical lists of
approximately 50,000 word types of the
Brown Corpus arid 75,000 word types of
both Brown and LOB corpora. Frequency
lists specifying the frevehcy of tags
for word endings consisting of 1 to 5
characters were used to establish the
efficiency of each rule. Johansson and
Jahr were guided by the Longman
Dictionary of Contemporary Ehglish (1978)
and other dictionaries and grammars
including Quirk, Greenbaum, Leech and
Svartvik (1972) in identifying tags for
each item in the wordlist. For the
version used for Lancaster-Oslo/Bergen
word tagging (1983), the suffixlist was
expanded to about 700 strings of word
final characters, the wordlist consisted
of about 7,000 entries and a total of
133 word tag types were used.
Potential tag disambiguation.
The problem of resolving lexical
ambiguity for the large proportion of
Eaglish words that occur in more than one
word class, (BLOW, CONTACT, HIT, LEFT,
RAIN&apos;, RUN, REFUSE, ROSE, WALK, WATCH ...),
is solved, whenever possible by examining
the local context. Word tag selection
for homographs in Greene and Rubin (op.
cit.) was attempted by using &apos;context
frame rules&apos;, an ordered list of 3,300
rules designed to take into account the
tags assigned to up to two words
preceding or following the ambiguous
homograph. The program was 77 per cent
successful but several errors were due to
appropriate rules being blocked when
adjacent ambiguities were encountered
(Marshall, 1983: 140). Moreover, about
80 per cent of rule application took
just one immediately neighbouring tag
into account, even though only a quarter
of the context frame rules specified
only one immediately neighbouring tag.
To overcome these difficulties,
research associates at Lancaster have
devised a transition probability matrix
of tag pairs to compute the most probable
tag for an ambiguous form given the
immediately preceding and following tags.
This method of calculating one-step
transition probabilities is suitable for
disambiguating strings of ambiguously
tagged words because the most likely path
through a string of ambiguously tagged
words can be calculated.
The likelihood of a tag being selected
in context is also influenced by likeli-
hood markers which are assigned to
entries with more than one tag in the
lists. Only two markers, &apos;@&apos; and &apos;%&apos;,
are used, &apos;@&apos; notionally indicating
that the tag is correct for the
associated form less than 1 in 110
occasions, &apos;%&apos; notionally.indicating that
the tag occurs less than 1 in 100
occasions. The word tag disambiguation
program uses these markers to reduce the
probability of the less likely tags
occurring in context; tig&apos; results in the
probability being halved, 1%&apos; results in
the probability being divided by eight.
Hence tags marked with &apos;@&apos; or 15.L&apos; are
only selected if the context indicates
that the tag is very likely.
Error analysis.
At several stages during design and
implementation of the tagging software,
error analysis was used to improve various
aspects of the word tagging system.
Error statistics were used to amend the
lists, the transition matrix entries and
even the formula used for calculating
transition probabilities (originally this
was the frequency of potential tag A
followed by potential tag B divided by
the frequency of A. Subsequently, it was
changed to the frequency of A followed by
B divided by the product of the frequency
of A and the frequency of B (Marshall,
1983: 144ff)).
Error analysis indicated that the one-
step transition method for word tag
disambiguation was very successful, but
it was evident that further gains could be
made by including a separate list of a
small set of sequences of words such as
according to, as well as, and so as to
which were retagged prior to word tag
disambiguation. Another modification
was to include an algorithm for altering
the values of sequences of three tags,
such as constructions with an intervening
adverb or simple co-ordinated
constructions such that the two words on
either side of a co-ordinating conjunction
contained the same tag where a choice was
available.
No value in the matrix was allowed to
be as little as zero, by providing a
minimum positive value for even extremely
unlikely tag co-occurrences; this allowed
at least some kind of analysis for unusual
or eccentric syntax and prevented the
system from grinding to a halt when
confronted with a construction that it
did not recognize.
Once these refinements to the suite of
word tagging programs were made, the
corpus was word-tagged. It was estimated
that the number of manual post-editing
interventions had been reduced from about
230,000 required for word tagging of the
Brawn corpus to about 35,000 required
for the LOB corpus (Leech, Garside and
Atwell, 1983: 36). The method achieves
far greater consistency than could be
attained by a human, were such a person
able to labour through the task of
attributing a tag to every word token in
the corpus.
A record of decisions made at the post-
editing stage was kept for the purpose of
recording the criteria for judging
whether tags were considered to be correct
or not (Atwell, 1982b).
Improving word tagging.
Work currently being undertaken at
Lancaster includes revising and extending
the word tag set and improving the suite
of programs and data files required to
carry out automatic word tagging.
Revision of the word tag set.
The word tag set is being revised so
that, whenever possible, tags are
mnemonic such that the characters chosen
for a tag are abbreviations of the
grammatical categories they represent.
This criterion for word tag improvement
is solely for the benefit of human
intelligibility and in some cases,
because of conflicting criteria of
distinctiveness and brevity, it is not
always possible to devise clearly
mnemonic tags. For instance, nouns and
verbs can be unequivocally tagged by the
first letter abbreviations &apos;N&apos; and &apos;V&apos;,
but the same cannot be said for articles,
adverbs and adjectives. These categories
are represented by the tags &apos;AT&apos;, &apos;RR&apos;,
and &apos;JJ&apos;.
It was decided, on the grounds of
improving mnemonicity, to change
representation of the category of number
in the tag set. In the old tag set,
singular forms of articles, determiners,
pronouns and nouns were unmarked, and
plural forms had the same tags as the
singular forms but with &apos;S&apos; as the end
character denoting plural. As far as
mnemonicity is concerned, this is
confusing, especially to someone
uninitiated in the refinements of LOB
tagging. In the new tag set, number is
</bodyText>
<page confidence="0.995917">
295
</page>
<bodyText confidence="0.999009147286822">
now marked by having &apos;1&apos; for singular
forms, &amp;quot;e2&apos; for plural forms and no number
character for nouns, articles and
determiners which exhibit no singular or
plural morphological distinctiveness (COD,
bAtLF, TROUT ... ).
It is desirable, 1-,oth for the purposes
of human intelligibility and for
mechanical processing, to make the tagged
system as hierarchized as possible. In
the old tag set modal verbs, and forms of
the verbs BE, DO and HAVE were tagged as
and &apos;H&amp;quot; (where
represents any of the characters used for
these tags denoting sub6lasses of each
tag class). In the new word tag set,
these have been recoded &apos;VM&apos;&apos;, &apos;VE*&apos;,
&apos;VD*&apos;, &apos;VU*&apos;, to show that they are, in
fact, verbs, and to facilitate verb
counting in a frequency Analysis of the
tagged corpus; &amp;quot;n&amp;quot; is the new tag for
lexical verbs.
It has been taken as a design principle
of the new tag set that, wherever possible,
subcategories and supPrcatpgoriesâ€¢should
be retrieved by referring to the
character position in the string of
characters making up a tag, major word
class Coding being denoted. by the initial
character(s) of the tag and subsequent
characters denoting morpho-syntac tic
subcategories.
Hierarchization of the new tag set is
best exemplified by pronouns. &apos;P&apos;1 is a
pronoun, ns distinct from other tag
. : , - -
initial characters, such as &apos;7&apos; for
noun, &apos;7&amp;quot; for verb and so on.
is a personal pronoun, as distinct from
an indefinite pronoun; &apos;FPI&amp;quot;
is a first person personal pronoun: I,
me, we, us, as distinct, from &apos;PTY.&apos;,
TrPin-r ZIT &apos;PPX*1 which are second,
third person and reflexive pronouns;
&apos;MS*. is a first person subject
personal pronoun: I and we, as distinct
from first person d(Tjeot personal pronouns,
me, and ea, denoted by 1PPIO*1; finally
1rPIS1:&apos;-ims the first person singular
subject personal pronoun, I (the colon
is used to show that the form must have
an initial capital letter).
The third criterion for revising and
enlargine the word tag set is to improve
and extend the linguistic categorisation.
For instance, a tag for the category of
predicative adjective, &apos;JA&apos;, has been
introduced for adjectives like ablaze,
adrift and afloat, in addition to the
7I-71711y existing distinction between
attributive and ordinary adjectives,
marked &apos;JB&apos; as distinct from &apos;,M.
There is an essential distributional
restriction on subclasses of adjectives
occurring only attributively or
predicatively, and it was considered
appropriate to:notate this in the tag set
in a consistent manner. The attributive
category has been introduced for
comparative adjectives, &apos;,MR&apos;, (UPPER,
CUTER ...) and superlative adjectives,
&apos;JET&apos;, (UTMOST, UTTERMOST ... ).
As a further example of improving the
linguistic categorization without
affecting the proportion of correctly
tagged word forms, consider the word ONE.
In the old tagging system, this word
was always assigned the tag &apos;CD1&apos;.
This is unsatisfactory, even though ONE
is always assigned the tag it is supposed
to receive, because ONE is not simply
a singular cardinal number. It can be a
singular impersonal pronoun, One is often
surprised la the reaction of Fh7 pupils,
or a singular common noun,-Tie wants this
one, contrasting, for instance, with=
Tiral form He wants those ones. It is
therefore appropriate for CITZ-Fo be
assigned 3 potential tags, &apos;CD1&apos;, &apos;P1&apos;,
and 1N1T11, one of which is to be selected
by the transition probability procedure.
Revision of the programs and data files.
Revision of the word tag set has
necessitated extensive revision of the
word- and suffixlists. The transition
matrix will be adapted so that the
corpus can be retagged with tags from
the new word tag set. In addition,
programs are being revised to reduce the
need for special pre-editing and input
format requirements. In this way, it will
be possible for the system to tag
English texts other than the LOB corpus
without pre-editing.
Reducing Pre-editing.
For the 1983 version of the tagged
corpus, a pre-editing stage was carried
out partly by computer and partly by a
human pre-editor (Atwell, 1982a). As part
of this stage, the computer automatically
reduced all sentence-initial capital
letters and the human pre-editor recapit-
alized those sentence initial characters
that began proper nouns. We are now
endeavouring to cut out this phase so that
the automatic tagging suite can process
input text in its normal orthographic
form as mixed case characters.
Sentence boundaries were explicitly
marked, an part of the input requirements
to the tagging procedures, and since
the word class of a word with an initial
capital letter is significantly affected
by whether it occurs at the beginning
of a sentence, it was considered
appropriate to make both sentence
boundary recognition and word class
assignment of words with a word initial
capital automatic. All entries in the
</bodyText>
<page confidence="0.99526">
296
</page>
<bodyText confidence="0.994149">
word list now appear entirely in lower
case and words which occur with different
tags according to initial letter status
(board, march, pija, white ...) are
assigned tags according to a field
selection procedure: the appropriate tags
are given in two fields, one for the
initial upper case form (when not acting
as the standard beginning-of-sentence
marker) and the other for the initial
lower case form. The probability of tags
being selected from the alternative lists
is weighted according to whether the form
occurs at the beginning of the sentence
or elsewhere.
Knut Hofland estimated a success rate
of about 94.3 per cent without pre-editing
(Leech, Garside and Atwell, 1983: 36).
Hence, the success rate only drops by
about 2 per cent without pre-editing.
Nevertheless, the problems raised by words
with tags varying according to initial
capital letter status need to be solved
if the system is to become completely
automatic and capable of correct tagging
of standard text.
Constituent Analysis.
The high success rate of word tag
selection achieved by the one-step
probability disambiguation procedure
prompted us to attempt a similar method
for the more complex tasks of phrase and
clause tagging. The paper by Garside and
Leech In this volume deals more fully with
this aspect of the work.
Rules and symbols for providing
a constituent analysis of each of the
sentences in the corpus are set out in a
Case-Law Manual (Sampson, 1984) and a
series of associated documents give the
reasoning for the choice of rules and
symbols (Sampson, 1983 - ). Extensive
tree drawing was undertaken while the
Case-Law Manual was being written, partly
to establish whether high-level tags and
rules for high-level tag assignment
needed to be modified in the light of the
enormous variety and complexity of
ordinary sentences in the corpus, and
partly to create a databank of manually
parsed samples of the LOB corpus, for the
purposes of providing a first-
approximation of the statistical data
required to disambiguate alternative
parses.
To date, about 35,000 words (1,500
sentences) have been manually parsed and
keyed into an ICL VME 2900 machine. We
are presently aiming for a tree hank of
about 50,000 words of evenly distributed
samples taken from different corpus
categories representing a cross-section
of about 5 per cent of the word tagged
corpus.
The future.
It should be made clear to the reader
that several aspects of the research
are cumulative. For instance, the
statistics derived from the tagged Brown
corpus were used to devise the one-step
probability program for word tag
disambiguation. Similarly, the word
tagged LOB corpus is taken as the Input
to automatic parsing.
At present, we are attempting to !
provide constituent structures for the
LOB corpus. Many of these constructions
are long and complex; it is notoriously
difficult to summarise the rich variety
of written Ehglish, as it actually occurs
in newspapers and books, by using a
limited set of rewrite rules. Initially,
we are attempting to parse the LOB
corpus using the statistics provided by
the tree bank and subsequently, after
error analysis and post-editing,
statistics of the parsed corpus can be
used for further research.
ACIUT0447.71GEMMTS
The work described by the author of
this paper is currently supported by
Science and Eagineering Research Council
Grant GR/C/47700.
</bodyText>
<sectionHeader confidence="0.997311" genericHeader="method">
REFEREUCES
</sectionHeader>
<reference confidence="0.996710113636364">
Abbreviation:
ICA ME . International Computer Archive
of Modern Eftglish.
Atwell, E.S. (1982a). LOB Corpus Tagin
Prodect: Manual Pre-edit Handbook.
thpublishea=a7177-771t for
Computer Research on the Ehglish
Language, University of Lancaster.
(1982b). LOB Corpus TaggingProject:
Manual Post-edit Handbook. (A mini-
grammar of LOB Corpus English,
examining the types of error commonly
made during automatic (computational)
analysis of ordinary written English).
Unpublished document: Unit for
Computer Research on the English
Language, University of Lancaster.
Francis, U.N. (1980). &apos;A tagged corpus -
problems and prospects&apos;, in Studies
in En lish linguistics for Randolph
171r 00) edited by S. G17705717,
G.N. Leech and J. Svartvik, 192-209.
London: Longman.
Greene, B.B. and Rubin, G.M. (1971).
&apos;Automatic Grammatical Tagging of
English&apos;, Providence, R.I.:
Department of Linguistics, Brown
University.
Hauge, J. and Hof land, K. (1978).
Microfiche version of the Brown
n3
177.747a7=7&amp;quot;---usrlor-PiTie=gy
American En lish. MWrgen: NAVF&apos;s E0B-
Senter for Huma.nistisk Forskning.
Jespersen, O. (1909-49). A Modern English,
Grammar on Historical FrIMITTes,
MunksgaaFT.
Johansson, S. (1982) (editor). Computer
Corpora in English, language research.
Bergen: -UOrwegian Computing Centre
for the Humanities.
Johansson, S. and Jahr, M-C. (1982).
&apos;Grammatical Tagging of the LOB Corpus:
Predicting Word Class from Word
Endings&apos;, in S. Johansson (1982), 118-
134.
Johansson, S., Leech, G. and Goodluck, H.
(1978). Manual of information to
accompany the Lancaster-OsyBergen
corvus of nitish English, or use with
digital computers. Unpublished document:
Department of English, University of
Oslo.
Kruisinga, E. and Erades, P.A. (1911).
An ,English Grammar. Nordhoof.
maniTa, H. and Francis, W.N. (1964,
revised 1971 and 1979). Manual of
Information to accompany 777-allaard
Corpus of Present-Day Sifted American
g is , for use with Digital
Combuterst-7r7ridence, Rhode Island:
Brown University Press.
Leech, G.N., Garside, R., and Atwell, E.
(1983). &apos;Recent Developments in the
use of Computer Corpora in English
Language Research&apos;, Transactions r)f the
Philological Society, 23-40.
Lo an Dictionary of Contemporary English
c 8). London: Longman.
Marshall, I. (1983). &apos;Choice of
Grammatical Word-Class without Global
Syntactic Analysis: Tagging Words in
the LOB Corpus&apos;, Computers and the
Humanities, Vol. 17, No. 3, 139-150.
Quirk, R., Greenbaum, S., Leech., G.N.
and Srartvik, J. (1972). A Grammar of
Contemporary English. London7IFFEEin.
(1985). A Compre ensive Grammar of the
English nnguage. London: Longman.
Sampson, G.R. (1984). UCREL Symbols and
Rules for Manual Tr;7:15Fawing.
nEFEITTlea-nriment: Unit Sor Computer
Research on the English Language,
University of Lancaster.
(1983 -). Tree Notes I - XIV.
Unpublished documents: Unit for
Computer Research on the English
Language, University of Lancaster.
</reference>
<page confidence="0.997178">
298
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9265255">GRAMMATICAL ANALYSIS BY COMPUTER OF THE LANCASTER-OSLO/BERGEN (LOB) CORPUS OF BRITISH ENGLISH TEXTS.</title>
<author confidence="0.999676">Andrew David Beale</author>
<affiliation confidence="0.9926595">Unit for Computer Research on the English Language Bowland College, University of Lancaster</affiliation>
<address confidence="0.970581">Bailrigg, Lancaster; England LA1 4YT.</address>
<abstract confidence="0.988471323529412">Research has been under way at the Unit for Computer Research on the English Language at the University of Lancaster, England, to develop a suite of computer programs which provide a detailed grammatical analysis of the LOB corpus, a collection of about 1 million words of. British English texts available in machine readable form. The first phrase of the project, completed in September 1983, produced a grammatically annotated version of the corpus giving a tag showing the word of each word token. Over cent of the word tags were correctly selected by using a matrix of tag pair probabilities and this figure was upgraded a further cent by retagging problematic strings of words prior to disambiguation and by altering the probability weightings for sequences of tags. The remaining 4 per cent were corrected by a human post-editor. The system was originally designed to run in batch mode over the corpus but we have recently modified procedures to run interactively for sample sentences typed in by a user at a terminal. We are currently extending the word tag set and improving the word tagging procedures to further reduce manual intervention. A similar probabilistic system is being developed for phrase and clause tagging.</abstract>
<note confidence="0.854683076923077">THE STRUCTURE AND PURPOSE OF THE LOB OORPUS. The LOB Corpus (Johansson, Leech and Goodluck, 1978), like its American English counterpart, the Brown Corpus (Kura and Francis, 1964; Hauge and Hofland, 1978), is a collection of 300 English texts, each containing about 2,000 word tokens. The samples are representations of 15 different text categories: A. Press (Reportage); B. Press (Editorial); C. Press cReviews); D. Religion; E.</note>
<title confidence="0.802912">Skills and Hobbies; F. Popular Lore;</title>
<author confidence="0.650749">G Belles Lettres</author>
<author confidence="0.650749">Memoirs Biography</author>
<abstract confidence="0.985881079303675">etc.; H. Miscellaneous; J. Learned and Scientific; K. General Fiction; L. Mystery and Detective Fiction; M. Science Fiction; N. Adventure and Western Fiction, Romance and Love Story; R. Humour. There are two main sections, informative prose and imaginative prose, and all the texts contained in the corpus were printed in a single year (1961). The structure of the LOB corpus was designed to resemble that of the Brown corpus as closely as possible so that a systematic comparison of British and American written English could be made. Both corpora contain samples of texts published in the same year (1961) so that comparisons are not distorted by diachronic factors. The LOB corpus is used as a database for linguistic research and language description. Historically, different linguists have been concerned to a greater or lesser extent with the use of corpus citations, to some degree, at least, because of differences in the perceived view of the descriptive requirements of grammar. Jespersen (1909-49), Kruisinga and Erades (1911) gave frequent examples of citations from assembled corpora of written texts to illustrate grammatical rules. Work on corpora course, very much alive today. Storage, retrieval and processing of natural language text is a more efficient and less laborious task with modern computer hardware than it was with hand-written card files but data capture is still a significant problem (Francis, 1980). The forthcoming Comprehensive Grammar of the Language(quirk, Greenbaum, leech, and Svartvik, 1985) contains many citations from both LOB and Brown Corpora. 293 A GRAMMATICALLY ANNOTATZD VERSION OF THE OORPUS Since 1981, research has been directed towards writing programs to grammatically annotate the LOB corpus. From 1981-83, the research effort produced a version of the corpus with every word token labelled by a grammatical tag showing the word class of each word form. Subsequent research has attempted to build on the techniques used for automatic word tagging by using the output from the word tagging programs as input to phrase and clause tagging and by using probabilistic methods to provide a constituent analysis of the LOB corpus. The programs and data files used for word tagging were developed from work done at Brown University (Greene and Rubin, 1971). Staff and research associates at Lancaster undertook the programming in PASCAL while colleagues in Oslo revised and extended the lists used by Greene and Rubin (op.cit.) for word tag assignment. Half of the corpus was post-edited at Lancaster and the other half at the Norwegian Computing Centre for the Humanities. How word tagging works. The major difficulties to be encountered with word tagging of written English are the lack of distinctive inflectional or derivational endings and the large proportion of word forms that belong to more than one word class. such as -able, and -ness are graphic realizations of morphological units indicating word class, but they occur infrequently for the purposes of automatic word tag assignment; the reader will be able to establish exceptions to rules assigning word classes to words with these suffixes, because the characters do not invariably represent the same morphemes. The solution we have adopted is to use a look up procedure to assign one or more potential tags to each input word. The appropriate word tag is then selected for words with more than one potential tag by calculating the probability of the tag&apos;s occurrence given neighbouring potential tags. â€žPotential word tag assignment. In cases where more than one potential tag is assigned to the input word, the tags represent word classes of the word without taking the syntactic environment into account. A list of one to five word final characters, known as the &apos;suffixlist&apos;, is used for assignment of appropriate word class tags to as many word types as possible. A list of full word forms, known as the &apos;wordlist&apos;, used for exceptions to the suffixlist, and, in addition, word forms that occur more than 50 times in the corpus are included in the wordlist, for speed of processing. The term &apos;suffixlist&apos; is used as a convenient name, and the reader is warned that the list does not necessarily contain word final morphs; strings of between one and five word final characters are included if their occurrence as a tagged form in the Brown corpus merits it. The &apos;suffixlist&apos; used by Greene and Rubin (op.cit.) was substantially revised and extended by Johansson and Jahr (1982) using reverse alphabetical lists of approximately 50,000 word types of the Brown Corpus arid 75,000 word types of both Brown and LOB corpora. Frequency lists specifying the frevehcy of tags word endings consisting of 1 5 characters were used to establish the efficiency of each rule. Johansson and Jahr were guided by the Longman Dictionary of Contemporary Ehglish (1978) and other dictionaries and grammars including Quirk, Greenbaum, Leech and identifying tags for each item in the wordlist. For the version used for Lancaster-Oslo/Bergen word tagging (1983), the suffixlist was expanded to about 700 strings of word final characters, the wordlist consisted of about 7,000 entries and a total of 133 word tag types were used. Potential tag disambiguation. The problem of resolving lexical ambiguity for the large proportion of Eaglish words that occur in more than one word class, (BLOW, CONTACT, HIT, LEFT, RAIN&apos;, RUN, REFUSE, ROSE, WALK, WATCH ...), is solved, whenever possible by examining the local context. Word tag selection for homographs in Greene and Rubin (op. cit.) was attempted by using &apos;context frame rules&apos;, an ordered list of 3,300 rules designed to take into account the tags assigned to up to two words preceding or following the ambiguous The program was cent successful but several errors were due to appropriate rules being blocked when adjacent ambiguities were encountered (Marshall, 1983: 140). Moreover, about 80 per cent of rule application took just one immediately neighbouring tag into account, even though only a quarter of the context frame rules specified only one immediately neighbouring tag. To overcome these difficulties, research associates at Lancaster have devised a transition probability matrix of tag pairs to compute the most probable tag for an ambiguous form given the immediately preceding and following tags. This method of calculating one-step transition probabilities is suitable for disambiguating strings of ambiguously tagged words because the most likely path through a string of ambiguously tagged words can be calculated. The likelihood of a tag being selected in context is also influenced by likelihood markers which are assigned to entries with more than one tag in the two markers, &apos;@&apos; and are used, &apos;@&apos; notionally indicating that the tag is correct for the form less than in 110 &apos;%&apos; notionally.indicating the tag occurs less than 1 in 100 occasions. The word tag disambiguation program uses these markers to reduce the probability of the less likely tags occurring in context; tig&apos; results in the being halved, results in the probability being divided by eight. tags marked with &apos;@&apos; or are only selected if the context indicates that the tag is very likely. Error analysis. At several stages during design and implementation of the tagging software, error analysis was used to improve various aspects of the word tagging system. Error statistics were used to amend the lists, the transition matrix entries and even the formula used for calculating transition probabilities (originally this was the frequency of potential tag A followed by potential tag B divided by the frequency of A. Subsequently, it was changed to the frequency of A followed by B divided by the product of the frequency of A and the frequency of B (Marshall, Error analysis indicated that the onestep transition method for word tag disambiguation was very successful, but was evident gains could be made by including a separate list of a small set of sequences of words such as to, as well as,and as to which were retagged prior to word tag disambiguation. Another modification was to include an algorithm for altering the values of sequences of three tags, such as constructions with an intervening adverb or simple co-ordinated constructions such that the two words on either side of a co-ordinating conjunction contained the same tag where a choice was available. No value in the matrix was allowed to be as little as zero, by providing a minimum positive value for even extremely unlikely tag co-occurrences; this allowed at least some kind of analysis for unusual or eccentric syntax and prevented the system from grinding to a halt when confronted with a construction that it did not recognize. Once these refinements to the suite of word tagging programs were made, the corpus was word-tagged. It was estimated that the number of manual post-editing interventions had been reduced from about 230,000 required for word tagging of the Brawn corpus to about 35,000 required for the LOB corpus (Leech, Garside and Atwell, 1983: 36). The method achieves far greater consistency than could be attained by a human, were such a person able to labour through the task of attributing a tag to every word token in the corpus. record of decisions made the postediting stage was kept for the purpose of recording the criteria for judging whether tags were considered to be correct or not (Atwell, 1982b). Improving word tagging. Work currently being undertaken at Lancaster includes revising and extending the word tag set and improving the suite of programs and data files required to carry out automatic word tagging. Revision of the word tag set. The word tag set is being revised so that, whenever possible, tags are mnemonic such that the characters chosen for a tag are abbreviations of the grammatical categories they represent. This criterion for word tag improvement is solely for the benefit of human intelligibility and in some cases, because of conflicting criteria of distinctiveness and brevity, it is not always possible to devise clearly mnemonic tags. For instance, nouns and verbs can be unequivocally tagged by the letter abbreviations &apos;V&apos;, but the same cannot be said for articles, adverbs and adjectives. These categories are represented by the tags &apos;AT&apos;, &apos;RR&apos;, and &apos;JJ&apos;. It was decided, on the grounds of improving mnemonicity, to change representation of the category of number in the tag set. In the old tag set, singular forms of articles, determiners, pronouns and nouns were unmarked, and plural forms had the same tags as the singular forms but with &apos;S&apos; as the end character denoting plural. As far as mnemonicity is concerned, this is confusing, especially to someone uninitiated in the refinements of LOB tagging. In the new tag set, number is 295 now marked by having &apos;1&apos; for singular forms, &amp;quot;e2&apos; for plural forms and no number character for nouns, articles and determiners which exhibit no singular or morphological distinctiveness ... ). It is desirable, 1-,oth for the purposes of human intelligibility and for mechanical processing, to make the tagged system as hierarchized as possible. In the old tag set modal verbs, and forms of the verbs BE, DO and HAVE were tagged as and &apos;H&amp;quot; (where represents any of the characters used for these tags denoting sub6lasses of each class). the new word tag set, these have been recoded &apos;VM&apos;&apos;, &apos;VE*&apos;, &apos;VD*&apos;, &apos;VU*&apos;, to show that they are, in fact, verbs, and to facilitate verb counting in a frequency Analysis of the corpus; the new tag for lexical verbs. It has been taken as a design principle the new set wherever possible, and be retrieved by referring to the character position in the string of characters making up a tag, major word class Coding being denoted. by the initial character(s) of the tag and subsequent characters denoting morpho-syntac tic subcategories. Hierarchization of the new tag set is exemplified by pronouns. is a pronoun, ns distinct from other tag . : , - initial characters, such as &apos;7&apos; for noun, &apos;7&amp;quot; for verb and so on. a personal pronoun, from an indefinite pronoun; &apos;FPI&amp;quot; is a first person personal pronoun: I, we, us, as from &apos;PTY.&apos;, ZIT which are second, third person and reflexive pronouns; is person personal pronoun: I and we, as distinct from first person d(Tjeot personal pronouns, and ea, denoted by finally the first person singular subject personal pronoun, I (the colon is used to show that the form must have an initial capital letter). third criterion for revising the word tag set is improve and extend the linguistic categorisation. For instance, a tag for the category of has been for adjectives like adrift and afloat, in addition to the distinction between attributive and ordinary adjectives, distinct There is an essential distributional restriction on subclasses of adjectives occurring only attributively or predicatively, and it was considered appropriate to:notate this in the tag set in a consistent manner. The attributive category has been introduced for comparative adjectives, &apos;,MR&apos;, (UPPER, CUTER ...) and superlative adjectives, &apos;JET&apos;, (UTMOST, UTTERMOST ... ). further example of improving the linguistic categorization without affecting the proportion of correctly tagged word forms, consider the word ONE. the tagging this word was always assigned the tag &apos;CD1&apos;. unsatisfactory, even though ONE is always assigned the tag it is supposed to receive, because ONE is not simply number. It can be a singular impersonal pronoun, One is often surprisedla the reactionof Fh7 pupils, a singular common wants this one, contrasting, for instance, with= Tiral form He wants those ones. It is appropriate for be assigned 3 potential tags, &apos;CD1&apos;, &apos;P1&apos;, one of which is to be selected by the transition probability procedure. Revision of the programs and data files. Revision of the word tag set has necessitated extensive revision of the wordand suffixlists. The transition matrix will be adapted so that the corpus can be retagged with tags from the new word tag set. In addition, revised to reduce the need for special pre-editing and input format requirements. In this way, it will be possible for the system to tag English texts other than the LOB corpus without pre-editing. Reducing Pre-editing. For the 1983 version of the tagged corpus, a pre-editing stage was carried out partly by computer and partly by a human pre-editor (Atwell, 1982a). As part of this stage, the computer automatically reduced all sentence-initial capital letters and the human pre-editor recapitalized those sentence initial characters that began proper nouns. We are now endeavouring to cut out this phase so that the automatic tagging suite can process input text in its normal orthographic as mixed characters. were explicitly marked, an part of the input requirements tagging procedures, and since word of a word with initial capital letter is significantly affected by whether it occurs at the beginning of a sentence, it was considered appropriate to make both sentence boundary recognition and word class assignment of words with a word initial capital automatic. All entries in the 296 word list now appear entirely in lower case and words which occur with different tags according to initial letter status (board, march, pija, white ...) are assigned tags according to a field selection procedure: the appropriate tags are given in two fields, one for the initial upper case form (when not acting as the standard beginning-of-sentence marker) and the other for the initial lower case form. The probability of tags being selected from the alternative lists is weighted according to whether the form occurs at the beginning of the sentence or elsewhere. Knut Hofland estimated a success rate of about 94.3 per cent without pre-editing (Leech, Garside and Atwell, 1983: 36). Hence, the success rate only drops by about 2 per cent without pre-editing. Nevertheless, the problems raised by words with tags varying according to initial capital letter status need to be solved if the system is to become completely automatic and capable of correct tagging of standard text. Constituent Analysis. The high success rate of word tag selection achieved by the one-step probability disambiguation procedure prompted us to attempt a similar method for the more complex tasks of phrase and clause tagging. The paper by Garside and Leech In this volume deals more fully with this aspect of the work. Rules and symbols for providing a constituent analysis of each of the sentences in the corpus are set out in a Case-Law Manual (Sampson, 1984) and a series of associated documents give the reasoning for the choice of rules and symbols (Sampson, 1983 - ). Extensive tree drawing was undertaken while the Case-Law Manual was being written, partly to establish whether high-level tags and rules for high-level tag assignment needed to be modified in the light of the enormous variety and complexity of ordinary sentences in the corpus, and partly to create a databank of manually parsed samples of the LOB corpus, for the purposes of providing a firstapproximation of the statistical data required to disambiguate alternative parses. To date, about 35,000 words (1,500 sentences) have been manually parsed and keyed into an ICL VME 2900 machine. We are presently aiming for a tree hank of about 50,000 words of evenly distributed samples taken from different corpus categories representing a cross-section of about 5 per cent of the word tagged corpus. The future. It should be made clear to the reader that several aspects of the research are cumulative. For instance, the statistics derived from the tagged Brown corpus were used to devise the one-step probability program for word tag disambiguation. Similarly, the word tagged LOB corpus is taken as the Input to automatic parsing. At present, we are attempting to ! provide constituent structures for the LOB corpus. Many of these constructions are long and complex; it is notoriously difficult to summarise the rich variety of written Ehglish, as it actually occurs in newspapers and books, by using a limited set of rewrite rules. Initially, we are attempting to parse the LOB corpus using the statistics provided by the tree bank and subsequently, after error analysis and post-editing, statistics of the parsed corpus can be used for further research.</abstract>
<note confidence="0.905378727272727">ACIUT0447.71GEMMTS The work described by the author of this paper is currently supported by Science and Eagineering Research Council Grant GR/C/47700. REFEREUCES Abbreviation: ICA ME . International Computer Archive of Modern Eftglish. E.S. (1982a). LOB CorpusTagin Prodect:Manual Pre-edit Handbook.</note>
<email confidence="0.594387">for</email>
<affiliation confidence="0.720700333333333">Computer Research on the Ehglish Language, University of Lancaster. LOB Corpus</affiliation>
<abstract confidence="0.8632122">Handbook.(A miniof LOB English, examining the types of error commonly made during automatic (computational) analysis of ordinary written English).</abstract>
<affiliation confidence="0.855535">Unpublished document: Unit for Computer Research on the English Language, University of Lancaster.</affiliation>
<address confidence="0.765972">Francis, U.N. (1980). &apos;A tagged corpus -</address>
<note confidence="0.922659512195122">and prospects&apos;, in En lish linguisticsfor Randolph 171r00) edited by S. G17705717, G.N. Leech and J. Svartvik, 192-209. London: Longman. Greene, B.B. and Rubin, G.M. (1971). &apos;Automatic Grammatical Tagging of Providence, Department of Linguistics, Brown University. Hauge, J. and Hof land, K. (1978). Microfiche version of the Brown n3 AmericanEn lish. MWrgen: NAVF&apos;s E0B- Senter for Huma.nistisk Forskning. O. (1909-49). A Modern Grammaron FrIMITTes, MunksgaaFT. S. (1982) (editor). Corporain language research. Computing Centre for the Humanities. Johansson, S. and Jahr, M-C. (1982). &apos;Grammatical Tagging of the LOB Corpus: Predicting Word Class from Word Endings&apos;, in S. Johansson (1982), 118- 134. Johansson, S., Leech, G. and Goodluck, H. Manualof informationto accompanythe corvusof English,or computers.Unpublished document: English, University of Oslo. Kruisinga, E. and Erades, P.A. (1911). ,EnglishGrammar. Nordhoof. H. Francis, (1964, revised 1971 and 1979). Manual of Informationto accompany of Sifted American is , for use with</note>
<author confidence="0.693186">Rhode Island</author>
<affiliation confidence="0.977596">Brown University Press.</affiliation>
<address confidence="0.624662">Leech, G.N., Garside, R., and Atwell, E.</address>
<note confidence="0.908129555555555">(1983). &apos;Recent Developments in the use of Computer Corpora in English Language Research&apos;, Transactions r)f the Philological Society, 23-40. an Dictionaryof English 8). London: Marshall, I. (1983). &apos;Choice of Grammatical Word-Class without Global Analysis: Words the LOB Corpus&apos;, Computers and the Humanities, Vol. 17, No. 3, 139-150. Quirk, R., Greenbaum, S., Leech., G.N. and Srartvik, J. (1972). A Grammar of ContemporaryEnglish. London7IFFEEin. A ensiveGrammar of the Englishnnguage.London: Longman. Sampson, G.R. (1984). UCREL Symbols and for Manual Tr;7:15Fawing.</note>
<affiliation confidence="0.804149428571429">Unit Sor Computer Research on the English Language, University of Lancaster. (1983 -). Tree Notes I - XIV. Unpublished documents: Unit for Computer Research on the English Language, University of Lancaster.</affiliation>
<address confidence="0.850525">298</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>ICA ME</author>
</authors>
<journal>International Computer Archive of Modern Eftglish.</journal>
<marker>ME, </marker>
<rawString>ICA ME . International Computer Archive of Modern Eftglish.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E S Atwell</author>
</authors>
<title>LOB Corpus Tagin Prodect: Manual Pre-edit Handbook. thpublishea=a7177-771t for Computer Research on the Ehglish Language,</title>
<date>1982</date>
<institution>University of Lancaster.</institution>
<contexts>
<context position="11681" citStr="Atwell, 1982" startWordPosition="1885" endWordPosition="1886">word-tagged. It was estimated that the number of manual post-editing interventions had been reduced from about 230,000 required for word tagging of the Brawn corpus to about 35,000 required for the LOB corpus (Leech, Garside and Atwell, 1983: 36). The method achieves far greater consistency than could be attained by a human, were such a person able to labour through the task of attributing a tag to every word token in the corpus. A record of decisions made at the postediting stage was kept for the purpose of recording the criteria for judging whether tags were considered to be correct or not (Atwell, 1982b). Improving word tagging. Work currently being undertaken at Lancaster includes revising and extending the word tag set and improving the suite of programs and data files required to carry out automatic word tagging. Revision of the word tag set. The word tag set is being revised so that, whenever possible, tags are mnemonic such that the characters chosen for a tag are abbreviations of the grammatical categories they represent. This criterion for word tag improvement is solely for the benefit of human intelligibility and in some cases, because of conflicting criteria of distinctiveness and </context>
<context position="17095" citStr="Atwell, 1982" startWordPosition="2768" endWordPosition="2769">ata files. Revision of the word tag set has necessitated extensive revision of the word- and suffixlists. The transition matrix will be adapted so that the corpus can be retagged with tags from the new word tag set. In addition, programs are being revised to reduce the need for special pre-editing and input format requirements. In this way, it will be possible for the system to tag English texts other than the LOB corpus without pre-editing. Reducing Pre-editing. For the 1983 version of the tagged corpus, a pre-editing stage was carried out partly by computer and partly by a human pre-editor (Atwell, 1982a). As part of this stage, the computer automatically reduced all sentence-initial capital letters and the human pre-editor recapitalized those sentence initial characters that began proper nouns. We are now endeavouring to cut out this phase so that the automatic tagging suite can process input text in its normal orthographic form as mixed case characters. Sentence boundaries were explicitly marked, an part of the input requirements to the tagging procedures, and since the word class of a word with an initial capital letter is significantly affected by whether it occurs at the beginning of a </context>
</contexts>
<marker>Atwell, 1982</marker>
<rawString>Atwell, E.S. (1982a). LOB Corpus Tagin Prodect: Manual Pre-edit Handbook. thpublishea=a7177-771t for Computer Research on the Ehglish Language, University of Lancaster. (1982b). LOB Corpus TaggingProject: Manual Post-edit Handbook. (A minigrammar of LOB Corpus English, examining the types of error commonly made during automatic (computational) analysis of ordinary written English). Unpublished document: Unit for Computer Research on the English Language, University of Lancaster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U N Francis</author>
</authors>
<title>A tagged corpus -problems and prospects&apos;,</title>
<date>1980</date>
<booktitle>in Studies in En lish linguistics for Randolph 171r 00) edited by S. G17705717, G.N. Leech</booktitle>
<pages>192--209</pages>
<publisher>Longman.</publisher>
<location>London:</location>
<contexts>
<context position="3491" citStr="Francis, 1980" startWordPosition="550" endWordPosition="551">ser extent with the use of corpus citations, to some degree, at least, because of differences in the perceived view of the descriptive requirements of grammar. Jespersen (1909-49), Kruisinga and Erades (1911) gave frequent examples of citations from assembled corpora of written texts to illustrate grammatical rules. Work on text corpora is, of course, very much alive today. Storage, retrieval and processing of natural language text is a more efficient and less laborious task with modern computer hardware than it was with hand-written card files but data capture is still a significant problem (Francis, 1980). The forthcoming work, A Comprehensive Grammar of the aglish Language (quirk, Greenbaum, leech, and Svartvik, 1985) contains many citations from both LOB and Brown Corpora. 293 A GRAMMATICALLY ANNOTATZD VERSION OF THE OORPUS Since 1981, research has been directed towards writing programs to grammatically annotate the LOB corpus. From 1981-83, the research effort produced a version of the corpus with every word token labelled by a grammatical tag showing the word class of each word form. Subsequent research has attempted to build on the techniques used for automatic word tagging by using the o</context>
</contexts>
<marker>Francis, 1980</marker>
<rawString>Francis, U.N. (1980). &apos;A tagged corpus -problems and prospects&apos;, in Studies in En lish linguistics for Randolph 171r 00) edited by S. G17705717, G.N. Leech and J. Svartvik, 192-209. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B B Greene</author>
<author>G M Rubin</author>
</authors>
<title>Automatic Grammatical Tagging of English&apos;,</title>
<date>1971</date>
<institution>Department of Linguistics, Brown University.</institution>
<location>Providence, R.I.:</location>
<contexts>
<context position="4378" citStr="Greene and Rubin, 1971" startWordPosition="689" endWordPosition="692"> towards writing programs to grammatically annotate the LOB corpus. From 1981-83, the research effort produced a version of the corpus with every word token labelled by a grammatical tag showing the word class of each word form. Subsequent research has attempted to build on the techniques used for automatic word tagging by using the output from the word tagging programs as input to phrase and clause tagging and by using probabilistic methods to provide a constituent analysis of the LOB corpus. The programs and data files used for word tagging were developed from work done at Brown University (Greene and Rubin, 1971). Staff and research associates at Lancaster undertook the programming in PASCAL while colleagues in Oslo revised and extended the lists used by Greene and Rubin (op.cit.) for word tag assignment. Half of the corpus was post-edited at Lancaster and the other half at the Norwegian Computing Centre for the Humanities. How word tagging works. The major difficulties to be encountered with word tagging of written English are the lack of distinctive inflectional or derivational endings and the large proportion of word forms that belong to more than one word class. Endings such as -able, -1.z. and -n</context>
</contexts>
<marker>Greene, Rubin, 1971</marker>
<rawString>Greene, B.B. and Rubin, G.M. (1971). &apos;Automatic Grammatical Tagging of English&apos;, Providence, R.I.: Department of Linguistics, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hauge</author>
<author>Hof land</author>
<author>K</author>
</authors>
<title>Microfiche version of the Brown n3 American En lish. MWrgen: NAVF&apos;s E0BSenter for Huma.nistisk Forskning.</title>
<date>1978</date>
<marker>Hauge, land, K, 1978</marker>
<rawString>Hauge, J. and Hof land, K. (1978). Microfiche version of the Brown n3 American En lish. MWrgen: NAVF&apos;s E0BSenter for Huma.nistisk Forskning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Jespersen</author>
</authors>
<date>1909</date>
<journal>A Modern English, Grammar on Historical FrIMITTes, MunksgaaFT.</journal>
<contexts>
<context position="3052" citStr="Jespersen (1909" startWordPosition="483" endWordPosition="484">to resemble that of the Brown corpus as closely as possible so that a systematic comparison of British and American written English could be made. Both corpora contain samples of texts published in the same year (1961) so that comparisons are not distorted by diachronic factors. The LOB corpus is used as a database for linguistic research and language description. Historically, different linguists have been concerned to a greater or lesser extent with the use of corpus citations, to some degree, at least, because of differences in the perceived view of the descriptive requirements of grammar. Jespersen (1909-49), Kruisinga and Erades (1911) gave frequent examples of citations from assembled corpora of written texts to illustrate grammatical rules. Work on text corpora is, of course, very much alive today. Storage, retrieval and processing of natural language text is a more efficient and less laborious task with modern computer hardware than it was with hand-written card files but data capture is still a significant problem (Francis, 1980). The forthcoming work, A Comprehensive Grammar of the aglish Language (quirk, Greenbaum, leech, and Svartvik, 1985) contains many citations from both LOB and Br</context>
</contexts>
<marker>Jespersen, 1909</marker>
<rawString>Jespersen, O. (1909-49). A Modern English, Grammar on Historical FrIMITTes, MunksgaaFT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Johansson</author>
</authors>
<date>1982</date>
<booktitle>Computer Corpora in English, language research. Bergen: -UOrwegian Computing Centre for the Humanities.</booktitle>
<editor>(editor).</editor>
<marker>Johansson, 1982</marker>
<rawString>Johansson, S. (1982) (editor). Computer Corpora in English, language research. Bergen: -UOrwegian Computing Centre for the Humanities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Johansson</author>
<author>M-C Jahr</author>
</authors>
<title>Grammatical Tagging of the LOB Corpus: Predicting Word Class from Word Endings&apos;,</title>
<date>1982</date>
<booktitle>in S. Johansson</booktitle>
<pages>118--134</pages>
<contexts>
<context position="6582" citStr="Johansson and Jahr (1982)" startWordPosition="1052" endWordPosition="1055">as possible. A list of full word forms, known as the &apos;wordlist&apos;, used for exceptions to the suffixlist, and, in addition, word forms that occur more than 50 times in the corpus are included in the wordlist, for speed of processing. The term &apos;suffixlist&apos; is used as a convenient name, and the reader is warned that the list does not necessarily contain word final morphs; strings of between one and five word final characters are included if their occurrence as a tagged form in the Brown corpus merits it. The &apos;suffixlist&apos; used by Greene and Rubin (op.cit.) was substantially revised and extended by Johansson and Jahr (1982) using reverse alphabetical lists of approximately 50,000 word types of the Brown Corpus arid 75,000 word types of both Brown and LOB corpora. Frequency lists specifying the frevehcy of tags for word endings consisting of 1 to 5 characters were used to establish the efficiency of each rule. Johansson and Jahr were guided by the Longman Dictionary of Contemporary Ehglish (1978) and other dictionaries and grammars including Quirk, Greenbaum, Leech and Svartvik (1972) in identifying tags for each item in the wordlist. For the version used for Lancaster-Oslo/Bergen word tagging (1983), the suffixl</context>
</contexts>
<marker>Johansson, Jahr, 1982</marker>
<rawString>Johansson, S. and Jahr, M-C. (1982). &apos;Grammatical Tagging of the LOB Corpus: Predicting Word Class from Word Endings&apos;, in S. Johansson (1982), 118-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Johansson</author>
<author>G Leech</author>
<author>H Goodluck</author>
</authors>
<title>Manual of information to accompany the Lancaster-OsyBergen corvus of nitish English, or use with digital computers. Unpublished document:</title>
<date>1978</date>
<institution>Department of English, University of Oslo.</institution>
<marker>Johansson, Leech, Goodluck, 1978</marker>
<rawString>Johansson, S., Leech, G. and Goodluck, H. (1978). Manual of information to accompany the Lancaster-OsyBergen corvus of nitish English, or use with digital computers. Unpublished document: Department of English, University of Oslo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kruisinga</author>
<author>P A Erades</author>
</authors>
<date>1911</date>
<journal>An ,English Grammar. Nordhoof.</journal>
<contexts>
<context position="3085" citStr="Kruisinga and Erades (1911)" startWordPosition="485" endWordPosition="488">he Brown corpus as closely as possible so that a systematic comparison of British and American written English could be made. Both corpora contain samples of texts published in the same year (1961) so that comparisons are not distorted by diachronic factors. The LOB corpus is used as a database for linguistic research and language description. Historically, different linguists have been concerned to a greater or lesser extent with the use of corpus citations, to some degree, at least, because of differences in the perceived view of the descriptive requirements of grammar. Jespersen (1909-49), Kruisinga and Erades (1911) gave frequent examples of citations from assembled corpora of written texts to illustrate grammatical rules. Work on text corpora is, of course, very much alive today. Storage, retrieval and processing of natural language text is a more efficient and less laborious task with modern computer hardware than it was with hand-written card files but data capture is still a significant problem (Francis, 1980). The forthcoming work, A Comprehensive Grammar of the aglish Language (quirk, Greenbaum, leech, and Svartvik, 1985) contains many citations from both LOB and Brown Corpora. 293 A GRAMMATICALLY </context>
</contexts>
<marker>Kruisinga, Erades, 1911</marker>
<rawString>Kruisinga, E. and Erades, P.A. (1911). An ,English Grammar. Nordhoof.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H maniTa</author>
<author>W N Francis</author>
</authors>
<title>revised 1971 and 1979). Manual of Information to accompany 777-allaard Corpus of Present-Day Sifted American g is , for use with Digital Combuterst-7r7ridence, Rhode Island:</title>
<date>1964</date>
<publisher>Brown University Press.</publisher>
<marker>maniTa, Francis, 1964</marker>
<rawString>maniTa, H. and Francis, W.N. (1964, revised 1971 and 1979). Manual of Information to accompany 777-allaard Corpus of Present-Day Sifted American g is , for use with Digital Combuterst-7r7ridence, Rhode Island: Brown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Leech</author>
<author>R Garside</author>
<author>E Atwell</author>
</authors>
<title>Recent Developments in the use of</title>
<date>1983</date>
<journal>Computer Corpora in English Language Research&apos;, Transactions r)f the Philological Society,</journal>
<pages>23--40</pages>
<marker>Leech, Garside, Atwell, 1983</marker>
<rawString>Leech, G.N., Garside, R., and Atwell, E. (1983). &apos;Recent Developments in the use of Computer Corpora in English Language Research&apos;, Transactions r)f the Philological Society, 23-40.</rawString>
</citation>
<citation valid="false">
<title>Lo an Dictionary of Contemporary English c 8).</title>
<publisher>Longman.</publisher>
<location>London:</location>
<marker></marker>
<rawString>Lo an Dictionary of Contemporary English c 8). London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Marshall</author>
</authors>
<title>Choice of Grammatical Word-Class without Global Syntactic Analysis: Tagging Words in</title>
<date>1983</date>
<journal>the LOB Corpus&apos;, Computers and the Humanities,</journal>
<volume>17</volume>
<pages>139--150</pages>
<contexts>
<context position="8041" citStr="Marshall, 1983" startWordPosition="1285" endWordPosition="1286">portion of Eaglish words that occur in more than one word class, (BLOW, CONTACT, HIT, LEFT, RAIN&apos;, RUN, REFUSE, ROSE, WALK, WATCH ...), is solved, whenever possible by examining the local context. Word tag selection for homographs in Greene and Rubin (op. cit.) was attempted by using &apos;context frame rules&apos;, an ordered list of 3,300 rules designed to take into account the tags assigned to up to two words preceding or following the ambiguous homograph. The program was 77 per cent successful but several errors were due to appropriate rules being blocked when adjacent ambiguities were encountered (Marshall, 1983: 140). Moreover, about 80 per cent of rule application took just one immediately neighbouring tag into account, even though only a quarter of the context frame rules specified only one immediately neighbouring tag. To overcome these difficulties, research associates at Lancaster have devised a transition probability matrix of tag pairs to compute the most probable tag for an ambiguous form given the immediately preceding and following tags. This method of calculating one-step transition probabilities is suitable for disambiguating strings of ambiguously tagged words because the most likely pa</context>
<context position="9999" citStr="Marshall, 1983" startWordPosition="1601" endWordPosition="1602">ndicates that the tag is very likely. Error analysis. At several stages during design and implementation of the tagging software, error analysis was used to improve various aspects of the word tagging system. Error statistics were used to amend the lists, the transition matrix entries and even the formula used for calculating transition probabilities (originally this was the frequency of potential tag A followed by potential tag B divided by the frequency of A. Subsequently, it was changed to the frequency of A followed by B divided by the product of the frequency of A and the frequency of B (Marshall, 1983: 144ff)). Error analysis indicated that the onestep transition method for word tag disambiguation was very successful, but it was evident that further gains could be made by including a separate list of a small set of sequences of words such as according to, as well as, and so as to which were retagged prior to word tag disambiguation. Another modification was to include an algorithm for altering the values of sequences of three tags, such as constructions with an intervening adverb or simple co-ordinated constructions such that the two words on either side of a co-ordinating conjunction cont</context>
</contexts>
<marker>Marshall, 1983</marker>
<rawString>Marshall, I. (1983). &apos;Choice of Grammatical Word-Class without Global Syntactic Analysis: Tagging Words in the LOB Corpus&apos;, Computers and the Humanities, Vol. 17, No. 3, 139-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G N Leech</author>
<author>J Srartvik</author>
</authors>
<title>A Grammar of Contemporary English.</title>
<date>1972</date>
<booktitle>London7IFFEEin.</booktitle>
<publisher>Longman.</publisher>
<location>London:</location>
<marker>Quirk, Greenbaum, Leech, Srartvik, 1972</marker>
<rawString>Quirk, R., Greenbaum, S., Leech., G.N. and Srartvik, J. (1972). A Grammar of Contemporary English. London7IFFEEin. (1985). A Compre ensive Grammar of the English nnguage. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Sampson</author>
</authors>
<title>UCREL Symbols and Rules for Manual Tr;7:15Fawing. nEFEITTlea-nriment: Unit Sor Computer Research on the English Language,</title>
<date>1984</date>
<institution>University of Lancaster.</institution>
<contexts>
<context position="19317" citStr="Sampson, 1984" startWordPosition="3127" endWordPosition="3128">rding to initial capital letter status need to be solved if the system is to become completely automatic and capable of correct tagging of standard text. Constituent Analysis. The high success rate of word tag selection achieved by the one-step probability disambiguation procedure prompted us to attempt a similar method for the more complex tasks of phrase and clause tagging. The paper by Garside and Leech In this volume deals more fully with this aspect of the work. Rules and symbols for providing a constituent analysis of each of the sentences in the corpus are set out in a Case-Law Manual (Sampson, 1984) and a series of associated documents give the reasoning for the choice of rules and symbols (Sampson, 1983 - ). Extensive tree drawing was undertaken while the Case-Law Manual was being written, partly to establish whether high-level tags and rules for high-level tag assignment needed to be modified in the light of the enormous variety and complexity of ordinary sentences in the corpus, and partly to create a databank of manually parsed samples of the LOB corpus, for the purposes of providing a firstapproximation of the statistical data required to disambiguate alternative parses. To date, ab</context>
</contexts>
<marker>Sampson, 1984</marker>
<rawString>Sampson, G.R. (1984). UCREL Symbols and Rules for Manual Tr;7:15Fawing. nEFEITTlea-nriment: Unit Sor Computer Research on the English Language, University of Lancaster.</rawString>
</citation>
<citation valid="true">
<title>Tree Notes I - XIV. Unpublished documents:</title>
<date>1983</date>
<institution>Unit for Computer Research on the English Language, University of Lancaster.</institution>
<contexts>
<context position="7169" citStr="(1983)" startWordPosition="1146" endWordPosition="1146">son and Jahr (1982) using reverse alphabetical lists of approximately 50,000 word types of the Brown Corpus arid 75,000 word types of both Brown and LOB corpora. Frequency lists specifying the frevehcy of tags for word endings consisting of 1 to 5 characters were used to establish the efficiency of each rule. Johansson and Jahr were guided by the Longman Dictionary of Contemporary Ehglish (1978) and other dictionaries and grammars including Quirk, Greenbaum, Leech and Svartvik (1972) in identifying tags for each item in the wordlist. For the version used for Lancaster-Oslo/Bergen word tagging (1983), the suffixlist was expanded to about 700 strings of word final characters, the wordlist consisted of about 7,000 entries and a total of 133 word tag types were used. Potential tag disambiguation. The problem of resolving lexical ambiguity for the large proportion of Eaglish words that occur in more than one word class, (BLOW, CONTACT, HIT, LEFT, RAIN&apos;, RUN, REFUSE, ROSE, WALK, WATCH ...), is solved, whenever possible by examining the local context. Word tag selection for homographs in Greene and Rubin (op. cit.) was attempted by using &apos;context frame rules&apos;, an ordered list of 3,300 rules des</context>
</contexts>
<marker>1983</marker>
<rawString>(1983 -). Tree Notes I - XIV. Unpublished documents: Unit for Computer Research on the English Language, University of Lancaster.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>