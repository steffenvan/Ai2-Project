<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005104">
<title confidence="0.9954275">
Tackling Sparsity, the Achilles Heel of Social Networks:
Language Model Smoothing via Social Regularization
</title>
<author confidence="0.997575">
Rui Yan1, Xiang Li1,2, Mengwen Liu3 and Xiaohua Hu3
</author>
<affiliation confidence="0.984561333333333">
1Baidu Research, Baidu Inc., Beijing, China
2Dept. of Computer Science &amp; Technology, Peking University, Beijing, China
3College of Information Science &amp; Technology, Drexel University, Philadelphia, USA
</affiliation>
<email confidence="0.998952">
{yanrui02,lixiang32}@baidu.com, {ml943,xh29}@drexel.edu
</email>
<sectionHeader confidence="0.994789" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999643368421053">
Online social networks nowadays have the
worldwide prosperity, as they have revo-
lutionized the way for people to discover,
to share, and to diffuse information. So-
cial networks are powerful, yet they still
have Achilles Heel: extreme data sparsi-
ty. Individual posting documents, (e.g., a
microblog less than 140 characters), seem
to be too sparse to make a difference un-
der various scenarios, while in fact they
are quite different. We propose to tackle
this specific weakness of social networks
by smoothing the posting document lan-
guage model based on social regulariza-
tion. We formulate an optimization frame-
work with a social regularizer. Experimen-
tal results on the Twitter dataset validate
the effectiveness and efficiency of our pro-
posed model.
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.965365833333333">
Along with Web 2.0 online social networks have
revolutionized the way for people to discover, to
share and to propagate information via peer-to-
peer interactions (Kwak et al., 2010). Although
powerful as social networks are, they still suffer
from a severe weakness: extreme sparsity. Due
to the special characteristics of real-time propa-
gation, the postings on social networks are either
officially limited within a limit length (140 char-
acters on Twitter), or generally quite short due to
user preference. Given limited text data sampling,
a language model estimation usually encounters
with zero count problem when facing with data s-
parsity, which is not reliable. Therefore, sparsity
is regarded as the Achilles Heel of social networks
and now we aim at tackling the bottleneck (Yan et
al., 2015).
Statistical language models have attracted much
attention in research communities. Till now much
Figure 1: 2 different sources to smooth document
language models: texts (colored in yellow) and so-
cial contacts (colored in blue). Each piece of texts
is authored by a particular social network user.
work on language model smoothing has been in-
vestigated based on textual characteristics (Laffer-
ty and Zhai, 2001; Yan et al., 2013; Liu and Croft,
2004; Tao et al., 2006; Lavrenko and Croft, 2001;
Song and Croft, 1999). However, for social net-
works, texts are actually associated with users (as
illustrated in Figure 1). We propose that social fac-
tors should be utilized as an augmentation to better
smooth language models.
Here we propose an optimization framework
with regularization for language model smoothing
on social networks, using both textual informa-
tion and the social structure. We believe the social
factor is fundamental to smooth language models
on social networks. Our framework optimizes the
smoothed language model to be closer to social
neighbors in the online network, while avoid de-
viating too much from the original user language
models. Our contributions are as follows:
</bodyText>
<listItem confidence="0.995987571428571">
• We have proposed a balanced language mod-
el smoothing framework with optimization, using
text information with social structure as a regular-
izer;
• We have investigated an effective and efficien-
t strategy to model the social information among
social network users.
</listItem>
<page confidence="0.950449">
623
</page>
<bodyText confidence="0.924278235294118">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 623–629,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
We evaluate the effect of our proposed language
model smoothing model using datasets from Twit-
ter. Experimental results show that language mod-
el smoothing with social regularization is effec-
tive and efficient in terms of intrinsic evaluation
by perplexity and running time: we show that the
Achilles Heel of social networks could be to some
extent tackled.
The rest of the paper is organized as follows.
We start by reviewing previous works. Then we
introduce the language model smoothing with so-
cial regularization and its optimization. We de-
scribe the experiments and evaluation in the next
section and finally draw the conclusions.
</bodyText>
<sectionHeader confidence="0.999785" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999964126984127">
Language models have been paid high attention
to during recent years (Ponte and Croft, 1998).
Many different ways of language modeling have
been proposed to solve different tasks. Better es-
timation of query language models (Lafferty and
Zhai, 2001; Lavrenko and Croft, 2001) and more
accurate estimation of document language mod-
els (Liu and Croft, 2004; Tao et al., 2006) have
long been proved to be of great significance in
information retrieval and text mining, etc. Lan-
guage models are typically implemented based on
retrieval models, e.g., text weighting and normal-
ization (Zhai and Lafferty, 2001), but with more
elegant mathematical and statistical foundations
(Song and Croft, 1999).
There is one problem for language models.
Given limited data sampling, a language mod-
el estimation sometimes encounters with the zero
count problem: the maximum likelihood estima-
tor would assign unseen terms a zero probability,
which is not reliable. Language model enrichment
is proposed to address this problem, and has been
demonstrated to be of great significance (Zhai and
Lafferty, 2001; Lafferty and Zhai, 2001).
There are many ways to enrich the original lan-
guage model. The information of background cor-
pus has been incorporated using linear combina-
tion (Ponte and Croft, 1998; Zhai and Lafferty,
2001). In contrast to the simple strategy which s-
mooths all documents with the same background,
recently corpus structures have been exploited for
more accurate smoothing. The basic idea is to s-
mooth a document language model with the docu-
ments similar to the document under consideration
through clustering (Liu and Croft, 2004; Tao et al.,
2006). Position information has also been used to
enrich language model smoothing (Zhao and Yun,
2009; Lv and Zhai, 2009) and has been used in the
combination of both enrichment of position and
semantic (Yan et al., 2013). Beyond the semantic
and/or position related smoothing intuitions, doc-
ument structure based language model smoothing
is another direction to investigate (Duan and Zhai,
2011). Mei et al. have proposed to smooth lan-
guage model utilizing structural adjacency (2008).
None of these methods incorporates social factors
in language model smoothing.
There is a study in (Lin et al., 2011) which s-
mooths document language models of tweets for
topic tracking in online text streams. Basically, it
applies general smoothing strategies (e.g., Jelinek-
Mercer, Dirichlet, Absolute Discounting, etc.) on
the specific tracking task. Social information is
incorporated into a factor graph model as features
(Huang et al., 2014; Yan et al., 2015). These fac-
tor graph model based methods are less efficien-
t so as to better handle cold-start situations with
little training data. In contrast with these work-
s, we have proposed a language model smoothing
framework which incorporates social factors as a
regularizer. According to the experimental result-
s, our method is effective with social information
and as well much more efficient.
</bodyText>
<sectionHeader confidence="0.695267" genericHeader="method">
3 Smoothing with Social Regularization
</sectionHeader>
<bodyText confidence="0.999996095238095">
To motivate the model, we briefly discuss the in-
tuitions of proposed language model smoothing.
Generally, given a non-smoothed document lan-
guage model P(wld), which indicates a word dis-
tribution for a term w in document d, we attempt
to generate a smoothed language model P(wId+)
that could better estimate the text contents of a
document d as d+ to avoid zero probabilities for
those words not seen in d. Arbitrary assignmen-
t of pseudo word counts such as add-A to every
unseen words once was a major improvement for
language model smoothing (Chen and Goodman,
1996). However, the purpose of smoothing is to
estimate language model more accurately. One of
the most useful resources to smooth is the docu-
ments similar to d: documents with the larger tex-
tual similarity indicate the smaller distance and the
better smoothing effects.
Moreover, the author information of the posting
documents is easily accessible on social networks.
We hence have information related to social fac-
</bodyText>
<page confidence="0.994862">
624
</page>
<bodyText confidence="0.999790653846154">
tors, which could be used to better estimate the
document language model. Through our obser-
vation, people are more likely to inherit language
habits and usages from their contacts on the social
networks. This social factor is important and u-
nique for language model smoothing on social net-
works. It should be not surprising that smoothing
with social factors will be a better optimum. Pre-
viously, the pure similarity based smoothing with-
out social factors indicates equal distance for every
document from any user on the networks, which is
not a fair assumption and presumably leads to a
weaker performance.
Yet, with the objective of textual similarity
based smoothing with social factors, the smoothed
language model might possibly deviate from the
original posting documents of a specific user dra-
matically. It is intuitive that we ought to keep
the original representation of document language
models of the particular user, and in the mean-
while the postings could be distinguished from one
another. Therefore, the combination of the orig-
inal language model with the social factor as a
regularizer ensures the optimum smoothing effects
with proper optimization to balance both the tex-
tual and social components.
</bodyText>
<subsectionHeader confidence="0.999095">
3.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.993676222222222">
Now we give a formal definition as follows:
Input. Given the entire document set D, and the
social network of users U, we aim to smooth the
language model of the target document, denoted
as P(w|d0), based on the influence from all other
documents d where {d|d E D}, and d is authored
by ud E U.
Output. The smoothed language model of
P(w|do ) for the original document d0.
</bodyText>
<subsectionHeader confidence="0.998087">
3.2 Methodology Framework
</subsectionHeader>
<bodyText confidence="0.9999661">
We frame social language smoothing as the inter-
polation of document representation from the o-
riginal user and the social factor regularization.
Regularization has been cast as an optimization
problem in machine learning literature (Zhou and
Sch¨olkopf, 2005), and we could form the language
model smoothing under this optimization frame-
work. Formally, we propose the smoothing frame-
work for language models with the regularized so-
cial factor as follows:
</bodyText>
<equation confidence="0.9800375">
O(d0) = λ ∑ ϕdi|P(w|d�0 ) − P(w|dz)|2+
udi=u0
(1 − λ) ∑ ∑πu ϕd;|P(w|d�0 ) − P(w|dj)|2
u∈U\u0 ude ̸=u0
</equation>
<bodyText confidence="0.991772363636364">
where u0 = ud0, which means the author of d0 to
smooth. Function πu indicates the social relation-
ship between user u and u0. Function ϕd mea-
sures the textual similarity between document d
and the document d0 to smooth. The smoothed
document language model is denoted as P(w|do ),
and the unsmoothed document language model for
d is written as P(w|d).
The objective function of O(.) implement two
intuitions: 1) the first component guarantees the
smoothed language model would not deviate too
much from the language habits of the user of u0,
controlled by the similarity between all the doc-
uments from the author of d0; 2) the second ter-
m, namely a harmonic function in semi-supervised
learning, incorporating the influence from contacts
on the social networks. The framework is general
since the functions could be initiated in different
instances. Different initiations of functions indi-
cate different features or factors to be taken into
account. In this paper, we formulate the textu-
al similarity of ϕd, and the social relationship πu
based on the social network dimension. Eventu-
ally, we can find the flexibility to extend features
and factors in future work.
Firstly, we will define the correlation ϕd be-
tween document pairs. It is intuitive to measure
the relationship among documents based on the
textual similarity. In this paper, we utilize the
standard cosine metric to measure the similarity
between posting document in vector space model
representations (Salton et al., 1975). Vector com-
ponents are set to their tf.idf values (Manning et
al., 2008). tf is the term frequency and idf is the
inverse document frequency. Next we continue to
define the social factor among users.
For πu, the most intuitive way is to calculate
the contacts similarity of the social network user-
s, i.e., friends or followees in common. We first
apply the Jaccard distance (Jaccard, 1912; Pang-
Ning et al., 2006) on the social contact sets for the
two network users (i.e., between u0 and another
particular user u) as follows:
|{nb(u0)} U {nb(u)}|
</bodyText>
<equation confidence="0.874948">
πu =
|{nb(u0)} n {nb(u)}|
</equation>
<page confidence="0.9903">
625
</page>
<table confidence="0.9682235">
#User #Docs #Link
language model smoothed with both text informa-
tion and social factors.
9,449,542 364,287,744 596,777,491
4.2 Algorithms for Comparison
Clusters #Docs Notes
</table>
<listItem confidence="0.72035">
1. apple 42,528 Tech: apple products
2. nfl 40,340 Sport: American football
3. travel 38,345 General interst
</listItem>
<tableCaption confidence="0.994517">
Table 1: Statistics of dataset and topic clusters.
</tableCaption>
<bodyText confidence="0.999868538461538">
where {nb(u)} indicates the set of all neighbor
contacts of node u, each of which shares an edge
to u.
Now we have finished modeling the language
model smoothing with social factors as regular-
ization, and have defined the context correlation
between documents and user social relationship-
s. By plugging in Equation (2) into Equation (1),
we could compute the smoothed language model
of P(w|d�0 ). All the definitions for 7r(.) result in
a range which varies from 0 to 1. Particularly, the
ego user similarity 7ruo = 1, which would be a nat-
ural and intuitive answer.
</bodyText>
<sectionHeader confidence="0.999119" genericHeader="evaluation">
4 Experiments and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.99423">
4.1 Datasets and Experimental Setups
</subsectionHeader>
<bodyText confidence="0.999882037037037">
Utilizing the data in (Yan et al., 2012), we estab-
lish the dataset of microblogs and the correspond-
ing users from 9/29/2012 to 11/30/2012. We use
roughly one month as the training set and the rest
as testing set. Based on this dataset, we group the
posting documents with the same hashtag ‘#’ in-
to clusters as different datasets to evaluate (Lin et
al., 2011; Yan et al., 2015; Yan et al., 2011). We
manually selected top-3 topics based on populari-
ty (measured in the number of postings within the
cluster) and to obtain broad coverage of different
types: sports, technology, and general interests, as
listed in Table 1.
Pre-processing. Basically, the social network
graph can be established from all posting docu-
ments and all users. However, the data is noisy.
We first pre-filter the pointless babbles (Analytics,
2009) by applying the linguistic quality judgments
(e.g., OOV ratio) (Pitler et al., 2010), and then re-
move inactive users that have less than one follow-
er or followee and remove the users without any
linkage to the remaining posting documents. We
remove stopwords and URLs, perform stemming,
and build the graph after filtering. We establish the
The first baseline is based on the traditional lan-
guage model: LM is the language model without
smoothing at all. We include the plain smooth-
ing of Additive (also known as Add-S) smoothing
and Absolute Discounting decrease the probabil-
ity of seen words by subtracting a constant (Ney
et al., 1995). We also implement several classic
strategies smoothed from the whole collection as
background information: Jelinek-Mercer (J-M)
applies a linear interpolation, and Dirichlet em-
ploys a prior on collection influence (Zhai and Laf-
ferty, 2001; Lafferty and Zhai, 2001).
Beyond these simple heuristics, we also exam-
ine a series of semantic based language model s-
moothing. The most representative two semantic
smoothing methods are the Cluster-Based Docu-
ment Model (CBDM) proposed in (Liu and Croft,
2004), and the Document Expansion Language
Model (DELM) in (Tao et al., 2006). Both meth-
ods use semantically similar documents as a s-
moothing corpus for a particular document. We
also include Positional Language Model (PLM)
proposed in (Lv and Zhai, 2009), which is the
state-of-art positional proximity based language s-
moothing. PLM mainly utilizes positional infor-
mation without semantic information. We im-
plemented the best reported PLM configuration.
We also include the Factor Graph Model (FGM)
method to make a full comparison with our pro-
posed social regularized smoothing (SRS).
</bodyText>
<subsectionHeader confidence="0.997431">
4.3 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999654833333333">
We apply language perplexity to evaluate the s-
moothed language models. The experimental pro-
cedure is as follows: given the topic clusters
shown in Table 1, we remove the hashtags and
compute its perplexity with respect to the current
topic cluster, defined as a power function:
</bodyText>
<equation confidence="0.99469925">
[ ∑
1
pow 2, −
N wi∈V
</equation>
<bodyText confidence="0.8105574">
Perplexity is actually an entropy based evaluation.
In this sense, the lower perplexity within the same
topic cluster, the better performance in purity the
topic cluster would have.
]log P(wz)
</bodyText>
<page confidence="0.99537">
626
</page>
<table confidence="0.999867">
Topic #apple #nfl #travel
LM 15851 11356 10676
Additive 15195 10035 10342
Absolute 15323 10123 10379
J-M 14115 10011 10185
Dirichlet 13892 9516 10138
PLM 13730 9925 10426
CBDM 12931 9845 9311
DELM 11853 9820 9513
FGM 10788 9539 8408
SRS 11808 9888 9403
</table>
<tableCaption confidence="0.999624">
Table 2: Perplexity in hashtag clusters.
</tableCaption>
<sectionHeader confidence="0.991058" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999899833333333">
impact on language model smoothing.
We make a further comparison between FGM
and SRS: both are using social information. An
interesting phenomenon is that FGM slightly out-
performs SRS. The proposed SRS has more effi-
ciency than FGM. It is quite intuitive that FGM
is a complicated model based on propagation via
linkage while our proposed SRS is a lightweight
model using linear combination. Hence SRS is
proved to be both effective due to the comparable
performance with FGM, and more efficient as the
result of simple interpolation.
</bodyText>
<subsectionHeader confidence="0.998652">
4.4 Overall Performance
</subsectionHeader>
<bodyText confidence="0.999987428571429">
We compare the performance of all methods of
language model smoothing on the Twitter dataset-
s. In Table 2 we list the overall results against all
baseline methods. We have an average of -7.28%
improvement in terms of language perplexity in
hashtag topic clusters against all baselines without
social information.
The language model without any smoothing s-
trategy performs worst as expected, and once a-
gain demonstrates the Achilles Heel of data spar-
sity on social networks! Simple intuition based
methods such as additive smoothing does not help
a lot, since it only arbitrarily modifies the given
term counts straightforward to avoid zero occur-
rence, which is proved to be insufficient. Absolute
smoothing performs slightly better, due to the idea
to incorporate the collection information by term
counts. Jelinek-Mercer (J-M) and Dirichlet meth-
ods are more useful since they include the infor-
mation from the whole collection as background
language models, but they fail to distinguish docu-
ments from documents and use all of them equally
into smoothing. PLM offers a strengthened lan-
guage model smoothing strategy within each post-
ing document based on positions, and smooth the
terms outside of the posting document formulating
the background collection into a Dirichlet prior.
The performance of CBDM and DELM indicates
a prominent improvement, and proves that seman-
tic attributes included into the smoothing process
really make a difference. Both of the smoothing
methods cluster documents, and use the clustered
documents as a better background. However, none
of these methods has made use of the social factors
during the language model smoothing, while both
FGM and SRS suggests social factors do have an
We present a language model smoothing method
based on text correlation with social factors as reg-
ularization to solve the zero count phenomenon
(sparsity!) for short postings on social networks.
We smooth the extremely sparse language model
based on texts and social connections in optimiza-
tion. We evaluate the performance of our proposed
smoothing method. In general, the social factor
is proved to have a meaningful contribution. Our
model outperforms all baseline smoothing meth-
ods without social information while takes less
time to run: the lightweight method balances ef-
fectiveness and efficiency best.
</bodyText>
<sectionHeader confidence="0.985046" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99972575">
This work was partially done when the first author
was at University of Pennsylvania. We thank al-
l the anonymous reviewers for their valuable and
constructive comments in ACL short paper track&apos;.
</bodyText>
<sectionHeader confidence="0.902924" genericHeader="references">
References
</sectionHeader>
<subsectionHeader confidence="0.569268">
Pear Analytics. 2009. Twitter study–august 2009. 15.
</subsectionHeader>
<bodyText confidence="0.960280375">
Stanley F. Chen and Joshua Goodman. 1996. An em-
pirical study of smoothing techniques for language
modeling. In Proceedings of the 34th Annual Meet-
ing on Association for Computational Linguistics,
ACL ’96, pages 310–318, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Huizhong Duan and Chengxiang Zhai. 2011. Exploit-
ing thread structures to improve smoothing of lan-
guage models for forum post retrieval. In Advances
in Information Retrieval, pages 350–361. Springer.
&apos;This paper was at first submitted to the ACL long pa-
per track. One reviewer insisted his/her (perhaps disputable)
opinions and the other two reviewers were outvoted. If in-
terested, we would welcome this reviewer to write emails to
us and to discuss his/her very quick review offered initially
before the author response period.
</bodyText>
<page confidence="0.996481">
627
</page>
<reference confidence="0.9980888">
Yu-Yang Huang, Rui Yan, Tsung-Ting Kuo, and Shou-
De Lin. 2014. Enriching cold start personalized
language model using social network information.
In Proceedings of the 52nd Annual Meeting on As-
sociation for Computational Linguistics, ACL ’14,
pages 611–617.
Paul Jaccard. 1912. The distribution of the flora in the
alpine zone. New phytologist, 11(2):37–50.
Haewoon Kwak, Changhyun Lee, Hosung Park, and
Sue Moon. 2010. What is twitter, a social network
or a news media? In Proceedings of the 19th In-
ternational Conference on World Wide Web, WWW
’10, pages 591–600, New York, NY, USA. ACM.
John Lafferty and Chengxiang Zhai. 2001. Document
language models, query models, and risk minimiza-
tion for information retrieval. In Proceedings of the
24th Annual International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, SIGIR ’01, pages 111–119, New York, NY,
USA. ACM.
Victor Lavrenko and W. Bruce Croft. 2001. Rele-
vance based language models. In Proceedings of the
24th Annual International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, SIGIR ’01, pages 120–127, New York, NY,
USA. ACM.
Jimmy Lin, Rion Snow, and William Morgan. 2011.
Smoothing techniques for adaptive online language
models: Topic tracking in tweet streams. In Pro-
ceedings of the 17th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, KDD ’11, pages 422–429, New York, NY, USA.
ACM.
Xiaoyong Liu and W. Bruce Croft. 2004. Cluster-
based retrieval using language models. In Proceed-
ings of the 27th Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ’04, pages 186–193, New
York, NY, USA. ACM.
Yuanhua Lv and ChengXiang Zhai. 2009. Position-
al language models for information retrieval. In
Proceedings of the 32Nd International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ’09, pages 299–306, New
York, NY, USA. ACM.
Christopher D Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to information
retrieval, volume 1.
Qiaozhu Mei, Duo Zhang, and ChengXiang Zhai.
2008. A general optimization framework for s-
moothing language models on graph structures. In
Proceedings of the 31st Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, SIGIR ’08, pages 611–618,
New York, NY, USA. ACM.
Hermann Ney, Ute Essen, and Reinhard Kneser. 1995.
On the estimation ofsmall’probabilities by leaving-
one-out. Pattern Analysis and Machine Intelligence,
IEEE Transactions on, 17(12):1202–1212.
Tan Pang-Ning, Michael Steinbach, Vipin Kumar, et al.
2006. Introduction to data mining. In Library of
Congress, page 74.
Emily Pitler, Annie Louis, and Ani Nenkova. 2010.
Automatic evaluation of linguistic quality in multi-
document summarization. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, ACL ’10, pages 544–554,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Pro-
ceedings of the 21st Annual International ACM SI-
GIR Conference on Research and Development in
Information Retrieval, SIGIR ’98, pages 275–281,
New York, NY, USA. ACM.
G. Salton, A. Wong, and C. S. Yang. 1975. A vector s-
pace model for automatic indexing. Commun. ACM,
18(11):613–620, November.
Fei Song and W. Bruce Croft. 1999. A general lan-
guage model for information retrieval. In Proceed-
ings of the Eighth International Conference on In-
formation and Knowledge Management, CIKM ’99,
pages 316–321, New York, NY, USA. ACM.
Tao Tao, Xuanhui Wang, Qiaozhu Mei, and ChengX-
iang Zhai. 2006. Language model information re-
trieval with document expansion. In Proceedings of
the Main Conference on Human Language Technol-
ogy Conference of the North American Chapter of
the Association of Computational Linguistics, HLT-
NAACL ’06, pages 407–414, Stroudsburg, PA, US-
A. Association for Computational Linguistics.
Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,
Xiaoming Li, and Yan Zhang. 2011. Evolution-
ary timeline summarization: A balanced optimiza-
tion framework via iterative substitution. In Pro-
ceedings of the 34th International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, SIGIR ’11, pages 745–754, New Y-
ork, NY, USA. ACM.
Rui Yan, Mirella Lapata, and Xiaoming Li. 2012.
Tweet recommendation with graph co-ranking. In
Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics: Long Papers
- Volume 1, ACL ’12, pages 516–525, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Rui Yan, Han Jiang, Mirella Lapata, Shou-De Lin, X-
ueqiang Lv, and Xiaoming Li. 2013. Semantic
v.s. positions: Utilizing balanced proximity in lan-
guage model smoothing for information retrieval. In
</reference>
<page confidence="0.981222">
628
</page>
<reference confidence="0.998572592592593">
Proceedings of the 6th International Joint Confer-
ence on Natural Language Processing, IJCNLP’13,
pages 507–515.
Rui Yan, Ian E.H. Yen, Cheng-Te Li, Shiqi Zhao, and
Xiaohua Hu. 2015. Tackling the achilles heel of
social networks: Influence propagation based lan-
guage model smoothing. In Proceedings of the
24th International Conference on World Wide Web,
WWW ’15, pages 1318–1328, Republic and Canton
of Geneva, Switzerland. International World Wide
Web Conferences Steering Committee.
Chengxiang Zhai and John Lafferty. 2001. A study of
smoothing methods for language models applied to
ad hoc information retrieval. In Proceedings of the
24th Annual International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, SIGIR ’01, pages 334–342, New York, NY,
USA. ACM.
Jinglei Zhao and Yeogirl Yun. 2009. A proximity lan-
guage model for information retrieval. In Proceed-
ings of the 32Nd International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval, SIGIR ’09, pages 291–298, New York,
NY, USA. ACM.
Dengyong Zhou and Bernhard Sch¨olkopf. 2005. Reg-
ularization on discrete spaces. In Pattern Recogni-
tion, pages 361–368. Springer.
</reference>
<page confidence="0.998884">
629
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.553653">
<title confidence="0.997735">Tackling Sparsity, the Achilles Heel of Social Language Model Smoothing via Social Regularization</title>
<author confidence="0.855715">Xiang Mengwen</author>
<author confidence="0.855715">Xiaohua</author>
<affiliation confidence="0.852460333333333">Research, Baidu Inc., Beijing, of Computer Science &amp; Technology, Peking University, Beijing, of Information Science &amp; Technology, Drexel University, Philadelphia,</affiliation>
<abstract confidence="0.9962383">Online social networks nowadays have the worldwide prosperity, as they have revolutionized the way for people to discover, to share, and to diffuse information. Social networks are powerful, yet they still have Achilles Heel: extreme data sparsity. Individual posting documents, (e.g., a microblog less than 140 characters), seem to be too sparse to make a difference under various scenarios, while in fact they are quite different. We propose to tackle this specific weakness of social networks by smoothing the posting document language model based on social regularization. We formulate an optimization framework with a social regularizer. Experimenresults on the validate the effectiveness and efficiency of our proposed model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yu-Yang Huang</author>
<author>Rui Yan</author>
<author>Tsung-Ting Kuo</author>
<author>ShouDe Lin</author>
</authors>
<title>Enriching cold start personalized language model using social network information.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL ’14,</booktitle>
<pages>611--617</pages>
<contexts>
<context position="6954" citStr="Huang et al., 2014" startWordPosition="1074" endWordPosition="1077">language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) which smooths document language models of tweets for topic tracking in online text streams. Basically, it applies general smoothing strategies (e.g., JelinekMercer, Dirichlet, Absolute Discounting, etc.) on the specific tracking task. Social information is incorporated into a factor graph model as features (Huang et al., 2014; Yan et al., 2015). These factor graph model based methods are less efficient so as to better handle cold-start situations with little training data. In contrast with these works, we have proposed a language model smoothing framework which incorporates social factors as a regularizer. According to the experimental results, our method is effective with social information and as well much more efficient. 3 Smoothing with Social Regularization To motivate the model, we briefly discuss the intuitions of proposed language model smoothing. Generally, given a non-smoothed document language model P(w</context>
</contexts>
<marker>Huang, Yan, Kuo, Lin, 2014</marker>
<rawString>Yu-Yang Huang, Rui Yan, Tsung-Ting Kuo, and ShouDe Lin. 2014. Enriching cold start personalized language model using social network information. In Proceedings of the 52nd Annual Meeting on Association for Computational Linguistics, ACL ’14, pages 611–617.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Jaccard</author>
</authors>
<title>The distribution of the flora in the alpine zone. New phytologist,</title>
<date>1912</date>
<pages>11--2</pages>
<contexts>
<context position="12454" citStr="Jaccard, 1912" startWordPosition="1981" endWordPosition="1982">elationship among documents based on the textual similarity. In this paper, we utilize the standard cosine metric to measure the similarity between posting document in vector space model representations (Salton et al., 1975). Vector components are set to their tf.idf values (Manning et al., 2008). tf is the term frequency and idf is the inverse document frequency. Next we continue to define the social factor among users. For πu, the most intuitive way is to calculate the contacts similarity of the social network users, i.e., friends or followees in common. We first apply the Jaccard distance (Jaccard, 1912; PangNing et al., 2006) on the social contact sets for the two network users (i.e., between u0 and another particular user u) as follows: |{nb(u0)} U {nb(u)}| πu = |{nb(u0)} n {nb(u)}| 625 #User #Docs #Link language model smoothed with both text information and social factors. 9,449,542 364,287,744 596,777,491 4.2 Algorithms for Comparison Clusters #Docs Notes 1. apple 42,528 Tech: apple products 2. nfl 40,340 Sport: American football 3. travel 38,345 General interst Table 1: Statistics of dataset and topic clusters. where {nb(u)} indicates the set of all neighbor contacts of node u, each of </context>
</contexts>
<marker>Jaccard, 1912</marker>
<rawString>Paul Jaccard. 1912. The distribution of the flora in the alpine zone. New phytologist, 11(2):37–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haewoon Kwak</author>
<author>Changhyun Lee</author>
<author>Hosung Park</author>
<author>Sue Moon</author>
</authors>
<title>What is twitter, a social network or a news media?</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web, WWW ’10,</booktitle>
<pages>591--600</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1374" citStr="Kwak et al., 2010" startWordPosition="199" endWordPosition="202"> to be too sparse to make a difference under various scenarios, while in fact they are quite different. We propose to tackle this specific weakness of social networks by smoothing the posting document language model based on social regularization. We formulate an optimization framework with a social regularizer. Experimental results on the Twitter dataset validate the effectiveness and efficiency of our proposed model. 1 Introduction Along with Web 2.0 online social networks have revolutionized the way for people to discover, to share and to propagate information via peer-topeer interactions (Kwak et al., 2010). Although powerful as social networks are, they still suffer from a severe weakness: extreme sparsity. Due to the special characteristics of real-time propagation, the postings on social networks are either officially limited within a limit length (140 characters on Twitter), or generally quite short due to user preference. Given limited text data sampling, a language model estimation usually encounters with zero count problem when facing with data sparsity, which is not reliable. Therefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck</context>
</contexts>
<marker>Kwak, Lee, Park, Moon, 2010</marker>
<rawString>Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is twitter, a social network or a news media? In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 591–600, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Document language models, query models, and risk minimization for information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01,</booktitle>
<pages>111--119</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2404" citStr="Lafferty and Zhai, 2001" startWordPosition="360" endWordPosition="364"> with zero count problem when facing with data sparsity, which is not reliable. Therefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illustrated in Figure 1). We propose that social factors should be utilized as an augmentation to better smooth language models. Here we propose an optimization framework with regularization for language model smoothing on social networks, using both textual information and the social structure. We believe the social factor is fundamental to smooth language models on social networks. Our framework optimizes the sm</context>
<context position="4630" citStr="Lafferty and Zhai, 2001" startWordPosition="709" endWordPosition="712">we show that the Achilles Heel of social networks could be to some extent tackled. The rest of the paper is organized as follows. We start by reviewing previous works. Then we introduce the language model smoothing with social regularization and its optimization. We describe the experiments and evaluation in the next section and finally draw the conclusions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the max</context>
<context position="15336" citStr="Lafferty and Zhai, 2001" startWordPosition="2453" endWordPosition="2456">mming, and build the graph after filtering. We establish the The first baseline is based on the traditional language model: LM is the language model without smoothing at all. We include the plain smoothing of Additive (also known as Add-S) smoothing and Absolute Discounting decrease the probability of seen words by subtracting a constant (Ney et al., 1995). We also implement several classic strategies smoothed from the whole collection as background information: Jelinek-Mercer (J-M) applies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantically similar documents as a smoothing corpus for a particular document. We also include Positional Language Model (PLM) proposed in (Lv and Zhai, 2009), which is the state-of-art positional proximity based language smoothing. PLM mainly utilizes positional informati</context>
</contexts>
<marker>Lafferty, Zhai, 2001</marker>
<rawString>John Lafferty and Chengxiang Zhai. 2001. Document language models, query models, and risk minimization for information retrieval. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01, pages 111–119, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>W Bruce Croft</author>
</authors>
<title>Relevance based language models.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01,</booktitle>
<pages>120--127</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2487" citStr="Lavrenko and Croft, 2001" startWordPosition="377" endWordPosition="380">erefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illustrated in Figure 1). We propose that social factors should be utilized as an augmentation to better smooth language models. Here we propose an optimization framework with regularization for language model smoothing on social networks, using both textual information and the social structure. We believe the social factor is fundamental to smooth language models on social networks. Our framework optimizes the smoothed language model to be closer to social neighbors in the online network, while</context>
<context position="4657" citStr="Lavrenko and Croft, 2001" startWordPosition="713" endWordPosition="716"> Heel of social networks could be to some extent tackled. The rest of the paper is organized as follows. We start by reviewing previous works. Then we introduce the language model smoothing with social regularization and its optimization. We describe the experiments and evaluation in the next section and finally draw the conclusions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the maximum likelihood estimator w</context>
</contexts>
<marker>Lavrenko, Croft, 2001</marker>
<rawString>Victor Lavrenko and W. Bruce Croft. 2001. Relevance based language models. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01, pages 120–127, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jimmy Lin</author>
<author>Rion Snow</author>
<author>William Morgan</author>
</authors>
<title>Smoothing techniques for adaptive online language models: Topic tracking in tweet streams.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’11,</booktitle>
<pages>422--429</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6626" citStr="Lin et al., 2011" startWordPosition="1026" endWordPosition="1029"> Tao et al., 2006). Position information has also been used to enrich language model smoothing (Zhao and Yun, 2009; Lv and Zhai, 2009) and has been used in the combination of both enrichment of position and semantic (Yan et al., 2013). Beyond the semantic and/or position related smoothing intuitions, document structure based language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) which smooths document language models of tweets for topic tracking in online text streams. Basically, it applies general smoothing strategies (e.g., JelinekMercer, Dirichlet, Absolute Discounting, etc.) on the specific tracking task. Social information is incorporated into a factor graph model as features (Huang et al., 2014; Yan et al., 2015). These factor graph model based methods are less efficient so as to better handle cold-start situations with little training data. In contrast with these works, we have proposed a language model smoothing framework which incorporates social factors as </context>
<context position="13968" citStr="Lin et al., 2011" startWordPosition="2234" endWordPosition="2237">ge model of P(w|d�0 ). All the definitions for 7r(.) result in a range which varies from 0 to 1. Particularly, the ego user similarity 7ruo = 1, which would be a natural and intuitive answer. 4 Experiments and Evaluation 4.1 Datasets and Experimental Setups Utilizing the data in (Yan et al., 2012), we establish the dataset of microblogs and the corresponding users from 9/29/2012 to 11/30/2012. We use roughly one month as the training set and the rest as testing set. Based on this dataset, we group the posting documents with the same hashtag ‘#’ into clusters as different datasets to evaluate (Lin et al., 2011; Yan et al., 2015; Yan et al., 2011). We manually selected top-3 topics based on popularity (measured in the number of postings within the cluster) and to obtain broad coverage of different types: sports, technology, and general interests, as listed in Table 1. Pre-processing. Basically, the social network graph can be established from all posting documents and all users. However, the data is noisy. We first pre-filter the pointless babbles (Analytics, 2009) by applying the linguistic quality judgments (e.g., OOV ratio) (Pitler et al., 2010), and then remove inactive users that have less than</context>
</contexts>
<marker>Lin, Snow, Morgan, 2011</marker>
<rawString>Jimmy Lin, Rion Snow, and William Morgan. 2011. Smoothing techniques for adaptive online language models: Topic tracking in tweet streams. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’11, pages 422–429, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Liu</author>
<author>W Bruce Croft</author>
</authors>
<title>Clusterbased retrieval using language models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’04,</booktitle>
<pages>186--193</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2443" citStr="Liu and Croft, 2004" startWordPosition="369" endWordPosition="372">ata sparsity, which is not reliable. Therefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illustrated in Figure 1). We propose that social factors should be utilized as an augmentation to better smooth language models. Here we propose an optimization framework with regularization for language model smoothing on social networks, using both textual information and the social structure. We believe the social factor is fundamental to smooth language models on social networks. Our framework optimizes the smoothed language model to be closer to s</context>
<context position="4735" citStr="Liu and Croft, 2004" startWordPosition="726" endWordPosition="729">rganized as follows. We start by reviewing previous works. Then we introduce the language model smoothing with social regularization and its optimization. We describe the experiments and evaluation in the next section and finally draw the conclusions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the maximum likelihood estimator would assign unseen terms a zero probability, which is not reliable. Language m</context>
<context position="6008" citStr="Liu and Croft, 2004" startWordPosition="927" endWordPosition="930">nd has been demonstrated to be of great significance (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). There are many ways to enrich the original language model. The information of background corpus has been incorporated using linear combination (Ponte and Croft, 1998; Zhai and Lafferty, 2001). In contrast to the simple strategy which smooths all documents with the same background, recently corpus structures have been exploited for more accurate smoothing. The basic idea is to smooth a document language model with the documents similar to the document under consideration through clustering (Liu and Croft, 2004; Tao et al., 2006). Position information has also been used to enrich language model smoothing (Zhao and Yun, 2009; Lv and Zhai, 2009) and has been used in the combination of both enrichment of position and semantic (Yan et al., 2013). Beyond the semantic and/or position related smoothing intuitions, document structure based language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in </context>
<context position="15571" citStr="Liu and Croft, 2004" startWordPosition="2490" endWordPosition="2493"> smoothing and Absolute Discounting decrease the probability of seen words by subtracting a constant (Ney et al., 1995). We also implement several classic strategies smoothed from the whole collection as background information: Jelinek-Mercer (J-M) applies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantically similar documents as a smoothing corpus for a particular document. We also include Positional Language Model (PLM) proposed in (Lv and Zhai, 2009), which is the state-of-art positional proximity based language smoothing. PLM mainly utilizes positional information without semantic information. We implemented the best reported PLM configuration. We also include the Factor Graph Model (FGM) method to make a full comparison with our proposed social regularized smoothing (SRS). 4.3 Evaluation Met</context>
</contexts>
<marker>Liu, Croft, 2004</marker>
<rawString>Xiaoyong Liu and W. Bruce Croft. 2004. Clusterbased retrieval using language models. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’04, pages 186–193, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanhua Lv</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Positional language models for information retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09,</booktitle>
<pages>299--306</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6143" citStr="Lv and Zhai, 2009" startWordPosition="950" endWordPosition="953">he original language model. The information of background corpus has been incorporated using linear combination (Ponte and Croft, 1998; Zhai and Lafferty, 2001). In contrast to the simple strategy which smooths all documents with the same background, recently corpus structures have been exploited for more accurate smoothing. The basic idea is to smooth a document language model with the documents similar to the document under consideration through clustering (Liu and Croft, 2004; Tao et al., 2006). Position information has also been used to enrich language model smoothing (Zhao and Yun, 2009; Lv and Zhai, 2009) and has been used in the combination of both enrichment of position and semantic (Yan et al., 2013). Beyond the semantic and/or position related smoothing intuitions, document structure based language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) which smooths document language models of tweets for topic tracking in online text streams. Basically, it applies ge</context>
<context position="15821" citStr="Lv and Zhai, 2009" startWordPosition="2531" endWordPosition="2534">lies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantically similar documents as a smoothing corpus for a particular document. We also include Positional Language Model (PLM) proposed in (Lv and Zhai, 2009), which is the state-of-art positional proximity based language smoothing. PLM mainly utilizes positional information without semantic information. We implemented the best reported PLM configuration. We also include the Factor Graph Model (FGM) method to make a full comparison with our proposed social regularized smoothing (SRS). 4.3 Evaluation Metric We apply language perplexity to evaluate the smoothed language models. The experimental procedure is as follows: given the topic clusters shown in Table 1, we remove the hashtags and compute its perplexity with respect to the current topic cluste</context>
</contexts>
<marker>Lv, Zhai, 2009</marker>
<rawString>Yuanhua Lv and ChengXiang Zhai. 2009. Positional language models for information retrieval. In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09, pages 299–306, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to information retrieval,</title>
<date>2008</date>
<volume>1</volume>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to information retrieval, volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Duo Zhang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A general optimization framework for smoothing language models on graph structures.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’08,</booktitle>
<pages>611--618</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Mei, Zhang, Zhai, 2008</marker>
<rawString>Qiaozhu Mei, Duo Zhang, and ChengXiang Zhai. 2008. A general optimization framework for smoothing language models on graph structures. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’08, pages 611–618, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Ney</author>
<author>Ute Essen</author>
<author>Reinhard Kneser</author>
</authors>
<title>On the estimation ofsmall’probabilities by leavingone-out. Pattern Analysis and Machine Intelligence,</title>
<date>1995</date>
<journal>IEEE Transactions on,</journal>
<volume>17</volume>
<issue>12</issue>
<contexts>
<context position="15070" citStr="Ney et al., 1995" startWordPosition="2415" endWordPosition="2418">istic quality judgments (e.g., OOV ratio) (Pitler et al., 2010), and then remove inactive users that have less than one follower or followee and remove the users without any linkage to the remaining posting documents. We remove stopwords and URLs, perform stemming, and build the graph after filtering. We establish the The first baseline is based on the traditional language model: LM is the language model without smoothing at all. We include the plain smoothing of Additive (also known as Add-S) smoothing and Absolute Discounting decrease the probability of seen words by subtracting a constant (Ney et al., 1995). We also implement several classic strategies smoothed from the whole collection as background information: Jelinek-Mercer (J-M) applies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantic</context>
</contexts>
<marker>Ney, Essen, Kneser, 1995</marker>
<rawString>Hermann Ney, Ute Essen, and Reinhard Kneser. 1995. On the estimation ofsmall’probabilities by leavingone-out. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 17(12):1202–1212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tan Pang-Ning</author>
<author>Michael Steinbach</author>
<author>Vipin Kumar</author>
</authors>
<title>Introduction to data mining.</title>
<date>2006</date>
<booktitle>In Library of Congress,</booktitle>
<pages>74</pages>
<marker>Pang-Ning, Steinbach, Kumar, 2006</marker>
<rawString>Tan Pang-Ning, Michael Steinbach, Vipin Kumar, et al. 2006. Introduction to data mining. In Library of Congress, page 74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatic evaluation of linguistic quality in multidocument summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>544--554</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14516" citStr="Pitler et al., 2010" startWordPosition="2321" endWordPosition="2324">ag ‘#’ into clusters as different datasets to evaluate (Lin et al., 2011; Yan et al., 2015; Yan et al., 2011). We manually selected top-3 topics based on popularity (measured in the number of postings within the cluster) and to obtain broad coverage of different types: sports, technology, and general interests, as listed in Table 1. Pre-processing. Basically, the social network graph can be established from all posting documents and all users. However, the data is noisy. We first pre-filter the pointless babbles (Analytics, 2009) by applying the linguistic quality judgments (e.g., OOV ratio) (Pitler et al., 2010), and then remove inactive users that have less than one follower or followee and remove the users without any linkage to the remaining posting documents. We remove stopwords and URLs, perform stemming, and build the graph after filtering. We establish the The first baseline is based on the traditional language model: LM is the language model without smoothing at all. We include the plain smoothing of Additive (also known as Add-S) smoothing and Absolute Discounting decrease the probability of seen words by subtracting a constant (Ney et al., 1995). We also implement several classic strategies</context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2010</marker>
<rawString>Emily Pitler, Annie Louis, and Ani Nenkova. 2010. Automatic evaluation of linguistic quality in multidocument summarization. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 544–554, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’98,</booktitle>
<pages>275--281</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4475" citStr="Ponte and Croft, 1998" startWordPosition="685" endWordPosition="688">show that language model smoothing with social regularization is effective and efficient in terms of intrinsic evaluation by perplexity and running time: we show that the Achilles Heel of social networks could be to some extent tackled. The rest of the paper is organized as follows. We start by reviewing previous works. Then we introduce the language model smoothing with social regularization and its optimization. We describe the experiments and evaluation in the next section and finally draw the conclusions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). T</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’98, pages 275–281, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Commun. ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="12065" citStr="Salton et al., 1975" startWordPosition="1912" endWordPosition="1915">ons of functions indicate different features or factors to be taken into account. In this paper, we formulate the textual similarity of ϕd, and the social relationship πu based on the social network dimension. Eventually, we can find the flexibility to extend features and factors in future work. Firstly, we will define the correlation ϕd between document pairs. It is intuitive to measure the relationship among documents based on the textual similarity. In this paper, we utilize the standard cosine metric to measure the similarity between posting document in vector space model representations (Salton et al., 1975). Vector components are set to their tf.idf values (Manning et al., 2008). tf is the term frequency and idf is the inverse document frequency. Next we continue to define the social factor among users. For πu, the most intuitive way is to calculate the contacts similarity of the social network users, i.e., friends or followees in common. We first apply the Jaccard distance (Jaccard, 1912; PangNing et al., 2006) on the social contact sets for the two network users (i.e., between u0 and another particular user u) as follows: |{nb(u0)} U {nb(u)}| πu = |{nb(u0)} n {nb(u)}| 625 #User #Docs #Link lan</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>G. Salton, A. Wong, and C. S. Yang. 1975. A vector space model for automatic indexing. Commun. ACM, 18(11):613–620, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Song</author>
<author>W Bruce Croft</author>
</authors>
<title>A general language model for information retrieval.</title>
<date>1999</date>
<booktitle>In Proceedings of the Eighth International Conference on Information and Knowledge Management, CIKM ’99,</booktitle>
<pages>316--321</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2510" citStr="Song and Croft, 1999" startWordPosition="381" endWordPosition="384">ded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illustrated in Figure 1). We propose that social factors should be utilized as an augmentation to better smooth language models. Here we propose an optimization framework with regularization for language model smoothing on social networks, using both textual information and the social structure. We believe the social factor is fundamental to smooth language models on social networks. Our framework optimizes the smoothed language model to be closer to social neighbors in the online network, while avoid deviating too mu</context>
<context position="5072" citStr="Song and Croft, 1999" startWordPosition="778" endWordPosition="781"> (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the maximum likelihood estimator would assign unseen terms a zero probability, which is not reliable. Language model enrichment is proposed to address this problem, and has been demonstrated to be of great significance (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). There are many ways to enrich the original language model. The information of background corpus has been incorporated using linear combination (Ponte and Croft, 1998; Zhai and La</context>
</contexts>
<marker>Song, Croft, 1999</marker>
<rawString>Fei Song and W. Bruce Croft. 1999. A general language model for information retrieval. In Proceedings of the Eighth International Conference on Information and Knowledge Management, CIKM ’99, pages 316–321, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>Xuanhui Wang</author>
<author>Qiaozhu Mei</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Language model information retrieval with document expansion.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLTNAACL ’06,</booktitle>
<pages>407--414</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2461" citStr="Tao et al., 2006" startWordPosition="373" endWordPosition="376">s not reliable. Therefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illustrated in Figure 1). We propose that social factors should be utilized as an augmentation to better smooth language models. Here we propose an optimization framework with regularization for language model smoothing on social networks, using both textual information and the social structure. We believe the social factor is fundamental to smooth language models on social networks. Our framework optimizes the smoothed language model to be closer to social neighbors in</context>
<context position="4754" citStr="Tao et al., 2006" startWordPosition="730" endWordPosition="733">We start by reviewing previous works. Then we introduce the language model smoothing with social regularization and its optimization. We describe the experiments and evaluation in the next section and finally draw the conclusions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the maximum likelihood estimator would assign unseen terms a zero probability, which is not reliable. Language model enrichment is </context>
<context position="6027" citStr="Tao et al., 2006" startWordPosition="931" endWordPosition="934">ted to be of great significance (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). There are many ways to enrich the original language model. The information of background corpus has been incorporated using linear combination (Ponte and Croft, 1998; Zhai and Lafferty, 2001). In contrast to the simple strategy which smooths all documents with the same background, recently corpus structures have been exploited for more accurate smoothing. The basic idea is to smooth a document language model with the documents similar to the document under consideration through clustering (Liu and Croft, 2004; Tao et al., 2006). Position information has also been used to enrich language model smoothing (Zhao and Yun, 2009; Lv and Zhai, 2009) and has been used in the combination of both enrichment of position and semantic (Yan et al., 2013). Beyond the semantic and/or position related smoothing intuitions, document structure based language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) </context>
<context position="15643" citStr="Tao et al., 2006" startWordPosition="2502" endWordPosition="2505">by subtracting a constant (Ney et al., 1995). We also implement several classic strategies smoothed from the whole collection as background information: Jelinek-Mercer (J-M) applies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantically similar documents as a smoothing corpus for a particular document. We also include Positional Language Model (PLM) proposed in (Lv and Zhai, 2009), which is the state-of-art positional proximity based language smoothing. PLM mainly utilizes positional information without semantic information. We implemented the best reported PLM configuration. We also include the Factor Graph Model (FGM) method to make a full comparison with our proposed social regularized smoothing (SRS). 4.3 Evaluation Metric We apply language perplexity to evaluate the smoothed language model</context>
</contexts>
<marker>Tao, Wang, Mei, Zhai, 2006</marker>
<rawString>Tao Tao, Xuanhui Wang, Qiaozhu Mei, and ChengXiang Zhai. 2006. Language model information retrieval with document expansion. In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLTNAACL ’06, pages 407–414, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Xiaojun Wan</author>
<author>Jahna Otterbacher</author>
<author>Liang Kong</author>
<author>Xiaoming Li</author>
<author>Yan Zhang</author>
</authors>
<title>Evolutionary timeline summarization: A balanced optimization framework via iterative substitution.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’11,</booktitle>
<pages>745--754</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="14005" citStr="Yan et al., 2011" startWordPosition="2242" endWordPosition="2245">itions for 7r(.) result in a range which varies from 0 to 1. Particularly, the ego user similarity 7ruo = 1, which would be a natural and intuitive answer. 4 Experiments and Evaluation 4.1 Datasets and Experimental Setups Utilizing the data in (Yan et al., 2012), we establish the dataset of microblogs and the corresponding users from 9/29/2012 to 11/30/2012. We use roughly one month as the training set and the rest as testing set. Based on this dataset, we group the posting documents with the same hashtag ‘#’ into clusters as different datasets to evaluate (Lin et al., 2011; Yan et al., 2015; Yan et al., 2011). We manually selected top-3 topics based on popularity (measured in the number of postings within the cluster) and to obtain broad coverage of different types: sports, technology, and general interests, as listed in Table 1. Pre-processing. Basically, the social network graph can be established from all posting documents and all users. However, the data is noisy. We first pre-filter the pointless babbles (Analytics, 2009) by applying the linguistic quality judgments (e.g., OOV ratio) (Pitler et al., 2010), and then remove inactive users that have less than one follower or followee and remove </context>
</contexts>
<marker>Yan, Wan, Otterbacher, Kong, Li, Zhang, 2011</marker>
<rawString>Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong, Xiaoming Li, and Yan Zhang. 2011. Evolutionary timeline summarization: A balanced optimization framework via iterative substitution. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’11, pages 745–754, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Mirella Lapata</author>
<author>Xiaoming Li</author>
</authors>
<title>Tweet recommendation with graph co-ranking.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>516--525</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13650" citStr="Yan et al., 2012" startWordPosition="2177" endWordPosition="2180">s of node u, each of which shares an edge to u. Now we have finished modeling the language model smoothing with social factors as regularization, and have defined the context correlation between documents and user social relationships. By plugging in Equation (2) into Equation (1), we could compute the smoothed language model of P(w|d�0 ). All the definitions for 7r(.) result in a range which varies from 0 to 1. Particularly, the ego user similarity 7ruo = 1, which would be a natural and intuitive answer. 4 Experiments and Evaluation 4.1 Datasets and Experimental Setups Utilizing the data in (Yan et al., 2012), we establish the dataset of microblogs and the corresponding users from 9/29/2012 to 11/30/2012. We use roughly one month as the training set and the rest as testing set. Based on this dataset, we group the posting documents with the same hashtag ‘#’ into clusters as different datasets to evaluate (Lin et al., 2011; Yan et al., 2015; Yan et al., 2011). We manually selected top-3 topics based on popularity (measured in the number of postings within the cluster) and to obtain broad coverage of different types: sports, technology, and general interests, as listed in Table 1. Pre-processing. Bas</context>
</contexts>
<marker>Yan, Lapata, Li, 2012</marker>
<rawString>Rui Yan, Mirella Lapata, and Xiaoming Li. 2012. Tweet recommendation with graph co-ranking. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12, pages 516–525, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Han Jiang</author>
<author>Mirella Lapata</author>
<author>Xueqiang Lv Shou-De Lin</author>
<author>Xiaoming Li</author>
</authors>
<title>Semantic v.s. positions: Utilizing balanced proximity in language model smoothing for information retrieval.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Joint Conference on Natural Language Processing, IJCNLP’13,</booktitle>
<pages>507--515</pages>
<marker>Yan, Jiang, Lapata, Shou-De Lin, Li, 2013</marker>
<rawString>Rui Yan, Han Jiang, Mirella Lapata, Shou-De Lin, Xueqiang Lv, and Xiaoming Li. 2013. Semantic v.s. positions: Utilizing balanced proximity in language model smoothing for information retrieval. In Proceedings of the 6th International Joint Conference on Natural Language Processing, IJCNLP’13, pages 507–515.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Ian E H Yen</author>
<author>Cheng-Te Li</author>
<author>Shiqi Zhao</author>
<author>Xiaohua Hu</author>
</authors>
<title>Tackling the achilles heel of social networks: Influence propagation based language model smoothing.</title>
<date>2015</date>
<booktitle>In Proceedings of the 24th International Conference on World Wide Web, WWW ’15,</booktitle>
<pages>1318--1328</pages>
<institution>Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="1993" citStr="Yan et al., 2015" startWordPosition="297" endWordPosition="300">Although powerful as social networks are, they still suffer from a severe weakness: extreme sparsity. Due to the special characteristics of real-time propagation, the postings on social networks are either officially limited within a limit length (140 characters on Twitter), or generally quite short due to user preference. Given limited text data sampling, a language model estimation usually encounters with zero count problem when facing with data sparsity, which is not reliable. Therefore, sparsity is regarded as the Achilles Heel of social networks and now we aim at tackling the bottleneck (Yan et al., 2015). Statistical language models have attracted much attention in research communities. Till now much Figure 1: 2 different sources to smooth document language models: texts (colored in yellow) and social contacts (colored in blue). Each piece of texts is authored by a particular social network user. work on language model smoothing has been investigated based on textual characteristics (Lafferty and Zhai, 2001; Yan et al., 2013; Liu and Croft, 2004; Tao et al., 2006; Lavrenko and Croft, 2001; Song and Croft, 1999). However, for social networks, texts are actually associated with users (as illust</context>
<context position="6973" citStr="Yan et al., 2015" startWordPosition="1078" endWordPosition="1081">hing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) which smooths document language models of tweets for topic tracking in online text streams. Basically, it applies general smoothing strategies (e.g., JelinekMercer, Dirichlet, Absolute Discounting, etc.) on the specific tracking task. Social information is incorporated into a factor graph model as features (Huang et al., 2014; Yan et al., 2015). These factor graph model based methods are less efficient so as to better handle cold-start situations with little training data. In contrast with these works, we have proposed a language model smoothing framework which incorporates social factors as a regularizer. According to the experimental results, our method is effective with social information and as well much more efficient. 3 Smoothing with Social Regularization To motivate the model, we briefly discuss the intuitions of proposed language model smoothing. Generally, given a non-smoothed document language model P(wld), which indicate</context>
<context position="13986" citStr="Yan et al., 2015" startWordPosition="2238" endWordPosition="2241">0 ). All the definitions for 7r(.) result in a range which varies from 0 to 1. Particularly, the ego user similarity 7ruo = 1, which would be a natural and intuitive answer. 4 Experiments and Evaluation 4.1 Datasets and Experimental Setups Utilizing the data in (Yan et al., 2012), we establish the dataset of microblogs and the corresponding users from 9/29/2012 to 11/30/2012. We use roughly one month as the training set and the rest as testing set. Based on this dataset, we group the posting documents with the same hashtag ‘#’ into clusters as different datasets to evaluate (Lin et al., 2011; Yan et al., 2015; Yan et al., 2011). We manually selected top-3 topics based on popularity (measured in the number of postings within the cluster) and to obtain broad coverage of different types: sports, technology, and general interests, as listed in Table 1. Pre-processing. Basically, the social network graph can be established from all posting documents and all users. However, the data is noisy. We first pre-filter the pointless babbles (Analytics, 2009) by applying the linguistic quality judgments (e.g., OOV ratio) (Pitler et al., 2010), and then remove inactive users that have less than one follower or f</context>
</contexts>
<marker>Yan, Yen, Li, Zhao, Hu, 2015</marker>
<rawString>Rui Yan, Ian E.H. Yen, Cheng-Te Li, Shiqi Zhao, and Xiaohua Hu. 2015. Tackling the achilles heel of social networks: Influence propagation based language model smoothing. In Proceedings of the 24th International Conference on World Wide Web, WWW ’15, pages 1318–1328, Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to ad hoc information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01,</booktitle>
<pages>334--342</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4985" citStr="Zhai and Lafferty, 2001" startWordPosition="766" endWordPosition="769">sions. 2 Related Work Language models have been paid high attention to during recent years (Ponte and Croft, 1998). Many different ways of language modeling have been proposed to solve different tasks. Better estimation of query language models (Lafferty and Zhai, 2001; Lavrenko and Croft, 2001) and more accurate estimation of document language models (Liu and Croft, 2004; Tao et al., 2006) have long been proved to be of great significance in information retrieval and text mining, etc. Language models are typically implemented based on retrieval models, e.g., text weighting and normalization (Zhai and Lafferty, 2001), but with more elegant mathematical and statistical foundations (Song and Croft, 1999). There is one problem for language models. Given limited data sampling, a language model estimation sometimes encounters with the zero count problem: the maximum likelihood estimator would assign unseen terms a zero probability, which is not reliable. Language model enrichment is proposed to address this problem, and has been demonstrated to be of great significance (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). There are many ways to enrich the original language model. The information of background co</context>
<context position="15310" citStr="Zhai and Lafferty, 2001" startWordPosition="2448" endWordPosition="2452">rds and URLs, perform stemming, and build the graph after filtering. We establish the The first baseline is based on the traditional language model: LM is the language model without smoothing at all. We include the plain smoothing of Additive (also known as Add-S) smoothing and Absolute Discounting decrease the probability of seen words by subtracting a constant (Ney et al., 1995). We also implement several classic strategies smoothed from the whole collection as background information: Jelinek-Mercer (J-M) applies a linear interpolation, and Dirichlet employs a prior on collection influence (Zhai and Lafferty, 2001; Lafferty and Zhai, 2001). Beyond these simple heuristics, we also examine a series of semantic based language model smoothing. The most representative two semantic smoothing methods are the Cluster-Based Document Model (CBDM) proposed in (Liu and Croft, 2004), and the Document Expansion Language Model (DELM) in (Tao et al., 2006). Both methods use semantically similar documents as a smoothing corpus for a particular document. We also include Positional Language Model (PLM) proposed in (Lv and Zhai, 2009), which is the state-of-art positional proximity based language smoothing. PLM mainly uti</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Chengxiang Zhai and John Lafferty. 2001. A study of smoothing methods for language models applied to ad hoc information retrieval. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01, pages 334–342, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinglei Zhao</author>
<author>Yeogirl Yun</author>
</authors>
<title>A proximity language model for information retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09,</booktitle>
<pages>291--298</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6123" citStr="Zhao and Yun, 2009" startWordPosition="946" endWordPosition="949">any ways to enrich the original language model. The information of background corpus has been incorporated using linear combination (Ponte and Croft, 1998; Zhai and Lafferty, 2001). In contrast to the simple strategy which smooths all documents with the same background, recently corpus structures have been exploited for more accurate smoothing. The basic idea is to smooth a document language model with the documents similar to the document under consideration through clustering (Liu and Croft, 2004; Tao et al., 2006). Position information has also been used to enrich language model smoothing (Zhao and Yun, 2009; Lv and Zhai, 2009) and has been used in the combination of both enrichment of position and semantic (Yan et al., 2013). Beyond the semantic and/or position related smoothing intuitions, document structure based language model smoothing is another direction to investigate (Duan and Zhai, 2011). Mei et al. have proposed to smooth language model utilizing structural adjacency (2008). None of these methods incorporates social factors in language model smoothing. There is a study in (Lin et al., 2011) which smooths document language models of tweets for topic tracking in online text streams. Basi</context>
</contexts>
<marker>Zhao, Yun, 2009</marker>
<rawString>Jinglei Zhao and Yeogirl Yun. 2009. A proximity language model for information retrieval. In Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’09, pages 291–298, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dengyong Zhou</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>Regularization on discrete spaces.</title>
<date>2005</date>
<booktitle>In Pattern Recognition,</booktitle>
<pages>361--368</pages>
<publisher>Springer.</publisher>
<marker>Zhou, Sch¨olkopf, 2005</marker>
<rawString>Dengyong Zhou and Bernhard Sch¨olkopf. 2005. Regularization on discrete spaces. In Pattern Recognition, pages 361–368. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>