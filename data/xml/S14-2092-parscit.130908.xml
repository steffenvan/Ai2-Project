<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000456">
<title confidence="0.99699">
SeemGo: Conditional Random Fields Labeling and Maximum Entropy
Classification for Aspect Based Sentiment Analysis
</title>
<author confidence="0.992337">
Pengfei Liu and Helen Meng
</author>
<affiliation confidence="0.991557">
Human-Computer Communications Laboratory
Department of Systems Engineering and Engineering Management
The Chinese University of Hong Kong, Hong Kong SAR, China
</affiliation>
<email confidence="0.998604">
{pfliu,hmmeng}@se.cuhk.edu.hk
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999535047619048">
This paper describes our SeemGo sys-
tem for the task of Aspect Based Sen-
timent Analysis in SemEval-2014. The
subtask of aspect term extraction is cast
as a sequence labeling problem modeled
with Conditional Random Fields that ob-
tains the F-score of 0.683 for Laptops and
0.791 for Restaurants by exploiting both
word-based features and context features.
The other three subtasks are solved by the
Maximum Entropy model, with the occur-
rence counts of unigram and bigram words
of each sentence as features. The sub-
task of aspect category detection obtains
the best result when applying the Boosting
method on the Maximum Entropy model,
with the precision of 0.869 for Restau-
rants. The Maximum Entropy model also
shows good performance in the subtasks
of both aspect term and aspect category
polarity classification.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931">
In this paper, we present the SeemGo system de-
veloped for the task of Aspect Based Sentiment
Analysis in SemEval-2014. The task consists of
four subtasks: (1) aspect term extraction (iden-
tify particular aspects of a given entity, e.g., lap-
top, restaurant, etc.); (2) aspect category detection
(detect the category of a given sentence, e.g., food,
service for a restaurant, etc.), (3) aspect term po-
larity, and (4) aspect category polarity. The po-
larity of each aspect term or aspect category in-
cludes positive, negative, neutral or conflict (i.e.,
both positive and negative).
</bodyText>
<footnote confidence="0.4846965">
This work is licenced under a Creative Commons Attribu-
tion 4.0 International License. Page numbers and proceed-
ings footer are added by the organizers. License details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.999819263157895">
In the SeemGo system, the subtask of aspect
term extraction is implemented with the CRF
model that shows good performance by integrat-
ing both word-based features and context features.
The other subtasks of aspect category detection,
aspect term/category polarity classification are all
developed with the MaxEnt model with the occur-
rence counts of unigram and bigram words of each
sentence as features. Experimental results show
that MaxEnt obtains good performance in all the
three subtasks. For the subtask of aspect cate-
gory detection, MaxEnt obtains even better perfor-
mance when combined with the Boosting method.
The rest of this paper is organized as fol-
lows: Section 2 discusses related work; Section 3
presents the architecture and the underlying mod-
els of the SeemGo system as well as the experi-
mental results. We summarize the paper and pro-
pose future work in Section 4.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99990655">
The subtask of aspect term extraction is quite
similar with Noun Phrase Chunking (NPC) (Sha
and Pereira, 2003) and Named Entity Recognition
(NER) (Finkel et al., 2005). NPC recognizes noun
phrases from sentences, while NER extracts a set
of entities such as Person, Place, and Organiza-
tion. Both NPC and NER are sequential learn-
ing problems and they are typically modelled by
sequence models such as Hidden Markov Model
(HMM) and CRF (Finkel et al., 2005).
For the task of aspect term extraction, some re-
lated papers also model it with sequence models.
Jin et al. (2009) proposed an HMM-based frame-
work to extract product entities and associated
opinion orientations by integrating linguistic fea-
tures such as part-of-speech tag, lexical patterns
and surrounding words/phrases. Choi et al. (2005)
proposed a hybrid approach using both CRF and
extraction patterns to identify sources of opinions
in text. Jakob and Gurevych (2010) described a
</bodyText>
<page confidence="0.960549">
527
</page>
<note confidence="0.730057">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999822125">
CRF-based approach for the opinion target extrac-
tion problem in both single- and cross-domain set-
tings. Shariaty and Moghaddam (2011) used CRF
for the task of identifying aspects, aspect usages
and opinions in review sentences by making use
of labeled dataset on aspects, opinions as well as
background words in the sentences.
The task of aspect category detection is essen-
tially a text classification problem, for which many
techniques exist. Joachims (1998) explored the
use of Support Vector Machines (SVM) for text
categorization and obtained good performance
due to their ability to generalize well in high-
dimensional feature spaces. Nigam et al. (1999)
proposed the MaxEnt model for document clas-
sification by estimating the conditional distribu-
tion of the class variable give the document, and
showed that MaxEnt is significantly better that
Naive Bayes on some datasets.
For polarity classification, Pang et al. (2002)
conducted experiments on movie reviews and
showed that standard machine learning techniques
(e.g., Naive Bayes, SVM and MaxEnt) outperform
human-produced baselines.
</bodyText>
<sectionHeader confidence="0.940487" genericHeader="method">
3 The SeemGo System
</sectionHeader>
<bodyText confidence="0.999882">
We use the CRF model (Lafferty et al., 2001) for
the subtask of aspect term extraction, and adopt
the MaxEnt model for the other three subtasks
with the vectors of word count as features. Each
entry in the vector represents the occurrence count
of each unigram or bigram words in the sentence.
Figure 1 shows the architecture and the MaxEnt
and CRF models of the SeemGo system. The la-
bel is denoted in lowercase (e.g. y for sentiment),
while word count, label sequence and word se-
quence are vectors, denoted in bold lowercase (e.g.
y for label sequence). We developed the SeemGo
system in Java based on the MALLET Toolkit
(McCallum, 2002) for MaxEnt and the Stanford
CRFClassifier(Finkel et al., 2005) for CRF.
</bodyText>
<subsectionHeader confidence="0.9848835">
3.1 Background
3.1.1 Maximum Entropy Classifier
</subsectionHeader>
<bodyText confidence="0.997866">
The MaxEnt model defines the conditional distri-
bution of the class (y) given an observation vector
x as the exponential form in Formula 1:
</bodyText>
<equation confidence="0.998833">
K
P(y|x) = Z(x)exp(k=1
E Œ∏kfk (x, y) (1)
</equation>
<figureCaption confidence="0.9260755">
Figure 1: The Architecture, the MaxEnt and CRF
Models of the SeemGo System.
</figureCaption>
<bodyText confidence="0.9999932">
where Bk is a weight parameter to be estimated for
the corresponding feature function fk(x, y), and
Z(x) is a normalizing factor over all classes to en-
sure a proper probability. K is the total number of
feature functions.
</bodyText>
<subsectionHeader confidence="0.931171">
3.1.2 Conditional Random Fields
</subsectionHeader>
<bodyText confidence="0.999542454545455">
CRF is an extension to the MaxEnt model for han-
dling sequence data. The linear-chain CRF is a
special case of CRF that obeys the Markov prop-
erty between its neighbouring labels. Following
McCallum and Li (2003), Formula 2 defines the
linear-chain CRF: y = {yt}Tt=1, x = {xt}Tt=1 are
label sequence and observation sequence respec-
tively, and there are K arbitrary feature functions
{fk}1&lt;k&lt;K and the corresponding weight param-
eters {Bk}1&lt;k&lt;K. Z(x) is a normalizing factor
over all label sequences.
</bodyText>
<equation confidence="0.9994705">
1 T K
P(y|x) = Z(x) exp(t=1
EEŒ∏kfk(yt, yt‚àí1, x, t) (2)
k=1
</equation>
<bodyText confidence="0.999878666666667">
In the labeling phase, the Viterbi decoding algo-
rithm is applied to find the best label sequence y‚àó
for the observation sequence x.
</bodyText>
<subsectionHeader confidence="0.999823">
3.2 Subtask 1: Aspect Term Extraction
</subsectionHeader>
<bodyText confidence="0.99995225">
The datasets (Laptops and Restaurants) are pro-
vided in XML format, with each sentence and its
annotations consisting of a training instance. For
each instance, SeemGo first transform the sen-
tence into a word sequence x, and converts the cor-
responding annotations into the label sequence y.
SeemGo then learns a CRF model P(y|x) based
on the N the training instances {(xn, yn)}Nn=1.
</bodyText>
<figure confidence="0.9966486">
ùê±1 word sequence
ùê≤1 label sequence
ùê±ùëÅ word sequence
ùê≤ùëÅ label sequence
ùê±1 word count
ùë¶1 label
ùê±ùëÅ word count
ùë¶ùëÅ label
Training
Set
Training
Set
Train
CRF
Train P(ùê≤|X) Predict
Test sentence:
Test sentence:
MaxEnt
P(ùë¶ |ùê±)
(a) MaxEnt model for label classification
(b) CRF model for sequence labeling
I‚Äôve been to several places
for Dim Sum and this has
got to be the WORST.
I‚Äôve been to several places
for Dim Sum and this has
got to be the WORST.
ùê± word sequence
X
word count
Predict
Transform
Transform
ùë¶ label
ùê≤ label sequence
</figure>
<page confidence="0.921267">
528
</page>
<subsectionHeader confidence="0.555651">
3.2.1 IOB Labeling
</subsectionHeader>
<bodyText confidence="0.998935666666667">
Since an aspect term can contain multiple words
(e.g., hard disk), we define the label B-TERM
for the beginning of an aspect term, the label I-
TERM for the subsequent inside words or end
word of an aspect term and the label O for all other
words. This definition follows the Inside, Out-
side, Beginning (IOB) labeling scheme (Ramshaw
and Marcus, 1999). The subtask 1 can be viewed
as a sequence labeling problem by labeling each
word either as B-TERM, I-TERM or O. Figure
2 shows two example sentences labeled with the
IOB2 scheme 1.
</bodyText>
<figure confidence="0.70356975">
I liked the service and the staff.
O O O B-TERM O O B-TERM
The hard disk is very noisy.
O B-TERM I-TERM O O O
</figure>
<figureCaption confidence="0.996732">
Figure 2: Example Sentences with IOB2 Labels.
</figureCaption>
<subsubsectionHeader confidence="0.865708">
3.2.2 Features for the CRF Model
</subsubsectionHeader>
<bodyText confidence="0.999880740740741">
In CRF, features typically refer to feature func-
tions {fk}, which can be arbitrary functions. In
text applications, CRF features are typically bi-
nary (Sutton and McCallum, 2012). As an exam-
ple for ‚Äúvirus protection‚Äù, a binary feature func-
tion may have value 1 if and only if the label for
‚Äúvirus‚Äù is B-TERM and the current word ‚Äúprotec-
tion‚Äù has the suffix of ‚Äútion‚Äù, and otherwise 0.
Similar to the features used in Finkel et al. (2005)
for the NER task, Table 1 summarizes the features
for the aspect term extraction task. We call the fea-
tures derived from the current word word-based
features such as wid, wcharacter, and the features
from the surrounding words and the previous label
the contex features (context).
We consider the sentence ‚ÄúI‚Äôve been to several
places for Dim Sum and this has got to be the
WORST.‚Äù as an example to explain why we choose
these features: (a) word-based features: the word
‚ÄúSum‚Äù is located in the middle of the sentence,
with the first character capitalized. (b) context fea-
tures: the previous word ‚ÄúDim‚Äù is also capitalized
in the first character and the label of ‚ÄúDim‚Äù is as-
sumed to be ‚ÄúB-TERM‚Äù. By combining the word-
based features and the context features, the Viterbi
decoding algorithm will then label ‚ÄúSum‚Äù as ‚ÄúI-
TERM‚Äù with high degree of confidence, which is
</bodyText>
<footnote confidence="0.606811">
1With IOB2, every aspect term begins with the B label.
</footnote>
<bodyText confidence="0.940577">
a part of the multi-word term ‚ÄúDim Sum‚Äù, instead
of a mathematical function in some other context.
</bodyText>
<tableCaption confidence="0.949637">
Table 1: Features for the CRF Model.
</tableCaption>
<figureCaption confidence="0.942244923076923">
Feature Description
wid word identity
wcharacter whether the word characters are capital-
ized, hyphenated, numeric, e.g., built-in
camera, BIOS, Dim Sum, Windows 7
wlocation word index in the word sequence x
wngram n-gram character sequences of each
word with maximum length of 6, includ-
ing prefixes and suffixes, e.g., ‚Äútion‚Äù in
specification, navigation
context current word wt, its neighbouring words
(wt_2,...,wt+2) and previous label yt_1
wpos part-of-speech tag of each word
</figureCaption>
<subsectionHeader confidence="0.778638">
3.2.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999141777777778">
We trained the CRF model with different fea-
ture set on the training set provided by the Se-
mEval2014 organizers, and reported the experi-
mental results on the testing set by the evaluation
tool eval.jar. The detailed experimental results are
listed in Table 2. The basic feature set consists of
wid, wcharacter and wlocation. The results from one
of the best systems on each dataset are also listed,
marked with the star (*).
</bodyText>
<tableCaption confidence="0.9560585">
Table 2: Experimental Results on Different Fea-
ture Set for Aspect Term Extraction.
</tableCaption>
<table confidence="0.999585608695652">
Feature Set Precision Recall F-score
basic 0.780 0.402 0.531
(263/337) (263/654)
Lap 0.781 0.573 0.661
basic + wngram (375/480) (375/654) (+0.13)
basic + wcontext 0.827 0.453 0.585
(296/358) (296/654) (+0.054)
basic+wngram+ 0.830 0.581 0.683
context (380/458) (380/654) (+0.152)
basic+wngram+ 0.837 0.558 0.670
context + wpos (365/436) (365/654) (-0.013)
IHS RD Belarus* 0.848 0.665 0.746
basic 0.862 0.610 0.715
(692/803) (692/1134)
Res 0.838 0.709 0.768
basic + wngram (804/959) (804/1134) (+0.053)
basic + wcontext 0.856 0.621 0.720
(704/822) (704/1134) (+0.05)
basic+wngram+ 0.865 0.729 0.791
context (827/956) (827/1134) (+0.076)
basic+wngram+ 0.870 0.711 0.783
context + wpos (806/926) (806/1134) (-0.08)
XRCE* 0.909 0.818 0.840
</table>
<footnote confidence="0.613896333333333">
We have the following observations:
(1) Compared with using only the basic features,
adding the feature of wn‚àígram contributes the
</footnote>
<page confidence="0.998107">
529
</page>
<bodyText confidence="0.9996288">
greatest performance improvement, with the
absolute increase of F-score by 13% for Lap-
tops and 5.3% for Restaurants; while adding
the wcontext feature improves the F-score by
around 5% for both datasets.
</bodyText>
<listItem confidence="0.9766703">
(2) Combining the word-based features (basic
and wngram) and the context-based features
(wcontext) lead to the best performance for
both datasets in terms of recall and F-score.
(3) The POS tags lead to a decrease in both re-
call and F-score, with the absolute decrease
of F-score by 1.3% for Laptops and 8% for
Restaurants. The same observation is also re-
ported by Tkachenko and Simanovsky (2012)
for NER.
</listItem>
<subsectionHeader confidence="0.995963">
3.3 Subtask 3: Aspect Category Detection
</subsectionHeader>
<bodyText confidence="0.9996023125">
We encode each sentence as a feature vector x
with each entry representing occurrence count of
each unigram word and bigram words (i.e., word
count). All words are lowercased, while keeping
the stopwords as most sentences in the datasets are
short. Using the provided training set, We trained
a MaxEnt classifier (ME) P(ylx) with a Gaussian
prior variance of 20 to prevent overfitting.
We also tried the Bagging (Breiman, 1996) on
MaxEnt (BaggingME) and the Boosting (Freund
and Schapire, 1996) on MaxEnt (BoostME). Table
3 shows the experimental results on the provided
testing set. It shows that the Boosting method on
MaxEnt improves both precision and recall as well
as the F-score by 1.1%. The best evaluation result
is by the NRC-Canada team.
</bodyText>
<tableCaption confidence="0.776948">
Table 3: Performance of Different Classifiers for
Aspect Category Detection.
</tableCaption>
<table confidence="0.999679909090909">
Classifier Precision Recall F-score
ME 0.669 0.752
0.858 (686/1025)
(686/800)
BagME 0.658 0.739
0.843 (674/1025)
(674/800)
BoostME 0.678 0.762
0.869 (695/1025)
(695/800)
Best* 0.910 0.862 0.886
</table>
<subsectionHeader confidence="0.917016">
3.4 Subtask 2 &amp; 4: Aspect Term &amp; Category
Polarity Classification
</subsectionHeader>
<bodyText confidence="0.999483842105263">
Similar to subtask-3, we also used MaxEnt for the
subtasks of 2 and 4, with word count as features.
For category polarity classification, we count the
words from both the sentence and the category
name. For example, we count the sentence ‚ÄúThe
Dim Sum is delicious.‚Äù and its category ‚ÄúFood‚Äù
as features. This improves performance compared
with counting the sentence only.
Table 4 shows the accuracy of each classifier for
the subtasks of 2 and 4 on Laptops and Restau-
rants, including the best results from NRC-Canada
(a) and DCU (b). In both datasets, the distributions
of aspect term/category polarities are very imbal-
anced with very few sentences on conflict but with
most sentences on positive or negative. This leads
to very low classification performance for the con-
flict class, with the F-score less than 0.2. In this
case, the Boosting method does not necessarily
improve the performance.
</bodyText>
<tableCaption confidence="0.84501">
Table 4: Accuracy of Different Classifiers for As-
pect Term &amp; Category Polarity Classification.
</tableCaption>
<table confidence="0.999323818181818">
Classifier Term Category
(Restaurants)
Laptops Restaurants
ME 0.648 0.729 0.752
(424/654) (827/1134) (771/1025)
BagME 0.635 0.732 0.752
(415/654) (830/1134) (771/1025)
BoostME 0.642 0.730 0.747
(420/654) (828/1134) (766/1025)
Best* 0.705 (a,b) 0.810 (b) 0.829 (a)
(461/654) (918/1134) (850/1025)
</table>
<subsectionHeader confidence="0.668822">
3.5 Evaluation Ranks
</subsectionHeader>
<bodyText confidence="0.9998225">
Table 5 shows the official ranks (and the new ranks
in braces of the revised version after evaluation) of
the SeemGo system on the two datasets. The eval-
uation metrics are Precision, Recall and F-score
for the subtasks of 1 and 3, and Accuracy (Acc)
for the subtasks of 2 and 4.
</bodyText>
<tableCaption confidence="0.758731">
Table 5: Ranks of SeemGo on the Constrained
Run (Using only the Provided Datasets).
</tableCaption>
<table confidence="0.796048142857143">
Subtask Precision Recall F-score Acc
Lap 1 4 12 (8) 8 (4) -
2 - - - 12 (6)
Res 1 3 11 (7) 5 -
2 - - - 8 (6)
3 3 (2) 12 8 (7) -
4 - - - 4
</table>
<sectionHeader confidence="0.998972" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.998069666666667">
This paper presents the architecture, the CRF
and MaxEnt models of our SeemGo system for
the task of Aspect Based Sentiment Analysis in
</bodyText>
<page confidence="0.982172">
530
</page>
<bodyText confidence="0.999884642857143">
SemEval-2014. For the subtask of aspect term ex-
traction, CRF is trained with both the word-based
features and the context features. For the other
three subtasks, MaxEnt is trained with the fea-
tures of the occurrence counts of unigram and bi-
gram words in the sentence. The subtask of aspect
category detection obtains the best performance
when applying the Boosting method on MaxEnt.
MaxEnt also shows good average accuracy for po-
larity classification, but obtains low performance
for the conflict class due to very few training sen-
tences.This leaves us the future work to improve
classification performance for imbalanced datasets
(He and Garcia, 2009).
</bodyText>
<sectionHeader confidence="0.998379" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999835">
We thank the organizers for their hard work in or-
ganizing this evaluation, and the two anonymous
reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998824" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999405688311688">
Leo Breiman. 1996. Bagging predictors. Machine
learning, 24(2):123‚Äì140.
Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth
Patwardhan. 2005. Identifying sources of opin-
ions with conditional random fields and extraction
patterns. In Proceedings of the Conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, pages 355‚Äì362.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 363‚Äì370.
Yoav Freund and Robert E Schapire. 1996. Experi-
ments with a new boosting algorithm. In Interna-
tional Conference on Machine Learning, volume 96,
pages 148‚Äì156.
Haibo He and Edwardo A Garcia. 2009. Learning
from imbalanced data. Knowledge and Data Engi-
neering, IEEE Transactions on, 21(9):1263‚Äì1284.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with conditional random fields. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 1035‚Äì1045.
Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A
novel lexicalized HMM-based learning framework
for web opinion mining. In Proceedings of the In-
ternational Conference on Machine Learning, pages
465‚Äì472. Citeseer.
Thorsten Joachims. 1998. Text categorization with
support vector machines: Learning with many rel-
evant features. Springer.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.
Andrew McCallum and Wei Li. 2003. Early results for
named entity recognition with conditional random
fields, feature induction and web-enhanced lexicons.
In Proceedings of the seventh conference on Natural
language learning at HLT-NAACL 2003-Volume 4,
pages 188‚Äì191.
Andrew Kachites McCallum. 2002. MALLET: A Ma-
chine Learning for Language Toolkit.
Kamal Nigam, John Lafferty, and Andrew McCallum.
1999. Using maximum entropy for text classifica-
tion. In IJCAI-99 workshop on machine learning
for information filtering, volume 1, pages 61‚Äì67.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79‚Äì86.
Lance A Ramshaw and Mitchell P Marcus. 1999. Text
chunking using transformation-based learning. In
Natural language processing using very large cor-
pora, pages 157‚Äì176. Springer.
Fei Sha and Fernando Pereira. 2003. Shallow pars-
ing with conditional random fields. In Proceedings
of the Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 134‚Äì141.
Shabnam Shariaty and Samaneh Moghaddam. 2011.
Fine-grained opinion mining using conditional ran-
dom fields. In Data Mining Workshops (ICDMW),
2011 IEEE 11th International Conference on, pages
109‚Äì114. IEEE.
Charles Sutton and Andrew McCallum. 2012. An in-
troduction to conditional random fields. Founda-
tions and Trends in Machine Learning, 4(4):267‚Äì
373.
Maksim Tkachenko and Andrey Simanovsky. 2012.
Named entity recognition: Exploring features. In
Proceedings of KONVENS, volume 2012, pages
118‚Äì127.
</reference>
<page confidence="0.997956">
531
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.610114">
<title confidence="0.999718">SeemGo: Conditional Random Fields Labeling and Maximum Classification for Aspect Based Sentiment Analysis</title>
<author confidence="0.967037">Pengfei Liu</author>
<author confidence="0.967037">Helen</author>
<affiliation confidence="0.869924333333333">Human-Computer Communications Department of Systems Engineering and Engineering The Chinese University of Hong Kong, Hong Kong SAR,</affiliation>
<abstract confidence="0.993973681818182">This paper describes our SeemGo sysfor the task of Based Sen- Analysis SemEval-2014. The subtask of aspect term extraction is cast as a sequence labeling problem modeled with Conditional Random Fields that obtains the F-score of 0.683 for Laptops and 0.791 for Restaurants by exploiting both word-based features and context features. The other three subtasks are solved by the Maximum Entropy model, with the occurrence counts of unigram and bigram words of each sentence as features. The subtask of aspect category detection obtains the best result when applying the Boosting method on the Maximum Entropy model, with the precision of 0.869 for Restaurants. The Maximum Entropy model also shows good performance in the subtasks of both aspect term and aspect category polarity classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Bagging predictors.</title>
<date>1996</date>
<booktitle>Machine learning,</booktitle>
<pages>24--2</pages>
<contexts>
<context position="13148" citStr="Breiman, 1996" startWordPosition="2136" endWordPosition="2137">decrease of F-score by 1.3% for Laptops and 8% for Restaurants. The same observation is also reported by Tkachenko and Simanovsky (2012) for NER. 3.3 Subtask 3: Aspect Category Detection We encode each sentence as a feature vector x with each entry representing occurrence count of each unigram word and bigram words (i.e., word count). All words are lowercased, while keeping the stopwords as most sentences in the datasets are short. Using the provided training set, We trained a MaxEnt classifier (ME) P(ylx) with a Gaussian prior variance of 20 to prevent overfitting. We also tried the Bagging (Breiman, 1996) on MaxEnt (BaggingME) and the Boosting (Freund and Schapire, 1996) on MaxEnt (BoostME). Table 3 shows the experimental results on the provided testing set. It shows that the Boosting method on MaxEnt improves both precision and recall as well as the F-score by 1.1%. The best evaluation result is by the NRC-Canada team. Table 3: Performance of Different Classifiers for Aspect Category Detection. Classifier Precision Recall F-score ME 0.669 0.752 0.858 (686/1025) (686/800) BagME 0.658 0.739 0.843 (674/1025) (674/800) BoostME 0.678 0.762 0.869 (695/1025) (695/800) Best* 0.910 0.862 0.886 3.4 Sub</context>
</contexts>
<marker>Breiman, 1996</marker>
<rawString>Leo Breiman. 1996. Bagging predictors. Machine learning, 24(2):123‚Äì140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
</authors>
<title>Identifying sources of opinions with conditional random fields and extraction patterns.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>355--362</pages>
<contexts>
<context position="3649" citStr="Choi et al. (2005)" startWordPosition="565" endWordPosition="568">nizes noun phrases from sentences, while NER extracts a set of entities such as Person, Place, and Organization. Both NPC and NER are sequential learning problems and they are typically modelled by sequence models such as Hidden Markov Model (HMM) and CRF (Finkel et al., 2005). For the task of aspect term extraction, some related papers also model it with sequence models. Jin et al. (2009) proposed an HMM-based framework to extract product entities and associated opinion orientations by integrating linguistic features such as part-of-speech tag, lexical patterns and surrounding words/phrases. Choi et al. (2005) proposed a hybrid approach using both CRF and extraction patterns to identify sources of opinions in text. Jakob and Gurevych (2010) described a 527 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531, Dublin, Ireland, August 23-24, 2014. CRF-based approach for the opinion target extraction problem in both single- and cross-domain settings. Shariaty and Moghaddam (2011) used CRF for the task of identifying aspects, aspect usages and opinions in review sentences by making use of labeled dataset on aspects, opinions as well as background words in t</context>
</contexts>
<marker>Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth Patwardhan. 2005. Identifying sources of opinions with conditional random fields and extraction patterns. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 355‚Äì362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="3020" citStr="Finkel et al., 2005" startWordPosition="464" endWordPosition="467">tains good performance in all the three subtasks. For the subtask of aspect category detection, MaxEnt obtains even better performance when combined with the Boosting method. The rest of this paper is organized as follows: Section 2 discusses related work; Section 3 presents the architecture and the underlying models of the SeemGo system as well as the experimental results. We summarize the paper and propose future work in Section 4. 2 Related Work The subtask of aspect term extraction is quite similar with Noun Phrase Chunking (NPC) (Sha and Pereira, 2003) and Named Entity Recognition (NER) (Finkel et al., 2005). NPC recognizes noun phrases from sentences, while NER extracts a set of entities such as Person, Place, and Organization. Both NPC and NER are sequential learning problems and they are typically modelled by sequence models such as Hidden Markov Model (HMM) and CRF (Finkel et al., 2005). For the task of aspect term extraction, some related papers also model it with sequence models. Jin et al. (2009) proposed an HMM-based framework to extract product entities and associated opinion orientations by integrating linguistic features such as part-of-speech tag, lexical patterns and surrounding word</context>
<context position="5749" citStr="Finkel et al., 2005" startWordPosition="897" endWordPosition="900">ction, and adopt the MaxEnt model for the other three subtasks with the vectors of word count as features. Each entry in the vector represents the occurrence count of each unigram or bigram words in the sentence. Figure 1 shows the architecture and the MaxEnt and CRF models of the SeemGo system. The label is denoted in lowercase (e.g. y for sentiment), while word count, label sequence and word sequence are vectors, denoted in bold lowercase (e.g. y for label sequence). We developed the SeemGo system in Java based on the MALLET Toolkit (McCallum, 2002) for MaxEnt and the Stanford CRFClassifier(Finkel et al., 2005) for CRF. 3.1 Background 3.1.1 Maximum Entropy Classifier The MaxEnt model defines the conditional distribution of the class (y) given an observation vector x as the exponential form in Formula 1: K P(y|x) = Z(x)exp(k=1 E Œ∏kfk (x, y) (1) Figure 1: The Architecture, the MaxEnt and CRF Models of the SeemGo System. where Bk is a weight parameter to be estimated for the corresponding feature function fk(x, y), and Z(x) is a normalizing factor over all classes to ensure a proper probability. K is the total number of feature functions. 3.1.2 Conditional Random Fields CRF is an extension to the MaxEn</context>
<context position="9131" citStr="Finkel et al. (2005)" startWordPosition="1492" endWordPosition="1495">ed the service and the staff. O O O B-TERM O O B-TERM The hard disk is very noisy. O B-TERM I-TERM O O O Figure 2: Example Sentences with IOB2 Labels. 3.2.2 Features for the CRF Model In CRF, features typically refer to feature functions {fk}, which can be arbitrary functions. In text applications, CRF features are typically binary (Sutton and McCallum, 2012). As an example for ‚Äúvirus protection‚Äù, a binary feature function may have value 1 if and only if the label for ‚Äúvirus‚Äù is B-TERM and the current word ‚Äúprotection‚Äù has the suffix of ‚Äútion‚Äù, and otherwise 0. Similar to the features used in Finkel et al. (2005) for the NER task, Table 1 summarizes the features for the aspect term extraction task. We call the features derived from the current word word-based features such as wid, wcharacter, and the features from the surrounding words and the previous label the contex features (context). We consider the sentence ‚ÄúI‚Äôve been to several places for Dim Sum and this has got to be the WORST.‚Äù as an example to explain why we choose these features: (a) word-based features: the word ‚ÄúSum‚Äù is located in the middle of the sentence, with the first character capitalized. (b) context features: the previous word ‚ÄúD</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363‚Äì370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Experiments with a new boosting algorithm.</title>
<date>1996</date>
<booktitle>In International Conference on Machine Learning,</booktitle>
<volume>96</volume>
<pages>148--156</pages>
<contexts>
<context position="13215" citStr="Freund and Schapire, 1996" startWordPosition="2144" endWordPosition="2147">aurants. The same observation is also reported by Tkachenko and Simanovsky (2012) for NER. 3.3 Subtask 3: Aspect Category Detection We encode each sentence as a feature vector x with each entry representing occurrence count of each unigram word and bigram words (i.e., word count). All words are lowercased, while keeping the stopwords as most sentences in the datasets are short. Using the provided training set, We trained a MaxEnt classifier (ME) P(ylx) with a Gaussian prior variance of 20 to prevent overfitting. We also tried the Bagging (Breiman, 1996) on MaxEnt (BaggingME) and the Boosting (Freund and Schapire, 1996) on MaxEnt (BoostME). Table 3 shows the experimental results on the provided testing set. It shows that the Boosting method on MaxEnt improves both precision and recall as well as the F-score by 1.1%. The best evaluation result is by the NRC-Canada team. Table 3: Performance of Different Classifiers for Aspect Category Detection. Classifier Precision Recall F-score ME 0.669 0.752 0.858 (686/1025) (686/800) BagME 0.658 0.739 0.843 (674/1025) (674/800) BoostME 0.678 0.762 0.869 (695/1025) (695/800) Best* 0.910 0.862 0.886 3.4 Subtask 2 &amp; 4: Aspect Term &amp; Category Polarity Classification Similar </context>
</contexts>
<marker>Freund, Schapire, 1996</marker>
<rawString>Yoav Freund and Robert E Schapire. 1996. Experiments with a new boosting algorithm. In International Conference on Machine Learning, volume 96, pages 148‚Äì156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haibo He</author>
<author>Edwardo A Garcia</author>
</authors>
<title>Learning from imbalanced data.</title>
<date>2009</date>
<journal>Knowledge and Data Engineering, IEEE Transactions on,</journal>
<volume>21</volume>
<issue>9</issue>
<marker>He, Garcia, 2009</marker>
<rawString>Haibo He and Edwardo A Garcia. 2009. Learning from imbalanced data. Knowledge and Data Engineering, IEEE Transactions on, 21(9):1263‚Äì1284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single-and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="3782" citStr="Jakob and Gurevych (2010)" startWordPosition="586" endWordPosition="589">NER are sequential learning problems and they are typically modelled by sequence models such as Hidden Markov Model (HMM) and CRF (Finkel et al., 2005). For the task of aspect term extraction, some related papers also model it with sequence models. Jin et al. (2009) proposed an HMM-based framework to extract product entities and associated opinion orientations by integrating linguistic features such as part-of-speech tag, lexical patterns and surrounding words/phrases. Choi et al. (2005) proposed a hybrid approach using both CRF and extraction patterns to identify sources of opinions in text. Jakob and Gurevych (2010) described a 527 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531, Dublin, Ireland, August 23-24, 2014. CRF-based approach for the opinion target extraction problem in both single- and cross-domain settings. Shariaty and Moghaddam (2011) used CRF for the task of identifying aspects, aspect usages and opinions in review sentences by making use of labeled dataset on aspects, opinions as well as background words in the sentences. The task of aspect category detection is essentially a text classification problem, for which many techniques exist. Jo</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single-and cross-domain setting with conditional random fields. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1035‚Äì1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>A novel lexicalized HMM-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>465--472</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="3423" citStr="Jin et al. (2009)" startWordPosition="534" endWordPosition="537">opose future work in Section 4. 2 Related Work The subtask of aspect term extraction is quite similar with Noun Phrase Chunking (NPC) (Sha and Pereira, 2003) and Named Entity Recognition (NER) (Finkel et al., 2005). NPC recognizes noun phrases from sentences, while NER extracts a set of entities such as Person, Place, and Organization. Both NPC and NER are sequential learning problems and they are typically modelled by sequence models such as Hidden Markov Model (HMM) and CRF (Finkel et al., 2005). For the task of aspect term extraction, some related papers also model it with sequence models. Jin et al. (2009) proposed an HMM-based framework to extract product entities and associated opinion orientations by integrating linguistic features such as part-of-speech tag, lexical patterns and surrounding words/phrases. Choi et al. (2005) proposed a hybrid approach using both CRF and extraction patterns to identify sources of opinions in text. Jakob and Gurevych (2010) described a 527 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531, Dublin, Ireland, August 23-24, 2014. CRF-based approach for the opinion target extraction problem in both single- and cross-</context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A novel lexicalized HMM-based learning framework for web opinion mining. In Proceedings of the International Conference on Machine Learning, pages 465‚Äì472. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<publisher>Springer.</publisher>
<contexts>
<context position="4395" citStr="Joachims (1998)" startWordPosition="681" endWordPosition="682">0) described a 527 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531, Dublin, Ireland, August 23-24, 2014. CRF-based approach for the opinion target extraction problem in both single- and cross-domain settings. Shariaty and Moghaddam (2011) used CRF for the task of identifying aspects, aspect usages and opinions in review sentences by making use of labeled dataset on aspects, opinions as well as background words in the sentences. The task of aspect category detection is essentially a text classification problem, for which many techniques exist. Joachims (1998) explored the use of Support Vector Machines (SVM) for text categorization and obtained good performance due to their ability to generalize well in highdimensional feature spaces. Nigam et al. (1999) proposed the MaxEnt model for document classification by estimating the conditional distribution of the class variable give the document, and showed that MaxEnt is significantly better that Naive Bayes on some datasets. For polarity classification, Pang et al. (2002) conducted experiments on movie reviews and showed that standard machine learning techniques (e.g., Naive Bayes, SVM and MaxEnt) outp</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando CN Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<contexts>
<context position="5092" citStr="Lafferty et al., 2001" startWordPosition="785" endWordPosition="788">and obtained good performance due to their ability to generalize well in highdimensional feature spaces. Nigam et al. (1999) proposed the MaxEnt model for document classification by estimating the conditional distribution of the class variable give the document, and showed that MaxEnt is significantly better that Naive Bayes on some datasets. For polarity classification, Pang et al. (2002) conducted experiments on movie reviews and showed that standard machine learning techniques (e.g., Naive Bayes, SVM and MaxEnt) outperform human-produced baselines. 3 The SeemGo System We use the CRF model (Lafferty et al., 2001) for the subtask of aspect term extraction, and adopt the MaxEnt model for the other three subtasks with the vectors of word count as features. Each entry in the vector represents the occurrence count of each unigram or bigram words in the sentence. Figure 1 shows the architecture and the MaxEnt and CRF models of the SeemGo system. The label is denoted in lowercase (e.g. y for sentiment), while word count, label sequence and word sequence are vectors, denoted in bold lowercase (e.g. y for label sequence). We developed the SeemGo system in Java based on the MALLET Toolkit (McCallum, 2002) for M</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Wei Li</author>
</authors>
<title>Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL</booktitle>
<volume>2003</volume>
<pages>188--191</pages>
<contexts>
<context position="6527" citStr="McCallum and Li (2003)" startWordPosition="1031" endWordPosition="1034"> x as the exponential form in Formula 1: K P(y|x) = Z(x)exp(k=1 E Œ∏kfk (x, y) (1) Figure 1: The Architecture, the MaxEnt and CRF Models of the SeemGo System. where Bk is a weight parameter to be estimated for the corresponding feature function fk(x, y), and Z(x) is a normalizing factor over all classes to ensure a proper probability. K is the total number of feature functions. 3.1.2 Conditional Random Fields CRF is an extension to the MaxEnt model for handling sequence data. The linear-chain CRF is a special case of CRF that obeys the Markov property between its neighbouring labels. Following McCallum and Li (2003), Formula 2 defines the linear-chain CRF: y = {yt}Tt=1, x = {xt}Tt=1 are label sequence and observation sequence respectively, and there are K arbitrary feature functions {fk}1&lt;k&lt;K and the corresponding weight parameters {Bk}1&lt;k&lt;K. Z(x) is a normalizing factor over all label sequences. 1 T K P(y|x) = Z(x) exp(t=1 EEŒ∏kfk(yt, yt‚àí1, x, t) (2) k=1 In the labeling phase, the Viterbi decoding algorithm is applied to find the best label sequence y‚àó for the observation sequence x. 3.2 Subtask 1: Aspect Term Extraction The datasets (Laptops and Restaurants) are provided in XML format, with each sentenc</context>
</contexts>
<marker>McCallum, Li, 2003</marker>
<rawString>Andrew McCallum and Wei Li. 2003. Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 188‚Äì191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<contexts>
<context position="5686" citStr="McCallum, 2002" startWordPosition="890" endWordPosition="891">afferty et al., 2001) for the subtask of aspect term extraction, and adopt the MaxEnt model for the other three subtasks with the vectors of word count as features. Each entry in the vector represents the occurrence count of each unigram or bigram words in the sentence. Figure 1 shows the architecture and the MaxEnt and CRF models of the SeemGo system. The label is denoted in lowercase (e.g. y for sentiment), while word count, label sequence and word sequence are vectors, denoted in bold lowercase (e.g. y for label sequence). We developed the SeemGo system in Java based on the MALLET Toolkit (McCallum, 2002) for MaxEnt and the Stanford CRFClassifier(Finkel et al., 2005) for CRF. 3.1 Background 3.1.1 Maximum Entropy Classifier The MaxEnt model defines the conditional distribution of the class (y) given an observation vector x as the exponential form in Formula 1: K P(y|x) = Z(x)exp(k=1 E Œ∏kfk (x, y) (1) Figure 1: The Architecture, the MaxEnt and CRF Models of the SeemGo System. where Bk is a weight parameter to be estimated for the corresponding feature function fk(x, y), and Z(x) is a normalizing factor over all classes to ensure a proper probability. K is the total number of feature functions. 3</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. MALLET: A Machine Learning for Language Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamal Nigam</author>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
</authors>
<title>Using maximum entropy for text classification.</title>
<date>1999</date>
<booktitle>In IJCAI-99 workshop on machine learning for information filtering,</booktitle>
<volume>1</volume>
<pages>61--67</pages>
<contexts>
<context position="4594" citStr="Nigam et al. (1999)" startWordPosition="710" endWordPosition="713">et extraction problem in both single- and cross-domain settings. Shariaty and Moghaddam (2011) used CRF for the task of identifying aspects, aspect usages and opinions in review sentences by making use of labeled dataset on aspects, opinions as well as background words in the sentences. The task of aspect category detection is essentially a text classification problem, for which many techniques exist. Joachims (1998) explored the use of Support Vector Machines (SVM) for text categorization and obtained good performance due to their ability to generalize well in highdimensional feature spaces. Nigam et al. (1999) proposed the MaxEnt model for document classification by estimating the conditional distribution of the class variable give the document, and showed that MaxEnt is significantly better that Naive Bayes on some datasets. For polarity classification, Pang et al. (2002) conducted experiments on movie reviews and showed that standard machine learning techniques (e.g., Naive Bayes, SVM and MaxEnt) outperform human-produced baselines. 3 The SeemGo System We use the CRF model (Lafferty et al., 2001) for the subtask of aspect term extraction, and adopt the MaxEnt model for the other three subtasks wi</context>
</contexts>
<marker>Nigam, Lafferty, McCallum, 1999</marker>
<rawString>Kamal Nigam, John Lafferty, and Andrew McCallum. 1999. Using maximum entropy for text classification. In IJCAI-99 workshop on machine learning for information filtering, volume 1, pages 61‚Äì67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="4862" citStr="Pang et al. (2002)" startWordPosition="751" endWordPosition="754"> in the sentences. The task of aspect category detection is essentially a text classification problem, for which many techniques exist. Joachims (1998) explored the use of Support Vector Machines (SVM) for text categorization and obtained good performance due to their ability to generalize well in highdimensional feature spaces. Nigam et al. (1999) proposed the MaxEnt model for document classification by estimating the conditional distribution of the class variable give the document, and showed that MaxEnt is significantly better that Naive Bayes on some datasets. For polarity classification, Pang et al. (2002) conducted experiments on movie reviews and showed that standard machine learning techniques (e.g., Naive Bayes, SVM and MaxEnt) outperform human-produced baselines. 3 The SeemGo System We use the CRF model (Lafferty et al., 2001) for the subtask of aspect term extraction, and adopt the MaxEnt model for the other three subtasks with the vectors of word count as features. Each entry in the vector represents the occurrence count of each unigram or bigram words in the sentence. Figure 1 shows the architecture and the MaxEnt and CRF models of the SeemGo system. The label is denoted in lowercase (e</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 79‚Äì86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning. In Natural language processing using very large corpora,</title>
<date>1999</date>
<pages>157--176</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="8323" citStr="Ramshaw and Marcus, 1999" startWordPosition="1342" endWordPosition="1345"> for sequence labeling I‚Äôve been to several places for Dim Sum and this has got to be the WORST. I‚Äôve been to several places for Dim Sum and this has got to be the WORST. ùê± word sequence X word count Predict Transform Transform ùë¶ label ùê≤ label sequence 528 3.2.1 IOB Labeling Since an aspect term can contain multiple words (e.g., hard disk), we define the label B-TERM for the beginning of an aspect term, the label ITERM for the subsequent inside words or end word of an aspect term and the label O for all other words. This definition follows the Inside, Outside, Beginning (IOB) labeling scheme (Ramshaw and Marcus, 1999). The subtask 1 can be viewed as a sequence labeling problem by labeling each word either as B-TERM, I-TERM or O. Figure 2 shows two example sentences labeled with the IOB2 scheme 1. I liked the service and the staff. O O O B-TERM O O B-TERM The hard disk is very noisy. O B-TERM I-TERM O O O Figure 2: Example Sentences with IOB2 Labels. 3.2.2 Features for the CRF Model In CRF, features typically refer to feature functions {fk}, which can be arbitrary functions. In text applications, CRF features are typically binary (Sutton and McCallum, 2012). As an example for ‚Äúvirus protection‚Äù, a binary fe</context>
</contexts>
<marker>Ramshaw, Marcus, 1999</marker>
<rawString>Lance A Ramshaw and Mitchell P Marcus. 1999. Text chunking using transformation-based learning. In Natural language processing using very large corpora, pages 157‚Äì176. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Sha</author>
<author>Fernando Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>134--141</pages>
<contexts>
<context position="2963" citStr="Sha and Pereira, 2003" startWordPosition="455" endWordPosition="458">tence as features. Experimental results show that MaxEnt obtains good performance in all the three subtasks. For the subtask of aspect category detection, MaxEnt obtains even better performance when combined with the Boosting method. The rest of this paper is organized as follows: Section 2 discusses related work; Section 3 presents the architecture and the underlying models of the SeemGo system as well as the experimental results. We summarize the paper and propose future work in Section 4. 2 Related Work The subtask of aspect term extraction is quite similar with Noun Phrase Chunking (NPC) (Sha and Pereira, 2003) and Named Entity Recognition (NER) (Finkel et al., 2005). NPC recognizes noun phrases from sentences, while NER extracts a set of entities such as Person, Place, and Organization. Both NPC and NER are sequential learning problems and they are typically modelled by sequence models such as Hidden Markov Model (HMM) and CRF (Finkel et al., 2005). For the task of aspect term extraction, some related papers also model it with sequence models. Jin et al. (2009) proposed an HMM-based framework to extract product entities and associated opinion orientations by integrating linguistic features such as </context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>Fei Sha and Fernando Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 134‚Äì141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shabnam Shariaty</author>
<author>Samaneh Moghaddam</author>
</authors>
<title>Fine-grained opinion mining using conditional random fields.</title>
<date>2011</date>
<booktitle>In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on,</booktitle>
<pages>109--114</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="4069" citStr="Shariaty and Moghaddam (2011)" startWordPosition="627" endWordPosition="630">based framework to extract product entities and associated opinion orientations by integrating linguistic features such as part-of-speech tag, lexical patterns and surrounding words/phrases. Choi et al. (2005) proposed a hybrid approach using both CRF and extraction patterns to identify sources of opinions in text. Jakob and Gurevych (2010) described a 527 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527‚Äì531, Dublin, Ireland, August 23-24, 2014. CRF-based approach for the opinion target extraction problem in both single- and cross-domain settings. Shariaty and Moghaddam (2011) used CRF for the task of identifying aspects, aspect usages and opinions in review sentences by making use of labeled dataset on aspects, opinions as well as background words in the sentences. The task of aspect category detection is essentially a text classification problem, for which many techniques exist. Joachims (1998) explored the use of Support Vector Machines (SVM) for text categorization and obtained good performance due to their ability to generalize well in highdimensional feature spaces. Nigam et al. (1999) proposed the MaxEnt model for document classification by estimating the co</context>
</contexts>
<marker>Shariaty, Moghaddam, 2011</marker>
<rawString>Shabnam Shariaty and Samaneh Moghaddam. 2011. Fine-grained opinion mining using conditional random fields. In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference on, pages 109‚Äì114. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>An introduction to conditional random fields.</title>
<date>2012</date>
<booktitle>Foundations and Trends in Machine Learning,</booktitle>
<volume>4</volume>
<issue>4</issue>
<pages>373</pages>
<contexts>
<context position="8872" citStr="Sutton and McCallum, 2012" startWordPosition="1442" endWordPosition="1445">e Inside, Outside, Beginning (IOB) labeling scheme (Ramshaw and Marcus, 1999). The subtask 1 can be viewed as a sequence labeling problem by labeling each word either as B-TERM, I-TERM or O. Figure 2 shows two example sentences labeled with the IOB2 scheme 1. I liked the service and the staff. O O O B-TERM O O B-TERM The hard disk is very noisy. O B-TERM I-TERM O O O Figure 2: Example Sentences with IOB2 Labels. 3.2.2 Features for the CRF Model In CRF, features typically refer to feature functions {fk}, which can be arbitrary functions. In text applications, CRF features are typically binary (Sutton and McCallum, 2012). As an example for ‚Äúvirus protection‚Äù, a binary feature function may have value 1 if and only if the label for ‚Äúvirus‚Äù is B-TERM and the current word ‚Äúprotection‚Äù has the suffix of ‚Äútion‚Äù, and otherwise 0. Similar to the features used in Finkel et al. (2005) for the NER task, Table 1 summarizes the features for the aspect term extraction task. We call the features derived from the current word word-based features such as wid, wcharacter, and the features from the surrounding words and the previous label the contex features (context). We consider the sentence ‚ÄúI‚Äôve been to several places for D</context>
</contexts>
<marker>Sutton, McCallum, 2012</marker>
<rawString>Charles Sutton and Andrew McCallum. 2012. An introduction to conditional random fields. Foundations and Trends in Machine Learning, 4(4):267‚Äì 373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maksim Tkachenko</author>
<author>Andrey Simanovsky</author>
</authors>
<title>Named entity recognition: Exploring features.</title>
<date>2012</date>
<booktitle>In Proceedings of KONVENS,</booktitle>
<volume>volume</volume>
<pages>118--127</pages>
<contexts>
<context position="12670" citStr="Tkachenko and Simanovsky (2012)" startWordPosition="2056" endWordPosition="2059">of wn‚àígram contributes the 529 greatest performance improvement, with the absolute increase of F-score by 13% for Laptops and 5.3% for Restaurants; while adding the wcontext feature improves the F-score by around 5% for both datasets. (2) Combining the word-based features (basic and wngram) and the context-based features (wcontext) lead to the best performance for both datasets in terms of recall and F-score. (3) The POS tags lead to a decrease in both recall and F-score, with the absolute decrease of F-score by 1.3% for Laptops and 8% for Restaurants. The same observation is also reported by Tkachenko and Simanovsky (2012) for NER. 3.3 Subtask 3: Aspect Category Detection We encode each sentence as a feature vector x with each entry representing occurrence count of each unigram word and bigram words (i.e., word count). All words are lowercased, while keeping the stopwords as most sentences in the datasets are short. Using the provided training set, We trained a MaxEnt classifier (ME) P(ylx) with a Gaussian prior variance of 20 to prevent overfitting. We also tried the Bagging (Breiman, 1996) on MaxEnt (BaggingME) and the Boosting (Freund and Schapire, 1996) on MaxEnt (BoostME). Table 3 shows the experimental re</context>
</contexts>
<marker>Tkachenko, Simanovsky, 2012</marker>
<rawString>Maksim Tkachenko and Andrey Simanovsky. 2012. Named entity recognition: Exploring features. In Proceedings of KONVENS, volume 2012, pages 118‚Äì127.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>