<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007636">
<title confidence="0.789173">
Mood at work: Ramses versus Pharaoh
</title>
<author confidence="0.767771">
Alexandre Patry, Fabrizio Gotti and Philippe Langlais
</author>
<affiliation confidence="0.48855">
RALI — DIRO
Universit´e de Montr´eal
</affiliation>
<email confidence="0.996192">
{patryale,gottif,felipe}@iro.umontreal.ca
</email>
<sectionHeader confidence="0.998582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989916666667">
We present here the translation system we
used in this year’s WMT shared task. The
main objective of our participation was
to test RAMSES, an open source phrase-
based decoder. For that purpose, we used
the baseline system made available by the
organizers of the shared task1 to build the
necessary models. We then carried out a
pair-to-pair comparison of RAMSES with
PHARAOH on the six different translation
directions that we were asked to perform.
We present this comparison in this paper.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999565466666667">
Phrase-based (PB) machine translation (MT) is now
a popular paradigm, partly because of the relative
ease with which we can automatically create an ac-
ceptable translation engine from a bitext. As a mat-
ter of fact, deriving such an engine from a bitext con-
sists in (more or less) gluing together dedicated soft-
ware modules, often freely available. Word-based
models, or the so-called IBM models, can be trained
using the GIZA or GIZA++ toolkits (Och and Ney,
2000). One can then train phrase-based models us-
ing the THOT toolkit (Ortiz-Martinez et al., 2005).
For their part, language models currently in use in
SMT systems can be trained using packages such as
SRILM (Stolcke, 2002) and the CMU-SLM toolkit
(Clarkson and Rosenfeld, 1997).
</bodyText>
<footnote confidence="0.693587">
1www.statmt.org/wmt06/shared-task/
baseline.html
</footnote>
<bodyText confidence="0.999675181818182">
Once all the models are built, one can choose
to use PHARAOH (Koehn, 2004), an efficient full-
fledged phrase-based decoder. We only know of
one major drawback when using PHARAOH: its
licensing policy. Indeed, it is available for non-
commercial use in its binary form only. This
severely limits its use, both commercially and sci-
entifically (Walker, 2005).
For this reason, we undertook the design of a
generic architecture called MOOD (Modular Object-
Oriented Decoder), especially suited for instantiat-
ing SMT decoders. Two major goals directed our
design of this package: offering open source, state-
of-the-art decoders and providing an architecture to
easily build these decoders. This effort is described
in (Patry et al., 2006).
As a proof of concept that our framework (MOOD)
is viable, we attempted to use its functionalities to
implement a clone of PHARAOH, based on the com-
prehensive user manual of the latter. This clone,
called RAMSES, is now part of the MOOD distribu-
tion, which can be downloaded freely from the page
http://smtmood.sourceforge.net.
We conducted a pair-to-pair comparison between
the two engines that we describe in this paper. We
provide an overview of the MOOD architecture in
Section 2. Then we describe briefly RAMSES in Sec-
tion 3. The comparison between the two decoders in
terms of automatic metrics is analyzed in Section 4.
We confirm this comparison by presenting a man-
ual evaluation we conducted on an random sample
of the translations produced by both decoders. This
is reported in Section 5. We conclude in Section 6.
</bodyText>
<page confidence="0.976266">
126
</page>
<note confidence="0.4747925">
Proceedings of the Workshop on Statistical Machine Translation, pages 126–129,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.971022" genericHeader="method">
2 The MOOD Framework
</sectionHeader>
<bodyText confidence="0.999975071428572">
A decoder must implement a specific combination of
two elements: a model representation and a search
space exploration strategy. MOOD is a framework
designed precisely to allow such a combination, by
clearly separating its two elements. The design of
the framework is described in (Patry et al., 2006).
MOOD is implemented with the C++ program-
ming language and is licensed under the Gnu Gen-
eral Public License (GPL)2. This license grants the
right to anybody to use, modify and distribute the
program and its source code, provided that any mod-
ified version be licensed under the GPL as well.
As explained in (Walker, 2005), this kind of license
stimulates new ideas and research.
</bodyText>
<sectionHeader confidence="0.979289" genericHeader="method">
3 MOOD at work: RAMSES
</sectionHeader>
<bodyText confidence="0.999978636363636">
As we said above, in order to test our design, we
reproduced the most popular phrase-based decoder,
PHARAOH (Koehn, 2004), by following as faithfully
as possible its detailed user manual. The command-
line syntax RAMSES recognizes is compatible with
that of PHARAOH. The output produced by both
decoders are compatible as well and RAMSES can
also output its n-best lists in the same format as
PHARAOH does, i.e. in a format that the CARMEL
toolkit can parse (Knight and Al-Onaizan, 1999).
Switching decoders is therefore straightforward.
</bodyText>
<sectionHeader confidence="0.998867" genericHeader="method">
4 RAMSES versus PHARAOH
</sectionHeader>
<bodyText confidence="0.999940428571429">
To compare the translation performances of both
decoders in a meaningful manner, RAMSES and
PHARAOH were given the exact same language
model and translation table for each translation ex-
periment. Both models were produced with the
scripts provided by the organizers. This means in
practice that the language model was trained using
the SRILM toolkit (Stolcke, 2002). The word align-
ment required to build the phrase table was pro-
duced with the GIZA++ package. A Viterbi align-
ment computed from an IBM model 4 (Brown et al.,
1993) was computed for each translation direction.
Both alignments were then combined in a heuristic
way (Koehn et al., ). Each pair of phrases in the
</bodyText>
<footnote confidence="0.501759">
2http://www.gnu.org/copyleft/gpl.html
</footnote>
<bodyText confidence="0.999977666666667">
model is given 5 scores, described in the PHARAOH
training manual.3
To tune the coefficients of the log-linear
combination that both PHARAOH and RAMSES
use when decoding, we used the organizers’
minimum-error-rate-training.perl
script. This tuning step was performed on the
first 500 sentences of the dedicated development
corpora. Inevitably, RAMSES differs slightly
from PHARAOH, because of some undocumented
embedded heuristics. Thus, we found appropriate
to tune each decoder separately (although with
the same material). In effect, each decoder does
slightly better (with BLEU) when it uses its own best
parameters obtained from tuning, than when it uses
the parameters of its counterpart.
Eight coefficents were adjusted this way: five for
the translation table (one for each score associated
to each pair of phrases), and one for each of the fol-
lowing models: the language model, the so-called
word penalty model and the distortion model (word
reordering model). Each parameter is given a start-
ing value and a range within which it is allowed to
vary. For instance, the language model coefficient’s
starting value is 1.0 and the coefficient is in the range
[0.5–1.5]. Eventually, we obtained two optimal con-
figurations (one for each decoder) with which we
translated the TEST material.
We evaluated the translations produced by both
decoders with the organizers’ multi-bleu.perl
script, which computes a BLEU score (and displays
the n-gram precisions and brevity penalty used). We
report the scores we gathered on the test corpus of
2000 pairs of sentences in Table 1. Overall, both
decoders offer similar performances, down to the
n-gram precisions. To assess the statistical signifi-
cance of the observed differences in BLEU, we used
the bootstrapping technique described in (Zhang
and Vogel, 2004), randomly selecting 500 sentences
from each test set, 1000 times. Using a 95% con-
fidence interval, we determined that the small dif-
ferences between the two decoders are not statis-
tically significant, except for two tests. For the
direction English to French, RAMSES outperforms
PHARAOH, while in the German to English direc-
</bodyText>
<footnote confidence="0.9961135">
3http://www.statmt.org/wmt06/
shared-task/training-release-1.3.tgz
</footnote>
<page confidence="0.992996">
127
</page>
<bodyText confidence="0.9999014">
tion, PHARAOH is better. Whenever a decoder is
better than the other, Table 1 shows that it is at-
tributable to higher n-gram precisions; not to the
brevity penalty.
We further investigated these two cases by calcu-
lating BLEU for subsets of the test corpus sharing
similar sentence lengths (Table 2). We see that both
decoders have similar performances on short sen-
tences, but can differ by as much as 1% in BLEU on
longer ones. In contrast, on the Spanish-to-English
translation direction, where the two decoders offer
similar performances, the difference between BLEU
scores never exceeds 0.23%.
Expectedly, Spanish and French are much easier
to translate than German. This is because, in this
study, we did not apply any pre-processing strat-
egy that we know can improve performances, such
as clause reordering or compound-word splitting
(Collins et al., 2005; Langlais et al., 2005).
Table 2 shows that it does not seem much more
difficult to translate into English than from English.
This is surprising: translating into a morphologically
richer language should be more challenging. The
opposite is true for German here: without doing any-
thing specific for this language, it is much easier to
translate from German to English than the other way
around. This may be attributed in part to the lan-
guage model: for the test corpus, the perplexity of
the language models provided is 105.5 for German,
compared to 59.7 for English.
</bodyText>
<sectionHeader confidence="0.989993" genericHeader="method">
5 Human Evaluation
</sectionHeader>
<bodyText confidence="0.999981533333333">
In an effort to correlate the objective metrics with
human reviews, we undertook the blind evaluation
of a sample of 100 pairwise translations for the three
Foreign language-to-English translation tasks. The
pairs were randomly selected from the 3064 trans-
lations produced by each engine. They had to be
different for each decoder and be no more than 25
words long.
Each evaluator was presented with a source sen-
tence, its reference translation and the translation
produced by each decoder. The last two were in ran-
dom order, so the evaluator did not know which en-
gine produced the translation. The evaluator’s task
was two-fold. (1) He decided whether one transla-
tion was better than the other. (2) If he replied ’yes’
</bodyText>
<table confidence="0.999876315789474">
D BLEU p1 p2 p3 p4 BP
es-*en
P 30.65 64.10 36.52 23.70 15.91 1.00
R 30.48 64.08 36.30 23.52 15.76 1.00
fr -* en
P 30.42 64.28 36.45 23.39 15.64 1.00
R 30.43 64.58 36.59 23.54 15.73 0.99
de -* en
P 25.15 61.19 31.32 18.53 11.61 0.99
R 24.49 61.06 30.75 17.73 10.81 1.00
en -* es
P 29.40 61.86 35.32 22.77 15.02 1.00
R 28.75 62.23 35.03 22.32 14.58 0.99
en-*fr
P 30.96 61.10 36.56 24.49 16.80 1.00
R 31.79 61.57 37.38 25.30 17.53 1.00
en -* de
P 18.03 52.77 22.70 12.45 7.25 0.99
R 18.14 53.38 23.15 12.75 7.47 0.98
</table>
<tableCaption confidence="0.999266">
Table 1: Performance of RAMSES and PHARAOH
</tableCaption>
<bodyText confidence="0.97104265">
on the provided test set of 2000 pairs of sentences
per language pair. P stands for PHARAOH, R for
RAMSES. All scores are percentages. p,,, is the n-
gram precision and BP is the brevity penalty used
when computing BLEU.
in test (1), he stated whether the best translation was
satisfactory while the other was not. Two evalua-
tors went through the 3 x 100 sentence pairs. None
of them understands German; subject B understands
Spanish, and both understand French and English.
The results of this informal, yet informative exercise
are reported in Table 3.
Overall, in many cases (64% and 48% for subject
A and B respectively), the evaluators did not pre-
fer one translation over the other. On the Spanish-
and French-to-English tasks, both subjects slightly
preferred the translations produced by RAMSES. In
about one fourth of the cases where one translation
was preferred did the evaluators actually flag the se-
lected translation as significantly better.
</bodyText>
<sectionHeader confidence="0.999146" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.998282666666667">
We presented a pairwise comparison of two de-
coders, RAMSES and PHARAOH. Although RAM-
SES is roughly twice as slow as PHARAOH, both de-
</bodyText>
<page confidence="0.978544">
128
</page>
<figure confidence="0.949878857142857">
Test set
en → fr
en → fr
de → en
de → en
es → en
es → en
[0,15] [16,25] [26,∞[
(P) 33.52 30.65 30.39
(R) 33.78 31.19 31.35
(P) 29.74 24.30 24.76
(R) 29.85 23.92 23.78
(P) 34.23 28.32 30.60
(R) 34.46 28.39 30.40
</figure>
<sectionHeader confidence="0.928879" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.878993857142857">
P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R.L.
Mercer. 1993. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation. Computa-
tional Linguistics, 19(2):263–311.
P. Clarkson and R. Rosenfeld. 1997. Statistical language
modeling using the CMU-cambridge toolkit. In Proc.
of Eurospeech, pages 2707–2710, Rhodes, Greece.
</reference>
<tableCaption confidence="0.996182333333333">
Table 2: BLEU scores on subsets of the test corpus
filtered by sentence length ([min words, max words]
intervals), for Pharaoh and Ramses.
</tableCaption>
<table confidence="0.999820416666667">
Preferred Improved
P R No P R
es → en
subject A 13 16 71 6 1
subject B 23 31 46 3 8
fr → en
subject A 18 19 63 5 3
subject B 20 21 59 8 8
de → en
subject A 24 18 58 5 9
subject B 30 31 39 3 3
Total 128 136 336 30 32
</table>
<tableCaption confidence="0.994347">
Table 3: Human evaluation figures. The column
</tableCaption>
<bodyText confidence="0.975385642857143">
Preferred indicates the preference of the subject
(Pharaoh, Ramses or No preference). The column
Improved shows when a subject did prefer a trans-
lation and also said that the preferred translation was
correct while the other one was not.
coders offer comparable performances, according to
automatic and informal human evaluations.
Moreover, RAMSES is the product of clean frame-
work: MOOD, a solid tool for research projects. Its
code is open source and the architecture is modular,
making it easier for researchers to experiment with
SMT. We hope that the availability of the source
code and the clean design of MOOD will make it a
useful platform to implement new decoders.
</bodyText>
<sectionHeader confidence="0.999333" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996567">
We warmly thanks Elliott Macklovitch for his par-
ticipation in the manual annotation task. This work
has been partially funded by an NSERC grant.
</bodyText>
<reference confidence="0.9969392">
M. Collins, P. Koehn, and I. Kucerova. 2005. Clause re-
structuring for statistical machine translation. In Proc.
of the 43rd ACL, pages 531–540, Ann Arbor, MI.
K. Knight and Y. Al-Onaizan, 1999. A Primer on
Finite-State Software for Natural Language Process-
ing. www.isi.edu/licensed-sw/carmel.
P. Koehn, F. Joseph Och, and D. Marcu. Statistical
Phrase-Based Translation. In Proc. of HLT, Edmon-
ton, Canada.
P. Koehn. 2004. Pharaoh: a Beam Search Decoder for
Phrase-Based SMT. In Proc. of the 6th AMTA, pages
115–124, Washington, DC.
P. Langlais, G. Cao, and F. Gotti. 2005. RALI: SMT
shared task system description. In 2nd ACL workshop
on Building and Using Parallel Texts, pages 137–140,
Ann Arbor, MI.
F.J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proc. of ACL, pages 440–447,
Hongkong, China.
D. Ortiz-Martinez, I. Garci´a-Varea, and F. Casacuberta.
2005. Thot: a toolkit to train phrase-based statistical
translation models. In Proc. of MT Summit X, pages
141–148, Phuket, Thailand.
A. Patry, F. Gotti, and P. Langlais. 2006. MOOD
a modular object-oriented decoder for statistical ma-
chine translation. In Proc. ofLREC, Genoa, Italy.
A. Stolcke. 2002. SRILM - an Extensible Language
Modeling Toolkit. In Proc. ofICSLP, Denver, USA.
D.J. Walker. 2005. The open ”a.i.” kitTM: General ma-
chine learning modules from statistical machine trans-
lation. In Workshop of MT Summit X, ”Open-Source
Machine Translation”, Phuket, Thailand.
Ying Zhang and Stephan Vogel. 2004. Measuring confi-
dence intervals for the machine translation evaluation
metrics. In Proc. of the 10th TMI, Baltimore, MD.
</reference>
<page confidence="0.99857">
129
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914427">
<title confidence="0.996609">Mood at work: Ramses versus Pharaoh</title>
<author confidence="0.993524">Alexandre Patry</author>
<author confidence="0.993524">Fabrizio Gotti</author>
<author confidence="0.993524">Philippe Langlais</author>
<affiliation confidence="0.993074">RALI — DIRO Universit´e de Montr´eal</affiliation>
<abstract confidence="0.994944076923077">We present here the translation system we used in this year’s WMT shared task. The main objective of our participation was test an open source phrasebased decoder. For that purpose, we used the baseline system made available by the of the shared to build the necessary models. We then carried out a comparison of the six different translation directions that we were asked to perform. We present this comparison in this paper.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="4995" citStr="Brown et al., 1993" startWordPosition="800" endWordPosition="803">l-Onaizan, 1999). Switching decoders is therefore straightforward. 4 RAMSES versus PHARAOH To compare the translation performances of both decoders in a meaningful manner, RAMSES and PHARAOH were given the exact same language model and translation table for each translation experiment. Both models were produced with the scripts provided by the organizers. This means in practice that the language model was trained using the SRILM toolkit (Stolcke, 2002). The word alignment required to build the phrase table was produced with the GIZA++ package. A Viterbi alignment computed from an IBM model 4 (Brown et al., 1993) was computed for each translation direction. Both alignments were then combined in a heuristic way (Koehn et al., ). Each pair of phrases in the 2http://www.gnu.org/copyleft/gpl.html model is given 5 scores, described in the PHARAOH training manual.3 To tune the coefficients of the log-linear combination that both PHARAOH and RAMSES use when decoding, we used the organizers’ minimum-error-rate-training.perl script. This tuning step was performed on the first 500 sentences of the dedicated development corpora. Inevitably, RAMSES differs slightly from PHARAOH, because of some undocumented embed</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R.L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clarkson</author>
<author>R Rosenfeld</author>
</authors>
<title>Statistical language modeling using the CMU-cambridge toolkit.</title>
<date>1997</date>
<booktitle>In Proc. of Eurospeech,</booktitle>
<pages>2707--2710</pages>
<location>Rhodes, Greece.</location>
<contexts>
<context position="1420" citStr="Clarkson and Rosenfeld, 1997" startWordPosition="223" endWordPosition="226">ith which we can automatically create an acceptable translation engine from a bitext. As a matter of fact, deriving such an engine from a bitext consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the GIZA or GIZA++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the THOT toolkit (Ortiz-Martinez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1www.statmt.org/wmt06/shared-task/ baseline.html Once all the models are built, one can choose to use PHARAOH (Koehn, 2004), an efficient fullfledged phrase-based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This severely limits its use, both commercially and scientifically (Walker, 2005). For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for instantiating SMT decoders. Two major goals directed our des</context>
</contexts>
<marker>Clarkson, Rosenfeld, 1997</marker>
<rawString>P. Clarkson and R. Rosenfeld. 1997. Statistical language modeling using the CMU-cambridge toolkit. In Proc. of Eurospeech, pages 2707–2710, Rhodes, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd ACL,</booktitle>
<pages>531--540</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="8240" citStr="Collins et al., 2005" startWordPosition="1301" endWordPosition="1304">the test corpus sharing similar sentence lengths (Table 2). We see that both decoders have similar performances on short sentences, but can differ by as much as 1% in BLEU on longer ones. In contrast, on the Spanish-to-English translation direction, where the two decoders offer similar performances, the difference between BLEU scores never exceeds 0.23%. Expectedly, Spanish and French are much easier to translate than German. This is because, in this study, we did not apply any pre-processing strategy that we know can improve performances, such as clause reordering or compound-word splitting (Collins et al., 2005; Langlais et al., 2005). Table 2 shows that it does not seem much more difficult to translate into English than from English. This is surprising: translating into a morphologically richer language should be more challenging. The opposite is true for German here: without doing anything specific for this language, it is much easier to translate from German to English than the other way around. This may be attributed in part to the language model: for the test corpus, the perplexity of the language models provided is 105.5 for German, compared to 59.7 for English. 5 Human Evaluation In an effort</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>M. Collins, P. Koehn, and I. Kucerova. 2005. Clause restructuring for statistical machine translation. In Proc. of the 43rd ACL, pages 531–540, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>Y Al-Onaizan</author>
</authors>
<date>1999</date>
<booktitle>A Primer on Finite-State Software for Natural Language Processing. www.isi.edu/licensed-sw/carmel.</booktitle>
<contexts>
<context position="4392" citStr="Knight and Al-Onaizan, 1999" startWordPosition="703" endWordPosition="706">licensed under the GPL as well. As explained in (Walker, 2005), this kind of license stimulates new ideas and research. 3 MOOD at work: RAMSES As we said above, in order to test our design, we reproduced the most popular phrase-based decoder, PHARAOH (Koehn, 2004), by following as faithfully as possible its detailed user manual. The commandline syntax RAMSES recognizes is compatible with that of PHARAOH. The output produced by both decoders are compatible as well and RAMSES can also output its n-best lists in the same format as PHARAOH does, i.e. in a format that the CARMEL toolkit can parse (Knight and Al-Onaizan, 1999). Switching decoders is therefore straightforward. 4 RAMSES versus PHARAOH To compare the translation performances of both decoders in a meaningful manner, RAMSES and PHARAOH were given the exact same language model and translation table for each translation experiment. Both models were produced with the scripts provided by the organizers. This means in practice that the language model was trained using the SRILM toolkit (Stolcke, 2002). The word alignment required to build the phrase table was produced with the GIZA++ package. A Viterbi alignment computed from an IBM model 4 (Brown et al., 19</context>
</contexts>
<marker>Knight, Al-Onaizan, 1999</marker>
<rawString>K. Knight and Y. Al-Onaizan, 1999. A Primer on Finite-State Software for Natural Language Processing. www.isi.edu/licensed-sw/carmel.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>F Joseph Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<booktitle>In Proc. of HLT,</booktitle>
<location>Edmonton, Canada.</location>
<marker>Koehn, Och, Marcu, </marker>
<rawString>P. Koehn, F. Joseph Och, and D. Marcu. Statistical Phrase-Based Translation. In Proc. of HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Pharaoh: a Beam Search Decoder for Phrase-Based SMT.</title>
<date>2004</date>
<booktitle>In Proc. of the 6th AMTA,</booktitle>
<pages>115--124</pages>
<location>Washington, DC.</location>
<contexts>
<context position="1545" citStr="Koehn, 2004" startWordPosition="241" endWordPosition="242">xt consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the GIZA or GIZA++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the THOT toolkit (Ortiz-Martinez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1www.statmt.org/wmt06/shared-task/ baseline.html Once all the models are built, one can choose to use PHARAOH (Koehn, 2004), an efficient fullfledged phrase-based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This severely limits its use, both commercially and scientifically (Walker, 2005). For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for instantiating SMT decoders. Two major goals directed our design of this package: offering open source, stateof-the-art decoders and providing an architecture to easily build these decod</context>
<context position="4028" citStr="Koehn, 2004" startWordPosition="644" endWordPosition="645">rating its two elements. The design of the framework is described in (Patry et al., 2006). MOOD is implemented with the C++ programming language and is licensed under the Gnu General Public License (GPL)2. This license grants the right to anybody to use, modify and distribute the program and its source code, provided that any modified version be licensed under the GPL as well. As explained in (Walker, 2005), this kind of license stimulates new ideas and research. 3 MOOD at work: RAMSES As we said above, in order to test our design, we reproduced the most popular phrase-based decoder, PHARAOH (Koehn, 2004), by following as faithfully as possible its detailed user manual. The commandline syntax RAMSES recognizes is compatible with that of PHARAOH. The output produced by both decoders are compatible as well and RAMSES can also output its n-best lists in the same format as PHARAOH does, i.e. in a format that the CARMEL toolkit can parse (Knight and Al-Onaizan, 1999). Switching decoders is therefore straightforward. 4 RAMSES versus PHARAOH To compare the translation performances of both decoders in a meaningful manner, RAMSES and PHARAOH were given the exact same language model and translation tabl</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Pharaoh: a Beam Search Decoder for Phrase-Based SMT. In Proc. of the 6th AMTA, pages 115–124, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Langlais</author>
<author>G Cao</author>
<author>F Gotti</author>
</authors>
<title>RALI: SMT shared task system description.</title>
<date>2005</date>
<booktitle>In 2nd ACL workshop on Building and Using Parallel Texts,</booktitle>
<pages>137--140</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="8264" citStr="Langlais et al., 2005" startWordPosition="1305" endWordPosition="1308">g similar sentence lengths (Table 2). We see that both decoders have similar performances on short sentences, but can differ by as much as 1% in BLEU on longer ones. In contrast, on the Spanish-to-English translation direction, where the two decoders offer similar performances, the difference between BLEU scores never exceeds 0.23%. Expectedly, Spanish and French are much easier to translate than German. This is because, in this study, we did not apply any pre-processing strategy that we know can improve performances, such as clause reordering or compound-word splitting (Collins et al., 2005; Langlais et al., 2005). Table 2 shows that it does not seem much more difficult to translate into English than from English. This is surprising: translating into a morphologically richer language should be more challenging. The opposite is true for German here: without doing anything specific for this language, it is much easier to translate from German to English than the other way around. This may be attributed in part to the language model: for the test corpus, the perplexity of the language models provided is 105.5 for German, compared to 59.7 for English. 5 Human Evaluation In an effort to correlate the object</context>
</contexts>
<marker>Langlais, Cao, Gotti, 2005</marker>
<rawString>P. Langlais, G. Cao, and F. Gotti. 2005. RALI: SMT shared task system description. In 2nd ACL workshop on Building and Using Parallel Texts, pages 137–140, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China.</location>
<contexts>
<context position="1147" citStr="Och and Ney, 2000" startWordPosition="179" endWordPosition="182">of RAMSES with PHARAOH on the six different translation directions that we were asked to perform. We present this comparison in this paper. 1 Introduction Phrase-based (PB) machine translation (MT) is now a popular paradigm, partly because of the relative ease with which we can automatically create an acceptable translation engine from a bitext. As a matter of fact, deriving such an engine from a bitext consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the GIZA or GIZA++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the THOT toolkit (Ortiz-Martinez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1www.statmt.org/wmt06/shared-task/ baseline.html Once all the models are built, one can choose to use PHARAOH (Koehn, 2004), an efficient fullfledged phrase-based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. Improved Statistical Alignment Models. In Proc. of ACL, pages 440–447, Hongkong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ortiz-Martinez</author>
<author>I Garci´a-Varea</author>
<author>F Casacuberta</author>
</authors>
<title>Thot: a toolkit to train phrase-based statistical translation models.</title>
<date>2005</date>
<booktitle>In Proc. of MT Summit X,</booktitle>
<pages>141--148</pages>
<location>Phuket, Thailand.</location>
<marker>Ortiz-Martinez, Garci´a-Varea, Casacuberta, 2005</marker>
<rawString>D. Ortiz-Martinez, I. Garci´a-Varea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proc. of MT Summit X, pages 141–148, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Patry</author>
<author>F Gotti</author>
<author>P Langlais</author>
</authors>
<title>MOOD a modular object-oriented decoder for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ofLREC,</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="2198" citStr="Patry et al., 2006" startWordPosition="340" endWordPosition="343">based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This severely limits its use, both commercially and scientifically (Walker, 2005). For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for instantiating SMT decoders. Two major goals directed our design of this package: offering open source, stateof-the-art decoders and providing an architecture to easily build these decoders. This effort is described in (Patry et al., 2006). As a proof of concept that our framework (MOOD) is viable, we attempted to use its functionalities to implement a clone of PHARAOH, based on the comprehensive user manual of the latter. This clone, called RAMSES, is now part of the MOOD distribution, which can be downloaded freely from the page http://smtmood.sourceforge.net. We conducted a pair-to-pair comparison between the two engines that we describe in this paper. We provide an overview of the MOOD architecture in Section 2. Then we describe briefly RAMSES in Section 3. The comparison between the two decoders in terms of automatic metri</context>
<context position="3505" citStr="Patry et al., 2006" startWordPosition="552" endWordPosition="555">n we conducted on an random sample of the translations produced by both decoders. This is reported in Section 5. We conclude in Section 6. 126 Proceedings of the Workshop on Statistical Machine Translation, pages 126–129, New York City, June 2006. c�2006 Association for Computational Linguistics 2 The MOOD Framework A decoder must implement a specific combination of two elements: a model representation and a search space exploration strategy. MOOD is a framework designed precisely to allow such a combination, by clearly separating its two elements. The design of the framework is described in (Patry et al., 2006). MOOD is implemented with the C++ programming language and is licensed under the Gnu General Public License (GPL)2. This license grants the right to anybody to use, modify and distribute the program and its source code, provided that any modified version be licensed under the GPL as well. As explained in (Walker, 2005), this kind of license stimulates new ideas and research. 3 MOOD at work: RAMSES As we said above, in order to test our design, we reproduced the most popular phrase-based decoder, PHARAOH (Koehn, 2004), by following as faithfully as possible its detailed user manual. The comman</context>
</contexts>
<marker>Patry, Gotti, Langlais, 2006</marker>
<rawString>A. Patry, F. Gotti, and P. Langlais. 2006. MOOD a modular object-oriented decoder for statistical machine translation. In Proc. ofLREC, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proc. ofICSLP,</booktitle>
<location>Denver, USA.</location>
<contexts>
<context position="1365" citStr="Stolcke, 2002" startWordPosition="217" endWordPosition="218">m, partly because of the relative ease with which we can automatically create an acceptable translation engine from a bitext. As a matter of fact, deriving such an engine from a bitext consists in (more or less) gluing together dedicated software modules, often freely available. Word-based models, or the so-called IBM models, can be trained using the GIZA or GIZA++ toolkits (Och and Ney, 2000). One can then train phrase-based models using the THOT toolkit (Ortiz-Martinez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1www.statmt.org/wmt06/shared-task/ baseline.html Once all the models are built, one can choose to use PHARAOH (Koehn, 2004), an efficient fullfledged phrase-based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This severely limits its use, both commercially and scientifically (Walker, 2005). For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for insta</context>
<context position="4832" citStr="Stolcke, 2002" startWordPosition="771" endWordPosition="772">tible as well and RAMSES can also output its n-best lists in the same format as PHARAOH does, i.e. in a format that the CARMEL toolkit can parse (Knight and Al-Onaizan, 1999). Switching decoders is therefore straightforward. 4 RAMSES versus PHARAOH To compare the translation performances of both decoders in a meaningful manner, RAMSES and PHARAOH were given the exact same language model and translation table for each translation experiment. Both models were produced with the scripts provided by the organizers. This means in practice that the language model was trained using the SRILM toolkit (Stolcke, 2002). The word alignment required to build the phrase table was produced with the GIZA++ package. A Viterbi alignment computed from an IBM model 4 (Brown et al., 1993) was computed for each translation direction. Both alignments were then combined in a heuristic way (Koehn et al., ). Each pair of phrases in the 2http://www.gnu.org/copyleft/gpl.html model is given 5 scores, described in the PHARAOH training manual.3 To tune the coefficients of the log-linear combination that both PHARAOH and RAMSES use when decoding, we used the organizers’ minimum-error-rate-training.perl script. This tuning step </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proc. ofICSLP, Denver, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Walker</author>
</authors>
<title>The open ”a.i.” kitTM: General machine learning modules from statistical machine translation.</title>
<date>2005</date>
<booktitle>In Workshop of MT Summit X, ”Open-Source Machine Translation”,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="1823" citStr="Walker, 2005" startWordPosition="285" endWordPosition="286"> (Ortiz-Martinez et al., 2005). For their part, language models currently in use in SMT systems can be trained using packages such as SRILM (Stolcke, 2002) and the CMU-SLM toolkit (Clarkson and Rosenfeld, 1997). 1www.statmt.org/wmt06/shared-task/ baseline.html Once all the models are built, one can choose to use PHARAOH (Koehn, 2004), an efficient fullfledged phrase-based decoder. We only know of one major drawback when using PHARAOH: its licensing policy. Indeed, it is available for noncommercial use in its binary form only. This severely limits its use, both commercially and scientifically (Walker, 2005). For this reason, we undertook the design of a generic architecture called MOOD (Modular ObjectOriented Decoder), especially suited for instantiating SMT decoders. Two major goals directed our design of this package: offering open source, stateof-the-art decoders and providing an architecture to easily build these decoders. This effort is described in (Patry et al., 2006). As a proof of concept that our framework (MOOD) is viable, we attempted to use its functionalities to implement a clone of PHARAOH, based on the comprehensive user manual of the latter. This clone, called RAMSES, is now par</context>
<context position="3826" citStr="Walker, 2005" startWordPosition="610" endWordPosition="611"> must implement a specific combination of two elements: a model representation and a search space exploration strategy. MOOD is a framework designed precisely to allow such a combination, by clearly separating its two elements. The design of the framework is described in (Patry et al., 2006). MOOD is implemented with the C++ programming language and is licensed under the Gnu General Public License (GPL)2. This license grants the right to anybody to use, modify and distribute the program and its source code, provided that any modified version be licensed under the GPL as well. As explained in (Walker, 2005), this kind of license stimulates new ideas and research. 3 MOOD at work: RAMSES As we said above, in order to test our design, we reproduced the most popular phrase-based decoder, PHARAOH (Koehn, 2004), by following as faithfully as possible its detailed user manual. The commandline syntax RAMSES recognizes is compatible with that of PHARAOH. The output produced by both decoders are compatible as well and RAMSES can also output its n-best lists in the same format as PHARAOH does, i.e. in a format that the CARMEL toolkit can parse (Knight and Al-Onaizan, 1999). Switching decoders is therefore </context>
</contexts>
<marker>Walker, 2005</marker>
<rawString>D.J. Walker. 2005. The open ”a.i.” kitTM: General machine learning modules from statistical machine translation. In Workshop of MT Summit X, ”Open-Source Machine Translation”, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Stephan Vogel</author>
</authors>
<title>Measuring confidence intervals for the machine translation evaluation metrics.</title>
<date>2004</date>
<booktitle>In Proc. of the 10th TMI,</booktitle>
<location>Baltimore, MD.</location>
<contexts>
<context position="6985" citStr="Zhang and Vogel, 2004" startWordPosition="1106" endWordPosition="1109">y, we obtained two optimal configurations (one for each decoder) with which we translated the TEST material. We evaluated the translations produced by both decoders with the organizers’ multi-bleu.perl script, which computes a BLEU score (and displays the n-gram precisions and brevity penalty used). We report the scores we gathered on the test corpus of 2000 pairs of sentences in Table 1. Overall, both decoders offer similar performances, down to the n-gram precisions. To assess the statistical significance of the observed differences in BLEU, we used the bootstrapping technique described in (Zhang and Vogel, 2004), randomly selecting 500 sentences from each test set, 1000 times. Using a 95% confidence interval, we determined that the small differences between the two decoders are not statistically significant, except for two tests. For the direction English to French, RAMSES outperforms PHARAOH, while in the German to English direc3http://www.statmt.org/wmt06/ shared-task/training-release-1.3.tgz 127 tion, PHARAOH is better. Whenever a decoder is better than the other, Table 1 shows that it is attributable to higher n-gram precisions; not to the brevity penalty. We further investigated these two cases </context>
</contexts>
<marker>Zhang, Vogel, 2004</marker>
<rawString>Ying Zhang and Stephan Vogel. 2004. Measuring confidence intervals for the machine translation evaluation metrics. In Proc. of the 10th TMI, Baltimore, MD.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>