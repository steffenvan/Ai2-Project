<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998628">
Discriminative Parse Reranking for Chinese with Homogeneous and
Heterogeneous Annotations
</title>
<author confidence="0.956039">
Weiwei Sun†‡ and Rui Wang† and Yi Zhang†‡†Department of Computational Linguistics, Saarland University
</author>
<affiliation confidence="0.790187">
‡German Research Center for Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.564331">
D-66123, Saarbr¨ucken, Germany
</address>
<email confidence="0.99315">
{wsun,rwang,yzhang}@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.998579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99749655">
Discriminative parse reranking has been
shown to be an effective technique to im-
prove the generative parsing models. In
this paper, we present a series of exper-
iments on parsing the Tsinghua Chinese
Treebank with hierarchically split-merge
grammars and reranked with a perceptron-
based discriminative model. In addition to
the homogeneous annotation on TCT, we
also incorporate the PCTB-based parsing
result as heterogeneous annotation into
the reranking feature model. The rerank-
ing model achieved 1.12% absolute im-
provement on F1 over the Berkeley parser
on a development set. The head labels in
Task 2.1 are annotated with a sequence
labeling model. The system achieved
80.32 (B+C+H F1) in CIPS-SIGHAN-
2010 Task 2.1 (Open Track) and 76.11
(Overall F1) in Task 2.2 (Open Track)1.
</bodyText>
<sectionHeader confidence="0.999611" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99980675">
The data-driven approach to syntactic analysis of
natural language has undergone revolutionary de-
velopment in the last 15 years, ever since the
first few large scale syntactically annotated cor-
pora, i.e. treebanks, became publicly available in
the mid-90s of the last century. One and a half
decades later, treebanks remain to be an expensive
type of language resources and only available for
</bodyText>
<footnote confidence="0.886348666666667">
1This result is achieved with a bug-fixed version of the
system and does not correspond to the numbers in the origi-
nal evaluation report.
</footnote>
<bodyText confidence="0.996683857142857">
a small number of languages. The main issue that
hinders large treebank development projects is
the difficulties in creating a complete and consis-
tent annotation guideline which then constitutes
the very basis for sustainable parallel annotation
and quality assurance. While traditional linguistic
studies typically focus on either isolated language
phenomena or limited interaction among a small
groups of phenomena, the annotation scheme in
treebanking project requires full coverage of lan-
guage use in the source media, and proper treat-
ment with an uniformed annotation format. Such
high demand from the practical application of lin-
guistic theory has given rise to a countless num-
ber of attempts and variations in the formaliza-
tion frameworks. While the harsh natural selec-
tion set the bar high and many attempts failed to
even reach the actual annotation phase, a hand-
ful highly competent grammar frameworks have
given birth to several large scale treebanks.
The co-existence of multiple treebanks with
heterogeneous annotation presents a new chal-
lenge to the consumers of such resources. The im-
mediately relevant task is the automated syntactic
analysis, or parsing. While many state-of-the-art
statistical parsing systems are not bound to spe-
cific treebank annotation (assuming the formal-
ism is predetermined independently), almost all
of them assume homogeneous annotation in the
training corpus. Therefore, such treebanks can not
be simply put together when training the parser.
One approach would be to convert them into an
uniformed representation, although such conver-
sion is usually difficult and by its nature error-
prune. The differences in annotations constitute
different generative stories: i.e., when the pars-
ing models are viewed as mechanisms to produce
structured sentences, each treebank model will as-
sociate its own structure with the surface string in-
dependently. On the other hand, if the discrimina-
tive view is adopted, it is possible to use annota-
tions in different treebanks as indication of good-
ness of the tree in the original annotation.
In this paper, we present a series of experi-
ments to improve the Chinese parsing accuracy
on the Tsinghua Chinese Treebank. First, we use
coarse-to-fine parsing with hierarchically split-
merge generative grammars to obtain a list of can-
didate trees in TCT annotation. A discriminative
parse selection model is then used to rerank the
list of candidates. The reranking model is trained
with both homogeneous (TCT) and heterogeneous
(PCTB) data. A sequence labeling system is used
to annotate the heads in Task 2-1.
The remaining part of the paper is organized as
follows. Section 2 reviews the relevant previous
study on generative split-merge parsing and dis-
criminative reranking models. Section 3 describes
the work flow of our system participated in the
CIPS-SIGHAN-2010 bake-off Task 2. Section 4
describes the detailed settings for the evaluation
and the empirical results. Section 5 concludes the
paper.
</bodyText>
<sectionHeader confidence="0.987279" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999953738461539">
Statistical constituent-based parsing is popular-
ized through the decade-long competition on pars-
ing the Wall Street Journal sections of the English
Penn Treebank. While the evaluation setup has
for long seen its limitation (a frustratingly low
of 2% overall improvement throughout a decade
of research), the value of newly proposed pars-
ing methods along the way has clearly much more
profound merits than the seemly trivial increase in
evaluation figures. In this section we review two
effective techniques in constituent-based statisti-
cal parsing, and their potential benefits in parsing
Chinese.
Comparing with many other languages, statisti-
cal parsing for Chinese has reached early success,
due to the fact that the language has relatively
fixed word order and extremely poor inflectional
morphology. Both facts allow the PCFG-based
statistical modeling to perform well. On the other
hand, the much higher ambiguity between basic
word categories like nouns and verbs makes Chi-
nese parsing interestingly different from the situ-
ation of English.
The type of treebank annotations also affects
the performance of the parsing models. Tak-
ing the Penn Chinese Treebank (PCTB; Xue
et al. (2005)) and Tsinghua Chinese Treebank
(TCT; Zhou (2004)) as examples, PCTB is anno-
tated with a much more detailed set of phrase cat-
egories, while TCT uses a more fine-grained POS
tagset. The asymmetry in the annotation informa-
tion is partially due to the difference of linguis-
tic treatment. But more importantly, it shows that
both treebanks have the potential of being refined
with more detailed classification, on either phrasal
or word categories. One data-driven approach to
derive more fine-grained annotation is the hierar-
chically split-merge parsing (Petrov et al., 2006;
Petrov and Klein, 2007), which induces subcat-
egories from coarse-grained annotations through
an expectation maximization procedure. In com-
bination with the coarse-to-fine parsing strategy,
efficient inference can be done with a cascade
of grammars of different granularity. Such pars-
ing models have reached (close to) state-of-the-art
performance for many languages including Chi-
nese and English.
Another effective technique to improve parsing
results is discriminative reranking (Charniak and
Johnson, 2005; Collins and Koo, 2005). While
the generative models compose candidate parse
trees, a discriminative reranker reorders the list
of candidates in favor of those trees which max-
imizes the properties of being a good analysis.
Such extra model refines the original scores as-
signed by the generative model by focusing its de-
cisions on the fine details among already “good”
candidates. Due to this nature, the set of features
in the reranker focus on those global (and poten-
tially long distance) properties which are difficult
to model with the generative model. Also, since
it is not necessary for the reranker to generate the
candidate trees, one can easily integrate additional
external information to help adjust the ranking of
the analysis. In the following section, we will de-
</bodyText>
<equation confidence="0.384081">
e.g. WO GAJ学 A
</equation>
<figureCaption confidence="0.999439">
Figure 1: Workflow of the System
</figureCaption>
<bodyText confidence="0.9999338">
scribe the reranking model we developed for the
CIPS-SIGHAN-2010 parsing tasks. We will also
show how the heterogeneous parsing results can
be integrated through the reranker to further im-
prove the performance of the system.
</bodyText>
<sectionHeader confidence="0.990222" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.9999736">
In this section, we will present our approach
in detail. The whole system consists of three
main components, the Berkeley Parser, the Parse
Reranker, and the Head Classifier. The workflow
is shown in Figure 1. Firstly, we use the Berke-
ley Parser trained on the TCT to parse the in-
put sentence and obtain a list of possible parses;
then, all the parses2 will be re-ranked by the Parse
Reranker; and finally, the Head Classifer will an-
notate the head information for each constituent
</bodyText>
<footnote confidence="0.8322405">
2In practice, we only take the top n parses. We have dif-
ferent n values in the experiment settings, and n is up to 50.
</footnote>
<listItem confidence="0.599978833333333">
Algorithm 1: The Perptron learning proce-
dure.
input : Data {(xt, yt), t = 1, 2, ..., m�
1 Initialize: w &lt;-- (0, ..., 0)
2 for i = 1, 2, ..., I do
11 return aw = I �Z 1 wi
</listItem>
<bodyText confidence="0.999457533333333">
on the best parse tree. For parse reranking, we
can extract features either from TCT-style parses
or together with the PCTB-style parse of the same
sentence. For example, we can check whether
the boundary predictions given by the TCT parser
are agreed by the PCTB parser. Since the PCTB
parser is trained on a different treebank from TCT,
our reranking model can be seen as a method to
use a heterogenous resource. The best parse tree
given by the Parse Reranker will be the result for
Task 2.2; and the final output of the system will
be the result for Task 2.1. Since we have already
mentioned the Berkeley Parser in the related work,
we will focus on the other two modules in the rest
of this section.
</bodyText>
<subsectionHeader confidence="0.999867">
3.1 Parse Reranker
</subsectionHeader>
<bodyText confidence="0.999933307692308">
We follow Collins and Koo (2005)’s discrimina-
tive reranking model to score possible parse trees
of each sentence given by the Berkeley Parser.
Previous research on English shows that struc-
tured perceptron (Collins, 2002) is one of the
strongest machine learning algorithms for parse
reranking (Collins and Duffy, 2002; Gao et al.,
2007). In our system, we use the averaged per-
ceptron algorithm to do parameter estimation. Al-
gorithm 1 illustrates the learning procedure. The
parameter vector w is initialized to (0, ..., 0). The
learner processes all the instances (t is from 1 to
n) in each iteration (i). If current hypothesis (w)
</bodyText>
<figure confidence="0.998641837837838">
PCTB
Parser
TCT
Task 2.2
Task 2.1
Open
A B C D
C D B A
Head
Classifier
Berkeley
Parser
Parse
Reranker
C
H
H
H
...
...
3
4
5
6
7
8
9
for t =SHUFFLE (1, ..., m) do
y∗t =
arg maxy∈GENbest
n (Xt) wTb(xt,y)
if y∗t =� yt then
w &lt;-- w+(b(xt, yt)−b(xt, y∗t ))
end
end
wi &lt;-- w
10 end
</figure>
<bodyText confidence="0.9983102">
fails to predict xt, the learner update w through
calculating the difference between Φ(xt, y∗t ) and
Φ(xt, yt). At the end of each iteration, the learner
save the current model as w + i, and finally all
these models will be added up to get aw.
</bodyText>
<subsectionHeader confidence="0.961167">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.999412">
We use an example to show the features we extract
in Figure 2.
</bodyText>
<figure confidence="0.7358485">
vp
v np
买 的 苹果
buy apple
</figure>
<figureCaption confidence="0.878827">
Figure 2: An Example
</figureCaption>
<figure confidence="0.9084745">
Rules The context-free rule itself:
np → v + uJDE + np.
</figure>
<bodyText confidence="0.990658984375">
Grandparent Rules Same as the Rules, but
also including the nonterminal above the rule:
vp(np → v + uJDE + np)
Bigrams Pairs of nonterminals from the left to
right of the the rule. The example rule would con-
tribute the bigrams np(STOP, v), np(v, uJDE),
np(uJDE, np) and np(np, STOP).
Grandparent Bigrams Same as Bigrams, but
also including the nonterminal above the bigrams.
For instance, vp(np(STOP, v))
Lexical Bigrams Same as Bigrams, but with
the lexical heads of the two nonterminals also in-
cluded. For instance, np(STOP,买).
Trigrams All trigrams within the rule. The
example rule would contribute the trigrams
np(STOP, STOP, v), np(STOP, v, uJDE),
np(v, uJDE, np), np(uJDE, np, STOP) and
np(np, STOP, STOP).
Combination of Boundary Words and
Rules The first word and the rule (i.e.
买+(np → v + uJDE + np)), the last word
and the rule one word before and the rule, one
word after and the rule, the first word, the last
word and the rule, and the first word’s POS, last
word’s POS and the rule.
Combination of Boundary Words and Phrasal
Category : Same as combination of boundary
words and rules, but substitute the rule with the
category of current phrases.
Two level Rules Same as Rules, but also
including the entire rule above the rule:
vp → v + (np → v + uJDE + np)
Original Rank : The logarithm of the original
rank of n-best candidates.
Affixation features In order to better handle
unknown words, we also extract morphologi-
cal features: character n-gram prefixes and suf-
fixes for n up to 3. For example, for word/tag
pair 自 然 环 /n, we add the following fea-
tures: (prefix1,自,n), (prefix2,自然,n), (prefix3,自
然 环,n), (suffix1, ,n), (suffix2,环 ,n), (suf-
fix3,然环 ,n).
Apart from training the reranking model using
the same dataset (i.e. the TCT), we can also use
another treebank (e.g. the PCTB). Although they
have quite different annotations as well as the data
source, it would still be interesting to see whether
a heterogenous resource is helpful with the parse
reranking.
Consist Category If a phrase is also analyzed
as one phrase by the PCTB parser, both the TCT
and PCTB categories are used as two individual
features. The combination of the two categories
are also used.
Inconsist Category If a phrase is not analyzed
as one phrase by the PCTB parser, the TCT cate-
gory is used as a feature.
Number of Consist and Inconsist phrases The
two number are used as two individual featuers.
We also use the ratio of the number of consist
phrases and inconsist phrase (we add 0.1 to each
number for smoothing), the ratio of the number
of consist/inconsist phrases and the length of the
current sentence.
</bodyText>
<equation confidence="0.8315146">
uJDE
吃
eat
n
v
</equation>
<bodyText confidence="0.986213666666667">
POS Tags For each word, the combination of
TCT and PCTB POS tags (with or without word
content) are used.
</bodyText>
<subsectionHeader confidence="0.999167">
3.3 Head Classifier
</subsectionHeader>
<bodyText confidence="0.982160285714285">
Following (Song and Kit, 2009), we apply a se-
quence tagging method to find head constituents.
We suggest readers to refer to the original paper
for details of the method. However, since the fea-
ture set is different, we give the discription of
them in this paper. To predict whether current
phrase is a head phrase of its parent, we use the
same example above (Figure 2) for convenience.
If we consider np as our current phrase, the fol-
lowing features are extracted,
Rules The generative rule, vp → v + (np).
Category of the Current Phrase and its Parent
np, vp, and (np, vp).
Bigrams and Trigrams (v, np), (np, STOP),
(STOP, v, np), and (np, STOP, STOP).
Parent Bigrams and Trigrams vp(v, np),
vp(np, STOP), vp(STOP, v, np),
vp(np, STOP, STOP).
Lexical Unigram The first word 买, the last
word 苹果, and together with the parent, (vp,买)
and (vp,苹果)
</bodyText>
<sectionHeader confidence="0.999095" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.888497">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.980937095238095">
The dataset used in the CIPS-ParsEval-2010 eval-
uation is converted from the Tsinghua Chinese
Treebank (TCT). There are two subtasks: (1)
event description sub-sentence analysis and (2)
complete sentence parsing. On the assumption
that the boundaries and relations between these
event description units are determined separately,
the first task aims to identify the local fine-grained
syntactic structures. The goal of the second task
is to evaluate the performance of the automatic
parsers on complete sentences in real texts. The
training dataset is a mixture of several genres, in-
cluding newspaper texts, encyclopedic texts and
novel texts.
The annotation in the dataset is different to
the other frequently used Chinese treebank (i.e.
PCTB) Whereas TCT annotation strongly reflects
early descriptive linguistics, PCTB draws primar-
ily on Government-Binding (GB) theory from
1980s. PCTB annotation differs from TCT anno-
tation from many perspectives:
</bodyText>
<listItem confidence="0.87323984">
• TCT and PCTB have different segmentation
standards.
• TCT is somehow branching-rich annota-
tion, while PCTB annotation is category-
rich. Specifically the topological tree struc-
tures is more detailed in TCT, and there
are not many flat structures. However con-
stituents are detailed classified, namely the
number of phrasal categories is small. On the
contrary, though flat structures are very com-
mon in PCTB, the categorization of phrases
is fine-grained. In addition, PCTB contains
functional information. Function tags ap-
pended to constituent labels are used to in-
dicate additional syntactic or semantic infor-
mation.
• TCT contains head indices, making head
identification of each constituent an impor-
tant goal of task 1.
• Following the GB theory, PCTB assume
there are movements, so there are empty cat-
egory annotation. Because of different theo-
retical foundations, there are different expla-
nations for a series of linguistic phenomena
such as the usage of function word “的”.
</listItem>
<bodyText confidence="0.999757666666667">
In the reranking experiments, we also use a
parser trained on PCTB to provide more syntac-
tic clues.
</bodyText>
<subsectionHeader confidence="0.997882">
4.2 Setting
</subsectionHeader>
<bodyText confidence="0.9996992">
In order to gain a representative set of training
data, we use cross-validation scheme described in
(Collins, 2000). The dataset is a mixture of three
genres. We equally split every genre data into 10
subsets, and collect three subset of different gen-
res as one fold of the whole data. In this way, we
can divide the whole data into 10 balanced sub-
sets. For each fold data, a complement parser is
trained using all other data to produce multiple hy-
potheses for each sentence. This cross-validation
</bodyText>
<table confidence="0.4752865">
n 1 2 5 10 20 30 40 50
F1 79.97 81.62 83.51 84.63 85.59 86.07 86.38 86.60
</table>
<tableCaption confidence="0.998812">
Table 1: Upper bound of f-score as a function of number n of n-best parses.
</tableCaption>
<bodyText confidence="0.999896692307692">
scheme can prevent the initial model from being
unrealistically “good” on the training sentences.
We use the first 9 folds as training data and the last
fold as development data for the following exper-
iments. For the final submission of the evaluation
task, we re-train a reranking model using all 10
folds data. All reranking models are trained with
30 iterations.
For parsing experiments, we use the Berkeley
parser3. All parsers are trained with 5 iterations
of split, merge, smooth. To produce PCTB-style
analysis, we train the Berkeley parse with PCTB
5.0 data that contains 18804 sentences and 508764
words. For the evaluation of development experi-
ments, we used the EVALB tool4 for evaluation,
and used labeled recall (LR), labeled precision
(LP) and F1 score (which is the harmonic mean
of LR and LP) to measure accuracy.
For the head classification, we use SVMhmm5,
an implementation of structural SVMs for se-
quence tagging. The main setting of learning pa-
rameter is C that trades off margin size and train-
ing error. In our experiments, the head classifica-
tion is not sensitive to this parameter and we set
it to 1 for all experiments reported. For the kernel
function setting, we use the simplest linear kernel.
</bodyText>
<subsectionHeader confidence="0.8894055">
4.3 Results
4.3.1 Upper Bound of Reranking
</subsectionHeader>
<bodyText confidence="0.9999855">
The upper bound of n-best parse reranking is
shown in Table 1. From the 1-best result we see
that the base accuracy of the parser is 79.97. 2-
best and 10-best show promising oracle-rate im-
provements. After that things start to slow down,
and we achieve an oracle rate of 86.60 at 50-best.
</bodyText>
<subsectionHeader confidence="0.815312">
4.3.2 Reranking Using Homogeneous Data
</subsectionHeader>
<bodyText confidence="0.99517">
Table 2 summarizes the performance of the ba-
sic reranking model. It is evaluated on short sen-
</bodyText>
<footnote confidence="0.99946575">
3http://code.google.com/p/
berkeleyparser/
4http://nlp.cs.nyu.edu/evalb/
5http://www.cs.cornell.edu/People/tj/
</footnote>
<page confidence="0.37429">
svm_light/svm_hmm.html
</page>
<bodyText confidence="0.99980825">
tences (less than 40 words) from the development
data of the task 2. When 40 reranking candidates
are used, the model gives a 0.76% absolute im-
provement over the basic Berkeley parser.
</bodyText>
<equation confidence="0.90322">
POS(%) LP(%) LR(%) F1
Baseline 93.59 85.60 85.36 85.48
n = 2 93.66 85.84 85.54 85.69
n = 5 93.62 86.04 85.73 85.88
n = 10 93.66 86.22 85.85 86.04
n = 20 93.70 86.19 85.87 86.03
n = 30 93.70 86.32 86.00 86.16
n = 40 93.76 86.40 86.09 86.24
n = 50 93.73 86.10 85.81 85.96
</equation>
<tableCaption confidence="0.68629">
Table 2: Reranking performance with different
</tableCaption>
<bodyText confidence="0.993036">
number of parse candidates on the sentences that
contain no more than 40 words in the development
data.
</bodyText>
<subsectionHeader confidence="0.700947">
4.3.3 Reranking Using Heterogeneous Data
</subsectionHeader>
<bodyText confidence="0.739908066666667">
Table 3 summarizes the reranking performance
using PCTB data. It is also evaluated on short sen-
tences of the task 2. When 30 reranking candi-
dates are used, the model gives a 1.12% absolute
improvement over the Berkeley parser. Compar-
ison of Table 2 and 3 shows an improvement by
using heterogeneous data.
POS(%) LP(%) LR(%) F1
n = 2 93.70 85.98 85.67 85.82
n = 5 93.75 86.52 86.19 86.35
n = 10 93.77 86.64 86.29 86.47
n = 20 93.79 86.71 86.34 86.53
n = 30 93.80 86.72 86.48 86.60
n = 40 93.80 86.54 86.22 86.38
n = 50 93.89 86.73 86.41 86.57
</bodyText>
<tableCaption confidence="0.909815">
Table 3: Reranking performance with different
</tableCaption>
<bodyText confidence="0.748967">
number of parse candidates on the sentences that
contain no more than 40 words in the development
data.
</bodyText>
<table confidence="0.998302">
Task 1 “B+C”-P “B+C”-R “B+C”-F1 “B+C+H”-P “B+C+H”-R “B+C+H”-F1 POS
Old data 82.37 83.05 82.71 79.99 80.65 80.32 81.87
Table 4: Final results of task 1.
Task 2 dj-P dj-R dj-F1 fj-P fj-R fj-F1 Avg. POS
Old data 79.37 79.27 79.32 71.06 73.22 72.13 75.72 81.23
New data 79.60 79.13 79.36 70.01 75.94 72.85 76.11 89.05
</table>
<tableCaption confidence="0.994984">
Table 5: Final results of task 2.
</tableCaption>
<subsubsectionHeader confidence="0.604423">
4.3.4 Head Classification
</subsubsectionHeader>
<bodyText confidence="0.999796375">
The head classification performance is evalu-
ated using gold-standard syntactic trees. For each
constituent in a gold parse tree, a structured clas-
sifier is trained to predict whether it is a head con-
stituent of its parent. Table 6 shows the overall
performance of head classification. We can see
that the head classification can achieve a high per-
formance.
</bodyText>
<equation confidence="0.835606">
P(%) R(%) Fβ=1
98.59% 98.20% 98.39
</equation>
<bodyText confidence="0.562051">
Table 6: Head classification performance with
gold trees on the development data.
</bodyText>
<subsectionHeader confidence="0.598895">
4.3.5 Final Result
</subsectionHeader>
<bodyText confidence="0.999968272727273">
Table 4 and 5 summarize the final results. Here
we use the reranking model with heterogeneous
data. The second line of Table 5 shows the offi-
cal final results. In this submission, we trained a
model using an old version of training data. Note
that, the standard of POS tags of the “old” version
is different from the latest version which is also
used as test data. For example, the name of some
tags are changed. The third line of Table 46 shows
the results predicted by the newest data7. This re-
sult is comparable to other systems.
</bodyText>
<sectionHeader confidence="0.999523" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.925533">
In this paper, we described our participation of
the CIPS-SIGHAN-2010 parsing task. The gen-
</bodyText>
<footnote confidence="0.969248571428571">
6There are two sentences that are not parsed by the Berke-
ley parser. We use a simple strategy to solve this problem:
We first roughly segment the sentence according to punctu-
ation; Then the parsed sub-sentences are merged as a single
zj.
7We would like to thank the organizer to re-test our new
submission.
</footnote>
<bodyText confidence="0.999808375">
erative coarse-to-fine parsing model is integrated
with a discriminative parse reranking model, as
well as a head classifier based on sequence la-
beling. We use the perceptron algorithm to train
the reranking models and experiment with both
homogenous and heterogenous data. The results
show improvements over the baseline in both
cases.
</bodyText>
<sectionHeader confidence="0.999074" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999780166666667">
The first author is supported by the German Aca-
demic Exchange Service (DAAD). The second
author is supported by the PIRE scholarship pro-
gram; the third author thanks DFKI and the Clus-
ter of Excellence on Multimodal Computing and
Interaction for their support of the work.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998920442307692">
Charniak, E. and M Johnson. 2005. oarse-to-fine n-
best parsing and maxent discriminative reranking.
In Proceedings of ACL, pages 173–180.
Collins, Michael and Nigel Duffy. 2002. New rank-
ing algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In
Proceedings of 40th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 263–270,
Philadelphia, Pennsylvania, USA, July. Association
for Computational Linguistics.
Collins, Michael and Terry Koo. 2005. Discriminative
reranking for natural language parsing. In Compu-
tational Linguistics, volume 31(1), pages 25–69.
Collins, Michael. 2000. Discriminative reranking for
natural language parsing. In Computational Lin-
guistics, pages 175–182. Morgan Kaufmann.
Collins, Michael. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In EMNLP ’02:
Proceedings of the ACL-02 conference on Empiri-
cal methods in natural language processing, pages
1–8, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Gao, Jianfeng, Galen Andrew, Mark Johnson, and
Kristina Toutanova. 2007. A comparative study of
parameter estimation methods for statistical natural
language processing. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 824–831, Prague, Czech Repub-
lic, June. Association for Computational Linguis-
tics.
Petrov, S. and D. Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL-2007, Rochester, NY, USA, April.
Petrov, Slav, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proceedings of the
21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 433–440,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Song, Yan and Chunyu Kit. 2009. Pcfg parsing with
crf tagging for head recognition. In Proceedings of
the CIPS-ParsEval-2009.
Xue, Nianwen, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The penn chinese treebank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207–238.
Zhou, Qiang. 2004. Annotation scheme for chinese
treebank (in chinese). Journal of Chinese Informa-
tion Processing, 18(4):1–8.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.181232">
<title confidence="0.970304">Discriminative Parse Reranking for Chinese with Homogeneous Heterogeneous Annotations</title>
<author confidence="0.46945">of Computational Linguistics</author>
<author confidence="0.46945">Saarland</author>
<affiliation confidence="0.653955">Research Center for Artificial Intelligence</affiliation>
<address confidence="0.770812">D-66123, Saarbr¨ucken,</address>
<email confidence="0.992068">wsun@coli.uni-saarland.de</email>
<email confidence="0.992068">rwang@coli.uni-saarland.de</email>
<email confidence="0.992068">yzhang@coli.uni-saarland.de</email>
<abstract confidence="0.97169825">Discriminative parse reranking has been shown to be an effective technique to improve the generative parsing models. In this paper, we present a series of experiments on parsing the Tsinghua Chinese Treebank with hierarchically split-merge grammars and reranked with a perceptronbased discriminative model. In addition to the homogeneous annotation on TCT, we also incorporate the PCTB-based parsing result as heterogeneous annotation into the reranking feature model. The reranking model achieved 1.12% absolute improvement on F1 over the Berkeley parser on a development set. The head labels in Task 2.1 are annotated with a sequence labeling model. The system achieved 80.32 (B+C+H F1) in CIPS-SIGHAN- 2010 Task 2.1 (Open Track) and 76.11</abstract>
<intro confidence="0.831001">F1) in Task 2.2 (Open</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>oarse-to-fine nbest parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="6917" citStr="Charniak and Johnson, 2005" startWordPosition="1048" endWordPosition="1051">driven approach to derive more fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), which induces subcategories from coarse-grained annotations through an expectation maximization procedure. In combination with the coarse-to-fine parsing strategy, efficient inference can be done with a cascade of grammars of different granularity. Such parsing models have reached (close to) state-of-the-art performance for many languages including Chinese and English. Another effective technique to improve parsing results is discriminative reranking (Charniak and Johnson, 2005; Collins and Koo, 2005). While the generative models compose candidate parse trees, a discriminative reranker reorders the list of candidates in favor of those trees which maximizes the properties of being a good analysis. Such extra model refines the original scores assigned by the generative model by focusing its decisions on the fine details among already “good” candidates. Due to this nature, the set of features in the reranker focus on those global (and potentially long distance) properties which are difficult to model with the generative model. Also, since it is not necessary for the re</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Charniak, E. and M Johnson. 2005. oarse-to-fine nbest parsing and maxent discriminative reranking. In Proceedings of ACL, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="9801" citStr="Collins and Duffy, 2002" startWordPosition="1554" endWordPosition="1557"> best parse tree given by the Parse Reranker will be the result for Task 2.2; and the final output of the system will be the result for Task 2.1. Since we have already mentioned the Berkeley Parser in the related work, we will focus on the other two modules in the rest of this section. 3.1 Parse Reranker We follow Collins and Koo (2005)’s discriminative reranking model to score possible parse trees of each sentence given by the Berkeley Parser. Previous research on English shows that structured perceptron (Collins, 2002) is one of the strongest machine learning algorithms for parse reranking (Collins and Duffy, 2002; Gao et al., 2007). In our system, we use the averaged perceptron algorithm to do parameter estimation. Algorithm 1 illustrates the learning procedure. The parameter vector w is initialized to (0, ..., 0). The learner processes all the instances (t is from 1 to n) in each iteration (i). If current hypothesis (w) PCTB Parser TCT Task 2.2 Task 2.1 Open A B C D C D B A Head Classifier Berkeley Parser Parse Reranker C H H H ... ... 3 4 5 6 7 8 9 for t =SHUFFLE (1, ..., m) do y∗t = arg maxy∈GENbest n (Xt) wTb(xt,y) if y∗t =� yt then w &lt;-- w+(b(xt, yt)−b(xt, y∗t )) end end wi &lt;-- w 10 end fails to </context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Collins, Michael and Nigel Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 263–270, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2005</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>31</volume>
<issue>1</issue>
<pages>25--69</pages>
<contexts>
<context position="6941" citStr="Collins and Koo, 2005" startWordPosition="1052" endWordPosition="1055">re fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), which induces subcategories from coarse-grained annotations through an expectation maximization procedure. In combination with the coarse-to-fine parsing strategy, efficient inference can be done with a cascade of grammars of different granularity. Such parsing models have reached (close to) state-of-the-art performance for many languages including Chinese and English. Another effective technique to improve parsing results is discriminative reranking (Charniak and Johnson, 2005; Collins and Koo, 2005). While the generative models compose candidate parse trees, a discriminative reranker reorders the list of candidates in favor of those trees which maximizes the properties of being a good analysis. Such extra model refines the original scores assigned by the generative model by focusing its decisions on the fine details among already “good” candidates. Due to this nature, the set of features in the reranker focus on those global (and potentially long distance) properties which are difficult to model with the generative model. Also, since it is not necessary for the reranker to generate the c</context>
<context position="9516" citStr="Collins and Koo (2005)" startWordPosition="1511" endWordPosition="1514">e of the same sentence. For example, we can check whether the boundary predictions given by the TCT parser are agreed by the PCTB parser. Since the PCTB parser is trained on a different treebank from TCT, our reranking model can be seen as a method to use a heterogenous resource. The best parse tree given by the Parse Reranker will be the result for Task 2.2; and the final output of the system will be the result for Task 2.1. Since we have already mentioned the Berkeley Parser in the related work, we will focus on the other two modules in the rest of this section. 3.1 Parse Reranker We follow Collins and Koo (2005)’s discriminative reranking model to score possible parse trees of each sentence given by the Berkeley Parser. Previous research on English shows that structured perceptron (Collins, 2002) is one of the strongest machine learning algorithms for parse reranking (Collins and Duffy, 2002; Gao et al., 2007). In our system, we use the averaged perceptron algorithm to do parameter estimation. Algorithm 1 illustrates the learning procedure. The parameter vector w is initialized to (0, ..., 0). The learner processes all the instances (t is from 1 to n) in each iteration (i). If current hypothesis (w) </context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Collins, Michael and Terry Koo. 2005. Discriminative reranking for natural language parsing. In Computational Linguistics, volume 31(1), pages 25–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>175--182</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="16594" citStr="Collins, 2000" startWordPosition="2735" endWordPosition="2736"> or semantic information. • TCT contains head indices, making head identification of each constituent an important goal of task 1. • Following the GB theory, PCTB assume there are movements, so there are empty category annotation. Because of different theoretical foundations, there are different explanations for a series of linguistic phenomena such as the usage of function word “的”. In the reranking experiments, we also use a parser trained on PCTB to provide more syntactic clues. 4.2 Setting In order to gain a representative set of training data, we use cross-validation scheme described in (Collins, 2000). The dataset is a mixture of three genres. We equally split every genre data into 10 subsets, and collect three subset of different genres as one fold of the whole data. In this way, we can divide the whole data into 10 balanced subsets. For each fold data, a complement parser is trained using all other data to produce multiple hypotheses for each sentence. This cross-validation n 1 2 5 10 20 30 40 50 F1 79.97 81.62 83.51 84.63 85.59 86.07 86.38 86.60 Table 1: Upper bound of f-score as a function of number n of n-best parses. scheme can prevent the initial model from being unrealistically “go</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Collins, Michael. 2000. Discriminative reranking for natural language parsing. In Computational Linguistics, pages 175–182. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9704" citStr="Collins, 2002" startWordPosition="1541" endWordPosition="1542">rom TCT, our reranking model can be seen as a method to use a heterogenous resource. The best parse tree given by the Parse Reranker will be the result for Task 2.2; and the final output of the system will be the result for Task 2.1. Since we have already mentioned the Berkeley Parser in the related work, we will focus on the other two modules in the rest of this section. 3.1 Parse Reranker We follow Collins and Koo (2005)’s discriminative reranking model to score possible parse trees of each sentence given by the Berkeley Parser. Previous research on English shows that structured perceptron (Collins, 2002) is one of the strongest machine learning algorithms for parse reranking (Collins and Duffy, 2002; Gao et al., 2007). In our system, we use the averaged perceptron algorithm to do parameter estimation. Algorithm 1 illustrates the learning procedure. The parameter vector w is initialized to (0, ..., 0). The learner processes all the instances (t is from 1 to n) in each iteration (i). If current hypothesis (w) PCTB Parser TCT Task 2.2 Task 2.1 Open A B C D C D B A Head Classifier Berkeley Parser Parse Reranker C H H H ... ... 3 4 5 6 7 8 9 for t =SHUFFLE (1, ..., m) do y∗t = arg maxy∈GENbest n (</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Collins, Michael. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Galen Andrew</author>
<author>Mark Johnson</author>
<author>Kristina Toutanova</author>
</authors>
<title>A comparative study of parameter estimation methods for statistical natural language processing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>824--831</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="9820" citStr="Gao et al., 2007" startWordPosition="1558" endWordPosition="1561"> the Parse Reranker will be the result for Task 2.2; and the final output of the system will be the result for Task 2.1. Since we have already mentioned the Berkeley Parser in the related work, we will focus on the other two modules in the rest of this section. 3.1 Parse Reranker We follow Collins and Koo (2005)’s discriminative reranking model to score possible parse trees of each sentence given by the Berkeley Parser. Previous research on English shows that structured perceptron (Collins, 2002) is one of the strongest machine learning algorithms for parse reranking (Collins and Duffy, 2002; Gao et al., 2007). In our system, we use the averaged perceptron algorithm to do parameter estimation. Algorithm 1 illustrates the learning procedure. The parameter vector w is initialized to (0, ..., 0). The learner processes all the instances (t is from 1 to n) in each iteration (i). If current hypothesis (w) PCTB Parser TCT Task 2.2 Task 2.1 Open A B C D C D B A Head Classifier Berkeley Parser Parse Reranker C H H H ... ... 3 4 5 6 7 8 9 for t =SHUFFLE (1, ..., m) do y∗t = arg maxy∈GENbest n (Xt) wTb(xt,y) if y∗t =� yt then w &lt;-- w+(b(xt, yt)−b(xt, y∗t )) end end wi &lt;-- w 10 end fails to predict xt, the lea</context>
</contexts>
<marker>Gao, Andrew, Johnson, Toutanova, 2007</marker>
<rawString>Gao, Jianfeng, Galen Andrew, Mark Johnson, and Kristina Toutanova. 2007. A comparative study of parameter estimation methods for statistical natural language processing. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 824–831, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLTNAACL-2007,</booktitle>
<location>Rochester, NY, USA,</location>
<contexts>
<context position="6433" citStr="Petrov and Klein, 2007" startWordPosition="983" endWordPosition="986">nk (PCTB; Xue et al. (2005)) and Tsinghua Chinese Treebank (TCT; Zhou (2004)) as examples, PCTB is annotated with a much more detailed set of phrase categories, while TCT uses a more fine-grained POS tagset. The asymmetry in the annotation information is partially due to the difference of linguistic treatment. But more importantly, it shows that both treebanks have the potential of being refined with more detailed classification, on either phrasal or word categories. One data-driven approach to derive more fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), which induces subcategories from coarse-grained annotations through an expectation maximization procedure. In combination with the coarse-to-fine parsing strategy, efficient inference can be done with a cascade of grammars of different granularity. Such parsing models have reached (close to) state-of-the-art performance for many languages including Chinese and English. Another effective technique to improve parsing results is discriminative reranking (Charniak and Johnson, 2005; Collins and Koo, 2005). While the generative models compose candidate parse trees, a discriminative reranker reord</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Petrov, S. and D. Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLTNAACL-2007, Rochester, NY, USA, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="6408" citStr="Petrov et al., 2006" startWordPosition="979" endWordPosition="982">e Penn Chinese Treebank (PCTB; Xue et al. (2005)) and Tsinghua Chinese Treebank (TCT; Zhou (2004)) as examples, PCTB is annotated with a much more detailed set of phrase categories, while TCT uses a more fine-grained POS tagset. The asymmetry in the annotation information is partially due to the difference of linguistic treatment. But more importantly, it shows that both treebanks have the potential of being refined with more detailed classification, on either phrasal or word categories. One data-driven approach to derive more fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), which induces subcategories from coarse-grained annotations through an expectation maximization procedure. In combination with the coarse-to-fine parsing strategy, efficient inference can be done with a cascade of grammars of different granularity. Such parsing models have reached (close to) state-of-the-art performance for many languages including Chinese and English. Another effective technique to improve parsing results is discriminative reranking (Charniak and Johnson, 2005; Collins and Koo, 2005). While the generative models compose candidate parse trees, a disc</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Petrov, Slav, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433–440, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Song</author>
<author>Chunyu Kit</author>
</authors>
<title>Pcfg parsing with crf tagging for head recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the CIPS-ParsEval-2009.</booktitle>
<contexts>
<context position="13595" citStr="Song and Kit, 2009" startWordPosition="2250" endWordPosition="2253">tegories are also used. Inconsist Category If a phrase is not analyzed as one phrase by the PCTB parser, the TCT category is used as a feature. Number of Consist and Inconsist phrases The two number are used as two individual featuers. We also use the ratio of the number of consist phrases and inconsist phrase (we add 0.1 to each number for smoothing), the ratio of the number of consist/inconsist phrases and the length of the current sentence. uJDE 吃 eat n v POS Tags For each word, the combination of TCT and PCTB POS tags (with or without word content) are used. 3.3 Head Classifier Following (Song and Kit, 2009), we apply a sequence tagging method to find head constituents. We suggest readers to refer to the original paper for details of the method. However, since the feature set is different, we give the discription of them in this paper. To predict whether current phrase is a head phrase of its parent, we use the same example above (Figure 2) for convenience. If we consider np as our current phrase, the following features are extracted, Rules The generative rule, vp → v + (np). Category of the Current Phrase and its Parent np, vp, and (np, vp). Bigrams and Trigrams (v, np), (np, STOP), (STOP, v, np</context>
</contexts>
<marker>Song, Kit, 2009</marker>
<rawString>Song, Yan and Chunyu Kit. 2009. Pcfg parsing with crf tagging for head recognition. In Proceedings of the CIPS-ParsEval-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The penn chinese treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="5837" citStr="Xue et al. (2005)" startWordPosition="889" endWordPosition="892">efits in parsing Chinese. Comparing with many other languages, statistical parsing for Chinese has reached early success, due to the fact that the language has relatively fixed word order and extremely poor inflectional morphology. Both facts allow the PCFG-based statistical modeling to perform well. On the other hand, the much higher ambiguity between basic word categories like nouns and verbs makes Chinese parsing interestingly different from the situation of English. The type of treebank annotations also affects the performance of the parsing models. Taking the Penn Chinese Treebank (PCTB; Xue et al. (2005)) and Tsinghua Chinese Treebank (TCT; Zhou (2004)) as examples, PCTB is annotated with a much more detailed set of phrase categories, while TCT uses a more fine-grained POS tagset. The asymmetry in the annotation information is partially due to the difference of linguistic treatment. But more importantly, it shows that both treebanks have the potential of being refined with more detailed classification, on either phrasal or word categories. One data-driven approach to derive more fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), wh</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Xue, Nianwen, Fei Xia, Fu-Dong Chiou, and Martha Palmer. 2005. The penn chinese treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
</authors>
<title>Annotation scheme for chinese treebank (in chinese).</title>
<date>2004</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="5886" citStr="Zhou (2004)" startWordPosition="898" endWordPosition="899">guages, statistical parsing for Chinese has reached early success, due to the fact that the language has relatively fixed word order and extremely poor inflectional morphology. Both facts allow the PCFG-based statistical modeling to perform well. On the other hand, the much higher ambiguity between basic word categories like nouns and verbs makes Chinese parsing interestingly different from the situation of English. The type of treebank annotations also affects the performance of the parsing models. Taking the Penn Chinese Treebank (PCTB; Xue et al. (2005)) and Tsinghua Chinese Treebank (TCT; Zhou (2004)) as examples, PCTB is annotated with a much more detailed set of phrase categories, while TCT uses a more fine-grained POS tagset. The asymmetry in the annotation information is partially due to the difference of linguistic treatment. But more importantly, it shows that both treebanks have the potential of being refined with more detailed classification, on either phrasal or word categories. One data-driven approach to derive more fine-grained annotation is the hierarchically split-merge parsing (Petrov et al., 2006; Petrov and Klein, 2007), which induces subcategories from coarse-grained ann</context>
</contexts>
<marker>Zhou, 2004</marker>
<rawString>Zhou, Qiang. 2004. Annotation scheme for chinese treebank (in chinese). Journal of Chinese Information Processing, 18(4):1–8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>