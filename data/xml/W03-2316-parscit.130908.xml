<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.993083">
Adapting Chart Realization to CCG
</title>
<author confidence="0.997984">
Michael White and Jason Baldridge
</author>
<affiliation confidence="0.9981565">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.998258">
fmwhite,jmbl@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.996654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999790466666667">
We describe a bottom-up chart re-
alization algorithm adapted for use
with Combinatory Categorial Grammar
(CCG), and show how it can be used to
efficiently realize a wide range of co-
ordination phenomena, including argu-
ment cluster coordination and gapping.
The algorithm has been implemented
as an extension to the OpenNLP open
source CCG parser. As an avenue for
future exploration, we also suggest how
the realizer could be used to simplify the
treatment of aggregation in conjunction
with higher level content planning com-
ponents.
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991633214285714">
In this paper, we describe our initial efforts to de-
velop a practical, open source realizer for Com-
binatory Categorial Grammar (CCG, Steedman
(2000b)). While CCG provides theoretically at-
tractive accounts of numerous linguistic phenom-
ena — including unique accounts of coordination
and intonation, which is of particular interest to
builders of dialog systems&apos; — its adoption by the
NLG community has been hindered by the lack of
a practical realizer. As a first step towards making
such a realizer available, we have implemented a
&apos;We are primarily targeting the realizer for use in dia-
log systems, and intend to use it in the IST project COMIC
(COnversational Multimodal Interaction with Computers),
http://www.mpI.nl/comic/.
bottom-up chart realization algorithm (Carroll et
al., 1999) adapted for use with CCG. The imple-
mentation builds upon the Java-based OpenNLP
CCG parser2 described in Baldridge (2002).
The paper is organized as follows. We provide
the rationale for our algorithm choice in P. In 9
and 0, we provide background for the realization
algorithm and the algorithm itself. In §5, we show
how the realizer handles a wide range of coordina-
tion phenomena. In §6, we provide initial evidence
that the realizer can be reasonably efficient in prac-
tice. In §7, we discuss related work and conclude
with a discussion of future directions.
</bodyText>
<sectionHeader confidence="0.994655" genericHeader="introduction">
2 Rationale
</sectionHeader>
<bodyText confidence="0.999031571428571">
Since our chart realization algorithm may not be
the most efficient algorithm one might consider
implementing, we provide the following rationale
for our choice:
Completeness The simple nature of our algo-
rithm makes it relatively straightforward to
achieve completeness;3 in contrast, it would
be more difficult to do so for all combinatory
rules with Hoffman&apos;s (1995) adaptation of se-
mantic head driven realization for CCG.
Parser reuse Since the algorithm is entirely
bottom-up, it can directly reuse the parsing-
oriented optimizations of the CCG rules de-
scribed in Baldridge (2002).
</bodyText>
<footnote confidence="0.991186666666667">
2http://opennlp.sourceforge.net/
3That is, to ensure that all derivations licensed by the
grammar can be reversed.
</footnote>
<page confidence="0.998238">
119
</page>
<bodyText confidence="0.996884444444444">
LF order independence The algorithm does not
rely on the order of conjuncts in the input log-
ical form, and thus handles this oft-discussed
aspect of the logical form equivalence prob-
lem (Shieber, 1993).
Anytime search The use of an agenda makes it
easy to control the search for possible real-
izations, and thus to run the algorithm in any-
time mode.4
</bodyText>
<sectionHeader confidence="0.999546" genericHeader="method">
3 Background
</sectionHeader>
<subsectionHeader confidence="0.997889">
3.1 Combinatory Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.99967775">
We provide here a brief overview of CCG; see
Steedman (2000b) for an extensive introduction.
A given CCG grammar is defined almost en-
tirely in terms of the entries of the lexicon, which
are (possibly complex) categories bearing stan-
dard feature information (such as tense, agree-
ment, etc.) and subcategorization information.
Some (simplified) lexical entries are given below:
</bodyText>
<listItem confidence="0.8102486">
(1) a. manl— n
b. that I— (n\n)/(5,10,...,._fi,./np)
c. Bob I— np
d. saw I— (stense=past,tforrrt=fitc\np)/np
CCG has a small set of rules which can be used
to combine categories in derivations. The two
most basic rules are forward (&gt;) and backward
(&lt;) function application:
(&gt;) X/Y Y X
(&lt;) Y X\Y X
</listItem>
<bodyText confidence="0.9933755">
CCG also employs further rules based on the com-
position (B), type-raising (T), and substitution (S)
combinators of combinatory logic. Each combina-
tor gives rise to several directionally-distinct rules;
for example, there are forward and backward rules
for both composition and type-raising:
</bodyText>
<equation confidence="0.99970375">
(&gt;B) X/Y Y/Z = X/Z
(&lt;B) Y\Z X\Y X\Z
(&gt;T) X = Y/(Y \X)
(&lt;T) X Y \ (Y/X)
</equation>
<bodyText confidence="0.996668">
These rules are crucial for building the &amp;quot;non-
standard&amp;quot; constituents for which CCG is well-
known, and which are essential for CCG&apos;s han-
dling of coordination, extraction, intonation, and
</bodyText>
<footnote confidence="0.959431">
4That is, to allow the client program to request the best
solution found so far at any time. We are currently explor-
ing strategies for ranking partial solutions based on n-gram
measures (Varges, 2001).
</footnote>
<bodyText confidence="0.999687666666667">
other phenomena. For example, CCG&apos;s rules and
the categories given in (1) lead to the following
derivation of the relative clause man that Bob saw:
</bodyText>
<equation confidence="0.9137758">
(2) man that Bob saw
(n\n)/(s/np) npT (s\np)/np
s/(s\n&gt;p)
s/np
&gt;
</equation>
<bodyText confidence="0.998446833333333">
The OpenNLP CCG system uses a multi-modal
version of CCG (Baldridge, 2002; Baldridge and
Kruijff, 2003), which has a fully universal rule
component that makes it possible to write more
efficient unification schemes for rule application
than for the original CCG framework.
</bodyText>
<subsectionHeader confidence="0.99876">
3.2 Hybrid Logic Dependency Semantics
</subsectionHeader>
<bodyText confidence="0.999926967741935">
Like other compositional grammatical frame-
works, CCG allows logical forms to be built in
parallel with the derivational process. Tradition-
ally, the A-calculus has been used to express se-
mantic interpretations, but work in other frame-
works has moved to using more flexible represen-
tations in computational implementations, such
as the MRS framework (Copestake et al., 2001)
used for HPSG. In the context of categorial gram-
mar, Kruijff (2001) proposes a framework that
utilizes hybrid logic (Blackburn, 2000) to re-
alize a dependency-based perspective on mean-
ing. Baldridge and Kruijff (2002) show how this
framework, Hybrid Logic Dependency Semantics
(HLDS), relates closely to MRS, and show how
terms of HLDS can be built compositionally with
CCG via unification. In the next section, we show
how HLDS&apos;s flexibility enables an approach to se-
mantic construction that ensures semantic mono-
tonicity, simplifies equality tests, and avoids copy-
ing in coordinate constructions.
Hybrid logic provides a language for represent-
ing relational structures that overcomes standard
modal logic&apos;s inability to directly reference states
in a model. It does so by using nominals, a new
sort of basic formula with which we can explic-
itly name states. In addition to propositions, nom-
inals are first-class citizens of the object language:
formulas can be formed using propositions, nomi-
nals, standard boolean operators, and the satisfac-
tion operator &amp;quot;@&amp;quot;. A formula ©z (p A (F) (j A q))
</bodyText>
<equation confidence="0.7765455">
&gt;B
n \n
</equation>
<page confidence="0.967583">
120
</page>
<bodyText confidence="0.999932583333333">
indicates that the formulas p and (F) ( j A g) hold at
the state named by i and that the state j is reach-
able via the modal relation F.
In HLDS, hybrid logic is used as a language for
describing discourse representation structures —
which have their own underlying semantics — as
follows. Each semantic head is associated with a
nominal that identifies its discourse referent, and
heads are connected to their dependents via de-
pendency relations, which are modeled as modal
relations. As an example, the sentence Bob saw
Gil receives the represention in (3).
</bodyText>
<equation confidence="0.4422245">
(3) e (see A (TENSE)past
A (AcT)(b A Bob) A (PAT) (g A Gil))
</equation>
<bodyText confidence="0.999832444444444">
In this example, c is a nominal that labels the pred-
ications and relations for the head see, and b and
g label those for the the Bob and Gil, respectively.
The relations ACT and PAT represent the depen-
dency roles Actor and Patient, respectively.5
By using the @ operator, hierarchical terms
such as (3) can be flattened to an equivalent
conjunction of fixed-size elementary predications
(EPs), closely related to MRS terms:
</bodyText>
<listItem confidence="0.984613">
(4) la.see A ©,(TENsE)past A Ae(ACT)b A tte(PAT)g
A AbBob A ©,Gil
</listItem>
<bodyText confidence="0.931174666666667">
As (4) shows, EPs come in three varieties: lexical
predications, (e.g. Kiesee); semantic features (e.g.
(TENSE)past); and relations, (e.g. A, AcT)b).
</bodyText>
<subsectionHeader confidence="0.998258">
3.3 Semantic Construction
</subsectionHeader>
<bodyText confidence="0.999857090909091">
To facilitate realization from HLDS terms, we
have slightly changed Baldridge and Kruijff&apos;s
(2002) approach to semantic construction to one
which uses maximally flat representations such as
(4). In our revised approach, EPs are paired with
syntactic categories in the lexicon to form signs, as
shown in (5)–(7) below. Each atomic category has
an index feature which makes a nominal available
for capturing syntactically induced dependencies;
these indices are shown as subscripts on the cate-
gory labels.
</bodyText>
<listItem confidence="0.88621075">
(5) saw H (se \np)/np, :
Aesee A 0, (TEN sfi)pastA (AcT) x A (0e (PAT) y
(6) Bob H npb CubBob
(7) Gil H np, :
</listItem>
<footnote confidence="0.5335065">
5To refrain from committing to a particular set of depen-
dency roles, relations such as ARG1, ARG2, etc. can be used.
</footnote>
<bodyText confidence="0.999650222222222">
In derivations, applications of the combinatory
rules coindex the appropriate nominals via unifi-
cation on the categories, and the EPs are then con-
joined to form the resulting interpretation. For ex-
ample, (6) can type-raise and compose with (5) to
yield (8), where has been coindexed with b, and
where the EPs have been conjoined; (8) can then
apply to (7) to yield (9), which has the same con-
junction of predications as (4).6
</bodyText>
<figure confidence="0.966867666666667">
(8) Bob saw H s„/np, :
(geseeAcQe(TENsE)pastA )e(AcT)bA©.e(13A-r)y
K_ObBob
(9) Bob saw Gil H se :
AeseeA ©, (TENsE)pastA Acr)b A ©, (PAT)g
A (c_i b Bob A A9 Gil
</figure>
<bodyText confidence="0.999282">
Since the EPs are always conjoined by the com-
binatory rules, semantic construction is guaran-
teed to be monotonic — in the sense that no se-
mantic information can be dropped during the
course of a derivation — which is an essential
property for ensuring that the realization algorithm
is complete (Copestake et al., 2001).
Another benefit of this approach to semantic
construction is that it becomes easier to perform
equality tests on signs, since the flat conjunctions
of EPs can be sorted into a canonical order and
compared in turn. Such equality tests can be used
to avoid adding duplicate entries into the chart
when there are multiple equivalent derivations for
a given sign, thereby alleviating the problem of so-
called &amp;quot;spurious&amp;quot; ambiguity (Steedman, 2000b).
A final benefit of simply conjoining EPs in
derivations is that it avoids any copying of predica-
tions in coordinate constructions. In contrast, the
approach implicit in Baldridge and Kruijff (2002)
yields duplicate predications in examples such as
Bob heard and Ted saw Gil, where the proposition
Gil appears twice (ignoring tense):
</bodyText>
<equation confidence="0.378235333333333">
(10) ©,, (hear A ACT)(bABob) A (PAT) (gAGil)
A (COORD)(e2 A see
A (ACT) (tATed) A (PAT) (gAGil)))
</equation>
<bodyText confidence="0.99992875">
As we will show in §5, by avoiding such dupli-
cate predications, the present approach to seman-
tic construction keeps the output of the parser in
line with the expected input of the realizer.
</bodyText>
<footnote confidence="0.997064">
6There is another more traditional (but less incremental)
derivation for Bob saw Gil, where saw combines first with the
object Gil before combining with the subject Bob.
</footnote>
<page confidence="0.996942">
121
</page>
<sectionHeader confidence="0.978874" genericHeader="method">
4 The Algorithm
</sectionHeader>
<subsectionHeader confidence="0.972792">
4.1 Data Structures
</subsectionHeader>
<bodyText confidence="0.999943714285714">
The input to the algorithm is a logical form en-
coded as an HLDS term. The input term is
flattened to a list of EPs, so that the extent to
which partial realizations cover the input LF can
be tracked positionally. For example, to realize
man that Bob saw, the hierarchically structured in-
put in (11) is flattened to (12):
</bodyText>
<listItem confidence="0.9872418">
(11) (man A (GENREL)(e A see A (TENSE)past
A (AcT)(b A Bob) A (PAT)x))
(12) 0 : Oxman, 1 : Ax(GENREL)e, 2 : ©see
3: (TENSE)past, 4: (Oe(AcT)b
: A(PAT)x, 6 : AbBob
</listItem>
<bodyText confidence="0.99940025">
The algorithm makes use of three principal data
structures: edges, an agenda and a chart. An edge
is just a CCG sign plus a couple of bit vectors
which record the sign&apos;s coverage of the input LF
and the sign&apos;s indices (nominals) that are syntacti-
cally available. These bit vectors make it possible
to instantly check whether two edges cover dis-
joint parts of the input LF and whether they have
any indices in common. For example, the edges
for the finite past and non-finite forms of see are
given below, with the bit vectors for the EPs and
indices shown in braces:
</bodyText>
<equation confidence="0.820158166666667">
(13) {2,3,4,5} {e,b,x}
saw H (s„\npb)/npx
©,seeA (TENsE)pastA (AcT)bACO,(PAT)x
(14) {2,4,5} {e, b,
see H (se,„0„fi„\np,)/np, :
(oesee A (0e (AcTb A (0e (PAT):E
</equation>
<bodyText confidence="0.998011222222222">
The agenda is a priority queue of edges which
manages the edges that have yet to be added to the
chart. Using the agenda makes it easy to vary the
search order by changing the edge sorting strategy.
The chart is a collection of edges that enables
a dynamic programming search for realizations.
Whereas a chart for parsing uses string positions
to track partial parses, one for realization uses an
edge&apos;s coverage vector to track partial realizations.
</bodyText>
<subsectionHeader confidence="0.995501">
4.2 Lexical Lookup
</subsectionHeader>
<bodyText confidence="0.999928714285714">
In the first phase of the algorithm, for each EP
in the flattened input LF, relevant lexical entries
are accessed according to the following indexing
scheme. Most lexical items are indexed by the
principal lexical predicate which they introduce.
However, if a lexical item (e.g. a relative pronoun)
only introduces a dependency relation or a seman-
tic feature, it is indexed by the relation or feature.
Semantically null lexical items, i.e. ones which
introduce no EPs (e g infinitival to), are not in-
dexed at all; instead, they receive special handling
in the combinatory rule phase (see step 4 in fig-
ure 1). Case marking prepositions and particles
are only considered when there is a matching fea-
ture on one of the indexed lexical items indicating
that they may be needed.
Once a lexical entry indexed by the current EP
has been accessed, instantiation is attempted. Dur-
ing instantiation, the current EP is unified first, and
then unification of the remaining EPs in the lexical
entry is attempted against the remaining EPs in the
input LF. The lexical entry is allowed to introduce
extra semantic features, enabling some limited un-
derspecification in the input LF.
For example, the predicational EP ©,see trig-
gers the lookup of the edges shown in (13) and
(14). Note that the present tense form sees is ac-
cessed as well, but instantiation fails due to its in-
compatible (TENSE) value (whereas the non-finite
form see has no (TENSE) value). The relational EP
Ax(GENREL)e triggers the lookup and instantiation
of the two edges for the relative pronoun shown
in (15) and (16) below. Similarly, the featural EP
(TENSE)past triggers the introduction of the aux-
iliary did.
</bodyText>
<equation confidence="0.5802775">
(15) {1} {e, x}
that H (or \ nr)/(s, \ npr) : COx(GENREL)e
(16) {1} {e, ,E}
that H (n, \ ri,)/(s, fi„/np,) : 0„(GENREL)e
</equation>
<subsectionHeader confidence="0.997156">
4.3 Combinatory Rules
</subsectionHeader>
<bodyText confidence="0.999793909090909">
In the second, main phase of the algorithm — at a
high level — edges are successively moved from
the agenda to the chart and combined with the
edges already on the chart, with any resulting new
edges added to the agenda, until no more combina-
tions are possible and the agenda becomes empty.
Figure 1 describes the main loop in more detail.
Continuing our example, some of the edges
generated during the combinatory rule phase are
shown in (17)–(21) below, without the bit vectors.
The edge for Bob is type-raised, yielding (17), and
</bodyText>
<page confidence="0.988396">
122
</page>
<bodyText confidence="0.788834">
Until the agenda is empty:
</bodyText>
<listItem confidence="0.940134428571428">
I. Remove the first edge from the agenda and set it to be
the current edge. If the chart contains an already de-
rived equivalent edge, skip the rest of the loop.
2. Combine the current edge with the edges already on the
chart. More specifically, for each chart edge:
(a) Check the coverage bit vectors for the current
edge and the chart edge for intersection. If they
overlap, skip the chart edge.
(b) Check the index bit vectors for intersection. If
they do not overlap, only combine the cuiTent
edge with the chart edge if the input LF con-
tains an appropriate ( PA IR E DW I T H) relation (cf.
§5 for discussion).
(c) Combine the current edge with the chart edge us-
ing all available binary combinatory rules, and
add any resulting new edges to the agenda.
3. Apply all unary combinatory rules to the current edge,
adding any resulting new edges to the agenda.
4. Combine the current edge with edges for all semanti-
cally null lexical items, as if these were chart edges.
5. Add the current edge to the chart.
</listItem>
<figureCaption confidence="0.999093">
Figure 1: Main loop
</figureCaption>
<bodyText confidence="0.999864444444444">
the edge for see (14) combines with the seman-
tically null infinitival to, yielding (18); (17) then
forward composes with both saw (13) and to see
(18), yielding (19) and (20). Since Bob to see (20)
is marked syntactically as infinitival rather than fi-
nite, the relative pronoun edge (16) will only com-
bine (via forward application) with Bob saw (19),
before combining (via backward application) with
man to yield the complete edge in (21).
</bodyText>
<figure confidence="0.9948475">
(17) Bob H si/(s, \npb) : CibBob
(18) to see H (sAnp,)/np, :
(see A (0,(ACT)t) A Ue (PAT)&amp;quot;,
(19) Bob saw H sfi.,Inp, :
©see A (0, (TENSE)past
A (0,(AC&apos;Ob A Ue(PA&apos;Or, A UbBob
(20) Bob to see H s,,,„f /np, :
©see A ),(ACT)b A ),(PAT)x A (0.bBob
(21) man that Bob saw H :
:Oxman A (0,-,(GENREL)e
A Aesee A (qie (TENSE)past
A ©,(AcT)b A ©,(PAT)x A %Bob
</figure>
<sectionHeader confidence="0.590132" genericHeader="method">
5 Coordination
</sectionHeader>
<subsectionHeader confidence="0.980727">
5.1 Sentential Coordination
</subsectionHeader>
<bodyText confidence="0.962133444444444">
CCG&apos;s flexible approach to constituency delivers
derivations for a wide variety of coordinate struc-
tures, often involving the coordination of such
&amp;quot;non-standard&amp;quot; constituents as s/n p, as in the fol-
lowing right node raising example:
(22) [Bob saw]5/np and [Ted heard]5/n p Gil.
Examples like (22) can be handled using the cate-
gory for and given in (23), where s$ schematizes
over functions into s:7
</bodyText>
<figure confidence="0.954744666666667">
(23) and H (s,Si\s,1S1)/se&gt;$1 :
©and A (die (LIST)ei A A (COORD)e2
Category (23) enables Bob saw and Ted heard to
coordinate as follows:
(24) Bob saw and Ted heard H
s,/np, :
Cieand A 0,(L1ST)ei A (ti(„ (COORD)C2
A U„ see A ... (0„ (PAT).r,
A ©,2hear A ... (PAT)x
</figure>
<bodyText confidence="0.89776825">
Category (24) can then be combined with Gil to
yield a flat conjunction of HLDS terms equivalent
to the one below (ignoring tense), which has been
collapsed into hierarchical form for readability:
</bodyText>
<figure confidence="0.9897648">
(25) ©t (and
A (LIST)(ei A see A (ACT) (m ABob) A (PAT)g
A (COOW(e2 A hear
A (ACT) (tATed) A (PAT)g)))
A (OgGil
</figure>
<bodyText confidence="0.999631333333333">
Since the present approach to semantic con-
struction does not produce duplicate EPs for Gil,
the output of the CCG parser for (22) shown in
(25) can be directly reversed by the realizer. In
contrast, the duplicate EPs seen in (10) (cf. 9.3)
would cause problems for the realizer&apos;s tracking of
input LF coverage. Indeed, the LF in (10) is per-
haps more similar to the one for the clause-level
coordination in (26) below than it is to (25):8
</bodyText>
<figure confidence="0.98764725">
(26) Bob heard Gil and Ted saw Gil F-
s: 0,(and A (LIST) (cA heard A (ACT)(bABob)
A (PAT)(giAGil) A (COORD)(e2 A see
A (AcT)(tATed) A (PAT) (g2AGil))))
</figure>
<footnote confidence="0.9943646">
7The relations (LIST) and (CooRD) encode a linked list:
(LisT) points to the first item in the list, and (CooRD) points
from one item to the next.
8Note that each use of a lexical item gives rise to a distinct
index nominal, similarly to DRT.
</footnote>
<page confidence="0.998863">
123
</page>
<bodyText confidence="0.999936666666667">
The HLDS terms in (25) and (26) show how
differences in the realizer&apos;s input logical form —
which are reminiscent of the differences between
reduced and unreduced A-terms — can be used to
control the choice of coordination options made
available by the grammar.9
</bodyText>
<subsectionHeader confidence="0.954553">
5.2 NP Coordination
</subsectionHeader>
<bodyText confidence="0.95886775">
Of the multiple possible readings involving NP co-
ordination, we will only focus on the distributive
reading here. As Moore (1989) points out, NPs
such as Ted and Gil in (27) below pose a challenge
for first-order unification–based approaches to se-
mantic construction, since the index x cannot be
unified with the referents for both Ted and Gil:10
(27) [Bob saw]5 /npx Ted and Gil.
Following (Moore, 1989), we tackle this problem
by introducing a A-binder into the semantic repre-
sentation for (27), while still eschewing the use of
A&apos;s in variable binding:
</bodyText>
<listItem confidence="0.875086333333333">
(28) ©,(and A (LisT)(t A Ted A (CooRD)(yAGil))
A (PRED)(/ A lambda A (BouNDVAR)x
A(BoDY)(eAseeA (ACT) (bABob)A(PAT)x)))
</listItem>
<bodyText confidence="0.9990105">
The HLDS term in (28) is intended to be equiv-
alent to the conjunction of the terms formed by
distributing the A-term across each member of the
list. (27) can be parsed and realized with the se-
mantics in (28) using the category (29), which
takes the two NPs and forms a type-raised NP:
</bodyText>
<figure confidence="0.41924">
(29) and H ((s.,$\(seS/np,))\np,i)/np,, :
©,and A ©6 (LisT)xl A Ax, (Co0RD)x2
A As (PRED)/ A &apos;A/lambda
A A/ (BouNDVAR)x A A/ (BoDv)e
</figure>
<subsectionHeader confidence="0.998574">
5.3 Argument Clusters and Gapping
</subsectionHeader>
<bodyText confidence="0.930957117647059">
The above approach to distributive NP coordina-
tion can be extended to handle argument clusters
— as in (30) below — without the need to invoke
otherwise unnecessary deletion operations.
(30) [Bob gave](se/np)/npx
[Tedt a dogd]svs/npd/npt) and
[Gilg a catclsvs/npanpg)
9Cf. (Prevost, 1995) for a related use of unreduced
terms in the context of representing information structural
units.
1°In the collective reading, also plausible in (27), x can
simply be unified with a set-valued referent for Ted and Gil:
with Ted or Gil, in contrast, only the distributive reading is
possible.
To handle (30), we introduce a (PAIREDwiTn) re-
lation to connect pairs of NP referents and bound
variables, in the following category for and:
</bodyText>
<equation confidence="0.714967285714286">
(31) and H ((s,$\((se$/npu)/npx))
Vs$\((s$/np„ )/npzi )))
/(s$V(s$/np„)/np„)) :
©sand A :0_(1_,Isx)x) A (0„, (PAiREDWITH)yi
A (Q., (CooRD)x2 A Ax2(PAIREDWITH)92
A A, (PRED)/ A ©,lambda A Coi (BoDY)e
A Kt) (B ouNDVAR)x A K(PAIREDWITH)y
</equation>
<bodyText confidence="0.997754705882353">
Category (31) enables (30) to be parsed into a
semantic representation analogous to (28). The
derivation of (30) requires the base NPs Tedt and
a dogs to type raise and compose together into the
category s\ (s/np,/np,), as indicated (and simi-
larly for Gilg and a cat). Reversing this derivation
during realization thus requires Tedt and a dogd
to combine, even though they have no indices in
common Since removing the index intersection
filter from the realization algorithm entirely would
let all NPs combine via type-raising and composi-
tion in all possible orders, we instead require the
indices to be in a (PAIREDWITE) relation in the input
LF in order for the NPs to combine.
To handle gapping examples like (32), a similar
category can be supplied for and, as shown in (33)
without the semantics, which remains unchanged:
</bodyText>
<listItem confidence="0.9701885">
(32) Tech received(se \npoo/np, a dogs and
[Giiq a
(33) and H (((sAnp,)\((sAnp,)/np,,))\np„,)
/(s\((s\n132)/nPy2))
</listItem>
<bodyText confidence="0.999316444444445">
Category (33) combines first with the pair of NPs
Gil a cat on the right, then successively with the
NP a dog, the transitive verb received and the
NP Ted on the left. As such, it handles gapping
without appealing to reanalysis, as in Steedman
(2000b), though at the expense of requiring and to
coordinate unlike categories, suggesting that (33)
should be viewed as a compiled-out version of
Steedman&apos;s (2000b) approach to gapping.
</bodyText>
<sectionHeader confidence="0.995926" genericHeader="method">
6 Efficiency
</sectionHeader>
<bodyText confidence="0.992469333333333">
As Moore (2002) notes, it appears that the real-
ization problem is inherently exponential in worst
case complexity unless one is willing to rely on
</bodyText>
<page confidence="0.995551">
124
</page>
<table confidence="0.841458">
First All
Avg 0.19 1.32
Max 0.98 13.0
</table>
<tableCaption confidence="0.9978495">
Table 1: Realizer Timing (in seconds)
Table 2: Realizer Timing Without Index Filter
</tableCaption>
<bodyText confidence="0.999974551020409">
the potentially arbitrary order of LF conjuncts.
In practice, as Carroll et al. (1999) explain, the
main complexity issue is the factorial number
of possible word orders that can arise when the
grammar leaves modifier order relatively uncon-
strained. Our current strategy to address this issue
is to concentrate on reliably finding good realiza-
tions in a reasonably short time span when running
the algorithm in anytime mode, rather than worry-
ing about the amount of time it might take on oc-
casion to find all possible realizations. We suggest
that this anytime focus is appropriate for practical
use in dialog systems.
To test whether our realizer&apos;s speed is in the
right ballpark for dialog applications, we have
measured its performance on a pre-existing set
of test phrases — namely all those discussed in
Baldridge (2002) — using a small but linguisti-
cally rich grammar covering heavy NP shift, non-
peripheral extraction, parasitic gaps, particle shift,
relativization, right node raising, topicalization,
and argument cluster coordination. On this test
suite, the performance is reasonably promising,
averaging under 200 ms. until the first realization
is found, on a Linux PC. Table 1 shows the aver-
age and maximum times until the first realization
is found and until all realizations are found.
Even with this small test suite, it is clear that the
index filter is essential for efficient realization. Ta-
ble 2 shows the comparable realization times with
the index filter turned off. As the table shows, the
average time until the first realization more than
doubles, and the maximum time until the first re-
alization is nearly four times worse. The expected
exponential increase in realization times (cf. 0)
can be seen in the times to find all realizations.
To increase performance, there is ample room to
make improvements to the unification algorithm.
While the index filter reduces the number of unifi-
cation operations attempted, unification still dom-
inates the realization time. The implementations
of the combinatory rules have been optimized as
described in Baldridge (2002), but unification is
otherwise naive and performs more copying than
necessary.
Employing packing and pruning strategies
could also improve performance. Currently, there
is no structure sharing among edges, and no means
to prune low ranked edges from the chart.
</bodyText>
<sectionHeader confidence="0.996264" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999538322580645">
Our approach to chart realization with CCG is
most closely related to Carroll et al. (1999),
which in turn builds upon much earlier work
cited therein, such as Kay (1996). Moore (2002)
presents a related algorithm for a broad class of
context free grammars
Compared to Carroll et al. (1999), we have
employed a similar but more straightforward ap-
proach to semantic construction than described in
Copestake et al. (2001), since we do not allow
underspecification of the logical scope of quanti-
fiers,11 and since there is no need for special treat-
ment of external arguments to handle control phe-
nomena in CCG. We also have not tried delaying
the insertion of intersective modifiers (Carroll et
al., 1999), in part because doing so would compli-
cate the use of n-gram ranking strategies.
The primary novel contribution of our approach
is showing how to efficiently realize a wide range
of coordination phenomena with CCG. In particu-
lar, we have shown how to use an index filter sen-
sitive to paired entities in the input LF in order to
handle argument cluster coordination and gapping.
In future work, we plan to take several steps
to make the realizer more practical. As already
mentioned, we are currently exploring strategies
for ranking partial solutions based on n-gram mea-
sures, and we plan to improve efficiency via en-
hancements to our unification algorithm. We are
also currently investigating techniques for han-
dling Steedman&apos;s (2000a) approach to information
</bodyText>
<table confidence="0.54216475">
&apos;10E Steedman (1999) for discussion.
First All
Avg 0.50 13.3
Max 3.84 349
</table>
<page confidence="0.996085">
125
</page>
<bodyText confidence="0.999990740740741">
structure and intonation. In addition, we plan to
bootstrap a wide coverage grammar for English
from the CCG Bank (Hockenmaier and Steedman,
2002), and to develop improved XML grammar
management tools.
Beyond these practically-oriented steps, we also
plan to investigate new techniques for coupling
CCG realization with higher level planning com-
ponents. A particularly appealing direction is to
see whether the present approach to coordina-
tion can simplify the treatment of aggregation in
higher level planning components used in con-
junction with the realizer. Since current bottom-
up approaches to aggregation such as Dalianis
(1996) and Shaw (1998) combine simple syntac-
tic phrases into more complex ones by looking for
patterns of related semantic material, they do not
fit naturally into applications where it makes sense
to group semantic material during content plan-
ning, based on intentions or information structural
considerations. In contrast, working with our re-
alizer, content planning components could specify
their aggregation decisions via distinctions made
at the level of logical form, taking advantage of
the realizer&apos;s ability to use differences in the input
LF to control the choice of coordination options
made available by the grammar.
</bodyText>
<sectionHeader confidence="0.997483" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9441836">
We would like to thank Mark Steedman, Geert-Jan Kruijff,
Johanna Moore, Jon Oberlander and Mary Ellen Foster for
helpful discussions. This work was supported in part by the
COMIC (IST-2001-32311) and ROSIE (Edinburgh-Stanford
Link R36763) projects.
</bodyText>
<sectionHeader confidence="0.994225" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999902476923077">
Jason Baldridge and Geert-Jan Kruijff. 2002. Coupling CCG
and Hybrid Logic Dependency Semantics. In Proc. of
40th Annual Meeting of the Association for Computational
Linguistics, pages 319-326.
Jason Baldridge and Geert-Jan Kruijff. 2003. Multi-Modal
Combinatory Categorial Grammar. In Proc. of 10th An-
nual Meeting of the European Association for Computa-
tional Linguistics.
Jason Baldridge. 2002. Lexically Specified Derivational
Control in Combinatory Categorial Grammar. Ph.D. the-
sis, School of Informatics, University of Edinburgh.
Patrick Blackburn. 2000. Representation, reasoning, and re-
lational structures: a hybrid logic manifesto. Logic Jour-
nal of the IGPL, 8(3):339-625.
John Carroll, Ann Copestake, Dan Flickinger, and Victor
Poznafiski. 1999. An efficient chart generator for (semi-)
lexicalist grammars. In Proc. of the 7th European Work-
shop on Natural Language Generation, pages 86-95.
Ann Copestake, Alex Lascarides, and Dan Flickinger. 2001.
An algebra for semantic construction in constraint-based
grammars. In Proc. of the 39th Annual Meeting of the
Association of Computational Linguistics, pages 132-139.
Hercules Dalianis. 1996. Concise Natural Language Gen-
eration from Formal Specifications. Ph.D. thesis, Royal
Institute of Technology, Stockholm.
Julia Hockenmaier and Mark Steedman. 2002. Acquiring
compact lexicalized grammars from a cleaner treebank. In
Proc. of the Third International Conference on Language
Resources and Evaluation.
Beryl Hoffman. 1995. Computational Analysis of the Syntax
and Interpretation of &apos;Free&apos; Word-order in Turkish. Ph.D.
thesis, University of Pennsylvania. IRCS Report 95-17.
Martin Kay. 1996. Chart generation. In Proc. of the 34th
Annual Meeting of the Association for Computational Lin-
guistics, pages 200-204.
Geert-Jan M. Kruijff. 2001. A Categorial Modal Architec-
ture of Infonnativity: Dependency Grammar Logic &amp; In-
formation Structure. Ph.D. thesis, Charles University.
Robert C. Moore. 1989. Unification-based semantic inter-
pretation. In Proc. of the 27th Annual Meeting of the As-
sociation for Computational Linguistics, pages 33-41.
Robert C. Moore. 2002. A complete, efficient sentence-
realization algorithm for unification grammar. In Proc. of
the 2nd International Natural Language Generation Con-
ference.
Scott Prevost. 1995. A Semantics of Contrast and Informa-
tion Structure for Specifying Intonation in Spoken Lan-
guage Generation. Ph.D. thesis, University of Pennsyl-
vania. IRCS TR 96-01.
James Shaw. 1998. Clause aggregation using linguistic
knowledge. In Proc. of the Ninth International Workshop
on Natural Language Generation, pages 138-148.
Stuart Shieber. 1993. The problem of logical-form equiva-
lence. Computational Linguistics, 19(1):179-190.
Mark Steedman. 1999. Quantifier Scope Alternation in
CCG. In Proc. of the 37th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 301-308.
Mark Steedman. 2000a. Information structure and
the syntax-phonology interface. Linguistic Inquiry,
31(4):649-689.
Mark Steedman. 2000b. The Syntactic Process. MIT Press.
Sebastian Varges. 2001. Instance-based natural language
generation. In Proc. of the 2nd Meeting of the North Amer-
ican Chapter of the Association for Computational Lin-
guistics, pages 1-8.
</reference>
<page confidence="0.998529">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.830163">
<title confidence="0.999584">Adapting Chart Realization to CCG</title>
<author confidence="0.999701">Michael White</author>
<author confidence="0.999701">Jason</author>
<affiliation confidence="0.9994005">School of University of</affiliation>
<email confidence="0.996426">fmwhite,jmbl@inf.ed.ac.uk</email>
<abstract confidence="0.9892706875">We describe a bottom-up chart realization algorithm adapted for use with Combinatory Categorial Grammar (CCG), and show how it can be used to efficiently realize a wide range of coordination phenomena, including argument cluster coordination and gapping. The algorithm has been implemented as an extension to the OpenNLP open source CCG parser. As an avenue for future exploration, we also suggest how the realizer could be used to simplify the treatment of aggregation in conjunction with higher level content planning components.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Geert-Jan Kruijff</author>
</authors>
<title>Coupling CCG and Hybrid Logic Dependency Semantics.</title>
<date>2002</date>
<booktitle>In Proc. of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>319--326</pages>
<contexts>
<context position="5696" citStr="Baldridge and Kruijff (2002)" startWordPosition="902" endWordPosition="905"> 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et al., 2001) used for HPSG. In the context of categorial grammar, Kruijff (2001) proposes a framework that utilizes hybrid logic (Blackburn, 2000) to realize a dependency-based perspective on meaning. Baldridge and Kruijff (2002) show how this framework, Hybrid Logic Dependency Semantics (HLDS), relates closely to MRS, and show how terms of HLDS can be built compositionally with CCG via unification. In the next section, we show how HLDS&apos;s flexibility enables an approach to semantic construction that ensures semantic monotonicity, simplifies equality tests, and avoids copying in coordinate constructions. Hybrid logic provides a language for representing relational structures that overcomes standard modal logic&apos;s inability to directly reference states in a model. It does so by using nominals, a new sort of basic formula</context>
<context position="10151" citStr="Baldridge and Kruijff (2002)" startWordPosition="1652" endWordPosition="1655">it of this approach to semantic construction is that it becomes easier to perform equality tests on signs, since the flat conjunctions of EPs can be sorted into a canonical order and compared in turn. Such equality tests can be used to avoid adding duplicate entries into the chart when there are multiple equivalent derivations for a given sign, thereby alleviating the problem of socalled &amp;quot;spurious&amp;quot; ambiguity (Steedman, 2000b). A final benefit of simply conjoining EPs in derivations is that it avoids any copying of predications in coordinate constructions. In contrast, the approach implicit in Baldridge and Kruijff (2002) yields duplicate predications in examples such as Bob heard and Ted saw Gil, where the proposition Gil appears twice (ignoring tense): (10) ©,, (hear A ACT)(bABob) A (PAT) (gAGil) A (COORD)(e2 A see A (ACT) (tATed) A (PAT) (gAGil))) As we will show in §5, by avoiding such duplicate predications, the present approach to semantic construction keeps the output of the parser in line with the expected input of the realizer. 6There is another more traditional (but less incremental) derivation for Bob saw Gil, where saw combines first with the object Gil before combining with the subject Bob. 121 4 </context>
</contexts>
<marker>Baldridge, Kruijff, 2002</marker>
<rawString>Jason Baldridge and Geert-Jan Kruijff. 2002. Coupling CCG and Hybrid Logic Dependency Semantics. In Proc. of 40th Annual Meeting of the Association for Computational Linguistics, pages 319-326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Geert-Jan Kruijff</author>
</authors>
<title>Multi-Modal Combinatory Categorial Grammar.</title>
<date>2003</date>
<booktitle>In Proc. of 10th Annual Meeting of the European Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4899" citStr="Baldridge and Kruijff, 2003" startWordPosition="780" endWordPosition="783">ich CCG is wellknown, and which are essential for CCG&apos;s handling of coordination, extraction, intonation, and 4That is, to allow the client program to request the best solution found so far at any time. We are currently exploring strategies for ranking partial solutions based on n-gram measures (Varges, 2001). other phenomena. For example, CCG&apos;s rules and the categories given in (1) lead to the following derivation of the relative clause man that Bob saw: (2) man that Bob saw (n\n)/(s/np) npT (s\np)/np s/(s\n&gt;p) s/np &gt; The OpenNLP CCG system uses a multi-modal version of CCG (Baldridge, 2002; Baldridge and Kruijff, 2003), which has a fully universal rule component that makes it possible to write more efficient unification schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et al., 2001) used for HPSG. In t</context>
</contexts>
<marker>Baldridge, Kruijff, 2003</marker>
<rawString>Jason Baldridge and Geert-Jan Kruijff. 2003. Multi-Modal Combinatory Categorial Grammar. In Proc. of 10th Annual Meeting of the European Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>Lexically Specified Derivational Control in Combinatory Categorial Grammar.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="1606" citStr="Baldridge (2002)" startWordPosition="243" endWordPosition="244">on, which is of particular interest to builders of dialog systems&apos; — its adoption by the NLG community has been hindered by the lack of a practical realizer. As a first step towards making such a realizer available, we have implemented a &apos;We are primarily targeting the realizer for use in dialog systems, and intend to use it in the IST project COMIC (COnversational Multimodal Interaction with Computers), http://www.mpI.nl/comic/. bottom-up chart realization algorithm (Carroll et al., 1999) adapted for use with CCG. The implementation builds upon the Java-based OpenNLP CCG parser2 described in Baldridge (2002). The paper is organized as follows. We provide the rationale for our algorithm choice in P. In 9 and 0, we provide background for the realization algorithm and the algorithm itself. In §5, we show how the realizer handles a wide range of coordination phenomena. In §6, we provide initial evidence that the realizer can be reasonably efficient in practice. In §7, we discuss related work and conclude with a discussion of future directions. 2 Rationale Since our chart realization algorithm may not be the most efficient algorithm one might consider implementing, we provide the following rationale f</context>
<context position="4869" citStr="Baldridge, 2002" startWordPosition="778" endWordPosition="779">nstituents for which CCG is wellknown, and which are essential for CCG&apos;s handling of coordination, extraction, intonation, and 4That is, to allow the client program to request the best solution found so far at any time. We are currently exploring strategies for ranking partial solutions based on n-gram measures (Varges, 2001). other phenomena. For example, CCG&apos;s rules and the categories given in (1) lead to the following derivation of the relative clause man that Bob saw: (2) man that Bob saw (n\n)/(s/np) npT (s\np)/np s/(s\n&gt;p) s/np &gt; The OpenNLP CCG system uses a multi-modal version of CCG (Baldridge, 2002; Baldridge and Kruijff, 2003), which has a fully universal rule component that makes it possible to write more efficient unification schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et </context>
<context position="23363" citStr="Baldridge (2002)" startWordPosition="3935" endWordPosition="3936">modifier order relatively unconstrained. Our current strategy to address this issue is to concentrate on reliably finding good realizations in a reasonably short time span when running the algorithm in anytime mode, rather than worrying about the amount of time it might take on occasion to find all possible realizations. We suggest that this anytime focus is appropriate for practical use in dialog systems. To test whether our realizer&apos;s speed is in the right ballpark for dialog applications, we have measured its performance on a pre-existing set of test phrases — namely all those discussed in Baldridge (2002) — using a small but linguistically rich grammar covering heavy NP shift, nonperipheral extraction, parasitic gaps, particle shift, relativization, right node raising, topicalization, and argument cluster coordination. On this test suite, the performance is reasonably promising, averaging under 200 ms. until the first realization is found, on a Linux PC. Table 1 shows the average and maximum times until the first realization is found and until all realizations are found. Even with this small test suite, it is clear that the index filter is essential for efficient realization. Table 2 shows the</context>
<context position="24624" citStr="Baldridge (2002)" startWordPosition="4134" endWordPosition="4135">filter turned off. As the table shows, the average time until the first realization more than doubles, and the maximum time until the first realization is nearly four times worse. The expected exponential increase in realization times (cf. 0) can be seen in the times to find all realizations. To increase performance, there is ample room to make improvements to the unification algorithm. While the index filter reduces the number of unification operations attempted, unification still dominates the realization time. The implementations of the combinatory rules have been optimized as described in Baldridge (2002), but unification is otherwise naive and performs more copying than necessary. Employing packing and pruning strategies could also improve performance. Currently, there is no structure sharing among edges, and no means to prune low ranked edges from the chart. 7 Conclusions and Future Work Our approach to chart realization with CCG is most closely related to Carroll et al. (1999), which in turn builds upon much earlier work cited therein, such as Kay (1996). Moore (2002) presents a related algorithm for a broad class of context free grammars Compared to Carroll et al. (1999), we have employed </context>
</contexts>
<marker>Baldridge, 2002</marker>
<rawString>Jason Baldridge. 2002. Lexically Specified Derivational Control in Combinatory Categorial Grammar. Ph.D. thesis, School of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
</authors>
<title>Representation, reasoning, and relational structures: a hybrid logic manifesto.</title>
<date>2000</date>
<journal>Logic Journal of the IGPL,</journal>
<pages>8--3</pages>
<contexts>
<context position="5613" citStr="Blackburn, 2000" startWordPosition="891" endWordPosition="892">ation schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et al., 2001) used for HPSG. In the context of categorial grammar, Kruijff (2001) proposes a framework that utilizes hybrid logic (Blackburn, 2000) to realize a dependency-based perspective on meaning. Baldridge and Kruijff (2002) show how this framework, Hybrid Logic Dependency Semantics (HLDS), relates closely to MRS, and show how terms of HLDS can be built compositionally with CCG via unification. In the next section, we show how HLDS&apos;s flexibility enables an approach to semantic construction that ensures semantic monotonicity, simplifies equality tests, and avoids copying in coordinate constructions. Hybrid logic provides a language for representing relational structures that overcomes standard modal logic&apos;s inability to directly ref</context>
</contexts>
<marker>Blackburn, 2000</marker>
<rawString>Patrick Blackburn. 2000. Representation, reasoning, and relational structures: a hybrid logic manifesto. Logic Journal of the IGPL, 8(3):339-625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Victor Poznafiski</author>
</authors>
<title>An efficient chart generator for (semi-) lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proc. of the 7th European Workshop on Natural Language Generation,</booktitle>
<pages>86--95</pages>
<contexts>
<context position="1484" citStr="Carroll et al., 1999" startWordPosition="222" endWordPosition="225">des theoretically attractive accounts of numerous linguistic phenomena — including unique accounts of coordination and intonation, which is of particular interest to builders of dialog systems&apos; — its adoption by the NLG community has been hindered by the lack of a practical realizer. As a first step towards making such a realizer available, we have implemented a &apos;We are primarily targeting the realizer for use in dialog systems, and intend to use it in the IST project COMIC (COnversational Multimodal Interaction with Computers), http://www.mpI.nl/comic/. bottom-up chart realization algorithm (Carroll et al., 1999) adapted for use with CCG. The implementation builds upon the Java-based OpenNLP CCG parser2 described in Baldridge (2002). The paper is organized as follows. We provide the rationale for our algorithm choice in P. In 9 and 0, we provide background for the realization algorithm and the algorithm itself. In §5, we show how the realizer handles a wide range of coordination phenomena. In §6, we provide initial evidence that the realizer can be reasonably efficient in practice. In §7, we discuss related work and conclude with a discussion of future directions. 2 Rationale Since our chart realizati</context>
<context position="22624" citStr="Carroll et al. (1999)" startWordPosition="3811" endWordPosition="3814">dles gapping without appealing to reanalysis, as in Steedman (2000b), though at the expense of requiring and to coordinate unlike categories, suggesting that (33) should be viewed as a compiled-out version of Steedman&apos;s (2000b) approach to gapping. 6 Efficiency As Moore (2002) notes, it appears that the realization problem is inherently exponential in worst case complexity unless one is willing to rely on 124 First All Avg 0.19 1.32 Max 0.98 13.0 Table 1: Realizer Timing (in seconds) Table 2: Realizer Timing Without Index Filter the potentially arbitrary order of LF conjuncts. In practice, as Carroll et al. (1999) explain, the main complexity issue is the factorial number of possible word orders that can arise when the grammar leaves modifier order relatively unconstrained. Our current strategy to address this issue is to concentrate on reliably finding good realizations in a reasonably short time span when running the algorithm in anytime mode, rather than worrying about the amount of time it might take on occasion to find all possible realizations. We suggest that this anytime focus is appropriate for practical use in dialog systems. To test whether our realizer&apos;s speed is in the right ballpark for d</context>
<context position="25006" citStr="Carroll et al. (1999)" startWordPosition="4192" endWordPosition="4195">n algorithm. While the index filter reduces the number of unification operations attempted, unification still dominates the realization time. The implementations of the combinatory rules have been optimized as described in Baldridge (2002), but unification is otherwise naive and performs more copying than necessary. Employing packing and pruning strategies could also improve performance. Currently, there is no structure sharing among edges, and no means to prune low ranked edges from the chart. 7 Conclusions and Future Work Our approach to chart realization with CCG is most closely related to Carroll et al. (1999), which in turn builds upon much earlier work cited therein, such as Kay (1996). Moore (2002) presents a related algorithm for a broad class of context free grammars Compared to Carroll et al. (1999), we have employed a similar but more straightforward approach to semantic construction than described in Copestake et al. (2001), since we do not allow underspecification of the logical scope of quantifiers,11 and since there is no need for special treatment of external arguments to handle control phenomena in CCG. We also have not tried delaying the insertion of intersective modifiers (Carroll et</context>
</contexts>
<marker>Carroll, Copestake, Flickinger, Poznafiski, 1999</marker>
<rawString>John Carroll, Ann Copestake, Dan Flickinger, and Victor Poznafiski. 1999. An efficient chart generator for (semi-) lexicalist grammars. In Proc. of the 7th European Workshop on Natural Language Generation, pages 86-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Alex Lascarides</author>
<author>Dan Flickinger</author>
</authors>
<title>An algebra for semantic construction in constraint-based grammars.</title>
<date>2001</date>
<booktitle>In Proc. of the 39th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="5479" citStr="Copestake et al., 2001" startWordPosition="868" endWordPosition="871">ldridge, 2002; Baldridge and Kruijff, 2003), which has a fully universal rule component that makes it possible to write more efficient unification schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et al., 2001) used for HPSG. In the context of categorial grammar, Kruijff (2001) proposes a framework that utilizes hybrid logic (Blackburn, 2000) to realize a dependency-based perspective on meaning. Baldridge and Kruijff (2002) show how this framework, Hybrid Logic Dependency Semantics (HLDS), relates closely to MRS, and show how terms of HLDS can be built compositionally with CCG via unification. In the next section, we show how HLDS&apos;s flexibility enables an approach to semantic construction that ensures semantic monotonicity, simplifies equality tests, and avoids copying in coordinate constructions. H</context>
<context position="9508" citStr="Copestake et al., 2001" startWordPosition="1550" endWordPosition="1553">with b, and where the EPs have been conjoined; (8) can then apply to (7) to yield (9), which has the same conjunction of predications as (4).6 (8) Bob saw H s„/np, : (geseeAcQe(TENsE)pastA )e(AcT)bA©.e(13A-r)y K_ObBob (9) Bob saw Gil H se : AeseeA ©, (TENsE)pastA Acr)b A ©, (PAT)g A (c_i b Bob A A9 Gil Since the EPs are always conjoined by the combinatory rules, semantic construction is guaranteed to be monotonic — in the sense that no semantic information can be dropped during the course of a derivation — which is an essential property for ensuring that the realization algorithm is complete (Copestake et al., 2001). Another benefit of this approach to semantic construction is that it becomes easier to perform equality tests on signs, since the flat conjunctions of EPs can be sorted into a canonical order and compared in turn. Such equality tests can be used to avoid adding duplicate entries into the chart when there are multiple equivalent derivations for a given sign, thereby alleviating the problem of socalled &amp;quot;spurious&amp;quot; ambiguity (Steedman, 2000b). A final benefit of simply conjoining EPs in derivations is that it avoids any copying of predications in coordinate constructions. In contrast, the approa</context>
<context position="25334" citStr="Copestake et al. (2001)" startWordPosition="4246" endWordPosition="4249">g packing and pruning strategies could also improve performance. Currently, there is no structure sharing among edges, and no means to prune low ranked edges from the chart. 7 Conclusions and Future Work Our approach to chart realization with CCG is most closely related to Carroll et al. (1999), which in turn builds upon much earlier work cited therein, such as Kay (1996). Moore (2002) presents a related algorithm for a broad class of context free grammars Compared to Carroll et al. (1999), we have employed a similar but more straightforward approach to semantic construction than described in Copestake et al. (2001), since we do not allow underspecification of the logical scope of quantifiers,11 and since there is no need for special treatment of external arguments to handle control phenomena in CCG. We also have not tried delaying the insertion of intersective modifiers (Carroll et al., 1999), in part because doing so would complicate the use of n-gram ranking strategies. The primary novel contribution of our approach is showing how to efficiently realize a wide range of coordination phenomena with CCG. In particular, we have shown how to use an index filter sensitive to paired entities in the input LF </context>
</contexts>
<marker>Copestake, Lascarides, Flickinger, 2001</marker>
<rawString>Ann Copestake, Alex Lascarides, and Dan Flickinger. 2001. An algebra for semantic construction in constraint-based grammars. In Proc. of the 39th Annual Meeting of the Association of Computational Linguistics, pages 132-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
</authors>
<title>Concise Natural Language Generation from Formal Specifications.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Royal Institute of Technology,</institution>
<location>Stockholm.</location>
<contexts>
<context position="27090" citStr="Dalianis (1996)" startWordPosition="4529" endWordPosition="4530">nation. In addition, we plan to bootstrap a wide coverage grammar for English from the CCG Bank (Hockenmaier and Steedman, 2002), and to develop improved XML grammar management tools. Beyond these practically-oriented steps, we also plan to investigate new techniques for coupling CCG realization with higher level planning components. A particularly appealing direction is to see whether the present approach to coordination can simplify the treatment of aggregation in higher level planning components used in conjunction with the realizer. Since current bottomup approaches to aggregation such as Dalianis (1996) and Shaw (1998) combine simple syntactic phrases into more complex ones by looking for patterns of related semantic material, they do not fit naturally into applications where it makes sense to group semantic material during content planning, based on intentions or information structural considerations. In contrast, working with our realizer, content planning components could specify their aggregation decisions via distinctions made at the level of logical form, taking advantage of the realizer&apos;s ability to use differences in the input LF to control the choice of coordination options made ava</context>
</contexts>
<marker>Dalianis, 1996</marker>
<rawString>Hercules Dalianis. 1996. Concise Natural Language Generation from Formal Specifications. Ph.D. thesis, Royal Institute of Technology, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Acquiring compact lexicalized grammars from a cleaner treebank.</title>
<date>2002</date>
<booktitle>In Proc. of the Third International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="26603" citStr="Hockenmaier and Steedman, 2002" startWordPosition="4455" endWordPosition="4458">ordination and gapping. In future work, we plan to take several steps to make the realizer more practical. As already mentioned, we are currently exploring strategies for ranking partial solutions based on n-gram measures, and we plan to improve efficiency via enhancements to our unification algorithm. We are also currently investigating techniques for handling Steedman&apos;s (2000a) approach to information &apos;10E Steedman (1999) for discussion. First All Avg 0.50 13.3 Max 3.84 349 125 structure and intonation. In addition, we plan to bootstrap a wide coverage grammar for English from the CCG Bank (Hockenmaier and Steedman, 2002), and to develop improved XML grammar management tools. Beyond these practically-oriented steps, we also plan to investigate new techniques for coupling CCG realization with higher level planning components. A particularly appealing direction is to see whether the present approach to coordination can simplify the treatment of aggregation in higher level planning components used in conjunction with the realizer. Since current bottomup approaches to aggregation such as Dalianis (1996) and Shaw (1998) combine simple syntactic phrases into more complex ones by looking for patterns of related seman</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002. Acquiring compact lexicalized grammars from a cleaner treebank. In Proc. of the Third International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beryl Hoffman</author>
</authors>
<title>Computational Analysis of the Syntax and Interpretation of &apos;Free&apos; Word-order in Turkish.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<marker>Hoffman, 1995</marker>
<rawString>Beryl Hoffman. 1995. Computational Analysis of the Syntax and Interpretation of &apos;Free&apos; Word-order in Turkish. Ph.D. thesis, University of Pennsylvania. IRCS Report 95-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Chart generation.</title>
<date>1996</date>
<booktitle>In Proc. of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>200--204</pages>
<contexts>
<context position="25085" citStr="Kay (1996)" startWordPosition="4208" endWordPosition="4209">, unification still dominates the realization time. The implementations of the combinatory rules have been optimized as described in Baldridge (2002), but unification is otherwise naive and performs more copying than necessary. Employing packing and pruning strategies could also improve performance. Currently, there is no structure sharing among edges, and no means to prune low ranked edges from the chart. 7 Conclusions and Future Work Our approach to chart realization with CCG is most closely related to Carroll et al. (1999), which in turn builds upon much earlier work cited therein, such as Kay (1996). Moore (2002) presents a related algorithm for a broad class of context free grammars Compared to Carroll et al. (1999), we have employed a similar but more straightforward approach to semantic construction than described in Copestake et al. (2001), since we do not allow underspecification of the logical scope of quantifiers,11 and since there is no need for special treatment of external arguments to handle control phenomena in CCG. We also have not tried delaying the insertion of intersective modifiers (Carroll et al., 1999), in part because doing so would complicate the use of n-gram rankin</context>
</contexts>
<marker>Kay, 1996</marker>
<rawString>Martin Kay. 1996. Chart generation. In Proc. of the 34th Annual Meeting of the Association for Computational Linguistics, pages 200-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan M Kruijff</author>
</authors>
<title>A Categorial Modal Architecture of Infonnativity: Dependency Grammar Logic &amp; Information Structure.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Charles University.</institution>
<contexts>
<context position="5547" citStr="Kruijff (2001)" startWordPosition="882" endWordPosition="883"> component that makes it possible to write more efficient unification schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms to be built in parallel with the derivational process. Traditionally, the A-calculus has been used to express semantic interpretations, but work in other frameworks has moved to using more flexible representations in computational implementations, such as the MRS framework (Copestake et al., 2001) used for HPSG. In the context of categorial grammar, Kruijff (2001) proposes a framework that utilizes hybrid logic (Blackburn, 2000) to realize a dependency-based perspective on meaning. Baldridge and Kruijff (2002) show how this framework, Hybrid Logic Dependency Semantics (HLDS), relates closely to MRS, and show how terms of HLDS can be built compositionally with CCG via unification. In the next section, we show how HLDS&apos;s flexibility enables an approach to semantic construction that ensures semantic monotonicity, simplifies equality tests, and avoids copying in coordinate constructions. Hybrid logic provides a language for representing relational structur</context>
</contexts>
<marker>Kruijff, 2001</marker>
<rawString>Geert-Jan M. Kruijff. 2001. A Categorial Modal Architecture of Infonnativity: Dependency Grammar Logic &amp; Information Structure. Ph.D. thesis, Charles University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Unification-based semantic interpretation.</title>
<date>1989</date>
<booktitle>In Proc. of the 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>33--41</pages>
<contexts>
<context position="18921" citStr="Moore (1989)" startWordPosition="3204" endWordPosition="3205">ed list: (LisT) points to the first item in the list, and (CooRD) points from one item to the next. 8Note that each use of a lexical item gives rise to a distinct index nominal, similarly to DRT. 123 The HLDS terms in (25) and (26) show how differences in the realizer&apos;s input logical form — which are reminiscent of the differences between reduced and unreduced A-terms — can be used to control the choice of coordination options made available by the grammar.9 5.2 NP Coordination Of the multiple possible readings involving NP coordination, we will only focus on the distributive reading here. As Moore (1989) points out, NPs such as Ted and Gil in (27) below pose a challenge for first-order unification–based approaches to semantic construction, since the index x cannot be unified with the referents for both Ted and Gil:10 (27) [Bob saw]5 /npx Ted and Gil. Following (Moore, 1989), we tackle this problem by introducing a A-binder into the semantic representation for (27), while still eschewing the use of A&apos;s in variable binding: (28) ©,(and A (LisT)(t A Ted A (CooRD)(yAGil)) A (PRED)(/ A lambda A (BouNDVAR)x A(BoDY)(eAseeA (ACT) (bABob)A(PAT)x))) The HLDS term in (28) is intended to be equivalent to</context>
</contexts>
<marker>Moore, 1989</marker>
<rawString>Robert C. Moore. 1989. Unification-based semantic interpretation. In Proc. of the 27th Annual Meeting of the Association for Computational Linguistics, pages 33-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A complete, efficient sentencerealization algorithm for unification grammar.</title>
<date>2002</date>
<booktitle>In Proc. of the 2nd International Natural Language Generation Conference.</booktitle>
<contexts>
<context position="22280" citStr="Moore (2002)" startWordPosition="3755" endWordPosition="3756"> semantics, which remains unchanged: (32) Tech received(se \npoo/np, a dogs and [Giiq a (33) and H (((sAnp,)\((sAnp,)/np,,))\np„,) /(s\((s\n132)/nPy2)) Category (33) combines first with the pair of NPs Gil a cat on the right, then successively with the NP a dog, the transitive verb received and the NP Ted on the left. As such, it handles gapping without appealing to reanalysis, as in Steedman (2000b), though at the expense of requiring and to coordinate unlike categories, suggesting that (33) should be viewed as a compiled-out version of Steedman&apos;s (2000b) approach to gapping. 6 Efficiency As Moore (2002) notes, it appears that the realization problem is inherently exponential in worst case complexity unless one is willing to rely on 124 First All Avg 0.19 1.32 Max 0.98 13.0 Table 1: Realizer Timing (in seconds) Table 2: Realizer Timing Without Index Filter the potentially arbitrary order of LF conjuncts. In practice, as Carroll et al. (1999) explain, the main complexity issue is the factorial number of possible word orders that can arise when the grammar leaves modifier order relatively unconstrained. Our current strategy to address this issue is to concentrate on reliably finding good realiz</context>
<context position="25099" citStr="Moore (2002)" startWordPosition="4210" endWordPosition="4211">n still dominates the realization time. The implementations of the combinatory rules have been optimized as described in Baldridge (2002), but unification is otherwise naive and performs more copying than necessary. Employing packing and pruning strategies could also improve performance. Currently, there is no structure sharing among edges, and no means to prune low ranked edges from the chart. 7 Conclusions and Future Work Our approach to chart realization with CCG is most closely related to Carroll et al. (1999), which in turn builds upon much earlier work cited therein, such as Kay (1996). Moore (2002) presents a related algorithm for a broad class of context free grammars Compared to Carroll et al. (1999), we have employed a similar but more straightforward approach to semantic construction than described in Copestake et al. (2001), since we do not allow underspecification of the logical scope of quantifiers,11 and since there is no need for special treatment of external arguments to handle control phenomena in CCG. We also have not tried delaying the insertion of intersective modifiers (Carroll et al., 1999), in part because doing so would complicate the use of n-gram ranking strategies. </context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>Robert C. Moore. 2002. A complete, efficient sentencerealization algorithm for unification grammar. In Proc. of the 2nd International Natural Language Generation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Prevost</author>
</authors>
<title>A Semantics of Contrast and Information Structure for Specifying Intonation in Spoken Language Generation.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="20208" citStr="Prevost, 1995" startWordPosition="3418" endWordPosition="3419">ch member of the list. (27) can be parsed and realized with the semantics in (28) using the category (29), which takes the two NPs and forms a type-raised NP: (29) and H ((s.,$\(seS/np,))\np,i)/np,, : ©,and A ©6 (LisT)xl A Ax, (Co0RD)x2 A As (PRED)/ A &apos;A/lambda A A/ (BouNDVAR)x A A/ (BoDv)e 5.3 Argument Clusters and Gapping The above approach to distributive NP coordination can be extended to handle argument clusters — as in (30) below — without the need to invoke otherwise unnecessary deletion operations. (30) [Bob gave](se/np)/npx [Tedt a dogd]svs/npd/npt) and [Gilg a catclsvs/npanpg) 9Cf. (Prevost, 1995) for a related use of unreduced terms in the context of representing information structural units. 1°In the collective reading, also plausible in (27), x can simply be unified with a set-valued referent for Ted and Gil: with Ted or Gil, in contrast, only the distributive reading is possible. To handle (30), we introduce a (PAIREDwiTn) relation to connect pairs of NP referents and bound variables, in the following category for and: (31) and H ((s,$\((se$/npu)/npx)) Vs$\((s$/np„ )/npzi ))) /(s$V(s$/np„)/np„)) : ©sand A :0_(1_,Isx)x) A (0„, (PAiREDWITH)yi A (Q., (CooRD)x2 A Ax2(PAIREDWITH)92 A A,</context>
</contexts>
<marker>Prevost, 1995</marker>
<rawString>Scott Prevost. 1995. A Semantics of Contrast and Information Structure for Specifying Intonation in Spoken Language Generation. Ph.D. thesis, University of Pennsylvania. IRCS TR 96-01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Clause aggregation using linguistic knowledge.</title>
<date>1998</date>
<booktitle>In Proc. of the Ninth International Workshop on Natural Language Generation,</booktitle>
<pages>138--148</pages>
<contexts>
<context position="27106" citStr="Shaw (1998)" startWordPosition="4532" endWordPosition="4533"> we plan to bootstrap a wide coverage grammar for English from the CCG Bank (Hockenmaier and Steedman, 2002), and to develop improved XML grammar management tools. Beyond these practically-oriented steps, we also plan to investigate new techniques for coupling CCG realization with higher level planning components. A particularly appealing direction is to see whether the present approach to coordination can simplify the treatment of aggregation in higher level planning components used in conjunction with the realizer. Since current bottomup approaches to aggregation such as Dalianis (1996) and Shaw (1998) combine simple syntactic phrases into more complex ones by looking for patterns of related semantic material, they do not fit naturally into applications where it makes sense to group semantic material during content planning, based on intentions or information structural considerations. In contrast, working with our realizer, content planning components could specify their aggregation decisions via distinctions made at the level of logical form, taking advantage of the realizer&apos;s ability to use differences in the input LF to control the choice of coordination options made available by the gr</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. 1998. Clause aggregation using linguistic knowledge. In Proc. of the Ninth International Workshop on Natural Language Generation, pages 138-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>The problem of logical-form equivalence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="2964" citStr="Shieber, 1993" startWordPosition="461" endWordPosition="462">ld be more difficult to do so for all combinatory rules with Hoffman&apos;s (1995) adaptation of semantic head driven realization for CCG. Parser reuse Since the algorithm is entirely bottom-up, it can directly reuse the parsingoriented optimizations of the CCG rules described in Baldridge (2002). 2http://opennlp.sourceforge.net/ 3That is, to ensure that all derivations licensed by the grammar can be reversed. 119 LF order independence The algorithm does not rely on the order of conjuncts in the input logical form, and thus handles this oft-discussed aspect of the logical form equivalence problem (Shieber, 1993). Anytime search The use of an agenda makes it easy to control the search for possible realizations, and thus to run the algorithm in anytime mode.4 3 Background 3.1 Combinatory Categorial Grammar We provide here a brief overview of CCG; see Steedman (2000b) for an extensive introduction. A given CCG grammar is defined almost entirely in terms of the entries of the lexicon, which are (possibly complex) categories bearing standard feature information (such as tense, agreement, etc.) and subcategorization information. Some (simplified) lexical entries are given below: (1) a. manl— n b. that I— (</context>
</contexts>
<marker>Shieber, 1993</marker>
<rawString>Stuart Shieber. 1993. The problem of logical-form equivalence. Computational Linguistics, 19(1):179-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Quantifier Scope Alternation in CCG.</title>
<date>1999</date>
<booktitle>In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>301--308</pages>
<contexts>
<context position="26399" citStr="Steedman (1999)" startWordPosition="4423" endWordPosition="4424">a wide range of coordination phenomena with CCG. In particular, we have shown how to use an index filter sensitive to paired entities in the input LF in order to handle argument cluster coordination and gapping. In future work, we plan to take several steps to make the realizer more practical. As already mentioned, we are currently exploring strategies for ranking partial solutions based on n-gram measures, and we plan to improve efficiency via enhancements to our unification algorithm. We are also currently investigating techniques for handling Steedman&apos;s (2000a) approach to information &apos;10E Steedman (1999) for discussion. First All Avg 0.50 13.3 Max 3.84 349 125 structure and intonation. In addition, we plan to bootstrap a wide coverage grammar for English from the CCG Bank (Hockenmaier and Steedman, 2002), and to develop improved XML grammar management tools. Beyond these practically-oriented steps, we also plan to investigate new techniques for coupling CCG realization with higher level planning components. A particularly appealing direction is to see whether the present approach to coordination can simplify the treatment of aggregation in higher level planning components used in conjunction </context>
</contexts>
<marker>Steedman, 1999</marker>
<rawString>Mark Steedman. 1999. Quantifier Scope Alternation in CCG. In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics, pages 301-308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Information structure and the syntax-phonology interface. Linguistic Inquiry,</title>
<date>2000</date>
<pages>31--4</pages>
<contexts>
<context position="843" citStr="Steedman (2000" startWordPosition="127" endWordPosition="128">tory Categorial Grammar (CCG), and show how it can be used to efficiently realize a wide range of coordination phenomena, including argument cluster coordination and gapping. The algorithm has been implemented as an extension to the OpenNLP open source CCG parser. As an avenue for future exploration, we also suggest how the realizer could be used to simplify the treatment of aggregation in conjunction with higher level content planning components. 1 Introduction In this paper, we describe our initial efforts to develop a practical, open source realizer for Combinatory Categorial Grammar (CCG, Steedman (2000b)). While CCG provides theoretically attractive accounts of numerous linguistic phenomena — including unique accounts of coordination and intonation, which is of particular interest to builders of dialog systems&apos; — its adoption by the NLG community has been hindered by the lack of a practical realizer. As a first step towards making such a realizer available, we have implemented a &apos;We are primarily targeting the realizer for use in dialog systems, and intend to use it in the IST project COMIC (COnversational Multimodal Interaction with Computers), http://www.mpI.nl/comic/. bottom-up chart rea</context>
<context position="3220" citStr="Steedman (2000" startWordPosition="506" endWordPosition="507"> rules described in Baldridge (2002). 2http://opennlp.sourceforge.net/ 3That is, to ensure that all derivations licensed by the grammar can be reversed. 119 LF order independence The algorithm does not rely on the order of conjuncts in the input logical form, and thus handles this oft-discussed aspect of the logical form equivalence problem (Shieber, 1993). Anytime search The use of an agenda makes it easy to control the search for possible realizations, and thus to run the algorithm in anytime mode.4 3 Background 3.1 Combinatory Categorial Grammar We provide here a brief overview of CCG; see Steedman (2000b) for an extensive introduction. A given CCG grammar is defined almost entirely in terms of the entries of the lexicon, which are (possibly complex) categories bearing standard feature information (such as tense, agreement, etc.) and subcategorization information. Some (simplified) lexical entries are given below: (1) a. manl— n b. that I— (n\n)/(5,10,...,._fi,./np) c. Bob I— np d. saw I— (stense=past,tforrrt=fitc\np)/np CCG has a small set of rules which can be used to combine categories in derivations. The two most basic rules are forward (&gt;) and backward (&lt;) function application: (&gt;) X/Y Y</context>
<context position="9950" citStr="Steedman, 2000" startWordPosition="1623" endWordPosition="1624">formation can be dropped during the course of a derivation — which is an essential property for ensuring that the realization algorithm is complete (Copestake et al., 2001). Another benefit of this approach to semantic construction is that it becomes easier to perform equality tests on signs, since the flat conjunctions of EPs can be sorted into a canonical order and compared in turn. Such equality tests can be used to avoid adding duplicate entries into the chart when there are multiple equivalent derivations for a given sign, thereby alleviating the problem of socalled &amp;quot;spurious&amp;quot; ambiguity (Steedman, 2000b). A final benefit of simply conjoining EPs in derivations is that it avoids any copying of predications in coordinate constructions. In contrast, the approach implicit in Baldridge and Kruijff (2002) yields duplicate predications in examples such as Bob heard and Ted saw Gil, where the proposition Gil appears twice (ignoring tense): (10) ©,, (hear A ACT)(bABob) A (PAT) (gAGil) A (COORD)(e2 A see A (ACT) (tATed) A (PAT) (gAGil))) As we will show in §5, by avoiding such duplicate predications, the present approach to semantic construction keeps the output of the parser in line with the expecte</context>
<context position="22069" citStr="Steedman (2000" startWordPosition="3723" endWordPosition="3724"> require the indices to be in a (PAIREDWITE) relation in the input LF in order for the NPs to combine. To handle gapping examples like (32), a similar category can be supplied for and, as shown in (33) without the semantics, which remains unchanged: (32) Tech received(se \npoo/np, a dogs and [Giiq a (33) and H (((sAnp,)\((sAnp,)/np,,))\np„,) /(s\((s\n132)/nPy2)) Category (33) combines first with the pair of NPs Gil a cat on the right, then successively with the NP a dog, the transitive verb received and the NP Ted on the left. As such, it handles gapping without appealing to reanalysis, as in Steedman (2000b), though at the expense of requiring and to coordinate unlike categories, suggesting that (33) should be viewed as a compiled-out version of Steedman&apos;s (2000b) approach to gapping. 6 Efficiency As Moore (2002) notes, it appears that the realization problem is inherently exponential in worst case complexity unless one is willing to rely on 124 First All Avg 0.19 1.32 Max 0.98 13.0 Table 1: Realizer Timing (in seconds) Table 2: Realizer Timing Without Index Filter the potentially arbitrary order of LF conjuncts. In practice, as Carroll et al. (1999) explain, the main complexity issue is the fa</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000a. Information structure and the syntax-phonology interface. Linguistic Inquiry, 31(4):649-689.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="843" citStr="Steedman (2000" startWordPosition="127" endWordPosition="128">tory Categorial Grammar (CCG), and show how it can be used to efficiently realize a wide range of coordination phenomena, including argument cluster coordination and gapping. The algorithm has been implemented as an extension to the OpenNLP open source CCG parser. As an avenue for future exploration, we also suggest how the realizer could be used to simplify the treatment of aggregation in conjunction with higher level content planning components. 1 Introduction In this paper, we describe our initial efforts to develop a practical, open source realizer for Combinatory Categorial Grammar (CCG, Steedman (2000b)). While CCG provides theoretically attractive accounts of numerous linguistic phenomena — including unique accounts of coordination and intonation, which is of particular interest to builders of dialog systems&apos; — its adoption by the NLG community has been hindered by the lack of a practical realizer. As a first step towards making such a realizer available, we have implemented a &apos;We are primarily targeting the realizer for use in dialog systems, and intend to use it in the IST project COMIC (COnversational Multimodal Interaction with Computers), http://www.mpI.nl/comic/. bottom-up chart rea</context>
<context position="3220" citStr="Steedman (2000" startWordPosition="506" endWordPosition="507"> rules described in Baldridge (2002). 2http://opennlp.sourceforge.net/ 3That is, to ensure that all derivations licensed by the grammar can be reversed. 119 LF order independence The algorithm does not rely on the order of conjuncts in the input logical form, and thus handles this oft-discussed aspect of the logical form equivalence problem (Shieber, 1993). Anytime search The use of an agenda makes it easy to control the search for possible realizations, and thus to run the algorithm in anytime mode.4 3 Background 3.1 Combinatory Categorial Grammar We provide here a brief overview of CCG; see Steedman (2000b) for an extensive introduction. A given CCG grammar is defined almost entirely in terms of the entries of the lexicon, which are (possibly complex) categories bearing standard feature information (such as tense, agreement, etc.) and subcategorization information. Some (simplified) lexical entries are given below: (1) a. manl— n b. that I— (n\n)/(5,10,...,._fi,./np) c. Bob I— np d. saw I— (stense=past,tforrrt=fitc\np)/np CCG has a small set of rules which can be used to combine categories in derivations. The two most basic rules are forward (&gt;) and backward (&lt;) function application: (&gt;) X/Y Y</context>
<context position="9950" citStr="Steedman, 2000" startWordPosition="1623" endWordPosition="1624">formation can be dropped during the course of a derivation — which is an essential property for ensuring that the realization algorithm is complete (Copestake et al., 2001). Another benefit of this approach to semantic construction is that it becomes easier to perform equality tests on signs, since the flat conjunctions of EPs can be sorted into a canonical order and compared in turn. Such equality tests can be used to avoid adding duplicate entries into the chart when there are multiple equivalent derivations for a given sign, thereby alleviating the problem of socalled &amp;quot;spurious&amp;quot; ambiguity (Steedman, 2000b). A final benefit of simply conjoining EPs in derivations is that it avoids any copying of predications in coordinate constructions. In contrast, the approach implicit in Baldridge and Kruijff (2002) yields duplicate predications in examples such as Bob heard and Ted saw Gil, where the proposition Gil appears twice (ignoring tense): (10) ©,, (hear A ACT)(bABob) A (PAT) (gAGil) A (COORD)(e2 A see A (ACT) (tATed) A (PAT) (gAGil))) As we will show in §5, by avoiding such duplicate predications, the present approach to semantic construction keeps the output of the parser in line with the expecte</context>
<context position="22069" citStr="Steedman (2000" startWordPosition="3723" endWordPosition="3724"> require the indices to be in a (PAIREDWITE) relation in the input LF in order for the NPs to combine. To handle gapping examples like (32), a similar category can be supplied for and, as shown in (33) without the semantics, which remains unchanged: (32) Tech received(se \npoo/np, a dogs and [Giiq a (33) and H (((sAnp,)\((sAnp,)/np,,))\np„,) /(s\((s\n132)/nPy2)) Category (33) combines first with the pair of NPs Gil a cat on the right, then successively with the NP a dog, the transitive verb received and the NP Ted on the left. As such, it handles gapping without appealing to reanalysis, as in Steedman (2000b), though at the expense of requiring and to coordinate unlike categories, suggesting that (33) should be viewed as a compiled-out version of Steedman&apos;s (2000b) approach to gapping. 6 Efficiency As Moore (2002) notes, it appears that the realization problem is inherently exponential in worst case complexity unless one is willing to rely on 124 First All Avg 0.19 1.32 Max 0.98 13.0 Table 1: Realizer Timing (in seconds) Table 2: Realizer Timing Without Index Filter the potentially arbitrary order of LF conjuncts. In practice, as Carroll et al. (1999) explain, the main complexity issue is the fa</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000b. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Varges</author>
</authors>
<title>Instance-based natural language generation.</title>
<date>2001</date>
<booktitle>In Proc. of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="4581" citStr="Varges, 2001" startWordPosition="730" endWordPosition="731"> Each combinator gives rise to several directionally-distinct rules; for example, there are forward and backward rules for both composition and type-raising: (&gt;B) X/Y Y/Z = X/Z (&lt;B) Y\Z X\Y X\Z (&gt;T) X = Y/(Y \X) (&lt;T) X Y \ (Y/X) These rules are crucial for building the &amp;quot;nonstandard&amp;quot; constituents for which CCG is wellknown, and which are essential for CCG&apos;s handling of coordination, extraction, intonation, and 4That is, to allow the client program to request the best solution found so far at any time. We are currently exploring strategies for ranking partial solutions based on n-gram measures (Varges, 2001). other phenomena. For example, CCG&apos;s rules and the categories given in (1) lead to the following derivation of the relative clause man that Bob saw: (2) man that Bob saw (n\n)/(s/np) npT (s\np)/np s/(s\n&gt;p) s/np &gt; The OpenNLP CCG system uses a multi-modal version of CCG (Baldridge, 2002; Baldridge and Kruijff, 2003), which has a fully universal rule component that makes it possible to write more efficient unification schemes for rule application than for the original CCG framework. 3.2 Hybrid Logic Dependency Semantics Like other compositional grammatical frameworks, CCG allows logical forms </context>
</contexts>
<marker>Varges, 2001</marker>
<rawString>Sebastian Varges. 2001. Instance-based natural language generation. In Proc. of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics, pages 1-8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>