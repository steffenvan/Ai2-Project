<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000800">
<title confidence="0.989771">
Building NLP resources for Dzongkha:
A Tagset and A Tagged Corpus
Chungku Chungku, Jurmey Rabgay
</title>
<author confidence="0.904633">
Research Division
</author>
<affiliation confidence="0.985611">
Department of Information Technology
</affiliation>
<address confidence="0.594186">
&amp; Telecom
</address>
<email confidence="0.983634">
{chungku,jrabgay}@dit.gov.bt
</email>
<author confidence="0.51065">
Gertrud Faaß
</author>
<affiliation confidence="0.664319">
Institute für Maschinelle
Sprachverarbeitung(NLP processing),
University of Stuttgart
</affiliation>
<email confidence="0.986439">
faasz@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.993654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998863">
This paper describes the application of
probabilistic part of speech taggers to
the Dzongkha language. A tag set
containing 66 tags is designed, which is
based on the Penn Treebank1. A
training corpus of 40,247 tokens is
utilized to train the model. Using the
lexicon extracted from the training
corpus and lexicon from the available
word list, we used two statistical
taggers for comparison reasons. The
best result achieved was 93.1%
accuracy in a 10-fold cross validation
on the training set. The winning tagger
was thereafter applied to annotate a
570,247 token corpus.
</bodyText>
<sectionHeader confidence="0.999094" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999527">
Dzongkha is the national language of Bhutan.
Bhutan has only begun recently applying
Natural Language Processing (henceforth NLP)
methodologies and tools. However, Dzongkha
computing is currently progressing rapidly.
Part of speech (henceforth POS) tagging means
annotating each word with their respective POS
label according to its definition and context.
Such annotation generates a description of the
text on a meta-level, i.e. a representation of
linguistic units on the basis of their properties.
This POS-level provides significant information
usable by further linguistic research, may it be
of the morphological, syntactic or semantic
</bodyText>
<footnote confidence="0.552386">
1 [http://www.cis.upenn.edu/~treebank/]
</footnote>
<bodyText confidence="0.99957175">
kind. Producing such enriched data is proven to
be useful especially when designing NLP
representations of higher levels of
representation, e.g. syntactic parses.
Our project is designed to annotate Dzongkha
cyclopedia text with parts of speech using a
probabilistic tagger. This means that a set of
tags is to be developed and applied manually to
parts of these texts creating training data.
Probabilistic taggers can then be applied to
annotate other texts with their parts of speech
automatically. In this paper, we make use of two
such taggers and report on their results.
At present, our POS tagged data is already in
use in projects concerning Dzongkha Text to
Speech (TTS) processing, further tests on word
segmentation (see current state below) and in
corpus-linguistic research. Future work entails
its utilization for higher-level NLP tasks such as
parsing, building parallel corpora, research on
semantics, machine translation, and many more.
Sections 2 and 3 of this paper describe the
Dzongkha script and the challenges in
Dzongkha, section 4 presents our resources,
tagset and corpus. Section 5 describes tagging
and validation processes and reports on their
results. Section 6 concludes and discusses future
work.
</bodyText>
<sectionHeader confidence="0.78888" genericHeader="introduction">
2 The Dzongkha Language
</sectionHeader>
<bodyText confidence="0.999591666666667">
Dzongkha is recognized as the national and
official language of Bhutan. It is categorized as
a Sino-Tibetan Language and said to have
derived from the classical Tibetan or choka:
Dzongkha consonants, vowels, phonemes,
phonetics and writing system are all identical.
</bodyText>
<page confidence="0.991558">
103
</page>
<note confidence="0.99526">
Proceedings of the 8th Workshop on Asian Language Resources, pages 103–110,
Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing
</note>
<bodyText confidence="0.998872882352941">
From a linguistic perspective, Dzongkha script
is syllabic, a syllable can contain one character
or as many as six characters. A syllable marker
known as “tsheg”, which is simply a
superscripted dot, separates the syllables of a
word. Linguistic words may contain one or
more syllables and are also separated by the
same symbol, “tsheg”, thus the language is
lacking word boundaries.
Sentences of Dzongkha contain one or more
phrases which themselves contain one or more
words. A character known as “shed” marks a
sentence border, it looks like a vertical pipe.
Phonetic information is available, too: In most
sentences, a pause of silence is taken after each
phrase while speaking the Dzongkha language.
The written form of Dzongkha represents this
pause with a space after each phrase in the case
that it occurs not at the end of the sentence. The
Dzongkha writing system leads to a serious
problem: the detection of word borders, because
only phrases are separated by a space. POS
tagging usually requires a one-token-per line
format, which is produced by a process called
word segmentation. The tagger then adds the
POS category to each token.
The training data of (40247 tokens) was
segmented manually to achieve higher accuracy
of word boundary and also due to lack of word
segmentation during that time. After a
Dzongkha word segmentation2 tool was
developed, the remaining text was segmented
with this tool, which works basically with a
lexicon and the longest string matching method.
</bodyText>
<sectionHeader confidence="0.9878725" genericHeader="method">
3 Challenges and suggestions for
tagging Dzongkha texts
</sectionHeader>
<subsectionHeader confidence="0.999693">
3.1 Words unknown to the language model
</subsectionHeader>
<bodyText confidence="0.99990775">
A statistical tagger learns from POS dis-
tributions in manually tagged data while being
trained and, when being applied to unknown
text, “guesses” the POS of each word. The
TreeTagger (Schmid, 1994) additionally makes
use of a lexicon externally provided when
producing its language model (the “parameter
file”). We had opted for using the TreeTagger
</bodyText>
<footnote confidence="0.950035">
2This tool was developed at NETEC(National Electronics
and Computer Technology Center), Thailand.
</footnote>
<bodyText confidence="0.999804384615384">
and hence we have listed about 28,300
Dzongkha words with their POS in a lexicon
selected from the 570,247 token corpus to be
tagged. We fed these data to the tagger during
its training phase. Note, however, that such a
lexicon may never be complete, as there are
morphologically productive processes creating
new forms (these belong to POS classes that are
often named “open”). Such forms may be taken
into account when developing a tagset,
however, in this work, we opted for postponing
the issue until a morphological analyser can be
developed.
</bodyText>
<subsectionHeader confidence="0.999613">
3.2 Ambiguous function words
</subsectionHeader>
<bodyText confidence="0.993643866666667">
A number of Dzongkha function words are
ambiguous; for each occurrence of such a word,
the tagger has to decide on the basis of the
word’s contexts, which of the possible tags is to
be assigned. Here, the tagset itself comes into
view: whenever it is planned to utilize
probabilistic POS taggers, the tagset should be
designed on the basis of the words’
distributions, otherwise the potential accuracy
of the taggers may never be achieved.
In Dzongkha it is mainly the function words that
are ambiguous in terms of their POS. A typical
example is ལས་/le/(from) belonging to the
category PP (post position) and ལས་/le/(so)
which is of the category CC (conjunction).
</bodyText>
<subsectionHeader confidence="0.995398">
3.3 Fused forms
</subsectionHeader>
<bodyText confidence="0.999884153846154">
Some morpho-phonemic processes in Dzongkha
lead to the fusing of words, presenting another
challenge for tagging. Such words3 are not very
frequent, thus proposing a challenge to
statistical taggers. The word རལ་པོའི་/gelpoi/
(king[+genitive]), for example, is fused from the
phrase རལ་པོ་གི་/gelpo gi/ (king is); another
example is the fused form བསེདན་/sen/ ([to] kill),
made from བསེད་་བ་ཅིན་/se wa cin/ (if [to] kill).
When a tagset does not cater for fused forms of
words, one could split these forms while
tokenizing adding an intermediate level of
representation between original text level and
</bodyText>
<footnote confidence="0.9950115">
3 In our training set, there were 1.73% of all words
detected as fused forms.
</footnote>
<page confidence="0.998604">
104
</page>
<bodyText confidence="0.999929735294118">
the POS level: a level of text material to be
utilized for tagging or other further processing,
as e.g. done by (Taljard et al., 2008) for the
Bantu Language Northern Sotho. However, the
forms could not easily be split, as the resulting
first parts of the words would not contain the
separator “tsheg”. Splitting the word རལ་
པོའི་/gelpoi/ (king[+genitive]), for example, would
result in རལ་པོ/gelpo/(king) and འི་/yi/[+genitive].
The language model does not cater for words
ending in characters other than &amp;quot;tsheg&amp;quot; (word
border) or being directly followed by &amp;quot;shed&amp;quot; (a
word like རལ་པོ/gelpo/(king) may only appear if
preceding a sentence border). Tagging accuracy
for such theoretical forms are not expected to be
acceptable. Fusing processes are productive,
therefore, further research in the frame of a
project developing a Dzongkha tokenizer is
deemed necessary.
We examined all fused words contained in our
textual data to find an workable solution at the
current stage of the project. As long as the
problem of tokenizing automatically is not
solved, we opted for keeping the fused forms as
they are. To enhance our tagger results, we
suggest to add a number of tags to our tagset
that consist of the two POS tags involved. རལ་
པོའི་/gelpoi/ (king[+genitive]), for example, is
tagged as “NN+CG” and བསེདན་/sen/ ([to] kill)
as “VB+SC”. The “+” indicates combined
individual tags. All known forms are added to a
new version of the lexicon. Note, however, that
all tagging results reported upon in this paper,
are still based on the tag set described below.
</bodyText>
<sectionHeader confidence="0.980723" genericHeader="method">
4 Resources used
</sectionHeader>
<subsectionHeader confidence="0.985534">
4.1 Tagset
</subsectionHeader>
<bodyText confidence="0.999752666666667">
During the first phase of PAN Localization
project, the first Dzongkha POS tagset4 was
created. It consisted of 47 tags, its design is
based on the Penn Guidelines5 and its categories
of POS correspond to the respective English
Penn categories. PAN generally makes use of
</bodyText>
<footnote confidence="0.78483025">
4 The original Dzongkha tag set is described at
http://www.panl10n.net
5 The Penn Guidelines can be downloaded from:
http://www.cis.upenn.edu/~treebank/
</footnote>
<bodyText confidence="0.997868428571429">
the Penn Treebank tags as a basis for tagging.
Examining the similar features exhibited by
both the languages (Dzongkha and English),
tags that were applicable to Dzongkha were
taken directly from the Penn Treebank. In cases
where these languages showed dissimilarities in
their nature, new tags for Dzongkha were
assigned (based e.g. on the work on Urdu of
Sajjad and Schmid, 2009). As an example for
such dissimilarity, Dzongkha postpositions are
mentioned here, cf. (1); the respective tag (PP)
only exist for Dzongkha whereas in English the
whole set of ad position tags (preposition and
postpositions) exist.
</bodyText>
<equation confidence="0.941764">
(1) བི་ལི་ ཤིང་གི་འོག་ལའདག
j&apos;ili shing-gi wôlu -dû
Cat tree[posp] under[PP] be
&amp;quot;A cat is under the tree&amp;quot;Whenever a tagset designed on theoretical
</equation>
<bodyText confidence="0.99985012">
implications is applied to text, it will be found
in the course of creating the training data that
not all morpho-syntactic phenomena of the
language had been considered. This happened
for Dzongkha, too: words appeared in the texts
that didn&apos;t fit in any of the pre-defined classes.
Dzongkha uses honorific forms: ན་བཟའ་/nam za/
(cloths) is the honorific form of the noun གོ་
ལ་/gola/(cloths), གསངས་/sung/(tell) the honorific
form of the verb སབ་/lab/(tell). We opted to mark
them by adding the tag NNH (honorific
common noun) and VBH (honorific verb) to
enable future research on this specific usage of
Dzongkha language. A number of tags were
added to the set, of which we describe four in
more detail: two of the additional tags are sub-
classes of verbs: VBH (honorific verb form),
and VBN which describes past participle forms,
like, e.g. བངམ་/jun/(created), the past particle
form of བང་/jung/(create).
Concerning case, we added two subclasses of
case: CDt and CA. These differentiate between
dative (CDt) and ablative (CA): The CDt
(Dative case) labels e.g.དོན་ལས་/doen le/(for it)
and དོན་ལ་/doen lu/(for this). The Ablative case
</bodyText>
<page confidence="0.996098">
105
</page>
<bodyText confidence="0.9990955">
(CA) is used when the argument of the
preposition describes a source. For example, in
the phrase ཤིང་ལས་རང་ཁི་/shing le kang thri/(from
wood chair), ལས་/le/from/ will be labeled CA
since the chair described is made from (the
source) wood (Muaz, et al. 2009). The tagset
utilized in our experiment consists of a total of
66 parts of speech as shown in Appendix (A).
</bodyText>
<subsectionHeader confidence="0.9886805">
4.2 Collecting a Corpus and generating a
training data set
</subsectionHeader>
<bodyText confidence="0.999924869565217">
The Corpus collection process. The process of
collecting a corpus should be based on its
purpose. As our goal was the design a
Dzongkha text corpus as balanced as possible in
terms of its linguistic diversity, the text data was
gathered from different sources like newspaper
articles, samples from traditional books, and
dictionaries, some text was added manually
(poetry and songs). The text selection was also
processed with a view on the widest range of
genres possible: texts from social science, arts
and culture, and texts describing world affairs,
travel adventure, fiction and history books were
added as our goal is to make it representative of
every linguistic phenomena of language
(Sarkar, et al. 2007). The corpus is however not
balanced for a lack of available electronic
resources of informative text (so far only 14%
belong to this category). Future work will
therefore entail collecting more data from
respective websites and newspapers.
The entire corpus contains 570,247 tokens; it
made from the domains described in table (1).
</bodyText>
<table confidence="0.99990025">
Domain Share % Text type
1) World Affairs 12% Informative
2) Social Science 2% Informative
3) Arts 9% Descriptive
4) Literature 72% Expository
5) Adventure 1% Narrative
6) Culture 2% Narrative
7) History 2% Descriptive
</table>
<tableCaption confidence="0.9379915">
Table (1): Textual domains contained
in the corpus
</tableCaption>
<bodyText confidence="0.981333619047619">
The Training data set
Cleaning of texts. Raw text is usually to be
modified before it can be offered to a tagger. It
is to be cleaned manually, e.g. by removing
extra blank spaces, inserting missing blanks,
correcting spelling mistakes, and by removing
duplicate occurrences of sequences. Secondly,
the process of tokenization (“Word
Segmentation”) is to be applied.
Design and generation of training data. The
training data set was produced in several steps:
Firstly, 20,000 tokens were manually labeled
with their respective parts of speech (for a
comparison of tagging techniques, cf. Hasan et
al., 2007). Thereafter, the problems that had
occurred during the manual process were
summarized and the tagset revised as described
in section 4.1. Thereafter, we added another
20,247 tokens. The final training data set hence
consists of 40,247 tokens (2,742 sentences,
36,362 words, 3,265 punctuation, 650 numbers).
</bodyText>
<subsectionHeader confidence="0.708719">
4.3 Tagging technique: TreeTagger and
TnT
</subsectionHeader>
<bodyText confidence="0.99629275">
TreeTagger (Schmid, 1994): TreeTagger
(Schmid, 1994) is a probabilistic part of speech
tagger operating on the basis of decision trees.
Helmut Schmid developed it in the frame of the
“TC”6 project at the Institute for Computational
Linguistics at the University of Stuttgart,
Germany.
The software consists of two modules
</bodyText>
<listItem confidence="0.979214428571429">
a) train-tree-tagger: utilized to generate a
parameter file from a lexicon and a hand-
tagged corpus.
b) tree-tagger: makes use of the parameter file
generated with a); annotates text (which is to
be tokenized first) with part-of-speech
automatically.
</listItem>
<bodyText confidence="0.9487238">
a) Generating a language model: Training
When generating a language model stored in a
so-called “parameter file”, three files are
required: a lexicon describing tokens and their
respective tags, a list of open tags, and training
</bodyText>
<footnote confidence="0.531479333333333">
6 The tagger is freely available at http://www.ims.uni-
stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTag
ger.html
</footnote>
<page confidence="0.994345">
106
</page>
<bodyText confidence="0.999292846153846">
data. The “train-tree-tagger” module generates
a binary parameter file.
The lexicon is a file that contains tokens (word
forms and punctuation), in the format of one
per line. The TreeTagger was developed for
languages with inflection, i.e. languages where
one word may occur in a number of
allomorphs. To ease the task of tagging such
languages, the tool can operate on the level of
a base form, the “lemma” which may be added
to every word form. In the case of Dzongkha,
lemmatization has not been developed yet,
therefore, we either make use of the word form
itself, or a hyphen in the case that no lemma is
available. As table (2) demonstrates, the
lexicon contains the word forms in the first
column, the second column contains the POS
and the third a hyphen. In the case of
ambiguous entries, one line may contain a
sequence of tag-“lemma” pairs that follow the
word form of the first column. The lexicon
may not contain any spaces; all columns must
be separated by exactly one tab(ulator).
Because the lexicon is only made use of during
the training phase of the tagger, any update
must result in reproducing the parameter file.
</bodyText>
<table confidence="0.9971218">
Word Pos tag lemma Pos tag lemma
ཀ་ NN ཀ་
ཀ་ཀ་ NN ཀ་ཀ
ཀ་ཀ་ར་ NNP --
ལས་ PP ལས་ CC ལས་
</table>
<tableCaption confidence="0.998823">
Table (2) Example entries of the lexicon
</tableCaption>
<bodyText confidence="0.999855227272727">
Open class tags: a file containing the list of
open class tags, i.e. the productive classes (one
entry per line), cf. Appendix A. In the upcoming
version of the tagset, tags of the following fused
forms will be added, like, e.g. NN+CG
(combination of all forms nouns with genitive
case CG), VB+CG (combination of all forms
verb with genitive case CG), JJ+CG
(combination of all forms of adjective with
genitive case CG), RB+CG (combination of all
adverb with genitive case CG), and same with
the combination of Subordinate conjunction
NN+SC, VB+SC, JJ+SC, RB+SC, just to name
a few.
Tagged training data: a file that contains
tagged training data. The data must be stored in
one-token-per-line format. This means that each
line contains one token and its respective tag,
these are separated by one tabulator. The file
should be cleaned from empty lines, no meta-
information, like, e.g. SGML markup is
allowed.
</bodyText>
<subsectionHeader confidence="0.856359">
b) Tagging
</subsectionHeader>
<bodyText confidence="0.999904863636364">
Two files serve as input: the binary parameter
file and a text file that is to be tagged.
Parameter file: the file that was generated by
step a) above.
Text file: a file that is to be tagged; it is
mandatory that the data in this file appears in a
one-token-per line format.
TnT (Brants, 2000):The Trigram’s’n’Tags
(TnT) tagger was developed by Thorsten Brants
(Brants, 2000). It is language independent and
has been used widely for a number of
languages, often yielding an accuracy of +96%
without utilizing an external lexicon or an open
word class file. TnT is based on Markov
models, and takes not only distributional data of
tokens, but also the final sequences of
characters of a token into account when
guessing the POS of a word. It can use the same
format for training data as the TreeTagger,
therefore, in order to use TnT for comparison
reasons, no additional preparations for tagging
Dzongkha are necessary.
</bodyText>
<sectionHeader confidence="0.996203" genericHeader="method">
5 Validation and Results
</sectionHeader>
<subsectionHeader confidence="0.9066325">
5.1 k-fold cross validation and
bootstrapping
</subsectionHeader>
<bodyText confidence="0.9999231">
When applying a tagset to training data for the
first time, it is advisable to progress in steps and
to validate each step separately: One begins
with annotating a rather small portion of text
that is then divided into k number of slices.
Slices k-1 are then utilized to create a parameter
file, the slice k is stripped of its annotations and
annotated by the tagger using that parameter
file. The same procedure is followed for all
other slices (“k-fold cross validation”).
</bodyText>
<page confidence="0.99774">
107
</page>
<bodyText confidence="0.999971307692308">
Afterwards, a comparison between the original
tags with the tags assigned by the tagger will
then help to judge upon a number of issues, like,
e.g., whether the size of the training data is
sufficient (quantitative review). Examining the
most frequent (typical) assignment errors of the
tagger will also support the enhancement of the
tagset: if e.g. the distribution of two different
tags is more or less identical, a probabilistic
tagger will not succeed in making the right
choices, here, one is to consider if using one tag
would be acceptable from a linguistic point of
view (qualitative review).
The knowledge gained here usually leads to
updates in the tagset and/or to the necessity to
add more amounts of texts containing
constellations that were found as being
problematic for probabilistic tagging for they
occur too rarely in the texts. After such updates
are done on the existing training texts and tagset
respectively, the k-fold validation may be
repeated and reviewed again.
Updating training data and tagset will be
repeated until the tagging results are satisfying
(such a progressing method is usually called
“bootstrap-ping”).
</bodyText>
<subsectionHeader confidence="0.998967">
5.2 TreeTagger results
</subsectionHeader>
<bodyText confidence="0.99999">
The work on automatic part of speech tagging
for Dzongkha began with the manual annotation
of 20,000 tokens. Because a non-linguistic
person performed the process manually, the
language coordinator did thorough correction.
The 20,000 token training set, made use of 43
different single tags (of 47 provided by the
tagset). The token-tag combinations from there
were combined with an external lexicon
produced from a dictionary; the resulting
lexicon file thus contained all types.
The 10-fold cross validation resulted in an
accuracy of around 78%. Result introspection
lead to the knowledge that more data had to be
added and that fused words will have to receive
separate tags. It also showed that manual
tokenization is an error-prone procedure, as a
significant number of word and sentence
borders had to be corrected in the data.
After updating tagset and training data, another
20,247 tokens were added to the training set and
the lexicon was updated accordingly, except for
the fused forms, where a final solution on how
to tag them is not found yet. The tagset was
extended to 66 tags (cf. Appendix A). With a
full knowledge of the possible tag-token
combinations, the Tree-Tagger achieved a
median accuracy of 93.1%.
</bodyText>
<subsectionHeader confidence="0.996415">
5.3 TnT results and comparison with
the TreeTagger
</subsectionHeader>
<bodyText confidence="0.999720769230769">
Using the 40,247 tokens text segment, a 10-fold
cross validation was also performed with the
TnT tagger. It achieves a 91.5 % median
accuracy when the tagset containing 47 tags is
applied. Results for each slice and mean/median
can be found in table (3) of both taggers for
comparison reasons. TnT reports on the number
of unknown tokens detected in each slice; the
mean of 16.49 % (median 14.18%) of unknown
tokens offers an explanation why TnT does not
perform as good as the TreeTagger which was
supplied with a complete lexicon thus not being
faced with unknown tokens at all.
</bodyText>
<table confidence="0.973396785714286">
Tagger: Tree-Tagger TNT
accuracy % accuracy %
slice 1 92.13 92.33
slice 2 84.61 89.73
slice 3 89.08 89.88
slice 4 90.17 90.43
slice 5 92.95 91.01
slice 6 93.32 91.35
slice 7 94.24 91.69
slice 8 93.32 92.03
slice 9 95.21 92.55
slice 10 94.56 92.60
Mean 91.96 91.36
Median 93.14 91.20
</table>
<tableCaption confidence="0.972841">
Table (3) 10-fold cross validation results for
TreeTagger and TnT
</tableCaption>
<bodyText confidence="0.999783875">
A qualitative review of the results showed that
usually it is the tag CC that is confused with
others (NN, DT, NN, DT, PRL, etc.) by TnT,
while the TreeTagger is rather confusing NN
(with VB, NNP, PRL, CC).
However, a more thorough qualitative
examination of these results is still to be done
and may lead to further updates on the tagset.
</bodyText>
<page confidence="0.998716">
108
</page>
<sectionHeader confidence="0.8710775" genericHeader="method">
6 Discussion, Conclusions and Future
work
</sectionHeader>
<bodyText confidence="0.999976782608696">
This paper describes the building of NLP
resources for the national language of Bhutan,
namely Dzongkha. We have designed and built
an electronic corpus containing 570,247 tokens
belonging to different text types and domains.
Automated word segmentation with a high
precision/recall still remains a challenge. We
have begun to examine statistical methods to
find solutions for this and we plan to report on
our progress in the near future.
We have developed a first version of a tag set
on the basis of the Penn Tree tagset for English
(cf. section 4.1) A training data set of 40,247
tokens has been tagged manually and
thoroughly checked. Lastly, we have tagged the
corpus with the TreeTagger (Schmid, 1994)
using a full form lexicon achieving 93.1% and,
for comparison reasons, with TnT (Brants,
2000), without a lexicon, achieving 91.5 %.
We have used the present output in the
construction of an advance Dzongkha TTS
(text to speech) using an HMM-based method
which is developed by the Bhutan team in
collaboration with HLT team at NECTEC,
Thailand7
Loads of work still remains, we are still to
examine the tagger results from a qualitative
aspect in order to answer inter Alia the
following questions: Are there any further
updates on the tag set necessary, what is the
best way to process fused forms. Quantitative
aspects might also still play a role: It still might
be necessary to add further training data
containing part of speech constellations that
rarely occur, so tagger results for those will
enhance.
We also plan to increase our corpus collection
from various ranges of domains. At present
there are more media, e.g. newspapers available
in the world wide web, we will be able to
collect such texts easily. In Bhutan, there is an
ongoing project on OCR (optical character
recognition) of Dzongkha under the PAN
project (www.PANL10n.net). Given the success
of this project, we will be able to scan text from
textbooks.
</bodyText>
<page confidence="0.449645">
7 http://www.nectec.or.th/en/
</page>
<sectionHeader confidence="0.997621" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992975428571429">
This research work carried out as part of PAN
Localization Project (www.PAN10n.net) with
the aid of grant from the International
Development Research Center (IDRC), Ottawa,
Canada, administered through the Center of
Research in Urdu language Processing
(CRULP), National University of Computer and
Emerging Sciences (NUCES), Pakistan. The
research team would also like to thank PD Dr.
Helmut Schmid and Prof. Dr. Heid, Insitut für
Maschinelle Sprachverarbeitung (NLP
institute), Universität Stuttgart, Germany for
their valuable support and contributions that
made this research successful.
</bodyText>
<sectionHeader confidence="0.999353" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994100034482759">
Brants, Thorsten. 2000. TnT - as statistical part-of-
speech tagger. In Proceedings of the Sixth Applied
Natural Language Processing Conference
(ANLP-2000), Seattle, WA, USA, pages 224 – 231.
Hasan, Fahim Muhammad, Naushad UzZaman, and
Mumit Khan. 2007. Comparison of different POS
Tagging Techniques (N-Gram, HMM and
Brill’s tagger) for Bangla. PAN Localization
Working Papers, 2004-2007, pages 31-37.
Hassan, Sajjad and Helmut Schmid . 2009. Tagging
Urdu Text with Parts of Speech: A Tagger
Comparison, Proceedings of the 12th Conference of
the European Chapter of the Association for
Computational Linguistics (EACL) . Athens, Greece,
2009.
Muaz, Ahmed, Aasim Ali, and Sarmad Hussain.
2009. Analysis and Development of Urdu POS
Tagged Corpus. Association for Computational
Linguistics. Morristown, NJ, USA.
Retrieved December 1, 2009, from
http:// www.lancs.ac.uk
Schmid, Helmut. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In Proceedings of
the International Conference on New Methods in
Language Processing. Manchester, UK, pages 44 –
49.
Sarkar, Asif Iqbal, Dewan Shahriar Hossain Pavel
and Mumit Khan. 2007. Automatic Bangla Corpus
Creation. BRAC University, Dhaka, Bangladesh.
</reference>
<page confidence="0.993544">
109
</page>
<reference confidence="0.997215625">
PAN Localization Working Papers, 2004-2007.
pages 22-26.
Taljard Elsabé, Faaß Gertrud, Heid Ulrich, and Daan
J. Prinsloo. 2000. On the development of a tagset for
Northern Sotho with special reference to
standardization. Literator 29(1), April 2008 (special
edition on Human Language Technologies), South
Africa, pages 111 – 137
</reference>
<sectionHeader confidence="0.978286" genericHeader="references">
APPENDIX A
</sectionHeader>
<bodyText confidence="0.9587895">
The Dzongkha Tagset
as used for the validation tests
</bodyText>
<table confidence="0.983122151898734">
Type SubClass Label
Open classes:
Noun Common Noun NN
Honorific form NNH
Particular/Person NNP
Quantifier NNQ
Plural NNS
Verb Aspirational VBAs
Honorific VBH
Agentive VBAt
Non-Agentive VBNa
Auxiliary VBAUX
Imperative VBI
Modal VBMD
Past participle VBN
Verb VB
Adjective Characteristic JJCt
Periodic JJP
Comparative JJR
Superlative JJS
Adjective JJ
Adverb Behavioral RBB
Comparative RBR
Superlative RBS
Adverb RB
Interjection UH
Closed classes:
Marker Affirmative AM
Interrogative IrM
Tense TM
Case marker Ablative Case CA
Dative Case CDt
Genitive Case CG
Type SubClass Label
Vocative Case CV
Pronouns Locative PRL
Differential PRD
Personal PRP
Reflexive PRRF
Conjunction Coordinate CC
Subordinate SC
Number Cardinal Number CD
Ordinal Number OD
Nominal Number ND
Ad position Post position PP
Determiner Definite DT
Possessive DT$
Indefinite DTI
Negator NEG
Punctuation PUN
Combined
tags:
Noun+Genitiv Common+CG NNCG
e case(CG)
Particular+CG NNPCG
Quantifier+CG NNQCG
Plural+CG NNSCG
Adjective+CG Adjective+CG JJCG
Characteristic +CG JJCtCG
Periodic+CG JJPCG
Verb+CG Honorific+CG VBHCG
Agentive+CG VBAtCG
Verb+CG VBCG
Modal+CG VBMDCG
DefiniteDeter Determiner+CG DTCG
miner+CG
Locative Locative+CG PRLCG
Pronoun +CG
Negator+CG Negator+CG NEGCG
Noun+ Common Noun NNSC
Subordinate +SC
Conjunction(S
C)
Verb+SC Verb+SC VBSC
Agentive+SC VBAtSC
Modal verb+SC VBMDC
Affirmative Affirmative +SC AMSC
+SC
Negator+SC Negator+SC NEGSC
</table>
<page confidence="0.990059">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.053847">
<title confidence="0.998926">Building NLP resources for A Tagset and A Tagged Corpus</title>
<author confidence="0.930764">Chungku Chungku</author>
<author confidence="0.930764">Jurmey</author>
<affiliation confidence="0.762283666666667">Research Department of Information &amp; Telecom</affiliation>
<email confidence="0.719229">chungku@dit.gov.bt</email>
<email confidence="0.719229">jrabgay@dit.gov.bt</email>
<affiliation confidence="0.51260475">Gertrud Institute für Sprachverarbeitung(NLP University of Stuttgart</affiliation>
<email confidence="0.996694">faasz@ims.uni-stuttgart.de</email>
<abstract confidence="0.998647647058824">This paper describes the application of probabilistic part of speech taggers to the Dzongkha language. A tag set containing 66 tags is designed, which is on the Penn A training corpus of 40,247 tokens is utilized to train the model. Using the lexicon extracted from the training corpus and lexicon from the available word list, we used two statistical taggers for comparison reasons. The best result achieved was 93.1% accuracy in a 10-fold cross validation on the training set. The winning tagger was thereafter applied to annotate a 570,247 token corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT - as statistical part-ofspeech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference (ANLP-2000),</booktitle>
<pages>224--231</pages>
<location>Seattle, WA, USA,</location>
<contexts>
<context position="17279" citStr="Brants, 2000" startWordPosition="2745" endWordPosition="2746">ata: a file that contains tagged training data. The data must be stored in one-token-per-line format. This means that each line contains one token and its respective tag, these are separated by one tabulator. The file should be cleaned from empty lines, no metainformation, like, e.g. SGML markup is allowed. b) Tagging Two files serve as input: the binary parameter file and a text file that is to be tagged. Parameter file: the file that was generated by step a) above. Text file: a file that is to be tagged; it is mandatory that the data in this file appears in a one-token-per line format. TnT (Brants, 2000):The Trigram’s’n’Tags (TnT) tagger was developed by Thorsten Brants (Brants, 2000). It is language independent and has been used widely for a number of languages, often yielding an accuracy of +96% without utilizing an external lexicon or an open word class file. TnT is based on Markov models, and takes not only distributional data of tokens, but also the final sequences of characters of a token into account when guessing the POS of a word. It can use the same format for training data as the TreeTagger, therefore, in order to use TnT for comparison reasons, no additional preparations for taggi</context>
<context position="23022" citStr="Brants, 2000" startWordPosition="3699" endWordPosition="3700">o different text types and domains. Automated word segmentation with a high precision/recall still remains a challenge. We have begun to examine statistical methods to find solutions for this and we plan to report on our progress in the near future. We have developed a first version of a tag set on the basis of the Penn Tree tagset for English (cf. section 4.1) A training data set of 40,247 tokens has been tagged manually and thoroughly checked. Lastly, we have tagged the corpus with the TreeTagger (Schmid, 1994) using a full form lexicon achieving 93.1% and, for comparison reasons, with TnT (Brants, 2000), without a lexicon, achieving 91.5 %. We have used the present output in the construction of an advance Dzongkha TTS (text to speech) using an HMM-based method which is developed by the Bhutan team in collaboration with HLT team at NECTEC, Thailand7 Loads of work still remains, we are still to examine the tagger results from a qualitative aspect in order to answer inter Alia the following questions: Are there any further updates on the tag set necessary, what is the best way to process fused forms. Quantitative aspects might also still play a role: It still might be necessary to add further t</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, Thorsten. 2000. TnT - as statistical part-ofspeech tagger. In Proceedings of the Sixth Applied Natural Language Processing Conference (ANLP-2000), Seattle, WA, USA, pages 224 – 231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fahim Muhammad Hasan</author>
<author>Naushad UzZaman</author>
<author>Mumit Khan</author>
</authors>
<date>2007</date>
<booktitle>Comparison of different POS Tagging Techniques (N-Gram, HMM and Brill’s tagger) for Bangla. PAN Localization Working Papers,</booktitle>
<pages>2004--2007</pages>
<contexts>
<context position="13528" citStr="Hasan et al., 2007" startWordPosition="2123" endWordPosition="2126"> the corpus The Training data set Cleaning of texts. Raw text is usually to be modified before it can be offered to a tagger. It is to be cleaned manually, e.g. by removing extra blank spaces, inserting missing blanks, correcting spelling mistakes, and by removing duplicate occurrences of sequences. Secondly, the process of tokenization (“Word Segmentation”) is to be applied. Design and generation of training data. The training data set was produced in several steps: Firstly, 20,000 tokens were manually labeled with their respective parts of speech (for a comparison of tagging techniques, cf. Hasan et al., 2007). Thereafter, the problems that had occurred during the manual process were summarized and the tagset revised as described in section 4.1. Thereafter, we added another 20,247 tokens. The final training data set hence consists of 40,247 tokens (2,742 sentences, 36,362 words, 3,265 punctuation, 650 numbers). 4.3 Tagging technique: TreeTagger and TnT TreeTagger (Schmid, 1994): TreeTagger (Schmid, 1994) is a probabilistic part of speech tagger operating on the basis of decision trees. Helmut Schmid developed it in the frame of the “TC”6 project at the Institute for Computational Linguistics at the</context>
</contexts>
<marker>Hasan, UzZaman, Khan, 2007</marker>
<rawString>Hasan, Fahim Muhammad, Naushad UzZaman, and Mumit Khan. 2007. Comparison of different POS Tagging Techniques (N-Gram, HMM and Brill’s tagger) for Bangla. PAN Localization Working Papers, 2004-2007, pages 31-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sajjad Hassan</author>
<author>Helmut Schmid</author>
</authors>
<title>Tagging Urdu Text with Parts of Speech: A Tagger Comparison,</title>
<date>2009</date>
<booktitle>Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL) .</booktitle>
<location>Athens, Greece,</location>
<marker>Hassan, Schmid, 2009</marker>
<rawString>Hassan, Sajjad and Helmut Schmid . 2009. Tagging Urdu Text with Parts of Speech: A Tagger Comparison, Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL) . Athens, Greece, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Muaz</author>
<author>Aasim Ali</author>
<author>Sarmad Hussain</author>
</authors>
<title>Analysis and Development of Urdu POS Tagged Corpus. Association for Computational Linguistics.</title>
<date>2009</date>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="11437" citStr="Muaz, et al. 2009" startWordPosition="1787" endWordPosition="1790">rm), and VBN which describes past participle forms, like, e.g. བངམ་/jun/(created), the past particle form of བང་/jung/(create). Concerning case, we added two subclasses of case: CDt and CA. These differentiate between dative (CDt) and ablative (CA): The CDt (Dative case) labels e.g.དོན་ལས་/doen le/(for it) and དོན་ལ་/doen lu/(for this). The Ablative case 105 (CA) is used when the argument of the preposition describes a source. For example, in the phrase ཤིང་ལས་རང་ཁི་/shing le kang thri/(from wood chair), ལས་/le/from/ will be labeled CA since the chair described is made from (the source) wood (Muaz, et al. 2009). The tagset utilized in our experiment consists of a total of 66 parts of speech as shown in Appendix (A). 4.2 Collecting a Corpus and generating a training data set The Corpus collection process. The process of collecting a corpus should be based on its purpose. As our goal was the design a Dzongkha text corpus as balanced as possible in terms of its linguistic diversity, the text data was gathered from different sources like newspaper articles, samples from traditional books, and dictionaries, some text was added manually (poetry and songs). The text selection was also processed with a view</context>
</contexts>
<marker>Muaz, Ali, Hussain, 2009</marker>
<rawString>Muaz, Ahmed, Aasim Ali, and Sarmad Hussain. 2009. Analysis and Development of Urdu POS Tagged Corpus. Association for Computational Linguistics. Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<title>from http:// www.lancs.ac.uk Schmid, Helmut.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing.</booktitle>
<pages>44--49</pages>
<institution>Retrieved</institution>
<location>Manchester, UK,</location>
<marker>2009</marker>
<rawString>Retrieved December 1, 2009, from http:// www.lancs.ac.uk Schmid, Helmut. 1994. Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proceedings of the International Conference on New Methods in Language Processing. Manchester, UK, pages 44 – 49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Iqbal Sarkar</author>
<author>Dewan Shahriar Hossain Pavel</author>
<author>Mumit Khan</author>
</authors>
<date>2007</date>
<institution>Automatic Bangla Corpus Creation. BRAC University,</institution>
<location>Dhaka, Bangladesh.</location>
<contexts>
<context position="12318" citStr="Sarkar, et al. 2007" startWordPosition="1932" endWordPosition="1935">se. As our goal was the design a Dzongkha text corpus as balanced as possible in terms of its linguistic diversity, the text data was gathered from different sources like newspaper articles, samples from traditional books, and dictionaries, some text was added manually (poetry and songs). The text selection was also processed with a view on the widest range of genres possible: texts from social science, arts and culture, and texts describing world affairs, travel adventure, fiction and history books were added as our goal is to make it representative of every linguistic phenomena of language (Sarkar, et al. 2007). The corpus is however not balanced for a lack of available electronic resources of informative text (so far only 14% belong to this category). Future work will therefore entail collecting more data from respective websites and newspapers. The entire corpus contains 570,247 tokens; it made from the domains described in table (1). Domain Share % Text type 1) World Affairs 12% Informative 2) Social Science 2% Informative 3) Arts 9% Descriptive 4) Literature 72% Expository 5) Adventure 1% Narrative 6) Culture 2% Narrative 7) History 2% Descriptive Table (1): Textual domains contained in the corp</context>
</contexts>
<marker>Sarkar, Pavel, Khan, 2007</marker>
<rawString>Sarkar, Asif Iqbal, Dewan Shahriar Hossain Pavel and Mumit Khan. 2007. Automatic Bangla Corpus Creation. BRAC University, Dhaka, Bangladesh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PAN Localization</author>
</authors>
<title>Working Papers,</title>
<date>2004</date>
<pages>22--26</pages>
<marker>Localization, 2004</marker>
<rawString>PAN Localization Working Papers, 2004-2007. pages 22-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taljard Elsabé</author>
<author>Faaß Gertrud</author>
<author>Heid Ulrich</author>
<author>Daan J Prinsloo</author>
</authors>
<title>On the development of a tagset for Northern Sotho with special reference to standardization.</title>
<date>2000</date>
<journal>Literator</journal>
<volume>29</volume>
<issue>1</issue>
<pages>111--137</pages>
<marker>Elsabé, Gertrud, Ulrich, Prinsloo, 2000</marker>
<rawString>Taljard Elsabé, Faaß Gertrud, Heid Ulrich, and Daan J. Prinsloo. 2000. On the development of a tagset for Northern Sotho with special reference to standardization. Literator 29(1), April 2008 (special edition on Human Language Technologies), South Africa, pages 111 – 137</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>