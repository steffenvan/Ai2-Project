<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<note confidence="0.602657">
GRAMMAR VIEWED AS A FUNCTIONING PART OF A COGNITIVE SYSTEM
</note>
<author confidence="0.883527">
Helen M. Gigley
</author>
<affiliation confidence="0.9090725">
Department of Computer Science
University of New Hampshire
</affiliation>
<address confidence="0.390567">
Durham, NH 03824
</address>
<sectionHeader confidence="0.793876" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999882">
How can grammar be viewed as a functional
part of a cognitive system? Given a neural basis
for the processing control paradigm of language
performance, what roles does &amp;quot;grammar&amp;quot; play? Is
there evidence to suggest that grammatical pro-
cessing can be independent from other aspects of
language processing?
This paper will focus on these issues and
suggest answers within the context of one com-
putational solution. The example model of sen-
tence comprehension, HOPE, is intended to demon-
strate both representational considerations for a
grammar within such a system as well as to illus-
trate that by interpreting a grammar as a feedback
control mechanism of a &amp;quot;neural-like&amp;quot; process,
additional insights into language processing can
be obtained.
</bodyText>
<sectionHeader confidence="0.995207" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.99977708">
The role of grammar in defining cognitive
models that are neurally plausible and psycho-
logically valid will be the focus of this paper.
While inguistic theory greatly influences the
actual representation that is included in any such
model, there are vast differences in how any
grammar selected is &amp;quot;processed&amp;quot; within a &amp;quot;natural
computation&amp;quot; paradigm. The processing does not
grow trees explicitly; it does not transform trees
explicitly; nor does it move constituents.
In this type of model, a grammar is an ex-
plicit encoded representation that coordinates the
integrated parallel process. It provides the
interfaces between parallel processes that can be
interpreted within semantic and syntactic levels
separately. It furthermore acts as a &amp;quot;conductor&amp;quot;
of a time-synchronized process. Aspects of how a
grammar might be processed within a cognitive view
of sentence comprehension will be demonstrated
within an implemented model of such processing,
HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984;
1985). This view of grammatical &amp;quot;process&amp;quot; sug-
gests that neural processing should be included as
a basis for defining what is universal in lan-
guage.
</bodyText>
<sectionHeader confidence="0.993011" genericHeader="introduction">
2. Background
</sectionHeader>
<bodyText confidence="0.999928787234042">
There are currently several approaches to
developing cognitive models of linguistic function
(Cottrell, 1984; Cottrell and Small, 1983; Gigley,
1981; 1982a; 1982b; 1983; 1984; 1985; Small,
Cottrell and Shastri, 1982; Waltz and Pollack, in
press). These models include assumptions about
memory processing within a spreading activation
framework (Collins and Loftus, 1975; Hinton, 1981;
Quillian, 1968/1980), and a parallel, interactive
control paradigm for the processing. They differ
in the explicit implementations of these theories
and the degree to which they claim to be psycho-
logically valid.
Computational Neurolinguistics (CN), first
suggested as a problem domain by Arbib and Caplan
(1979), is an Artificial Intelligence (AI) ap-
proach to modelling neural processes which sub-
serve natural language performance. As CN has
developed, such models are highly constrained by
behavioral evidence, both normal and pathological.
CN provides a framework for defining cognitive
models of natural language performance of behavior
that includes claims of validity at two levels,
the natural computation or neural-like processing
level, and at the system result or behavioral
level.
Using one implementation of a CN model, HOPE
(Gigley, 1981; 1982a; 1982b; 1983) a model of
single sentence comprehension, the remainder of
the paper will illustrate how the role of grammar
can be integrated into the design of such a model.
It will emphasize the importance of the parallel
control assumptions in constraining the repre-
sentation in which the grammar is encoded. It
will demonstrate how the grammar contributes to
control the coordination of the parallel, asyn-
chronous processes included in the model.
The HOPE model is chosen explicitly because
the underlying assumptions in its design are
intended to be psychologically valid on two
levels, while the other referenced models do not
make such claims. The complete model is discussed
in Gigley (1982a; 1982b; 1983) and will be sum-
marized here to illustrate the role of the grammar
in its function. The suggested implications and
goals for including neurophysiological evidence in
designing such models have been discussed else-
</bodyText>
<page confidence="0.997633">
324
</page>
<bodyText confidence="0.993534666666667">
where in Lavorel and Gigley (1983) and will be
included only as they relate to the role and
function of the grammar.
</bodyText>
<subsectionHeader confidence="0.7344835">
2.1 Summary of Included Knowledge and its Repre-
sentation
</subsectionHeader>
<bodyText confidence="0.938580493506493">
Types of representations included in the HOPE
model, phonetic, categorially accessed meanings,
grammar, and pragmatic or local context, receive
support as separately definable knowledge within
studies of aphasia. There is a vast literature
concerning what aspects of language are indepen-
dently affected in aphasia that has been used as a
basis for deciding these representations. (See
Gigley, 1982b for complete documentation.)
Information that is defined within the HOPE
model is presented at a phonological level as
phonetic representations of words (a stub for a
similar interactive process underlying word re-
cognition). Information at the word meaning level
is represented as multiple representations, each
of which has a designated syntactic category type
and orthographic spelling associate to represent
the phonetic word&apos;s meaning (also a stub). The
grammatical representation has two components.
One is strictly a local representation of the
grammatical structural co-occurrences in normal
language. The other is a functional repre-
sentation, related to interpretation, that is
unique for each syntactic category type. Please
note that type is not used in the strictest sense
of its use wittlin a typed semantic system. &amp;quot;TM
W11 be desc75171 in detail ter.Finally, the
pragmatic interpretation is assumed to reflect the
sentential context of the utterance.
Each piece of information is a thresholding
device with memory. Associational interconnec-
tions are made by using an hierarchical graph
which includes a hypergraph facility that permits
simultaneous multiple interpretations for any
active information in the process. Using this
concept, an active node can be ambiguous, repre-
senting information that is shared among many
interpretations. Sentence comprehension is viewed
as the resolution of the ambiguities that are
activated over the time course of the process.
Within our implementation, graphs can repre-
sent an aspect of the problem representation by
name. Any name can be attached to a node, or an
edge, or a space (hypergraph) of the graph. There
are some naming constraints required due to the
graph processing system implementation, but they
do not affect the conceptual representation on
which the encoding of the cognitive linguistic
knowledge relies.
Any name can have multiple meanings asso-
ciated with it. These meanings can be interpreted
differently by viewing each space in which the
name is referenced as a different viewpoint for
the same information. This means that whenever
the name is the same for any information, it is
indeed the same information, although it may mean
several things simultaneously. An example related
to the grammatical representation is that the
syntactic category aspect of each meaning of a
phonetic word is also a part of the grammatical
representation where it makes associations with
other syntactic categories. The associations
visible in the grammatical representation and
interpreted as grammatical &amp;quot;meanings&amp;quot; are not
viewable within the phonetic word meaning per-
spective.
However, any information associated with a
name, for instance, an activity value, is viewable
from any spaces in which the name exists. This
means that any interpreted meaning associated with
a name can only be evaluated within the context,
or contexts, in which the name occurs. Meaning
for any name is contextually evaluable. The
explicit meaning within any space depends on the
rest of the state of the space, which furthermore
depends on what previous processing has occurred
to affect the state of that space.
</bodyText>
<subsectionHeader confidence="0.999674">
2.2 Summary of the Processing Paradigm
</subsectionHeader>
<bodyText confidence="0.998696863636364">
The development of CN models emphasizes
process. A primary assumption of this approach is
that neural-like computations must be included in
models which attempt to simulate any cognitive
behavior (Cf Lavorel and Gigley, 1983), speci-
fically natural language processing in this case.
Furthermore, CN includes the assumption that time
is a critical factor in neural procesTi7q
mechanisiria—That—TE7Ein be airliMicant factor
In language behavior in its degraded or &amp;quot;lesioned&amp;quot;
state.
Simulation of a process paradigm for natural
language comprehension in HOPE is achieved by
incorporating a neurally plausible control that is
internal to the processing mechanism. There is no
external process that decides which path or pro-
cess to execute next based on the current state of
the solution space. The process is time-locked;
at each process time interval. There are six
types of serial-order computations that can occur.
They apply to all representation viewpoints or
spaces simultaneously, and uniformly. Threshold
firing can affect multiple spaces, and has a local
effect within the space of firing.
Each of these serial-order computations is
intended to represent an aspect of &amp;quot;natural compu-
tation&amp;quot; as defined in Lavorel and Gigley, 1983. A
natural computation, as opposed to a mechanistic
one, is a &amp;quot;computation&amp;quot; that is achieved by neural
processing components, such as threshold devices
and energy transducers, rather than by components
such as are found in digital devices. The most
important aspect of the control is that all of the
serial order computations can occur simultaneously
and can affect any informai777-that has been
defined in the instantiated model.
Processing control is achieved using activity
values on information. As there is no preset
context in the current implementation, all in-
formation initially has a resting activity value.
This activity value can be modified over time
depending on the sentential input. Furthermore,
there is an automatic activity decay scheme in-
tended to represent memory processing which is
</bodyText>
<page confidence="0.998462">
325
</page>
<bodyText confidence="0.9994696">
It is in the interaction of the results of these
asychronous processes that the process of compre-
hension is simulated.
based on the state of the information, whether it
has reached threshold and fired or not.
Activity is propagated in a fixed-time scheme
to all &amp;quot;connected&amp;quot; aspects of the meaning of the
words by spreading activation (Collins and Loftus,
1975; 1983; Hinton, 1981; Quillian, 1968/1980).
Simultaneously, information interacts
asynchronously due to threshold firing. A state
of threshold firing is realized as a result of
summed inputs over time that are the result of the
fixed-time spreading activation, other threshold
firing or memory cilcay effects in combination.
The time course of new information introduction,
which initiates activity spread and automatic
memory decay is parameterized due to the under-
lying reason for designing such models (Gigley,
1982b; 1983; 1985).
The exact serial-order processes that occur
at any time-slice of the process depend on the
&amp;quot;current state&amp;quot; of the global information; they
are context dependent. The serial-order processes
include:
</bodyText>
<listItem confidence="0.9979775">
(1) NEW-WORD-RECOGNITION: Introduction of the
next phonetically recognized word in the
sentence.
(2) DECAY: Automatic memory decay exponentially
</listItem>
<bodyText confidence="0.66858475">
reduces the activity of all active informa-
tion that does not receive additional input.
It is an important part of the neural pro-
cesses that occur during memory processing.
</bodyText>
<listItem confidence="0.871933625">
(3) REFRACTORY-STATE-ACTIVATION:(--- An auto-
matic change of state that occurs after
active information has reached threshold and
fired. In this state, the information can
not affect or be affected by other informa-
tion in the system.
(4) POST-REFRACTORY-STATE-ACTIVATION: C:D An
automatic change of state which all fired in-
</listItem>
<bodyText confidence="0.98226475">
formation enters after it has existed in the
REFRACTORY-STATE. The decay rate is dif-
ferent than before firing, although still
exponential.
</bodyText>
<listItem confidence="0.98757375">
(5) MEANING-PROPAGATION: Fixed-time spreading
activation to the distributed parts of
recognized words&apos; meanings.
(6) FIRING-INFORMATION-PROPAGATION: ED
</listItem>
<bodyText confidence="0.999818071428572">
Asynchronous activity propagation that occurs
when information reaches threshold and fires.
It can be INHIBITORY and EXCITATORY in its
effect. INTERPRETATION results Triaivation
of a pragmatic representation of a dis-
ambiguated word meaning.
Processes (2) through (6) are applicable to
all active information in the global representa-
tion, while process (1) provides the interface
with the external input of the sentence to be
understood. The state of the grammar representa-
tion affects inhibitory and excitatory firing
propagation, as well as coordinates &amp;quot;meaning&amp;quot;
interpretation with on-going &amp;quot;input&amp;quot; processing.
</bodyText>
<sectionHeader confidence="0.778899" genericHeader="method">
3. The Role of a Grammar in Cognitive Processing
</sectionHeader>
<subsectionHeader confidence="0.467527">
Models
</subsectionHeader>
<bodyText confidence="0.992910103448276">
Within our behavioral approach to studying
natural language processing, several considera-
tions must be met. Justification must be made for
separate representations of information and, when-
ever possible, neural processing support must be
found.
3.1 Evidence for a Separate Representation of
Grammar
Neurolinguistic and psycholinguistic evidence
supports a separately interpretable representation
for a grammar. The neurolinguistic literature
demonstrates that the grammar can be affected in
isolation from other aspects of language function.
(Cf Studies of agrammatic and Broca&apos;s aphasia as
described in Goodenough, Zurif, and Weintraub,
1977; Goodglass, 1976; Goodglass and Berko, 1960;
Goodglass, Gleason, Bernholtz, and Hyde, 1970;
Zurif and Blumstein, 1978).
In the HOPE model, this separation is
achieved by including all relevant grammatical
information within a space or hypergraph called
the grammar. The associated interpretation func-
tions for each grammatical type provide the in-
terface with the pragmatic representation. Before
describing the nature of the local representation&amp;quot;
of the currently included grammar, a brief dis-
cussion of the structure of the grammar and the
role of the grammar in the global nature of the
control must be given.
</bodyText>
<subsectionHeader confidence="0.99977">
3.2 The Local Representation of the Grammar
</subsectionHeader>
<bodyText confidence="0.999977884615385">
The grammar space contains the locally de-
fined grammar for the process. The current model
defined within the HOPE system includes a form of
a Categorial Grammar (Ajdukiewicz, 1935; Lewis,
1972). Although the original use of the grammar
is not heeded, the relationship that ensues be-
tween a well defined syntactic form and a &amp;quot;final
state&amp;quot; meaning representation is borrowed.
Validity of the &amp;quot;final state&amp;quot; meaning is not the
issue. Final state here means, at the end of the
process. As previously mentioned, typed semantics
is also not rigidly enforced in the current model.
HOPE allows one to define a lexicon within
user selected syntactic types, and allows one to
define a suitable grammar of the selected types in
the prescribed form as well. The grammar may be
defined to suit the aspects of language per-
formance being modelled.
There are two parts to the grammatical aspect
of the HOPE model. One is a form of the struc-
tural co-occurrences that constitute context free
phrase structure representations of grammar.
However, these specifications only make one &amp;quot;con-
stituent&amp;quot; predictions for subsequent input types
where each constituent may have additional sub-
structure.
</bodyText>
<page confidence="0.995062">
326
</page>
<bodyText confidence="0.999646112903226">
Predictions at this time do not spread to
substructures because of the &amp;quot;time&amp;quot; factor between
computational updates that is used. A spread to
substructures will require a refinement in time-
sequence specifications.
The second aspect of the representation is an
interpretation function, for each specified syn-
tactic type in the grammar definition. Each
interpretation function is activated when a word
meaning fires for whatever reason. The inter-
pretation function represents a firing activation
level for the &amp;quot;concept&amp;quot; of the meaning and in-
cludes its syntactic form. For this reason, each
syntactic form has a unique functional description
that uses the instantiated meaning that is firing
(presently, the spelling notation) to activate
structures and relations in the pragmatic space
that represent the &amp;quot;meaning understood.&amp;quot;
Each function activates different types of
structures and relations, some of which depend on
prior activation of other types to complete the
process correctly. These functions can trigger
semantic feature checks and morphological matches
where appropriate.
Syntactic types in the HOPE system are of two
forms, lexical and derived. A lexical category
1121 is one which can be a category type of a
teiical item. A derived category type is one
which is &amp;quot;composed&amp;quot;. Derived category types
represent the occurrence of proper &amp;quot;meaning&amp;quot;
interpretation in the pragmatic space.
The current represented grammar in ROPE
contains the following lexical categories: DET
for determiner, ENOCONT for end of sentence in-
tonation, NOUN for common noun, PAUSE for end of
clause intonation, TERM for proper nouns, VIP for
intrasitive verb, VTP for transitive verb. As is
seen, the lexical &amp;quot;categories&amp;quot; relate
&amp;quot;grammatical&amp;quot; structure to aspects of the input
signal, hence in this sense ENDCONT and PAUSE are
categories.
The derived categories in the current in-
stantiated model include: SENTENCE, representing
a composition of agent determination of a TERM for
an appropriate verb phrase, TERM, representing a
composed designated DET NOUN referent, and VIP,
representing the state of proper composition of a
TERM object with a VIP. transitive verb sense.
TERM and VIP are examples of category types in
this model that are both lexical and derived.
&amp;quot;Rules&amp;quot; in the independently represented
grammar are intended to represent what is con-
sidered in HOPE as the &amp;quot;syntactic meaning&amp;quot; of the
respective category. They are expressed as local
interactions, not global ones. Global effects of
grammar, the concern of many rule based systems,
can only be studied as the result of the time
sequenced processing of an &amp;quot;input&amp;quot;. Table 1
contains examples of &amp;quot;rules&amp;quot; in our current model.
Other categories may be defined; other lexical
items defined; other interpretations defined
within the HOPE paradigm.
</bodyText>
<tableCaption confidence="0.995831">
Table 1: Category specification
</tableCaption>
<table confidence="0.484709666666667">
DET: = TERM / NOUN
VIP: = SENTENCE / ENDCOUNT
VIP: = VIP / TERM
</table>
<bodyText confidence="0.999962710526316">
In Table 1, the &amp;quot;numerator&amp;quot; of the specifi-
cation is the derived type which results from
composition of the &amp;quot;denominator&amp;quot; type interpre-
tation with the interpretation of the category
whose meaning is being defined. For example,
DETerminer, the defined category, combines with a
NOUN category type to produce an interpretation
which is a TERM type. When a category occurs in
more than one place, any interpretation and re-
sultant activity propagation of the correct type
may affect any &amp;quot;rule&amp;quot; in which it appears. Ef-
fects are in parallel and simultaneous. Inter-
pretation can be blocked for composition by un-
successful matches on designated attribute fea-
tures or morphological inconsistencies.
Successful completion of function execution
results in a pragmatic representation that will
either fire immediately if it is non-compositional
or in one time delay if the &amp;quot;meaning&amp;quot; is composed.
Firing is of the syntactic type that represents
the correctly &amp;quot;understood&amp;quot; entity. This &amp;quot;top-
down&amp;quot; firing produces feedback activity whose
effect is &amp;quot;directed&amp;quot; by the state of the grammar,
space, i.e. what information is active and its
degree of activity.
The nature of the research in its present
state has not addressed the generality of the lin-
guistic structures it can process. This is left
to future work. The concentration at this time is
on initial validation of model produced simulation
results before any additional effort on expansion
is undertaken. With so many assumptions included
in the design of such models, initial assessment
of the model&apos;s performance was felt to be more
critical than its immediate expansion along any of
the possible dimensions previously noted as stubs.
The initial investigation is also intended to
suggest how to expand these stubs.
</bodyText>
<subsectionHeader confidence="0.997793">
3.3 The Grammar as a Feedback Control System
</subsectionHeader>
<bodyText confidence="0.999977111111111">
The role of the grammar as it is encoded in
HOPE is to function in a systems theoretic manner.
It provides the representation of the feedforward,
or prediction, and feedback, or confirmation
interconnections among syntactic entities which
have produced appropriate entities as pragmatic
interpretations. It coordinates the serial or-
dered expectations, with what actually occurs in
the input signal, with any suitable meaning in-
terpretations that can affect the state of the
process in a top-down sense. It represents the
interface between the serial-order input and the
parallel functioning system.
Grammatical categories are activated via
spreading activation that is the result of word
meaning activation as words are recognized.
Firing of an instance of a grammatical type acti-
vates that type&apos;s interpretation function which
</bodyText>
<page confidence="0.992169">
327
</page>
<bodyText confidence="0.999975181818182">
results in the appropriate pragmatic interpreta-
tion for it, including the specific meaning that
was fired.
example processing effects that arise due to its
interactive activation.
Interpretation functions are defined for
syntactic types not specific items within each
type. Each type interpretation has one form with
specific lexical &amp;quot;parameters&amp;quot; All nouns are
interpreted the same; all intransitive verbs the
same. What differs- in interpretation is the
attributes that occur for the lexical item being
interpreted. These also affect the interpreta-
tion.
The meaning representation for all instances
of a certain category have the same meta-
structure. General nouns (NOUN) are presently
depicted as nodes in the pragmatic space. The
node name is the &amp;quot;noun meaning.&amp;quot; For transitive
verbs, nodes named as the verb stem are produced
with a directed edge designating the appropriate
TERN- category as agent. The effect of firing of a
grammatical category can trigger feature propaga-
tions or morphological checks depending on which
category fires and the current pragmatic state of
the on-going interpretation.
Successful interpretation results in thres-
hold firing of the &amp;quot;meaning.&amp;quot; This &amp;quot;meaning&amp;quot; has
a syntactic component which can affect grammatical
representations that have an activity value. This
process is time constrained depending on whether
the syntactic type of the interpretation is lexi-
cal or derived.
</bodyText>
<subsectionHeader confidence="0.996065">
3.4 Spreading Activation of the Grammar
</subsectionHeader>
<bodyText confidence="0.999959181818182">
Input to HOPE is time-sequenced, as phone-
tically recognized words, (a stub for future
development). Each phonetic &amp;quot;word&amp;quot; activates all
of its associated meanings. (HOPE uses homophones
to access meanings.) Using spreading activation,
the syntactic category aspect of each meaning in
turn activates the category&apos;s meaning in the
grammar space representation.
Part of the grammatical meaning of any syn-
tactic category is the meaning category that is
expected to follow it in the input. The other
part of the grammatical meaning for any category
type, is the type it can derive by its correct
interpretation within the context of a sentence.
Because each of these predictions and interpreta-
tions are encoded locally, one can observe inter-
actions among the global &amp;quot;rules&amp;quot; of the grammar
during the processing. This is one of the moti-
vating factors for designing the neurally moti-
vated model, as it provides insights into how
processing deviations can produce degraded lan-
guage performance.
</bodyText>
<subsectionHeader confidence="0.994401">
3.5 Grammar State and Its Effect on Processing
</subsectionHeader>
<bodyText confidence="0.999980875">
Lexical category types have different effects
than derived ones with respect to timing and
pragmatic interpretation. However, both lexical
and derived category types have the same effect on
the subsequent input. This section will describe
the currently represented grammar and provide
Through spreading activation, the state of
the syntactic types represented in the grammar
affects subsequent category biases in the input
(feedforward) and on-going interpretation or
disambiguation of previously &amp;quot;heard&amp;quot; words (feed-
back). The order of processing of the input
appears to be both right to left and left to
right. Furthermore, each syntactic type, on
firing, triggers the interpretation function that
is particular to each syntactic type.
Rules, as previously discussed, are activated
during processing via spreading activation. Each
recognized word activates all &amp;quot;meanings&amp;quot; in
parallel. Each &amp;quot;meaning&amp;quot; contains a syntactic
type. Spreading activation along &amp;quot;syntactic type
associates&amp;quot; (defined in the grammar) predictively
activates the &amp;quot;expected&amp;quot; subsequent categories in
the input.
In the HOPE model, spreading activation
currently propagates this activity which is not at
the &amp;quot;threshold&amp;quot; level. Propagated activity due to
firing is always a parameter controlled percentage
of the above threshold activity and in the pre-
sently &amp;quot;tuned&amp;quot; simulations always propagates a
value that is under threshold by a substantial
amount.
All activations occur in parallel and affect
subsequent &amp;quot;meaning&amp;quot; activities of later words in
the sentence. In addition, when composition
succeeds (or pragmatic interpretation is
finalized) the state of the grammar is affected to
produce or changes in category aspects of all
active meanings in the process.
The remainder of this section will present
instances of the feedforward and feedback effects
of the grammar during simulation runs to illus-
trate the role of grammar in the process. The
last example will illustrate how a change in state
of the grammar representation can affect the
process. All examples will use snapshots of the
sentence: &amp;quot;The boy saw the building.&amp;quot; This is
input phonetically as: (TH-UH 8-0Y SAO TH-UH
</bodyText>
<subsectionHeader confidence="0.6919205">
3.5.1 An Example of Feedforward, Feedback, and
Composition
</subsectionHeader>
<bodyText confidence="0.998968153846154">
This example will illustrate the feedforward
activation of NOUN for the DETerminer grammatical
meaning during interpretation of the initial TERM
or noun phrase of the sentence. All figures are
labelled to correspond with the text. Each in-
terval is labelled at the top, ti, t2, etc. The
size of each node reflects the activity level,
larger means more active. Threshold firing is
represented as 0 . Other changes of state that
affect memory are are denoted CZ:: andc==&gt; and
are shown for completeness. They indicate
serial-order changes of state described earlier,
but are not critical to the following discussion.
</bodyText>
<page confidence="0.997084">
328
</page>
<table confidence="0.986072205128205">
II 13 14 IS
PRAGMA TIC - / &amp;quot;&amp;quot;Nboy TEM ( i)
f lf %
r
.4
■
■
ND dIMO •N&gt; a
p1
4 ■
/ ■
GRAMMA,. (c) . II % I I
mi I % I 41
&gt; 4( 0 ez4____,,_
. i s
0 44
; ),
S..,- , 1
/
PNON•CAT•AISAN!. 4111122-4.÷—e------)--• (d) I , -4V.e&amp;quot;-• •
• i r ( e
i F I
o 41 „! —
t 1 %--&amp;quot;/---&gt;
r-1 ./.%. .
, .
.....
1.-A 7.
(f)
PI•0111,103 .....__ •=1111,■ (h) .
, , , •
, •
a(a)
-- ..&gt;
• ••••• MOO
&gt;
—t.:
.
TN-UH 3-01! S-AO
</table>
<figureCaption confidence="0.959157">
Figure 1
</figureCaption>
<bodyText confidence="0.99996802631579">
On &amp;quot;hearing&amp;quot; /TH-UH/ (a) at ti, the repre-
sented meaning &amp;quot;DET-the&amp;quot; is activated as the only
meaning (b). At the next time interval, t2, the
meaning of OET is activated - which spreads acti-
vity to what OET predicts, a NOUN (c). All NOUN
meanings are activated by spread in the next time
interval, t3, in combination with new activity.
This produces a threshold which &amp;quot;fires&amp;quot; the
&amp;quot;meaning&amp;quot; selected (d). At completion of inter-
pretation (e), in t4, feedback occurs to all
instances of meaning with category types in the
grammar associated as predictors of the inter-
preted category. OET is the only active category
that predicts NOUN so all active meanings of type
0E7 will receive the feedback activity. In Figure
1, DET-the is ready to fire (f). The increase or
decrease in activity of all related types,
competitive ones for the meaning (inhibitory) (g)
as well as syntactic ones for composition (ex-
citatory) (f) is propagated at the next interval
after firing, shown in t3 and t4. In t5, IS-AO/
enters the process (h) with its associated mean-
ings.
The effect of DET-the firing is also seen in
t5 where the compositional TERM is activated (i).
NOTE: OETerminers are not physically represented
as entities in the pragmatic space. Their meaning
is only functional and has a &amp;quot;semantic&amp;quot; composi-
tional effect. Here &apos;tne&apos; requires a &amp;quot;one and
only one&amp;quot; NOUN that is unattached as a TERM to
successfully denote the meaning of the boy as a
proper TERM (i). As this is a compositional
&amp;quot;meaning&amp;quot;, the firing will affect t6. Because
there is no active TERM prediction in the grammar
space, and no competitive meanings, the top-down
effect in t6 will be null and is not shown. The
next example will illustrate a top-down effect
following TERM composition.
</bodyText>
<subsectionHeader confidence="0.880776">
3.5.2 An Example of Feedforward, Feedback,
</subsectionHeader>
<bodyText confidence="0.983409">
Composition, and Subsequent Feedback
This example, shown in Figure 2, will be very
similar to the previous one. Only active informa-
tion discussed is shown as otherwise the figures
become cluttered. The grammar is in a different
state in Figure 2 when successful TERM interpre-
tation occurs at tll (a). This is due to the
activation at t9 of all meanings of B-UI-L-O-IH-NG
(b).
The VTP meanings of /S-A0/ and then
/B-UI-L-0-IH-NG/ make a TERM prediction shown as
it remains in t10 (c). After composition of &amp;quot;the
building&amp;quot; (a) shown in t11, TERM will fire top-
down. It subsequently, through feedback, acti-
vates all meanings of the category type which
predicted the TERM, all VIP type meanings in this
case. This excitatory feedback, raises both VIP
meanings in t12, for saw (d), as well as, building
(e). However, the activity level of &amp;quot;building
does&amp;quot; not reach threshold because of previous
disambiguation of its NOUN meaning. When the VIP
meaning, saw, fires (d) in t12, additional
composition occurs. The VIP interpretation
composes with a suitable TERM (a), one which
matches feature attribute specifications of saw,
</bodyText>
<page confidence="0.995561">
329
</page>
<figure confidence="0.9672753">
.t10 tl 1 t12
TERN
ENOCONT
NOUN
saw
DET-the
building
(b)
5-AO
TR-UR
</figure>
<table confidence="0.991411846153846">
PRAGMATIC ( a ) TERM
building
. -
( • ■
,... - ... • /
—
.. / .4
i •
GRAMMAR&apos; ( C ) ---19.
w / - l&apos;. - - &apos; /
. i — . •
„,
/ . :. 4&apos; / \ N N .... _ /I-7
Li( -• • -. , 1 /(---•—• /
—-.
e ) 4 ■ ) a\-17.... ‘ --4 0—
,...... j t 1 .)
. .&apos;/
I- /
PlION-C T-MEAN (d)
/
a&apos;
- - — I&apos;.. • &apos;N,
...
1.4--1.-- :••■ \ Is. .... • i-•—••••-•••
- ...
=- &amp;quot;I • %--0.- i • 1 cillev
,
...
... ..&amp;quot;
&apos;MONISTIC I
110
C3 CO •...
. - -.
• 1
/ &apos;&apos;&apos;&apos;&apos;&apos;N
- w • - - - -1 • C.)
,.. .... • l /
.......
</table>
<figureCaption confidence="0.538052">
Figure 2.
</figureCaption>
<table confidence="0.990626347826087">
-11 12 13 14
PRAGISAIIG 0.,•••■•
(
I ,n
I %.&apos;li
/ w
i (g)
I
Gil AAAAA ( ) NOUN /
4
/
/ a
/ .1, •
, Pr
),&apos; , ,„ •
•
.4 ,,e :7---4----
1 #
....
Imon-cAT-mismil
1
/
i(
e
.1.. a &apos;..&amp;quot;
■
r7 -
(f)L --1
(b) / i r
•
,&apos;)•
&apos;i I 1:.
I I
0
PR gain G (e) • - ).- ....e.... .
/ (d)
t i
-i- (a) • - -&apos;
-.0---f-•-si &apos;I),
.*-4--0-
r
t: - - -&gt; -i---7—
li ._,
. , „ ----4--
.....•i •
TN-UN 3-0Y 5-A0
</table>
<figureCaption confidence="0.985223">
Figure 3.
</figureCaption>
<bodyText confidence="0.965145">
Phrase Structure Grammar (Gazdar, 1982; 1983)
could be equally suitable.
to produce a VIP type at t13 this will sub-
sequently produce feedback at t14. Neither are
shown.
</bodyText>
<note confidence="0.4323055">
3.5.3 Effect of a Different Grammar State on
Processing
</note>
<bodyText confidence="0.999978794117647">
The final example, Figure 3, will use one of
the &amp;quot;lesion&amp;quot; simulations using HOPE. The grammar
representations remain intact. This example will
present the understanding of the first three words
of the sentence under the condition that they are
presented faster than the system is processing.
Effectively, a slow-down of activation spread to
the grammar is assumed. Figures such as Figure 1
and Figure 3 can be compared to suggest possible
language performance problems and to gain insights
into their possible causes.
In Figure 3, when /TH-UH/ is introduced at tl
(a), all meanings are activated (b) as in Figure
1. The spread of activation to the grammar occurs
in t2 (c). However, the second word, /8-0Y/ (d)
is &amp;quot;heard&amp;quot; at the same time as the activity
reaches the grammar. The predictive activation
spread from the grammar takes effect at t3, when
the new word IS-A0/ (e) is &amp;quot;heard.&amp;quot; The immediate
result is that the NOUN meaning, saw (f), fires
and is interpreted at t4 (g).
This shows in a very simple case, how the
grammar can affect the processing states of an
interactive parallel model. Timing can be seen to
be critical. There are many more critical results
that occur in such &amp;quot;lesion&amp;quot; simulations that
better illustrate such grammatical affects, how-
ever they are very difficult to present in a
static form, other than within a behaviorial
analysis of the overall linguistic performance of
the entire model. This is considered an hypo-
thesized patient profile and is described in
Gigley (1985). Other examples of processing are
presented in detail in Gigley (1982b; 1983).
</bodyText>
<subsectionHeader confidence="0.911799">
3.6 Summary
</subsectionHeader>
<bodyText confidence="0.9999858">
The above figures present a very simple
example of the interactive process. It is hoped
that they provide an idea of the interactions and
feedback, feedforward processing that is coor-
dinated by the state of the grammar. Any pre-
diction in the grammar that is not sufficiently
active affects the process. Any decay that ac-
cidently reduces a grammatical aspect can affect
the process. The timing of activation, the cate-
gorial content and the interactions between in-
terpretation and prediction are important factors
when one considers grammar as part of a func-
tioning dynamic system.
Finally, the Categorial Grammar is one form
of a Context-Free (CF) grammar which provides a
suitable integration of syntactic and semantic
processing. In addition, it has been used in many
studies of English so that instances of grammars
sufficiently defined for the current implementa-
tion level of processing could be found. Other
forms of grammar, such as Lexical-Functional
Grammar (Kaplan and Bresnan, 1982) or Generalized
The criteria to be met all that they can be
encoded as predictive mechanisms, not necessarily
unambiguous or deterministic, and also that they
Specify constraints on compositionality. The
composition depends on adequate definition of
interpretation constraints to assure that it is
&amp;quot;Computed&amp;quot; properly or else suitably marked for
its deviation.
</bodyText>
<sectionHeader confidence="0.995239" genericHeader="conclusions">
4. Conclusion
</sectionHeader>
<bodyText confidence="0.999983185185185">
HOPE provides evidence for how one can view a
grammar as an integrated part of a neurally-
motivated processing model that is psychologically
valid. 4oitable constraints on grammatical form
that are relevant for using any grammar in the CN
context are that the grammar make serial predic-
tions and provide the synchronization information
to coordinate top-down effects of interpretation
with the on-going process.
This type of model suggests that universals
of language are inseparable from how the are
computed. Universals of language may only be
definable within neural substrata and their pro-
cesses. Furthermore, if this view of linguistic
universals holds, then grammar becomes a control
representation that synchronizes the kinds of
signals that occur and when they get propagated.
The states of the grammar in this suggested view
of grammatical function are a form of the rewrite
rules that are the focus of much linguistic
theory.
A neurally motivated processing paradigm for
natural language processing, demonstrates how one
can view an integrated process for language that
employs integrated syntactic and semantic pro-
cessing which relies on a suitable grammatical
form that coordinates the processes.
</bodyText>
<sectionHeader confidence="0.996823" genericHeader="acknowledgments">
5. Acknowledgements
</sectionHeader>
<bodyText confidence="0.999824857142857">
The initial development of the reported
research was supported by an Alfred P. Sloan
Foundation Grant for &amp;quot;A Training Program in Cog-
nitive Science&amp;quot; at the University of Massachusetts
at Amherst. Continuing development is supported
through a Biomedical Research Support Grant at the
University of New Hampshire.
</bodyText>
<sectionHeader confidence="0.996553" genericHeader="references">
6. References
</sectionHeader>
<reference confidence="0.998686333333333">
Ajdukiewicz, O. Die Syntaktische Konnexitat,
1935. Translated as &amp;quot;Syntactic Connection&amp;quot; in
Polish Logic, S. McCall, Oxford, 1967, 207-231.
Arbib, M.A. and Caplan, O. Neurolinguistics
Must Be Computational. Behavioral and Brain
Sciences, 1979, 2, 449-483.
Collins, A.M., and Loftus, E.A. A spreading
activation . theory of semantic processing.
Psychological Review, 1975, 82:6, 407-428.
</reference>
<page confidence="0.981745">
331
</page>
<reference confidence="0.999612049382716">
Cottrell, G.W. and Small, S.L. A Connec-
tionist Scheme for Modelling Word Sense Disam-
biguation. Cognition and Brain Theory, 1983, 8:1,
89-120.
Cottrell, G.W. A model of Lexical Access of
Ambiguous Words. Proceedings of AAAI -- 1984.
Gazdar, G. Phrase Structure Grammar. In P.
Jacobson and G. Pullum (eds.), The Nature of
Syntactic Representation. ReideT7- 6737iFiCht,
1982.
Gazdar, G. Phrase Structure Grammars and
Natural Languages. Proceedings of the Eighth
International Joint Conference on Artificial
Intelligence. Karlsruhe, west Germany, 1983.
Gigley, H.M. Neurolinguistically Based.
Modeling of Natural Language Processing. Paper
presented at the ACL Session of the Linguistic
Society of American Meeting, New York, December,
1981.
Gigley, H.M. A computational neurolinguistic
approach to processing models of sentence compre-
hension. -ZOINS Technical Report 82797-17tiversity
of Massachusetts, Amherst, 1982.
Gigley, H.M. Neurolinguistically constrained
simultation of sentence comprehension: ntegrat-
IF-17777Cial -77117077gence and brain theory.
Ph.0:11717Ution, University of Massachusetts,
Amherst, 1982b.
Gigley, H.M. HOPE -- Al and the Dynamic
Process of Lanaguage Behavior. Cognition and
Brain Theory, 1983, 8, 1.
Gigley, H.M. Computational Neurolinguis-
tics - What is it all about? proceedings of IJCAI
85, Los Angeles, to appear.
Gigley, H.M. Fron HOPE en l&apos;ESPERANCE -- On
the Role of Computational Neurolinguistics in
Cross-Language Studies. Proceedings of COLING 84.
Stanford University, July, 1984.
Goodenough, C., Zurif, E. and Weintraub, S.
Aphasic&apos;s attention to grammatical morphemes,
Language and Speech, 1977, 11-19.
Goodglass, H. Agrammatism. In H. Whitaker
and H.A. Whitaker (eds.) Studies in Neurolinguis-
tics, lo1. 1, Academic Press, 1976. 237-260.
Goodglass, H. and Berko, J. Agrammatism and
inflectional morphology in English. Journal of
Speech, and Hearing Research, 1960, 3, 257=-107—
Goodglass, H., Gleason, J., Bernholtz, N. and
Hyde, M. Some Linguistic Structures in the Speech
of a Braces Aphasic. Cortex, 1970, 8, 191-212.
Hinton, G.E. Implementing Semantic Nets in
Parallel Hardware. In G.E. Hinton and J.A.
Anderson (eds.), Parallel Models of Associative
Memory. Lawrence -E--WaT-sei Associates Publishers,
1981.
Kaplan, R.M. and Bresnan, J. Lexical-
Functional Grammar: A Formal System for Gram-
matical Representation. In J. Bresnan (ed.), The
Mental Representation of Grammatical Relations.
MIT Press, 1982.
Lavorel, P.M. and Gigley, H.M. Elements pour
une theorie generale des machines intelligentes.
Intellectica, 1983, 7, 20-38.
Lewis, O. General Semantics. In Davidson
and Harmon (eds.), Semantics of Natural Language,
1972, 169-218.
Quillian, . M.R. Semantic Memory. In M.
Minsky (ed.), Semantic Information Processing.
Cambridge, Ma.: MIT Press, 1980.
Small, S., Cottrell, G., and Shastri, L.
Toward connectionist parsing. Proceedings of the
National Conference on Artificial Intelligence,
Pittsburgh, PA:
Waltz, O. and Pollack, J. Massively Parallel
Parsing: A Strongly Interactive Model of Natural
Language Interpretation. Cognitive Science. In
press.
Zurif, E.B. and Blumstein, S.E. Language and
the Brain. In M. Halle, J. Bresnan, and G.
Miller, (eds.), Linguistic Theory and
Psychological Reality. MIT Press, 1978.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.936622">
<title confidence="0.999478">GRAMMAR VIEWED AS A FUNCTIONING PART OF A COGNITIVE SYSTEM</title>
<author confidence="0.999996">Helen M Gigley</author>
<affiliation confidence="0.9980635">Department of Computer Science University of New Hampshire</affiliation>
<address confidence="0.994118">Durham, NH 03824</address>
<abstract confidence="0.996950944444444">How can grammar be viewed as a functional part of a cognitive system? Given a neural basis for the processing control paradigm of language performance, what roles does &amp;quot;grammar&amp;quot; play? Is there evidence to suggest that grammatical processing can be independent from other aspects of language processing? This paper will focus on these issues and suggest answers within the context of one computational solution. The example model of sentence comprehension, HOPE, is intended to demonstrate both representational considerations for a grammar within such a system as well as to illustrate that by interpreting a grammar as a feedback control mechanism of a &amp;quot;neural-like&amp;quot; process, additional insights into language processing can be obtained.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O Ajdukiewicz</author>
</authors>
<title>Die Syntaktische Konnexitat,</title>
<date>1935</date>
<booktitle>in Polish Logic, S. McCall,</booktitle>
<pages>207--231</pages>
<location>Oxford,</location>
<contexts>
<context position="14214" citStr="Ajdukiewicz, 1935" startWordPosition="2150" endWordPosition="2151">ithin a space or hypergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control must be given. 3.2 The Local Representation of the Grammar The grammar space contains the locally defined grammar for the process. The current model defined within the HOPE system includes a form of a Categorial Grammar (Ajdukiewicz, 1935; Lewis, 1972). Although the original use of the grammar is not heeded, the relationship that ensues between a well defined syntactic form and a &amp;quot;final state&amp;quot; meaning representation is borrowed. Validity of the &amp;quot;final state&amp;quot; meaning is not the issue. Final state here means, at the end of the process. As previously mentioned, typed semantics is also not rigidly enforced in the current model. HOPE allows one to define a lexicon within user selected syntactic types, and allows one to define a suitable grammar of the selected types in the prescribed form as well. The grammar may be defined to suit</context>
</contexts>
<marker>Ajdukiewicz, 1935</marker>
<rawString>Ajdukiewicz, O. Die Syntaktische Konnexitat, 1935. Translated as &amp;quot;Syntactic Connection&amp;quot; in Polish Logic, S. McCall, Oxford, 1967, 207-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Arbib</author>
<author>O Caplan</author>
</authors>
<date>1979</date>
<journal>Neurolinguistics Must Be Computational. Behavioral and Brain Sciences,</journal>
<volume>2</volume>
<pages>449--483</pages>
<contexts>
<context position="2769" citStr="Arbib and Caplan (1979)" startWordPosition="416" endWordPosition="419">inguistic function (Cottrell, 1984; Cottrell and Small, 1983; Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985; Small, Cottrell and Shastri, 1982; Waltz and Pollack, in press). These models include assumptions about memory processing within a spreading activation framework (Collins and Loftus, 1975; Hinton, 1981; Quillian, 1968/1980), and a parallel, interactive control paradigm for the processing. They differ in the explicit implementations of these theories and the degree to which they claim to be psychologically valid. Computational Neurolinguistics (CN), first suggested as a problem domain by Arbib and Caplan (1979), is an Artificial Intelligence (AI) approach to modelling neural processes which subserve natural language performance. As CN has developed, such models are highly constrained by behavioral evidence, both normal and pathological. CN provides a framework for defining cognitive models of natural language performance of behavior that includes claims of validity at two levels, the natural computation or neural-like processing level, and at the system result or behavioral level. Using one implementation of a CN model, HOPE (Gigley, 1981; 1982a; 1982b; 1983) a model of single sentence comprehension</context>
</contexts>
<marker>Arbib, Caplan, 1979</marker>
<rawString>Arbib, M.A. and Caplan, O. Neurolinguistics Must Be Computational. Behavioral and Brain Sciences, 1979, 2, 449-483.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Collins</author>
<author>E A Loftus</author>
</authors>
<title>A spreading activation . theory of semantic processing. Psychological Review,</title>
<date>1975</date>
<pages>82--6</pages>
<contexts>
<context position="2441" citStr="Collins and Loftus, 1975" startWordPosition="368" endWordPosition="371">ithin an implemented model of such processing, HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985). This view of grammatical &amp;quot;process&amp;quot; suggests that neural processing should be included as a basis for defining what is universal in language. 2. Background There are currently several approaches to developing cognitive models of linguistic function (Cottrell, 1984; Cottrell and Small, 1983; Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985; Small, Cottrell and Shastri, 1982; Waltz and Pollack, in press). These models include assumptions about memory processing within a spreading activation framework (Collins and Loftus, 1975; Hinton, 1981; Quillian, 1968/1980), and a parallel, interactive control paradigm for the processing. They differ in the explicit implementations of these theories and the degree to which they claim to be psychologically valid. Computational Neurolinguistics (CN), first suggested as a problem domain by Arbib and Caplan (1979), is an Artificial Intelligence (AI) approach to modelling neural processes which subserve natural language performance. As CN has developed, such models are highly constrained by behavioral evidence, both normal and pathological. CN provides a framework for defining cogn</context>
<context position="10406" citStr="Collins and Loftus, 1975" startWordPosition="1596" endWordPosition="1599">t implementation, all information initially has a resting activity value. This activity value can be modified over time depending on the sentential input. Furthermore, there is an automatic activity decay scheme intended to represent memory processing which is 325 It is in the interaction of the results of these asychronous processes that the process of comprehension is simulated. based on the state of the information, whether it has reached threshold and fired or not. Activity is propagated in a fixed-time scheme to all &amp;quot;connected&amp;quot; aspects of the meaning of the words by spreading activation (Collins and Loftus, 1975; 1983; Hinton, 1981; Quillian, 1968/1980). Simultaneously, information interacts asynchronously due to threshold firing. A state of threshold firing is realized as a result of summed inputs over time that are the result of the fixed-time spreading activation, other threshold firing or memory cilcay effects in combination. The time course of new information introduction, which initiates activity spread and automatic memory decay is parameterized due to the underlying reason for designing such models (Gigley, 1982b; 1983; 1985). The exact serial-order processes that occur at any time-slice of t</context>
</contexts>
<marker>Collins, Loftus, 1975</marker>
<rawString>Collins, A.M., and Loftus, E.A. A spreading activation . theory of semantic processing. Psychological Review, 1975, 82:6, 407-428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G W Cottrell</author>
<author>S L Small</author>
</authors>
<title>A Connectionist Scheme for Modelling Word Sense Disambiguation. Cognition and Brain Theory,</title>
<date>1983</date>
<volume>8</volume>
<pages>89--120</pages>
<contexts>
<context position="2206" citStr="Cottrell and Small, 1983" startWordPosition="335" endWordPosition="338"> within semantic and syntactic levels separately. It furthermore acts as a &amp;quot;conductor&amp;quot; of a time-synchronized process. Aspects of how a grammar might be processed within a cognitive view of sentence comprehension will be demonstrated within an implemented model of such processing, HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985). This view of grammatical &amp;quot;process&amp;quot; suggests that neural processing should be included as a basis for defining what is universal in language. 2. Background There are currently several approaches to developing cognitive models of linguistic function (Cottrell, 1984; Cottrell and Small, 1983; Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985; Small, Cottrell and Shastri, 1982; Waltz and Pollack, in press). These models include assumptions about memory processing within a spreading activation framework (Collins and Loftus, 1975; Hinton, 1981; Quillian, 1968/1980), and a parallel, interactive control paradigm for the processing. They differ in the explicit implementations of these theories and the degree to which they claim to be psychologically valid. Computational Neurolinguistics (CN), first suggested as a problem domain by Arbib and Caplan (1979), is an Artificial Intelligence (AI) </context>
</contexts>
<marker>Cottrell, Small, 1983</marker>
<rawString>Cottrell, G.W. and Small, S.L. A Connectionist Scheme for Modelling Word Sense Disambiguation. Cognition and Brain Theory, 1983, 8:1, 89-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G W Cottrell</author>
</authors>
<title>A model of Lexical Access of Ambiguous Words.</title>
<date>1984</date>
<booktitle>Proceedings of AAAI --</booktitle>
<contexts>
<context position="2180" citStr="Cottrell, 1984" startWordPosition="333" endWordPosition="334">n be interpreted within semantic and syntactic levels separately. It furthermore acts as a &amp;quot;conductor&amp;quot; of a time-synchronized process. Aspects of how a grammar might be processed within a cognitive view of sentence comprehension will be demonstrated within an implemented model of such processing, HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985). This view of grammatical &amp;quot;process&amp;quot; suggests that neural processing should be included as a basis for defining what is universal in language. 2. Background There are currently several approaches to developing cognitive models of linguistic function (Cottrell, 1984; Cottrell and Small, 1983; Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985; Small, Cottrell and Shastri, 1982; Waltz and Pollack, in press). These models include assumptions about memory processing within a spreading activation framework (Collins and Loftus, 1975; Hinton, 1981; Quillian, 1968/1980), and a parallel, interactive control paradigm for the processing. They differ in the explicit implementations of these theories and the degree to which they claim to be psychologically valid. Computational Neurolinguistics (CN), first suggested as a problem domain by Arbib and Caplan (1979), is an Art</context>
</contexts>
<marker>Cottrell, 1984</marker>
<rawString>Cottrell, G.W. A model of Lexical Access of Ambiguous Words. Proceedings of AAAI -- 1984.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Gazdar</author>
</authors>
<title>Phrase Structure Grammar. In</title>
<booktitle>The Nature of Syntactic Representation. ReideT7- 6737iFiCht,</booktitle>
<pages>1982</pages>
<editor>P. Jacobson and G. Pullum (eds.),</editor>
<marker>Gazdar, </marker>
<rawString>Gazdar, G. Phrase Structure Grammar. In P. Jacobson and G. Pullum (eds.), The Nature of Syntactic Representation. ReideT7- 6737iFiCht, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Phrase Structure Grammars and Natural Languages.</title>
<date>1983</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence.</booktitle>
<location>Karlsruhe, west</location>
<marker>Gazdar, 1983</marker>
<rawString>Gazdar, G. Phrase Structure Grammars and Natural Languages. Proceedings of the Eighth International Joint Conference on Artificial Intelligence. Karlsruhe, west Germany, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Gigley</author>
</authors>
<title>Neurolinguistically Based. Modeling of Natural Language Processing. Paper presented at the ACL Session of the Linguistic Society of American Meeting,</title>
<date>1981</date>
<location>New York,</location>
<contexts>
<context position="1882" citStr="Gigley, 1981" startWordPosition="288" endWordPosition="289">processing does not grow trees explicitly; it does not transform trees explicitly; nor does it move constituents. In this type of model, a grammar is an explicit encoded representation that coordinates the integrated parallel process. It provides the interfaces between parallel processes that can be interpreted within semantic and syntactic levels separately. It furthermore acts as a &amp;quot;conductor&amp;quot; of a time-synchronized process. Aspects of how a grammar might be processed within a cognitive view of sentence comprehension will be demonstrated within an implemented model of such processing, HOPE (Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985). This view of grammatical &amp;quot;process&amp;quot; suggests that neural processing should be included as a basis for defining what is universal in language. 2. Background There are currently several approaches to developing cognitive models of linguistic function (Cottrell, 1984; Cottrell and Small, 1983; Gigley, 1981; 1982a; 1982b; 1983; 1984; 1985; Small, Cottrell and Shastri, 1982; Waltz and Pollack, in press). These models include assumptions about memory processing within a spreading activation framework (Collins and Loftus, 1975; Hinton, 1981; Quillian, 1968/1980), and</context>
<context position="3307" citStr="Gigley, 1981" startWordPosition="498" endWordPosition="499">stics (CN), first suggested as a problem domain by Arbib and Caplan (1979), is an Artificial Intelligence (AI) approach to modelling neural processes which subserve natural language performance. As CN has developed, such models are highly constrained by behavioral evidence, both normal and pathological. CN provides a framework for defining cognitive models of natural language performance of behavior that includes claims of validity at two levels, the natural computation or neural-like processing level, and at the system result or behavioral level. Using one implementation of a CN model, HOPE (Gigley, 1981; 1982a; 1982b; 1983) a model of single sentence comprehension, the remainder of the paper will illustrate how the role of grammar can be integrated into the design of such a model. It will emphasize the importance of the parallel control assumptions in constraining the representation in which the grammar is encoded. It will demonstrate how the grammar contributes to control the coordination of the parallel, asynchronous processes included in the model. The HOPE model is chosen explicitly because the underlying assumptions in its design are intended to be psychologically valid on two levels, w</context>
</contexts>
<marker>Gigley, 1981</marker>
<rawString>Gigley, H.M. Neurolinguistically Based. Modeling of Natural Language Processing. Paper presented at the ACL Session of the Linguistic Society of American Meeting, New York, December, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Gigley</author>
</authors>
<title>A computational neurolinguistic approach to processing models of sentence comprehension.</title>
<date>1982</date>
<tech>ZOINS Technical Report 82797-17tiversity</tech>
<institution>of Massachusetts,</institution>
<location>Amherst,</location>
<contexts>
<context position="4012" citStr="Gigley (1982" startWordPosition="611" endWordPosition="612">ll illustrate how the role of grammar can be integrated into the design of such a model. It will emphasize the importance of the parallel control assumptions in constraining the representation in which the grammar is encoded. It will demonstrate how the grammar contributes to control the coordination of the parallel, asynchronous processes included in the model. The HOPE model is chosen explicitly because the underlying assumptions in its design are intended to be psychologically valid on two levels, while the other referenced models do not make such claims. The complete model is discussed in Gigley (1982a; 1982b; 1983) and will be summarized here to illustrate the role of the grammar in its function. The suggested implications and goals for including neurophysiological evidence in designing such models have been discussed else324 where in Lavorel and Gigley (1983) and will be included only as they relate to the role and function of the grammar. 2.1 Summary of Included Knowledge and its Representation Types of representations included in the HOPE model, phonetic, categorially accessed meanings, grammar, and pragmatic or local context, receive support as separately definable knowledge within st</context>
<context position="10924" citStr="Gigley, 1982" startWordPosition="1673" endWordPosition="1674">nnected&amp;quot; aspects of the meaning of the words by spreading activation (Collins and Loftus, 1975; 1983; Hinton, 1981; Quillian, 1968/1980). Simultaneously, information interacts asynchronously due to threshold firing. A state of threshold firing is realized as a result of summed inputs over time that are the result of the fixed-time spreading activation, other threshold firing or memory cilcay effects in combination. The time course of new information introduction, which initiates activity spread and automatic memory decay is parameterized due to the underlying reason for designing such models (Gigley, 1982b; 1983; 1985). The exact serial-order processes that occur at any time-slice of the process depend on the &amp;quot;current state&amp;quot; of the global information; they are context dependent. The serial-order processes include: (1) NEW-WORD-RECOGNITION: Introduction of the next phonetically recognized word in the sentence. (2) DECAY: Automatic memory decay exponentially reduces the activity of all active information that does not receive additional input. It is an important part of the neural processes that occur during memory processing. (3) REFRACTORY-STATE-ACTIVATION:(--- An automatic change of state tha</context>
<context position="32084" citStr="Gigley (1982" startWordPosition="5147" endWordPosition="5148">rpreted at t4 (g). This shows in a very simple case, how the grammar can affect the processing states of an interactive parallel model. Timing can be seen to be critical. There are many more critical results that occur in such &amp;quot;lesion&amp;quot; simulations that better illustrate such grammatical affects, however they are very difficult to present in a static form, other than within a behaviorial analysis of the overall linguistic performance of the entire model. This is considered an hypothesized patient profile and is described in Gigley (1985). Other examples of processing are presented in detail in Gigley (1982b; 1983). 3.6 Summary The above figures present a very simple example of the interactive process. It is hoped that they provide an idea of the interactions and feedback, feedforward processing that is coordinated by the state of the grammar. Any prediction in the grammar that is not sufficiently active affects the process. Any decay that accidently reduces a grammatical aspect can affect the process. The timing of activation, the categorial content and the interactions between interpretation and prediction are important factors when one considers grammar as part of a functioning dynamic system</context>
</contexts>
<marker>Gigley, 1982</marker>
<rawString>Gigley, H.M. A computational neurolinguistic approach to processing models of sentence comprehension. -ZOINS Technical Report 82797-17tiversity of Massachusetts, Amherst, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Gigley</author>
</authors>
<title>Neurolinguistically constrained simultation of sentence comprehension: ntegratIF-17777Cial -77117077gence and brain theory.</title>
<date>1982</date>
<tech>Ph.0:11717Ution,</tech>
<institution>University of Massachusetts,</institution>
<location>Amherst,</location>
<contexts>
<context position="4012" citStr="Gigley (1982" startWordPosition="611" endWordPosition="612">ll illustrate how the role of grammar can be integrated into the design of such a model. It will emphasize the importance of the parallel control assumptions in constraining the representation in which the grammar is encoded. It will demonstrate how the grammar contributes to control the coordination of the parallel, asynchronous processes included in the model. The HOPE model is chosen explicitly because the underlying assumptions in its design are intended to be psychologically valid on two levels, while the other referenced models do not make such claims. The complete model is discussed in Gigley (1982a; 1982b; 1983) and will be summarized here to illustrate the role of the grammar in its function. The suggested implications and goals for including neurophysiological evidence in designing such models have been discussed else324 where in Lavorel and Gigley (1983) and will be included only as they relate to the role and function of the grammar. 2.1 Summary of Included Knowledge and its Representation Types of representations included in the HOPE model, phonetic, categorially accessed meanings, grammar, and pragmatic or local context, receive support as separately definable knowledge within st</context>
<context position="10924" citStr="Gigley, 1982" startWordPosition="1673" endWordPosition="1674">nnected&amp;quot; aspects of the meaning of the words by spreading activation (Collins and Loftus, 1975; 1983; Hinton, 1981; Quillian, 1968/1980). Simultaneously, information interacts asynchronously due to threshold firing. A state of threshold firing is realized as a result of summed inputs over time that are the result of the fixed-time spreading activation, other threshold firing or memory cilcay effects in combination. The time course of new information introduction, which initiates activity spread and automatic memory decay is parameterized due to the underlying reason for designing such models (Gigley, 1982b; 1983; 1985). The exact serial-order processes that occur at any time-slice of the process depend on the &amp;quot;current state&amp;quot; of the global information; they are context dependent. The serial-order processes include: (1) NEW-WORD-RECOGNITION: Introduction of the next phonetically recognized word in the sentence. (2) DECAY: Automatic memory decay exponentially reduces the activity of all active information that does not receive additional input. It is an important part of the neural processes that occur during memory processing. (3) REFRACTORY-STATE-ACTIVATION:(--- An automatic change of state tha</context>
<context position="32084" citStr="Gigley (1982" startWordPosition="5147" endWordPosition="5148">rpreted at t4 (g). This shows in a very simple case, how the grammar can affect the processing states of an interactive parallel model. Timing can be seen to be critical. There are many more critical results that occur in such &amp;quot;lesion&amp;quot; simulations that better illustrate such grammatical affects, however they are very difficult to present in a static form, other than within a behaviorial analysis of the overall linguistic performance of the entire model. This is considered an hypothesized patient profile and is described in Gigley (1985). Other examples of processing are presented in detail in Gigley (1982b; 1983). 3.6 Summary The above figures present a very simple example of the interactive process. It is hoped that they provide an idea of the interactions and feedback, feedforward processing that is coordinated by the state of the grammar. Any prediction in the grammar that is not sufficiently active affects the process. Any decay that accidently reduces a grammatical aspect can affect the process. The timing of activation, the categorial content and the interactions between interpretation and prediction are important factors when one considers grammar as part of a functioning dynamic system</context>
</contexts>
<marker>Gigley, 1982</marker>
<rawString>Gigley, H.M. Neurolinguistically constrained simultation of sentence comprehension: ntegratIF-17777Cial -77117077gence and brain theory. Ph.0:11717Ution, University of Massachusetts, Amherst, 1982b.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M HOPE Gigley</author>
</authors>
<title>Al and the Dynamic Process of Lanaguage Behavior. Cognition and Brain Theory,</title>
<date>1983</date>
<volume>8</volume>
<contexts>
<context position="4277" citStr="Gigley (1983)" startWordPosition="653" endWordPosition="654">ntributes to control the coordination of the parallel, asynchronous processes included in the model. The HOPE model is chosen explicitly because the underlying assumptions in its design are intended to be psychologically valid on two levels, while the other referenced models do not make such claims. The complete model is discussed in Gigley (1982a; 1982b; 1983) and will be summarized here to illustrate the role of the grammar in its function. The suggested implications and goals for including neurophysiological evidence in designing such models have been discussed else324 where in Lavorel and Gigley (1983) and will be included only as they relate to the role and function of the grammar. 2.1 Summary of Included Knowledge and its Representation Types of representations included in the HOPE model, phonetic, categorially accessed meanings, grammar, and pragmatic or local context, receive support as separately definable knowledge within studies of aphasia. There is a vast literature concerning what aspects of language are independently affected in aphasia that has been used as a basis for deciding these representations. (See Gigley, 1982b for complete documentation.) Information that is defined with</context>
<context position="8231" citStr="Gigley, 1983" startWordPosition="1260" endWordPosition="1261">d meaning associated with a name can only be evaluated within the context, or contexts, in which the name occurs. Meaning for any name is contextually evaluable. The explicit meaning within any space depends on the rest of the state of the space, which furthermore depends on what previous processing has occurred to affect the state of that space. 2.2 Summary of the Processing Paradigm The development of CN models emphasizes process. A primary assumption of this approach is that neural-like computations must be included in models which attempt to simulate any cognitive behavior (Cf Lavorel and Gigley, 1983), specifically natural language processing in this case. Furthermore, CN includes the assumption that time is a critical factor in neural procesTi7q mechanisiria—That—TE7Ein be airliMicant factor In language behavior in its degraded or &amp;quot;lesioned&amp;quot; state. Simulation of a process paradigm for natural language comprehension in HOPE is achieved by incorporating a neurally plausible control that is internal to the processing mechanism. There is no external process that decides which path or process to execute next based on the current state of the solution space. The process is time-locked; at each </context>
</contexts>
<marker>Gigley, 1983</marker>
<rawString>Gigley, H.M. HOPE -- Al and the Dynamic Process of Lanaguage Behavior. Cognition and Brain Theory, 1983, 8, 1.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H M Gigley</author>
</authors>
<title>Computational Neurolinguistics - What is it all about?</title>
<booktitle>proceedings of IJCAI 85,</booktitle>
<location>Los Angeles,</location>
<note>to appear.</note>
<marker>Gigley, </marker>
<rawString>Gigley, H.M. Computational Neurolinguistics - What is it all about? proceedings of IJCAI 85, Los Angeles, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Gigley</author>
</authors>
<title>Fron HOPE en l&apos;ESPERANCE -- On the Role of Computational Neurolinguistics in Cross-Language Studies.</title>
<date>1984</date>
<booktitle>Proceedings of COLING 84.</booktitle>
<institution>Stanford University,</institution>
<marker>Gigley, 1984</marker>
<rawString>Gigley, H.M. Fron HOPE en l&apos;ESPERANCE -- On the Role of Computational Neurolinguistics in Cross-Language Studies. Proceedings of COLING 84. Stanford University, July, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Goodenough</author>
<author>E Zurif</author>
<author>S Weintraub</author>
</authors>
<title>Aphasic&apos;s attention to grammatical morphemes, Language and Speech,</title>
<date>1977</date>
<pages>11--19</pages>
<contexts>
<context position="13378" citStr="Goodenough, Zurif, and Weintraub, 1977" startWordPosition="2017" endWordPosition="2021">hin our behavioral approach to studying natural language processing, several considerations must be met. Justification must be made for separate representations of information and, whenever possible, neural processing support must be found. 3.1 Evidence for a Separate Representation of Grammar Neurolinguistic and psycholinguistic evidence supports a separately interpretable representation for a grammar. The neurolinguistic literature demonstrates that the grammar can be affected in isolation from other aspects of language function. (Cf Studies of agrammatic and Broca&apos;s aphasia as described in Goodenough, Zurif, and Weintraub, 1977; Goodglass, 1976; Goodglass and Berko, 1960; Goodglass, Gleason, Bernholtz, and Hyde, 1970; Zurif and Blumstein, 1978). In the HOPE model, this separation is achieved by including all relevant grammatical information within a space or hypergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control mu</context>
</contexts>
<marker>Goodenough, Zurif, Weintraub, 1977</marker>
<rawString>Goodenough, C., Zurif, E. and Weintraub, S. Aphasic&apos;s attention to grammatical morphemes, Language and Speech, 1977, 11-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Agrammatism Goodglass</author>
</authors>
<date>1976</date>
<booktitle>Studies in Neurolinguistics, lo1. 1,</booktitle>
<pages>237--260</pages>
<editor>In H. Whitaker and H.A. Whitaker (eds.)</editor>
<publisher>Academic Press,</publisher>
<contexts>
<context position="13395" citStr="Goodglass, 1976" startWordPosition="2022" endWordPosition="2023">natural language processing, several considerations must be met. Justification must be made for separate representations of information and, whenever possible, neural processing support must be found. 3.1 Evidence for a Separate Representation of Grammar Neurolinguistic and psycholinguistic evidence supports a separately interpretable representation for a grammar. The neurolinguistic literature demonstrates that the grammar can be affected in isolation from other aspects of language function. (Cf Studies of agrammatic and Broca&apos;s aphasia as described in Goodenough, Zurif, and Weintraub, 1977; Goodglass, 1976; Goodglass and Berko, 1960; Goodglass, Gleason, Bernholtz, and Hyde, 1970; Zurif and Blumstein, 1978). In the HOPE model, this separation is achieved by including all relevant grammatical information within a space or hypergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control must be given. 3.2 </context>
</contexts>
<marker>Goodglass, 1976</marker>
<rawString>Goodglass, H. Agrammatism. In H. Whitaker and H.A. Whitaker (eds.) Studies in Neurolinguistics, lo1. 1, Academic Press, 1976. 237-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Goodglass</author>
<author>J Berko</author>
</authors>
<title>Agrammatism and inflectional morphology in English.</title>
<date>1960</date>
<journal>Journal of Speech, and Hearing Research,</journal>
<volume>3</volume>
<pages>257--107</pages>
<contexts>
<context position="13422" citStr="Goodglass and Berko, 1960" startWordPosition="2024" endWordPosition="2027">processing, several considerations must be met. Justification must be made for separate representations of information and, whenever possible, neural processing support must be found. 3.1 Evidence for a Separate Representation of Grammar Neurolinguistic and psycholinguistic evidence supports a separately interpretable representation for a grammar. The neurolinguistic literature demonstrates that the grammar can be affected in isolation from other aspects of language function. (Cf Studies of agrammatic and Broca&apos;s aphasia as described in Goodenough, Zurif, and Weintraub, 1977; Goodglass, 1976; Goodglass and Berko, 1960; Goodglass, Gleason, Bernholtz, and Hyde, 1970; Zurif and Blumstein, 1978). In the HOPE model, this separation is achieved by including all relevant grammatical information within a space or hypergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control must be given. 3.2 The Local Representation of</context>
</contexts>
<marker>Goodglass, Berko, 1960</marker>
<rawString>Goodglass, H. and Berko, J. Agrammatism and inflectional morphology in English. Journal of Speech, and Hearing Research, 1960, 3, 257=-107—</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Goodglass</author>
<author>J Gleason</author>
<author>N Bernholtz</author>
<author>M Hyde</author>
</authors>
<title>Some Linguistic Structures in the Speech of a Braces Aphasic. Cortex,</title>
<date>1970</date>
<volume>8</volume>
<pages>191--212</pages>
<contexts>
<context position="13469" citStr="Goodglass, Gleason, Bernholtz, and Hyde, 1970" startWordPosition="2028" endWordPosition="2033">rations must be met. Justification must be made for separate representations of information and, whenever possible, neural processing support must be found. 3.1 Evidence for a Separate Representation of Grammar Neurolinguistic and psycholinguistic evidence supports a separately interpretable representation for a grammar. The neurolinguistic literature demonstrates that the grammar can be affected in isolation from other aspects of language function. (Cf Studies of agrammatic and Broca&apos;s aphasia as described in Goodenough, Zurif, and Weintraub, 1977; Goodglass, 1976; Goodglass and Berko, 1960; Goodglass, Gleason, Bernholtz, and Hyde, 1970; Zurif and Blumstein, 1978). In the HOPE model, this separation is achieved by including all relevant grammatical information within a space or hypergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control must be given. 3.2 The Local Representation of the Grammar The grammar space contains the loc</context>
</contexts>
<marker>Goodglass, Gleason, Bernholtz, Hyde, 1970</marker>
<rawString>Goodglass, H., Gleason, J., Bernholtz, N. and Hyde, M. Some Linguistic Structures in the Speech of a Braces Aphasic. Cortex, 1970, 8, 191-212.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G E Hinton</author>
</authors>
<title>Implementing Semantic Nets in Parallel Hardware.</title>
<booktitle>Parallel Models of Associative</booktitle>
<editor>In G.E. Hinton and J.A. Anderson (eds.),</editor>
<marker>Hinton, </marker>
<rawString>Hinton, G.E. Implementing Semantic Nets in Parallel Hardware. In G.E. Hinton and J.A. Anderson (eds.), Parallel Models of Associative</rawString>
</citation>
<citation valid="true">
<authors>
<author>Memory</author>
</authors>
<title>Lawrence -E--WaT-sei Associates Publishers,</title>
<date>1981</date>
<marker>Memory, 1981</marker>
<rawString>Memory. Lawrence -E--WaT-sei Associates Publishers, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>LexicalFunctional Grammar: A Formal System for Grammatical Representation.</title>
<date>1982</date>
<editor>In J. Bresnan (ed.),</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="33097" citStr="Kaplan and Bresnan, 1982" startWordPosition="5306" endWordPosition="5309">ct the process. The timing of activation, the categorial content and the interactions between interpretation and prediction are important factors when one considers grammar as part of a functioning dynamic system. Finally, the Categorial Grammar is one form of a Context-Free (CF) grammar which provides a suitable integration of syntactic and semantic processing. In addition, it has been used in many studies of English so that instances of grammars sufficiently defined for the current implementation level of processing could be found. Other forms of grammar, such as Lexical-Functional Grammar (Kaplan and Bresnan, 1982) or Generalized The criteria to be met all that they can be encoded as predictive mechanisms, not necessarily unambiguous or deterministic, and also that they Specify constraints on compositionality. The composition depends on adequate definition of interpretation constraints to assure that it is &amp;quot;Computed&amp;quot; properly or else suitably marked for its deviation. 4. Conclusion HOPE provides evidence for how one can view a grammar as an integrated part of a neurallymotivated processing model that is psychologically valid. 4oitable constraints on grammatical form that are relevant for using any gramm</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Kaplan, R.M. and Bresnan, J. LexicalFunctional Grammar: A Formal System for Grammatical Representation. In J. Bresnan (ed.), The Mental Representation of Grammatical Relations. MIT Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P M Lavorel</author>
<author>H M Gigley</author>
</authors>
<title>Elements pour une theorie generale des machines intelligentes. Intellectica,</title>
<date>1983</date>
<contexts>
<context position="4277" citStr="Lavorel and Gigley (1983)" startWordPosition="651" endWordPosition="654">e grammar contributes to control the coordination of the parallel, asynchronous processes included in the model. The HOPE model is chosen explicitly because the underlying assumptions in its design are intended to be psychologically valid on two levels, while the other referenced models do not make such claims. The complete model is discussed in Gigley (1982a; 1982b; 1983) and will be summarized here to illustrate the role of the grammar in its function. The suggested implications and goals for including neurophysiological evidence in designing such models have been discussed else324 where in Lavorel and Gigley (1983) and will be included only as they relate to the role and function of the grammar. 2.1 Summary of Included Knowledge and its Representation Types of representations included in the HOPE model, phonetic, categorially accessed meanings, grammar, and pragmatic or local context, receive support as separately definable knowledge within studies of aphasia. There is a vast literature concerning what aspects of language are independently affected in aphasia that has been used as a basis for deciding these representations. (See Gigley, 1982b for complete documentation.) Information that is defined with</context>
<context position="8231" citStr="Lavorel and Gigley, 1983" startWordPosition="1258" endWordPosition="1261">y interpreted meaning associated with a name can only be evaluated within the context, or contexts, in which the name occurs. Meaning for any name is contextually evaluable. The explicit meaning within any space depends on the rest of the state of the space, which furthermore depends on what previous processing has occurred to affect the state of that space. 2.2 Summary of the Processing Paradigm The development of CN models emphasizes process. A primary assumption of this approach is that neural-like computations must be included in models which attempt to simulate any cognitive behavior (Cf Lavorel and Gigley, 1983), specifically natural language processing in this case. Furthermore, CN includes the assumption that time is a critical factor in neural procesTi7q mechanisiria—That—TE7Ein be airliMicant factor In language behavior in its degraded or &amp;quot;lesioned&amp;quot; state. Simulation of a process paradigm for natural language comprehension in HOPE is achieved by incorporating a neurally plausible control that is internal to the processing mechanism. There is no external process that decides which path or process to execute next based on the current state of the solution space. The process is time-locked; at each </context>
</contexts>
<marker>Lavorel, Gigley, 1983</marker>
<rawString>Lavorel, P.M. and Gigley, H.M. Elements pour une theorie generale des machines intelligentes. Intellectica, 1983, 7, 20-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Lewis</author>
</authors>
<title>General Semantics. In</title>
<date>1972</date>
<booktitle>Semantics of Natural Language,</booktitle>
<pages>169--218</pages>
<editor>Davidson and Harmon (eds.),</editor>
<contexts>
<context position="14228" citStr="Lewis, 1972" startWordPosition="2152" endWordPosition="2153">pergraph called the grammar. The associated interpretation functions for each grammatical type provide the interface with the pragmatic representation. Before describing the nature of the local representation&amp;quot; of the currently included grammar, a brief discussion of the structure of the grammar and the role of the grammar in the global nature of the control must be given. 3.2 The Local Representation of the Grammar The grammar space contains the locally defined grammar for the process. The current model defined within the HOPE system includes a form of a Categorial Grammar (Ajdukiewicz, 1935; Lewis, 1972). Although the original use of the grammar is not heeded, the relationship that ensues between a well defined syntactic form and a &amp;quot;final state&amp;quot; meaning representation is borrowed. Validity of the &amp;quot;final state&amp;quot; meaning is not the issue. Final state here means, at the end of the process. As previously mentioned, typed semantics is also not rigidly enforced in the current model. HOPE allows one to define a lexicon within user selected syntactic types, and allows one to define a suitable grammar of the selected types in the prescribed form as well. The grammar may be defined to suit the aspects o</context>
</contexts>
<marker>Lewis, 1972</marker>
<rawString>Lewis, O. General Semantics. In Davidson and Harmon (eds.), Semantics of Natural Language, 1972, 169-218.</rawString>
</citation>
<citation valid="true">
<date>1980</date>
<booktitle>Semantic Information Processing.</booktitle>
<editor>Quillian, . M.R. Semantic Memory. In M. Minsky (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Ma.:</location>
<marker>1980</marker>
<rawString>Quillian, . M.R. Semantic Memory. In M. Minsky (ed.), Semantic Information Processing. Cambridge, Ma.: MIT Press, 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Small</author>
<author>G Cottrell</author>
<author>L Shastri</author>
</authors>
<title>Toward connectionist parsing.</title>
<booktitle>Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<location>Pittsburgh, PA:</location>
<marker>Small, Cottrell, Shastri, </marker>
<rawString>Small, S., Cottrell, G., and Shastri, L. Toward connectionist parsing. Proceedings of the National Conference on Artificial Intelligence, Pittsburgh, PA:</rawString>
</citation>
<citation valid="false">
<authors>
<author>O Waltz</author>
<author>J Pollack</author>
</authors>
<title>Massively Parallel Parsing: A Strongly Interactive Model of Natural Language Interpretation. Cognitive Science.</title>
<publisher>In press.</publisher>
<marker>Waltz, Pollack, </marker>
<rawString>Waltz, O. and Pollack, J. Massively Parallel Parsing: A Strongly Interactive Model of Natural Language Interpretation. Cognitive Science. In press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E B Zurif</author>
<author>S E Blumstein</author>
</authors>
<title>Language and the</title>
<marker>Zurif, Blumstein, </marker>
<rawString>Zurif, E.B. and Blumstein, S.E. Language and the Brain. In M. Halle, J. Bresnan, and G.</rawString>
</citation>
<citation valid="true">
<date>1978</date>
<booktitle>Linguistic Theory and Psychological Reality.</booktitle>
<editor>Miller, (eds.),</editor>
<publisher>MIT Press,</publisher>
<marker>1978</marker>
<rawString>Miller, (eds.), Linguistic Theory and Psychological Reality. MIT Press, 1978.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>