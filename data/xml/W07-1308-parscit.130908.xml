<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.9978855">
Phonological Reconstruction of a Dead Language
Using the Gradual Learning Algorithm
</title>
<author confidence="0.997879">
Eric J. M. Smith
</author>
<affiliation confidence="0.9989185">
Department of Linguistics
University of Toronto
</affiliation>
<address confidence="0.812532666666667">
130 St. George Street, Room 6076
Toronto, Ont. M5S 3H1
Canada
</address>
<email confidence="0.998506">
eric.smith@utoronto.ca
</email>
<sectionHeader confidence="0.998595" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998667">
This paper discusses the reconstruction of
the Elamite language’s phonology from its
orthography using the Gradual Learning Al-
gorithm, which was re-purposed to “learn”
underlying phonological forms from surface
orthography. Practical issues are raised re-
garding the difficulty of mapping between
orthography and phonology, and Optimal-
ity Theory’s neglected Lexicon Optimiza-
tion module is highlighted.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993068125">
The purpose of this paper is to reconstruct the
phonology of Elamite, an extinct language known
only from written sources, whose phonology is cur-
rently poorly understood. Given that the mecha-
nisms provided by Optimality Theory are powerful
enough for a language learner to acquire a natural
language given only overt forms, it should be possi-
ble to apply the same mechanisms to “learn” Elamite
phonology given only its orthography.
The research described here was carried out with
the aid of a piece of software, nicknamed Grote-
fend, which was developed as part of a larger re-
search project into Elamite.1 The data used in this
paper consisted of the contents of the Elamisches
W¨orterbuch (Hinz and Koch, 1987) marked up as
XML with attributes such as morphology, cognates,
</bodyText>
<footnote confidence="0.9684798">
1Grotefend was written in C++ using Trolltech’s Qt toolkit,
and runs under Mac OS X. The portions that implement the
Gradual Learning Algorithm (§4.3) were adapted from Paul
Boersma’s Visual Basic source code for the OTSoft program,
which was kindly provided by Bruce Hayes.
</footnote>
<page confidence="0.994658">
57
</page>
<bodyText confidence="0.999537428571429">
semantics, corpus frequency, and chronology. The
W¨orterbuch was used because it is the only source
that incorporates Elamite data from all historical pe-
riods. It also has the virtue of containing every sin-
gle attested form known to the authors, which is par-
ticularly useful for this project, since we have spe-
cial interest in alternative spellings of given words.
</bodyText>
<sectionHeader confidence="0.998327" genericHeader="introduction">
2 Elamite Language
</sectionHeader>
<subsectionHeader confidence="0.995315">
2.1 Historical and geographical context
</subsectionHeader>
<bodyText confidence="0.999974058823529">
Elamite is an extinct language spoken in what is now
southwestern and central Iran. Elamite-language
texts dating from 2400 BCE until 360 BCE are
attested, written in the cuneiform script borrowed
from the Sumerians and Akkadians.2 Elamite has
no known linguistic affiliations, although a connec-
tion to the Dravidian family has been proposed by
McAlpin (1982) and others.
Since both the language and scribal practices are
certain to have changed over such a long time-span,
this study will restrict itself to text from a single era.
The Achæmenid Elamite period (539 BCE to 360
BCE) was chosen, because this period contains the
largest volume of texts, and also because those texts
are particularly rich in Old Persian names and loan-
words that provide a useful starting point for esti-
mating the phonology.
</bodyText>
<subsectionHeader confidence="0.992355">
2.2 The cuneiform writing system
</subsectionHeader>
<bodyText confidence="0.9991955">
As part of their adaptation of cuneiform, the
Elamites abandoned most of the logographic ele-
</bodyText>
<footnote confidence="0.984490333333333">
2Early texts from Elam using two other indigenous writing
systems are not well-enough understood to provide useful lin-
guistic information.
</footnote>
<note confidence="0.917807">
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 57–64,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999295076923077">
ments found in Sumerian and Akkadian usage, mov-
ing to an almost completely phonetic system, which
would be a “core syllabary” in Sproat’s (2000) typol-
ogy. That is, each grapheme represents a syllable,
but the system lacks graphemes to represent all of
the language’s syllables. This is particularly the case
for many (CVC) graphemes, which must be writ-
ten using “syllable telescoping”, where a (CV-VC)
combination is written, with the internal vowel being
repeated. For example, lacking a (lan) grapheme,
the syllable /lan/ would have to be written (la-an)3.
Even when the (CVC) grapheme does exist, the
(CV-VC) writing is often preferred.
</bodyText>
<subsectionHeader confidence="0.997647">
2.3 Hypotheses to be tested
</subsectionHeader>
<bodyText confidence="0.966029333333334">
The strategy of this research is to use the techniques
of Optimality Theory to reconstruct the language’s
phonology. We will take the various hypotheses pre-
sented by earlier authors and attempt to encapsulate
each in the form of an OT constraint.
Altogether 30 separate hypotheses were evalu-
ated, arranged into 11 major groupings. Within
each grouping, the sub-hypotheses (which may or
may not be mutually exclusive) refer to a related
context or related orthographic phenomenon. This
paper will largely restrict its discussion to only two
of the groupings: H3 (Geminate consonants) and
H4 (Nasal vowels).4
H3 Geminate consonants
H3a Geminate orthographies represent underlying
geminate phonologies.
H3b Geminate orthographies indicate voicelessness
(Reiner, 1969).
H3c Certain geminate spellings indicate a distinc-
tion other than voicing, such as retroflex/alveolar
(McAlpin, 1982).
</bodyText>
<footnote confidence="0.966975166666667">
H4 Nasal vowels
H4a Alternations in the writing of nasals indicate
3Or ( &apos;V&amp;quot;-T), but since the readership of this paper is un-
likely to be familiar with cuneiform, all graphemes will be pre-
sented in the traditional transliterated form used in Assyriology.
4The full list of hypothesis groups also includes: H1 (In-
</footnote>
<bodyText confidence="0.902173545454545">
terpretation of broken (CV1-V2C) writings), H2 (Voicing of
stops), H5 (Word-final vowels), H6 (Sibilants), H7 (Existence
of an /h/ phoneme), H8 (Existence of an /f/ or /v/ phoneme), H9
(Existence of a /j/ phoneme), H10 (Existence of a /w/ phoneme),
and H11 (Existence of an /e/ phoneme). Full discussion of the
results for these hypotheses can be found in Smith (2004).
the presence of nasal vowels (e.g. /h˜uban/ ,
(hu-um-ban), (hu-ban)).
H4b Alternations in the writing of nasals can be
explained by underlying nasal consonants (e.g.
/humban/ , (hu-um-ban), (hu-ban)).
</bodyText>
<sectionHeader confidence="0.921666" genericHeader="method">
3 Theory of Writing Systems
</sectionHeader>
<bodyText confidence="0.9998655">
The discussion of Elamite orthography will be
framed within the theory of writing systems pro-
posed by Sproat (2000), whose core claim that “par-
ticular (sets of) linguistic elements license the oc-
currence of (sets of) orthographic elements”. The
details of which linguistic elements license which
orthographic ones are specific to any given combi-
nation of spoken language and writing system.
The licensing is implemented by a mapping func-
tion, MORL,r, whose input is the Orthographically
Relevant Level (ORL), and whose output is the
orthography(I). In the case of Elamite, the rele-
vant level is the surface phonology after the applica-
tion of phonological processes such as assimilation
and cluster simplification, so in Sproat’s schema,
Elamite is classified as having a “shallow” ORL.5
</bodyText>
<sectionHeader confidence="0.987366" genericHeader="method">
4 Applying OT to Orthography
</sectionHeader>
<bodyText confidence="0.999973">
In the normal application of Optimality Theory, the
input and the output are both the same type of lin-
guistic entity. However, in the problem dealt with
here, the relationship is between an input that is
phonological and an output that is orthographic. The
comparison of phonological apples to orthographic
oranges leads to complications that will be discussed
in §6.1. All the modules of Optimality Theory must
be adapted for use with orthography.
</bodyText>
<subsectionHeader confidence="0.993375">
4.1 Background
</subsectionHeader>
<bodyText confidence="0.999777777777778">
As originally formulated, Optimality Theory can be
considered as a set of three interconnected modules:
GEN, H-EVAL, and Lexicon Optimization (Prince
and Smolensky, 1993). Together GEN and H-EVAL
comprise the grammar proper. For any given in-
put, GEN generates a set of output candidates, and
these candidates are then evaluated against a set of
constraints by the H-EVAL module. Lexicon Opti-
mization is not part of the grammar, but it provides
</bodyText>
<footnote confidence="0.997314">
5For instance, the noun kittin ‘length’ is spelled (ki-it-ti-im-
ma) when followed by the locative suffix -ma, while the 3SG
object prefix in- is written (id) before a verb like dunih ‘I gave’.
</footnote>
<page confidence="0.999382">
58
</page>
<bodyText confidence="0.999395933333333">
a mechanism by which language learners can use
that grammar to determine underlying forms based
on the overt forms that are presented to them.
Optimality Theory can be seen as a model for how
a language learner acquires a natural language, pre-
sented only with overt forms (Tesar and Smolensky,
2000). At first, the learner’s constraint rankings and
underlying forms will be inaccurate, but as more in-
formation is presented the estimates of the under-
lying forms become more accurate, which in turn
improves the constraint rankings, which further im-
proves the estimates of the underlying forms, and so
on. In this study, the “learner” is the Grotefend soft-
ware, which is presented with surface orthography
and attempts to deduce the phonology.
</bodyText>
<subsectionHeader confidence="0.896377">
4.2 Adaptation for orthography
</subsectionHeader>
<bodyText confidence="0.999989043478261">
The GEN module must be adapted to generate plau-
sible overt forms (i.e. rival orthographies). The gen-
eral strategy for GEN is described in §5, with the
specific details given in §5.2.
The constraints are used by a ranking algorithm
(§4.3) that compares the rival orthographies from
GEN against underlying phonological forms in or-
der to determine the number of constraint violations.
In order to start the process, those underlying forms
have to be seeded with reasonable initial estimates.
If the word is a loanword, the initial estimate is
based on the Old Persian or Akkadian phonology.
If there is no available loanword phonology, the ini-
tial estimate is a direct transcription of the grapheme
values as if the word were being read in Akkadian.
Once the constraints have been ranked, Lexical
Optimization takes the orthographic forms and the
newly-ranked constraints, and calculates an esti-
mated phonology for each of the forms. At this
point, the process can stop, or else it can proceed
through another iteration of the ranking algorithm,
using the new improved estimated phonologies as
underlying forms.
</bodyText>
<subsectionHeader confidence="0.999553">
4.3 Gradual Learning Algorithm
</subsectionHeader>
<bodyText confidence="0.999929921052632">
The Gradual Learning Algorithm (Boersma, 1997;
Boersma and Hayes, 2001) is an evolution of the
Constraint Demotion algorithm (Tesar, 1995), but
avoids the infinite-looping which can arise in Con-
straint Demotion if underlying forms have more than
one overt form. This limitation of Constraint Demo-
tion is a serious one given the data from Elamite or-
thography; not only are the orthographic forms sub-
ject to considerable variation, but also this variation
is a key piece of information in attempting to recon-
struct the phonology.
In the GLA, constraints each have a numeric rank-
ing value associated with them. It is no longer the
case that Constraint A consistently outranks Con-
straint B; whenever a constraint is evaluated, a ran-
dom “noise” factor is added to each of the ranking
values, and an instantaneous constraint ordering is
determined based on these adjusted values. If the
ranking values for two constraints are far apart, the
noise is unlikely to alter the ordering, and the re-
sults will be effectively the same as ordinary OT. If
the ranking values for two constraints are close to-
gether, the noise could put either constraint on top,
but ties are avoided.
In the GLA implementation within Grotefend, all
constraints start with ranking values of 100.00. With
each iteration of the algorithm, one of the observed
forms is selected as an exemplar, and rivals (pro-
duced by GEN) are compared against the observed
exemplar form. Whenever a rival beats the exemplar
form, the constraint ranking values must be adjusted:
all constraints that picked the wrong winner are pe-
nalized (adjusted downwards), and all constraints
that picked the right winner are rewarded (adjusted
upwards). The size of this adjustment is determined
by a variable called “plasticity”, which starts at 2.00
and is reduced gradually to 0.002 as the algorithm
proceeds through its iterations.
</bodyText>
<sectionHeader confidence="0.895965" genericHeader="method">
5 Implementation of GEN
</sectionHeader>
<bodyText confidence="0.999966125">
The purpose of GEN is to generate a set of plausi-
ble overt forms consisting of the real form and a set
of rivals which will lose out to the real form. In
this problem the overt forms are orthographies, so
for any underlying form the challenge is to gener-
ate orthographic strings that compete with the real
orthography, but which are “wrong” with respect to
one or more of the constraints.
</bodyText>
<subsectionHeader confidence="0.982861">
5.1 Background
</subsectionHeader>
<bodyText confidence="0.999785333333333">
There have been a number of computational imple-
mentations of GEN, but the most promising one for
our purposes was that of Heiberg (1999). Heiberg’s
</bodyText>
<page confidence="0.993334">
59
</page>
<bodyText confidence="0.999995888888889">
algorithm proceeds by choosing a starting point and
then adding constraints to the system. As each con-
straint is added, new candidates are generated using
what she calls “relevant” GEN operations. A GEN
operation is considered to be relevant for the current
constraint if the operation could affect a candidate’s
harmony relative to that constraint. So for instance,
if the constraint being added evaluates the [+back]
feature, the only GEN operations that are relevant
are those which affect [+back] or its associations.
The candidates at each stage of the algorithm are
not fully formed, and are slowly refined as the con-
straints are added to the system. One advantage of
Heiberg’s algorithm is that it functions even if the
relative rankings of the constraints are not known. If
the constraint rankings are known, the algorithm can
operate more efficiently, by culling known losers,
but knowing the rankings is not essential.
</bodyText>
<subsectionHeader confidence="0.999594">
5.2 Adaptation of GEN for orthography
</subsectionHeader>
<bodyText confidence="0.9697318">
Generating all “plausible” orthographic candidates
for a given form is computationally prohibitive.6
So, borrowing Heiberg’s notion of “relevant” oper-
ations, our approach is to generate candidates that
specifically exercise one of the constraints in the
constraint system.
Each of the hypothesis groups described in §2.3
refers to a particular orthographic context, and each
context has a miniature version of GEN to generate
appropriately test-worthy rivals. For example, the
mini-GEN function for context H3 is as follows:
GEN H3 (Geminate consonants)
Rule Whenever a geminate consonant is found
in the orthography, generate a rival with the non-
geminate equivalent.
</bodyText>
<equation confidence="0.780526">
Example (hu-ut-ta) { (hu-ta) }
</equation>
<sectionHeader confidence="0.955895" genericHeader="method">
6 Implementation of H-EVAL
</sectionHeader>
<bodyText confidence="0.9989115">
The H-EVAL module is responsible for the actual
evaluations of the various candidates. It takes any
output candidate produced by GEN, and counts the
violation marks for each of the constraints.
</bodyText>
<footnote confidence="0.56488175">
6Initial experiments indicated that a moderately long string
of four graphemes would generate in the neighbourhood of
18000 rivals. It seemed unrealistic to evaluate tens of thousands
of rivals for each of the 8000+ forms in the database.
</footnote>
<figureCaption confidence="0.9037895">
Figure 1: Annotation graph for Ahuramazd¯ah �
(du-ri-um-maˇs-da)
</figureCaption>
<bodyText confidence="0.999965">
Each constraint is implemented as a function
which takes two inputs (an underlying form and a
surface form), and produces as an output the num-
ber of violations incurred by the comparing the two
inputs. For full generality, both inputs are anno-
tation graphs (Bird and Liberman, 1999; Sproat,
2000) such as the one shown in Figure 1. As imple-
mented in Grotefend, the comparison involves only
the PHON tier of the underlying form’s graph and the
ORTH tier of the surface form’s graph.
Constraints were written to test each of the hy-
potheses described in §2.3. Since there is no prior
art in the area of constraints involving orthography
and phonology, they were developed in the most
straightforward way possible. The implementation
of these functions is described in §6.2.
</bodyText>
<subsectionHeader confidence="0.998309">
6.1 Implementation of alignment
</subsectionHeader>
<bodyText confidence="0.999982095238095">
In order to count violations, the two inputs must
be properly aligned. For an annotation graph to
be “aligned”, every grapheme must be licensed by
some part of the phonology, and every phoneme
must be represented in the orthography. Without
such a licensing relationship, it is impossible to
make the comparisons needed to count constraint vi-
olations.
There is considerable previous work in the area of
alignment, most recently summarized by Kondrak
and Sherif (2006). The algorithm used in this study
is a similarity-based approach, not unlike ALINE
(Kondrak, 2000). It differs in some significant re-
spects, notably the use of binary features.
Determining the eligibility of two phonemes for
matching requires a distance function. The approach
taken was to assign a weight to each phonological
feature, and to calculate the distance as the sum of
the weights of all features that differ between the
two phonemes. The full listing of feature weights is
shown in Table 1. The weighting values were deter-
</bodyText>
<figure confidence="0.8853305">
SEM divinity: d
ORTH u ri um masà da
a h u r a m a z d Ûa h
PHON
</figure>
<page confidence="0.950232">
60
</page>
<tableCaption confidence="0.998728">
Table 1: Feature weights for computing distance
</tableCaption>
<table confidence="0.907021125">
Phonological Feature Weight
delayed release, voice, labio-dental, 1
anterior, distributed, strident
approximant, continuant, nasal, lateral, 2
round, low, pharyngeal
syllabic, consonantal, constricted glot- 4
tis, spread glottis, high, front, back
sonorant, place of articulation 8
</table>
<bodyText confidence="0.968160028571429">
mined empirically, selecting the weightings that did
the best job of aligning the orthography for the Old
Persian loanwords given by Hinz and Koch (1987).
For the actual alignment, several approaches
were tried, but the most effective one was simply
to line up the consonants and let the vowels fall
where they may. For instance, the licensing of
(du-ri-um-maˇs-da) in Figure 1 used the Old Persian
phonology as the best available initial estimate for
the Elamite phonology, and proceeded as follows:
(d) is the divine determinative, and is licensed
by the semantic tier of the annotation graph, so it
does not need to be anchored to the phonology.
(u) is anchored at the left edge of the phonology.
(ri) starts at /r/, but has no clear right edge. The
anchoring of /r/ sets a right boundary on the (u),
which must therefore be licensed by the initial /ahu/
of /ahuramazd¯ah/.
(um) right edge at phoneme /m/; since the (um) has
no clear left edge, the second /a/ of /ahuramazd¯ah/
is left floating between the (ri) and the (um). Since
there is no clear choice between the two locations,
the /a/ will be shared by (ri) and (um).
(maˇs) starts at /m/ and ends at /z/, which is suffi-
ciently similar to match ˇs. The /m/ will be shared by
(um) and (maˇs).
(da) starts at /d/; since (da) is the last grapheme, it
must be licensed by the remainder of the phonology.
The general strategy of aligning consonants
proved to be an effective one. In the working dataset
of Achæmenid Elamite words, there were 3045 that
used Old Persian or Akkadian data to provide an ini-
tial estimate of the underlying phonology. The algo-
rithm successfully aligned 2902 of those words, for
a success rate of over 95%.
</bodyText>
<subsectionHeader confidence="0.99991">
6.2 Implementation of constraints
</subsectionHeader>
<bodyText confidence="0.939069666666667">
Once the orthography has been successfully aligned
with the underlying phonology, it is possible to
evaluate the forms for violations against all the con-
straints in the system. In terms of the tiers shown in
annotation graphs like Figure 1, the constraints are
performing comparisons between the underlying
forms in the PHON tier and overt forms in the ORTH
tier. For example, the rules for calculating constraint
violations for H3 are as follows:
113a Geminate spellings indicate geminate pronun-
ciations.
Rule Count a violation if the orthography contains
a geminate consonant not matched by a geminate in
the phonology.7
Violation /ata/ —* (at-ta)
Non-violations /atta/ —* (at-ta), /atta/ —* (a-ta)
113b Geminate spellings indicate voicelessness.
Rule Count a violation if 1) the orthography con-
tains an intervocalic geminate stop not matched by a
voiceless stop in the phonology, or 2) the orthogra-
phy contains an intervocalic non-geminate stop not
matched by a voiced stop in the phonology, or 3) the
phonology contains an intervocalic voiceless stop
not matched by a geminate in the orthography, or 4)
the phonology contains an intervocalic voiced stop
not matched by a non-geminate in the orthography.8
Violations /duba:la/ —* (du-ib-ba-la), /garmapada/
</bodyText>
<equation confidence="0.673917333333333">
—* (dkar-ma-ba-taˇs)
Non-violations /gauma:ta/ —* (kam-ma-ad-da),
/babili/ —* (ba-pi-li)
</equation>
<bodyText confidence="0.9717065">
113c Certain geminate spellings indicate a distinc-
tion other than voicing, such as retroflex/alveolar.
Rule Count a violation if 1) the orthography con-
tains a (Vl-lV) or (Vr-rV) sequence not matched by
a retroflex in the phonology, or 2) the phonology
contains a /L/ or /t/ not matched by a (Vl-lV) or
</bodyText>
<footnote confidence="0.970739285714286">
7The claim made by Grillot-Susini and Roche (1988) was
only that a geminate orthography represents a geminate phonol-
ogy; a non-geminate orthography could still conceal a geminate
phonology.
8Reiner (1969) restricted her claim about gemination repre-
senting voicelessness to intervocalic stops. Word-initial stops
and intervocalic non-stops were not relevant here.
</footnote>
<page confidence="0.99831">
61
</page>
<bodyText confidence="0.856718">
(Vr-rV) in the orthography.
</bodyText>
<equation confidence="0.586655">
Violations /talu/ —* (ta-al-lu), /taíu/ —* (ta-lu)
Non-violation /taíu/ —* (ta-al-lu)
</equation>
<sectionHeader confidence="0.814858" genericHeader="method">
7 Implementation of Lexicon Optimization
</sectionHeader>
<bodyText confidence="0.996578151515152">
Given the set of constraints provided in §6.2 and
rankings determined by the Gradual Learning Algo-
rithm (§4.3), it is now possible to move on to the
final stage of the “learning” process: Lexicon Opti-
mization, which is responsible for choosing the most
harmonic input form for any given output form.
There has been surprisingly little literature de-
voted to Lexicon Optimization, and discussions of
how it might be implemented have been restricted to
toy algorithms such as Itˆo et al’s (1995) “tableau des
tableaux”. Hence, a novel approach was devised,
based on the observation that Lexicon Optimization
is a sort of mirror image of H-EVAL. For H-EVAL,
there exists a separate GEN module whose task is
to generate the possible output candidates. Clearly,
Lexicon Optimization needs an equivalent module,
but one that would generate a range of rival input
forms. Since the GEN algorithm described in §5.2
uses a constraint-driven technique for generating
output candidates, it seems appropriate to also use
a constraint-driven technique for generating input
candidates. Accordingly, this anti-GEN is imple-
mented as a set of miniature anti-GENs, each of
which is responsible for generating “relevant” input
candidates for one of the hypothesis groupings. For
example, the anti-GEN function for H3 is as follows:
Anti-GEN H3 (Geminate consonants)
Rule Whenever a geminate consonant is found
in the orthography, create input candidates with
the geminate phonology and the equivalent non-
geminate phonology. If the geminate orthography is
a (Vl-lV) or (Vr-rV), also create an input candidate
with a “retroflex” phonology.9
</bodyText>
<equation confidence="0.401438">
Example (ta-al-lu) —* { /tallu/, /talu/, /talu/ }
</equation>
<sectionHeader confidence="0.998305" genericHeader="evaluation">
8 Results and Discussion
</sectionHeader>
<bodyText confidence="0.997768">
We ran 40000 iterations of the Gradual Learning
Algorithm against the Achæmenid Elamite forms
</bodyText>
<footnote confidence="0.9963375">
9McAlpin (1982) hedges on whether the phonology repre-
sented by these geminates actually represents retroflexion, but
he then proceeds to discuss Proto-Elamo-Dravidian cognates as
if this orthography actually did represent a retroflex articulation.
</footnote>
<tableCaption confidence="0.968851">
Table 2: Final constraint rankings for H3 and H4
</tableCaption>
<table confidence="0.998846142857143">
Hypo- Constraint Ranking
thesis Value
H4b NasalConsonants −136.93
H3b (Geminate)=/Voiceless/ −283.70
H4a NasalVowels −1434.77
H3c (Geminate)=/Retroflex/ −1629.74
H3a (Geminate)=/Geminate/ −3189.11
</table>
<bodyText confidence="0.999815428571429">
found in the Elamisches W¨orterbuch. The final con-
straint rankings for hypothesis groups H3 and H4 are
shown in Table 2.10 The combination of constraints,
GEN, and anti-GEN functions used by Grotefend
tends to penalize constraints much more often than
it rewards them. The absolute ranking values are not
significant; what matters is their relative values.
</bodyText>
<sectionHeader confidence="0.832005" genericHeader="evaluation">
8.1 Results for H3 (Geminate consonants)
</sectionHeader>
<bodyText confidence="0.979915703703704">
The results for H3 strongly support the hypothesis
(Reiner, 1969) that geminate orthographies are an
attempt to indicate voicelessness; the opposing hy-
pothesis (Grillot-Susini and Roche, 1988) that gem-
inate orthographies represent geminate phonologies
ended up being very heavily penalized.
What was surprising was that hypothesis H3c, that
(Vl-lV) and (Vr-rV) geminates represent a sepa-
rate phoneme from the non-geminate orthographies,
ranked so poorly. The problem here is a side-effect
of the process for generating input candidates.
Consider the Akkadian name Nabˆu-kudurri-us.ur;
the (ur-ri) sequence that occurs in the various
spellings of this name would appear to be an ideal
context for evaluating H3c. However, when gen-
erating input candidates for Nabˆu-kudurri-us.ur, the
various anti-GEN functions create 238 permutations
(mostly permutations of voicing), but only four of
those input candidates contain an /ó/ phoneme, with
the rest having an /rr/ or an /r/. Since the anti-GEN
function produces so few /ó/ input candidates for the
(ur-ri) orthography, it is likely that the software will
find an /r/ in the underlying phonology, and will
count a violation against this constraint.
The prejudice against /l/ and /ó/ highlights the im-
portance of having a fair and balanced anti-GEN
10Results for the other nine groups are in Smith (2004).
</bodyText>
<page confidence="0.994414">
62
</page>
<figure confidence="0.8965455">
0 H4a (nasal vowel) violations
1 H4b (nasal consonant) violation
</figure>
<figureCaption confidence="0.999704">
Figure 2: Licensing of (hi-in-du-iˇs) ‘Indian’
</figureCaption>
<bodyText confidence="0.99993475">
function. The proposal to be discussed in §8.3 for
cross-permuting the results of the constraint-specific
anti-GEN functions would probably also improve
the results for this hypothesis.
</bodyText>
<sectionHeader confidence="0.961441" genericHeader="evaluation">
8.2 Results for H4 (Nasal vowels)
</sectionHeader>
<bodyText confidence="0.999995875">
The effectiveness of the constraints for evaluating
nasals was undermined by choices made in the align-
ment algorithm. Although constraint H4b (Nasal-
Consonants) is ranked significantly higher than H4a
(NasalVowels), this may be merely a side-effect of
the alignment algorithm.
Consider the word for ‘Indian’, which shows up
as (hi-du-iˇs), (hi-in-du-iˇs), or (in-du-iˇs). It is not
unreasonable to postulate an underlying phonol-
ogy of /hiduf/, based both on the range of written
forms, and on the Old Persian phonology. However,
when the alignment algorithm attempts to deter-
mine which phoneme sequences are licensing which
graphemes, it has a difficult choice to make for the
( in) grapheme. Licensing the vowel portion of (in)
is straightforward, but what should be done for the
consonant? If the software assumes that the most
salient features are [+consonantal] and [−syllabic],
we get the first annotation graph shown in Figure
2, but if the most salient features are [+nasal] and
[+sonorant], we get the second graph.
The choice of how to license the (in) grapheme
makes a difference for how the H4a and H4b con-
straints are evaluated. Using the weightings given
in Table 1, the software will align (in) with /˜ıd/, be-
cause the distance between /n/ and /d/ is less than
that between /n/ and /˜ı/. Hence, the alignment algo-
rithm chooses the first of the two annotation graphs
given in Figure 2. This has the result of prejudic-
ing the learning algorithm in favour of H4b instead
of H4a. Ideally, the alignment algorithm should be
neutral with respect to the various constraints.
The licensing of the (in) sign in this example
is one case of several where it appears that us-
ing phonological segments as the basis for licensing
may be the wrong thing to do. It would be better to
think of the second portion of the (in) sign in (hi-in-
du-iˇs) as being licensed by a [+nasal] feature, with-
out attempting to tie the feature down to either the
/i/ or the /d/ segment.11
</bodyText>
<subsectionHeader confidence="0.995467">
8.3 Discussion of Lexicon Optimization
</subsectionHeader>
<bodyText confidence="0.998940970588235">
The generation of useful input candidates is limited
by the information that is available to us. For all
we know, Elamite had an /W/ vowel, and Grotefend
could even generate input candidates that contained
an /W/. However, none of the constraints would
weigh either for or against it, so there is no point in
generating such an input candidate. Consequently,
the correct underlying form may well be inaccessi-
ble to Lexicon Optimization. At best, Lexicon Opti-
mization can produce an estimated underlying form
that leaves as underspecified any features that can-
not be verified by a corresponding constraint. This
is a limitation of Lexicon Optimization in general,
not just of the implementation in Grotefend.
One problem specific to our constraint-based gen-
eration of input candidates is that the anti-GEN func-
tions work in isolation from each other. For exam-
ple, when processing (da-iˇs), the H1 (broken-vowel)
anti-GEN produces /daif/, /dajf/, /def/, and /daf/.
Separately, the H6 (sibilant) anti-GEN will produce
/dais/, /daif/, /daiz/, /daitf/, and /daits/. Since the
two functions operate independently, the software
fails to generate a whole range of candidates. If
the actual underlying phonology were /detf/, Grote-
fend would never find it, since that particular phonol-
ogy will never be generated and presented to Lexi-
con Optimization as a possible input candidate. A
more sophisticated anti-GEN implementation would
allow for the input candidates produced by one con-
straint’s anti-GEN function to be further permuted
11Sproat (2000) uses phonological segments to describe li-
censing, but there is nothing in his theory that requires this; in
fact, he says that his use of segments is merely a “shorthand”
for a set of overlapping gestures.
</bodyText>
<figure confidence="0.5427177">
hi in du isà
ORTH
PHON h )ö d u
1 H4a (nasal vowel) violation
0 H4b (nasal consonant) violations
hi in du isà
ORTH
PHON h )ö d u
§
§
</figure>
<page confidence="0.988283">
63
</page>
<bodyText confidence="0.887021">
by the anti-GEN function of another constraint.
</bodyText>
<sectionHeader confidence="0.998194" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999982634146341">
This project represented an expedition into three
largely unexplored territories: the application of Op-
timality Theory to orthography, the implementation
of Lexicon Optimization in software, and the mass
analysis of Elamite phonology. All three presented
unanticipated challenges.
The problem of implementing GEN algorithmi-
cally appears to be at an early stage even in the pro-
cessing of phonological data. The constraint-driven
GEN adopted from Heiberg (1999) does appear to be
a useful starting point for working with orthography.
The determination of the mapping between
phonology and orthography can have unexpected
consequences for the evaluation of constraints. Even
when properly aligned, implementing meaningful
constraints to evaluate the mismatches between
phonology and orthography proved to be surpris-
ingly complex. An alternative representation, licens-
ing graphemes based on bundles of features rather
than phonemes, might be more effective.
The whole area of Lexicon Optimization has re-
ceived surprisingly little mention in the literature of
Optimality Theory. The notion that there must be
some form of anti-GEN module to produce suitable
input candidates appears never to have been raised
at all. The existence of anti-GEN is hardly specific
to the study of orthography, but would seem to be an
omission from Optimality Theory in general.
The constraint-driven implementation of the anti-
GEN function does seem like a promising strategy,
although the details need work. In particular, there
is a need for the outputs of the various constraint-
specific anti-GENs to be permuted together in order
to produce all plausible input candidates.
Elamite has always been problematic both due to
its status as an isolate and because the available clues
end up being obscured by the writing system. So
far, we can claim that this computational analysis
of the body of Elamite vocabulary has succeeded in
duplicating some of the tentative conclusions drawn
from a century of hard work “by hand”.
</bodyText>
<sectionHeader confidence="0.99845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999238155555556">
Steven Bird and Mark Liberman. 1999. A formal frame-
work for linguistic annotation. Technical Report Tech-
nical Report MS-CIS-99-01, Department of Computer
and Information Science, University of Pennsylvania.
Paul Boersma and Bruce Hayes. 2001. Empirical tests
of the gradual learning algorithm. Linguistic Inquiry,
32:45–86.
Paul Boersma. 1997. How we learn variation, option-
ality, and probability. Proceedings of the Institute
of Phonetic Sciences of the University of Amsterdam,
21:43–58.
Franc¸oise Grillot-Susini and Claude Roche. 1988.
El´ements de grammaire ´elamite. Etudes elamites. Edi-
tions Recherche sur les civilisations, Paris.
Andrea Heiberg. 1999. Features in Optimality Theory:
A computational model. Ph.D. thesis, University of
Arizona.
Walther Hinz and Heidemarie Koch. 1987. Elamisches
W¨orterbuch. D. Reimer, Berlin.
Junko Itˆo, Armin Mester, and Jaye Padgett. 1995. NC:
Licensing and underspecification in optimality theory.
Linguistic Inquiry, 26(4):571–613.
Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation
of several phonetic similarity algorithms on the task
of cognate identification. In Proceedings of the Work-
shop on Linguistic Distances, pages 43–50.
Grzegorz Kondrak. 2000. A new algorithm for the align-
ment of phonetic sequences. In Proceedings of the
First Meeting of the NAACL, pages 288–295.
David W. McAlpin. 1982. Proto-Elamo-Dravidian: The
evidence and its implications. Transactions of the
American Philosophical Society, 71(3):1–155.
Alan Prince and Paul Smolensky. 1993. Optimality the-
ory. Rutgers Optimality Archive, #537.
Erica Reiner. 1969. The Elamite language. Handbuch
der Orientalistik I/II/1/2/2, pages 54–118.
Eric J. M. Smith. 2004. Optimality Theory and Orthog-
raphy: Using OT to Reconstruct Elamite Phonology.
M.A. forum paper, University of Toronto.
Richard Sproat. 2000. A Computational Theory of Writ-
ing Systems. Cambridge University Press.
Bruce Tesar and Paul Smolensky. 2000. Learnability in
Optimality Theory. MIT Press, Cambridge, Mass.
Bruce Tesar. 1995. Computational Optimality Theory.
Ph.D. thesis, University of Colorado.
</reference>
<page confidence="0.999424">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921196">
<title confidence="0.9991225">Phonological Reconstruction of a Dead Using the Gradual Learning Algorithm</title>
<author confidence="0.999992">J M Eric</author>
<affiliation confidence="0.999764">Department of University of</affiliation>
<address confidence="0.997417">130 St. George Street, Room Toronto, Ont. M5S</address>
<email confidence="0.994141">eric.smith@utoronto.ca</email>
<abstract confidence="0.993447181818182">This paper discusses the reconstruction of the Elamite language’s phonology from its orthography using the Gradual Learning Algorithm, which was re-purposed to “learn” underlying phonological forms from surface orthography. Practical issues are raised regarding the difficulty of mapping between orthography and phonology, and Optimality Theory’s neglected Lexicon Optimization module is highlighted.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Mark Liberman</author>
</authors>
<title>A formal framework for linguistic annotation.</title>
<date>1999</date>
<tech>Technical Report Technical Report MS-CIS-99-01,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="14608" citStr="Bird and Liberman, 1999" startWordPosition="2325" endWordPosition="2328">on marks for each of the constraints. 6Initial experiments indicated that a moderately long string of four graphemes would generate in the neighbourhood of 18000 rivals. It seemed unrealistic to evaluate tens of thousands of rivals for each of the 8000+ forms in the database. Figure 1: Annotation graph for Ahuramazd¯ah � (du-ri-um-maˇs-da) Each constraint is implemented as a function which takes two inputs (an underlying form and a surface form), and produces as an output the number of violations incurred by the comparing the two inputs. For full generality, both inputs are annotation graphs (Bird and Liberman, 1999; Sproat, 2000) such as the one shown in Figure 1. As implemented in Grotefend, the comparison involves only the PHON tier of the underlying form’s graph and the ORTH tier of the surface form’s graph. Constraints were written to test each of the hypotheses described in §2.3. Since there is no prior art in the area of constraints involving orthography and phonology, they were developed in the most straightforward way possible. The implementation of these functions is described in §6.2. 6.1 Implementation of alignment In order to count violations, the two inputs must be properly aligned. For an </context>
</contexts>
<marker>Bird, Liberman, 1999</marker>
<rawString>Steven Bird and Mark Liberman. 1999. A formal framework for linguistic annotation. Technical Report Technical Report MS-CIS-99-01, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
<author>Bruce Hayes</author>
</authors>
<title>Empirical tests of the gradual learning algorithm. Linguistic Inquiry,</title>
<date>2001</date>
<pages>32--45</pages>
<contexts>
<context position="9759" citStr="Boersma and Hayes, 2001" startWordPosition="1537" endWordPosition="1540"> If there is no available loanword phonology, the initial estimate is a direct transcription of the grapheme values as if the word were being read in Akkadian. Once the constraints have been ranked, Lexical Optimization takes the orthographic forms and the newly-ranked constraints, and calculates an estimated phonology for each of the forms. At this point, the process can stop, or else it can proceed through another iteration of the ranking algorithm, using the new improved estimated phonologies as underlying forms. 4.3 Gradual Learning Algorithm The Gradual Learning Algorithm (Boersma, 1997; Boersma and Hayes, 2001) is an evolution of the Constraint Demotion algorithm (Tesar, 1995), but avoids the infinite-looping which can arise in Constraint Demotion if underlying forms have more than one overt form. This limitation of Constraint Demotion is a serious one given the data from Elamite orthography; not only are the orthographic forms subject to considerable variation, but also this variation is a key piece of information in attempting to reconstruct the phonology. In the GLA, constraints each have a numeric ranking value associated with them. It is no longer the case that Constraint A consistently outrank</context>
</contexts>
<marker>Boersma, Hayes, 2001</marker>
<rawString>Paul Boersma and Bruce Hayes. 2001. Empirical tests of the gradual learning algorithm. Linguistic Inquiry, 32:45–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
</authors>
<title>How we learn variation, optionality, and probability.</title>
<date>1997</date>
<booktitle>Proceedings of the Institute of Phonetic Sciences of the University of Amsterdam,</booktitle>
<pages>21--43</pages>
<contexts>
<context position="9733" citStr="Boersma, 1997" startWordPosition="1535" endWordPosition="1536">dian phonology. If there is no available loanword phonology, the initial estimate is a direct transcription of the grapheme values as if the word were being read in Akkadian. Once the constraints have been ranked, Lexical Optimization takes the orthographic forms and the newly-ranked constraints, and calculates an estimated phonology for each of the forms. At this point, the process can stop, or else it can proceed through another iteration of the ranking algorithm, using the new improved estimated phonologies as underlying forms. 4.3 Gradual Learning Algorithm The Gradual Learning Algorithm (Boersma, 1997; Boersma and Hayes, 2001) is an evolution of the Constraint Demotion algorithm (Tesar, 1995), but avoids the infinite-looping which can arise in Constraint Demotion if underlying forms have more than one overt form. This limitation of Constraint Demotion is a serious one given the data from Elamite orthography; not only are the orthographic forms subject to considerable variation, but also this variation is a key piece of information in attempting to reconstruct the phonology. In the GLA, constraints each have a numeric ranking value associated with them. It is no longer the case that Constra</context>
</contexts>
<marker>Boersma, 1997</marker>
<rawString>Paul Boersma. 1997. How we learn variation, optionality, and probability. Proceedings of the Institute of Phonetic Sciences of the University of Amsterdam, 21:43–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franc¸oise Grillot-Susini</author>
<author>Claude Roche</author>
</authors>
<title>El´ements de grammaire ´elamite. Etudes elamites. Editions Recherche sur les civilisations,</title>
<date>1988</date>
<location>Paris.</location>
<contexts>
<context position="19954" citStr="Grillot-Susini and Roche (1988)" startWordPosition="3205" endWordPosition="3208">a geminate in the orthography, or 4) the phonology contains an intervocalic voiced stop not matched by a non-geminate in the orthography.8 Violations /duba:la/ —* (du-ib-ba-la), /garmapada/ —* (dkar-ma-ba-taˇs) Non-violations /gauma:ta/ —* (kam-ma-ad-da), /babili/ —* (ba-pi-li) 113c Certain geminate spellings indicate a distinction other than voicing, such as retroflex/alveolar. Rule Count a violation if 1) the orthography contains a (Vl-lV) or (Vr-rV) sequence not matched by a retroflex in the phonology, or 2) the phonology contains a /L/ or /t/ not matched by a (Vl-lV) or 7The claim made by Grillot-Susini and Roche (1988) was only that a geminate orthography represents a geminate phonology; a non-geminate orthography could still conceal a geminate phonology. 8Reiner (1969) restricted her claim about gemination representing voicelessness to intervocalic stops. Word-initial stops and intervocalic non-stops were not relevant here. 61 (Vr-rV) in the orthography. Violations /talu/ —* (ta-al-lu), /taíu/ —* (ta-lu) Non-violation /taíu/ —* (ta-al-lu) 7 Implementation of Lexicon Optimization Given the set of constraints provided in §6.2 and rankings determined by the Gradual Learning Algorithm (§4.3), it is now possibl</context>
<context position="23296" citStr="Grillot-Susini and Roche, 1988" startWordPosition="3697" endWordPosition="3700">29.74 H3a (Geminate)=/Geminate/ −3189.11 found in the Elamisches W¨orterbuch. The final constraint rankings for hypothesis groups H3 and H4 are shown in Table 2.10 The combination of constraints, GEN, and anti-GEN functions used by Grotefend tends to penalize constraints much more often than it rewards them. The absolute ranking values are not significant; what matters is their relative values. 8.1 Results for H3 (Geminate consonants) The results for H3 strongly support the hypothesis (Reiner, 1969) that geminate orthographies are an attempt to indicate voicelessness; the opposing hypothesis (Grillot-Susini and Roche, 1988) that geminate orthographies represent geminate phonologies ended up being very heavily penalized. What was surprising was that hypothesis H3c, that (Vl-lV) and (Vr-rV) geminates represent a separate phoneme from the non-geminate orthographies, ranked so poorly. The problem here is a side-effect of the process for generating input candidates. Consider the Akkadian name Nabˆu-kudurri-us.ur; the (ur-ri) sequence that occurs in the various spellings of this name would appear to be an ideal context for evaluating H3c. However, when generating input candidates for Nabˆu-kudurri-us.ur, the various a</context>
</contexts>
<marker>Grillot-Susini, Roche, 1988</marker>
<rawString>Franc¸oise Grillot-Susini and Claude Roche. 1988. El´ements de grammaire ´elamite. Etudes elamites. Editions Recherche sur les civilisations, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Heiberg</author>
</authors>
<title>Features in Optimality Theory: A computational model.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Arizona.</institution>
<contexts>
<context position="12121" citStr="Heiberg (1999)" startWordPosition="1937" endWordPosition="1938">as the algorithm proceeds through its iterations. 5 Implementation of GEN The purpose of GEN is to generate a set of plausible overt forms consisting of the real form and a set of rivals which will lose out to the real form. In this problem the overt forms are orthographies, so for any underlying form the challenge is to generate orthographic strings that compete with the real orthography, but which are “wrong” with respect to one or more of the constraints. 5.1 Background There have been a number of computational implementations of GEN, but the most promising one for our purposes was that of Heiberg (1999). Heiberg’s 59 algorithm proceeds by choosing a starting point and then adding constraints to the system. As each constraint is added, new candidates are generated using what she calls “relevant” GEN operations. A GEN operation is considered to be relevant for the current constraint if the operation could affect a candidate’s harmony relative to that constraint. So for instance, if the constraint being added evaluates the [+back] feature, the only GEN operations that are relevant are those which affect [+back] or its associations. The candidates at each stage of the algorithm are not fully for</context>
<context position="29198" citStr="Heiberg (1999)" startWordPosition="4649" endWordPosition="4650">l vowel) violation 0 H4b (nasal consonant) violations hi in du isà ORTH PHON h )ö d u § § 63 by the anti-GEN function of another constraint. 9 Conclusions This project represented an expedition into three largely unexplored territories: the application of Optimality Theory to orthography, the implementation of Lexicon Optimization in software, and the mass analysis of Elamite phonology. All three presented unanticipated challenges. The problem of implementing GEN algorithmically appears to be at an early stage even in the processing of phonological data. The constraint-driven GEN adopted from Heiberg (1999) does appear to be a useful starting point for working with orthography. The determination of the mapping between phonology and orthography can have unexpected consequences for the evaluation of constraints. Even when properly aligned, implementing meaningful constraints to evaluate the mismatches between phonology and orthography proved to be surprisingly complex. An alternative representation, licensing graphemes based on bundles of features rather than phonemes, might be more effective. The whole area of Lexicon Optimization has received surprisingly little mention in the literature of Opti</context>
</contexts>
<marker>Heiberg, 1999</marker>
<rawString>Andrea Heiberg. 1999. Features in Optimality Theory: A computational model. Ph.D. thesis, University of Arizona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walther Hinz</author>
<author>Heidemarie Koch</author>
</authors>
<title>Elamisches W¨orterbuch.</title>
<date>1987</date>
<location>D. Reimer, Berlin.</location>
<contexts>
<context position="1370" citStr="Hinz and Koch, 1987" startWordPosition="206" endWordPosition="209">nown only from written sources, whose phonology is currently poorly understood. Given that the mechanisms provided by Optimality Theory are powerful enough for a language learner to acquire a natural language given only overt forms, it should be possible to apply the same mechanisms to “learn” Elamite phonology given only its orthography. The research described here was carried out with the aid of a piece of software, nicknamed Grotefend, which was developed as part of a larger research project into Elamite.1 The data used in this paper consisted of the contents of the Elamisches W¨orterbuch (Hinz and Koch, 1987) marked up as XML with attributes such as morphology, cognates, 1Grotefend was written in C++ using Trolltech’s Qt toolkit, and runs under Mac OS X. The portions that implement the Gradual Learning Algorithm (§4.3) were adapted from Paul Boersma’s Visual Basic source code for the OTSoft program, which was kindly provided by Bruce Hayes. 57 semantics, corpus frequency, and chronology. The W¨orterbuch was used because it is the only source that incorporates Elamite data from all historical periods. It also has the virtue of containing every single attested form known to the authors, which is par</context>
<context position="16683" citStr="Hinz and Koch (1987)" startWordPosition="2663" endWordPosition="2666"> feature weights is shown in Table 1. The weighting values were deterSEM divinity: d ORTH u ri um masà da a h u r a m a z d Ûa h PHON 60 Table 1: Feature weights for computing distance Phonological Feature Weight delayed release, voice, labio-dental, 1 anterior, distributed, strident approximant, continuant, nasal, lateral, 2 round, low, pharyngeal syllabic, consonantal, constricted glot- 4 tis, spread glottis, high, front, back sonorant, place of articulation 8 mined empirically, selecting the weightings that did the best job of aligning the orthography for the Old Persian loanwords given by Hinz and Koch (1987). For the actual alignment, several approaches were tried, but the most effective one was simply to line up the consonants and let the vowels fall where they may. For instance, the licensing of (du-ri-um-maˇs-da) in Figure 1 used the Old Persian phonology as the best available initial estimate for the Elamite phonology, and proceeded as follows: (d) is the divine determinative, and is licensed by the semantic tier of the annotation graph, so it does not need to be anchored to the phonology. (u) is anchored at the left edge of the phonology. (ri) starts at /r/, but has no clear right edge. The </context>
</contexts>
<marker>Hinz, Koch, 1987</marker>
<rawString>Walther Hinz and Heidemarie Koch. 1987. Elamisches W¨orterbuch. D. Reimer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junko Itˆo</author>
<author>Armin Mester</author>
<author>Jaye Padgett</author>
</authors>
<title>NC: Licensing and underspecification in optimality theory.</title>
<date>1995</date>
<journal>Linguistic Inquiry,</journal>
<volume>26</volume>
<issue>4</issue>
<marker>Itˆo, Mester, Padgett, 1995</marker>
<rawString>Junko Itˆo, Armin Mester, and Jaye Padgett. 1995. NC: Licensing and underspecification in optimality theory. Linguistic Inquiry, 26(4):571–613.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Evaluation of several phonetic similarity algorithms on the task of cognate identification.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Linguistic Distances,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="15597" citStr="Kondrak and Sherif (2006)" startWordPosition="2486" endWordPosition="2489">gy, they were developed in the most straightforward way possible. The implementation of these functions is described in §6.2. 6.1 Implementation of alignment In order to count violations, the two inputs must be properly aligned. For an annotation graph to be “aligned”, every grapheme must be licensed by some part of the phonology, and every phoneme must be represented in the orthography. Without such a licensing relationship, it is impossible to make the comparisons needed to count constraint violations. There is considerable previous work in the area of alignment, most recently summarized by Kondrak and Sherif (2006). The algorithm used in this study is a similarity-based approach, not unlike ALINE (Kondrak, 2000). It differs in some significant respects, notably the use of binary features. Determining the eligibility of two phonemes for matching requires a distance function. The approach taken was to assign a weight to each phonological feature, and to calculate the distance as the sum of the weights of all features that differ between the two phonemes. The full listing of feature weights is shown in Table 1. The weighting values were deterSEM divinity: d ORTH u ri um masà da a h u r a m a z d Ûa h PHON </context>
</contexts>
<marker>Kondrak, Sherif, 2006</marker>
<rawString>Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation of several phonetic similarity algorithms on the task of cognate identification. In Proceedings of the Workshop on Linguistic Distances, pages 43–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Meeting of the NAACL,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="15696" citStr="Kondrak, 2000" startWordPosition="2503" endWordPosition="2504">cribed in §6.2. 6.1 Implementation of alignment In order to count violations, the two inputs must be properly aligned. For an annotation graph to be “aligned”, every grapheme must be licensed by some part of the phonology, and every phoneme must be represented in the orthography. Without such a licensing relationship, it is impossible to make the comparisons needed to count constraint violations. There is considerable previous work in the area of alignment, most recently summarized by Kondrak and Sherif (2006). The algorithm used in this study is a similarity-based approach, not unlike ALINE (Kondrak, 2000). It differs in some significant respects, notably the use of binary features. Determining the eligibility of two phonemes for matching requires a distance function. The approach taken was to assign a weight to each phonological feature, and to calculate the distance as the sum of the weights of all features that differ between the two phonemes. The full listing of feature weights is shown in Table 1. The weighting values were deterSEM divinity: d ORTH u ri um masà da a h u r a m a z d Ûa h PHON 60 Table 1: Feature weights for computing distance Phonological Feature Weight delayed release, voi</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In Proceedings of the First Meeting of the NAACL, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David W McAlpin</author>
</authors>
<title>Proto-Elamo-Dravidian: The evidence and its implications.</title>
<date>1982</date>
<journal>Transactions of the American Philosophical Society,</journal>
<volume>71</volume>
<issue>3</issue>
<contexts>
<context position="2495" citStr="McAlpin (1982)" startWordPosition="387" endWordPosition="388">as the virtue of containing every single attested form known to the authors, which is particularly useful for this project, since we have special interest in alternative spellings of given words. 2 Elamite Language 2.1 Historical and geographical context Elamite is an extinct language spoken in what is now southwestern and central Iran. Elamite-language texts dating from 2400 BCE until 360 BCE are attested, written in the cuneiform script borrowed from the Sumerians and Akkadians.2 Elamite has no known linguistic affiliations, although a connection to the Dravidian family has been proposed by McAlpin (1982) and others. Since both the language and scribal practices are certain to have changed over such a long time-span, this study will restrict itself to text from a single era. The Achæmenid Elamite period (539 BCE to 360 BCE) was chosen, because this period contains the largest volume of texts, and also because those texts are particularly rich in Old Persian names and loanwords that provide a useful starting point for estimating the phonology. 2.2 The cuneiform writing system As part of their adaptation of cuneiform, the Elamites abandoned most of the logographic ele2Early texts from Elam using</context>
<context position="4943" citStr="McAlpin, 1982" startWordPosition="763" endWordPosition="764">e hypotheses were evaluated, arranged into 11 major groupings. Within each grouping, the sub-hypotheses (which may or may not be mutually exclusive) refer to a related context or related orthographic phenomenon. This paper will largely restrict its discussion to only two of the groupings: H3 (Geminate consonants) and H4 (Nasal vowels).4 H3 Geminate consonants H3a Geminate orthographies represent underlying geminate phonologies. H3b Geminate orthographies indicate voicelessness (Reiner, 1969). H3c Certain geminate spellings indicate a distinction other than voicing, such as retroflex/alveolar (McAlpin, 1982). H4 Nasal vowels H4a Alternations in the writing of nasals indicate 3Or ( &apos;V&amp;quot;-T), but since the readership of this paper is unlikely to be familiar with cuneiform, all graphemes will be presented in the traditional transliterated form used in Assyriology. 4The full list of hypothesis groups also includes: H1 (Interpretation of broken (CV1-V2C) writings), H2 (Voicing of stops), H5 (Word-final vowels), H6 (Sibilants), H7 (Existence of an /h/ phoneme), H8 (Existence of an /f/ or /v/ phoneme), H9 (Existence of a /j/ phoneme), H10 (Existence of a /w/ phoneme), and H11 (Existence of an /e/ phoneme)</context>
<context position="22227" citStr="McAlpin (1982)" startWordPosition="3550" endWordPosition="3551"> “relevant” input candidates for one of the hypothesis groupings. For example, the anti-GEN function for H3 is as follows: Anti-GEN H3 (Geminate consonants) Rule Whenever a geminate consonant is found in the orthography, create input candidates with the geminate phonology and the equivalent nongeminate phonology. If the geminate orthography is a (Vl-lV) or (Vr-rV), also create an input candidate with a “retroflex” phonology.9 Example (ta-al-lu) —* { /tallu/, /talu/, /talu/ } 8 Results and Discussion We ran 40000 iterations of the Gradual Learning Algorithm against the Achæmenid Elamite forms 9McAlpin (1982) hedges on whether the phonology represented by these geminates actually represents retroflexion, but he then proceeds to discuss Proto-Elamo-Dravidian cognates as if this orthography actually did represent a retroflex articulation. Table 2: Final constraint rankings for H3 and H4 Hypo- Constraint Ranking thesis Value H4b NasalConsonants −136.93 H3b (Geminate)=/Voiceless/ −283.70 H4a NasalVowels −1434.77 H3c (Geminate)=/Retroflex/ −1629.74 H3a (Geminate)=/Geminate/ −3189.11 found in the Elamisches W¨orterbuch. The final constraint rankings for hypothesis groups H3 and H4 are shown in Table 2.1</context>
</contexts>
<marker>McAlpin, 1982</marker>
<rawString>David W. McAlpin. 1982. Proto-Elamo-Dravidian: The evidence and its implications. Transactions of the American Philosophical Society, 71(3):1–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality theory. Rutgers Optimality Archive,</title>
<date>1993</date>
<pages>537</pages>
<contexts>
<context position="7306" citStr="Prince and Smolensky, 1993" startWordPosition="1136" endWordPosition="1139">normal application of Optimality Theory, the input and the output are both the same type of linguistic entity. However, in the problem dealt with here, the relationship is between an input that is phonological and an output that is orthographic. The comparison of phonological apples to orthographic oranges leads to complications that will be discussed in §6.1. All the modules of Optimality Theory must be adapted for use with orthography. 4.1 Background As originally formulated, Optimality Theory can be considered as a set of three interconnected modules: GEN, H-EVAL, and Lexicon Optimization (Prince and Smolensky, 1993). Together GEN and H-EVAL comprise the grammar proper. For any given input, GEN generates a set of output candidates, and these candidates are then evaluated against a set of constraints by the H-EVAL module. Lexicon Optimization is not part of the grammar, but it provides 5For instance, the noun kittin ‘length’ is spelled (ki-it-ti-imma) when followed by the locative suffix -ma, while the 3SG object prefix in- is written (id) before a verb like dunih ‘I gave’. 58 a mechanism by which language learners can use that grammar to determine underlying forms based on the overt forms that are present</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>Alan Prince and Paul Smolensky. 1993. Optimality theory. Rutgers Optimality Archive, #537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erica Reiner</author>
</authors>
<title>The Elamite language. Handbuch der Orientalistik I/II/1/2/2,</title>
<date>1969</date>
<pages>54--118</pages>
<contexts>
<context position="4825" citStr="Reiner, 1969" startWordPosition="747" endWordPosition="748">s presented by earlier authors and attempt to encapsulate each in the form of an OT constraint. Altogether 30 separate hypotheses were evaluated, arranged into 11 major groupings. Within each grouping, the sub-hypotheses (which may or may not be mutually exclusive) refer to a related context or related orthographic phenomenon. This paper will largely restrict its discussion to only two of the groupings: H3 (Geminate consonants) and H4 (Nasal vowels).4 H3 Geminate consonants H3a Geminate orthographies represent underlying geminate phonologies. H3b Geminate orthographies indicate voicelessness (Reiner, 1969). H3c Certain geminate spellings indicate a distinction other than voicing, such as retroflex/alveolar (McAlpin, 1982). H4 Nasal vowels H4a Alternations in the writing of nasals indicate 3Or ( &apos;V&amp;quot;-T), but since the readership of this paper is unlikely to be familiar with cuneiform, all graphemes will be presented in the traditional transliterated form used in Assyriology. 4The full list of hypothesis groups also includes: H1 (Interpretation of broken (CV1-V2C) writings), H2 (Voicing of stops), H5 (Word-final vowels), H6 (Sibilants), H7 (Existence of an /h/ phoneme), H8 (Existence of an /f/ or </context>
<context position="20108" citStr="Reiner (1969)" startWordPosition="3229" endWordPosition="3230">-la), /garmapada/ —* (dkar-ma-ba-taˇs) Non-violations /gauma:ta/ —* (kam-ma-ad-da), /babili/ —* (ba-pi-li) 113c Certain geminate spellings indicate a distinction other than voicing, such as retroflex/alveolar. Rule Count a violation if 1) the orthography contains a (Vl-lV) or (Vr-rV) sequence not matched by a retroflex in the phonology, or 2) the phonology contains a /L/ or /t/ not matched by a (Vl-lV) or 7The claim made by Grillot-Susini and Roche (1988) was only that a geminate orthography represents a geminate phonology; a non-geminate orthography could still conceal a geminate phonology. 8Reiner (1969) restricted her claim about gemination representing voicelessness to intervocalic stops. Word-initial stops and intervocalic non-stops were not relevant here. 61 (Vr-rV) in the orthography. Violations /talu/ —* (ta-al-lu), /taíu/ —* (ta-lu) Non-violation /taíu/ —* (ta-al-lu) 7 Implementation of Lexicon Optimization Given the set of constraints provided in §6.2 and rankings determined by the Gradual Learning Algorithm (§4.3), it is now possible to move on to the final stage of the “learning” process: Lexicon Optimization, which is responsible for choosing the most harmonic input form for any gi</context>
<context position="23169" citStr="Reiner, 1969" startWordPosition="3682" endWordPosition="3683">Consonants −136.93 H3b (Geminate)=/Voiceless/ −283.70 H4a NasalVowels −1434.77 H3c (Geminate)=/Retroflex/ −1629.74 H3a (Geminate)=/Geminate/ −3189.11 found in the Elamisches W¨orterbuch. The final constraint rankings for hypothesis groups H3 and H4 are shown in Table 2.10 The combination of constraints, GEN, and anti-GEN functions used by Grotefend tends to penalize constraints much more often than it rewards them. The absolute ranking values are not significant; what matters is their relative values. 8.1 Results for H3 (Geminate consonants) The results for H3 strongly support the hypothesis (Reiner, 1969) that geminate orthographies are an attempt to indicate voicelessness; the opposing hypothesis (Grillot-Susini and Roche, 1988) that geminate orthographies represent geminate phonologies ended up being very heavily penalized. What was surprising was that hypothesis H3c, that (Vl-lV) and (Vr-rV) geminates represent a separate phoneme from the non-geminate orthographies, ranked so poorly. The problem here is a side-effect of the process for generating input candidates. Consider the Akkadian name Nabˆu-kudurri-us.ur; the (ur-ri) sequence that occurs in the various spellings of this name would app</context>
</contexts>
<marker>Reiner, 1969</marker>
<rawString>Erica Reiner. 1969. The Elamite language. Handbuch der Orientalistik I/II/1/2/2, pages 54–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric J M Smith</author>
</authors>
<title>Optimality Theory and Orthography: Using OT to Reconstruct Elamite Phonology. M.A. forum paper,</title>
<date>2004</date>
<institution>University of Toronto.</institution>
<contexts>
<context position="5625" citStr="Smith (2004)" startWordPosition="877" endWordPosition="878">Or ( &apos;V&amp;quot;-T), but since the readership of this paper is unlikely to be familiar with cuneiform, all graphemes will be presented in the traditional transliterated form used in Assyriology. 4The full list of hypothesis groups also includes: H1 (Interpretation of broken (CV1-V2C) writings), H2 (Voicing of stops), H5 (Word-final vowels), H6 (Sibilants), H7 (Existence of an /h/ phoneme), H8 (Existence of an /f/ or /v/ phoneme), H9 (Existence of a /j/ phoneme), H10 (Existence of a /w/ phoneme), and H11 (Existence of an /e/ phoneme). Full discussion of the results for these hypotheses can be found in Smith (2004). the presence of nasal vowels (e.g. /h˜uban/ , (hu-um-ban), (hu-ban)). H4b Alternations in the writing of nasals can be explained by underlying nasal consonants (e.g. /humban/ , (hu-um-ban), (hu-ban)). 3 Theory of Writing Systems The discussion of Elamite orthography will be framed within the theory of writing systems proposed by Sproat (2000), whose core claim that “particular (sets of) linguistic elements license the occurrence of (sets of) orthographic elements”. The details of which linguistic elements license which orthographic ones are specific to any given combination of spoken languag</context>
<context position="24453" citStr="Smith (2004)" startWordPosition="3878" endWordPosition="3879">input candidates for Nabˆu-kudurri-us.ur, the various anti-GEN functions create 238 permutations (mostly permutations of voicing), but only four of those input candidates contain an /ó/ phoneme, with the rest having an /rr/ or an /r/. Since the anti-GEN function produces so few /ó/ input candidates for the (ur-ri) orthography, it is likely that the software will find an /r/ in the underlying phonology, and will count a violation against this constraint. The prejudice against /l/ and /ó/ highlights the importance of having a fair and balanced anti-GEN 10Results for the other nine groups are in Smith (2004). 62 0 H4a (nasal vowel) violations 1 H4b (nasal consonant) violation Figure 2: Licensing of (hi-in-du-iˇs) ‘Indian’ function. The proposal to be discussed in §8.3 for cross-permuting the results of the constraint-specific anti-GEN functions would probably also improve the results for this hypothesis. 8.2 Results for H4 (Nasal vowels) The effectiveness of the constraints for evaluating nasals was undermined by choices made in the alignment algorithm. Although constraint H4b (NasalConsonants) is ranked significantly higher than H4a (NasalVowels), this may be merely a side-effect of the alignmen</context>
</contexts>
<marker>Smith, 2004</marker>
<rawString>Eric J. M. Smith. 2004. Optimality Theory and Orthography: Using OT to Reconstruct Elamite Phonology. M.A. forum paper, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>A Computational Theory of Writing Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5971" citStr="Sproat (2000)" startWordPosition="930" endWordPosition="931">nts), H7 (Existence of an /h/ phoneme), H8 (Existence of an /f/ or /v/ phoneme), H9 (Existence of a /j/ phoneme), H10 (Existence of a /w/ phoneme), and H11 (Existence of an /e/ phoneme). Full discussion of the results for these hypotheses can be found in Smith (2004). the presence of nasal vowels (e.g. /h˜uban/ , (hu-um-ban), (hu-ban)). H4b Alternations in the writing of nasals can be explained by underlying nasal consonants (e.g. /humban/ , (hu-um-ban), (hu-ban)). 3 Theory of Writing Systems The discussion of Elamite orthography will be framed within the theory of writing systems proposed by Sproat (2000), whose core claim that “particular (sets of) linguistic elements license the occurrence of (sets of) orthographic elements”. The details of which linguistic elements license which orthographic ones are specific to any given combination of spoken language and writing system. The licensing is implemented by a mapping function, MORL,r, whose input is the Orthographically Relevant Level (ORL), and whose output is the orthography(I). In the case of Elamite, the relevant level is the surface phonology after the application of phonological processes such as assimilation and cluster simplification, s</context>
<context position="14623" citStr="Sproat, 2000" startWordPosition="2329" endWordPosition="2330">constraints. 6Initial experiments indicated that a moderately long string of four graphemes would generate in the neighbourhood of 18000 rivals. It seemed unrealistic to evaluate tens of thousands of rivals for each of the 8000+ forms in the database. Figure 1: Annotation graph for Ahuramazd¯ah � (du-ri-um-maˇs-da) Each constraint is implemented as a function which takes two inputs (an underlying form and a surface form), and produces as an output the number of violations incurred by the comparing the two inputs. For full generality, both inputs are annotation graphs (Bird and Liberman, 1999; Sproat, 2000) such as the one shown in Figure 1. As implemented in Grotefend, the comparison involves only the PHON tier of the underlying form’s graph and the ORTH tier of the surface form’s graph. Constraints were written to test each of the hypotheses described in §2.3. Since there is no prior art in the area of constraints involving orthography and phonology, they were developed in the most straightforward way possible. The implementation of these functions is described in §6.2. 6.1 Implementation of alignment In order to count violations, the two inputs must be properly aligned. For an annotation grap</context>
<context position="28334" citStr="Sproat (2000)" startWordPosition="4505" endWordPosition="4506">es /daif/, /dajf/, /def/, and /daf/. Separately, the H6 (sibilant) anti-GEN will produce /dais/, /daif/, /daiz/, /daitf/, and /daits/. Since the two functions operate independently, the software fails to generate a whole range of candidates. If the actual underlying phonology were /detf/, Grotefend would never find it, since that particular phonology will never be generated and presented to Lexicon Optimization as a possible input candidate. A more sophisticated anti-GEN implementation would allow for the input candidates produced by one constraint’s anti-GEN function to be further permuted 11Sproat (2000) uses phonological segments to describe licensing, but there is nothing in his theory that requires this; in fact, he says that his use of segments is merely a “shorthand” for a set of overlapping gestures. hi in du isà ORTH PHON h )ö d u 1 H4a (nasal vowel) violation 0 H4b (nasal consonant) violations hi in du isà ORTH PHON h )ö d u § § 63 by the anti-GEN function of another constraint. 9 Conclusions This project represented an expedition into three largely unexplored territories: the application of Optimality Theory to orthography, the implementation of Lexicon Optimization in software, and </context>
</contexts>
<marker>Sproat, 2000</marker>
<rawString>Richard Sproat. 2000. A Computational Theory of Writing Systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
<author>Paul Smolensky</author>
</authors>
<title>Learnability in Optimality Theory.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="8074" citStr="Tesar and Smolensky, 2000" startWordPosition="1268" endWordPosition="1271"> then evaluated against a set of constraints by the H-EVAL module. Lexicon Optimization is not part of the grammar, but it provides 5For instance, the noun kittin ‘length’ is spelled (ki-it-ti-imma) when followed by the locative suffix -ma, while the 3SG object prefix in- is written (id) before a verb like dunih ‘I gave’. 58 a mechanism by which language learners can use that grammar to determine underlying forms based on the overt forms that are presented to them. Optimality Theory can be seen as a model for how a language learner acquires a natural language, presented only with overt forms (Tesar and Smolensky, 2000). At first, the learner’s constraint rankings and underlying forms will be inaccurate, but as more information is presented the estimates of the underlying forms become more accurate, which in turn improves the constraint rankings, which further improves the estimates of the underlying forms, and so on. In this study, the “learner” is the Grotefend software, which is presented with surface orthography and attempts to deduce the phonology. 4.2 Adaptation for orthography The GEN module must be adapted to generate plausible overt forms (i.e. rival orthographies). The general strategy for GEN is d</context>
</contexts>
<marker>Tesar, Smolensky, 2000</marker>
<rawString>Bruce Tesar and Paul Smolensky. 2000. Learnability in Optimality Theory. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
</authors>
<title>Computational Optimality Theory.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Colorado.</institution>
<contexts>
<context position="9826" citStr="Tesar, 1995" startWordPosition="1549" endWordPosition="1550">transcription of the grapheme values as if the word were being read in Akkadian. Once the constraints have been ranked, Lexical Optimization takes the orthographic forms and the newly-ranked constraints, and calculates an estimated phonology for each of the forms. At this point, the process can stop, or else it can proceed through another iteration of the ranking algorithm, using the new improved estimated phonologies as underlying forms. 4.3 Gradual Learning Algorithm The Gradual Learning Algorithm (Boersma, 1997; Boersma and Hayes, 2001) is an evolution of the Constraint Demotion algorithm (Tesar, 1995), but avoids the infinite-looping which can arise in Constraint Demotion if underlying forms have more than one overt form. This limitation of Constraint Demotion is a serious one given the data from Elamite orthography; not only are the orthographic forms subject to considerable variation, but also this variation is a key piece of information in attempting to reconstruct the phonology. In the GLA, constraints each have a numeric ranking value associated with them. It is no longer the case that Constraint A consistently outranks Constraint B; whenever a constraint is evaluated, a random “noise</context>
</contexts>
<marker>Tesar, 1995</marker>
<rawString>Bruce Tesar. 1995. Computational Optimality Theory. Ph.D. thesis, University of Colorado.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>