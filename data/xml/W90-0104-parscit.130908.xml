<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000054">
<title confidence="0.914395">
A New Model for Lexical Choice for Open-Class Words
</title>
<author confidence="0.745884">
Ehud Reitert
</author>
<affiliation confidence="0.66376">
Aiken Computation Laboratory
Harvard University
</affiliation>
<sectionHeader confidence="0.7072115" genericHeader="abstract">
Cambridge, Mass 02138
Abstract
</sectionHeader>
<bodyText confidence="0.997341181818182">
The lexical choice process should be regarded as a con-
straint satisfaction problem: the generation system must
choose a lexical unit that is accurate (truthful), valid
(conveys the necessary information), and preferred (max-
imal under a preference function). This constraint-based
architecture allows a clean separation to be made
between what the system knows of the object or event,
and what the system wishes to communicate about the
object or event. It also allows lexical choices to be
biased towards basic-level (Rosch 1978) and other pre-
ferred lexical units.
</bodyText>
<sectionHeader confidence="0.995187" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.95427968">
Lexical choice for open-class words has typically been
regarded as a matching or classification problem. The
generation system is given a semantic structure that
represents an object or event, and a dictionary that
represents the semantic meanings of the lexical units
(Zgusta 1971) of the target language; it then chooses the
lexical unit (or set of lexical units) that best matches the
object or event. This paper proposes an alternative lexi-
cal choice architecture, in which the lexical choice pro-
cess is regarded as a constraint satisfaction problem: the
generation system must choose a lexical unit that is
accurate (truthful), valid (conveys the necessary infor-
mation), and preferred (maximal under a preference
function).1 This constraint-based architecture is more
robust than classification systems. In particular, it
allows a clean separation to be made between what the
system knows of the object or event, and what the sys-
tem wishes to communicate about the object or event;
and it allows lexical choices to be biased towards
basic-level (Bosch 1978) and other preferred lexical
units.
Throughout this paper, it will be assumed that both
lexical units and objects/events are represented as
t Currently at the Deparunent of Artificial Intelligence,
University of Edinburgh, 80 South Bridge, Edinburgh EH1 1H14,
</bodyText>
<note confidence="0.82256975">
Scotland. E-mail: reiter@aipna.edinburgb.ac.uk
1 This paper does not examine the kind of collocations&apos; and
selections&apos; constraints discussed by Cumming (1986) and Niren-
burg and Nirenburg (1988).
</note>
<bodyText confidence="0.986227258064516">
classes in a KL-ONE type taxonomy (Brachman and
Schmolze 1985). For example, the lexical unit
Bachelor might be represented as the generic class
(Human with role value restrictions Sex:Male, Age-
status:Adult, Married:False); and the object Terry might
be represented as the individual class (Human with role
fillers Sex:Male, Eye-color:Brown, Birthplace:Chicago,
Employer:IBM, Default attributes as well as
definitional information can be associated with lexical
units; this is essential for making appropriate lexical
choices (Section 5). Figure 1 shows a sample taxonomy
that will be used for most of the examples in this paper.
Lexical units (e.g., Bachelor) are shown in bold font,
while objects (e.g., Terry) are shown in italic font.
Role value restrictions (VR&apos;s), such as Sex:Male for
Man, are listed textually instead of displayed graphi-
cally, to simplify the complexity of the diagram; default
attributes (e.g., Can-fiy:True for Bird) are listed in italic
font. Basic-level classes (e.g., Man) are underlined.
Section 2 of the paper discusses classification-based
systems and some of the problems associated with them.
Section 3 introduces the proposed constraint-based sys-
tem; Section 4 looks in more detail at the lexical prefer-
ences used by the system; and Section 5 briefly
discusses the need for default attributes in the semantic
representations of lexical units. The constraint-based
lexical choice system has been incorporated into the FN
system (Reiter 1990), which generates certain kinds of
natural language object descriptions. FN uses some
additional preference rules that primarily affect NP for-
mation; these rules are not discussed in this paper.
</bodyText>
<sectionHeader confidence="0.879379" genericHeader="method">
2. Lexical Choice as Classification
</sectionHeader>
<bodyText confidence="0.9994476">
The two major approaches (to date) for lexical choice
have been discrimination nets and structure mapping
systems. Both of these approaches can be regarded as
classification/matching architectures, where a classifier
is given an object or event, and is asked to find an
appropriate lexical unit that fits that object or event.
Discrimination nets (e.g., Goldman 1975; Pustejovsky
and Nirenburg 1987) are basically decision trees. They
are typically used as high-speed &apos;compiled&apos; classifiers
that select the most specific lexical unit that subsumes
</bodyText>
<page confidence="0.995893">
23
</page>
<figure confidence="0.998587761904762">
Object
Animal
Machine
Vertebrate Network
Fish
Breathes:Wate
Mammal
Breathes:Air
Ethernet
Data-rate:10Mbit/sec
Circuit-type:Packet
Physical-medium:Coaxial-cable
(Number-of-legs:4)
CLNET
(Tiger
)shark
Pekingese
Chdo
English
sparrow
(Ostrich Can-fly:False)
Adult
Age-status:Adult
Male
Big-Bird
Woman
sex:Female
Terry
Eye-color:Brown
Birthplace:Chicago
EmployerIBM
(Primitive)
Class
defining role VR
(default role filler)
(Key)
Basic Level Class
Lexical Unit Class
Object Class
Defined
Class
ndividuar)
</figure>
<figureCaption confidence="0.997691">
Figure 1: Objects and
</figureCaption>
<footnote confidence="0.531598333333333">
Lexical Units in a
Taxonomy
is subsumed by
</footnote>
<page confidence="0.964465">
---------40,
24
</page>
<bodyText confidence="0.970970773584906">
Bachelor
Married:False
the target object or event. For instance, looking at
some of Goldman&apos;s examples, the event
Ingest(John,Mi1k027), which can be represented in KL-
ONE as (Ingest with VR&apos;s actor:John and
theme:Milk027), has as its most specific subsuming lexi-
cal unit (Ingest with VR theme:Liquid), and thus is lexi-
cally realized as &amp;quot;drink&amp;quot;. Similarly, the action
Ingest(Bear036,Fish802), which &apos; can be represented in
KL-ONE as (Ingest with VR&apos;s actor:Bear036 and
theme:Fish802), has (Ingest with VR&apos;s agent :Non-
human-animal and theme:Solid) as its most specific sub-
sumer in a taxonomy of German lexical units, and thus
is realized, in German, as &amp;quot;fressen&amp;quot;.
Structure-mapping systems (e.g., Jacobs 1987; Ionian-
slcaja et al. 1988; note that different terminology is
used in different papers) take as input a semantic struc-
ture that needs to be communicated to the uses, search
for pieces of the input structure that are equivalent to
lexical units, and then replace the matched structure by
the corresponding lexical unit. The matching and sub-
stitution process continues until the semantic structure
has been completely reformulated in terms of lexical
units. For example, the structure (Human (:sex male)
(:age-status adult) (:wealth high)) might be mapped into
the structure (&amp;quot;man&amp;quot; (:attribute &amp;quot;rich&amp;quot;)), and hence lexi-
cally realized as &amp;quot;rich man&amp;quot;. In KL-ONE terms, the
matching process can be considered to be a search for a
class definition that uses only classes and role VR&apos;s that
can be realized as lexical units; e.g., the above example
essentially redefines the class (Human with role VR&apos;s
Sex:Male, Age-status:Adult, Wealth:High) as the
equivalent class (&amp;quot;man&amp;quot; with VR &amp;quot;rich&amp;quot;), where the
lexical unit &amp;quot;man&amp;quot; represents the class (Human with
role VR&apos;s Sex:Male, Age-status:Adult), and the lexical
unit &amp;quot;rich&amp;quot; is equivalent to the role VR Wealth:High.
Recently, the machine translation group at CMU has
proposed an alternative lexical choice system that is
based on a variant of nearest neighbor classification
(Center for Machine Translation 1989; Nirenburg et al.
1987). In the CMU system, both objects and lexical
units are treated as points or regions in a feature space,
and the classifier works by choosing the lexical unit that
is closest to the target object, using a fairly complex
distance (matching) metric (collocation constraints are
also taken into consideration). For example, the object
(Human with &apos;VR&apos;s Sex:Male and Age:13) would be
judged closest to the lexical unit (Human with VR&apos;s
Sex:Male and Age:range(2,15)), and thus would be real-
ized as &amp;quot;boy&amp;quot;.
All of the above classification-based lexical-choice
architectures2 suffer from two basic flaws:
</bodyText>
<listItem confidence="0.996501666666667">
• they do not allow a clean separation to be made
between what the system knows, and what it wishes
to communicate;
• they do not provide a clean mechanism for allowing
the lexical choice process to be biased towards pre-
ferred lexical units.
</listItem>
<bodyText confidence="0.998945">
These failures may lead classification-based systems to
choose inappropriate lexical units that carry unwanted
conversational implicatures (Grice 1975), and therefore
mislead the user.
</bodyText>
<subsectionHeader confidence="0.88368">
2.1. One Input vs Two Inputs
</subsectionHeader>
<bodyText confidence="0.99847852631579">
Classification-based systems take as their input a single
set of attributes about the object/event being lexicalized,
and use this set of attributes to select a matching
classification. However, lexical choice systems should
look at two input sets of attributes: the set of
object/event attributes that are relevant and need to be
conveyed to the user, and the set of attributes that con-
stitute the system&apos;s total knowledge of the object/event
being lexicalized.
A lexical choice system that looks only at the
system&apos;s domain knowledge about the object/event, and
ignores the set of relevant attributes, may choose inap-
propriate lexical items that carry unwanted relevance
conversational implicatures. In particular, a system that
simply selects the most specific lexical unit that sub-
sumes the object/event (as many discrimination net sys-
tems do) may mislead the user by choosing lexical units
that are too specific. For example, consider the follow-
ing exchange:
</bodyText>
<listItem confidence="0.996143333333333">
1) A: &amp;quot;Is Terry a woman?&amp;quot;
2a) B: &amp;quot;No, Terry is a man&amp;quot;
2b) B: &amp;quot;No, Terry is a bachelor&amp;quot;
</listItem>
<bodyText confidence="0.999364454545455">
B&apos;s communicative goal is simply to inform A that
Terry has the attributes (Human, Age-status:Adult,
Sex:Male), so utterance (2a) is an appropriate response.
A lexical choice system that simply selected the most
specific lexical unit that subsumed Terry would generate
utterance (2b), however. Utterance (2b) is inappropri-
ate, and would probably lead A to infer the (incorrect)
conversational implicature that B thought that Terry&apos;s
marital status was relevant to the conversation.
A lexical choice system that looks only at the attri-
butes being communicated, and ignores the system&apos;s
</bodyText>
<footnote confidence="0.99871775">
2 Individual lexical-choice systems can, of course, be aug-
mented with special code that addresses some of these issues; the
claim is that the classification-based lexical-choice architectures
do not easily or naturally deal with these ptnblems.
</footnote>
<page confidence="0.997966">
25
</page>
<bodyText confidence="0.998893857142857">
general domain knowledge about the object/event, may
also make inappropriate lexical choices that lead to
unwanted conversational implicatures. For example,
suppose A wished to communicate to B that XNET was
a Network with the attributes (Data-rate:10MbitIsec,
Circuit-type:Packet-switched). Consider three possible
lexicalizations:
</bodyText>
<equation confidence="0.90875175">
3a) &amp;quot;XNET is a network&amp;quot;
3b) &amp;quot;XNET is a 10 Mbit/sec packet-based network&amp;quot;
3c) &amp;quot;XNET is an Ethernet&amp;quot;
Utterance (3c) is the most appropriate utterance (assum-
</equation>
<bodyText confidence="0.999653888888889">
ing the user has some domain knowledge about Ether-
nets). Utterance (3a), however, would be generated by
a system that simply chose the most specific lexical unit
that subsumed (Network, Data-rate:10MbitIsec,
Circuit-type:Packet-switched).3 This utterance fails to
fulfill the communicative goal of informing the reader
that the network has the attributes (Data-
rate:10MbitIsec, Circuit-type:Packet-switched), and is
therefore unacceptable. Utterance (3b) would be gen-
erated by a structure-mapping system that chose a lexi-
cal unit according to the above strategy, and then added
explicit modifiers to communicate attributes that were
not implied by the lexical class.4 This utterance success-
fully communicates the relevant information, but it also
implicates, to the knowledgeable hearer, that XNET is
not an Ethernet — because if it was, the knowledgeable
hearer would reason, then the speaker would have used
utterance (3c).
</bodyText>
<subsectionHeader confidence="0.771767">
2.2. Preferred Lexical Units
</subsectionHeader>
<bodyText confidence="0.99462364">
Certain lexical units, in particular those that represent
basic-level classes (Rosch 1978), are preferred and
should be chosen whenever possible. Cruse (1977) and
3 Another possibility is choosing the most general lexical unit
that is subsumed by the attributes being communicated. Howev-
er, this cannot be done by a system that ignores the object and
only looks at the attributes being communicated, because such a
system would not know which lexical units accurately described
the object. For example, if there were two classes Ethernet and
Applenet that had the attributes (Network, Data-rate:)0Mbillsec,
Circuit-type:Packet-switched}, the system could only decide
whether to generate &amp;quot;Ethernet&apos; or &amp;quot;Applenet&amp;quot; by determining
which of these classes subsumed the object being described (e.g.,
&amp;quot;Ethernet&amp;quot; should be used to describe XNET). See also exam-
ple 5, where the most appropriate lexical unit that informs the
hewer that Fido has the attributes (Animal, Breathes:Air) is
&apos;dog&amp;quot;, not &amp;quot;mammal&apos; or &amp;quot;animal&amp;quot;.
4 In this example, the &apos;lexical choice&apos; system is assumed to
capable of forming a complete NP. In general, it is often
difficult to separate the task of selecting a single word from the
task of forming a complete phrase.
others have suggested that the failure to use a basic-
level class in an utterance will conversationally impli-
cate that the basic-level class could not have been used.
For example, consider the following utterances:
</bodyText>
<listItem confidence="0.9992875">
4) A: &amp;quot;I want to flood room 16 with carbon dioxide&amp;quot;
5a) B: &amp;quot;Wait, there is an animal in the room&amp;quot;
5b) B: &amp;quot;Wait, there is a dog in the room&amp;quot;
5c) B: &amp;quot;Wait, there is a Pekingese in the room&amp;quot;
</listItem>
<bodyText confidence="0.999623071428571">
Assume the object in question is Fido, and A&apos;s com-
municative goal is simply to inform B that Fido has the
attributes (Animal, Breathes:Air), and hence would be
adversely affected if the mom was flooded with carbon
dioxide. Utterances (5a), (5b), and (5c) all fulfill this
communicative goal (assuming that Breathes:Air is a
default attribute of Animal), but utterance (5b) is pre-
ferred because Dog is a basic-level class. Utterance
(5a) is odd because the use of the superordinate class
Animal implicates, according to Cruse&apos;s hypothesis, that
the animal in question is not a Dog, Cat, or other com-
monly known type of animal (or at least the speaker
does not know that the animal is a member of one of
these species); utterance (5c) is odd because the use of
the subordinate class Pekingese implicates that it is
somehow relevant that the animal is a Pekingese and
not some other kind of dog. If both of these implica-
tures are incorrect, the speaker should choose the lexical
unit Dog if he wishes to avoid misleading the hearer.
It should be pointed out that the strategy of simply
always picking a basic-level class that subsumes the
object/event will not work, because it ignores the
system&apos;s communicative goals. For instance, a system
that followed the basic-level strategy would, in the
situation of example 3, generate utterance (3a) or (3b).
Both of these are inappropriate and implicate, to the
knowledgeable user, that utterance (3c) could not have
been used, i.e., that XNET is not an Ethernet.
</bodyText>
<listItem confidence="0.917498">
3. Lexical Choice as Constraint Satisfaction
</listItem>
<bodyText confidence="0.963678833333333">
The above problems can be avoided by regarding lexi-
cal choice as a constraint-satisfaction task instead of a
classification task. More precisely, the task of choosing
an appropriate open-class lexical unit should be formal-
ized as follows:
Input.
</bodyText>
<listItem confidence="0.9988156">
• Entity: a taxonomy class that represents the system&apos;s
knowledge of the object or event being lexicalized.
• To-Communicate: a set of predicates (attributes) that
represent the relevant information about the object
that needs to be communicated to the user.
</listItem>
<page confidence="0.958645">
26
</page>
<bodyText confidence="0.758404333333333">
Output: A lexical unit Lex that is a member of the
knowledge-base taxonomy, and that satisfies the follow-
ing constraints:
</bodyText>
<listItem confidence="0.996794454545455">
• Accurate: Lex must be a truthful description of Entity.
Formally, Lex must subsume Entity.
• Valid: The use of Lex in an utterance must inform the
user that the predicates in To-Communicate hold for
Entity. Formally, every predicate in To-Communicate
must either be inferrable from the definition of Lex
(e.g., subsume Lex), or be a default attribute that is
associated with Lex.
• Preferred: Lex must be a maximal element of the set
of accurate and valid lexical units under certain lexi-
cal preference rules (Section 4).
</listItem>
<bodyText confidence="0.999823888888889">
In other words, the lexical choice system is given two
inputs, which represent the system&apos;s knowledge of the
object or event, and the relevant information about that
object or event that needs to be communicated to the
user; and is expected to produce as its output a maximal
lexical unit (under the lexical preference rules) that is
truthful and conveys the relevant information.
The constraint-based system makes appropriate lexi-
cal choices in each of the previous examples:
</bodyText>
<listItem confidence="0.953813923076923">
• Entity = Terry, To-Communicate = (Human,
Sex:Male) (example 2). Both Man and Bachelor are
accurate and valid lexical units. Man is chosen,
because it is basic-level and therefore preferred.
• Entity = XNET, To-Communicate = (Network, Data-
rate :1 OM bitlsec Circuit-type:Packet-switched)
(example 3). Ethernet is chosen, because it is the
only accurate and valid lexical unit.
• Entity = Fido, To-Communicate = (Animal,
Breathes:Air) (example 5). Accurate and valid lexi-
cal units include Animal, Mammal, Dog, and Pek-
ingese. Dog is chosen, because it is basic-level.
4. Preferences Among Lexical Classes
</listItem>
<bodyText confidence="0.999952181818182">
If several lexical units are accurate and valid, a set of
lexical preferences rules is used to select the lexical
unit the system will utter. The preference for basic-
level classes was previously mentioned (Section 2.2),
but it is complicated by entry-level effects (Section 4.1),
Additional lexical preferences include the length/subset
preference (Section 4.2). Combined, the lexical prefer-
ence rules impose a lexical preference hierarchy on the
lexical units in the knowledge base. Figure 2 shows
part of the lexical preference hierarchy that is associated
with the knowledge base of Figure 1.
</bodyText>
<subsectionHeader confidence="0.991512">
4.1. Basic-Level vs Entry-Level Preferences
</subsectionHeader>
<bodyText confidence="0.997002">
Hirschberg (1985) has suggested that it may be better to
use Jolicoeur et al.&apos;s (1984) notion of entry level classes
instead of Rosch&apos;s basic level classes. The difference is
that under the entry-level hypothesis, which category is
unmarked (i.e., which category may be used without
generating a conversational implicature) may depend on
how atypical the object is. For example, consider:
(the speaker points to a robin)
</bodyText>
<listItem confidence="0.936719">
7a) &amp;quot;Look at the bird&amp;quot;
7b) &amp;quot;Look at the robin&amp;quot;
(the speaker points to an ostrich)
8a) &amp;quot;Look at the bird&amp;quot;
8b) &amp;quot;Look at the ostrich&amp;quot;
</listItem>
<bodyText confidence="0.99996464516129">
Under the basic-level hypothesis, a category is either
basic-level or it is not, and if it is basic-level, then it is
always the unmarked way of referring to any object that
belongs to it. Therefore, under this hypothesis utter-
ances (7a) and (8a) are both unmarked and carry no
conversational iunplicatures, since Bird is a basic-level
category for most urban Americans. Under the entry-
level hypothesis, in contrast, while a basic-level
category is the unmarked way of referring to &apos;normal&apos;
members of the category, it may not be the unmarked
way of referring to atypical members. Instead, a more
specialized category may be the unmarked way of refer-
ring to atypical members. Thus, under the entry-level
hypothesis, even if utterance (7a) was the unmarked
way of referring to robins (which are typical birds),
utterance (8b) could still be the unmarked way of refer-
ring to ostriches (which are atypical birds).
The lexical-choice system can allow for entry-level
effects if it allows any lexical unit to be marked as
basic-level in the taxonomy, but then only considers the
lowest such marked class to be a true basic-level (and
hence lexically-preferred) class for an object. More
precisely, if an object has two subsumers A and B that
are both marked as basic-level classes, and A subsumes
B, then the system should only treat B as a lexically-
preferred class for the object. For example, in Figure 1
Bird and Ostrich are both marked as basic-level. There-
fore, the lexical-choice system should treat Bird (but not
Sparrow) as a lexically-preferred class for Tweety (a
Sparrow), and Ostrich (but not Bird) as a lexically-
preferred class class for Big-Bird (an Ostrich).
</bodyText>
<subsectionHeader confidence="0.881853">
4.2. Length/Subset Preferences
</subsectionHeader>
<bodyText confidence="0.986327666666667">
A lexical unit A is almost always preferred over a lexi-
cal unit B if A&apos;s surface form uses a subset of the
words used by B&apos;s surface form (this can be considered
</bodyText>
<page confidence="0.99282">
27
</page>
<figure confidence="0.872543">
(Shark (Sparrow) (Pekinese Bachelor)
(Tiger) (Englishi
Shark Sparrow
Basic Level Preference Word Subset Preference
</figure>
<figureCaption confidence="0.995481">
Figure 2: Some of the Lexical Preferences from Figure 1
</figureCaption>
<page confidence="0.995248">
28
</page>
<bodyText confidence="0.9684355">
to be a consequence of Grice&apos;s maxim of quantity
(Grice 1975)). Consider, for example,
</bodyText>
<listItem confidence="0.980592333333333">
9a) &amp;quot;Don&apos;t go swimming; there is a shark in the water&amp;quot;
9b) &amp;quot;Don&apos;t go swimming; there is a tiger shark in the
water&amp;quot;
</listItem>
<bodyText confidence="0.999944709677419">
According to the subset lexical, preference rule, lexical
unit Shark is preferred over lexical unit Tiger-shark.
Therefore, the use of utterance (9b) carries the conver-
sational implicature that utterance (9a) could not be
used, i.e., that it was relevant that the animal was a
Tiger-shark and not some other kind of Shark. A hearer
who heard utterance (9b) might infer, for example, that
the speaker thought that tiger sharks were unusually
dangerous kinds of sharks. If no such implicature was
intended by the speaker, then he should use utterance
(9a), not utterance (9b).
A stronger version of this preference rule would be to
prefer lexical unit A to lexical unit B if A&apos;s surface
form used fewer open-class words than B&apos;s surface
form. This would, for example, correctly predict that
Dog is preferred over Great-Dane, and that Flower is
preferred over Rocky-Mountain-iris. This preference is
usually accurate, but it does fail in some cases. For
example, it is questionable whether Porsche is preferred
over Sports-car, and doubtful whether Mammal is pre-
ferred over Great-Dane.
There are cases where the basic-level preference
conflicts with (and takes precedence over) both the sub-
set and the length preferences. Such conflicts are prob-
ably rare, because psychological and linguistic findings
suggest that basic-level classes are almost always lexi-
cally realized with single words (Bosch 1978; Berlin et
a/. 1973). However, there are a small number of basic-
level classes that have multi-word realizations, and this
can lead to conflicts of the above type. Consider, for
example,
</bodyText>
<listItem confidence="0.9578">
10a) &amp;quot;Joe has a machine&amp;quot;
10b) &amp;quot;Joe has an appliance&amp;quot;
10c) &amp;quot;Joe has a washing machine&amp;quot;
</listItem>
<bodyText confidence="0.998851714285714">
Washing-machine is probably basic-level for most
Americans. Therefore, utterance (10c) is preferred over
utterances (10a) and (10b), despite the fact that the
length preference suggests that utterances (10a) and
(10b) should be preferred over utterance (10c), and the
subset preference suggests that utterance (10a) should
be preferred over utterance (10c).
</bodyText>
<subsectionHeader confidence="0.978495">
4.3. Other Lexical Preference
</subsectionHeader>
<bodyText confidence="0.9997774">
There are lexical preferences that are not captured by
either the basic-level preference or the subset/length
preference. For example, suppose the speaker wished to
refer to two animals, a horse and a cow. Consider the
difference between
</bodyText>
<listItem confidence="0.996165666666667">
11a) &amp;quot;Look at the animals&amp;quot;
11b) &amp;quot;Look at the mammals&amp;quot;
11c) &amp;quot;Look at the vertebrates&amp;quot;
</listItem>
<bodyText confidence="0.998993888888889">
None of the above are basic-level classes (Horse and
Cow are basic-level for most urban Americans). There-
fore, neither the basic-level nor the length/subset rules
indicate any preferences among the above. However, it
seems clear that utterance (11a) is much preferable to
utterance (11b), and that utterance (11b) is probably
preferable to utterance (11c). In addition, the use of
utterances (11b) or (11c) seems to implicate that utter-
ance (11a) could not have been used.
</bodyText>
<subsectionHeader confidence="0.555754">
S. Default Attributes
</subsectionHeader>
<bodyText confidence="0.999782538461538">
One final point is that the representation of the seman-
tics of lexical units must include default attributes as
well as definitional information. These defaults may
represent domain knowledge (e.g., birds typically fly) or
useful conventions that have evolved in a particular
environment (e.g., most computers at Harvard&apos;s Aiken
Computation Lab run the UNIX operating system).
Systems that ignore default attributes may make inap-
propriate lexical choices, and therefore generate utter-
ances that carry unwanted conversational impficatures.
For example, if To-Communicate was (Bird, Can-
fly:True), and Entity was Tweety, consider the
difference between
</bodyText>
<equation confidence="0.9021715">
12a) &amp;quot;Tweety is a bird&amp;quot;
12b) &amp;quot;Tweety is a bird that can _fly&amp;quot;
</equation>
<bodyText confidence="0.999326615384615">
If the generation system ignored default attributes, it
would have to generate something like utterance (12b).
Utterance (12b) sounds odd, however, and a person who
heard it might infer unwanted and unintended conversa-
tional implicatures, e.g., that some other bird under dis-
cussion was not able to fly. Utterance (12a) is much
better, but it can only be generated by a generation sys-
tem that takes into consideration the fact that Can-
fly:True is a default attribute of Bird.
For another example, suppose an NLG system wished
to inform a user that a particular computer was a VAX
that ran the UNIX operating system and the Latex text
processor (i.e., To-Communicate = (VAX, Operating-
</bodyText>
<page confidence="0.995514">
29
</page>
<bodyText confidence="0.897599583333333">
system:UNIX, Available-software:Latex)). Consider two
possible utterances:
13a) &amp;quot;Huc 1 is a VAX that runs Latex&amp;quot;
13b) &amp;quot;Huc 1 is a UNIX VAX that runs Latex&amp;quot;
Utterance (13a) is acceptable, and indeed expected, if
the user thinks that Operating-system:UNIX is a default
attribute of VAX&apos;s in the current environment (e.g., at
the Aiken Computation Lab). In a different environ-
ment, where users by default associate Operating-
system:VMS with VAX&apos;s, utterance (13a) would be
misleading and unacceptable, and utterance (13b) should
be generated.
</bodyText>
<sectionHeader confidence="0.995051" genericHeader="conclusions">
6. Conclusion
</sectionHeader>
<bodyText confidence="0.999914733333333">
This paper has proposed a lexical choice system that
searches for lexical units that are accurate, valid, and
preferred with respect to the information the generation
system wishes to communicate (To-Communicate), and
the object or event being lexicalized (Entity). This sys-
tem is more robust than discrimination nets and other
existing classification-based lexical choice systems, and
in particular is less likely to make inappropriate lexical
choices that lead human readers to infer unwanted
conversational implicatures. The improved performance
is largely a consequence of the fact that the system
allows a clean separation to be made between what the
system knows, and what it wishes to communicate; and
the fact that the system allows lexical choice to be
biased towards preferred lexical units.
</bodyText>
<sectionHeader confidence="0.85161" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999086333333333">
Many thanks to Joyce Friedman, Barbara Grosz, Chris
Mellish, Stuart Shieber, and Bill Woods for their help.
This work was partially supported by a National Sci-
ence Foundation Graduate Fellowship, an IBM Graduate
Fellowship, and a contract from U S West Advanced
Technologies. Any opinions, findings, conclusions, or
recommendations are those of the authors and do not
necessarily reflect the views of the National Science
Foundation, IBM, or U S West Advanced Technologies.
</bodyText>
<sectionHeader confidence="0.991928" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999902301886792">
Berlin, B.;Breedlove, D.; and Raven, P. 1973 General
Principles of Classification and Nomenclature in Folk
Biology. American Anthropologist 75:214-242.
Brachman, R. and Schmolze, J. 1985 An overview of
the KL-ONE knowledge representation system. Cog-
nitive Science 9:171-216.
Center for Machine Translation 1989 KBMT-89 Project
Report. Carnegie-Mellon University.
Cruse, D. 1977 The pragmatics of lexical specificity.
Journal of Linguistics 13:153-164.
Cumming, S. 1986 The Lexicon in Text Generation. ISI
Research Report ISI/RR-86-168. Information Sciences
Institute, University of Southern California.
Goldman, N. 1975 Conceptual generation. In R. Schank
and C. Riesbeck (Eds.), Conceptual Information Pro-
cessing. American Elselvier. New York.
Grice, H. 1975 Logic and conversation. In P. Cole and
J. Morgan (Eds.), Syntax and Semantics: Vol 3,
Speech Acts, pg 43-58. Academic Press: New York.
Hirschberg, J. 1985 A Theory of Scalar Implicature.
Ph.D thesis. Report MS-CIS-85-56, LINC LAB 21,
Department of Computer and Information Science,
University of Pennsylvania.
Iordanskaja, L.; Kittredge, R.; Polguere, A. 1988 Imple-
menting a Meaning-Text Model for Language Gen-
eration. Presented at COLING 1988 (not in proc.).
Jacobs, P. 1987 Knowledge-Intensive Natural Language
Generation. Artificial Intelligence 33:325-378.
Jolicoeur, P.; Gluck, M.; and Kosslyn, S. 1984 Pictures
and Names: Making the Connection. Cognitive
Psychology 16:243-275.
Nirenburg, S. and Nirenburg, I. 1988 A Framework for
Lexical Selection in Natural Language Generation.
Proceedings of the 12th International Conference on
Computational Linguistics (2):471-475.
Nirenburg, S.; Nyberg, E.; and Kenschaft, E. 1987 Inex-
act Frame Matching for Lexical Selection in Natural
Language Generation. Unpublished memo, Center for
Machine Translation, Carnegie-Mellon University.
Pustejovsky, J. and Nirenburg, S. 1987 Lexical selection
in the process of natural language generation. In
Proceedings of the 25th Annual Meeting of the Asso-
ciation for Computational Linguistics: pages 201-206.
Reiter, E. 1990 Generating Descriptions that Exploit a
User&apos;s Domain Knowledge. In R. Dale, C. Mellish,
and M. Zock (Eds.), Current Research in Natural
Language Generation. Academic Press: London.
Forthcoming.
Rosch, E. 1978 Principles of Categorization. In E.
Rosch and B. Lloyd (Eds.), Cognition and Categori-
zation. Lawrence Erlbaum: Hillsdale, NJ.
Zgusta, L. 1971 Manual of Lexicography. Academia
Press: Prague.
</reference>
<page confidence="0.998811">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.551359">
<title confidence="0.99988">A New Model for Lexical Choice for Open-Class</title>
<author confidence="0.794503">Ehud Reitert</author>
<affiliation confidence="0.854054">Aiken Computation Harvard</affiliation>
<address confidence="0.999702">Cambridge, Mass 02138</address>
<abstract confidence="0.995355666666667">The lexical choice process should be regarded as a constraint satisfaction problem: the generation system must a lexical unit that is the necessary information), and (maxa preference function). This constraint-based architecture allows a clean separation to be made what the system the object or event, what the system wishes to the object or event. It also allows lexical choices to be towards 1978) and other preferred lexical units.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Berlin</author>
<author>D Breedlove</author>
<author>P Raven</author>
</authors>
<date>1973</date>
<booktitle>General Principles of Classification and Nomenclature in Folk Biology. American Anthropologist</booktitle>
<pages>75--214</pages>
<marker>Berlin, Breedlove, Raven, 1973</marker>
<rawString>Berlin, B.;Breedlove, D.; and Raven, P. 1973 General Principles of Classification and Nomenclature in Folk Biology. American Anthropologist 75:214-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brachman</author>
<author>J Schmolze</author>
</authors>
<title>An overview of the KL-ONE knowledge representation system.</title>
<date>1985</date>
<journal>Cognitive Science</journal>
<pages>9--171</pages>
<contexts>
<context position="2304" citStr="Brachman and Schmolze 1985" startWordPosition="347" endWordPosition="350">unicate about the object or event; and it allows lexical choices to be biased towards basic-level (Bosch 1978) and other preferred lexical units. Throughout this paper, it will be assumed that both lexical units and objects/events are represented as t Currently at the Deparunent of Artificial Intelligence, University of Edinburgh, 80 South Bridge, Edinburgh EH1 1H14, Scotland. E-mail: reiter@aipna.edinburgb.ac.uk 1 This paper does not examine the kind of collocations&apos; and selections&apos; constraints discussed by Cumming (1986) and Nirenburg and Nirenburg (1988). classes in a KL-ONE type taxonomy (Brachman and Schmolze 1985). For example, the lexical unit Bachelor might be represented as the generic class (Human with role value restrictions Sex:Male, Agestatus:Adult, Married:False); and the object Terry might be represented as the individual class (Human with role fillers Sex:Male, Eye-color:Brown, Birthplace:Chicago, Employer:IBM, Default attributes as well as definitional information can be associated with lexical units; this is essential for making appropriate lexical choices (Section 5). Figure 1 shows a sample taxonomy that will be used for most of the examples in this paper. Lexical units (e.g., Bachelor) a</context>
</contexts>
<marker>Brachman, Schmolze, 1985</marker>
<rawString>Brachman, R. and Schmolze, J. 1985 An overview of the KL-ONE knowledge representation system. Cognitive Science 9:171-216.</rawString>
</citation>
<citation valid="false">
<date>1989</date>
<tech>KBMT-89 Project Report.</tech>
<institution>Center for Machine Translation</institution>
<marker>1989</marker>
<rawString>Center for Machine Translation 1989 KBMT-89 Project Report. Carnegie-Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>The pragmatics of lexical specificity.</title>
<date>1977</date>
<journal>Journal of Linguistics</journal>
<pages>13--153</pages>
<contexts>
<context position="11695" citStr="Cruse (1977)" startWordPosition="1750" endWordPosition="1751">em that chose a lexical unit according to the above strategy, and then added explicit modifiers to communicate attributes that were not implied by the lexical class.4 This utterance successfully communicates the relevant information, but it also implicates, to the knowledgeable hearer, that XNET is not an Ethernet — because if it was, the knowledgeable hearer would reason, then the speaker would have used utterance (3c). 2.2. Preferred Lexical Units Certain lexical units, in particular those that represent basic-level classes (Rosch 1978), are preferred and should be chosen whenever possible. Cruse (1977) and 3 Another possibility is choosing the most general lexical unit that is subsumed by the attributes being communicated. However, this cannot be done by a system that ignores the object and only looks at the attributes being communicated, because such a system would not know which lexical units accurately described the object. For example, if there were two classes Ethernet and Applenet that had the attributes (Network, Data-rate:)0Mbillsec, Circuit-type:Packet-switched}, the system could only decide whether to generate &amp;quot;Ethernet&apos; or &amp;quot;Applenet&amp;quot; by determining which of these classes subsumed</context>
</contexts>
<marker>Cruse, 1977</marker>
<rawString>Cruse, D. 1977 The pragmatics of lexical specificity. Journal of Linguistics 13:153-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cumming</author>
</authors>
<title>The Lexicon in Text Generation.</title>
<date>1986</date>
<tech>ISI Research Report ISI/RR-86-168.</tech>
<institution>Information Sciences Institute, University of Southern California.</institution>
<contexts>
<context position="2205" citStr="Cumming (1986)" startWordPosition="333" endWordPosition="334">tween what the system knows of the object or event, and what the system wishes to communicate about the object or event; and it allows lexical choices to be biased towards basic-level (Bosch 1978) and other preferred lexical units. Throughout this paper, it will be assumed that both lexical units and objects/events are represented as t Currently at the Deparunent of Artificial Intelligence, University of Edinburgh, 80 South Bridge, Edinburgh EH1 1H14, Scotland. E-mail: reiter@aipna.edinburgb.ac.uk 1 This paper does not examine the kind of collocations&apos; and selections&apos; constraints discussed by Cumming (1986) and Nirenburg and Nirenburg (1988). classes in a KL-ONE type taxonomy (Brachman and Schmolze 1985). For example, the lexical unit Bachelor might be represented as the generic class (Human with role value restrictions Sex:Male, Agestatus:Adult, Married:False); and the object Terry might be represented as the individual class (Human with role fillers Sex:Male, Eye-color:Brown, Birthplace:Chicago, Employer:IBM, Default attributes as well as definitional information can be associated with lexical units; this is essential for making appropriate lexical choices (Section 5). Figure 1 shows a sample </context>
</contexts>
<marker>Cumming, 1986</marker>
<rawString>Cumming, S. 1986 The Lexicon in Text Generation. ISI Research Report ISI/RR-86-168. Information Sciences Institute, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Goldman</author>
</authors>
<title>Conceptual generation. In</title>
<date>1975</date>
<location>New York.</location>
<contexts>
<context position="4315" citStr="Goldman 1975" startWordPosition="650" endWordPosition="651">m (Reiter 1990), which generates certain kinds of natural language object descriptions. FN uses some additional preference rules that primarily affect NP formation; these rules are not discussed in this paper. 2. Lexical Choice as Classification The two major approaches (to date) for lexical choice have been discrimination nets and structure mapping systems. Both of these approaches can be regarded as classification/matching architectures, where a classifier is given an object or event, and is asked to find an appropriate lexical unit that fits that object or event. Discrimination nets (e.g., Goldman 1975; Pustejovsky and Nirenburg 1987) are basically decision trees. They are typically used as high-speed &apos;compiled&apos; classifiers that select the most specific lexical unit that subsumes 23 Object Animal Machine Vertebrate Network Fish Breathes:Wate Mammal Breathes:Air Ethernet Data-rate:10Mbit/sec Circuit-type:Packet Physical-medium:Coaxial-cable (Number-of-legs:4) CLNET (Tiger )shark Pekingese Chdo English sparrow (Ostrich Can-fly:False) Adult Age-status:Adult Male Big-Bird Woman sex:Female Terry Eye-color:Brown Birthplace:Chicago EmployerIBM (Primitive) Class defining role VR (default role fille</context>
</contexts>
<marker>Goldman, 1975</marker>
<rawString>Goldman, N. 1975 Conceptual generation. In R. Schank and C. Riesbeck (Eds.), Conceptual Information Processing. American Elselvier. New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<publisher>Academic Press:</publisher>
<location>New York.</location>
<contexts>
<context position="8149" citStr="Grice 1975" startWordPosition="1218" endWordPosition="1219"> judged closest to the lexical unit (Human with VR&apos;s Sex:Male and Age:range(2,15)), and thus would be realized as &amp;quot;boy&amp;quot;. All of the above classification-based lexical-choice architectures2 suffer from two basic flaws: • they do not allow a clean separation to be made between what the system knows, and what it wishes to communicate; • they do not provide a clean mechanism for allowing the lexical choice process to be biased towards preferred lexical units. These failures may lead classification-based systems to choose inappropriate lexical units that carry unwanted conversational implicatures (Grice 1975), and therefore mislead the user. 2.1. One Input vs Two Inputs Classification-based systems take as their input a single set of attributes about the object/event being lexicalized, and use this set of attributes to select a matching classification. However, lexical choice systems should look at two input sets of attributes: the set of object/event attributes that are relevant and need to be conveyed to the user, and the set of attributes that constitute the system&apos;s total knowledge of the object/event being lexicalized. A lexical choice system that looks only at the system&apos;s domain knowledge a</context>
<context position="20247" citStr="Grice 1975" startWordPosition="3150" endWordPosition="3151">hould treat Bird (but not Sparrow) as a lexically-preferred class for Tweety (a Sparrow), and Ostrich (but not Bird) as a lexicallypreferred class class for Big-Bird (an Ostrich). 4.2. Length/Subset Preferences A lexical unit A is almost always preferred over a lexical unit B if A&apos;s surface form uses a subset of the words used by B&apos;s surface form (this can be considered 27 (Shark (Sparrow) (Pekinese Bachelor) (Tiger) (Englishi Shark Sparrow Basic Level Preference Word Subset Preference Figure 2: Some of the Lexical Preferences from Figure 1 28 to be a consequence of Grice&apos;s maxim of quantity (Grice 1975)). Consider, for example, 9a) &amp;quot;Don&apos;t go swimming; there is a shark in the water&amp;quot; 9b) &amp;quot;Don&apos;t go swimming; there is a tiger shark in the water&amp;quot; According to the subset lexical, preference rule, lexical unit Shark is preferred over lexical unit Tiger-shark. Therefore, the use of utterance (9b) carries the conversational implicature that utterance (9a) could not be used, i.e., that it was relevant that the animal was a Tiger-shark and not some other kind of Shark. A hearer who heard utterance (9b) might infer, for example, that the speaker thought that tiger sharks were unusually dangerous kinds o</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Grice, H. 1975 Logic and conversation. In P. Cole and J. Morgan (Eds.), Syntax and Semantics: Vol 3, Speech Acts, pg 43-58. Academic Press: New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>A Theory of Scalar Implicature.</title>
<date>1985</date>
<tech>Ph.D thesis. Report MS-CIS-85-56, LINC LAB 21,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="17612" citStr="Hirschberg (1985)" startWordPosition="2710" endWordPosition="2711">d valid, a set of lexical preferences rules is used to select the lexical unit the system will utter. The preference for basiclevel classes was previously mentioned (Section 2.2), but it is complicated by entry-level effects (Section 4.1), Additional lexical preferences include the length/subset preference (Section 4.2). Combined, the lexical preference rules impose a lexical preference hierarchy on the lexical units in the knowledge base. Figure 2 shows part of the lexical preference hierarchy that is associated with the knowledge base of Figure 1. 4.1. Basic-Level vs Entry-Level Preferences Hirschberg (1985) has suggested that it may be better to use Jolicoeur et al.&apos;s (1984) notion of entry level classes instead of Rosch&apos;s basic level classes. The difference is that under the entry-level hypothesis, which category is unmarked (i.e., which category may be used without generating a conversational implicature) may depend on how atypical the object is. For example, consider: (the speaker points to a robin) 7a) &amp;quot;Look at the bird&amp;quot; 7b) &amp;quot;Look at the robin&amp;quot; (the speaker points to an ostrich) 8a) &amp;quot;Look at the bird&amp;quot; 8b) &amp;quot;Look at the ostrich&amp;quot; Under the basic-level hypothesis, a category is either basic-leve</context>
</contexts>
<marker>Hirschberg, 1985</marker>
<rawString>Hirschberg, J. 1985 A Theory of Scalar Implicature. Ph.D thesis. Report MS-CIS-85-56, LINC LAB 21, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>R Kittredge</author>
<author>A Polguere</author>
</authors>
<title>Implementing a Meaning-Text Model for Language Generation. Presented at COLING</title>
<date>1988</date>
<note>(not in proc.).</note>
<marker>Iordanskaja, Kittredge, Polguere, 1988</marker>
<rawString>Iordanskaja, L.; Kittredge, R.; Polguere, A. 1988 Implementing a Meaning-Text Model for Language Generation. Presented at COLING 1988 (not in proc.).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jacobs</author>
</authors>
<date>1987</date>
<journal>Knowledge-Intensive Natural Language Generation. Artificial Intelligence</journal>
<pages>33--325</pages>
<contexts>
<context position="5785" citStr="Jacobs 1987" startWordPosition="849" endWordPosition="850">examples, the event Ingest(John,Mi1k027), which can be represented in KLONE as (Ingest with VR&apos;s actor:John and theme:Milk027), has as its most specific subsuming lexical unit (Ingest with VR theme:Liquid), and thus is lexically realized as &amp;quot;drink&amp;quot;. Similarly, the action Ingest(Bear036,Fish802), which &apos; can be represented in KL-ONE as (Ingest with VR&apos;s actor:Bear036 and theme:Fish802), has (Ingest with VR&apos;s agent :Nonhuman-animal and theme:Solid) as its most specific subsumer in a taxonomy of German lexical units, and thus is realized, in German, as &amp;quot;fressen&amp;quot;. Structure-mapping systems (e.g., Jacobs 1987; Ionianslcaja et al. 1988; note that different terminology is used in different papers) take as input a semantic structure that needs to be communicated to the uses, search for pieces of the input structure that are equivalent to lexical units, and then replace the matched structure by the corresponding lexical unit. The matching and substitution process continues until the semantic structure has been completely reformulated in terms of lexical units. For example, the structure (Human (:sex male) (:age-status adult) (:wealth high)) might be mapped into the structure (&amp;quot;man&amp;quot; (:attribute &amp;quot;rich&amp;quot;)</context>
</contexts>
<marker>Jacobs, 1987</marker>
<rawString>Jacobs, P. 1987 Knowledge-Intensive Natural Language Generation. Artificial Intelligence 33:325-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jolicoeur</author>
<author>M Gluck</author>
<author>S Kosslyn</author>
</authors>
<date>1984</date>
<booktitle>Pictures and Names: Making the Connection. Cognitive Psychology</booktitle>
<pages>16--243</pages>
<marker>Jolicoeur, Gluck, Kosslyn, 1984</marker>
<rawString>Jolicoeur, P.; Gluck, M.; and Kosslyn, S. 1984 Pictures and Names: Making the Connection. Cognitive Psychology 16:243-275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nirenburg</author>
<author>I Nirenburg</author>
</authors>
<title>A Framework for Lexical Selection in Natural Language Generation.</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics</booktitle>
<pages>2--471</pages>
<contexts>
<context position="2240" citStr="Nirenburg and Nirenburg (1988)" startWordPosition="336" endWordPosition="340">em knows of the object or event, and what the system wishes to communicate about the object or event; and it allows lexical choices to be biased towards basic-level (Bosch 1978) and other preferred lexical units. Throughout this paper, it will be assumed that both lexical units and objects/events are represented as t Currently at the Deparunent of Artificial Intelligence, University of Edinburgh, 80 South Bridge, Edinburgh EH1 1H14, Scotland. E-mail: reiter@aipna.edinburgb.ac.uk 1 This paper does not examine the kind of collocations&apos; and selections&apos; constraints discussed by Cumming (1986) and Nirenburg and Nirenburg (1988). classes in a KL-ONE type taxonomy (Brachman and Schmolze 1985). For example, the lexical unit Bachelor might be represented as the generic class (Human with role value restrictions Sex:Male, Agestatus:Adult, Married:False); and the object Terry might be represented as the individual class (Human with role fillers Sex:Male, Eye-color:Brown, Birthplace:Chicago, Employer:IBM, Default attributes as well as definitional information can be associated with lexical units; this is essential for making appropriate lexical choices (Section 5). Figure 1 shows a sample taxonomy that will be used for most</context>
</contexts>
<marker>Nirenburg, Nirenburg, 1988</marker>
<rawString>Nirenburg, S. and Nirenburg, I. 1988 A Framework for Lexical Selection in Natural Language Generation. Proceedings of the 12th International Conference on Computational Linguistics (2):471-475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nirenburg</author>
<author>E Nyberg</author>
<author>E Kenschaft</author>
</authors>
<title>Inexact Frame Matching for Lexical Selection in Natural Language Generation. Unpublished memo,</title>
<date>1987</date>
<institution>Center for Machine Translation, Carnegie-Mellon University.</institution>
<contexts>
<context position="7159" citStr="Nirenburg et al. 1987" startWordPosition="1061" endWordPosition="1064">nly classes and role VR&apos;s that can be realized as lexical units; e.g., the above example essentially redefines the class (Human with role VR&apos;s Sex:Male, Age-status:Adult, Wealth:High) as the equivalent class (&amp;quot;man&amp;quot; with VR &amp;quot;rich&amp;quot;), where the lexical unit &amp;quot;man&amp;quot; represents the class (Human with role VR&apos;s Sex:Male, Age-status:Adult), and the lexical unit &amp;quot;rich&amp;quot; is equivalent to the role VR Wealth:High. Recently, the machine translation group at CMU has proposed an alternative lexical choice system that is based on a variant of nearest neighbor classification (Center for Machine Translation 1989; Nirenburg et al. 1987). In the CMU system, both objects and lexical units are treated as points or regions in a feature space, and the classifier works by choosing the lexical unit that is closest to the target object, using a fairly complex distance (matching) metric (collocation constraints are also taken into consideration). For example, the object (Human with &apos;VR&apos;s Sex:Male and Age:13) would be judged closest to the lexical unit (Human with VR&apos;s Sex:Male and Age:range(2,15)), and thus would be realized as &amp;quot;boy&amp;quot;. All of the above classification-based lexical-choice architectures2 suffer from two basic flaws: • t</context>
</contexts>
<marker>Nirenburg, Nyberg, Kenschaft, 1987</marker>
<rawString>Nirenburg, S.; Nyberg, E.; and Kenschaft, E. 1987 Inexact Frame Matching for Lexical Selection in Natural Language Generation. Unpublished memo, Center for Machine Translation, Carnegie-Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>S Nirenburg</author>
</authors>
<title>Lexical selection in the process of natural language generation.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics:</booktitle>
<pages>201--206</pages>
<contexts>
<context position="4348" citStr="Pustejovsky and Nirenburg 1987" startWordPosition="652" endWordPosition="655">), which generates certain kinds of natural language object descriptions. FN uses some additional preference rules that primarily affect NP formation; these rules are not discussed in this paper. 2. Lexical Choice as Classification The two major approaches (to date) for lexical choice have been discrimination nets and structure mapping systems. Both of these approaches can be regarded as classification/matching architectures, where a classifier is given an object or event, and is asked to find an appropriate lexical unit that fits that object or event. Discrimination nets (e.g., Goldman 1975; Pustejovsky and Nirenburg 1987) are basically decision trees. They are typically used as high-speed &apos;compiled&apos; classifiers that select the most specific lexical unit that subsumes 23 Object Animal Machine Vertebrate Network Fish Breathes:Wate Mammal Breathes:Air Ethernet Data-rate:10Mbit/sec Circuit-type:Packet Physical-medium:Coaxial-cable (Number-of-legs:4) CLNET (Tiger )shark Pekingese Chdo English sparrow (Ostrich Can-fly:False) Adult Age-status:Adult Male Big-Bird Woman sex:Female Terry Eye-color:Brown Birthplace:Chicago EmployerIBM (Primitive) Class defining role VR (default role filler) (Key) Basic Level Class Lexica</context>
</contexts>
<marker>Pustejovsky, Nirenburg, 1987</marker>
<rawString>Pustejovsky, J. and Nirenburg, S. 1987 Lexical selection in the process of natural language generation. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics: pages 201-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>Generating Descriptions that Exploit a User&apos;s Domain Knowledge. In</title>
<date>1990</date>
<publisher>Academic Press:</publisher>
<location>London. Forthcoming.</location>
<contexts>
<context position="3718" citStr="Reiter 1990" startWordPosition="560" endWordPosition="561">the complexity of the diagram; default attributes (e.g., Can-fiy:True for Bird) are listed in italic font. Basic-level classes (e.g., Man) are underlined. Section 2 of the paper discusses classification-based systems and some of the problems associated with them. Section 3 introduces the proposed constraint-based system; Section 4 looks in more detail at the lexical preferences used by the system; and Section 5 briefly discusses the need for default attributes in the semantic representations of lexical units. The constraint-based lexical choice system has been incorporated into the FN system (Reiter 1990), which generates certain kinds of natural language object descriptions. FN uses some additional preference rules that primarily affect NP formation; these rules are not discussed in this paper. 2. Lexical Choice as Classification The two major approaches (to date) for lexical choice have been discrimination nets and structure mapping systems. Both of these approaches can be regarded as classification/matching architectures, where a classifier is given an object or event, and is asked to find an appropriate lexical unit that fits that object or event. Discrimination nets (e.g., Goldman 1975; P</context>
</contexts>
<marker>Reiter, 1990</marker>
<rawString>Reiter, E. 1990 Generating Descriptions that Exploit a User&apos;s Domain Knowledge. In R. Dale, C. Mellish, and M. Zock (Eds.), Current Research in Natural Language Generation. Academic Press: London. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rosch</author>
</authors>
<title>Principles of Categorization. In</title>
<date>1978</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="673" citStr="Rosch 1978" startWordPosition="100" endWordPosition="101">rt Aiken Computation Laboratory Harvard University Cambridge, Mass 02138 Abstract The lexical choice process should be regarded as a constraint satisfaction problem: the generation system must choose a lexical unit that is accurate (truthful), valid (conveys the necessary information), and preferred (maximal under a preference function). This constraint-based architecture allows a clean separation to be made between what the system knows of the object or event, and what the system wishes to communicate about the object or event. It also allows lexical choices to be biased towards basic-level (Rosch 1978) and other preferred lexical units. 1. Introduction Lexical choice for open-class words has typically been regarded as a matching or classification problem. The generation system is given a semantic structure that represents an object or event, and a dictionary that represents the semantic meanings of the lexical units (Zgusta 1971) of the target language; it then chooses the lexical unit (or set of lexical units) that best matches the object or event. This paper proposes an alternative lexical choice architecture, in which the lexical choice process is regarded as a constraint satisfaction pr</context>
<context position="11627" citStr="Rosch 1978" startWordPosition="1740" endWordPosition="1741">able. Utterance (3b) would be generated by a structure-mapping system that chose a lexical unit according to the above strategy, and then added explicit modifiers to communicate attributes that were not implied by the lexical class.4 This utterance successfully communicates the relevant information, but it also implicates, to the knowledgeable hearer, that XNET is not an Ethernet — because if it was, the knowledgeable hearer would reason, then the speaker would have used utterance (3c). 2.2. Preferred Lexical Units Certain lexical units, in particular those that represent basic-level classes (Rosch 1978), are preferred and should be chosen whenever possible. Cruse (1977) and 3 Another possibility is choosing the most general lexical unit that is subsumed by the attributes being communicated. However, this cannot be done by a system that ignores the object and only looks at the attributes being communicated, because such a system would not know which lexical units accurately described the object. For example, if there were two classes Ethernet and Applenet that had the attributes (Network, Data-rate:)0Mbillsec, Circuit-type:Packet-switched}, the system could only decide whether to generate &amp;quot;Et</context>
</contexts>
<marker>Rosch, 1978</marker>
<rawString>Rosch, E. 1978 Principles of Categorization. In E. Rosch and B. Lloyd (Eds.), Cognition and Categorization. Lawrence Erlbaum: Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zgusta</author>
</authors>
<title>Manual of Lexicography.</title>
<date>1971</date>
<publisher>Academia Press: Prague.</publisher>
<contexts>
<context position="1007" citStr="Zgusta 1971" startWordPosition="151" endWordPosition="152">tion). This constraint-based architecture allows a clean separation to be made between what the system knows of the object or event, and what the system wishes to communicate about the object or event. It also allows lexical choices to be biased towards basic-level (Rosch 1978) and other preferred lexical units. 1. Introduction Lexical choice for open-class words has typically been regarded as a matching or classification problem. The generation system is given a semantic structure that represents an object or event, and a dictionary that represents the semantic meanings of the lexical units (Zgusta 1971) of the target language; it then chooses the lexical unit (or set of lexical units) that best matches the object or event. This paper proposes an alternative lexical choice architecture, in which the lexical choice process is regarded as a constraint satisfaction problem: the generation system must choose a lexical unit that is accurate (truthful), valid (conveys the necessary information), and preferred (maximal under a preference function).1 This constraint-based architecture is more robust than classification systems. In particular, it allows a clean separation to be made between what the s</context>
</contexts>
<marker>Zgusta, 1971</marker>
<rawString>Zgusta, L. 1971 Manual of Lexicography. Academia Press: Prague.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>