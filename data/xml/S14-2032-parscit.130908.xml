<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.992779">
COMMIT-P1WP3: A Co-occurrence Based Approach
to Aspect-Level Sentiment Analysis
</title>
<author confidence="0.98416">
Kim Schouten1,2 Flavius Frasincar1 Franciska de Jong2
</author>
<email confidence="0.608204">
schouten@ese.eur.nl frasincar@ese.eur.nl fdejong@ese.eur.nl
</email>
<affiliation confidence="0.95366">
1Econometric Institute, Erasmus University Rotterdam, The Netherlands
2Erasmus Studio, Erasmus University Rotterdam, The Netherlands
</affiliation>
<sectionHeader confidence="0.977522" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965666666667">
In this paper, the crucial ingredients for
our submission to SemEval-2014 Task 4
“Aspect Level Sentiment Analysis” are
discussed. We present a simple aspect de-
tection algorithm, a co-occurrence based
method for category detection and a dic-
tionary based sentiment classification al-
gorithm. The dictionary for the latter is
based on co-occurrences as well. The fail-
ure analysis and related work section focus
mainly on the category detection method
as it is most distinctive for our work.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998444619047619">
In recent years, sentiment analysis has taken flight
and is now actively used, on the Web and be-
yond (Liu, 2012). To provide users of sentiment
tools with more detailed and useful information, a
number of innovations have been introduced, and
among others a switch from document-level sen-
timent analysis towards fine-grained, aspect-level
sentiment analysis can be seen (Feldman, 2013).
In line with the many challenges associated with
this, SemEval-2014 Task 4 “Aspect Level Senti-
ment Analysis” (Pontiki et al., 2014) is split into
four sub-tasks: Aspect Detection, Aspect Senti-
ment Classification, Category Detection, and Cat-
egory Sentiment Classification.
The main focus of this paper is on the category
detection algorithm we developed, but a method
for aspect detection and a sentiment classifica-
tion algorithm (both for aspects and categories) are
also included. The aspect detection algorithm will
be presented first, followed by the category de-
tection algorithm and the sentiment classification
</bodyText>
<footnote confidence="0.907808">
This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.9984992">
method. Next, the benchmark results for all algo-
rithms are presented, plus a discussion and failure
analysis of the category detection method. Finally,
conclusions are drawn and some suggestions for
future work are presented.
</bodyText>
<sectionHeader confidence="0.999814" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999844090909091">
Because the focus of this paper lies on the cat-
egory detection method, only for that method a
short snippet of related work is given. That algo-
rithm, being an adapted version of Schouten and
Frasincar (2014), is inspired by the work of Zhang
and Zhu (2013) and Hai et al (2011). In these
works, a co-occurrence matrix is created between
words in the sentence and aspects in order to find
implicit aspects (i.e., aspects that are not literally
mentioned, as opposed to the explicit aspects used
in this task).
While implicit aspects are similar to aspect cat-
egories to some extent, these methods do not work
when a fixed, limited set of possible aspect cat-
egories is used that is, most importantly, not a
subset of the set of aspects. The above meth-
ods could never, for instance, identify the ‘anec-
dotes/miscellaneous’ category, as this word never
appears as an aspect in the data set. This is the
main reason why we have chosen to count the co-
occurrences between words and the annotated as-
pect categories.
</bodyText>
<sectionHeader confidence="0.980069" genericHeader="method">
3 Aspect Detection Method
</sectionHeader>
<bodyText confidence="0.9991495">
In the work reported here, the aspect detection
method plays the role of a baseline method rather
than a full-fledged algorithm. In its most basic
form, it annotates all noun phrases as aspects.
However, by using the training set to count how
often each word appears within an aspect, a sim-
ple probability can be computed representing the
chance that this word is an aspect word or not.
This probability is used to filter the set of noun
phrases, such that only noun phrases remain that
</bodyText>
<page confidence="0.988196">
203
</page>
<note confidence="0.7303575">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 203–207,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999699777777778">
have at least one word for which the aspect proba-
bility ≥ 0.05 and for those noun phrases, all lead-
ing words in the noun phrase with a probability
below 0.05 are removed. This will remove words
like determiners from the initial noun phrase, as
those are not included in the aspect term. Because
this filtering is strict, the result is a typical high
precision, low recall algorithm for aspect detec-
tion.
</bodyText>
<sectionHeader confidence="0.991996" genericHeader="method">
4 Category Detection Method
</sectionHeader>
<bodyText confidence="0.999922363636364">
To find the aspect categories, the co-occurrence
based algorithm from Schouten and Frasin-
car (2014) is used and improved upon. The cen-
tral construct in this algorithm is a co-occurrence
matrix that captures the frequency of the co-
occurrences between words (i.e., the lemmas of
the words) in the sentence and the annotated as-
pect category. This gives a mapping from words to
aspect categories. When processing an unlabelled
sentence, a score is computed for each aspect cat-
egory as shown in Eq. 1.
</bodyText>
<equation confidence="0.9634865">
ci,j , (1)
oj
</equation>
<bodyText confidence="0.9881318">
where v is the number of words in the sentence,
ai is the ith aspect category in the list of possible
aspect categories for which the score is computed,
j represents the jth word in the sentence, ci,j is the
co-occurrence frequency of aspect category i and
lemma j in the data set, and oj is the frequency of
lemma j in the data set.
Whereas in Schouten and Frasincar (2014), the
highest scoring category was chosen on the con-
dition that its score exceeded a threshold, our
method is now able to choose more than one as-
pect category per sentence. This is done by train-
ing a separate threshold for each of the five aspect
categories using all training data. When the score
for some aspect category is higher than its associ-
ated threshold (i.e., scoreai &gt; thresholdai), the
sentence is annotated as having that aspect cate-
gory.
Since we assume the five threshold values to be
independent of each other, a simple linear search
is performed separately for all five of them to find
the optimal threshold value by optimizing F1 (cf.
Sec. 6). As a default option, the fifth category
(‘anecdotes/miscellaneous’) is associated to any
sentence for which none of the five categories ex-
ceeded their threshold. The trained threshold val-
ues for the five categories are:
ambience
0.042
The pseudocode for the creation of the co-
occurrence matrix can be found in Algorithm 1,
and Algorithm 2 describes the process of annotat-
ing a sentence with aspect categories.
Algorithm 1 Aspect category detection training.
Initialize set of word lemmas with frequencies
</bodyText>
<equation confidence="0.434664">
O
</equation>
<bodyText confidence="0.98678875">
Initialize set of aspect categories A
Initialize co-occurrence matrix C
for sentence s E training data do
for word w E s do
</bodyText>
<equation confidence="0.7711245">
O(w) = O(w) + 1
end for
</equation>
<bodyText confidence="0.888776">
for aspect category a E s do
</bodyText>
<subsectionHeader confidence="0.517653">
add a to A
</subsectionHeader>
<bodyText confidence="0.957934">
for word w E s do
</bodyText>
<listItem confidence="0.74444375">
C(w, a) = C(w, a) + 1
end for
end for
end for
</listItem>
<bodyText confidence="0.673873">
for aspect category a in A do
</bodyText>
<equation confidence="0.9549336">
thresholda=0
bestF1 = 0
for t = 0 to 1 step 0.001 do
Execute Algorithm 2 on training data
Compute F1
</equation>
<construct confidence="0.428761">
if F1 &gt; bestF1 then thresholda = t
</construct>
<listItem confidence="0.706807">
end if
end for
end for
</listItem>
<sectionHeader confidence="0.964624" genericHeader="method">
5 Sentiment Classification Method
</sectionHeader>
<bodyText confidence="0.999823083333333">
For sentiment classification, a method is devel-
oped that first creates a sentiment lexicon based
on the aspect sentiment annotation. That lexicon
is then consequently used to determine the senti-
ment of both aspects and categories that have no
sentiment annotation. The intuition behind this
method is that a lexicon should cover domain-
specific words and expressions in order to be ef-
fective. To avoid creating such a sentiment lexi-
con manually, the aspect sentiment annotations are
leveraged to create one automatically. The idea is
that words that often appear close to positive or
</bodyText>
<figure confidence="0.764270884615385">
1
v
scoreai =
�v
j=1
price food service misc
0.024 0.211 0.071 0.143
204
Algorithm 2 Aspect category detection execution.
for sentence s E test data do
for aspect category a E A do
score = 0
for word w E s do
if O(w) &gt; 0 then
score = score+C(w, a)/O(w)
end if
end for
score = score/length(s)
if score &gt; thresholda then
Assign aspect category a to s
end if
end for
if s has no assigned aspect categories then
Assign ‘anecdotes/miscellaneous’ to s
end if
end for
</figure>
<bodyText confidence="0.999464777777778">
negative aspects are likely to have the same polar-
ity. Since sentiment is also carried by expressions,
rather than single words only, the constructed sen-
timent lexicon has entries for encountered uni-
grams, bigrams, and trigrams. In each sentence,
the distance between each n-gram and each aspect
is computed and the sentiment of the aspect, dis-
counted by the computed distance, is added to the
sentiment value of the n-gram, as shown in Eq. 2.
</bodyText>
<equation confidence="0.880063428571429">
sentimentg =
1
p torder(g) &apos; polaritya
freqg 1: 1:
(distanceg,a)m,
s∈Sg a∈As
(2)
</equation>
<sectionHeader confidence="0.995809" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.997027866666667">
the closest two are used to compute the distance).
Note that essentially, dictionary creation is based
on how often an n-gram co-occurs with positive
or negative aspects. In our submitted run on the
restaurant data, we set torder(g) to 1, 5, and 4 for
unigrams, bigrams, and trigrams, respectively, and
p = 2 and for the laptop data we set torder(g) to 1,
0, and 3 for the n-grams and p = 1. In both cases,
m was kept at 1. These values were determined by
manual experimentation.
To compute the sentiment of an aspect, the sen-
timent value of each n-gram is divided by the dis-
tance between that n-gram and the aspect, com-
puted in a similar fashion as in the above formula)
and summed up, as shown in Eq. 3.
</bodyText>
<figure confidence="0.5589815">
1: sentimenta,sa = sentimentg (3)
g∈sa (min distanceg,a)m
</figure>
<bodyText confidence="0.999664288888889">
where, in addition to the definitions in the previ-
ous equation, g is an n-gram in sa, which is the
sentence in which aspect a occurs. Note that for
each occurrence of a term, its sentiment value is
added to the total score. If the result is above zero,
the class will be ‘positive’, and if the result is be-
low zero, the class will be ‘negative’. In the rare
event of the sentiment score being exactly zero,
the ‘neutral’ class is assigned.
For category sentiment classification, the for-
mula of Eq. 3 remains the same, except that the
distance term min distancemg,a is set to 1, since
aspect categories pertain to the whole sentence in-
stead of having specific offsets.
where g is the n-gram (i.e., word unigram, bigram,
or trigram), freqg is the frequency of n-gram g
in the data set, s is a sentence in Sg, which is
the set of sentences that contain n-gram g, p is a
parameter to correct for the overall positivity of
the data set, t is a parameter that corrects for the
relative influence of the type of n-gram (i.e., dif-
ferent values are used for t1, t2, and t3), a is an
aspect in As, which is the set of aspects in sen-
tence s, polaritya is 1 when aspect a is positive
and −1 when a is negative, and m is a parame-
ter that determines how strong the discounting by
the distance should be. The distance computed
is the shortest word distance between the aspect
and the n-gram (i.e., both an n-gram and an as-
pect can consist of multiple words, in which case
All three algorithms presented above were evalu-
ated through a submission in the SemEval-2014
Task 4 “Aspect Level Sentiment Analysis”. Two
data sets have been used, one consisting of sen-
tences from restaurant reviews, the other consist-
ing of sentences from laptop reviews. Both sets
have been annotated with aspects and aspect senti-
ment, but only the restaurant set is also annotated
with aspect categories and their associated senti-
ment class. Both data sets are split into a training
set of roughly 3000 sentences and a test set of 800
sentences.
All sentences in the data set have been pre-
processed by a tokenizer, a Part-of-Speech tagger,
and a lemmatizer. These tasks were performed by
</bodyText>
<page confidence="0.995478">
205
</page>
<table confidence="0.886674352941177">
recall
0.558
F1
0.593
precision
restaurant 0.633
Table 1: Official results for both algorithms.
aspect detection (subtask 1)
precision recall F1
laptop 0.836 0.148 0.252
restaurant 0.909 0.388 0.544
category detection (subtask 3)
aspect sentiment classification (subtask 2)
laptop accuracy 0.570
restaurant accuracy 0.660
category sentiment classification (subtask 4)
restaurant accuracy 0.677
</table>
<bodyText confidence="0.977569205882353">
the Stanford CoreNLP framework1. Furthermore,
the OpenNLP2 chunker was used to provide basic
phrase chunking in order to retrieve noun phrases
for instance.
The official scores, as computed by the task or-
ganizers are shown in Table 1. Note that the senti-
ment classification algorithm is used for subtasks 2
and 4, so two scores are reported, and that subtasks
3 and 4 can only be performed with the restaurant
data set.
As the performance of the category detection
method was lower than anticipated, a failure anal-
ysis has been performed. This led to the observa-
tion that overfitting is one of major factors in ex-
plaining the lower performance . This is shown in
Figure 1, in which one can easily notice the great
difference in in-sample performance, and the per-
formance on unseen data. Notice that by using 10-
fold cross-validation, better results are achieved
than on the official test set. This indicates that
there are factors other than overfitting that influ-
ence the performance.
Interestingly, especially recall is influenced by
the overfitting problem: precision is almost the
same for the 10-fold cross-validation and even
with the in-sample performance it increases only
a little bit. To gain more insight into the difference
in recall, a graph showing the relative contribution
to false negatives of the five categories is shown in
Figure 2. For completeness, the same graph but for
false positives is also shown, together with the fre-
quency distribution of the categories in both train-
ing and test set.
Immediately visible is the effect of defaulting to
</bodyText>
<footnote confidence="0.999936">
1http://nlp.stanford.edu/software/corenlp.shtml
2https://opennlp.apache.org/
</footnote>
<figureCaption confidence="0.846403">
Figure 1: Performance measure of category detec-
tion on different parts of data.
</figureCaption>
<bodyText confidence="0.998834583333334">
the ‘anecdotes/miscellaneous’ when no category is
assigned to that sentence: many false positives are
generated by this rule, but there are almost no false
negatives for this category. Note that without this
default, F1-measure would drop by roughly 3 per-
centage points.
Also notable is the difference between the in-
sample bar and the official results bar: two cat-
egories, namely ‘anecdotes/miscellaneous’ and
‘food’ show large differences in contribution to
false positives and false negatives. The algo-
rithm finds fewer ‘food’ categories in the test
set, than in the training set, while for ‘anec-
dotes/miscellaneous’, the reverse is the case. This
can at least be partly explained by the change in
data statistics: in the training set, 33% of the an-
notated categories are ‘food’ and 30% are ‘anec-
dotes/miscellaneous’, whereas in the test set, these
numbers are 40% and 22%, respectively. With
much more sentences having the ‘food’ category,
false positives will be lower but false negatives
will be higher. For ‘anecdotes/miscellaneous’, the
reverse is true: with less sentences in the test set
having this category, false positives will by higher,
but false negatives will be lower, a change rein-
forced by ‘anecdotes/miscellaneous’ being the de-
fault.
Two factors remain that might have negatively
impacted the performance of the algorithm. The
first is that in the restaurant set, many words ap-
pear only once (e.g., dishes, ingredients), and
when words do not appear in the training set, no
co-occurrence with any category can be recorded.
This primarily affects recall. The second is that
the category thresholds, while working well on the
training set, do not seem to generalize well to the
</bodyText>
<page confidence="0.997802">
206
</page>
<figureCaption confidence="0.981943">
Figure 2: The frequency distribution of each category and its relative contribution to the total number of
</figureCaption>
<bodyText confidence="0.853655285714286">
false negatives (left graph) and false positives (right graph). The middle graph shows the change in the
distribution of categories in the training and test set.
test set. Testing the algorithm with one threshold
for all five categories, while showing a sharply de-
creased in-sample performance, yields an out-of-
sample F1-measure that is only slightly lower than
F1-measure with different thresholds.
</bodyText>
<sectionHeader confidence="0.998355" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999975423076923">
In this paper the main ingredients for our submis-
sion to SemEval-2014 Task 4 “Aspect Level Sen-
timent Analysis” are discussed: a simple aspect
detection method, a co-occurrence based method
for category detection, and a dictionary based sen-
timent classification algorithm. Since the category
detection algorithm did not perform as expected, a
failure analysis has been performed, while for the
others this was less necessary as they performed
roughly as expected.
The failure analysis provides several starting
points for future research. First, it would be in-
teresting to determine the exact nature of the de-
pendency between category performance and cat-
egory frequency, as discussed above, and to re-
move this dependency, since it is not guaranteed in
real-life scenarios that the frequency distribution
of the training set is the same as the set of instances
an algorithm will encounter when in use. Fur-
thermore, training five separate category thresh-
old, while good for performance in general, also
aggravates the problem of overfitting. Hence, im-
proving the generalization of the algorithm, and
the thresholds in particular, is important. Last,
a method to deal with very low frequency words
could prove useful as well.
</bodyText>
<sectionHeader confidence="0.98271" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999077">
The authors are partially supported by the Dutch
national program COMMIT.
</bodyText>
<sectionHeader confidence="0.99905" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996588">
Ronen Feldman. 2013. Techniques and Applications
for Sentiment Analysis. Communications of the
ACM, 56(4):82–89.
Zhen Hai, Kuiyu Chang, and J. Kim. 2011. Implicit
Feature Identification via Co-occurrence Associa-
tion Rule Mining. In Proceedings of the 12th In-
ternational Conference on Computational Linguis-
tics and Intelligent Text processing (CICLing 2011),
volume 6608, pages 393–404. Springer.
Bing Liu. 2012. Sentiment Analysis and Opinion
Mining, volume 16 of Synthesis Lectures on Human
Language Technologies. Morgan &amp; Claypool.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 Task 4:
Aspect Based Sentiment Analysis. In Proceedings
of the International Workshop on Semantic Evalua-
tion (SemEval 2014).
Kim Schouten and Flavius Frasincar. 2014. Find-
ing Implicit Features in Consumer Reviews for Sen-
timent Analysis. In Proceedings of the 14th In-
ternational Conference on Web Engineering (ICWE
2014), pages 130–144. Springer.
Yu Zhang and Weixiang Zhu. 2013. Extracting
Implicit Features in Online Customer Reviews for
Opinion Mining. In Proceedings of the 22nd Inter-
national Conference on World Wide Web Companion
(WWW 2013 Companion), pages 103–104. Interna-
tional World Wide Web Conferences Steering Com-
mittee.
</reference>
<page confidence="0.998007">
207
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.068277">
<title confidence="0.6619805">COMMIT-P1WP3: A Co-occurrence Based to Aspect-Level Sentiment Analysis</title>
<abstract confidence="0.2409095">de schouten@ese.eur.nl frasincar@ese.eur.nl</abstract>
<address confidence="0.6506695">Institute, Erasmus University Rotterdam, The Studio, Erasmus University Rotterdam, The Netherlands</address>
<abstract confidence="0.999297153846154">In this paper, the crucial ingredients for our submission to SemEval-2014 Task 4 “Aspect Level Sentiment Analysis” are discussed. We present a simple aspect detection algorithm, a co-occurrence based method for category detection and a dictionary based sentiment classification algorithm. The dictionary for the latter is based on co-occurrences as well. The failure analysis and related work section focus mainly on the category detection method as it is most distinctive for our work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and Applications for Sentiment Analysis.</title>
<date>2013</date>
<journal>Communications of the ACM,</journal>
<volume>56</volume>
<issue>4</issue>
<contexts>
<context position="1223" citStr="Feldman, 2013" startWordPosition="171" endWordPosition="172">tion algorithm. The dictionary for the latter is based on co-occurrences as well. The failure analysis and related work section focus mainly on the category detection method as it is most distinctive for our work. 1 Introduction In recent years, sentiment analysis has taken flight and is now actively used, on the Web and beyond (Liu, 2012). To provide users of sentiment tools with more detailed and useful information, a number of innovations have been introduced, and among others a switch from document-level sentiment analysis towards fine-grained, aspect-level sentiment analysis can be seen (Feldman, 2013). In line with the many challenges associated with this, SemEval-2014 Task 4 “Aspect Level Sentiment Analysis” (Pontiki et al., 2014) is split into four sub-tasks: Aspect Detection, Aspect Sentiment Classification, Category Detection, and Category Sentiment Classification. The main focus of this paper is on the category detection algorithm we developed, but a method for aspect detection and a sentiment classification algorithm (both for aspects and categories) are also included. The aspect detection algorithm will be presented first, followed by the category detection algorithm and the sentime</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and Applications for Sentiment Analysis. Communications of the ACM, 56(4):82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Hai</author>
<author>Kuiyu Chang</author>
<author>J Kim</author>
</authors>
<title>Implicit Feature Identification via Co-occurrence Association Rule Mining.</title>
<date>2011</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text processing (CICLing 2011),</booktitle>
<volume>6608</volume>
<pages>393--404</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2572" citStr="Hai et al (2011)" startWordPosition="376" endWordPosition="379">footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ method. Next, the benchmark results for all algorithms are presented, plus a discussion and failure analysis of the category detection method. Finally, conclusions are drawn and some suggestions for future work are presented. 2 Related Work Because the focus of this paper lies on the category detection method, only for that method a short snippet of related work is given. That algorithm, being an adapted version of Schouten and Frasincar (2014), is inspired by the work of Zhang and Zhu (2013) and Hai et al (2011). In these works, a co-occurrence matrix is created between words in the sentence and aspects in order to find implicit aspects (i.e., aspects that are not literally mentioned, as opposed to the explicit aspects used in this task). While implicit aspects are similar to aspect categories to some extent, these methods do not work when a fixed, limited set of possible aspect categories is used that is, most importantly, not a subset of the set of aspects. The above methods could never, for instance, identify the ‘anecdotes/miscellaneous’ category, as this word never appears as an aspect in the da</context>
</contexts>
<marker>Hai, Chang, Kim, 2011</marker>
<rawString>Zhen Hai, Kuiyu Chang, and J. Kim. 2011. Implicit Feature Identification via Co-occurrence Association Rule Mining. In Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text processing (CICLing 2011), volume 6608, pages 393–404. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining,</title>
<date>2012</date>
<volume>16</volume>
<publisher>Morgan &amp; Claypool.</publisher>
<contexts>
<context position="950" citStr="Liu, 2012" startWordPosition="132" endWordPosition="133">his paper, the crucial ingredients for our submission to SemEval-2014 Task 4 “Aspect Level Sentiment Analysis” are discussed. We present a simple aspect detection algorithm, a co-occurrence based method for category detection and a dictionary based sentiment classification algorithm. The dictionary for the latter is based on co-occurrences as well. The failure analysis and related work section focus mainly on the category detection method as it is most distinctive for our work. 1 Introduction In recent years, sentiment analysis has taken flight and is now actively used, on the Web and beyond (Liu, 2012). To provide users of sentiment tools with more detailed and useful information, a number of innovations have been introduced, and among others a switch from document-level sentiment analysis towards fine-grained, aspect-level sentiment analysis can be seen (Feldman, 2013). In line with the many challenges associated with this, SemEval-2014 Task 4 “Aspect Level Sentiment Analysis” (Pontiki et al., 2014) is split into four sub-tasks: Aspect Detection, Aspect Sentiment Classification, Category Detection, and Category Sentiment Classification. The main focus of this paper is on the category detec</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining, volume 16 of Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Harris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>SemEval-2014 Task 4: Aspect Based Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="1356" citStr="Pontiki et al., 2014" startWordPosition="190" endWordPosition="193">n focus mainly on the category detection method as it is most distinctive for our work. 1 Introduction In recent years, sentiment analysis has taken flight and is now actively used, on the Web and beyond (Liu, 2012). To provide users of sentiment tools with more detailed and useful information, a number of innovations have been introduced, and among others a switch from document-level sentiment analysis towards fine-grained, aspect-level sentiment analysis can be seen (Feldman, 2013). In line with the many challenges associated with this, SemEval-2014 Task 4 “Aspect Level Sentiment Analysis” (Pontiki et al., 2014) is split into four sub-tasks: Aspect Detection, Aspect Sentiment Classification, Category Detection, and Category Sentiment Classification. The main focus of this paper is on the category detection algorithm we developed, but a method for aspect detection and a sentiment classification algorithm (both for aspects and categories) are also included. The aspect detection algorithm will be presented first, followed by the category detection algorithm and the sentiment classification This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings </context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the International Workshop on Semantic Evaluation (SemEval 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kim Schouten</author>
<author>Flavius Frasincar</author>
</authors>
<title>Finding Implicit Features in Consumer Reviews for Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th International Conference on Web Engineering (ICWE 2014),</booktitle>
<pages>130--144</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2502" citStr="Schouten and Frasincar (2014)" startWordPosition="361" endWordPosition="364">eative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ method. Next, the benchmark results for all algorithms are presented, plus a discussion and failure analysis of the category detection method. Finally, conclusions are drawn and some suggestions for future work are presented. 2 Related Work Because the focus of this paper lies on the category detection method, only for that method a short snippet of related work is given. That algorithm, being an adapted version of Schouten and Frasincar (2014), is inspired by the work of Zhang and Zhu (2013) and Hai et al (2011). In these works, a co-occurrence matrix is created between words in the sentence and aspects in order to find implicit aspects (i.e., aspects that are not literally mentioned, as opposed to the explicit aspects used in this task). While implicit aspects are similar to aspect categories to some extent, these methods do not work when a fixed, limited set of possible aspect categories is used that is, most importantly, not a subset of the set of aspects. The above methods could never, for instance, identify the ‘anecdotes/misc</context>
<context position="4486" citStr="Schouten and Frasincar (2014)" startWordPosition="701" endWordPosition="705">rkshop on Semantic Evaluation (SemEval 2014), pages 203–207, Dublin, Ireland, August 23-24, 2014. have at least one word for which the aspect probability ≥ 0.05 and for those noun phrases, all leading words in the noun phrase with a probability below 0.05 are removed. This will remove words like determiners from the initial noun phrase, as those are not included in the aspect term. Because this filtering is strict, the result is a typical high precision, low recall algorithm for aspect detection. 4 Category Detection Method To find the aspect categories, the co-occurrence based algorithm from Schouten and Frasincar (2014) is used and improved upon. The central construct in this algorithm is a co-occurrence matrix that captures the frequency of the cooccurrences between words (i.e., the lemmas of the words) in the sentence and the annotated aspect category. This gives a mapping from words to aspect categories. When processing an unlabelled sentence, a score is computed for each aspect category as shown in Eq. 1. ci,j , (1) oj where v is the number of words in the sentence, ai is the ith aspect category in the list of possible aspect categories for which the score is computed, j represents the jth word in the se</context>
</contexts>
<marker>Schouten, Frasincar, 2014</marker>
<rawString>Kim Schouten and Flavius Frasincar. 2014. Finding Implicit Features in Consumer Reviews for Sentiment Analysis. In Proceedings of the 14th International Conference on Web Engineering (ICWE 2014), pages 130–144. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Zhang</author>
<author>Weixiang Zhu</author>
</authors>
<title>Extracting Implicit Features in Online Customer Reviews for Opinion Mining.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd International Conference on World Wide Web Companion (WWW 2013 Companion),</booktitle>
<pages>103--104</pages>
<institution>International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="2551" citStr="Zhang and Zhu (2013)" startWordPosition="371" endWordPosition="374"> numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ method. Next, the benchmark results for all algorithms are presented, plus a discussion and failure analysis of the category detection method. Finally, conclusions are drawn and some suggestions for future work are presented. 2 Related Work Because the focus of this paper lies on the category detection method, only for that method a short snippet of related work is given. That algorithm, being an adapted version of Schouten and Frasincar (2014), is inspired by the work of Zhang and Zhu (2013) and Hai et al (2011). In these works, a co-occurrence matrix is created between words in the sentence and aspects in order to find implicit aspects (i.e., aspects that are not literally mentioned, as opposed to the explicit aspects used in this task). While implicit aspects are similar to aspect categories to some extent, these methods do not work when a fixed, limited set of possible aspect categories is used that is, most importantly, not a subset of the set of aspects. The above methods could never, for instance, identify the ‘anecdotes/miscellaneous’ category, as this word never appears a</context>
</contexts>
<marker>Zhang, Zhu, 2013</marker>
<rawString>Yu Zhang and Weixiang Zhu. 2013. Extracting Implicit Features in Online Customer Reviews for Opinion Mining. In Proceedings of the 22nd International Conference on World Wide Web Companion (WWW 2013 Companion), pages 103–104. International World Wide Web Conferences Steering Committee.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>