<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002151">
<title confidence="0.987998">
The NL2KR Platform for building Natural Language Translation Systems
</title>
<author confidence="0.99732">
Nguyen H. Vo, Arindam Mitra and Chitta Baral
</author>
<affiliation confidence="0.9984975">
School of Computing, Informatics and Decision Systems Engineering
Arizona State University
</affiliation>
<email confidence="0.995286">
{nguyen.h.vo, amitra7, chitta }@asu.edu
</email>
<sectionHeader confidence="0.997354" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973">
This paper presents the NL2KR platform
to build systems that can translate text to
different formal languages. It is freely-
available1, customizable, and comes with
an Interactive GUI support that is use-
ful in the development of a translation
system. Our key contribution is a user-
friendly system based on an interactive
multistage learning algorithm. This effec-
tive algorithm employs Inverse-A, Gener-
alization and user provided dictionary to
learn new meanings of words from sen-
tences and their representations. Using
the learned meanings, and the Generaliza-
tion approach, it is able to translate new
sentences. NL2KR is evaluated on two
standard corpora, Jobs and GeoQuery and
it exhibits state-of-the-art performance on
both of them.
</bodyText>
<sectionHeader confidence="0.994074" genericHeader="categories and subject descriptors">
1 Introduction and Related Work
</sectionHeader>
<bodyText confidence="0.999737461538462">
For natural language interaction with systems one
needs to translate natural language text to the input
language of that system. Since different systems
(such as a robot or database system) may have dif-
ferent input language, we need a way to translate
natural language to different formal languages as
needed by the application. We have developed a
user friendly platform, NL2KR, that takes exam-
ples of sentences and their translations (in a de-
sired target language that varies with the applica-
tion), and some bootstrap information (an initial
lexicon), and constructs a translation system from
text to that desired target language.
</bodyText>
<footnote confidence="0.930114">
1http://nl2kr.engineering.asu.edu/
</footnote>
<bodyText confidence="0.999933605263158">
Our approach to translate natural language text
to formal representation is inspired by Montague’s
work (Montague, 1974) where the meanings of
words and phrases are expressed as A-calculus ex-
pressions and the meaning of a sentence is built
from semantics of constituent words through ap-
propriate A-calculus (Church, 1936) applications.
A major challenge in using this approach has been
the difficulty of coming up with the A-calculus
representation of words.
Montague’s approach has been widely used in
(Zettlemoyer and Collins, 2005; Kwiatkowski et
al., 2010) to translate natural language to formal
languages. In ZC05 (Zettlemoyer and Collins,
2005) the learning algorithm requires the user to
provide the semantic templates for all words. A
semantic template is a A-expression (e.g. Ax.p(x)
for an arity one predicate), which describes a par-
ticular pattern of representation in that formal lan-
guage. With all these possible templates, the
learning algorithm extracts the semantic represen-
tation of the words from the formal representa-
tion of a sentence. It then associates the extracted
meanings to the words of the sentence in all possi-
ble ways and ranks the associations according to
some goodness measure. While manually com-
ing up with semantic templates for one target lan-
guage is perhaps reasonable, manually doing it for
different target languages corresponding to differ-
ent applications may not be a good idea as manual
creation of semantic templates requires deep un-
derstanding of translation to the target language.
This calls for automating this process. In UBL
(Kwiatkowski et al., 2010) this process is auto-
mated by restricting the choices of formal rep-
resentation and learning the meanings in a brute
force manner. Given, a sentence S and its rep-
resentation M in the restricted formal language,
</bodyText>
<page confidence="0.984162">
899
</page>
<note confidence="0.978276333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 899–908,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999796371794872">
it breaks the sentence into two smaller substrings
51, 52 and uses higher-order unification to com-
pute two A-terms M1, M2 which combines to pro-
duce M. It then recursively learns the meanings
of the words, from the sub-instance &lt; 51, M1 &gt;
and &lt; 52, M2 &gt;. Since, there are many ways
to split the input sentence 5 and the choice of
M1, M2 can be numerous, it needs to consider all
possible splittings and their combinations; which
produces many spurious meanings. Most impor-
tantly, their higher-order unification algorithm im-
poses various restrictions (such as limited num-
ber of conjunctions in a sentence, limited forms of
functional application) on the meaning representa-
tion language which severely limits its applicabil-
ity to new applications. Another common draw-
back of these two algorithms is that they both suf-
fer when the test sentence contains words that are
not part of the training corpus.
Our platform NL2KR uses a different auto-
mated approach based on Inverse-A (section 2.1)
and Generalization (section 2.2) which does not
impose such restrictions enforced by their higher-
order unification algorithm. Also, Generaliza-
tion algorithm along with Combinatory Categor-
ical Grammar (Steedman, 2000) parser, allows
NL2KR to go beyond the training dictionary and
translate sentences which contain previously un-
seen words. The main aspect of our approach is as
follows: given a sentence, its semantic representa-
tion and an initial dictionary containing the mean-
ing of some words, NL2KR first obtains several
derivation of the input sentence in Combinatory
Categorical Grammar (CCG). Each CCG deriva-
tion tree describes the rules of functional appli-
cation through which constituents combine with
each other. With the user provided initial dictio-
nary, NL2KR then traverses the tree in a bottom-
up fashion to compute the semantic expressions
of intermediate nodes. It then traverses the aug-
mented tree in a top-down manner to learn the
meaning of missing words using Inverse-A (sec-
tion 2.1). If Inverse-A is not sufficient to learn the
meaning of all unknown words, it employs Gen-
eralization (section 2.2) to guess the meanings of
unknown words with the meaning of known sim-
ilar words. It then restarts the learning process
with the updated knowledge. The learning pro-
cess stops if it learns the meanings of all words or
fails to learn any new meaning in an iteration. In
the latter case, it shows the augmented tree to the
user. The user can then provide meanings of some
unknown words and resumes the learning process.
Another distinguishing feature of NL2KR is its
user-friendly interface that helps users in creating
their own translation system. The closest system
to NL2KR is the UW Semantic Parsing Frame-
work (UW SPF) (Artzi and Zettlemoyer, 2013)
which incorporates the algorithms in (Zettlemoyer
and Collins, 2005; Kwiatkowski et al., 2010) .
However, to use UW SPF for the development of
a new system, the user needs to learn their coding
guidelines and needs to write new code in their
system. NL2KR does not require the users to
write new code and guides the development pro-
cess with its rich user interface.
We have evaluated NL2KR on two standard
datasets: GeoQuery (Tang and Mooney, 2001) and
Jobs (Tang and Mooney, 2001). GeoQuery is a
database of geographical questions and Jobs con-
tains sentences with job related query. Experi-
ments demonstrate that NL2KR can exhibit state-
of-the-art performance with fairly small initial dic-
tionary. The rest of the paper is organized as fol-
lows: we first present the algorithms and archi-
tecture of the NL2KR platform in section 2; we
discuss about the experiments in section 3; and fi-
nally, we conclude in section 4.
</bodyText>
<sectionHeader confidence="0.962732" genericHeader="method">
2 Algorithms and Architecture
</sectionHeader>
<bodyText confidence="0.999921727272728">
The NL2KR architecture (Figure 1) has two sub-
parts which depend on each other (1) NL2KR-
L for learning and (2) NL2KR-T for translation.
The NL2KR-L sub-part takes the following as in-
put: (1) a set of training sentences and their tar-
get formal representations, and (2) an initial lexi-
con or dictionary consisting of some words, their
CCG categories, and their meanings in terms of A-
calculus expressions. It then constructs the CCG
parse trees and uses them for learning of word
meanings.
Learning of word meanings is done by using
Inverse-A and Generalization (Baral et al., 2012;
Baral et al., 2011) and ambiguity is addressed
by a Parameter Learning module that learns the
weights of the meanings. The learned meanings
update the lexicon. The translation sub-part uses
this updated lexicon to get the meaning of all the
words in a new sentence, and combines them to get
the meaning of the new sentence. Details of each
module will be presented in the following subsec-
tions.
</bodyText>
<page confidence="0.996525">
900
</page>
<figureCaption confidence="0.999961">
Figure 1: Architecture of NL2KR
</figureCaption>
<bodyText confidence="0.999868555555556">
The NL2KR platform provides a GUI (Figure 2)
with six features: A-application, Inverse-A, Gen-
eralization, CCG-Parser, NL2KR-L and NL2KR-
T. The fourth feature is a stand-alone CCG parser
and the first four features can help on user with
constructing the initial lexicon. The user can then
use NL2KR-L to update the lexicon using train-
ing data and the NL2KR-T button then works as a
translation system.
</bodyText>
<subsectionHeader confidence="0.955338">
2.1 Inverse-A
</subsectionHeader>
<bodyText confidence="0.999079714285714">
Inverse-A plays a key role in the learning pro-
cess. Formally, given two A-expressions H and
G with H = F@G or H = G@F, the
Inverse-A operation computes the A expression
F. For example, given the meaning of “is texas”
as Ax2.x2@stateid(texas) and the meaning of
“texas” as stateid(texas), with the additional
information that “is” acts as the function while
“texas” is the argument, the Inverse-A algorithm
computes the meaning of “is” as Ax3.Ax2.x2@x3
(Figure 4). NL2KR implements the Inverse-A al-
gorithm specified in (Baral et al., 2012). The
Inverse-A module is separately accessible through
the main GUI (Figure 2).
</bodyText>
<subsectionHeader confidence="0.997229">
2.2 Generalization
</subsectionHeader>
<bodyText confidence="0.9983087">
Generalization (Baral et al., 2012; Baral et al.,
2011) is used when Inverse-A is not sufficient to
learn new semantic representation of words. In
contrast to Inverse-A which learns the exact mean-
ing of a word in a particular context, General-
ization learns the meanings of a word from sim-
ilar words with existing representations. Thus,
Generalization helps NL2KR to learn meanings
of words that are not even present in the train-
ing data set. In the current implementation, two
words are considered as similar if they have the
exact same CCG category. As an example, if
we want to generalize the meaning of the word
“plays” with CCG category (S\NP)/NP) and
the lexicon already contains an entry for “eats”
with the same CCG category, and the mean-
ing Ay.Ax.eats(x, y), the algorithm will ex-
tract the template Ay.Ax.WORD(x, y) and ap-
ply the template to plays to get the meaning
Ay.Ax.plays(x, y).
</bodyText>
<subsectionHeader confidence="0.998071">
2.3 Combinatory Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.99995696">
Derivation of a sentence in Combinatory Catego-
rial Grammar (CCG) determines the way the con-
stituents combine together to establish the mean-
ing of the whole. CCG is a type of phrase struc-
ture grammar and clearly describes the predicate-
argument structure of constituents.
Figure 3 shows an example output of NL2KR’s
CCG parser. In the figure, “John” and “home”
have the category [N] (means noun) and can
change to [NP] (means noun phrase). The
phrase“walk home” has the category [S\NP],
which means that it can combine with a con-
stituent with category [NP] (“John” in this case)
from left with the backward application to form
category [S] (sentence). The word “walk” has
the category [(S\NP)/NP], which means it can
combine with a constituent with category [NP]
(“home”) from right through the forward appli-
cation combinator to form category [S\NP] (of
“walk home”).
A detailed description on CCG goes beyond the
scope of this paper (see (Steedman, 2000) for more
details). Since, natural language sentences can
have various CCG parse trees, each expressing a
different meaning of the sentence, a key challenge
</bodyText>
<page confidence="0.995729">
901
</page>
<figureCaption confidence="0.9999875">
Figure 2: NL2KR’s main GUI, Version 1.7.0001
Figure 3: CCG parse tree of ”John walked home”.
</figureCaption>
<bodyText confidence="0.99989424137931">
in the learning and the translation process is to find
a suitable CCG parse tree for a sentence in natu-
ral language. We overcome this impediment by
allowing our learning and translation subsystem
to work with multiple weighted parse trees for a
given sentence and determining on the fly, the one
that is most suitable. We discuss more on this in
sections 2.4-2.6.
Existing CCG parsers (Curran et al., 2007; Lier-
ler and Sch¨uller, 2012) either return a single best
parse tree for a given sentence or parse it in all
possible ways with no preferential ordering among
them. In order to overcome this shortcoming and
generate more than one weighted candidate parse
trees, we have developed a new parser using beam
search with Cocke-Younger-Kasami(CYK) algo-
rithm. NL2KRs CCG parser uses the C&amp;C model
(Curran et al., 2007) and constraints from the Stan-
ford parser (Socher et al., 2013; Toutanova et al.,
2003) to guide the derivation of a sentence. The
output of the CCG parser is a set of k weighted
parse trees, where the parameter k is provided by
the user.
NL2KR system allows one to use the CCG
parser independently through the interactive GUI.
The output graphs look like the one in Figure 3. It
can be zoomed in/out and its nodes can be moved
around, making it easier to work with complex
sentences.
</bodyText>
<subsectionHeader confidence="0.997097">
2.4 Multistage learning approach
</subsectionHeader>
<bodyText confidence="0.9998192">
Learning meanings of words is the major com-
ponent of our system. The inputs to the learning
module are a list of training sentences, their target
formal representations and an initial lexicon con-
sisting of triplets of the form &lt;word, CCG cate-
gory, meaning&gt;, where meanings are represented
in terms of A-calculus expressions. The output
of the algorithm is a final dictionary containing
a set of 4-tuples (word, CCG category, meaning,
weight).
</bodyText>
<subsectionHeader confidence="0.653644">
Interactive Multistage Learning Algorithm
</subsectionHeader>
<bodyText confidence="0.99972325">
(IMLA) NL2KR employs an Interactive Multi-
stage Learning Algorithm (Algorithm 1) that runs
many iterations on the input sentences. In each
iteration, it goes through one or more of the fol-
lowing stages:
Stage 1 In Stage 1, it gets all the unfinished
sentences. It then employs Bottom Up-Top Down
algorithm (Algorithm 2) to learn new meanings
(by Inverse-A). For a sentence, if it has com-
puted the meanings of all its constituents, which
can be combined to produce the given representa-
tion, that sentence is considered as learned. Each
</bodyText>
<page confidence="0.985046">
902
</page>
<bodyText confidence="0.325167">
Algorithm 1 IMLA algorithm
</bodyText>
<listItem confidence="0.9926825">
1: function IMLA(initLexicon,sentences,
sentsMeanings)
2: regWords +— 0
3: generalize +— false
4: lexicon +— initLexicon
5: repeat
6: repeat
7: repeat
8: for all s E sentences do
9: newMeanings �
BT(s,lexicon,sentsMeanings)
10: lexicon +— lexicon U newMeanings
11: for all n E newMeanings do
12: ms +— GENERALIZE(regWords, n)
13: lexicon +— lexicon U ms
14: end for
15: end for
16: until newMeanings = 0
17: if generalize=false then
18: generalize +— true
19: for all t E unfinished5ents do
20: words +— GETALLWORDS(t)
21: ms +— GENERALIZE(words)
22: lexicon +— lexicon U ms
23: regWords +— regWords U words
24: end for
25: end if
26: until newMeanings = 0
27: INTERATIVELEARNING
28: until unfinished5ents = 0 OR userBreak
29: lexicon +— PARAMETERESTIMA-
TION(lexicon,sentences)
30: return lexicon
31: end function
</listItem>
<bodyText confidence="0.98785584375">
new meaning learned by this process is used to
generalize the words in a waiting list. Initially,
this waiting list is empty and is updated in stage
2. When no more new meaning can be learned
by Bottom Up-Top Down algorithm, IMLA (Algo-
rithm 1) enters stage 2.
Stage 2 In this stage, it takes all the sentences
for which the learning is not yet finished and ap-
plies Generalization process on all the words of
those sentences. At the same time, it populates
those words into the waiting list, so that from now
on, Bottom Up-Top Down will try to generalize
new meanings for them when it learns some new
meanings. It then goes back to stage 1. Next time,
after exiting stage 1, it directly goes to stage 3.
Stage 3 When both aforementioned stages
can not learn all the sentences, the Interactive
Learning process is invoked and all the unfinished
sentences are shown on the interactive GUI (Fig-
ure 4). Users can either skip or provide more in-
formation on the GUI and the learning process is
continued.
After finishing all stages, IMLA (Algorithm 1)
calls Parameter Estimation (section 2.5) algorithm
to compute the weight of each lexicon tuple.
Bottom Up-Top Down learning For a given
sentence, the CCG parser is used for the CCG
parse trees like the one of how big is texas in Fig-
ure 4. For each parse tree, two main processes
are called, namely “bottom up” and “top down”.
In the first process, all the meanings of the words
in the sentences are retrieved from the lexicon.
These meanings are populated in the leaf nodes
of a parse tree (see Figure 4), which are combined
in a bottom-up manner to compute the meanings
of phrases and full sentences. We call these mean-
ings, the current meanings.
In the “top down” process, using Inverse-A al-
gorithm, the given meaning of the whole sentence
(called the expected meaning of the sentence) and
the current meanings of the phrases, we calcu-
late the expected meanings of each of the phrases
from the root of the tree to the leaves. For ex-
ample, given the expected meaning of how big is
texas and the current meaning of how big, we use
Inverse-A algorithm to get the meaning (expected)
of is texas. This expected meaning is used together
with current meanings of is (texas) to calculate
the expected meanings of texas (is). The expected
meanings of the leaf nodes we have just learned
will be saved to the lexicon and will be used in the
other sentences and in subsequent learning itera-
tion. The “top down” process is stopped when the
expected meanings are same as the current mean-
ings. And in both “bottom up” and “top-down”
processes, the beam search algorithm is used to
speed-up the learning process.
Interactive learning In the interactive learning
process it opens a GUI which shows the unfinished
sentences. Users can see the current and expected
meanings for the unfinished sentences. When the
user gives additional meanings of word(s), the A-
application or Inverse-A operation is automatically
performed to update the new meaning(s) to related
</bodyText>
<page confidence="0.998662">
903
</page>
<figureCaption confidence="0.999049">
Figure 4: Interactive learning GUI. The box under each node show: the corresponding phrases [CCG category], the expected
meanings and the current meanings. Click on the red node will show the window to change the current meaning (CLE)
</figureCaption>
<figure confidence="0.47075575">
Algorithm 2 BottomUp-TopDown (BT) algo-
rithm
1: function BT(
sentence, lexicon, sentsMeanings)
</figure>
<listItem confidence="0.983330666666667">
2: parseTrees ← CCGPARSER(sentence)
3: for all tree E parseTrees do
4: t ← BOTTOMUP(tree,lexicon)
5: TOPDOWN(t,sentsMeanings)
6: end for
7: end function
</listItem>
<bodyText confidence="0.995874625">
word(s). Once satisfied, the user can switch back
to the automated learning mode.
Example Let us consider the ques-
tion “How big is texas?” with meaning
answer(size(stateid(texas))) (see Figure
4).
Let us assume that the initial dictionary has
the following entries: how := NP/(N/N) :
Ax.Ay.answer(x@y), big := N/N : Ax.size(x)
and texas := NP : stateid(texas). The algorithm
then proceeds as follows.
First, the meanings of “how” and “big” are com-
bined to compute the current meaning of “how
big” := NP : Ax.answer(size(x)) in the “bot-
tom up” process. Since the meaning of “is” is un-
known, the current meaning of “is texas” still re-
mains unknown.
It then starts the “top down” process where
it knows the expected meaning of “How big is
texas” := 5 : answer(size(stateid(texas)))
and the current meaning of “how big”. Using
them in the Inverse-A algorithm, it then com-
pute the meaning of “is texas” := 5\NP :
Ax1.x1@stateid(texas). Using this expected
meaning and current meaning of “texas” := NP :
stateid(texas), it then calculates the expected
meaning of “is” as “is” := (5\NP)/NP :
Ax2.Ax1.x1@x2. This newly learned expected
meaning is then saved into the lexicon.
Since the meaning of all the words in the ques-
tion are known, the learning algorithm stops here
and the Interactive Learning is never called.
If initially, the dictionary contains only two
meanings: “big” := N/N : Ax.size(x) and
“texas” := NP : stateid(texas), NL2KR tries
to first learn the sentence but fails to learn
the complete sentence and switches to Inter-
active Learning which shows the interactive
GUI (see Figure 4). If the user specifies
that “how” means Ax.Ay.answer(x@y), NL2KR
combines its meaning with the meaning of “big”
to get the meaning “how big” := NP :
Ax.answer(size(x)). It will then use Inverse-
A to figure out the meaning of “is texas” and
then the meaning of “is”. Now all the mean-
ings are combined to compute the current mean-
ing answer(size(stateid(texas))) of “How big
is texas”. This meaning is same as the expected
</bodyText>
<page confidence="0.996776">
904
</page>
<bodyText confidence="0.999333333333333">
meaning, so we know that the sentence is suc-
cessfully learned. Now, the user can press Retry
Learning to switch back to automated learning.
</bodyText>
<subsectionHeader confidence="0.976738">
2.5 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.999236166666667">
The Parameter Estimation module estimates a
weight for each word-meaning pair such that the
joint probability of the training sentences getting
translated to their given representation is maxi-
mized. It implements the algorithm described in
Zettlemoyer et. al.(2005).
</bodyText>
<subsectionHeader confidence="0.963735">
2.6 Translation
</subsectionHeader>
<bodyText confidence="0.980046588235294">
The goal of this module is to convert input sen-
tences into the target formalism using the lexi-
con previously learned. The algorithm used in
Translation module (Algorithm 3) is similar to the
bottom-up process in the learning algorithm. It
first obtains several weighted CCG parse trees of
the input sentence. It then computes a formal rep-
resentation for each of the parse trees using the
learned dictionary. Finally, it ranks the transla-
tions according to the weights of word-meaning
pairs and the weights of the CCG parse trees.
However, test sentences may contain words which
were not present in the training set. In such cases,
Generalization is used to guess the meanings of
those unknown words from the meanings of the
similar words present in the dictionary.
Algorithm 3 Translation algorithm
</bodyText>
<listItem confidence="0.983567181818182">
1: function TRANSLATE(sentence, lexicon)
2: candidates +— 0
3: parseTrees +— CCGPARSER(sentence)
4: for all tree E parseTrees do
5: GENERALIZE(tree);
6: t +— BOTTOMUP(tree)
7: candidates +— candidates U t
8: end for
9: output +— VERIFY-RANK(candidates)
10: return output
11: end function
</listItem>
<sectionHeader confidence="0.993739" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999905722222222">
We have evaluated NL2KR on two standard cor-
pora: GeoQuery and Jobs. For both the corpus, the
output generated by the learned system has been
considered correct if it is an exact replica of the
logical formula described in the corpus.
We report the performance in terms of precision
(percentage of returned logical-forms that are cor-
rect), recall (percentage of sentences for which the
correct logical-form was returned), F1-measure
(harmonic mean of precision and recall) and the
size of the initial dictionary.
We compare the performance of our sys-
tem with recently published, directly-comparable
works, namely, FUBL (Kwiatkowski et al.,
2011), UBL (Kwiatkowski et al., 2010), A-WASP
(Wong and Mooney, 2007), ZC07 (Zettlemoyer
and Collins, 2007) and ZC05 (Zettlemoyer and
Collins, 2005) systems.
</bodyText>
<subsectionHeader confidence="0.998047">
3.1 Corpora
</subsectionHeader>
<bodyText confidence="0.958920782608696">
GeoQuery GeoQuery (Tang and Mooney, 2001)
is a corpus containing questions on geographical
facts about the United States. It contains a total of
880 sentences written in natural language, paired
with their meanings in a formal query language,
which can be executed against a database of the
geographical information of the United States.
We follow the standard training/testing split of
600/280. An example sentence meaning pair is
shown below.
Sentence: How long is the Colorado river?
Meaning: answer(A,(len(B,A),const(B,
riverid(colorado)), river(B)))
Jobs The Jobs (Tang and Mooney, 2001) dataset
contains a total of 640 job related queries written
in natural language. The Prolog programming
language has been used to represent the meaning
of a query. Each query specifies a list of job
criteria and can be directly executed against a
database of job listings. An example sentence
meaning pair from the corpus is shown below.
Question: What jobs are there for program-
mers that know assembly?
</bodyText>
<equation confidence="0.584704666666667">
Meaning: answer(J,(job(J),title(J,T),
const(T,’Programmer’),language(J,L),
const(L,’assembly’))))
</equation>
<bodyText confidence="0.999248">
The dataset contains a training split of 500 sen-
tences and a test split of 140 sentences.
</bodyText>
<subsectionHeader confidence="0.99776">
3.2 Initial Dictionary Formulation
</subsectionHeader>
<bodyText confidence="0.999652">
GeoQuery For GeoQuery corpus, we manually
selected a set of 100 structurally different sen-
tences from the training set and initiated the learn-
ing process with a dictionary containing the repre-
</bodyText>
<page confidence="0.995093">
905
</page>
<table confidence="0.99214225">
GUI Driven Initial Dictionary Learned Dictionary
� &lt;word, category &gt; 31 118 401
� &lt;word, category, meaning&gt; 36 127 1572
� meaning 30 89 819
</table>
<tableCaption confidence="0.990445333333333">
Table 1: Comparison of Initial and Learned dictionary for GeoQuery corpus on the basis of the number of entries in the
dictionary, number of unique &lt;word, CCG category&gt; pairs and the number of unique meanings across all the entries. “GUI
Driven” denotes the amount of the total meanings given through interactive GUI and is a subset of the Initial dictionary.
</tableCaption>
<table confidence="0.99982775">
GUI Driven Initial Dictionary Learned Dictionary
� &lt;word, category&gt; 58 103 226
� &lt;word, category, meaning&gt; 74 119 1793
� meaning 57 71 940
</table>
<tableCaption confidence="0.999918">
Table 2: Comparison of Initial and Learned dictionary for Jobs corpus.
</tableCaption>
<bodyText confidence="0.999973152173913">
sentation of the nouns and question words. These
meanings were easy to obtain as they follow sim-
ple patterns. We then trained the translation sys-
tem on those selected sentences. The output of
this process was used as the initial dictionary for
training step. Further meanings were provided on
demand through interactive learning. A total of
119 word meanings tuples (Table 1, � &lt;word, cat-
egory, meaning &gt;) were provided from which the
NL2KR system learned 1793 tuples. 45 of the 119
were representation of nouns and question words
that were obtained using simple patterns. The re-
maining 74 were obtained by a human using the
NL2KR GUI. These numbers illustrate the useful-
ness of the NL2KR GUI as well as the NL2KR
learning component. One of our future goals is to
further automate the process and reduce the GUI
interaction part.
Table 1 compares the initial and learned dic-
tionary for GeoQuery on the basis of number
of unique &lt;word, category, meaning&gt; entries in
dictionary, number of unique &lt;word, category&gt;
pairs and the number of unique meanings across
all the entries in the dictionary. Since each unique
&lt;word, CCG category&gt; pair must have at least
one meaning, the total number of unique &lt;word,
category&gt; pairs in the training corpus provides a
lower bound on the size of the ideal output dictio-
nary. However, one &lt;word, category&gt; pair may
have multiple meanings, so the ideal dictionary
can be much bigger than the number of unique
&lt;word, category&gt; pairs. Indeed, there were many
words such as “of”, “in” that had multiple mean-
ings for the same CCG category. Table 1 clearly
describes that the amount of initial effort is sub-
stantially less compared to the return.
Jobs For the Jobs dataset, we followed a similar
process as in the GeoQuery dataset. A set of 120
structurally different sentences were selected and a
dictionary was created which contained the repre-
sentation of the nouns and the question words from
the training corpus. A total of 127 word meanings
were provided in the process. Table 2 compares
the initial and learned dictionary for Jobs. Again,
we can see that the amount of initial effort is sub-
stantially less in comparison to the return.
</bodyText>
<subsectionHeader confidence="0.971906">
3.3 Precision, Recall and F1-measure
</subsectionHeader>
<figureCaption confidence="0.917897">
Figure 5: Comparison of Precision, Recall and F1-measure
on GeoQuery and Jobs dataset.
</figureCaption>
<bodyText confidence="0.830507">
Table 3, Table 4 and Figure 5 present the com-
parison of the performance of NL2KR on the Geo-
Query and Jobs domain with other recent works.
NL2KR obtained 91.1% precision value, 92.1%
</bodyText>
<page confidence="0.984603">
906
</page>
<table confidence="0.999853142857143">
System Precision Recall F1
ZC05 0.963 0.793 0.87
ZC07 0.916 0.861 0.888
λ-WASP 0.9195 0.8659 0.8919
UBL 0.885 0.879 0.882
FUBL 0.886 0.886 0.886
NL2KR 0.911 0.921 0.916
</table>
<tableCaption confidence="0.9887815">
Table 3: Comparison of Precision, Recall and F1-measure on
GeoQuery dataset.
</tableCaption>
<bodyText confidence="0.999627658536585">
recall value and a F1-measure of 91.6% on Geo-
Query (Figure 5, Geo880) dataset. For Jobs cor-
pus, the precision, recall and F1-measure were
95.43%, 94.03% and 94.72% respectively. In
all cases, NL2KR achieved state-of-the-art recall
and F1 measures and it significantly outperformed
FUBL (the latest work on translation systems) on
GeoQuery.
For both GeoQuery and Jobs corpus, our recall
is significantly higher than existing systems be-
cause meanings discovered by NL2KRs learning
algorithm is more general and reusable. In other
words, meanings learned from a particular sen-
tence are highly likely to be applied again in the
context of other sentences. It may be noted that,
larger lexicons do not necessarily imply higher re-
call as lambda expressions for two phrases may
not be suitable for functional application, thus
failing to generate any translation for the whole.
Moreover, the use of a CCG parser maximizes the
recall by exhibiting consistency and providing a
set of weighted parse trees. By consistency, we
mean that the order of the weighted parse tree re-
mains same over multiple parses of the same sen-
tence and the sentences having similar syntactic
structures have identical ordering of the deriva-
tions, thus making Generalization to be more ef-
fective in the process of translation.
The sentences for which NL2KR did not have
a translation are the ones having structural dif-
ference with the sentences present in the train-
ing dataset. More precisely, their structure was
not identical with any of the sentences present in
the training dataset or could not be constructed by
combining the structures observed in the training
sentences.
We analyzed the sentences for which the trans-
lated meaning did not match the correct one and
observed that the translation algorithm selected
the wrong meaning, even though it discovered the
correct one as one of the possible meanings the
</bodyText>
<table confidence="0.999279">
System Precision Recall F1
ZC05 0.9736 0.7929 0.8740
COCKTAIL 0.9325 0.7984 0.8603
NL2KR 0.9543 0.9403 0.9472
</table>
<tableCaption confidence="0.989986">
Table 4: Comparison of Precision, Recall and F1-measure on
Jobs dataset.
</tableCaption>
<bodyText confidence="0.9995603125">
sentence could have had in the target formal lan-
guage. Among the sentences for which NL2KR
returned a translation, there were very few in-
stances where it did not discover the correct mean-
ing in the set of possible meanings.
It may be noted that even though our preci-
sion is lower than ZC05 and very close to ZC07
and WASP; we have achieved significantly higher
F1 measure than all the related systems. In
fact, ZC05, which achieves the best precision for
both the datasets, is better by a margin of only
0.019 on the Jobs dataset and 0.052 on the Geo-
Query dataset. We think one of the main rea-
sons is that it uses manually predefined lambda-
templates, which we try to automate as much as
possible.
</bodyText>
<sectionHeader confidence="0.999531" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999910214285714">
NL2KR is a freely available2, user friendly, rich
graphical platform for building translation systems
to convert sentences from natural language to their
equivalent formal representations in a wide vari-
ety of domains. We have described the system al-
gorithms and architecture and its performance on
the GeoQuery and Jobs datasets. As mentioned
earlier, the NL2KR GUI and the NL2KR learning
module help in starting from a small initial lex-
icon (for example, 119 in Table 2) and learning
a much larger lexicon (1793 in Table 2). One of
our future goals is to reduce the initial lexicon to
be even smaller by further automating the NL2KR
GUI interaction component.
</bodyText>
<sectionHeader confidence="0.99802" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99900925">
We thank NSF for the DataNet Federation Consor-
tium grant OCI-0940841 and ONR for their grant
N00014-13-1-0334 for partially supporting this re-
search.
</bodyText>
<footnote confidence="0.7687705">
2More examples and a tutorial to use NL2KR are available
in the download package.
</footnote>
<page confidence="0.995562">
907
</page>
<sectionHeader confidence="0.998303" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999815575">
Yoav Artzi and Luke Zettlemoyer. 2013. UW SPF:
The University of Washington Semantic Parsing
Framework. arXiv preprint arXiv:1311.3011.
Chitta Baral, Juraj Dzifcak, Marcos Alvarez Gonzalez,
and Jiayu Zhou. 2011. Using inverse λ and gener-
alization to translate english to formal languages. In
Proceedings of the Ninth International Conference
on Computational Semantics, pages 35–44. Associ-
ation for Computational Linguistics.
Chitta Baral, Juraj Dzifcak, Marcos Alvarez Gonzalez,
and Aaron Gottesman. 2012. Typed answer set pro-
gramming lambda calculus theories and correctness
of inverse lambda algorithms with respect to them.
TPLP, 12(4-5):775–791.
Alonzo Church. 1936. An Unsolvable Problem of
Elementary Number Theory. American Journal of
Mathematics, 58(2):345–363, April.
James Curran, Stephen Clark, and Johan Bos. 2007.
Linguistically Motivated Large-Scale NLP with
C&amp;C and Boxer. In Proceedings of the 45th An-
nual Meeting of the Association for Computational
Linguistics Companion Volume Proceedings of the
Demo and Poster Sessions, pages 33–36, Prague,
Czech Republic, June. Association for Computa-
tional Linguistics.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilis-
tic CCG grammars from logical form with higher-
order unification. In Proceedings of the 2010 con-
ference on empirical methods in natural language
processing, pages 1223–1233. Association for Com-
putational Linguistics.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2011. Lexical general-
ization in ccg grammar induction for semantic pars-
ing. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1512–1523. Association for Computational Linguis-
tics.
Yuliya Lierler and Peter Sch¨uller. 2012. Parsing com-
binatory categorial grammar via planning in answer
set programming. In Correct Reasoning, pages 436–
453. Springer.
Richard Montague. 1974. English as a Formal Lan-
guage. In Richmond H. Thomason, editor, Formal
Philosophy: Selected Papers of Richard Montague,
pages 188–222. Yale University Press, New Haven,
London.
Richard Socher, John Bauer, Christopher D. Manning,
and Andrew Y. Ng. 2013. Parsing with Composi-
tional Vector Grammars. In ACL (1), pages 455–
465.
Mark Steedman. 2000. The syntactic process, vol-
ume 35. MIT Press.
Lappoon R Tang and Raymond J Mooney. 2001. Us-
ing multiple clause constructors in inductive logic
programming for semantic parsing. In Machine
Learning: ECML 2001, pages 466–477. Springer.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1.
Yuk Wah Wong and Raymond J Mooney. 2007.
Learning synchronous grammars for semantic pars-
ing with lambda calculus. In Annual Meeting-
Association for computational Linguistics, vol-
ume 45, page 960. Citeseer.
Luke S. Zettlemoyer and Michael Collins. 2005.
Learning to Map Sentences to Logical Form: Struc-
tured Classification with Probabilistic Categorial
Grammars. In UAI, pages 658–666. AUAI Press.
Luke S Zettlemoyer and Michael Collins. 2007. On-
line learning of relaxed CCG grammars for parsing
to logical form. In In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL-2007).
</reference>
<page confidence="0.997453">
908
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.609023">
<title confidence="0.999513">The NL2KR Platform for building Natural Language Translation Systems</title>
<author confidence="0.979323">Nguyen H Vo</author>
<author confidence="0.979323">Arindam Mitra</author>
<author confidence="0.979323">Chitta</author>
<affiliation confidence="0.9438095">School of Computing, Informatics and Decision Systems Arizona State</affiliation>
<email confidence="0.700826">amitra7,chitta</email>
<abstract confidence="0.9996671">This paper presents the NL2KR platform to build systems that can translate text to different formal languages. It is freelycustomizable, and comes with an Interactive GUI support that is useful in the development of a translation system. Our key contribution is a userfriendly system based on an interactive multistage learning algorithm. This effective algorithm employs Inverse-A, Generalization and user provided dictionary to learn new meanings of words from sentences and their representations. Using the learned meanings, and the Generalization approach, it is able to translate new sentences. NL2KR is evaluated on two standard corpora, Jobs and GeoQuery and it exhibits state-of-the-art performance on both of them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>UW SPF: The University of Washington Semantic Parsing Framework. arXiv preprint arXiv:1311.3011.</title>
<date>2013</date>
<contexts>
<context position="6516" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="1022" endWordPosition="1025">s of unknown words with the meaning of known similar words. It then restarts the learning process with the updated knowledge. The learning process stops if it learns the meanings of all words or fails to learn any new meaning in an iteration. In the latter case, it shows the augmented tree to the user. The user can then provide meanings of some unknown words and resumes the learning process. Another distinguishing feature of NL2KR is its user-friendly interface that helps users in creating their own translation system. The closest system to NL2KR is the UW Semantic Parsing Framework (UW SPF) (Artzi and Zettlemoyer, 2013) which incorporates the algorithms in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) . However, to use UW SPF for the development of a new system, the user needs to learn their coding guidelines and needs to write new code in their system. NL2KR does not require the users to write new code and guides the development process with its rich user interface. We have evaluated NL2KR on two standard datasets: GeoQuery (Tang and Mooney, 2001) and Jobs (Tang and Mooney, 2001). GeoQuery is a database of geographical questions and Jobs contains sentences with job related query. Experiments dem</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Yoav Artzi and Luke Zettlemoyer. 2013. UW SPF: The University of Washington Semantic Parsing Framework. arXiv preprint arXiv:1311.3011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chitta Baral</author>
<author>Juraj Dzifcak</author>
<author>Marcos Alvarez Gonzalez</author>
<author>Jiayu Zhou</author>
</authors>
<title>Using inverse λ and generalization to translate english to formal languages.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics,</booktitle>
<pages>35--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8060" citStr="Baral et al., 2011" startWordPosition="1285" endWordPosition="1288">hms and Architecture The NL2KR architecture (Figure 1) has two subparts which depend on each other (1) NL2KRL for learning and (2) NL2KR-T for translation. The NL2KR-L sub-part takes the following as input: (1) a set of training sentences and their target formal representations, and (2) an initial lexicon or dictionary consisting of some words, their CCG categories, and their meanings in terms of Acalculus expressions. It then constructs the CCG parse trees and uses them for learning of word meanings. Learning of word meanings is done by using Inverse-A and Generalization (Baral et al., 2012; Baral et al., 2011) and ambiguity is addressed by a Parameter Learning module that learns the weights of the meanings. The learned meanings update the lexicon. The translation sub-part uses this updated lexicon to get the meaning of all the words in a new sentence, and combines them to get the meaning of the new sentence. Details of each module will be presented in the following subsections. 900 Figure 1: Architecture of NL2KR The NL2KR platform provides a GUI (Figure 2) with six features: A-application, Inverse-A, Generalization, CCG-Parser, NL2KR-L and NL2KRT. The fourth feature is a stand-alone CCG parser and</context>
<context position="9579" citStr="Baral et al., 2011" startWordPosition="1535" endWordPosition="1538">expressions H and G with H = F@G or H = G@F, the Inverse-A operation computes the A expression F. For example, given the meaning of “is texas” as Ax2.x2@stateid(texas) and the meaning of “texas” as stateid(texas), with the additional information that “is” acts as the function while “texas” is the argument, the Inverse-A algorithm computes the meaning of “is” as Ax3.Ax2.x2@x3 (Figure 4). NL2KR implements the Inverse-A algorithm specified in (Baral et al., 2012). The Inverse-A module is separately accessible through the main GUI (Figure 2). 2.2 Generalization Generalization (Baral et al., 2012; Baral et al., 2011) is used when Inverse-A is not sufficient to learn new semantic representation of words. In contrast to Inverse-A which learns the exact meaning of a word in a particular context, Generalization learns the meanings of a word from similar words with existing representations. Thus, Generalization helps NL2KR to learn meanings of words that are not even present in the training data set. In the current implementation, two words are considered as similar if they have the exact same CCG category. As an example, if we want to generalize the meaning of the word “plays” with CCG category (S\NP)/NP) and</context>
</contexts>
<marker>Baral, Dzifcak, Gonzalez, Zhou, 2011</marker>
<rawString>Chitta Baral, Juraj Dzifcak, Marcos Alvarez Gonzalez, and Jiayu Zhou. 2011. Using inverse λ and generalization to translate english to formal languages. In Proceedings of the Ninth International Conference on Computational Semantics, pages 35–44. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chitta Baral</author>
<author>Juraj Dzifcak</author>
<author>Marcos Alvarez Gonzalez</author>
<author>Aaron Gottesman</author>
</authors>
<title>Typed answer set programming lambda calculus theories and correctness of inverse lambda algorithms with respect to them.</title>
<date>2012</date>
<journal>TPLP,</journal>
<pages>12--4</pages>
<contexts>
<context position="8039" citStr="Baral et al., 2012" startWordPosition="1281" endWordPosition="1284">section 4. 2 Algorithms and Architecture The NL2KR architecture (Figure 1) has two subparts which depend on each other (1) NL2KRL for learning and (2) NL2KR-T for translation. The NL2KR-L sub-part takes the following as input: (1) a set of training sentences and their target formal representations, and (2) an initial lexicon or dictionary consisting of some words, their CCG categories, and their meanings in terms of Acalculus expressions. It then constructs the CCG parse trees and uses them for learning of word meanings. Learning of word meanings is done by using Inverse-A and Generalization (Baral et al., 2012; Baral et al., 2011) and ambiguity is addressed by a Parameter Learning module that learns the weights of the meanings. The learned meanings update the lexicon. The translation sub-part uses this updated lexicon to get the meaning of all the words in a new sentence, and combines them to get the meaning of the new sentence. Details of each module will be presented in the following subsections. 900 Figure 1: Architecture of NL2KR The NL2KR platform provides a GUI (Figure 2) with six features: A-application, Inverse-A, Generalization, CCG-Parser, NL2KR-L and NL2KRT. The fourth feature is a stand</context>
<context position="9424" citStr="Baral et al., 2012" startWordPosition="1512" endWordPosition="1515">ng data and the NL2KR-T button then works as a translation system. 2.1 Inverse-A Inverse-A plays a key role in the learning process. Formally, given two A-expressions H and G with H = F@G or H = G@F, the Inverse-A operation computes the A expression F. For example, given the meaning of “is texas” as Ax2.x2@stateid(texas) and the meaning of “texas” as stateid(texas), with the additional information that “is” acts as the function while “texas” is the argument, the Inverse-A algorithm computes the meaning of “is” as Ax3.Ax2.x2@x3 (Figure 4). NL2KR implements the Inverse-A algorithm specified in (Baral et al., 2012). The Inverse-A module is separately accessible through the main GUI (Figure 2). 2.2 Generalization Generalization (Baral et al., 2012; Baral et al., 2011) is used when Inverse-A is not sufficient to learn new semantic representation of words. In contrast to Inverse-A which learns the exact meaning of a word in a particular context, Generalization learns the meanings of a word from similar words with existing representations. Thus, Generalization helps NL2KR to learn meanings of words that are not even present in the training data set. In the current implementation, two words are considered as</context>
</contexts>
<marker>Baral, Dzifcak, Gonzalez, Gottesman, 2012</marker>
<rawString>Chitta Baral, Juraj Dzifcak, Marcos Alvarez Gonzalez, and Aaron Gottesman. 2012. Typed answer set programming lambda calculus theories and correctness of inverse lambda algorithms with respect to them. TPLP, 12(4-5):775–791.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alonzo Church</author>
</authors>
<title>An Unsolvable Problem of Elementary Number Theory.</title>
<date>1936</date>
<journal>American Journal of Mathematics,</journal>
<volume>58</volume>
<issue>2</issue>
<contexts>
<context position="2011" citStr="Church, 1936" startWordPosition="301" endWordPosition="302">KR, that takes examples of sentences and their translations (in a desired target language that varies with the application), and some bootstrap information (an initial lexicon), and constructs a translation system from text to that desired target language. 1http://nl2kr.engineering.asu.edu/ Our approach to translate natural language text to formal representation is inspired by Montague’s work (Montague, 1974) where the meanings of words and phrases are expressed as A-calculus expressions and the meaning of a sentence is built from semantics of constituent words through appropriate A-calculus (Church, 1936) applications. A major challenge in using this approach has been the difficulty of coming up with the A-calculus representation of words. Montague’s approach has been widely used in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) to translate natural language to formal languages. In ZC05 (Zettlemoyer and Collins, 2005) the learning algorithm requires the user to provide the semantic templates for all words. A semantic template is a A-expression (e.g. Ax.p(x) for an arity one predicate), which describes a particular pattern of representation in that formal language. With all these pos</context>
</contexts>
<marker>Church, 1936</marker>
<rawString>Alonzo Church. 1936. An Unsolvable Problem of Elementary Number Theory. American Journal of Mathematics, 58(2):345–363, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
<author>Stephen Clark</author>
<author>Johan Bos</author>
</authors>
<title>Linguistically Motivated Large-Scale NLP with C&amp;C and Boxer.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>33--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="12065" citStr="Curran et al., 2007" startWordPosition="1952" endWordPosition="1955">age sentences can have various CCG parse trees, each expressing a different meaning of the sentence, a key challenge 901 Figure 2: NL2KR’s main GUI, Version 1.7.0001 Figure 3: CCG parse tree of ”John walked home”. in the learning and the translation process is to find a suitable CCG parse tree for a sentence in natural language. We overcome this impediment by allowing our learning and translation subsystem to work with multiple weighted parse trees for a given sentence and determining on the fly, the one that is most suitable. We discuss more on this in sections 2.4-2.6. Existing CCG parsers (Curran et al., 2007; Lierler and Sch¨uller, 2012) either return a single best parse tree for a given sentence or parse it in all possible ways with no preferential ordering among them. In order to overcome this shortcoming and generate more than one weighted candidate parse trees, we have developed a new parser using beam search with Cocke-Younger-Kasami(CYK) algorithm. NL2KRs CCG parser uses the C&amp;C model (Curran et al., 2007) and constraints from the Stanford parser (Socher et al., 2013; Toutanova et al., 2003) to guide the derivation of a sentence. The output of the CCG parser is a set of k weighted parse tre</context>
</contexts>
<marker>Curran, Clark, Bos, 2007</marker>
<rawString>James Curran, Stephen Clark, and Johan Bos. 2007. Linguistically Motivated Large-Scale NLP with C&amp;C and Boxer. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 33–36, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higherorder unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 conference on empirical methods in natural language processing,</booktitle>
<pages>1223--1233</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2250" citStr="Kwiatkowski et al., 2010" startWordPosition="335" endWordPosition="338">that desired target language. 1http://nl2kr.engineering.asu.edu/ Our approach to translate natural language text to formal representation is inspired by Montague’s work (Montague, 1974) where the meanings of words and phrases are expressed as A-calculus expressions and the meaning of a sentence is built from semantics of constituent words through appropriate A-calculus (Church, 1936) applications. A major challenge in using this approach has been the difficulty of coming up with the A-calculus representation of words. Montague’s approach has been widely used in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) to translate natural language to formal languages. In ZC05 (Zettlemoyer and Collins, 2005) the learning algorithm requires the user to provide the semantic templates for all words. A semantic template is a A-expression (e.g. Ax.p(x) for an arity one predicate), which describes a particular pattern of representation in that formal language. With all these possible templates, the learning algorithm extracts the semantic representation of the words from the formal representation of a sentence. It then associates the extracted meanings to the words of the sentence in all possible ways and ranks t</context>
<context position="6611" citStr="Kwiatkowski et al., 2010" startWordPosition="1035" endWordPosition="1038">with the updated knowledge. The learning process stops if it learns the meanings of all words or fails to learn any new meaning in an iteration. In the latter case, it shows the augmented tree to the user. The user can then provide meanings of some unknown words and resumes the learning process. Another distinguishing feature of NL2KR is its user-friendly interface that helps users in creating their own translation system. The closest system to NL2KR is the UW Semantic Parsing Framework (UW SPF) (Artzi and Zettlemoyer, 2013) which incorporates the algorithms in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) . However, to use UW SPF for the development of a new system, the user needs to learn their coding guidelines and needs to write new code in their system. NL2KR does not require the users to write new code and guides the development process with its rich user interface. We have evaluated NL2KR on two standard datasets: GeoQuery (Tang and Mooney, 2001) and Jobs (Tang and Mooney, 2001). GeoQuery is a database of geographical questions and Jobs contains sentences with job related query. Experiments demonstrate that NL2KR can exhibit stateof-the-art performance with fairly small initial dictionar</context>
<context position="22590" citStr="Kwiatkowski et al., 2010" startWordPosition="3709" endWordPosition="3712">oQuery and Jobs. For both the corpus, the output generated by the learned system has been considered correct if it is an exact replica of the logical formula described in the corpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is shown below. Sentence: How long is </context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higherorder unification. In Proceedings of the 2010 conference on empirical methods in natural language processing, pages 1223–1233. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Lexical generalization in ccg grammar induction for semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1512--1523</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="22558" citStr="Kwiatkowski et al., 2011" startWordPosition="3704" endWordPosition="3707">L2KR on two standard corpora: GeoQuery and Jobs. For both the corpus, the output generated by the learned system has been considered correct if it is an exact replica of the logical formula described in the corpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is sho</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2011</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2011. Lexical generalization in ccg grammar induction for semantic parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1512–1523. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuliya Lierler</author>
<author>Peter Sch¨uller</author>
</authors>
<title>Parsing combinatory categorial grammar via planning in answer set programming.</title>
<date>2012</date>
<booktitle>In Correct Reasoning,</booktitle>
<pages>436--453</pages>
<publisher>Springer.</publisher>
<marker>Lierler, Sch¨uller, 2012</marker>
<rawString>Yuliya Lierler and Peter Sch¨uller. 2012. Parsing combinatory categorial grammar via planning in answer set programming. In Correct Reasoning, pages 436– 453. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>English as a Formal Language. In</title>
<date>1974</date>
<pages>188--222</pages>
<editor>Richmond H. Thomason, editor,</editor>
<publisher>Yale University Press,</publisher>
<location>New Haven, London.</location>
<contexts>
<context position="1810" citStr="Montague, 1974" startWordPosition="269" endWordPosition="270">database system) may have different input language, we need a way to translate natural language to different formal languages as needed by the application. We have developed a user friendly platform, NL2KR, that takes examples of sentences and their translations (in a desired target language that varies with the application), and some bootstrap information (an initial lexicon), and constructs a translation system from text to that desired target language. 1http://nl2kr.engineering.asu.edu/ Our approach to translate natural language text to formal representation is inspired by Montague’s work (Montague, 1974) where the meanings of words and phrases are expressed as A-calculus expressions and the meaning of a sentence is built from semantics of constituent words through appropriate A-calculus (Church, 1936) applications. A major challenge in using this approach has been the difficulty of coming up with the A-calculus representation of words. Montague’s approach has been widely used in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) to translate natural language to formal languages. In ZC05 (Zettlemoyer and Collins, 2005) the learning algorithm requires the user to provide the semantic tem</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Richard Montague. 1974. English as a Formal Language. In Richmond H. Thomason, editor, Formal Philosophy: Selected Papers of Richard Montague, pages 188–222. Yale University Press, New Haven, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Parsing with Compositional Vector Grammars.</title>
<date>2013</date>
<booktitle>In ACL (1),</booktitle>
<pages>455--465</pages>
<contexts>
<context position="12539" citStr="Socher et al., 2013" startWordPosition="2031" endWordPosition="2034">and determining on the fly, the one that is most suitable. We discuss more on this in sections 2.4-2.6. Existing CCG parsers (Curran et al., 2007; Lierler and Sch¨uller, 2012) either return a single best parse tree for a given sentence or parse it in all possible ways with no preferential ordering among them. In order to overcome this shortcoming and generate more than one weighted candidate parse trees, we have developed a new parser using beam search with Cocke-Younger-Kasami(CYK) algorithm. NL2KRs CCG parser uses the C&amp;C model (Curran et al., 2007) and constraints from the Stanford parser (Socher et al., 2013; Toutanova et al., 2003) to guide the derivation of a sentence. The output of the CCG parser is a set of k weighted parse trees, where the parameter k is provided by the user. NL2KR system allows one to use the CCG parser independently through the interactive GUI. The output graphs look like the one in Figure 3. It can be zoomed in/out and its nodes can be moved around, making it easier to work with complex sentences. 2.4 Multistage learning approach Learning meanings of words is the major component of our system. The inputs to the learning module are a list of training sentences, their targe</context>
</contexts>
<marker>Socher, Bauer, Manning, Ng, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D. Manning, and Andrew Y. Ng. 2013. Parsing with Compositional Vector Grammars. In ACL (1), pages 455– 465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The syntactic process, volume 35.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4968" citStr="Steedman, 2000" startWordPosition="768" endWordPosition="769">s in a sentence, limited forms of functional application) on the meaning representation language which severely limits its applicability to new applications. Another common drawback of these two algorithms is that they both suffer when the test sentence contains words that are not part of the training corpus. Our platform NL2KR uses a different automated approach based on Inverse-A (section 2.1) and Generalization (section 2.2) which does not impose such restrictions enforced by their higherorder unification algorithm. Also, Generalization algorithm along with Combinatory Categorical Grammar (Steedman, 2000) parser, allows NL2KR to go beyond the training dictionary and translate sentences which contain previously unseen words. The main aspect of our approach is as follows: given a sentence, its semantic representation and an initial dictionary containing the meaning of some words, NL2KR first obtains several derivation of the input sentence in Combinatory Categorical Grammar (CCG). Each CCG derivation tree describes the rules of functional application through which constituents combine with each other. With the user provided initial dictionary, NL2KR then traverses the tree in a bottomup fashion </context>
<context position="11406" citStr="Steedman, 2000" startWordPosition="1843" endWordPosition="1844">e, “John” and “home” have the category [N] (means noun) and can change to [NP] (means noun phrase). The phrase“walk home” has the category [S\NP], which means that it can combine with a constituent with category [NP] (“John” in this case) from left with the backward application to form category [S] (sentence). The word “walk” has the category [(S\NP)/NP], which means it can combine with a constituent with category [NP] (“home”) from right through the forward application combinator to form category [S\NP] (of “walk home”). A detailed description on CCG goes beyond the scope of this paper (see (Steedman, 2000) for more details). Since, natural language sentences can have various CCG parse trees, each expressing a different meaning of the sentence, a key challenge 901 Figure 2: NL2KR’s main GUI, Version 1.7.0001 Figure 3: CCG parse tree of ”John walked home”. in the learning and the translation process is to find a suitable CCG parse tree for a sentence in natural language. We overcome this impediment by allowing our learning and translation subsystem to work with multiple weighted parse trees for a given sentence and determining on the fly, the one that is most suitable. We discuss more on this in </context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The syntactic process, volume 35. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lappoon R Tang</author>
<author>Raymond J Mooney</author>
</authors>
<title>Using multiple clause constructors in inductive logic programming for semantic parsing.</title>
<date>2001</date>
<booktitle>In Machine Learning: ECML</booktitle>
<pages>466--477</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6965" citStr="Tang and Mooney, 2001" startWordPosition="1099" endWordPosition="1102"> interface that helps users in creating their own translation system. The closest system to NL2KR is the UW Semantic Parsing Framework (UW SPF) (Artzi and Zettlemoyer, 2013) which incorporates the algorithms in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) . However, to use UW SPF for the development of a new system, the user needs to learn their coding guidelines and needs to write new code in their system. NL2KR does not require the users to write new code and guides the development process with its rich user interface. We have evaluated NL2KR on two standard datasets: GeoQuery (Tang and Mooney, 2001) and Jobs (Tang and Mooney, 2001). GeoQuery is a database of geographical questions and Jobs contains sentences with job related query. Experiments demonstrate that NL2KR can exhibit stateof-the-art performance with fairly small initial dictionary. The rest of the paper is organized as follows: we first present the algorithms and architecture of the NL2KR platform in section 2; we discuss about the experiments in section 3; and finally, we conclude in section 4. 2 Algorithms and Architecture The NL2KR architecture (Figure 1) has two subparts which depend on each other (1) NL2KRL for learning a</context>
<context position="22764" citStr="Tang and Mooney, 2001" startWordPosition="3734" endWordPosition="3737">rpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is shown below. Sentence: How long is the Colorado river? Meaning: answer(A,(len(B,A),const(B, riverid(colorado)), river(B))) Jobs The Jobs (Tang and Mooney, 2001) dataset contains a total of 640 job related quer</context>
</contexts>
<marker>Tang, Mooney, 2001</marker>
<rawString>Lappoon R Tang and Raymond J Mooney. 2001. Using multiple clause constructors in inductive logic programming for semantic parsing. In Machine Learning: ECML 2001, pages 466–477. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -</booktitle>
<volume>1</volume>
<contexts>
<context position="12564" citStr="Toutanova et al., 2003" startWordPosition="2035" endWordPosition="2038">e fly, the one that is most suitable. We discuss more on this in sections 2.4-2.6. Existing CCG parsers (Curran et al., 2007; Lierler and Sch¨uller, 2012) either return a single best parse tree for a given sentence or parse it in all possible ways with no preferential ordering among them. In order to overcome this shortcoming and generate more than one weighted candidate parse trees, we have developed a new parser using beam search with Cocke-Younger-Kasami(CYK) algorithm. NL2KRs CCG parser uses the C&amp;C model (Curran et al., 2007) and constraints from the Stanford parser (Socher et al., 2013; Toutanova et al., 2003) to guide the derivation of a sentence. The output of the CCG parser is a set of k weighted parse trees, where the parameter k is provided by the user. NL2KR system allows one to use the CCG parser independently through the interactive GUI. The output graphs look like the one in Figure 3. It can be zoomed in/out and its nodes can be moved around, making it easier to work with complex sentences. 2.4 Multistage learning approach Learning meanings of words is the major component of our system. The inputs to the learning module are a list of training sentences, their target formal representations </context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Annual MeetingAssociation for computational Linguistics,</booktitle>
<volume>45</volume>
<pages>960</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="22622" citStr="Wong and Mooney, 2007" startWordPosition="3714" endWordPosition="3717">s, the output generated by the learned system has been considered correct if it is an exact replica of the logical formula described in the corpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is shown below. Sentence: How long is the Colorado river? Meaning: ans</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Yuk Wah Wong and Raymond J Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Annual MeetingAssociation for computational Linguistics, volume 45, page 960. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars. In</title>
<date>2005</date>
<booktitle>UAI,</booktitle>
<pages>658--666</pages>
<publisher>AUAI Press.</publisher>
<contexts>
<context position="2223" citStr="Zettlemoyer and Collins, 2005" startWordPosition="331" endWordPosition="334">ranslation system from text to that desired target language. 1http://nl2kr.engineering.asu.edu/ Our approach to translate natural language text to formal representation is inspired by Montague’s work (Montague, 1974) where the meanings of words and phrases are expressed as A-calculus expressions and the meaning of a sentence is built from semantics of constituent words through appropriate A-calculus (Church, 1936) applications. A major challenge in using this approach has been the difficulty of coming up with the A-calculus representation of words. Montague’s approach has been widely used in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) to translate natural language to formal languages. In ZC05 (Zettlemoyer and Collins, 2005) the learning algorithm requires the user to provide the semantic templates for all words. A semantic template is a A-expression (e.g. Ax.p(x) for an arity one predicate), which describes a particular pattern of representation in that formal language. With all these possible templates, the learning algorithm extracts the semantic representation of the words from the formal representation of a sentence. It then associates the extracted meanings to the words of the sentence in al</context>
<context position="6584" citStr="Zettlemoyer and Collins, 2005" startWordPosition="1031" endWordPosition="1034"> restarts the learning process with the updated knowledge. The learning process stops if it learns the meanings of all words or fails to learn any new meaning in an iteration. In the latter case, it shows the augmented tree to the user. The user can then provide meanings of some unknown words and resumes the learning process. Another distinguishing feature of NL2KR is its user-friendly interface that helps users in creating their own translation system. The closest system to NL2KR is the UW Semantic Parsing Framework (UW SPF) (Artzi and Zettlemoyer, 2013) which incorporates the algorithms in (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) . However, to use UW SPF for the development of a new system, the user needs to learn their coding guidelines and needs to write new code in their system. NL2KR does not require the users to write new code and guides the development process with its rich user interface. We have evaluated NL2KR on two standard datasets: GeoQuery (Tang and Mooney, 2001) and Jobs (Tang and Mooney, 2001). GeoQuery is a database of geographical questions and Jobs contains sentences with job related query. Experiments demonstrate that NL2KR can exhibit stateof-the-art performance with fai</context>
<context position="22701" citStr="Zettlemoyer and Collins, 2005" startWordPosition="3725" endWordPosition="3728">ct if it is an exact replica of the logical formula described in the corpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is shown below. Sentence: How long is the Colorado river? Meaning: answer(A,(len(B,A),const(B, riverid(colorado)), river(B))) Jobs The Jobs (Tang and</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2005. Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars. In UAI, pages 658–666. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form. In</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-2007).</booktitle>
<contexts>
<context position="22660" citStr="Zettlemoyer and Collins, 2007" startWordPosition="3719" endWordPosition="3722"> learned system has been considered correct if it is an exact replica of the logical formula described in the corpus. We report the performance in terms of precision (percentage of returned logical-forms that are correct), recall (percentage of sentences for which the correct logical-form was returned), F1-measure (harmonic mean of precision and recall) and the size of the initial dictionary. We compare the performance of our system with recently published, directly-comparable works, namely, FUBL (Kwiatkowski et al., 2011), UBL (Kwiatkowski et al., 2010), A-WASP (Wong and Mooney, 2007), ZC07 (Zettlemoyer and Collins, 2007) and ZC05 (Zettlemoyer and Collins, 2005) systems. 3.1 Corpora GeoQuery GeoQuery (Tang and Mooney, 2001) is a corpus containing questions on geographical facts about the United States. It contains a total of 880 sentences written in natural language, paired with their meanings in a formal query language, which can be executed against a database of the geographical information of the United States. We follow the standard training/testing split of 600/280. An example sentence meaning pair is shown below. Sentence: How long is the Colorado river? Meaning: answer(A,(len(B,A),const(B, riverid(color</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Luke S Zettlemoyer and Michael Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-2007).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>