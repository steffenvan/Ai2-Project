<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.955011">
Optimal Dialog in Consumer-Rating Systems using a POMDP Framework
</title>
<author confidence="0.997981">
Zhifei Li
</author>
<affiliation confidence="0.9454205">
Center for Language and Speech Processing
Johns Hopkins University
</affiliation>
<address confidence="0.675951">
Baltimore, MD 21218, USA
</address>
<email confidence="0.99242">
zhifei.work@gmail.com
</email>
<author confidence="0.997064">
Patrick Nguyen, Geoffrey Zweig
</author>
<affiliation confidence="0.87279">
Microsoft Corporation
1 Microsoft Way,
</affiliation>
<address confidence="0.946084">
Redmond, WA 98052, USA
</address>
<email confidence="0.998016">
1panguyen,gzweigl@microsoft.com
</email>
<sectionHeader confidence="0.997367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999621176470589">
Voice-Rate is an experimental dialog system
through which a user can call to get prod-
uct information. In this paper, we describe
an optimal dialog management algorithm for
Voice-Rate. Our algorithm uses a POMDP
framework, which is probabilistic and cap-
tures uncertainty in speech recognition and
user knowledge. We propose a novel method
to learn a user knowledge model from a review
database. Simulation results show that the
POMDP system performs significantly better
than a deterministic baseline system in terms
of both dialog failure rate and dialog interac-
tion time. To the best of our knowledge, our
work is the first to show that a POMDP can
be successfully used for disambiguation in a
complex voice search domain like Voice-Rate.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983433962265">
In recent years, web-based shopping and rating sys-
tems have provided a valuable service to consumers
by allowing them to shop products and share their
assessments of products online. The use of these
systems, however, requires access to a web interface,
typically through a laptop or desktop computer, and
this restricts their usefulness. While mobile phones
also provide some web access, their small screens
make them inconvenient to use. Therefore, there
arises great interests in having a spoken dialog in-
terface through which a user can call to get product
information (e.g., price, rating, review, etc.) on the
fly. Voice-Rate (Zweig et al., 2007) is such a sys-
tem. Here is a typical scenario under which shows
the usefulness of the Voice-Rate system. A user en-
ters a store and finds that a digital camera he has
not planned to buy is on sale. Before he decides
to buy the camera, he takes out his cell phone and
calls Voice-Rate to see whether the price is really
a bargain and what other people have said about
the camera. This helps him to make a wise deci-
sion. The Voice-Rate system (Zweig et al., 2007) in-
volves many techniques, e.g., information retrieval,
review summarization, speech recognition, speech
synthesis, dialog management, etc. In this paper, we
mainly focus on the dialog management component.
When a user calls Voice-Rate for the information
of a specific product, the system needs to identify,
from a database containing millions of products, the
exact product the user intends. To achieve this, the
system first solicits the user for the product name.
Using the product name as a query, the system then
retrieves from its database a list of products related
to the query. Ideally, the highest-ranked product
should be the one intended by the user. In reality,
this is often not the case due to various reasons. For
example, there might be a speech recognition error
or an information retrieval ranking error. Moreover,
the product name is usually very ambiguous in iden-
tifying an exact product. The product name that the
user says may not be exactly the same as the name
in the product database. For example, while the user
says “Canon Powershot SD750”, the exact name
in the product database may be “Canon Powershot
SD750 Digital Camera”. Even the user says the ex-
act name, it is possible that the same name may be
corresponding to different products in different cat-
egories, for instance books and movies.
Due to the above reasons, whenever the Voice-
Rate system finds multiple products matching the
user’s initial speech query, it initiates a dialog proce-
dure to identify the intended product by asking ques-
tions about the products. In the product database,
</bodyText>
<page confidence="0.984191">
104
</page>
<note confidence="0.869029">
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 104–111,
Columbus, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999904977272728">
many attributes can be used to identify a product.
For example, a digital camera has the product name,
category, brand, resolution, zoom, etc. Given a list
of products, different attributes may have different
ability to distinguish the products. For example, if
the products belong to many categories, the category
attribute is very useful to distinguish the products. In
contrast, if all the products belong to a single cate-
gory, it makes no sense to ask a question on the cat-
egory. In addition to the variability in distinguishing
products, different attributes may require different
knowledge from the user in order for them to an-
swer questions about these attributes. For example,
while most users can easily answer a question on
category, they may not be able to answer a question
on the part number of a product, though the part
number is unique and perfect to distinguish prod-
ucts. Other variabilities are in the difficulty that the
attributes impose on speech recognition and speech
synthesis. Clearly, given a list of products and a set
of attributes, what questions and in what order to ask
is essential to make the dialog successful. Our goal
is to dynamically find such important attributes at
each stage/turn.
The baseline system (Zweig et al., 2007) asks
questions only on product name and category. The
order of questions is fixed: first ask questions on
product category, and then on name. Moreover, it
is deterministic and does not model uncertainly in
speech recognition and user knowledge. Partially
observable Markov decision process (POMDP) has
been shown to be a general framework to capture the
uncertainty in spoken dialog systems. In this paper,
we present a POMDP-based probabilistic system,
which utilizes rich product information and captures
uncertainty in speech recognition and user knowl-
edge. We propose a novel method to learn a user
knowledge model from a review database. Our sim-
ulation results show that the POMDP-based system
improves the baseline significantly.
To the best of our knowledge, our work is the first
to show that a POMDP can be successfully used for
disambiguation in a complex voice search domain
like Voice-Rate.
</bodyText>
<sectionHeader confidence="0.964971" genericHeader="method">
2 Voice-Rate Dialog System Overview
</sectionHeader>
<bodyText confidence="0.521258333333333">
Figure 1 shows the main flow in the Voice-Rate sys-
tem with simplification. Specifically, when a user
calls Voice-Rate for the information of a specific
</bodyText>
<figure confidence="0.991127333333333">
Begin
Initial Speech Query
InformationRetrieval
</figure>
<figureCaption confidence="0.999875">
Figure 1: Flow Chart of Voice-Rate System
</figureCaption>
<bodyText confidence="0.968399833333333">
Step-1: remove products that do not match
the user action
Step-2: any category question to ask?
yes: ask the question and return
no: go to step-3
Step-3: ask a product name question
</bodyText>
<tableCaption confidence="0.991188">
Table 1: Baseline Dialog Manager Algorithm
</tableCaption>
<bodyText confidence="0.999779421052632">
product, the system first solicits the user for the
product name. Treating the user input as a query
and the product names in the product database as
documents, the system retrieves a list of products
that match the user input based on TF-IDF mea-
sure. Then, the dialog manager dynamically gener-
ates questions to identify the specific intended prod-
uct. Once the product is found, the system plays
back its rating information. In this paper, we mainly
focus on the dialog manager component.
Baseline Dialog Manager: Table 1 shows the
baseline dialog manager. In Step-1, it removes all
the products that are not consistent with the user re-
sponse. For example, if the user answers “camera”
when given a question on category, the system re-
moves all the products that do not belong to category
“camera”. In Step-2 and Step-3, the baseline system
asks questions about product name and product cat-
egory, and product category has a higher priority.
</bodyText>
<sectionHeader confidence="0.914915" genericHeader="method">
3 Overview of POMDP
</sectionHeader>
<subsectionHeader confidence="0.997165">
3.1 Basic Definitions
</subsectionHeader>
<bodyText confidence="0.968341">
A Partially Observable Markov Decision Process
(POMDP) is a general framework to handle uncer-
tainty in a spoken dialog system. Following nota-
</bodyText>
<figure confidence="0.997832571428572">
List of
Products
Corrupted User Action
Dialog Manager
Human
Question
product? No
Found
Yes
Play Rating
End
• Intended product
Speech recognizer
User Action
</figure>
<page confidence="0.993134">
105
</page>
<bodyText confidence="0.9665088">
tions in Williams and Young (2007), a POMDP is
defined as a tuple IS, A, T, R, O, Z, A,b0} where S
is a set of states s describing the environment; A is
a set of machine actions a operating on the environ-
ment; T defines a transition probability P(s&apos;Is, a);
R defines a reward function r(s, a); O is a set of ob-
servations o, and an observation can be thought as
a corrupted version of a user action; Z defines an
observation probability P(o&apos;Is&apos;, a); A is a geometric
�
discount factor; and bo is an initial belief vector.
The POMDP operates as follows. At each time-
step (a.k.a. stage), the environment is in some unob-
served state s. Since s is not known exactly, a distri-
bution (called a belief vector b) over possible states
is maintained where b(s) indicates the probability of
being in a particular state s. Based on the current be-
lief vector b, an optimal action selection algorithm
selects a machine action a, receives a reward r, and
the environment transits to a new unobserved state
s &apos; . The environment then generates an observation
o&apos; (i.e., a user action), after which the system update
�
the belief vector b. We call the process of adjusting
the belief vector b at each stage “belief update”.
</bodyText>
<subsectionHeader confidence="0.999747">
3.2 Applying POMDP in Practice
</subsectionHeader>
<bodyText confidence="0.999924">
As mentioned in Williams and Young (2007), it is
not trivial to apply the POMDP framework to a
specific application. To achieve this, one normally
needs to design the following three components:
</bodyText>
<listItem confidence="0.999987">
• State Diagram Modeling
• Belief Update
• Optimal Action Selection
</listItem>
<bodyText confidence="0.999970133333333">
The state diagram defines the topology of the
graph, which contains three kinds of elements: sys-
tem state, machine action, and user action. To drive
the transitions, one also needs to define a set of
models (e.g., user goal model, user action model,
etc.). The modeling assumptions are application-
dependent. The state diagram, together with the
models, determines the dynamics of the system.
In general, the belief update depends on the ob-
servation probability and the transition probability,
while the transition probability itself depends on the
modeling assumptions the system makes. Thus, the
exact belief update formula is application-specific.
Optimal action selection is essentially an opti-
mization algorithm, which can be defined as,
</bodyText>
<equation confidence="0.9994495">
a* = arg max
aEA G(P(a)), (1)
</equation>
<bodyText confidence="0.9994467">
where A refers to a set of machine actions a.
Clearly, the optimal action selection requires three
sub-components: a goodness measure function G, a
prediction algorithm P, and a search algorithm (i.e.,
the argmax operator). The prediction algorithm is
used to predict the behavior of the system in the
future if a given machine action a was taken. The
search algorithm can use an exhaustive linear search
or an approximated greedy search depending on the
size of A (Murphy, 2000; Spaan and Vlassis, 2005).
</bodyText>
<sectionHeader confidence="0.99711" genericHeader="method">
4 POMDP Framework in Voice-Rate
</sectionHeader>
<bodyText confidence="0.9989225">
In this section, we present our instantiation of
POMDP in the Voice-Rate system.
</bodyText>
<subsectionHeader confidence="0.9638365">
4.1 State Diagram Modeling
4.1.1 State Diagram Design
</subsectionHeader>
<bodyText confidence="0.9999936">
Table 2 summarizes the main design choices in
the state diagram for our application, i.e., identifying
the intended product from a large list of products.
As in Williams and Young (2007), we incorporate
both the user goal (i.e., the intended product) and
the user action in the system state. Moreover, to ef-
ficiently update belief vector and compute optimal
action, the state space is dynamically generated and
pruned. In particular, instead of listing all the possi-
ble combinations between the products and the user
actions, at each stage, we only generate states con-
taining the products and the user actions that are rel-
evant to the last machine action. Moreover, at each
stage, if the belief probability of a product is smaller
than a threshold, we prune out this product and all
its associated system states. Note that the intended
product may be pruned away due to an overly large
threshold. In the simulation, we will use a develop-
ment set to tune this threshold.
As shown in Table 2, five kinds of machine ac-
tions are defined. The questions on product names
are usually long, imposing difficulty in speech syn-
thesis/recgonition and user input. Thus, short ques-
tions (e.g., questions on category or simple at-
tributes) are preferable. This partly motivate us to
exploit rich product information to help the dialog.
Seven kinds of user actions are defined as shown
in Table 2. Among them, the user actions “others”,
“not related”, and “not known” are special. Specif-
ically, to limit the question length and to ensure the
</bodyText>
<page confidence="0.989877">
106
</page>
<table confidence="0.933209944444444">
Component Design Comments
System State (Product, User action) e.g., (HP Computer, Category: computer)
Machine Action Question on Category e.g., choose category: Electronics, Movie, Book
Question on Product name e.g., choose product name: Canon SD750 digital cam-
era, Canon Powershot A40 digital camera, Canon
SD950 digital camera, Others
Question on Attribute e.g., choose memory size: 64M, 128M, 256M
Confirmation question e.g., you want Canon SD750 camera, yes or no?
Play Rating e.g., I think you want Canon SD750 digital camera,
here is the rating!
User Action Category e.g., Movie
Product name e.g., Canon SD750 digital camera
Attribute value e.g., memory size: 64M
Others used when a question has too many possible options
Yes/No used for a confirmation question
Not related used if the intended product is unrelated to the question
Not known used if the user does not have required knowledge to
answer the question
</table>
<tableCaption confidence="0.999107">
Table 2: State Diagram Design in Voice-Rate
</tableCaption>
<bodyText confidence="0.999972653846154">
human is able to memorize all the options, we re-
strict the number of options in a single question to a
threshold N (e.g., 5). Clearly, given a list of prod-
ucts and a question, there might be more than N pos-
sible options. In such a case, we need to merge some
options into the “others” class. The third example in
Table 2 shows an example with the “others” option.
One may exploit a clustering algorithm (e.g., an it-
erative greedy search algorithm) to find an optimal
merge. In our system, we simply take the top-(N-1)
options (ranked by the belief probabilities) and treat
all the remaining options as “others”.
The “not related” option is required when some
candidate products are irrelevant to the question. For
example, when the system asks a question regarding
the attribute “cpu speed” while the products contain
both books and computers, the “not related” option
is required in case the intended product is a book.
Lastly, while some attributes are very useful to
distinguish the products, a user may not have enough
knowledge to answer a question on these attributes.
For example, while there is a unique part number for
each product, however, the user may not know the
exact part number for the intended product. Thus,
“not known” option is required whenever the system
expects the user is unable to answer the question.
</bodyText>
<subsectionHeader confidence="0.682737">
4.1.2 Models
</subsectionHeader>
<bodyText confidence="0.9998728125">
We assume that the user does not change his goal
(i.e., the intended product) along the dialog. We
also assume that the user rationally answers the
question to achieve his goal. Additionally, we as-
sume that the speech synthesis is good enough such
that the user always gets the right information that
the system intends to convey. The two main mod-
els that we consider include an observation model
that captures speech recognition uncertainty, and a
user knowledge model that captures the variability
of user knowledge required for answering questions
on different attributes.
Observation Model: Since the speech recogni-
tion engine we are using returns only a one-best and
its confidence value C E [0, 1]. We define the obser-
vation function as follows,
</bodyText>
<equation confidence="0.9862998">
� ��a��a�� =
C
1−C
if a,, = a,otherwise. (2)
�Au�−1
</equation>
<bodyText confidence="0.9158895">
where a,, is the true user action, a,, is the speech
recognition output (i.e., corrupted user action), and
A,, is the set of user actions related to the last ma-
chine action.
User Knowledge Model: In most of the appli-
cations (Roy et al., 2000; Williams, 2007) where
</bodyText>
<page confidence="0.995533">
107
</page>
<bodyText confidence="0.999944285714286">
the POMDP framework got applied, it is normally
assumed that the user needs only common sense to
answer the questions asked by the dialog system.
Our application is more complex as the product in-
formation is very rich. A user may have different
difficulty in answering different questions. For ex-
ample, while a user can easily answer a question on
category, he may not be able to answer a question
on the part number. Thus, we define a user knowl-
edge model to capture such uncertainty. Specifically,
given a question (say am) and an intended product
(say gu) in the user’s mind, we want to know how
likely the user has required knowledge to answer the
question. Formally, the user knowledge model is,
</bodyText>
<equation confidence="0.9200015">
P(au|gu, am) = { P(unk|gu, am) if au=unk,
0 otherwise.
1 − P(unk|gu, am) if au=truth,
(3)
</equation>
<bodyText confidence="0.999972947368421">
where unk represents the user action “not known”.
Clearly, given a specific product gu and a specific
question am, there is exactly one correct user ac-
tion (represented by truth in Equation 3), and its
probability is 1 − P(unk|gu, am). Now, to obtain
a user knowledge model, we only need to obtain
P(unk|gu, am). As shown in Table 2, there are four
kinds of question-type machine actions am. We as-
sume that the user always has knowledge to answer
a question regarding the category and product name,
and thus P(unk|gu, am) for these types of machine
actions are zero regardless of what the specific prod-
uct gu is. Therefore, we only need to consider
P(unk|gu, am) when am is a question about an at-
tribute (say attr). Moreover, since there are millions
of products, to deal with the data sparsity issue, we
assume P(unk|gu, am) does not depends on a spe-
cific product gu, instead it depends on only the cate-
gory (say cat) of the product gu. Therefore,
</bodyText>
<equation confidence="0.954066">
P(unk|gu, am) Pz� P(unk|cat,attr). (4)
</equation>
<bodyText confidence="0.999228">
Now, we only need to get the probability
P(unk|cat,attr) for each attribute attr in each cate-
gory cat. To learn P(unk|cat,attr), one may collect
data from human, which is very expensive. Instead,
we learn this model from a database of online re-
views for the products. Our method is based on the
following intuition: if a user cares/knows about an
attribute of a product, he will mention either the at-
tribute name, or the attribute value, or both in his
review of this product. With this intuition, the occur-
rence frequency of a given attr in a given category
cat is collected from the review database, followed
by proper weighting, scaling and normalization, and
thus P(unk|cat,attr) is obtained.
</bodyText>
<subsectionHeader confidence="0.99711">
4.2 Belief Update
</subsectionHeader>
<bodyText confidence="0.995634">
Based on the model assumptions in Section 4.1.2,
</bodyText>
<equation confidence="0.9363088">
0
the belief update formula for the state (gu, au) is,
b(gu, a�u) = (5)
�k x P(�a�u|a�u)P(a�u|gu, am) b(gu, au)
auEA(gu)
</equation>
<bodyText confidence="0.999975555555556">
where k is a normalization constant. The P(�a�u|a� u)
is the observation function as defined in Equation 2,
while P(a�u|gu, am) is the user knowledge model as
defined in Equation 3. The A(gu) represents the set
of user actions au related to the system states for
which the intended product is gu.
In our state representation, a single product gu
is associated with several states which differ in the
user action au, and the belief probability of gu is the
sum of the probabilities of these states. Therefore,
even there is a speech recognition error or an un-
intentional user mistake, the true product still gets
a non-zero belief probability (though the true/ideal
user action au gets a zero probability). Moreover,
the probability of the true product will get promoted
through later iterations. Therefore, our system has
error-handling capability, which is one of the major
advantages over the deterministic baseline system.
</bodyText>
<subsectionHeader confidence="0.999275">
4.3 Optimal Action Selection
</subsectionHeader>
<bodyText confidence="0.9999782">
As mentioned in Section 3.2, the optimal action se-
lection involves three sub-components: a prediction
algorithm, a goodness measure, and a search algo-
rithm. Ideally, in our application, we should mini-
mize the time required to successfully identify the
intended product. Clearly, this is too difficult as
it needs to predict the infinite future and needs to
encode the time into a reward function. Therefore,
for simplicity, we predict only one-step forward, and
use the entropy as a goodness measure1. Formally,
</bodyText>
<footnote confidence="0.718644333333333">
1Due to this approximation, one may argue that our model
is more like the greedy information theoretic model in Paek and
Chickering (2005), instead of a POMDP model. However, we
believe that our model follows the POMDP modeling frame-
work in general, though it does not involve reinforcement learn-
ing currently.
</footnote>
<page confidence="0.9966">
108
</page>
<bodyText confidence="0.887055">
the optimization function is as follows:
</bodyText>
<equation confidence="0.78484">
a* = arg min H(Products I a), (6)
aEA
</equation>
<bodyText confidence="0.9999733">
where H(Products I a) is the entropy over the belief
probabilities of the products if the machine action
a was taken. When predicting the belief vector us-
ing Equation 5, we consider only the user knowledge
model and ignore the observation function2.
In the above, we consider only the question-type
machine actions. We also need to decide when
to take the play rating action such that the dialog
will terminate. Specifically, we take the play rating
action whenever the belief probability of the most
probable product is greater than a threshold. More-
over, the threshold should depend on the number of
surviving products. For example, if there are fifty
surviving products and the most probable product
has a belief probability greater than 0.3, it is reason-
able to take the play rating action. This is not true
if there are only four surviving products. Also note
that if we set the thresholds to too small values, the
system may play the rating for a wrong product. We
will use a development set to tune these thresholds.
</bodyText>
<subsubsectionHeader confidence="0.493434">
4.3.1 Machine Action Filtering during Search
</subsubsectionHeader>
<bodyText confidence="0.999392666666667">
We use an exhaustive linear search for the opera-
tor argmin in Equation 6. However, additional filter-
ing during the search is required.
Repeated Question: Since the speech response
from the user to a question is probabilistic, it is quite
possible that the system will choose the same ques-
tion that has been asked in previous stages3. Since
our product information is very rich, many differ-
ent questions have the similar capability to reduce
entropy. Therefore, during the search, we simply ig-
nore all the questions asked in previous stages.
“Not Related” Option: While reducing entropy
helps to reduce the confusion at the machine side, it
does not measure the “weirdness” of a question to
the human. For example, when the intended product
is a book and the candidate products contain both
books and computers, it is quite possible that the
optimal action, based solely on entropy reduction,
</bodyText>
<footnote confidence="0.813974833333333">
2Note that we ignore the observation function only in the
prediction, not in real belief update.
3In a regular decision tree, the answer to a question is deter-
ministic. It never asks the same question as that does not lead to
any additional reduction of entropy. This problem is also due to
the fact we do not have an explicit reward function.
</footnote>
<bodyText confidence="0.999639035714286">
is a question on the attribute “cpu speed”. Clearly,
such a question is very weird to the human as he is
looking for a book that has nothing related to “cpu
speed”. Though the user may be able to choose the
“not related” option correctly after thinking for a
while, it degrades the dialog quality. Therefore, for
a given question, whenever the system predicts that
the user will have to choose the “not related” option
with a probability greater than a threshold, we sim-
ply ignore such questions in the search. Clearly, if
we set the threshold as zero, we essentially elimi-
nates the “not related” option. That is, at each stage,
we generate questions only on attributes that apply
to all the candidate products. Since we dynamically
remove products whose probability is smaller than
a threshold at each stage, the valid question set dy-
namically expands. Specifically, at the beginning,
only very general questions (e.g., questions on cate-
gory) are valid, then more refined questions become
valid (e.g., questions on product brand), and finally
very specific questions are valid (e.g, questions on
product model). This leads to very natural behav-
ior in identifying a product, i.e., coarse to fine4. It
also makes the system adapt to the user knowledge.
Specifically, as the user demonstrates deeper knowl-
edge of the products by answering the questions cor-
rectly, it makes sense to ask more refined questions
about the products.
</bodyText>
<sectionHeader confidence="0.936964" genericHeader="method">
5 Simulation Results
</sectionHeader>
<bodyText confidence="0.999924428571428">
To evaluate system performance, ideally one should
ask people to call the system, and manually collect
the performance data. This is very expensive. Al-
ternatively, we develop a simulation method, which
is automatic and thus allow fast evaluation of the
system during development5. In fact, many design
choices in Section 4 are inspired by the simulation.
</bodyText>
<subsectionHeader confidence="0.797231">
5.1 Simulation Model
</subsectionHeader>
<figureCaption confidence="0.984660333333333">
Figure 2 illustrates the general framework for the
simulation. The process is very similar to that in
Figure 1 except that the human user and the speech
</figureCaption>
<footnote confidence="0.978035">
4While the baseline dialog manager achieves the similar be-
havior by manually enforcing the order of questions, the sys-
tem here automatically discovers the order of questions and the
question set is much more richer than that in the baseline.
5However, we agree that simulation is not without its limi-
tations and the results may not precisely reflect real scenarios.
</footnote>
<page confidence="0.996076">
109
</page>
<figure confidence="0.824599">
InformationRetrieval
</figure>
<figureCaption confidence="0.998081">
Figure 2: Flow Chart in Simulation
</figureCaption>
<bodyText confidence="0.999973785714286">
recognizer are replaced with a simulated compo-
nent, and that the simulated user has access to a user
knowledge model. In particular, we generate the
user action and its corrupted version using random
number generators by following the models defined
in Equations 3 and 2, respectively. We use a fixed
value (e.g., 0.9) for C in Equation 2.
Clearly, our goal here is not to evaluate the good-
ness of the user knowledge model or the speech rec-
ognizer. Instead, we want to see how the probabilis-
tic dialog manger (i.e., POMDP) performs compared
with the deterministic baseline dialog manager, and
to see whether the richer attribute information helps
to reduce the dialog interaction time.
</bodyText>
<subsectionHeader confidence="0.995866">
5.2 Data Resources
</subsectionHeader>
<bodyText confidence="0.999886">
In the system, we use three data resources: a prod-
uct database, a review database, and a query-click
database. The product database contains detailed in-
formation for 0.2 million electronics and computer
related products. The review database is used for
learning the user knowledge model. The query-
click database contains 2289 pairs in the format (text
query, product clicked). One example pair is (Canon
Powershot A700, Canon Powershot A700 6.2MP
digital camera). We divide it into a development set
(1308 pairs) and a test set (981 pairs).
</bodyText>
<subsectionHeader confidence="0.937714">
5.3 Results on Information Retrieval
</subsectionHeader>
<bodyText confidence="0.997064615384615">
For each initial query, the information retrieval
(IR) engine returns a list of top-ranked products.
Whether the intended product is in the returned list
depends on the size of the list. If the intended prod-
uct is in the list, the IR successfully recalled the
product. Table 3 shows the correlation between the
recall rate and the size of the returned list. Clearly,
the larger the list size is, the larger the recall rate is.
One may notice that the IR recall rate is low. This
is because the query-click data set is very noisy, that
is, the clicked product may be nothing to do with
the query. For example, (msn shopping, Handspring
Treo 270) is one of the pairs in our data set.
</bodyText>
<table confidence="0.9973765">
List Size Recall Rate (%)
50 38.36
100 41.46
150 43.5
</table>
<tableCaption confidence="0.999773">
Table 3: Information Retrieval Recall Rates on Test set
</tableCaption>
<subsectionHeader confidence="0.976667">
5.4 Dialog System Configuration and Tuning
</subsectionHeader>
<bodyText confidence="0.999978">
As mentioned in Section 4, several parameters in the
system are configurable and tunable. Specifically,
we set the max number of options in a question as
5, and the threshold for “not related” option as zero.
We use the development set to tune the following pa-
rameters: the threshold of the belief probability be-
low which the product is pruned, and the thresholds
above which the most probable product is played.
The parameters are tuned in a way such that no dia-
log error is made on the development set.
</bodyText>
<subsectionHeader confidence="0.574069">
5.5 Results on Error Handling
</subsectionHeader>
<bodyText confidence="0.999986944444445">
Even the IR succeeds, the dialog system may not
find the intended product successfully. In particu-
lar, the baseline system does not have error handling
capability. Whenever the system makes a speech
recognition error or the user mistakenly answers a
question, the dialog system fails (either plays the rat-
ing for a wrong product or fails to find any product).
On the contrary, our POMDP framework has error
handling functionality due to its probabilistic na-
ture. Table 5 compares the dialog error rate between
the baseline and the POMDP systems. Clearly,
the POMDP system performs much better to han-
dle errors. Note that the POMDP system does not
eliminate dialog failures on the test set because the
thresholds are not perfect for the test set6. This is
due to two reasons: the system may prune the in-
tended product (reason-1), and the system may play
the rating for a wrong product (reason-2).
</bodyText>
<footnote confidence="0.6758685">
6Note that the POMDP system does not have dialog failures
on the development set as we tune the system in this way.
</footnote>
<figure confidence="0.9993681">
Initial Query
Begin
Products
Corrupted User Action
List of
Dialog Manager
• Baseline
• POMDP
Simulated
Speech Recognizer
User Action
Simulated User
Question
• Intended product
• User knowledge model
End
Found
product? No
Yes
Play Rating
</figure>
<page confidence="0.981094">
110
</page>
<table confidence="0.998974">
System Size Average Max
Stages Characters Words Stages Characters Words
50 2.44 524.0 82.3 11 2927 546
Baseline 100 3.37 765.4 120.4 25 7762 1369
150 3.90 906.4 143.0 30 9345 1668
50 1.57 342.8 54.3 4 2659 466
POMDP 100 2.36 487.9 76.6 18 3575 597
150 2.59 541.3 85.0 19 4898 767
</table>
<tableCaption confidence="0.996298">
Table 4: Interaction Time Results on Test Set
</tableCaption>
<table confidence="0.99983">
Size Baseline POMDP (%)
Total Reason-1 Reason-2
(%)
50 13.8 8.2 4.2 4.0
100 17.7 2.7 1.2 1.5
150 19.3 4.7 0.7 4.0
</table>
<tableCaption confidence="0.998259">
Table 5: Dialog Failure Rate on Test Set
</tableCaption>
<sectionHeader confidence="0.51016" genericHeader="evaluation">
5.6 Results on Interaction Time
</sectionHeader>
<bodyText confidence="0.999984117647059">
It is quite difficult to measure the exact interaction
time, so instead we measure it through the number of
stages/characters/words required during the dialog
process. Clearly, the number of characters is the one
that matches most closely to the true time. Table 4
reports the average and maximum numbers. In gen-
eral, the POMDP system performs much better than
the baseline system. One may notice the difference
in the number of stages between the baseline and
the POMDP systems is not as significant as in the
number of characters. This is because the POMDP
system is able to exploit very short questions while
the baseline system mainly uses the product name
question, which is normally very long. The long
question on product name also imposes difficulty in
speech synthesis, user input, and speech recognition,
though this is not reflected in the simulation.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999982277777778">
In this paper, we have applied the POMDP frame-
work into Voice-Rate, a system through which a
user can call to get product information (e.g., price,
rating, review, etc.). We have proposed a novel
method to learn a user knowledge model from a re-
view database. Compared with a deterministic base-
line system (Zweig et al., 2007), the POMDP system
is probabilistic and is able to handle speech recogni-
tion errors and user mistakes, in which case the de-
terministic baseline system is doomed to fail. More-
over, the POMDP system exploits richer product in-
formation to reduce the interaction time required to
complete a dialog. We have developed a simulation
model, and shown that the POMDP system improves
the baseline system significantly in terms of both di-
alog failure rate and dialog interaction time. We also
implement our POMDP system into a speech demo
and plan to carry out tests through humans.
</bodyText>
<sectionHeader confidence="0.980513" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9930442">
This work was conducted during the first author’s
internship at Microsoft Research; thanks to Dan Bo-
hus, Ghinwa Choueiter, Yun-Cheng Ju, Xiao Li,
Milind Mahajan, Tim Paek, Yeyi Wang, and Dong
Yu for helpful discussions.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999716">
K. Murphy. 2000. A survey of POMDP solution tech-
niques. Technical Report, U. C. Berkeley.
T. Paek and D. Chickering. 2005. The Markov assump-
tion in spoken dialogue management. In Proc of SIG-
dial 2005.
N. Roy, J. Pineau, and S. Thrun. 2000. Spoken dialog
management for robots. In Proc of ACL 2000.
M. Spaan and N. Vlassis. 2005. Perseus: randomized
point-based value iteration for POMDPs. Journal of
Artificial Intelligence Research, 24:195-220.
J. Williams. 2007. Applying POMDPs to Dialog
Systems in the Troubleshooting Domain. In Proc
HLT/NAACL Workshop on Bridging the Gap: Aca-
demic and Industrial Research in Dialog Technology.
J. Williams and S. Young. 2007. Partially Observable
Markov Decision Processes for Spoken Dialog Sys-
tems. Computer Speech and Language 21(2): 231-
422.
G. Zweig, P. Nguyen, Y.C. Ju, Y.Y. Wang, D. Yu, and
A. Acero. 2007. The Voice-Rate Dialog System for
Consumer Ratings. In Proc of Interspeech 2007.
</reference>
<page confidence="0.998793">
111
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.396509">
<title confidence="0.999658">Optimal Dialog in Consumer-Rating Systems using a POMDP Framework</title>
<author confidence="0.965706">Zhifei</author>
<affiliation confidence="0.8078225">Center for Language and Speech Johns Hopkins</affiliation>
<address confidence="0.995915">Baltimore, MD 21218,</address>
<email confidence="0.999724">zhifei.work@gmail.com</email>
<author confidence="0.998882">Patrick Nguyen</author>
<author confidence="0.998882">Geoffrey</author>
<affiliation confidence="0.8263895">Microsoft 1 Microsoft</affiliation>
<address confidence="0.996113">Redmond, WA 98052,</address>
<abstract confidence="0.9986765">Voice-Rate is an experimental dialog system through which a user can call to get product information. In this paper, we describe an optimal dialog management algorithm for Voice-Rate. Our algorithm uses a POMDP framework, which is probabilistic and captures uncertainty in speech recognition and user knowledge. We propose a novel method to learn a user knowledge model from a review database. Simulation results show that the POMDP system performs significantly better than a deterministic baseline system in terms of both dialog failure rate and dialog interaction time. To the best of our knowledge, our work is the first to show that a POMDP can be successfully used for disambiguation in a complex voice search domain like Voice-Rate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Murphy</author>
</authors>
<title>A survey of POMDP solution techniques.</title>
<date>2000</date>
<tech>Technical Report,</tech>
<contexts>
<context position="10625" citStr="Murphy, 2000" startWordPosition="1750" endWordPosition="1751">n-specific. Optimal action selection is essentially an optimization algorithm, which can be defined as, a* = arg max aEA G(P(a)), (1) where A refers to a set of machine actions a. Clearly, the optimal action selection requires three sub-components: a goodness measure function G, a prediction algorithm P, and a search algorithm (i.e., the argmax operator). The prediction algorithm is used to predict the behavior of the system in the future if a given machine action a was taken. The search algorithm can use an exhaustive linear search or an approximated greedy search depending on the size of A (Murphy, 2000; Spaan and Vlassis, 2005). 4 POMDP Framework in Voice-Rate In this section, we present our instantiation of POMDP in the Voice-Rate system. 4.1 State Diagram Modeling 4.1.1 State Diagram Design Table 2 summarizes the main design choices in the state diagram for our application, i.e., identifying the intended product from a large list of products. As in Williams and Young (2007), we incorporate both the user goal (i.e., the intended product) and the user action in the system state. Moreover, to efficiently update belief vector and compute optimal action, the state space is dynamically generate</context>
</contexts>
<marker>Murphy, 2000</marker>
<rawString>K. Murphy. 2000. A survey of POMDP solution techniques. Technical Report, U. C. Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Paek</author>
<author>D Chickering</author>
</authors>
<title>The Markov assumption in spoken dialogue management.</title>
<date>2005</date>
<booktitle>In Proc of SIGdial</booktitle>
<contexts>
<context position="19998" citStr="Paek and Chickering (2005)" startWordPosition="3329" endWordPosition="3332">3.2, the optimal action selection involves three sub-components: a prediction algorithm, a goodness measure, and a search algorithm. Ideally, in our application, we should minimize the time required to successfully identify the intended product. Clearly, this is too difficult as it needs to predict the infinite future and needs to encode the time into a reward function. Therefore, for simplicity, we predict only one-step forward, and use the entropy as a goodness measure1. Formally, 1Due to this approximation, one may argue that our model is more like the greedy information theoretic model in Paek and Chickering (2005), instead of a POMDP model. However, we believe that our model follows the POMDP modeling framework in general, though it does not involve reinforcement learning currently. 108 the optimization function is as follows: a* = arg min H(Products I a), (6) aEA where H(Products I a) is the entropy over the belief probabilities of the products if the machine action a was taken. When predicting the belief vector using Equation 5, we consider only the user knowledge model and ignore the observation function2. In the above, we consider only the question-type machine actions. We also need to decide when </context>
</contexts>
<marker>Paek, Chickering, 2005</marker>
<rawString>T. Paek and D. Chickering. 2005. The Markov assumption in spoken dialogue management. In Proc of SIGdial 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>J Pineau</author>
<author>S Thrun</author>
</authors>
<title>Spoken dialog management for robots.</title>
<date>2000</date>
<booktitle>In Proc of ACL</booktitle>
<contexts>
<context position="15701" citStr="Roy et al., 2000" startWordPosition="2600" endWordPosition="2603"> uncertainty, and a user knowledge model that captures the variability of user knowledge required for answering questions on different attributes. Observation Model: Since the speech recognition engine we are using returns only a one-best and its confidence value C E [0, 1]. We define the observation function as follows, � ��a��a�� = C 1−C if a,, = a,otherwise. (2) �Au�−1 where a,, is the true user action, a,, is the speech recognition output (i.e., corrupted user action), and A,, is the set of user actions related to the last machine action. User Knowledge Model: In most of the applications (Roy et al., 2000; Williams, 2007) where 107 the POMDP framework got applied, it is normally assumed that the user needs only common sense to answer the questions asked by the dialog system. Our application is more complex as the product information is very rich. A user may have different difficulty in answering different questions. For example, while a user can easily answer a question on category, he may not be able to answer a question on the part number. Thus, we define a user knowledge model to capture such uncertainty. Specifically, given a question (say am) and an intended product (say gu) in the user’s</context>
</contexts>
<marker>Roy, Pineau, Thrun, 2000</marker>
<rawString>N. Roy, J. Pineau, and S. Thrun. 2000. Spoken dialog management for robots. In Proc of ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Spaan</author>
<author>N Vlassis</author>
</authors>
<title>Perseus: randomized point-based value iteration for POMDPs.</title>
<date>2005</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>24--195</pages>
<contexts>
<context position="10651" citStr="Spaan and Vlassis, 2005" startWordPosition="1752" endWordPosition="1755">timal action selection is essentially an optimization algorithm, which can be defined as, a* = arg max aEA G(P(a)), (1) where A refers to a set of machine actions a. Clearly, the optimal action selection requires three sub-components: a goodness measure function G, a prediction algorithm P, and a search algorithm (i.e., the argmax operator). The prediction algorithm is used to predict the behavior of the system in the future if a given machine action a was taken. The search algorithm can use an exhaustive linear search or an approximated greedy search depending on the size of A (Murphy, 2000; Spaan and Vlassis, 2005). 4 POMDP Framework in Voice-Rate In this section, we present our instantiation of POMDP in the Voice-Rate system. 4.1 State Diagram Modeling 4.1.1 State Diagram Design Table 2 summarizes the main design choices in the state diagram for our application, i.e., identifying the intended product from a large list of products. As in Williams and Young (2007), we incorporate both the user goal (i.e., the intended product) and the user action in the system state. Moreover, to efficiently update belief vector and compute optimal action, the state space is dynamically generated and pruned. In particula</context>
</contexts>
<marker>Spaan, Vlassis, 2005</marker>
<rawString>M. Spaan and N. Vlassis. 2005. Perseus: randomized point-based value iteration for POMDPs. Journal of Artificial Intelligence Research, 24:195-220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Williams</author>
</authors>
<title>Applying POMDPs to Dialog Systems in the Troubleshooting Domain.</title>
<date>2007</date>
<booktitle>In Proc HLT/NAACL Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technology.</booktitle>
<contexts>
<context position="15718" citStr="Williams, 2007" startWordPosition="2604" endWordPosition="2605">a user knowledge model that captures the variability of user knowledge required for answering questions on different attributes. Observation Model: Since the speech recognition engine we are using returns only a one-best and its confidence value C E [0, 1]. We define the observation function as follows, � ��a��a�� = C 1−C if a,, = a,otherwise. (2) �Au�−1 where a,, is the true user action, a,, is the speech recognition output (i.e., corrupted user action), and A,, is the set of user actions related to the last machine action. User Knowledge Model: In most of the applications (Roy et al., 2000; Williams, 2007) where 107 the POMDP framework got applied, it is normally assumed that the user needs only common sense to answer the questions asked by the dialog system. Our application is more complex as the product information is very rich. A user may have different difficulty in answering different questions. For example, while a user can easily answer a question on category, he may not be able to answer a question on the part number. Thus, we define a user knowledge model to capture such uncertainty. Specifically, given a question (say am) and an intended product (say gu) in the user’s mind, we want to</context>
</contexts>
<marker>Williams, 2007</marker>
<rawString>J. Williams. 2007. Applying POMDPs to Dialog Systems in the Troubleshooting Domain. In Proc HLT/NAACL Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Williams</author>
<author>S Young</author>
</authors>
<title>Partially Observable Markov Decision Processes for Spoken Dialog Systems.</title>
<date>2007</date>
<journal>Computer Speech and Language</journal>
<volume>21</volume>
<issue>2</issue>
<pages>231--422</pages>
<contexts>
<context position="7910" citStr="Williams and Young (2007)" startWordPosition="1284" endWordPosition="1287">iven a question on category, the system removes all the products that do not belong to category “camera”. In Step-2 and Step-3, the baseline system asks questions about product name and product category, and product category has a higher priority. 3 Overview of POMDP 3.1 Basic Definitions A Partially Observable Markov Decision Process (POMDP) is a general framework to handle uncertainty in a spoken dialog system. Following notaList of Products Corrupted User Action Dialog Manager Human Question product? No Found Yes Play Rating End • Intended product Speech recognizer User Action 105 tions in Williams and Young (2007), a POMDP is defined as a tuple IS, A, T, R, O, Z, A,b0} where S is a set of states s describing the environment; A is a set of machine actions a operating on the environment; T defines a transition probability P(s&apos;Is, a); R defines a reward function r(s, a); O is a set of observations o, and an observation can be thought as a corrupted version of a user action; Z defines an observation probability P(o&apos;Is&apos;, a); A is a geometric � discount factor; and bo is an initial belief vector. The POMDP operates as follows. At each timestep (a.k.a. stage), the environment is in some unobserved state s. Si</context>
<context position="9153" citStr="Williams and Young (2007)" startWordPosition="1512" endWordPosition="1515"> exactly, a distribution (called a belief vector b) over possible states is maintained where b(s) indicates the probability of being in a particular state s. Based on the current belief vector b, an optimal action selection algorithm selects a machine action a, receives a reward r, and the environment transits to a new unobserved state s &apos; . The environment then generates an observation o&apos; (i.e., a user action), after which the system update � the belief vector b. We call the process of adjusting the belief vector b at each stage “belief update”. 3.2 Applying POMDP in Practice As mentioned in Williams and Young (2007), it is not trivial to apply the POMDP framework to a specific application. To achieve this, one normally needs to design the following three components: • State Diagram Modeling • Belief Update • Optimal Action Selection The state diagram defines the topology of the graph, which contains three kinds of elements: system state, machine action, and user action. To drive the transitions, one also needs to define a set of models (e.g., user goal model, user action model, etc.). The modeling assumptions are applicationdependent. The state diagram, together with the models, determines the dynamics o</context>
<context position="11006" citStr="Williams and Young (2007)" startWordPosition="1809" endWordPosition="1812">tion algorithm is used to predict the behavior of the system in the future if a given machine action a was taken. The search algorithm can use an exhaustive linear search or an approximated greedy search depending on the size of A (Murphy, 2000; Spaan and Vlassis, 2005). 4 POMDP Framework in Voice-Rate In this section, we present our instantiation of POMDP in the Voice-Rate system. 4.1 State Diagram Modeling 4.1.1 State Diagram Design Table 2 summarizes the main design choices in the state diagram for our application, i.e., identifying the intended product from a large list of products. As in Williams and Young (2007), we incorporate both the user goal (i.e., the intended product) and the user action in the system state. Moreover, to efficiently update belief vector and compute optimal action, the state space is dynamically generated and pruned. In particular, instead of listing all the possible combinations between the products and the user actions, at each stage, we only generate states containing the products and the user actions that are relevant to the last machine action. Moreover, at each stage, if the belief probability of a product is smaller than a threshold, we prune out this product and all its</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>J. Williams and S. Young. 2007. Partially Observable Markov Decision Processes for Spoken Dialog Systems. Computer Speech and Language 21(2): 231-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zweig</author>
<author>P Nguyen</author>
<author>Y C Ju</author>
<author>Y Y Wang</author>
<author>D Yu</author>
<author>A Acero</author>
</authors>
<title>The Voice-Rate Dialog System for Consumer Ratings. In</title>
<date>2007</date>
<booktitle>Proc of Interspeech</booktitle>
<contexts>
<context position="1731" citStr="Zweig et al., 2007" startWordPosition="262" endWordPosition="265">ng and rating systems have provided a valuable service to consumers by allowing them to shop products and share their assessments of products online. The use of these systems, however, requires access to a web interface, typically through a laptop or desktop computer, and this restricts their usefulness. While mobile phones also provide some web access, their small screens make them inconvenient to use. Therefore, there arises great interests in having a spoken dialog interface through which a user can call to get product information (e.g., price, rating, review, etc.) on the fly. Voice-Rate (Zweig et al., 2007) is such a system. Here is a typical scenario under which shows the usefulness of the Voice-Rate system. A user enters a store and finds that a digital camera he has not planned to buy is on sale. Before he decides to buy the camera, he takes out his cell phone and calls Voice-Rate to see whether the price is really a bargain and what other people have said about the camera. This helps him to make a wise decision. The Voice-Rate system (Zweig et al., 2007) involves many techniques, e.g., information retrieval, review summarization, speech recognition, speech synthesis, dialog management, etc. </context>
<context position="5186" citStr="Zweig et al., 2007" startWordPosition="842" endWordPosition="845">ons about these attributes. For example, while most users can easily answer a question on category, they may not be able to answer a question on the part number of a product, though the part number is unique and perfect to distinguish products. Other variabilities are in the difficulty that the attributes impose on speech recognition and speech synthesis. Clearly, given a list of products and a set of attributes, what questions and in what order to ask is essential to make the dialog successful. Our goal is to dynamically find such important attributes at each stage/turn. The baseline system (Zweig et al., 2007) asks questions only on product name and category. The order of questions is fixed: first ask questions on product category, and then on name. Moreover, it is deterministic and does not model uncertainly in speech recognition and user knowledge. Partially observable Markov decision process (POMDP) has been shown to be a general framework to capture the uncertainty in spoken dialog systems. In this paper, we present a POMDP-based probabilistic system, which utilizes rich product information and captures uncertainty in speech recognition and user knowledge. We propose a novel method to learn a u</context>
<context position="30583" citStr="Zweig et al., 2007" startWordPosition="5126" endWordPosition="5129">t very short questions while the baseline system mainly uses the product name question, which is normally very long. The long question on product name also imposes difficulty in speech synthesis, user input, and speech recognition, though this is not reflected in the simulation. 6 Conclusions In this paper, we have applied the POMDP framework into Voice-Rate, a system through which a user can call to get product information (e.g., price, rating, review, etc.). We have proposed a novel method to learn a user knowledge model from a review database. Compared with a deterministic baseline system (Zweig et al., 2007), the POMDP system is probabilistic and is able to handle speech recognition errors and user mistakes, in which case the deterministic baseline system is doomed to fail. Moreover, the POMDP system exploits richer product information to reduce the interaction time required to complete a dialog. We have developed a simulation model, and shown that the POMDP system improves the baseline system significantly in terms of both dialog failure rate and dialog interaction time. We also implement our POMDP system into a speech demo and plan to carry out tests through humans. Acknowledgement This work wa</context>
</contexts>
<marker>Zweig, Nguyen, Ju, Wang, Yu, Acero, 2007</marker>
<rawString>G. Zweig, P. Nguyen, Y.C. Ju, Y.Y. Wang, D. Yu, and A. Acero. 2007. The Voice-Rate Dialog System for Consumer Ratings. In Proc of Interspeech 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>