<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.036143">
<title confidence="0.982471">
Building a Large Knowledge Base
for a Natural Language System
</title>
<author confidence="0.617109">
Jerry R. Hobbs
</author>
<sectionHeader confidence="0.9167815" genericHeader="abstract">
Artificial Intelligence Center
SRI International
</sectionHeader>
<bodyText confidence="0.922843666666667">
and
Center for the Study of Language and Information
Stanford University
</bodyText>
<sectionHeader confidence="0.935157" genericHeader="introduction">
Abstract
</sectionHeader>
<bodyText confidence="0.999933375">
A sophisticated natural language system requires a
large knowledge base. A methodology is described for con-
structing one in a principled way. Facts are selected for the
knowledge base by determining what facts are linguistically
presupposed by a text in the domain of interest. The facts
are sorted into clusters, and within each cluster they are
organized according to their logical dependencies. Finally,
the facts are encoded as predicate calculus axioms.
</bodyText>
<sectionHeader confidence="0.985798" genericHeader="method">
1. The Problem&apos;
</sectionHeader>
<bodyText confidence="0.975874649122807">
It is well-known that the interpretation of natural
language discourse can require arbitrarily detailed world
knowledge and that a sophisticated natural language sys-
tem must have a large knowledge base. But heretofore, the
knowledge bases in natural language systems have either
encoded only a few kinds of knowledge - e.g., sort hier-
archies - or facts in only very narrow domains. The aim
of this paper is to present a methodology for construct-
ing an intermediate-size knowledge base for a natural lan-
guage system, which constitutes a manageable and princi-
pled midway point between these simple knowledge bases
and the impossibly detailed knowledge bases that people
seem to use.
The work described in this paper has been carried out
as part of a project to build a system for natural language
access to a computerized medical textbook on hepatitis.
The user asks a question in English, and rather than at-
tempting to answer it, the system returns the passages in
the text relevant to the question. The English query is
translated into a logical form by a syntactic and semantic
translation component [Grosz et al., 19821. The textbook is
represented by a &amp;quot;text structure&amp;quot;, consisting, among other
things, of summaries of the contents of individual passages,
expressed in a logical language. Inference procedures, mak-
ing use of a knowledge base, seek to match the logical form
I am indebted to Bob Amsler and Don Walker for discussions concern-
ing this work. This research was supported by NIH Grant LM03611
from the National Library of Medicine, by Grant IST-8209346 from
the National Science Foundation, and by a gift from the Systems De-
velopment Foundation.
of the query with some part of the text structure. In ad-
dition, they attempt to attempt to solve various pragmatic
problems posed by the query, including the resolution of
coreference, metonymy, and the implicit predicates in com-
pound nominals. The inference procedures are discussed
elsewhere [Walker and Hobbs, 19811. In this paper a brief
example will have to suffice.
Suppose the user asks the question, &amp;quot;Can a patient with
mild hepatitis engage in strenuous exercise?&amp;quot; The relevant
passage in the textbook is labelled, &amp;quot;Management of the
Patient: Requirements for Bed Rest&amp;quot;. The inference pro-
cedures must show that this heading is relevant to this ques-
tion by drawing the appropriate inferences from the knowl-
edge base. Thus the knowledge base must contain the facts
that rest is an activity that consumes little energy, that ex-
ercise is an activity, and that if something is strenuous it
consumes much energy, and axioms that relate the concepts
&amp;quot;can&amp;quot; and &amp;quot;require&amp;quot; via the concept of possibility.
One way to build the knowledge base would have been
to analyze the queries in some target dialogs we collected
to determine what facts they seem to require, and to put
just these facts into our knowledge base. However, we
are interested in discovering general principles of selection
and structuring of such intermediate-sized knowledge bases,
principles that would give us reason to believe our knowl-
edge base would be useful for unanticipated queries.
Thus we have developed a three-stage methodology:
</bodyText>
<listItem confidence="0.974814909090909">
1. Select the facts that should be in the knowledge base
by determining what facts are linguistically presupposed by
the medical textbook. This gives us a very good indication
of what knowledge of the domain the user is eNpected to
bring to the textbook and would bring to the system.
2. Organize the facts into clusters and organize the facts
within each cluster according to the logical dependencies
among the concepts they involve.
3. Encode the facts as predicate calculus axioms, regu-
larizing the concepts, or predicates, as necessary.
These stages are discussed in the next three sections.
</listItem>
<sectionHeader confidence="0.746855" genericHeader="method">
2. Selecting the Facts
</sectionHeader>
<bodyText confidence="0.962707">
To be useful, a natural language system must. have a
</bodyText>
<page confidence="0.992802">
283
</page>
<figure confidence="0.336229">
•
</figure>
<bodyText confidence="0.999435511111111">
large vocabulary. 1.\ loreover, when one sets out to axioma-
tize a domain. unless one has a rich set of predicates and
facts to be responsible for, a sense of coherence in the ax-
iomatizat ion is hard to achieve. One&apos;s efforts seem ad hoc.
So the first step in building the knowledge base is to make
up an extensive list of words, or predicates, or concepts
(the three terms will be used interchangeably here), and an
extensive list of relevant facts about these predicates. We
chose about 350 words from our target dialogs and headings
in the textbook and encoded the relevant facts involving
these concepts. Because there are dozens of facts one could
state involving any one of these predicates, we were faced
with the problem of determining those facts that would be
most pertinent for natural language understanding in this
domain.
Our principal tool at this stage was a full-sentence con-
cordance of the textbook, displaying the contexts in which
the words were used. Our method was to examine these
contexts and to ask what facts about each concept were
required to justify each of these uses, what did their uses
linguistically presuppose.
The three principal linguistic phenomena we looked
at were predicate-argument relations, compound nominals,
and conjoined phrases. As an example of the first, consider
two uses of the word &amp;quot;data&amp;quot;. The phrase &amp;quot;extensive data
on histocotnpatibility antigens&amp;quot; points to the fact about
data that it is a set (justifying &amp;quot;extensive&amp;quot;) of particular
facts about some subject (justifying the &amp;quot;on&amp;quot; argument).
The phrase &amp;quot;the data do not consistently show ...&amp;quot; points
to the fact that data is assembled to support some conclu-
sion. To arrive at the facts, we ask questions like &amp;quot;What
is data that it can be extensive or that it can show some-
thing?&amp;quot; For compound nominals we ask, &amp;quot;What general
facts about the two nouns underlie the implicit relation?&amp;quot;
So for &amp;quot;casual contact circumstances&amp;quot; we posit that contact
is a concomitant of activities, and the phrase &amp;quot;contact mode
of transmission&amp;quot; leads us to the fact that contact possibly
leads to transmission of an agent. Conjoined noun phrases
indicate the existence of a superordinate in a sort hierar-
chy covering all the conjoined concepts. Thus, the phrase
&amp;quot;epidemiology, clinical aspects, pathology, diagnosis, and
management&amp;quot; tells us to encode the facts that all of these
are aspects of a disease.
As an illustration of the method, let us examine various
uses of the word &amp;quot;disease&amp;quot; to see what facts it suggests:
</bodyText>
<listItem confidence="0.990670083333333">
• &amp;quot;destructive liver disease&amp;quot;: A disease has a harmful
effect on one or more body parts.
• &amp;quot;hepatitis A virus plays a role in chronic liver dis-
ease&amp;quot;: A disease may be caused by an agent.
• &amp;quot;the clinical manifestations of a disease&amp;quot;: A disease
is detectable by signs and symptoms.
• &amp;quot;the course of a disease&amp;quot;: A disease goes through sev-
eral stages in time.
• &amp;quot;infectious disease&amp;quot;: A disease can be transmitted.
• &amp;quot;a notifiable disease&amp;quot;: A disease has patterns in the
population that can be traced by the medical com-
munity.
</listItem>
<bodyText confidence="0.9979936">
We emphasize that this is not a mechanical procedure
but a method of discovery that relies on our informed in-
tuitions. Since it is largely background knowledge we are
after, we can not expect to get it directly by interviewing
experts. Our method is a way of extracting it from the
presuppositions behind linguistic use.
The first thing our method gives us is a great deal of
selectivity in the facts we encode. Consider the word &amp;quot;an-
imal&amp;quot;. There are hundreds of facts that we know about
animals. However, in this domain there are only two facts
we need. Animals are used in experiments, as seen in the
compound nominal &amp;quot;laboratory animal&amp;quot;, and animals can
have a disease, and thus transmit it, as seen in the phrase
&amp;quot;animals implicated in hepatitis&amp;quot;. Similarly, the only rele-
vant fact about &amp;quot;water&amp;quot; is that it may be a medium for the
transmission of disease.
Secondly, the method points us toward generalizations
we might otherwise miss, when we see a number of uses
that seem to fall within the same class. For example, the
uses of the word &amp;quot;laboratory&amp;quot; seem to be of two kinds:
</bodyText>
<listItem confidence="0.910238">
1. &amp;quot;laboratory animals&amp;quot;, &amp;quot;laboratory spores&amp;quot;, &amp;quot;labora-
tory contamination&amp;quot;, &amp;quot;laboratory methods&amp;quot;.
2. &amp;quot;a study by a research laboratory&amp;quot;, &amp;quot;laboratory test-
ing&amp;quot;, &amp;quot;laboratory abnormalities&amp;quot;, &amp;quot;laboratory charac-
teristics of hepatitis A&amp;quot;, &amp;quot;laboratory picture&amp;quot;.
</listItem>
<bodyText confidence="0.999412866666667">
The first of these rests on the fact that experiments involv-
ing certain events and entities take place in laboratories.
The second rests on the fact that information is acquired
there.
A classical issue in lexical semantics that arises at this
stage is the problem of polysemy. Should we consider a
word, or predicate, as ambiguous, or should we try to find a
very general characterization of its meaning that abstracts
away from its use in various contexts? The concordance
method suggests a solution. The rule of thumb we have
followed is this: if the uses fall into two or three distinct,
large classes, the word is treated as having separate senses,
whereas if the uses seem to be spread all over the map, we
try to find a general characterization that covers them all.
The word &amp;quot;derive&amp;quot; is an example of the first case. A deriva-
tion is either of information from an investigative activity,
as in &amp;quot;epidemiologic patterns derived from historical stud-
ies&amp;quot;, or of chemicals from body parts, as in &amp;quot;enzymes de-
rived from intestinal mucosa&amp;quot;. By contrast, the word &amp;quot;pro-
duce&amp;quot; (and the word &amp;quot;product&amp;quot;) can be used in a variety of
ways: a disease can produce a condition, a virus can pro-
duce a disease or a viral particle, something can produce a
virus (&amp;quot;the amount of virus produced in the carrier state&amp;quot;),
intestinal flora can produce compounds, and something can
produce chemicals from blood (&amp;quot;blood products&amp;quot;). All of
this suggests that we want to encode only the fact that if x
produces y, then x causes y to come into existence.
At this stage in our method, we aimed at only infor-
mal, English statements of the facts. We ended up with
approximately 1000 facts for the knowledge base.
</bodyText>
<page confidence="0.997829">
284
</page>
<sectionHeader confidence="0.944796" genericHeader="method">
3. Organizing the Knowledge Base
</sectionHeader>
<bodyText confidence="0.999974956896552">
The next step is to sort the facts into natural &amp;quot;clusters&amp;quot;
(cf. [Hayes, 1989]). For example, the fact &amp;quot;If x produces y,
then x causes y to exist&amp;quot; is a fact about causality. The fact
&amp;quot;The replication of a virus requires components of a cell of
an organism&amp;quot; is a fact about viruses. The fact &amp;quot;A household
is an environment with a high rate of intimate contact, thus
a high risk of transmission&amp;quot; is in the cluster of facts about
people and their activities. The fact &amp;quot;If bilirubin is not
secreted by the liver, it may indicate injury to the liver
tissues&amp;quot; is in the medical practice cluster.
It is useful to distinguish between clusters of &amp;quot;core
knowledge&amp;quot; that is common to most domains and &amp;quot;domain-
specific knowledge&amp;quot;. Among the clusters of core knowledge
are space, time, belief, and goal-directed behavior. The
domain-specific knowledge includes clusters of facts about
viruses, immunology, physiology, disease, and medical prac-
tice. The cluster of facts about people and their activities
lies somewhere in between these two.
We are taking a rather novel approach to the axiom-
atization of core knowledge. Much of our knowledge and
language seems to be based on an underlying &amp;quot;topology&amp;quot;,
which is then instantiated in many other areas, like space,
time, belief, social organizations, and so on. We have be-
gun by axiomatizing this fundamental topology. At its base
is set theory, axiomatized along traditional lines. Next is
a theory of granularity, in which the key concept is &amp;quot;x is
indistinguishable from y with respect to grain g&amp;quot;. A the-
ory of scalar concepts combines granularity and partial or-
ders. The concept of change of state and the interactions of
containment and causality are given (perhaps overly sim-
ple) axiomatizations. Finally there is a cluster centered
around the notion of a &amp;quot;system&amp;quot;, which is defined as a set
of entities and a set of relations among them. In the &amp;quot;sys-
tem&amp;quot; cluster we provide an interrelated set of predicates
enabling one to characterize the &amp;quot;structure&amp;quot; of a system,
producer-consumer relations among the components, the
&amp;quot;function&amp;quot; of a component of a system as a relation be-
tween the component&apos;s behavior and the behavior of the
system as a whole, notions of normality, and distributions
of properties among the elements of a system. The appli-
cability of the notion of &amp;quot;system&amp;quot; is very wide; among the
entities that can be viewed as systems are viruses, organs,
activities, populations, and scientific disciplines.
Other general commonsense knowledge is built on top
of this naive topology. The domain of time is seen as a
particular kind of scale defined by change of state, and the
axiomatization builds toward such predicates as &amp;quot;regular&amp;quot;
and &amp;quot;persist&amp;quot;. The domain of belief has three principal
subclusters in this application: learning, which includes
such predicates as &amp;quot;find&amp;quot;, &amp;quot;test&amp;quot; and &amp;quot;manifest&amp;quot;; reasoning,
explicating predicates such as &amp;quot;leads-to&amp;quot; and &amp;quot;consistent&amp;quot;;
and classifying, with such predicates as &amp;quot;distinguish&amp;quot;, &amp;quot;dif-
ferentiate&amp;quot; and &amp;quot;identify&amp;quot;. The domain of modalities expli-
cates such concepts as necessity, possibility, and likelihood.
Finally, in the domain of goal-directed behavior, we char-
acterize such predicates as &amp;quot;help&amp;quot;, &amp;quot;care&amp;quot; and &amp;quot;risk&amp;quot;.
In the lowest-level domain-specific clusters - viruses,
immunology, physiology, and people and their activities -
we begin by specifying their ontology (the different sorts
of entities and classes of entities in the cluster), the inclu-
sion relations among the classes, the behaviors of entities
in the clusters and their interactions with other entities.
The &amp;quot;Disease&amp;quot; cluster is axiomatized primarily in terms of
a temporal schema of the progress of an infection. The
cluster of &amp;quot;Medical Practice&amp;quot;, or medical intervention in
the natural course of the disease, can be axiomatized as a
plan, in the Al sense, for maintaining or achieving a state of
health in the patient, where different branches of the plan
correspond to where in the temporal schema for disease the
physician intervenes and to the mode of intervention.
Most of the content of the domain-specific clusters is
specific to medicine, but the general principles along which
it was constructed are relevant to many applications. Fre-
quently the best way to proceed is first to identify the enti-
ties and classification schemes in several clusters, state the
relationships among the entities, and encode axioms artic-
ulating clusters with higher- and lower-level clusters. Often
one then wants to specify temporal schemas involving inter-
actions of entities from several domains and goal-directed
intervention in the natural course of these schemas.
The concordance method of the second stage is quite
useful in ferreting out the relevant facts, but it leaves some
lacunae, or gaps, that become apparent when we look at
the knowledge base as a whole. The gaps are especially fre-
quent in commonsense knowledge. The general principle we
follow in encoding this lowest level of the knowledge base is
to aim for a vocabulary of predicates that is minimally ad-
equate for expressing the higher-level, medical facts and to
encode the obvious connections among them. One heuristic
has proved useful: If the axioms in higher-level domains are
especially complicated to express, this indicates that some
underlying domain has not been sufficiently explicated and
axiomatized. For example, this consideration has led to a
fuller elaboration of the &amp;quot;systems&amp;quot; domain. Another ex-
ample concerns the predicates &amp;quot;parenteral&amp;quot;, &amp;quot;needle&amp;quot; and
&amp;quot;bite&amp;quot;, appearing in the domain of &amp;quot;disease transmission&amp;quot;.
Initial attempts to axiomatize them indicated the need for
axioms, in the &amp;quot;naive topology&amp;quot; domain, about membranes
and the penetration of membranes allowing substances to
move from one side of the membrane to the other.
Within each cluster, concepts and facts seem to fall into
small groups that need to be defined together. For example.
the predicates &amp;quot;clean&amp;quot; and &amp;quot;contaminate&amp;quot; need to be de-
fined in tandem. There is a larger example in the &amp;quot;Disease
Transmission&amp;quot; cluster. The predicate &amp;quot;transmit&amp;quot; is funda-
mental, and once it has been characterized as the motion
of an infectious agent from a person or animal to a person
via some medium, the predicates &amp;quot;source&amp;quot;, &amp;quot;route&amp;quot;, &amp;quot;mech-
anism&amp;quot;, &amp;quot;mode&amp;quot;, &amp;quot;vehicle&amp;quot; and &amp;quot;expose&amp;quot; can be defined in
terms of its schema. In addition, relevant facts about body
fluids, food, water, contamination, needles, bites, propaga-
tion, and epidemiology rest on an understanding of &amp;quot;trans-
mit&amp;quot;. In each domain there tends to be a core of central
predicates whose nature must be explicated with some care.
A large number of other predicates can then be character-
ized fairly easily in terms of these.
</bodyText>
<page confidence="0.997071">
285
</page>
<sectionHeader confidence="0.9758055" genericHeader="method">
4. Encoding the Facts in Predicate
Calculus
</sectionHeader>
<bodyText confidence="0.999990347826087">
Encoding world knowledge in a logical language is of-
ten taken to be a very hard problem. It is my belief that
the difficulties result from attempts to devise representa-
tions that lend themselves in obvious ways to efficient de-
duction algorithms and that adhere to stringent ontological
scruples. I have abandoned the latter constraint altogether
(see [Hobbs, 198.1], for arguments) and believe the former
concern should be postponed until we have a better idea
of precisely what sort of deductions need to be optimized.
Under these ground rules, translating individual facts into
predicate calculus is usually fairly straightforward.
There are still considerable difficulties in making the
axioms mesh well together. A predicate should not be used
in some higher-level cluster unless it has been elucidated in
that or some lower-level cluster. This necessarily restricts
one&apos;s vocabulary. For example, the predicate &amp;quot;in&amp;quot; does
a lot of work. There are facts about viruses in tissues,
chemicals in body fluids, infections in patient&apos;s bodies, and
so on, and a direct translation of some of these axioms back
into English is somewhat awkward. One has the feeling
that subtle shades of meaning have been lost. But this is
inevitable in a knowledge base whose size is intended to be
intermediate rather than exhaustive.
</bodyText>
<sectionHeader confidence="0.997254" genericHeader="conclusions">
5. Summary
</sectionHeader>
<bodyText confidence="0.999920823529412">
Much of this paper has been written almost as a case
study. It would be useful for me to highlight the new and
general principles and results that come out of this project.
The method of using linguistic presuppositions as a &amp;quot;forc-
ing function&amp;quot; for the underlying knowledge is fairly gen-
erally applicable in any domain for which there is a large
body of text to exploit. It has been used in ethnography
and discourse analysis, but to my knowledge it has not
been previously used in the construction of an Al knowl-
edge base. The core knowledge has been encoded in ways
that are independent of domain and hence should be useful
for any natural language application. Of particular interest
here is the identification and axiomatization of the topologi-
cal substructure of language The domain-specific knowledge
will not of course carry over to other applications, but, as
mentioned above, certain general principles of axiomatizing
complex domains have emerged.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999545">
Grosz, B., N. Ilaas, G. Ilendrix, J. Hobbs, P. Martin, R. Moore,
.1. Robinson, and S. Rosenschein, 1982. DIALOGIC: A
core natural language processing system. Proceedings of the
Ninth international Conference on Computational Linguis-
tics. 95-1th, Prague. Czechoslovakia.
haves, P., 1981. The second naive physics manifesto. In Hobbs,
J. and R. Moore (Eds.), Formal Theories of the Common-
sense World. Ablex Publishing Company, Norwood, New
Jersey.
Hobbs, J. 1984. Ontological promiscuity. Manuscript.
Walker, D. and J. Hobbs, 1981. Natural language access to med-
ical text. SRI International Technical Note 240. March
1981.
</reference>
<page confidence="0.998464">
286
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402226">
<title confidence="0.9999075">Building a Large Knowledge Base for a Natural Language System</title>
<author confidence="0.999985">Jerry R Hobbs</author>
<affiliation confidence="0.9987662">Artificial Intelligence Center SRI International and Center for the Study of Language and Information Stanford University</affiliation>
<abstract confidence="0.999618283707865">sophisticated language system requires a knowledge base. methodology is described for conin a way. Facts are selected for the base by what facts are linguistically by a text the domain of interest. The facts sorted into and within each cluster they are according to their logical Finally, facts are encoded predicate calculus axioms. 1. The Problem&apos; is well-known that the of natural discourse can require detailed world and that a sophisticated language syshave a large knowledge But heretofore, the bases in natural language have either only a few kinds of knowledge sort hieror facts in only very narrow The aim of this paper is to present a methodology for constructan intermediate-size knowledge base for a lanwhich constitutes a and principoint between simple knowledge bases the impossibly detailed bases that people seem to use. work described in this has been carried out part of a project to build a system natural language to a computerized medical on hepatitis. user asks a question in and rather than atanswer it, the system the passages in text relevant to the The English query is into a logical by a syntactic and semantic component [Grosz et 19821. The textbook is by &amp;quot;text structure&amp;quot;, among other things, of summaries of the contents of individual passages, expressed in a logical language. Inference procedures, makof a knowledge seek to the logical form I am indebted to Bob Amsler and Don Walker for discussions concerning this work. This research was supported by NIH Grant LM03611 from the National Library of Medicine, by Grant IST-8209346 from the National Science Foundation, and by a gift from the Systems Development Foundation. of the query with some part of the text structure. In addition, they attempt to attempt to solve various pragmatic problems posed by the query, including the resolution of coreference, metonymy, and the implicit predicates in compound nominals. The inference procedures are discussed [Walker and Hobbs, In this paper a brief example will have to suffice. Suppose the user asks the question, &amp;quot;Can a patient with mild hepatitis engage in strenuous exercise?&amp;quot; The relevant passage in the textbook is labelled, &amp;quot;Management of the Patient: Requirements for Bed Rest&amp;quot;. The inference procedures must show that this heading is relevant to this question by drawing the appropriate inferences from the knowledge base. Thus the knowledge base must contain the facts that rest is an activity that consumes little energy, that exercise is an activity, and that if something is strenuous it consumes much energy, and axioms that relate the concepts &amp;quot;can&amp;quot; and &amp;quot;require&amp;quot; via the concept of possibility. One way to build the knowledge base would have been to analyze the queries in some target dialogs we collected to determine what facts they seem to require, and to put just these facts into our knowledge base. However, we are interested in discovering general principles of selection and structuring of such intermediate-sized knowledge bases, principles that would give us reason to believe our knowledge base would be useful for unanticipated queries. Thus we have developed a three-stage methodology: Select the facts that should be in knowledge base by determining what facts are linguistically presupposed by medical textbook. This gives a very good indication of what knowledge of the domain the user is eNpected to to the textbook and would bring to system. 2. Organize the facts into clusters and organize the facts within each cluster according to the logical dependencies among the concepts they involve. 3. Encode the facts as predicate calculus axioms, regularizing the concepts, or predicates, as necessary. These stages are discussed in the next three sections. 2. Selecting the Facts be useful, a natural language must. have a 283 • vocabulary. loreover, when one sets out to axiomatize a domain. unless one has a rich set of predicates and facts to be responsible for, a sense of coherence in the axion is hard to achieve. One&apos;s efforts seem ad So the first step in building the knowledge base is to make up an extensive list of words, or predicates, or concepts (the three terms will be used interchangeably here), and an extensive list of relevant facts about these predicates. We chose about 350 words from our target dialogs and headings in the textbook and encoded the relevant facts involving these concepts. Because there are dozens of facts one could state involving any one of these predicates, we were faced with the problem of determining those facts that would be most pertinent for natural language understanding in this domain. Our principal tool at this stage was a full-sentence concordance of the textbook, displaying the contexts in which the words were used. Our method was to examine these contexts and to ask what facts about each concept were required to justify each of these uses, what did their uses linguistically presuppose. The three principal linguistic phenomena we looked at were predicate-argument relations, compound nominals, and conjoined phrases. As an example of the first, consider two uses of the word &amp;quot;data&amp;quot;. The phrase &amp;quot;extensive data on histocotnpatibility antigens&amp;quot; points to the fact about that it is a &amp;quot;extensive&amp;quot;) of particular some subject the &amp;quot;on&amp;quot; argument). The phrase &amp;quot;the data do not consistently show ...&amp;quot; points to the fact that data is assembled to support some conclusion. To arrive at the facts, we ask questions like &amp;quot;What is data that it can be extensive or that it can show something?&amp;quot; For compound nominals we ask, &amp;quot;What general facts about the two nouns underlie the implicit relation?&amp;quot; So for &amp;quot;casual contact circumstances&amp;quot; we posit that contact is a concomitant of activities, and the phrase &amp;quot;contact mode of transmission&amp;quot; leads us to the fact that contact possibly leads to transmission of an agent. Conjoined noun phrases indicate the existence of a superordinate in a sort hierarchy covering all the conjoined concepts. Thus, the phrase &amp;quot;epidemiology, clinical aspects, pathology, diagnosis, and management&amp;quot; tells us to encode the facts that all of these are aspects of a disease. As an illustration of the method, let us examine various uses of the word &amp;quot;disease&amp;quot; to see what facts it suggests: • &amp;quot;destructive liver disease&amp;quot;: A disease has a harmful effect on one or more body parts. • &amp;quot;hepatitis A virus plays a role in chronic liver disease&amp;quot;: A disease may be caused by an agent. • &amp;quot;the clinical manifestations of a disease&amp;quot;: A disease is detectable by signs and symptoms. • &amp;quot;the course of a disease&amp;quot;: A disease goes through several stages in time. • &amp;quot;infectious disease&amp;quot;: A disease can be transmitted. • &amp;quot;a notifiable disease&amp;quot;: A disease has patterns in the population that can be traced by the medical community. emphasize is not a mechanical procedure but a method of discovery that relies on our informed intuitions. Since it is largely background knowledge we are we not expect to get it directly by interviewing experts. Our method is a way of extracting it from the presuppositions behind linguistic use. The first thing our method gives us is a great deal of selectivity in the facts we encode. Consider the word &amp;quot;animal&amp;quot;. There are hundreds of facts that we know about in this domain there are only two facts we need. Animals are used in experiments, as seen in the compound nominal &amp;quot;laboratory animal&amp;quot;, and animals can have a disease, and thus transmit it, as seen in the phrase &amp;quot;animals implicated in hepatitis&amp;quot;. Similarly, the only relevant fact about &amp;quot;water&amp;quot; is that it may be a medium for the transmission of disease. Secondly, the method points us toward generalizations we might otherwise miss, when we see a number of uses that seem to fall within the same class. For example, the uses of the word &amp;quot;laboratory&amp;quot; seem to be of two kinds: 1. &amp;quot;laboratory animals&amp;quot;, &amp;quot;laboratory spores&amp;quot;, &amp;quot;laboratory contamination&amp;quot;, &amp;quot;laboratory methods&amp;quot;. 2. &amp;quot;a study by a research laboratory&amp;quot;, &amp;quot;laboratory testing&amp;quot;, &amp;quot;laboratory abnormalities&amp;quot;, &amp;quot;laboratory characteristics of hepatitis A&amp;quot;, &amp;quot;laboratory picture&amp;quot;. The first of these rests on the fact that experiments involving certain events and entities take place in laboratories. The second rests on the fact that information is acquired there. A classical issue in lexical semantics that arises at this stage is the problem of polysemy. Should we consider a word, or predicate, as ambiguous, or should we try to find a very general characterization of its meaning that abstracts away from its use in various contexts? The concordance method suggests a solution. The rule of thumb we have followed is this: if the uses fall into two or three distinct, large classes, the word is treated as having separate senses, whereas if the uses seem to be spread all over the map, we try to find a general characterization that covers them all. The word &amp;quot;derive&amp;quot; is an example of the first case. A derivation is either of information from an investigative activity, as in &amp;quot;epidemiologic patterns derived from historical studies&amp;quot;, or of chemicals from body parts, as in &amp;quot;enzymes derived from intestinal mucosa&amp;quot;. By contrast, the word &amp;quot;produce&amp;quot; (and the word &amp;quot;product&amp;quot;) can be used in a variety of ways: a disease can produce a condition, a virus can produce a disease or a viral particle, something can produce a virus (&amp;quot;the amount of virus produced in the carrier state&amp;quot;), intestinal flora can produce compounds, and something can produce chemicals from blood (&amp;quot;blood products&amp;quot;). All of this suggests that we want to encode only the fact that if x produces y, then x causes y to come into existence. At this stage in our method, we aimed at only informal, English statements of the facts. We ended up with approximately 1000 facts for the knowledge base. 284 3. Organizing the Knowledge Base The next step is to sort the facts into natural &amp;quot;clusters&amp;quot; (cf. [Hayes, 1989]). For example, the fact &amp;quot;If x produces y, then x causes y to exist&amp;quot; is a fact about causality. The fact &amp;quot;The replication of a virus requires components of a cell of an organism&amp;quot; is a fact about viruses. The fact &amp;quot;A household is an environment with a high rate of intimate contact, thus a high risk of transmission&amp;quot; is in the cluster of facts about people and their activities. The fact &amp;quot;If bilirubin is not secreted by the liver, it may indicate injury to the liver tissues&amp;quot; is in the medical practice cluster. It is useful to distinguish between clusters of &amp;quot;core knowledge&amp;quot; that is common to most domains and &amp;quot;domainspecific knowledge&amp;quot;. Among the clusters of core knowledge are space, time, belief, and goal-directed behavior. The domain-specific knowledge includes clusters of facts about viruses, immunology, physiology, disease, and medical practice. The cluster of facts about people and their activities lies somewhere in between these two. We are taking a rather novel approach to the axiomatization of core knowledge. Much of our knowledge and language seems to be based on an underlying &amp;quot;topology&amp;quot;, which is then instantiated in many other areas, like space, time, belief, social organizations, and so on. We have begun by axiomatizing this fundamental topology. At its base is set theory, axiomatized along traditional lines. Next is a theory of granularity, in which the key concept is &amp;quot;x is indistinguishable from y with respect to grain g&amp;quot;. A theory of scalar concepts combines granularity and partial orders. The concept of change of state and the interactions of containment and causality are given (perhaps overly simple) axiomatizations. Finally there is a cluster centered around the notion of a &amp;quot;system&amp;quot;, which is defined as a set of entities and a set of relations among them. In the &amp;quot;system&amp;quot; cluster we provide an interrelated set of predicates enabling one to characterize the &amp;quot;structure&amp;quot; of a system, producer-consumer relations among the components, the &amp;quot;function&amp;quot; of a component of a system as a relation between the component&apos;s behavior and the behavior of the system as a whole, notions of normality, and distributions of properties among the elements of a system. The applicability of the notion of &amp;quot;system&amp;quot; is very wide; among the entities that can be viewed as systems are viruses, organs, activities, populations, and scientific disciplines. Other general commonsense knowledge is built on top of this naive topology. The domain of time is seen as a particular kind of scale defined by change of state, and the axiomatization builds toward such predicates as &amp;quot;regular&amp;quot; and &amp;quot;persist&amp;quot;. The domain of belief has three principal subclusters in this application: learning, which includes such predicates as &amp;quot;find&amp;quot;, &amp;quot;test&amp;quot; and &amp;quot;manifest&amp;quot;; reasoning, explicating predicates such as &amp;quot;leads-to&amp;quot; and &amp;quot;consistent&amp;quot;; and classifying, with such predicates as &amp;quot;distinguish&amp;quot;, &amp;quot;differentiate&amp;quot; and &amp;quot;identify&amp;quot;. The domain of modalities explicates such concepts as necessity, possibility, and likelihood. Finally, in the domain of goal-directed behavior, we characterize such predicates as &amp;quot;help&amp;quot;, &amp;quot;care&amp;quot; and &amp;quot;risk&amp;quot;. In the lowest-level domain-specific clusters viruses, immunology, physiology, and people and their activities begin by specifying their different sorts entities and classes of entities in the cluster), the inclurelations the classes, the behaviors of entities in the clusters and their interactions with other entities. The &amp;quot;Disease&amp;quot; cluster is axiomatized primarily in terms of a temporal schema of the progress of an infection. The cluster of &amp;quot;Medical Practice&amp;quot;, or medical intervention in the natural course of the disease, can be axiomatized as a plan, in the Al sense, for maintaining or achieving a state of health in the patient, where different branches of the plan correspond to where in the temporal schema for disease the physician intervenes and to the mode of intervention. Most of the content of the domain-specific clusters is specific to medicine, but the general principles along which it was constructed are relevant to many applications. Frequently the best way to proceed is first to identify the entities and classification schemes in several clusters, state the relationships among the entities, and encode axioms articulating clusters with higherand lower-level clusters. Often one then wants to specify temporal schemas involving interactions of entities from several domains and goal-directed intervention in the natural course of these schemas. The concordance method of the second stage is quite useful in ferreting out the relevant facts, but it leaves some lacunae, or gaps, that become apparent when we look at the knowledge base as a whole. The gaps are especially frequent in commonsense knowledge. The general principle we follow in encoding this lowest level of the knowledge base is to aim for a vocabulary of predicates that is minimally adequate for expressing the higher-level, medical facts and to encode the obvious connections among them. One heuristic has proved useful: If the axioms in higher-level domains are especially complicated to express, this indicates that some underlying domain has not been sufficiently explicated and axiomatized. For example, this consideration has led to a fuller elaboration of the &amp;quot;systems&amp;quot; domain. Another example concerns the predicates &amp;quot;parenteral&amp;quot;, &amp;quot;needle&amp;quot; and &amp;quot;bite&amp;quot;, appearing in the domain of &amp;quot;disease transmission&amp;quot;. Initial attempts to axiomatize them indicated the need for axioms, in the &amp;quot;naive topology&amp;quot; domain, about membranes and the penetration of membranes allowing substances to move from one side of the membrane to the other. Within each cluster, concepts and facts seem to fall into small groups that need to be defined together. For example. the predicates &amp;quot;clean&amp;quot; and &amp;quot;contaminate&amp;quot; need to be defined in tandem. There is a larger example in the &amp;quot;Disease Transmission&amp;quot; cluster. The predicate &amp;quot;transmit&amp;quot; is fundamental, and once it has been characterized as the motion of an infectious agent from a person or animal to a person via some medium, the predicates &amp;quot;source&amp;quot;, &amp;quot;route&amp;quot;, &amp;quot;mechanism&amp;quot;, &amp;quot;mode&amp;quot;, &amp;quot;vehicle&amp;quot; and &amp;quot;expose&amp;quot; can be defined in terms of its schema. In addition, relevant facts about body fluids, food, water, contamination, needles, bites, propagation, and epidemiology rest on an understanding of &amp;quot;transmit&amp;quot;. In each domain there tends to be a core of central predicates whose nature must be explicated with some care. A large number of other predicates can then be characterized fairly easily in terms of these. 285 4. Encoding the Facts in Predicate Calculus Encoding world knowledge in a logical language is often taken to be a very hard problem. It is my belief that the difficulties result from attempts to devise representations that lend themselves in obvious ways to efficient deduction algorithms and that adhere to stringent ontological scruples. I have abandoned the latter constraint altogether (see [Hobbs, 198.1], for arguments) and believe the former concern should be postponed until we have a better idea of precisely what sort of deductions need to be optimized. Under these ground rules, translating individual facts into predicate calculus is usually fairly straightforward. There are still considerable difficulties in making the axioms mesh well together. A predicate should not be used in some higher-level cluster unless it has been elucidated in that or some lower-level cluster. This necessarily restricts one&apos;s vocabulary. For example, the predicate &amp;quot;in&amp;quot; does a lot of work. There are facts about viruses in tissues, chemicals in body fluids, infections in patient&apos;s bodies, and so on, and a direct translation of some of these axioms back into English is somewhat awkward. One has the feeling that subtle shades of meaning have been lost. But this is inevitable in a knowledge base whose size is intended to be intermediate rather than exhaustive. 5. Summary Much of this paper has been written almost as a case study. It would be useful for me to highlight the new and general principles and results that come out of this project. The method of using linguistic presuppositions as a &amp;quot;forcing function&amp;quot; for the underlying knowledge is fairly generally applicable in any domain for which there is a large body of text to exploit. It has been used in ethnography and discourse analysis, but to my knowledge it has not previously used in the construction of Al knowlbase. core knowledge has been encoded in ways are independent of domain and hence be useful for any natural language application. Of particular interest here is the identification and axiomatization of the topological substructure of language The domain-specific knowledge will not of course carry over to other applications, but, as mentioned above, certain general principles of axiomatizing complex domains have emerged.</abstract>
<note confidence="0.903471933333333">References Grosz, B., N. Ilaas, G. Ilendrix, J. Hobbs, P. Martin, R. Moore, .1. Robinson, and S. Rosenschein, 1982. DIALOGIC: A natural language processing system. of the Ninth international Conference on Computational Linguis- Prague. Czechoslovakia. haves, P., 1981. The second naive physics manifesto. In Hobbs, and R. Moore (Eds.), Theories of the Common- World. Publishing Company, Norwood, New Jersey. 1984. Ontological promiscuity. Manuscript. Walker, D. and J. Hobbs, 1981. Natural language access to medical text. SRI International Technical Note 240. March 1981. 286</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>N Ilaas</author>
<author>G Ilendrix</author>
<author>J Hobbs</author>
<author>P Martin</author>
<author>R Moore</author>
</authors>
<title>DIALOGIC: A core natural language processing system.</title>
<date>1982</date>
<booktitle>Proceedings of the Ninth international Conference on Computational Linguistics. 95-1th,</booktitle>
<location>Prague. Czechoslovakia.</location>
<contexts>
<context position="1803" citStr="Grosz et al., 1982" startWordPosition="286" endWordPosition="289">guage system, which constitutes a manageable and principled midway point between these simple knowledge bases and the impossibly detailed knowledge bases that people seem to use. The work described in this paper has been carried out as part of a project to build a system for natural language access to a computerized medical textbook on hepatitis. The user asks a question in English, and rather than attempting to answer it, the system returns the passages in the text relevant to the question. The English query is translated into a logical form by a syntactic and semantic translation component [Grosz et al., 19821. The textbook is represented by a &amp;quot;text structure&amp;quot;, consisting, among other things, of summaries of the contents of individual passages, expressed in a logical language. Inference procedures, making use of a knowledge base, seek to match the logical form I am indebted to Bob Amsler and Don Walker for discussions concerning this work. This research was supported by NIH Grant LM03611 from the National Library of Medicine, by Grant IST-8209346 from the National Science Foundation, and by a gift from the Systems Development Foundation. of the query with some part of the text structure. In additi</context>
</contexts>
<marker>Grosz, Ilaas, Ilendrix, Hobbs, Martin, Moore, 1982</marker>
<rawString>Grosz, B., N. Ilaas, G. Ilendrix, J. Hobbs, P. Martin, R. Moore, .1. Robinson, and S. Rosenschein, 1982. DIALOGIC: A core natural language processing system. Proceedings of the Ninth international Conference on Computational Linguistics. 95-1th, Prague. Czechoslovakia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P haves</author>
</authors>
<title>The second naive physics manifesto. In</title>
<date>1981</date>
<publisher>Ablex Publishing Company,</publisher>
<location>Norwood, New Jersey.</location>
<marker>haves, 1981</marker>
<rawString>haves, P., 1981. The second naive physics manifesto. In Hobbs, J. and R. Moore (Eds.), Formal Theories of the Commonsense World. Ablex Publishing Company, Norwood, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Ontological promiscuity.</title>
<date>1984</date>
<tech>Manuscript.</tech>
<marker>Hobbs, 1984</marker>
<rawString>Hobbs, J. 1984. Ontological promiscuity. Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Walker</author>
<author>J Hobbs</author>
</authors>
<title>Natural language access to medical text.</title>
<date>1981</date>
<journal>SRI International Technical Note</journal>
<volume>240</volume>
<contexts>
<context position="2660" citStr="Walker and Hobbs, 1981" startWordPosition="423" endWordPosition="426">atch the logical form I am indebted to Bob Amsler and Don Walker for discussions concerning this work. This research was supported by NIH Grant LM03611 from the National Library of Medicine, by Grant IST-8209346 from the National Science Foundation, and by a gift from the Systems Development Foundation. of the query with some part of the text structure. In addition, they attempt to attempt to solve various pragmatic problems posed by the query, including the resolution of coreference, metonymy, and the implicit predicates in compound nominals. The inference procedures are discussed elsewhere [Walker and Hobbs, 19811. In this paper a brief example will have to suffice. Suppose the user asks the question, &amp;quot;Can a patient with mild hepatitis engage in strenuous exercise?&amp;quot; The relevant passage in the textbook is labelled, &amp;quot;Management of the Patient: Requirements for Bed Rest&amp;quot;. The inference procedures must show that this heading is relevant to this question by drawing the appropriate inferences from the knowledge base. Thus the knowledge base must contain the facts that rest is an activity that consumes little energy, that exercise is an activity, and that if something is strenuous it consumes much energy, a</context>
</contexts>
<marker>Walker, Hobbs, 1981</marker>
<rawString>Walker, D. and J. Hobbs, 1981. Natural language access to medical text. SRI International Technical Note 240. March 1981.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>