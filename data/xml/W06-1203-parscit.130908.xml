<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002494">
<title confidence="0.999219">
Automatic Identification of Non-Compositional Multi-Word Expressions
using Latent Semantic Analysis
</title>
<author confidence="0.999529">
Graham Katz Eugenie Giesbrecht
</author>
<affiliation confidence="0.999783">
Institute of Cognitive Science Institute of Cognitive Science
University of Osnabr¨uck University of Osnabr¨uck
</affiliation>
<email confidence="0.995779">
gkatz@uos.de egiesbre@uos.de
</email>
<sectionHeader confidence="0.993807" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999674538461538">
Making use of latent semantic analy-
sis, we explore the hypothesis that lo-
cal linguistic context can serve to iden-
tify multi-word expressions that have non-
compositional meanings. We propose that
vector-similarity between distribution vec-
tors associated with an MWE as a whole
and those associated with its constitutent
parts can serve as a good measure of the
degree to which the MWE is composi-
tional. We present experiments that show
that low (cosine) similarity does, in fact,
correlate with non-compositionality.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978565217391">
Identifying non-compositional (or idiomatic)
multi-word expressions (MWEs) is an important
subtask for any computational system (Sag et al.,
2002), and significant attention has been paid
to practical methods for solving this problem in
recent years (Lin, 1999; Baldwin et al., 2003;
Villada Moir´on and Tiedemann, 2006). While
corpus-based techniques for identifying collo-
cational multi-word expressions by exploiting
statistical properties of the co-occurrence of the
component words have become increasingly
sophisticated (Evert and Krenn, 2001; Evert,
2004), it is well known that mere co-occurrence
does not well distinguish compositional from
non-compositional expressions (Manning and
Sch¨utze, 1999, Ch. 5).
While expressions which may potentially have
idiomatic meanings can be identified using various
lexical association measures (Evert and Krenn,
2001; Evert and Kermes, 2003), other techniques
must be used to determining whether or not a par-
ticular MWE does, in fact, have an idiomatic use.
In this paper we explore the hypothesis that the
local linguistic context can provide adequate cues
for making this determination and propose one
method for doing this.
We characterize our task on analogy with word-
sense disambiguation (Sch¨utze, 1998; Ide and
V´eronis, 1998). As noted by Sch¨utze, WSD
involves two related tasks: the general task of
sense discrimination—determining what senses
a given word has—and the more specific task
of sense selection—determining for a particular
use of the word in context which sense was in-
tended. For us the discrimination task involves
determining for a given expression whether it has
a non-compositional interpretation in addition to
its compositional interpretation, and the selec-
tion task involves determining in a given context,
whether a given expression is being used compo-
sitionally or non-compostionally. The German ex-
pression ins Wasser fallen, for example, has a non-
compositional interpretation on which it means ‘to
fail to happen’ (as in (1)) and a compositional in-
terpretation on which it means ‘to fall into water
(as in (2)).1
</bodyText>
<listItem confidence="0.841213571428571">
(1) Das Kind war beim Baden von einer Luftma-
tratze ins Wasser gefallen.
‘The child had fallen into the water from an a
air matress while swimming’
(2) Die Er¨ofnung des Skateparks ist ins Wasser
gefallen.
‘The opening of the skatepark was cancelled’
</listItem>
<bodyText confidence="0.998638333333333">
The discrimination task, then, is to identify ins
Wasser fallen as an MWE that has an idiomatic
meaning and the selection task is to determine that
</bodyText>
<footnote confidence="0.9770715">
1Examples taken from a newspaper corpus of the German
S¨uddeutsche Zeitung (1994-2000)
</footnote>
<page confidence="0.963567">
12
</page>
<note confidence="0.6998895">
Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 12–19,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999893725">
in (1) it is the compositional meaning that is in-
tended, while in (2) it is the non-compositional
meaning.
Following Sch¨utze (1998) and Landauer &amp; Du-
mais (1997) our general assumption is that the
meaning of an expression can be modelled in
terms of the words that it co-occurs with: its
co-occurrence signature. To determine whether
a phrase has a non-compositional meaning we
compute whether the co-occurrence signature of
the phrase is systematically related to the co-
occurrence signatures of its parts. Our hypoth-
esis is that a systematic relationship is indica-
tive of compositional interpretation and lack of
a systematic relationship is symptomatic of non-
compositionality. In other words, we expect com-
positional MWEs to appear in contexts more sim-
ilar to those in which their component words ap-
pear than do non-compositional MWEs.
In this paper we describe two experiments that
test this hypothesis. In the first experiment we
seek to confirm that the local context of a known
idiom can reliably distinguish idiomatic uses from
non-idiomatic uses. In the second experiment we
attempt to determine whether the difference be-
tween the contexts in which an MWE appears and
the contexts in which its component words appear
can indeed serve to tell us whether the MWE has
an idiomatic use.
In our experiments we make use of lexical se-
mantic analysis (LSA) as a model of context-
similarity (Deerwester et al., 1990). Since this
technique is often used to model meaning, we will
speak in terms of “meaning” similiarity. It should
be clear, however, that we are only using the LSA
vectors—derived from context of occurrence in a
corpus—to model meaning and meaning composi-
tion in a very rough way. Our hope is simply that
this rough model is sufficient to the task of identi-
fying non-compositional MWEs.
</bodyText>
<sectionHeader confidence="0.994386" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999931666666667">
Recent work which attempts to discriminate
between compositional and non-compositional
MWEs include Lin (1999), who used mutual-
information measures identify such phrases, Bald-
win et al. (2003), who compare the distribution
of the head of the MWE with the distribution of
the entire MWE, and Vallada Moir´on &amp; Tiede-
mann (2006), who use a word-alignment strat-
egy to identify non-compositional MWEs making
use of parallel texts. Schone &amp; Jurafsky (2001)
applied LSA to MWE identification, althought
they did not focus on distinguishing compositional
from non-compositional MWEs.
Lin’s goal, like ours, was to discriminate non-
compositional MWEs from compositional MWEs.
His method was to compare the mutual informa-
tion measure of the constituents parts of an MWE
with the mutual information of similar expressions
obtained by substituting one of the constituents
with a related word obtained by thesaurus lookup.
The hope was that a significant difference between
these measures, as in the case of red tape (mutual
information: 5.87) compared to yellow tape (3.75)
or orange tape (2.64), would be characteristic of
non-compositional MWEs. Although intuitively
appealing, Lin’s algorithm only achieves precision
and recall of 15.7% and 13.7%, respectively (as
compared to a gold standard generate from an id-
iom dictionary—but see below for discussion).
Schone &amp; Jurafsky (2001) evaluated a num-
ber of co-occurrence-based metrics for identify-
ing MWEs, showing that, as suggested by Lin’s
results, there was need for improvement in this
area. Since LSA has been used in a number
of meaning-related language tasks to good ef-
fect (Landauer and Dumais, 1997; Landauer and
Psotka, 2000; Cederberg and Widdows, 2003),
they had hoped to improve their results by identify
non-compositional expressions using a method
similar to that which we are exploring here. Al-
though they do not demonstrate that this method
actually identifies non-compositional expressions,
they do show that the LSA similarity technique
only improves MWE identification minimally.
Baldwin et al., (2003) focus more narrowly
on distinguishing English noun-noun compounds
and verb-particle constructions which are com-
positional from those which are not composi-
tional. Their approach is methodologically similar
to ours, in that they compute similarity on the ba-
sis of contexts of occurrance, making use of LSA.
Their hypothesis is that high LSA-based similar-
ity between the MWE and each of its constituent
parts is indicative of compositionality. They evalu-
ate their technique by assessing the correlation be-
tween high semantic similarity of the constituents
of an MWE to the MWE as a whole with the like-
lihood that the MWE appears in WordNet as a hy-
ponym of one of the constituents. While the ex-
pected correlation was not attested, we suspect this
</bodyText>
<page confidence="0.998337">
13
</page>
<bodyText confidence="0.999964258064516">
to be more an indication of the inappropriateness
of the evaluation used than of the faultiness of the
general approach.
Lin, Baldwin et al., and Schone &amp; Jurafsky, all
use as their gold standard either idiom dictionaries
or WordNet (Fellbaum, 1998). While Schone &amp;
Jurafsky show that WordNet is as good a standard
as any of a number of machine readable dictionar-
ies, none of these authors shows that the MWEs
that appear in WordNet (or in the MRDs) are gen-
erally non-compositional, in the relevant sense. As
noted by Sag et al. (2002) many MWEs are sim-
ply “institutionalized phrases” whose meanings
are perfectly compositional, but whose frequency
of use (or other non-linguistic factors) make them
highly salient. It is certainly clear that many
MWEs that appear in WordNet—examples being
law student, medical student, college man—are
perfectly compositional semantically.
Zhai (1997), in an early attempt to apply
statistical methods to the extraction of non-
compositional MWEs, made use of what we take
to be a more appropriate evaluation metric. In his
comparison among a number of different heuris-
tics for identifying non-compositional noun-noun
compounds, Zhai did his evaluation by applying
each heuristic to a corpus of items hand-classified
as to their compositionality. Although Zhai’s clas-
sification appears to be problematic, we take this
to be the appropirate paradigm for evaluation in
this domain, and we adopt it here.
</bodyText>
<sectionHeader confidence="0.99462" genericHeader="method">
3 Proceedure
</sectionHeader>
<bodyText confidence="0.9996282">
In our work we made use of the Word Space
model of (semantic) similiarty (Sch¨utze, 1998)
and extended it slightly to MWEs. In this frame-
work, “meaning” is modeled as an n-dimensional
vector, derived via singular value decomposition
(Deerwester et al., 1990) from word co-occurrence
counts for the expression in question, a technique
frequently referred to as Latent Semantic Analysis
(LSA). This kind of dimensionality reduction has
been shown to improve performance in a number
of text-based domains (Berry et al., 1999).
For our experiments we used a local German
newspaper corpus.2 We built our LSA model
with the Infomap Software package.3, using the
1000 most frequent words not on the 102-word
</bodyText>
<footnote confidence="0.930241666666667">
2S¨uddeutsche Zeitung (SZ) corpus for 2003 with about 42
million words.
3Available from infomap.stanford.edu.
</footnote>
<figureCaption confidence="0.999769">
Figure 1: Two dimensional Word Space
</figureCaption>
<bodyText confidence="0.999913714285714">
hand-generated stop list as the content-bearing di-
mension words (the columns of the matrix). The
20,000 most frequent content words were assigned
row values by counting occurrences within a 30-
word window. SVD was used to reduce the di-
mensionality from 1000 to 100, resulting in 100
dimensional “meaning”-vectors for each word. In
our experiments, MWEs were assigned meaning-
vectors as a whole, using the same proceedure.
For meaning similarity we adopt the standard mea-
sure of cosine of the angle between two vectors
(the normalized correlation coefficient) as a met-
ric (Sch¨utze, 1998; Baeza-Yates and Ribeiro-Neto,
1999). On this metric, two expressions are taken
to be unrelated if their meaning vectors are orthog-
onal (the cosine is 0) and synonymous if their vec-
tors are parallel (the cosine is 1).
Figure 1 illustrates such a vector space in two
dimensions. Note that the meaning vector for
L¨offel ‘spoon’ is quite similar to that for es-
sen ‘to eat’ but distant from sterben ‘to die’,
while the meaning vector for the MWE den L¨offel
abgeben is close to that for sterben. Indeed den
L¨offel abgeben, like to kick the bucket, is a non-
compositional idiom meaning ‘to die’.
While den L¨offel abgeben is used almost ex-
clusively in its idiomatic sense (all four occur-
rences in our corpus), many MWEs are used reg-
ularly in both their idiomatic and in their literal
senses. About two thirds of the uses of the MWE
ins Wasser fallen in our corpus are idiomatic uses,
and the remaing one third are literal uses. In
our first experiment we tested the hypothesis that
these uses could reliably be distinguished using
distribution-based models of their meaning.
</bodyText>
<page confidence="0.993784">
14
</page>
<subsectionHeader confidence="0.995523">
3.1 Experiment I
</subsectionHeader>
<bodyText confidence="0.963712479166667">
For this experiment we manually annotated the
67 occurrences of ins Wasser fallen in our cor-
pus as to whether the expression was used com-
positionally (literally) or non-compositionally (id-
iomatically).4 Marking this distinction we gen-
erate an LSA meaning vectors for the composi-
tional uses and an LSA meaning vector for the
non-compositional uses of ins Wasser fallen. The
vectors turned out, as expected, to be almost or-
thogonal, with a cosine of the angle between them
of 0.02. This result confirms that the linguis-
tic contexts in which the literal and the idiomatic
use of ins Wasser fallen appear are very differ-
ent, indicating—not surprisingly—that the seman-
tic difference between the literal meaning and the
idiomatic meaning is reflected in the way these
these phrases are used.
Our next task was to investigate whether this
difference could be used in particular cases to de-
termine what the intended use of an MWE in a
particular context was. To evaluate this, we did a
10-fold cross-validation study, calculating the lit-
eral and idiomatic vectors for ins Wasser fallen on
the basis of the training data and doing a simple
nearest neighbor classification of each memember
of the test set on the basis of the meaning vectors
computed from its local context (the 30 word win-
dow). Our result of an average accurace of 72%
for our LSA-based classifier far exceeds the sim-
ple maximum-likelihood baseline of 58%.
In the final part of this experiment we compared
the meaning vector that was computed by sum-
ming over all uses of ins Wasser fallen with the
literal and idiomatic vectors from above. Since id-
iomatic uses of ins Wasserfallen prevail in the cor-
pus (2/3 vs. 1/3), it is not surprisingly that the sim-
ilarity to the literal vector (0.0946) is much than
similarity to the idiomatic vector (0.3712).
To summarize Experiment I, which is a vari-
ant of a supervised phrase sense disambiguation
task, demonstrates that we can use LSA to distin-
guish between literal and the idiomatic usage of an
MWE by using local linguistic context.
4This was a straightforward task; two annotators anno-
tated independently, with very high agreement—kappa score
of over 0.95 (Carletta, 1996). Occurrences on which the an-
notators disagreed were thrown out. Of the 64 occurrences
we used, 37 were idiomatic and 27 were literal.
</bodyText>
<subsectionHeader confidence="0.994313">
3.2 Experiment II
</subsectionHeader>
<bodyText confidence="0.999984288888889">
In our second experiment we sought to make
use of the fact that there are typically clear
distributional difference between compositional
and non-compositional uses of MWEs to deter-
mine whether a given MWE indeed has non-
compositional uses at all. In this experi-
ment we made use of a test set of German
Preposition-Noun-Verb “collocation candidate”
database whose extraction is described by Krenn
(2000) and which has been made available elec-
tronically.5 From this database only word com-
binations with frequency of occurrence more than
30 in our test corpus were considered. Our task
was to classify these 81 potential MWEs accord-
ing whether or not thay have an idiomatic mean-
ing.
To accomplish this task we took the following
approach. We computed on the basis of the dis-
tribution of the components of the MWE an esti-
mate for the compositional meaning vector for the
MWE. We then compared this to the actual vec-
tor for the MWE as a whole, with the expecta-
tion MWEs which indeed have non-compositinoal
uses will be distinguished by a relatively low vec-
tor similarity between the estimated compositional
meaning vector and the actual meaning vector.
In other words small similarity values should be
diagnostic for the presense of non-compositinoal
uses of the MWE.
We calculated the estimated compositional
meaning vector by taking it to be the sum of the
meaning vector of the parts, i.e., the compositional
meaning of an expression w1w2 consisting of two
words is taken to be sum of the meaning vectors
for the constituent words.6 In order to maximize
the independent contribution of the constituent
words, the meaning vectors for these words were
always computed from contexts in which they ap-
pear alone (that is, not in the local context of the
other constituent). We call the estimated composi-
tional meaning vector the “composed” vector.7
The comparisons we made are illustrated in Fig-
ure 2, where vectors for the MWE auf die Strecke
bleiben ‘to fall by the wayside’ and the words
Strecke ‘route’ and bleiben ‘to stay’ are mapped
</bodyText>
<footnote confidence="0.997100666666667">
5Available as an example data collection in UCS-Toolkit
5 from www.collocations.de.
6For all our experiments we consider only two-word com-
binations.
7Schone &amp; Jurafsky (2001) explore a few modest varia-
tions of this estimate.
</footnote>
<page confidence="0.991311">
15
</page>
<figureCaption confidence="0.999894">
Figure 2: Composed versus Multi-Word
</figureCaption>
<bodyText confidence="0.999510263157895">
into two dimensions8. (the words Autobahn ‘high-
way’ and eigenst¨andig ‘independent’ are given for
comparison). Here we see that the linear com-
bination of the component words of the MWE is
clearly distinct from that of the MWE as a whole.
As a further illustration of the difference be-
tween the composed vector and the MWE vector,
in Table 2 we list the words whose meaning vector
is most similar to that of the MWE auf dis Strecke
bleiben along with their similarity values, and in
Table 3 we list those words whose meaning vec-
tor is most similar to the composed vector. The
semantic differences among these two classes are
readily apparent.
0.769663
0.732372
0.731411
0.717294
0.704939
</bodyText>
<tableCaption confidence="0.991686">
Table 1: auf die Strecke bleiben
</tableCaption>
<bodyText confidence="0.5978244">
strecken ‘to lengthen’ 0.743309
fahren ‘to drive’ 0.741059
laufen ‘to run’ 0.726631
fahrt ‘drives’ 0.712352
schließen ‘to close’ 0.704364
</bodyText>
<tableCaption confidence="0.975228">
Table 2: Strecke+bleiben
</tableCaption>
<bodyText confidence="0.999895166666667">
We recognize that the composed vector is
clearly nowhere near a perfect model of compo-
sitional meaning in the general case. This can be
illustrated by considering, for example, the MWE
fire breathing. This expression is clearly com-
positional, as it denotes the process of producing
</bodyText>
<subsectionHeader confidence="0.450007">
8The preposition auf and the article die are on the stop list
</subsectionHeader>
<bodyText confidence="0.999954454545455">
combusting exhalation, exactly what the seman-
tic combination rules of the English would pre-
dict. Nevertheless the distribution of fire breath-
ing is quite unrelated to that of its constituents
fire and breathing ( the former appears frequently
with dragon and circus while the later appear fre-
quently with blaze and lungs, respectively). De-
spite these principled objections, the composed
vector provides a useful baseline for our investiga-
tion. We should note that a number of researchers
in the LSA tradition have attempted to provide
more compelling combinatory functions to cap-
ture the non-linearity of linguistic compositional
interpretation (Kintsch, 2001; Widdows and Pe-
ters, 2003).
As a check we chose, at random, a number of
simple clearly-compositional word combinations
(not from the candidate MWE list). We expected
that on the whole these would evidence a very high
similarity measure when compared with their as-
sociated composed vector, and this is indeed the
case, as shown in Table 1. We also compared
</bodyText>
<table confidence="0.9954615">
vor Gericht verantworten 0.80735103
‘to appear in court’
im Bett liegen 0.76056000
‘to lie in bed’
aus Gef¨angnis entlassen 0.66532673
‘dismiss from prison’
</table>
<tableCaption confidence="0.999342">
Table 3: Non-idiomatic phrases
</tableCaption>
<bodyText confidence="0.999951647058824">
the literal and non-literal vectors for ins Wasser
fallen from the first experiment with the composed
vector, computed out of the meaning vectors for
Wasser and for fallen.9 The difference isn’t large,
but nevertheless the composed vector is more sim-
ilar to the literal vector (cosine of 0.2937) than to
the non-literal vector (cosine of 0.1733).
Extending to the general case, our task was to
compare the composed vector to the actual vec-
tor for all the MWEs in our test set. The result-
ing cosine similarity values range from 0.01 to
0.80. Our hope was that there would be a similar-
ity threshold for distinguishing MWEs that have
non-compositional interpretations from those that
do not. Indeed of the MWEs with a similarity val-
ues of under 0.1, just over half are MWEs which
were hand-annotated to have non-literal uses.10 It
</bodyText>
<footnote confidence="0.984669333333333">
9The preposition ins is on the stop list and plays no role
in the computation.
10The similarity scores for the entire test set are given in
</footnote>
<figure confidence="0.8838362">
folgerung ‘consequence’
eigenst¨andig ‘independent’
langfristiger ‘long-term’
herbeif¨uhren ‘to effect’
ausnahmef¨alle ‘exceptions’
</figure>
<page confidence="0.990546">
16
</page>
<bodyText confidence="0.999294666666667">
used in their idiomatic sense (apparently for hu-
morous effect) particularly frequently in contexts
in which elements of the literal meaning were also
present.11
is clear then that the technique described is, prima
facie, capable of detecting idiomatic MWEs.
</bodyText>
<subsectionHeader confidence="0.927239">
3.3 Evaluation and Discussion
</subsectionHeader>
<bodyText confidence="0.999986934782609">
To evaluate the method, we used the careful man-
ual annotation of the PNV database described by
Krenn (2000) as our gold standard. By adopt-
ing different threshholds for the classification de-
cision, we obtained a range of results (trading off
precision and recall). Table 4 illustrates this range.
The F-score measure is maximized in our ex-
periments by adopting a similarity threshold of
0.2. This means that MWEs which have a mean-
ing vector whose cosine is under this value when
compared with with the combined vector should
be classified as having a non-literal meaning.
To compare our method with that proposed by
Baldwin et al. (2003), we applied their method
to our materials, generating LSA vectors for the
component content words in our candidate MWEs
and comparing their semantic similarity to the
MWEs LSA vector as a whole, with the expecta-
tion being that low similarity between the MWE as
a whole and its component words is indication of
the non-compositionality of the MWE. The results
are given in Table 5.
It is clear that while Baldwin et al.’s expectation
is borne out in the case of the constituent noun
(the non-head), it is not in the case of the con-
stituent verb (the head). Even in the case of the
nouns, however, the results are, for the most part,
markedly inferior to the results we achieved using
the composed vectors.
There are a number of issues that complicate
the workability of the unsupervised technique de-
scribed here. We rely on there being enough
non-compositional uses of an idiomatic MWE in
the corpus that the overall meaning vector for the
MWE reflects this usage. If the literal meaning
is overwhelmingly frequent, this will reduce the
effectivity of the method significantly. A second
problem concerns the relationship between the lit-
eral and the non-literal meaning. Our technique
relies on these meaning being highly distinct. If
the meanings are similar, it is likely that local con-
text will be inadequate to distinguish a composi-
tional from a non-compositional use of the expres-
sion. In our investigation it became apparent, in
fact, that in the newspaper genre, highly idiomatic
expressions such as ins Wasser fallen were often
</bodyText>
<sectionHeader confidence="0.770932" genericHeader="method">
Appendix I.
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999975848484849">
To summarize, in order to classify an MWE as
non-compositional, we compute an approximation
of its compositional meaning and compare this
with the meaning of the expression as it is used
on the whole. One of the obvious improvements
to the algorithm could come from better mod-
els for simulating compositional meaning. A fur-
ther issue that can be explored is whether linguis-
tic preprocessing would influence the results. We
worked only on raw text data. There is some ev-
idence (Baldwin et al., 2003) that part of speech
tagging might improve results in this kind of task.
We also only considered local word sequences.
Certainly some recognition of the syntactic struc-
ture would improve results. These are, however,
more general issues associated with MWE pro-
cessing.
Rather promising results were attained using
only local context, however. Our study shows
that the F-score measure is maximized by taking
as threshold for distinguishing non-compositional
phrases from compositional ones a cosine simi-
larity value somewhere between 0.1-0.2. An im-
portant point to be explored is that compositional-
ity appears to come in degrees. As Bannard and
Lascarides (2003) have noted, MWEs “do not fall
cleanly into the binary classes of compositional
and non-compositional expressions, but populate
a continuum between the two extremes.” While
our experiment was designed to classify MWEs,
the technique described here, of course, provides
a means, if rather a blunt one, for quantifying the
degreee of compositonality of an expression.
</bodyText>
<sectionHeader confidence="0.991182" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.9934406">
Ricardo A. Baeza-Yates and Berthier A. Ribeiro-Neto.
1999. Modern Information Retrieval. ACM Press /
Addison-Wesley.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model
</reference>
<footnote confidence="0.943171666666667">
11One such example from the SZ corpus:
Der Auftakt w¨are allerdings fast ins Wasser gefallen, weil ein
geplatzter Hydrant eine f¨unfzehn Meter hohe Wasserfont¨ane
in die Luft schleuderte.
‘The prelude almost didn’t occur, because a burst hydrant
shot a fifteen-meter high fountain into the sky.’
</footnote>
<page confidence="0.995552">
17
</page>
<table confidence="0.99844175">
cos &lt; 0.1 cos &lt; 0.2 cos &lt; 0.3 cos &lt; 0.4 cos &lt; 0.5
Precision 0.53 0.39 0.29 0.22 0.21
Recall 0.42 0.63 0.84 0.89 0.95
F-measure 0.47 0.48 0.43 0.35 0.34
</table>
<tableCaption confidence="0.99681">
Table 4: Evaluation of Various Similarity Thresholds
</tableCaption>
<table confidence="0.999318333333333">
cos &lt; 0.1 cos &lt; 0.2 cos &lt; 0.3 cos &lt; 0.4 cos &lt; 0.5
Verb F-measure 0.21 0.16 0.29 0.26 0.27
Noun F-measure 0.28 0.51 0.43 0.39 0.33
</table>
<tableCaption confidence="0.99973">
Table 5: Evaluation of Method of Baldwin et al. (2003)
</tableCaption>
<reference confidence="0.973463370370371">
of multiword expression decomposability. In Pro-
ceedings of the ACL-2003 Workshop on Multiword
Expressions: Analysis, Acquisition and Treatment,
pages 89–96, Sapporo, Japan.
Colin Bannard, Timothy Baldwin, and Alex Las-
carides. 2003. A statistical approach to the seman-
tics of verb-particles. In Proceedings of the ACL-
2003 Workshop on Multiword Expressions: Analy-
sis, Acquisition and Treatment, pages 65–72, Sap-
poro, Japan.
Michael W. Berry, Zlatko Drmavc, and Elisabeth R.
Jessup. 1999. Matrices, vector spaces, and infor-
mation retrieval. SIAMReview, 41(2):335–362.
Jean Carletta. 1996. Assessing agreement on classi-
fication tasks: The kappa statistic. Computational
Linguistics, 22(2):249–254.
Scott Cederberg and Dominic Widdows. 2003. Using
LSA and noun coordination information to improve
the precision and recall of automatic hyponymy ex-
traction. In In Seventh Conference on Computa-
tional Natural Language Learning, pages 111–118,
Edmonton, Canada, June.
Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society of Information Science,
41(6):391–407.
Stefan Evert and Hannah Kermes. 2003. Experi-
ments on candidate data for collocation extraction.
In Companion Volume to the Proceedings of the 10th
Conference of The European Chapter of the Associ-
ation for Computational Linguistics, pages 83–86,
Budapest, Hungary.
Stefan Evert and Brigitte Krenn. 2001. Methods for
the qualitative evaluation of lexical association mea-
sures. In Proceedings of the 39th Annual Meeting
of the Association for Computational Linguistics,
pages 188–195, Toulouse, France.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
University of Stuttgart.
Christiane Fellbaum. 1998. WordNet, an electronic
lexical database. MIT Press, Cambridge, MA.
Nancy Ide and Jean V´eronis. 1998. Word sense dis-
ambiguation: The state of the art. Computational
Linguistics, 14(1).
Walter Kintsch. 2001. Predication. Cognitive Science,
25(2):173–202.
Brigitte Krenn. 2000. The Usual Suspects: Data-
Oriented Models for Identification and Representa-
tion of Lexical Collocations. Dissertations in Com-
putational Linguistics and Language Technology.
German Research Center for Artificial Intelligence
and Saarland University, Saarbr¨ucken, Germany.
Thomas K. Landauer and Susan T. Dumais. 1997.
A solution to plato’s problem: The latent seman-
tic analysis theory of the acquisition, induction, and
representation of knowledge. Psychological Review,
104:211–240.
Thomas K. Landauer and Joseph Psotka. 2000. Sim-
ulating text understanding for educational applica-
tions with latent semantic analysis: Introduction to
LSA. Interactive Learning Environments, 8(2):73–
86.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proceedings of the 37th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 317–324, College Park,
MD.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical NaturalLanguage Pro-
cessing. The MIT Press, Cambridge, MA.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann A.
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the 3rd International Conferences on
Intelligent Text Processing and Computational Lin-
guistics, pages 1–15.
Patrick Schone and Daniel Jurafsky. 2001. Is
knowledge-free induction of multiword unit dictio-
nary headwords a solved problem? In Proceedings
</reference>
<page confidence="0.994797">
18
</page>
<reference confidence="0.99676235">
ofEmpirical Methods in Natural Language Process-
ing, Pittsburgh, PA.
Hinrich Sch¨utze. 1998. Automatic word sense dis-
crimination. Computational Linguistics, 24(1):97–
124.
Bego˜na Villada Moir´on and J¨org Tiedemann. 2006.
Identifying idiomatic expressions using automatic
word-alignment. In Proceedings of the EACL 2006
Workshop on Multiword Expressions in a Multilin-
gual Context, Trento, Italy.
Dominic Widdows and Stanley Peters. 2003. Word
vectors and quantum logic: Experiments with nega-
tion and disjunction. In Eighth Mathematics ofLan-
guage Conference, pages 141–150, Bloomington,
Indiana.
Chengxiang Zhai. 1997. Exploiting context to iden-
tify lexical atoms – a statistical view of linguistic
context. In Proceedings of the International and In-
terdisciplinary Conference on Modelling and Using
Context (CONTEXT-97), pages 119–129.
</reference>
<sectionHeader confidence="0.991108" genericHeader="references">
APPENDIX
</sectionHeader>
<bodyText confidence="0.998908">
Similarity (cosine) values for the combined and
the MWE vector. Uppercase entries are those
hand-annotated as being MWEs which have an id-
iomatic interpretation.
</bodyText>
<figure confidence="0.997336105263158">
Word Combinations Cosines
(vor) gericht verantworten 0.80735103
(in) bett liegen 0.76056000
(aus) gef¨angnis entlassen 0.66532673
(zu) verf¨uung stellen 0.60310321
(aus) haft entlassen 0.59105617
(um) prozent steigern 0.55889772
(ZU) KASSE BITTEN 0.526331
(auf) prozent sinken 0.51281725
(IN) TASCHE GREIFEN 0.49350031
(zu) verf¨ugung stehen 0.49236563
(auf) prozent steigen 0.47422122
(um) prozent zulegen 0.47329672
(in) betrieb gehen 0.47262171
(unter) druck geraten 0.44377297
(in) deutschland leben 0.44226071
(um) prozent steigen 0.41498688
(in) rechnung stellen 0.40985534
(von) prozent erreichen 0.39407666
(auf) markt kommen 0.38740534
(unter) druck setzen 0.37822936
(in) vergessenheit geraten 0.36654168
(um) prozent sinken 0.36600216
(in) rente gehen 0.36272313
(zu) einsatz kommen 0.3562527
(zu) schule gehen 0.35595884
(in) frage stellen 0.35406327
(in) frage kommen 0.34714701
(in) luft sprengen 0.34241143
(ZU) GESICHT BEKOMMEN 0.34160325
(vor) gericht ziehen 0.33405685
(in) gang setzen 0.33231573
(in) anspruch nehmen 0.32217044
(auf) prozent erh¨ohen 0.31574088
(um) prozent wachsen 0.3151615
(in) empfang nehmen 0.31420746
(f¨ur) sicherheit sorgen 0.30230156
(zu) ausdruck bringen 0.30001438
(IM) MITTELPUNKT STEHEN 0.29770654
(zu) ruhe kommen 0.29753093
(IM) AUGE BEHALTEN 0.2969367
(in) urlaub fahren 0.29627064
(in) kauf nehmen 0.2947628
(in) pflicht nehmen 0.29470704
(in) h¨ohe treiben 0.29450525
(in) kraft treten 0.29311349
(zu) kenntnis nehmen 0.28969961
(an) start gehen 0.28315812
(auf) markt bringen 0.2800427
(in) ruhe standgehen 0.27575604
(bei) prozent liegen 0.27287073
(um) prozent senken 0.26506203
(UNTER) LUPE NEHMEN 0.2607078
(zu) zug kommen 0.25663165
(zu) ende bringen 0.25210009
(in) brand geraten 0.24819525
( ¨UBER) B ¨UHNE GEHEN 0.24644366
(um) prozent erh¨ohen 0.24058016
(auf) tisch legen 0.23264335
(auf) b¨uhne stehen 0.23136641
(auf) idee kommen 0.23097735
(zu) ende gehen 0.20237252
(auf) spiel setzen 0.20112171
(IM) VORDERGRUND STEHEN 0.18957473
(IN) LEERE LAUFEN 0.18390151
(zu) opfer fallen 0.17724105
(in) gefahr geraten 0.17454816
(in) angriff nehmen 0.1643926
(auer) kontrolle geraten 0.16212899
(IN) HAND NEHMEN 0.15916243
(in) szene setzen 0.15766861
(ZU) SEITE STEHEN 0.14135151
(zu) geltung kommen 0.13119923
(in) geschichte eingehen 0.12458956
(aus) ruhe bringen 0.10973377
(zu) fall bringen 0.10900036
(zu) wehr setzen 0.10652383
(in) griffbekommen 0.10359659
(auf) tisch liegen 0.10011075
(IN) LICHTER SCHEINEN 0.08507655
(zu) sprache kommen 0.08503791
(IM) STICH LASSEN 0.0735844
(unter) beweis stellen 0.06064519
(IM) WEG STEHEN 0.05174435
(AUS) FUGEN GERATEN 0.05103952
(in) erinnerung bleiben 0.04339438
(ZU) WORT KOMMEN 0.03808749
(AUF) STRAßE GEHEN 0.03492515
(AUF) STRECKE BLEIBEN 0.03463844
(auer) kraft setzen 0.0338813
(AUF) WEG BRINGEN 0.03122951
(zu) erfolg f¨uhren 0.02882997
(in) sicherheit bringen 0.02862914
(in) erf¨uhlung gehen 0.01515792
(in) zeitung lesen 0.00354598
</figure>
<page confidence="0.961955">
19
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.652890">
<title confidence="0.9988675">Automatic Identification of Non-Compositional Multi-Word Expressions using Latent Semantic Analysis</title>
<author confidence="0.999726">Graham Katz Eugenie Giesbrecht</author>
<affiliation confidence="0.9988495">Institute of Cognitive Science Institute of Cognitive Science University of Osnabr¨uck University of Osnabr¨uck</affiliation>
<email confidence="0.687868">gkatz@uos.deegiesbre@uos.de</email>
<abstract confidence="0.996545785714286">Making use of latent semantic analysis, we explore the hypothesis that local linguistic context can serve to identify multi-word expressions that have noncompositional meanings. We propose that vector-similarity between distribution vectors associated with an MWE as a whole and those associated with its constitutent parts can serve as a good measure of the degree to which the MWE is compositional. We present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ricardo A Baeza-Yates</author>
<author>Berthier A Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>ACM Press / Addison-Wesley.</publisher>
<contexts>
<context position="11121" citStr="Baeza-Yates and Ribeiro-Neto, 1999" startWordPosition="1729" endWordPosition="1732"> Word Space hand-generated stop list as the content-bearing dimension words (the columns of the matrix). The 20,000 most frequent content words were assigned row values by counting occurrences within a 30- word window. SVD was used to reduce the dimensionality from 1000 to 100, resulting in 100 dimensional “meaning”-vectors for each word. In our experiments, MWEs were assigned meaningvectors as a whole, using the same proceedure. For meaning similarity we adopt the standard measure of cosine of the angle between two vectors (the normalized correlation coefficient) as a metric (Sch¨utze, 1998; Baeza-Yates and Ribeiro-Neto, 1999). On this metric, two expressions are taken to be unrelated if their meaning vectors are orthogonal (the cosine is 0) and synonymous if their vectors are parallel (the cosine is 1). Figure 1 illustrates such a vector space in two dimensions. Note that the meaning vector for L¨offel ‘spoon’ is quite similar to that for essen ‘to eat’ but distant from sterben ‘to die’, while the meaning vector for the MWE den L¨offel abgeben is close to that for sterben. Indeed den L¨offel abgeben, like to kick the bucket, is a noncompositional idiom meaning ‘to die’. While den L¨offel abgeben is used almost exc</context>
</contexts>
<marker>Baeza-Yates, Ribeiro-Neto, 1999</marker>
<rawString>Ricardo A. Baeza-Yates and Berthier A. Ribeiro-Neto. 1999. Modern Information Retrieval. ACM Press / Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="1093" citStr="Baldwin et al., 2003" startWordPosition="151" endWordPosition="154">t vector-similarity between distribution vectors associated with an MWE as a whole and those associated with its constitutent parts can serve as a good measure of the degree to which the MWE is compositional. We present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality. 1 Introduction Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (Evert and Krenn, 2001; Evert and Kermes,</context>
<context position="5586" citStr="Baldwin et al. (2003)" startWordPosition="856" endWordPosition="860"> (Deerwester et al., 1990). Since this technique is often used to model meaning, we will speak in terms of “meaning” similiarity. It should be clear, however, that we are only using the LSA vectors—derived from context of occurrence in a corpus—to model meaning and meaning composition in a very rough way. Our hope is simply that this rough model is sufficient to the task of identifying non-compositional MWEs. 2 Previous work Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutualinformation measures identify such phrases, Baldwin et al. (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moir´on &amp; Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. Schone &amp; Jurafsky (2001) applied LSA to MWE identification, althought they did not focus on distinguishing compositional from non-compositional MWEs. Lin’s goal, like ours, was to discriminate noncompositional MWEs from compositional MWEs. His method was to compare the mutual information measure of the constituents parts of an MWE with the mutual information of si</context>
<context position="7455" citStr="Baldwin et al., (2003)" startWordPosition="1144" endWordPosition="1147">MWEs, showing that, as suggested by Lin’s results, there was need for improvement in this area. Since LSA has been used in a number of meaning-related language tasks to good effect (Landauer and Dumais, 1997; Landauer and Psotka, 2000; Cederberg and Widdows, 2003), they had hoped to improve their results by identify non-compositional expressions using a method similar to that which we are exploring here. Although they do not demonstrate that this method actually identifies non-compositional expressions, they do show that the LSA similarity technique only improves MWE identification minimally. Baldwin et al., (2003) focus more narrowly on distinguishing English noun-noun compounds and verb-particle constructions which are compositional from those which are not compositional. Their approach is methodologically similar to ours, in that they compute similarity on the basis of contexts of occurrance, making use of LSA. Their hypothesis is that high LSA-based similarity between the MWE and each of its constituent parts is indicative of compositionality. They evaluate their technique by assessing the correlation between high semantic similarity of the constituents of an MWE to the MWE as a whole with the likel</context>
<context position="21262" citStr="Baldwin et al. (2003)" startWordPosition="3412" endWordPosition="3415"> method, we used the careful manual annotation of the PNV database described by Krenn (2000) as our gold standard. By adopting different threshholds for the classification decision, we obtained a range of results (trading off precision and recall). Table 4 illustrates this range. The F-score measure is maximized in our experiments by adopting a similarity threshold of 0.2. This means that MWEs which have a meaning vector whose cosine is under this value when compared with with the combined vector should be classified as having a non-literal meaning. To compare our method with that proposed by Baldwin et al. (2003), we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to the MWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE. The results are given in Table 5. It is clear that while Baldwin et al.’s expectation is borne out in the case of the constituent noun (the non-head), it is not in the case of the constituent verb (the head). Even in the case of the nouns, however, the</context>
<context position="23320" citStr="Baldwin et al., 2003" startWordPosition="3759" endWordPosition="3762">t, that in the newspaper genre, highly idiomatic expressions such as ins Wasser fallen were often Appendix I. 4 Conclusion To summarize, in order to classify an MWE as non-compositional, we compute an approximation of its compositional meaning and compare this with the meaning of the expression as it is used on the whole. One of the obvious improvements to the algorithm could come from better models for simulating compositional meaning. A further issue that can be explored is whether linguistic preprocessing would influence the results. We worked only on raw text data. There is some evidence (Baldwin et al., 2003) that part of speech tagging might improve results in this kind of task. We also only considered local word sequences. Certainly some recognition of the syntactic structure would improve results. These are, however, more general issues associated with MWE processing. Rather promising results were attained using only local context, however. Our study shows that the F-score measure is maximized by taking as threshold for distinguishing non-compositional phrases from compositional ones a cosine similarity value somewhere between 0.1-0.2. An important point to be explored is that compositionality </context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verb-particles.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>65--72</pages>
<location>Sapporo, Japan.</location>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verb-particles. In Proceedings of the ACL2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 65–72, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael W Berry</author>
<author>Zlatko Drmavc</author>
<author>Elisabeth R Jessup</author>
</authors>
<title>Matrices, vector spaces, and information retrieval.</title>
<date>1999</date>
<journal>SIAMReview,</journal>
<pages>41--2</pages>
<contexts>
<context position="10172" citStr="Berry et al., 1999" startWordPosition="1581" endWordPosition="1584">to be the appropirate paradigm for evaluation in this domain, and we adopt it here. 3 Proceedure In our work we made use of the Word Space model of (semantic) similiarty (Sch¨utze, 1998) and extended it slightly to MWEs. In this framework, “meaning” is modeled as an n-dimensional vector, derived via singular value decomposition (Deerwester et al., 1990) from word co-occurrence counts for the expression in question, a technique frequently referred to as Latent Semantic Analysis (LSA). This kind of dimensionality reduction has been shown to improve performance in a number of text-based domains (Berry et al., 1999). For our experiments we used a local German newspaper corpus.2 We built our LSA model with the Infomap Software package.3, using the 1000 most frequent words not on the 102-word 2S¨uddeutsche Zeitung (SZ) corpus for 2003 with about 42 million words. 3Available from infomap.stanford.edu. Figure 1: Two dimensional Word Space hand-generated stop list as the content-bearing dimension words (the columns of the matrix). The 20,000 most frequent content words were assigned row values by counting occurrences within a 30- word window. SVD was used to reduce the dimensionality from 1000 to 100, resulti</context>
</contexts>
<marker>Berry, Drmavc, Jessup, 1999</marker>
<rawString>Michael W. Berry, Zlatko Drmavc, and Elisabeth R. Jessup. 1999. Matrices, vector spaces, and information retrieval. SIAMReview, 41(2):335–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="14353" citStr="Carletta, 1996" startWordPosition="2284" endWordPosition="2285">l and idiomatic vectors from above. Since idiomatic uses of ins Wasserfallen prevail in the corpus (2/3 vs. 1/3), it is not surprisingly that the similarity to the literal vector (0.0946) is much than similarity to the idiomatic vector (0.3712). To summarize Experiment I, which is a variant of a supervised phrase sense disambiguation task, demonstrates that we can use LSA to distinguish between literal and the idiomatic usage of an MWE by using local linguistic context. 4This was a straightforward task; two annotators annotated independently, with very high agreement—kappa score of over 0.95 (Carletta, 1996). Occurrences on which the annotators disagreed were thrown out. Of the 64 occurrences we used, 37 were idiomatic and 27 were literal. 3.2 Experiment II In our second experiment we sought to make use of the fact that there are typically clear distributional difference between compositional and non-compositional uses of MWEs to determine whether a given MWE indeed has noncompositional uses at all. In this experiment we made use of a test set of German Preposition-Noun-Verb “collocation candidate” database whose extraction is described by Krenn (2000) and which has been made available electronic</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Cederberg</author>
<author>Dominic Widdows</author>
</authors>
<title>Using LSA and noun coordination information to improve the precision and recall of automatic hyponymy extraction.</title>
<date>2003</date>
<booktitle>In In Seventh Conference on Computational Natural Language Learning,</booktitle>
<pages>111--118</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="7097" citStr="Cederberg and Widdows, 2003" startWordPosition="1092" endWordPosition="1095"> (2.64), would be characteristic of non-compositional MWEs. Although intuitively appealing, Lin’s algorithm only achieves precision and recall of 15.7% and 13.7%, respectively (as compared to a gold standard generate from an idiom dictionary—but see below for discussion). Schone &amp; Jurafsky (2001) evaluated a number of co-occurrence-based metrics for identifying MWEs, showing that, as suggested by Lin’s results, there was need for improvement in this area. Since LSA has been used in a number of meaning-related language tasks to good effect (Landauer and Dumais, 1997; Landauer and Psotka, 2000; Cederberg and Widdows, 2003), they had hoped to improve their results by identify non-compositional expressions using a method similar to that which we are exploring here. Although they do not demonstrate that this method actually identifies non-compositional expressions, they do show that the LSA similarity technique only improves MWE identification minimally. Baldwin et al., (2003) focus more narrowly on distinguishing English noun-noun compounds and verb-particle constructions which are compositional from those which are not compositional. Their approach is methodologically similar to ours, in that they compute simila</context>
</contexts>
<marker>Cederberg, Widdows, 2003</marker>
<rawString>Scott Cederberg and Dominic Widdows. 2003. Using LSA and noun coordination information to improve the precision and recall of automatic hyponymy extraction. In In Seventh Conference on Computational Natural Language Learning, pages 111–118, Edmonton, Canada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="4991" citStr="Deerwester et al., 1990" startWordPosition="761" endWordPosition="764">nt words appear than do non-compositional MWEs. In this paper we describe two experiments that test this hypothesis. In the first experiment we seek to confirm that the local context of a known idiom can reliably distinguish idiomatic uses from non-idiomatic uses. In the second experiment we attempt to determine whether the difference between the contexts in which an MWE appears and the contexts in which its component words appear can indeed serve to tell us whether the MWE has an idiomatic use. In our experiments we make use of lexical semantic analysis (LSA) as a model of contextsimilarity (Deerwester et al., 1990). Since this technique is often used to model meaning, we will speak in terms of “meaning” similiarity. It should be clear, however, that we are only using the LSA vectors—derived from context of occurrence in a corpus—to model meaning and meaning composition in a very rough way. Our hope is simply that this rough model is sufficient to the task of identifying non-compositional MWEs. 2 Previous work Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutualinformation measures identify such phrases, Baldwin et al. (2003), who</context>
<context position="9908" citStr="Deerwester et al., 1990" startWordPosition="1541" endWordPosition="1544"> of different heuristics for identifying non-compositional noun-noun compounds, Zhai did his evaluation by applying each heuristic to a corpus of items hand-classified as to their compositionality. Although Zhai’s classification appears to be problematic, we take this to be the appropirate paradigm for evaluation in this domain, and we adopt it here. 3 Proceedure In our work we made use of the Word Space model of (semantic) similiarty (Sch¨utze, 1998) and extended it slightly to MWEs. In this framework, “meaning” is modeled as an n-dimensional vector, derived via singular value decomposition (Deerwester et al., 1990) from word co-occurrence counts for the expression in question, a technique frequently referred to as Latent Semantic Analysis (LSA). This kind of dimensionality reduction has been shown to improve performance in a number of text-based domains (Berry et al., 1999). For our experiments we used a local German newspaper corpus.2 We built our LSA model with the Infomap Software package.3, using the 1000 most frequent words not on the 102-word 2S¨uddeutsche Zeitung (SZ) corpus for 2003 with about 42 million words. 3Available from infomap.stanford.edu. Figure 1: Two dimensional Word Space hand-gener</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society of Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Hannah Kermes</author>
</authors>
<title>Experiments on candidate data for collocation extraction.</title>
<date>2003</date>
<booktitle>In Companion Volume to the Proceedings of the 10th Conference of The European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>83--86</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1699" citStr="Evert and Kermes, 2003" startWordPosition="231" endWordPosition="234">dwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (Evert and Krenn, 2001; Evert and Kermes, 2003), other techniques must be used to determining whether or not a particular MWE does, in fact, have an idiomatic use. In this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for doing this. We characterize our task on analogy with wordsense disambiguation (Sch¨utze, 1998; Ide and V´eronis, 1998). As noted by Sch¨utze, WSD involves two related tasks: the general task of sense discrimination—determining what senses a given word has—and the more specific task of sense selection—determining for a partic</context>
</contexts>
<marker>Evert, Kermes, 2003</marker>
<rawString>Stefan Evert and Hannah Kermes. 2003. Experiments on candidate data for collocation extraction. In Companion Volume to the Proceedings of the 10th Conference of The European Chapter of the Association for Computational Linguistics, pages 83–86, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>188--195</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="1358" citStr="Evert and Krenn, 2001" startWordPosition="184" endWordPosition="187">larity does, in fact, correlate with non-compositionality. 1 Introduction Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (Evert and Krenn, 2001; Evert and Kermes, 2003), other techniques must be used to determining whether or not a particular MWE does, in fact, have an idiomatic use. In this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose </context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 188–195, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="1372" citStr="Evert, 2004" startWordPosition="188" endWordPosition="189">orrelate with non-compositionality. 1 Introduction Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (Evert and Krenn, 2001; Evert and Kermes, 2003), other techniques must be used to determining whether or not a particular MWE does, in fact, have an idiomatic use. In this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. The Statistics of Word Cooccurrences: Word Pairs and Collocations. Ph.D. thesis, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet, an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="8451" citStr="Fellbaum, 1998" startWordPosition="1311" endWordPosition="1312"> of its constituent parts is indicative of compositionality. They evaluate their technique by assessing the correlation between high semantic similarity of the constituents of an MWE to the MWE as a whole with the likelihood that the MWE appears in WordNet as a hyponym of one of the constituents. While the expected correlation was not attested, we suspect this 13 to be more an indication of the inappropriateness of the evaluation used than of the faultiness of the general approach. Lin, Baldwin et al., and Schone &amp; Jurafsky, all use as their gold standard either idiom dictionaries or WordNet (Fellbaum, 1998). While Schone &amp; Jurafsky show that WordNet is as good a standard as any of a number of machine readable dictionaries, none of these authors shows that the MWEs that appear in WordNet (or in the MRDs) are generally non-compositional, in the relevant sense. As noted by Sag et al. (2002) many MWEs are simply “institutionalized phrases” whose meanings are perfectly compositional, but whose frequency of use (or other non-linguistic factors) make them highly salient. It is certainly clear that many MWEs that appear in WordNet—examples being law student, medical student, college man—are perfectly co</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet, an electronic lexical database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean V´eronis</author>
</authors>
<title>Word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>1</issue>
<marker>Ide, V´eronis, 1998</marker>
<rawString>Nancy Ide and Jean V´eronis. 1998. Word sense disambiguation: The state of the art. Computational Linguistics, 14(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
</authors>
<date>2001</date>
<journal>Predication. Cognitive Science,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="18690" citStr="Kintsch, 2001" startWordPosition="2996" endWordPosition="2997">ic combination rules of the English would predict. Nevertheless the distribution of fire breathing is quite unrelated to that of its constituents fire and breathing ( the former appears frequently with dragon and circus while the later appear frequently with blaze and lungs, respectively). Despite these principled objections, the composed vector provides a useful baseline for our investigation. We should note that a number of researchers in the LSA tradition have attempted to provide more compelling combinatory functions to capture the non-linearity of linguistic compositional interpretation (Kintsch, 2001; Widdows and Peters, 2003). As a check we chose, at random, a number of simple clearly-compositional word combinations (not from the candidate MWE list). We expected that on the whole these would evidence a very high similarity measure when compared with their associated composed vector, and this is indeed the case, as shown in Table 1. We also compared vor Gericht verantworten 0.80735103 ‘to appear in court’ im Bett liegen 0.76056000 ‘to lie in bed’ aus Gef¨angnis entlassen 0.66532673 ‘dismiss from prison’ Table 3: Non-idiomatic phrases the literal and non-literal vectors for ins Wasser fall</context>
</contexts>
<marker>Kintsch, 2001</marker>
<rawString>Walter Kintsch. 2001. Predication. Cognitive Science, 25(2):173–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
</authors>
<title>The Usual Suspects: DataOriented Models for Identification and Representation of Lexical Collocations.</title>
<date>2000</date>
<booktitle>Dissertations in Computational Linguistics and Language Technology. German Research Center for Artificial Intelligence</booktitle>
<institution>and Saarland University,</institution>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="14908" citStr="Krenn (2000)" startWordPosition="2374" endWordPosition="2375"> high agreement—kappa score of over 0.95 (Carletta, 1996). Occurrences on which the annotators disagreed were thrown out. Of the 64 occurrences we used, 37 were idiomatic and 27 were literal. 3.2 Experiment II In our second experiment we sought to make use of the fact that there are typically clear distributional difference between compositional and non-compositional uses of MWEs to determine whether a given MWE indeed has noncompositional uses at all. In this experiment we made use of a test set of German Preposition-Noun-Verb “collocation candidate” database whose extraction is described by Krenn (2000) and which has been made available electronically.5 From this database only word combinations with frequency of occurrence more than 30 in our test corpus were considered. Our task was to classify these 81 potential MWEs according whether or not thay have an idiomatic meaning. To accomplish this task we took the following approach. We computed on the basis of the distribution of the components of the MWE an estimate for the compositional meaning vector for the MWE. We then compared this to the actual vector for the MWE as a whole, with the expectation MWEs which indeed have non-compositinoal u</context>
<context position="20733" citStr="Krenn (2000)" startWordPosition="3325" endWordPosition="3326"> in the computation. 10The similarity scores for the entire test set are given in folgerung ‘consequence’ eigenst¨andig ‘independent’ langfristiger ‘long-term’ herbeif¨uhren ‘to effect’ ausnahmef¨alle ‘exceptions’ 16 used in their idiomatic sense (apparently for humorous effect) particularly frequently in contexts in which elements of the literal meaning were also present.11 is clear then that the technique described is, prima facie, capable of detecting idiomatic MWEs. 3.3 Evaluation and Discussion To evaluate the method, we used the careful manual annotation of the PNV database described by Krenn (2000) as our gold standard. By adopting different threshholds for the classification decision, we obtained a range of results (trading off precision and recall). Table 4 illustrates this range. The F-score measure is maximized in our experiments by adopting a similarity threshold of 0.2. This means that MWEs which have a meaning vector whose cosine is under this value when compared with with the combined vector should be classified as having a non-literal meaning. To compare our method with that proposed by Baldwin et al. (2003), we applied their method to our materials, generating LSA vectors for </context>
</contexts>
<marker>Krenn, 2000</marker>
<rawString>Brigitte Krenn. 2000. The Usual Suspects: DataOriented Models for Identification and Representation of Lexical Collocations. Dissertations in Computational Linguistics and Language Technology. German Research Center for Artificial Intelligence and Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to plato’s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<pages>104--211</pages>
<contexts>
<context position="7040" citStr="Landauer and Dumais, 1997" startWordPosition="1084" endWordPosition="1087">n: 5.87) compared to yellow tape (3.75) or orange tape (2.64), would be characteristic of non-compositional MWEs. Although intuitively appealing, Lin’s algorithm only achieves precision and recall of 15.7% and 13.7%, respectively (as compared to a gold standard generate from an idiom dictionary—but see below for discussion). Schone &amp; Jurafsky (2001) evaluated a number of co-occurrence-based metrics for identifying MWEs, showing that, as suggested by Lin’s results, there was need for improvement in this area. Since LSA has been used in a number of meaning-related language tasks to good effect (Landauer and Dumais, 1997; Landauer and Psotka, 2000; Cederberg and Widdows, 2003), they had hoped to improve their results by identify non-compositional expressions using a method similar to that which we are exploring here. Although they do not demonstrate that this method actually identifies non-compositional expressions, they do show that the LSA similarity technique only improves MWE identification minimally. Baldwin et al., (2003) focus more narrowly on distinguishing English noun-noun compounds and verb-particle constructions which are compositional from those which are not compositional. Their approach is meth</context>
<context position="3738" citStr="Landauer &amp; Dumais (1997)" startWordPosition="554" endWordPosition="558">opening of the skatepark was cancelled’ The discrimination task, then, is to identify ins Wasser fallen as an MWE that has an idiomatic meaning and the selection task is to determine that 1Examples taken from a newspaper corpus of the German S¨uddeutsche Zeitung (1994-2000) 12 Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 12–19, Sydney, July 2006. c�2006 Association for Computational Linguistics in (1) it is the compositional meaning that is intended, while in (2) it is the non-compositional meaning. Following Sch¨utze (1998) and Landauer &amp; Dumais (1997) our general assumption is that the meaning of an expression can be modelled in terms of the words that it co-occurs with: its co-occurrence signature. To determine whether a phrase has a non-compositional meaning we compute whether the co-occurrence signature of the phrase is systematically related to the cooccurrence signatures of its parts. Our hypothesis is that a systematic relationship is indicative of compositional interpretation and lack of a systematic relationship is symptomatic of noncompositionality. In other words, we expect compositional MWEs to appear in contexts more similar to</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K. Landauer and Susan T. Dumais. 1997. A solution to plato’s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge. Psychological Review, 104:211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Joseph Psotka</author>
</authors>
<title>Simulating text understanding for educational applications with latent semantic analysis: Introduction to LSA. Interactive Learning Environments,</title>
<date>2000</date>
<volume>8</volume>
<issue>2</issue>
<pages>86</pages>
<contexts>
<context position="7067" citStr="Landauer and Psotka, 2000" startWordPosition="1088" endWordPosition="1091"> tape (3.75) or orange tape (2.64), would be characteristic of non-compositional MWEs. Although intuitively appealing, Lin’s algorithm only achieves precision and recall of 15.7% and 13.7%, respectively (as compared to a gold standard generate from an idiom dictionary—but see below for discussion). Schone &amp; Jurafsky (2001) evaluated a number of co-occurrence-based metrics for identifying MWEs, showing that, as suggested by Lin’s results, there was need for improvement in this area. Since LSA has been used in a number of meaning-related language tasks to good effect (Landauer and Dumais, 1997; Landauer and Psotka, 2000; Cederberg and Widdows, 2003), they had hoped to improve their results by identify non-compositional expressions using a method similar to that which we are exploring here. Although they do not demonstrate that this method actually identifies non-compositional expressions, they do show that the LSA similarity technique only improves MWE identification minimally. Baldwin et al., (2003) focus more narrowly on distinguishing English noun-noun compounds and verb-particle constructions which are compositional from those which are not compositional. Their approach is methodologically similar to our</context>
</contexts>
<marker>Landauer, Psotka, 2000</marker>
<rawString>Thomas K. Landauer and Joseph Psotka. 2000. Simulating text understanding for educational applications with latent semantic analysis: Introduction to LSA. Interactive Learning Environments, 8(2):73– 86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>317--324</pages>
<location>College Park, MD.</location>
<contexts>
<context position="1071" citStr="Lin, 1999" startWordPosition="149" endWordPosition="150">propose that vector-similarity between distribution vectors associated with an MWE as a whole and those associated with its constitutent parts can serve as a good measure of the degree to which the MWE is compositional. We present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality. 1 Introduction Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures (Evert and Krenn, 2</context>
<context position="5504" citStr="Lin (1999)" startWordPosition="846" endWordPosition="847"> use of lexical semantic analysis (LSA) as a model of contextsimilarity (Deerwester et al., 1990). Since this technique is often used to model meaning, we will speak in terms of “meaning” similiarity. It should be clear, however, that we are only using the LSA vectors—derived from context of occurrence in a corpus—to model meaning and meaning composition in a very rough way. Our hope is simply that this rough model is sufficient to the task of identifying non-compositional MWEs. 2 Previous work Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutualinformation measures identify such phrases, Baldwin et al. (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moir´on &amp; Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. Schone &amp; Jurafsky (2001) applied LSA to MWE identification, althought they did not focus on distinguishing compositional from non-compositional MWEs. Lin’s goal, like ours, was to discriminate noncompositional MWEs from compositional MWEs. His method was to compare the mutual informa</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 317–324, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of Statistical NaturalLanguage Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical NaturalLanguage Processing. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann A Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conferences on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="957" citStr="Sag et al., 2002" startWordPosition="129" endWordPosition="132">thesis that local linguistic context can serve to identify multi-word expressions that have noncompositional meanings. We propose that vector-similarity between distribution vectors associated with an MWE as a whole and those associated with its constitutent parts can serve as a good measure of the degree to which the MWE is compositional. We present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality. 1 Introduction Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (Sag et al., 2002), and significant attention has been paid to practical methods for solving this problem in recent years (Lin, 1999; Baldwin et al., 2003; Villada Moir´on and Tiedemann, 2006). While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated (Evert and Krenn, 2001; Evert, 2004), it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions (Manning and Sch¨utze, 1999, Ch. 5). While expressions which may po</context>
<context position="8737" citStr="Sag et al. (2002)" startWordPosition="1362" endWordPosition="1365">constituents. While the expected correlation was not attested, we suspect this 13 to be more an indication of the inappropriateness of the evaluation used than of the faultiness of the general approach. Lin, Baldwin et al., and Schone &amp; Jurafsky, all use as their gold standard either idiom dictionaries or WordNet (Fellbaum, 1998). While Schone &amp; Jurafsky show that WordNet is as good a standard as any of a number of machine readable dictionaries, none of these authors shows that the MWEs that appear in WordNet (or in the MRDs) are generally non-compositional, in the relevant sense. As noted by Sag et al. (2002) many MWEs are simply “institutionalized phrases” whose meanings are perfectly compositional, but whose frequency of use (or other non-linguistic factors) make them highly salient. It is certainly clear that many MWEs that appear in WordNet—examples being law student, medical student, college man—are perfectly compositional semantically. Zhai (1997), in an early attempt to apply statistical methods to the extraction of noncompositional MWEs, made use of what we take to be a more appropriate evaluation metric. In his comparison among a number of different heuristics for identifying non-composit</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann A. Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the 3rd International Conferences on Intelligent Text Processing and Computational Linguistics, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Is knowledge-free induction of multiword unit dictionary headwords a solved problem?</title>
<date>2001</date>
<booktitle>In Proceedings ofEmpirical Methods in Natural Language Processing,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="5844" citStr="Schone &amp; Jurafsky (2001)" startWordPosition="900" endWordPosition="903">eaning and meaning composition in a very rough way. Our hope is simply that this rough model is sufficient to the task of identifying non-compositional MWEs. 2 Previous work Recent work which attempts to discriminate between compositional and non-compositional MWEs include Lin (1999), who used mutualinformation measures identify such phrases, Baldwin et al. (2003), who compare the distribution of the head of the MWE with the distribution of the entire MWE, and Vallada Moir´on &amp; Tiedemann (2006), who use a word-alignment strategy to identify non-compositional MWEs making use of parallel texts. Schone &amp; Jurafsky (2001) applied LSA to MWE identification, althought they did not focus on distinguishing compositional from non-compositional MWEs. Lin’s goal, like ours, was to discriminate noncompositional MWEs from compositional MWEs. His method was to compare the mutual information measure of the constituents parts of an MWE with the mutual information of similar expressions obtained by substituting one of the constituents with a related word obtained by thesaurus lookup. The hope was that a significant difference between these measures, as in the case of red tape (mutual information: 5.87) compared to yellow t</context>
<context position="16713" citStr="Schone &amp; Jurafsky (2001)" startWordPosition="2675" endWordPosition="2678"> the constituent words, the meaning vectors for these words were always computed from contexts in which they appear alone (that is, not in the local context of the other constituent). We call the estimated compositional meaning vector the “composed” vector.7 The comparisons we made are illustrated in Figure 2, where vectors for the MWE auf die Strecke bleiben ‘to fall by the wayside’ and the words Strecke ‘route’ and bleiben ‘to stay’ are mapped 5Available as an example data collection in UCS-Toolkit 5 from www.collocations.de. 6For all our experiments we consider only two-word combinations. 7Schone &amp; Jurafsky (2001) explore a few modest variations of this estimate. 15 Figure 2: Composed versus Multi-Word into two dimensions8. (the words Autobahn ‘highway’ and eigenst¨andig ‘independent’ are given for comparison). Here we see that the linear combination of the component words of the MWE is clearly distinct from that of the MWE as a whole. As a further illustration of the difference between the composed vector and the MWE vector, in Table 2 we list the words whose meaning vector is most similar to that of the MWE auf dis Strecke bleiben along with their similarity values, and in Table 3 we list those words</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Patrick Schone and Daniel Jurafsky. 2001. Is knowledge-free induction of multiword unit dictionary headwords a solved problem? In Proceedings ofEmpirical Methods in Natural Language Processing, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>124</pages>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97– 124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bego˜na Villada Moir´on</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Identifying idiomatic expressions using automatic word-alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop on Multiword Expressions in a Multilingual Context,</booktitle>
<location>Trento, Italy.</location>
<marker>Moir´on, Tiedemann, 2006</marker>
<rawString>Bego˜na Villada Moir´on and J¨org Tiedemann. 2006. Identifying idiomatic expressions using automatic word-alignment. In Proceedings of the EACL 2006 Workshop on Multiword Expressions in a Multilingual Context, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Stanley Peters</author>
</authors>
<title>Word vectors and quantum logic: Experiments with negation and disjunction.</title>
<date>2003</date>
<booktitle>In Eighth Mathematics ofLanguage Conference,</booktitle>
<pages>141--150</pages>
<location>Bloomington, Indiana.</location>
<contexts>
<context position="18717" citStr="Widdows and Peters, 2003" startWordPosition="2998" endWordPosition="3002">rules of the English would predict. Nevertheless the distribution of fire breathing is quite unrelated to that of its constituents fire and breathing ( the former appears frequently with dragon and circus while the later appear frequently with blaze and lungs, respectively). Despite these principled objections, the composed vector provides a useful baseline for our investigation. We should note that a number of researchers in the LSA tradition have attempted to provide more compelling combinatory functions to capture the non-linearity of linguistic compositional interpretation (Kintsch, 2001; Widdows and Peters, 2003). As a check we chose, at random, a number of simple clearly-compositional word combinations (not from the candidate MWE list). We expected that on the whole these would evidence a very high similarity measure when compared with their associated composed vector, and this is indeed the case, as shown in Table 1. We also compared vor Gericht verantworten 0.80735103 ‘to appear in court’ im Bett liegen 0.76056000 ‘to lie in bed’ aus Gef¨angnis entlassen 0.66532673 ‘dismiss from prison’ Table 3: Non-idiomatic phrases the literal and non-literal vectors for ins Wasser fallen from the first experimen</context>
</contexts>
<marker>Widdows, Peters, 2003</marker>
<rawString>Dominic Widdows and Stanley Peters. 2003. Word vectors and quantum logic: Experiments with negation and disjunction. In Eighth Mathematics ofLanguage Conference, pages 141–150, Bloomington, Indiana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
</authors>
<title>Exploiting context to identify lexical atoms – a statistical view of linguistic context.</title>
<date>1997</date>
<booktitle>In Proceedings of the International and Interdisciplinary Conference on Modelling and Using Context (CONTEXT-97),</booktitle>
<pages>119--129</pages>
<contexts>
<context position="9088" citStr="Zhai (1997)" startWordPosition="1412" endWordPosition="1413">show that WordNet is as good a standard as any of a number of machine readable dictionaries, none of these authors shows that the MWEs that appear in WordNet (or in the MRDs) are generally non-compositional, in the relevant sense. As noted by Sag et al. (2002) many MWEs are simply “institutionalized phrases” whose meanings are perfectly compositional, but whose frequency of use (or other non-linguistic factors) make them highly salient. It is certainly clear that many MWEs that appear in WordNet—examples being law student, medical student, college man—are perfectly compositional semantically. Zhai (1997), in an early attempt to apply statistical methods to the extraction of noncompositional MWEs, made use of what we take to be a more appropriate evaluation metric. In his comparison among a number of different heuristics for identifying non-compositional noun-noun compounds, Zhai did his evaluation by applying each heuristic to a corpus of items hand-classified as to their compositionality. Although Zhai’s classification appears to be problematic, we take this to be the appropirate paradigm for evaluation in this domain, and we adopt it here. 3 Proceedure In our work we made use of the Word Sp</context>
</contexts>
<marker>Zhai, 1997</marker>
<rawString>Chengxiang Zhai. 1997. Exploiting context to identify lexical atoms – a statistical view of linguistic context. In Proceedings of the International and Interdisciplinary Conference on Modelling and Using Context (CONTEXT-97), pages 119–129.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>