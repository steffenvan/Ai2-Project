<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000443">
<note confidence="0.46418075">
DEFINING NATURAL LANGUAGE GRAMMARS IN GPSG
Eric Sven Ristad
MIT Artificial Intelligence Lab Thinking Machines Corporation
545 Technology Square and 245 First Street
</note>
<copyright confidence="0.145281">
Cambridge, MA 02139 Cambridge, MA 02142
</copyright>
<sectionHeader confidence="0.914262" genericHeader="abstract">
1 Overview
</sectionHeader>
<bodyText confidence="0.999981782608696">
Three central goals of work in the generalized phrase struc-
ture grammar (GPSG) linguistic framework, as stated in the
leading book &amp;quot;Generalized Phrase Structure Grammar&amp;quot; G az-
dar et al (1985) (hereafter GKPS), are: (1) to characterize all
and only the natural language grammars, (2) to algorithmically
determine membership and generative power consequences of
GPSGs, and (3) to embody the universalism of natural lan-
guage entirely in the formal system, rather than by statements
made in it.1
These pages formally consider whether GPSG&apos;s weak context-
free generative power (wcfgp) will allow it to achieve the three
goals. The centerpiece of this paper is a proof that it is unde-
cidable whether an arbitrary GPSG generates the nonnatural
language E*. On the basis of this result, I argue that GPSG
fails to define the natural language grammars, and that the gen-
erative power consequences of the GPSG framework cannot be
algorithmically determined, contrary to goals one and two.2 In
the process, I examine the linguistic universalism of the GPSG
formal system and argue that GPSGs can describe an infinite
class of nonnatural context-free languages. The paper concludes
with a brief diagnosis of the result and suggests that the problem
might be met by abandoning the weak context-free generative
power framework and assuming substantive constraints.
</bodyText>
<subsectionHeader confidence="0.997691">
1.1 The Structure of GPSG Theory
</subsectionHeader>
<bodyText confidence="0.913881510204082">
A generalized phrase structure grammar contains five language-
particular components (immediate dominance (ID) rules, meta-
rules, linear precedence (LP) statements, feature co-occurrence
&apos;GKPS clearly outline their goals. One, &amp;quot;to arrive at a constrained met-
alanguage capable of defining the grammars of natural languages, but not
the grammar of, say, the set of prime numbers.&amp;quot;(p4). Two, to construct
an explicit linguistic theory whose formal consequences are clearly and eas-
ily determinable. These &apos;formal consequences&apos; include both the generative
power consequences demanded by the first goal and membership determi-
nation: GPSG regards languages &amp;quot;as collections whose membership is def-
initely and precisely specifiable.&amp;quot; (p.1) Three, to define a linguistic theory
where &amp;quot;the universalism [of natural language] is, ultimately, intended to be
entirely embodied in the formal system, not expressed by statements made in
it.&amp;quot;(p.4, my emphasis)
2The proof technique make use of invalid computations, and the actual
GPSG constructed is so simple, so similar to the GPSGs proposed for actual
natural languages, and so flexible in its exact formulation that the method of
proof suggests there may be no simple reformulations of GPSG that avoid
this problem. The proof also suggests that it is impossible in principle
to algorithmically determine whether linguistic theories based on a wcfgp
framework (e.g. GPSG) actually define the natural language grammars.
restrictions (FCRs), and feature specification defaults (FSDs))
and four universal components: a theory of syntactic features,
principles of universal feature instantiation, principles of seman-
tic interpretation, and formal relationships among various com-
ponents of the grammar.3
The set of ID rules obtained by taking the finite closure
of the metarules on the ID rules is mapped into local phrase
structure trees, subject to principles of universal feature instan-
tiation, FSDs, FCRs, and LP statements. Finally, these local
trees are assembled to form phrase structure trees, which are
terminated by lexical elements.
The essence of GPSG is the constrained mapping of ID rules
into local trees. The constraints of GPSG theory subdivide
into absolute constraints on local trees (due to FCRs and LP-
statements) and relative constraints on the rule to local tree
mapping (stemming from FSDs and universal feature instan-
tiation). The absolute constraints are all language-particular,
and consequently not inherent in the formal GPSG framework.
Similarly, the relative constraints, of which only universal in-
stantiation is not explicitly language-particular, do not apply
to fully specified ID rules and consequently are not strongly in-
herent in the GPSG framework either.4 In summary, GPSG
local trees are only as constrained as ID rules are: that is, not
at all.
The only constraint strongly inherent in GPSG theory (when
compared to context-free grammars (CFGs)) is finite feature
closure, which limits the number of GPSG nonterminal symbols
to be finite and bounded.3
</bodyText>
<subsectionHeader confidence="0.982587">
1.2 A Nonnatural GPSG
</subsectionHeader>
<bodyText confidence="0.963421733333333">
Consider the exceedingly simple GPSG for the nonnatural lan-
guage E*, consisting solely of the two ID rules
&apos;This work is based on current GPSG theory as presented in GKPS. The
reader is urged to consult that work for a formal presentation and thorough
exposition of current GPSG theory.
41 use &amp;quot;strongly inherent&amp;quot; to mean &amp;quot;unavoidable by virtue of the formal
framework.&amp;quot; Note that the use of problematic feature specifications in
universal feature instantiation means that this constraint is dependent on
other, parochial, components (e.g. FCRs). Appropriate choice of FCRs
or ID rules will abrogate universal feature instantiation, thus rendering it
implicitly language particular too.
&apos;This formal constraint is extremely weak, however, since the theory
of syntactic features licenses more than 10774 syntactic categories. See
Ristad, E.S. (1986), &amp;quot;Computational Complexity of Current GPSG Theory&amp;quot;
in these proceedings for a discussion.
</bodyText>
<page confidence="0.997685">
40
</page>
<sectionHeader confidence="0.538191" genericHeader="method">
S {},H E
</sectionHeader>
<bodyText confidence="0.997973921052632">
This GPSG generates local trees with all possible subcategoriza-
tion specifications — the SUBCAT feature may assume any value
in the non-head daughter of the first ID rule, and S generates
the nonnatural language E.
This exhibit is inconclusive, however. We have only shown
that GKPS — and not GPSG — have failed to achieve the first
goal of GPSG theory. The exhibition leaves open the possibility
of trivially reformalizing GPSG or imposing ad-hoc constraints
on the theory such that I will no longer be able to personally
construct a GPSG for E..
2 Undecidability and Generative Power
in GPSG
That &amp;quot;= E*?&amp;quot; is undecidable for arbitrary context-free gram-
mars is a well-known result in the formal language literature
(see Hoperaft and Ullman(1979:201-203)). The standard proof
is to construct a PDA that accepts all invalid computations of
a TM M. From this PDA an equivalent CFG G is directly con-
structible. Thus, L(G) = E* if and only if all computations of
M are invalid, i.e. L(M) = 0. The latter problem is undecid-
able, so the former must be also.
No such reduction is possible for a proof that &amp;quot;= E*?&amp;quot; is
undecidable for arbitrary GPSGs. In the above reduction, the
number of nonterminals in G is a function of the size of the
simulated TM M. GPSGs, however, have a bounded number
of nonterminal symbols, and as discussed above, that is the
essential difference between CFGs and GPSGs.
Only weak generative power is of interest for the follow-
ing proof, and the formal GPSG constraints on weak generative
power are trivially abrogated. For example, exhaustive constant
partial ordering (ECPO) — which is a constraint on strong gen-
erative capacity — can be done away with for all intents and
purposes by nonterminal renaming, and constraints arising from
principles of universal feature instantiation don&apos;t apply to fully
instantiated ID rules.
First, a proof that &amp;quot;= E*?&amp;quot; is undecidable for context-free
grammars with a very small number of terminal and nonter-
minal symbols is sketched. Following the proof for CFGs, the
equivalent proof for GPSGs is outlined.
</bodyText>
<subsectionHeader confidence="0.975242">
2.1 Outline of a Proof for Small CFGs
</subsectionHeader>
<bodyText confidence="0.997974117647059">
Let L(z,y) be the class of context-free grammars with at least
x nonterminal and y terminal symbols. I now sketch a proof
that it is undecidable of an arbitrary CFG G E L(z,v) whether
L(G) = E* for some x, y greater than fixed lower bounds. The
actual construction details are of no obvious mathematical or
pedagogical interest, and will not be included. The idea is
to directly construct a CFG to generate the invalid computa-
tions of the Universal Turing Machine (UTM). This grammar
will be small if the UTM is small. The &amp;quot;smallest UTM&amp;quot; of
Minsky(1967:276-281) has seven states and a four symbol tape
alphabet, for a state-symbol product of 28 (!). Hence, it is not
surprising that the &amp;quot;smallest GuTm&amp;quot; that generates the invalid
computations of the UTM has seventeen nonterminals and two
terminals.
Observe that if a string w is an invalid computation of the
universal Miring machine M = (Q , E, r,s, go, B, F) on input x,
then one of the following conditions must hold.
</bodyText>
<listItem confidence="0.98882">
1. w has a &amp;quot;syntactic error,&amp;quot; that is, w is not of the form
xi#x2# • • • #x”,,#, where each xi is an instantaneous de-
scription (ID) of M. Therefore, some xi is not an ID of
M.
2. x1 is not initial; that is, x1 V q0E*
3. x„, is not final; that is Zm r. fr.
4. x, 1-w (x1±1)R is false for some odd i
5. (zi)R1-9/4 xi+1 is false for some even i
</listItem>
<bodyText confidence="0.960485068965517">
Straightforward construction of GuTM will result in a CFG
containing on the order of twenty or thirty nonterminals and
at least fifteen terminals (one for each UTM state and tape
symbol, one for the blank-tape symbol, and one for the instan-
taneous description separator &amp;quot;#&amp;quot;). Then the subgrammars
which ensure that (x,)R is false for some even i and
that x, ■-■m. (xj+i)E is false for some odd i may be cleverly
combined so that nonterminals encode more information, and
SO On.
The final trick, due to Albert Meyer, reduces the terminals
to 2 at the cost of a lone nonterminal by encoding the n ter-
minals as log n = k-bit words over the new terminal alphabet
{0, 1}, and adding some rules to ensure that the final grammar
could generate E* and not (E4)*. The productions
N4 0L41L4 0014 01L4 11L4 I ...
are added to the converted CFG GiuTm, which generates a
language of the form
14 0000 I 0001 I 0010 ... I E L4L4
Where 14 generates all symbols of length 4, and N4 gener-
ates all strings not of length 0 mod k, where k = 4 (i.e. all
strings of length 1,2,3 mod 4). Deeper consideration of the ac-
tual GuTm reveals that the N4 nonterminal is also eliminable.
Note that all the preceding efforts to reduce the number of
nonterminals and terminals increase the number of context-free
productions. This symbol-production tradeoff becomes clearer
when one actually constructs Gurm•
Suppose the distinguished start symbol for GUTM is SUTM•
Then we form a new CFG consisting of all productions of the
form
</bodyText>
<page confidence="0.995032">
41
</page>
<figure confidence="0.70894">
S {Q - go}{EP - (M)}{N4 u L4}
and the one production
S SUTM
</figure>
<bodyText confidence="0.995720833333333">
where (M) is the length p encoding of an arbitrary TM M,
and L4, N4 are as defined above.
This ensures that strings whose prefix is &amp;quot;q0(M)&amp;quot; will be
generated starting from S if and only if they are generated start-
ing from Su TM: that is, they are invalid computations of the
UTM on M.
</bodyText>
<subsectionHeader confidence="0.995857">
2.2 Some Details for L(z,5) and GPSG
</subsectionHeader>
<bodyText confidence="0.993872571428571">
Let the nonterminal symbols F ,Q, and E in the following CFG
portion generate the obvious terminal symbols corresponding to
the equivalent UTM sets. B is the terminal blank symbol.
Then, the following sketched CF productions generate the
IDs of M such that x, (xi+i)R is false for some odd i.
The S4 and S5 nonterminals are used to locate the even and
odd i IDs zi of w. Sok generates the language {I&apos; U #}*.
</bodyText>
<equation confidence="0.977750571428571">
S4 rs4 #.55 #SoddSok
S5 S5 #S4 #SevenSok
Sodd -4 Sl#
Si -* rsir s2 s6 I S7
S6 rs6 rss
S7 s,r s2r
S2 EaES311,1&amp;quot;
</equation>
<bodyText confidence="0.944375">
where a t b, both in E
</bodyText>
<equation confidence="0.9974758">
S2 -+ aqbS3{r3 - pca} if b(q,b) = (p, c, R)
aqbS3{F3 - cap} if 5(q,b) = (p, c, L)
S2 -■ aqB#B{r3 - pca} if 8(q, B) = (p, c, R)
aqB#B{F3 - cap} if 5(q, B) = (p, c, L)
S3 -■ rs3r QB#Brr I EB# BF
</equation>
<bodyText confidence="0.999426655172414">
S1 and S2 must generate a false transition for odd i, while S3
need not generate a false transition and is used to pad out the
IDs of w. The nonterminals S6, S7 accept IDs with improperly
different tape lengths. The first S2 production accepts transi-
tions where the tape contents differ in a bad place, the second S2
production accepts invalid transitions other than at the end of
the tape, and the third S2 accepts invalid end of the tape transi-
tions. Note that the last two S2 productions are actually classes
of productions, one for each string in - pca, r3 - cap.....
The GPSG for &amp;quot;= E`?&amp;quot; is constructed in a virtually iden-
tical fashion. Recall that the GPSG formal framework does not
bar us from constructing a grammar equivalent to the CFG just
presented. The ID rules used in the construction will be fully
specified so as to defeat universal feature instantiation, and the
construction will use nonterminal renaming to avoid ECPO.
Let the GPSG category C be fully specified for all features
(the actual values don&apos;t matter) with the exception of, say, the
binary features GER, NEG , NULL and POSS. Arrange those four
features in some canonical order, and let binary strings of length
four represent the values assigned to those features in a given
category. For example, C[0100] represents the category C with
the additional specifications ( [-GER] , [+NEG] , [-NULL]. [-
POSS] ). We replace Sodd by C10000], SI by C[00011, S2 by
C[0010], S3 by C[0011], S6 by C[0100], and S7 by C[01011. The
nonterminal I&apos; is replaced by three symbols of the form C[11x4
one for each linear precedence r conforms too. Similarly, E is
replaced by two symbols of the form C[1004 The ID rules, in
the same order as the CF productions above (with a portion of
the necessary LP statements) are:
</bodyText>
<equation confidence="0.9958728">
C[0000] C[00011#
C[0001] C[1100]C1000110110111 C[0010]1 001001 I C[01011
C101001 -4 C[11001C[0100] C[1100]C[0011]
C101011 C[0101]C[1101] C[00111C[1101)
C10010] -4 C110001aC[1001]C[0011]C[1101]bC[11101
</equation>
<bodyText confidence="0.933525">
where a b, both in E
</bodyText>
<equation confidence="0.998844555555556">
00010] -4 aqbC[0011]{0 - pca} if (q, b) = (p, c, R)
aqbC[00111{F3 - cap} if S(q,b) = (p,c, L)
C[0010] -■ aqB#B{F3 - pca} if .5(q, B) = (p, c, R)
aqB#B{F3 - cap} if 6(q, B) = (p, c, L)
C[0011] C[11001C[00111C[1101]
QB#BC[1100]C[1101]1
C [1000]B# BC [11001
C[1100] &lt; C[0001],C[00111,001001,C[0101] &lt; C[11011
C[1000] &lt; a &lt; C[1001] &lt; C[0011] &lt; C[1110]
</equation>
<bodyText confidence="0.999291333333333">
While the sketched ID rules are not valid GPSG rules, just
as the sketched context-free productions were not the valid com-
ponents of a context-free grammar, a valid GPSG can be con-
structed in a straightforward and obvious manner from the
sketched ID rules. There would be no metarules, FCRs or FSDs
in the actual grammar.
The last comment to be made is that in the actual GUTM,
only the number of productions is a function of the size of the
UTM. The UTM is used only as a convincing crutch — i.e. not
</bodyText>
<construct confidence="0.806993666666667">
at all. Only a small, fixed number of nonterminals are needed to
construct a CFG for the invalid computations of any arbitrary
Turing Machine.
</construct>
<sectionHeader confidence="0.989704" genericHeader="method">
3 Interpreting the Result
</sectionHeader>
<bodyText confidence="0.99996875">
The preceding pages have shown that the extremely simple non-
natural language E* is generated by a GPSG, as is the more
complex language Lic consisting of the invalid computations of
an arbitrary Turing machine on an arbitrary input. Because
</bodyText>
<page confidence="0.997916">
42
</page>
<bodyText confidence="0.992540527777778">
Lic is a GPSG language, &amp;quot;= E*?&amp;quot; is undecidable for GPSGs:
there is no algorithmic way of knowing whether any given GPSG
generates a natural language or an unnatural one. So, for ex-
ample, no algorithm can tell us whether the English GPSG of
GKPS really generates English or E*.
The result suggests that goals 1, 2, 3 and the context-free
framework conflict with each other. Weak context-free gener-
ative power allows both E&amp;quot; and Lw, yet by goal 1 we must
exclude nonnatural languages. Goal 2 demands it be possi-
ble to algorithmically determine whether a given GPSG gener-
ates a desired language or not, yet this cannot be done in the
context-free framework. Lastly, goal 3 requires that all nonnat-
ural languages be excluded on the basis of the formal system
alone, but this looks to be impossible given the other two goals,
the adopted framework, and the technical vagueness of &amp;quot;natural
language grammar.&amp;quot;
The problem can be met in part by abandoning the context-
free framework. Other authors have argued that natural lan-
guage is not context-free, and here we argue that the GPSG
theory of GKPS can characterize context-free languages that
are too simple or trivial to be natural, e.g. any finite or reg-
ular language.6 The context-free framework is both too weak
and too strong — it includes nonnatural languages and excludes
natural ones. Moreover, CFL&apos;s have the wrong formal proper-
ties entirely: natural language is surely not closed under union,
concatenation, Kleene closure, substitution, or intersection with
regular sets!7 In short, the context-free framework is the wrong
idea completely, and this is to be expected: why should the ar-
bitrary generative power classifications of mathematics (formal
language theory) be at all relevant to biology (human language)?
Goal 2, that the naturalness of grammars postulated by.
linguistic theory be decidable, and to a lesser extent goal 3,
are of dubious merit. In my view, substantive constraints aris-
ing from psychology, biology or even physics may be freely in-
voked, with a corresponding change in the meaning of &amp;quot;natural
language grammar&amp;quot; from &amp;quot;mentally-representable grammar&amp;quot; to
something like &amp;quot;easily learnable and speakable mentally-representable
grammar.&amp;quot; There is no a priori reason or empirical evidence to
suggest that the class of mentally representable grammars is not
fantastically complex, maybe not even decidable.8
One promising restriction in this regard, which if properly
formulated would alleviate GPSG&apos;s actual and formal inability
to characterize only the natural language grammars, is strong
nativism — the restrictive theory that the class of natural lan-
&amp;quot;While &apos;natural language grammar&apos; is not defined precisely, recent work
has demonstrated empirically that natural language is not context-free, and
therefore GPSG theory will not be able to characterize all the human lan-
guage grammars. See, for example, Higginbotham(1984), Shieber(1985),
and Culy(1985). For counterarguments, see Pullum(1985). Nash(1980),
chapter 5, discusses the impossibility of accounting for free word order lan-
guages (e.g. Warlpiri) using ID/LP grammars. I focus on the goal of
characterizing only the natural language grammars in this paper.
&apos;The finite, bounded number of nonterminals allowed in GPSG theory
plays a linguistic role in this regard, because the direct consequence of finite
feature closure is that GPSG languages are not truly closed under union,
concatenation, or substitution.
&amp;quot;See Chomsky(1980:120) for a discussion.
guages is finite. This restriction is well motivated both by the
issues raised here and by other empirical considerations.9 The
restriction, which may be substantive or purely formal, is a for-
mal attack on the heart of the result: the theory of undecidabil-
ity is concerned with the existence or nonexistence of algorithms
for solving problems with an infinity of instances. Furthermore,
the restriction may be empirically plausible.16,11
The author does not have a clear idea how GPSG might be
restricted in this manner, and merely suggests strong nativism
as a well-motivated direction for future GPSG research.
Acknowledgments. The author is indebted to Ed Barton,
Robert Berwick, Noam Chomsky, Jim Higginbotham, Richard
Larson, Albert Meyer, and David Waltz for assistance in writ-
ing this paper, and to the MIT Artificial Intelligence Lab and
Thinking Machines Corporation for supporting this research.
</bodyText>
<sectionHeader confidence="0.99828" genericHeader="method">
4 References
</sectionHeader>
<reference confidence="0.917738714285714">
Chomsky, N. (1980) Rules and Representations. New York:
Columbia University Press.
Gazdar, G., E. Klein, G. Pullum, and I. Sag (1985) General-
ized Phrase Structure Grammar. Oxford, England: Basil
Blackwell.
Higginbotham, J. (1984) &amp;quot;English is not a Context-Free Lan-
guage,&amp;quot; Linguistic Inquiry 15: 119-126.
</reference>
<bodyText confidence="0.999231727272727">
&amp;quot;Note that invoking finiteness here is technically different from hiding
intractability with finiteness. Finiteness is the correct generalization here,
because we are interested in whether GPSG generates nonnatural languages
or not, and not in the computational cost of determining the generative
capacity of an arbitrary GPSG. A finiteness restriction for the purposes of
computational complexity is invalid because it prevents us from properly
using the tools of complexity theory to study the computational complexity
of a problem.
&apos;&amp;quot;See Osherson et. al. (1984) for an exposition of strong nativism and
related issues. The theory of strong nativism can be derived in formal
learning theory from three empirically motivated axioms: (1) the ability of
language learners to learn in noisy environments, (2) language learner mem-
ory limitations (e.g. inability to remember long-past utterances), and (3)
the likelihood that language learners choose simple grammars over more
complex, equivalent ones. These formal results are weaker empirically
than they might appear at first glance: the equivalence of &amp;quot;learned&apos; gram-
mars is measured using only weak generative capacity, ignoring uniformity
considerations.
&amp;quot;An alternate substantive constraint, suggested by Higginbotham (per-
sonal communication) and not explored here, is to require natural language
grammars to generate non-dense languages. Let the density of a class of lan-
guages be an upper bound (across all languages in the class) on the ratio
of grammatical utterances to grammatical and ungrammatical utterances,
in terms of utterance lengths. If the density of natural languages was small
or even logarithmic in utterance length, as one might expect, and a decid-
able property of the reformulated GPSG&apos;s, then undecidability of &amp;quot;= E•?&amp;quot;
would no longer reflect on the decidability of whether the GPSG framework
characterized all and only the natural language grammars. The exact spec-
ification of this density constraint is tricky because unit density decides
&amp;quot;= E&amp;quot;?&amp;quot; , and therefore density measurements cannot be too accurate.
Furthermore, E&apos; and Lic can be buried in other languages, i.e. concate-
nated onto the end of an arbitrary (finite or infinite) language, weakening
the accuracy and relevance of density measurements.
</bodyText>
<page confidence="0.999717">
43
</page>
<reference confidence="0.9962292">
Hoperoft, J.E., and J.D. Ullman (1979) Introduction to Au-
tomata Theory, Languages, and Computation. Reading,
MA: Addison-Wesley.
Minsky, M. (1967) Computation: Finite and Infinite Machines.
Englewood Cliffs, NJ: Prentice-Hall.
Nash, D. (1980) &amp;quot;Topics in Warlpiri Grammars,&amp;quot; M.I.T. De-
partment of Linguistics and Philosophy Ph.D dissertation,
Cambridge.
Osherson, D., M. Stob, and S. Weinstein (1984) &amp;quot;Learning The-
ory and Natural Language,&amp;quot; Cognition 17: 1-28.
Pullum, G.K. (1985) &amp;quot;On Two Recent Attempts to Show that
English is Not a CFL,&amp;quot; Computational Linguistics 10: 182-
186.
Shieber, S.M. (1985) &amp;quot;Evidence Against the Context-Freeness of
Natural Language,&amp;quot; Linguistics and Philosophy 8: 333-344.
</reference>
<page confidence="0.99929">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000032">
<title confidence="0.999201">DEFINING NATURAL LANGUAGE GRAMMARS IN GPSG</title>
<author confidence="0.999953">Eric Sven Ristad</author>
<affiliation confidence="0.999888">MIT Artificial Intelligence Lab Thinking Machines Corporation</affiliation>
<address confidence="0.9997725">545 Technology Square and 245 First Street Cambridge, MA 02139 Cambridge, MA 02142</address>
<email confidence="0.576956">1Overview</email>
<abstract confidence="0.998695222222223">Three central goals of work in the generalized phrase structure grammar (GPSG) linguistic framework, as stated in the leading book &amp;quot;Generalized Phrase Structure Grammar&amp;quot; G azdar et al (1985) (hereafter GKPS), are: (1) to characterize all and only the natural language grammars, (2) to algorithmically determine membership and generative power consequences of GPSGs, and (3) to embody the universalism of natural language entirely in the formal system, rather than by statements in These pages formally consider whether GPSG&apos;s weak contextfree generative power (wcfgp) will allow it to achieve the three goals. The centerpiece of this paper is a proof that it is undecidable whether an arbitrary GPSG generates the nonnatural language E*. On the basis of this result, I argue that GPSG fails to define the natural language grammars, and that the generative power consequences of the GPSG framework cannot be determined, contrary to goals one and In the process, I examine the linguistic universalism of the GPSG formal system and argue that GPSGs can describe an infinite of nonnatural context-free languages. paper with a brief diagnosis of the result and suggests that the problem might be met by abandoning the weak context-free generative power framework and assuming substantive constraints. 1.1 The Structure of GPSG Theory A generalized phrase structure grammar contains five languageparticular components (immediate dominance (ID) rules, metarules, linear precedence (LP) statements, feature co-occurrence &apos;GKPS clearly outline their goals. One, &amp;quot;to arrive at a constrained metalanguage capable of defining the grammars of natural languages, but not the grammar of, say, the set of prime numbers.&amp;quot;(p4). Two, to construct an explicit linguistic theory whose formal consequences are clearly and easily determinable. These &apos;formal consequences&apos; include both the generative power consequences demanded by the first goal and membership determination: GPSG regards languages &amp;quot;as collections whose membership is definitely and precisely specifiable.&amp;quot; (p.1) Three, to define a linguistic theory universalism [of is, ultimately, intended to be embodied formal system, not expressed by statements made in emphasis) proof technique make use of invalid computations, and the actual GPSG constructed is so simple, so similar to the GPSGs proposed for actual languages, and so flexible in its exact formulation that method of there may be no simple reformulations of GPSG that avoid this problem. The proof also suggests that it is impossible in principle to algorithmically determine whether linguistic theories based on a wcfgp framework (e.g. GPSG) actually define the natural language grammars. (FCRs), and feature specification (FSDs)) and four universal components: a theory of syntactic features, principles of universal feature instantiation, principles of semantic interpretation, and formal relationships among various comof the The set of ID rules obtained by taking the finite closure of the metarules on the ID rules is mapped into local phrase structure trees, subject to principles of universal feature instantiation, FSDs, FCRs, and LP statements. Finally, these local trees are assembled to form phrase structure trees, which are terminated by lexical elements. The essence of GPSG is the constrained mapping of ID rules into local trees. The constraints of GPSG theory subdivide into absolute constraints on local trees (due to FCRs and LPstatements) and relative constraints on the rule to local tree mapping (stemming from FSDs and universal feature instantiation). The absolute constraints are all language-particular, and consequently not inherent in the formal GPSG framework. Similarly, the relative constraints, of which only universal instantiation is not explicitly language-particular, do not apply to fully specified ID rules and consequently are not strongly inin the GPSG framework In summary, GPSG local trees are only as constrained as ID rules are: that is, not at all. The only constraint strongly inherent in GPSG theory (when compared to context-free grammars (CFGs)) is finite feature closure, which limits the number of GPSG nonterminal symbols be finite and 1.2 A Nonnatural GPSG Consider the exceedingly simple GPSG for the nonnatural language E*, consisting solely of the two ID rules &apos;This work is based on current GPSG theory as presented in GKPS. The reader is urged to consult that work for a formal presentation and thorough exposition of current GPSG theory. use &amp;quot;strongly inherent&amp;quot; to mean &amp;quot;unavoidable by virtue of the formal framework.&amp;quot; Note that the use of problematic feature specifications in universal feature instantiation means that this constraint is dependent on other, parochial, components (e.g. FCRs). Appropriate choice of FCRs or ID rules will abrogate universal feature instantiation, thus rendering it implicitly language particular too. &apos;This formal constraint is extremely weak, however, since the theory syntactic features licenses more than syntactic categories. See Ristad, E.S. (1986), &amp;quot;Computational Complexity of Current GPSG Theory&amp;quot; in these proceedings for a discussion. 40 This GPSG generates local trees with all possible subcategorizaspecifications — the may assume any value the non-head daughter of the first and the nonnatural language E. This exhibit is inconclusive, however. We have only shown that GKPS — and not GPSG — have failed to achieve the first goal of GPSG theory. The exhibition leaves open the possibility of trivially reformalizing GPSG or imposing ad-hoc constraints on the theory such that I will no longer be able to personally a GPSG for 2 Undecidability and Generative Power in GPSG That &amp;quot;= E*?&amp;quot; is undecidable for arbitrary context-free grammars is a well-known result in the formal language literature (see Hoperaft and Ullman(1979:201-203)). The standard proof is to construct a PDA that accepts all invalid computations of TM this PDA an equivalent CFG directly con- Thus, E* if and only if computations of are invalid, i.e. L(M) = 0. latter problem is undecidable, so the former must be also. No such reduction is possible for a proof that &amp;quot;= E*?&amp;quot; is undecidable for arbitrary GPSGs. In the above reduction, the of nonterminals in a function of the size of the TM however, have a bounded number of nonterminal symbols, and as discussed above, that is the essential difference between CFGs and GPSGs. Only weak generative power is of interest for the following proof, and the formal GPSG constraints on weak generative power are trivially abrogated. For example, exhaustive constant partial ordering (ECPO) — which is a constraint on strong generative capacity — can be done away with for all intents and purposes by nonterminal renaming, and constraints arising from principles of universal feature instantiation don&apos;t apply to fully instantiated ID rules. First, a proof that &amp;quot;= E*?&amp;quot; is undecidable for context-free grammars with a very small number of terminal and nonterminal symbols is sketched. Following the proof for CFGs, the equivalent proof for GPSGs is outlined. of a Proof for Small CFGs be the class of context-free grammars with at least and symbols. I now sketch a proof it is undecidable of an arbitrary CFG = for some y than fixed lower bounds. The actual construction details are of no obvious mathematical or pedagogical interest, and will not be included. The idea is to directly construct a CFG to generate the invalid computations of the Universal Turing Machine (UTM). This grammar will be small if the UTM is small. The &amp;quot;smallest UTM&amp;quot; of Minsky(1967:276-281) has seven states and a four symbol tape alphabet, for a state-symbol product of 28 (!). Hence, it is not that the &amp;quot;smallest generates the invalid computations of the UTM has seventeen nonterminals and two terminals. Observe that if a string w is an invalid computation of the Miring machine = (Q , r,s, B, F) input x, then one of the following conditions must hold. 1. w has a &amp;quot;syntactic error,&amp;quot; that is, w is not of the form • • each is an instantaneous de- M. Therefore, some xi is not an ID of M. 2. is not initial; that is, V x„, not final; that is x, 1-w false for some odd 5. is false for some even construction of result in a CFG containing on the order of twenty or thirty nonterminals and at least fifteen terminals (one for each UTM state and tape symbol, one for the blank-tape symbol, and one for the instantaneous description separator &amp;quot;#&amp;quot;). Then the subgrammars ensure that is false for some even i and ■-■m. is false for some odd i may be cleverly combined so that nonterminals encode more information, and SO On. The final trick, due to Albert Meyer, reduces the terminals to 2 at the cost of a lone nonterminal by encoding the n terminals as log n = k-bit words over the new terminal alphabet adding some rules to ensure that the final grammar generate E* and not The productions 0L41L4 01L4 11L4 I ... added to the converted CFG generates a language of the form 0000 I 0001 I 0010 ... IE L4L4 14generates all symbols of length and generall strings not of length 0 mod = all of length 1,2,3 mod consideration of the acthat the is also eliminable. Note that all the preceding efforts to reduce the number of nonterminals and terminals increase the number of context-free productions. This symbol-production tradeoff becomes clearer one actually constructs the distinguished start symbol for Then we form a new CFG consisting of all productions of the form 41 - - L4} and the one production S SUTM the length p encoding of an arbitrary TM N4 as defined above. ensures that strings whose prefix is be starting from and only if they are generated startfrom is, they are invalid computations of the on Some Details for and GPSG the nonterminal symbols ,Q, E in the following CFG portion generate the obvious terminal symbols corresponding to equivalent UTM sets. the terminal blank symbol. Then, the following sketched CF productions generate the of M such that false for some odd i. are used to locate the even and i IDs zi of w. the language {I&apos; U #}*. rs4 #.55 S5 #SevenSok -4 Sl# s2 s6 I s2r a t in E -+ pca} = (p, c, R) cap} = L) -■ if B) = (p, c, R) cap} B) = (p, c, L) -■ I BF and must generate a false transition for odd i, while need not generate a false transition and is used to pad out the of w. The nonterminals accept IDs with improperly tape lengths. The first production accepts transiwhere the tape contents differ in a bad place, the second production accepts invalid transitions other than at the end of tape, and the third accepts invalid end of the tape transi- Note that the last two productions are actually classes productions, one for each string in - - The GPSG for &amp;quot;= E`?&amp;quot; is constructed in a virtually identical fashion. Recall that the GPSG formal framework does not bar us from constructing a grammar equivalent to the CFG just presented. The ID rules used in the construction will be fully specified so as to defeat universal feature instantiation, and the construction will use nonterminal renaming to avoid ECPO. the GPSG category fully specified for all features (the actual values don&apos;t matter) with the exception of, say, the binary features GER, NEG , NULL and POSS. Arrange those four features in some canonical order, and let binary strings of length four represent the values assigned to those features in a given category. For example, C[0100] represents the category C with the additional specifications ( [-GER] , [+NEG] , [-NULL]. [-</abstract>
<note confidence="0.803123368421053">We replace C10000], SI by C[00011, by C[0011], by C[0100], and by C[01011. The nonterminal I&apos; is replaced by three symbols of the form C[11x4 for each linear precedence too. Similarly, E is replaced by two symbols of the form C[1004 The ID rules, in the same order as the CF productions above (with a portion of the necessary LP statements) are: C[1100]C1000110110111 C[0010]1 001001 IC[01011 -4C[11001C[0100] C[1100]C[0011] C101011 C[0101]C[1101] C[00111C[1101) -4C110001aC[1001]C[0011]C[1101]bC[11101 a in E -4 aqbC[0011]{0 b) = (p, c, R) if = (p,c, L) -■ if B) = (p, c, R) cap} B) = L) C[0011] C[11001C[00111C[1101] QB#BC[1100]C[1101]1 C[1100] &lt; C[0001],C[00111,001001,C[0101] &lt; C[11011</note>
<abstract confidence="0.997123023255814">lt; a &lt; &lt; C[0011] &lt; C[1110] While the sketched ID rules are not valid GPSG rules, just as the sketched context-free productions were not the valid components of a context-free grammar, a valid GPSG can be constructed in a straightforward and obvious manner from the sketched ID rules. There would be no metarules, FCRs or FSDs in the actual grammar. last comment to be made is that in the actual only the number of productions is a function of the size of the UTM. The UTM is used only as a convincing crutch — i.e. not all. fixed number of nonterminals are needed to a CFG for the invalid computations of any Turing Machine. 3 Interpreting the Result The preceding pages have shown that the extremely simple nonnatural language E* is generated by a GPSG, as is the more complex language Lic consisting of the invalid computations of an arbitrary Turing machine on an arbitrary input. Because 42 is GPSG language, &amp;quot;= E*?&amp;quot; is undecidable for GPSGs: there is no algorithmic way of knowing whether any given GPSG a natural language or an unnatural one. for example, no algorithm can tell us whether the English GPSG of GKPS really generates English or E*. The result suggests that goals 1, 2, 3 and the context-free framework conflict with each other. Weak context-free generpower allows both E&amp;quot; and by goal 1 we must exclude nonnatural languages. Goal 2 demands it be possible to algorithmically determine whether a given GPSG generates a desired language or not, yet this cannot be done in the context-free framework. Lastly, goal 3 requires that all nonnatural languages be excluded on the basis of the formal system alone, but this looks to be impossible given the other two goals, the adopted framework, and the technical vagueness of &amp;quot;natural language grammar.&amp;quot; The problem can be met in part by abandoning the contextfree framework. Other authors have argued that natural language is not context-free, and here we argue that the GPSG theory of GKPS can characterize context-free languages that are too simple or trivial to be natural, e.g. any finite or reg- The context-free framework is both too weak and too strong — it includes nonnatural languages and excludes natural ones. Moreover, CFL&apos;s have the wrong formal properties entirely: natural language is surely not closed under union, concatenation, Kleene closure, substitution, or intersection with In short, the context-free framework is the wrong completely, and is to be expected: should the arbitrary generative power classifications of mathematics (formal language theory) be at all relevant to biology (human language)? 2, that the naturalness of grammars postulated linguistic theory be decidable, and to a lesser extent goal 3, are of dubious merit. In my view, substantive constraints arising from psychology, biology or even physics may be freely invoked, with a corresponding change in the meaning of &amp;quot;natural language grammar&amp;quot; from &amp;quot;mentally-representable grammar&amp;quot; to something like &amp;quot;easily learnable and speakable mentally-representable grammar.&amp;quot; There is no a priori reason or empirical evidence to suggest that the class of mentally representable grammars is not complex, maybe not even One promising restriction in this regard, which if properly formulated would alleviate GPSG&apos;s actual and formal inability to characterize only the natural language grammars, is strong — the restrictive theory that the class of natural lan- &amp;quot;While &apos;natural language grammar&apos; is not defined precisely, recent work has demonstrated empirically that natural language is not context-free, and therefore GPSG theory will not be able to characterize all the human langrammars. example, Higginbotham(1984), Shieber(1985), and Culy(1985). For counterarguments, see Pullum(1985). Nash(1980), chapter 5, discusses the impossibility of accounting for free word order languages (e.g. Warlpiri) using ID/LP grammars. I focus on the goal of natural language grammars in this paper. &apos;The finite, bounded number of nonterminals allowed in GPSG theory plays a linguistic role in this regard, because the direct consequence of finite feature closure is that GPSG languages are not truly closed under union, concatenation, or substitution. &amp;quot;See Chomsky(1980:120) for a discussion. This restriction is well motivated both by the raised here and by other empirical The restriction, which may be substantive or purely formal, is a formal attack on the heart of the result: the theory of undecidability is concerned with the existence or nonexistence of algorithms for solving problems with an infinity of instances. Furthermore, restriction may be empirically The author does not have a clear idea how GPSG might be restricted in this manner, and merely suggests strong nativism as a well-motivated direction for future GPSG research.</abstract>
<note confidence="0.450170333333333">Acknowledgments. The author is indebted to Ed Barton, Robert Berwick, Noam Chomsky, Jim Higginbotham, Richard Larson, Albert Meyer, and David Waltz for assistance in writing this paper, and to the MIT Artificial Intelligence Lab and Thinking Machines Corporation for supporting this research. N. (1980) and Representations. York:</note>
<affiliation confidence="0.72899575">Columbia University Press. G., E. Klein, G. Pullum, and I. Sag (1985) General- Phrase Structure Oxford, England: Basil Blackwell.</affiliation>
<address confidence="0.756275">Higginbotham, J. (1984) &amp;quot;English is not a Context-Free Lan-</address>
<abstract confidence="0.949579583333333">Inquiry 119-126. &amp;quot;Note that invoking finiteness here is technically different from hiding intractability with finiteness. Finiteness is the correct generalization here, because we are interested in whether GPSG generates nonnatural languages or not, and not in the computational cost of determining the generative of an arbitrary GPSG. restriction for the purposes of computational complexity is invalid because it prevents us from properly using the tools of complexity theory to study the computational complexity of a problem. &apos;&amp;quot;See Osherson et. al. (1984) for an exposition of strong nativism and related issues. The theory of strong nativism can be derived in formal learning theory from three empirically motivated axioms: (1) the ability of language learners to learn in noisy environments, (2) language learner memory limitations (e.g. inability to remember long-past utterances), and (3) the likelihood that language learners choose simple grammars over more complex, equivalent ones. These formal results are weaker empirically than they might appear at first glance: the equivalence of &amp;quot;learned&apos; grammars is measured using only weak generative capacity, ignoring uniformity considerations. &amp;quot;An alternate substantive constraint, suggested by Higginbotham (personal communication) and not explored here, is to require natural language to generate non-dense languages. Let the a class of languages be an upper bound (across all languages in the class) on the ratio of grammatical utterances to grammatical and ungrammatical utterances, in terms of utterance lengths. If the density of natural languages was small in utterance length, as one might expect, and a decidable property of the reformulated GPSG&apos;s, then undecidability of &amp;quot;= E•?&amp;quot; would no longer reflect on the decidability of whether the GPSG framework characterized all and only the natural language grammars. The exact specof this density constraint is tricky because unit density &amp;quot;= E&amp;quot;?&amp;quot; , and therefore density measurements cannot be too accurate. E&apos; and be buried in other languages, i.e. concatenated onto the end of an arbitrary (finite or infinite) language, weakening the accuracy and relevance of density measurements. 43 J.E., and J.D. Ullman (1979) to Au-</abstract>
<keyword confidence="0.57579325">Theory, Languages, and Computation. MA: Addison-Wesley. M. (1967) Finite and Infinite Machines. Englewood Cliffs, NJ: Prentice-Hall.</keyword>
<author confidence="0.356781">D Topics in Warlpiri Grammars Nash</author>
<author confidence="0.356781">M I T De-</author>
<affiliation confidence="0.912503">partment of Linguistics and Philosophy Ph.D dissertation,</affiliation>
<address confidence="0.874489">Cambridge.</address>
<note confidence="0.934078285714286">Osherson, D., M. Stob, and S. Weinstein (1984) &amp;quot;Learning Theand Natural Language,&amp;quot; 1-28. Pullum, G.K. (1985) &amp;quot;On Two Recent Attempts to Show that is Not a CFL,&amp;quot; Linguistics 182- 186. Shieber, S.M. (1985) &amp;quot;Evidence Against the Context-Freeness of Language,&amp;quot; and Philosophy 333-344.</note>
<intro confidence="0.54495">44</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Rules and Representations.</title>
<date>1980</date>
<publisher>Columbia University Press.</publisher>
<location>New York:</location>
<marker>Chomsky, 1980</marker>
<rawString>Chomsky, N. (1980) Rules and Representations. New York: Columbia University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G Pullum</author>
<author>I Sag</author>
</authors>
<date>1985</date>
<booktitle>Generalized Phrase Structure Grammar.</booktitle>
<publisher>Basil Blackwell.</publisher>
<location>Oxford, England:</location>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G., E. Klein, G. Pullum, and I. Sag (1985) Generalized Phrase Structure Grammar. Oxford, England: Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Higginbotham</author>
</authors>
<title>English is not a Context-Free Language,&amp;quot;</title>
<date>1984</date>
<journal>Linguistic Inquiry</journal>
<volume>15</volume>
<pages>119--126</pages>
<marker>Higginbotham, 1984</marker>
<rawString>Higginbotham, J. (1984) &amp;quot;English is not a Context-Free Language,&amp;quot; Linguistic Inquiry 15: 119-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley.</publisher>
<location>Reading, MA:</location>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, J.E., and J.D. Ullman (1979) Introduction to Automata Theory, Languages, and Computation. Reading, MA: Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<title>Computation: Finite and Infinite Machines. Englewood Cliffs,</title>
<date>1967</date>
<publisher>Prentice-Hall.</publisher>
<location>NJ:</location>
<marker>Minsky, 1967</marker>
<rawString>Minsky, M. (1967) Computation: Finite and Infinite Machines. Englewood Cliffs, NJ: Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nash</author>
</authors>
<title>Topics in Warlpiri Grammars,&amp;quot;</title>
<date>1980</date>
<booktitle>M.I.T. Department of Linguistics and Philosophy Ph.D dissertation,</booktitle>
<location>Cambridge.</location>
<marker>Nash, 1980</marker>
<rawString>Nash, D. (1980) &amp;quot;Topics in Warlpiri Grammars,&amp;quot; M.I.T. Department of Linguistics and Philosophy Ph.D dissertation, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Osherson</author>
<author>M Stob</author>
<author>S Weinstein</author>
</authors>
<title>Learning Theory and Natural Language,&amp;quot;</title>
<date>1984</date>
<journal>Cognition</journal>
<volume>17</volume>
<pages>1--28</pages>
<marker>Osherson, Stob, Weinstein, 1984</marker>
<rawString>Osherson, D., M. Stob, and S. Weinstein (1984) &amp;quot;Learning Theory and Natural Language,&amp;quot; Cognition 17: 1-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Pullum</author>
</authors>
<title>On Two Recent Attempts to Show that English is Not a CFL,&amp;quot;</title>
<date>1985</date>
<journal>Computational Linguistics</journal>
<volume>10</volume>
<pages>182--186</pages>
<marker>Pullum, 1985</marker>
<rawString>Pullum, G.K. (1985) &amp;quot;On Two Recent Attempts to Show that English is Not a CFL,&amp;quot; Computational Linguistics 10: 182-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Evidence Against the Context-Freeness of Natural Language,&amp;quot;</title>
<date>1985</date>
<journal>Linguistics and Philosophy</journal>
<volume>8</volume>
<pages>333--344</pages>
<marker>Shieber, 1985</marker>
<rawString>Shieber, S.M. (1985) &amp;quot;Evidence Against the Context-Freeness of Natural Language,&amp;quot; Linguistics and Philosophy 8: 333-344.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>