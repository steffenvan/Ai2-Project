<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.993835">
Logical Form Equivalence:
the Case of Referring Expressions Generation
</title>
<author confidence="0.816412">
Kees van Deemter Magn´us M. Halld´orsson
</author>
<affiliation confidence="0.9135445">
ITRI Computer Science Dept.
University of Brighton University of Iceland,
</affiliation>
<address confidence="0.93739">
Brighton BN2 4GJ Taeknigardur, 107 Reykjavik, Iceland
United Kingdom and Iceland Genomics Corp., Reykjavik
</address>
<email confidence="0.994724">
Kees.van.Deemter@itri.brighton.ac.uk mmh@hi.is
</email>
<sectionHeader confidence="0.995558" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999615222222222">
We examine the principle of co-
extensivity which underlies current al-
gorithms for the generation of referring
expressions, and investigate to what ex-
tent the principle allows these algo-
rithms to be generalized. The discus-
sion focusses on the generation of com-
plex Boolean descriptions and sentence
aggregation.
</bodyText>
<sectionHeader confidence="0.930494" genericHeader="method">
1 Logic in GRE
</sectionHeader>
<bodyText confidence="0.989631417475729">
A key question regarding the foundations of Nat-
ural Language Generation (NLG) is the problem
of logical form equivalence (Appelt 1987). The
problem goes as follows. NLG systems take se-
mantic expressions as input, usually formulated
in some logical language. These expressions are
governed by rules determining which of them
count as ‘equivalent’. If two expressions are
equivalent then, ideally, the NLG program should
verbalize them in the same ways. (Being equiv-
alent, the generator would not be warranted in
distinguishing between the two.) The question
is: what is the proper relation of equivalence?
Appelt argued that classical logical equivalence
(i.e., having the same truth conditions) is not a
good candidate. For example, is logi-
cally equivalent with , yet – so the argu-
ment goes – an NLG system should word the two
formulas differently. Shieber (1993) suggested
that some more sophisticated notion of equiva-
lence is needed, which would count fewer seman-
tic expressions as equivalent.&apos; In the present pa-
per, a different response to the problem is ex-
plored, which keeps the notion of equivalence
classical and prevents the generator from distin-
guishing between inputs that are logically equiva-
lent (i.e., inputs that have the same truth condi-
tions). Pragmatic constraints determine which
of all the logically equivalent semantic expres-
sions is put into words by the NLG program.
Whereas this programme, which might be called
‘logic-oriented’ generation, would constitute a
fairly radical departure from current practice if
applied to all of NLG (Krahmer &amp; van Deemter
(forthcoming); Power 2000 for related work), the
main aim of the present paper is modest: to show
that logic-oriented generation is standard prac-
tice in connection with the generation of referring
expressions (GRE). More specifically, we show
the semantics of current GRE algorithms to be
guided by a surprisingly simple principle of co-
extensivity, while their pragmatics is guided by
Gricean Brevity.
Our game plan is as follows. In section 2, we
illustrate the collaboration between Brevity and
co-extensivity, focussing on ‘simple’ referring ex-
pressions, which intersect atomic properties (e.g.,
‘dog’ and ‘black’). Section 3 proceeds by show-
ing how other algorithms use the principle to le-
gitimize the creation of more elaborate structures
involving, for example, complex Boolean combi-
nations (e.g., the union of some properties, each
of which is the intersection of some atomic prop-
&apos;See also van Deemter (1990) where, on identical
grounds, a variant of Carnap-style intensional isomorphism
was proposed as an alternative notion of equivalence.
erties). This part of the paper will borrow from
van Deemter (2001), which focusses on compu-
tational aspects of GRE. Section 4 asks how the
principle of co-extensivity may be generalized be-
yond GRE and questions its validity.
2 Intersective reference to sets of
domain objects
The Knowledge Base (KB) forming the input to
the generator will often designate objects using
the jargon of computerized databases, which is
not always meaningful for the reader/hearer. This
is true, for example, for an artificial name (i.e.,
a database key) like ‘ ’ when a per-
son’s proper name is not uniquely distinguishing;
it is also true for objects (e.g., furniture, trees,
atomic particles) for which no proper names are
in common usage. In all such cases, the NLG pro-
gram has to ‘invent’ a description that enables the
hearer to identify the target object. The program
transforms the original semantic structure in the
KB into some other structure.
Let us examine simple references first. Assume
that the information used for interpreting a de-
scription is stored in a KB representing what
properties are true of each given object. In ad-
dition to these properties, whose extensions are
shared between speaker and hearer, there are
other properties, which are being conveyed from
speaker to hearer. For example, the speaker may
say ‘The white poodle is pregnant’, to convey the
new information that the referent of ‘the white
poodle’ is pregnant. GRE ‘sees’ the first, shared
KB only. We will restrict attention to the prob-
lem of determining the semantic content of a de-
scription, leaving linguistic realization aside. (Cf.
Stone and Webber 1998, Krahmer and Theune
1999, which interleave linguistic realization and
generation.) Accordingly, ‘Generation of Refer-
ring Expressions’ (GRE) will refer specifically to
content determination. We will call a GRE algo-
rithm complete if it is successful whenever an in-
dividuating description exists. Most GRE algo-
rithms are limited to individual target objects (for
an exception, Stone 2000), but we will present
ones that refer to sets of objects (Van Deemter
2000); reference to an individual will equal ref-
erence to the singleton set .
</bodyText>
<subsectionHeader confidence="0.996294">
2.1 The Incremental Algorithm
</subsectionHeader>
<bodyText confidence="0.996127893617021">
Dale and Reiter (1995) proposed an algorithm
that takes a shared KB as its input and delivers a
set of properties which jointly identify the target.
Descriptions produced by the algorithm fullfill
the criterion of co-extensivity. According to this
principle, a description is semantically correct if
it has the target as its referent (i.e., its extension).
The authors observed that a semantically correct
description can still be unnatural, but that natural-
ness is not always easy to achieve. In particular,
the problem of finding a (‘Full Brevity’) descrip-
tion that contains the minimum number of prop-
erties is computationally intractable, and human
speakers often produce non-minimal descriptions.
Accordingly, they proposed an algorithm that ap-
proximates Full Brevity, while being of only lin-
ear complexity. The algorithm produces a finite
set of properties such that the inter-
section of their denotations
equals the target set , causing to be a ‘dis-
tinguishing description’ of . The properties in
are selected one by one, and there is no back-
tracking, which is why the algorithm is called In-
cremental. As a result, some of the properties in
may be logically superfluous.
For simplicity, we will focus here on properties,
without separating them into Attributes and Val-
ues (see also Reiter and Dale 2000, section 5.4.5).
Accordingly, reflecting the fact that not all prop-
erties are equally ‘preferred’, they are ordered lin-
early in a list IP, with more preferred ones preced-
ing less preferred ones. We also simplify by not
taking the special treatment of head nouns into ac-
count. Suppose is the target set, and is the
set of elements from which is to be selected.2
The algorithm iterates through IP; for each prop-
erty, it checks whether it would rule out at least
one member of that has not already been ruled
out; if so, the property is added to . Members
that are ruled out are removed from . The pro-
cess of expanding and contracting continues
until ; if and when this condition is met,
is a distinguishing set of properties.
2We have chosen a formulation in which is a superset
of , rather than a ‘contrast set’, from whose elements those
of must be distinguished (Dale and Reiter 1995). The dif-
ference is purely presentational.
</bodyText>
<figure confidence="0.798518">
is initialized to the empty set
For each PI do
If removes dis-
tractors from but keeps all elements of
Then do
All elements outside
are removed from
If then Return Success
Return Failure All properties in PI have been
tested, yet
</figure>
<bodyText confidence="0.998145428571429">
This algorithm, D&amp;RPlur, constructs better and
better approximations of the target set . Assum-
ing (cf. Dale and Reiter 1995) that the tests in the
body of the loop take some constant amount of
time, the worst-case running time is in the order
of (i.e., ) where is the total number
of properties.
</bodyText>
<sectionHeader confidence="0.967148" genericHeader="method">
3 Reference using Boolean descriptions
</sectionHeader>
<bodyText confidence="0.999131829268293">
Based on co-extensivity, the algorithms discussed
construct an intersective Boolean expression (i.e.,
an expression of the form , where
are atomic) that has the target set as its
extension. But, intersection is not the only oper-
ation on sets. Consider a KB whose domain is a
set of dogs ( ) and whose only Attributes
are TYPE and COLOUR:
In this situation, D&amp;R does not allow us to
individuate any of the dogs. In fact, however, the
KB should enable one to refer to dog , since it is
the only black dog that is not a poodle:
A similar gap exists where disjunctions might be
used. For example, D&amp;R does not make the
set of dogs that are either white or poodles refer-
able, whereas it is referable in English, e.g., ‘The
white dogs and the poodles’.
Presently, we will investigate how GRE can take
negation and disjunction into account. Section
3.1 will ask how GRE algorithms can achieve
Full Boolean Completeness; section 3.2, which
follows Van Deemter (2001), adds Brevity as a
requirement. Boolean descriptions do the same
thing that intersective descriptions do, except in
a more dramatic way: they ‘create’ even more
structure. As a result, the problem of optimizing
these structures with respect to constraints such as
Brevity becomes harder as well.
As a first step, we show how one can tell which
targets are identifiable given a set of properties
and set intersection. We calculate, for each el-
ement in the domain, the ‘Satellite set’ of ,
that is, the intersection of the extensions of all the
properties that are true of . Taking all extensions
from our example,
If two objects occur in the same Satellite set then
no intersective description can separate them: any
description true of one must be true of the other. It
follows, for example, that no object in the domain
is uniquely identifiable, since none of them occurs
in a Satellite set that is a singleton.
</bodyText>
<subsectionHeader confidence="0.7487755">
3.1 Boolean descriptions (i): generate and
simplify
</subsectionHeader>
<bodyText confidence="0.942412333333333">
Boolean completeness is fairly easy to achieve
until further constraints are added. Suppose the
task is to construct a description of a target set ,
given a set PI of atomic properties, without any fur-
ther constraints. We will discuss an algorithm that
starts by calculating a generalized type of Satel-
lite sets, based on all atomic properties and their
negations.
Construction of Satellite sets:
</bodyText>
<equation confidence="0.489857666666667">
IP PI PI
For each do
IP
</equation>
<bodyText confidence="0.967111384615385">
Property is added to
TYPE: dog , poodle
COLOUR: black , white
First, the algorithm adds to PI the properties whose
extensions are the complements of those in IP.
Then it calculates, for each element in ,
by lining up all the properties in
PI that are true of , then taking the intersec-
tion of their extensions. Satellite sets may be
exploited for the construction of descriptions by
forming the union of a number of expressions,
each of which is the intersection of the elements
of (for some ).
</bodyText>
<subsectionHeader confidence="0.975023">
Description By Satellite sets (DBS):
</subsectionHeader>
<bodyText confidence="0.908681851851852">
Description
Meaning
(Note that Description is returned instead of
Meaning, since the latter is just the set .) De-
scription is a set of sets of sets of domain ob-
jects. As is made explicit in Meaning, this third-
order set is interpreted as a union of intersections.
A Description is successful if it evaluates to
the target set ; otherwise the algorithm returns
Fail. If Fail is returned, no Boolean descrip-
tion of is possible:
DBS is computationally cheap: it has a worst-
case running time of , where is the num-
ber of objects in , and the number of atomic
properties. Rather than searching among all the
possible unions of some large set of sets, a set
is described as the union of
Satellites sets, each of which equals the intersec-
tion of those (at most ) sets inIP that contain
. Descriptions can make use of the Satellite sets
computed for earlier descriptions, causing a fur-
ther reduction of time. Satellites sets can even
be calculated off-line, for all the elements in the
domain, before the need for specific referring ex-
pressions has arisen.3
Unfortunately, the descriptions produced by DBS
tend to be far from brief:
.
.
.
To describe the target set , for exam-
ple, the algorithm generates the Description
. Consequently, the boolean expres-
sion generated is
But of course, a much shorter description, ,
would have sufficed. What are the prospects for
simplifying the output of DBS? Unfortunately,
perfect simplification (i.e., Full Brevity) is incom-
patible with computational tractibility. Suppose
brevity of descriptions is defined as follows:
is less brief than if either contains only
atomic properties while contains non-atomic
properties as well, or contains more Boolean
operators than . Then the intractability of Full
Brevity for intersections of atomic properties log-
ically implies that of the new algorithm:
Proof: Suppose an algorithm, BOOL, produced
a maximally brief Boolean description when-
ever one exists. Then whenever a target set
can be described as an intersection of atomic
properties, BOOL( ) would be a maximally
brief intersection of atomic properties, and this
is inconsistent with the intractability of Full
Brevity for intersections of atomic properties.
</bodyText>
<footnote confidence="0.562485333333333">
3Compare Bateman (1999), where a KB is compiled into
a format that brings out the commonalities between objects
before the content of a referring expression is determined.
</footnote>
<table confidence="0.61586425">
.
If Meaning=
then Return Description
else Fail
</table>
<bodyText confidence="0.980289645833334">
Full Boolean Completeness: For any set ,
is obtainable by a sequence of boolean op-
erations on the properties in PI if and only if
equals .
Proof: The implication from right to left is ob-
vious. For the reverse direction, suppose
. Then for some ,
Satellites contains an element that is not in
. But Satellites implies that every
set in PI must either contain both of and , or
neither. It follows that , which contains only
one of , cannot be obtained by a combina-
tion of Boolean operations on the sets in IP.
This negative result gives rise to the question
whether Full Brevity may be approximated, per-
haps in the spirit of Reiter (1990)’s ‘Local
Brevity’ algorithm which takes a given intersec-
tive description and tests whether any set of prop-
erties in it may be replaced by one other property.
Unfortunately, however, simplification is much
harder in the Boolean setting. Suppose, for exam-
ple, one wanted to use the Quine-McCluskey al-
gorithm (McCluskey 1965), known from its appli-
cations to electronic circuits, to reduce the num-
ber of Boolean operators in the description. This
would go only a small part of the way, since
Quine-McCluskey assumes logical independence
of all the properties involved. Arbitrarily com-
plex information about the extensions of prop-
erties can affect the simplification task, and this
reintroduces the spectre of computationally in-
tractability.4 Moreover, the ‘generate and sim-
plify’ approach has other disadvantages in addi-
tion. In particular, the division into two phases,
the first of which generates an unwieldy descrip-
tion while the second simplifies it, makes it psy-
chologically unrealistic, at least as a model for
speaking. Also, unlike the Incremental algorithm,
it treats all properties alike, regardless of their
degree of preferedness. For these reasons, it is
worthwhile to look for an alternative approach,
which takes the Incremental algorithm as its point
of departure. This does not mean that DBS is use-
less: we suggest that it is used for determining
whether a Boolean description exists; if not, the
program returns Fail; if a Boolean description
is possible, the computationally more expensive
algorithm of the following section is called.
</bodyText>
<subsectionHeader confidence="0.9900045">
3.2 Boolean descriptions (ii): extending the
Incremental algorithm
</subsectionHeader>
<bodyText confidence="0.99969375">
In this section, we will explore how the Incre-
mental algorithm may be generalized to take all
Boolean combinations into account. Given that
the Incremental algorithm deals with intersections
</bodyText>
<footnote confidence="0.963575375">
4For example, the automatic simplificator at
http://logik.phl.univie.ac.at/chris/qmo-
uk.html.O5 can only reduce our description to
if it ‘knows’ that being black, in this
KB, is tantamount to not being white. To reduce even
further, the program needs to know that all elements in the
domain are dogs. In more complex cases, equalities between
complex intersections and/or unions can be relevant.
</footnote>
<bodyText confidence="0.99868084">
between sets, Full Boolean Completeness can be
achieved by the addition of set difference. Set
difference may be added to D&amp;RPlur as follows.
First we add negations to the list of atomic proper-
ties (much like the earlier DBS algorithm). Then
D&amp;RPlur runs a number of times: first, in phase
1, the algorithm is performed using all positive
and negative literals; if this algorithm ends before
, phase 2 is entered in which further dis-
tractors are removed from using negations of
intersections of two literals, and so on, until ei-
ther (Success) or all combinations have
been tried (Failure). Observe that the nega-
tion of an intersection comes down to set union,
because of De Morgan’s Law:
. Thus, phase 2 of the algorithm deals
with disjunctions of length 2, phase 3 deals with
disjunctions of length 3, etcetera.
A schematic presentation will be useful, in which
stands for any positive or negative literal.
The length of a property will equal the number
of literals occurring in it. We will say that a D&amp;R
phase uses a set of properties if it loops through
the properties in (i.e., takes the place ofPI in
the original D&amp;RPlur).
</bodyText>
<listItem confidence="0.781674">
D&amp;R :
1. Perform a D&amp;R phase using all prop-
</listItem>
<bodyText confidence="0.977278290909091">
erties of the form ;
if this phase is successful then stop, oth-
erwise go to phase (2).
2. Based on the Values of and com-
ing out of phase (1),
perform a D&amp;R phase using all proper-
ties of the form ;
if this phase is successful then stop, oth-
erwise go to phase (3).
3. Based on the Values of and com-
ing out of phase (2),
perform a D&amp;R phase using all proper-
ties of the form ;
if this phase is successful then stop, oth-
erwise go to phase (4).
Etcetera.
One can require without loss of generality that
no property, considered at any phase, may have
different occurrences of the same atom.5 Since,
therefore, at phase , there is room for properties
of length , the maximal number of phases equals
the total number of atomic properties in the lan-
guage.
Note that D&amp;R is incremental in two dif-
ferent ways: within a phase, and from one phase
to the next. The latter guarantees that shorter dis-
junctions are favoured over longer ones. Once a
property has been selected, it will not be aban-
doned even if properties selected during later
phases make it superfluous. As a result, one may
generate descriptions like
(i.e., ‘white (cats and dogs)’) when
(i.e., ‘cats and dogs’) would have sufficed. The
empirical correctness of this type of incremen-
tality is debatable, but repairs can be made if
needed.6 Unfortunately, however, the algorithm
is not tractable as it stands. To estimate its run-
ning time as a function of the number of proper-
ties ( ) in the KB and the number of properties
used in the description ( ), note that the maximal
number of properties to be considered equals
(The factor of derives from inspecting both each
atom and its negation.) If then this
is in the order of .7 To avoid intractability,
the algorithm can be pruned. No matter where
this is done, the result is polynomial. By cut-
ting off after phase (1), for example, we gener-
ate negations of atomic properties only, produc-
ing such descriptions as ‘the black dog that is
not a poodle’, while disregarding more complex
descriptions. As a result, Boolean completeness
is lost, but only for references to non-singleton
sets.8 The number of properties to be considered
main, or the property , which is equivalent to
the earlier-considered property .
</bodyText>
<footnote confidence="0.953692166666667">
6E.g., phases might run separately before running in
combination: first phase 1, then 2, 1&amp;2, 3, 1&amp;3, 2&amp;3,
1&amp;2&amp;3, etc. (Suggested by Richard Power.)
7Compare an analogous argument in Dale and Reiter
(1995, section 3.1.1).
8If individuates the individualthen
</footnote>
<bodyText confidence="0.923993875">
either or does. Where singletons
are concerned, set union does not add descriptive power.
by this simpler algorithm equals .
If one wanted to produce more complex descrip-
tions like (‘the white dogs
and the poodles’), the algorithm might be cut off
one phase later, leading to a worst-case running
time of .
</bodyText>
<sectionHeader confidence="0.998293" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999827">
Hybrid algorithms, which make use of elements
of both algorithms, are possible. In particular,
the idea of incrementality can be injected into the
generate and simplify algorithm of section 3.1,
firstly, at the level of the construction of Satel-
lite sets (i.e., by letting take into account only
those properties from PI that are necessary for
singling out ) and, secondly, where the union of
the is formed in DBS (i.e., by taking
only those into account that change the
resulting Meaning). Instead of offering any de-
tails on this, we choose to discuss a more general
problem relating to the problem of Logical Form
Equivalence that was noted in section 1.
GRE algorithms exploit a principle of coexten-
sivity for determining what are semantically cor-
rect ways of referring to an entity. Thus, consis-
tent with the idea of logic-oriented generation, the
structure of the description is not prejudged by
the syntactic form of the input to the generator
(i.e., by the fact that the input contains an indi-
vidual constant rather than a description). As a
result, GRE can ‘create’ substantial amounts of
new semantic structure containing, for example,
any number of Boolean operators. In section 1,
it was suggested that the processes of structure
transformation used in GRE might have wider ap-
plicability. The present section questions the va-
lidity of coextensivity as a general principle, first
for GRE (section 4.1), then for sentence aggrega-
tion (section 4.2).
</bodyText>
<subsectionHeader confidence="0.996498">
4.1 Descriptions in intensional contexts
</subsectionHeader>
<bodyText confidence="0.9998575">
The principle of co-extensivity is not valid in in-
tensional contexts. For example, consider
</bodyText>
<listItem confidence="0.799472">
(a) John knows that [the red button] is
dangerous
(b) John knows that [the rocket launch-
ing button] is dangerous.
5For example, it is useless to consider the property
, which must be true of any element in the do-
(a) and (b) have different truth conditions even if
</listItem>
<bodyText confidence="0.998943370370371">
speaker and hearer share the information that the
red button is the rocket launching button. In other
words, the two descriptions are not interchange-
able, even if reader and hearer know them to be
coextensive; what would be necessary is for John
to know that they are coextensive. Extending cur-
rent GRE algorithms to the generation of referring
expressions in intensional contexts is likely to be
a difficult enterprise.
Failiure of substitutivity in intensional contexts
is, of course, a well-known problem, for which
various solutions are available on the theoreti-
cal market (e.g., Montague 1973, Barwise and
Perry 1983). But one has to wonder whether co-
extensivity is ever really sufficient. Consider ex-
tensional truncations of (a) and (b), such as may
be generated from an input I(1) (where the seman-
tic predicate ‘dangerous’ is abbreviated as and
is a constant referring to the button):
Suppose (a) and (b) are semantically interchange-
able (e.g., when said to someone who knows the
colours and functions of all objects in the do-
main), so a choice between them can only be mo-
tivated by an appeal to pragmatic principles. Even
then, it is difficult to accept that the same choice
must be made regardless whether the input to the
generator is I(1), I(2) or I(3): (Here says
that is for launching rockets; is the Russellian
description operator.)
Co-extensivity, after all, does not allow the gen-
erator to distinguish between I(1), I(2) and I(3),
because these three have the same extension!
Perhaps a weakened version of co-extensivity is
needed which allows the generator to add new
structure (e.g., when the input is I(1)), but not to
destroy existing structure (e.g., when the input is
I(2) or I(3)). It is, however, unclear what the the-
oretical justification for such a limitation of co-
extensivity might be.
Note that these problems become more dramatic
as GRE is able to ‘invent’ more structure (e.g.,
elaborate Boolean structure, as discussed in sec-
tion 3). Crucially, we have to assume that, in
an ideal generator, there are many other prag-
matic constraints than Brevity. One description
can be chosen over another, for example, because
it fullfills some additional communicative goal
(Dale and Reiter 1995, section 2.4; also Stone
and Webber 1998). Depending on the commu-
nicative goal, for example, (b) might be chosen
over (a) because the properties that identify the
button also explain why it is dangerous. Brevity
will then have to be interpreted as ‘Brevity pro-
vided all the other constraints are fullfilled’.
</bodyText>
<subsectionHeader confidence="0.943189">
4.2 Logic in sentence aggregation
</subsectionHeader>
<bodyText confidence="0.995894428571429">
GRE algorithms are sometimes presented as if
the principles underlying them were unrelated to
those underlying other components of an NLG
system.9 This is especially true for the logic-
based structure transformations on which this pa-
per has focused. In what follows, however, we
will suggest that analogous transformations moti-
vate some of the key operations in sentence aggre-
gation (Reiter and Dale 2000, p.133-144). To ex-
emplify, (and limiting the discussion to distribu-
tive readings only) the choice between the (a) and
(b) variants of (1)-(3) involves a decision as to
whether information is expressed in one or more
sentences:
</bodyText>
<reference confidence="0.961666833333333">
1a. John is eating; Mary is eating; Car-
los is eating.
1b. John, Mary and Carlos are eating.
2a. John is eating; John is drinking;
John is taking a rest
2b. John is eating and drinking and tak-
ing a rest.
3a. If John is eating then Mary is eat-
ing; If Bill is eating then Mary is eating.
3b. If either John or Bill is eating then
Mary is eating.
Writing for (Kamp
</reference>
<footnote confidence="0.45752225">
and Reyle 1993), the linguistic equivalence of
(1a) and (1b) rests on the logical equivalence
9But see Bateman (2000), where GRE and aggregation
are linked.
</footnote>
<figure confidence="0.5504924">
.
I(1)
(a ) [The red button] is dangerous
(b ) [The rocket launching button] is
dangerous
</figure>
<bodyText confidence="0.996463142857143">
Analogous to uses of Brevity in GRE, a prefer-
ence for (1b) over (1a) might be motivated by
a preference for a semantic structure with fewer
logical operations. Examples (2)-(3) are not dis-
similar to what we see in (1). For example, the
following logical equivalences support the lin-
guistic equivalence of (2a)/(2b) and (3a)/(3b):
</bodyText>
<reference confidence="0.997028222222222">
Dale 1992. R. Dale. Generating Referring Expressions:
Constructing Descriptions in a Domain of Objects and Pro-
cesses. MIT Press, Cambridge.
Dale and Reiter 1995. R. Dale and E. Reiter. Computational
Interpretations of the Gricean Maximes in the Generation of
Referring Expressions. Cognitive Science 18: 233-263.
Grice 1975. P. Grice. Logic and Conversation. In P. Cole
and J. Morgan (Eds.), “Syntax and Semantics: Vol 3, Speech
Acts”: 43-58. New York, Academic Press.
</reference>
<figure confidence="0.601914333333333">
1 .
2 .
3 .
</figure>
<bodyText confidence="0.996899076923077">
In ( ), three properties, and , are aggre-
gated into (i.e., to have each
of the three properties and ). In ( ),
two antecedents and are aggregated into
.10 As before, a generator might prefer
the (b) versions because they are structurally sim-
pler than the logically equivalent (a) versions. In
sentence aggregation, however, co-extensivity is
not enough. For example, we expect ‘Eat(j)’ to
be worded differently from ‘Eat(m)’, even if both
propositions are true and consequently have the
same extension. Unlike GRE, therefore, aggrega-
tion requires at least logical equivalence.11
</bodyText>
<sectionHeader confidence="0.99894" genericHeader="method">
5 Acknowledgment
</sectionHeader>
<bodyText confidence="0.999893">
Thanks are due to Emiel Krahmer for discussion
and comments.
</bodyText>
<sectionHeader confidence="0.999835" genericHeader="method">
6 References
</sectionHeader>
<reference confidence="0.990260479166667">
Appelt 1987. D.E. Appelt. Bidirectional Grammars and the
Design of Natural Language Generation systems. In Theo-
retical Issues in Natural Language Processing-3, p.185-191.
New Mexico State University, Las Cruces.
Barwise and Perry 1983. J. Barwise and J. Perry. Situations
and Attitudes. MIT Press.
Bateman 1999. J.A. Bateman. Using Aggregation for Se-
lecting Content when Generating Referring Expressions. In
Procs. ACL-99, Univ. Maryland.
10Note the disjunction, which would be difficult to get if
the transformation was performed at a syntactic level.
11In some (e.g., epistemic) contexts, even logical equiv-
alence is not enough. This mirrors the problems with co-
extensivity that were noted in connection with GRE.
Kamp and Reyle 1993. From Discourse to Logic. Kluwer
Academic Publishers, Dordrecht.
Krahmer and Theune 1999. E. Krahmer and M. Theune.
Generating Descriptions in Context. In R. Kibble and K.
van Deemter (Eds.), Procs. of ws. Generation of Nominal
Expressions, ESSLLI’99.
McCluskey 1965. McCluskey, Jr., E.J. Introduction to the
Theory of Switching. New York. McGraw-Hill.
Montague 1973. R. Montague. The Proper treatment of
Quantification in Ordinary English. In R.H.Thomason (ed.)
Formal Philosophy. Yale University Press, New Haven.
Power 2000. R.J.D. Power. Planning texts by constraint sat-
isfaction. Procs of the 18th Int. Conf. on Computational
Linguistics (COLING-2000), Saarbruecken, pp. 642-648.
Reiter 1990. E. Reiter. The Computational Complexity of
Avoiding Conversational Implicatures. In Proc. ACL-1990,
Pittsburgh.
Reiter and Dale 2000. E. Reiter and R. Dale. Building Nat-
ural language Generation Systems. Cambridge University
Press, Cambridge, UK.
Shieber 1993. S. Shieber. The Problem of Logical-Form
Equivalence. Squib in Computational Linguistics 19, 1.
Stone 2000. M. Stone. On Identifying Sets. In Procs. of
INLG-2000, Mitzpe Ramon.
Stone and Webber 1998. M. Stone and B. Webber. Textual
Economy through Close Coupling of Syntax and Semantics.
In Procs. ofINLG-1998, p.178-187.
van Deemter 1990. Structured Meanings in Computational
Linguistics. In Procs. of COLING-1990, Helsinki.
van Deemter 2000. K. van Deemter. Generating Vague De-
scriptions. In Procs. of INLG-2000, Mitzpe Ramon.
van Deemter 2001. Generating Referring Expressions: Be-
yond the Incremental Algorithm. In Procs. of Int. Workshop
on Computational Semantics (IWCS-4), Tilburg.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.015822">
<title confidence="0.997364">Logical Form the Case of Referring Expressions Generation</title>
<author confidence="0.999748">Kees van_Deemter Magn´us M Halld´orsson</author>
<affiliation confidence="0.9999605">ITRI Computer Science Dept. University of Brighton University of Iceland,</affiliation>
<address confidence="0.999387">Brighton BN2 4GJ Taeknigardur, 107 Reykjavik, Iceland</address>
<note confidence="0.823735">United Kingdom and Iceland Genomics Corp., Reykjavik Kees.van.Deemter@itri.brighton.ac.uk mmh@hi.is</note>
<abstract confidence="0.99876339">We examine the principle of coextensivity which underlies current algorithms for the generation of referring expressions, and investigate to what extent the principle allows these algorithms to be generalized. The discussion focusses on the generation of complex Boolean descriptions and sentence aggregation. 1 Logic in GRE A key question regarding the foundations of Natural Language Generation (NLG) is the problem form equivalence 1987). The problem goes as follows. NLG systems take semantic expressions as input, usually formulated in some logical language. These expressions are governed by rules determining which of them count as ‘equivalent’. If two expressions are equivalent then, ideally, the NLG program should verbalize them in the same ways. (Being equivalent, the generator would not be warranted in distinguishing between the two.) The question what is the of equivalence? Appelt argued that classical logical equivalence (i.e., having the same truth conditions) is not a candidate. For example, is logiequivalent with , yet – so the argument goes – an NLG system should word the two formulas differently. Shieber (1993) suggested that some more sophisticated notion of equivais needed, which would count fewer semanexpressions as the present paper, a different response to the problem is explored, which keeps the notion of equivalence classical and prevents the generator from distinguishing between inputs that are logically equivalent (i.e., inputs that have the same truth condiconstraints which of all the logically equivalent semantic expressions is put into words by the NLG program. Whereas this programme, which might be called ‘logic-oriented’ generation, would constitute a fairly radical departure from current practice if applied to all of NLG (Krahmer &amp; van Deemter (forthcoming); Power 2000 for related work), the main aim of the present paper is modest: to show that logic-oriented generation is standard pracin connection with the generation of More specifically, we show current GRE algorithms to be by a surprisingly simple principle of cowhile their pragmatics is guided by Gricean Brevity. Our game plan is as follows. In section 2, we illustrate the collaboration between Brevity and co-extensivity, focussing on ‘simple’ referring expressions, which intersect atomic properties (e.g., ‘dog’ and ‘black’). Section 3 proceeds by showing how other algorithms use the principle to legitimize the creation of more elaborate structures involving, for example, complex Boolean combinations (e.g., the union of some properties, each which is the intersection of some atomic propalso van Deemter (1990) where, on identical grounds, a variant of Carnap-style intensional isomorphism was proposed as an alternative notion of equivalence. erties). This part of the paper will borrow from van Deemter (2001), which focusses on computational aspects of GRE. Section 4 asks how the principle of co-extensivity may be generalized beyond GRE and questions its validity. 2 Intersective reference to sets of domain objects The Knowledge Base (KB) forming the input to the generator will often designate objects using the jargon of computerized databases, which is not always meaningful for the reader/hearer. This is true, for example, for an artificial name (i.e., database key) like ‘ ’ when a son’s proper name is not uniquely distinguishing; it is also true for objects (e.g., furniture, trees, atomic particles) for which no proper names are in common usage. In all such cases, the NLG program has to ‘invent’ a description that enables the to identify the The program transforms the original semantic structure in the KB into some other structure. Let us examine simple references first. Assume that the information used for interpreting a description is stored in a KB representing what properties are true of each given object. In addition to these properties, whose extensions are shared between speaker and hearer, there are other properties, which are being conveyed from speaker to hearer. For example, the speaker may white poodle is to convey the new information that the referent of ‘the white poodle’ is pregnant. GRE ‘sees’ the first, shared KB only. We will restrict attention to the problem of determining the semantic content of a description, leaving linguistic realization aside. (Cf. Stone and Webber 1998, Krahmer and Theune 1999, which interleave linguistic realization and generation.) Accordingly, ‘Generation of Refer- Expressions’ will refer specifically to content determination. We will call a GRE algoit is successful whenever an individuating description exists. Most GRE algorithms are limited to individual target objects (for an exception, Stone 2000), but we will present that refer to objects (Van Deemter reference to an individual will equal reference to the singleton set . 2.1 The Incremental Algorithm Dale and Reiter (1995) proposed an algorithm that takes a shared KB as its input and delivers a set of properties which jointly identify the target. Descriptions produced by the algorithm fullfill criterion of According to this principle, a description is semantically correct if it has the target as its referent (i.e., its extension). The authors observed that a semantically correct description can still be unnatural, but that naturalness is not always easy to achieve. In particular, the problem of finding a (‘Full Brevity’) description that contains the minimum number of propis computationally and human speakers often produce non-minimal descriptions. they proposed an algorithm that ap- Brevity, while being of only linear complexity. The algorithm produces a finite of properties such that the section of their denotations the target set , causing to be a tinguishing description’ of . The properties in are selected one by one, and there is no backtracking, which is why the algorithm is called Incremental. As a result, some of the properties in may be logically superfluous. simplicity, we will focus here on without separating them into Attributes and Values (see also Reiter and Dale 2000, section 5.4.5). Accordingly, reflecting the fact that not all properties are equally ‘preferred’, they are ordered linearly in a list IP, with more preferred ones preceding less preferred ones. We also simplify by not taking the special treatment of head nouns into account. Suppose is the target set, and is the of elements from which is to be The algorithm iterates through IP; for each property, it checks whether it would rule out at least one member of that has not already been ruled out; if so, the property is added to . Members that are ruled out are removed from . The process of expanding and contracting continues until ; if and when this condition is is a distinguishing set of properties. have chosen a formulation in which is a superset of , rather than a ‘contrast set’, from whose elements those of must be distinguished (Dale and Reiter 1995). The difference is purely presentational. is initialized to the empty set For each do If distractors from but keeps all elements of Then do All elements outside are removed from then Return properties in PI have been tested, yet algorithm, constructs better and better approximations of the target set . Assuming (cf. Dale and Reiter 1995) that the tests in the body of the loop take some constant amount of time, the worst-case running time is in the order of (i.e., ) where is the total of properties. 3 Reference using Boolean descriptions Based on co-extensivity, the algorithms discussed construct an intersective Boolean expression (i.e., an expression of the form , are atomic) that has the target set as its extension. But, intersection is not the only operation on sets. Consider a KB whose domain is a set of dogs ( ) and whose only In this situation, D&amp;R does not allow us to individuate any of the dogs. In fact, however, the KB should enable one to refer to dog , since it is only black dog that is poodle: similar gap exists where be used. For example, D&amp;R does not make set of dogs that are either white or poodles referwhereas it in English, e.g., ‘The white dogs and the poodles’. we will investigate how take negation and disjunction into account. Section will ask how can achieve Full Boolean Completeness; section 3.2, which follows Van Deemter (2001), adds Brevity as a requirement. Boolean descriptions do the same thing that intersective descriptions do, except in a more dramatic way: they ‘create’ even more structure. As a result, the problem of optimizing these structures with respect to constraints such as Brevity becomes harder as well. As a first step, we show how one can tell which targets are identifiable given a set of properties and set intersection. We calculate, for each element in the domain, the ‘Satellite set’ of , that is, the intersection of the extensions of all the properties that are true of . Taking all extensions from our example, If two objects occur in the same Satellite set then no intersective description can separate them: any description true of one must be true of the other. It follows, for example, that no object in the domain is uniquely identifiable, since none of them occurs in a Satellite set that is a singleton. 3.1 Boolean descriptions (i): generate and simplify Boolean completeness is fairly easy to achieve constraints are added. Suppose the task is to construct a description of a target set , given a set PI of atomic properties, without any further constraints. We will discuss an algorithm that starts by calculating a generalized type of Satellite sets, based on all atomic properties and their of Satellite IP PI PI For each do IP Property is added to dog , poodle black , white First, the algorithm adds to PI the properties whose extensions are the complements of those in IP. Then it calculates, for each element in by lining up all the properties in that are true of , then taking the tion of their extensions. Satellite sets may be exploited for the construction of descriptions by forming the union of a number of expressions, each of which is the intersection of the elements of (for some ). By Satellite sets Description Meaning that returned instead of since the latter is just the set .) Dea set of sets of sets of domain ob- As is made explicit in this thirdorder set is interpreted as a union of intersections. successful if it evaluates to the target set ; otherwise the algorithm returns If returned, Boolean descripof is computationally cheap: it has a worstrunning time of , where is the ber of objects in , and the number of atomic properties. Rather than searching among all the possible unions of some large set of sets, a set is described as the union of sets, each of which equals the intersection of those (at most ) sets inIP that contain . Descriptions can make use of the Satellite sets computed for earlier descriptions, causing a further reduction of time. Satellites sets can even calculated for all the elements in the domain, before the need for specific referring exhas the descriptions produced by tend to be far from brief: . . . describe the target set , for examthe algorithm generates the . Consequently, the boolean expression generated is But of course, a much shorter description, , would have sufficed. What are the prospects for the output of Unfortunately, perfect simplification (i.e., Full Brevity) is incompatible with computational tractibility. Suppose brevity of descriptions is defined as follows: less brief than if only atomic properties while contains non-atomic as well, more Boolean operators than . Then the intractability of Full Brevity for intersections of atomic properties logically implies that of the new algorithm: an algorithm, produced a maximally brief Boolean description whenever one exists. Then whenever a target set be described as an intersection of ) would be a maximally brief intersection of atomic properties, and this is inconsistent with the intractability of Full Brevity for intersections of atomic properties. Bateman (1999), where a compiled into a format that brings out the commonalities between objects before the content of a referring expression is determined. . Return Boolean Completeness: any set , is obtainable by a sequence of boolean operations on the properties in PI if and only if equals . implication from right to left is obvious. For the reverse direction, suppose . Then for some , Satellites contains an element that is not in . But Satellites implies that every set in PI must either contain both of and , or neither. It follows that , which contains only of , cannot be obtained by a tion of Boolean operations on the sets in IP. This negative result gives rise to the question Full Brevity may be perhaps in the spirit of Reiter (1990)’s ‘Local Brevity’ algorithm which takes a given intersective description and tests whether any set of properties in it may be replaced by one other property. Unfortunately, however, simplification is much harder in the Boolean setting. Suppose, for example, one wanted to use the Quine-McCluskey algorithm (McCluskey 1965), known from its applications to electronic circuits, to reduce the number of Boolean operators in the description. This would go only a small part of the way, since Quine-McCluskey assumes logical independence of all the properties involved. Arbitrarily cominformation about the properties can affect the simplification task, and this reintroduces the spectre of computationally in- Moreover, the ‘generate and simplify’ approach has other disadvantages in addition. In particular, the division into two phases, the first of which generates an unwieldy description while the second simplifies it, makes it psychologically unrealistic, at least as a model for speaking. Also, unlike the Incremental algorithm, it treats all properties alike, regardless of their degree of preferedness. For these reasons, it is worthwhile to look for an alternative approach, which takes the Incremental algorithm as its point departure. This does not mean that useless: we suggest that it is used for determining whether a Boolean description exists; if not, the returns if a Boolean description is possible, the computationally more expensive algorithm of the following section is called. 3.2 Boolean descriptions (ii): extending the Incremental algorithm In this section, we will explore how the Incremental algorithm may be generalized to take all Boolean combinations into account. Given that the Incremental algorithm deals with intersections example, the automatic simplificator at http://logik.phl.univie.ac.at/chris/qmoonly reduce our description to if it ‘knows’ that being black, in this is tantamount to not being white. To reduce even further, the program needs to know that all elements in the domain are dogs. In more complex cases, equalities between complex intersections and/or unions can be relevant. between sets, Full Boolean Completeness can be by the addition of Set may be added to as follows. First we add negations to the list of atomic proper- (much like the earlier Then a number of times: first, in phase 1, the algorithm is performed using all positive and negative literals; if this algorithm ends before , phase 2 is entered in which further distractors are removed from using negations of of two literals, and so on, until eior all combinations tried Observe that the negation of an intersection comes down to set union, because of De Morgan’s Law: . Thus, phase 2 of the algorithm deals with disjunctions of length 2, phase 3 deals with of length 3, A schematic presentation will be useful, in which stands for any positive or negative literal. a property will equal the number of literals occurring in it. We will say that a D&amp;R set of properties if it loops through the properties in (i.e., takes the place ofPI in original Perform a D&amp;R phase using propof the form if this phase is successful then stop, otherwise go to phase (2). 2. Based on the Values of and coming out of phase (1), a D&amp;R phase using properof the form if this phase is successful then stop, otherwise go to phase (3). Based on the Values of and coming out of phase (2), a D&amp;R phase using properof the form if this phase is successful then stop, otherwise go to phase (4). One can require without loss of generality that no property, considered at any phase, may have occurrences of the same Since, therefore, at phase , there is room for properties of length , the maximal number of phases equals the total number of atomic properties in the language. that D&amp;R is incremental in two different ways: within a phase, and from one phase to the next. The latter guarantees that shorter disjunctions are favoured over longer ones. Once a property has been selected, it will not be abandoned even if properties selected during later phases make it superfluous. As a result, one may generate descriptions like (i.e., ‘white (cats and dogs)’) when (i.e., ‘cats and dogs’) would have sufficed. The empirical correctness of this type of incrementality is debatable, but repairs can be made if Unfortunately, however, the algorithm is not tractable as it stands. To estimate its running time as a function of the number of properties ( ) in the KB and the number of properties used in the description ( ), note that the maximal number of properties to be considered equals (The factor of derives from inspecting both each atom and its negation.) If then this in the order of To avoid intractability, the algorithm can be pruned. No matter where this is done, the result is polynomial. By cutting off after phase (1), for example, we generate negations of atomic properties only, producing such descriptions as ‘the black dog that is poodle’, while disregarding more complex descriptions. As a result, Boolean completeness is lost, but only for references to non-singleton The number of properties to be considered main, or the property , which is equivalent to the earlier-considered property . phases might run separately before running in combination: first phase 1, then 2, 1&amp;2, 3, 1&amp;3, 2&amp;3, 1&amp;2&amp;3, etc. (Suggested by Richard Power.) an analogous argument in Dale and Reiter (1995, section 3.1.1). individuates the individualthen either or does. Where are concerned, set union does not add descriptive power. by this simpler algorithm equals . one wanted to produce more complex descriptions like (‘the white dogs and the poodles’), the algorithm might be cut off one phase later, leading to a worst-case running time of . 4 Discussion Hybrid algorithms, which make use of elements of both algorithms, are possible. In particular, the idea of incrementality can be injected into the and simplify of section 3.1, at the level of the construction of Satellite sets (i.e., by letting take into account only those properties from PI that are necessary for singling out ) and, secondly, where the union of is formed in by taking only those into account that change the Instead of offering any details on this, we choose to discuss a more general relating to the problem of Form was noted in section 1. GRE algorithms exploit a principle of coextensivity for determining what are semantically correct ways of referring to an entity. Thus, consistent with the idea of logic-oriented generation, the of the description is not the syntactic form of the input to the generator (i.e., by the fact that the input contains an individual constant rather than a description). As a result, GRE can ‘create’ substantial amounts of new semantic structure containing, for example, any number of Boolean operators. In section 1, it was suggested that the processes of structure transformation used in GRE might have wider applicability. The present section questions the validity of coextensivity as a general principle, first for GRE (section 4.1), then for sentence aggregation (section 4.2). 4.1 Descriptions in intensional contexts principle of co-extensivity is not valid in in- For example, consider (a) John knows that [the red button] is dangerous (b) John knows that [the rocket launching button] is dangerous. example, it is useless to consider the property which must be true of any element in the do- (a) and (b) have different truth conditions even if and hearer share the information that button rocket launching In other words, the two descriptions are not interchangeable, even if reader and hearer know them to be what would be necessary is for to know that they are coextensive. Extending current GRE algorithms to the generation of referring expressions in intensional contexts is likely to be a difficult enterprise. Failiure of substitutivity in intensional contexts is, of course, a well-known problem, for which various solutions are available on the theoretical market (e.g., Montague 1973, Barwise and Perry 1983). But one has to wonder whether cois sufficient. Consider extensional truncations of (a) and (b), such as may be generated from an input I(1) (where the semantic predicate ‘dangerous’ is abbreviated as and is a constant referring to the button): Suppose (a) and (b) are semantically interchangeable (e.g., when said to someone who knows the colours and functions of all objects in the domain), so a choice between them can only be motivated by an appeal to pragmatic principles. Even it is difficult to accept that the must be made regardless whether the input to the generator is I(1), I(2) or I(3): (Here that is for launching rockets; is the Russellian description operator.) Co-extensivity, after all, does not allow the generator to distinguish between I(1), I(2) and I(3), because these three have the same extension! Perhaps a weakened version of co-extensivity is which allows the generator to structure (e.g., when the input is I(1)), but not to structure (e.g., when the input is I(2) or I(3)). It is, however, unclear what the theoretical justification for such a limitation of coextensivity might be. Note that these problems become more dramatic as GRE is able to ‘invent’ more structure (e.g., elaborate Boolean structure, as discussed in section 3). Crucially, we have to assume that, in an ideal generator, there are many other pragmatic constraints than Brevity. One description can be chosen over another, for example, because it fullfills some additional communicative goal (Dale and Reiter 1995, section 2.4; also Stone and Webber 1998). Depending on the communicative goal, for example, (b) might be chosen over (a) because the properties that identify the why it is dangerous. Brevity will then have to be interpreted as ‘Brevity provided all the other constraints are fullfilled’. 4.2 Logic in sentence aggregation GRE algorithms are sometimes presented as if the principles underlying them were unrelated to those underlying other components of an NLG This is especially true for the logicbased structure transformations on which this paper has focused. In what follows, however, we will suggest that analogous transformations motivate some of the key operations in sentence aggregation (Reiter and Dale 2000, p.133-144). To ex- (and limiting the discussion to distribuonly) the choice between the (a) and (b) variants of (1)-(3) involves a decision as to whether information is expressed in one or more sentences: 1a. John is eating; Mary is eating; Carlos is eating. 1b. John, Mary and Carlos are eating. 2a. John is eating; John is drinking; John is taking a rest 2b. John is eating and drinking and taking a rest. 3a. If John is eating then Mary is eating; If Bill is eating then Mary is eating. 3b. If either John or Bill is eating then Mary is eating. Writing for (Kamp and Reyle 1993), the linguistic equivalence of (1a) and (1b) rests on the logical equivalence see Bateman (2000), where GRE and aggregation are linked. . I(1) ) red button] is dangerous ) rocket launching button] is dangerous Analogous to uses of Brevity in GRE, a preference for (1b) over (1a) might be motivated by a preference for a semantic structure with fewer logical operations. Examples (2)-(3) are not dissimilar to what we see in (1). For example, the following logical equivalences support the lin-</abstract>
<note confidence="0.950764909090909">guistic equivalence of (2a)/(2b) and (3a)/(3b): 1992. R. Dale. Referring Expressions: Constructing Descriptions in a Domain of Objects and Pro- Press, Cambridge. Dale and Reiter 1995. R. Dale and E. Reiter. Computational Interpretations of the Gricean Maximes in the Generation of Expressions. Science 233-263. Grice 1975. P. Grice. Logic and Conversation. In P. Cole and J. Morgan (Eds.), “Syntax and Semantics: Vol 3, Speech Acts”: 43-58. New York, Academic Press. 1 .</note>
<abstract confidence="0.9676595">2 . 3 . ( ), three properties, and , are aggregated into (i.e., to have each of the three properties and ). In ( ), two antecedents and are aggregated into before, a generator might prefer the (b) versions because they are structurally simpler than the logically equivalent (a) versions. In sentence aggregation, however, co-extensivity is not enough. For example, we expect ‘Eat(j)’ to be worded differently from ‘Eat(m)’, even if both propositions are true and consequently have the same extension. Unlike GRE, therefore, aggregarequires at least 5 Acknowledgment Thanks are due to Emiel Krahmer for discussion and comments.</abstract>
<note confidence="0.974386333333333">6 References Appelt 1987. D.E. Appelt. Bidirectional Grammars and the of Natural Language Generation systems. In Theo- Issues in Natural Language p.185-191. New Mexico State University, Las Cruces. Barwise and Perry 1983. J. Barwise and J. Perry. Situations</note>
<abstract confidence="0.690832555555556">and Attitudes. MIT Press. Bateman 1999. J.A. Bateman. Using Aggregation for Selecting Content when Generating Referring Expressions. In Procs. ACL-99, Univ. Maryland. the disjunction, which would be difficult to get if the transformation was performed at a syntactic level. some (e.g., epistemic) contexts, even logical equivalence is not enough. This mirrors the problems with coextensivity that were noted in connection with GRE.</abstract>
<note confidence="0.847667">and Reyle 1993. Discourse to Logic. Academic Publishers, Dordrecht. Krahmer and Theune 1999. E. Krahmer and M. Theune. Generating Descriptions in Context. In R. Kibble and K.</note>
<intro confidence="0.719189">van Deemter (Eds.), Procs. of ws. Generation of Nominal</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>1a. John is eating; Mary is eating; Carlos is eating.</title>
<marker></marker>
<rawString>1a. John is eating; Mary is eating; Carlos is eating.</rawString>
</citation>
<citation valid="false">
<authors>
<author>1b John</author>
</authors>
<title>Mary and Carlos are eating. 2a. John is eating; John is drinking; John is taking a rest 2b. John is eating and drinking and taking a rest. 3a. If John is eating then Mary is eating; If Bill is eating then Mary is eating. 3b. If either John or Bill is eating then Mary is eating.</title>
<marker>John, </marker>
<rawString>1b. John, Mary and Carlos are eating. 2a. John is eating; John is drinking; John is taking a rest 2b. John is eating and drinking and taking a rest. 3a. If John is eating then Mary is eating; If Bill is eating then Mary is eating. 3b. If either John or Bill is eating then Mary is eating.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<institution>Writing for (Kamp Dale</institution>
<location>Cambridge.</location>
<marker>Dale, 1992</marker>
<rawString>Writing for (Kamp Dale 1992. R. Dale. Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<journal>Computational Interpretations of the Gricean Maximes in the Generation of Referring Expressions. Cognitive Science</journal>
<volume>18</volume>
<pages>233--263</pages>
<marker>Dale, Reiter, </marker>
<rawString>Dale and Reiter 1995. R. Dale and E. Reiter. Computational Interpretations of the Gricean Maximes in the Generation of Referring Expressions. Cognitive Science 18: 233-263.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Logic</author>
<author>Conversation In P Cole</author>
<author>J Morgan</author>
</authors>
<title>Syntax and Semantics: Vol 3, Speech Acts”:</title>
<pages>43--58</pages>
<publisher>Academic Press.</publisher>
<location>New York,</location>
<marker>Logic, Cole, Morgan, </marker>
<rawString>Grice 1975. P. Grice. Logic and Conversation. In P. Cole and J. Morgan (Eds.), “Syntax and Semantics: Vol 3, Speech Acts”: 43-58. New York, Academic Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D E Appelt</author>
</authors>
<title>Bidirectional Grammars and the Design of Natural Language Generation systems.</title>
<booktitle>In Theoretical Issues in Natural Language Processing-3,</booktitle>
<pages>185--191</pages>
<institution>New Mexico State University, Las Cruces.</institution>
<marker>Appelt, </marker>
<rawString>Appelt 1987. D.E. Appelt. Bidirectional Grammars and the Design of Natural Language Generation systems. In Theoretical Issues in Natural Language Processing-3, p.185-191. New Mexico State University, Las Cruces.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Barwise</author>
<author>J Perry</author>
</authors>
<title>Situations and Attitudes.</title>
<publisher>MIT Press.</publisher>
<marker>Barwise, Perry, </marker>
<rawString>Barwise and Perry 1983. J. Barwise and J. Perry. Situations and Attitudes. MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J A Bateman</author>
</authors>
<title>Using Aggregation for Selecting Content when Generating Referring Expressions.</title>
<booktitle>In Procs. ACL-99, Univ.</booktitle>
<location>Maryland.</location>
<marker>Bateman, </marker>
<rawString>Bateman 1999. J.A. Bateman. Using Aggregation for Selecting Content when Generating Referring Expressions. In Procs. ACL-99, Univ. Maryland.</rawString>
</citation>
<citation valid="false">
<title>10Note the disjunction, which would be difficult to get if the transformation was performed at a syntactic level. 11In some (e.g., epistemic) contexts, even logical equivalence is not enough. This mirrors the problems with coextensivity that were noted in connection with GRE.</title>
<marker></marker>
<rawString>10Note the disjunction, which would be difficult to get if the transformation was performed at a syntactic level. 11In some (e.g., epistemic) contexts, even logical equivalence is not enough. This mirrors the problems with coextensivity that were noted in connection with GRE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamp</author>
<author>Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp and Reyle 1993. From Discourse to Logic. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Krahmer</author>
<author>M Theune</author>
</authors>
<title>Generating Descriptions in Context. In</title>
<date></date>
<marker>Krahmer, Theune, </marker>
<rawString>Krahmer and Theune 1999. E. Krahmer and M. Theune. Generating Descriptions in Context. In R. Kibble and K. van Deemter (Eds.), Procs. of ws. Generation of Nominal Expressions, ESSLLI’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J McCluskey</author>
</authors>
<title>Introduction to the Theory of Switching.</title>
<date>1973</date>
<booktitle>The Proper treatment of Quantification in Ordinary English. In R.H.Thomason (ed.) Formal Philosophy.</booktitle>
<editor>R. Montague.</editor>
<publisher>Yale University Press,</publisher>
<location>New York. McGraw-Hill. Montague</location>
<marker>McCluskey, 1973</marker>
<rawString>McCluskey 1965. McCluskey, Jr., E.J. Introduction to the Theory of Switching. New York. McGraw-Hill. Montague 1973. R. Montague. The Proper treatment of Quantification in Ordinary English. In R.H.Thomason (ed.) Formal Philosophy. Yale University Press, New Haven.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R J D Power</author>
</authors>
<title>Planning texts by constraint satisfaction.</title>
<booktitle>Procs of the 18th Int. Conf. on Computational Linguistics (COLING-2000), Saarbruecken,</booktitle>
<pages>642--648</pages>
<marker>Power, </marker>
<rawString>Power 2000. R.J.D. Power. Planning texts by constraint satisfaction. Procs of the 18th Int. Conf. on Computational Linguistics (COLING-2000), Saarbruecken, pp. 642-648.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Reiter</author>
</authors>
<title>The Computational Complexity of Avoiding Conversational Implicatures.</title>
<booktitle>In Proc. ACL-1990,</booktitle>
<location>Pittsburgh.</location>
<marker>Reiter, </marker>
<rawString>Reiter 1990. E. Reiter. The Computational Complexity of Avoiding Conversational Implicatures. In Proc. ACL-1990, Pittsburgh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Reiter</author>
<author>R Dale</author>
</authors>
<title>Building Natural language Generation Systems.</title>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Reiter, Dale, </marker>
<rawString>Reiter and Dale 2000. E. Reiter and R. Dale. Building Natural language Generation Systems. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Shieber</author>
</authors>
<title>The Problem of Logical-Form Equivalence.</title>
<journal>Squib in Computational Linguistics</journal>
<volume>19</volume>
<pages>1</pages>
<marker>Shieber, </marker>
<rawString>Shieber 1993. S. Shieber. The Problem of Logical-Form Equivalence. Squib in Computational Linguistics 19, 1.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Stone</author>
</authors>
<title>On Identifying Sets.</title>
<booktitle>In Procs. of INLG-2000,</booktitle>
<location>Mitzpe Ramon.</location>
<marker>Stone, </marker>
<rawString>Stone 2000. M. Stone. On Identifying Sets. In Procs. of INLG-2000, Mitzpe Ramon.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Stone</author>
<author>B Webber</author>
</authors>
<title>Textual Economy through Close Coupling of Syntax and Semantics.</title>
<booktitle>In Procs. ofINLG-1998,</booktitle>
<pages>178--187</pages>
<marker>Stone, Webber, </marker>
<rawString>Stone and Webber 1998. M. Stone and B. Webber. Textual Economy through Close Coupling of Syntax and Semantics. In Procs. ofINLG-1998, p.178-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>van Deemter</author>
</authors>
<date>1990</date>
<booktitle>Structured Meanings in Computational Linguistics. In Procs. of COLING-1990,</booktitle>
<location>Helsinki.</location>
<marker>van Deemter, 1990</marker>
<rawString>van Deemter 1990. Structured Meanings in Computational Linguistics. In Procs. of COLING-1990, Helsinki.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K van Deemter</author>
</authors>
<title>Generating Vague Descriptions.</title>
<booktitle>In Procs. of INLG-2000,</booktitle>
<location>Mitzpe Ramon.</location>
<marker>van Deemter, </marker>
<rawString>van Deemter 2000. K. van Deemter. Generating Vague Descriptions. In Procs. of INLG-2000, Mitzpe Ramon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>van Deemter</author>
</authors>
<title>Generating Referring Expressions: Beyond the Incremental Algorithm.</title>
<date>2001</date>
<booktitle>In Procs. of Int. Workshop on Computational Semantics (IWCS-4),</booktitle>
<location>Tilburg.</location>
<marker>van Deemter, 2001</marker>
<rawString>van Deemter 2001. Generating Referring Expressions: Beyond the Incremental Algorithm. In Procs. of Int. Workshop on Computational Semantics (IWCS-4), Tilburg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>