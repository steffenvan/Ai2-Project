<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001018">
<title confidence="0.971152">
Regular polysemy: A distributional model
</title>
<author confidence="0.989874">
Gemma Boleda Sebastian Pad´o Jason Utt
</author>
<affiliation confidence="0.996183">
Dept. of Linguistics ICL IMS
University of Texas at Austin University of Heidelberg University of Stuttgart
</affiliation>
<email confidence="0.996651">
gemma.boleda@upf.edu pado@cl.uni-heidelberg.de uttjn@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.995611" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999770928571428">
Many types of polysemy are not word specific,
but are instances of general sense alternations
such as ANIMAL-FOOD. Despite their perva-
siveness, regular alternations have been mostly
ignored in empirical computational semantics.
This paper presents (a) a general framework
which grounds sense alternations in corpus
data, generalizes them above individual words,
and allows the prediction of alternations for
new words; and (b) a concrete unsupervised
implementation of the framework, the Cen-
troid Attribute Model. We evaluate this model
against a set of 2,400 ambiguous words and
demonstrate that it outperforms two baselines.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98709432">
One of the biggest challenges in computational se-
mantics is the fact that many words are polysemous.
For instance, lamb can refer to an animal (as in The
lamb squeezed through the gap) or to a food item (as
in Sue had lamb for lunch). Polysemy is pervasive
in human language and is a problem in almost all
applications of NLP, ranging from Machine Trans-
lation (as word senses can translate differently) to
Textual Entailment (as most lexical entailments are
sense-specific).
The field has thus devoted a large amount of effort
to the representation and modeling of word senses.
The arguably most prominent effort is Word Sense
Disambiguation, WSD (Navigli, 2009), an in-vitro
task whose goal is to identify which, of a set of pre-
defined senses, is the one used in a given context.
In work on WSD and other tasks related to pol-
ysemy, such as word sense induction, sense alter-
nations are treated as word-specific. As a result, a
model for the meaning of lamb that accounts for the
relation between the animal and food senses cannot
predict that the same relation holds between instances
of chicken or salmon in the same type of contexts.
A large number of studies in linguistics and cog-
nitive science show evidence that there are regulari-
ties in the way words vary in their meaning (Apres-
jan, 1974; Lakoff and Johnson, 1980; Copestake
and Briscoe, 1995; Pustejovsky, 1995; Gentner et
al., 2001; Murphy, 2002), due to general analogical
processes such as regular polysemy, metonymy and
metaphor. Most work in theoretical linguistics has
focused on regular, systematic, or logical polysemy,
which accounts for alternations like ANIMAL-FOOD.
Sense alternations also arise from metaphorical use
of words, as dark in dark glass-dark mood, and also
from metonymy when, for instance, using the name
of a place for a representative (as in Germany signed
the treatise). Disregarding this evidence is empiri-
cally inadequate and leads to the well-known lexical
bottleneck of current word sense models, which have
serious problems in achieving high coverage (Navigli,
2009).
We believe that empirical computational semantics
could profit from a model of polysemy1 which (a) is
applicable across individual words, and thus capable
of capturing general patterns and generalizing to new
1Our work is mostly inspired in research on regular polysemy.
However, given the fuzzy nature of “regularity” in meaning
variation, we extend the focus of our attention to include other
types of analogical sense construction processes.
</bodyText>
<page confidence="0.970477">
151
</page>
<note confidence="0.972833">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 151–160,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999531357142857">
words, and (b) is induced in an unsupervised fashion
from corpus data. This is a long-term goal with many
unsolved subproblems.
The current paper presents two contributions to-
wards this goal. First, since we are working on a
relatively unexplored area, we introduce a formal
framework that can encompass different approaches
(Section 2). Second, we implement a concrete instan-
tiation of this framework, the unsupervised Centroid
Attribute Model (Section 3), and evaluate it on a new
task, namely, to detect which of a set of words in-
stantiate a given type of polysemy (Sections 4 and 5).
We finish with some conclusions and future work
(Section 7).
</bodyText>
<sectionHeader confidence="0.998775" genericHeader="method">
2 Formal framework
</sectionHeader>
<bodyText confidence="0.999981923076923">
In addition to introducing formal definitions for terms
commonly found in the literature, our framework pro-
vides novel terminology to deal with regular poly-
semy in a general fashion (cf. Table 1; capital letters
designate sets and small letters elements of sets).2
For a lemma l like lamb, we want to know
how well a meta alternation (such as ANIMAL-
FOOD) explains a pair of its senses (such as the
animal and food senses of lamb).3 This is for-
malized through the function score, which maps
a meta alternation and two senses onto a score.
As an example, let lambanm denote the ANIMAL
sense of lamb, lambfod the FOOD sense, and
lambh„m the PERSON sense. Then, an appropri-
ate model of meta alternations should predict that
score(animal, food, lambanm, lambfod) is greater
than score(animal, food, lambanm, lambh„m).
Meta alternations are defined as unordered pairs
of meta senses, or cross-word senses like ANIMAL.
The meta senses M can be defined a priori or induced
from data. They are equivalence classes of senses to
which they are linked through the function meta. A
sense s instantiates a meta sense m iff meta(s) =
m. Functions inst and sns allow us to define meta
senses and lemma-specific senses in terms of actual
instances, or occurrences of words in context.
</bodyText>
<footnote confidence="0.7980464">
2We re-use inst as a function that returns the set of instances
for a sense: SL --+ fp(IL) and assume that senses partition
lemmas’ instances: `dl : inst(l) = UsEsns(l) inst(s).
3Consistent with the theoretical literature, this paper focuses
on two-way polysemy. See Section 7 for further discussion.
</footnote>
<figure confidence="0.81146675">
L set of lemmas
IL set of (lemma-wise) instances
SL set of (lemma-wise) senses
inst: L → V(IL) mapping lemma → instances
sns: L → V(SL) mapping lemma → senses
M set of meta senses
meta: SL → M mapping senses → meta senses
A C_ M x M set of meta alternations (MAs)
a set of MA representations
score: A x SL → ]IR scoring function for MAs
repA : A → a MA representation function
comp: % xSL → ]IR compatibility function
</figure>
<tableCaption confidence="0.997496">
Table 1: Notation and signatures for our framework.
</tableCaption>
<bodyText confidence="0.998339285714286">
We decompose the score function into two parts:
a representation function repA that maps a meta al-
ternation into some suitable representation for meta
alternations, 91, and a compatibility function comp
that compares the relation between the senses of a
word to the meta alternation’s representation. Thus,
comp o repA = score.
</bodyText>
<sectionHeader confidence="0.983066" genericHeader="method">
3 The Centroid Attribute Model
</sectionHeader>
<bodyText confidence="0.988934739130435">
The Centroid Attribute Model (CAM) is a simple
instantiation of the framework defined in Section 2,
designed with two primary goals in mind. First, it is
a data-driven model. Second, it does not require any
manual sense disambiguation, a notorious bottleneck.
To achieve the first goal, CAM uses a distribu-
tional approach. It represents the relevant entities as
co-occurrence vectors that can be acquired from a
large corpus (Turney and Pantel, 2010). To achieve
the second goal, CAM represents meta senses using
monosemous words only, that is, words whose senses
all correspond to one meta sense. 4 Examples are
cattle and robin for the meta sense ANIMAL. We
define the vector for a meta sense as the centroid (av-
erage vector) of the monosemous words instantiating
it. In turn, meta alternations are represented by the
centroids of their meta senses’ vectors.
This strategy is not applicable to test lemmas,
which instantiate some meta alternation and are by
definition ambiguous. To deal with these without
410.8% of noun types in the corpus we use are monosemous
and 2.3% are disemous, while, on a token level, 23.3% are
monosemous and 20.2% disemous.
</bodyText>
<page confidence="0.944173">
152
</page>
<equation confidence="0.99902625">
vecI : IL → Rk instance vector computation
(t: Rkxm → Rk centroid computation
vecL : L → Rk lemma (type) vector computation
repM : M → Rk meta sense representation
</equation>
<tableCaption confidence="0.989049">
Table 3: Additional notation and signatures for CAM
</tableCaption>
<bodyText confidence="0.999039535714286">
explicit sense disambiguation, CAM represents lem-
mas by their type vectors, i.e., the centroid of their
instances, and compares their vectors (attributes) to
those of the meta alternation – hence the name.
CoreLex: A Semantic Inventory. CAM uses
CoreLex (Buitelaar, 1998) as its meta sense inven-
tory. CoreLex is a lexical resource that was designed
specifically for the study of polysemy. It builds on
WordNet (Fellbaum, 1998), whose sense distinctions
are too fine-grained to describe general sense al-
ternations. CoreLex defines a layer of abstraction
above WordNet consisting of 39 basic types, coarse-
grained ontological classes (Table 2). These classes
are linked to one or more Wordnet anchor nodes,
which define a mapping from WordNet synsets onto
basic types: A synset s maps onto a basic type b if b
has an anchor node that dominates s and there is no
other anchor node on the path from b and s.5
We adopt the WordNet synsets as 5, the set of
senses, and the CoreLex basic types as our set of
meta senses M. The meta function (mapping word
senses onto meta senses) is given directly by the an-
chor mapping defined in the previous paragraph. This
means that the set of meta alternations is given by the
set of pairs of basic types. Although basic types do
not perfectly model meta senses, they constitute an
approximation that allows us to model many promi-
nent alternations such as ANIMAL-FOOD.
</bodyText>
<subsectionHeader confidence="0.505025">
Vectors for Meta Senses and Alternations. All
</subsectionHeader>
<bodyText confidence="0.9993445">
representations used by CAM are co-occurrence vec-
tors in Rk (i.e., 9 := Rk). Table 3 lists new concepts
that CAM introduces to manipulate vector represen-
tations. vecI returns a vector for a lemma instance,
vecL a (type) vector for a lemma, and (t the centroid
of a set of vectors.
We leave vecI and (t unspecified: we will experi-
ment with these functions in Section 4. CAM does fix
</bodyText>
<footnote confidence="0.981578">
5This is necessary because some classes have non-disjoint
anchor nodes: e.g., ANIMALs are a subset of LIVING BEINGs.
</footnote>
<bodyText confidence="0.9789065">
the definitions for vecL and repA. First, vecL defines
a lemma’s vector as the centroid of its instances:
</bodyText>
<equation confidence="0.999344">
vecL(l) = (t{vecI(i)  |i ∈ inst(l)} (1)
</equation>
<bodyText confidence="0.998365">
Before defining repA, we specify a function repM
that computes vector representations for meta senses
m. In CAM, this vector is defined as the centroid
of the vectors for all monosemous lemmas whose
WordNet sense maps onto m:
</bodyText>
<equation confidence="0.999457">
repM(m) = (t{vecL(l)  |meta(sns(l)) = {m}} (2)
</equation>
<bodyText confidence="0.951921">
Now, repA can be defined simply as the centroid of
the meta senses instantiating a:
</bodyText>
<equation confidence="0.994248">
repA(m1, m2) = (t{repM(m1), repM(m2)} (3)
</equation>
<bodyText confidence="0.9705972">
Predicting Meta Alternations. The final compo-
nent of CAM is an instantiation of comp (cf. Table 1),
i.e., the degree to which a sense pair (s1, s2) matches
a meta alternation a. Since CAM does not represent
these senses separately, we define comp as
</bodyText>
<equation confidence="0.9491756">
comp(a, s1, s2) = sim(a, vecL(l))4
so that {s1, s2} = sns(l) ( )
The complete model, score, can now be stated as:
score(m, m&apos;, s, s&apos;) = sim(repA(m, m&apos;), vecL(l))
so that {s, s&apos;} = sns(l) (5)
</equation>
<bodyText confidence="0.999608833333334">
CAM thus assesses how well a meta alternation
a = (m, m&apos;) explains a lemma l by comparing the
centroid of the meta senses m, m&apos; to l’s centroid.
Discussion. The central feature of CAM is that
it avoids word sense disambiguation, although it
still relies on a predefined sense inventory (Word-
Net, through CoreLex). Our use of monosemous
words to represent meta senses and meta alternations
goes beyond previous work which uses monosemous
words to disambiguate polysemous words in context
(Izquierdo et al., 2009; Navigli and Velardi, 2005).
Because of its focus on avoiding disambiguation,
CAM simplifies the representation of meta alterna-
tions and polysemous words to single centroid vec-
tors. In the future, we plan to induce word senses
(Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and
Mooney, 2010), which will allow for more flexible
and realistic models.
</bodyText>
<page confidence="0.958474">
153
</page>
<bodyText confidence="0.9737896">
abs ABSTRACTION ent ENTITY loc LOCATION prt PART
act ACT evt EVENT log GEO. LOCATION psy PSYCHOL. FEATURE
agt AGENT fod FOOD mea MEASURE qud DEFINITE QUANTITY
anm ANIMAL frm FORM mic MICROORGANISM qui INDEFINITE QUANTITY
art ARTIFACT grb BIOLOG. GROUP nat NATURAL BODY rel RELATION
atr ATTRIBUTE grp GROUPING phm PHENOMENON spc SPACE
cel CELL grs SOCIAL GROUP pho PHYSICAL OBJECT sta STATE
chm CHEMICAL hum HUMAN plt PLANT sub SUBSTANCE
com COMMUNICATION lfr LIVING BEING pos POSSESSION tme TIME
con CONSEQUENCE lme LINEAR MEASURE pro PROCESS pro PROCESS
</bodyText>
<tableCaption confidence="0.994997">
Table 2: CoreLex’s basic types with their corresponding WordNet anchors. CAM adopts these as meta senses.
</tableCaption>
<sectionHeader confidence="0.994049" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999962111111111">
We test CAM on the task of identifying which lem-
mas of a given set instantiate a specific meta alterna-
tion. We let the model rank the lemmas through the
score function (cf. Table (1) and Eq. (5)) and evaluate
the ranked list using Average Precision. While an
alternative would be to rank meta alternations for a
given polysemous lemma, the method chosen here
has the benefit of providing data on the performance
of individual meta senses and meta alternations.
</bodyText>
<subsectionHeader confidence="0.991622">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999922818181818">
All modeling and data extraction was carried out on
the written part of the British National Corpus (BNC;
Burnage and Dunlop (1992)) parsed with the C&amp;C
tools (Clark and Curran, 2007). 6
For the evaluation, we focus on disemous words,
words which instantiate exactly two meta senses
according to WordNet. For each meta alternation
(m, m&apos;), we evaluate CAM on a set of disemous tar-
gets (lemmas that instantiate (m, m&apos;)) and disemous
distractors (lemmas that do not). We define three
types of distractors: (1) distractors sharing m with
the targets (but not m&apos;), (2) distractors sharing m&apos;
with the targets (but not m), and (3) distractors shar-
ing neither. In this way, we ensure that CAM cannot
obtain good results by merely modeling the similarity
of targets to either m or m&apos;, which would rather be a
coarse-grained word sense modeling task.
To ensure that we have enough data, we evaluate
CAM on all meta alternations with at least ten targets
that occur at least 50 times in the corpus, discarding
nouns that have fewer than 3 characters or contain
non-alphabetical characters. The distractors are cho-
</bodyText>
<footnote confidence="0.667225">
6The C&amp;C tools were able to reliably parse about 40M words.
</footnote>
<bodyText confidence="0.998897875">
sen so that they match targets in frequency. This
leaves us with 60 meta alternations, shown in Ta-
ble 5. For each meta alternation, we randomly select
40 lemmas as experimental items (10 targets and 10
distractors of each type) so that a total of 2,400 lem-
mas is used in the evaluation.7 Table 4 shows four
targets and their distractors for the meta alternation
ANIMAL-FOOD.8
</bodyText>
<subsectionHeader confidence="0.999412">
4.2 Evaluation Measure and Baselines
</subsectionHeader>
<bodyText confidence="0.999984571428571">
To measure success on this task, we use Average
Precision (AP), an evaluation measure from IR that
reaches its maximum value of 1 when all correct
items are ranked at the top (Manning et al., 2008).
It interpolates the precision values of the top-n pre-
diction lists for all positions n in the list that con-
tain a target. Let T = (q1, ... , qm) be the list of
targets, and let P = (p1, ... , pn) be the list of pre-
dictions as ranked by the model. Let I(xi) = 1 if
pi E T, and zero otherwise. Then AP(P,T) =
m �m 1 I (xi) �&apos;= i (xi) . AP measures the quality
of the ranked list for a single meta alternation. The
overall quality of a model is given by Mean Average
Precision (MAP), the mean of the AP values for all
meta alternations.
We consider two baselines: (1) A random baseline
that ranks all lemmas in random order. This baseline
is the same for all meta alternations, since the distri-
bution is identical. We estimate it by sampling. (2)
A meta alternation-specific frequency baseline which
orders the lemmas by their corpus frequencies. This
</bodyText>
<footnote confidence="0.774655">
7Dataset available at http://www.nlpado.de/
˜sebastian/data.shtml.
8Note that this experimental design avoids any overlap be-
tween the words used to construct sense vectors (one meta sense)
and the words used in the evaluation (two meta senses).
</footnote>
<page confidence="0.999084">
154
</page>
<subsectionHeader confidence="0.73797">
Targets Distractors with meta sense anm Distractors with meta sense fod Random distractors
</subsectionHeader>
<bodyText confidence="0.86625875">
carp amphibian (anm-art) mousse (art-fod) appropriation (act-mea)
duckling ape (anm-hum) parsley (fod-plt) scissors (act-art)
eel leopard (anm-sub) pickle (fod-sta) showman (agt-hum)
hare lizard (anm-hum) pork (fod-mea) upholstery (act-art)
</bodyText>
<tableCaption confidence="0.968317">
Table 4: Sample of experimental items for the meta alternation anm-fod. (Abbreviations are listed in Table 2.)
</tableCaption>
<bodyText confidence="0.9981505">
baseline uses the intuition that frequent words will
tend to exhibit more typical alternations.
</bodyText>
<subsectionHeader confidence="0.999632">
4.3 Model Parameters
</subsectionHeader>
<bodyText confidence="0.999952357142857">
There are four more parameters to set.
Definition of vector space. We instantiate the vecI
function in three ways. All three are based on
dependency-parsed spaces, following our intuition
that topical similarity as provided by window-based
spaces is insufficient for this task. The functions dif-
fer in the definition of the space’s dimensions, incor-
porating different assumptions about distributional
differences among meta alternations.
The first option, gram, uses grammatical paths
of lengths 1 to 3 as dimensions and thus character-
izes lemmas and meta senses in terms of their gram-
matical context (Schulte im Walde, 2006), with a
total of 2,528 paths. The second option, lex, uses
words as dimensions, treating the dependency parse
as a co-occurrence filter (Pad´o and Lapata, 2007),
and captures topical distinctions. The third option,
gramlex, uses lexicalized dependency paths like
obj–see to mirror more fine-grained semantic proper-
ties (Grefenstette, 1994). Both lex and gramlex
use the 10,000 most frequent items in the corpus.
Vector elements. We use “raw” corpus co-
occurrence frequencies as well as log-likelihood-
transformed counts (Lowe, 2001) as elements of the
co-occurrence vectors.
Definition of centroid computation. There are
three centroid computations in CAM: to combine
instances into lemma (type) vectors (function vecL
in Eq. (1)); to combine lemma vectors into meta
sense vectors (function repM in Eq. (2)); and to com-
bine meta sense vectors into meta alternation vectors
(function repA in Eq. (3)).
For vecL, the obvious definition of the centroid
function is as a micro-average, that is, a simple av-
erage over all instances. For repM and repA, there
is a design choice: The centroid can be computed
by micro-averaging as well, which assigns a larger
weight to more frequent lemmas (repM) or meta
senses (repA). Alternatively, it can be computed
by macro-averaging, that is, by normalizing the in-
dividual vectors before averaging. This gives equal
weight to the each lemma or meta sense, respectively.
Macro-averaging in repA thus assumes that senses
are equally distributed, which is an oversimplifica-
tion, as word senses are known to present skewed
distributions (McCarthy et al., 2004) and vectors for
words with a predominant sense will be similar to the
dominant meta sense vector. Micro-averaging par-
tially models sense skewedness under the assumption
that word frequency correlates with sense frequency.
Similarity measure. As the vector similarity mea-
sure in Eq. (5), we use the standard cosine similar-
ity (Lee, 1999). It ranges between −1 and 1, with 1
denoting maximum similarity. In the current model
where the vectors do not contain negative counts, the
range is [0; 1].
</bodyText>
<sectionHeader confidence="0.999945" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.9996645">
Effect of Parameters The four parameters of Sec-
tion 4.3 (three space types, macro-/micro-averaging
for repM and repA, and log-likelihood transforma-
tion) correspond to 24 instantiations of CAM.
Figure 1 shows the influence of the four parame-
ters. The only significant difference is tied to the use
of lexicalized vector spaces (gramlex / lex are
better than gram). The statistical significance of this
difference was verified by a t-test (p &lt; 0.01). This
indicates that meta alternations can be characterized
better through fine-grained semantic distinctions than
by syntactic ones.
The choice of micro- vs. macro-average does not
have a clear effect, and the large variation observed
in Figure 1 suggests that the best setup is dependent
on the specific meta sense or meta alternation being
</bodyText>
<page confidence="0.997405">
155
</page>
<figureCaption confidence="0.972370666666667">
Figure 1: Effect of model parameters on performance. A
data point is the mean AP (MAP) across all meta alterna-
tions for a specific setting.
</figureCaption>
<bodyText confidence="0.994945479452055">
modeled. Focusing on meta alternations, whether the
two intervening meta senses should be balanced or
not can be expected to depend on the frequencies of
the concepts denoted by each meta sense, which vary
for each case. Indeed, for AGENT-HUMAN, the alter-
nation which most benefits from the micro-averaging
setting, the targets are much more similar to the HU-
MAN meta sense (which is approximately 8 times as
frequent as AGENT) than to the AGENT meta sense.
The latter contains anything that can have an effect on
something, e.g. emulsifier, force, valium. The targets
for AGENT-HUMAN, in contrast, contain words such
as engineer, manipulator, operative, which alternate
between an agentive role played by a person and the
person herself.
While lacking in clear improvement, log-
likelihood transformation tends to reduce variance,
consistent with the effect previously found in selec-
tional preference modeling (Erk et al., 2010).
Overall Performance Although the performance
of the CAM models is still far from perfect, all 24
models obtain MAP scores of 0.35 or above, while
the random baseline is at 0.313, and the overall fre-
quency baseline at 0.291. Thus, all models con-
sistently outperform both baselines. A bootstrap
resampling test (Efron and Tibshirani, 1994) con-
firmed that the difference to the frequency baseline
is significant at p &lt; 0.01 for all 24 models. The
difference to the random baseline is significant at
p &lt; 0.01 for 23 models and at p &lt; 0.05 for the
remaining model. This shows that the models cap-
ture the meta alternations to some extent. The best
model uses macro-averaging for repM and repA in
a log-likelihood transformed gramlex space and
achieves a MAP of 0.399.
Table 5 breaks down the performance of the best
CAM model by meta alternation. It shows an en-
couraging picture: CAM outperforms the frequency
baseline for 49 of the 60 meta alternations and both
baselines for 44 (73.3%) of all alternations. The per-
formance shows a high degree of variance, however,
ranging from 0.22 to 0.71.
Analysis by Meta Alternation Coherence Meta
alternations vary greatly in their difficulty. Since
CAM is an attribute similarity-based approach, we
expect it to perform better on the alternations whose
meta senses are ontologically more similar. We next
test this hypothesis.
Let D., = {dij} be the set of distractors for
the targets T = {tj} that share the meta sense mi,
and DR = {d3j} the set of random distractors. We
define the coherence K of an alternation a of meta
senses m1, m2 as the mean (0) difference between
the similarity of each target vector to a and the simi-
larity of the corresponding distractors to a, or for-
mally K(a) = o sim(repA(m1,m2),vecL(tj)) −
sim(repA(m1,m2),vecL(dij)), for 1 &lt; i &lt; 3 and
1 &lt; j &lt; 10. That is, K measures how much more
similar, on average, the meta alternation vector is to
the target vectors than to the distractor vectors. For a
meta alternation with a higher K, the targets should
be easier to distinguish from the distractors.
Figure 2 plots AP by K for all meta alternations.
As we expect from the definition of K, AP is strongly
correlated with K. However, there is a marked Y
shape, i.e., a divergence in behavior between high-
K and mid-AP alternations (upper right corner) and
mid-K and high-AP alternations (upper left corner).
In the first case, meta alternations perform worse
than expected, and we find that this typically points
to missing senses, that is, problems in the underlying
lexical resource (WordNet, via CoreLex). For in-
stance, the FOOD-PLANT distractor almond is given
</bodyText>
<figure confidence="0.99250075862069">
MACRO MICRO MACRO MICRO
repM repA
gram gramlex lex False True
space type LL transformation
0.35 0.37 0.39
0.35 0.37 0.39
0.35 0.37 0.39
0.35 0.37 0.39
●
156
grs-psy 0.709 com-evt 0.501 art-com 0.400 atr-com 0.361 art-frm 0.286
pro-sta 0.678
fod-plt 0.645
psy-sta 0.630
hum-prt 0.602
grp-psy 0.574
grs-log 0.573
act-evt 0.539
evt-psy 0.526
act-tme 0.523
art-pho 0.520
act-pro 0.513
art-grs 0.498
hum-psy 0.486
hum-nat 0.456
anm-hum 0.448
com-psy 0.443
act-grs 0.441
atr-rel 0.440
art-qui 0.433
act-sta 0.413
art-sub 0.412
art-log 0.407
act-pos 0.396
phm-sta 0.388
atr-psy 0.384
fod-hum 0.383
plt-sub 0.383
act-com 0.382
grp-grs 0.379
art-psy 0.373
art-prt 0.364
evt-sta 0.364
anm-fod 0.361
atr-sta 0.361
act-phm 0.339
anm-art 0.335
art-atr 0.333
act-psy 0.333
agt-hum 0.319
art-evt 0.314
atr-evt 0.312
art-sta 0.302
act-grp 0.296
com-hum 0.292
act-hum 0.281
art-fod 0.280
grs-hum 0.272
</figure>
<tableCaption confidence="0.814617636363636">
act-art 0.267
art-grp 0.258
art-nat 0.248
act-atr 0.246
art-hum 0.240
art-loc 0.238
art-pos 0.228
com-sta 0.219
Table 5: Meta alternations and their average precision values for the task. The random baseline performs at 0.313 while
the frequency baseline ranges from 0.255 to 0.369 with a mean of 0.291. Alternations for which the model outperforms
the frequency baseline are in boldface (mean AP: 0.399, standard deviation: 0.119).
</tableCaption>
<construct confidence="0.9986368">
grs-psy democracy, faculty, humanism, regime,
pro-sta bondage, dehydration, erosion,urbanization
psy-sta anaemia,delight, pathology, sensibility
hum-prt bum, contractor, peter, subordinate
grp-psy category, collectivism, socialism, underworld
</construct>
<tableCaption confidence="0.9702705">
Table 6: Sample targets for meta alternations with high
AP and mid-coherence values.
</tableCaption>
<bodyText confidence="0.999400045454545">
a PLANT sense by WordNet, but no FOOD sense. In
the case of SOCIAL GROUP-GEOGRAPHICAL LOCA-
TION, distractors laboratory and province are miss-
ing SOCIAL GROUP senses, which they clearly pos-
sess (cf. The whole laboratory celebrated Christmas).
This suggests that our approach can help in Word
Sense Induction and thesaurus construction.
In the second case, meta alternations perform bet-
ter than expected: They have a low rc, but a high
AP. These include grs-psy, pro-sta, psy-sta,
hum-prt and grp-psy. These meta alternations
involve fairly abstract meta senses such as PSYCHO-
LOGICAL FEATURE and STATE.9 Table 6 lists a
sample of targets for the five meta alternations in-
volved. The targets are clearly similar to each other
on the level of their meta senses. However, they can
occur in very different semantic contexts. Thus, here
it is the underlying model (the gramlex space) that
can explain the lower than average coherence. It is
striking that CAM can account for abstract words and
meta alternations between these, given that it uses
first-order co-occurrence information only.
</bodyText>
<footnote confidence="0.9459215">
9An exception is hum-prt. It has a low coherence because
many WordNet lemmas with a PART sense are body parts.
</footnote>
<figureCaption confidence="0.9970575">
Figure 2: Average Precision and Coherence (rc) for each
meta alternation. Correlation: r = 0.743 (p &lt; 0.001)
</figureCaption>
<sectionHeader confidence="0.999477" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999633214285714">
As noted in Section 1, there is little work in empiri-
cal computational semantics on explicitly modeling
sense alternations, although the notions that we have
formalized here affect several tasks across NLP sub-
fields.
Most work on regular sense alternations has fo-
cused on regular polysemy. A pioneering study is
Buitelaar (1998), who accounts for regular polysemy
through the CoreLex resource (cf. Section 3). A
similar effort is carried out by Tomuro (2001), but
he represents regular polysemy at the level of senses.
Recently, Utt and Pad´o (2011) explore the differences
between between idiosyncratic and regular polysemy
patterns building on CoreLex. Lapata (2000) focuses
</bodyText>
<figure confidence="0.99946778125">
0.00 0.05 0.10 0.15 0.20 0.25
coherence
AP
0.2 0.3 0.4 0.5 0.6 0.7
−sy
act−phm
agt−hum
art−at
anm−art
r−sta
art−evt
act−grp
atr−evt
com−hum
grs−hum
act−art
c−hu
art−frm
art−fod
−atr
art−grp
rt−hum
t−loc
t−nat
art−pos
om−sta
art−com
act−pos
ac−com
phm−stapl
grpgrs
ev−sta
co
art−psy
atr−psy
fod−hum
atr−sta
art−prt
anm−f
act−grs
com−psy
hum−nat
anm−hum
rt−qui
atr−rel
art−log
act−sta
art−sub
evt−psy
act−evt
act−pro
act−tme art−pho
hum−psy
art−grs
com−evt
grp−psy
grs−psy
pro−sta
psy−sta
hum−prt
od
t−sub
grs−log
fod−plt
</figure>
<page confidence="0.988252">
157
</page>
<bodyText confidence="0.997305882352941">
on the default meaning arising from word combina-
tions, as opposed to the polysemy of single words as
in this study.
Meta alternations other than regular polysemy,
such as metonymy, play a crucial role in Informa-
tion Extraction. For instance, the meta alternation
SOCIAL GROUP-GEOGRAPHICAL LOCATION cor-
responds to an ambiguity between the LOCATION-
ORGANIZATION Named Entity classes which is
known to be a hard problem in Named Entity Recog-
nition and Classification (Markert and Nissim, 2009).
Metaphorical meta alternations have also received
attention recently (Turney et al., 2011)
On a structural level, the prediction of meta al-
ternations shows a clear correspondence to analogy
prediction as approached in Turney (2006) (carpen-
ter:wood is analogous to mason:stone, but not to
photograph:camera). The framework defined in Sec-
tion 2 conceptualizes our task in a way parallel to that
of analogical reasoning, modeling not “first-order”
semantic similarity, but “second-order” semantic re-
lations. However, the two tasks cannot be approached
with the same methods, as Turney’s model relies on
contexts linking two nouns in corpus sentences (what
does A do to B?). In contrast, we are interested in
relations within words, namely between word senses.
We cannot expect two different senses of the same
noun to co-occur in the same sentence, as this is dis-
couraged for pragmatic reasons (Gale et al., 1992).
A concept analogous to our notion of meta sense
(i.e., senses beyond single words) has been used in
previous work on class-based WSD (Yarowsky, 1992;
Curran, 2005; Izquierdo et al., 2009), and indeed,
the CAM might be used for class-based WSD as
well. However, our emphasis lies rather on modeling
polysemy across words (meta alternations), some-
thing that is absent in WSD, class-based or not. The
only exception, to our knowledge, is Ando (2006),
who pools the labeled examples for all words from a
dataset for learning, implicitly exploiting regularities
in sense alternations.
Meta senses also bear a close resemblance to the
notion of semantic class as used in lexical acqui-
sition (Hindle, 1990; Merlo and Stevenson, 2001;
Schulte im Walde, 2006; Joanis et al., 2008). How-
ever, in most of this research polysemy is ignored.
A few exceptions use soft clustering for multiple as-
signment of verbs to semantic classes (Pereira et al.,
1993; Rooth et al., 1999; Korhonen et al., 2003),
and Boleda et al. (to appear) explicitly model regular
polysemy for adjectives.
</bodyText>
<sectionHeader confidence="0.990522" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999988666666667">
We have argued that modeling regular polysemy and
other analogical processes will help improve current
models of word meaning in empirical computational
semantics. We have presented a formal framework
to represent and operate with regular sense alterna-
tions, as well as a first simple instantiation of the
framework. We have conducted an evaluation of dif-
ferent implementations of this model in the new task
of determining whether words match a given sense
alternation. All models significantly outperform the
baselines when considered as a whole, and the best
implementation outperforms the baselines for 73.3%
of the tested alternations.
We have two next steps in mind. The first is to
become independent of WordNet by unsupervised
induction of (meta) senses and alternations from the
data. This will allow for models that, unlike CAM,
can go beyond “disemous” words. Other improve-
ments on the model and evaluation will be to develop
more informed baselines that capture semantic shifts,
as well as to test alternate weighting schemes for the
co-occurrence vectors (e.g. PMI) and to use larger
corpora than the BNC.
The second step is to go beyond the limited in-vitro
evaluation we have presented here by integrating al-
ternation prediction into larger NLP tasks. Knowl-
edge about alternations can play an important role in
counteracting sparseness in many tasks that involve
semantic compatibility, e.g., testing the applicability
of lexical inference rules (Szpektor et al., 2008).
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999780444444444">
This research is partially funded by the Spanish Min-
istry of Science and Innovation (FFI2010-15006,
TIN2009-14715-C04-04), the AGAUR (2010 BP-
A00070), the German Research Foundation (SFB
732), and the EU (PASCAL2; FP7-ICT-216886). It
is largely inspired on a course by Ann Copestake at
U. Pompeu Fabra (2008). We thank Marco Baroni,
Katrin Erk, and the reviewers of this and four other
conferences for valuable feedback.
</bodyText>
<page confidence="0.997469">
158
</page>
<sectionHeader confidence="0.974565" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997114346153846">
Rie Kubota Ando. 2006. Applying alternating structure
optimization to word sense disambiguation. In Proceed-
ings of the 10th Conference on Computational Natural
Language Learning, pages 77–84, New York City, NY.
Iurii Derenikovich Apresjan. 1974. Regular polysemy.
Linguistics, 142:5–32.
Gemma Boleda, Sabine Schulte im Walde, and Toni Badia.
to appear. Modeling regular polysemy: A study of the
semantic classification of Catalan adjectives. Computa-
tional Linguistics.
Paul Buitelaar. 1998. CoreLex: An ontology of sys-
tematic polysemous classes. In Proceedings of For-
mal Ontologies in Information Systems, pages 221–235,
Amsterdam, The Netherlands.
Gavin Burnage and Dominic Dunlop. 1992. Encoding
the British National Corpus. In Jan Aarts, Pieter de
Haan, and Nelleke Oostdijk, editors, English Language
Corpora: Design, Analysis and Exploitation, Papers
from the Thirteenth International Conference on En-
glish Language Research on Computerized Corpora.
Rodopi, Amsterdam.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with ccg and log-l
inear models. Computational Linguistics, 33(4).
Ann Copestake and Ted Briscoe. 1995. Semi-productive
Polysemy and Sense Extension. Journal of Semantics,
12(1):15–67.
James Curran. 2005. Supersense tagging of unknown
nouns using semantic similarity. In Proceedings of the
43rd Annual Meeting of the Association for Computa-
tional Linguistics (ACL’05), pages 26–33, Ann Arbor,
Michigan.
Bradley Efron and Robert Tibshirani. 1994. An Introduc-
tion to the Bootstrap. Monographs on Statistics and
Applied Probability 57. Chapman &amp; Hall.
Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
flexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics,
36(4):723–763.
Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT, London.
William A. Gale, Kenneth W. Church, and David
Yarowsky. 1992. One sense per discourse. In Proceed-
ings of the 1992 ARPA Human Language Technologies
Workshop, pages 233–237, Harriman, NY.
Dedre Gentner, Brian F. Bowdle, Phillip Wolff, and Con-
suelo Boronat. 2001. Metaphor is like analogy. In
D. Gentner, K. J. Holyoak, and B. N. Kokinov, edi-
tors, The analogical mind: Perspectives from Cognitive
Science, pages 199–253. MIT Press, Cambridge, MA.
Gregory Grefenstette. 1994. Explorations in Automatic
Thesaurus Discovery. Kluwer Academic Publishers.
Donald Hindle. 1990. Noun classification from predicate-
argument structures. In Proceedings of the 28th Meet-
ing of the Association for Computational Linguistics,
pages 268–275.
Rub´en Izquierdo, Armando Su´arez, and German Rigau.
2009. An empirical study on class-based word sense
disambiguation. In Proceedings of the 12th Conference
of the European Chapter of the ACL (EACL 2009),
pages 389–397, Athens, Greece.
Eric Joanis, Suzanne Stevenson, and David James. 2008.
A general feature space for automatic verb classifica-
tion. Natural Language Engineering, 14(03):337–367.
Anna Korhonen, Yuval Krymolowski, and Zvika Marx.
2003. Clustering polysemic subcategorization frame
distributions semantically. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 64–71.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University of Chicago Press.
Mirella Lapata. 2000. The Acquisition and Modeling
of Lexical Knowledge: A Corpus-based Investigation
of Systematic Polysemy. Ph.D. thesis, University of
Edinburgh.
Lillian Lee. 1999. Measures of distributional similarity.
In Proceedings of the 37th Annual Meeting on Asso-
ciation for Computational Linguistics, pages 25–32,
College Park, MA.
Will Lowe. 2001. Towards a theory of semantic space. In
Proceedings of the 23rd Annual Meeting of the Cogni-
tive Science Society, pages 576–581, Edinburgh, UK.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Sch¨utze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, Cambridge, UK,
1st edition.
Katja Markert and Malvina Nissim. 2009. Data and
models for metonymy resolution. Language Resources
and Evaluation, 43(2):123–138.
Diana McCarthy, Rob Koeling, Julie Weeds, and John Car-
roll. 2004. Using automatically acquired predominant
senses for word sense disambiguation. In Proceedings
of the ACL SENSEVAL-3 workshop, pages 151–154.
Paola Merlo and Suzanne Stevenson. 2001. Automatic
verb classification based on statistical distributions
of argument structure. Computational Linguistics,
27(3):373–408.
Gregory L. Murphy. 2002. The Big Book of Concepts.
MIT Press, Cambridge, MA.
Roberto Navigli and Paola Velardi. 2005. Structural se-
mantic interconnections: a knowledge-based approach
to word sense disambiguation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 27(7):1075–
1086, July.
</reference>
<page confidence="0.986267">
159
</page>
<reference confidence="0.999915421875">
Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Computing Surveys, 41:10:1–10:69,
February.
Sebastian Pad´o and Mirella Lapata. 2007. Dependency-
based construction of semantic space models. Compu-
tational Linguistics, 33(2):161–199.
Patrick Pantel and Dekang Lin. 2002. Discovering word
senses from text. In Proceedings of ACM SIGKDD
Conference on Knowledge Discovery and Data Mining
2002, pages 613–619, Edmonton.
Fernando C. N. Pereira, Naftali Tishby, and Lillian Lee.
1993. Distributional clustering of English words. In
Proceedings of the 31st Meeting of the Association for
Computational Linguistics, pages 183–190, Columbus,
OH.
James Pustejovsky. 1995. The Generative Lexicon. MIT
Press, Cambridge, MA.
Joseph Reisinger and Raymond J. Mooney. 2010. Multi-
prototype vector-space models of word meaning. In
Proceedings of the 11th Annual Conference of the North
American Chapter of the Association for Computational
Linguistics (NAACL-2010), pages 109–117.
Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-
roll, and Franz Beil. 1999. Inducing a semantically
annotated lexicon via EM-based clustering. In Proceed-
ings of the 37th Annual Meeting of the Association for
Computational Linguistics, College Park, MD.
Sabine Schulte im Walde. 2006. Experiments on the
automatic induction of German semantic verb classes.
Computational Linguistics, 32(2):159–194.
Hinrich Sch¨utze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97–123.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Gold-
berger. 2008. Contextual preferences. In Proceed-
ings of the 46th Annual Meeting of the Association for
Computational Linguistics, pages 683–691, Columbus,
Ohio.
Noriko Tomuro. 2001. Tree-cut and a lexicon based on
systematic polysemy. In Proceedings of the second
meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics on Language
technologies, NAACL ’01, pages 1–8, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Peter D. Turney and Patrick Pantel. 2010. From frequency
to meaning: Vector space models of semantics. Journal
of Artificial Intelligence Research, 37:141–188.
Peter Turney, Yair Neuman, Dan Assaf, and Yohai Cohen.
2011. Literal and metaphorical sense identification
through concrete and abstract context. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 680–690, Edinburgh, Scot-
land, UK.
Peter D. Turney. 2006. Similarity of semantic relations.
Computational Linguistics, 32:379–416.
Jason Utt and Sebastian Pad´o. 2011. Ontology-based
distinction between polysemy and homonymy. In Pro-
ceedings of the 9th International Conference on Com-
putational Semantics, Oxford, UK.
David Yarowsky. 1992. Word-sense disambiguation using
statistical models of Roget’s categories trained on large
corpora. In Proceedings of the 14th conference on
Computational linguistics - Volume 2, COLING ’92,
pages 454–460, Stroudsburg, PA, USA. Association for
Computational Linguistics.
</reference>
<page confidence="0.997479">
160
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.835353">
<title confidence="0.962648">Regular polysemy: A distributional model</title>
<author confidence="0.998209">Gemma Boleda Sebastian Pad´o Jason Utt</author>
<affiliation confidence="0.999832">Dept. of Linguistics ICL IMS University of Texas at Austin University of Heidelberg University of Stuttgart</affiliation>
<email confidence="0.87309">gemma.boleda@upf.edupado@cl.uni-heidelberg.deuttjn@ims.uni-stuttgart.de</email>
<abstract confidence="0.999611333333333">Many types of polysemy are not word specific, but are instances of general sense alternations as Despite their pervasiveness, regular alternations have been mostly ignored in empirical computational semantics. This paper presents (a) a general framework which grounds sense alternations in corpus data, generalizes them above individual words, and allows the prediction of alternations for new words; and (b) a concrete unsupervised implementation of the framework, the Centroid Attribute Model. We evaluate this model against a set of 2,400 ambiguous words and demonstrate that it outperforms two baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rie Kubota Ando</author>
</authors>
<title>Applying alternating structure optimization to word sense disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning,</booktitle>
<pages>77--84</pages>
<location>New York City, NY.</location>
<contexts>
<context position="29627" citStr="Ando (2006)" startWordPosition="4822" endWordPosition="4823">d senses. We cannot expect two different senses of the same noun to co-occur in the same sentence, as this is discouraged for pragmatic reasons (Gale et al., 1992). A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polyse</context>
</contexts>
<marker>Ando, 2006</marker>
<rawString>Rie Kubota Ando. 2006. Applying alternating structure optimization to word sense disambiguation. In Proceedings of the 10th Conference on Computational Natural Language Learning, pages 77–84, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iurii Derenikovich Apresjan</author>
</authors>
<title>Regular polysemy.</title>
<date>1974</date>
<journal>Linguistics,</journal>
<pages>142--5</pages>
<contexts>
<context position="2208" citStr="Apresjan, 1974" startWordPosition="349" endWordPosition="351">whose goal is to identify which, of a set of predefined senses, is the one used in a given context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empiri</context>
</contexts>
<marker>Apresjan, 1974</marker>
<rawString>Iurii Derenikovich Apresjan. 1974. Regular polysemy. Linguistics, 142:5–32.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gemma Boleda</author>
<author>Sabine Schulte im Walde</author>
<author>Toni Badia</author>
</authors>
<title>to appear. Modeling regular polysemy: A study of the semantic classification of Catalan adjectives.</title>
<journal>Computational Linguistics.</journal>
<marker>Boleda, Walde, Badia, </marker>
<rawString>Gemma Boleda, Sabine Schulte im Walde, and Toni Badia. to appear. Modeling regular polysemy: A study of the semantic classification of Catalan adjectives. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Buitelaar</author>
</authors>
<title>CoreLex: An ontology of systematic polysemous classes.</title>
<date>1998</date>
<booktitle>In Proceedings of Formal Ontologies in Information Systems,</booktitle>
<pages>221--235</pages>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="8304" citStr="Buitelaar, 1998" startWordPosition="1346" endWordPosition="1347">in the corpus we use are monosemous and 2.3% are disemous, while, on a token level, 23.3% are monosemous and 20.2% disemous. 152 vecI : IL → Rk instance vector computation (t: Rkxm → Rk centroid computation vecL : L → Rk lemma (type) vector computation repM : M → Rk meta sense representation Table 3: Additional notation and signatures for CAM explicit sense disambiguation, CAM represents lemmas by their type vectors, i.e., the centroid of their instances, and compares their vectors (attributes) to those of the meta alternation – hence the name. CoreLex: A Semantic Inventory. CAM uses CoreLex (Buitelaar, 1998) as its meta sense inventory. CoreLex is a lexical resource that was designed specifically for the study of polysemy. It builds on WordNet (Fellbaum, 1998), whose sense distinctions are too fine-grained to describe general sense alternations. CoreLex defines a layer of abstraction above WordNet consisting of 39 basic types, coarsegrained ontological classes (Table 2). These classes are linked to one or more Wordnet anchor nodes, which define a mapping from WordNet synsets onto basic types: A synset s maps onto a basic type b if b has an anchor node that dominates s and there is no other anchor</context>
<context position="26905" citStr="Buitelaar (1998)" startWordPosition="4400" endWordPosition="4401"> it uses first-order co-occurrence information only. 9An exception is hum-prt. It has a low coherence because many WordNet lemmas with a PART sense are body parts. Figure 2: Average Precision and Coherence (rc) for each meta alternation. Correlation: r = 0.743 (p &lt; 0.001) 6 Related work As noted in Section 1, there is little work in empirical computational semantics on explicitly modeling sense alternations, although the notions that we have formalized here affect several tasks across NLP subfields. Most work on regular sense alternations has focused on regular polysemy. A pioneering study is Buitelaar (1998), who accounts for regular polysemy through the CoreLex resource (cf. Section 3). A similar effort is carried out by Tomuro (2001), but he represents regular polysemy at the level of senses. Recently, Utt and Pad´o (2011) explore the differences between between idiosyncratic and regular polysemy patterns building on CoreLex. Lapata (2000) focuses 0.00 0.05 0.10 0.15 0.20 0.25 coherence AP 0.2 0.3 0.4 0.5 0.6 0.7 −sy act−phm agt−hum art−at anm−art r−sta art−evt act−grp atr−evt com−hum grs−hum act−art c−hu art−frm art−fod −atr art−grp rt−hum t−loc t−nat art−pos om−sta art−com act−pos ac−com phm−</context>
</contexts>
<marker>Buitelaar, 1998</marker>
<rawString>Paul Buitelaar. 1998. CoreLex: An ontology of systematic polysemous classes. In Proceedings of Formal Ontologies in Information Systems, pages 221–235, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gavin Burnage</author>
<author>Dominic Dunlop</author>
</authors>
<title>Encoding the British National Corpus.</title>
<date>1992</date>
<booktitle>English Language Corpora: Design, Analysis and Exploitation, Papers from the Thirteenth International Conference on English Language Research on Computerized Corpora. Rodopi,</booktitle>
<editor>In Jan Aarts, Pieter de Haan, and Nelleke Oostdijk, editors,</editor>
<location>Amsterdam.</location>
<contexts>
<context position="13104" citStr="Burnage and Dunlop (1992)" startWordPosition="2163" endWordPosition="2166">ta senses. 4 Evaluation We test CAM on the task of identifying which lemmas of a given set instantiate a specific meta alternation. We let the model rank the lemmas through the score function (cf. Table (1) and Eq. (5)) and evaluate the ranked list using Average Precision. While an alternative would be to rank meta alternations for a given polysemous lemma, the method chosen here has the benefit of providing data on the performance of individual meta senses and meta alternations. 4.1 Data All modeling and data extraction was carried out on the written part of the British National Corpus (BNC; Burnage and Dunlop (1992)) parsed with the C&amp;C tools (Clark and Curran, 2007). 6 For the evaluation, we focus on disemous words, words which instantiate exactly two meta senses according to WordNet. For each meta alternation (m, m&apos;), we evaluate CAM on a set of disemous targets (lemmas that instantiate (m, m&apos;)) and disemous distractors (lemmas that do not). We define three types of distractors: (1) distractors sharing m with the targets (but not m&apos;), (2) distractors sharing m&apos; with the targets (but not m), and (3) distractors sharing neither. In this way, we ensure that CAM cannot obtain good results by merely modelin</context>
</contexts>
<marker>Burnage, Dunlop, 1992</marker>
<rawString>Gavin Burnage and Dominic Dunlop. 1992. Encoding the British National Corpus. In Jan Aarts, Pieter de Haan, and Nelleke Oostdijk, editors, English Language Corpora: Design, Analysis and Exploitation, Papers from the Thirteenth International Conference on English Language Research on Computerized Corpora. Rodopi, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with ccg and log-l inear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="13156" citStr="Clark and Curran, 2007" startWordPosition="2172" endWordPosition="2175">ntifying which lemmas of a given set instantiate a specific meta alternation. We let the model rank the lemmas through the score function (cf. Table (1) and Eq. (5)) and evaluate the ranked list using Average Precision. While an alternative would be to rank meta alternations for a given polysemous lemma, the method chosen here has the benefit of providing data on the performance of individual meta senses and meta alternations. 4.1 Data All modeling and data extraction was carried out on the written part of the British National Corpus (BNC; Burnage and Dunlop (1992)) parsed with the C&amp;C tools (Clark and Curran, 2007). 6 For the evaluation, we focus on disemous words, words which instantiate exactly two meta senses according to WordNet. For each meta alternation (m, m&apos;), we evaluate CAM on a set of disemous targets (lemmas that instantiate (m, m&apos;)) and disemous distractors (lemmas that do not). We define three types of distractors: (1) distractors sharing m with the targets (but not m&apos;), (2) distractors sharing m&apos; with the targets (but not m), and (3) distractors sharing neither. In this way, we ensure that CAM cannot obtain good results by merely modeling the similarity of targets to either m or m&apos;, which</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. Widecoverage efficient statistical parsing with ccg and log-l inear models. Computational Linguistics, 33(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Ted Briscoe</author>
</authors>
<title>Semi-productive Polysemy and Sense Extension.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="2263" citStr="Copestake and Briscoe, 1995" startWordPosition="356" endWordPosition="359">of predefined senses, is the one used in a given context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads to the well-known lexical bo</context>
</contexts>
<marker>Copestake, Briscoe, 1995</marker>
<rawString>Ann Copestake and Ted Briscoe. 1995. Semi-productive Polysemy and Sense Extension. Journal of Semantics, 12(1):15–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
</authors>
<title>Supersense tagging of unknown nouns using semantic similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>26--33</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="29343" citStr="Curran, 2005" startWordPosition="4775" endWordPosition="4776">ty, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies on contexts linking two nouns in corpus sentences (what does A do to B?). In contrast, we are interested in relations within words, namely between word senses. We cannot expect two different senses of the same noun to co-occur in the same sentence, as this is discouraged for pragmatic reasons (Gale et al., 1992). A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et a</context>
</contexts>
<marker>Curran, 2005</marker>
<rawString>James Curran. 2005. Supersense tagging of unknown nouns using semantic similarity. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 26–33, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Efron</author>
<author>Robert Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1994</date>
<booktitle>Monographs on Statistics and Applied Probability 57.</booktitle>
<publisher>Chapman &amp; Hall.</publisher>
<contexts>
<context position="21327" citStr="Efron and Tibshirani, 1994" startWordPosition="3499" endWordPosition="3502">tor, operative, which alternate between an agentive role played by a person and the person herself. While lacking in clear improvement, loglikelihood transformation tends to reduce variance, consistent with the effect previously found in selectional preference modeling (Erk et al., 2010). Overall Performance Although the performance of the CAM models is still far from perfect, all 24 models obtain MAP scores of 0.35 or above, while the random baseline is at 0.313, and the overall frequency baseline at 0.291. Thus, all models consistently outperform both baselines. A bootstrap resampling test (Efron and Tibshirani, 1994) confirmed that the difference to the frequency baseline is significant at p &lt; 0.01 for all 24 models. The difference to the random baseline is significant at p &lt; 0.01 for 23 models and at p &lt; 0.05 for the remaining model. This shows that the models capture the meta alternations to some extent. The best model uses macro-averaging for repM and repA in a log-likelihood transformed gramlex space and achieves a MAP of 0.399. Table 5 breaks down the performance of the best CAM model by meta alternation. It shows an encouraging picture: CAM outperforms the frequency baseline for 49 of the 60 meta al</context>
</contexts>
<marker>Efron, Tibshirani, 1994</marker>
<rawString>Bradley Efron and Robert Tibshirani. 1994. An Introduction to the Bootstrap. Monographs on Statistics and Applied Probability 57. Chapman &amp; Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
<author>Ulrike Pad´o</author>
</authors>
<title>A flexible, corpus-driven model of regular and inverse selectional preferences.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<marker>Erk, Pad´o, Pad´o, 2010</marker>
<rawString>Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A flexible, corpus-driven model of regular and inverse selectional preferences. Computational Linguistics, 36(4):723–763.</rawString>
</citation>
<citation valid="true">
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT,</publisher>
<location>London.</location>
<contexts>
<context position="26905" citStr="(1998)" startWordPosition="4401" endWordPosition="4401">irst-order co-occurrence information only. 9An exception is hum-prt. It has a low coherence because many WordNet lemmas with a PART sense are body parts. Figure 2: Average Precision and Coherence (rc) for each meta alternation. Correlation: r = 0.743 (p &lt; 0.001) 6 Related work As noted in Section 1, there is little work in empirical computational semantics on explicitly modeling sense alternations, although the notions that we have formalized here affect several tasks across NLP subfields. Most work on regular sense alternations has focused on regular polysemy. A pioneering study is Buitelaar (1998), who accounts for regular polysemy through the CoreLex resource (cf. Section 3). A similar effort is carried out by Tomuro (2001), but he represents regular polysemy at the level of senses. Recently, Utt and Pad´o (2011) explore the differences between between idiosyncratic and regular polysemy patterns building on CoreLex. Lapata (2000) focuses 0.00 0.05 0.10 0.15 0.20 0.25 coherence AP 0.2 0.3 0.4 0.5 0.6 0.7 −sy act−phm agt−hum art−at anm−art r−sta art−evt act−grp atr−evt com−hum grs−hum act−art c−hu art−frm art−fod −atr art−grp rt−hum t−loc t−nat art−pos om−sta art−com act−pos ac−com phm−</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: an electronic lexical database. MIT, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the 1992 ARPA Human Language Technologies Workshop,</booktitle>
<pages>233--237</pages>
<location>Harriman, NY.</location>
<contexts>
<context position="29179" citStr="Gale et al., 1992" startWordPosition="4746" endWordPosition="4749">ograph:camera). The framework defined in Section 2 conceptualizes our task in a way parallel to that of analogical reasoning, modeling not “first-order” semantic similarity, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies on contexts linking two nouns in corpus sentences (what does A do to B?). In contrast, we are interested in relations within words, namely between word senses. We cannot expect two different senses of the same noun to co-occur in the same sentence, as this is discouraged for pragmatic reasons (Gale et al., 1992). A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also b</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. 1992. One sense per discourse. In Proceedings of the 1992 ARPA Human Language Technologies Workshop, pages 233–237, Harriman, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dedre Gentner</author>
<author>Brian F Bowdle</author>
<author>Phillip Wolff</author>
<author>Consuelo Boronat</author>
</authors>
<title>Metaphor is like analogy.</title>
<date>2001</date>
<booktitle>The analogical mind: Perspectives from Cognitive Science,</booktitle>
<pages>199--253</pages>
<editor>In D. Gentner, K. J. Holyoak, and B. N. Kokinov, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2304" citStr="Gentner et al., 2001" startWordPosition="362" endWordPosition="365"> context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads to the well-known lexical bottleneck of current word sense models, wh</context>
</contexts>
<marker>Gentner, Bowdle, Wolff, Boronat, 2001</marker>
<rawString>Dedre Gentner, Brian F. Bowdle, Phillip Wolff, and Consuelo Boronat. 2001. Metaphor is like analogy. In D. Gentner, K. J. Holyoak, and B. N. Kokinov, editors, The analogical mind: Perspectives from Cognitive Science, pages 199–253. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Explorations in Automatic Thesaurus Discovery.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="17372" citStr="Grefenstette, 1994" startWordPosition="2867" endWordPosition="2868">corporating different assumptions about distributional differences among meta alternations. The first option, gram, uses grammatical paths of lengths 1 to 3 as dimensions and thus characterizes lemmas and meta senses in terms of their grammatical context (Schulte im Walde, 2006), with a total of 2,528 paths. The second option, lex, uses words as dimensions, treating the dependency parse as a co-occurrence filter (Pad´o and Lapata, 2007), and captures topical distinctions. The third option, gramlex, uses lexicalized dependency paths like obj–see to mirror more fine-grained semantic properties (Grefenstette, 1994). Both lex and gramlex use the 10,000 most frequent items in the corpus. Vector elements. We use “raw” corpus cooccurrence frequencies as well as log-likelihoodtransformed counts (Lowe, 2001) as elements of the co-occurrence vectors. Definition of centroid computation. There are three centroid computations in CAM: to combine instances into lemma (type) vectors (function vecL in Eq. (1)); to combine lemma vectors into meta sense vectors (function repM in Eq. (2)); and to combine meta sense vectors into meta alternation vectors (function repA in Eq. (3)). For vecL, the obvious definition of the </context>
</contexts>
<marker>Grefenstette, 1994</marker>
<rawString>Gregory Grefenstette. 1994. Explorations in Automatic Thesaurus Discovery. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicateargument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Meeting of the Association for Computational Linguistics,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="29879" citStr="Hindle, 1990" startWordPosition="4862" endWordPosition="4863"> been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicateargument structures. In Proceedings of the 28th Meeting of the Association for Computational Linguistics, pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rub´en Izquierdo</author>
<author>Armando Su´arez</author>
<author>German Rigau</author>
</authors>
<title>An empirical study on class-based word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>389--397</pages>
<location>Athens, Greece.</location>
<marker>Izquierdo, Su´arez, Rigau, 2009</marker>
<rawString>Rub´en Izquierdo, Armando Su´arez, and German Rigau. 2009. An empirical study on class-based word sense disambiguation. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 389–397, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
<author>David James</author>
</authors>
<title>A general feature space for automatic verb classification.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>03</issue>
<contexts>
<context position="29952" citStr="Joanis et al., 2008" startWordPosition="4872" endWordPosition="4875">urran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with regular sense alternations, as well as a firs</context>
</contexts>
<marker>Joanis, Stevenson, James, 2008</marker>
<rawString>Eric Joanis, Suzanne Stevenson, and David James. 2008. A general feature space for automatic verb classification. Natural Language Engineering, 14(03):337–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Zvika Marx</author>
</authors>
<title>Clustering polysemic subcategorization frame distributions semantically.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>64--71</pages>
<contexts>
<context position="30164" citStr="Korhonen et al., 2003" startWordPosition="4909" endWordPosition="4912">sent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with regular sense alternations, as well as a first simple instantiation of the framework. We have conducted an evaluation of different implementations of this model in the new task of determining whether words match a given sense alternation. All models signifi</context>
</contexts>
<marker>Korhonen, Krymolowski, Marx, 2003</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Zvika Marx. 2003. Clustering polysemic subcategorization frame distributions semantically. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 64–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2234" citStr="Lakoff and Johnson, 1980" startWordPosition="352" endWordPosition="355"> identify which, of a set of predefined senses, is the one used in a given context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>The Acquisition and Modeling of Lexical Knowledge: A Corpus-based Investigation of Systematic Polysemy.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="27245" citStr="Lapata (2000)" startWordPosition="4451" endWordPosition="4452">l computational semantics on explicitly modeling sense alternations, although the notions that we have formalized here affect several tasks across NLP subfields. Most work on regular sense alternations has focused on regular polysemy. A pioneering study is Buitelaar (1998), who accounts for regular polysemy through the CoreLex resource (cf. Section 3). A similar effort is carried out by Tomuro (2001), but he represents regular polysemy at the level of senses. Recently, Utt and Pad´o (2011) explore the differences between between idiosyncratic and regular polysemy patterns building on CoreLex. Lapata (2000) focuses 0.00 0.05 0.10 0.15 0.20 0.25 coherence AP 0.2 0.3 0.4 0.5 0.6 0.7 −sy act−phm agt−hum art−at anm−art r−sta art−evt act−grp atr−evt com−hum grs−hum act−art c−hu art−frm art−fod −atr art−grp rt−hum t−loc t−nat art−pos om−sta art−com act−pos ac−com phm−stapl grpgrs ev−sta co art−psy atr−psy fod−hum atr−sta art−prt anm−f act−grs com−psy hum−nat anm−hum rt−qui atr−rel art−log act−sta art−sub evt−psy act−evt act−pro act−tme art−pho hum−psy art−grs com−evt grp−psy grs−psy pro−sta psy−sta hum−prt od t−sub grs−log fod−plt 157 on the default meaning arising from word combinations, as opposed t</context>
</contexts>
<marker>Lapata, 2000</marker>
<rawString>Mirella Lapata. 2000. The Acquisition and Modeling of Lexical Knowledge: A Corpus-based Investigation of Systematic Polysemy. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<location>College Park, MA.</location>
<contexts>
<context position="18958" citStr="Lee, 1999" startWordPosition="3119" endWordPosition="3120">fore averaging. This gives equal weight to the each lemma or meta sense, respectively. Macro-averaging in repA thus assumes that senses are equally distributed, which is an oversimplification, as word senses are known to present skewed distributions (McCarthy et al., 2004) and vectors for words with a predominant sense will be similar to the dominant meta sense vector. Micro-averaging partially models sense skewedness under the assumption that word frequency correlates with sense frequency. Similarity measure. As the vector similarity measure in Eq. (5), we use the standard cosine similarity (Lee, 1999). It ranges between −1 and 1, with 1 denoting maximum similarity. In the current model where the vectors do not contain negative counts, the range is [0; 1]. 5 Results Effect of Parameters The four parameters of Section 4.3 (three space types, macro-/micro-averaging for repM and repA, and log-likelihood transformation) correspond to 24 instantiations of CAM. Figure 1 shows the influence of the four parameters. The only significant difference is tied to the use of lexicalized vector spaces (gramlex / lex are better than gram). The statistical significance of this difference was verified by a t-</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In Proceedings of the 37th Annual Meeting on Association for Computational Linguistics, pages 25–32, College Park, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Will Lowe</author>
</authors>
<title>Towards a theory of semantic space.</title>
<date>2001</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society,</booktitle>
<pages>576--581</pages>
<location>Edinburgh, UK.</location>
<contexts>
<context position="17563" citStr="Lowe, 2001" startWordPosition="2897" endWordPosition="2898">s and meta senses in terms of their grammatical context (Schulte im Walde, 2006), with a total of 2,528 paths. The second option, lex, uses words as dimensions, treating the dependency parse as a co-occurrence filter (Pad´o and Lapata, 2007), and captures topical distinctions. The third option, gramlex, uses lexicalized dependency paths like obj–see to mirror more fine-grained semantic properties (Grefenstette, 1994). Both lex and gramlex use the 10,000 most frequent items in the corpus. Vector elements. We use “raw” corpus cooccurrence frequencies as well as log-likelihoodtransformed counts (Lowe, 2001) as elements of the co-occurrence vectors. Definition of centroid computation. There are three centroid computations in CAM: to combine instances into lemma (type) vectors (function vecL in Eq. (1)); to combine lemma vectors into meta sense vectors (function repM in Eq. (2)); and to combine meta sense vectors into meta alternation vectors (function repA in Eq. (3)). For vecL, the obvious definition of the centroid function is as a micro-average, that is, a simple average over all instances. For repM and repA, there is a design choice: The centroid can be computed by micro-averaging as well, wh</context>
</contexts>
<marker>Lowe, 2001</marker>
<rawString>Will Lowe. 2001. Towards a theory of semantic space. In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society, pages 576–581, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK,</location>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press, Cambridge, UK, 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Data and models for metonymy resolution.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="28267" citStr="Markert and Nissim, 2009" startWordPosition="4603" endWordPosition="4606">ub evt−psy act−evt act−pro act−tme art−pho hum−psy art−grs com−evt grp−psy grs−psy pro−sta psy−sta hum−prt od t−sub grs−log fod−plt 157 on the default meaning arising from word combinations, as opposed to the polysemy of single words as in this study. Meta alternations other than regular polysemy, such as metonymy, play a crucial role in Information Extraction. For instance, the meta alternation SOCIAL GROUP-GEOGRAPHICAL LOCATION corresponds to an ambiguity between the LOCATIONORGANIZATION Named Entity classes which is known to be a hard problem in Named Entity Recognition and Classification (Markert and Nissim, 2009). Metaphorical meta alternations have also received attention recently (Turney et al., 2011) On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). The framework defined in Section 2 conceptualizes our task in a way parallel to that of analogical reasoning, modeling not “first-order” semantic similarity, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies o</context>
</contexts>
<marker>Markert, Nissim, 2009</marker>
<rawString>Katja Markert and Malvina Nissim. 2009. Data and models for metonymy resolution. Language Resources and Evaluation, 43(2):123–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Using automatically acquired predominant senses for word sense disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL SENSEVAL-3 workshop,</booktitle>
<pages>151--154</pages>
<contexts>
<context position="18621" citStr="McCarthy et al., 2004" startWordPosition="3064" endWordPosition="3067">icro-average, that is, a simple average over all instances. For repM and repA, there is a design choice: The centroid can be computed by micro-averaging as well, which assigns a larger weight to more frequent lemmas (repM) or meta senses (repA). Alternatively, it can be computed by macro-averaging, that is, by normalizing the individual vectors before averaging. This gives equal weight to the each lemma or meta sense, respectively. Macro-averaging in repA thus assumes that senses are equally distributed, which is an oversimplification, as word senses are known to present skewed distributions (McCarthy et al., 2004) and vectors for words with a predominant sense will be similar to the dominant meta sense vector. Micro-averaging partially models sense skewedness under the assumption that word frequency correlates with sense frequency. Similarity measure. As the vector similarity measure in Eq. (5), we use the standard cosine similarity (Lee, 1999). It ranges between −1 and 1, with 1 denoting maximum similarity. In the current model where the vectors do not contain negative counts, the range is [0; 1]. 5 Results Effect of Parameters The four parameters of Section 4.3 (three space types, macro-/micro-averag</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Using automatically acquired predominant senses for word sense disambiguation. In Proceedings of the ACL SENSEVAL-3 workshop, pages 151–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="29906" citStr="Merlo and Stevenson, 2001" startWordPosition="4864" endWordPosition="4867">previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory L Murphy</author>
</authors>
<title>The Big Book of Concepts.</title>
<date>2002</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2319" citStr="Murphy, 2002" startWordPosition="366" endWordPosition="367">SD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads to the well-known lexical bottleneck of current word sense models, which have seriou</context>
</contexts>
<marker>Murphy, 2002</marker>
<rawString>Gregory L. Murphy. 2002. The Big Book of Concepts. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Structural semantic interconnections: a knowledge-based approach to word sense disambiguation.</title>
<date>2005</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>27</volume>
<issue>7</issue>
<pages>1086</pages>
<contexts>
<context position="11500" citStr="Navigli and Velardi, 2005" startWordPosition="1899" endWordPosition="1902">stated as: score(m, m&apos;, s, s&apos;) = sim(repA(m, m&apos;), vecL(l)) so that {s, s&apos;} = sns(l) (5) CAM thus assesses how well a meta alternation a = (m, m&apos;) explains a lemma l by comparing the centroid of the meta senses m, m&apos; to l’s centroid. Discussion. The central feature of CAM is that it avoids word sense disambiguation, although it still relies on a predefined sense inventory (WordNet, through CoreLex). Our use of monosemous words to represent meta senses and meta alternations goes beyond previous work which uses monosemous words to disambiguate polysemous words in context (Izquierdo et al., 2009; Navigli and Velardi, 2005). Because of its focus on avoiding disambiguation, CAM simplifies the representation of meta alternations and polysemous words to single centroid vectors. In the future, we plan to induce word senses (Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010), which will allow for more flexible and realistic models. 153 abs ABSTRACTION ent ENTITY loc LOCATION prt PART act ACT evt EVENT log GEO. LOCATION psy PSYCHOL. FEATURE agt AGENT fod FOOD mea MEASURE qud DEFINITE QUANTITY anm ANIMAL frm FORM mic MICROORGANISM qui INDEFINITE QUANTITY art ARTIFACT grb BIOLOG. GROUP nat NATURAL BODY re</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Roberto Navigli and Paola Velardi. 2005. Structural semantic interconnections: a knowledge-based approach to word sense disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(7):1075– 1086, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<pages>41--10</pages>
<contexts>
<context position="1575" citStr="Navigli, 2009" startWordPosition="234" endWordPosition="235">emantics is the fact that many words are polysemous. For instance, lamb can refer to an animal (as in The lamb squeezed through the gap) or to a food item (as in Sue had lamb for lunch). Polysemy is pervasive in human language and is a problem in almost all applications of NLP, ranging from Machine Translation (as word senses can translate differently) to Textual Entailment (as most lexical entailments are sense-specific). The field has thus devoted a large amount of effort to the representation and modeling of word senses. The arguably most prominent effort is Word Sense Disambiguation, WSD (Navigli, 2009), an in-vitro task whose goal is to identify which, of a set of predefined senses, is the one used in a given context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary</context>
<context position="2972" citStr="Navigli, 2009" startWordPosition="463" endWordPosition="464">uch as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads to the well-known lexical bottleneck of current word sense models, which have serious problems in achieving high coverage (Navigli, 2009). We believe that empirical computational semantics could profit from a model of polysemy1 which (a) is applicable across individual words, and thus capable of capturing general patterns and generalizing to new 1Our work is mostly inspired in research on regular polysemy. However, given the fuzzy nature of “regularity” in meaning variation, we extend the focus of our attention to include other types of analogical sense construction processes. 151 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 151–160, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Comput</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Computing Surveys, 41:10:1–10:69, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependencybased construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependencybased construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining</booktitle>
<pages>613--619</pages>
<location>Edmonton.</location>
<contexts>
<context position="11737" citStr="Pantel and Lin, 2002" startWordPosition="1937" endWordPosition="1940">. The central feature of CAM is that it avoids word sense disambiguation, although it still relies on a predefined sense inventory (WordNet, through CoreLex). Our use of monosemous words to represent meta senses and meta alternations goes beyond previous work which uses monosemous words to disambiguate polysemous words in context (Izquierdo et al., 2009; Navigli and Velardi, 2005). Because of its focus on avoiding disambiguation, CAM simplifies the representation of meta alternations and polysemous words to single centroid vectors. In the future, we plan to induce word senses (Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010), which will allow for more flexible and realistic models. 153 abs ABSTRACTION ent ENTITY loc LOCATION prt PART act ACT evt EVENT log GEO. LOCATION psy PSYCHOL. FEATURE agt AGENT fod FOOD mea MEASURE qud DEFINITE QUANTITY anm ANIMAL frm FORM mic MICROORGANISM qui INDEFINITE QUANTITY art ARTIFACT grb BIOLOG. GROUP nat NATURAL BODY rel RELATION atr ATTRIBUTE grp GROUPING phm PHENOMENON spc SPACE cel CELL grs SOCIAL GROUP pho PHYSICAL OBJECT sta STATE chm CHEMICAL hum HUMAN plt PLANT sub SUBSTANCE com COMMUNICATION lfr LIVING BEING pos POSSESSION tme TIME con CONSEQUE</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining 2002, pages 613–619, Edmonton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="30120" citStr="Pereira et al., 1993" startWordPosition="4901" endWordPosition="4904"> (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with regular sense alternations, as well as a first simple instantiation of the framework. We have conducted an evaluation of different implementations of this model in the new task of determining whether words match a</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando C. N. Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Meeting of the Association for Computational Linguistics, pages 183–190, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2282" citStr="Pustejovsky, 1995" startWordPosition="360" endWordPosition="361">one used in a given context. In work on WSD and other tasks related to polysemy, such as word sense induction, sense alternations are treated as word-specific. As a result, a model for the meaning of lamb that accounts for the relation between the animal and food senses cannot predict that the same relation holds between instances of chicken or salmon in the same type of contexts. A large number of studies in linguistics and cognitive science show evidence that there are regularities in the way words vary in their meaning (Apresjan, 1974; Lakoff and Johnson, 1980; Copestake and Briscoe, 1995; Pustejovsky, 1995; Gentner et al., 2001; Murphy, 2002), due to general analogical processes such as regular polysemy, metonymy and metaphor. Most work in theoretical linguistics has focused on regular, systematic, or logical polysemy, which accounts for alternations like ANIMAL-FOOD. Sense alternations also arise from metaphorical use of words, as dark in dark glass-dark mood, and also from metonymy when, for instance, using the name of a place for a representative (as in Germany signed the treatise). Disregarding this evidence is empirically inadequate and leads to the well-known lexical bottleneck of current</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>James Pustejovsky. 1995. The Generative Lexicon. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Raymond J Mooney</author>
</authors>
<title>Multiprototype vector-space models of word meaning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2010),</booktitle>
<pages>109--117</pages>
<contexts>
<context position="11766" citStr="Reisinger and Mooney, 2010" startWordPosition="1941" endWordPosition="1944">of CAM is that it avoids word sense disambiguation, although it still relies on a predefined sense inventory (WordNet, through CoreLex). Our use of monosemous words to represent meta senses and meta alternations goes beyond previous work which uses monosemous words to disambiguate polysemous words in context (Izquierdo et al., 2009; Navigli and Velardi, 2005). Because of its focus on avoiding disambiguation, CAM simplifies the representation of meta alternations and polysemous words to single centroid vectors. In the future, we plan to induce word senses (Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010), which will allow for more flexible and realistic models. 153 abs ABSTRACTION ent ENTITY loc LOCATION prt PART act ACT evt EVENT log GEO. LOCATION psy PSYCHOL. FEATURE agt AGENT fod FOOD mea MEASURE qud DEFINITE QUANTITY anm ANIMAL frm FORM mic MICROORGANISM qui INDEFINITE QUANTITY art ARTIFACT grb BIOLOG. GROUP nat NATURAL BODY rel RELATION atr ATTRIBUTE grp GROUPING phm PHENOMENON spc SPACE cel CELL grs SOCIAL GROUP pho PHYSICAL OBJECT sta STATE chm CHEMICAL hum HUMAN plt PLANT sub SUBSTANCE com COMMUNICATION lfr LIVING BEING pos POSSESSION tme TIME con CONSEQUENCE lme LINEAR MEASURE pro PR</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>Joseph Reisinger and Raymond J. Mooney. 2010. Multiprototype vector-space models of word meaning. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2010), pages 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="30140" citStr="Rooth et al., 1999" startWordPosition="4905" endWordPosition="4908">something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with regular sense alternations, as well as a first simple instantiation of the framework. We have conducted an evaluation of different implementations of this model in the new task of determining whether words match a given sense alterna</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via EM-based clustering. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Experiments on the automatic induction of German semantic verb classes.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<contexts>
<context position="17032" citStr="Walde, 2006" startWordPosition="2818" endWordPosition="2819">r more parameters to set. Definition of vector space. We instantiate the vecI function in three ways. All three are based on dependency-parsed spaces, following our intuition that topical similarity as provided by window-based spaces is insufficient for this task. The functions differ in the definition of the space’s dimensions, incorporating different assumptions about distributional differences among meta alternations. The first option, gram, uses grammatical paths of lengths 1 to 3 as dimensions and thus characterizes lemmas and meta senses in terms of their grammatical context (Schulte im Walde, 2006), with a total of 2,528 paths. The second option, lex, uses words as dimensions, treating the dependency parse as a co-occurrence filter (Pad´o and Lapata, 2007), and captures topical distinctions. The third option, gramlex, uses lexicalized dependency paths like obj–see to mirror more fine-grained semantic properties (Grefenstette, 1994). Both lex and gramlex use the 10,000 most frequent items in the corpus. Vector elements. We use “raw” corpus cooccurrence frequencies as well as log-likelihoodtransformed counts (Lowe, 2001) as elements of the co-occurrence vectors. Definition of centroid com</context>
<context position="29930" citStr="Walde, 2006" startWordPosition="4870" endWordPosition="4871">wsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 2006; Joanis et al., 2008). However, in most of this research polysemy is ignored. A few exceptions use soft clustering for multiple assignment of verbs to semantic classes (Pereira et al., 1993; Rooth et al., 1999; Korhonen et al., 2003), and Boleda et al. (to appear) explicitly model regular polysemy for adjectives. 7 Conclusions and Future Work We have argued that modeling regular polysemy and other analogical processes will help improve current models of word meaning in empirical computational semantics. We have presented a formal framework to represent and operate with regular sense alternati</context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>Sabine Schulte im Walde. 2006. Experiments on the automatic induction of German semantic verb classes. Computational Linguistics, 32(2):159–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Roy Bar-Haim</author>
<author>Jacob Goldberger</author>
</authors>
<title>Contextual preferences.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>683--691</pages>
<location>Columbus, Ohio.</location>
<marker>Szpektor, Dagan, Bar-Haim, Goldberger, 2008</marker>
<rawString>Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Goldberger. 2008. Contextual preferences. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 683–691, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noriko Tomuro</author>
</authors>
<title>Tree-cut and a lexicon based on systematic polysemy.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="27035" citStr="Tomuro (2001)" startWordPosition="4421" endWordPosition="4422">h a PART sense are body parts. Figure 2: Average Precision and Coherence (rc) for each meta alternation. Correlation: r = 0.743 (p &lt; 0.001) 6 Related work As noted in Section 1, there is little work in empirical computational semantics on explicitly modeling sense alternations, although the notions that we have formalized here affect several tasks across NLP subfields. Most work on regular sense alternations has focused on regular polysemy. A pioneering study is Buitelaar (1998), who accounts for regular polysemy through the CoreLex resource (cf. Section 3). A similar effort is carried out by Tomuro (2001), but he represents regular polysemy at the level of senses. Recently, Utt and Pad´o (2011) explore the differences between between idiosyncratic and regular polysemy patterns building on CoreLex. Lapata (2000) focuses 0.00 0.05 0.10 0.15 0.20 0.25 coherence AP 0.2 0.3 0.4 0.5 0.6 0.7 −sy act−phm agt−hum art−at anm−art r−sta art−evt act−grp atr−evt com−hum grs−hum act−art c−hu art−frm art−fod −atr art−grp rt−hum t−loc t−nat art−pos om−sta art−com act−pos ac−com phm−stapl grpgrs ev−sta co art−psy atr−psy fod−hum atr−sta art−prt anm−f act−grs com−psy hum−nat anm−hum rt−qui atr−rel art−log act−st</context>
</contexts>
<marker>Tomuro, 2001</marker>
<rawString>Noriko Tomuro. 2001. Tree-cut and a lexicon based on systematic polysemy. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141</pages>
<contexts>
<context position="7108" citStr="Turney and Pantel, 2010" startWordPosition="1145" endWordPosition="1148">ity function comp that compares the relation between the senses of a word to the meta alternation’s representation. Thus, comp o repA = score. 3 The Centroid Attribute Model The Centroid Attribute Model (CAM) is a simple instantiation of the framework defined in Section 2, designed with two primary goals in mind. First, it is a data-driven model. Second, it does not require any manual sense disambiguation, a notorious bottleneck. To achieve the first goal, CAM uses a distributional approach. It represents the relevant entities as co-occurrence vectors that can be acquired from a large corpus (Turney and Pantel, 2010). To achieve the second goal, CAM represents meta senses using monosemous words only, that is, words whose senses all correspond to one meta sense. 4 Examples are cattle and robin for the meta sense ANIMAL. We define the vector for a meta sense as the centroid (average vector) of the monosemous words instantiating it. In turn, meta alternations are represented by the centroids of their meta senses’ vectors. This strategy is not applicable to test lemmas, which instantiate some meta alternation and are by definition ambiguous. To deal with these without 410.8% of noun types in the corpus we use</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
</authors>
<title>Literal and metaphorical sense identification through concrete and abstract context.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>680--690</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="28359" citStr="Turney et al., 2011" startWordPosition="4615" endWordPosition="4618">a hum−prt od t−sub grs−log fod−plt 157 on the default meaning arising from word combinations, as opposed to the polysemy of single words as in this study. Meta alternations other than regular polysemy, such as metonymy, play a crucial role in Information Extraction. For instance, the meta alternation SOCIAL GROUP-GEOGRAPHICAL LOCATION corresponds to an ambiguity between the LOCATIONORGANIZATION Named Entity classes which is known to be a hard problem in Named Entity Recognition and Classification (Markert and Nissim, 2009). Metaphorical meta alternations have also received attention recently (Turney et al., 2011) On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). The framework defined in Section 2 conceptualizes our task in a way parallel to that of analogical reasoning, modeling not “first-order” semantic similarity, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies on contexts linking two nouns in corpus sentences (what does A do to B?). In contrast, we are</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Peter Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification through concrete and abstract context. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 680–690, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Similarity of semantic relations.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<pages>32--379</pages>
<contexts>
<context position="28500" citStr="Turney (2006)" startWordPosition="4639" endWordPosition="4640">study. Meta alternations other than regular polysemy, such as metonymy, play a crucial role in Information Extraction. For instance, the meta alternation SOCIAL GROUP-GEOGRAPHICAL LOCATION corresponds to an ambiguity between the LOCATIONORGANIZATION Named Entity classes which is known to be a hard problem in Named Entity Recognition and Classification (Markert and Nissim, 2009). Metaphorical meta alternations have also received attention recently (Turney et al., 2011) On a structural level, the prediction of meta alternations shows a clear correspondence to analogy prediction as approached in Turney (2006) (carpenter:wood is analogous to mason:stone, but not to photograph:camera). The framework defined in Section 2 conceptualizes our task in a way parallel to that of analogical reasoning, modeling not “first-order” semantic similarity, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies on contexts linking two nouns in corpus sentences (what does A do to B?). In contrast, we are interested in relations within words, namely between word senses. We cannot expect two different senses of the same noun to co-occur in the </context>
</contexts>
<marker>Turney, 2006</marker>
<rawString>Peter D. Turney. 2006. Similarity of semantic relations. Computational Linguistics, 32:379–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Utt</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Ontology-based distinction between polysemy and homonymy.</title>
<date>2011</date>
<booktitle>In Proceedings of the 9th International Conference on Computational Semantics,</booktitle>
<location>Oxford, UK.</location>
<marker>Utt, Pad´o, 2011</marker>
<rawString>Jason Utt and Sebastian Pad´o. 2011. Ontology-based distinction between polysemy and homonymy. In Proceedings of the 9th International Conference on Computational Semantics, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguistics - Volume 2, COLING ’92,</booktitle>
<pages>454--460</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29329" citStr="Yarowsky, 1992" startWordPosition="4773" endWordPosition="4774">emantic similarity, but “second-order” semantic relations. However, the two tasks cannot be approached with the same methods, as Turney’s model relies on contexts linking two nouns in corpus sentences (what does A do to B?). In contrast, we are interested in relations within words, namely between word senses. We cannot expect two different senses of the same noun to co-occur in the same sentence, as this is discouraged for pragmatic reasons (Gale et al., 1992). A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well. However, our emphasis lies rather on modeling polysemy across words (meta alternations), something that is absent in WSD, class-based or not. The only exception, to our knowledge, is Ando (2006), who pools the labeled examples for all words from a dataset for learning, implicitly exploiting regularities in sense alternations. Meta senses also bear a close resemblance to the notion of semantic class as used in lexical acquisition (Hindle, 1990; Merlo and Stevenson, 2001; Schulte im Walde, 200</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>David Yarowsky. 1992. Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora. In Proceedings of the 14th conference on Computational linguistics - Volume 2, COLING ’92, pages 454–460, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>