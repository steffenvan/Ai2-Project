<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.974814">
Robust pronoun resolution with limited knowledge
</title>
<author confidence="0.991019">
Ruslan Mitkov
</author>
<affiliation confidence="0.997344">
School of Languages and European Studies
University of Wolverhampton
</affiliation>
<address confidence="0.862341666666667">
Stafford Street
Wolverhampton WV1 1SB
United Kingdom
</address>
<email confidence="0.356644">
R Mi tkov@wly ac . uk
</email>
<sectionHeader confidence="0.97923" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999733111111111">
Most traditional approaches to anaphora resolution
rely heavily on linguistic and domain knowledge.
One of the disadvantages of developing a knowledge-
based system, however, is that it is a very labour-
intensive and time-consuming task. This paper pres-
ents a robust, knowledge-poor approach to resolving
pronouns in technical manuals, which operates on
texts pre-processed by a part-of-speech tagger. Input
is checked against agreement and for a number of
antecedent indicators. Candidates are assigned scores
by each indicator and the candidate with the highest
score is returned as the antecedent. Evaluation reports
a success rate of 89.7% which is better than the suc-
cess rates of the approaches selected for comparison
and tested on the same data. In addition, preliminary
experiments show that the approach can be success-
fully adapted for other languages with minimum
modifications.
</bodyText>
<sectionHeader confidence="0.996139" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999910454545455">
For the most part, anaphora resolution has focused
on traditional linguistic methods (Carbonell &amp;
Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp;
Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp;
Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988;
Sidner 1979; Webber 1979). However, to represent
and manipulate the various types of linguistic and
domain knowledge involved requires considerable
human input and computational expense.
While various alternatives have been proposed,
making use of e.g. neural networks, a situation se-
mantics framework, or the principles of reasoning
with uncertainty (e.g. Connoly et al. 1994; Mitkov
1995; Tin &amp; Alc.man 1995), there is still a strong
need for the development of robust and effective
strategies to meet the demands of practical NLP
systems, and to enhance further the automatic pro-
cessing of growing language resources.
Several proposals have already addressed the
anaphora resolution problem by deliberately limiting
the extent to which they rely on domain and/or lin-
guistic knowledge (Baldwin 1997; Dagan &amp; Itai
1990; Kennedy &amp; Boguraev 1996; Mitkov 1998;
Nasukawa 1994; Williams et al. 1996). Our work is
a continuation of these latest trends in the search for
inexpensive, fast and reliable procedures for anaph-
ora resolution. It is also an example of how anaphors
in a specific genre can be resolved quite successfully
without any sophisticated linguistic knowledge or
even without parsing. Finally, our evaluation shows
that the basic set of antecedent tracking indicators
can work well not only for English, but also for
other languages (in our case Polish and Arabic).
</bodyText>
<sectionHeader confidence="0.961671" genericHeader="method">
2. The approach
</sectionHeader>
<bodyText confidence="0.999980695652174">
With a view to avoiding complex syntactic, seman-
tic and discourse analysis (which is vital for real-
world applications), we developed a robust, knowl-
edge-poor approach to pronoun resolution which
does not parse and analyse the input in order to
identify antecedents of anaphors. It makes use of
only a part-of-speech tagger, plus simple noun
phrase rules (sentence constituents are identified at
the level of noun phrase at most) and operates on the
basis of antecedent-tracking preferences (referred to
hereafter as &amp;quot;antecedent indicators&amp;quot;). The approach
works as follows: it takes as an input the output of a
text processed by a part-of-speech tagger, identifies
the noun phrases which precede the anaphor within a
distance of 2 sentences, checks them for gender and
number agreement with the anaphor and then applies
the genre-specific antecedent indicators to the re-
maining candidates (see next section). The noun
phrase with the highest aggregate score is proposed
as antecedent; in the rare event of a tie, priority is
given to the candidate with the higher score for im-
mediate reference. If immediate reference has not
been identified, then priority is given to the candi-
</bodyText>
<page confidence="0.997557">
869
</page>
<bodyText confidence="0.999969">
date with the best collocation pattern score. If this
does not help, the candidate with the higher score
for indicating verbs is preferred. If still no choice is
possible, the most recent from the remaining candi-
dates is selected as the antecedent.
</bodyText>
<subsectionHeader confidence="0.996295">
2.1 Antecedent indicators
</subsectionHeader>
<bodyText confidence="0.999911055555556">
Antecedent indicators (preferences) play a decisive
role in tracking down the antecedent from a set of
possible candidates. Candidates are assigned a score
(-1, 0, 1 or 2) for each indicator; the candidate with
the highest aggregate score is proposed as the ante-
cedent. The antecedent indicators have been identi-
fied empirically and are related to salience
(definiteness, givenness, indicating verbs, lexical
reiteration, section heading preference, &amp;quot;non-
prepositional&amp;quot; noun phrases), to structural matches
(collocation, immediate reference), to referential
distance or to preference of terms. Whilst some of
the indicators are more genre-specific (term prefer-
ence) and others are less genre-specific (&amp;quot;immediate
reference&amp;quot;), the majority appear to be genre-
independent. In the following we shall outline some
the indicators used and shall illustrate them by ex-
amples.
</bodyText>
<subsectionHeader confidence="0.301665">
Definiteness
</subsectionHeader>
<bodyText confidence="0.999887272727273">
Definite noun phrases in previous sentences are
more likely antecedents of pronominal anaphors
than indefinite ones (definite noun phrases score 0
and indefinite ones are penalised by -1). We regard a
noun phrase as definite if the head noun is modified
by a definite article, or by demonstrative or posses-
sive pronouns. This rule is ignored if there are no
definite articles, possessive or demonstrative pro-
nouns in the paragraph (this exception is taken into
account because some English user&apos;s guides tend to
omit articles).
</bodyText>
<subsubsectionHeader confidence="0.290997">
Givenness
</subsubsectionHeader>
<bodyText confidence="0.973763727272727">
Noun phrases in previous sentences representing the
&amp;quot;given information&amp;quot; (theme)1 are deemed good
candidates for antecedents and score 1 (candidates
not representing the theme score 0). In a coherent
text (Firbas 1992), the given or known information,
or theme, usually appears first, and thus forms a co-
referential link with the preceding text. The new
information, or rheme, provides some information
about the theme.
&apos;We use the simple heuristics that the given information
is the first noun phrase in a non-imperative sentence.
Indicating verbs
If a verb is a member of the Verb_set = {discuss,
present, illustrate, identify, summarise, examine,
describe, define, show, check, develop, review, re-
port, outline, consider, investigate, explore, assess,
analyse, synthesise, study, survey, deal, cover}, we
consider the first NP following it as the preferred an-
tecedent (scores 1 and 0). Empirical evidence sug-
gests that because of the salience of the noun
phrases which follow them, the verbs listed above
are particularly good indicators.
</bodyText>
<subsectionHeader confidence="0.583865">
Lexical reiteration
</subsectionHeader>
<bodyText confidence="0.983752444444445">
Lexically reiterated items are likely candidates for
antecedent (a NP scores 2 if is repeated within the
same paragraph twice or more, 1 if repeated once
and 0 if not). Lexically reiterated items include re-
peated synonymous noun phrases which may often
be preceded by definite articles or demonstratives.
Also, a sequence of noun phrases with the same
head counts as lexical reiteration (e.g. &amp;quot;toner bottle&amp;quot;,
&amp;quot;bottle of toner&amp;quot;, &amp;quot;the bottle&amp;quot;).
Section heading preference
If a noun phrase occurs in the heading of the section,
part of which is the current sentence, then we con-
sider it as the preferred candidate (1, 0).
&amp;quot;Non-prepositional&amp;quot; noun phrases
A &amp;quot;pure&amp;quot;, &amp;quot;non-prepositional&amp;quot; noun phrase is given a
higher preference than a noun phrase which is part
of a prepositional phrase (0, -1). Example:
Insert the cassettei into the VCR making sure iti is
suitable for the length of recording.
Here &amp;quot;the VCR&amp;quot; is penalised (-1) for being part of
the prepositional phrase &amp;quot;into the VCR&amp;quot;.
This preference can be explained in terms of sali-
ence from the point of view of the centering theory.
The latter proposes the ranking &amp;quot;subject, direct ob-
ject, indirect object&amp;quot; (Brennan et al. 1987) and noun
phrases which are parts of prepositional phrases are
usually indirect objects.
</bodyText>
<subsubsectionHeader confidence="0.497235">
Collocation pattern preference
</subsubsectionHeader>
<bodyText confidence="0.99988725">
This preference is given to candidates which have an
identical collocation pattern with a pronoun (2,0).
The collocation preference here is restricted to the
patterns &amp;quot;noun phrase (pronoun), verb&amp;quot; and &amp;quot;verb,
</bodyText>
<page confidence="0.972936">
870
</page>
<bodyText confidence="0.975442675">
noun phrase (pronoun)&amp;quot;. Owing to lack of syntactic
information, this preference is somewhat weaker
than the collocation preference described in (Dagan
&amp; Itai 1990). Example:
Press the keyi down and turn the volume up... Press
iti again.
Immediate reference
In technical manuals the &amp;quot;immediate reference&amp;quot; clue
can often be useful in identifying the antecedent.
The heuristics used is that in constructions of the
form &amp;quot;...(You) V1 NP ... con (you) V2 it (con (you)
V3 it)&amp;quot;, where con e {and/or/before/after...}, the
noun phrase immediately after V1 is a very likely
candidate for antecedent of the pronoun &amp;quot;it&amp;quot; imme-
diately following V2 and is therefore given prefer-
ence (scores 2 and 0).
This preference can be viewed as a modification
of the collocation preference. It is also quite fre-
quent with imperative constructions. Example:
To print the paper, you can stand the printeri up or
lay iti flat.
To turn on the printer, press the Power button i and
hold iti down for a moment.
Unwrap the paperi, form iti and align iti, then load iti
into the drawer.
Referential distance
In complex sentences, noun phrases in the previous
clause2 are the best candidate for the antecedent of
an anaphor in the subsequent clause, followed by
noun phrases in the previous sentence, then by nouns
situated 2 sentences further back and finally nouns 3
sentences further back (2, 1, 0, -1). For anaphors in
simple sentences, noun phrases in the previous sen-
tence are the best candidate for antecedent, followed
by noun phrases situated 2 sentences further back
and finally nouns 3 sentences further back (1, 0, -1).
Term preference
NPs representing terms in the field are more likely
to be the antecedent than NPs which are not terms
(score 1 if the NP is a term and 0 if not).
</bodyText>
<footnote confidence="0.5622875">
2Identification of clauses in complex sentences is done
heuristically.
</footnote>
<page confidence="0.917286">
871
</page>
<bodyText confidence="0.9999806">
As already mentioned, each of the antecedent in-
dicators assigns a score with a value (-1, 0, 1, 2).
These scores have been determined experimentally
on an empirical basis and are constantly being up-
dated. Top symptoms like &amp;quot;lexical reiteration&amp;quot; as-
sign score &amp;quot;2&amp;quot; whereas &amp;quot;non-prepositional&amp;quot; noun
phrases are given a negative score of &amp;quot;-1&amp;quot;. We
should point out that the antecedent indicators are
preferences and not absolute factors. There might be
cases where one or more of the antecedent indicators
do not &amp;quot;point&amp;quot; to the correct antecedent. For in-
stance, in the sentence &amp;quot;Insert the cassette into the
VCR i making sure iti is turned on&amp;quot;, the indicator
&amp;quot;non-prepositional noun phrases&amp;quot; would penalise the
correct antecedent. When all preferences (antecedent
indicators) are taken into account, however, the right
antecedent is still very likely to be tracked down - in
the above example, the &amp;quot;non-prepositional noun
phrases&amp;quot; heuristics (penalty) would be overturned by
the &amp;quot;collocational preference&amp;quot; heuristics.
</bodyText>
<subsectionHeader confidence="0.950659">
2.2 Informal description of the algorithm
</subsectionHeader>
<bodyText confidence="0.9997395">
The algorithm for pronoun resolution can be de-
scribed informally as follows:
</bodyText>
<listItem confidence="0.9751586">
1. Examine the current sentence and the two pre-
ceding sentences (if available). Look for noun
phrases3 only to the left of the anaphor4
2. Select from the noun phrases identified only
those which agree in gender and number5 with
the pronominal anaphor and group them as a set
of potential candidates
3. Apply the antecedent indicators to each poten-
tial candidate and assign scores; the candidate
with the highest aggregate score is proposed as
</listItem>
<bodyText confidence="0.911338647058824">
3A sentence splitter would already have segmented the
text into sentences, a POS tagger would already have
determined the parts of speech and a simple phrasal
grammar would already have detected the noun phrases
4In this project we do not treat cataphora; non-anaphoric
&amp;quot;it&amp;quot; occurring in constructions such as &amp;quot;It is important&amp;quot;,
&amp;quot;It is necessary&amp;quot; is eliminated by a &amp;quot;referential filter&amp;quot;
5Note that this restriction may not always apply in lan-
guages other than English (e.g. German); on the other
hand, there are certain collective nouns in English which
do not agree in number with their antecedents (e.g.
&amp;quot;government&amp;quot;, &amp;quot;team&amp;quot;, &amp;quot;parliament&amp;quot; etc. can be referred
to by &amp;quot;they&amp;quot;; equally some plural nouns (e.g. &amp;quot;data&amp;quot;) can
be referred to by &amp;quot;it&amp;quot;) and are exempted from the agree-
ment test. For this purpose we have drawn up a compre-
hensive list of all such cases; to our knowledge, no other
computational treatment of pronominal anaphora resolu-
tion has addressed the problem of &amp;quot;agreement excep-
tions&amp;quot;.
antecedent. If two candidates have an equal In order to evaluate the effectiveness of the ap-
score, the candidate with the higher score for proach and to explore if / how far it is superior over
immediate reference is proposed as antecedent. the baseline models for anaphora resolution, we also
If immediate reference does not hold, propose tested the sample text on (i) a Baseline Model which
the candidate with higher score for collocational checks agreement in number and gender and, where
pattern. If collocational pattern suggests a tie or more than one candidate remains, picks as antece-
does not hold, select the candidate with higher dent the most recent subject matching the gender
score for indicating verbs. If this indicator does and number of the anaphor (ii) a Baseline Model
not hold again, go for the most recent candidate. which picks as antecedent the most recent noun
3. Evaluation phrase that matches the gender and number of the
For practical reasons, the approach presented does anaphor.
not incorporate syntactic and semantic information The success rate of the &amp;quot;Baseline Subject&amp;quot; was
(other than a list of domain terms) and it is not real- 29.2%, whereas the success rate of &amp;quot;Baseline Most
istic to expect its performance to be as good as an Recent NP&amp;quot; was 62.5%. Given that our knowledge-
approach which makes use of syntactic and semantic poor approach is basically an enhancement of a
knowledge in terms of constraints and preferences. baseline model through a set of antecedent indica-
The lack of syntactic information, for instance, tors, we see a dramatic improvement in performance
means giving up c-command constraints and subject (95.8%) when these preferences are called upon.
preference (or on other occasions object preference, Typically, our preference-based model proved
see Mitkov 1995) which could be used in center superior to both baseline models when the antece-
tracking. Syntactic parallelism, useful in discrimi- dent was neither the most recent subject nor the
nating between identical pronouns on the basis of most recent noun phrase matching the anaphor in
their syntactic function, also has to be forgone. Lack gender and number. Example:
of semantic knowledge rules out the use of verb se- Identify the draweri by the lit paper port LED and
mantics and semantic parallelism. Our evaluation, add paper to iti.
however, suggests that much less is lost than might The aggregate score for &amp;quot;the drawer&amp;quot; is 7
be feared. In fact, our evaluation shows that the re- (definiteness 1 + givenness 0 + term preference 1 +
sults are comparable to syntax-based methods indicating verbs 1 + lexical reiteration 0 + section
(Lappin &amp; Leass 1994). We believe that the good heading 0 + collocation 0 + referential distance 2 +
success rate is due to the fact that a number of ante- non-prepositional noun phrase 0 + immediate refer-
cedent indicators are taken into account and no fac- ence 2 = 7), whereas aggregate score for the most
tor is given absolute preference. In particular, this recent matching noun phrase (&amp;quot;the lit paper port
</bodyText>
<figureCaption confidence="0.880399285714286">
strategy can often override incorrect decisions linked LED&amp;quot;) is 4 (definiteness 1 + givenness 0 + term
with strong centering preference (Mitkov &amp; Belguith preference 1 + indicating verbs 0 + lexical reitera-
1998) or syntactic and semantic parallelism prefer- tion 0 + section heading 0 + collocation 0 + referen-
ences (see below). tial distance 2 + non-prepositional noun phrase 0 +
3.1 Evaluation A immediate reference 0 = 4).
Our first evaluation exercise (Mitkov &amp; Stys 1997) From this example we can also see that our
was based on a random sample text from a technical knowledge-poor approach successfully tackles cases
manual in English (Minolta 1994). There were 71 in which the anaphor and the antecedent have not
pronouns in the 140 page technical manual; 7 of the only different syntactic functions but also different
pronouns were non-anaphoric and 16 exophoric. The semantic roles. Usually knowledge-based ap-
resolution of anaphors was carried out with a suc- proaches have difficulties in such a situation because
cess rate of 95.8%. The approach being robust (an they use preferences such as &amp;quot;syntactic parallelism&amp;quot;
attempt is made to resolve each anaphor and a pro- or &amp;quot;semantic parallelism&amp;quot;. Our robust approach does
posed antecedent is returned), this figure represents not use these because it has no information about the
both &amp;quot;precision&amp;quot; and &amp;quot;recall&amp;quot; if we use the MUC syntactic structure of the sentence or about the syn-
terminology. To avoid any terminological confusion, tactic function/semantic role of each individual
we shall therefore use the more neutral term word.
&amp;quot;success rate&amp;quot; while discussing the evaluation. As far as the typical failure cases are concerned,
872 we anticipate the knowledge-poor approach to have
difficulties with sentences which have a more com-
plex syntactic structure. This should not be surpris-
</figureCaption>
<bodyText confidence="0.9998908">
ing, given that the approach does not rely on any
syntactic knowledge and in particular, it does not
produce any parse tree. Indeed, the approach fails on
the sentence:
The paper through key can be used to feed [a
blank sheet of paperh through the copier out
into the copy tray without making a copy on
iti.
where &amp;quot;blank sheet of paper&amp;quot; scores only 2 as op-
posed to the &amp;quot;the paper through key&amp;quot; which scores 6.
</bodyText>
<subsectionHeader confidence="0.99675">
3.2 Evaluation B
</subsectionHeader>
<bodyText confidence="0.999827914893617">
We carried out a second evaluation of the approach
on a different set of sample texts from the genre of
technical manuals (47-page Portable Style-Writer
User&apos;s Guide (Stylewriter 1994). Out of 223 pro-
nouns in the text, 167 were non-anaphoric (deictic
and non-anaphoric &amp;quot;it&amp;quot;). The evaluation carried out
was manual to ensure that no added error was gen-
erated (e.g. due to possible wrong sentence/clause
detection or POS tagging). Another reason for doing
it by hand is to ensure a fair comparison with Breck
Baldwin&apos;s method, which not being available to us,
had to be hand-simulated (see 3.3).
The evaluation indicated 83.6% success rate. The
&amp;quot;Baseline subject&amp;quot; model tested on the same data
scored 33.9% recall and 67.9% precision, whereas
&amp;quot;Baseline most recent&amp;quot; scored 66.7%. Note that
&amp;quot;Baseline subject&amp;quot; can be assessed both in terms of
recall and precision because this &amp;quot;version&amp;quot; is not
robust: in the event of no subject being available, it
is not able to propose an antecedent (the manual
guide used as evaluation text contained many im-
perative zero-subject sentences).
In the second experiment we evaluated the ap-
proach from the point of view also of its &amp;quot;critical
success rate&amp;quot;. This measure (Mitkov 1998b) applies
only to anaphors &amp;quot;ambiguous&amp;quot; from the point of
view of number and gender (i.e. to those &amp;quot;tough&amp;quot;
anaphors which, after activating the gender and
number filters, still have more than one candidate
for antecedent) and is indicative of the performance
of the antecedent indicators. Our evaluation estab-
lished the critical success rate as 82%.
A case where the system failed was when the
anaphor and the antecedent were in the same sen-
tence and where preference was given to a candidate
in the preceding sentence. This case and other cases
suggest that it might be worthwhile reconsider-
ing/refining the weights for the indicator &amp;quot;referential
distance&amp;quot;.
Similarly to the first evaluation, we found that the
robust approach was not very successful on sen-
tences with too complicated syntax - a price we have
to pay for the &amp;quot;convenience&amp;quot; of developing a knowl-
edge-poor system.
The results from experiment 1 and experiment 2
can be summarised in the following (statistically)
slightly more representative figures.
</bodyText>
<table confidence="0.9940708">
Robust Baseline Baseline
approach subject most recent
Success rate 89.7% 31.55% / 65.95%
(=Precision/ 48.55%
Recall)
</table>
<bodyText confidence="0.9998919375">
The lower figure in &amp;quot;Baseline subject&amp;quot; corresponds
to &amp;quot;recall&amp;quot; and the higher figure - to &amp;quot;precision&amp;quot;.
If we regard as &amp;quot;discriminative power&amp;quot; of each
antecedent indicator the ratio &amp;quot;number of successful
antecedent identifications when this indicator was
applied&amp;quot;/&amp;quot;number of applications of this indicator&amp;quot;
(for the non-prepositional noun phrase and definite-
ness being penalising indicators, this figure is calcu-
lated as the ratio &amp;quot;number of unsuccessful antece-
dent identifications&amp;quot;/&amp;quot;number of applications&amp;quot;), the
immediate reference emerges as the most discrimi-
native indicator (100%), followed by non-
prepositional noun phrase (92.2%), collocation
(90.9%), section heading (61.9%), lexical reiteration
(58.5%), givenness (49.3%), term preference
(35.7%) and referential distance (34.4%). The rela-
tively low figures for the majority of indicators
should not be regarded as a surprise: firstly, we
should bear in mind that in most cases a candidate
was picked (or rejected) as an antecedent on the ba-
sis of applying a number of different indicators and
secondly, that most anaphors had a relatively high
number of candidates for antecedent.
In terms of frequency of use (&amp;quot;number of non-zero
applications&amp;quot;/&amp;quot;number of anaphors&amp;quot;), the most fre-
quently used indicator proved to be referential dis-
tance used in 98.9% of the cases, followed by term
preference (97.8%), givenness (83.3%), lexical reit-
eration (64.4%), definiteness (40%), section heading
(37.8%), immediate reference (31.1%) and colloca-
tion (11.1%). As expected, the most frequent indica-
tors were not the most discriminative ones.
</bodyText>
<subsectionHeader confidence="0.9688065">
3.3 Comparison to similar approaches: compara-
tive evaluation of Breck Baldwin&apos;s CogNIAC
</subsectionHeader>
<bodyText confidence="0.99980925">
We felt appropriate to extend the evaluation of our
approach by comparing it to Breck Baldwin&apos;s Cog-
MAC (Baldwin 1997) approach which features
&amp;quot;high precision coreference with limited knowledge
</bodyText>
<page confidence="0.997225">
873
</page>
<bodyText confidence="0.999961083333333">
and linguistics resources&amp;quot;. The reason is that both
our approach and Breck Baldwin&apos;s approach share
common principles (both are knowledge-poor and
use a POS tagger to provide the input) and therefore
a comparison would be appropriate.
Given that our approach is robust and returns an-
tecedent for each pronoun, in order to make the
comparison as fair as possible, we used CogNIAC&apos;s
&amp;quot;resolve all&amp;quot; version by simulating it manually on
the same training data used in evaluation B above.
CogNIAC successfully resolved the pronouns in
75% of the cases. This result is comparable with the
results described in (Baldwin 1997). For the training
data from the genre of technical manuals, it was rule
5 (see Baldwin 1997) which was most frequently
used (39% of the cases, 100% success), followed by
rule 8 (33% of the cases, 33% success), rule 7 (11%,
100%), rule 1 (9%, 100%) and rule 3 (7.4%, 100%).
It would be fair to say that even though the results
show superiority of our approach on the training
data used (the genre of technical manuals), they
cannot be generalised automatically for other genres
or unrestricted texts and for a more accurate picture,
further extensive tests are necessary.
</bodyText>
<sectionHeader confidence="0.552673" genericHeader="method">
4. Adapting the robust approach for other
languages
</sectionHeader>
<bodyText confidence="0.999941911111111">
An attractive feature of any NLP approach would be
its language &amp;quot;universality&amp;quot;. While we acknowledge
that most of the monolingual NLP approaches are
not automatically transferable (with the same degree
of efficiency) to other languages, it would be highly
desirable if this could be done with minimal adapta-
tion.
We used the robust approach as a basis for devel-
oping a genre-specific reference resolution approach
in Polish. As expected, some of the preferences had
to be modified in order to fit with specific features
of Polish (Mitkov &amp; Stys 1997). For the time being,
we are using the same scores for Polish.
The evaluation for Polish was based technical
manuals available on the Internet (Internet Manual,
1994; Java Manual 1998). The sample texts con-
tained 180 pronouns among which were 120 in-
stances of exophoric reference (most being zero pro-
nouns). The robust approach adapted for Polish
demonstrated a high success rate of 93.3% in resolv-
ing anaphors (with critical success rate of 86.2%).
Similarly to the evaluation for English, we com-
pared the approach for Polish with (i) a Baseline
Model which discounts candidates on the basis of
agreement in number and gender and, if there were
still competing candidates, selects as the antecedent
the most recent subject matching the anaphor in
gender and number (ii) a Baseline Model which
checks agreement in number and gender and, if there
were still more than one candidate left, picks up as
the antecedent the most recent noun phrase that
agrees with the anaphor.
Our preference-based approach showed clear su-
periority over both baseline models. The first Base-
line Model (Baseline Subject) was successful in only
23.7% of the cases, whereas the second (Baseline
Most Recent) had a success rate of 68.4%. There-
fore, the 93.3% success rate (see above) demon-
strates a dramatic increase in precision, which is due
to the use of antecedent tracking preferences.
We have recently adapted the approach for Ara-
bic as well (Mitkov &amp; Belguith 1998). Our evalua-
tion, based on 63 examples (anaphors) from a tech-
nical manual (Sony 1992), indicates a success rate of
95.2% (and critical success rate 89.3 %).
</bodyText>
<sectionHeader confidence="0.998182" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999947222222222">
We have described a robust, knowledge-poor ap-
proach to pronoun resolution which operates on texts
pre-processed by a part-of-speech tagger. Evaluation
shows a success rate of 89.7% for the genre of tech-
nical manuals and at least in this genre, the approach
appears to be more successful than other similar
methods. We have also adapted and evaluated the
approach for Polish (93.3 % success rate) and for
Arabic (95.2% success rate).
</bodyText>
<sectionHeader confidence="0.998169" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.974026458333333">
Baldwin, Breck. 1997. &amp;quot;CogNIAC: high precision
coreference with limited knowledge and linguistic re-
sources&amp;quot;. Proceedings of the ACL97/EACL97 workshop
on Operational factors in practical, robust anaphora
resolution, 38-45, Madrid, Spain.
Brennan, S., M. Fridman and C. Pollard. 1987. A center-
ing approach to pronouns. Proceedings of the 25th An-
nual Meeting of the ACL (ACL&apos;87), 155-162, Stanford,
CA, USA.
Carbonell, James G. &amp; Ralf D. Brown. 1988. &amp;quot;Anaphora
resolution: a multi-strategy approach&amp;quot;. Proceedings of
the 12. International Conference on Computational Lin-
guistics (COLING&apos;88), Vol.1, 96-101, Budapest, Hun-
gary.
Carter, David M. 1987. Interpreting anaphora in natural
language texts. Chichester: Ellis Horwood
Connoly, Dennis, John D. Burger &amp; David S. Day. 1994.
&amp;quot;A Machine learning approach to anaphoric reference&amp;quot;.
Proceedings of the International Conference &amp;quot;New
Methods in Language Processing&amp;quot;, 255-261, Manches-
ter, United Kingdom.
Dagan, Ido &amp; Alon Itai. 1990. &amp;quot;Automatic processing of
large corpora for the resolution of anaphora references&amp;quot;.
Proceedings of the 13theInternational Conference on
</reference>
<page confidence="0.994831">
874
</page>
<reference confidence="0.9998163">
Computational Linguistics (COLING&apos;90), Vol. III, 1-3,
Helsinki, Finland
Firbas, Jan. 1992. Functional sentence perspective in
written and spoken communication. Cambridge: Cam-
bridge University Press
Hobbs, Jerry R. 1978 &amp;quot;Resolving pronoun references&amp;quot;.
Lingua, 44, 339-352.
Ingria, Robert J.P. &amp; David Stallard. 1989. &amp;quot;A computa-
tional mechanism for pronominal reference&amp;quot;. Proceed-
ings of the 27th Annual Meeting of the ACL, 262-271,
Vancouver, British Columbia.
Internet Manual. 1994. Translation of Internet Manual
Internet i okolice: Przewodnik po swiatowych sieciach
komputerowych. Tracy LaQuey, Jeanne C. Ryer Trans-
lated by Monika Zielinska, BIZNET Poland.
Java Manual. 1998. Jezyk Java. Clico, Krakow.
Kennedy, Christopher &amp; Branimir Boguraev, 1996.
&amp;quot;Anaphora for everyone: pronominal anaphora resolu-
tion without a parser&amp;quot;. Proceedings of the 16th Interna-
tional Conference on Computational Linguistics
(COLING&apos;96), 113-118. Copenhagen, Denmark
Lappin, Shalom &amp; Michael McCord. 1990. &amp;quot;Anaphora
resolution in slot grammar&amp;quot;. Computational Linguistics,
16:4, 197-212.
Lappin, Shalom &amp; Herbert Leass. 1994. &amp;quot;An algorithm
for pronominal anaphora resolution&amp;quot;. Computational
Linguistics, 20(4), 535-561.
Minolta. 1994. Minolta Operator&apos;s Manual for Photocop-
ier EP5325. Technical Manual Minolta Camera Co.,
Ltd., Business Equipment Division 3-13, 2-Chome,
Azuchi, -Machi, Chuo-Ku, Osaka 541, Japan
Mitkov, Ruslan. 1994. &amp;quot;An integrated model for anaphora
resolution&amp;quot;. Proceedings of the 15th International Con-
ference on Computational Linguistics (COLING&apos;94),
1170-1176, Kyoto, Japan.
Mitkov, Ruslan. 1995. &amp;quot;Un uncertainty reasoning ap-
proach for anaphora resolution&amp;quot;. Proceedings of the
Natural Language Processing Pacific Rim Symposium
(NLPRS&apos;95), 149-154, Seoul, Korea.
Mitkov, Ruslan. 1998a. &amp;quot;Pronoun resolution: the practical
alternative&amp;quot;. In T. McEnery, S. Botley(Eds) Discourse
Anaphora and Anaphor Resolution. John Benjamins.
Mitkov, Ruslan. 1998b. &amp;quot;Evaluating anaphora resolution
approaches&amp;quot;. Proceedings of the Discourse Anaphora
and Anaphora Resolution Colloquium (DAARC2),
(forthcoming) Lancaster, UK
Mitkov, Ruslan &amp; Malgorzata Stys. 1997. &amp;quot;Robust refer-
ence resolution with limited knowledge: high precision
genre-specific approach for English and Polish&amp;quot;. Pro-
ceedings of the International Conference &amp;quot;Recent Ad-
vances in Natural Language Proceeding&amp;quot; (RANLP97),
74-81, Tzigov Chark, Bulgaria.
Mitkov, Ruslan &amp; Lamia Belguith. 1998. &amp;quot;Pronoun reso-
lution made simple: a robust, knowledge-poor approach
in action&amp;quot;. Proceedings of the International Conference
&amp;quot;Traduction Automatique et Langage Naturel&amp;quot;
(TALN&apos;98) (forthcoming). Paris, France.
Rich, Elaine &amp; Susann LuperFoy. 1988. &amp;quot;An architecture
for anaphora resolution&amp;quot;. Proceedings of the Second
Conference on Applied Natural Language Processing
(ANLP-2), 18-24, Texas, U.S.A.
Sidner, Candy L. 1979. Towards a computational theory
of definite anaphora comprehension in English dis-
course. Technical Report No. 537. M.I.T., Artificial
Intelligence Laboratory.
Sony. 1992. Video cassette recorder. Operating Instruc-
tions. Sony Corporation.
Stylewriter 1994. Portable StyleWriter. User&apos;s guide.
Apple Computers.
Tin, Erkan &amp; Varol, Akman. 1994. &amp;quot;Situated processing
of pronominal anaphora&amp;quot;. Proceedings of the
KONVENS&amp;quot;94 Conference, 369-378, Webber, Bonnie L.
1979. A formal approach to discourse anaphora. Lon-
don: Garland Publishing.
Williams, Sandra, Mark Harvey &amp; Keith Preston. 1996.
&amp;quot;Rule-based reference resolution for unrestricted text
using part-of-speech tagging and noun phrase parsing&amp;quot;.
Proceedings of the International Colloquium on Dis-
course Anaphora and Anaphora Resolution (DAARC),
441-456. Lancaster, UK.
</reference>
<page confidence="0.998898">
875
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.284507">
<title confidence="0.997851">Robust pronoun resolution with limited knowledge</title>
<author confidence="0.995506">Ruslan Mitkov</author>
<affiliation confidence="0.9995535">School of Languages and European Studies University of Wolverhampton</affiliation>
<address confidence="0.6569935">Stafford Street Wolverhampton WV1 1SB</address>
<title confidence="0.693444">United Kingdom</title>
<author confidence="0.945065">R Mi tkovwly ac</author>
<abstract confidence="0.997179526315789">Most traditional approaches to anaphora resolution rely heavily on linguistic and domain knowledge. One of the disadvantages of developing a knowledgebased system, however, is that it is a very labourintensive and time-consuming task. This paper presents a robust, knowledge-poor approach to resolving pronouns in technical manuals, which operates on texts pre-processed by a part-of-speech tagger. Input is checked against agreement and for a number of antecedent indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Breck Baldwin</author>
</authors>
<title>CogNIAC: high precision coreference with limited knowledge and linguistic resources&amp;quot;.</title>
<date>1997</date>
<booktitle>Proceedings of the ACL97/EACL97 workshop on Operational factors in practical, robust anaphora resolution,</booktitle>
<pages>38--45</pages>
<location>Madrid,</location>
<contexts>
<context position="2156" citStr="Baldwin 1997" startWordPosition="324" endWordPosition="325">hile various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a</context>
<context position="22072" citStr="Baldwin 1997" startWordPosition="3520" endWordPosition="3521"> non-zero applications&amp;quot;/&amp;quot;number of anaphors&amp;quot;), the most frequently used indicator proved to be referential distance used in 98.9% of the cases, followed by term preference (97.8%), givenness (83.3%), lexical reiteration (64.4%), definiteness (40%), section heading (37.8%), immediate reference (31.1%) and collocation (11.1%). As expected, the most frequent indicators were not the most discriminative ones. 3.3 Comparison to similar approaches: comparative evaluation of Breck Baldwin&apos;s CogNIAC We felt appropriate to extend the evaluation of our approach by comparing it to Breck Baldwin&apos;s CogMAC (Baldwin 1997) approach which features &amp;quot;high precision coreference with limited knowledge 873 and linguistics resources&amp;quot;. The reason is that both our approach and Breck Baldwin&apos;s approach share common principles (both are knowledge-poor and use a POS tagger to provide the input) and therefore a comparison would be appropriate. Given that our approach is robust and returns antecedent for each pronoun, in order to make the comparison as fair as possible, we used CogNIAC&apos;s &amp;quot;resolve all&amp;quot; version by simulating it manually on the same training data used in evaluation B above. CogNIAC successfully resolved the pro</context>
</contexts>
<marker>Baldwin, 1997</marker>
<rawString>Baldwin, Breck. 1997. &amp;quot;CogNIAC: high precision coreference with limited knowledge and linguistic resources&amp;quot;. Proceedings of the ACL97/EACL97 workshop on Operational factors in practical, robust anaphora resolution, 38-45, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brennan</author>
<author>M Fridman</author>
<author>C Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>Proceedings of the 25th Annual Meeting of the ACL (ACL&apos;87),</booktitle>
<pages>155--162</pages>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="7865" citStr="Brennan et al. 1987" startWordPosition="1224" endWordPosition="1227">ce, then we consider it as the preferred candidate (1, 0). &amp;quot;Non-prepositional&amp;quot; noun phrases A &amp;quot;pure&amp;quot;, &amp;quot;non-prepositional&amp;quot; noun phrase is given a higher preference than a noun phrase which is part of a prepositional phrase (0, -1). Example: Insert the cassettei into the VCR making sure iti is suitable for the length of recording. Here &amp;quot;the VCR&amp;quot; is penalised (-1) for being part of the prepositional phrase &amp;quot;into the VCR&amp;quot;. This preference can be explained in terms of salience from the point of view of the centering theory. The latter proposes the ranking &amp;quot;subject, direct object, indirect object&amp;quot; (Brennan et al. 1987) and noun phrases which are parts of prepositional phrases are usually indirect objects. Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun (2,0). The collocation preference here is restricted to the patterns &amp;quot;noun phrase (pronoun), verb&amp;quot; and &amp;quot;verb, 870 noun phrase (pronoun)&amp;quot;. Owing to lack of syntactic information, this preference is somewhat weaker than the collocation preference described in (Dagan &amp; Itai 1990). Example: Press the keyi down and turn the volume up... Press iti again. Immediate reference In technica</context>
</contexts>
<marker>Brennan, Fridman, Pollard, 1987</marker>
<rawString>Brennan, S., M. Fridman and C. Pollard. 1987. A centering approach to pronouns. Proceedings of the 25th Annual Meeting of the ACL (ACL&apos;87), 155-162, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James G Carbonell</author>
<author>Ralf D Brown</author>
</authors>
<title>Anaphora resolution: a multi-strategy approach&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the 12. International Conference on Computational Linguistics (COLING&apos;88), Vol.1,</booktitle>
<pages>96--101</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1227" citStr="Carbonell &amp; Brown 1988" startWordPosition="180" endWordPosition="183">h tagger. Input is checked against agreement and for a number of antecedent indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust </context>
</contexts>
<marker>Carbonell, Brown, 1988</marker>
<rawString>Carbonell, James G. &amp; Ralf D. Brown. 1988. &amp;quot;Anaphora resolution: a multi-strategy approach&amp;quot;. Proceedings of the 12. International Conference on Computational Linguistics (COLING&apos;88), Vol.1, 96-101, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Carter</author>
</authors>
<title>Interpreting anaphora in natural language texts.</title>
<date>1987</date>
<location>Chichester: Ellis Horwood</location>
<contexts>
<context position="1240" citStr="Carter 1987" startWordPosition="184" endWordPosition="185">ed against agreement and for a number of antecedent indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective</context>
</contexts>
<marker>Carter, 1987</marker>
<rawString>Carter, David M. 1987. Interpreting anaphora in natural language texts. Chichester: Ellis Horwood</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Connoly</author>
<author>John D Burger</author>
<author>David S Day</author>
</authors>
<title>A Machine learning approach to anaphoric reference&amp;quot;.</title>
<date>1994</date>
<booktitle>Proceedings of the International Conference &amp;quot;New Methods in Language Processing&amp;quot;,</booktitle>
<pages>255--261</pages>
<location>Manchester, United Kingdom.</location>
<contexts>
<context position="1732" citStr="Connoly et al. 1994" startWordPosition="256" endWordPosition="259">ction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive</context>
</contexts>
<marker>Connoly, Burger, Day, 1994</marker>
<rawString>Connoly, Dennis, John D. Burger &amp; David S. Day. 1994. &amp;quot;A Machine learning approach to anaphoric reference&amp;quot;. Proceedings of the International Conference &amp;quot;New Methods in Language Processing&amp;quot;, 255-261, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Automatic processing of large corpora for the resolution of anaphora references&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 13theInternational Conference on Computational Linguistics (COLING&apos;90),</booktitle>
<volume>Vol. III,</volume>
<pages>1--3</pages>
<location>Helsinki, Finland</location>
<contexts>
<context position="2175" citStr="Dagan &amp; Itai 1990" startWordPosition="326" endWordPosition="329">lternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a view to avoiding c</context>
<context position="8360" citStr="Dagan &amp; Itai 1990" startWordPosition="1296" endWordPosition="1299">ew of the centering theory. The latter proposes the ranking &amp;quot;subject, direct object, indirect object&amp;quot; (Brennan et al. 1987) and noun phrases which are parts of prepositional phrases are usually indirect objects. Collocation pattern preference This preference is given to candidates which have an identical collocation pattern with a pronoun (2,0). The collocation preference here is restricted to the patterns &amp;quot;noun phrase (pronoun), verb&amp;quot; and &amp;quot;verb, 870 noun phrase (pronoun)&amp;quot;. Owing to lack of syntactic information, this preference is somewhat weaker than the collocation preference described in (Dagan &amp; Itai 1990). Example: Press the keyi down and turn the volume up... Press iti again. Immediate reference In technical manuals the &amp;quot;immediate reference&amp;quot; clue can often be useful in identifying the antecedent. The heuristics used is that in constructions of the form &amp;quot;...(You) V1 NP ... con (you) V2 it (con (you) V3 it)&amp;quot;, where con e {and/or/before/after...}, the noun phrase immediately after V1 is a very likely candidate for antecedent of the pronoun &amp;quot;it&amp;quot; immediately following V2 and is therefore given preference (scores 2 and 0). This preference can be viewed as a modification of the collocation preferenc</context>
</contexts>
<marker>Dagan, Itai, 1990</marker>
<rawString>Dagan, Ido &amp; Alon Itai. 1990. &amp;quot;Automatic processing of large corpora for the resolution of anaphora references&amp;quot;. Proceedings of the 13theInternational Conference on Computational Linguistics (COLING&apos;90), Vol. III, 1-3, Helsinki, Finland</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Firbas</author>
</authors>
<title>Functional sentence perspective in written and spoken communication. Cambridge:</title>
<date>1992</date>
<publisher>Cambridge University Press</publisher>
<contexts>
<context position="5841" citStr="Firbas 1992" startWordPosition="901" endWordPosition="902">e 0 and indefinite ones are penalised by -1). We regard a noun phrase as definite if the head noun is modified by a definite article, or by demonstrative or possessive pronouns. This rule is ignored if there are no definite articles, possessive or demonstrative pronouns in the paragraph (this exception is taken into account because some English user&apos;s guides tend to omit articles). Givenness Noun phrases in previous sentences representing the &amp;quot;given information&amp;quot; (theme)1 are deemed good candidates for antecedents and score 1 (candidates not representing the theme score 0). In a coherent text (Firbas 1992), the given or known information, or theme, usually appears first, and thus forms a coreferential link with the preceding text. The new information, or rheme, provides some information about the theme. &apos;We use the simple heuristics that the given information is the first noun phrase in a non-imperative sentence. Indicating verbs If a verb is a member of the Verb_set = {discuss, present, illustrate, identify, summarise, examine, describe, define, show, check, develop, review, report, outline, consider, investigate, explore, assess, analyse, synthesise, study, survey, deal, cover}, we consider t</context>
</contexts>
<marker>Firbas, 1992</marker>
<rawString>Firbas, Jan. 1992. Functional sentence perspective in written and spoken communication. Cambridge: Cambridge University Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Resolving pronoun references&amp;quot;.</title>
<date>1978</date>
<journal>Lingua,</journal>
<volume>44</volume>
<pages>339--352</pages>
<contexts>
<context position="1252" citStr="Hobbs 1978" startWordPosition="186" endWordPosition="187">reement and for a number of antecedent indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies </context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>Hobbs, Jerry R. 1978 &amp;quot;Resolving pronoun references&amp;quot;. Lingua, 44, 339-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J P Ingria</author>
<author>David Stallard</author>
</authors>
<title>A computational mechanism for pronominal reference&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the ACL,</booktitle>
<pages>262--271</pages>
<location>Vancouver, British Columbia.</location>
<contexts>
<context position="1276" citStr="Ingria &amp; Stallard 1989" startWordPosition="188" endWordPosition="191">for a number of antecedent indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of p</context>
</contexts>
<marker>Ingria, Stallard, 1989</marker>
<rawString>Ingria, Robert J.P. &amp; David Stallard. 1989. &amp;quot;A computational mechanism for pronominal reference&amp;quot;. Proceedings of the 27th Annual Meeting of the ACL, 262-271, Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Internet Manual</author>
</authors>
<title>Translation of Internet Manual Internet i okolice: Przewodnik po swiatowych sieciach komputerowych. Tracy LaQuey, Jeanne C. Ryer Translated by Monika Zielinska, BIZNET Poland. Java Manual.</title>
<date>1994</date>
<journal>Jezyk Java. Clico, Krakow.</journal>
<contexts>
<context position="24108" citStr="Manual, 1994" startWordPosition="3854" endWordPosition="3855">at most of the monolingual NLP approaches are not automatically transferable (with the same degree of efficiency) to other languages, it would be highly desirable if this could be done with minimal adaptation. We used the robust approach as a basis for developing a genre-specific reference resolution approach in Polish. As expected, some of the preferences had to be modified in order to fit with specific features of Polish (Mitkov &amp; Stys 1997). For the time being, we are using the same scores for Polish. The evaluation for Polish was based technical manuals available on the Internet (Internet Manual, 1994; Java Manual 1998). The sample texts contained 180 pronouns among which were 120 instances of exophoric reference (most being zero pronouns). The robust approach adapted for Polish demonstrated a high success rate of 93.3% in resolving anaphors (with critical success rate of 86.2%). Similarly to the evaluation for English, we compared the approach for Polish with (i) a Baseline Model which discounts candidates on the basis of agreement in number and gender and, if there were still competing candidates, selects as the antecedent the most recent subject matching the anaphor in gender and number</context>
</contexts>
<marker>Manual, 1994</marker>
<rawString>Internet Manual. 1994. Translation of Internet Manual Internet i okolice: Przewodnik po swiatowych sieciach komputerowych. Tracy LaQuey, Jeanne C. Ryer Translated by Monika Zielinska, BIZNET Poland. Java Manual. 1998. Jezyk Java. Clico, Krakow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Boguraev</author>
</authors>
<title>Anaphora for everyone: pronominal anaphora resolution without a parser&amp;quot;.</title>
<date>1996</date>
<booktitle>Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96),</booktitle>
<pages>113--118</pages>
<location>Copenhagen, Denmark</location>
<contexts>
<context position="2200" citStr="Kennedy &amp; Boguraev 1996" startWordPosition="330" endWordPosition="333">en proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a view to avoiding complex syntactic, semanti</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Kennedy, Christopher &amp; Branimir Boguraev, 1996. &amp;quot;Anaphora for everyone: pronominal anaphora resolution without a parser&amp;quot;. Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96), 113-118. Copenhagen, Denmark</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Michael McCord</author>
</authors>
<title>Anaphora resolution in slot grammar&amp;quot;.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>197--212</pages>
<contexts>
<context position="1298" citStr="Lappin &amp; McCord 1990" startWordPosition="192" endWordPosition="195">nt indicators. Candidates are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, </context>
</contexts>
<marker>Lappin, McCord, 1990</marker>
<rawString>Lappin, Shalom &amp; Michael McCord. 1990. &amp;quot;Anaphora resolution in slot grammar&amp;quot;. Computational Linguistics, 16:4, 197-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution&amp;quot;.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>535--561</pages>
<contexts>
<context position="1319" citStr="Lappin &amp; Leass 1994" startWordPosition="196" endWordPosition="199">tes are assigned scores by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance furthe</context>
<context position="15277" citStr="Lappin &amp; Leass 1994" startWordPosition="2434" endWordPosition="2437">ost recent noun phrase matching the anaphor in their syntactic function, also has to be forgone. Lack gender and number. Example: of semantic knowledge rules out the use of verb se- Identify the draweri by the lit paper port LED and mantics and semantic parallelism. Our evaluation, add paper to iti. however, suggests that much less is lost than might The aggregate score for &amp;quot;the drawer&amp;quot; is 7 be feared. In fact, our evaluation shows that the re- (definiteness 1 + givenness 0 + term preference 1 + sults are comparable to syntax-based methods indicating verbs 1 + lexical reiteration 0 + section (Lappin &amp; Leass 1994). We believe that the good heading 0 + collocation 0 + referential distance 2 + success rate is due to the fact that a number of ante- non-prepositional noun phrase 0 + immediate refercedent indicators are taken into account and no fac- ence 2 = 7), whereas aggregate score for the most tor is given absolute preference. In particular, this recent matching noun phrase (&amp;quot;the lit paper port strategy can often override incorrect decisions linked LED&amp;quot;) is 4 (definiteness 1 + givenness 0 + term with strong centering preference (Mitkov &amp; Belguith preference 1 + indicating verbs 0 + lexical reitera1998</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Lappin, Shalom &amp; Herbert Leass. 1994. &amp;quot;An algorithm for pronominal anaphora resolution&amp;quot;. Computational Linguistics, 20(4), 535-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minolta</author>
</authors>
<title>Minolta Operator&apos;s Manual for Photocopier</title>
<date>1994</date>
<booktitle>EP5325. Technical Manual Minolta Camera Co., Ltd., Business Equipment Division 3-13, 2-Chome,</booktitle>
<location>Azuchi, -Machi, Chuo-Ku, Osaka 541, Japan</location>
<contexts>
<context position="16321" citStr="Minolta 1994" startWordPosition="2613" endWordPosition="2614">isions linked LED&amp;quot;) is 4 (definiteness 1 + givenness 0 + term with strong centering preference (Mitkov &amp; Belguith preference 1 + indicating verbs 0 + lexical reitera1998) or syntactic and semantic parallelism prefer- tion 0 + section heading 0 + collocation 0 + referenences (see below). tial distance 2 + non-prepositional noun phrase 0 + 3.1 Evaluation A immediate reference 0 = 4). Our first evaluation exercise (Mitkov &amp; Stys 1997) From this example we can also see that our was based on a random sample text from a technical knowledge-poor approach successfully tackles cases manual in English (Minolta 1994). There were 71 in which the anaphor and the antecedent have not pronouns in the 140 page technical manual; 7 of the only different syntactic functions but also different pronouns were non-anaphoric and 16 exophoric. The semantic roles. Usually knowledge-based apresolution of anaphors was carried out with a suc- proaches have difficulties in such a situation because cess rate of 95.8%. The approach being robust (an they use preferences such as &amp;quot;syntactic parallelism&amp;quot; attempt is made to resolve each anaphor and a pro- or &amp;quot;semantic parallelism&amp;quot;. Our robust approach does posed antecedent is retur</context>
</contexts>
<marker>Minolta, 1994</marker>
<rawString>Minolta. 1994. Minolta Operator&apos;s Manual for Photocopier EP5325. Technical Manual Minolta Camera Co., Ltd., Business Equipment Division 3-13, 2-Chome, Azuchi, -Machi, Chuo-Ku, Osaka 541, Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>An integrated model for anaphora resolution&amp;quot;.</title>
<date>1994</date>
<booktitle>Proceedings of the 15th International Conference on Computational Linguistics (COLING&apos;94),</booktitle>
<pages>1170--1176</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="1332" citStr="Mitkov 1994" startWordPosition="200" endWordPosition="201">es by each indicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automat</context>
</contexts>
<marker>Mitkov, 1994</marker>
<rawString>Mitkov, Ruslan. 1994. &amp;quot;An integrated model for anaphora resolution&amp;quot;. Proceedings of the 15th International Conference on Computational Linguistics (COLING&apos;94), 1170-1176, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Un uncertainty reasoning approach for anaphora resolution&amp;quot;.</title>
<date>1995</date>
<booktitle>Proceedings of the Natural Language Processing Pacific Rim Symposium (NLPRS&apos;95),</booktitle>
<pages>149--154</pages>
<location>Seoul,</location>
<contexts>
<context position="1745" citStr="Mitkov 1995" startWordPosition="260" endWordPosition="261">rt, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and re</context>
<context position="14425" citStr="Mitkov 1995" startWordPosition="2292" endWordPosition="2293">ost istic to expect its performance to be as good as an Recent NP&amp;quot; was 62.5%. Given that our knowledgeapproach which makes use of syntactic and semantic poor approach is basically an enhancement of a knowledge in terms of constraints and preferences. baseline model through a set of antecedent indicaThe lack of syntactic information, for instance, tors, we see a dramatic improvement in performance means giving up c-command constraints and subject (95.8%) when these preferences are called upon. preference (or on other occasions object preference, Typically, our preference-based model proved see Mitkov 1995) which could be used in center superior to both baseline models when the antecetracking. Syntactic parallelism, useful in discrimi- dent was neither the most recent subject nor the nating between identical pronouns on the basis of most recent noun phrase matching the anaphor in their syntactic function, also has to be forgone. Lack gender and number. Example: of semantic knowledge rules out the use of verb se- Identify the draweri by the lit paper port LED and mantics and semantic parallelism. Our evaluation, add paper to iti. however, suggests that much less is lost than might The aggregate s</context>
</contexts>
<marker>Mitkov, 1995</marker>
<rawString>Mitkov, Ruslan. 1995. &amp;quot;Un uncertainty reasoning approach for anaphora resolution&amp;quot;. Proceedings of the Natural Language Processing Pacific Rim Symposium (NLPRS&apos;95), 149-154, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Pronoun resolution: the practical alternative&amp;quot;. In</title>
<date>1998</date>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="2213" citStr="Mitkov 1998" startWordPosition="334" endWordPosition="335">f e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a view to avoiding complex syntactic, semantic and discour</context>
<context position="19148" citStr="Mitkov 1998" startWordPosition="3077" endWordPosition="3078">luation indicated 83.6% success rate. The &amp;quot;Baseline subject&amp;quot; model tested on the same data scored 33.9% recall and 67.9% precision, whereas &amp;quot;Baseline most recent&amp;quot; scored 66.7%. Note that &amp;quot;Baseline subject&amp;quot; can be assessed both in terms of recall and precision because this &amp;quot;version&amp;quot; is not robust: in the event of no subject being available, it is not able to propose an antecedent (the manual guide used as evaluation text contained many imperative zero-subject sentences). In the second experiment we evaluated the approach from the point of view also of its &amp;quot;critical success rate&amp;quot;. This measure (Mitkov 1998b) applies only to anaphors &amp;quot;ambiguous&amp;quot; from the point of view of number and gender (i.e. to those &amp;quot;tough&amp;quot; anaphors which, after activating the gender and number filters, still have more than one candidate for antecedent) and is indicative of the performance of the antecedent indicators. Our evaluation established the critical success rate as 82%. A case where the system failed was when the anaphor and the antecedent were in the same sentence and where preference was given to a candidate in the preceding sentence. This case and other cases suggest that it might be worthwhile reconsidering/refi</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Mitkov, Ruslan. 1998a. &amp;quot;Pronoun resolution: the practical alternative&amp;quot;. In T. McEnery, S. Botley(Eds) Discourse Anaphora and Anaphor Resolution. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Evaluating anaphora resolution approaches&amp;quot;.</title>
<date>1998</date>
<booktitle>Proceedings of the Discourse Anaphora and Anaphora Resolution Colloquium (DAARC2),</booktitle>
<location>(forthcoming) Lancaster, UK</location>
<contexts>
<context position="2213" citStr="Mitkov 1998" startWordPosition="334" endWordPosition="335">f e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a view to avoiding complex syntactic, semantic and discour</context>
<context position="19148" citStr="Mitkov 1998" startWordPosition="3077" endWordPosition="3078">luation indicated 83.6% success rate. The &amp;quot;Baseline subject&amp;quot; model tested on the same data scored 33.9% recall and 67.9% precision, whereas &amp;quot;Baseline most recent&amp;quot; scored 66.7%. Note that &amp;quot;Baseline subject&amp;quot; can be assessed both in terms of recall and precision because this &amp;quot;version&amp;quot; is not robust: in the event of no subject being available, it is not able to propose an antecedent (the manual guide used as evaluation text contained many imperative zero-subject sentences). In the second experiment we evaluated the approach from the point of view also of its &amp;quot;critical success rate&amp;quot;. This measure (Mitkov 1998b) applies only to anaphors &amp;quot;ambiguous&amp;quot; from the point of view of number and gender (i.e. to those &amp;quot;tough&amp;quot; anaphors which, after activating the gender and number filters, still have more than one candidate for antecedent) and is indicative of the performance of the antecedent indicators. Our evaluation established the critical success rate as 82%. A case where the system failed was when the anaphor and the antecedent were in the same sentence and where preference was given to a candidate in the preceding sentence. This case and other cases suggest that it might be worthwhile reconsidering/refi</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Mitkov, Ruslan. 1998b. &amp;quot;Evaluating anaphora resolution approaches&amp;quot;. Proceedings of the Discourse Anaphora and Anaphora Resolution Colloquium (DAARC2), (forthcoming) Lancaster, UK</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
<author>Malgorzata Stys</author>
</authors>
<title>Robust reference resolution with limited knowledge: high precision genre-specific approach for English and Polish&amp;quot;.</title>
<date>1997</date>
<booktitle>Proceedings of the International Conference &amp;quot;Recent Advances in Natural Language Proceeding&amp;quot; (RANLP97),</booktitle>
<pages>74--81</pages>
<institution>Tzigov Chark, Bulgaria.</institution>
<contexts>
<context position="16143" citStr="Mitkov &amp; Stys 1997" startWordPosition="2582" endWordPosition="2585">), whereas aggregate score for the most tor is given absolute preference. In particular, this recent matching noun phrase (&amp;quot;the lit paper port strategy can often override incorrect decisions linked LED&amp;quot;) is 4 (definiteness 1 + givenness 0 + term with strong centering preference (Mitkov &amp; Belguith preference 1 + indicating verbs 0 + lexical reitera1998) or syntactic and semantic parallelism prefer- tion 0 + section heading 0 + collocation 0 + referenences (see below). tial distance 2 + non-prepositional noun phrase 0 + 3.1 Evaluation A immediate reference 0 = 4). Our first evaluation exercise (Mitkov &amp; Stys 1997) From this example we can also see that our was based on a random sample text from a technical knowledge-poor approach successfully tackles cases manual in English (Minolta 1994). There were 71 in which the anaphor and the antecedent have not pronouns in the 140 page technical manual; 7 of the only different syntactic functions but also different pronouns were non-anaphoric and 16 exophoric. The semantic roles. Usually knowledge-based apresolution of anaphors was carried out with a suc- proaches have difficulties in such a situation because cess rate of 95.8%. The approach being robust (an the</context>
<context position="23943" citStr="Mitkov &amp; Stys 1997" startWordPosition="3825" endWordPosition="3828">s are necessary. 4. Adapting the robust approach for other languages An attractive feature of any NLP approach would be its language &amp;quot;universality&amp;quot;. While we acknowledge that most of the monolingual NLP approaches are not automatically transferable (with the same degree of efficiency) to other languages, it would be highly desirable if this could be done with minimal adaptation. We used the robust approach as a basis for developing a genre-specific reference resolution approach in Polish. As expected, some of the preferences had to be modified in order to fit with specific features of Polish (Mitkov &amp; Stys 1997). For the time being, we are using the same scores for Polish. The evaluation for Polish was based technical manuals available on the Internet (Internet Manual, 1994; Java Manual 1998). The sample texts contained 180 pronouns among which were 120 instances of exophoric reference (most being zero pronouns). The robust approach adapted for Polish demonstrated a high success rate of 93.3% in resolving anaphors (with critical success rate of 86.2%). Similarly to the evaluation for English, we compared the approach for Polish with (i) a Baseline Model which discounts candidates on the basis of agre</context>
</contexts>
<marker>Mitkov, Stys, 1997</marker>
<rawString>Mitkov, Ruslan &amp; Malgorzata Stys. 1997. &amp;quot;Robust reference resolution with limited knowledge: high precision genre-specific approach for English and Polish&amp;quot;. Proceedings of the International Conference &amp;quot;Recent Advances in Natural Language Proceeding&amp;quot; (RANLP97), 74-81, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
<author>Lamia Belguith</author>
</authors>
<title>Pronoun resolution made simple: a robust, knowledge-poor approach in action&amp;quot;.</title>
<date>1998</date>
<booktitle>Proceedings of the International Conference &amp;quot;Traduction Automatique et Langage Naturel&amp;quot; (TALN&apos;98) (forthcoming).</booktitle>
<location>Paris, France.</location>
<contexts>
<context position="25389" citStr="Mitkov &amp; Belguith 1998" startWordPosition="4065" endWordPosition="4068">d gender and, if there were still more than one candidate left, picks up as the antecedent the most recent noun phrase that agrees with the anaphor. Our preference-based approach showed clear superiority over both baseline models. The first Baseline Model (Baseline Subject) was successful in only 23.7% of the cases, whereas the second (Baseline Most Recent) had a success rate of 68.4%. Therefore, the 93.3% success rate (see above) demonstrates a dramatic increase in precision, which is due to the use of antecedent tracking preferences. We have recently adapted the approach for Arabic as well (Mitkov &amp; Belguith 1998). Our evaluation, based on 63 examples (anaphors) from a technical manual (Sony 1992), indicates a success rate of 95.2% (and critical success rate 89.3 %). 5. Conclusion We have described a robust, knowledge-poor approach to pronoun resolution which operates on texts pre-processed by a part-of-speech tagger. Evaluation shows a success rate of 89.7% for the genre of technical manuals and at least in this genre, the approach appears to be more successful than other similar methods. We have also adapted and evaluated the approach for Polish (93.3 % success rate) and for Arabic (95.2% success rat</context>
</contexts>
<marker>Mitkov, Belguith, 1998</marker>
<rawString>Mitkov, Ruslan &amp; Lamia Belguith. 1998. &amp;quot;Pronoun resolution made simple: a robust, knowledge-poor approach in action&amp;quot;. Proceedings of the International Conference &amp;quot;Traduction Automatique et Langage Naturel&amp;quot; (TALN&apos;98) (forthcoming). Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Rich</author>
<author>Susann LuperFoy</author>
</authors>
<title>An architecture for anaphora resolution&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the Second Conference on Applied Natural Language Processing (ANLP-2),</booktitle>
<pages>18--24</pages>
<location>Texas, U.S.A.</location>
<contexts>
<context position="1354" citStr="Rich &amp; LuperFoy 1988" startWordPosition="202" endWordPosition="205">dicator and the candidate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growi</context>
</contexts>
<marker>Rich, LuperFoy, 1988</marker>
<rawString>Rich, Elaine &amp; Susann LuperFoy. 1988. &amp;quot;An architecture for anaphora resolution&amp;quot;. Proceedings of the Second Conference on Applied Natural Language Processing (ANLP-2), 18-24, Texas, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candy L Sidner</author>
</authors>
<title>Towards a computational theory of definite anaphora comprehension in English discourse.</title>
<date>1979</date>
<tech>Technical Report No. 537. M.I.T.,</tech>
<institution>Artificial Intelligence Laboratory.</institution>
<contexts>
<context position="1367" citStr="Sidner 1979" startWordPosition="206" endWordPosition="207">ate with the highest score is returned as the antecedent. Evaluation reports a success rate of 89.7% which is better than the success rates of the approaches selected for comparison and tested on the same data. In addition, preliminary experiments show that the approach can be successfully adapted for other languages with minimum modifications. 1. Introduction For the most part, anaphora resolution has focused on traditional linguistic methods (Carbonell &amp; Brown 1988; Carter 1987; Hobbs 1978; Ingria &amp; Stallard 1989; Lappin &amp; McCord 1990; Lappin &amp; Leass 1994; Mitkov 1994; Rich &amp; LuperFoy 1988; Sidner 1979; Webber 1979). However, to represent and manipulate the various types of linguistic and domain knowledge involved requires considerable human input and computational expense. While various alternatives have been proposed, making use of e.g. neural networks, a situation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language r</context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>Sidner, Candy L. 1979. Towards a computational theory of definite anaphora comprehension in English discourse. Technical Report No. 537. M.I.T., Artificial Intelligence Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sony</author>
</authors>
<title>Video cassette recorder. Operating Instructions. Sony Corporation.</title>
<date>1992</date>
<marker>Sony, 1992</marker>
<rawString>Sony. 1992. Video cassette recorder. Operating Instructions. Sony Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stylewriter</author>
</authors>
<title>Portable StyleWriter. User&apos;s guide. Apple Computers.</title>
<date>1994</date>
<contexts>
<context position="18120" citStr="Stylewriter 1994" startWordPosition="2908" endWordPosition="2909">surprising, given that the approach does not rely on any syntactic knowledge and in particular, it does not produce any parse tree. Indeed, the approach fails on the sentence: The paper through key can be used to feed [a blank sheet of paperh through the copier out into the copy tray without making a copy on iti. where &amp;quot;blank sheet of paper&amp;quot; scores only 2 as opposed to the &amp;quot;the paper through key&amp;quot; which scores 6. 3.2 Evaluation B We carried out a second evaluation of the approach on a different set of sample texts from the genre of technical manuals (47-page Portable Style-Writer User&apos;s Guide (Stylewriter 1994). Out of 223 pronouns in the text, 167 were non-anaphoric (deictic and non-anaphoric &amp;quot;it&amp;quot;). The evaluation carried out was manual to ensure that no added error was generated (e.g. due to possible wrong sentence/clause detection or POS tagging). Another reason for doing it by hand is to ensure a fair comparison with Breck Baldwin&apos;s method, which not being available to us, had to be hand-simulated (see 3.3). The evaluation indicated 83.6% success rate. The &amp;quot;Baseline subject&amp;quot; model tested on the same data scored 33.9% recall and 67.9% precision, whereas &amp;quot;Baseline most recent&amp;quot; scored 66.7%. Note t</context>
</contexts>
<marker>Stylewriter, 1994</marker>
<rawString>Stylewriter 1994. Portable StyleWriter. User&apos;s guide. Apple Computers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erkan Tin</author>
<author>Akman Varol</author>
</authors>
<title>Situated processing of pronominal anaphora&amp;quot;.</title>
<date>1994</date>
<booktitle>Proceedings of the KONVENS&amp;quot;94 Conference,</booktitle>
<pages>369--378</pages>
<publisher>Garland Publishing.</publisher>
<location>Webber, Bonnie</location>
<marker>Tin, Varol, 1994</marker>
<rawString>Tin, Erkan &amp; Varol, Akman. 1994. &amp;quot;Situated processing of pronominal anaphora&amp;quot;. Proceedings of the KONVENS&amp;quot;94 Conference, 369-378, Webber, Bonnie L. 1979. A formal approach to discourse anaphora. London: Garland Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Williams</author>
<author>Mark Harvey</author>
<author>Keith Preston</author>
</authors>
<title>Rule-based reference resolution for unrestricted text using part-of-speech tagging and noun phrase parsing&amp;quot;.</title>
<date>1996</date>
<booktitle>Proceedings of the International Colloquium on Discourse Anaphora and Anaphora Resolution (DAARC),</booktitle>
<pages>441--456</pages>
<location>Lancaster, UK.</location>
<contexts>
<context position="2251" citStr="Williams et al. 1996" startWordPosition="338" endWordPosition="341">tuation semantics framework, or the principles of reasoning with uncertainty (e.g. Connoly et al. 1994; Mitkov 1995; Tin &amp; Alc.man 1995), there is still a strong need for the development of robust and effective strategies to meet the demands of practical NLP systems, and to enhance further the automatic processing of growing language resources. Several proposals have already addressed the anaphora resolution problem by deliberately limiting the extent to which they rely on domain and/or linguistic knowledge (Baldwin 1997; Dagan &amp; Itai 1990; Kennedy &amp; Boguraev 1996; Mitkov 1998; Nasukawa 1994; Williams et al. 1996). Our work is a continuation of these latest trends in the search for inexpensive, fast and reliable procedures for anaphora resolution. It is also an example of how anaphors in a specific genre can be resolved quite successfully without any sophisticated linguistic knowledge or even without parsing. Finally, our evaluation shows that the basic set of antecedent tracking indicators can work well not only for English, but also for other languages (in our case Polish and Arabic). 2. The approach With a view to avoiding complex syntactic, semantic and discourse analysis (which is vital for realwo</context>
</contexts>
<marker>Williams, Harvey, Preston, 1996</marker>
<rawString>Williams, Sandra, Mark Harvey &amp; Keith Preston. 1996. &amp;quot;Rule-based reference resolution for unrestricted text using part-of-speech tagging and noun phrase parsing&amp;quot;. Proceedings of the International Colloquium on Discourse Anaphora and Anaphora Resolution (DAARC), 441-456. Lancaster, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>