<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.988023">
Inference Rules and their Application to Recognizing Textual Entailment
</title>
<author confidence="0.990458">
Georgiana Dinu
</author>
<affiliation confidence="0.986284">
Saarland University
</affiliation>
<address confidence="0.714398">
Campus, D-66123 Saarbr¨ucken
</address>
<email confidence="0.94673">
dinu@coli.uni-sb.de
</email>
<author confidence="0.978283">
Rui Wang
</author>
<affiliation confidence="0.975379">
Saarland University
</affiliation>
<address confidence="0.729855">
Campus, D-66123 Saarbr¨ucken
</address>
<email confidence="0.982957">
rwang@coli.uni-sb.de
</email>
<sectionHeader confidence="0.993533" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823375">
In this paper, we explore ways of improv-
ing an inference rule collection and its ap-
plication to the task of recognizing textual
entailment. For this purpose, we start with
an automatically acquired collection and
we propose methods to refine it and ob-
tain more rules using a hand-crafted lex-
ical resource. Following this, we derive
a dependency-based structure representa-
tion from texts, which aims to provide a
proper base for the inference rule appli-
cation. The evaluation of our approach
on the recognizing textual entailment data
shows promising results on precision and
the error analysis suggests possible im-
provements.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999829222222222">
Textual inference plays an important role in many
natural language processing (NLP) tasks. In recent
years, the recognizing textual entailment (RTE)
(Dagan et al., 2006) challenge, which focuses on
detecting semantic inference, has attracted a lot of
attention. Given a text T (several sentences) and a
hypothesis H (one sentence), the goal is to detect
if H can be inferred from T.
Studies such as (Clark et al., 2007) attest that
lexical substitution (e.g. synonyms, antonyms) or
simple syntactic variation account for the entail-
ment only in a small number of pairs. Thus, one
essential issue is to identify more complex expres-
sions which, in appropriate contexts, convey the
same (or similar) meaning. However, more gener-
ally, we are also interested in pairs of expressions
in which only a uni-directional inference relation
holds1.
</bodyText>
<footnote confidence="0.840733">
1We will use the term inference rule to stand for such con-
cept; the two expressions can be actual paraphrases if the re-
lation is bi-directional
</footnote>
<bodyText confidence="0.982472297297297">
A typical example is the following RTE pair in
which accelerate to in H is used as an alternative
formulation for reach speed of in T.
T: The high-speed train, scheduled for a trial run on Tues-
day, is able to reach a maximum speed of up to 430 kilome-
ters per hour, or 119 meters per second.
H: The train accelerates to 430 kilometers per hour.
One way to deal with textual inference is
through rule representation, for example X wrote
Y Pz� X is author of Y. However, manually building
collections of inference rules is time-consuming
and it is unlikely that humans can exhaustively
enumerate all the rules encoding the knowledge
needed in reasoning with natural language. In-
stead, an alternative is to acquire these rules au-
tomatically from large corpora. Given such a rule
collection, the next step to focus on is how to suc-
cessfully use it in NLP applications. This paper
tackles both aspects, acquiring inference rules and
using them for the task of recognizing textual en-
tailment.
For the first aspect, we extend and refine an ex-
isting collection of inference rules acquired based
on the Distributional Hypothesis (DH). One of the
main advantages of using the DH is that the only
input needed is a large corpus of (parsed) text2.
For the extension and refinement, a hand-crafted
lexical resource is used for augmenting the origi-
nal inference rule collection and exclude some of
the incorrect rules.
For the second aspect, we focus on applying
these rules to the RTE task. In particular, we use
a structure representation derived from the depen-
dency parse trees of T and H, which aims to cap-
ture the essential information they convey.
The rest of the paper is organized as follows:
Section 2 introduces the inference rule collection
</bodyText>
<footnote confidence="0.990493">
2Another line of work on acquiring paraphrases uses com-
parable corpora, for instance (Barzilay and McKeown, 2001),
(Pang et al., 2003)
</footnote>
<note confidence="0.962272">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 211–219,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998258">
211
</page>
<bodyText confidence="0.997668071428572">
we use, based on the Discovery of Inference Rules
from Text (henceforth DIRT) algorithm and dis-
cusses previous work on applying it to the RTE
task. Section 3 focuses on the rule collection it-
self and on the methods in which we use an exter-
nal lexical resource to extend and refine it. Sec-
tion 4 discusses the application of the rules for the
RTE data, describing the structure representation
we use to identify the appropriate context for the
rule application. The experimental results will be
presented in Section 5, followed by an error analy-
sis and discussions in Section 6. Finally Section 7
will conclude the paper and point out future work
directions.
</bodyText>
<sectionHeader confidence="0.98214" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999952272727273">
A number of automatically acquired inference
rule/paraphrase collections are available, such as
(Szpektor et al., 2004), (Sekine, 2005). In our
work we use the DIRT collection because it is the
largest one available and it has a relatively good
accuracy (in the 50% range for top generated para-
phrases, (Szpektor et al., 2007)). In this section,
we describe the DIRT algorithm for acquiring in-
ference rules. Following that, we will overview
the RTE systems which take DIRT as an external
knowledge resource.
</bodyText>
<subsectionHeader confidence="0.998806">
2.1 Discovery of Inference Rules from Text
</subsectionHeader>
<bodyText confidence="0.999092352941177">
The DIRT algorithm has been introduced by (Lin
and Pantel, 2001) and it is based on what is called
the Extended Distributional Hypothesis. The orig-
inal DH states that words occurring in similar
contexts have similar meaning, whereas the ex-
tended version hypothesizes that phrases occur-
ring in similar contexts are similar.
An inference rule in DIRT is a pair of binary
relations ( pattern1(X, Y ), pattern2(X, Y ) )
which stand in an inference relation. pattern1 and
pattern2 are chains in dependency trees3 while X
and Y are placeholders for nouns at the end of this
chain. The two patterns will constitute a candi-
date paraphrase if the sets of X and Y values ex-
hibit relevant overlap. In the following example,
the two patterns are prevent and provide protection
against.
</bodyText>
<equation confidence="0.780075">
X subj
���� prevent obj
��� Y
X subj
���� provide obj
��� protection mod
���� against pcomp
����� Y
</equation>
<footnote confidence="0.807682">
3obtained with the Minipar parser (Lin, 1998)
</footnote>
<equation confidence="0.993917714285714">
X put emphasis on Y
� X pay attention to Y
� X attach importance to Y
� X increase spending on Y
� X place emphasis on Y
� Y priority of X
� X focus on Y
</equation>
<tableCaption confidence="0.992952">
Table 1: Example of DIRT algorithm output. Most
confident paraphrases of X put emphasis on Y
</tableCaption>
<bodyText confidence="0.997828382352941">
Such rules can be informally defined (Szpek-
tor et al., 2007) as directional relations between
two text patterns with variables. The left-hand-
side pattern is assumed to entail the right-hand-
side pattern in certain contexts, under the same
variable instantiation. The definition relaxes the
intuition of inference, as we only require the en-
tailment to hold in some and not all contexts, mo-
tivated by the fact that such inferences occur often
in natural text.
The algorithm does not extract directional in-
ference rules, it can only identify candidate para-
phrases; many of the rules are however uni-
directional. Besides syntactic rewriting or lexi-
cal rules, rules in which the patterns are rather
complex phrases are also extracted. Some of the
rules encode lexical relations which can also be
found in resources such as WordNet while oth-
ers are lexical-syntactic variations that are unlikely
to occur in hand-crafted resources (Lin and Pan-
tel, 2001). Table 1 gives a few examples of rules
present in DIRT4.
Current work on inference rules focuses on
making such resources more precise. (Basili et
al., 2007) and (Szpektor et al., 2008) propose at-
taching selectional preferences to inference rules.
These are semantic classes which correspond to
the anchor values of an inference rule and have
the role of making precise the context in which the
rule can be applied 5. This aspect is very impor-
tant and we plan to address it in our future work.
However in this paper we investigate the first and
more basic issue: how to successfully use rules in
their current form.
</bodyText>
<footnote confidence="0.9972516">
4For simplification, in the rest of the paper we will omit
giving the dependency relations in a pattern.
5For example X won Y entails X played Y only when Y
refers to some sort of competition, but not if Y refers to a
musical instrument.
</footnote>
<page confidence="0.997379">
212
</page>
<sectionHeader confidence="0.522993" genericHeader="related work">
2.2 Related Work
</sectionHeader>
<bodyText confidence="0.99998004">
Intuitively such inference rules should be effective
for recognizing textual entailment. However, only
a small number of systems have used DIRT as a re-
source in the RTE-3 challenge, and the experimen-
tal results have not fully shown it has an important
contribution.
In (Clark et al., 2007)’s approach, semantic
parsing to clause representation is performed and
true entailment is decided only if every clause
in the semantic representation of T semantically
matches some clause in H. The only variation al-
lowed consists of rewritings derived from Word-
Net and DIRT. Given the preliminary stage of this
system, the overall results show very low improve-
ment over a random classification baseline.
(Bar-Haim et al., 2007) implement a proof
system using rules for generic linguistic struc-
tures, lexical-based rules, and lexical-syntactic
rules (these obtained with a DIRT-like algorithm
on the first CD of the Reuters RCV1 corpus). The
entailment considers not only the strict notion of
proof but also an approximate one. Given premise
p and hypothesis h, the lexical-syntactic compo-
nent marks all lexical noun alignments. For ev-
ery pair of alignment, the paths between the two
nouns are extracted, and the DIRT algorithm is
applied to obtain a similarity score. If the score
is above a threshold the rule is applied. However
these lexical-syntactic rules are only used in about
3% of the attempted proofs and in most cases there
is no lexical variation.
(Iftene and Balahur-Dobrescu, 2007) use DIRT
in a more relaxed manner. A DIRT rule is em-
ployed in the system if at least one of the anchors
match in T and H, i.e. they use them as unary
rules. However, the detailed analysis of the sys-
tem that they provide shows that the DIRT com-
ponent is the least relevant one (adding 0.4% of
precision).
In (Marsi et al., 2007), the focus is on the use-
fulness of DIRT. In their system a paraphrase sub-
stitution step is added on top of a system based on
a tree alignment algorithm. The basic paraphrase
substitution method follows three steps. Initially,
the two patterns of a rule are matched in T and
H (instantiations of the anchors X, Y do not have
to match). The text tree is transformed by apply-
ing the paraphrase substitution. Following this,
the transformed text tree and hypothesis trees are
aligned. The coverage (proportion of aligned con-
</bodyText>
<equation confidence="0.96457">
X write Y —*X author Y
X, founded in Y —*X, opened in Y
X launch Y —* X produce Y
X represent Z —* X work for Y
death relieved X —* X died
X faces menace from Y H X endangered by Y
X, peace agreement for Y
—* X is formulated to end war in Y
</equation>
<tableCaption confidence="0.574346">
Table 2: Example of inference rules needed in
RTE
</tableCaption>
<bodyText confidence="0.999666333333333">
tent words) is computed and if above some thresh-
old, entailment is true. The paraphrase compo-
nent adds 1.0% to development set results and only
0.5% to test sets, but a more detailed analysis on
the results of the interaction with the other system
components is not given.
</bodyText>
<sectionHeader confidence="0.964526" genericHeader="method">
3 Extending and refining DIRT
</sectionHeader>
<bodyText confidence="0.999939142857143">
Based on observations of using the inference rule
collection on the real data, we discover that 1)
some of the needed rules still lack even in a very
large collection such as DIRT and 2) some system-
atic errors in the collection can be excluded. On
both aspects, we use WordNet as additional lexi-
cal resource.
</bodyText>
<subsectionHeader confidence="0.930689">
Missing Rules
</subsectionHeader>
<bodyText confidence="0.999664">
A closer look into the RTE data reveals that
DIRT lacks many of the rules that entailment pairs
require.
Table 2 lists a selection of such rules. The
first rows contain rules which are structurally very
simple. These, however, are missing from DIRT
and most of them also from other hand-crafted re-
sources such as WordNet (i.e. there is no short
path connecting the two verbs). This is to be ex-
pected as they are rules which hold in specific con-
texts, but difficult to be captured by a sense dis-
tinction of the lexical items involved.
The more complex rules are even more difficult
to capture with a DIRT-like algorithm. Some of
these do not occur frequently enough even in large
amounts of text to permit acquiring them via the
DH.
</bodyText>
<subsectionHeader confidence="0.735316">
Combining WordNet and DIRT
</subsectionHeader>
<bodyText confidence="0.999902">
In order to address the issue of missing rules,
we investigate the effects of combining DIRT with
an exact hand-coded lexical resource in order to
create new rules.
For this we extended the DIRT rules by adding
</bodyText>
<page confidence="0.994643">
213
</page>
<construct confidence="0.553091444444444">
X face threat of Y
Pz� X at risk of Y
face
� confront, front, look, face up
threat
� menace, terror, scourge
risk
� danger, hazard, jeopardy,
endangerment, peril
</construct>
<tableCaption confidence="0.946452">
Table 3: Lexical variations creating new rules
</tableCaption>
<bodyText confidence="0.97509902">
based on DIRT rule X face threat of Y —* X at risk
of Y
rules in which any of the lexical items involved
in the patterns can be replaced by WordNet syn-
onyms. In the example above, we consider the
DIRT rule X face threat of Y —* X, at risk of Y
(Table 3).
Of course at this moment due to the lack of
sense disambiguation, our method introduces lots
of rules that are not correct. As one can see, ex-
pressions such as front scourge do not make any
sense, therefore any rules containing this will be
incorrect. However some of the new rules created
in this example, such as X face threat of Y Pz� X,
at danger of Y are reasonable ones and the rules
which are incorrect often contain patterns that are
very unlikely to occur in natural text.
The idea behind this is that a combination of
various lexical resources is needed in order to
cover the vast variety of phrases which humans
can judge to be in an inference relation.
The method just described allows us to identify
the first four rules listed in Table 2. We also ac-
quire the rule X face menace of Y Pz� X endangered
by Y (via X face threat of Y Pz� X threatened by Y,
menace Pz� threat, threaten Pz� endanger).
Our extension is application-oriented therefore
it is not intended to be evaluated as an independent
rule collection, but in an application scenario such
as RTE (Section 6).
In our experiments we also made a step towards
removing the most systematic errors present in
DIRT. DH algorithms have the main disadvantage
that not only phrases with the same meaning are
extracted but also phrases with opposite meaning.
In order to overcome this problem and since
such errors are relatively easy to detect, we ap-
plied a filter to the DIRT rules. This eliminates
inference rules which contain WordNet antonyms.
For such a rule to be eliminated the two patterns
have to be identical (with respect to edge labels
and content words) except from the antonymous
words; an example of a rule eliminated this way is
X have confidence in Y Pz� X lack confidence in Y.
As pointed out by (Szpektor et al., 2007) a thor-
ough evaluation of a rule collection is not a trivial
task; however due to our methodology we can as-
sume that the percentage of rules eliminated this
way that are indeed contradictions gets close to
100%.
</bodyText>
<sectionHeader confidence="0.994941" genericHeader="method">
4 Applying DIRT on RTE
</sectionHeader>
<bodyText confidence="0.999987">
In this section we point out two issues that are en-
countered when applying inference rules for tex-
tual entailment. The first issue is concerned with
correctly identifying the pairs in which the knowl-
edge encoded in these rules is needed. Follow-
ing this, another non-trivial task is to determine
the way this knowledge interacts with the rest of
information conveyed in an entailment pair. In or-
der to further investigate these issues, we apply the
rule collection on a dependency-based representa-
tion of text and hypothesis, namely Tree Skeleton.
</bodyText>
<subsectionHeader confidence="0.966202">
4.1 Observations
</subsectionHeader>
<bodyText confidence="0.999011133333333">
A straightforward experiment can reveal the num-
ber of pairs in the RTE data which contain rules
present in DIRT. For all the experiments in this pa-
per, we use the DIRT collection provided by (Lin
and Pantel, 2001), derived from the DIRT algo-
rithm applied on 1GB of news text. The results
we report here use only the most confident rules
amounting to more than 4 million rules (top 40 fol-
lowing (Lin and Pantel, 2001)).6
Following the definition of an entail-
ment rule, we identify RTE pairs in which
patterns(w1, w2) and pattern2(w1, w2) are
matched one in T and the other one in H and
(patterns(X, Y ), pattern2(X, Y)) is an infer-
ence rule. The pair bellow is an example of this.
</bodyText>
<construct confidence="0.772643">
T: The sale was made to pay Yukos US$ 27.5 billion tax
bill, Yuganskneftegaz was originally sold for US$ 9.4 bil-
lion to a little known company Baikalfinansgroup which was
later bought by the Russian state-owned oil company Ros-
neft.
H: Baikalfinansgroup was sold to Rosneft.
</construct>
<footnote confidence="0.998199666666667">
6Another set of experiments showed that for this particu-
lar task, using the entire collection instead of a subset gave
similar results.
</footnote>
<page confidence="0.997132">
214
</page>
<bodyText confidence="0.999722210526316">
On average, only 2% of the pairs in the RTE
data is subject to the application of such inference
rules. Out of these, approximately 50% are lexical
rules (one verb entailing the other). Out of these
lexical rules, around 50% are present in WordNet
in a synonym, hypernym or sister relation. At a
manual analysis, close to 80% of these are correct
rules; this is higher than the estimated accuracy of
DIRT, probably due to the bias of the data which
consists of pairs which are entailment candidates.
However, given the small number of inference
rules identified this way, we performed another
analysis. This aims at determining an upper
bound of the number of pairs featuring entailment
phrases present in a collection. Given DIRT and
the RTE data, we compute in how many pairs
the two patterns of a paraphrase can be matched
irrespective of their anchor values. An example is
the following pair,
</bodyText>
<construct confidence="0.8760684">
T: Libya’s case against Britain and the US concerns the
dispute over their demand for extradition of Libyans charged
with blowing up a Pan Am jet over Lockerbie in 1988.
H: One case involved the extradition of Libyan suspects
in the Pan Am Lockerbie bombing.
</construct>
<bodyText confidence="0.896126456521739">
This is a case in which the rule is correct and
the entailment is positive. In order to determine
this, a system will have to know that Libya’s case
against Britain and the US in T entails one case
in H. Similarly, in this context, the dispute over
their demand for extradition of Libyans charged
with blowing up a Pan Am jet over Lockerbie in
1988 in T can be replaced with the extradition of
Libyan suspects in the Pan Am Lockerbie bombing
preserving the meaning.
Altogether in around 20% of the pairs, patterns
of a rule can be found this way, many times with
more than one rule found in a pair. However, in
many of these pairs, finding the patterns of an in-
ference rule does not imply that the rule is truly
present in that pair.
Considering a system is capable of correctly
identifying the cases in which an inference rule
is needed, subsequent issues arise from the way
these fragments of text interact with the surround-
ing context. Assuming we have a correct rule
present in an entailment pair, the cases in which
the pair is still not a positive case of entailment
can be summarized as follows:
• The entailment rule is present in parts of the
text which are not relevant to the entailment
value of the pair.
• The rule is relevant, however the sentences
in which the patterns are embedded block the
entailment (e.g. through negative markers,
modifiers, embedding verbs not preserving
entailment)7
• The rule is correct in a limited number of con-
texts, but the current context is not the correct
one.
To sum up, making use of the knowledge en-
coded with such rules is not a trivial task. If rules
are used strictly in concordance with their defini-
tion, their utility is limited to a very small number
of entailment pairs. For this reason, 1) instead of
forcing the anchor values to be identical as most
previous work, we allow more flexible rule match-
ing (similar to (Marsi et al., 2007)) and 2) fur-
thermore, we control the rule application process
using a text representation based on dependency
structure.
</bodyText>
<subsectionHeader confidence="0.989208">
4.2 Tree Skeleton
</subsectionHeader>
<bodyText confidence="0.99991">
The Tree Skeleton (TS) structure was proposed by
(Wang and Neumann, 2007), and can be viewed
as an extended version of the predicate-argument
structure. Since it contains not only the predi-
cate and its arguments, but also the dependency
paths in-between, it captures the essential part of
the sentence.
Following their algorithm, we first preprocess
the data using a dependency parser8 and then
select overlapping topic words (i.e. nouns) in T
and H. By doing so, we use fuzzy match at the
substring level instead of full match. Starting
with these nouns, we traverse the dependency
tree to identify the lowest common ancestor node
(named as root node). This sub-tree without the
inner yield is defined as a Tree Skeleton. Figure
1 shows the TS of T of the following positive
example,
</bodyText>
<footnote confidence="0.689135">
T For their discovery of ulcer-causing bacteria, Aus-
tralian doctors Robin Warren and Barry Marshall have re-
ceived the 2005 Nobel Prize in Physiology or Medicine.
H Robin Warren was awarded a Nobel Prize.
Notice that, in order to match the inference rules
with two anchors, the number of the dependency
7See (Nairn et al., 2006) for a detailed analysis of these
aspects.
8Here we also use Minipar for the reason of consistence
</footnote>
<page confidence="0.998322">
215
</page>
<figureCaption confidence="0.9950265">
Figure 1: Dependency structure of text. Tree
skeleton in bold
</figureCaption>
<bodyText confidence="0.95568496875">
paths contained in a TS should also be two. In
practice, among all the 800 T-H pairs of the RTE-
2 test set, we successfully extracted tree skeletons
in 296 text pairs, i.e., 37% of the test data is cov-
ered by this step and results on other data sets are
similar.
Applying DIRT on a TS
Dependency representations like the tree skele-
ton have been explored by many researchers, e.g.
(Zanzotto and Moschitti, 2006) have utilized a tree
kernel method to calculate the similarity between
T and H, and (Wang and Neumann, 2007) chose
subsequence kernel to reduce the computational
complexity. However, the focus of this paper is to
evaluate the application of inference rules on RTE,
instead of exploring methods of tackling the task
itself. Therefore, we performed a straightforward
matching algorithm to apply the inference rules
on top of the tree skeleton structure. Given tree
skeletons of T and H, we check if the two left de-
pendency paths, the two right ones or the two root
nodes contain the patterns of a rule.
In the example above, the rule X obj
←−−
su bj obj2 o
receive −−−→ Y ≈ X ← award −−−→bj1 Y satisfies
this criterion, as it is matched at the root nodes.
Notice that the rule is correct only in restricted
contexts, in which the object of receive is some-
thing which is conferred on the basis of merit.
However in this pair, the context is indeed the cor-
rect one.
</bodyText>
<sectionHeader confidence="0.999011" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999954133333333">
Our experiments consist in predicting positive en-
tailment in a very straightforward rule-based man-
ner (Table 4 summarizes the results using three
different rule collections). For each collection we
select the RTE pairs in which we find a tree skele-
ton and match an inference rule. The first number
in our table entries represents how many of such
pairs we have identified, out the 1600 of devel-
opment and test pairs. For these pairs we simply
predict positive entailment and the second entry
represents what percentage of these pairs are in-
deed positive entailment. Our work does not fo-
cus on building a complete RTE system; however,
we also combine our method with a bag of words
baseline to see the effects on the whole data set.
</bodyText>
<subsectionHeader confidence="0.984485">
5.1 Results on a subset of the data
</subsectionHeader>
<bodyText confidence="0.999992628571429">
In the first two columns (DirtTS and Dirt+WNTS)
we consider DIRT in its original state and DIRT
with rules generated with WordNet as described
in Section 3; all precisions are higher than 67%9.
After adding WordNet, approximately in twice as
many pairs, tree skeletons and rules are matched,
while the precision is not harmed. This may in-
dicate that our method of adding rules does not
decrease precision of an RTE system.
In the third column we report the results of us-
ing a set of rules containing only the trivial iden-
tity ones (IdTS). For our current system, this can
be seen as a precision upper bound for all the
other collections, in concordance with the fact that
identical rules are nothing but inference rules of
highest possible confidence. The fourth column
(Dirt+Id+WNTS) contains what can be consid-
ered our best setting. In this setting considerably
more pairs are covered using a collection contain-
ing DIRT and identity rules with WordNet exten-
sion.
Although the precision results with this setting
are encouraging (65% for RTE2 data and 72% for
RTE3 data), the coverage is still low, 8% for RTE2
and 6% for RTE3. This aspect together with an er-
ror analysis we performed are the focus of Section
7.
The last column (Dirt+Id+WN) gives the preci-
sion we obtain if we simply decide a pair is true
entailment if we have an inference rule matched in
it (irrespective of the values of the anchors or of
the existence of tree skeletons). As expected, only
identifying the patterns of a rule in a pair irrespec-
tive of tree skeletons does not give any indication
of the entailment value of the pair.
</bodyText>
<footnote confidence="0.997880666666667">
9The RTE task is considered to be difficult. The aver-
age accuracy of the systems in the RTE-3 challenge is around
61% (Giampiccolo et al., 2007)
</footnote>
<page confidence="0.993135">
216
</page>
<table confidence="0.955126666666667">
RTE Set DirtTS Dirt + WNTS IdTS Dirt + Id + WNTS Dirt + Id + WN
RTE2 49/69.38 94/67.02 45/66.66 130/65.38 673/50.07
RTE3 42/69.04 70/70.00 29/79.31 93/72.05 661/55.06
</table>
<tableCaption confidence="0.998473">
Table 4: Coverage/precision with various rule collections
</tableCaption>
<table confidence="0.9153058">
RTE Set
BoW Main
ference rule for this pair.
RTE2 (85 pairs)
RTE3 (64 pairs)
</table>
<tableCaption confidence="0.9832228">
Table 5: Precision on the covered RTE data
RTE Set (800 pairs) BoW Main &amp; BoW
56.87% 57.75%
61.12% 61.75%
Table 6: Precision on full RTE data
</tableCaption>
<subsectionHeader confidence="0.950409">
5.2 Results on the entire data
</subsectionHeader>
<bodyText confidence="0.999928727272727">
At last, we also integrate our method with a bag
of words baseline, which calculates the ratio of
overlapping words in T and H. For the pairs that
our method covers, we overrule the baseline’s de-
cision. The results are shown in Table 6 (Main
stands for the Dirt + Id + WNTS configuration).
On the full data set, the improvement is still small
due to the low coverage of our method, however
on the pairs that are covered by our method (Ta-
ble 5), there is a significant improvement over the
overlap baseline.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999954491803279">
In this section we take a closer look at the data in
order to better understand how does our method
of combining tree skeletons and inference rules
work. We will first perform error analysis on what
we have considered our best setting so far. Fol-
lowing this, we analyze data to identify the main
reasons which cause the low coverage.
For error analysis we consider the pairs incor-
rectly classified in the RTE3 test data set, consist-
ing of a total of 25 pairs. We classify the errors
into three main categories: rule application errors,
inference rule errors, and other errors (Table 7).
In the first category, the tree skeleton fails to
match the corresponding anchors of the inference
rules. For instance, if someone founded the Insti-
tute of Mathematics (Instituto di Matematica) at
the University ofMilan, it does not follow that they
founded The University of Milan. The Institute of
Mathematics should be aligned with the Univer-
sity of Milan, which should avoid applying the in-
A rather small portion of the errors (16%) are
caused by incorrect inference rules. Out of these,
two are correct in some contexts but not in the en-
tailment pairs in which they are found. For exam-
ple, the following rule X generate Y Pt� X earn Y is
used incorrectly, however in the restricted context
of money or income, the two verbs have similar
meaning. An example of an incorrect rule is X is-
sue Y Pt� X hit Y since it is difficult to find a context
in which this holds.
The last category contains all the other errors.
In all these cases, the additional information con-
veyed by the text or the hypothesis which cannot
be captured by our current approach, affects the
entailment. For example an imitation diamond is
not a diamond, and more than 1,000 members
of the Russian and foreign media does not entail
more than 1,000 members from Russia; these are
not trivial, since lexical semantics and fine-grained
analysis of the restrictors are needed.
For the second part of our analysis we discuss
the coverage issue, based on an analysis of uncov-
ered pairs. A main factor in failing to detect pairs
in which entailment rules should be applied is the
fact that the tree skeleton does not find the corre-
sponding lexical items of two rule patterns.
Issues will occur even if the tree skeleton struc-
ture is modified to align all the corresponding frag-
ments together. Consider cases such as threaten to
boycott and boycott or similar constructions with
other embedding verbs such as manage, forget, at-
tempt. Our method can detect if the two embedded
verbs convey a similar meaning, however not how
the embedding verbs affect the implication.
Independent of the shortcomings of our tree
skeleton structure, a second factor in failing to de-
tect true entailment still lies in lack of rules. For
instance, the last two examples in Table 2 are en-
tailment pair fragments which can be formulated
as inference rules, but it is not straightforward to
acquire them via the DH.
</bodyText>
<figure confidence="0.88380575">
51.76% 60.00%
54.68% 62.50%
RTE2
RTE3
</figure>
<page confidence="0.917344">
217
</page>
<table confidence="0.99872875">
Source of error % pairs
Incorrect rule application 32%
Incorrect inference rules 16%
Other errors 52%
</table>
<tableCaption confidence="0.998885">
Table 7: Error analysis
</tableCaption>
<sectionHeader confidence="0.994547" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9991055">
Throughout the paper we have identified impor-
tant issues encountered in using inference rules for
textual entailment and proposed methods to solve
them. We explored the possibility of combin-
ing a collection obtained in a statistical, unsuper-
vised manner, DIRT, with a hand-crafted lexical
resource in order to make inference rules have a
larger contribution to applications. We also inves-
tigated ways of effectively applying these rules.
The experiment results show that although cover-
age is still not satisfying, the precision is promis-
ing. Therefore our method has the potential to be
successfully integrated in a larger entailment de-
tection framework.
The error analysis points out several possible
future directions. The tree skeleton representation
we used needs to be enhanced in order to capture
more accurately the relevant fragments of the text.
A different issue remains the fact that a lot of rules
we could use for textual entailment detection are
still lacking. A proper study of the limitations of
the DH as well as a classification of the knowledge
we want to encode as inference rules would be a
step forward towards solving this problem.
Furthermore, although all the inference rules we
used aim at recognizing positive entailment cases,
it is natural to use them for detecting negative
cases of entailment as well. In general, we can
identify pairs in which the patterns of an inference
rule are present but the anchors are mismatched, or
they are not the correct hypernym/hyponym rela-
tion. This can be the base of a principled method
for detecting structural contradictions (de Marn-
effe et al., 2008).
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.998546">
We thank Dekang Lin and Patrick Pantel for
providing the DIRT collection and to Grzegorz
Chrupała, Alexander Koller, Manfred Pinkal and
Stefan Thater for very useful discussions. Geor-
giana Dinu and Rui Wang are funded by the IRTG
and PIRE PhD scholarship programs.
</bodyText>
<sectionHeader confidence="0.99001" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884642857143">
Roy Bar-Haim, Ido Dagan, Iddo Greental, Idan Szpek-
tor, and Moshe Friedman. 2007. Semantic inference
at the lexical-syntactic level for textual entailment
recognition. In Proceedings of the ACL-PASCAL
Workshop on Textual Entailment and Paraphrasing,
pages 131–136, Prague, June. Association for Com-
putational Linguistics.
Regina Barzilay and Kathleen R. McKeown. 2001.
Extracting paraphrases from a parallel corpus. In
Proceedings of 39th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 50–57,
Toulouse, France, July. Association for Computa-
tional Linguistics.
Roberto Basili, Diego De Cao, Paolo Marocco, and
Marco Pennacchiotti. 2007. Learning selectional
preferences for entailment or paraphrasing rules. In
In Proceedings of RANLP, Borovets, Bulgaria.
Peter Clark, Phil Harrison, John Thompson, William
Murray, Jerry Hobbs, and Christiane Fellbaum.
2007. On the role of lexical and world knowledge
in rte3. In Proceedings of the ACL-PASCAL Work-
shop on Textual Entailment and Paraphrasing, pages
54–59, Prague, June. Association for Computational
Linguistics.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The pascal recognising textual entailment
challenge. In Lecture Notes in Computer Science,
Vol. 3944, Springer, pages 177–190. Quionero-
Candela, J.; Dagan, I.; Magnini, B.; d’Alch-Buc, F.
Machine Learning Challenges.
Marie-Catherine de Marneffe, Anna N. Rafferty, and
Christopher D. Manning. 2008. Finding contradic-
tions in text. In Proceedings ofACL-08: HLT, pages
1039–1047, Columbus, Ohio, June. Association for
Computational Linguistics.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recognizing
textual entailment challenge. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, pages 1–9, Prague, June. Association
for Computational Linguistics.
Adrian Iftene and Alexandra Balahur-Dobrescu. 2007.
Hypothesis transformation and semantic variability
rules used in recognizing textual entailment. In
Proceedings of the ACL-PASCAL Workshop on Tex-
tual Entailment and Paraphrasing, pages 125–130,
Prague, June. Association for Computational Lin-
guistics.
Dekang Lin and Patrick Pantel. 2001. Dirt. discov-
ery of inference rules from text. In KDD ’01: Pro-
ceedings of the seventh ACM SIGKDD international
conference on Knowledge discovery and data min-
ing, pages 323–328, New York, NY, USA. ACM.
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Proc. Workshop on the Evaluation of
Parsing Systems, Granada.
</reference>
<page confidence="0.980022">
218
</page>
<reference confidence="0.999864765957447">
Erwin Marsi, Emiel Krahmer, and Wauter Bosma.
2007. Dependency-based paraphrasing for recog-
nizing textual entailment. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, pages 83–88, Prague, June. Associa-
tion for Computational Linguistics.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. In Proceedings of ICoS-5 (Inference in Com-
putational Semantics, Buxton, UK.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations:
Extracting paraphrases and generating new sen-
tences. In HLT-NAACL, pages 102–109.
Satoshi Sekine. 2005. Automatic paraphrase discovery
based on context and keywords between NE pairs.
In Proceedings of International Workshop on Para-
phrase, pages 80–87, Jeju Island, Korea.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisi-
tion of entailment relations. In In Proceedings of
EMNLP, pages 41–48.
Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007.
Instance-based evaluation of entailment rule acqui-
sition. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
456–463, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob
Goldberger. 2008. Contextual preferences. In Pro-
ceedings of ACL-08: HLT, pages 683–691, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
Rui Wang and G¨unter Neumann. 2007. Recognizing
textual entailment using sentence similarity based on
dependency tree skeletons. In Proceedings of the
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, pages 36–41, Prague, June. Associa-
tion for Computational Linguistics.
Fabio Massimo Zanzotto and Alessandro Moschitti.
2006. Automatic learning of textual entailments
with cross-pair similarities. In ACL-44: Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics,
pages 401–408, Morristown, NJ, USA. Association
for Computational Linguistics.
</reference>
<page confidence="0.999215">
219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.823178">
<title confidence="0.999626">Inference Rules and their Application to Recognizing Textual Entailment</title>
<author confidence="0.99917">Georgiana Dinu</author>
<affiliation confidence="0.999999">Saarland University</affiliation>
<address confidence="0.99894">Campus, D-66123 Saarbr¨ucken</address>
<email confidence="0.987396">dinu@coli.uni-sb.de</email>
<author confidence="0.999546">Rui Wang</author>
<affiliation confidence="0.999998">Saarland University</affiliation>
<address confidence="0.998682">Campus, D-66123 Saarbr¨ucken</address>
<email confidence="0.993939">rwang@coli.uni-sb.de</email>
<abstract confidence="0.990032764705882">In this paper, we explore ways of improving an inference rule collection and its application to the task of recognizing textual entailment. For this purpose, we start with an automatically acquired collection and we propose methods to refine it and obtain more rules using a hand-crafted lexical resource. Following this, we derive a dependency-based structure representation from texts, which aims to provide a proper base for the inference rule application. The evaluation of our approach on the recognizing textual entailment data shows promising results on precision and the error analysis suggests possible improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Ido Dagan</author>
<author>Iddo Greental</author>
<author>Idan Szpektor</author>
<author>Moshe Friedman</author>
</authors>
<title>Semantic inference at the lexical-syntactic level for textual entailment recognition.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>131--136</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="8844" citStr="Bar-Haim et al., 2007" startWordPosition="1479" endWordPosition="1482">r, only a small number of systems have used DIRT as a resource in the RTE-3 challenge, and the experimental results have not fully shown it has an important contribution. In (Clark et al., 2007)’s approach, semantic parsing to clause representation is performed and true entailment is decided only if every clause in the semantic representation of T semantically matches some clause in H. The only variation allowed consists of rewritings derived from WordNet and DIRT. Given the preliminary stage of this system, the overall results show very low improvement over a random classification baseline. (Bar-Haim et al., 2007) implement a proof system using rules for generic linguistic structures, lexical-based rules, and lexical-syntactic rules (these obtained with a DIRT-like algorithm on the first CD of the Reuters RCV1 corpus). The entailment considers not only the strict notion of proof but also an approximate one. Given premise p and hypothesis h, the lexical-syntactic component marks all lexical noun alignments. For every pair of alignment, the paths between the two nouns are extracted, and the DIRT algorithm is applied to obtain a similarity score. If the score is above a threshold the rule is applied. Howe</context>
</contexts>
<marker>Bar-Haim, Dagan, Greental, Szpektor, Friedman, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, Idan Szpektor, and Moshe Friedman. 2007. Semantic inference at the lexical-syntactic level for textual entailment recognition. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 131–136, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>50--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Toulouse, France,</location>
<contexts>
<context position="3715" citStr="Barzilay and McKeown, 2001" startWordPosition="601" endWordPosition="604">sed) text2. For the extension and refinement, a hand-crafted lexical resource is used for augmenting the original inference rule collection and exclude some of the incorrect rules. For the second aspect, we focus on applying these rules to the RTE task. In particular, we use a structure representation derived from the dependency parse trees of T and H, which aims to capture the essential information they convey. The rest of the paper is organized as follows: Section 2 introduces the inference rule collection 2Another line of work on acquiring paraphrases uses comparable corpora, for instance (Barzilay and McKeown, 2001), (Pang et al., 2003) Proceedings of the 12th Conference of the European Chapter of the ACL, pages 211–219, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 211 we use, based on the Discovery of Inference Rules from Text (henceforth DIRT) algorithm and discusses previous work on applying it to the RTE task. Section 3 focuses on the rule collection itself and on the methods in which we use an external lexical resource to extend and refine it. Section 4 discusses the application of the rules for the RTE data, describing the structure representation we use</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 50–57, Toulouse, France, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Diego De Cao</author>
<author>Paolo Marocco</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Learning selectional preferences for entailment or paraphrasing rules. In</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<marker>Basili, De Cao, Marocco, Pennacchiotti, 2007</marker>
<rawString>Roberto Basili, Diego De Cao, Paolo Marocco, and Marco Pennacchiotti. 2007. Learning selectional preferences for entailment or paraphrasing rules. In In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
<author>John Thompson</author>
<author>William Murray</author>
<author>Jerry Hobbs</author>
<author>Christiane Fellbaum</author>
</authors>
<title>On the role of lexical and world knowledge in rte3.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>54--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="1304" citStr="Clark et al., 2007" startWordPosition="193" endWordPosition="196"> rule application. The evaluation of our approach on the recognizing textual entailment data shows promising results on precision and the error analysis suggests possible improvements. 1 Introduction Textual inference plays an important role in many natural language processing (NLP) tasks. In recent years, the recognizing textual entailment (RTE) (Dagan et al., 2006) challenge, which focuses on detecting semantic inference, has attracted a lot of attention. Given a text T (several sentences) and a hypothesis H (one sentence), the goal is to detect if H can be inferred from T. Studies such as (Clark et al., 2007) attest that lexical substitution (e.g. synonyms, antonyms) or simple syntactic variation account for the entailment only in a small number of pairs. Thus, one essential issue is to identify more complex expressions which, in appropriate contexts, convey the same (or similar) meaning. However, more generally, we are also interested in pairs of expressions in which only a uni-directional inference relation holds1. 1We will use the term inference rule to stand for such concept; the two expressions can be actual paraphrases if the relation is bi-directional A typical example is the following RTE </context>
<context position="8416" citStr="Clark et al., 2007" startWordPosition="1412" endWordPosition="1415">more basic issue: how to successfully use rules in their current form. 4For simplification, in the rest of the paper we will omit giving the dependency relations in a pattern. 5For example X won Y entails X played Y only when Y refers to some sort of competition, but not if Y refers to a musical instrument. 212 2.2 Related Work Intuitively such inference rules should be effective for recognizing textual entailment. However, only a small number of systems have used DIRT as a resource in the RTE-3 challenge, and the experimental results have not fully shown it has an important contribution. In (Clark et al., 2007)’s approach, semantic parsing to clause representation is performed and true entailment is decided only if every clause in the semantic representation of T semantically matches some clause in H. The only variation allowed consists of rewritings derived from WordNet and DIRT. Given the preliminary stage of this system, the overall results show very low improvement over a random classification baseline. (Bar-Haim et al., 2007) implement a proof system using rules for generic linguistic structures, lexical-based rules, and lexical-syntactic rules (these obtained with a DIRT-like algorithm on the </context>
</contexts>
<marker>Clark, Harrison, Thompson, Murray, Hobbs, Fellbaum, 2007</marker>
<rawString>Peter Clark, Phil Harrison, John Thompson, William Murray, Jerry Hobbs, and Christiane Fellbaum. 2007. On the role of lexical and world knowledge in rte3. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 54–59, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2006</date>
<booktitle>In Lecture Notes in Computer Science,</booktitle>
<volume>3944</volume>
<pages>177--190</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="1054" citStr="Dagan et al., 2006" startWordPosition="149" endWordPosition="152">quired collection and we propose methods to refine it and obtain more rules using a hand-crafted lexical resource. Following this, we derive a dependency-based structure representation from texts, which aims to provide a proper base for the inference rule application. The evaluation of our approach on the recognizing textual entailment data shows promising results on precision and the error analysis suggests possible improvements. 1 Introduction Textual inference plays an important role in many natural language processing (NLP) tasks. In recent years, the recognizing textual entailment (RTE) (Dagan et al., 2006) challenge, which focuses on detecting semantic inference, has attracted a lot of attention. Given a text T (several sentences) and a hypothesis H (one sentence), the goal is to detect if H can be inferred from T. Studies such as (Clark et al., 2007) attest that lexical substitution (e.g. synonyms, antonyms) or simple syntactic variation account for the entailment only in a small number of pairs. Thus, one essential issue is to identify more complex expressions which, in appropriate contexts, convey the same (or similar) meaning. However, more generally, we are also interested in pairs of expr</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The pascal recognising textual entailment challenge. In Lecture Notes in Computer Science, Vol. 3944, Springer, pages 177–190. QuioneroCandela, J.; Dagan, I.; Magnini, B.; d’Alch-Buc, F. Machine Learning Challenges.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Anna N Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Finding contradictions in text.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08: HLT,</booktitle>
<pages>1039--1047</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<marker>de Marneffe, Rafferty, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe, Anna N. Rafferty, and Christopher D. Manning. 2008. Finding contradictions in text. In Proceedings ofACL-08: HLT, pages 1039–1047, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="24879" citStr="Giampiccolo et al., 2007" startWordPosition="4331" endWordPosition="4334">TE3. This aspect together with an error analysis we performed are the focus of Section 7. The last column (Dirt+Id+WN) gives the precision we obtain if we simply decide a pair is true entailment if we have an inference rule matched in it (irrespective of the values of the anchors or of the existence of tree skeletons). As expected, only identifying the patterns of a rule in a pair irrespective of tree skeletons does not give any indication of the entailment value of the pair. 9The RTE task is considered to be difficult. The average accuracy of the systems in the RTE-3 challenge is around 61% (Giampiccolo et al., 2007) 216 RTE Set DirtTS Dirt + WNTS IdTS Dirt + Id + WNTS Dirt + Id + WN RTE2 49/69.38 94/67.02 45/66.66 130/65.38 673/50.07 RTE3 42/69.04 70/70.00 29/79.31 93/72.05 661/55.06 Table 4: Coverage/precision with various rule collections RTE Set BoW Main ference rule for this pair. RTE2 (85 pairs) RTE3 (64 pairs) Table 5: Precision on the covered RTE data RTE Set (800 pairs) BoW Main &amp; BoW 56.87% 57.75% 61.12% 61.75% Table 6: Precision on full RTE data 5.2 Results on the entire data At last, we also integrate our method with a bag of words baseline, which calculates the ratio of overlapping words in T</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 1–9, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Iftene</author>
<author>Alexandra Balahur-Dobrescu</author>
</authors>
<title>Hypothesis transformation and semantic variability rules used in recognizing textual entailment.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>125--130</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="9612" citStr="Iftene and Balahur-Dobrescu, 2007" startWordPosition="1603" endWordPosition="1606">ned with a DIRT-like algorithm on the first CD of the Reuters RCV1 corpus). The entailment considers not only the strict notion of proof but also an approximate one. Given premise p and hypothesis h, the lexical-syntactic component marks all lexical noun alignments. For every pair of alignment, the paths between the two nouns are extracted, and the DIRT algorithm is applied to obtain a similarity score. If the score is above a threshold the rule is applied. However these lexical-syntactic rules are only used in about 3% of the attempted proofs and in most cases there is no lexical variation. (Iftene and Balahur-Dobrescu, 2007) use DIRT in a more relaxed manner. A DIRT rule is employed in the system if at least one of the anchors match in T and H, i.e. they use them as unary rules. However, the detailed analysis of the system that they provide shows that the DIRT component is the least relevant one (adding 0.4% of precision). In (Marsi et al., 2007), the focus is on the usefulness of DIRT. In their system a paraphrase substitution step is added on top of a system based on a tree alignment algorithm. The basic paraphrase substitution method follows three steps. Initially, the two patterns of a rule are matched in T a</context>
</contexts>
<marker>Iftene, Balahur-Dobrescu, 2007</marker>
<rawString>Adrian Iftene and Alexandra Balahur-Dobrescu. 2007. Hypothesis transformation and semantic variability rules used in recognizing textual entailment. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 125–130, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Dirt. discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In KDD ’01: Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>323--328</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5203" citStr="Lin and Pantel, 2001" startWordPosition="849" endWordPosition="852">round A number of automatically acquired inference rule/paraphrase collections are available, such as (Szpektor et al., 2004), (Sekine, 2005). In our work we use the DIRT collection because it is the largest one available and it has a relatively good accuracy (in the 50% range for top generated paraphrases, (Szpektor et al., 2007)). In this section, we describe the DIRT algorithm for acquiring inference rules. Following that, we will overview the RTE systems which take DIRT as an external knowledge resource. 2.1 Discovery of Inference Rules from Text The DIRT algorithm has been introduced by (Lin and Pantel, 2001) and it is based on what is called the Extended Distributional Hypothesis. The original DH states that words occurring in similar contexts have similar meaning, whereas the extended version hypothesizes that phrases occurring in similar contexts are similar. An inference rule in DIRT is a pair of binary relations ( pattern1(X, Y ), pattern2(X, Y ) ) which stand in an inference relation. pattern1 and pattern2 are chains in dependency trees3 while X and Y are placeholders for nouns at the end of this chain. The two patterns will constitute a candidate paraphrase if the sets of X and Y values exh</context>
<context position="7251" citStr="Lin and Pantel, 2001" startWordPosition="1206" endWordPosition="1210">require the entailment to hold in some and not all contexts, motivated by the fact that such inferences occur often in natural text. The algorithm does not extract directional inference rules, it can only identify candidate paraphrases; many of the rules are however unidirectional. Besides syntactic rewriting or lexical rules, rules in which the patterns are rather complex phrases are also extracted. Some of the rules encode lexical relations which can also be found in resources such as WordNet while others are lexical-syntactic variations that are unlikely to occur in hand-crafted resources (Lin and Pantel, 2001). Table 1 gives a few examples of rules present in DIRT4. Current work on inference rules focuses on making such resources more precise. (Basili et al., 2007) and (Szpektor et al., 2008) propose attaching selectional preferences to inference rules. These are semantic classes which correspond to the anchor values of an inference rule and have the role of making precise the context in which the rule can be applied 5. This aspect is very important and we plan to address it in our future work. However in this paper we investigate the first and more basic issue: how to successfully use rules in the</context>
<context position="15629" citStr="Lin and Pantel, 2001" startWordPosition="2703" endWordPosition="2706">ly identifying the pairs in which the knowledge encoded in these rules is needed. Following this, another non-trivial task is to determine the way this knowledge interacts with the rest of information conveyed in an entailment pair. In order to further investigate these issues, we apply the rule collection on a dependency-based representation of text and hypothesis, namely Tree Skeleton. 4.1 Observations A straightforward experiment can reveal the number of pairs in the RTE data which contain rules present in DIRT. For all the experiments in this paper, we use the DIRT collection provided by (Lin and Pantel, 2001), derived from the DIRT algorithm applied on 1GB of news text. The results we report here use only the most confident rules amounting to more than 4 million rules (top 40 following (Lin and Pantel, 2001)).6 Following the definition of an entailment rule, we identify RTE pairs in which patterns(w1, w2) and pattern2(w1, w2) are matched one in T and the other one in H and (patterns(X, Y ), pattern2(X, Y)) is an inference rule. The pair bellow is an example of this. T: The sale was made to pay Yukos US$ 27.5 billion tax bill, Yuganskneftegaz was originally sold for US$ 9.4 billion to a little know</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Dirt. discovery of inference rules from text. In KDD ’01: Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 323–328, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of minipar.</title>
<date>1998</date>
<booktitle>In Proc. Workshop on the Evaluation of Parsing Systems,</booktitle>
<location>Granada.</location>
<contexts>
<context position="6058" citStr="Lin, 1998" startWordPosition="1000" endWordPosition="1001"> are similar. An inference rule in DIRT is a pair of binary relations ( pattern1(X, Y ), pattern2(X, Y ) ) which stand in an inference relation. pattern1 and pattern2 are chains in dependency trees3 while X and Y are placeholders for nouns at the end of this chain. The two patterns will constitute a candidate paraphrase if the sets of X and Y values exhibit relevant overlap. In the following example, the two patterns are prevent and provide protection against. X subj ���� prevent obj ��� Y X subj ���� provide obj ��� protection mod ���� against pcomp ����� Y 3obtained with the Minipar parser (Lin, 1998) X put emphasis on Y � X pay attention to Y � X attach importance to Y � X increase spending on Y � X place emphasis on Y � Y priority of X � X focus on Y Table 1: Example of DIRT algorithm output. Most confident paraphrases of X put emphasis on Y Such rules can be informally defined (Szpektor et al., 2007) as directional relations between two text patterns with variables. The left-handside pattern is assumed to entail the right-handside pattern in certain contexts, under the same variable instantiation. The definition relaxes the intuition of inference, as we only require the entailment to ho</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of minipar. In Proc. Workshop on the Evaluation of Parsing Systems, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
<author>Wauter Bosma</author>
</authors>
<title>Dependency-based paraphrasing for recognizing textual entailment.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>83--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="9940" citStr="Marsi et al., 2007" startWordPosition="1669" endWordPosition="1672">and the DIRT algorithm is applied to obtain a similarity score. If the score is above a threshold the rule is applied. However these lexical-syntactic rules are only used in about 3% of the attempted proofs and in most cases there is no lexical variation. (Iftene and Balahur-Dobrescu, 2007) use DIRT in a more relaxed manner. A DIRT rule is employed in the system if at least one of the anchors match in T and H, i.e. they use them as unary rules. However, the detailed analysis of the system that they provide shows that the DIRT component is the least relevant one (adding 0.4% of precision). In (Marsi et al., 2007), the focus is on the usefulness of DIRT. In their system a paraphrase substitution step is added on top of a system based on a tree alignment algorithm. The basic paraphrase substitution method follows three steps. Initially, the two patterns of a rule are matched in T and H (instantiations of the anchors X, Y do not have to match). The text tree is transformed by applying the paraphrase substitution. Following this, the transformed text tree and hypothesis trees are aligned. The coverage (proportion of aligned conX write Y —*X author Y X, founded in Y —*X, opened in Y X launch Y —* X produce</context>
<context position="19560" citStr="Marsi et al., 2007" startWordPosition="3401" endWordPosition="3404"> patterns are embedded block the entailment (e.g. through negative markers, modifiers, embedding verbs not preserving entailment)7 • The rule is correct in a limited number of contexts, but the current context is not the correct one. To sum up, making use of the knowledge encoded with such rules is not a trivial task. If rules are used strictly in concordance with their definition, their utility is limited to a very small number of entailment pairs. For this reason, 1) instead of forcing the anchor values to be identical as most previous work, we allow more flexible rule matching (similar to (Marsi et al., 2007)) and 2) furthermore, we control the rule application process using a text representation based on dependency structure. 4.2 Tree Skeleton The Tree Skeleton (TS) structure was proposed by (Wang and Neumann, 2007), and can be viewed as an extended version of the predicate-argument structure. Since it contains not only the predicate and its arguments, but also the dependency paths in-between, it captures the essential part of the sentence. Following their algorithm, we first preprocess the data using a dependency parser8 and then select overlapping topic words (i.e. nouns) in T and H. By doing s</context>
</contexts>
<marker>Marsi, Krahmer, Bosma, 2007</marker>
<rawString>Erwin Marsi, Emiel Krahmer, and Wauter Bosma. 2007. Dependency-based paraphrasing for recognizing textual entailment. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 83–88, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rowan Nairn</author>
<author>Cleo Condoravdi</author>
<author>Lauri Karttunen</author>
</authors>
<title>Computing relative polarity for textual inference.</title>
<date>2006</date>
<booktitle>In Proceedings of ICoS-5 (Inference in Computational Semantics,</booktitle>
<location>Buxton, UK.</location>
<contexts>
<context position="20811" citStr="Nairn et al., 2006" startWordPosition="3610" endWordPosition="3613">string level instead of full match. Starting with these nouns, we traverse the dependency tree to identify the lowest common ancestor node (named as root node). This sub-tree without the inner yield is defined as a Tree Skeleton. Figure 1 shows the TS of T of the following positive example, T For their discovery of ulcer-causing bacteria, Australian doctors Robin Warren and Barry Marshall have received the 2005 Nobel Prize in Physiology or Medicine. H Robin Warren was awarded a Nobel Prize. Notice that, in order to match the inference rules with two anchors, the number of the dependency 7See (Nairn et al., 2006) for a detailed analysis of these aspects. 8Here we also use Minipar for the reason of consistence 215 Figure 1: Dependency structure of text. Tree skeleton in bold paths contained in a TS should also be two. In practice, among all the 800 T-H pairs of the RTE2 test set, we successfully extracted tree skeletons in 296 text pairs, i.e., 37% of the test data is covered by this step and results on other data sets are similar. Applying DIRT on a TS Dependency representations like the tree skeleton have been explored by many researchers, e.g. (Zanzotto and Moschitti, 2006) have utilized a tree kern</context>
</contexts>
<marker>Nairn, Condoravdi, Karttunen, 2006</marker>
<rawString>Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen. 2006. Computing relative polarity for textual inference. In Proceedings of ICoS-5 (Inference in Computational Semantics, Buxton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>102--109</pages>
<contexts>
<context position="3736" citStr="Pang et al., 2003" startWordPosition="605" endWordPosition="608">and refinement, a hand-crafted lexical resource is used for augmenting the original inference rule collection and exclude some of the incorrect rules. For the second aspect, we focus on applying these rules to the RTE task. In particular, we use a structure representation derived from the dependency parse trees of T and H, which aims to capture the essential information they convey. The rest of the paper is organized as follows: Section 2 introduces the inference rule collection 2Another line of work on acquiring paraphrases uses comparable corpora, for instance (Barzilay and McKeown, 2001), (Pang et al., 2003) Proceedings of the 12th Conference of the European Chapter of the ACL, pages 211–219, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 211 we use, based on the Discovery of Inference Rules from Text (henceforth DIRT) algorithm and discusses previous work on applying it to the RTE task. Section 3 focuses on the rule collection itself and on the methods in which we use an external lexical resource to extend and refine it. Section 4 discusses the application of the rules for the RTE data, describing the structure representation we use to identify the appr</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In HLT-NAACL, pages 102–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Automatic paraphrase discovery based on context and keywords between NE pairs.</title>
<date>2005</date>
<booktitle>In Proceedings of International Workshop on Paraphrase,</booktitle>
<pages>80--87</pages>
<location>Jeju Island,</location>
<contexts>
<context position="4723" citStr="Sekine, 2005" startWordPosition="769" endWordPosition="770">lf and on the methods in which we use an external lexical resource to extend and refine it. Section 4 discusses the application of the rules for the RTE data, describing the structure representation we use to identify the appropriate context for the rule application. The experimental results will be presented in Section 5, followed by an error analysis and discussions in Section 6. Finally Section 7 will conclude the paper and point out future work directions. 2 Background A number of automatically acquired inference rule/paraphrase collections are available, such as (Szpektor et al., 2004), (Sekine, 2005). In our work we use the DIRT collection because it is the largest one available and it has a relatively good accuracy (in the 50% range for top generated paraphrases, (Szpektor et al., 2007)). In this section, we describe the DIRT algorithm for acquiring inference rules. Following that, we will overview the RTE systems which take DIRT as an external knowledge resource. 2.1 Discovery of Inference Rules from Text The DIRT algorithm has been introduced by (Lin and Pantel, 2001) and it is based on what is called the Extended Distributional Hypothesis. The original DH states that words occurring i</context>
</contexts>
<marker>Sekine, 2005</marker>
<rawString>Satoshi Sekine. 2005. Automatic paraphrase discovery based on context and keywords between NE pairs. In Proceedings of International Workshop on Paraphrase, pages 80–87, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In In Proceedings of EMNLP,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="4707" citStr="Szpektor et al., 2004" startWordPosition="765" endWordPosition="768"> the rule collection itself and on the methods in which we use an external lexical resource to extend and refine it. Section 4 discusses the application of the rules for the RTE data, describing the structure representation we use to identify the appropriate context for the rule application. The experimental results will be presented in Section 5, followed by an error analysis and discussions in Section 6. Finally Section 7 will conclude the paper and point out future work directions. 2 Background A number of automatically acquired inference rule/paraphrase collections are available, such as (Szpektor et al., 2004), (Sekine, 2005). In our work we use the DIRT collection because it is the largest one available and it has a relatively good accuracy (in the 50% range for top generated paraphrases, (Szpektor et al., 2007)). In this section, we describe the DIRT algorithm for acquiring inference rules. Following that, we will overview the RTE systems which take DIRT as an external knowledge resource. 2.1 Discovery of Inference Rules from Text The DIRT algorithm has been introduced by (Lin and Pantel, 2001) and it is based on what is called the Extended Distributional Hypothesis. The original DH states that w</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In In Proceedings of EMNLP, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Eyal Shnarch</author>
<author>Ido Dagan</author>
</authors>
<title>Instance-based evaluation of entailment rule acquisition.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>456--463</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="4914" citStr="Szpektor et al., 2007" startWordPosition="802" endWordPosition="805">e representation we use to identify the appropriate context for the rule application. The experimental results will be presented in Section 5, followed by an error analysis and discussions in Section 6. Finally Section 7 will conclude the paper and point out future work directions. 2 Background A number of automatically acquired inference rule/paraphrase collections are available, such as (Szpektor et al., 2004), (Sekine, 2005). In our work we use the DIRT collection because it is the largest one available and it has a relatively good accuracy (in the 50% range for top generated paraphrases, (Szpektor et al., 2007)). In this section, we describe the DIRT algorithm for acquiring inference rules. Following that, we will overview the RTE systems which take DIRT as an external knowledge resource. 2.1 Discovery of Inference Rules from Text The DIRT algorithm has been introduced by (Lin and Pantel, 2001) and it is based on what is called the Extended Distributional Hypothesis. The original DH states that words occurring in similar contexts have similar meaning, whereas the extended version hypothesizes that phrases occurring in similar contexts are similar. An inference rule in DIRT is a pair of binary relati</context>
<context position="6366" citStr="Szpektor et al., 2007" startWordPosition="1063" endWordPosition="1067">te a candidate paraphrase if the sets of X and Y values exhibit relevant overlap. In the following example, the two patterns are prevent and provide protection against. X subj ���� prevent obj ��� Y X subj ���� provide obj ��� protection mod ���� against pcomp ����� Y 3obtained with the Minipar parser (Lin, 1998) X put emphasis on Y � X pay attention to Y � X attach importance to Y � X increase spending on Y � X place emphasis on Y � Y priority of X � X focus on Y Table 1: Example of DIRT algorithm output. Most confident paraphrases of X put emphasis on Y Such rules can be informally defined (Szpektor et al., 2007) as directional relations between two text patterns with variables. The left-handside pattern is assumed to entail the right-handside pattern in certain contexts, under the same variable instantiation. The definition relaxes the intuition of inference, as we only require the entailment to hold in some and not all contexts, motivated by the fact that such inferences occur often in natural text. The algorithm does not extract directional inference rules, it can only identify candidate paraphrases; many of the rules are however unidirectional. Besides syntactic rewriting or lexical rules, rules i</context>
<context position="14617" citStr="Szpektor et al., 2007" startWordPosition="2529" endWordPosition="2532">RT. DH algorithms have the main disadvantage that not only phrases with the same meaning are extracted but also phrases with opposite meaning. In order to overcome this problem and since such errors are relatively easy to detect, we applied a filter to the DIRT rules. This eliminates inference rules which contain WordNet antonyms. For such a rule to be eliminated the two patterns have to be identical (with respect to edge labels and content words) except from the antonymous words; an example of a rule eliminated this way is X have confidence in Y Pz� X lack confidence in Y. As pointed out by (Szpektor et al., 2007) a thorough evaluation of a rule collection is not a trivial task; however due to our methodology we can assume that the percentage of rules eliminated this way that are indeed contradictions gets close to 100%. 4 Applying DIRT on RTE In this section we point out two issues that are encountered when applying inference rules for textual entailment. The first issue is concerned with correctly identifying the pairs in which the knowledge encoded in these rules is needed. Following this, another non-trivial task is to determine the way this knowledge interacts with the rest of information conveyed</context>
</contexts>
<marker>Szpektor, Shnarch, Dagan, 2007</marker>
<rawString>Idan Szpektor, Eyal Shnarch, and Ido Dagan. 2007. Instance-based evaluation of entailment rule acquisition. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 456–463, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Roy Bar-Haim</author>
<author>Jacob Goldberger</author>
</authors>
<title>Contextual preferences.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>683--691</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="7437" citStr="Szpektor et al., 2008" startWordPosition="1239" endWordPosition="1242"> rules, it can only identify candidate paraphrases; many of the rules are however unidirectional. Besides syntactic rewriting or lexical rules, rules in which the patterns are rather complex phrases are also extracted. Some of the rules encode lexical relations which can also be found in resources such as WordNet while others are lexical-syntactic variations that are unlikely to occur in hand-crafted resources (Lin and Pantel, 2001). Table 1 gives a few examples of rules present in DIRT4. Current work on inference rules focuses on making such resources more precise. (Basili et al., 2007) and (Szpektor et al., 2008) propose attaching selectional preferences to inference rules. These are semantic classes which correspond to the anchor values of an inference rule and have the role of making precise the context in which the rule can be applied 5. This aspect is very important and we plan to address it in our future work. However in this paper we investigate the first and more basic issue: how to successfully use rules in their current form. 4For simplification, in the rest of the paper we will omit giving the dependency relations in a pattern. 5For example X won Y entails X played Y only when Y refers to so</context>
</contexts>
<marker>Szpektor, Dagan, Bar-Haim, Goldberger, 2008</marker>
<rawString>Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Goldberger. 2008. Contextual preferences. In Proceedings of ACL-08: HLT, pages 683–691, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Wang</author>
<author>G¨unter Neumann</author>
</authors>
<title>Recognizing textual entailment using sentence similarity based on dependency tree skeletons.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>36--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<contexts>
<context position="19772" citStr="Wang and Neumann, 2007" startWordPosition="3434" endWordPosition="3437">t is not the correct one. To sum up, making use of the knowledge encoded with such rules is not a trivial task. If rules are used strictly in concordance with their definition, their utility is limited to a very small number of entailment pairs. For this reason, 1) instead of forcing the anchor values to be identical as most previous work, we allow more flexible rule matching (similar to (Marsi et al., 2007)) and 2) furthermore, we control the rule application process using a text representation based on dependency structure. 4.2 Tree Skeleton The Tree Skeleton (TS) structure was proposed by (Wang and Neumann, 2007), and can be viewed as an extended version of the predicate-argument structure. Since it contains not only the predicate and its arguments, but also the dependency paths in-between, it captures the essential part of the sentence. Following their algorithm, we first preprocess the data using a dependency parser8 and then select overlapping topic words (i.e. nouns) in T and H. By doing so, we use fuzzy match at the substring level instead of full match. Starting with these nouns, we traverse the dependency tree to identify the lowest common ancestor node (named as root node). This sub-tree witho</context>
<context position="21494" citStr="Wang and Neumann, 2007" startWordPosition="3732" endWordPosition="3735"> Minipar for the reason of consistence 215 Figure 1: Dependency structure of text. Tree skeleton in bold paths contained in a TS should also be two. In practice, among all the 800 T-H pairs of the RTE2 test set, we successfully extracted tree skeletons in 296 text pairs, i.e., 37% of the test data is covered by this step and results on other data sets are similar. Applying DIRT on a TS Dependency representations like the tree skeleton have been explored by many researchers, e.g. (Zanzotto and Moschitti, 2006) have utilized a tree kernel method to calculate the similarity between T and H, and (Wang and Neumann, 2007) chose subsequence kernel to reduce the computational complexity. However, the focus of this paper is to evaluate the application of inference rules on RTE, instead of exploring methods of tackling the task itself. Therefore, we performed a straightforward matching algorithm to apply the inference rules on top of the tree skeleton structure. Given tree skeletons of T and H, we check if the two left dependency paths, the two right ones or the two root nodes contain the patterns of a rule. In the example above, the rule X obj ←−− su bj obj2 o receive −−−→ Y ≈ X ← award −−−→bj1 Y satisfies this c</context>
</contexts>
<marker>Wang, Neumann, 2007</marker>
<rawString>Rui Wang and G¨unter Neumann. 2007. Recognizing textual entailment using sentence similarity based on dependency tree skeletons. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 36–41, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Automatic learning of textual entailments with cross-pair similarities.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>401--408</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="21385" citStr="Zanzotto and Moschitti, 2006" startWordPosition="3713" endWordPosition="3716"> the number of the dependency 7See (Nairn et al., 2006) for a detailed analysis of these aspects. 8Here we also use Minipar for the reason of consistence 215 Figure 1: Dependency structure of text. Tree skeleton in bold paths contained in a TS should also be two. In practice, among all the 800 T-H pairs of the RTE2 test set, we successfully extracted tree skeletons in 296 text pairs, i.e., 37% of the test data is covered by this step and results on other data sets are similar. Applying DIRT on a TS Dependency representations like the tree skeleton have been explored by many researchers, e.g. (Zanzotto and Moschitti, 2006) have utilized a tree kernel method to calculate the similarity between T and H, and (Wang and Neumann, 2007) chose subsequence kernel to reduce the computational complexity. However, the focus of this paper is to evaluate the application of inference rules on RTE, instead of exploring methods of tackling the task itself. Therefore, we performed a straightforward matching algorithm to apply the inference rules on top of the tree skeleton structure. Given tree skeletons of T and H, we check if the two left dependency paths, the two right ones or the two root nodes contain the patterns of a rule</context>
</contexts>
<marker>Zanzotto, Moschitti, 2006</marker>
<rawString>Fabio Massimo Zanzotto and Alessandro Moschitti. 2006. Automatic learning of textual entailments with cross-pair similarities. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 401–408, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>