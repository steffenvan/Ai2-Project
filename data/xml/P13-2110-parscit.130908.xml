<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.264046">
<title confidence="0.9994835">
A Lattice-based Framework for Joint Chinese Word Segmentation,
POS Tagging and Parsing
</title>
<author confidence="0.998799">
Zhiguo Wang1, Chengqing Zong1 and Nianwen Xue2
</author>
<affiliation confidence="0.978695">
1National Laboratory of Pattern Recognition,
Institute of Automation, Chinese Academy of Sciences, Beijing, China, 100190
2Computer Science Department, Brandeis University, Waltham, MA 02452
</affiliation>
<email confidence="0.997661">
{zgwang, cqzong}@nlpr.ia.ac.cn xuen@brandeis.edu
</email>
<sectionHeader confidence="0.993886" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999650388888889">
For the cascaded task of Chinese word seg-
mentation, POS tagging and parsing, the pipe-
line approach suffers from error propagation
while the joint learning approach suffers from
inefficient decoding due to the large combined
search space. In this paper, we present a novel
lattice-based framework in which a Chinese
sentence is first segmented into a word lattice,
and then a lattice-based POS tagger and a lat-
tice-based parser are used to process the lattice
from two different viewpoints: sequential POS
tagging and hierarchical tree building. A strat-
egy is designed to exploit the complementary
strengths of the tagger and parser, and encour-
age them to predict agreed structures. Experi-
mental results on Chinese Treebank show that
our lattice-based framework significantly im-
proves the accuracy of the three sub-tasks.
</bodyText>
<sectionHeader confidence="0.99898" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999913461538462">
Previous work on syntactic parsing generally
assumes a processing pipeline where an input
sentence is first tokenized, POS-tagged and then
parsed (Collins, 1999; Charniak, 2000; Petrov
and Klein, 2007). This approach works well for
languages like English where automatic tokeni-
zation and POS tagging can be performed with
high accuracy without the guidance of the high-
level syntactic structure. Such an approach, how-
ever, is not optimal for languages like Chinese
where there are no natural delimiters for word
boundaries, and word segmentation (or tokeniza-
tion) is a non-trivial research problem by itself.
Errors in word segmentation would propagate to
later processing stages such as POS tagging and
syntactic parsing. More importantly, Chinese is a
language that lacks the morphological clues that
help determine the POS tag of a word. For ex-
ample, 调 查 (“investigate/investigation”) can
either be a verb (“investigate”) or a noun (“inves-
tigation”), and there is no morphological varia-
tion between its verbal form and nominal form.
This contributes to the relatively low accuracy
(95% or below) in Chinese POS tagging when
evaluated as a stand-alone task (Sun and Uszko-
reit, 2012), and the noun/verb ambiguity is a ma-
jor source of error.
More recently, joint inference approaches
have been proposed to address the shortcomings
of the pipeline approach. Qian and Liu (2012)
proposed a joint inference approach where syn-
tactic parsing can provide feedback to word
segmentation and POS tagging and showed that
the joint inference approach leads to improve-
ments in all three sub-tasks. However, a major
challenge for joint inference approach is that the
large combined search space makes efficient de-
coding and parameter estimation very hard.
In this paper, we present a novel lattice-based
framework for Chinese. An input Chinese sen-
tence is first segmented into a word lattice,
which is a compact representation of a small set
of high-quality word segmentations. Then, a lat-
tice-based POS tagger and a lattice-based parser
are used to process the word lattice from two
different viewpoints. We next employ the dual
decomposition method to exploit the comple-
mentary strengths of the tagger and parser, and
encourage them to predict agreed structures. Ex-
perimental results show that our lattice-based
framework significantly improves the accuracies
of the three sub-tasks
</bodyText>
<sectionHeader confidence="0.828142" genericHeader="method">
2 The Lattice-based Framework
</sectionHeader>
<bodyText confidence="0.999442909090909">
Figure 1 gives the organization of the framework.
There are four types of linguistic structures: a
Chinese sentence, the word lattice, tagged word
sequence and parse tree of the Chinese sentence.
An example for each structure is provided in
Figure 2. We can see that the terminals and pre-
terminals of a parse tree constitute a tagged word
sequence. Therefore, we define a comparator
between a tagged word sequence and a parse tree:
if they contain the same word sequence and POS
tags, they are equal, otherwise unequal.
</bodyText>
<page confidence="0.973033">
623
</page>
<bodyText confidence="0.9822114375">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 623–627,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
Figure 1 also shows the workflow of the
framework. First, the Chinese sentence is seg-
mented into a word lattice using the word seg-
mentation system. Then the word lattice is fed
into the lattice-based POS tagger to produce a
tagged word sequence and into the lattice-
based parser to separately produce a parse tree .
We then compare with to see whether they
are equal. If they are equal, we output as the
final result. Otherwise, the guidance generator
generates some guidance orders based on the
difference between and , and guides the tag-
ger and the parser to process the lattice again.
This procedure may iterate many times until the
tagger and parser predict equal structures.
al., 2008). Therefore, a word lattice provides us a
good enough search space to allow sufficient
interaction among word segmentation, POS tag-
ging and parsing systems. Second, both the lat-
tice-based POS tagger and the lattice-based pars-
er can select word segmentation from the word
lattice and predict POS tags, but they do so from
two different perspectives. The lattice-based POS
tagger looks at a path in a word lattice as a se-
quence and performs sequence labeling based on
linear local context, while the lattice-based pars-
er builds the parse trees in a hierarchical manner.
They have different strengths with regard to
word segmentation and POS tagging. We hypo-
thesize that exploring the complementary
strengths of the tagger and parser would improve
each of the sub-tasks.
We build a character-based model (Xue, 2003)
for the word segmentation system, and treat
segmentation as a sequence labeling task, where
each Chinese character is labeled with a tag. We
use the tag set provided in Wang et al. (2011)
and use the same feature templates. We use the
Maximum Entropy (ME) model to estimate the
feature weights. To get a word lattice, we first
generate N-best word segmentation results, and
then compact the N-best lists into a word lattice
by collapsing all the identical words into one
edge. We also assign a probability to each edge,
which is calculated by multiplying the tagging
probabilities of each character in the word.
The goal of the lattice-based POS tagger is to
predict a tagged word sequence for an input
word lattice :
The motivation to design such a framework is
as follows. First, state-of-the-art word segmenta-
tion systems can now perform with high accura-
cy. We can easily get an F1 score greater than
96%, and an oracle (upper bound) F1 score
greater than 99% for the word lattice (Jiang et
is refined into
(Petrov and Klein, 2007). The traditional evalua-
tion metrics for POS tagging and parsing are not
suitable for the joint task. Following with Qian
and Liu (2012), we redefine precision and recall
by computing the span of a constituent based on
character offsets rather than word offsets.
</bodyText>
<subsectionHeader confidence="0.996589">
4.1 Performance of the Basic Sub-systems
</subsectionHeader>
<bodyText confidence="0.999985756756757">
We train the word segmentation system with 100
iterations of the Maximum Entropy model using
the OpenNLP toolkit. Table 1 shows the perfor-
mance. It shows that our word segmentation sys-
tem is comparable with the state-of-the-art sys-
tems and the upper bound F1 score of the word
lattice exceeds 99.6%. This indicates that our
word segmentation system can provide a good
search space for the lattice-based POS tagger and
the lattice-based parser.
To train the lattice-based POS tagger, we gen-
erate the word lattice for each sentence in the
training set using cross validation approach. We
divide the entire training set into 18 folds on av-
erage (each fold contains 1,000 sentences). For
each fold, we segment each sentence in the fold
into a word lattice by compacting 20-best seg-
mentation list produced with a model trained on
the other 17 folds. Then, we train the lattice-
based POS tagger with 20 iterations of the aver-
age perceptron algorithm. Table 2 presents the
joint word segmentation and POS tagging per-
formance and shows that our lattice-based POS
tagger obtains results that are comparable with
state-of-the-art systems.
We implement the lattice-based parser by
modifying the Berkeley Parser, and train it with
5 iterations of the split-merge-smooth strategy
(Petrov et al., 2006). Table 3 shows the perfor-
mance, where the “Pipeline Parser” represents
the system taking one-best segmentation result
from our word segmentation system as input and
“Lattice-based Parser” represents the system tak-
ing the compacted word lattice as input. We find
the lattice-based parser gets better performance
than the pipeline system among all three sub-
tasks.
</bodyText>
<subsectionHeader confidence="0.994989">
4.2 Performance of the Framework
</subsectionHeader>
<bodyText confidence="0.998755642857143">
For the lattice-based framework, we set the max-
imum iteration in Algorithm 1 as K = 20. The
step size S is tuned on the development set and
empirically set to be 0.8. Table 4 shows the pars-
ing performance on the test set. It shows that the
lattice-based framework achieves improvement
over the lattice-based parser alone among all
three sub-tasks: 0.16 points for word segmenta-
tion, 1.19 points for POS tagging and 1.65 points
for parsing. It also outperforms the lattice-based
POS tagger by 0.65 points on POS tagging accu-
racy. Our lattice-based framework also improves
over the best joint inference parsing system
(Qian and Liu, 2012) by 0.57 points.
</bodyText>
<table confidence="0.999777285714286">
P R F
(Qian and Liu, Seg. 97.56 98.36 97.96
2012) POS 93.43 94.2 93.81
Parse 83.03 82.66 82.85
Seg. 97.82 97.9 97.86
Lattice-based POS 94.36 94.44 94.40
Framework Parse 83.34 83.5 83.42
</table>
<tableCaption confidence="0.998681">
Table 4: Lattice-based framework evaluation.
</tableCaption>
<sectionHeader confidence="0.975489" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999902642857143">
In this paper, we present a novel lattice-based
framework for the cascaded task of Chinese
word segmentation, POS tagging and parsing.
We first segment a Chinese sentence into a word
lattice, then process the lattice using a lattice-
based POS tagger and a lattice-based parser. We
also design a strategy to exploit the complemen-
tary strengths of the tagger and the parser and
encourage them to predict agreed structures. Ex-
perimental results show that the lattice-based
framework significantly improves the accuracies
of the three tasks. The parsing accuracy of the
framework also outperforms the best joint pars-
ing system reported in the literature.
</bodyText>
<sectionHeader confidence="0.977647" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997420818181818">
The research work has been funded by the Hi-
Tech Research and Development Program (&amp;quot;863&amp;quot;
Program) of China under Grant No.
2011AA01A207, 2012AA011101, and
2012AA011102 and also supported by the Key
Project of Knowledge Innovation Program of
Chinese Academy of Sciences under Grant
No.KGZD-EW-501. This work is also supported
in part by the DAPRA via contract HR0011-11-
C-0145 entitled &amp;quot;Linguistic Resources for Multi-
lingual Processing&amp;quot;.
</bodyText>
<sectionHeader confidence="0.998496" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997701090909091">
S. Boyd, L. Xiao and A. Mutapcic. 2003. Subgradient
methods. Lecture notes of EE392o, Stanford Uni-
versity.
E. Charniak. 2000. A maximum–entropy–inspired
parser. In NAACL ’00, page 132–139.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Michael Collins. 2002. Discriminative training me-
thods for hidden markov models: Theory and expe-
riments with perceptron algorithms. In Proc. of
EMNLP2002, pages 1-8.
Yoav Goldberg and Michael Elhadad. 2011. Joint
Hebrew segmentation and parsing using a PCFG-
LA lattice parser. In Proc. of ACL2011.
Wenbin Jiang, Haitao Mi and Qun Liu. 2008. Word
lattice reranking for Chinese word segmentation
and part-of-speech tagging. In Proc. of Coling 2008,
pages 385-392.
Komodakis, N., Paragios, N., and Tziritas, G. 2007.
MRF optimization via dual decomposition: Mes-
sage-passing revisited. In ICCV 2007.
C. Kruengkrai, K. Uchimoto, J. Kazama, Y. Wang, K.
Torisawa and H. Isahara. 2009. An error-driven
word-character hybrid model for joint Chinese
word segmentation and POS tagging. In Proc. of
ACL2009, pages 513-521.
Takuya Matsuzaki, Yusuke Miyao and Jun&apos;ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
Proc. of ACL2005, pages 75-82.
Slav Petrov, Leon Barrett, Romain Thibaux and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proc. of ACL2006,
pages 433-440.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proc. of NAACL2007,
pages 404-411.
Xian Qian and Yang Liu. 2012. Joint Chinese Word
segmentation, POS Tagging Parsing. In Proc. of
EMNLP 2012, pages 501-511.
Alexander M. Rush, David Sontag, Michael Collins
and Tommi Jaakkola. 2010. On dual decomposi-
tion and linear programming relaxations for natural
language processing. In Proc. of EMNLP2010,
pages 1-11.
Weiwei Sun. 2011. A stacked sub-word model for
joint Chinese word segmentation and part-of-
speech tagging. In Proc. of ACL2011, pages 1385-
1394.
Weiwei Sun and Hans Uszkoreit. Capturing paradig-
matic and syntagmatic lexical relations: Towards
accurate Chinese part-of-speech tagging. In Proc.
of ACL2012.
Yiou Wang, Jun&apos;ichi Kazama, Yoshimasa Tsuruoka,
Wenliang Chen, Yujie Zhang and Kentaro Torisa-
wa. 2011. Improving Chinese word segmentation
and POS tagging with semi-supervised methods us-
ing large auto-analyzed data. In Proc. of
IJCNLP2011, pages 309-317.
Nianwen Xue. 2003. Chinese word segmentation as
character tagging. Computational Linguistics and
Chinese Language Processing, 8 (1). pages 29-48.
Yue Zhang and Stephen Clark. 2010. A fast decoder
for joint word segmentation and POS-tagging using
a single discriminative model. In Proc. of
EMNLP2010, pages 843-852.
</reference>
<page confidence="0.997847">
627
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.414661">
<title confidence="0.816486333333333">A Lattice-based Framework for Joint Chinese Word POS Tagging and Parsing Chengqing and</title>
<affiliation confidence="0.9706195">Laboratory of Pattern Institute of Automation, Chinese Academy of Sciences, Beijing, China,</affiliation>
<address confidence="0.996857">Science Department, Brandeis University, Waltham, MA 02452</address>
<email confidence="0.996612">zgwang@nlpr.ia.ac.cnxuen@brandeis.edu</email>
<email confidence="0.996612">cqzong@nlpr.ia.ac.cnxuen@brandeis.edu</email>
<abstract confidence="0.999688263157895">For the cascaded task of Chinese word segmentation, POS tagging and parsing, the pipeline approach suffers from error propagation while the joint learning approach suffers from inefficient decoding due to the large combined search space. In this paper, we present a novel lattice-based framework in which a Chinese sentence is first segmented into a word lattice, and then a lattice-based POS tagger and a lattice-based parser are used to process the lattice from two different viewpoints: sequential POS tagging and hierarchical tree building. A strategy is designed to exploit the complementary strengths of the tagger and parser, and encourage them to predict agreed structures. Experimental results on Chinese Treebank show that our lattice-based framework significantly improves the accuracy of the three sub-tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Boyd</author>
<author>L Xiao</author>
<author>A Mutapcic</author>
</authors>
<title>Subgradient methods. Lecture notes of EE392o,</title>
<date>2003</date>
<institution>Stanford University.</institution>
<marker>Boyd, Xiao, Mutapcic, 2003</marker>
<rawString>S. Boyd, L. Xiao and A. Mutapcic. 2003. Subgradient methods. Lecture notes of EE392o, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum–entropy–inspired parser.</title>
<date>2000</date>
<booktitle>In NAACL ’00,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="1395" citStr="Charniak, 2000" startWordPosition="200" endWordPosition="201">r and a lattice-based parser are used to process the lattice from two different viewpoints: sequential POS tagging and hierarchical tree building. A strategy is designed to exploit the complementary strengths of the tagger and parser, and encourage them to predict agreed structures. Experimental results on Chinese Treebank show that our lattice-based framework significantly improves the accuracy of the three sub-tasks. 1 Introduction Previous work on syntactic parsing generally assumes a processing pipeline where an input sentence is first tokenized, POS-tagged and then parsed (Collins, 1999; Charniak, 2000; Petrov and Klein, 2007). This approach works well for languages like English where automatic tokenization and POS tagging can be performed with high accuracy without the guidance of the highlevel syntactic structure. Such an approach, however, is not optimal for languages like Chinese where there are no natural delimiters for word boundaries, and word segmentation (or tokenization) is a non-trivial research problem by itself. Errors in word segmentation would propagate to later processing stages such as POS tagging and syntactic parsing. More importantly, Chinese is a language that lacks the</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A maximum–entropy–inspired parser. In NAACL ’00, page 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1379" citStr="Collins, 1999" startWordPosition="198" endWordPosition="199">based POS tagger and a lattice-based parser are used to process the lattice from two different viewpoints: sequential POS tagging and hierarchical tree building. A strategy is designed to exploit the complementary strengths of the tagger and parser, and encourage them to predict agreed structures. Experimental results on Chinese Treebank show that our lattice-based framework significantly improves the accuracy of the three sub-tasks. 1 Introduction Previous work on syntactic parsing generally assumes a processing pipeline where an input sentence is first tokenized, POS-tagged and then parsed (Collins, 1999; Charniak, 2000; Petrov and Klein, 2007). This approach works well for languages like English where automatic tokenization and POS tagging can be performed with high accuracy without the guidance of the highlevel syntactic structure. Such an approach, however, is not optimal for languages like Chinese where there are no natural delimiters for word boundaries, and word segmentation (or tokenization) is a non-trivial research problem by itself. Errors in word segmentation would propagate to later processing stages such as POS tagging and syntactic parsing. More importantly, Chinese is a languag</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP2002,</booktitle>
<pages>1--8</pages>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. of EMNLP2002, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Joint Hebrew segmentation and parsing using a PCFGLA lattice parser.</title>
<date>2011</date>
<booktitle>In Proc. of ACL2011.</booktitle>
<marker>Goldberg, Elhadad, 2011</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2011. Joint Hebrew segmentation and parsing using a PCFGLA lattice parser. In Proc. of ACL2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Haitao Mi</author>
<author>Qun Liu</author>
</authors>
<title>Word lattice reranking for Chinese word segmentation and part-of-speech tagging.</title>
<date>2008</date>
<booktitle>In Proc. of Coling</booktitle>
<pages>385--392</pages>
<marker>Jiang, Mi, Liu, 2008</marker>
<rawString>Wenbin Jiang, Haitao Mi and Qun Liu. 2008. Word lattice reranking for Chinese word segmentation and part-of-speech tagging. In Proc. of Coling 2008, pages 385-392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Komodakis</author>
<author>N Paragios</author>
<author>G Tziritas</author>
</authors>
<title>MRF optimization via dual decomposition: Message-passing revisited.</title>
<date>2007</date>
<booktitle>In ICCV</booktitle>
<marker>Komodakis, Paragios, Tziritas, 2007</marker>
<rawString>Komodakis, N., Paragios, N., and Tziritas, G. 2007. MRF optimization via dual decomposition: Message-passing revisited. In ICCV 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kruengkrai</author>
<author>K Uchimoto</author>
<author>J Kazama</author>
<author>Y Wang</author>
<author>K Torisawa</author>
<author>H Isahara</author>
</authors>
<title>An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging.</title>
<date>2009</date>
<booktitle>In Proc. of ACL2009,</booktitle>
<pages>513--521</pages>
<marker>Kruengkrai, Uchimoto, Kazama, Wang, Torisawa, Isahara, 2009</marker>
<rawString>C. Kruengkrai, K. Uchimoto, J. Kazama, Y. Wang, K. Torisawa and H. Isahara. 2009. An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. In Proc. of ACL2009, pages 513-521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Probabilistic CFG with latent annotations.</title>
<date>2005</date>
<booktitle>In Proc. of ACL2005,</booktitle>
<pages>75--82</pages>
<marker>Matsuzaki, Miyao, Tsujii, 2005</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao and Jun&apos;ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In Proc. of ACL2005, pages 75-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL2006,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="8458" citStr="Petrov et al., 2006" startWordPosition="1354" endWordPosition="1357"> sentences). For each fold, we segment each sentence in the fold into a word lattice by compacting 20-best segmentation list produced with a model trained on the other 17 folds. Then, we train the latticebased POS tagger with 20 iterations of the average perceptron algorithm. Table 2 presents the joint word segmentation and POS tagging performance and shows that our lattice-based POS tagger obtains results that are comparable with state-of-the-art systems. We implement the lattice-based parser by modifying the Berkeley Parser, and train it with 5 iterations of the split-merge-smooth strategy (Petrov et al., 2006). Table 3 shows the performance, where the “Pipeline Parser” represents the system taking one-best segmentation result from our word segmentation system as input and “Lattice-based Parser” represents the system taking the compacted word lattice as input. We find the lattice-based parser gets better performance than the pipeline system among all three subtasks. 4.2 Performance of the Framework For the lattice-based framework, we set the maximum iteration in Algorithm 1 as K = 20. The step size S is tuned on the development set and empirically set to be 0.8. Table 4 shows the parsing performance</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proc. of ACL2006, pages 433-440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proc. of NAACL2007,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="1420" citStr="Petrov and Klein, 2007" startWordPosition="202" endWordPosition="205">based parser are used to process the lattice from two different viewpoints: sequential POS tagging and hierarchical tree building. A strategy is designed to exploit the complementary strengths of the tagger and parser, and encourage them to predict agreed structures. Experimental results on Chinese Treebank show that our lattice-based framework significantly improves the accuracy of the three sub-tasks. 1 Introduction Previous work on syntactic parsing generally assumes a processing pipeline where an input sentence is first tokenized, POS-tagged and then parsed (Collins, 1999; Charniak, 2000; Petrov and Klein, 2007). This approach works well for languages like English where automatic tokenization and POS tagging can be performed with high accuracy without the guidance of the highlevel syntactic structure. Such an approach, however, is not optimal for languages like Chinese where there are no natural delimiters for word boundaries, and word segmentation (or tokenization) is a non-trivial research problem by itself. Errors in word segmentation would propagate to later processing stages such as POS tagging and syntactic parsing. More importantly, Chinese is a language that lacks the morphological clues that</context>
<context position="6867" citStr="Petrov and Klein, 2007" startWordPosition="1094" endWordPosition="1097">word lattice by collapsing all the identical words into one edge. We also assign a probability to each edge, which is calculated by multiplying the tagging probabilities of each character in the word. The goal of the lattice-based POS tagger is to predict a tagged word sequence for an input word lattice : The motivation to design such a framework is as follows. First, state-of-the-art word segmentation systems can now perform with high accuracy. We can easily get an F1 score greater than 96%, and an oracle (upper bound) F1 score greater than 99% for the word lattice (Jiang et is refined into (Petrov and Klein, 2007). The traditional evaluation metrics for POS tagging and parsing are not suitable for the joint task. Following with Qian and Liu (2012), we redefine precision and recall by computing the span of a constituent based on character offsets rather than word offsets. 4.1 Performance of the Basic Sub-systems We train the word segmentation system with 100 iterations of the Maximum Entropy model using the OpenNLP toolkit. Table 1 shows the performance. It shows that our word segmentation system is comparable with the state-of-the-art systems and the upper bound F1 score of the word lattice exceeds 99.</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proc. of NAACL2007, pages 404-411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xian Qian</author>
<author>Yang Liu</author>
</authors>
<title>Joint Chinese Word segmentation, POS Tagging Parsing.</title>
<date>2012</date>
<booktitle>In Proc. of EMNLP 2012,</booktitle>
<pages>501--511</pages>
<contexts>
<context position="2594" citStr="Qian and Liu (2012)" startWordPosition="390" endWordPosition="393">guage that lacks the morphological clues that help determine the POS tag of a word. For example, 调 查 (“investigate/investigation”) can either be a verb (“investigate”) or a noun (“investigation”), and there is no morphological variation between its verbal form and nominal form. This contributes to the relatively low accuracy (95% or below) in Chinese POS tagging when evaluated as a stand-alone task (Sun and Uszkoreit, 2012), and the noun/verb ambiguity is a major source of error. More recently, joint inference approaches have been proposed to address the shortcomings of the pipeline approach. Qian and Liu (2012) proposed a joint inference approach where syntactic parsing can provide feedback to word segmentation and POS tagging and showed that the joint inference approach leads to improvements in all three sub-tasks. However, a major challenge for joint inference approach is that the large combined search space makes efficient decoding and parameter estimation very hard. In this paper, we present a novel lattice-based framework for Chinese. An input Chinese sentence is first segmented into a word lattice, which is a compact representation of a small set of high-quality word segmentations. Then, a lat</context>
<context position="7003" citStr="Qian and Liu (2012)" startWordPosition="1117" endWordPosition="1120">ing the tagging probabilities of each character in the word. The goal of the lattice-based POS tagger is to predict a tagged word sequence for an input word lattice : The motivation to design such a framework is as follows. First, state-of-the-art word segmentation systems can now perform with high accuracy. We can easily get an F1 score greater than 96%, and an oracle (upper bound) F1 score greater than 99% for the word lattice (Jiang et is refined into (Petrov and Klein, 2007). The traditional evaluation metrics for POS tagging and parsing are not suitable for the joint task. Following with Qian and Liu (2012), we redefine precision and recall by computing the span of a constituent based on character offsets rather than word offsets. 4.1 Performance of the Basic Sub-systems We train the word segmentation system with 100 iterations of the Maximum Entropy model using the OpenNLP toolkit. Table 1 shows the performance. It shows that our word segmentation system is comparable with the state-of-the-art systems and the upper bound F1 score of the word lattice exceeds 99.6%. This indicates that our word segmentation system can provide a good search space for the lattice-based POS tagger and the lattice-ba</context>
<context position="9490" citStr="Qian and Liu, 2012" startWordPosition="1522" endWordPosition="1525">ased framework, we set the maximum iteration in Algorithm 1 as K = 20. The step size S is tuned on the development set and empirically set to be 0.8. Table 4 shows the parsing performance on the test set. It shows that the lattice-based framework achieves improvement over the lattice-based parser alone among all three sub-tasks: 0.16 points for word segmentation, 1.19 points for POS tagging and 1.65 points for parsing. It also outperforms the lattice-based POS tagger by 0.65 points on POS tagging accuracy. Our lattice-based framework also improves over the best joint inference parsing system (Qian and Liu, 2012) by 0.57 points. P R F (Qian and Liu, Seg. 97.56 98.36 97.96 2012) POS 93.43 94.2 93.81 Parse 83.03 82.66 82.85 Seg. 97.82 97.9 97.86 Lattice-based POS 94.36 94.44 94.40 Framework Parse 83.34 83.5 83.42 Table 4: Lattice-based framework evaluation. 5 Conclusion In this paper, we present a novel lattice-based framework for the cascaded task of Chinese word segmentation, POS tagging and parsing. We first segment a Chinese sentence into a word lattice, then process the lattice using a latticebased POS tagger and a lattice-based parser. We also design a strategy to exploit the complementary strengt</context>
</contexts>
<marker>Qian, Liu, 2012</marker>
<rawString>Xian Qian and Yang Liu. 2012. Joint Chinese Word segmentation, POS Tagging Parsing. In Proc. of EMNLP 2012, pages 501-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP2010,</booktitle>
<pages>1--11</pages>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M. Rush, David Sontag, Michael Collins and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Proc. of EMNLP2010, pages 1-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>A stacked sub-word model for joint Chinese word segmentation and part-ofspeech tagging.</title>
<date>2011</date>
<booktitle>In Proc. of ACL2011,</booktitle>
<pages>1385--1394</pages>
<marker>Sun, 2011</marker>
<rawString>Weiwei Sun. 2011. A stacked sub-word model for joint Chinese word segmentation and part-ofspeech tagging. In Proc. of ACL2011, pages 1385-1394.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Weiwei Sun</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Capturing paradigmatic and syntagmatic lexical relations: Towards accurate Chinese part-of-speech tagging.</title>
<booktitle>In Proc. of ACL2012.</booktitle>
<marker>Sun, Uszkoreit, </marker>
<rawString>Weiwei Sun and Hans Uszkoreit. Capturing paradigmatic and syntagmatic lexical relations: Towards accurate Chinese part-of-speech tagging. In Proc. of ACL2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiou Wang</author>
<author>Jun&apos;ichi Kazama</author>
</authors>
<title>Yoshimasa Tsuruoka, Wenliang Chen, Yujie Zhang and Kentaro Torisawa.</title>
<date>2011</date>
<booktitle>In Proc. of IJCNLP2011,</booktitle>
<pages>309--317</pages>
<marker>Wang, Kazama, 2011</marker>
<rawString>Yiou Wang, Jun&apos;ichi Kazama, Yoshimasa Tsuruoka, Wenliang Chen, Yujie Zhang and Kentaro Torisawa. 2011. Improving Chinese word segmentation and POS tagging with semi-supervised methods using large auto-analyzed data. In Proc. of IJCNLP2011, pages 309-317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Chinese word segmentation as character tagging.</title>
<date>2003</date>
<booktitle>Computational Linguistics and Chinese Language Processing,</booktitle>
<volume>8</volume>
<issue>1</issue>
<pages>29--48</pages>
<contexts>
<context position="5832" citStr="Xue, 2003" startWordPosition="916" endWordPosition="917"> the lattice-based parser can select word segmentation from the word lattice and predict POS tags, but they do so from two different perspectives. The lattice-based POS tagger looks at a path in a word lattice as a sequence and performs sequence labeling based on linear local context, while the lattice-based parser builds the parse trees in a hierarchical manner. They have different strengths with regard to word segmentation and POS tagging. We hypothesize that exploring the complementary strengths of the tagger and parser would improve each of the sub-tasks. We build a character-based model (Xue, 2003) for the word segmentation system, and treat segmentation as a sequence labeling task, where each Chinese character is labeled with a tag. We use the tag set provided in Wang et al. (2011) and use the same feature templates. We use the Maximum Entropy (ME) model to estimate the feature weights. To get a word lattice, we first generate N-best word segmentation results, and then compact the N-best lists into a word lattice by collapsing all the identical words into one edge. We also assign a probability to each edge, which is calculated by multiplying the tagging probabilities of each character </context>
</contexts>
<marker>Xue, 2003</marker>
<rawString>Nianwen Xue. 2003. Chinese word segmentation as character tagging. Computational Linguistics and Chinese Language Processing, 8 (1). pages 29-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A fast decoder for joint word segmentation and POS-tagging using a single discriminative model.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP2010,</booktitle>
<pages>843--852</pages>
<marker>Zhang, Clark, 2010</marker>
<rawString>Yue Zhang and Stephen Clark. 2010. A fast decoder for joint word segmentation and POS-tagging using a single discriminative model. In Proc. of EMNLP2010, pages 843-852.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>