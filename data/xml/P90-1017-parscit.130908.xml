<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.621400833333333">
SOLVING THEMATIC DIVERGENCES IN MACHINE
TRANSLATION
Bonnie Dorr*
M.I.T. Artificial Intelligence Laboratory
545 Technology Square, Room 810
Cambridge, MA 02139, USA
</note>
<email confidence="0.993696">
internet: bonnie@reagan.ai.mit.edu
</email>
<sectionHeader confidence="0.988788" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999098210526316">
Though most translation systems have some mechanism
for translating certain types of divergent predicate-argument
structures, they do not provide a general procedure that takes
advantage of the relationship between lexical-semantic struc-
ture and syntactic structure. A divergent predicate-argument
structure is one in which the predicate (e.g., the main verb)
or its arguments (e.g., the subject and object) do not have
the same syntactic ordering properties for both the source
and target language. To account for such ordering differ-
ences, a machine translator must consider language-specific
syntactic idiosyncrasies that distinguish a target language
from a source language, while making use of lexical-semantic
uniformities that tie the two languages together. This pa-
per describes the mechanisms used by the UNITRAN ma-
chine translation system for mapping an underlying lexical-
conceptual structure to a syntactic structure (and vice versa),
and it shows how these mechanisms coupled with a set of gen-
eral linking routines solve the problem of thematic divergence
in machine translation.
</bodyText>
<sectionHeader confidence="0.999382" genericHeader="keywords">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.993055727272727">
There are a number of different divergence types that
arise during the translation of a source language to a tar-
get language. Figure 1 shows some of these divergences
with respect to Spanish, English, and German.&apos;
We will look at each of these traditionally difficult di-
vergence types in turn. The first divergence type is a
structural divergence in that the verbal object is real-
ised as a noun phrase (John) in English and as a prepo-
sitional phrase (a Juan) in Spanish. The second diver-
*This paper describes research done at the Artificial In-
telligence Laboratory of the Massachusetts Institute of Tech-
nology. Support for this research has been provided by NSF
Grant DCR-85552543 under a Presidential Young Investiga-
tor&apos;s Award to Professor Robert C. Berwick. Useful guidance
and commentary during this research were provided by Bob
Berwick, Noarn Chomsky, Bruce Dawson, Ken Hale, Mike
Kashket, Jeff Siskind, and Patrick Winston. The author is
also indebted to three anonymous reviewers for their aid in
reshaping this paper into its current form.
&apos;Many sentences may fit into these divergence classes, not
just the ones listed here. Also, a single sentence may exhibit
any or all of these divergences.
</bodyText>
<figure confidence="0.992843285714286">
Divergence Translation
Type Example
Structural I saw John
3
Vi a Juan
(I saw to John)
Confiational I like Mary
kh habe Marie gemn
(1 have Mary likingly)
Lexical I stabbed John
g
Yo le di puf aladas a Juan
(I gave knife-wounds to John)
Categorial I am hungry
g
Ich habe Hunger
(I have hunger)
Thematic I like Mary
g
Maria me gusta a mf
_ (Mary pleases me)
</figure>
<figureCaption confidence="0.999924">
Figure 1: Divergence Types in Machine Translation
</figureCaption>
<bodyText confidence="0.996219705882353">
gence is conflational. Conflation is the incorporation of
necessary participants (or arguments) of a given action.
Here, English uses the single word like for the two Ger-
man words haben (have) and gem. (likingly); this is be-
cause the manner argument (i.e., the likingly portion of
the lexical token) is incorporated into the main verb in
English. The third divergence type is a lexical diver-
gence as illustrated in the stab example by the choice of
a different lexical word dar (literally give) for the word
stab. The fourth divergence type is categorial in that the
predicate is adjectival (hungry) in English but nominal
(hunger) in German. Finally, the fifth divergence type
is a thematic divergence: the object (Mary) of the En-
glish sentence is translated as the subject (Maria) in the
Spanish sentence.
The final divergence type, thematic divergence, is the
one that will be the focus of this paper. We will look at
</bodyText>
<page confidence="0.995213">
127
</page>
<bodyText confidence="0.999616666666667">
how the UNITRAN system [Derr, 1987, 1990] solves the
thematic divergence problem by mapping an underlying
lexical-conceptual structure to a syntactic structure (and
vice versa) on the basis of a set of general linking routines
and their associated mechanisms. The other divergences
are also handled by the UNITRAN system, but these are
discussed in (Darr, 1990].
It turns out there are two types of thematic diver-
gences that show up in the translation of a source lan-
guage to a target language: the first type consists of a
reordering of arguments for a given predicate; and the
second type consists of a reordering of predicates with
respect to their arguments or modifiers. We will look at
examples of each of these types in turn.
In the first case, an example is the reversal of the sub-
ject with an object as in the English-Spanish example of
gustar-like shown in figure 1. The predicate-argument
structures are shown here:2
</bodyText>
<sectionHeader confidence="0.428419" genericHeader="introduction">
[I-MAX [N-max Maria]
[v.mAx [v-i
</sectionHeader>
<keyword confidence="0.146332">
(1) 3
</keyword>
<sectionHeader confidence="0.786746" genericHeader="method">
[I-MAX [N-MAX
[V-MAX [V-I [V-MIN [N-MAX Man]]]]
</sectionHeader>
<bodyText confidence="0.9998965">
Here the subject Marra has reversed places with the ob-
ject mi. The result is that the object mi turns into the
subject I, and the subject Maria turns into the object
Mary. The reverse would be true if translation went in
the opposite direction.
An example of the second case of thematic divergence
(not shown in figure 1) is the promotion of a comple-
ment up to the main verb, and the demotion of the main
verb into an adjunct position (or vice versa). By promo-
tion, we mean placement &amp;quot;higher up&amp;quot; in the syntactic
structure, and by demotion, we mean placement &amp;quot;lower
down&amp;quot; in the syntactic structure. This situation arises
in the translation of the Spanish sentence Juan suck ir a
casa into the English sentence John usually goes home:
</bodyText>
<equation confidence="0.9414322">
[I-MAX EN-MAX Juan]
[v-MA X [v-Mm suele]
[V-MAX [v-mirr if] [P-MAX a &apos;ease]]]]]
3
[1.1dAx Jan]
</equation>
<bodyText confidence="0.946963727272727">
[v.msx [v-i [v_1 usually bi.fraN goes]]
[r.r.botx home]]]]
Here the main verb voter takes ir as a complement; but,
in English, the ir predicate has been placed into a higher
position as the main verb go, and soler is placed into a
lower position as the adjunct zonally associated with the
main verb. The reverse would be true if translation went
in the opposite direction.
&apos;Often times a native speaker of Spanish will invert the
subject to post-verbal position:
k-msx ei [V-MAX [V-MIN me gusts] [p-mAx a mi]l]
</bodyText>
<sectionHeader confidence="0.578724" genericHeader="method">
[N-MAX Maria]].
</sectionHeader>
<bodyText confidence="0.999735111111111">
However, this does not affect the internal/external reversal
scheme described here since inversion takes place indepen-
dently after thematic divergences have been handled.
Another example of the second case of thematic di-
vergence is the demotion of the main verb into a com-
plement position, and the promotion of an adjunct up
to the main verb (or vice versa). This situation arises
in the translation of the German sentence Ids esse gemn
into the English sentence I like eating:
</bodyText>
<equation confidence="0.587783">
[-MAX [N-MAX kit]
(3) [V-MAX [V-I [V-I fv-mm esse] gem]]])
ti-MAX (N.MA3,1
b.r.NtAx [v-miN like] [v-MAX eating]]]]
</equation>
<bodyText confidence="0.99997005">
Here the main verb essen takes germ as an adjunct;
but, in English, germ has been placed into a higher po-
sition as the main verb like, and the essen predicate
has been placed into a lower position as the complement
eating of the main verb. The reverse would be true if
translation went in the opposite direction.3
This paper will show how the system uses three mech-
anisms along with a set of general linking routines (to
be defined) to solve thematic divergences such as those
that have been presented. The next section introduces
the terminology and mechanisms that are used in the
solution of these divergences, and, in so doing, it will
provide a brief glimpse of how thematic divergences are
tackled. Section 3 discusses other approaches (and their
shortcomings) in light of the thematic divergence prob-
lem. Finally, section 4 presents a general solution for the
problem of thematic divergences, showing in more detail
how a set of general linking routines and their associ-
ated mechanisms provide the appropriate mapping from
source to target language.
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="method">
2 TERMINOLOGY AND
MECHANISMS
</sectionHeader>
<bodyText confidence="0.9997352">
Before we examine thematic divergences and how they
are solved, we must first look at the terminology and
mechanisms used throughout this paper:4
&apos;It might be argued that a &amp;quot;direct&amp;quot; translation is possible
for each of these three examples:
</bodyText>
<listItem confidence="0.906779">
(1i) Mary pleases me
(21) John is accustomed to going home
(31) I eat willingly
</listItem>
<bodyText confidence="0.987096875">
The problem with taking a direct approach is that it is not
general enough to handle a wide range of cases. For example,
germ can be used in conjunction with &apos;taken to mean like:
Ichhabe Marie gem (`1 like Mary&apos;). The literal translation, I
have Mary likingly, is not only stylistically unattractive, but
it is not a valid translation for this sentence. In addition, the
direct-mapping approach is not bidirectional in the general
case. Thus, even if we did take (1t), (20, and (3/) to be
the translations for (1), (2), and (3), we would not be able
to apply the same direct mapping on the English sentences
of (1), (2), and (3) (translating in the opposite direction)
because we would still need to translate like and ,ss sally into
Spanish and German. It is clear that we need some type of
uniform method for translating thematic divergences.
4The terms complement, specifier, and adjunct have not
been defined; roughly, these correspond to syntactic object,
</bodyText>
<equation confidence="0.625529">
me gusts] [P-MAX a ma]
</equation>
<page confidence="0.985209">
1.28
</page>
<construct confidence="0.94809775">
Definition 1: An LCS is a lexical conceptual
structure conforming to a modified version ofJack-
endoff&apos;s well-formedness rules [Jackendoff, 1983].
For example, I like Mary is represented as:
</construct>
<figure confidence="0.4564955">
BEIdent
([Thing REFERENT],
[Place ATIdefli
([Thing REFERENT], [Thing PERSON])],
[M .... LIKINGLYM
Definition 2: An RLCS is an uninstantiated LCS
</figure>
<bodyText confidence="0.97892725">
that is associated with a root word definition in
the lexicon (i.e., an LCS with unfilled variable po-
sitions). For example, an RLCS associated with
the word like is:
</bodyText>
<subsectionHeader confidence="0.47910275">
[Siete BEIdent
([Thing X],
ATIdent ([Thikg X], [Thing Mi.
[Manner LIKINGLYD]
</subsectionHeader>
<bodyText confidence="0.7829722">
Definition 3: A CLCS is a composed (in-
stantiated) LCS that is the result of combin-
ing two or more RLCS&apos;s by means of unification
(roughly). This is the interlingua or language-
independent form that is the pivot between the
source and target language. For example if we
compose the RLCS for like with the RLCS&apos;s for I
([Thi., REFERENT]) and Mary avdp., PERSON]),
we get the CLCS corresponding to I like Mary (as
shown in definition 1).
</bodyText>
<construct confidence="0.874504142857143">
Definition 4: An Internal Argument Position is
a syntactic complement for a lexical word of cate-
gory V, N, A, P, I, or C.&apos;
Definition 5: An External Argument Position is
a syntactic specifier of N for a lexical word of cat-
egory N or a specifier of I for a lexical word of
category V.
</construct>
<bodyText confidence="0.988816461538461">
The mapping that solves thematic divergences is de-
fined in terms of the RLCS, the CLCS, the syntactic
structure, and the markers that specify internal/external
and promotion/demotion information. These markers,
or mechanisms, are specified as follows:
Mechanism 1: The :INT and :EXT markers are
override position markers that determine where
the internal and external arguments will be po-
sitioned for a given lexical root word.
For example, the lexical entry for gustar is an
RLCS that looks like the RLCS for like (see defini-
tion 2) except that it includes the :INT and :EXT
markers:
</bodyText>
<figure confidence="0.46714625">
[slide BEIdent
([Thing X :INT],
[131AC$ ATId.,t([Thin XL [Thin Y :EXT])],
LTKINGLY])]
</figure>
<bodyText confidence="0.938089981481481">
During the mapping from the CLCS (shown in def-
inition 1) to the syntactic structure, the RLCS
for gustar (or like) is matched against the CLCS,
and the arguments are positioned according to the
specification associated with the RLCS.6 Thus,
the :INT and :EXT markers account for the syn-
tactic distinction between Spanish and English by
realizing the r
,Thing REFERENT] node of the CLCS
(corresponding to X in the RLCS) as the inter-
nal argument tra in Spanish, but as the external
argument I in English; and also by realizing the
[Thi., PERSON] node of the CLCS (corresponding
to Y in the RLCS) as the external argument Maria
in Spanish, but as the internal argument Mary in
English. Note that the :INT and :EXT mark-
ers show up only in the RLCS. The CLCS does
not include any such markers as it is intended to
be a language-independent representation for the
source-and target-language sentence.
Mechanism 2: The :PROMOTE marker associ-
ated with an RLCS lt places a restriction on the
complement Pt of the head ?it.&apos; This restriction
forces Pt to be promoted in the CLCS as the head
P. 7i is then dropped into a modifier position of
the CLCS, and the logical subject of P is inher-
ited from the CLCS associated with the syntactic
subject of &apos;It 1.8
For example, the lexical entry for soler contains
a :PROMOTE marker that is associated with the
RLCS: [au.. HABITUALLY :PROMOTE]
Thus, in the above formula ft corresponds to
soler, and Pt corresponds to the complement of
soler. The :PROMOTE marker forces the syntac-
tic complement Pt to be promoted into head
5The lexical-selection procedure that maps the CLCS to
the appropriate RLCS (for like or guitar) is not described in
detail here (see Porr, 19901). Roughly, lexical selection is a
unification-like process that matches the CLOS to the RLCS
templates in the lexicon, and chooses the associated lexical
words accordingly.
Definition 6: An Adjunct Argument Position is
a syntactic modifier that is neither internal nor
external with respect to a lexical word.
Each word entry in the lexicon is associated with an
RLCS, whose variable positions may have certain re-
strietions on them such as internal/external and pro-
motion/demotion information (to be described). The
CLCS is the structure that results from combining the
lexical items of a source-language sentence into a single
underlying pivot form.
subject, and modifier, respectively. For a more detailed de-
scription of these and some of the other definitions here, see
[Dorr, 1990].
</bodyText>
<page confidence="0.909917333333333">
5 V, N, A, P, I, and C stand for Verb, Noun, Adjective,
Preposition, Inflection, and Complenaentiser, respectively.
129
</page>
<bodyText confidence="0.886495333333333">
position as P in the CLCS, and the head &apos;Hi to be
demoted into modifier position as It in the CLCS.
So, in example (2) of the last section, the resulting
CLCS is:9
[Bacat G0L0c
([Thia g PERSON],
</bodyText>
<subsectionHeader confidence="0.865452">
[Path TOL.c
</subsectionHeader>
<bodyText confidence="0.815301">
&amp;Ise. ATLs. ([Thiss PERSON], [pi.a. HOME])])],
</bodyText>
<subsectionHeader confidence="0.735313">
EManate HABITUALLY])]
</subsectionHeader>
<bodyText confidence="0.969612526315789">
Here the RLCS for soler, fm...„ HABITUALLY],
corresponds to 71 and the RLCS for ir, [Eye.: GO ...],
corresponds to P. In the translation to English,
[NI HABITUALLY] is not promoted, so it is re-
alized as an adjunct usually of the main verb go.
Mechanism 3: The :DEMOTE marker associ-
ated with an RLCS P places a restriction on the
head 7i 1 of the adjunct Pr. This restriction forces
fl to be demoted into an argument position of the
CLCS, and the logical subject of P to be inherited
from the logical subject of N.
For example, the lexical entry for gem contains a
:DEMOTE marker that is associated with the Y
argument in the RLCS:
[stain BEctrn
U&apos;rliitir X/1
[Place ATOirc ([Thing X], bhaeat Y :DEMOTED],
LIKINGLYD]
Thus, in the above formula, P1 corresponds to
gem and lir corresponds to the syntactic head
that takes gem as an adjunct. The :DEMOTE
marker forces the head 71 / to be demoted into an
argument position as 71 in the CLCS, and the ad-
junct Pi to be promoted into head position as P
in the CLCS. So in example (3) of the last section,
the resulting CLCS is:
[stain BEeiin
([Th ia$ REFERENT],
[Fuse ATeirc
([Thing REFERENT],
[Baniii EAT ([fling REFERENT], [Thing F ODDDI ,
LIKINGLYD]l°
Here the RLCS for gem, [stain BEcinn • •
corresponds to P and the RLCS for es-
sen, [st„t. EAT corresponds to IL In the
translation to English, [sn,,, BEmrc ...] is not de-
moted, so it is realized as the main verb like that
takes eating as its complement.
</bodyText>
<footnote confidence="0.531858">
7In general, a syntactic argument to is the canonical syn-
tactic realization (CS) of the corresponding CLCS argu-
ment u. The CS7Z function is a modified version of a routine
proposed in [Chomsky, 1986]. See (Dorr, 19901 for a more
detailed discussion of this function.
6The logical subject is the highest/left-most argument in
</footnote>
<note confidence="0.193838">
the CLCS. 130
</note>
<bodyText confidence="0.999796">
Now that we have looked briefly at the mechanisms
involved in solving thematic divergences in UNITRAN,
we will look at how other approaches have attempted to
solve this problem.
</bodyText>
<sectionHeader confidence="0.999252" genericHeader="method">
3 PREVIOUS APPROACHES
</sectionHeader>
<bodyText confidence="0.838987394736842">
In tackling the more global problem of machine transla-
tion, many people have addressed different pieces of the
thematic divergence problem, but no single approach has
yet attempted to solve the entire space of thematic di-
vergence possibilities. Furthermore, the pieces that have
been solved are accounted for by mechanisms that are
not general enough to carry over to other pieces of the
problem, nor do they take advantage of cross-linguistic
uniformities that can tie seemingly different languages
together.
Gretchen Brown has provided a model of German-
English translation that uses lexical semantic structures
[Brown, 1974]. The work is related to the model devel-
oped for UNITRAN since both use a form of conceptual
structure as the basis of translation. While this approach
goes a long way toward solving a number of translation
problems (especially compound noun disambiguation), it
falls short of providing a systematic solution to the the-
matic divergence problem. This is largely because the
conceptual structure does not serve as a common repre-
sentation for the source and target languages. Instead, it
is used as a point of transfer, and as such, it is forced to
encode certain language-specific idiosyncrasies such as
the syntactic positioning of conceptual arguments. In
terms of the representations used in UNITRAN, this
approach is analogous to using a language-to-language
mapping from the RLCS&apos;s of the source language to the
RLCS&apos;s of the target language without using an interme-
diate language-independent structure as a pivot form. In
°It should be noted that promotion and demotion struc-
tures are inverses of each other. Thus, although this CLCS
looks somewhat &amp;quot;English-like,&amp;quot; it is possible to represent the
CLCS as something that looks somewhat &amp;quot;Spanish-like:&amp;quot;
[State BeCirc
(IThing PERSON],
[place &amp;quot;Clic
ailing PERSON],
fEveat G°Loc
</bodyText>
<subsectionHeader confidence="0.432752">
([Thing PERSON],
</subsectionHeader>
<bodyText confidence="0.968904452830189">
[Path TOLac
UPlace &amp;quot;Lac ([Thing PERSON], [Place &amp;quot;MA UD),
[Nu.. e, HABITUALLY]
In this case, we would need to use the :DEMOTE marker (see
mechanism 3) instead of the :PROMOTE marker, but this
marker would be used in the RLCS associated with usually
instead of the RLCS associated with soler. The justification
for using the &amp;quot;English-like&amp;quot; version for this example is that
the IMan etc HABITUALLY] Constituent is generally thought of
as an aspectual element associated with a predicate (e.g., in
German, the sentence would be Ich gehe gewohnlich mach
I/awe (`I go usually home)); this constituent cannot be
used as a predicate in its own right. Thus, the compli-
cated &amp;quot;Spanish-like&amp;quot; predicate-argument structure is not a
likely conceptual representation for constructions that use
HABITUALLY].
&amp;quot;The default object being eaten is [Thilig FOOD], although
this is not syntactically realized in this example.
this approach, there is no single language-independent
mechanism that links the conceptual representation to
the syntactic structure; thus, it is necessary to hand-
code the rules of thematic divergence for English and
German, and all divergence generalizations are lost.
In 1982, Lytinen and Schank developed the MOP-
TRANS Spanish-English system based on conceptual de-
pendency networks [Lytinen &amp; Schank, 19821.11 This
approach is related to the UNITRAN model of transla-
tion in that it uses an interliiagual representation as the
pivot from source to target language. The key distinc-
tion is that the approach lacks a generalized linking to
syntax. For example, there is no systematic method for
determining which conceptual argument is the subject
and which is the object. This means that there is no
uniform mechanism for handling divergences such as the
subject-object reversal of example (1).
The LMT system is a logic-based English-German ma-
chine translator based on a modular logical grammar
[McCord, 19891. McCord specifically addresses the prob-
lem of thematic divergence in translating the sentence
Mir gefallt der Wagen (I like the car). However, the so-
lution that he offers is to provide a &amp;quot;transfer entry&amp;quot; that
interchanges the subject and object positions. There are
two problems with this approach. First it relies specifi-
cally on this object-initial ordering, even though the sen-
tence is arguably more preferable with a subject-initial
ordering Der Wagen gefllt mir; thus, the solution is
dependent on syntactic ordering considerations, and will
not work in the general case. Second the approach does
not attempt to tie this particular type of thematic di-
vergence to the rest of the space of thematic divergence
possibilities; thus, it cannot uniformly translate a con-
ceptually similar sentence Ich fahre das Wagen gem (I
like to drive the car).
</bodyText>
<sectionHeader confidence="0.999659" genericHeader="method">
4 THEMATIC DIVERGENCES
</sectionHeader>
<bodyText confidence="0.992049666666667">
In section 1, we introduced some examples of thematic
divergences, and in section 2 we described some of the
mechanisms that are used to solve these divergences.
Now that we have looked at other machine transla-
tion approaches with respect to the thematic divergence
problem, we will look at the solution that is used in the
UNITRAN system.
Recall that there are two types of thematic diver-
gences:
</bodyText>
<listItem confidence="0.96803325">
1. Different argument positionings with respect
to a given predicate.
2. Different predicate positionings with respect
to arguments or modifiers.
</listItem>
<bodyText confidence="0.990911">
The first type covers the case of argument positions that
diverge; it is accounted for by the :INT and :EXT mark-
ers. The second type covers the case of predicate posi-
tions that diverge; it is accounted for by the :PROMOTE
&amp;quot;Several researchers have worked within this framework
including Goldman [19741, Schank &amp; Abelson [1977], and
many others. 131.
and :DEMOTE markers. Together, these two types of
divergences account for the entire space of thematic di-
vergences, since all participants must be one of these two
(either an argument, or a predicate, or both).
In both cases of thematic divergence, it is assumed
that there is a CLCS that is derived from a source-
language RLCS that is isomorphic to the correspond-
ing target-language RLCS (i.e., the variables in the 2
RLCS&apos;s map to the same positions, though they may
be labeled differently). Furthermore, it is assumed that
thematic divergence arises only in cases where there is a
logical subject.
A CLCS with logical subject w, non-subject
arguments zi, z2, , zk, , z„, and modifiers
ni, n2, , nt, , n, will look like the structure shown
in (4), where the dominating head P is a typed primitive
(e.g., BEcirc):
</bodyText>
<listItem confidence="0.643487">
(4) [P w, zi, z2, ,z, . . . ,z„,ni, n2, . , ,n]
</listItem>
<bodyText confidence="0.999864">
In order to derive the syntactic structure from the
CLCS, we need a mapping or linking rule between the
CLCS positions and the appropriate syntactic positions.
Roughly, this linking rule is stated as follows:
</bodyText>
<subsectionHeader confidence="0.792314">
General Linking Routine g:
</subsectionHeader>
<listItem confidence="0.927382571428571">
(a) Map the logical subject to the external argu-
ment position.
(b) Map the non-logical-subjects to internal ar-
gument positions.
(c) Map modifiers to adjunct positions.
(d) Map the dominating head to the phrasal head
position.
</listItem>
<bodyText confidence="0.99904625">
g is used for the second half of translation (i.e., mapping
to the target-language structure); we also need an in-
verse routine that maps syntactic positions of the source-
language structure to the CLCS positions:
</bodyText>
<subsectionHeader confidence="0.748229">
Inverse Linking Routine g-1:
</subsectionHeader>
<listItem confidence="0.932228285714286">
(a) Map the external argument to the logical sub-
ject position.
(b) Map the internal arguments to non-logical-
subject positions.
(c) Map adjuncts to modifier positions.
(d) Map the phrasal head to the dominating head
node.
</listItem>
<bodyText confidence="0.999303">
In terms of the representation shown in (4), the
g and g-i mappings would be defined as shown
in figure 2.12.13,14 Note that to:, zir,... ,zkr, znt,
and nit, , , nmr are the source-language re-
alizations of the corresponding CLCS tokens w,
zn, and n1, , , similarly, wit,
zift,... , rot, , znft, and u.111,...,stitt,. , ,nn are
target-language realizations of the same CLCS tokens.
This assumes that there is only one external argument
and zero or more internal arguments. We will now look
</bodyText>
<figureCaption confidence="0.962319">
Figure 2: Mapping From Source to Target via the CLCS
</figureCaption>
<bodyText confidence="0.9650804">
at a formal description of how each type of thematic di-
vergence is manifested. We will then see how the general
linking routines described here take the syntactic mech-
anisms into account in order to derive the appropriate
result.
</bodyText>
<subsectionHeader confidence="0.983143">
4.1 Divergent Argument Positionings
</subsectionHeader>
<bodyText confidence="0.998305117647059">
In order to account for the thematic reversal that shows
up in the gustar-like example of (1), we must have a
mechanism for mapping CLCS arguments to different
syntactic positions. In terms of the CLCS, we need to
allow the syntactic realization of the logical subject w
and the syntactic realization of a non-subject argument
(say zi,) to switch places between the source and target
language.
Figure 3 shows how this type of argument reversal is
achieved. The :INT and :EXT markers are used in the
RLCS specifications as override markers for the G and
g-i routines: the :INT marker is used to map the logi-
cal subject of the CLCS to an internal syntactic position
(and vice versa). Thus, steps (a) and (b) of g and g-i
are activated differently if the RLCS associated with the
phrasal head contains either of the :INT or :EXT over-
ride mechanisms. Note that the CLCS is the same for
</bodyText>
<figureCaption confidence="0.986460333333333">
Figure 3: Mapping From Source to Target for Divergent
Arguments
Figure 4: Translation of Maria me gusta a ml
</figureCaption>
<figure confidence="0.99833425">
[Y-MAX WIN-MIN VI ZI..Z I .Z11
I&apos; .. i • r2 I I. r2]
I ..—•--- ......
..-•&amp;quot;--
...,
1...-
../
1‘•
./
[0#
If
[13 w,zi,...,zi,...,z„,n1,...,no.„,rainl
........, , •...
`...sli `---.., %.,...
Ira,&apos;&amp;quot; - — — -ib. . 1 i &apos; &apos;&apos;&apos;,.•116 ji &apos; &apos;&apos;&apos;&apos; 46
1Y4MAXW&amp;quot; [IX-MINP- IZ 7.•.Z&amp;quot; .ZIII n.11.4.91.11 ..BI
i $2.— 2$ / / &apos; rrt
}G&apos;
RLCS entry for?&apos;:
(W [Zk
RLCS entry for Pit:
11:1114zi,•••re51••.,2,vnir ••)nry.••gnrn
irr
kr-max Ek [IX-MEN V114.4...Zni 1 /Ili... al i. _Wm]
, . ...,
,
--...
rr -DR] ;• 44 ,A
IY-MAX [[X-MIN r jz ..z 1245...nfi
.1. Ir.. 2 t•
10
RLCS entry for gustar:
[BE [X :INT] [AT [Xi [Y :EXTJI LIKINGLY]
RLCS entry for like:
[BE [X] (AT /X] IYIJ LIKINGLYI
[I-MAX IN-MAX Marial- ------
.mAx[v-i[v-bAIN me gusta)
[p.m/ix a mJJ;
/G
AIC
[BE [REFERENT] [AT [REFERENT] [PERSON]] LIKINGLY]
{I-MAX IN-MAX
IV-MAX IV-I [V-MIN like] [N-MAX Maryl Ill
1G
</figure>
<bodyText confidence="0.914862333333333">
&apos;The convention adopted in this paper is to use tsi for the
source-language realization, and WI for the target-language
realization for a CLCS argument u.
&amp;quot;Adjunction has been placed to the right at the maximal
level. However, this is not the general case. A parameter
setting determines the side and level at which a particu-
lar adjunct will occur (as discussed in [Dorr, 1990]). The
configuration shown corresponds to the spec-initial/head-
initial case. The other three possible configurations are:
</bodyText>
<subsectionHeader confidence="0.786294">
[v.asAx WI tx.i. zj,l Z21 • .. [X.1.1111 P1]] - • • .,nio0j,
</subsectionHeader>
<bodyText confidence="0.991243958333333">
[Y-NIAX [X.1 z11 z21 . ..zni] wo 711.1,.•• 7nmfb
and [y.r.rtAx [xi zit Z21 • • • Zat1 [X.11.1117 Pi]] wi nit, • • • , nm6.
Finally, the order of the ziz&apos;s and nji&apos;s is not being addressed
here; this is determined by independent principles also dis-
cussed in [Darr, 19901. Regardless of these syntactic vari-
ations, the g and g- routines operate uniformly because
they are language-independent. For simplicity, the spec-
initial/head-initial configuration will be used for the rest of
this paper.
&amp;quot;In addition to realization of arguments, the dominating
CLCS head (P) must also be realized as a lexical word (Pr
in the source language and POI in the target language). The
syntactic category of this lexical word is X, and the maximal
projection is Y-MAX. In general, Y = X unless X is a Verb
(in which case, Y is the Inflection category). 132
both the source and target language; only the RLCS&apos;s in
the lexical entries need to include language-specific in-
formation in order to account for thematic divergences.
Now using the g and g-i routines and the overriding
:INT and :EXT mechanisms, we can show how to ac-
count for the thematic divergence of example (1).
Figure 4 shows the mapping from Spanish to English
for example (1).1516 Because the Spanish RLCS
includes the :INT and :EXT markers, the g-1 routine
activates steps (a) and (b) differently: the external argu-
ment Maria is mapped to a non-logical-subject position
[Thin, PERSON], and the internal argument miis mapped
to the logical subject position f
,Thiag REFERENT]. By
&amp;quot;Because of space limitations, we will illustrate the three
examples (1), (2), and (3) in one direction only. However,
it should be clear that the thematic divergences are solved
going in the opposite direction as well since the g and G-1
mappings are reversible.
&amp;quot;A shorthand notation is being used for the RLCS&apos;s and
the CLCS. See section 2 for a description of the actual rep-
resentations used by the system.
contrast, the English RLCS does not include any spe-
cial markers. Thus, the G routine activates steps (a)
and (b) normally: the logical subject [Thing REFERENT]
is mapped to the external argument I, and the non-
logical-subject [Tki„, PERSON] is mapped to the internal
position Mary.
Now we have seen how argument positioning diver-
gences are solved during the translation process.&amp;quot; In
the next section, we will look at how we account for the
second part of thematic divergences: different predicate
positionings.
</bodyText>
<subsectionHeader confidence="0.974391">
4.2 Divergent Predicate Positionings
</subsectionHeader>
<bodyText confidence="0.99649455">
In the last section, we concentrated primarily on the-
matic interchange of arguments. In this section, we will
concentrate on thematic interchange of predicates. In
so doing, we will have accounted for the entire space of
thematic divergences.
There are two ways to be in a predicate-argument rela-
tionship: the first is by complementation, and the second
is by adjunction. That is, syntactic phrases include base-
generated complements and base-generated adjuncts,
both of which participate in a predicate-argument struc-
ture (where the predicate is the head that subcategorizes
for the base-generated complement or adjunct).&amp;quot;
In order to show how predicate divergences are
solved, we must enumerate all possible source-
language/target-language predicate positionings with
respect to arguments z1, z2, , zk, and mod-
ifiers n1, n2,.. • • • , um. In terms of the syn-
tactic structure, we must examine all the possible
positionings for syntactic head &apos;Pr with respect to
its complements z21, zhi, ,z„! and adjuncts
</bodyText>
<equation confidence="0.750551">
rtri,n2i, • • • 1 - • • ,nynt•
</equation>
<bodyText confidence="0.999229884615384">
It should be noted that the solution presented here (as
well as that of the next section) does not appeal to an already-
coded set of conceptual &amp;quot;frames.&amp;quot; Rather, the syntactic
structures are derived procedurally on the basis of two pieces
of information: lexical entries (i.e., the R.LCS&apos;s) and the re-
sult of composing the RLCS&apos;s into a single unit (i.e., the
CLCS). It would not be possible to map declaratively, i.e.,
from a set of static source-language frames to a set of static
target-language frames. This is because the g and gal rou-
tines are intended to operate recursively: an argument that
occurs in a divergent phrasal construction might itself be a
divergent phrasal construction. For example, in the sentence
Ie node gustar leer a Juan (`John usually likes to read&apos;), there
is a simultaneous occurrence of two types of divergences: the
verb soler exhibits a predicate positioning divergence with
respect to its complement pastar ker a Juan, which itself ex-
hibits an argument positioning divergence. The procedural
mappings described here are crucial for handling such cases.
We have left out the possibility of a base-generated spec-
ifier as a participant in the predicate-argument relationship.
Of course, the specifier is an argument to the predicate, but
it turns out that the syntactic specifier, which corresponds to
the logical subject in the LCS, has a special status, and does
not participate in predicate divergences in the same way as
syntactic complements and adjuncts. This will be illustrated
shortly.
</bodyText>
<figureCaption confidence="0.994261">
Figure 5: Mapping From Source to Target for Divergent
Predicates
</figureCaption>
<bodyText confidence="0.973283956521739">
There are a large number of possible positionings that
exhibit predicate divergences, but only two of them arise
in natural language.19 It turns out that the soler-
usually example of (2) and the gem-like example of (3)
are representative of the space of possibilities of predi-
cate divergences. The source-language/target-language
predicate positionings for these two cases are represented
as shown in figure 5. Part (a) of this figure accounts for
the translation of usually to soler (or vice versa), and
part (b) accounts for the translation of like to gem n (or
vice versa).
The g and g-i routines do not take into account the
predicate divergences that were just presented. As in the
case of argument divergences, predicate divergences re-
quire override markers. The :PROMOTE marker is used
to map a modifier of the CLCS to a syntactic head posi-
tion (and vice versa). The :DEMOTE marker is used to
map a non-subject argument of the CLCS to a syntac-
tic head position (and vice versa). Thus, steps (c), and
19There is not enough space to elaborate on this claim here.
See [Dom 1990] for a detailed discussion of what the possible
positionings are, and which ones make sense in the context
of linguistic structure.
</bodyText>
<figure confidence="0.99829525">
RLCS entry for?&apos;: (a)
1?
RLCS entry for ?Is,:
n, :PROMOTE
RLCS entry for Pu:
IP pit
1v-mAxfrr n n
z 211 &amp;quot;
}G:
•
[vaviax w&apos;s Rx-NurrIllajz!....4...zIin nig,..&amp;quot;*.tel,...n,sin]
RLCS entry for?&apos;: (b)
RLCS entry for VN:
I
ff /
[Y-MAX WOit X-M1NPM/ fhf ...nt
IPtv,zi,•--747. • -18osaft ••,tn ,Th
•
IY-MAX WU 11 X-Mit
}G
</figure>
<page confidence="0.902705">
133
</page>
<figureCaption confidence="0.999909">
Figure 6: Translation of Juan suele ir a casa
</figureCaption>
<bodyText confidence="0.999979125">
(d) of the g and G-1 routines are activated differently
if the RLCS associated with the phrasal head contains
the :PROMOTE override marker, and steps (b) and (d)
of these routines are activated differently if a phrasal
adjunct contains the :DEMOTE override marker.
Now using the g and G-1 routines and the overriding
:PROMOTE and :DEMOTE mechanisms, we can show
how to account for the thematic divergences of exam-
ples (2) and (3) (see figures 6 and 7, respectively).
In figure 6, the Spanish RLCS for soler includes the
:PROMOTE marker. Thus, steps (c) and (d) of G-1 are
overridden: the internal argument ir a casa is promoted
into the dominating head position FIP
GO); and the
phrasal head suele is mapped into a modifier position
thi...„ HABITUALLY]. By contrast, the English RLCS
does not include any special markers. Thus, the g rou-
tine activates steps (c) and (d) normally: the dominating
head [u...1 GOL0.1 is mapped into the phrasal head goes;
and the modifier [A.„„„= HABITUALLY] is mapped into
an adjunct position usually.
In figure 7, the German RLCS for germ includes the
:DEMOTE marker (associated with the variable Y).
Thus, steps (b) and (d) of g-i are overridden: the
phrasal head ease is demoted into a non-logical-subject
position [By.„t EAT]; and the adjunct gem is mapped into
the dominating head position [s iLte BEci,]. By contrast,
the English FMCS does not include any special mark-
ers. Thus, the g routine activates steps (b) and (d)
normally: the dominating head [stme BEcirc] is mapped
into the phrasal head like; and the non-logical-subject
[Event EAT] is mapped into the internal position eating.
</bodyText>
<sectionHeader confidence="0.999776" genericHeader="conclusions">
5 SUMMARY
</sectionHeader>
<bodyText confidence="0.999923">
This paper has presented a solution to the problem of
thematic divergences in machine translation. The so-
lution has been implemented in UNITRAN, a bidirec-
tional system currently operating on Spanish, English,
and German, running in Commonlisp on a Symbolics
3600 series machine. We have seen that the procedures
involved are general enough to operate uniformly across
different languages and divergence types. Furthermore,
the entire space of thematic divergence possibilities is
</bodyText>
<page confidence="0.991494">
134
</page>
<figureCaption confidence="0.999963">
Figure 7: Translation of Ich habe Marie germ
</figureCaption>
<bodyText confidence="0.999302833333333">
covered in this approach without recourse to language-
specific routines or transfer rules. In addition to the-
matic divergences, the system handles the other diver-
gence types shown in figure 1, and it is expected that
additional divergence types will be handled by means of
equally principled methods.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="references">
6 REFERENCES
</sectionHeader>
<reference confidence="0.99950225">
[Brown, 1974] Gretchen Brown, &amp;quot;Some Problems in German
to English Machine Translation,&amp;quot; MAC Technical Report
142, Massachusetts Institute of Technology, Cambridge, MA,
1974.
[Chomsky, 1986] Noam A. Chomsky, Knowledge of Language:
Its Nature, Origin and Use, MIT Press, Cambridge, MA,
1986.
[Don, 1987] Bonnie J. Dorr, &amp;quot;UNITRAN: A Principle-Based
Approach to Machine Translation,&amp;quot; Al Technical Report
1000, Master of Science thesis, Department Electrical En-
gineering and Computer Science, Massachusetts Institute of
Technology, Cambridge, MA, 1987.
[Derr, 1990] Bonnie J. Don, &amp;quot;Lexical Conceptual Structure
and Machine Translation,&amp;quot; Ph.D. thesis, Department of Elec-
trical Engineering and Computer Science, Massachusetts In-
stitute of Technology, Cambridge, MA, 2990.
[Goldman, 1974] Neil M. Goldman, &amp;quot;Computer Generation
of Natural Language from a Deep Conceptual Base,&amp;quot; Ph.D
thesis, Computer Science Department, Stanford University,
Stanford, CA, 1974.
[Jackendoff, 1983] Ray S. Jackendoff, Semantics and Cogni-
tion, MIT Press, Cambridge, MA, 1983.
[Lytinen &amp; Schank, 1982] Steven Lytinen and Roger Schank,
&amp;quot;Representation and Translation,&amp;quot; Technical Report 234, De-
partment of Computer Science, Yale University, New Haven,
CT, 1982.
[McCord, 1989] Michael C. McCord, &amp;quot;Design of LMT: A
Prolog-Based Machine Translation System,&amp;quot; Computational
Linguistics, 15:1, 33-52, 1989.
]Schank &amp; Abelson, 1977] Roger C. Schank and Robert Abel-
son, Scripts, Plans, Goals, and Understanding, Lawrence Eli-
baum Associates, Inc., Hillsdale, NJ, 1977.
</reference>
<figure confidence="0.996987409090909">
RLCS entry for ir:
[CO ]X/ (To [AT ixi fyjil]
RLCS entry for go:
100 IX] (TO (AT [XI [Yillj
--
RLCS entry for soler:
[HABITUALLY *PROMOTE]
RLCS entry for usually:
(HABITUALLY]
II-MAX IN-MAX JUST]] suele
[V-MAX IV-MIN
. [V-MAX
..... ...
(CO [PERSON] !To [AT
lv-mn4 irl[r-mAx 9asa]]]]]
...
•
1PERSON] [HOME1]] HABITUALLY]
--------------
[I-mAx IN-MAX John)
IV-MAX [1.,-1 usually [1.r.mn4 goes]]
IN-MAX home]]]]
}0
RLCS entry for gem:
{BE PC1 [AT [XI iY :DEMOTE]] LIK1NGLY]
RLCS entry for like:
[BE [x] [AT [X] [VII LIKINGLY]
•
-----
[HE [REFERENT]
(AT [REFERENT] [EAT (REFERENT] IFOODID
•
\LIMN/01JY] •
•
•
........
ir-MAX [N-MAX IJ
•
[V-MAX [V-1 Iv-miN like] [v.mAx eating)11]
[I-MAX [N-MAX ICh]
[V-MAX [V-11 V-11V-M[N nee] gm]]]]
-------
•
10
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968922">
<title confidence="0.992128">SOLVING THEMATIC DIVERGENCES IN MACHINE TRANSLATION</title>
<author confidence="0.996656">Bonnie Dorr</author>
<affiliation confidence="0.999886">M.I.T. Artificial Intelligence Laboratory</affiliation>
<address confidence="0.9997015">545 Technology Square, Room 810 Cambridge, MA 02139, USA</address>
<email confidence="0.999376">internet:bonnie@reagan.ai.mit.edu</email>
<abstract confidence="0.9994261">Though most translation systems have some mechanism for translating certain types of divergent predicate-argument structures, they do not provide a general procedure that takes advantage of the relationship between lexical-semantic structure and syntactic structure. A divergent predicate-argument is one in which the predicate main verb) or its arguments (e.g., the subject and object) do not have the same syntactic ordering properties for both the source and target language. To account for such ordering differences, a machine translator must consider language-specific syntactic idiosyncrasies that distinguish a target language from a source language, while making use of lexical-semantic uniformities that tie the two languages together. This paper describes the mechanisms used by the UNITRAN machine translation system for mapping an underlying lexicalconceptual structure to a syntactic structure (and vice versa), it coupled with a set of general linking routines solve the problem of thematic divergence in machine translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gretchen Brown</author>
</authors>
<title>Some Problems in German to English Machine Translation,&amp;quot;</title>
<date>1974</date>
<tech>MAC Technical Report 142,</tech>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA,</location>
<marker>[Brown, 1974]</marker>
<rawString>Gretchen Brown, &amp;quot;Some Problems in German to English Machine Translation,&amp;quot; MAC Technical Report 142, Massachusetts Institute of Technology, Cambridge, MA, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam A Chomsky</author>
</authors>
<title>Knowledge of Language: Its Nature, Origin and Use,</title>
<date>1986</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>[Chomsky, 1986]</marker>
<rawString>Noam A. Chomsky, Knowledge of Language: Its Nature, Origin and Use, MIT Press, Cambridge, MA, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>UNITRAN: A Principle-Based Approach to Machine Translation,&amp;quot; Al</title>
<date>1987</date>
<tech>Technical Report 1000,</tech>
<institution>Master of Science thesis, Department Electrical Engineering and Computer Science, Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA,</location>
<marker>[Don, 1987]</marker>
<rawString>Bonnie J. Dorr, &amp;quot;UNITRAN: A Principle-Based Approach to Machine Translation,&amp;quot; Al Technical Report 1000, Master of Science thesis, Department Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, 1987.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bonnie J Don</author>
</authors>
<title>Lexical Conceptual Structure and Machine Translation,&amp;quot;</title>
<tech>Ph.D. thesis,</tech>
<pages>2990</pages>
<institution>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA,</location>
<marker>[Derr, 1990]</marker>
<rawString>Bonnie J. Don, &amp;quot;Lexical Conceptual Structure and Machine Translation,&amp;quot; Ph.D. thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA, 2990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil M Goldman</author>
</authors>
<title>Computer Generation of Natural Language from a Deep Conceptual Base,&amp;quot;</title>
<date>1974</date>
<tech>Ph.D thesis,</tech>
<institution>Computer Science Department, Stanford University,</institution>
<location>Stanford, CA,</location>
<marker>[Goldman, 1974]</marker>
<rawString>Neil M. Goldman, &amp;quot;Computer Generation of Natural Language from a Deep Conceptual Base,&amp;quot; Ph.D thesis, Computer Science Department, Stanford University, Stanford, CA, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray S Jackendoff</author>
</authors>
<title>Semantics and Cognition,</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>[Jackendoff, 1983]</marker>
<rawString>Ray S. Jackendoff, Semantics and Cognition, MIT Press, Cambridge, MA, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Lytinen</author>
<author>Roger Schank</author>
</authors>
<title>Representation and Translation,&amp;quot;</title>
<date>1982</date>
<tech>Technical Report 234,</tech>
<institution>Department of Computer Science, Yale University,</institution>
<location>New Haven, CT,</location>
<marker>[Lytinen &amp; Schank, 1982]</marker>
<rawString>Steven Lytinen and Roger Schank, &amp;quot;Representation and Translation,&amp;quot; Technical Report 234, Department of Computer Science, Yale University, New Haven, CT, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
</authors>
<title>Design of LMT: A Prolog-Based Machine Translation System,&amp;quot;</title>
<date>1989</date>
<journal>Computational Linguistics,</journal>
<volume>15</volume>
<pages>33--52</pages>
<location>Hillsdale, NJ,</location>
<marker>[McCord, 1989]</marker>
<rawString>Michael C. McCord, &amp;quot;Design of LMT: A Prolog-Based Machine Translation System,&amp;quot; Computational Linguistics, 15:1, 33-52, 1989. ]Schank &amp; Abelson, 1977] Roger C. Schank and Robert Abelson, Scripts, Plans, Goals, and Understanding, Lawrence Elibaum Associates, Inc., Hillsdale, NJ, 1977.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>