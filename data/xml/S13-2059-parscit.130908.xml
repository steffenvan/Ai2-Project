<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014172">
<title confidence="0.9871095">
AMI&amp;ERIC: How to Learn with Naive Bayes and Prior Knowledge:
an Application to Sentiment Analysis
</title>
<author confidence="0.963212">
Mohamed Dermouche1,2, Leila Khouas1, Julien Velcin2 and Sabine Loudcher2
</author>
<affiliation confidence="0.837709">
1AMI Software R&amp;D
</affiliation>
<address confidence="0.935598">
1475 av. A. Einstein
34000 Montpellier, France
</address>
<email confidence="0.9833185">
mde@amisw.com
lkh@amisw.com
</email>
<note confidence="0.632613">
2Universit´e de Lyon, ERIC (Lyon 2)
</note>
<address confidence="0.778240333333333">
5 av. P. Mend`es-France
69676 Bron Cedex, France
julien.velcin@univ-lyon2.fr
</address>
<email confidence="0.763225">
sabine.loudcher@univ-lyon2.fr
</email>
<sectionHeader confidence="0.989948" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999415166666667">
In this paper, we describe our system that par-
ticipated in SemEval-2013, Task 2.B (senti-
ment analysis in Twitter). Our approach con-
sists of adapting Naive Bayes probabilities in
order to take into account prior knowledge
(represented in the form of a sentiment lex-
icon). We propose two different methods to
efficiently incorporate prior knowledge. We
show that our approach outperforms the clas-
sical Naive Bayes method and shows compet-
itive results with SVM while having less com-
putational complexity.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998950529411765">
With the advent of Internet microblogging, social
networks, like Twitter1 and Facebook2, have brought
about a real revolution in our way of communi-
cating. People share their opinions of everyday
life without taboos or restrictions thanks to the
anonymity offered by these tools, which makes them
a valuable source of information rather rich of sub-
jective data. These data can be mined using sen-
timent analysis as a means to understand people’s
feelings towards a political cause or what people are
thinking about a product or a service. Recent works
showed that Twitter sentiments can be correlated to
box-office revenues (Asur and Huberman, 2010) or
political polls (O’Connor et al., 2010).
Machine learning methods, like Naive Bayes
(NB) and Support Vector Machines (SVM), have
been widely used in sentiment analysis (Pang et al.,
</bodyText>
<footnote confidence="0.999779">
1http://www.twitter.com/
2http://www.facebook.com/
</footnote>
<bodyText confidence="0.9966174375">
2002; Pak and Paroubek, 2010). One major problem
with these methods, and in particular NB, is that the
model is built only on the learning data which can
lead to overfitting. In this paper, we describe our ap-
proach that participated in SemEval-2013, Task 2.B
(sentiment analysis in Twitter) (Wilson et al., 2013).
Our approach consists of learning with both NB and
prior knowledge. We show that our approach out-
performs the classical NB method and gives com-
petitive results compared to SVM while having less
computational complexity.
The remainder of this paper is organized as fol-
lows: prior works on sentiment analysis are dis-
cussed in Section 2. The proposed approach is de-
tailed in Section 3. Then, experiments and results
are given in Section 4 and 5.
</bodyText>
<sectionHeader confidence="0.971088" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9991943125">
Sentiment analysis is a text mining task which deals
with the feelings expressed explicitly or implicitly
in a textual content. It concerns subjectivity anal-
ysis (subjective/objective), opinion mining (posi-
tive/negative/neutral), strength analysis, etc. Al-
though the term “sentiment analysis” includes all
these tasks, it often refers to opinion mining. Sen-
timent analysis methods can be categorized into ma-
chine learning, linguistic and hybrid methods.
Machine learning methods are usually supervised.
A model is built based on a learning dataset com-
posed of annotated texts and represented by a bag of
words. The model is then deployed to classify new
texts. Pang et al. (2002) use machine learning meth-
ods (NB, SVM and MaxEnt) to detect sentiments on
movie reviews. Pak and Paroubek (2010) use NB to
</bodyText>
<page confidence="0.981195">
364
</page>
<bodyText confidence="0.989921888888889">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
perform sentiment analysis on Twitter data.
Linguistic methods use lexicons and manually-
crafted rules to detect sentiments. Kennedy and
Inkpen (2006) use syntactic analysis to capture lan-
guage aspects like negation and contextual valence
shifters. Other works (Turney and Littman, 2003;
Kamps et al., 2004) propose to use a term similarity
measure which can be statistical (e.g., Mutual Infor-
mation, LSA) or semantic (e.g., WordNet-based).
Hybrid methods use both statistical and linguistic
approaches. Esuli and Sebastiani (2011), which is
the closest work to ours, propose to use annotated
lexical resources to improve opinion extraction. The
bag-of-word text representation is enriched by new
tags (e.g. subjectivity, polarity). Then, an SVM-
based system is used for opinion classification.
</bodyText>
<sectionHeader confidence="0.976884" genericHeader="method">
3 Our approach
</sectionHeader>
<bodyText confidence="0.99998555882353">
NB is a machine learning method that builds a clas-
sification model based only on the learning data
which makes it highly dependent on this data. For
example, in a sentiment analysis task, if the term
actor appears more frequently within a negative
context than in a positive one, it will be classified as
negative while actually it is not. Moreover, NB tends
sometimes to predict the class of majority (observed
on learning data) which increases classification er-
rors on unbalanced data. Our approach consists of
incorporating prior knowledge into the NB model to
make it less dependent on learning data.
To be efficiently used, prior knowledge must be
represented in a structured form. We choose, here,
to represent it by a sentiment lexicon (a set of pos-
itive and negative terms). Several lexicons have al-
ready been developed to address sentiment analysis
issues. Some of them are publicly available like the
MPQA subjectivity lexicon (Wilson et al., 2005),
Liu’s opinion lexicon (Ding et al., 2008), Senti-
WordNet (Esuli and Sebastiani, 2006). We believe
that such knowledge can be quite useful if used cor-
rectly and efficiently by machine learning methods.
In the following, we settle for a 2-way classi-
fication task (positive vs. negative). Texts are
represented by a vector space model (Salton et
al., 1975) and terms are weighted according to
their presence/absence in the text because previous
works (Pang et al., 2002; Pak and Paroubek, 2010)
showed that Boolean model performs better than
other weighting schemes in sentiment analysis. We
denote by w and w� the presence, respectively ab-
sence, modality of a word w. A “term” stands, here,
for any type of text features (smileys, n-grams).
</bodyText>
<subsectionHeader confidence="0.999678">
3.1 Sentiment lexicon
</subsectionHeader>
<bodyText confidence="0.999993222222222">
We represent the prior knowledge by a 2-class sen-
timent lexicon: a list of subjective terms (words,
n-grams and smileys) manually annotated with two
scores: positive (score,+) and negative (score,_).
Each term has a score of 1 on a class polarity (we call
it right class) and 0 on the other one (wrong class).
For example, the word good has score,+ = 1 and
score,_ = 0. Then, c+ is the right class of the word
good and c_ is the wrong class.
</bodyText>
<subsectionHeader confidence="0.98945">
3.2 NB method
</subsectionHeader>
<bodyText confidence="0.9999602">
NB is based on calculating class-wise term prob-
abilities on a learning dataset D where each text
d E D is annotated with a class c E {c+, c_}. In
the learning step, probability values p(w|c) are esti-
mated from D as follows:
</bodyText>
<equation confidence="0.9988315">
1
p(w|c) = nb(c) &apos; nb(w, c) (1)
</equation>
<bodyText confidence="0.998887818181818">
Where nb(c) denotes the number of texts of class c
and nb(w, c) is the number of texts of class c that
contain the term w.
Once these probabilities are calculated for each
couple (w, c), the model can be used to classify new
texts. We choose to assign a new text d to the
class that maximizes the probability p(c|d). Using
Bayes’ theorem and independence assumption be-
tween term distributions, this probability is calcu-
lated as follows (the denominator can be dropped
because it is not dependent on the class c):
</bodyText>
<equation confidence="0.9779865">
p(c|d) = p(c) &apos; H-Ed p(w|c) (2)
p(d)
</equation>
<subsectionHeader confidence="0.99744">
3.3 Incorporating prior knowledge
</subsectionHeader>
<bodyText confidence="0.981835333333333">
Prior knowledge is incorporated by adapting NB for-
mulas. We propose two different methods to do this:
Add &amp; Remove and Transfer. These methods differ
in the way to calculate the class-wise term proba-
bilities p(w|c) but use the same classification rule:
class(d) = arg max1E{1+,1_} p(c|d).
</bodyText>
<page confidence="0.99394">
365
</page>
<bodyText confidence="0.99987925">
Add &amp; Remove. This method consists of artifi-
cially adding some occurrences of term w to the
right class and removing some occurrences from the
wrong class. The lexicon is used to determine for
each term its right and wrong classes. To ensure
that probability values do not exceed 1, we introduce
nb( ¯w, c), the number of texts of class c that do not
contain the term w, which is also equal to the maxi-
mum number of occurrences of w that can be added
to the class c. Thus, the number of added occur-
rences is a ratio αc of this maximum (0 &lt; αc &lt; 1).
Likewise, if c was the wrong class of w, the number
of removed occurrences from the class c is a ratio βc
of the maximum number that can be removed from
the class c, nb(w, c), with 0 &lt; βc &lt; 1. Formally,
term probabilities are calculated as follows:
</bodyText>
<equation confidence="0.996280666666667">
1
p(w|c) = nb(c) ·[nb(w,c)+αc·scorec(w)·nb( ¯w,c)
−βc · scoreF(w) · nb(w, c)] (3)
</equation>
<bodyText confidence="0.999838416666667">
Transfer. This method consists of transferring
some occurrences of a term w from the wrong class
to the right class. The number of transferred occur-
rences is such that the final probability is not greater
than 1 and the number of transferred occurrences is
not greater than the actual number of occurrences in
the wrong class. To meet these constraints, we in-
troduce max(w, c): the maximum number of occur-
rences of w that can be transferred to the class c from
the other class ¯c. This number must not be greater
than both the number of texts from c¯ containing w
and the number of texts from c not containing w.
</bodyText>
<equation confidence="0.522132">
max(w, c) = min{nb(w, ¯c), nb( ¯w, c)} (4)
</equation>
<bodyText confidence="0.999865333333333">
Finally, the number of occurrences actually trans-
ferred is a ratio αc of max(w, c) with 0 &lt; αc &lt; 1.
Term probabilities are estimated as follows:
</bodyText>
<equation confidence="0.995360333333333">
1
p(w|c)= nb(c)·[nb(w, c)+αc·scorec(w)·max(w, c)
−αc · scored(w) · max(w, ¯c)] (5)
</equation>
<bodyText confidence="0.99918">
Both methods, Add &amp; Remove and Transfer, con-
sist of removing occurrences from the wrong class
and adding occurrences to the right class with the
difference that in Transfer, the number of added oc-
currences is exactly the number of removed ones.
</bodyText>
<sectionHeader confidence="0.99958" genericHeader="method">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999515">
4.1 Sentiment lexicon
</subsectionHeader>
<bodyText confidence="0.999898125">
For SemEval-2013 contest (Wilson et al., 2013),
we have developed our own lexicon based on Liu’s
opinion lexicon (Ding et al., 2008) and enriched
with some “microblogging style” terms (e.g., luv,
xox, gd) manually collected on the Urban Dic-
tionary3. The whole lexicon contains 7720 English
terms (words, 2-grams, 3-grams and smileys) where
2475 are positive and 5245 negative.
</bodyText>
<subsectionHeader confidence="0.981714">
4.2 Dataset and preprocessing
</subsectionHeader>
<bodyText confidence="0.999930277777778">
To evaluate the proposed approach, we use
SemEval-2013 datasets: TW (tweets obtained by
merging learn and development data) and SMS, in
addition to MR (English movie reviews of Pang and
Lee (2004)). Concerning SMS, the classification is
performed using the model learned on tweets (TW)
in order to assess how it generalizes on SMS data.
Note that our approach is adapted to binary clas-
sification but can be used for 3-way classification
(which is the case of TW and SMS). We do this
by adapting only positive and negative probabilities,
neutral ones remain unchanged.
Texts are preprocessed by removing stopwords,
numerics, punctuation and terms that occur only
once (to reduce vocabulary size and data sparse-
ness). Texts are then stemmed using Porter stemmer
(Porter, 1997). We also remove URLs and Twitter
keywords (via, RT) from tweets.
</bodyText>
<subsectionHeader confidence="0.994372">
4.3 Tools
</subsectionHeader>
<bodyText confidence="0.957001833333333">
As we compare our approach to SVM method,
we have used SVMmulticlass (Crammer and Singer,
2002). For a compromise between processing time
and performance, we set the trade-off parameter c to
4 on MR dataset and 20 on TW and SMS (based on
empirical results).
</bodyText>
<sectionHeader confidence="0.998706" genericHeader="evaluation">
5 Results and discussion
</sectionHeader>
<bodyText confidence="0.9999838">
In addition to the two proposed methods: Add &amp;
Remove (A&amp;R) and Transfer (TRA), texts are clas-
sified using NB and SVM with two kernels: linear
(SVM-L) and polynomial of degree 2 (SVM-P). All
the scores given below correspond to the average
</bodyText>
<footnote confidence="0.952764">
3http://www.urbandictionary.com/
</footnote>
<page confidence="0.995218">
366
</page>
<table confidence="0.8500352">
F-score of positive and negative classes, even for F-score 85
3-way classification. This measure is also used in 80
SemEval-2013 result evaluation and ranking (Wil- 75
son et al., 2013). 70
0.0025 0.01 0.03 0.07 0.09 0.15 0.25
</table>
<subsectionHeader confidence="0.984267">
5.1 General results
</subsectionHeader>
<bodyText confidence="0.9973716">
General results are obtained only with unigrams and
smileys. Figure 1 presents the results obtained on
the different datasets on both 2-way (left) and 3-
way (right) classifications. For 2-way classification,
neutral texts are ignored and the model is evaluated
using a 5-fold cross validation. For 3-way classifi-
cation, the model is evaluated on the provided test
data. Compared with NB, our approach performs
better on all datasets. It also outperforms SVM, that
achieves poor results, except on MR.
</bodyText>
<table confidence="0.997802714285714">
Method 2-class 3-class
TW MR TW SMS
NB 74.07 73.06 59.43 48.80
SVM-L 49.79 74.56 37.56 32.13
SVM-P 49.74 84.64 37.56 32.13
A&amp;R 76.05 80.57 60.57 49.42
TRA 76.00 75.53 60.27 51.35
</table>
<figureCaption confidence="0.991736">
Figure 1: General results (unigrams and smileys)
</figureCaption>
<bodyText confidence="0.999621142857143">
Parameter effect. To examine the effect of pa-
rameters, we perform a 2-way classification on TW
and MR datasets using 5-fold cross validation (Fig-
ure 2). We take, for A&amp;R method, Qc+ = Qc� = 0
and for both methods, αc+ = αc� (denoted α).
This configuration does not necessarily give the best
scores. However, empirical tests showed that scores
are not significantly lower than the best ones. We
choose this configuration for simplicity (only one
parameter to tune).
Figure 2 shows that best scores are achieved with
different values of α depending on the used method
(A&amp;R, TRA) and the data. Therefore, parameters
must be fine-tuned for each dataset separately.
</bodyText>
<subsectionHeader confidence="0.999201">
5.2 SemEval-2013 results
</subsectionHeader>
<bodyText confidence="0.999820666666667">
For SemEval-2013 contest, we have enriched text
representation by 2-grams and 3-grams and used
A&amp;R method with: αc+ = αc� = 0.003, Qc+ =
0.04 and Qc� = 0.02. All of these parameters have
been fine-tuned using the development data. We
have also made an Information Gain-based feature
</bodyText>
<figure confidence="0.892718714285714">
0.001 0.005 0.02 0.05 0.08 0.1 0.2
α
85
80
75
70
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</figure>
<figureCaption confidence="0.99355">
Figure 2: Effect of the parameter α on a 2-way classifica-
tion using methods: A&amp;R (top) and TRA (bottom)
</figureCaption>
<bodyText confidence="0.9526602">
selection (Mitchell, 1997). Only the best 2000 terms
are kept to which we have added terms of the lexi-
con. Under these conditions, our approach achieved
the scores 62.55% on tweets (ranked 6th/35) and
53.63% on SMS (ranked 9th/28).
</bodyText>
<table confidence="0.996691142857143">
Dataset Class Pecision Recall F-score
positive 62.12 74.49 67.75
TW negative 46.23 75.54 57.36
neutral 76.74 44.27 56.15
positive 39.59 78.86 52.72
SMS negative 45.64 67.77 54.55
neutral 90.93 39.82 55.38
</table>
<figureCaption confidence="0.982849">
Figure 3: SemEval-2013 results (A&amp;R method)
</figureCaption>
<bodyText confidence="0.99764">
Regarding F-score of each class (Figure 3), our
approach gave better results on the negative class
(under-represented in the learning data) than NB
(49.09% on TW and 47.63% on SMS).
</bodyText>
<sectionHeader confidence="0.999248" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99995325">
In this paper, we have presented a novel approach
to sentiment analysis by incorporating prior knowl-
edge into NB model. We showed that our approach
outperforms NB and gives competitive results with
SVM while better handling unbalanced data.
As a future work, further processing may be re-
quired on Twitter data. Tweets, in contrast to tra-
ditional text genres, show many specificities (short
size, high misspelling rate, informal text, etc.).
Moreover, tweets rely on an underlying structure
(re-tweets, hashtags) that may be quite useful to
build more accurate analysis tools.
</bodyText>
<figure confidence="0.943211666666667">
α
TW MR
F-score
</figure>
<page confidence="0.984431">
367
</page>
<sectionHeader confidence="0.985234" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996833714285715">
Sitaram Asur and Bernardo A. Huberman. Predict-
ing the future with social media. In Proceedings of
the 2010 IEEE/WIC/ACM International Conference
on Web Intelligence and Intelligent Agent Technology
(WI-IAT’10), pages 492–499, Washington, DC, USA,
2010. IEEE Computer Society.
Koby Crammer and Yoram Singer. On the algorithmic
implementation of multiclass kernel-based vector ma-
chines. The Journal of Machine Learning Research,
2:265–292, 2002.
Xiaowen Ding, Bing Liu, and Philip S. Yu. A holistic
lexicon-based approach to opinion mining. In Pro-
ceedings of the 2008 International Conference on Web
Search and Data Mining (WSDM ’08), pages 231–240,
New York, NY, USA, 2008. ACM.
Andrea Esuli and Fabrizio Sebastiani. Sentiwordnet: A
publicly available lexical resource for opinion mining.
In Proceedings of the 5th Conference on Language
Resources and Evaluation (LREC06), pages 417–422,
Genova, IT, 2006.
Andrea Esuli and Fabrizio Sebastiani. Enhancing opin-
ion extraction by automatically annotated lexical re-
sources. In Proceedings of the 4th conference on Hu-
man language technology: challenges for computer
science and linguistics (LTC’09), pages 500–511, Poz-
nan, Poland, 2011. Springer-Verlag.
Vasileios Hatzivassiloglou and Kathleen R Mckeown.
Predicting the Semantic Orientation of Adjectives. In
Proceedings of the eighth conference of the European
chapter of the Association for Computational Linguis-
tics (EACL’97), pages 174–181, Madrid, Spain, 1997.
ACL.
Jaap Kamps, Maarten Marx, Robert J. Mokken, and
Maarten de Rijke. Using WordNet to measure seman-
tic orientations of adjectives. In Proceedings of the 4th
International Conference on Language Resources and
Evaluation (LREC-04), pages 1115–1118, Lisbon, PT,
2004.
Alistair Kennedy and Diana Inkpen. Sentiment clas-
sification of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110–125,
May 2006.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R. Routledge, and Noah A. Smith. From tweets
to polls: Linking text sentiment to public opinion
time series. In Proceedings of the 4th International
AAAI Conference on Weblogs and Social Media,
Washington, DC, USA, 2010.
Alexander Pak and Patrick Paroubek. Twitter as
a corpus for sentiment analysis and opinion min-
ing. In Proceedings of the Seventh conference on
International Language Resources and Evaluation
(LREC’10), pages 1320–1326, Valletta, Malta, 2010.
ELRA.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
Thumbs up?: sentiment classification using machine
learning techniques. In Proceedings of the ACL-02
conference on Empirical methods in natural language
processing (EMNLP’02), pages 79–86. ACL, 2002.
Bo Pang and Lillian Lee. A sentimental education: Senti-
ment analysis using subjectivity summarization based
on minimum cuts. In Proceedings of the 42nd An-
nual Meeting on Association for Computational Lin-
guistics (ACL’04), pages 271–278, Barcelona, Catalo-
nia, Spain, 2004. ACL.
Thomas M. Mitchell. Machine Learning. McGraw-Hill,
Inc., New York, NY, USA, 1 edition, 1997.
Martin F. Porter. An algorithm for suffix stripping. In
Readings in information retrieval, number 3, pages
313–316. Morgan Kaufmann Publishers Inc., San
Francisco, CA, USA, 1997.
Peter D. Turney and Michael L. Littman. Measuring
praise and criticism: Inference of semantic orientation
from association. ACM Transactions on Information
Systems (TOIS), 21(4):315–346, 2003.
Gerard Salton, Andrew K. C. Wong, and Chung S. Yang.
A vector space model for automatic indexing. Com-
munications of the ACM, 18(11):613–620, 1975.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. Rec-
ognizing contextual polarity in phrase-level sentiment
analysis. In Proceedings of the conference on Human
Language Technology and Empirical Methods in Natu-
ral Language Processing (HLT/EMNLP-2005), pages
347–354, Vancouver, British Columbia, Canada, 2005.
ACL.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,
Sara Rosenthal, Veselin Stoyanov, and Alan Ritter.
SemEval-2013 Task 2: Sentiment Analysis in Twit-
ter. In Proceedings of the International Workshop on
Semantic Evaluation (SemEval’13), Atlanta, Georgia,
USA, 2013. ACL.
</reference>
<page confidence="0.998263">
368
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.339490">
<title confidence="0.9990305">AMI&amp;ERIC: How to Learn with Naive Bayes and Prior Knowledge: an Application to Sentiment Analysis</title>
<author confidence="0.999398">Leila Julien</author>
<affiliation confidence="0.950547">Software</affiliation>
<address confidence="0.9927905">1475 av. A. Einstein 34000 Montpellier,</address>
<email confidence="0.999762">lkh@amisw.com</email>
<affiliation confidence="0.557441">de Lyon, ERIC (Lyon</affiliation>
<address confidence="0.805674">5 av. P. 69676 Bron Cedex,</address>
<email confidence="0.921313">sabine.loudcher@univ-lyon2.fr</email>
<abstract confidence="0.978714307692308">In this paper, we describe our system that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter). Our approach consists of adapting Naive Bayes probabilities in order to take into account prior knowledge (represented in the form of a sentiment lexicon). We propose two different methods to efficiently incorporate prior knowledge. We show that our approach outperforms the classical Naive Bayes method and shows competitive results with SVM while having less computational complexity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sitaram Asur</author>
<author>Bernardo A Huberman</author>
</authors>
<title>Predicting the future with social media.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT’10),</booktitle>
<pages>492--499</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA,</location>
<contexts>
<context position="1580" citStr="Asur and Huberman, 2010" startWordPosition="235" endWordPosition="238">rnet microblogging, social networks, like Twitter1 and Facebook2, have brought about a real revolution in our way of communicating. People share their opinions of everyday life without taboos or restrictions thanks to the anonymity offered by these tools, which makes them a valuable source of information rather rich of subjective data. These data can be mined using sentiment analysis as a means to understand people’s feelings towards a political cause or what people are thinking about a product or a service. Recent works showed that Twitter sentiments can be correlated to box-office revenues (Asur and Huberman, 2010) or political polls (O’Connor et al., 2010). Machine learning methods, like Naive Bayes (NB) and Support Vector Machines (SVM), have been widely used in sentiment analysis (Pang et al., 1http://www.twitter.com/ 2http://www.facebook.com/ 2002; Pak and Paroubek, 2010). One major problem with these methods, and in particular NB, is that the model is built only on the learning data which can lead to overfitting. In this paper, we describe our approach that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter) (Wilson et al., 2013). Our approach consists of learning with both NB an</context>
</contexts>
<marker>Asur, Huberman, 2010</marker>
<rawString>Sitaram Asur and Bernardo A. Huberman. Predicting the future with social media. In Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT’10), pages 492–499, Washington, DC, USA, 2010. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>On the algorithmic implementation of multiclass kernel-based vector machines.</title>
<date>2002</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>2</volume>
<contexts>
<context position="11158" citStr="Crammer and Singer, 2002" startWordPosition="1841" endWordPosition="1844">zes on SMS data. Note that our approach is adapted to binary classification but can be used for 3-way classification (which is the case of TW and SMS). We do this by adapting only positive and negative probabilities, neutral ones remain unchanged. Texts are preprocessed by removing stopwords, numerics, punctuation and terms that occur only once (to reduce vocabulary size and data sparseness). Texts are then stemmed using Porter stemmer (Porter, 1997). We also remove URLs and Twitter keywords (via, RT) from tweets. 4.3 Tools As we compare our approach to SVM method, we have used SVMmulticlass (Crammer and Singer, 2002). For a compromise between processing time and performance, we set the trade-off parameter c to 4 on MR dataset and 20 on TW and SMS (based on empirical results). 5 Results and discussion In addition to the two proposed methods: Add &amp; Remove (A&amp;R) and Transfer (TRA), texts are classified using NB and SVM with two kernels: linear (SVM-L) and polynomial of degree 2 (SVM-P). All the scores given below correspond to the average 3http://www.urbandictionary.com/ 366 F-score of positive and negative classes, even for F-score 85 3-way classification. This measure is also used in 80 SemEval-2013 result</context>
</contexts>
<marker>Crammer, Singer, 2002</marker>
<rawString>Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine Learning Research, 2:265–292, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 International Conference on Web Search and Data Mining (WSDM ’08),</booktitle>
<pages>231--240</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="5454" citStr="Ding et al., 2008" startWordPosition="840" endWordPosition="843"> class of majority (observed on learning data) which increases classification errors on unbalanced data. Our approach consists of incorporating prior knowledge into the NB model to make it less dependent on learning data. To be efficiently used, prior knowledge must be represented in a structured form. We choose, here, to represent it by a sentiment lexicon (a set of positive and negative terms). Several lexicons have already been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w� the presence, respectively absence</context>
<context position="9938" citStr="Ding et al., 2008" startWordPosition="1646" endWordPosition="1649"> occurrences actually transferred is a ratio αc of max(w, c) with 0 &lt; αc &lt; 1. Term probabilities are estimated as follows: 1 p(w|c)= nb(c)·[nb(w, c)+αc·scorec(w)·max(w, c) −αc · scored(w) · max(w, ¯c)] (5) Both methods, Add &amp; Remove and Transfer, consist of removing occurrences from the wrong class and adding occurrences to the right class with the difference that in Transfer, the number of added occurrences is exactly the number of removed ones. 4 Experiment 4.1 Sentiment lexicon For SemEval-2013 contest (Wilson et al., 2013), we have developed our own lexicon based on Liu’s opinion lexicon (Ding et al., 2008) and enriched with some “microblogging style” terms (e.g., luv, xox, gd) manually collected on the Urban Dictionary3. The whole lexicon contains 7720 English terms (words, 2-grams, 3-grams and smileys) where 2475 are positive and 5245 negative. 4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in addition to MR (English movie reviews of Pang and Lee (2004)). Concerning SMS, the classification is performed using the model learned on tweets (TW) in order to assess how it generalizes o</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. A holistic lexicon-based approach to opinion mining. In Proceedings of the 2008 International Conference on Web Search and Data Mining (WSDM ’08), pages 231–240, New York, NY, USA, 2008. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06),</booktitle>
<pages>417--422</pages>
<location>Genova, IT,</location>
<contexts>
<context position="5497" citStr="Esuli and Sebastiani, 2006" startWordPosition="846" endWordPosition="849">arning data) which increases classification errors on unbalanced data. Our approach consists of incorporating prior knowledge into the NB model to make it less dependent on learning data. To be efficiently used, prior knowledge must be represented in a structured form. We choose, here, to represent it by a sentiment lexicon (a set of positive and negative terms). Several lexicons have already been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w� the presence, respectively absence, modality of a word w. A “term” stands, he</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC06), pages 417–422, Genova, IT, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Enhancing opinion extraction by automatically annotated lexical resources.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th conference on Human language technology: challenges for computer science and linguistics (LTC’09),</booktitle>
<pages>500--511</pages>
<publisher>Springer-Verlag.</publisher>
<location>Poznan, Poland,</location>
<contexts>
<context position="4175" citStr="Esuli and Sebastiani (2011)" startWordPosition="632" endWordPosition="635">es 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and contextual valence shifters. Other works (Turney and Littman, 2003; Kamps et al., 2004) propose to use a term similarity measure which can be statistical (e.g., Mutual Information, LSA) or semantic (e.g., WordNet-based). Hybrid methods use both statistical and linguistic approaches. Esuli and Sebastiani (2011), which is the closest work to ours, propose to use annotated lexical resources to improve opinion extraction. The bag-of-word text representation is enriched by new tags (e.g. subjectivity, polarity). Then, an SVMbased system is used for opinion classification. 3 Our approach NB is a machine learning method that builds a classification model based only on the learning data which makes it highly dependent on this data. For example, in a sentiment analysis task, if the term actor appears more frequently within a negative context than in a positive one, it will be classified as negative while ac</context>
</contexts>
<marker>Esuli, Sebastiani, 2011</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. Enhancing opinion extraction by automatically annotated lexical resources. In Proceedings of the 4th conference on Human language technology: challenges for computer science and linguistics (LTC’09), pages 500–511, Poznan, Poland, 2011. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R Mckeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference of the European chapter of the Association for Computational Linguistics (EACL’97),</booktitle>
<pages>174--181</pages>
<publisher>ACL.</publisher>
<location>Madrid,</location>
<marker>Hatzivassiloglou, Mckeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R Mckeown. Predicting the Semantic Orientation of Adjectives. In Proceedings of the eighth conference of the European chapter of the Association for Computational Linguistics (EACL’97), pages 174–181, Madrid, Spain, 1997. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert J Mokken</author>
<author>Maarten de Rijke</author>
</authors>
<title>Using WordNet to measure semantic orientations of adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC-04),</booktitle>
<pages>1115--1118</pages>
<location>Lisbon, PT,</location>
<marker>Kamps, Marx, Mokken, de Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert J. Mokken, and Maarten de Rijke. Using WordNet to measure semantic orientations of adjectives. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC-04), pages 1115–1118, Lisbon, PT, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Kennedy</author>
<author>Diana Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="3794" citStr="Kennedy and Inkpen (2006)" startWordPosition="576" endWordPosition="579">presented by a bag of words. The model is then deployed to classify new texts. Pang et al. (2002) use machine learning methods (NB, SVM and MaxEnt) to detect sentiments on movie reviews. Pak and Paroubek (2010) use NB to 364 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and contextual valence shifters. Other works (Turney and Littman, 2003; Kamps et al., 2004) propose to use a term similarity measure which can be statistical (e.g., Mutual Information, LSA) or semantic (e.g., WordNet-based). Hybrid methods use both statistical and linguistic approaches. Esuli and Sebastiani (2011), which is the closest work to ours, propose to use annotated lexical resources to improve opinion extraction. The bag-of-word text representation is enriched by new tags (e.g. subjectivity, polarity). Then, an SVMbased</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>Alistair Kennedy and Diana Inkpen. Sentiment classification of movie reviews using contextual valence shifters. Computational Intelligence, 22(2):110–125, May 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From tweets to polls: Linking text sentiment to public opinion time series.</title>
<date>2010</date>
<booktitle>In Proceedings of the 4th International AAAI Conference on Weblogs and Social</booktitle>
<location>Media, Washington, DC, USA,</location>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. From tweets to polls: Linking text sentiment to public opinion time series. In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media, Washington, DC, USA, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a corpus for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>1320--1326</pages>
<publisher>ELRA.</publisher>
<location>Valletta, Malta,</location>
<contexts>
<context position="1846" citStr="Pak and Paroubek, 2010" startWordPosition="271" endWordPosition="274"> them a valuable source of information rather rich of subjective data. These data can be mined using sentiment analysis as a means to understand people’s feelings towards a political cause or what people are thinking about a product or a service. Recent works showed that Twitter sentiments can be correlated to box-office revenues (Asur and Huberman, 2010) or political polls (O’Connor et al., 2010). Machine learning methods, like Naive Bayes (NB) and Support Vector Machines (SVM), have been widely used in sentiment analysis (Pang et al., 1http://www.twitter.com/ 2http://www.facebook.com/ 2002; Pak and Paroubek, 2010). One major problem with these methods, and in particular NB, is that the model is built only on the learning data which can lead to overfitting. In this paper, we describe our approach that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter) (Wilson et al., 2013). Our approach consists of learning with both NB and prior knowledge. We show that our approach outperforms the classical NB method and gives competitive results compared to SVM while having less computational complexity. The remainder of this paper is organized as follows: prior works on sentiment analysis are disc</context>
<context position="3379" citStr="Pak and Paroubek (2010)" startWordPosition="520" endWordPosition="523">tive/objective), opinion mining (positive/negative/neutral), strength analysis, etc. Although the term “sentiment analysis” includes all these tasks, it often refers to opinion mining. Sentiment analysis methods can be categorized into machine learning, linguistic and hybrid methods. Machine learning methods are usually supervised. A model is built based on a learning dataset composed of annotated texts and represented by a bag of words. The model is then deployed to classify new texts. Pang et al. (2002) use machine learning methods (NB, SVM and MaxEnt) to detect sentiments on movie reviews. Pak and Paroubek (2010) use NB to 364 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and contextual valence shifters. Other works (Turney and Littman, 2003; Kamps et al., 2004) propose to use a term simil</context>
<context position="5903" citStr="Pak and Paroubek, 2010" startWordPosition="913" endWordPosition="916"> to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w� the presence, respectively absence, modality of a word w. A “term” stands, here, for any type of text features (smileys, n-grams). 3.1 Sentiment lexicon We represent the prior knowledge by a 2-class sentiment lexicon: a list of subjective terms (words, n-grams and smileys) manually annotated with two scores: positive (score,+) and negative (score,_). Each term has a score of 1 on a class polarity (we call it right class) and 0 on the other one (wrong class). For example, the wor</context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), pages 1320–1326, Valletta, Malta, 2010. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing (EMNLP’02),</booktitle>
<pages>79--86</pages>
<publisher>ACL,</publisher>
<contexts>
<context position="3266" citStr="Pang et al. (2002)" startWordPosition="501" endWordPosition="504"> feelings expressed explicitly or implicitly in a textual content. It concerns subjectivity analysis (subjective/objective), opinion mining (positive/negative/neutral), strength analysis, etc. Although the term “sentiment analysis” includes all these tasks, it often refers to opinion mining. Sentiment analysis methods can be categorized into machine learning, linguistic and hybrid methods. Machine learning methods are usually supervised. A model is built based on a learning dataset composed of annotated texts and represented by a bag of words. The model is then deployed to classify new texts. Pang et al. (2002) use machine learning methods (NB, SVM and MaxEnt) to detect sentiments on movie reviews. Pak and Paroubek (2010) use NB to 364 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and co</context>
<context position="5878" citStr="Pang et al., 2002" startWordPosition="909" endWordPosition="912">eady been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w� the presence, respectively absence, modality of a word w. A “term” stands, here, for any type of text features (smileys, n-grams). 3.1 Sentiment lexicon We represent the prior knowledge by a 2-class sentiment lexicon: a list of subjective terms (words, n-grams and smileys) manually annotated with two scores: positive (score,+) and negative (score,_). Each term has a score of 1 on a class polarity (we call it right class) and 0 on the other one (wrong cla</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing (EMNLP’02), pages 79–86. ACL, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL’04),</booktitle>
<pages>271--278</pages>
<publisher>ACL.</publisher>
<location>Barcelona, Catalonia,</location>
<contexts>
<context position="10409" citStr="Pang and Lee (2004)" startWordPosition="1719" endWordPosition="1722">ntiment lexicon For SemEval-2013 contest (Wilson et al., 2013), we have developed our own lexicon based on Liu’s opinion lexicon (Ding et al., 2008) and enriched with some “microblogging style” terms (e.g., luv, xox, gd) manually collected on the Urban Dictionary3. The whole lexicon contains 7720 English terms (words, 2-grams, 3-grams and smileys) where 2475 are positive and 5245 negative. 4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in addition to MR (English movie reviews of Pang and Lee (2004)). Concerning SMS, the classification is performed using the model learned on tweets (TW) in order to assess how it generalizes on SMS data. Note that our approach is adapted to binary classification but can be used for 3-way classification (which is the case of TW and SMS). We do this by adapting only positive and negative probabilities, neutral ones remain unchanged. Texts are preprocessed by removing stopwords, numerics, punctuation and terms that occur only once (to reduce vocabulary size and data sparseness). Texts are then stemmed using Porter stemmer (Porter, 1997). We also remove URLs </context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL’04), pages 271–278, Barcelona, Catalonia, Spain, 2004. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Mitchell</author>
</authors>
<title>Machine Learning.</title>
<date>1997</date>
<publisher>McGraw-Hill, Inc.,</publisher>
<location>New York, NY, USA, 1 edition,</location>
<contexts>
<context position="13784" citStr="Mitchell, 1997" startWordPosition="2284" endWordPosition="2285">R, TRA) and the data. Therefore, parameters must be fine-tuned for each dataset separately. 5.2 SemEval-2013 results For SemEval-2013 contest, we have enriched text representation by 2-grams and 3-grams and used A&amp;R method with: αc+ = αc� = 0.003, Qc+ = 0.04 and Qc� = 0.02. All of these parameters have been fine-tuned using the development data. We have also made an Information Gain-based feature 0.001 0.005 0.02 0.05 0.08 0.1 0.2 α 85 80 75 70 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Figure 2: Effect of the parameter α on a 2-way classification using methods: A&amp;R (top) and TRA (bottom) selection (Mitchell, 1997). Only the best 2000 terms are kept to which we have added terms of the lexicon. Under these conditions, our approach achieved the scores 62.55% on tweets (ranked 6th/35) and 53.63% on SMS (ranked 9th/28). Dataset Class Pecision Recall F-score positive 62.12 74.49 67.75 TW negative 46.23 75.54 57.36 neutral 76.74 44.27 56.15 positive 39.59 78.86 52.72 SMS negative 45.64 67.77 54.55 neutral 90.93 39.82 55.38 Figure 3: SemEval-2013 results (A&amp;R method) Regarding F-score of each class (Figure 3), our approach gave better results on the negative class (under-represented in the learning data) than </context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Thomas M. Mitchell. Machine Learning. McGraw-Hill, Inc., New York, NY, USA, 1 edition, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1997</date>
<booktitle>In Readings in information retrieval, number 3,</booktitle>
<pages>313--316</pages>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>San Francisco, CA, USA,</location>
<contexts>
<context position="10987" citStr="Porter, 1997" startWordPosition="1814" endWordPosition="1815">ovie reviews of Pang and Lee (2004)). Concerning SMS, the classification is performed using the model learned on tweets (TW) in order to assess how it generalizes on SMS data. Note that our approach is adapted to binary classification but can be used for 3-way classification (which is the case of TW and SMS). We do this by adapting only positive and negative probabilities, neutral ones remain unchanged. Texts are preprocessed by removing stopwords, numerics, punctuation and terms that occur only once (to reduce vocabulary size and data sparseness). Texts are then stemmed using Porter stemmer (Porter, 1997). We also remove URLs and Twitter keywords (via, RT) from tweets. 4.3 Tools As we compare our approach to SVM method, we have used SVMmulticlass (Crammer and Singer, 2002). For a compromise between processing time and performance, we set the trade-off parameter c to 4 on MR dataset and 20 on TW and SMS (based on empirical results). 5 Results and discussion In addition to the two proposed methods: Add &amp; Remove (A&amp;R) and Transfer (TRA), texts are classified using NB and SVM with two kernels: linear (SVM-L) and polynomial of degree 2 (SVM-P). All the scores given below correspond to the average 3</context>
</contexts>
<marker>Porter, 1997</marker>
<rawString>Martin F. Porter. An algorithm for suffix stripping. In Readings in information retrieval, number 3, pages 313–316. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="3930" citStr="Turney and Littman, 2003" startWordPosition="596" endWordPosition="599">nd MaxEnt) to detect sentiments on movie reviews. Pak and Paroubek (2010) use NB to 364 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 364–368, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and contextual valence shifters. Other works (Turney and Littman, 2003; Kamps et al., 2004) propose to use a term similarity measure which can be statistical (e.g., Mutual Information, LSA) or semantic (e.g., WordNet-based). Hybrid methods use both statistical and linguistic approaches. Esuli and Sebastiani (2011), which is the closest work to ours, propose to use annotated lexical resources to improve opinion extraction. The bag-of-word text representation is enriched by new tags (e.g. subjectivity, polarity). Then, an SVMbased system is used for opinion classification. 3 Our approach NB is a machine learning method that builds a classification model based only</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter D. Turney and Michael L. Littman. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Andrew K C Wong</author>
<author>Chung S Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="5765" citStr="Salton et al., 1975" startWordPosition="891" endWordPosition="894">oose, here, to represent it by a sentiment lexicon (a set of positive and negative terms). Several lexicons have already been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w� the presence, respectively absence, modality of a word w. A “term” stands, here, for any type of text features (smileys, n-grams). 3.1 Sentiment lexicon We represent the prior knowledge by a 2-class sentiment lexicon: a list of subjective terms (words, n-grams and smileys) manually annotated with two scores: positive (score,+) and negative (sc</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Gerard Salton, Andrew K. C. Wong, and Chung S. Yang. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT/EMNLP-2005),</booktitle>
<pages>347--354</pages>
<publisher>ACL.</publisher>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="5411" citStr="Wilson et al., 2005" startWordPosition="833" endWordPosition="836">. Moreover, NB tends sometimes to predict the class of majority (observed on learning data) which increases classification errors on unbalanced data. Our approach consists of incorporating prior knowledge into the NB model to make it less dependent on learning data. To be efficiently used, prior knowledge must be represented in a structured form. We choose, here, to represent it by a sentiment lexicon (a set of positive and negative terms). Several lexicons have already been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005), Liu’s opinion lexicon (Ding et al., 2008), SentiWordNet (Esuli and Sebastiani, 2006). We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by </context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT/EMNLP-2005), pages 347–354, Vancouver, British Columbia, Canada, 2005. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
</authors>
<title>SemEval-2013 Task 2: Sentiment Analysis in Twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation (SemEval’13),</booktitle>
<publisher>ACL.</publisher>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="2129" citStr="Wilson et al., 2013" startWordPosition="319" endWordPosition="322">ents can be correlated to box-office revenues (Asur and Huberman, 2010) or political polls (O’Connor et al., 2010). Machine learning methods, like Naive Bayes (NB) and Support Vector Machines (SVM), have been widely used in sentiment analysis (Pang et al., 1http://www.twitter.com/ 2http://www.facebook.com/ 2002; Pak and Paroubek, 2010). One major problem with these methods, and in particular NB, is that the model is built only on the learning data which can lead to overfitting. In this paper, we describe our approach that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter) (Wilson et al., 2013). Our approach consists of learning with both NB and prior knowledge. We show that our approach outperforms the classical NB method and gives competitive results compared to SVM while having less computational complexity. The remainder of this paper is organized as follows: prior works on sentiment analysis are discussed in Section 2. The proposed approach is detailed in Section 3. Then, experiments and results are given in Section 4 and 5. 2 Background Sentiment analysis is a text mining task which deals with the feelings expressed explicitly or implicitly in a textual content. It concerns su</context>
<context position="9852" citStr="Wilson et al., 2013" startWordPosition="1631" endWordPosition="1634">om c not containing w. max(w, c) = min{nb(w, ¯c), nb( ¯w, c)} (4) Finally, the number of occurrences actually transferred is a ratio αc of max(w, c) with 0 &lt; αc &lt; 1. Term probabilities are estimated as follows: 1 p(w|c)= nb(c)·[nb(w, c)+αc·scorec(w)·max(w, c) −αc · scored(w) · max(w, ¯c)] (5) Both methods, Add &amp; Remove and Transfer, consist of removing occurrences from the wrong class and adding occurrences to the right class with the difference that in Transfer, the number of added occurrences is exactly the number of removed ones. 4 Experiment 4.1 Sentiment lexicon For SemEval-2013 contest (Wilson et al., 2013), we have developed our own lexicon based on Liu’s opinion lexicon (Ding et al., 2008) and enriched with some “microblogging style” terms (e.g., luv, xox, gd) manually collected on the Urban Dictionary3. The whole lexicon contains 7720 English terms (words, 2-grams, 3-grams and smileys) where 2475 are positive and 5245 negative. 4.2 Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in addition to MR (English movie reviews of Pang and Lee (2004)). Concerning SMS, the classification is pe</context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Rosenthal, Stoyanov, Ritter, 2013</marker>
<rawString>Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter. SemEval-2013 Task 2: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Semantic Evaluation (SemEval’13), Atlanta, Georgia, USA, 2013. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>