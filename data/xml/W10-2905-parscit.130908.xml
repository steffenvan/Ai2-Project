<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.98821">
Identifying Patterns for Unsupervised Grammar Induction
</title>
<author confidence="0.713697">
Jes´us Santamaria
</author>
<affiliation confidence="0.3351105">
U. Nacional de Educaci´on a Distancia
NLP-IR Group, Madrid, Spain.
</affiliation>
<email confidence="0.69526">
jsant@lsi.uned.es
</email>
<note confidence="0.705815666666667">
Lourdes Araujo
U. Nacional de Educaci´on a Distancia
NLP-IR Group, Madrid, Spain.
</note>
<email confidence="0.890791">
lurdes@lsi.uned.es
</email>
<sectionHeader confidence="0.996322" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999872636363636">
This paper describes a new method for un-
supervised grammar induction based on
the automatic extraction of certain pat-
terns in the texts. Our starting hypoth-
esis is that there exist some classes of
words that function as separators, mark-
ing the beginning or the end of new con-
stituents. Among these separators we dis-
tinguish those which trigger new levels in
the parse tree. If we are able to detect these
separators we can follow a very simple
procedure to identify the constituents of a
sentence by taking the classes of words be-
tween separators. This paper is devoted to
describe the process that we have followed
to automatically identify the set of sepa-
rators from a corpus only annotated with
Part-of-Speech (POS) tags. The proposed
approach has allowed us to improve the re-
sults of previous proposals when parsing
sentences from the Wall Street Journal cor-
pus.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996775925926">
Most works dealing with Grammar Induction (GI)
are focused on Supervised Grammar Induction,
using a corpus of syntactically annotated sen-
tences, or treebank, as a reference to extract the
grammar. The existence of a treebank for the lan-
guage and for a particular type of texts from which
we want to extract the grammar is a great help to
GI, even taking into account the theoretical limi-
tations of GI, such as the fact that grammars can-
not be correctly identified from positive examples
alone (Gold, 1967). But the manual annotation
of thousands of sentences is a very expensive task
and thus there are many languages for which there
are not treebanks available. Even in languages for
which there is a treebank, it is usually composed
of a particular kind of texts (newspaper articles,
for example) and may not be appropriate for other
kind of texts, such as tales or poetry. These rea-
sons have led to the appearance of several works
focused on unsupervised GI.
Thanks to our knowledge of the language we
know that some classes of words are particularly
influential to determine the structure of a sentence.
For example, let us consider the tree in Figure 1,
for which the meaning of the POS tags appears in
Table 1. We can observe that the tag MD (Modal)
breaks the sentence into two parts. Analogously,
in the tree appearing in Figure 2 the POS tag VBZ
breaks the sentence. In both cases, we can see that
after the breaking tag, a new level appears in the
parse tree. A similar effect is observed for other
POS tags, such as VB in the tree of Figure 1 and
IN in the tree of Figure 2. We call these kind of
POS tags separators. There are also other POS
tags which are frequently the beginning or the end
of a constituent1. For example in the tree in Fig-
ure 1 we can find the sequences (DT NN) and (DT
JJ NN), which according to the parse tree are con-
stituents. In the tree in Figure 2 we find the se-
quence (DT NNP VBG NN). In both trees we can
also find sequences beginning with the tag NNP:
(NNP NNP) and (NNP CD) in the tree in Figure 1
and (NNP NNP), which appears twice, in the tree
in Figure 2. This suggests that there are classes
of words with a trend to be the beginning or the
end of constituents without giving rise to new lev-
els in the parse tree. We call these POS tags sub-
separators. These observations reflect some of our
intuitions, such as the fact that most sentences are
composed of a noun phrase and a verb phrase, be-
ing frequently the verb the beginning of the verbal
phrase, which usually leads to a new level of the
parse tree. We also know that determiners (DT)
are frequently the beginning of the noun phrases.
</bodyText>
<footnote confidence="0.8717415">
1Constituents are language units in which we can arrange
the structure of a sentence.
</footnote>
<page confidence="0.978776">
38
</page>
<note confidence="0.743166333333333">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 38–45,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
DT JJ NN
</note>
<figureCaption confidence="0.860708">
Figure 1: Parse tree for the sentence Pierre Vinken,
61 years old, will join the board as a nonexecutive
director Nov. 29. from the Penn Treebank
Figure 2: Parse tree for the sentence Mr. Vinken
is chairman ofElsevier N.V., the Dutch publishing
group. from the Penn Treebank
</figureCaption>
<bodyText confidence="0.999636045454545">
At this point we could either try to figure out
what is the set of tags which work as separators, or
to compute them from a parsed corpus for the con-
sidered language, provided it is available. How-
ever, because we do not want to rely on the exis-
tence of a treebank for the corresponding language
and type of texts we have done something differ-
ent: we have devised a statistical procedure to au-
tomatically capture the word classes which func-
tion as separators. In this way our approach can
be applied to most languages, and apart from pro-
viding a tool for extracting grammars and parsing
sentences, it can be useful to study the different
classes of words that work as separators in differ-
ent languages.
Our statistical mechanism to detect separators
is applied to a corpus of sentences annotated with
POS tags. This is not a strong requirement since
there are very accurate POS taggers (about 97%)
for many languages. The grammar that we obtain
does not specify the left-hand-side of the rules, but
only sequences of POS tags that are constituents.
</bodyText>
<table confidence="0.990894555555555">
CC Coordinating conjunction
CD Cardinal number
DT Determiner
EX Existential there
FW Foreign word
IN Preposition / subordinating conjunction
JJ Adjective
JJR Adjective, comparative
JJS Adjective, superlative
LS List item marker
MD Modal
NN Noun, singular or mass
NNS Noun, plural
NNP Proper noun, singular
NNPS Proper noun, plural
PDT Predeterminer
POS Possessive ending
PRP Personal pronoun
PP$ Possessive pronoun
RB Adverb.
RBR Adverb, comparative
RBS Adverb., superlative
RP Particle
SYM Symbol (mathematical or scientific)
TO To
UH Interjection
VB Verb, base form
VBD Verb, past tense
VBG Verb, gerund / present participle
VBN Verb, past participle
VBP Verb, non-3rd ps. sing. present
VBZ Verb, 3rd ps. sing. present
WDT wh-determiner
WP wh-pronoun
WP$ Possessive wh-pronoun
WRB wh-adverb
</table>
<tableCaption confidence="0.998082">
Table 1: Alphabetical list of part-of-speech tags
</tableCaption>
<bodyText confidence="0.993978272727273">
used in the Penn Treebank, the corpus used in our
experiments
At this point we have followed the Klein and Man-
ning (2005) setting for the problem, which allows
us to compare our results to theirs. As far as we
know these are the best results obtained so far for
unsupervised GI using a monolingual corpus. As
they do, we have used the Penn treebank (Mar-
cus et al., 1994) for our experiments, employing
the syntactic annotations that it provides for eval-
uation purposes only. Specifically, we have used
WSJ10, composed of 6842 sentences, which is the
subset of the Wall Street Journal section of the
Penn Treebank, containing only those sentences of
10 words or less after removing punctuation and
null elements, such as $, ”, etc.
The rest of the paper is organized as follows:
section 2 reviews some related works; section 3
describes the details of the proposal to automati-
cally extract the separators from a POS tagged cor-
pus; section 4 is devoted to describe the procedure
to find a parse tree using the separators; section
</bodyText>
<figure confidence="0.99848872">
NP-SBJ VP
NP
ADJP
MD VP
CD NNS DT NN IN NP NNP CD
S
JJ
NNP NNP
VB NP
NP-TMP
NP
PP-CLR
NN
IN NP
NNPNNP
DT NNPVBG NN
NP-SBJ
NNP NNP
PP
VP
VBZ NP-PRD
NP
S
NP
NP
</figure>
<page confidence="0.991072">
39
</page>
<listItem confidence="0.4044495">
5 presents and discusses the experimental results,
and section 6 draws the main conclusions of this
work.
2 State of the Art
</listItem>
<bodyText confidence="0.99994977027027">
A growing interest in unsupervised GI has been
observed recently with the appearance of several
works in the topic. Some of these works have fo-
cused on finding patterns of words (Solan et al.,
2005) more than syntactic structures. It has been
noted that the rules produced by GI can also be in-
terpreted semantically (David et al., 2003), where
a non-terminal describes interchangeable elements
which are instances of the same concepts.
Distributional approaches to unsupervised GI
exploit the principle of substitutability: con-
stituents of the same type may be exchanged with
one another without affecting the syntax of the
surrounding context. Distributional approaches to
grammar induction fall into two categories, de-
pending on their treatment of nested structure. The
first category covers Expectation-Maximization
(EM) systems (Dempster et al., 1977). These sys-
tems propose constituents based on analysis of the
text, and then select a non-contradictory combina-
tion of constituents for each sentence that maxi-
mizes a given metric, usually parsing probability.
One of the most successful proposals in this area
is the one by Klein and Manning (2005), which,
as mentioned before, starts from a corpus labelled
only with POS tags. The key idea of the model
proposed in this work is that constituents appear
in constituent contexts. However, the EM algo-
rithm presents some serious problems: it is very
slow (Lari and Young, 1990), and is easily trapped
in local maxima (Carroll and Charniak, 1992).
Alignment Based Learning (ABL) (van Zaanen
and Leeds, 2000) is the only EM system applied
directly to raw text. However, ABL is relatively
inefficient and has only been applied to small cor-
pora. Brooks (Brooks, 2006) reverses the notion
of distributional approaches: if we can identify
“surrounding context” by observation, we can hy-
pothesize that word sequences occurring in that
context will be constituents of the same type. He
describes a simplified model of distributional anal-
ysis (for raw test) which uses heuristics to reduce
the number of candidate constituents under con-
sideration. This is an interesting idea in spite that
Brook showed that the system was only capable of
learning a small subset of constituent structures in
a large test corpus.
The second category is that of incremental
learning systems. An incremental system analyzes
a corpus in a bottom-up fashion: each time a new
constituent type is found it is inserted into the cor-
pus to provide data for later learning. The EMILE
(Adriaans, 1999) and ADIOS (David et al., 2003)
systems are examples for this category, not yet
evaluated on large corpora.
Bilingual experiments have been also conducted
with the aim to exploit information from one lan-
guage to disambiguate another. Usually such a
setting requires a parallel corpus or another an-
notated data that ties the two languages. Co-
hen and Smith (2009) use the English and Chi-
nese treebanks, which are not parallel corpora, to
train parsers for both languages jointly. Their re-
sults shown that the performance on English im-
proved in the bilingual setting. Another related
work (Snyder et al., 2009) uses three corpora of
parallel text. Their approach is closer to the un-
supervised bilingual parsing model developed by
Kuhn (2004), which aims to improve monolingual
performance.
The approach considered in this work follows a
different direction, trying to identify certain pat-
terns that can determine the structure of the parse
trees.
</bodyText>
<sectionHeader confidence="0.950376" genericHeader="method">
3 Extracting Separators from the Corpus
</sectionHeader>
<bodyText confidence="0.999939">
To automatically extract the set of separators and
sub-separators from a corpus of POS tagged sen-
tences we start from some assumptions:
</bodyText>
<listItem confidence="0.980422875">
• The most frequent sequence (of any length)
of POS tags in the corpus is a constituent,
that we call safe constituent (sc). It is quite a
sensible assumption, since we can expect that
at least for the most frequent constituent the
number of occurrences overwhelms the num-
ber of sequences appearing by chance.
• We also assume that the POS tag on the left,
</listItem>
<bodyText confidence="0.614249888888889">
Lsc, and on the right, Rsc, of the safe con-
stituent are a kind of context for other se-
quences that play the same role. Accord-
ing to this, other extended sequences with
Lsc and Rsc at the ends but with other POS
tags inside are also considered constituents.
This assumption is somehow related to the
Klein and Manning’s (2005) idea underlying
their unsupervised GI proposal. According
</bodyText>
<page confidence="0.992503">
40
</page>
<bodyText confidence="0.999729166666667">
to them, constituents appear in constituent
contexts. Their model exploits the fact that
long constituents often have short, common
equivalents, which appear in similar contexts
and whose constituency as a grammar rule is
more easily found.
</bodyText>
<listItem confidence="0.990065631578947">
• According to the previous point, we use the
tag on the left (Lsc) and on the right (Rsc) of
the safe constituent as discriminant with re-
spect to which to study the behavior of each
POS tag. A POS tag E can have a bias to be
inside the safe constituent, to be outside the
safe constituent (separator), or not to have a
bias at all (sub-separator). We define the de-
termining side of a tag E, as the end tag, Lsc
or Rsc, of the sc with the greater difference
on the number of occurrences of E on both
sides of the end tag. For example, if the ra-
tio of occurrences of E on the left and on the
right of Lsc is smaller (they are more differ-
ent) than the ratio of E on the left and on the
right of Rsc, then Lsc is the determining side
of E, ds(E)2. Then:
– E is considered a separator in the fol-
lowing cases:
</listItem>
<bodyText confidence="0.981511181818182">
* if Lsc is the determining side for E
and E appears a 75% more often to
the left of Lsc than to the right (the
75% has been fixed after some esti-
mates described below), or
* if Rsc is the determining side for E
and E appears a 75% more often to
the right of Rsc than to the left.
– E is considered a sub-separator if the
following conditions hold:
* if Lsc is the determining side for E
and E appears a 75% less often to
the left of Lsc than to the right (the
ratios are very similar) , or
* if Rsc is the determining side for E
and E appears a 75% less often to
the right of Rsc than to the left.
– In the remaining cases E is considered
to be part of a constituent (the prefer-
ence is to be inside).
Let us introduce some notation to define more
formally the separators and sub-separators. Let
</bodyText>
<footnote confidence="0.876899">
2If the number of occurrences of E on any side of L3,
or R3, is zero, then we compare differences between occur-
rences instead of ratios.
</footnote>
<bodyText confidence="0.9659158">
#(E1, • • • , En) be the number of occurrences of
the sequence of tags (E1, • • • , En). We define a
predicate sim to denote the similarity between the
number of occurrences of a sequence of two tags
and the one with reverse order, as
</bodyText>
<equation confidence="0.9949676">
sim(E1, E2)) _
#(E1, E2) ) 0.75 if #(E1, E2) &lt;— #(E2, E1)
#(E2, E1) —
#(E2, E1) ) 0.75 if #(E2, E1) &lt;— #(E1, E2)
#(E1, E2) —
</equation>
<bodyText confidence="0.9833375">
Then a tag E is considered a separator if the
following predicate is true:
</bodyText>
<equation confidence="0.9308022">
sep(Lsc, E, Rsc) _
(sd(Lsc) h (#(E, Lsc) &gt; #(Lsc, E)h
—sim(E, Lsc)))V
(sd(Rsc) h (#(Rsc, E) &gt; #(E, Rsc) h —sim(E, Rsc))
. A tag is considered a sub-separator when the
following predicate is true:
subsep(Lsc, E, Rsc) _
(sd(Lsc) h sim(E, Lsc))V
(sd(Rsc) h sim(E, Rsc))
.
</equation>
<bodyText confidence="0.995941555555555">
We have computed the number of occurrences
of every sequence of POS tags in the corpus, find-
ing that the most frequent sequence of tags is
(DT,NN). This sequence, which is our safe con-
stituent, appears 2222 times in the considered cor-
pus WSJ10.
Applying our procedure to the corpus we have
obtained the following sets of separators and sub-
separators:
Separators MD, PRP, IN, RB, RBR,
CC, TO, VB, VBD, VBN,
VBZ, VBP, VBG, EX, LS,
RP, UH, WP, WRB, WDT
Sub-separators DT, PDT, POS, SYM, NN,
NNS, NNP, NNPS
For selecting a threshold value to discriminate
the preference of a POS tag to be inside or out-
side of a constituent we have studied the results
obtained for different threshold values greater than
50%. Table 2 shows the results. We can observe
all of them are very similar for all the thresholds,
as long as they are greater than 50%. Analyzing
the set of POS-tags that have been classified as
separators and sub-separators with each threshold
we have found that the only differences are that the
tag POS (Possessive ending), which is classified
as sub-separator using a threshold between 50%
</bodyText>
<page confidence="0.998727">
41
</page>
<bodyText confidence="0.99848025">
and 75%, is classified as separator using higher
thresholds, and the tag SYM (Symbol), which is
classified as sub-separator using a threshold be-
tween 50% and 75%, is classified neither as a sep-
arator nor as a sub-separator using higher thresh-
olds. We have adopted a threshold value of 75%
because higher values can be too restrictive, and in
fact provide worse results.
</bodyText>
<figure confidence="0.957401">
Similarity F1
55% 74.55
65% 74.55
75% 74.55
85% 72.24
95% 72.24
</figure>
<tableCaption confidence="0.719629">
Table 2: F-measure results obtained for different
</tableCaption>
<bodyText confidence="0.960371764705882">
values of the threshold used to classify the set of
POS-tags.
Sub-separators can be grouped to their right or
to their left, depending on the case. In order to
measure the bias of each of them for one direc-
tion or another we have compared the number of
occurrences of the most frequent sequence com-
posed of the sub-separator and a POS tag on the
right and on the left. We choose as preference di-
rection for a sub-separator the corresponding to
the most frequent sequence. Table 3 shows the
results obtained, the preference direction of each
sub-separator appearing in the last column. In the
case of NNP, for which the frequency of the most
frequent tag to the right and to the left are the
same, we have looked at the second most frequent
sequence to choose the grouping direction.
</bodyText>
<table confidence="0.992095555555556">
sub-sep left freq. right freq. D
DT (DT, NN)(2222) (IN,DT)(894) L
PDT (PDT,DT)(28) (NN,PDT)(14) L
POS (POS, NN)(169) (NNP, POS)(223) R
SYM (SYM, IN)(11) (NN,SYM)(4) L
NN (NN, IN)(892) (DT,NN)(2222) R
NNS (NNS, VBP)(591) (JJ,NNS)(797) R
NNP (NNP, NNP)(2127) (NNP,NNP)(2127) R
NNPS (NNPS, NNP)(42) (NNP,NNPS)(82) R
</table>
<tableCaption confidence="0.997927">
Table 3: Preference direction to which each sub-
</tableCaption>
<bodyText confidence="0.973715714285714">
separator clusters. The first column corresponds
to the sub-separator, the second one to the most
frequent sequence composed of the sub-separator
and a tag on its right, the third one to the most fre-
quent sequence of the sub-separator and a tag on
its left, and the last column to the resulting direc-
tion.
</bodyText>
<sectionHeader confidence="0.995274" genericHeader="method">
4 Identifying Constituents
</sectionHeader>
<bodyText confidence="0.999869333333333">
Once we have the sets of separators and sub-
separators the procedure to identify the con-
stituents of each sentence is as follows:
</bodyText>
<listItem confidence="0.791020043478261">
• We identify the separators in the sentence.
For example, if we consider the sentence:
CC DT NN IN NNP NNP POS NN VBZ
the separators are marked in boldface:
CC DT NN IN NNP NNP POS NN VBZ
• The next step is to split the sentence ac-
cording to the separators. The first separator
which is a verb, if any, is used to split the sen-
tence into two parts. Each separator can give
rise to two groups: one composed of the tag
sequence between the separator and the next
separator, and another one which includes the
separator and the POS tags up to the end of
the part of the sentence in which it appears
(usually sentences are divided into two parts
using the first separator which is a verb). In
our example, this mechanism leads to the fol-
lowing structure:
[[CC [DT NN] [IN [NNP NNP POS NN]]]
[VBZ]]
• Now it is the turn of the sub-separators (DT,
PDT, POS, SYM, NN, NNS, NNP, NNPS),
which are underlined in the sentence:
</listItem>
<sectionHeader confidence="0.332974" genericHeader="method">
[[CC [DT NN] [IN [NNP NNP POS NN]]]
</sectionHeader>
<bodyText confidence="0.774234363636364">
[VBZ]]
• Finally, each group of the sentence is split
according to the sub-separators. Each sub-
separator has been assigned a preference di-
rection to form the group with the next POS
tag. Looking at Table 3, which tells us the
direction in which each sub-separator forms
the group, we apply this step to our sentence
example, obtaining:
[[CC [DT NN] [IN [[NNP NNP POS] NN]]]
[VBZ]]
</bodyText>
<page confidence="0.997572">
42
</page>
<bodyText confidence="0.999907148148148">
The sub-separator DT is grouped with the
tags on its right, while NN is grouped with
the tags on its left, thus composing the group
(DT NN). When two or more sub-separators
appear in a sequence, they are grouped to-
gether in a unique constituent whenever they
have the same grouping direction. In our sen-
tence example this criterion leads to [NNP
NNP POS] instead of [NNP[NNP[POS]]]. A
constituent finishes if the next POS tag is a
separator or if it is a sub-separator that makes
groups towards the left. Since POS (Pos-
sessive ending) tends to be grouped with the
POS tag on its left, it is the end of the con-
stituent.
Figure 3 represents the obtained structure as a
parse tree. Figure 4 represents the correct parse
tree according to the Penn treebank. We can ob-
serve that both structures are very similar. The
method based on separators has been able to cap-
ture most of the constituent appearing in the parse
tree: (DT, NN), (NNP, NNP, POS), (NNP, NNP,
POS, NN), (IN, NNP, NNP, POS, NN). The differ-
ences between both trees come from our criterion
of splitting the sequence of tags into two subse-
quences using the first verb. This problem will be
tackled in the future in a more refined model.
</bodyText>
<sectionHeader confidence="0.444413" genericHeader="method">
NNP NNP POS
</sectionHeader>
<figureCaption confidence="0.894348666666667">
Figure 3: Parse tree for the sentence And the nose
on Mr. Courter’s face grows from the Penn tree-
bank (WSJ), obtained with our separators method.
</figureCaption>
<sectionHeader confidence="0.996612" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9985425">
Our proposal has been evaluated by comparing the
tree structures produced by the system to the gold-
standard trees produced by linguists, which can be
found in the Penn Treebank. Because we do not
assign class name to our constituents, i.e. a left
hand side symbol for the grammar rules, as the lin-
guists do in treebanks, the comparison ignores the
class labels, considering only groups of tags.
</bodyText>
<figure confidence="0.65381425">
VP
VBZ
NN
NNP NNP POS
</figure>
<figureCaption confidence="0.915546333333333">
Figure 4: Parse tree appearing in the Penn tree-
bank (WSJ) for the sentence And the nose on Mr.
Courter’s face grows.
</figureCaption>
<bodyText confidence="0.999975928571429">
The results presented in the work by Klein and
Manning (2005) have been our reference, since as
far we know they are the best ones obtained so far
for unsupervised GI. For the sake of comparison,
we have considered the same corpus and the same
measures. Accordingly, we performed the experi-
ments on the 6842 sentences3 of the WSJ10 selec-
tion from the Penn treebank Wall Street Journal
section.
In order to evaluate the quality of the obtained
grammar we have used the most common mea-
sures for parsing and grammar induction evalua-
tion: recall, precision, and their harmonic mean
(F-measure). They are defined assuming a bracket
representation of a parse tree.
Precision is given by the number of brackets
in the parse to evaluate which match those in the
correct tree and recall measures how many of the
brackets in the correct tree are in the parse. These
measures have counterparts for unlabeled trees,
the ones considered in this work – in which the
label assigned to each constituent is not checked.
Constituents which could not be wrong (those of
size one and those spanning the whole sentence)
have not been included in the measures.
The definitions of Unlabeled Precision (UP) and
Recall (UR) of a proposed corpus P = [Pi] against
a gold corpus G = [Gi] are:
</bodyText>
<equation confidence="0.8503076">
UP(P, G) = Ei |braitibrackets(Pc ets(GZ)
) |
Finally, UF (Unlabeled F-measure) is given by:
2 · UP(P, G) · UR(P, G)
UF = UP(P, G) + UR(P, G) .
</equation>
<footnote confidence="0.835233">
3More precisely sequences of POS tags
</footnote>
<figure confidence="0.998727523809524">
C
CC C
DT NN
C
VBZ
C
IN C
C
NN
UR(P, G) = Ei |brackets(Pi) ∩ brackets(Gi)
E
i |brackets(Gi)|
S
CC NP-SBJ
NP
DT NN
PP-LOC
IN NP
NP
,
.
</figure>
<page confidence="0.940152">
43
</page>
<figure confidence="0.998785777777778">
100
90
%
80
70
60
F-measure
1 2 3 4 5 6 7 8 9 10
Constituent size
</figure>
<figureCaption confidence="0.994742">
Figure 5: Results obtained per constituent size:
unlabeled recall, precision, and F-measure.
</figureCaption>
<bodyText confidence="0.98862325">
Figure 5 shows the results of unlabeled recall,
precision and F-measure obtained per constituent
size. We can observe that recall and precision, and
thus the corresponding F-measure, are quite sim-
ilar for every constituent size. This is important,
because obtaining a high F-measure thanks to a
very high recall but with a poor precision, is not
so useful. We can also observe that the best results
are obtained for short and long constituents, with
lower values for middle lengths, such as 5 and 6.
We believe that this is because intermediate size
constituents present more variability. Moreover,
for intermediate sizes, the composition of the con-
stituents is more dependent on sub-separators, for
which the statistical differences are less significant
than for separators.
</bodyText>
<figure confidence="0.937253625">
90
Separator approach
Klein-Manning approach
80
70
60
502 3 4 5 6 7 8 9
Constituent size
</figure>
<figureCaption confidence="0.857166333333333">
Figure 6: Comparison of the separator approach
and Klein and Manning’s approach per constituent
size.
</figureCaption>
<bodyText confidence="0.9997264">
We have compared our results to those obtained
by Klein and Manning (2005) for the same corpus.
Table 4 shows the obtained results for WSJ10. We
can observe that we have obtained more balanced
values of recall and precision, as well as a better
value for the F-measure. Thus the method pro-
posed in this work, that we expect to refine by
assigning different probabilities to separators and
sub-separators, depending on the context they ap-
pear in, provides a very promising approach.
</bodyText>
<table confidence="0.973469333333333">
UR UP OF
Separ. A. 77,63% 71,71% 74,55%
KM 80.2% 63.8% 71.1%
</table>
<tableCaption confidence="0.997254">
Table 4: Results (unlabeled recall, precision, and
</tableCaption>
<bodyText confidence="0.9826099">
F-measure), obtained with the separator approach
(first row) and with the Klein and Manning ap-
proach (second row) for the WSJ10 corpus.
Figure 6 compares the F-measure for the two
approaches by constituents length. We can ob-
serve that the separator approach obtains better re-
sults for all the lengths. The figure also shows that
the results per constituent length follow the same
trend in both approaches, thus reflecting that the
difficulty for middle length constituents is greater.
</bodyText>
<sectionHeader confidence="0.999604" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999997705882353">
We have proposed a novel approach for unsuper-
vised grammar induction which is based on iden-
tifying certain POS tags that very often divide the
sentences in particular manners. These separators
are obtained from POS tagged texts, thus making
the model valid for many languages. The con-
stituents corresponding to a sentence are found by
means of a simple procedure based on the sepa-
rators. This simple method has allowed us to im-
prove the results of previous proposals.
We are currently working in defining a more re-
fined statistical model which takes into account
the probability of a tag to be a separator or sub-
separator, depending on its context. We plan to
apply a similar study to other languages, in order
to study the different classes of words that func-
tion as separator in each of them.
</bodyText>
<sectionHeader confidence="0.998712" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999218166666667">
This paper has been funded in part by the Span-
ish MICINN project QEAVis-Catiex (Spanish
Ministerio de Educaci´on y Ciencia - TIN2007-
67581), as well as by the Regional Government of
Madrid under the Research Network MA2VICMR
(S2009/TIC-1542).
</bodyText>
<figure confidence="0.799549">
Recall
Precision
F-measure
</figure>
<page confidence="0.995085">
44
</page>
<sectionHeader confidence="0.998169" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998836338461539">
Pieter Adriaans. 1999. Learning Shallow Context-Free
Languages under Simple Distributions. Technical
Report, Institute for Logic, Language, and Compu-
tation, Amsterdam.
David J. Brooks. 2006. Unsupervised grammar in-
duction by distribution and attachment. In CoNLL-X
’06: Proceedings of the Tenth Conference on Com-
putational Natural Language Learning, pages 117–
124. Association for Computational Linguistics.
Glenn Carroll and Eugene Charniak. 1992. Two exper-
iments on learning probabilistic dependency gram-
mars from corpora. In Working Notes of the Work-
shop Statistically-Based NLP Techniques, pages 1–
13. AAAI.
Shay B. Cohen and Noah A. Smith. 2009. Shared
logistic normal distributions for soft parameter ty-
ing in unsupervised grammar induction. In NAACL
’09: Proceedings of Human Language Technolo-
gies: The 2009 Annual Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 74–82. Association for
Computational Linguistics.
Zach Solan David, David Horn, and Shimon Edelman.
2003. Unsupervised efficient learning and represen-
tation of language structure. In Proc. 25th Confer-
ence of the Cognitive Science Society, pages 2577–
3596. Erlbaum.
A. Dempster, N. Laird, and D. Rubin. 1977. Max-
imum likelihood from incomplete data via the EM
algorithm. Royal statistical Society B, 39:1–38.
E. Mark Gold. 1967. Language identification in the
limit. Information and Control, 10(5):447–474.
Dan Klein and Christopher D. Manning. 2005. Nat-
ural language grammar induction with a genera-
tive constituent-context model. Pattern Recognition,
38(9):1407–1419.
Jonas Kuhn. 2004. Experiments in parallel-text based
grammar induction. In ACL ’04: Proceedings of the
42nd Annual Meeting on Association for Computa-
tional Linguistics, page 470. Association for Com-
putational Linguistics.
K. Lari and S. J. Young. 1990. The estimation of
stochastic context-free grammars using the inside-
outside algorithm. Computer Speech and Language,
4:35–56.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of english: The penn treebank. Computa-
tional Linguistics, 19(2):313–330.
Benjamin Snyder, Tahira Naseem, and Regina Barzi-
lay. 2009. Unsupervised multilingual grammar in-
duction. In ACL-IJCNLP ’09: Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 1, pages 73–81. Association for Computational
Linguistics.
Zach Solan, David Horn, Eytan Ruppin, and Shi-
mon Edelman. 2005. Unsupervised learning of
natural languages. Proceedings of the National
Academy of Sciences of the United States of Amer-
ica, 102(33):11629–11634.
Menno van Zaanen and Ls Jt Leeds. 2000. Learning
structure using alignment based learning. In Univer-
sities of Brighton and Sussex, pages 75–82.
</reference>
<page confidence="0.999385">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.372384">
<title confidence="0.999792">Identifying Patterns for Unsupervised Grammar Induction</title>
<author confidence="0.87296">Jes´us</author>
<affiliation confidence="0.860975">U. Nacional de Educaci´on a NLP-IR Group, Madrid,</affiliation>
<email confidence="0.887218">jsant@lsi.uned.es</email>
<affiliation confidence="0.875764333333333">Lourdes U. Nacional de Educaci´on a NLP-IR Group, Madrid,</affiliation>
<email confidence="0.98886">lurdes@lsi.uned.es</email>
<abstract confidence="0.988832217391304">This paper describes a new method for unsupervised grammar induction based on the automatic extraction of certain patterns in the texts. Our starting hypothesis is that there exist some classes of words that function as separators, marking the beginning or the end of new constituents. Among these separators we distinguish those which trigger new levels in the parse tree. If we are able to detect these separators we can follow a very simple procedure to identify the constituents of a sentence by taking the classes of words between separators. This paper is devoted to describe the process that we have followed to automatically identify the set of separators from a corpus only annotated with Part-of-Speech (POS) tags. The proposed approach has allowed us to improve the results of previous proposals when parsing sentences from the Wall Street Journal corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pieter Adriaans</author>
</authors>
<title>Learning Shallow Context-Free Languages under Simple Distributions.</title>
<date>1999</date>
<tech>Technical Report,</tech>
<institution>Institute for Logic, Language, and Computation,</institution>
<location>Amsterdam.</location>
<contexts>
<context position="10063" citStr="Adriaans, 1999" startWordPosition="1715" endWordPosition="1716">ituents of the same type. He describes a simplified model of distributional analysis (for raw test) which uses heuristics to reduce the number of candidate constituents under consideration. This is an interesting idea in spite that Brook showed that the system was only capable of learning a small subset of constituent structures in a large test corpus. The second category is that of incremental learning systems. An incremental system analyzes a corpus in a bottom-up fashion: each time a new constituent type is found it is inserted into the corpus to provide data for later learning. The EMILE (Adriaans, 1999) and ADIOS (David et al., 2003) systems are examples for this category, not yet evaluated on large corpora. Bilingual experiments have been also conducted with the aim to exploit information from one language to disambiguate another. Usually such a setting requires a parallel corpus or another annotated data that ties the two languages. Cohen and Smith (2009) use the English and Chinese treebanks, which are not parallel corpora, to train parsers for both languages jointly. Their results shown that the performance on English improved in the bilingual setting. Another related work (Snyder et al.</context>
</contexts>
<marker>Adriaans, 1999</marker>
<rawString>Pieter Adriaans. 1999. Learning Shallow Context-Free Languages under Simple Distributions. Technical Report, Institute for Logic, Language, and Computation, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Brooks</author>
</authors>
<title>Unsupervised grammar induction by distribution and attachment.</title>
<date>2006</date>
<booktitle>In CoNLL-X ’06: Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>117--124</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9262" citStr="Brooks, 2006" startWordPosition="1585" endWordPosition="1586">n this area is the one by Klein and Manning (2005), which, as mentioned before, starts from a corpus labelled only with POS tags. The key idea of the model proposed in this work is that constituents appear in constituent contexts. However, the EM algorithm presents some serious problems: it is very slow (Lari and Young, 1990), and is easily trapped in local maxima (Carroll and Charniak, 1992). Alignment Based Learning (ABL) (van Zaanen and Leeds, 2000) is the only EM system applied directly to raw text. However, ABL is relatively inefficient and has only been applied to small corpora. Brooks (Brooks, 2006) reverses the notion of distributional approaches: if we can identify “surrounding context” by observation, we can hypothesize that word sequences occurring in that context will be constituents of the same type. He describes a simplified model of distributional analysis (for raw test) which uses heuristics to reduce the number of candidate constituents under consideration. This is an interesting idea in spite that Brook showed that the system was only capable of learning a small subset of constituent structures in a large test corpus. The second category is that of incremental learning systems</context>
</contexts>
<marker>Brooks, 2006</marker>
<rawString>David J. Brooks. 2006. Unsupervised grammar induction by distribution and attachment. In CoNLL-X ’06: Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 117– 124. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Eugene Charniak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Working Notes of the Workshop Statistically-Based NLP Techniques,</booktitle>
<pages>1--13</pages>
<publisher>AAAI.</publisher>
<contexts>
<context position="9044" citStr="Carroll and Charniak, 1992" startWordPosition="1547" endWordPosition="1550">propose constituents based on analysis of the text, and then select a non-contradictory combination of constituents for each sentence that maximizes a given metric, usually parsing probability. One of the most successful proposals in this area is the one by Klein and Manning (2005), which, as mentioned before, starts from a corpus labelled only with POS tags. The key idea of the model proposed in this work is that constituents appear in constituent contexts. However, the EM algorithm presents some serious problems: it is very slow (Lari and Young, 1990), and is easily trapped in local maxima (Carroll and Charniak, 1992). Alignment Based Learning (ABL) (van Zaanen and Leeds, 2000) is the only EM system applied directly to raw text. However, ABL is relatively inefficient and has only been applied to small corpora. Brooks (Brooks, 2006) reverses the notion of distributional approaches: if we can identify “surrounding context” by observation, we can hypothesize that word sequences occurring in that context will be constituents of the same type. He describes a simplified model of distributional analysis (for raw test) which uses heuristics to reduce the number of candidate constituents under consideration. This i</context>
</contexts>
<marker>Carroll, Charniak, 1992</marker>
<rawString>Glenn Carroll and Eugene Charniak. 1992. Two experiments on learning probabilistic dependency grammars from corpora. In Working Notes of the Workshop Statistically-Based NLP Techniques, pages 1– 13. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In NAACL ’09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>74--82</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10424" citStr="Cohen and Smith (2009)" startWordPosition="1772" endWordPosition="1776"> The second category is that of incremental learning systems. An incremental system analyzes a corpus in a bottom-up fashion: each time a new constituent type is found it is inserted into the corpus to provide data for later learning. The EMILE (Adriaans, 1999) and ADIOS (David et al., 2003) systems are examples for this category, not yet evaluated on large corpora. Bilingual experiments have been also conducted with the aim to exploit information from one language to disambiguate another. Usually such a setting requires a parallel corpus or another annotated data that ties the two languages. Cohen and Smith (2009) use the English and Chinese treebanks, which are not parallel corpora, to train parsers for both languages jointly. Their results shown that the performance on English improved in the bilingual setting. Another related work (Snyder et al., 2009) uses three corpora of parallel text. Their approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. The approach considered in this work follows a different direction, trying to identify certain patterns that can determine the structure of the parse trees. 3 Extracting Sepa</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In NAACL ’09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 74–82. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zach Solan David</author>
<author>David Horn</author>
<author>Shimon Edelman</author>
</authors>
<title>Unsupervised efficient learning and representation of language structure.</title>
<date>2003</date>
<booktitle>In Proc. 25th Conference of the Cognitive Science Society,</booktitle>
<pages>2577--3596</pages>
<publisher>Erlbaum.</publisher>
<contexts>
<context position="7882" citStr="David et al., 2003" startWordPosition="1369" endWordPosition="1372">SBJ VP NP ADJP MD VP CD NNS DT NN IN NP NNP CD S JJ NNP NNP VB NP NP-TMP NP PP-CLR NN IN NP NNPNNP DT NNPVBG NN NP-SBJ NNP NNP PP VP VBZ NP-PRD NP S NP NP 39 5 presents and discusses the experimental results, and section 6 draws the main conclusions of this work. 2 State of the Art A growing interest in unsupervised GI has been observed recently with the appearance of several works in the topic. Some of these works have focused on finding patterns of words (Solan et al., 2005) more than syntactic structures. It has been noted that the rules produced by GI can also be interpreted semantically (David et al., 2003), where a non-terminal describes interchangeable elements which are instances of the same concepts. Distributional approaches to unsupervised GI exploit the principle of substitutability: constituents of the same type may be exchanged with one another without affecting the syntax of the surrounding context. Distributional approaches to grammar induction fall into two categories, depending on their treatment of nested structure. The first category covers Expectation-Maximization (EM) systems (Dempster et al., 1977). These systems propose constituents based on analysis of the text, and then sele</context>
<context position="10094" citStr="David et al., 2003" startWordPosition="1719" endWordPosition="1722">e describes a simplified model of distributional analysis (for raw test) which uses heuristics to reduce the number of candidate constituents under consideration. This is an interesting idea in spite that Brook showed that the system was only capable of learning a small subset of constituent structures in a large test corpus. The second category is that of incremental learning systems. An incremental system analyzes a corpus in a bottom-up fashion: each time a new constituent type is found it is inserted into the corpus to provide data for later learning. The EMILE (Adriaans, 1999) and ADIOS (David et al., 2003) systems are examples for this category, not yet evaluated on large corpora. Bilingual experiments have been also conducted with the aim to exploit information from one language to disambiguate another. Usually such a setting requires a parallel corpus or another annotated data that ties the two languages. Cohen and Smith (2009) use the English and Chinese treebanks, which are not parallel corpora, to train parsers for both languages jointly. Their results shown that the performance on English improved in the bilingual setting. Another related work (Snyder et al., 2009) uses three corpora of p</context>
</contexts>
<marker>David, Horn, Edelman, 2003</marker>
<rawString>Zach Solan David, David Horn, and Shimon Edelman. 2003. Unsupervised efficient learning and representation of language structure. In Proc. 25th Conference of the Cognitive Science Society, pages 2577– 3596. Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Royal statistical Society B,</journal>
<pages>39--1</pages>
<contexts>
<context position="8401" citStr="Dempster et al., 1977" startWordPosition="1440" endWordPosition="1443"> has been noted that the rules produced by GI can also be interpreted semantically (David et al., 2003), where a non-terminal describes interchangeable elements which are instances of the same concepts. Distributional approaches to unsupervised GI exploit the principle of substitutability: constituents of the same type may be exchanged with one another without affecting the syntax of the surrounding context. Distributional approaches to grammar induction fall into two categories, depending on their treatment of nested structure. The first category covers Expectation-Maximization (EM) systems (Dempster et al., 1977). These systems propose constituents based on analysis of the text, and then select a non-contradictory combination of constituents for each sentence that maximizes a given metric, usually parsing probability. One of the most successful proposals in this area is the one by Klein and Manning (2005), which, as mentioned before, starts from a corpus labelled only with POS tags. The key idea of the model proposed in this work is that constituents appear in constituent contexts. However, the EM algorithm presents some serious problems: it is very slow (Lari and Young, 1990), and is easily trapped i</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. Dempster, N. Laird, and D. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Royal statistical Society B, 39:1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mark Gold</author>
</authors>
<title>Language identification in the limit.</title>
<date>1967</date>
<journal>Information and Control,</journal>
<volume>10</volume>
<issue>5</issue>
<contexts>
<context position="1656" citStr="Gold, 1967" startWordPosition="269" endWordPosition="270"> results of previous proposals when parsing sentences from the Wall Street Journal corpus. 1 Introduction Most works dealing with Grammar Induction (GI) are focused on Supervised Grammar Induction, using a corpus of syntactically annotated sentences, or treebank, as a reference to extract the grammar. The existence of a treebank for the language and for a particular type of texts from which we want to extract the grammar is a great help to GI, even taking into account the theoretical limitations of GI, such as the fact that grammars cannot be correctly identified from positive examples alone (Gold, 1967). But the manual annotation of thousands of sentences is a very expensive task and thus there are many languages for which there are not treebanks available. Even in languages for which there is a treebank, it is usually composed of a particular kind of texts (newspaper articles, for example) and may not be appropriate for other kind of texts, such as tales or poetry. These reasons have led to the appearance of several works focused on unsupervised GI. Thanks to our knowledge of the language we know that some classes of words are particularly influential to determine the structure of a sentenc</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>E. Mark Gold. 1967. Language identification in the limit. Information and Control, 10(5):447–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Natural language grammar induction with a generative constituent-context model.</title>
<date>2005</date>
<journal>Pattern Recognition,</journal>
<volume>38</volume>
<issue>9</issue>
<contexts>
<context position="6353" citStr="Klein and Manning (2005)" startWordPosition="1088" endWordPosition="1092">terminer POS Possessive ending PRP Personal pronoun PP$ Possessive pronoun RB Adverb. RBR Adverb, comparative RBS Adverb., superlative RP Particle SYM Symbol (mathematical or scientific) TO To UH Interjection VB Verb, base form VBD Verb, past tense VBG Verb, gerund / present participle VBN Verb, past participle VBP Verb, non-3rd ps. sing. present VBZ Verb, 3rd ps. sing. present WDT wh-determiner WP wh-pronoun WP$ Possessive wh-pronoun WRB wh-adverb Table 1: Alphabetical list of part-of-speech tags used in the Penn Treebank, the corpus used in our experiments At this point we have followed the Klein and Manning (2005) setting for the problem, which allows us to compare our results to theirs. As far as we know these are the best results obtained so far for unsupervised GI using a monolingual corpus. As they do, we have used the Penn treebank (Marcus et al., 1994) for our experiments, employing the syntactic annotations that it provides for evaluation purposes only. Specifically, we have used WSJ10, composed of 6842 sentences, which is the subset of the Wall Street Journal section of the Penn Treebank, containing only those sentences of 10 words or less after removing punctuation and null elements, such as $</context>
<context position="8699" citStr="Klein and Manning (2005)" startWordPosition="1489" endWordPosition="1492">ituents of the same type may be exchanged with one another without affecting the syntax of the surrounding context. Distributional approaches to grammar induction fall into two categories, depending on their treatment of nested structure. The first category covers Expectation-Maximization (EM) systems (Dempster et al., 1977). These systems propose constituents based on analysis of the text, and then select a non-contradictory combination of constituents for each sentence that maximizes a given metric, usually parsing probability. One of the most successful proposals in this area is the one by Klein and Manning (2005), which, as mentioned before, starts from a corpus labelled only with POS tags. The key idea of the model proposed in this work is that constituents appear in constituent contexts. However, the EM algorithm presents some serious problems: it is very slow (Lari and Young, 1990), and is easily trapped in local maxima (Carroll and Charniak, 1992). Alignment Based Learning (ABL) (van Zaanen and Leeds, 2000) is the only EM system applied directly to raw text. However, ABL is relatively inefficient and has only been applied to small corpora. Brooks (Brooks, 2006) reverses the notion of distributiona</context>
<context position="21097" citStr="Klein and Manning (2005)" startWordPosition="3719" endWordPosition="3722">arators method. 5 Evaluation Our proposal has been evaluated by comparing the tree structures produced by the system to the goldstandard trees produced by linguists, which can be found in the Penn Treebank. Because we do not assign class name to our constituents, i.e. a left hand side symbol for the grammar rules, as the linguists do in treebanks, the comparison ignores the class labels, considering only groups of tags. VP VBZ NN NNP NNP POS Figure 4: Parse tree appearing in the Penn treebank (WSJ) for the sentence And the nose on Mr. Courter’s face grows. The results presented in the work by Klein and Manning (2005) have been our reference, since as far we know they are the best ones obtained so far for unsupervised GI. For the sake of comparison, we have considered the same corpus and the same measures. Accordingly, we performed the experiments on the 6842 sentences3 of the WSJ10 selection from the Penn treebank Wall Street Journal section. In order to evaluate the quality of the obtained grammar we have used the most common measures for parsing and grammar induction evaluation: recall, precision, and their harmonic mean (F-measure). They are defined assuming a bracket representation of a parse tree. Pr</context>
<context position="23819" citStr="Klein and Manning (2005)" startWordPosition="4198" endWordPosition="4201">hort and long constituents, with lower values for middle lengths, such as 5 and 6. We believe that this is because intermediate size constituents present more variability. Moreover, for intermediate sizes, the composition of the constituents is more dependent on sub-separators, for which the statistical differences are less significant than for separators. 90 Separator approach Klein-Manning approach 80 70 60 502 3 4 5 6 7 8 9 Constituent size Figure 6: Comparison of the separator approach and Klein and Manning’s approach per constituent size. We have compared our results to those obtained by Klein and Manning (2005) for the same corpus. Table 4 shows the obtained results for WSJ10. We can observe that we have obtained more balanced values of recall and precision, as well as a better value for the F-measure. Thus the method proposed in this work, that we expect to refine by assigning different probabilities to separators and sub-separators, depending on the context they appear in, provides a very promising approach. UR UP OF Separ. A. 77,63% 71,71% 74,55% KM 80.2% 63.8% 71.1% Table 4: Results (unlabeled recall, precision, and F-measure), obtained with the separator approach (first row) and with the Klein </context>
</contexts>
<marker>Klein, Manning, 2005</marker>
<rawString>Dan Klein and Christopher D. Manning. 2005. Natural language grammar induction with a generative constituent-context model. Pattern Recognition, 38(9):1407–1419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Kuhn</author>
</authors>
<title>Experiments in parallel-text based grammar induction.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>470</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10801" citStr="Kuhn (2004)" startWordPosition="1837" endWordPosition="1838">ts have been also conducted with the aim to exploit information from one language to disambiguate another. Usually such a setting requires a parallel corpus or another annotated data that ties the two languages. Cohen and Smith (2009) use the English and Chinese treebanks, which are not parallel corpora, to train parsers for both languages jointly. Their results shown that the performance on English improved in the bilingual setting. Another related work (Snyder et al., 2009) uses three corpora of parallel text. Their approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. The approach considered in this work follows a different direction, trying to identify certain patterns that can determine the structure of the parse trees. 3 Extracting Separators from the Corpus To automatically extract the set of separators and sub-separators from a corpus of POS tagged sentences we start from some assumptions: • The most frequent sequence (of any length) of POS tags in the corpus is a constituent, that we call safe constituent (sc). It is quite a sensible assumption, since we can expect that at least for the most frequent co</context>
</contexts>
<marker>Kuhn, 2004</marker>
<rawString>Jonas Kuhn. 2004. Experiments in parallel-text based grammar induction. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 470. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lari</author>
<author>S J Young</author>
</authors>
<title>The estimation of stochastic context-free grammars using the insideoutside algorithm. Computer Speech and Language,</title>
<date>1990</date>
<pages>4--35</pages>
<contexts>
<context position="8976" citStr="Lari and Young, 1990" startWordPosition="1536" endWordPosition="1539">imization (EM) systems (Dempster et al., 1977). These systems propose constituents based on analysis of the text, and then select a non-contradictory combination of constituents for each sentence that maximizes a given metric, usually parsing probability. One of the most successful proposals in this area is the one by Klein and Manning (2005), which, as mentioned before, starts from a corpus labelled only with POS tags. The key idea of the model proposed in this work is that constituents appear in constituent contexts. However, the EM algorithm presents some serious problems: it is very slow (Lari and Young, 1990), and is easily trapped in local maxima (Carroll and Charniak, 1992). Alignment Based Learning (ABL) (van Zaanen and Leeds, 2000) is the only EM system applied directly to raw text. However, ABL is relatively inefficient and has only been applied to small corpora. Brooks (Brooks, 2006) reverses the notion of distributional approaches: if we can identify “surrounding context” by observation, we can hypothesize that word sequences occurring in that context will be constituents of the same type. He describes a simplified model of distributional analysis (for raw test) which uses heuristics to red</context>
</contexts>
<marker>Lari, Young, 1990</marker>
<rawString>K. Lari and S. J. Young. 1990. The estimation of stochastic context-free grammars using the insideoutside algorithm. Computer Speech and Language, 4:35–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="6602" citStr="Marcus et al., 1994" startWordPosition="1135" endWordPosition="1139">Verb, gerund / present participle VBN Verb, past participle VBP Verb, non-3rd ps. sing. present VBZ Verb, 3rd ps. sing. present WDT wh-determiner WP wh-pronoun WP$ Possessive wh-pronoun WRB wh-adverb Table 1: Alphabetical list of part-of-speech tags used in the Penn Treebank, the corpus used in our experiments At this point we have followed the Klein and Manning (2005) setting for the problem, which allows us to compare our results to theirs. As far as we know these are the best results obtained so far for unsupervised GI using a monolingual corpus. As they do, we have used the Penn treebank (Marcus et al., 1994) for our experiments, employing the syntactic annotations that it provides for evaluation purposes only. Specifically, we have used WSJ10, composed of 6842 sentences, which is the subset of the Wall Street Journal section of the Penn Treebank, containing only those sentences of 10 words or less after removing punctuation and null elements, such as $, ”, etc. The rest of the paper is organized as follows: section 2 reviews some related works; section 3 describes the details of the proposal to automatically extract the separators from a POS tagged corpus; section 4 is devoted to describe the pro</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual grammar induction.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>1</volume>
<pages>73--81</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10670" citStr="Snyder et al., 2009" startWordPosition="1814" endWordPosition="1817">riaans, 1999) and ADIOS (David et al., 2003) systems are examples for this category, not yet evaluated on large corpora. Bilingual experiments have been also conducted with the aim to exploit information from one language to disambiguate another. Usually such a setting requires a parallel corpus or another annotated data that ties the two languages. Cohen and Smith (2009) use the English and Chinese treebanks, which are not parallel corpora, to train parsers for both languages jointly. Their results shown that the performance on English improved in the bilingual setting. Another related work (Snyder et al., 2009) uses three corpora of parallel text. Their approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. The approach considered in this work follows a different direction, trying to identify certain patterns that can determine the structure of the parse trees. 3 Extracting Separators from the Corpus To automatically extract the set of separators and sub-separators from a corpus of POS tagged sentences we start from some assumptions: • The most frequent sequence (of any length) of POS tags in the corpus is a constituent</context>
</contexts>
<marker>Snyder, Naseem, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, and Regina Barzilay. 2009. Unsupervised multilingual grammar induction. In ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, pages 73–81. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zach Solan</author>
<author>David Horn</author>
<author>Eytan Ruppin</author>
<author>Shimon Edelman</author>
</authors>
<title>Unsupervised learning of natural languages.</title>
<date>2005</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America,</booktitle>
<pages>102--33</pages>
<contexts>
<context position="7744" citStr="Solan et al., 2005" startWordPosition="1345" endWordPosition="1348">separators from a POS tagged corpus; section 4 is devoted to describe the procedure to find a parse tree using the separators; section NP-SBJ VP NP ADJP MD VP CD NNS DT NN IN NP NNP CD S JJ NNP NNP VB NP NP-TMP NP PP-CLR NN IN NP NNPNNP DT NNPVBG NN NP-SBJ NNP NNP PP VP VBZ NP-PRD NP S NP NP 39 5 presents and discusses the experimental results, and section 6 draws the main conclusions of this work. 2 State of the Art A growing interest in unsupervised GI has been observed recently with the appearance of several works in the topic. Some of these works have focused on finding patterns of words (Solan et al., 2005) more than syntactic structures. It has been noted that the rules produced by GI can also be interpreted semantically (David et al., 2003), where a non-terminal describes interchangeable elements which are instances of the same concepts. Distributional approaches to unsupervised GI exploit the principle of substitutability: constituents of the same type may be exchanged with one another without affecting the syntax of the surrounding context. Distributional approaches to grammar induction fall into two categories, depending on their treatment of nested structure. The first category covers Expe</context>
</contexts>
<marker>Solan, Horn, Ruppin, Edelman, 2005</marker>
<rawString>Zach Solan, David Horn, Eytan Ruppin, and Shimon Edelman. 2005. Unsupervised learning of natural languages. Proceedings of the National Academy of Sciences of the United States of America, 102(33):11629–11634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Menno van Zaanen</author>
<author>Ls Jt Leeds</author>
</authors>
<title>Learning structure using alignment based learning.</title>
<date>2000</date>
<booktitle>In Universities of Brighton and Sussex,</booktitle>
<pages>75--82</pages>
<marker>van Zaanen, Leeds, 2000</marker>
<rawString>Menno van Zaanen and Ls Jt Leeds. 2000. Learning structure using alignment based learning. In Universities of Brighton and Sussex, pages 75–82.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>