<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.9979765">
Umigon: sentiment analysis for tweets
based on lexicons and heuristics
</title>
<author confidence="0.987891">
Clement Levallois
</author>
<affiliation confidence="0.767766">
Department of Marketing Management, Rotterda School of Management
and Erasmus Studio, Erasmus University Rotterdam
The Netherlands.
</affiliation>
<email confidence="0.98506">
clevallois@rsm.nl
</email>
<sectionHeader confidence="0.991858" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997363">
Umigon is developed since December 2012 as a
web application providing a service of sentiment
detection in tweets. It has been designed to be
fast and scalable. Umigon also provides
indications for additional semantic features
present in the tweets, such as time indications or
markers of subjectivity. Umigon is in continuous
development, it can be tried freely at
www.umigon.com. Its code is open sourced at:
https://github.com/seinecle/Umigon
</bodyText>
<listItem confidence="0.516844">
1. General principle of operation
</listItem>
<bodyText confidence="0.999701176470588">
Umigon belongs to the family of lexicon based
sentiment classifiers (Davidov et al. 2010, Kouloumpis
et al. 2011). It is specifically designed to detect
sentiment (positive, negative or neutral) in tweets. The
“sentiment detection engine” of Umigon consists of 4
main parts, which are detailed below:
- detection of semantic features in the entire tweet.
Smileys and onomatopes are given special attention.
- evaluation of hashtags.
- decomposition of the tweet into a list of its n-grams
(up to 4-grams), comparison of each n-gram with the
terms in lexicons. In case of a match, a heuristic is
applied.
- final series of heuristics at the level of the entire
tweet, taking advantage of the semantic features
detected in the previous steps. A final, unique
sentiment (pos, neg or neut) is ascribed to the tweet.
</bodyText>
<sectionHeader confidence="0.443606" genericHeader="method">
2. The four steps of the classification engine
</sectionHeader>
<bodyText confidence="0.668577">
We refer in footnotes to the Java classes which
implement the processes described here.
</bodyText>
<subsectionHeader confidence="0.943284">
2.1 Global heuristics
</subsectionHeader>
<bodyText confidence="0.999909714285714">
Smileys and onomatopes carry strong indications of
sentiment, but also come in a variety of orthographic
forms which require methods devoted to their
treatment1.
Onomatopes and exclamations often include repeated
vowels and consonants, as in yeaaaaahhhh (repeated
“a” and “h”), but also yeaah (repeated “a”), or
yeeeeaaaaah (repeated “e” and “a”). We list the most
common exclamations and use regular expressions to
capture the variety of forms they can assume. If such a
form is found in the tweet, the related sentiment
(positive or negative) is saved, and will be evaluated at
a final stage for the global sentiment of the entire
tweet.
Similarly, smileys are frequently spelled in multiple
variations: :-) can also be found as :-)) or :-)))))))) . For
this reason here also the flexibility of regular
expressions is used to detect spelling variations. In
addition, we consider that a smiley positioned at the
very end of a tweet gives an unambiguous signal as to
the sentiment of the tweet. For instance:
@mydearfriend You got to see Lady Gaga live, so lucky!
Hate you :)))
Here, whatever the negative sentiments (Hate you
signaled in the tweet, the final smiley has an overriding
effect and signals the strongest sentiment in the tweet.
For this reason smileys located in final positions are
recorded as such.
</bodyText>
<subsectionHeader confidence="0.998764">
2.2 Evaluation of hashtags
</subsectionHeader>
<bodyText confidence="0.9942052">
Hashtags are of special interest as they single out a
semantic unit of special significance in the tweet.
Exploiting the semantics in a hashtag faces the issue
that a hashtag can conflate several terms, as in
#greatstuff or #notveryexciting. Umigon applies a series
</bodyText>
<equation confidence="0.514754">
1
</equation>
<bodyText confidence="0.873914">
https://github.com/seinecle/Umigon/blob/master/src/java/Heur
istics/SentenceLevelHeuristicsPre.java
</bodyText>
<page confidence="0.921864">
414
</page>
<bodyText confidence="0.974120333333333">
)
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 414–417, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
of heuristics matching parts of the hashtag with
lexicons2. In the case of #notveryexciting , the starting
letters not will be identified as one of the terms in the
lexicon for negative terms. Similarly, the letters very
will be identified as one of the terms present in the
lexicon for “strength of sentiment”. exciting will be
detected as one of the terms in the lexicon for positive
sentiment. Taken together, not very exciting will lead
to an evaluation of a negative sentiment for this
hashtag. This evaluation is recorded and will be
combined with the evaluation of other features of the
tweet at a later stage.
</bodyText>
<subsectionHeader confidence="0.549498">
2.3 Decomposition in ngrams
</subsectionHeader>
<bodyText confidence="0.999647521739131">
The text of the tweet is decomposed in a list of
unigrams, bigrams, trigrams and quadrigrams. For
example, the tweet This service leaves to be desired
will be decomposed in list of the following expressions:
“This, service, leaves, to, be, desired, This service,
service leaves, leaves to, to be, be desired, This
service leaves, service leaves to, leaves to be, to be
desired, This service leaves to, service leaves to be,
leaves to be desired”
The reason for this decomposition is that some markers
of sentiment are contained in expressions made of
several terms. In the example above, to be desired is a
marker of negative judgment recorded as such in the
lexicon for negative sentiment, while desired is a
marker of positive sentiment.
Umigon loops through all the n-grams of the tweet and
checks for their presence in several lexicons3.
If an n-gram is indeed found to be listed in one of the
lexicons, the heuristic attached to this term in this
lexicon is executed, returning a classification (positive
sentiment, negative sentiment, or another semantic
feature). Heuristics attached to terms in the lexicons
are described in detail in section 3.
</bodyText>
<subsectionHeader confidence="0.920646">
2.4 Post-processing: a last look at the entire tweet .
</subsectionHeader>
<bodyText confidence="0.999679833333333">
At this stage, the methods described above may have
returned a large number of (possibly conflicting)
sentiment categories for a single tweet. For instance, in
the example This service leaves to be desired, the
examination of the n-grams has returned a positive
sentiment classification (desired) and also negative (to
</bodyText>
<page confidence="0.415696">
2
</page>
<bodyText confidence="0.907786">
https://github.com/seinecle/Umigon/blob/master/src/java/Heur
istics/HashtagLevelHeuristics.java
</bodyText>
<page confidence="0.625865">
3
</page>
<bodyText confidence="0.9945068">
https://github.com/seinecle/Umigon/blob/master/src/java/Class
ifier/ClassifierMachine.java
be desired). A series of heuristics adjucates which of
the conflicting indications for sentiments should be
retained in the end. In the case above, the co-presence
of negative and positive sentiments without any further
indication is resolved as the tweet being of a negative
sentiment. If the presence of a moderator is detected
in the tweet (such as but, even if, though), rules of a
more complex nature are applied4.
</bodyText>
<sectionHeader confidence="0.804601" genericHeader="method">
3. A focus on lexicons and heuristics
</sectionHeader>
<bodyText confidence="0.99916075">
Four lexicons are used for sentiment analysis (number
of terms in the lexicons in brackets): “positive tone”
(332), “negative tone” (630), “strength of sentiment”
(59), “negations” (45). These lexicons have been
created manually by the inspection of thousands of
tweets, and continue to be expanded on a regular
basis. Note that the same term can appear in different
lexicons (if rarely in practice). For example, the term
fucking appears in the lexicon for negative tone and in
the lexicon for strong sentiments. Each term in a
lexicon is accompanied by a heuristics and a decision
rule.
</bodyText>
<subsectionHeader confidence="0.466001">
3.1 Simple case from the “negative sentiments”
</subsectionHeader>
<bodyText confidence="0.424049">
lexicon:
</bodyText>
<table confidence="0.608840333333333">
Term sadfaced
Heuristics None
Decision Rule 012
</table>
<bodyText confidence="0.7553172">
If a tweet contains the term sadfaced, Umigon will
directly add the code “012” (which stands for negative
sentiment) to the tweet5.
3.2 More complex case from the “positive sentiments”
lexicon:
</bodyText>
<table confidence="0.9597235">
Term Satisfied
Heuristics !isImmediatelyPrecededBy
ANegation
Decision Rule 011|012
</table>
<bodyText confidence="0.994462666666667">
If the term satisfied is present in a tweet, the heuristics
!isImmediatelyPrecededByANegation is applied. This s a
method checking whether the term immediately
</bodyText>
<page confidence="0.712332">
4
</page>
<bodyText confidence="0.7792444">
https://github.com/seinecle/Umigon/blob/master/src/java/Heur
istics/SentenceLevelHeuristicsPost.java
5 See this class for the full list of possible classifications:
https://github.com/seinecle/Umigon/blob/master/src/java/Class
ifier/Categories.java
</bodyText>
<page confidence="0.99835">
415
</page>
<bodyText confidence="0.999252">
preceding satisfied in the tweet is a negation or not6.
This method returns a Boolean (true / false). The
Boolean returned by this heuristics will determine the
outcome of the decision rule. Here, the decision rule is
a simple binary choice: codify as 011 (meaning, a
positive sentiment) if satisfied is not preceded by a
negation; codify it as 012 (negative sentiment)
otherwise.
</bodyText>
<table confidence="0.815386875">
3.3 Complex case from the “negative sentiments”
lexicon:
Term hard
Heuristics !isImmediatelyPrecededBy
ANegation+++!isImmediat
elyFollowedBySpecificTer
m///work|disk
Decision Rule A?(B?(012):011)
</table>
<bodyText confidence="0.977785933333333">
This example shows how several heuristics (separated
by +++) can be combined, leading to complex rules of
decision. In this example, whenever the term hard is
detected in a tweet, 2 heuristics are evaluated: is the
term preceded by a negation? Is the term followed by
specific terms – work or disk, in this case? Each of these
heuristics returns a Boolean. The Booleans are fed into
the interpreter of the decision rule, where A and B
represent the 2 Booleans7. Depending on their value,
the decision tree takes a different branch, leading to
the selection of one codification. In the example:
If A is false, return 011: a positive sentiment.
Example: not hard
If A is true and B is true, return 012: a negative
sentiment. Example: it is hard
If A is true and B is false, returns null: nothing (a neutral
sentiment).
Example: this is a hard disk
While in practice it is rarely needed to write up rules of
such complexity, they offer an extra flexibility to exploit
the semantic features of terms in varying contexts.
6 The method actually checks the two terms before, in order to
capture cases such as “not very satisfied”, where a negative
term is present but not immediately preceding the term under
review. See the details of all heuristics here:
https://github.com/seinecle/Umigon/blob/master/src/java/Heur
istics/Heuristic.java
7 The class for the interpreter is:
https://github.com/seinecle/Umigon/blob/master/src/java/Rule
Interpreter/Interpreter.java
</bodyText>
<sectionHeader confidence="0.968304" genericHeader="conclusions">
4. Performance
</sectionHeader>
<subsectionHeader confidence="0.981788">
4.1 Accuracy
</subsectionHeader>
<bodyText confidence="0.992843111111111">
Umigon was formally evaluated in a semantic
evaluation task proposed by SemEval-2013, the
International Workshop on Semantic Evaluation
(Wilson et al., 2013). The task consisted in classifying
3,813 tweets as positive, negative or neutral in polarity
(task B). The results:
class Pos neg neut
prec 0.7721 0.4407 0.6471
rec 0.5604 0.5507 0.7579
fscore 0.6495 0.4896 0.6981
average(pos and neg) 0.5696
For reference, the best performing participant in this
task obtained the following results (Mohammad et al.,
2013):
class pos neg neut
prec 0.8138 0.6967 0.6765
rec 0.6673 0.604 0.8262
fscore 0.7333 0.6471 0.7439
average(pos and neg) 0.6902
We see that Umigon had an especially poor precision
for tweets of a negative sentiment (results greyed in
the table). This means that Umigon failed to identify
many negative tweets as such. One reason accounting
for this poor performance is the definition we adopt for
what a negative sentiment is. For example, the SemEval
task included this negative tweet:
“Renewed fighting rocks Syria: An early morning
explosion rocked the flashpoint city of Deir Ezzor on
Saturday in...”
By design, Umigon has not been conceived to classify
such a tweet as negative because if it contains negative
elements of a factual nature (explosion, fighting), but
contains no marker of a negative attitude.
This question aside, the accuracy of Umigon should be
improved by increasing the number of terms and
heuristics in the lexicons, which is an ongoing process.
</bodyText>
<subsectionHeader confidence="0.661942">
4.2 Speed
</subsectionHeader>
<bodyText confidence="0.9955162">
Tested on a dataset provided by sentiment140.com8
,
Umigon performs the classification of 1.6 million
tweets in less than 15 minutes. We believe that not
relying on Part of Speech tagging makes it a specially
</bodyText>
<footnote confidence="0.882452">
8 http://help.sentiment140.com/for-students
</footnote>
<page confidence="0.997493">
416
</page>
<bodyText confidence="0.999959">
fast solution for lexicon-based sentiment classifiers.
The classifier engine is implemented in such a way that
the presence of absence of n-grams in the terms lists is
checked through look-ups on hashsets (is this n-gram
contained in a set?), not loops through these sets. Since
look-ups in hashsets is typically of O(1) compexity9, this
insures that the performance of Umigon will not
degrade even with expanded lexicons.
</bodyText>
<sectionHeader confidence="0.999145" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.970709555555555">
Davidov, D., Tsur, O., and Rappoport, A. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. Proceedings of Coling.
Kouloumpis, E., Wilson, T., and Moore, J. 2011. Twitter
Sentiment Analysis: The Good the Bad and the OMG!
Proceedings of ICWSM.
Mohammad, S., Kiritchenko, S. and Zhu, X. 2013. NRC-
Canada: Building the State-of-the-Art in Sentiment
Analysis of Tweets. In Proceedings of the International
Workshop on Semantic Evaluation, SemEval ’13, June
2013, Atlanta, Georgia.
Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S.
Stoyanov, V. and Alan Ritter. 2013. SemEval-2013 Task
2: Sentiment Analysis in Twitter. In Proceedings of the
International Workshop on Semantic Evaluation,
SemEval ’13, June 2013, Atlanta, Georgia.
9 http://stackoverflow.com/questions/6574916/hashset-look-
up-complexity
</reference>
<page confidence="0.994561">
417
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.014022">
<title confidence="0.9925675">Umigon: sentiment analysis for based on lexicons and heuristics</title>
<author confidence="0.985576">Clement Levallois</author>
<affiliation confidence="0.9973885">Department of Marketing Management, Rotterda School of and Erasmus Studio, Erasmus University</affiliation>
<address confidence="0.511113">The</address>
<email confidence="0.975333">clevallois@rsm.nl</email>
<abstract confidence="0.984774526923077">Umigon is developed since December 2012 as a web application providing a service of sentiment detection in tweets. It has been designed to be fast and scalable. Umigon also provides indications for additional semantic features present in the tweets, such as time indications or markers of subjectivity. Umigon is in continuous development, it can be tried freely at www.umigon.com.Its code is open sourced at: https://github.com/seinecle/Umigon 1. General principle of operation Umigon belongs to the family of lexicon based sentiment classifiers (Davidov et al. 2010, Kouloumpis et al. 2011). It is specifically designed to detect sentiment (positive, negative or neutral) in tweets. The “sentiment detection engine” of Umigon consists of 4 main parts, which are detailed below: detection of semantic features in the entire tweet. Smileys and onomatopes are given special attention. evaluation of hashtags. decomposition of the tweet into a list of its n-grams (up to 4-grams), comparison of each n-gram with the terms in lexicons. In case of a match, a heuristic is applied. final series of heuristics at the level of the entire tweet, taking advantage of the semantic features detected in the previous steps. A final, unique sentiment (pos, neg or neut) is ascribed to the tweet. 2. The four steps of the classification engine We refer in footnotes to the Java classes which implement the processes described here. heuristics Smileys and onomatopes carry strong indications of sentiment, but also come in a variety of orthographic forms which require methods devoted to their Onomatopes and exclamations often include repeated vowels and consonants, as in yeaaaaahhhh (repeated “a” and “h”), but also yeaah (repeated “a”), or yeeeeaaaaah (repeated “e” and “a”). We list the most common exclamations and use regular expressions to capture the variety of forms they can assume. If such a form is found in the tweet, the related sentiment (positive or negative) is saved, and will be evaluated at a final stage for the global sentiment of the entire tweet. Similarly, smileys are frequently spelled in multiple variations: :-) can also be found as :-)) or :-)))))))) . For this reason here also the flexibility of regular expressions is used to detect spelling variations. In addition, we consider that a smiley positioned at the very end of a tweet gives an unambiguous signal as to the sentiment of the tweet. For instance: @mydearfriend You got to see Lady Gaga live, so lucky! Hate you :))) Here, whatever the negative sentiments (Hate you signaled in the tweet, the final smiley has an overriding effect and signals the strongest sentiment in the tweet. For this reason smileys located in final positions are recorded as such. of hashtags Hashtags are of special interest as they single out a semantic unit of special significance in the tweet. Exploiting the semantics in a hashtag faces the issue that a hashtag can conflate several terms, as in 1 https://github.com/seinecle/Umigon/blob/master/src/java/Heur istics/SentenceLevelHeuristicsPre.java 414 ) Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic (SemEval pages 414–417, Atlanta, Georgia, June 14-15, 2013. Association for Computational Linguistics of heuristics matching parts of the hashtag with In the case of #notveryexciting , the starting letters not will be identified as one of the terms in the lexicon for negative terms. Similarly, the letters very will be identified as one of the terms present in the lexicon for “strength of sentiment”. exciting will be detected as one of the terms in the lexicon for positive sentiment. Taken together, not very exciting will lead to an evaluation of a negative sentiment for this hashtag. This evaluation is recorded and will be combined with the evaluation of other features of the tweet at a later stage. in ngrams The text of the tweet is decomposed in a list of unigrams, bigrams, trigrams and quadrigrams. For example, the tweet This service leaves to be desired will be decomposed in list of the following expressions: “This, service, leaves, to, be, desired, This service, service leaves, leaves to, to be, be desired, This service leaves, service leaves to, leaves to be, to be desired, This service leaves to, service leaves to be, leaves to be desired” The reason for this decomposition is that some markers of sentiment are contained in expressions made of several terms. In the example above, to be desired is a marker of negative judgment recorded as such in the lexicon for negative sentiment, while desired is a marker of positive Umigon loops through all the n-grams of the tweet and for their presence in several If an n-gram is indeed found to be listed in one of the lexicons, the heuristic attached to this term in this lexicon is executed, returning a classification (positive sentiment, negative sentiment, or another semantic feature). Heuristics attached to terms in the lexicons are described in detail in section 3. a last look at the entire tweet . At this stage, the methods described above may have returned a large number of (possibly conflicting) sentiment categories for a single tweet. For instance, in the example This service leaves to be desired, the examination of the n-grams has returned a positive sentiment classification (desired) and also negative (to 2 https://github.com/seinecle/Umigon/blob/master/src/java/Heur istics/HashtagLevelHeuristics.java 3 https://github.com/seinecle/Umigon/blob/master/src/java/Class ifier/ClassifierMachine.java be desired). A series of heuristics adjucates which of the conflicting indications for sentiments should be retained in the end. In the case above, the co-presence of negative and positive sentiments without any further indication is resolved as the tweet being of a negative sentiment. If the presence of a moderator is detected in the tweet (such as but, even if, though), rules of a complex nature are 3. A focus on lexicons and heuristics Four lexicons are used for sentiment analysis (number of terms in the lexicons in brackets): “positive tone” (332), “negative tone” (630), “strength of sentiment” (59), “negations” (45). These lexicons have been created manually by the inspection of thousands of tweets, and continue to be expanded on a regular basis. Note that the same term can appear in different lexicons (if rarely in practice). For example, the term fucking appears in the lexicon for negative tone and in the lexicon for strong sentiments. Each term in a lexicon is accompanied by a heuristics and a decision rule. case from the “negative sentiments” lexicon: Term sadfaced Heuristics None Decision Rule 012 If a tweet contains the term sadfaced, Umigon will directly add the code “012” (which stands for negative to the complex case from the “positive sentiments” lexicon: Term Satisfied Heuristics ANegation Decision Rule 011|012 If the term satisfied is present in a tweet, the heuristics !isImmediatelyPrecededByANegation is applied. This s a method checking whether the term immediately 4 https://github.com/seinecle/Umigon/blob/master/src/java/Heur istics/SentenceLevelHeuristicsPost.java this class for the full list of possible classifications: https://github.com/seinecle/Umigon/blob/master/src/java/Class ifier/Categories.java 415 satisfied in the tweet is a negation or This method returns a Boolean (true / false). The Boolean returned by this heuristics will determine the outcome of the decision rule. Here, the decision rule is a simple binary choice: codify as 011 (meaning, a positive sentiment) if satisfied is not preceded by a negation; codify it as 012 (negative sentiment) otherwise. case from the “negative sentiments” lexicon: Term hard Heuristics !isImmediatelyPrecededBy ANegation+++!isImmediat elyFollowedBySpecificTer m///work|disk Decision Rule A?(B?(012):011) This example shows how several heuristics (separated by +++) can be combined, leading to complex rules of decision. In this example, whenever the term hard is detected in a tweet, 2 heuristics are evaluated: is the term preceded by a negation? Is the term followed by specific terms – work or disk, in this case? Each of these heuristics returns a Boolean. The Booleans are fed into the interpreter of the decision rule, where A and B the 2 Depending on their value, the decision tree takes a different branch, leading to the selection of one codification. In the example: If A is false, return 011: a positive sentiment. Example: not hard If A is true and B is true, return 012: a negative sentiment. Example: it is hard If A is true and B is false, returns null: nothing (a neutral sentiment). Example: this is a hard disk While in practice it is rarely needed to write up rules of such complexity, they offer an extra flexibility to exploit the semantic features of terms in varying contexts. method actually checks the two terms before, in order to capture cases such as “not very satisfied”, where a negative term is present but not immediately preceding the term under review. See the details of all heuristics here: https://github.com/seinecle/Umigon/blob/master/src/java/Heur istics/Heuristic.java class for the interpreter is: https://github.com/seinecle/Umigon/blob/master/src/java/Rule Interpreter/Interpreter.java 4. Performance Umigon was formally evaluated in a semantic evaluation task proposed by SemEval-2013, the International Workshop on Semantic Evaluation (Wilson et al., 2013). The task consisted in classifying 3,813 tweets as positive, negative or neutral in polarity (task B). The results: class Pos neg neut prec 0.7721 0.4407 0.6471 rec 0.5604 0.5507 0.7579 fscore 0.6495 0.4896 0.6981 average(pos and neg) 0.5696 For reference, the best performing participant in this task obtained the following results (Mohammad et al., 2013): class pos neg neut prec 0.8138 0.6967 0.6765 rec 0.6673 0.604 0.8262 fscore 0.7333 0.6471 0.7439 average(pos and neg) 0.6902 We see that Umigon had an especially poor precision for tweets of a negative sentiment (results greyed in the table). This means that Umigon failed to identify many negative tweets as such. One reason accounting for this poor performance is the definition we adopt for what a negative sentiment is. For example, the SemEval task included this negative tweet: “Renewed fighting rocks Syria: An early morning explosion rocked the flashpoint city of Deir Ezzor on Saturday in...” By design, Umigon has not been conceived to classify such a tweet as negative because if it contains negative of a (explosion, fighting), but no marker of a negative This question aside, the accuracy of Umigon should be improved by increasing the number of terms and heuristics in the lexicons, which is an ongoing process. on a dataset provided by , Umigon performs the classification of 1.6 million tweets in less than 15 minutes. We believe that not relying on Part of Speech tagging makes it a specially 8http://help.sentiment140.com/for-students 416 fast solution for lexicon-based sentiment classifiers. The classifier engine is implemented in such a way that the presence of absence of n-grams in the terms lists is checked through look-ups on hashsets (is this n-gram contained in a set?), not loops through these sets. Since in hashsets is typically of O(1) this insures that the performance of Umigon will not degrade even with expanded lexicons.</abstract>
<note confidence="0.8444923">References Davidov, D., Tsur, O., and Rappoport, A. 2010. Enhanced sentiment learning using twitter hashtags and smileys. Proceedings of Coling. Kouloumpis, E., Wilson, T., and Moore, J. 2011. Twitter Sentiment Analysis: The Good the Bad and the OMG! Proceedings of ICWSM. Mohammad, S., Kiritchenko, S. and Zhu, X. 2013. NRC- Canada: Building the State-of-the-Art in Sentiment of Tweets. In of the International on Semantic SemEval ’13, June 2013, Atlanta, Georgia. Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S. Stoyanov, V. and Alan Ritter. 2013. SemEval-2013 Task Sentiment Analysis in Twitter. In of the Workshop on Semantic SemEval ’13, June 2013, Atlanta, Georgia. 9http://stackoverflow.com/questions/6574916/hashset-lookup-complexity 417</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>O Tsur</author>
<author>A Rappoport</author>
</authors>
<title>Enhanced sentiment learning using twitter hashtags and smileys.</title>
<date>2010</date>
<booktitle>Proceedings of Coling.</booktitle>
<contexts>
<context position="816" citStr="Davidov et al. 2010" startWordPosition="111" endWordPosition="114">terdam The Netherlands. clevallois@rsm.nl Abstract Umigon is developed since December 2012 as a web application providing a service of sentiment detection in tweets. It has been designed to be fast and scalable. Umigon also provides indications for additional semantic features present in the tweets, such as time indications or markers of subjectivity. Umigon is in continuous development, it can be tried freely at www.umigon.com. Its code is open sourced at: https://github.com/seinecle/Umigon 1. General principle of operation Umigon belongs to the family of lexicon based sentiment classifiers (Davidov et al. 2010, Kouloumpis et al. 2011). It is specifically designed to detect sentiment (positive, negative or neutral) in tweets. The “sentiment detection engine” of Umigon consists of 4 main parts, which are detailed below: - detection of semantic features in the entire tweet. Smileys and onomatopes are given special attention. - evaluation of hashtags. - decomposition of the tweet into a list of its n-grams (up to 4-grams), comparison of each n-gram with the terms in lexicons. In case of a match, a heuristic is applied. - final series of heuristics at the level of the entire tweet, taking advantage of t</context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Davidov, D., Tsur, O., and Rappoport, A. 2010. Enhanced sentiment learning using twitter hashtags and smileys. Proceedings of Coling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kouloumpis</author>
<author>T Wilson</author>
<author>J Moore</author>
</authors>
<title>Twitter Sentiment Analysis: The Good the Bad and the OMG!</title>
<date>2011</date>
<booktitle>Proceedings of ICWSM.</booktitle>
<contexts>
<context position="841" citStr="Kouloumpis et al. 2011" startWordPosition="115" endWordPosition="118">s. clevallois@rsm.nl Abstract Umigon is developed since December 2012 as a web application providing a service of sentiment detection in tweets. It has been designed to be fast and scalable. Umigon also provides indications for additional semantic features present in the tweets, such as time indications or markers of subjectivity. Umigon is in continuous development, it can be tried freely at www.umigon.com. Its code is open sourced at: https://github.com/seinecle/Umigon 1. General principle of operation Umigon belongs to the family of lexicon based sentiment classifiers (Davidov et al. 2010, Kouloumpis et al. 2011). It is specifically designed to detect sentiment (positive, negative or neutral) in tweets. The “sentiment detection engine” of Umigon consists of 4 main parts, which are detailed below: - detection of semantic features in the entire tweet. Smileys and onomatopes are given special attention. - evaluation of hashtags. - decomposition of the tweet into a list of its n-grams (up to 4-grams), comparison of each n-gram with the terms in lexicons. In case of a match, a heuristic is applied. - final series of heuristics at the level of the entire tweet, taking advantage of the semantic features dete</context>
</contexts>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>Kouloumpis, E., Wilson, T., and Moore, J. 2011. Twitter Sentiment Analysis: The Good the Bad and the OMG! Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
<author>S Kiritchenko</author>
<author>X Zhu</author>
</authors>
<title>NRCCanada: Building the State-of-the-Art in Sentiment Analysis of Tweets.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<location>Atlanta,</location>
<contexts>
<context position="10450" citStr="Mohammad et al., 2013" startWordPosition="1581" endWordPosition="1584">thub.com/seinecle/Umigon/blob/master/src/java/Rule Interpreter/Interpreter.java 4. Performance 4.1 Accuracy Umigon was formally evaluated in a semantic evaluation task proposed by SemEval-2013, the International Workshop on Semantic Evaluation (Wilson et al., 2013). The task consisted in classifying 3,813 tweets as positive, negative or neutral in polarity (task B). The results: class Pos neg neut prec 0.7721 0.4407 0.6471 rec 0.5604 0.5507 0.7579 fscore 0.6495 0.4896 0.6981 average(pos and neg) 0.5696 For reference, the best performing participant in this task obtained the following results (Mohammad et al., 2013): class pos neg neut prec 0.8138 0.6967 0.6765 rec 0.6673 0.604 0.8262 fscore 0.7333 0.6471 0.7439 average(pos and neg) 0.6902 We see that Umigon had an especially poor precision for tweets of a negative sentiment (results greyed in the table). This means that Umigon failed to identify many negative tweets as such. One reason accounting for this poor performance is the definition we adopt for what a negative sentiment is. For example, the SemEval task included this negative tweet: “Renewed fighting rocks Syria: An early morning explosion rocked the flashpoint city of Deir Ezzor on Saturday in.</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Mohammad, S., Kiritchenko, S. and Zhu, X. 2013. NRCCanada: Building the State-of-the-Art in Sentiment Analysis of Tweets. In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13, June 2013, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>Z Kozareva</author>
<author>P Nakov</author>
<author>S Stoyanov Rosenthal</author>
<author>V</author>
<author>Alan Ritter</author>
</authors>
<title>SemEval-2013 Task 2: Sentiment Analysis in Twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<volume>9</volume>
<pages>6574916</pages>
<location>Atlanta,</location>
<contexts>
<context position="10093" citStr="Wilson et al., 2013" startWordPosition="1526" endWordPosition="1529">ethod actually checks the two terms before, in order to capture cases such as “not very satisfied”, where a negative term is present but not immediately preceding the term under review. See the details of all heuristics here: https://github.com/seinecle/Umigon/blob/master/src/java/Heur istics/Heuristic.java 7 The class for the interpreter is: https://github.com/seinecle/Umigon/blob/master/src/java/Rule Interpreter/Interpreter.java 4. Performance 4.1 Accuracy Umigon was formally evaluated in a semantic evaluation task proposed by SemEval-2013, the International Workshop on Semantic Evaluation (Wilson et al., 2013). The task consisted in classifying 3,813 tweets as positive, negative or neutral in polarity (task B). The results: class Pos neg neut prec 0.7721 0.4407 0.6471 rec 0.5604 0.5507 0.7579 fscore 0.6495 0.4896 0.6981 average(pos and neg) 0.5696 For reference, the best performing participant in this task obtained the following results (Mohammad et al., 2013): class pos neg neut prec 0.8138 0.6967 0.6765 rec 0.6673 0.604 0.8262 fscore 0.7333 0.6471 0.7439 average(pos and neg) 0.6902 We see that Umigon had an especially poor precision for tweets of a negative sentiment (results greyed in the table)</context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Rosenthal, V, Ritter, 2013</marker>
<rawString>Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S. Stoyanov, V. and Alan Ritter. 2013. SemEval-2013 Task 2: Sentiment Analysis in Twitter. In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13, June 2013, Atlanta, Georgia. 9 http://stackoverflow.com/questions/6574916/hashset-lookup-complexity</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>