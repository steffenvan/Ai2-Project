<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.227402">
<title confidence="0.995902">
Detecting Deceptive Opinion Spam using Linguistics, Behavioral and
Statistical Modeling
</title>
<author confidence="0.995888">
Arjun Mukherjee
</author>
<affiliation confidence="0.9955575">
Department of Computer Science
University of Houston
</affiliation>
<address confidence="0.815078">
501 PGH, 4800 Calhoun Rd. Houston, TX
</address>
<email confidence="0.999249">
arjun@cs.uh.edu
</email>
<sectionHeader confidence="0.999564" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988423076923">
With the advent of Web 2.0, consumer reviews
have become an important resource for public
opinion that influence our decisions over an ex-
tremely wide spectrum of daily and professional
activities: e.g., where to eat, where to stay, which
products to purchase, which doctors to see, which
books to read, which universities to attend, and so
on. Positive/negative reviews directly translate to
financial gains/losses for companies. This unfor-
tunately gives strong incentives for opinion spam-
ming which refers to illegal human activities (e.g.,
writing fake reviews and giving false ratings) that
try to mislead customers by promoting/demoting
certain entities (e.g., products and businesses).
The problem has been widely reported in the
news. Despite the recent research efforts on detec-
tion, the problem is far from solved. What is
worse is that opinion spamming is widespread.
While credit card fraud is as rare as 0.2%, based
on our research we estimated that up to 30% of the
reviews on many Web sites could be fake. Thus,
detecting fake reviews and opinions is a pressing
and also profound issue as it is critical to ensure
the trustworthiness of the information on the web.
Without detecting them, the social media could
become a place full of lies, fakes, and deceptions,
and completely useless.
Major review hosting sites and e-commerce
vendors have already made some progress in de-
tecting fake reviews. However, the task is still ex-
tremely challenging because it is very difficult to
obtain large-scale ground truth samples of decep-
tive opinions for algorithm development and for
evaluation, or to conduct large-scale domain ex-
pert evaluations. Further, in contrast to other kinds
of spamming (e.g., Web and link spam, so-
cial/blog spam, email spam, etc.) opinion spam
has a very unique flavor as it involves fluid senti-
ments of users and their evaluations. Thus, they
require a very different treatment. Since our first
paper in 2007 (Jindal and Liu, 2007) on the topic,
our group and many other researchers have pro-
posed several algorithms and bridged algorithmic
methodologies from various scientific disciplines
including computational linguistics (Ott et al.,
2011), social and behavioral sciences (Jindal and
Liu, 2008; Mukherjee et al., 2013a, b), machine
learning, data mining and Bayesian statistics
(Mukherjee et al., 2012; Fei et al., 2013;
Mukherjee et al., 2013c; Li et al., 2014b; Li et al.,
2014a) to solve the problem. The field of decep-
tive opinion spam has gained a lot of interest in
communications (Hancock et al., 2008), psycho-
linguistics communities (Gokhman et al., 2012),
and economic analysis (Wang, 2010) apart from
mainstream NLP and Web mining as attested by
publications in top tier venues in their respective
communities. The problem has far reaching impli-
cations in various allied NLP topics including Lie
Detection, Forensic Linguistics, Opinion Trust
and Veracity Verification and Plagiarism Detec-
tion. However, owing to the inherent nature of the
problem, a unique blend of NLP, data mining, ma-
chine learning, social, behavioral, and statistical
techniques are required which many NLP re-
searchers may not be familiar with.
In this tutorial, we aim to cover the problem in
its full depth and width, covering diverse algo-
rithms that have been developed over the past 7
years. The most attractive quality of these tech-
niques is that many of them can be adapted for
cross-domain and unsupervised settings. Some of
the methods are even in use by startups and estab-
lished companies. Our focus is on insight and un-
derstanding, using illustrations and intuitive de-
ductions. The goal of the tutorial is to make the
inner workings of these techniques transparent,
intuitive and their results interpretable.
</bodyText>
<sectionHeader confidence="0.969652" genericHeader="method">
2 Content Overview
</sectionHeader>
<bodyText confidence="0.9999646">
The first part of the tutorial presents the problem
in its various flavors, the NLP techniques, and the
algorithms motivated from social and behavioral
sciences. It also presents a detailed insight into
commercial vs. crowdsourced deceptive opinions
using information theory and linguistics. The sec-
ond section includes detailed math and algorithms
for training supervised, unsupervised, semi-super-
vised, and partially supervised machine learning
and statistical models for deceptive opinion spam
</bodyText>
<page confidence="0.983756">
21
</page>
<note confidence="0.94403">
Proceedings of the Tutorials of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, pages 21–22,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999903230769231">
detection. These algorithms allow us to work on
unlabeled data which is a key aspect of the prob-
lem as generating high quality labels of fake re-
views in large scale is hard if not impossible. We
also discuss some new evaluation methods. Addi-
tionally, we draw connections to Authorship At-
tribution to discover fake reviewers with multiple
accounts based on their writing styles, which is a
new frontier in deceptive opinion spamming. The
last part of the tutorial gives a general overview of
the different applications of the methods in allied
NLP problems and domains, data sources, and the
limitations of the existing methods.
</bodyText>
<sectionHeader confidence="0.769345" genericHeader="method">
3 Tutorial Outline
</sectionHeader>
<figure confidence="0.9264927">
I. Introduction
a. The socio-economic value of opinions
b. Deceptive Opinion Spam and Fraud
c. Opinion Spam Types: Individual, Group,
Singular, and Campaigns
II. Leveraging Linguistic Signals
a. N-gram language models
b. Psycholinguistics
c. Stylometry
III. Leveraging Behavioral Signals
a. Rating, Reviewing, &amp; Collusion Behaviors
b. Distributional and Time-Series Analysis
c. Graph Based Methods
d. Linguistic vs. Behavioral Features: A case
study on Commercial vs. Crowdsourced
Fake Reviews
IV. Machine Leaning &amp; Statistical Modeling
a. Supervised vs. Unsupervised Methods
b. Positive and Unlabeled (PU) and Semi-Su-
pervised Learning
c. Latent Variable Models
V. The Next Frontier: Sockpuppets
a. Authorship Attribution and Beyond
b. Modeling Latent Spaces of Language
c. Learning in Similarity Spaces
VI. Discussion and Resources
a. Applications
b. Data sources
c. Evaluation
d. Discussion
</figure>
<sectionHeader confidence="0.961012" genericHeader="method">
4 Instructor Biography
</sectionHeader>
<bodyText confidence="0.99877325">
Arjun Mukherjee is an Assistant Professor in the
Department of Computer Science at the Univer-
sity of Houston. He is an active researcher in the
area of opinion spam, sentiment analysis and Web
mining. He is the lead author behind several influ-
ential works on opinion spam research. These in-
clude group opinion spam, commercial fake re-
view filters (e.g., Yelp), and various statistical
</bodyText>
<footnote confidence="0.851638">
1 http://www.cs.uic.edu /~liub/FBS/media-cover-
age.html
</footnote>
<bodyText confidence="0.99966775">
models for detecting singular opinion spammers,
burstiness patterns, and campaign. His work on
opinion mining including deception detection
have also received significant media attention
(e.g., ACM Tech News, NYTimes, LATimes,
Business Week, CNet, etc1). Mukherjee has also
served as program committee members of WWW,
ACL, EMNLP, and IJCNLP.
</bodyText>
<sectionHeader confidence="0.998542" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999785222222222">
G. Fei, A. Mukherjee, B. Liu, M. Hsu, M. Castellanos,
and R. Ghosh. 2013. Exploiting Burstiness in
Reviews for Review Spammer Detection. ICWSM.
S. Gokhman, J. Hancock, P. Prabhu, M. Ott, and C.
Cardie. 2012. In search of a gold standard in studies
of deception. In Proceedings of the Workshop on
Computational Approaches to Deception Detection.
J. T. Hancock, L. E. Curry, S. Goorha, and M.
Woodworth. 2008. On lying and being lied to: A
linguistic analysis of deception in computer-
mediated communication. Discourse Processes.
N. Jindal and B. Liu. 2007. Review spam detection.
WWW.
N. Jindal and B. Liu. 2008 Opinion Spam and
Analysis. WSDM.
H. Li, B. Liu, A. Mukherjee, and J. Shao. 2014a.
Spotting Fake Reviews using Positive-Unlabeled
Learning. Computaci{ó}n y Sistemas, 18(3).
H. Li, A. Mukherjee, B. Liu, R. Kornfield, and S.
Emery. 2014b. Detecting Campaign Promoters on
Twitter using Markov Random Field. ICDM.
A. Mukherjee, V. Venkataraman. 2014. Opinion Spam
Detection: An Unsupervised Approach using
Generative Models. UH-CS-TR-2014-07.
A. Mukherjee, V. Venkataraman, B. Liu, and N.
Glance. 2013a. What Yelp Fake Review Filter might
be Doing? AAAI ICWSM.
A. Mukherjee, V. Venkataraman, B. Liu, and N.
Glance. 2013b. Fake Review Detection:
Classification and Analysis of Real and Pseudo
Reviews. UIC-CS-2013-03
A. Mukherjee, A. Kumar, B. Liu, J. Wang, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013c. Spotting Opinion Spammers using
Behavioral Footprints. KDD.
A. Mukherjee, B. Liu, and N. Glance. 2012. Spotting
Fake Reviewer Groups in Consumer Reviews.
WWW.
M. Ott, Y. Choi, C. Cardie, and J. T Hancock. 2011.
Finding Deceptive Opinion Spam by Any Stretch of
the Imagination. ACL.
Z. Wang. 2010. Anonymity, Social Image, and the
Competition for Volunteers: A Case Study of the
Online Market for Reviews. The B.E. Journal of
Economic Analysis &amp; Policy, 10(1):1–34, January.
</reference>
<page confidence="0.99901">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.819765">
<title confidence="0.996041">Detecting Deceptive Opinion Spam using Linguistics, Behavioral Statistical Modeling</title>
<author confidence="0.909197">Arjun</author>
<affiliation confidence="0.9996355">Department of Computer University of</affiliation>
<address confidence="0.910085">501 PGH, 4800 Calhoun Rd. Houston,</address>
<email confidence="0.995002">arjun@cs.uh.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Fei</author>
<author>A Mukherjee</author>
<author>B Liu</author>
<author>M Hsu</author>
<author>M Castellanos</author>
<author>R Ghosh</author>
</authors>
<title>Exploiting Burstiness in Reviews for Review Spammer Detection.</title>
<date>2013</date>
<publisher>ICWSM.</publisher>
<contexts>
<context position="2582" citStr="Fei et al., 2013" startWordPosition="400" endWordPosition="403">am, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detection. However, owing</context>
</contexts>
<marker>Fei, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>G. Fei, A. Mukherjee, B. Liu, M. Hsu, M. Castellanos, and R. Ghosh. 2013. Exploiting Burstiness in Reviews for Review Spammer Detection. ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gokhman</author>
<author>J Hancock</author>
<author>P Prabhu</author>
<author>M Ott</author>
<author>C Cardie</author>
</authors>
<title>In search of a gold standard in studies of deception.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Deception Detection.</booktitle>
<contexts>
<context position="2826" citStr="Gokhman et al., 2012" startWordPosition="442" endWordPosition="445">ur group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detection. However, owing to the inherent nature of the problem, a unique blend of NLP, data mining, machine learning, social, behavioral, and statistical techniques are required which many NLP researchers may not be familiar with. In this tutorial, we aim to cover the</context>
</contexts>
<marker>Gokhman, Hancock, Prabhu, Ott, Cardie, 2012</marker>
<rawString>S. Gokhman, J. Hancock, P. Prabhu, M. Ott, and C. Cardie. 2012. In search of a gold standard in studies of deception. In Proceedings of the Workshop on Computational Approaches to Deception Detection.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Hancock</author>
<author>L E Curry</author>
<author>S Goorha</author>
<author>M Woodworth</author>
</authors>
<title>On lying and being lied to: A linguistic analysis of deception in computermediated communication. Discourse Processes.</title>
<date>2008</date>
<contexts>
<context position="2772" citStr="Hancock et al., 2008" startWordPosition="435" endWordPosition="438">t paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detection. However, owing to the inherent nature of the problem, a unique blend of NLP, data mining, machine learning, social, behavioral, and statistical techniques are required which many NLP researchers may not b</context>
</contexts>
<marker>Hancock, Curry, Goorha, Woodworth, 2008</marker>
<rawString>J. T. Hancock, L. E. Curry, S. Goorha, and M. Woodworth. 2008. On lying and being lied to: A linguistic analysis of deception in computermediated communication. Discourse Processes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Jindal</author>
<author>B Liu</author>
</authors>
<title>Review spam detection.</title>
<date>2007</date>
<publisher>WWW.</publisher>
<contexts>
<context position="2189" citStr="Jindal and Liu, 2007" startWordPosition="343" endWordPosition="346"> vendors have already made some progress in detecting fake reviews. However, the task is still extremely challenging because it is very difficult to obtain large-scale ground truth samples of deceptive opinions for algorithm development and for evaluation, or to conduct large-scale domain expert evaluations. Further, in contrast to other kinds of spamming (e.g., Web and link spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguisti</context>
</contexts>
<marker>Jindal, Liu, 2007</marker>
<rawString>N. Jindal and B. Liu. 2007. Review spam detection. WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Jindal</author>
<author>B Liu</author>
</authors>
<title>Opinion Spam and Analysis.</title>
<date>2008</date>
<publisher>WSDM.</publisher>
<contexts>
<context position="2456" citStr="Jindal and Liu, 2008" startWordPosition="380" endWordPosition="383">ct large-scale domain expert evaluations. Further, in contrast to other kinds of spamming (e.g., Web and link spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics i</context>
</contexts>
<marker>Jindal, Liu, 2008</marker>
<rawString>N. Jindal and B. Liu. 2008 Opinion Spam and Analysis. WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>B Liu</author>
<author>A Mukherjee</author>
<author>J Shao</author>
</authors>
<title>Spotting Fake Reviews using Positive-Unlabeled Learning.</title>
<date>2014</date>
<journal>Computaci{ó}n y Sistemas,</journal>
<volume>18</volume>
<issue>3</issue>
<contexts>
<context position="2624" citStr="Li et al., 2014" startWordPosition="408" endWordPosition="411">ry unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detection. However, owing to the inherent nature of the problem, a </context>
</contexts>
<marker>Li, Liu, Mukherjee, Shao, 2014</marker>
<rawString>H. Li, B. Liu, A. Mukherjee, and J. Shao. 2014a. Spotting Fake Reviews using Positive-Unlabeled Learning. Computaci{ó}n y Sistemas, 18(3).</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Li</author>
<author>A Mukherjee</author>
<author>B Liu</author>
<author>R Kornfield</author>
<author>S Emery</author>
</authors>
<booktitle>2014b. Detecting Campaign Promoters on Twitter using Markov Random Field. ICDM.</booktitle>
<marker>Li, Mukherjee, Liu, Kornfield, Emery, </marker>
<rawString>H. Li, A. Mukherjee, B. Liu, R. Kornfield, and S. Emery. 2014b. Detecting Campaign Promoters on Twitter using Markov Random Field. ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mukherjee</author>
<author>V Venkataraman</author>
</authors>
<title>Opinion Spam Detection: An Unsupervised Approach using Generative Models.</title>
<date>2014</date>
<pages>2014--07</pages>
<marker>Mukherjee, Venkataraman, 2014</marker>
<rawString>A. Mukherjee, V. Venkataraman. 2014. Opinion Spam Detection: An Unsupervised Approach using Generative Models. UH-CS-TR-2014-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mukherjee</author>
<author>V Venkataraman</author>
<author>B Liu</author>
<author>N Glance</author>
</authors>
<title>What Yelp Fake Review Filter might be Doing? AAAI ICWSM.</title>
<date>2013</date>
<contexts>
<context position="2480" citStr="Mukherjee et al., 2013" startWordPosition="384" endWordPosition="387">expert evaluations. Further, in contrast to other kinds of spamming (e.g., Web and link spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, </context>
</contexts>
<marker>Mukherjee, Venkataraman, Liu, Glance, 2013</marker>
<rawString>A. Mukherjee, V. Venkataraman, B. Liu, and N. Glance. 2013a. What Yelp Fake Review Filter might be Doing? AAAI ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mukherjee</author>
<author>V Venkataraman</author>
<author>B Liu</author>
<author>N Glance</author>
</authors>
<title>Fake Review Detection: Classification and Analysis of Real and Pseudo Reviews.</title>
<date>2013</date>
<pages>2013--03</pages>
<contexts>
<context position="2480" citStr="Mukherjee et al., 2013" startWordPosition="384" endWordPosition="387">expert evaluations. Further, in contrast to other kinds of spamming (e.g., Web and link spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, </context>
</contexts>
<marker>Mukherjee, Venkataraman, Liu, Glance, 2013</marker>
<rawString>A. Mukherjee, V. Venkataraman, B. Liu, and N. Glance. 2013b. Fake Review Detection: Classification and Analysis of Real and Pseudo Reviews. UIC-CS-2013-03</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Mukherjee</author>
<author>A Kumar</author>
<author>B Liu</author>
<author>J Wang</author>
</authors>
<title>Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013c. Spotting Opinion Spammers using Behavioral Footprints.</title>
<publisher>KDD.</publisher>
<marker>Mukherjee, Kumar, Liu, Wang, </marker>
<rawString>A. Mukherjee, A. Kumar, B. Liu, J. Wang, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013c. Spotting Opinion Spammers using Behavioral Footprints. KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mukherjee</author>
<author>B Liu</author>
<author>N Glance</author>
</authors>
<title>Spotting Fake Reviewer Groups in Consumer Reviews.</title>
<date>2012</date>
<publisher>WWW.</publisher>
<contexts>
<context position="2564" citStr="Mukherjee et al., 2012" startWordPosition="396" endWordPosition="399">ink spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detecti</context>
</contexts>
<marker>Mukherjee, Liu, Glance, 2012</marker>
<rawString>A. Mukherjee, B. Liu, and N. Glance. 2012. Spotting Fake Reviewer Groups in Consumer Reviews. WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ott</author>
<author>Y Choi</author>
<author>C Cardie</author>
<author>J T Hancock</author>
</authors>
<title>Finding Deceptive Opinion Spam by Any Stretch of the Imagination.</title>
<date>2011</date>
<publisher>ACL.</publisher>
<contexts>
<context position="2402" citStr="Ott et al., 2011" startWordPosition="372" endWordPosition="375">gorithm development and for evaluation, or to conduct large-scale domain expert evaluations. Further, in contrast to other kinds of spamming (e.g., Web and link spam, social/blog spam, email spam, etc.) opinion spam has a very unique flavor as it involves fluid sentiments of users and their evaluations. Thus, they require a very different treatment. Since our first paper in 2007 (Jindal and Liu, 2007) on the topic, our group and many other researchers have proposed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has fa</context>
</contexts>
<marker>Ott, Choi, Cardie, Hancock, 2011</marker>
<rawString>M. Ott, Y. Choi, C. Cardie, and J. T Hancock. 2011. Finding Deceptive Opinion Spam by Any Stretch of the Imagination. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wang</author>
</authors>
<title>Anonymity, Social Image, and the Competition for Volunteers: A Case Study of the Online Market for Reviews. The B.E.</title>
<date>2010</date>
<journal>Journal of Economic Analysis &amp; Policy,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="2862" citStr="Wang, 2010" startWordPosition="449" endWordPosition="450">sed several algorithms and bridged algorithmic methodologies from various scientific disciplines including computational linguistics (Ott et al., 2011), social and behavioral sciences (Jindal and Liu, 2008; Mukherjee et al., 2013a, b), machine learning, data mining and Bayesian statistics (Mukherjee et al., 2012; Fei et al., 2013; Mukherjee et al., 2013c; Li et al., 2014b; Li et al., 2014a) to solve the problem. The field of deceptive opinion spam has gained a lot of interest in communications (Hancock et al., 2008), psycholinguistics communities (Gokhman et al., 2012), and economic analysis (Wang, 2010) apart from mainstream NLP and Web mining as attested by publications in top tier venues in their respective communities. The problem has far reaching implications in various allied NLP topics including Lie Detection, Forensic Linguistics, Opinion Trust and Veracity Verification and Plagiarism Detection. However, owing to the inherent nature of the problem, a unique blend of NLP, data mining, machine learning, social, behavioral, and statistical techniques are required which many NLP researchers may not be familiar with. In this tutorial, we aim to cover the problem in its full depth and width</context>
</contexts>
<marker>Wang, 2010</marker>
<rawString>Z. Wang. 2010. Anonymity, Social Image, and the Competition for Volunteers: A Case Study of the Online Market for Reviews. The B.E. Journal of Economic Analysis &amp; Policy, 10(1):1–34, January.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>