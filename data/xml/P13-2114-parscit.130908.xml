<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015995">
<title confidence="0.988001">
Temporal Signals Help Label Temporal Relations
</title>
<author confidence="0.987835">
Leon Derczynski and Robert Gaizauskas
</author>
<affiliation confidence="0.991174333333333">
Natural Language Processing Group
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.995179">
211 Portobello, S1 4DP, Sheffield, UK
</address>
<email confidence="0.999564">
{leon,robertg}@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.993914" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998426">
Automatically determining the temporal order
of events and times in a text is difficult, though
humans can readily perform this task. Some-
times events and times are related through use
of an explicit co-ordination which gives infor-
mation about the temporal relation: expres-
sions like “before” and “as soon as”. We in-
vestigate the rˆole that these co-ordinating tem-
poral signals have in determining the type of
temporal relations in discourse. Using ma-
chine learning, we improve upon prior ap-
proaches to the problem, achieving over 80%
accuracy at labelling the types of temporal re-
lation between events and times that are re-
lated by temporal signals.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999886161290323">
It is important to understand time in language. The
ability to express and comprehend expressions of time
enables us to plan, to tell stories, and to discuss change
in the world around us.
When we automatically extract temporal informa-
tion, we are often concerned with events and times – re-
ferred to collectively as temporal intervals. We might
ask, for example, “Who is the current President of the
USA?.” In order to extract an answer to this question
from a document collection, we need to identify events
related to persons becoming president and the times of
those events. Crucially, however, we also need to iden-
tify the temporal relations between these events and
times, perhaps, for example, by recognizing a tempo-
ral relation type from a set such as that of Allen (1983).
This last task, temporal relation typing, is challeng-
ing, and is the focus of this paper.
Temporal signals are words or phrases that act as
discourse markers that co-ordinate a pair of events or
times and explicitly state the nature of the temporal re-
lation that holds between them. For example, in “The
parade reached the town hall before noon”, the word
before is a temporal signal, co-ordinating the event
reached with the time noon. Intuitively, these signal
words act as discourse contain temporal ordering infor-
mation that human readers can readily access, and in-
deed this hypothesis is borne out empirically (Bestgen
and Vonk, 1999). In this paper, we present an in-depth
examination into the role temporal signals can play in
machine learning for temporal relation typing, within
the framework of TimeML (Pustejovsky et al., 2005).
</bodyText>
<sectionHeader confidence="0.999814" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999932484848485">
Temporal relation typing is not a new problem. Clas-
sical work using TimeML is that of Boguraev and
Ando (2005), Mani et al. (2007) and Yoshikawa et al.
(2009). The TempEval challenge series features re-
lation typing as a key task (Verhagen et al., 2009).
The take-home message from all this work is that tem-
poral relation typing is a hard problem, even using
advanced techniques and extensive engineering – ap-
proaches rarely achieve over 60% on typing relations
between two events or over 75% accuracy for those be-
tween an event and a time. Recent attempts to include
more linguistically sophisticated features representing
discourse, syntactic and semantic role information have
yielded but marginal improvements, e.g. Llorens et al.
(2010); Mirroshandel et al. (2011).
Although we focus solely on determining the types
of temporal relations, one must also identify which
pairs of temporal intervals should be temporally re-
lated. Previous work has covered the tasks of identi-
fying and typing temporal relations jointly with some
success (Denis and Muller, 2011; Do et al., 2012). The
TempEval3 challenge addresses exactly this task (Uz-
Zaman et al., 2013).
Investigations into using signals for temporal rela-
tion typing have had promising results. Lapata and
Lascarides (2006) learn temporal structure according
to these explicit signals, then predict temporal order-
ings in sentences without signals. As part of an early
TempEval system, Min et al. (2007) automatically an-
notate signals and associate them with temporal rela-
tions. They then include the signal text as a feature
for a relation type classifier. Their definition of sig-
nals varies somewhat from the traditional TimeML sig-
</bodyText>
<page confidence="0.995598">
645
</page>
<note confidence="0.530533">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 645–650,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<table confidence="0.999566666666667">
Event-event relations Overall Event-time relations Overall
Non-signalled Signalled Non-signalled Signalled
Baseline most-common-class 41.4% 57.4% 43.0% 49.2% 51.6% 49.6%
Maxent classifier 57.7% 58.6% 57.8% 81.4% 59.6% 77.3%
Error reduction 27.8% 2.74% 25.4% 64.5% 16.4% 55.5%
Sample size (number of relations) 3179 343 3 522 2 299 529 2 828
</table>
<tableCaption confidence="0.999945">
Table 1: Relation typing performance using the base feature set, for relations with and without a temporal signal.
</tableCaption>
<bodyText confidence="0.999974411764706">
nal definition, as they include words such as reporting
which would otherwise be annotated as an event. The
system achieves a 22% error reduction on a simplified
set of temporal relation types.
Later, Derczynski and Gaizauskas (2010) saw a 50%
error reduction in assignment of relation types on sig-
nalled relation instances from introducing simple fea-
tures describing a temporal signal’s interaction with the
events or times that it co-ordinates. The features for de-
scribing signals included the signal text itself and the
signal’s position in the document relative to the inter-
vals it co-ordinated. This led to a large increase in re-
lation typing accuracy to 82.19% for signalled event-
event relations, using a maximum entropy classifier.
Previous work has attempted to linguistically charac-
terise temporal signals (Br´ee et al., 1993; Derczynski
and Gaizauskas, 2011). Signal phrases typically fall
into one of three categories: monosemous as temporal
signals (e.g. “during”, “when”); bisemous as temporal
or spatial signals (e.g. “before”); or polysemous with
the temporal sense a minority class (e.g. “in”, “fol-
lowing”). Further, a signal phrase may take two argu-
ments, though its arguments need not be in the imme-
diate content and may be anaphoric. We leave the task
of automatic signal annotation to future work, instead
focusing on the impact that signals have on temporal
relation typing.
Our work builds on previous work by expanding the
study to include relations other than just event-event
relations, by extending the feature set, by doing tem-
poral relation labelling over a more carefully curated
version of the TimeBank corpus (see below), and by
providing detailed analysis of the performance of a set
of labelling techniques when using temporal signals.
</bodyText>
<sectionHeader confidence="0.996779" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.984034333333333">
We only approach the relation typing task, and we use
existing signal annotations – that is, we do not attempt
to automatically identify temporal signals.
The corpus used is the signal-curated version of
TimeBank (Pustejovsky et al., 2003). This corpus, TB-
sig,1 adds extra events, times and relations to Time-
Bank, in an effort to correct signal under-annotation in
the original corpus (Derczynski and Gaizauskas, 2011).
Like the original TimeBank corpus, it comprises 183
documents. In these, we are interested only in the tem-
poral relations that use a signal. There are 851 signals
annotated in the corpus, co-ordinating 886 temporal re-
</bodyText>
<footnote confidence="0.99295">
1See http://derczynski.com/sheffield/resources/tb sig.tar.bz2
</footnote>
<figureCaption confidence="0.656803">
lations (13.7% of all). For comparison, TimeBank has
688 signal annotations which co-ordinate 718 temporal
relations (11.2%).
</figureCaption>
<bodyText confidence="0.9998034">
When evaluating classifiers, we performed 10-fold
cross-validation, keeping splits at document level.
There are only 14 signalled time-time relations in this
corpus, which is not enough to support any generaliza-
tions, and so we disregard this interval type pairing.
As is common with statistical approaches to tempo-
ral relation typing, we also perform relation folding;
that is, to reduce the number of possible classes, we
sometimes invert argument order and relation type. For
example, A BEFORE B and B AFTER A convey the
same temporal relation, and so we can remove all AF-
TER-type relations by swapping their argument order
and converting them to BEFORE relations. This loss-
less process condenses the labels that our classifier has
to distinguish between, though classification remains a
multi-class problem.
We adopt the base feature set of Mani et al. (2007),
which consists mainly of TimeML event and time
annotation surface attributes. These are, for events:
class, aspect, modality, tense, polarity, part
of speech; and, for times: value, type, function
in document, mod, quant. To these are added
same-tense and same-aspect features, as well as
the string values of events/times.
The feature groups we use here are:
</bodyText>
<listItem confidence="0.9947436">
• Base – The attributes of TimeML annotations in-
volved (includes tense, aspect, polarity and so on
as above), as with previous approaches.
• Argument Ordering – Two features: a boolean
set if both arguments are in the same sentence (as
in Chambers et al. (2007)), and the text order of
argument intervals (as in Hepple et al. (2007)).
• Signal Ordering – Textual ordering is important
with temporal signals; compare “You walk before
you run” and “Before you walk you run”. We
add features accounting for relative textual posi-
tion of signal and arguments as per Derczynski
and Gaizauskas (2010). To these we add a feature
reporting whether the signal occurs in first, last,
or mid-sentence position, and features to indicate
whether each interval is in the same sentence as
the signal.
• Syntactic – We add syntactic features: fol-
lowing Bethard et al. (2007), the lowest com-
mon constituent label between each argument and
</listItem>
<page confidence="0.994832">
646
</page>
<table confidence="0.999881272727273">
Features Classifier Event-event accuracy Event-time accuracy
N/A Baseline most-common-class 57.4% 51.6%
Base Baseline maximum entropy 58.6% 59.6%
DG2010 Maximum entropy 72.6% 72.4%
Random forest 76.7% 78.6%
All Adaptive boosting 70.4% 73.0%
Naive Bayes 73.8% 71.5%
Maximum entropy 75.5% 78.1%
Linear SVC / Crammer-Singer 79.3% 75.6%
Linear SVC 80.7% 77.1%
Random forest 80.8% 80.3%
</table>
<tableCaption confidence="0.999801">
Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal
</tableCaption>
<bodyText confidence="0.999747777777778">
the signal; following Swampillai and Stevenson
(2011), the syntactic path from each argument
to the signal, using a top-level ROOT node for
cross-sentence paths; and three features indicat-
ing whether there is a temporal function tag (-TMP
between each of the intervals or the signal to the
root note. These features are generated using the
Stanford parser (Klein and Manning, 2003) and a
function tagger (Blaheta and Charniak, 2000).
</bodyText>
<listItem confidence="0.9900718">
• Signal Text – We add the signal’s raw string, as
well as its lower-case version and its lemma.
• DCT – For event-time relations, whether the time
expression also functions as the document’s cre-
ation timestamp.
</listItem>
<bodyText confidence="0.993494689655172">
Collectively, these feature groups comprise the All
feature set. For comparison, the feature set we reported
in previous work (Derczynski and Gaizauskas, 2010)
is also included, labeled DG2010. This set contains the
base and the signal ordering feature groups only, plus a
single signal feature for the signal raw string.
Using these feature representations we trained multi-
nomial naive Bayes (Rennie et al., 2003), maximum
entropy (Daum´e III, 2008), adaptive boosting (Fre-
und and Schapire, 1997; Zhu et al., 2009), multi-class
SVM (Crammer and Singer, 2002; Chang and Lin,
2011) and random forest2 (Breiman, 2001) classifiers
via Scikit-learn (Pedregosa et al., 2011).
We use two baselines: most-common-class and a
model trained with no signal features. We also in-
troduce two measures replicating earlier work: one
using the DG2010 features and the classifier used in
that work (maximum entropy), and another using the
DG2010 features with the best-performing classifier
under our All feature set, in order to see if performance
changes are due to features or classifier.
Classifiers were evaluated by determining if the class
they output matched the relation type in TB-sig. Re-
sults are given in Table 2. For comparison with the
general case, i.e. for both signalled and non-signalled
temporal relation instances, we list performance with
a maximum entropy classifier and the base feature set
2With nestimators = 200, a minimum of one sample per
node, and no maximum depth.
</bodyText>
<figureCaption confidence="0.9820915">
Figure 1: Effect of training data size on relation typing
performance.
</figureCaption>
<bodyText confidence="0.999955166666667">
on TB-sig’s temporal relations. Results are in Table 1.
These are split into those that use a signal and those that
do not, though no features relaying signal information
are included.
In order to assess the adequacy of the dataset in
terms of size, we also examined performance using a
maximum entropy classifier learned from varying sub-
proportions of the training data. This was measured
over event-event relations, using all features. Results
are given in Figure 1. That performance appears to sta-
bilise and level off indicates that the training set is of
sufficient size for these experiments.
</bodyText>
<sectionHeader confidence="0.99543" genericHeader="method">
4 Analysis
</sectionHeader>
<bodyText confidence="0.999947916666667">
The results in Table 2 echo earlier findings and intu-
ition: temporal signals are useful in temporal relation
typing. Results support that signals are not only helpful
in event-event relation typing but also event-time typ-
ing. For comparison, inter-annotator agreement across
all temporal relation labels, i.e. signalled and non-
signalled relations, in TimeBank is 77%.
Using the maximum entropy classifier, our approach
gives a 2.9% absolute performance increase over the
DG2010 feature set for event-event relations (10.6% er-
ror reduction) and a 5.7% absolute increase for event-
time relations (20.7% error reduction). Random forests
</bodyText>
<page confidence="0.988217">
647
</page>
<table confidence="0.9999709375">
Feature sets Evt-evt Evt-time
All 80.8% 80.3%
All-argument order 80.8% 78.3%
All-signal order 79.0% 77.5%
All-syntax 79.2% 79.6%
All-signal text 70.8% 72.7%
All-DCT 79.9% 79.4%
Base 54.2% 53.9%
Base+argument order 56.8% 60.1%
Base+signal order 59.7% 65.0%
Base+syntax 70.0% 71.0%
Base+signal text 75.5% 66.3%
Base+DCT 54.2% 53.9%
Base+signal text+signal order 80.4% 76.9%
Base+signal text+syntax 79.0% 74.1%
Base+arg order+signal order 77.8% 75.2%
</table>
<tableCaption confidence="0.999474">
Table 3: Relation typing accuracy based on various fea-
</tableCaption>
<bodyText confidence="0.976305897435897">
ture combinations, using random forests. Bold figures
indicate the largest performance change.
offer better performance under both feature sets, with
the extended features achieving notable error reduction
over DG2010 – 17.6% for event-event, 7.9% for event-
time relations. Linear support vector classification pro-
vided rapid labelling and comparable performance for
event-event relations but was accuracy was not as good
as random forests for event-time relation labelling.
Note, figures reported earlier in Derczynski and
Gaizauskas (2010) are not directly comparable to the
DG2010 figures reported here, as here we are using the
better-annotated TB-sig corpus, which contains a larger
and more varied set of temporal signal annotations.
Although we are only examining the 13.7% of tem-
poral relations that are co-ordinated with a signal, it
is important to note the performance of conventional
classification approaches on this subset of temporal
relations. Specifically, the error reduction relative to
the baseline that is achieved without signal features is
much lower on relations that use signals than on non-
signalled relations (Table 1). Thus, temporal relations
that use a signal appear to be more difficult to clas-
sify than other relations, unless signal information is
present in the features. This may be due to differences
in how signals are used by authors. One explanation
is that signals may be used in the stead of temporal or-
dering information in surrounding discourse, such as
modulations of dominant tense or aspect (Derczynski
and Gaizauskas, 2013).
Unlike earlier work using maxent, we experiment
with a variety of classifiers, and find a consistent im-
provement in temporal relation typing using signal fea-
tures. With the notable exception of adaptive boost-
ing, classifiers with preference bias (Liu et al., 2002)
– AdaBoost, random trees and SVC – performed best
in this task. Conversely, those tending toward the in-
dependence assumption (naive Bayes and maxent) did
not capitalise as effectively on the training data.
</bodyText>
<table confidence="0.998622857142857">
Features Evt-evt Evt-time
All 80.8% 80.3%
All-signal text 70.8% 72.7%
All-signal text-argument order 70.7% 72.2%
All-signal text-signal order 69.5% 71.2%
All-signal text-syntax 59.5% 69.0%
All-signal text-DCT 70.8% 72.8%
</table>
<tableCaption confidence="0.988433">
Table 4: Feature ablation without signal text features.
Bold figures indicate largest performance change.
</tableCaption>
<bodyText confidence="0.999676444444445">
We also investigated the impact of each feature
group on the best-performing classifier (random forests
with n = 200) through feature ablation. Results are
given in Table 3. Ablation suggested that the signal text
features (signal string, lower case string, head word and
lemma) had most impact in event-event relation typing,
though were second to syntax features in event-time re-
lations. Removing other feature groups gave only mi-
nor performance decreases.
We also experimented with adding feature groups to
the base set one-by-one. All but DCT features gave
above-baseline improvement, though argument order-
ing features were not very helpful for event-event re-
lation typing. Signal text features gave the strongest
improvement over baseline for event-event relations,
but syntax gave a larger improvement for event-time
relations. Accordingly, it may be useful to distinguish
between event-event and event-time relations when ex-
tracting temporal information using syntax (c.f. the ap-
proach of Wang et al. (2010)).
A strong above-baseline performance was still ob-
tained even when signal text features were removed,
which included the signal text itself. This was interest-
ing, as signal phrases can indicate quite different tem-
poral orderings (e.g. “Open the box while it rains” vs.
“Open the box before it rains”, and the words used are
typically critical to correct interpretation of the tempo-
ral relation. Further, the model is able to generalise
beyond particular signal phrase choices. To investigate
further, we examined the performance impact of each
group sans “signal text” features (Table 4). In this case,
removing the syntactic features had the greatest (neg-
ative) impact on performance, though the absolute im-
pact on event-event relations (a drop of 11.3%) was far
lower than that on event-time relations (3.7%).
To examine helpful features, we trained a max-
ent classifier on the entire dataset and collected fea-
ture:value pairs. These were then ranked by their
weight. The ten largest-weighted pairings for event-
event relations (the hardest problem in overall temporal
relation typing) are given in Table 5. Prefixes of 1- and
2- correspond to the two interval arguments (events).
Negative values are those where the presence of a par-
ticular feature:value pair suggests the mentioned class
is not applicable.
</bodyText>
<page confidence="0.995248">
648
</page>
<table confidence="0.999819272727273">
Weight Feature Value Class
9.346 2-polarity POS ENDS
-8.713 1-2-same-sent True BEGINS
-7.861 2-aspect NONE BEGINS
-7.256 1-aspect NONE INCLUDES
6.564 2-sig-synt-path NN-NP-IN INCLUDES
6.519 signal-lower before ENDS
-6.294 2-tense NONE BEGINS
-5.908 2-modality None ENDS
5.643 2-text took BEGINS
-5.580 1-modality None ENDS
</table>
<tableCaption confidence="0.999829">
Table 5: Top ten largest-weighted feature:value pairs.
</tableCaption>
<bodyText confidence="0.9961784">
It can be seen that BEGINS and INCLUDES rela-
tionships are not indicated if the arguments have no
TimeML aspect assigned; this is what one might ex-
pect, given how aspect is used in English, with these
temporal relation types corresponding to event starts
and the progressive. Also, notice how a particular syn-
tactic path, connecting adjacent nominalised event and
the word in acting as a signal, indicate a temporal inclu-
sion relationship. Temporal polysemy, where a word
has more than one possible temporal interpretation,
is also observable here (Derczynski and Gaizauskas
(2011) examine this polysemy in depth). This is vis-
ible in how the temporal signal phrase “before” is not,
as one might expect, a strong indicator of a BEFORE or
even AFTER relation, but of an ENDS relationship.
</bodyText>
<sectionHeader confidence="0.993858" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99997878125">
This paper set out to investigate the rˆole of temporal
signals in predicting the type of temporal relation be-
tween two intervals. The paper demonstrated the util-
ity of temporal signals in this task, and identified ap-
proaches for using the information these signals con-
tain, which performed consistently better than the state-
of-the-art across a range of machine learning classi-
fiers. Further, it identified the impact that signal text,
signal order and syntax features had in temporal rela-
tion typing of signalled relations.
Two directions of future work are indicated. Firstly,
the utility of signals prompts investigation into detect-
ing which words in a given text occur as temporal sig-
nals. Secondly, it is intuitive that temporal signals ex-
plicitly indicate related pairs of intervals (i.e. events or
times). So, the task of deciding which interval pair(s) a
temporal signal co-ordinates must be approached.
Although we have found a method for achieving
good temporal relation typing performance on a subset
of temporal relations, the greater problem of general
temporal relation typing remains. A better understand-
ing of the semantics of events, times, signals and how
they are related together through syntax may provide
further insights into the temporal relation typing task.
Finally, Bethard et al. (2007) reached high temporal
relation typing performance on one a subset of relations
(events and times in the same sentence); we reach high
temporal relation typing performance on another subset
of relations – those using a temporal signal. Identify-
ing further explicit sources of temporal information ap-
plicable to new sets of relations may reveal promising
paths for investigation.
</bodyText>
<sectionHeader confidence="0.955073" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.995221">
The first author was supported by UK EPSRC grant
EP/K017896/1, uComp (http://www.ucomp.eu/).
</bodyText>
<sectionHeader confidence="0.998518" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.840617365853659">
J. Allen. 1983. Maintaining knowledge about temporal
intervals. Communications of the ACM, 26(11):832–
843.
Y. Bestgen and W. Vonk. 1999. Temporal adverbials as
segmentation markers in discourse comprehension.
Journal of Memory and Language, 42(1):74–87.
S. Bethard, J. Martin, and S. Klingenstein. 2007.
Timelines from text: Identification of syntactic tem-
poral relations. In Proceedings of the International
Conference on Semantic Computing, pages 11–18.
D. Blaheta and E. Charniak. 2000. Assigning function
tags to parsed text. In Proceedings of the meeting
of the North American chapter of the Association for
Computational Linguistics, pages 234–240. ACL.
B. Boguraev and R. K. Ando. 2005. TimeBank-Driven
TimeML Analysis. In G. Katz, J. Pustejovsky, and
F. Schilder, editors, Annotating, Extracting and Rea-
soning about Time and Events, number 05151 in
Dagstuhl Seminar Proceedings, Dagstuhl, Germany.
Internationales Begegnungs- und Forschungszen-
trum f¨ur Informatik (IBFI), Schloss Dagstuhl, Ger-
many.
D. Br´ee, A. Feddag, and I. Pratt. 1993. Towards a for-
malization of the semantics of some temporal prepo-
sitions. Time &amp; Society, 2(2):219.
L. Breiman. 2001. Random forests. Machine Learn-
ing, 45(1):5–32.
N. Chambers, S. Wang, and D. Jurafsky. 2007. Clas-
sifying temporal relations between events. In Pro-
ceedings of the 45th meeting of the Association for
Computational Linguistics, pages 173–176. ACL.
C.-C. Chang and C.-J. Lin. 2011. LIBSVM: a library
for support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2(3):27.
K. Crammer and Y. Singer. 2002. On the algorith-
mic implementation of multiclass kernel-based vec-
tor machines. The Journal of Machine Learning Re-
search, 2:265–292.
H. Daum´e III. 2008. MegaM: Maximum entropy
model optimization package. ACL Data and Code
Repository, ADCR2008C003, 50.
</reference>
<page confidence="0.998088">
649
</page>
<reference confidence="0.953672943396227">
P. Denis and P. Muller. 2011. Predicting globally-
coherent temporal structures from texts via endpoint
inference and graph decomposition. In Proceedings
of the International Joint Conference on Artificial In-
telligence, pages 1788–1793. AAAI Press.
L. Derczynski and R. Gaizauskas. 2010. Using Sig-
nals to Improve Automatic Classification of Tempo-
ral Relations. In Proceedings of 15th Student Ses-
sion of the European Summer School for Logic, Lan-
guage and Information, pages 224–231. FoLLI.
L. Derczynski and R. Gaizauskas. 2011. A Corpus-
based Study of Temporal Signals. In Proceedings of
the Corpus Linguistics Conference.
L. Derczynski and R. Gaizauskas. 2013. Empirical
Validation of Reichenbach’s Tense Framework. In
Proceedings of the 10th International Conference on
Computational Semantics, pages 71–82. ACL.
Q. X. Do, W. Lu, and D. Roth. 2012. Joint infer-
ence for event timeline construction. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 677–687. ACL.
Y. Freund and R. E. Schapire. 1997. A decision-
theoretic generalization of on-line learning and an
application to boosting. Journal of Computer and
System Sciences, 55(1):119–139.
M. Hepple, A. Setzer, and R. Gaizauskas. 2007.
USFD: preliminary exploration of features and clas-
sifiers for the TempEval-2007 tasks. In Proceedings
of the 4th International Workshop on Semantic Eval-
uations, pages 438–441. ACL.
D. Klein and C. D. Manning. 2003. Accurate unlex-
icalized parsing. In Proceedings of the 41st meet-
ing of the Association for Computational Linguistics,
pages 423–430. ACL.
M. Lapata and A. Lascarides. 2006. Learning
sentence-internal temporal relations. Journal of Ar-
tificial Intelligence Research, 27(1):85–117.
Y. Liu, Y. Yang, and J. Carbonell. 2002. Boosting to
correct inductive bias in text classification. In Pro-
ceedings of the 11th international Conference on In-
formation and Knowledge Management, pages 348–
355. ACM.
H. Llorens, E. Saquete, and B. Navarro. 2010. TIPSem
(English and Spanish): Evaluating CRFs and Se-
mantic Roles in TempEval-2. In Proceedings of
SemEval-2010. ACL.
I. Mani, B. Wellner, M. Verhagen, and J. Pustejovsky.
2007. Three approaches to learning TLINKS in
TimeML. Technical report, CS-07-268, Brandeis
University.
C. Min, M. Srikanth, and A. Fowler. 2007. LCC-TE:
A hybrid approach to temporal relation identification
in news text. In Proceedings of the 4th International
Workshop on Semantic Evaluations, pages 219–222.
ACL.
S. A. Mirroshandel, G. Ghassem-Sani, and
M. Khayyamian. 2011. Using syntactic-based
kernels for classifying temporal relations. Journal
of Computer Science and Technology, 26(1):68–80.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, et al. 2011. Scikit-learn: Ma-
chine learning in Python. The Journal of Machine
Learning Research, 12:2825–2830.
J. Pustejovsky, R. Sauri, R. Gaizauskas, A. Setzer,
L. Ferro, et al. 2003. The TimeBank Corpus. In
Proceedings of the Corpus Linguistics Conference,
pages 647–656.
J. Pustejovsky, J. Castano, R. Ingria, R. Sauri,
R. Gaizauskas, A. Setzer, G. Katz, and D. Radev.
2005. TimeML: Robust specification of event and
temporal expressions in text. In I. Mani, J. Puste-
jovsky, and R. Gaizauskas, editors, The language of
time: a reader. Oxford University Press.
J. D. Rennie, L. Shih, J. Teevan, and D. Karger. 2003.
Tackling the Poor Assumptions of Naive Bayes Text
Classifiers. In Proceedings of the International Con-
ference on Machine Learning. AAAI Press.
K. Swampillai and M. Stevenson. 2011. Extracting re-
lations within and across sentences. In Proceedings
of the International Conference Recent Advances in
Natural Language Processing, pages 25–32. ACL.
N. UzZaman, H. Llorens, L. Derczynski, M. Verhagen,
J. F. Allen, and J. Pustejovsky. 2013. SemEval-2013
Task 1: TempEval-3: Evaluating Time Expressions,
Events, and Temporal Relations. In Proceedings of
the 7th International Workshop on Semantic Evalu-
ations.
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hep-
ple, J. Moszkowicz, and J. Pustejovsky. 2009.
The TempEval challenge: identifying temporal re-
lations in text. Language Resources and Evaluation,
43(2):161–179.
W. Wang, J. Su, and C. L. Tan. 2010. Kernel based
discourse relation recognition with temporal order-
ing information. In Proceedings of the 48th meet-
ing of the Association for Computational Linguistics,
pages 710–719. ACL.
K. Yoshikawa, S. Riedel, M. Asahara, and Y. Mat-
sumoto. 2009. Jointly identifying temporal relations
with Markov logic. In Proceedings of the Interna-
tional Joint Conference on Natural Language Pro-
cessing, pages 405–413. ACL.
J. Zhu, H. Zou, S. Rosset, and T. Hastie. 2009. Multi-
class AdaBoost. Statistics and Its Interface, 2:349–
360.
</reference>
<page confidence="0.997954">
650
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.801228">
<title confidence="0.998852">Temporal Signals Help Label Temporal Relations</title>
<author confidence="0.951907">Leon Derczynski</author>
<author confidence="0.951907">Robert</author>
<affiliation confidence="0.95445">Natural Language Processing Department of Computer University of</affiliation>
<address confidence="0.997185">211 Portobello, S1 4DP, Sheffield, UK</address>
<abstract confidence="0.996176">Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expreslike soon We investigate the rˆole that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Communications of the ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<pages>843</pages>
<contexts>
<context position="1696" citStr="Allen (1983)" startWordPosition="270" endWordPosition="271"> the world around us. When we automatically extract temporal information, we are often concerned with events and times – referred to collectively as temporal intervals. We might ask, for example, “Who is the current President of the USA?.” In order to extract an answer to this question from a document collection, we need to identify events related to persons becoming president and the times of those events. Crucially, however, we also need to identify the temporal relations between these events and times, perhaps, for example, by recognizing a temporal relation type from a set such as that of Allen (1983). This last task, temporal relation typing, is challenging, and is the focus of this paper. Temporal signals are words or phrases that act as discourse markers that co-ordinate a pair of events or times and explicitly state the nature of the temporal relation that holds between them. For example, in “The parade reached the town hall before noon”, the word before is a temporal signal, co-ordinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>J. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM, 26(11):832– 843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bestgen</author>
<author>W Vonk</author>
</authors>
<title>Temporal adverbials as segmentation markers in discourse comprehension.</title>
<date>1999</date>
<journal>Journal of Memory and Language,</journal>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="2337" citStr="Bestgen and Vonk, 1999" startWordPosition="374" endWordPosition="377">temporal relation typing, is challenging, and is the focus of this paper. Temporal signals are words or phrases that act as discourse markers that co-ordinate a pair of events or times and explicitly state the nature of the temporal relation that holds between them. For example, in “The parade reached the town hall before noon”, the word before is a temporal signal, co-ordinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and ex</context>
</contexts>
<marker>Bestgen, Vonk, 1999</marker>
<rawString>Y. Bestgen and W. Vonk. 1999. Temporal adverbials as segmentation markers in discourse comprehension. Journal of Memory and Language, 42(1):74–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bethard</author>
<author>J Martin</author>
<author>S Klingenstein</author>
</authors>
<title>Timelines from text: Identification of syntactic temporal relations.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Semantic Computing,</booktitle>
<pages>11--18</pages>
<contexts>
<context position="9581" citStr="Bethard et al. (2007)" startWordPosition="1510" endWordPosition="1513">in Chambers et al. (2007)), and the text order of argument intervals (as in Hepple et al. (2007)). • Signal Ordering – Textual ordering is important with temporal signals; compare “You walk before you run” and “Before you walk you run”. We add features accounting for relative textual position of signal and arguments as per Derczynski and Gaizauskas (2010). To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal. • Syntactic – We add syntactic features: following Bethard et al. (2007), the lowest common constituent label between each argument and 646 Features Classifier Event-event accuracy Event-time accuracy N/A Baseline most-common-class 57.4% 51.6% Base Baseline maximum entropy 58.6% 59.6% DG2010 Maximum entropy 72.6% 72.4% Random forest 76.7% 78.6% All Adaptive boosting 70.4% 73.0% Naive Bayes 73.8% 71.5% Maximum entropy 75.5% 78.1% Linear SVC / Crammer-Singer 79.3% 75.6% Linear SVC 80.7% 77.1% Random forest 80.8% 80.3% Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal the signal; following Swampillai and Stevenson (201</context>
</contexts>
<marker>Bethard, Martin, Klingenstein, 2007</marker>
<rawString>S. Bethard, J. Martin, and S. Klingenstein. 2007. Timelines from text: Identification of syntactic temporal relations. In Proceedings of the International Conference on Semantic Computing, pages 11–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blaheta</author>
<author>E Charniak</author>
</authors>
<title>Assigning function tags to parsed text.</title>
<date>2000</date>
<booktitle>In Proceedings of the meeting of the North American chapter of the Association for Computational Linguistics,</booktitle>
<pages>234--240</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="10562" citStr="Blaheta and Charniak, 2000" startWordPosition="1659" endWordPosition="1662"> 78.1% Linear SVC / Crammer-Singer 79.3% 75.6% Linear SVC 80.7% 77.1% Random forest 80.8% 80.3% Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal the signal; following Swampillai and Stevenson (2011), the syntactic path from each argument to the signal, using a top-level ROOT node for cross-sentence paths; and three features indicating whether there is a temporal function tag (-TMP between each of the intervals or the signal to the root note. These features are generated using the Stanford parser (Klein and Manning, 2003) and a function tagger (Blaheta and Charniak, 2000). • Signal Text – We add the signal’s raw string, as well as its lower-case version and its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive</context>
</contexts>
<marker>Blaheta, Charniak, 2000</marker>
<rawString>D. Blaheta and E. Charniak. 2000. Assigning function tags to parsed text. In Proceedings of the meeting of the North American chapter of the Association for Computational Linguistics, pages 234–240. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>R K Ando</author>
</authors>
<title>TimeBank-Driven TimeML Analysis. In</title>
<date>2005</date>
<booktitle>Annotating, Extracting and Reasoning about Time and Events, number 05151 in Dagstuhl Seminar Proceedings, Dagstuhl, Germany. Internationales Begegnungs- und Forschungszentrum f¨ur Informatik (IBFI), Schloss Dagstuhl,</booktitle>
<editor>G. Katz, J. Pustejovsky, and F. Schilder, editors,</editor>
<location>Germany.</location>
<contexts>
<context position="2663" citStr="Boguraev and Ando (2005)" startWordPosition="428" endWordPosition="431">oon”, the word before is a temporal signal, co-ordinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvemen</context>
</contexts>
<marker>Boguraev, Ando, 2005</marker>
<rawString>B. Boguraev and R. K. Ando. 2005. TimeBank-Driven TimeML Analysis. In G. Katz, J. Pustejovsky, and F. Schilder, editors, Annotating, Extracting and Reasoning about Time and Events, number 05151 in Dagstuhl Seminar Proceedings, Dagstuhl, Germany. Internationales Begegnungs- und Forschungszentrum f¨ur Informatik (IBFI), Schloss Dagstuhl, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Br´ee</author>
<author>A Feddag</author>
<author>I Pratt</author>
</authors>
<title>Towards a formalization of the semantics of some temporal prepositions.</title>
<date>1993</date>
<journal>Time &amp; Society,</journal>
<volume>2</volume>
<issue>2</issue>
<marker>Br´ee, Feddag, Pratt, 1993</marker>
<rawString>D. Br´ee, A. Feddag, and I. Pratt. 1993. Towards a formalization of the semantics of some temporal prepositions. Time &amp; Society, 2(2):219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Breiman</author>
</authors>
<title>Random forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="11391" citStr="Breiman, 2001" startWordPosition="1793" endWordPosition="1794">ollectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evaluated by determining if the class they output matched the relation type in TB-sig. Results are given in Table 2. For com</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>L. Breiman. 2001. Random forests. Machine Learning, 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>S Wang</author>
<author>D Jurafsky</author>
</authors>
<title>Classifying temporal relations between events.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th meeting of the Association for Computational Linguistics,</booktitle>
<pages>173--176</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="8985" citStr="Chambers et al. (2007)" startWordPosition="1410" endWordPosition="1413"> which consists mainly of TimeML event and time annotation surface attributes. These are, for events: class, aspect, modality, tense, polarity, part of speech; and, for times: value, type, function in document, mod, quant. To these are added same-tense and same-aspect features, as well as the string values of events/times. The feature groups we use here are: • Base – The attributes of TimeML annotations involved (includes tense, aspect, polarity and so on as above), as with previous approaches. • Argument Ordering – Two features: a boolean set if both arguments are in the same sentence (as in Chambers et al. (2007)), and the text order of argument intervals (as in Hepple et al. (2007)). • Signal Ordering – Textual ordering is important with temporal signals; compare “You walk before you run” and “Before you walk you run”. We add features accounting for relative textual position of signal and arguments as per Derczynski and Gaizauskas (2010). To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal. • Syntactic – We add syntactic features: following Bethard et al. (2007), th</context>
</contexts>
<marker>Chambers, Wang, Jurafsky, 2007</marker>
<rawString>N. Chambers, S. Wang, and D. Jurafsky. 2007. Classifying temporal relations between events. In Proceedings of the 45th meeting of the Association for Computational Linguistics, pages 173–176. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-C Chang</author>
<author>C-J Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="11356" citStr="Chang and Lin, 2011" startWordPosition="1786" endWordPosition="1789">s as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evaluated by determining if the class they output matched the relation type in TB-sig. Re</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>C.-C. Chang and C.-J. Lin. 2011. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>Y Singer</author>
</authors>
<title>On the algorithmic implementation of multiclass kernel-based vector machines.</title>
<date>2002</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>2--265</pages>
<contexts>
<context position="11334" citStr="Crammer and Singer, 2002" startWordPosition="1782" endWordPosition="1785">e expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evaluated by determining if the class they output matched the relat</context>
</contexts>
<marker>Crammer, Singer, 2002</marker>
<rawString>K. Crammer and Y. Singer. 2002. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine Learning Research, 2:265–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daum´e</author>
</authors>
<title>MegaM: Maximum entropy model optimization package.</title>
<date>2008</date>
<booktitle>ACL Data and Code Repository, ADCR2008C003,</booktitle>
<pages>50</pages>
<marker>Daum´e, 2008</marker>
<rawString>H. Daum´e III. 2008. MegaM: Maximum entropy model optimization package. ACL Data and Code Repository, ADCR2008C003, 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>P Muller</author>
</authors>
<title>Predicting globallycoherent temporal structures from texts via endpoint inference and graph decomposition.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1788--1793</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="3613" citStr="Denis and Muller, 2011" startWordPosition="578" endWordPosition="581">0% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal orderings in sentences without signals. As part of an early TempEval system, Min et al. (2007) automatically annotate signals and associate them with temporal relations. They then include the signal text as a feature for a relation type classifier. Their definition of signals varies somewhat from th</context>
</contexts>
<marker>Denis, Muller, 2011</marker>
<rawString>P. Denis and P. Muller. 2011. Predicting globallycoherent temporal structures from texts via endpoint inference and graph decomposition. In Proceedings of the International Joint Conference on Artificial Intelligence, pages 1788–1793. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Derczynski</author>
<author>R Gaizauskas</author>
</authors>
<title>Using Signals to Improve Automatic Classification of Temporal Relations.</title>
<date>2010</date>
<booktitle>In Proceedings of 15th Student Session of the European Summer School for Logic, Language and Information,</booktitle>
<pages>224--231</pages>
<publisher>FoLLI.</publisher>
<contexts>
<context position="5117" citStr="Derczynski and Gaizauskas (2010)" startWordPosition="804" endWordPosition="807">l Non-signalled Signalled Non-signalled Signalled Baseline most-common-class 41.4% 57.4% 43.0% 49.2% 51.6% 49.6% Maxent classifier 57.7% 58.6% 57.8% 81.4% 59.6% 77.3% Error reduction 27.8% 2.74% 25.4% 64.5% 16.4% 55.5% Sample size (number of relations) 3179 343 3 522 2 299 529 2 828 Table 1: Relation typing performance using the base feature set, for relations with and without a temporal signal. nal definition, as they include words such as reporting which would otherwise be annotated as an event. The system achieves a 22% error reduction on a simplified set of temporal relation types. Later, Derczynski and Gaizauskas (2010) saw a 50% error reduction in assignment of relation types on signalled relation instances from introducing simple features describing a temporal signal’s interaction with the events or times that it co-ordinates. The features for describing signals included the signal text itself and the signal’s position in the document relative to the intervals it co-ordinated. This led to a large increase in relation typing accuracy to 82.19% for signalled eventevent relations, using a maximum entropy classifier. Previous work has attempted to linguistically characterise temporal signals (Br´ee et al., 199</context>
<context position="9317" citStr="Derczynski and Gaizauskas (2010)" startWordPosition="1465" endWordPosition="1468">s. The feature groups we use here are: • Base – The attributes of TimeML annotations involved (includes tense, aspect, polarity and so on as above), as with previous approaches. • Argument Ordering – Two features: a boolean set if both arguments are in the same sentence (as in Chambers et al. (2007)), and the text order of argument intervals (as in Hepple et al. (2007)). • Signal Ordering – Textual ordering is important with temporal signals; compare “You walk before you run” and “Before you walk you run”. We add features accounting for relative textual position of signal and arguments as per Derczynski and Gaizauskas (2010). To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal. • Syntactic – We add syntactic features: following Bethard et al. (2007), the lowest common constituent label between each argument and 646 Features Classifier Event-event accuracy Event-time accuracy N/A Baseline most-common-class 57.4% 51.6% Base Baseline maximum entropy 58.6% 59.6% DG2010 Maximum entropy 72.6% 72.4% Random forest 76.7% 78.6% All Adaptive boosting 70.4% 73.0% Naive Bayes 73.8% 71.5% Max</context>
<context position="10935" citStr="Derczynski and Gaizauskas, 2010" startWordPosition="1719" endWordPosition="1722">eatures indicating whether there is a temporal function tag (-TMP between each of the intervals or the signal to the root note. These features are generated using the Stanford parser (Klein and Manning, 2003) and a function tagger (Blaheta and Charniak, 2000). • Signal Text – We add the signal’s raw string, as well as its lower-case version and its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We </context>
<context position="14612" citStr="Derczynski and Gaizauskas (2010)" startWordPosition="2278" endWordPosition="2281">se+arg order+signal order 77.8% 75.2% Table 3: Relation typing accuracy based on various feature combinations, using random forests. Bold figures indicate the largest performance change. offer better performance under both feature sets, with the extended features achieving notable error reduction over DG2010 – 17.6% for event-event, 7.9% for eventtime relations. Linear support vector classification provided rapid labelling and comparable performance for event-event relations but was accuracy was not as good as random forests for event-time relation labelling. Note, figures reported earlier in Derczynski and Gaizauskas (2010) are not directly comparable to the DG2010 figures reported here, as here we are using the better-annotated TB-sig corpus, which contains a larger and more varied set of temporal signal annotations. Although we are only examining the 13.7% of temporal relations that are co-ordinated with a signal, it is important to note the performance of conventional classification approaches on this subset of temporal relations. Specifically, the error reduction relative to the baseline that is achieved without signal features is much lower on relations that use signals than on nonsignalled relations (Table</context>
</contexts>
<marker>Derczynski, Gaizauskas, 2010</marker>
<rawString>L. Derczynski and R. Gaizauskas. 2010. Using Signals to Improve Automatic Classification of Temporal Relations. In Proceedings of 15th Student Session of the European Summer School for Logic, Language and Information, pages 224–231. FoLLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Derczynski</author>
<author>R Gaizauskas</author>
</authors>
<title>A Corpusbased Study of Temporal Signals.</title>
<date>2011</date>
<booktitle>In Proceedings of the Corpus Linguistics Conference.</booktitle>
<contexts>
<context position="5752" citStr="Derczynski and Gaizauskas, 2011" startWordPosition="903" endWordPosition="906">w a 50% error reduction in assignment of relation types on signalled relation instances from introducing simple features describing a temporal signal’s interaction with the events or times that it co-ordinates. The features for describing signals included the signal text itself and the signal’s position in the document relative to the intervals it co-ordinated. This led to a large increase in relation typing accuracy to 82.19% for signalled eventevent relations, using a maximum entropy classifier. Previous work has attempted to linguistically characterise temporal signals (Br´ee et al., 1993; Derczynski and Gaizauskas, 2011). Signal phrases typically fall into one of three categories: monosemous as temporal signals (e.g. “during”, “when”); bisemous as temporal or spatial signals (e.g. “before”); or polysemous with the temporal sense a minority class (e.g. “in”, “following”). Further, a signal phrase may take two arguments, though its arguments need not be in the immediate content and may be anaphoric. We leave the task of automatic signal annotation to future work, instead focusing on the impact that signals have on temporal relation typing. Our work builds on previous work by expanding the study to include relat</context>
<context position="7092" citStr="Derczynski and Gaizauskas, 2011" startWordPosition="1115" endWordPosition="1118">ng over a more carefully curated version of the TimeBank corpus (see below), and by providing detailed analysis of the performance of a set of labelling techniques when using temporal signals. 3 Experimental Setup We only approach the relation typing task, and we use existing signal annotations – that is, we do not attempt to automatically identify temporal signals. The corpus used is the signal-curated version of TimeBank (Pustejovsky et al., 2003). This corpus, TBsig,1 adds extra events, times and relations to TimeBank, in an effort to correct signal under-annotation in the original corpus (Derczynski and Gaizauskas, 2011). Like the original TimeBank corpus, it comprises 183 documents. In these, we are interested only in the temporal relations that use a signal. There are 851 signals annotated in the corpus, co-ordinating 886 temporal re1See http://derczynski.com/sheffield/resources/tb sig.tar.bz2 lations (13.7% of all). For comparison, TimeBank has 688 signal annotations which co-ordinate 718 temporal relations (11.2%). When evaluating classifiers, we performed 10-fold cross-validation, keeping splits at document level. There are only 14 signalled time-time relations in this corpus, which is not enough to supp</context>
<context position="19726" citStr="Derczynski and Gaizauskas (2011)" startWordPosition="3065" endWordPosition="3068">le 5: Top ten largest-weighted feature:value pairs. It can be seen that BEGINS and INCLUDES relationships are not indicated if the arguments have no TimeML aspect assigned; this is what one might expect, given how aspect is used in English, with these temporal relation types corresponding to event starts and the progressive. Also, notice how a particular syntactic path, connecting adjacent nominalised event and the word in acting as a signal, indicate a temporal inclusion relationship. Temporal polysemy, where a word has more than one possible temporal interpretation, is also observable here (Derczynski and Gaizauskas (2011) examine this polysemy in depth). This is visible in how the temporal signal phrase “before” is not, as one might expect, a strong indicator of a BEFORE or even AFTER relation, but of an ENDS relationship. 5 Conclusion This paper set out to investigate the rˆole of temporal signals in predicting the type of temporal relation between two intervals. The paper demonstrated the utility of temporal signals in this task, and identified approaches for using the information these signals contain, which performed consistently better than the stateof-the-art across a range of machine learning classifier</context>
</contexts>
<marker>Derczynski, Gaizauskas, 2011</marker>
<rawString>L. Derczynski and R. Gaizauskas. 2011. A Corpusbased Study of Temporal Signals. In Proceedings of the Corpus Linguistics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Derczynski</author>
<author>R Gaizauskas</author>
</authors>
<title>Empirical Validation of Reichenbach’s Tense Framework.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Semantics,</booktitle>
<pages>71--82</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="15640" citStr="Derczynski and Gaizauskas, 2013" startWordPosition="2442" endWordPosition="2445">of temporal relations. Specifically, the error reduction relative to the baseline that is achieved without signal features is much lower on relations that use signals than on nonsignalled relations (Table 1). Thus, temporal relations that use a signal appear to be more difficult to classify than other relations, unless signal information is present in the features. This may be due to differences in how signals are used by authors. One explanation is that signals may be used in the stead of temporal ordering information in surrounding discourse, such as modulations of dominant tense or aspect (Derczynski and Gaizauskas, 2013). Unlike earlier work using maxent, we experiment with a variety of classifiers, and find a consistent improvement in temporal relation typing using signal features. With the notable exception of adaptive boosting, classifiers with preference bias (Liu et al., 2002) – AdaBoost, random trees and SVC – performed best in this task. Conversely, those tending toward the independence assumption (naive Bayes and maxent) did not capitalise as effectively on the training data. Features Evt-evt Evt-time All 80.8% 80.3% All-signal text 70.8% 72.7% All-signal text-argument order 70.7% 72.2% All-signal tex</context>
</contexts>
<marker>Derczynski, Gaizauskas, 2013</marker>
<rawString>L. Derczynski and R. Gaizauskas. 2013. Empirical Validation of Reichenbach’s Tense Framework. In Proceedings of the 10th International Conference on Computational Semantics, pages 71–82. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q X Do</author>
<author>W Lu</author>
<author>D Roth</author>
</authors>
<title>Joint inference for event timeline construction.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>677--687</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="3631" citStr="Do et al., 2012" startWordPosition="582" endWordPosition="585">etween two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal orderings in sentences without signals. As part of an early TempEval system, Min et al. (2007) automatically annotate signals and associate them with temporal relations. They then include the signal text as a feature for a relation type classifier. Their definition of signals varies somewhat from the traditional Time</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Q. X. Do, W. Lu, and D. Roth. 2012. Joint inference for event timeline construction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 677–687. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>R E Schapire</author>
</authors>
<title>A decisiontheoretic generalization of on-line learning and an application to boosting.</title>
<date>1997</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>55</volume>
<issue>1</issue>
<contexts>
<context position="11272" citStr="Freund and Schapire, 1997" startWordPosition="1771" endWordPosition="1775">nd its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evalu</context>
</contexts>
<marker>Freund, Schapire, 1997</marker>
<rawString>Y. Freund and R. E. Schapire. 1997. A decisiontheoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hepple</author>
<author>A Setzer</author>
<author>R Gaizauskas</author>
</authors>
<title>USFD: preliminary exploration of features and classifiers for the TempEval-2007 tasks.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>438--441</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="9056" citStr="Hepple et al. (2007)" startWordPosition="1423" endWordPosition="1426">utes. These are, for events: class, aspect, modality, tense, polarity, part of speech; and, for times: value, type, function in document, mod, quant. To these are added same-tense and same-aspect features, as well as the string values of events/times. The feature groups we use here are: • Base – The attributes of TimeML annotations involved (includes tense, aspect, polarity and so on as above), as with previous approaches. • Argument Ordering – Two features: a boolean set if both arguments are in the same sentence (as in Chambers et al. (2007)), and the text order of argument intervals (as in Hepple et al. (2007)). • Signal Ordering – Textual ordering is important with temporal signals; compare “You walk before you run” and “Before you walk you run”. We add features accounting for relative textual position of signal and arguments as per Derczynski and Gaizauskas (2010). To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal. • Syntactic – We add syntactic features: following Bethard et al. (2007), the lowest common constituent label between each argument and 646 Feature</context>
</contexts>
<marker>Hepple, Setzer, Gaizauskas, 2007</marker>
<rawString>M. Hepple, A. Setzer, and R. Gaizauskas. 2007. USFD: preliminary exploration of features and classifiers for the TempEval-2007 tasks. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 438–441. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="10511" citStr="Klein and Manning, 2003" startWordPosition="1651" endWordPosition="1654">0% Naive Bayes 73.8% 71.5% Maximum entropy 75.5% 78.1% Linear SVC / Crammer-Singer 79.3% 75.6% Linear SVC 80.7% 77.1% Random forest 80.8% 80.3% Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal the signal; following Swampillai and Stevenson (2011), the syntactic path from each argument to the signal, using a top-level ROOT node for cross-sentence paths; and three features indicating whether there is a temporal function tag (-TMP between each of the intervals or the signal to the root note. These features are generated using the Stanford parser (Klein and Manning, 2003) and a function tagger (Blaheta and Charniak, 2000). • Signal Text – We add the signal’s raw string, as well as its lower-case version and its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these f</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C. D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st meeting of the Association for Computational Linguistics, pages 423–430. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
<author>A Lascarides</author>
</authors>
<title>Learning sentence-internal temporal relations.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="3828" citStr="Lapata and Lascarides (2006)" startWordPosition="611" endWordPosition="614"> semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal orderings in sentences without signals. As part of an early TempEval system, Min et al. (2007) automatically annotate signals and associate them with temporal relations. They then include the signal text as a feature for a relation type classifier. Their definition of signals varies somewhat from the traditional TimeML sig645 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 645–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics </context>
</contexts>
<marker>Lapata, Lascarides, 2006</marker>
<rawString>M. Lapata and A. Lascarides. 2006. Learning sentence-internal temporal relations. Journal of Artificial Intelligence Research, 27(1):85–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>Y Yang</author>
<author>J Carbonell</author>
</authors>
<title>Boosting to correct inductive bias in text classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 11th international Conference on Information and Knowledge Management,</booktitle>
<pages>348--355</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15906" citStr="Liu et al., 2002" startWordPosition="2484" endWordPosition="2487">o classify than other relations, unless signal information is present in the features. This may be due to differences in how signals are used by authors. One explanation is that signals may be used in the stead of temporal ordering information in surrounding discourse, such as modulations of dominant tense or aspect (Derczynski and Gaizauskas, 2013). Unlike earlier work using maxent, we experiment with a variety of classifiers, and find a consistent improvement in temporal relation typing using signal features. With the notable exception of adaptive boosting, classifiers with preference bias (Liu et al., 2002) – AdaBoost, random trees and SVC – performed best in this task. Conversely, those tending toward the independence assumption (naive Bayes and maxent) did not capitalise as effectively on the training data. Features Evt-evt Evt-time All 80.8% 80.3% All-signal text 70.8% 72.7% All-signal text-argument order 70.7% 72.2% All-signal text-signal order 69.5% 71.2% All-signal text-syntax 59.5% 69.0% All-signal text-DCT 70.8% 72.8% Table 4: Feature ablation without signal text features. Bold figures indicate largest performance change. We also investigated the impact of each feature group on the best-</context>
</contexts>
<marker>Liu, Yang, Carbonell, 2002</marker>
<rawString>Y. Liu, Y. Yang, and J. Carbonell. 2002. Boosting to correct inductive bias in text classification. In Proceedings of the 11th international Conference on Information and Knowledge Management, pages 348– 355. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Llorens</author>
<author>E Saquete</author>
<author>B Navarro</author>
</authors>
<title>TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2.</title>
<date>2010</date>
<booktitle>In Proceedings of SemEval-2010. ACL.</booktitle>
<contexts>
<context position="3293" citStr="Llorens et al. (2010)" startWordPosition="528" endWordPosition="531"> al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, th</context>
</contexts>
<marker>Llorens, Saquete, Navarro, 2010</marker>
<rawString>H. Llorens, E. Saquete, and B. Navarro. 2010. TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2. In Proceedings of SemEval-2010. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>B Wellner</author>
<author>M Verhagen</author>
<author>J Pustejovsky</author>
</authors>
<title>Three approaches to learning TLINKS in TimeML.</title>
<date>2007</date>
<tech>Technical report, CS-07-268,</tech>
<institution>Brandeis University.</institution>
<contexts>
<context position="2683" citStr="Mani et al. (2007)" startWordPosition="432" endWordPosition="435"> temporal signal, co-ordinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et </context>
<context position="8362" citStr="Mani et al. (2007)" startWordPosition="1308" endWordPosition="1311">terval type pairing. As is common with statistical approaches to temporal relation typing, we also perform relation folding; that is, to reduce the number of possible classes, we sometimes invert argument order and relation type. For example, A BEFORE B and B AFTER A convey the same temporal relation, and so we can remove all AFTER-type relations by swapping their argument order and converting them to BEFORE relations. This lossless process condenses the labels that our classifier has to distinguish between, though classification remains a multi-class problem. We adopt the base feature set of Mani et al. (2007), which consists mainly of TimeML event and time annotation surface attributes. These are, for events: class, aspect, modality, tense, polarity, part of speech; and, for times: value, type, function in document, mod, quant. To these are added same-tense and same-aspect features, as well as the string values of events/times. The feature groups we use here are: • Base – The attributes of TimeML annotations involved (includes tense, aspect, polarity and so on as above), as with previous approaches. • Argument Ordering – Two features: a boolean set if both arguments are in the same sentence (as in</context>
</contexts>
<marker>Mani, Wellner, Verhagen, Pustejovsky, 2007</marker>
<rawString>I. Mani, B. Wellner, M. Verhagen, and J. Pustejovsky. 2007. Three approaches to learning TLINKS in TimeML. Technical report, CS-07-268, Brandeis University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Min</author>
<author>M Srikanth</author>
<author>A Fowler</author>
</authors>
<title>LCC-TE: A hybrid approach to temporal relation identification in news text.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>219--222</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="4007" citStr="Min et al. (2007)" startWordPosition="639" endWordPosition="642">ions, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal orderings in sentences without signals. As part of an early TempEval system, Min et al. (2007) automatically annotate signals and associate them with temporal relations. They then include the signal text as a feature for a relation type classifier. Their definition of signals varies somewhat from the traditional TimeML sig645 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 645–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Event-event relations Overall Event-time relations Overall Non-signalled Signalled Non-signalled Signalled Baseline most-common-class 41.4% 57.4% 43.0% 49.2% 51.6% 49.6% Maxent cl</context>
</contexts>
<marker>Min, Srikanth, Fowler, 2007</marker>
<rawString>C. Min, M. Srikanth, and A. Fowler. 2007. LCC-TE: A hybrid approach to temporal relation identification in news text. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 219–222. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Mirroshandel</author>
<author>G Ghassem-Sani</author>
<author>M Khayyamian</author>
</authors>
<title>Using syntactic-based kernels for classifying temporal relations.</title>
<date>2011</date>
<journal>Journal of Computer Science and Technology,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="3321" citStr="Mirroshandel et al. (2011)" startWordPosition="532" endWordPosition="535">wa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal ordering</context>
</contexts>
<marker>Mirroshandel, Ghassem-Sani, Khayyamian, 2011</marker>
<rawString>S. A. Mirroshandel, G. Ghassem-Sani, and M. Khayyamian. 2011. Using syntactic-based kernels for classifying temporal relations. Journal of Computer Science and Technology, 26(1):68–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pedregosa</author>
<author>G Varoquaux</author>
<author>A Gramfort</author>
<author>V Michel</author>
<author>B Thirion</author>
<author>O Grisel</author>
<author>M Blondel</author>
<author>P Prettenhofer</author>
<author>R Weiss</author>
<author>V Dubourg</author>
</authors>
<title>Scikit-learn: Machine learning in Python.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<contexts>
<context position="11445" citStr="Pedregosa et al., 2011" startWordPosition="1798" endWordPosition="1801">e All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evaluated by determining if the class they output matched the relation type in TB-sig. Results are given in Table 2. For comparison with the general case, i.e. for both signalled</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, 2011</marker>
<rawString>F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. The Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>R Sauri</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>L Ferro</author>
</authors>
<title>The TimeBank Corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of the Corpus Linguistics Conference,</booktitle>
<pages>647--656</pages>
<contexts>
<context position="6913" citStr="Pustejovsky et al., 2003" startWordPosition="1087" endWordPosition="1090"> builds on previous work by expanding the study to include relations other than just event-event relations, by extending the feature set, by doing temporal relation labelling over a more carefully curated version of the TimeBank corpus (see below), and by providing detailed analysis of the performance of a set of labelling techniques when using temporal signals. 3 Experimental Setup We only approach the relation typing task, and we use existing signal annotations – that is, we do not attempt to automatically identify temporal signals. The corpus used is the signal-curated version of TimeBank (Pustejovsky et al., 2003). This corpus, TBsig,1 adds extra events, times and relations to TimeBank, in an effort to correct signal under-annotation in the original corpus (Derczynski and Gaizauskas, 2011). Like the original TimeBank corpus, it comprises 183 documents. In these, we are interested only in the temporal relations that use a signal. There are 851 signals annotated in the corpus, co-ordinating 886 temporal re1See http://derczynski.com/sheffield/resources/tb sig.tar.bz2 lations (13.7% of all). For comparison, TimeBank has 688 signal annotations which co-ordinate 718 temporal relations (11.2%). When evaluatin</context>
</contexts>
<marker>Pustejovsky, Sauri, Gaizauskas, Setzer, Ferro, 2003</marker>
<rawString>J. Pustejovsky, R. Sauri, R. Gaizauskas, A. Setzer, L. Ferro, et al. 2003. The TimeBank Corpus. In Proceedings of the Corpus Linguistics Conference, pages 647–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>J Castano</author>
<author>R Ingria</author>
<author>R Sauri</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>G Katz</author>
<author>D Radev</author>
</authors>
<title>TimeML: Robust specification of event and temporal expressions in text. In</title>
<date>2005</date>
<editor>I. Mani, J. Pustejovsky, and R. Gaizauskas, editors,</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="2536" citStr="Pustejovsky et al., 2005" startWordPosition="405" endWordPosition="408">ly state the nature of the temporal relation that holds between them. For example, in “The parade reached the town hall before noon”, the word before is a temporal signal, co-ordinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistica</context>
</contexts>
<marker>Pustejovsky, Castano, Ingria, Sauri, Gaizauskas, Setzer, Katz, Radev, 2005</marker>
<rawString>J. Pustejovsky, J. Castano, R. Ingria, R. Sauri, R. Gaizauskas, A. Setzer, G. Katz, and D. Radev. 2005. TimeML: Robust specification of event and temporal expressions in text. In I. Mani, J. Pustejovsky, and R. Gaizauskas, editors, The language of time: a reader. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Rennie</author>
<author>L Shih</author>
<author>J Teevan</author>
<author>D Karger</author>
</authors>
<title>Tackling the Poor Assumptions of Naive Bayes Text Classifiers.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="11190" citStr="Rennie et al., 2003" startWordPosition="1760" endWordPosition="1763">al Text – We add the signal’s raw string, as well as its lower-case version and its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to se</context>
</contexts>
<marker>Rennie, Shih, Teevan, Karger, 2003</marker>
<rawString>J. D. Rennie, L. Shih, J. Teevan, and D. Karger. 2003. Tackling the Poor Assumptions of Naive Bayes Text Classifiers. In Proceedings of the International Conference on Machine Learning. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Swampillai</author>
<author>M Stevenson</author>
</authors>
<title>Extracting relations within and across sentences.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing,</booktitle>
<pages>25--32</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="10183" citStr="Swampillai and Stevenson (2011)" startWordPosition="1597" endWordPosition="1600">llowing Bethard et al. (2007), the lowest common constituent label between each argument and 646 Features Classifier Event-event accuracy Event-time accuracy N/A Baseline most-common-class 57.4% 51.6% Base Baseline maximum entropy 58.6% 59.6% DG2010 Maximum entropy 72.6% 72.4% Random forest 76.7% 78.6% All Adaptive boosting 70.4% 73.0% Naive Bayes 73.8% 71.5% Maximum entropy 75.5% 78.1% Linear SVC / Crammer-Singer 79.3% 75.6% Linear SVC 80.7% 77.1% Random forest 80.8% 80.3% Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal the signal; following Swampillai and Stevenson (2011), the syntactic path from each argument to the signal, using a top-level ROOT node for cross-sentence paths; and three features indicating whether there is a temporal function tag (-TMP between each of the intervals or the signal to the root note. These features are generated using the Stanford parser (Klein and Manning, 2003) and a function tagger (Blaheta and Charniak, 2000). • Signal Text – We add the signal’s raw string, as well as its lower-case version and its lemma. • DCT – For event-time relations, whether the time expression also functions as the document’s creation timestamp. Collect</context>
</contexts>
<marker>Swampillai, Stevenson, 2011</marker>
<rawString>K. Swampillai and M. Stevenson. 2011. Extracting relations within and across sentences. In Proceedings of the International Conference Recent Advances in Natural Language Processing, pages 25–32. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N UzZaman</author>
<author>H Llorens</author>
<author>L Derczynski</author>
<author>M Verhagen</author>
<author>J F Allen</author>
<author>J Pustejovsky</author>
</authors>
<title>SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluations.</booktitle>
<contexts>
<context position="3707" citStr="UzZaman et al., 2013" startWordPosition="593" endWordPosition="597"> time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al., 2012). The TempEval3 challenge addresses exactly this task (UzZaman et al., 2013). Investigations into using signals for temporal relation typing have had promising results. Lapata and Lascarides (2006) learn temporal structure according to these explicit signals, then predict temporal orderings in sentences without signals. As part of an early TempEval system, Min et al. (2007) automatically annotate signals and associate them with temporal relations. They then include the signal text as a feature for a relation type classifier. Their definition of signals varies somewhat from the traditional TimeML sig645 Proceedings of the 51st Annual Meeting of the Association for Comp</context>
</contexts>
<marker>UzZaman, Llorens, Derczynski, Verhagen, Allen, Pustejovsky, 2013</marker>
<rawString>N. UzZaman, H. Llorens, L. Derczynski, M. Verhagen, J. F. Allen, and J. Pustejovsky. 2013. SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations. In Proceedings of the 7th International Workshop on Semantic Evaluations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Verhagen</author>
<author>R Gaizauskas</author>
<author>F Schilder</author>
<author>M Hepple</author>
<author>J Moszkowicz</author>
<author>J Pustejovsky</author>
</authors>
<title>The TempEval challenge: identifying temporal relations in text.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="2805" citStr="Verhagen et al., 2009" startWordPosition="453" endWordPosition="456"> contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et al. (2011). Although we focus solely on determining the types of temporal relations, one must </context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple, J. Moszkowicz, and J. Pustejovsky. 2009. The TempEval challenge: identifying temporal relations in text. Language Resources and Evaluation, 43(2):161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>Kernel based discourse relation recognition with temporal ordering information.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th meeting of the Association for Computational Linguistics,</booktitle>
<pages>710--719</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="17454" citStr="Wang et al. (2010)" startWordPosition="2712" endWordPosition="2715">ng other feature groups gave only minor performance decreases. We also experimented with adding feature groups to the base set one-by-one. All but DCT features gave above-baseline improvement, though argument ordering features were not very helpful for event-event relation typing. Signal text features gave the strongest improvement over baseline for event-event relations, but syntax gave a larger improvement for event-time relations. Accordingly, it may be useful to distinguish between event-event and event-time relations when extracting temporal information using syntax (c.f. the approach of Wang et al. (2010)). A strong above-baseline performance was still obtained even when signal text features were removed, which included the signal text itself. This was interesting, as signal phrases can indicate quite different temporal orderings (e.g. “Open the box while it rains” vs. “Open the box before it rains”, and the words used are typically critical to correct interpretation of the temporal relation. Further, the model is able to generalise beyond particular signal phrase choices. To investigate further, we examined the performance impact of each group sans “signal text” features (Table 4). In this ca</context>
</contexts>
<marker>Wang, Su, Tan, 2010</marker>
<rawString>W. Wang, J. Su, and C. L. Tan. 2010. Kernel based discourse relation recognition with temporal ordering information. In Proceedings of the 48th meeting of the Association for Computational Linguistics, pages 710–719. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yoshikawa</author>
<author>S Riedel</author>
<author>M Asahara</author>
<author>Y Matsumoto</author>
</authors>
<title>Jointly identifying temporal relations with Markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing,</booktitle>
<pages>405--413</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2711" citStr="Yoshikawa et al. (2009)" startWordPosition="437" endWordPosition="440">dinating the event reached with the time noon. Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al., 2005). 2 Related Work Temporal relation typing is not a new problem. Classical work using TimeML is that of Boguraev and Ando (2005), Mani et al. (2007) and Yoshikawa et al. (2009). The TempEval challenge series features relation typing as a key task (Verhagen et al., 2009). The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering – approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. Recent attempts to include more linguistically sophisticated features representing discourse, syntactic and semantic role information have yielded but marginal improvements, e.g. Llorens et al. (2010); Mirroshandel et </context>
</contexts>
<marker>Yoshikawa, Riedel, Asahara, Matsumoto, 2009</marker>
<rawString>K. Yoshikawa, S. Riedel, M. Asahara, and Y. Matsumoto. 2009. Jointly identifying temporal relations with Markov logic. In Proceedings of the International Joint Conference on Natural Language Processing, pages 405–413. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zhu</author>
<author>H Zou</author>
<author>S Rosset</author>
<author>T Hastie</author>
</authors>
<title>Multiclass AdaBoost. Statistics and Its Interface,</title>
<date>2009</date>
<pages>2--349</pages>
<contexts>
<context position="11291" citStr="Zhu et al., 2009" startWordPosition="1776" endWordPosition="1779">vent-time relations, whether the time expression also functions as the document’s creation timestamp. Collectively, these feature groups comprise the All feature set. For comparison, the feature set we reported in previous work (Derczynski and Gaizauskas, 2010) is also included, labeled DG2010. This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. Using these feature representations we trained multinomial naive Bayes (Rennie et al., 2003), maximum entropy (Daum´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al., 2009), multi-class SVM (Crammer and Singer, 2002; Chang and Lin, 2011) and random forest2 (Breiman, 2001) classifiers via Scikit-learn (Pedregosa et al., 2011). We use two baselines: most-common-class and a model trained with no signal features. We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier. Classifiers were evaluated by determining</context>
</contexts>
<marker>Zhu, Zou, Rosset, Hastie, 2009</marker>
<rawString>J. Zhu, H. Zou, S. Rosset, and T. Hastie. 2009. Multiclass AdaBoost. Statistics and Its Interface, 2:349– 360.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>