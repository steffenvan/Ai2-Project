<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.981343">
Inducing Lexico-Structural Transfer Rules from Parsed Bi-texts
</title>
<author confidence="0.996528">
Benoit Lavoie, Michael White, and Tanya Korelsky
</author>
<affiliation confidence="0.940384">
CoGenTex, Inc.
</affiliation>
<address confidence="0.95892">
840 Hanshaw Road
Ithaca, NY 14850, USA
</address>
<email confidence="0.99881">
benoit,mike,tanya@cogentex.com
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999688285714286">
This paper describes a novel approach
to inducing lexico-structural transfer
rules from parsed bi-texts using syn-
tactic pattern matching, statistical co-
occurrence and error-driven filtering.
We present initial evaluation results and
discuss future directions.
</bodyText>
<sectionHeader confidence="0.998802" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988945945946">
This paper describes a novel approach to inducing
transfer rules from syntactic parses of bi-texts and
available bilingual dictionaries. The approach
consists of inducing transfer rules using the four
major steps described in more detail below: (i)
aligning the nodes of the parses; (ii) generating
candidate rules from these alignments; (iii) order-
ing candidate rules by co- occurrence; and (iv) ap-
plying error-driven filtering to select the final set
of rules.
Our approach is based on lexico-structural
transfer (Nasr et. al., 1997), and extends recent
work reported in (Han et al., 2000) about Korean
to English transfer in particular. Whereas Han et
al. focus on high quality domain-specific transla-
tion using handcrafted transfer rules, in this work
we instead focus on automating the acquisition of
such rules.
Our approach can be considered a generaliza-
tion of syntactic approaches to example-based
machine translation (EBMT) such as (Nagao,
1984; Sato and Nagao, 1990; Maruyama and
Watanabe, 1992). While such approaches use
syntactic transfer examples during the actual
transfer of source parses, our approach instead
uses syntactic transfer examples to induce general
transfer rules that can be compiled into a transfer
dictionary for use in the actual translation process.
Our approach is similar to the recent work of
(Meyers et al., 1998) where transfer rules are also
derived after aligning the source and target nodes
of corresponding parses. However, it also differs
from (Meyers et al., 1998) in several important
points. The first difference concerns the content
of parses and the resulting transfer rules; in (Mey-
ers et al., 1998), parses contain only lexical labels
and syntactic roles (as arc labels), while our ap-
proach uses parses containing lexical labels, syn-
tactic roles, and any other syntactic information
provided by parsers (tense, number, person, etc.).
The second difference concerns the node align-
ment; in (Meyers et al., 1998), the alignment of
source and target nodes is designed in a way that
preserves node dominancy in the source and tar-
get parses, while our approach does not have such
restriction. One of the reasons for this difference
is due to the different language pairs under study;
(Meyers et al., 1998) deals with two languages
that are closely related syntactically (Spanish and
English) while we are dealing with languages that
syntactically are quite divergent, Korean and En-
glish (Dorr, 1994). The third difference is in the
process of identification of transfer rules candi-
dates; in (Meyers et al., 1998), the identification
is done by using the exact tree fragments in the
source and target parse that are delimited by the
alignment, while we use all source and target tree
sub-patterns matching a subset of the parse fea-
tures that satisfy a customizable set of alignment
constraints and attribute constraints. The fourth
third difference is in the level of abstraction of
transfer rules candidates; in (Meyers et al., 1998),
the source and target patterns of each transfer rule
are fully lexicalized (except possibly the terminal
nodes), while in our approach the nodes of trans-
fer rules do not have to be lexicalized.
Section 2 describes our approach to trans-
fer rules induction and its integration with data
preparation and evaluation. Section 3 describes
the data preparation process and resulting data.
Section 4 describes the transfer induction process
in detail. Section 5 describes the results of our ini-
tial evaluation. Finally, Section 6 concludes with
a discussion of future directions.
</bodyText>
<sectionHeader confidence="0.965642" genericHeader="method">
2 Overall Approach
</sectionHeader>
<bodyText confidence="0.99784225">
In its most general form, our approach to transfer
rules induction includes three different processes,
data preparation, transfer rule induction and eval-
uation. An overview of each process is provided
below; further details are provided in subsequent
sections.
The data preparation process creates the fol-
lowing resources from the bi-texts:
</bodyText>
<listItem confidence="0.984082111111111">
• A training set and a test set of source and
target parses for the bi-texts, post-processed
into a syntactic dependency representation.
• A baseline transfer dictionary, which may in-
clude (depending upon availability) lexical
transfer rules extracted from the bi-texts us-
ing statistical methods, lexical transfer rules
from existing bilingual dictionaries, and/or
handcrafted lexico-structural transfer rules.
</listItem>
<bodyText confidence="0.592423571428571">
The transfer induction process induces lexico-
structural transfer rules from the training set of
corresponding source and target parses that, when
added to the baseline transfer dictionary, produce
transferred parses that are closer to the corre-
sponding target parses. The transfer induction
process has the following steps:
</bodyText>
<listItem confidence="0.974881871794872">
• Nodes of the corresponding source and tar-
get parses are aligned using the baseline
transfer dictionary and some heuristics based
on the similarity of part-of-speech and syn-
tactic context.
• Transfer rule candidates are generated based
on the sub-patterns that contain the corre-
sponding aligned nodes in the source and tar-
get parses.
• The transfer rule candidates are ordered
based on their likelihood ratios.
• The transfer rule candidates are filtered, one
at a time, in the order of the likelihood ra-
tios, by removing those rule candidates that
do not produce an overall improvement in
the accuracy of the transferred parses.
The evaluation process has the following steps:
• Both the baseline transfer dictionary and the
induced transfer dictionary (i.e., the baseline
transfer dictionary augmented with the in-
duced transfer rules) are applied to the test
set in order to produce two sets of transferred
parses, the baseline set and the (hopefully)
improved induced set. For each set, the dif-
ferences between the transferred parses and
target parses are measured, and the improve-
ment in tree accuracy is calculated.
• After performing syntactic realization on the
baseline set and the induced set of trans-
ferred parses, the differences between the
resulting translated strings and the target
strings are measured, and the improvement
in string accuracy is calculated.
• For a subset of the translated strings, human
judgments of accuracy and grammaticality
are gathered, and the correlations between
the manual and automatic scores are calcu-
lated, in order to assess the meaningfulness
of the automatic measures.
</listItem>
<sectionHeader confidence="0.977623" genericHeader="method">
3 Data Preparation
</sectionHeader>
<subsectionHeader confidence="0.999872">
3.1 Parsing the Bi-texts
</subsectionHeader>
<bodyText confidence="0.9991529375">
In our experiments to date, we have used a cor-
pus consisting of a Korean dialog of 4183 sen-
tences and their English human translations. We
ran off-the-shelf parsers on each half of the cor-
pus, namely the Korean parser developed by Yoon
et al. (1997) and the English parser developed by
Collins (1997). Neither parser was trained on our
corpus.
We automatically converted the phrase struc-
ture output of the Collins parser into the syntac-
tic dependency representation used by our syn-
tactic realizer, RealPro (Lavoie and Rambow,
1997). This representation is based on the deep-
syntactic structures (DSyntS) of Meaning-Text
Theory (Mel’ˇcuk, 1988). The important features
of a DSyntS are as follows:
</bodyText>
<listItem confidence="0.9992055">
• a DSyntS is an unordered tree with labeled
nodes and labeled arcs;
• a DSyntS is lexicalized, meaning that the
nodes are labeled with lexemes (uninflected
words) from the target language;
• a DSyntS is a dependency structure and not a
phrase- structure structure: there are no non-
terminal nodes, and all nodes are labeled
with lexemes;
• a DSyntS is a syntactic representation,
meaning that the arcs of the tree are la-
beled with syntactic relations such as SUB-
JECT (represented in DSyntSs as I), rather
than conceptual or semantic relations such as
AGENT;
• a DSyntS is a deep syntactic representation,
meaning that only meaning-bearing lexemes
are represented, and not function words.
</listItem>
<bodyText confidence="0.999461733333333">
Since the output of the Yoon parser is quite sim-
ilar, with the exception of its treatment of syn-
tactic relations, we have used its output as is.
The DSyntS representations for two correspond-
ing Korean1 and English sentences are illustrated
in Figure 1.
In examining the outputs of the two parsers
on our corpus, we found that about half of the
parse pairs contained incorrect dependency as-
signments, incomplete lemmatization or incom-
plete parses. To reduce the impact of such pars-
ing errors in our initial experiments, we have pri-
marily focused on a higher quality subset of 1763
sentence pairs that were selected according to the
following criteria:
</bodyText>
<listItem confidence="0.9427125">
• Parse pairs where the source or target parse
contained more than 10 nodes were rejected,
</listItem>
<footnote confidence="0.775446">
1Korean is represented in romanized format in this paper.
</footnote>
<equation confidence="0.987676466666667">
(S1) {i} {Ci-To-Reul} {Ta-Si} {Po-Ra}.
this + map-accusative + again + look-imp
(D1) {po} [class=vbma ente={ra}] (
s1 {ci-to} [class=nnin2 ppca={reul}] (
s1 {i} [class=ande]
)
s1 {ta-si} [class=adco2]
)
(S2) Look at the map again.
(D2) look [class=verb mood=imp] (
attr at [class=preposition] (
ii map [class=common_noun article=def]
)
attr again [class=adverb]
)
</equation>
<figureCaption confidence="0.907472">
Figure 1: Syntactic dependency representations
for corresponding Korean and English sentences
</figureCaption>
<bodyText confidence="0.977304">
since these usually contained more parse er-
rors than smaller parses.
</bodyText>
<listItem confidence="0.697185125">
• Parse pairs where the source or target parse
contained non-final punctuation were re-
jected; this criterion was based on our ob-
servation that in most such cases, the source
or target parses contained only a fragment
of the original sentence content (i.e., one or
both parsers only parsed what was on one
side of an intra-sentential punctuation mark).
</listItem>
<bodyText confidence="0.999977857142857">
We divided this higher quality subset into train-
ing and test sets by randomly choosing 50% of
the 1763 higher quality parse pairs (described in
Section 3.1) for inclusion in the training set, re-
serving the remaining 50% for the test set. The
average numbers of parse nodes in the training set
and test set were respectively 6.91 and 6.11 nodes.
</bodyText>
<subsectionHeader confidence="0.969768">
3.2 Creating the Baseline Transfer
Dictionary
</subsectionHeader>
<bodyText confidence="0.824152411764706">
In the general case, any available bilingual dic-
tionaries can be combined to create the base-
line transfer dictionary. These dictionaries may
include lexical transfer dictionaries extracted
from the bi-texts using statistical methods, exist-
ing bilingual dictionaries, or handcrafted lexico-
structural transfer dictionaries. If probabilistic in-
formation is not already associated with the lexi-
cal entries, log likelihood ratios can be computed
and added to these entries based on the occur-
rences of these lexical items in the parse pairs.
In our initial experiments, we decided to focus
on the scenario where the baseline transfer dic-
@KOREAN: 4.1 Aligning the Parse Nodes
{po} [class=vbma] ( To align the nodes in the source and target parse
s1 $X [ppca={reul}] trees, we devised a new dynamic programming
) alignment algorithm that performs a top-down,
@ENGLISH: bidirectional beam search for the least cost map-
look [class=verb] ( ping between these nodes. The algorithm is pa-
attr at [class=preposition] ( rameterized by the costs of (1) aligning two nodes
ii $X whose lexemes are not found in the baseline trans-
) fer dictionary; (2) aligning two nodes with dif-
) fering parts of speech; (3) deleting or inserting a
@-2xLOG_LIKELIHOOD: 12.77 node in the source or target tree; and (4) aligning
two nodes whose relative locations differ.
To determine an appropriate part of speech cost
measure, we first extracted a small set of parse
pairs that could be reliably aligned using lexical
matching alone, and then based the cost measure
on the co-occurrence counts of the observed parts
of speech pairings. The remaining costs were set
by hand.
As a result of the alignment process, alignment
id attributes (aid) are added to the nodes of the
</bodyText>
<table confidence="0.823381666666667">
parse pairs. Some nodes may be in alignment
with no other node, such as English prepositions
not found in the Korean DSyntS.
4.2 Generating Rule Candidates
Candidate transfer rules are generated using three
data sources:
</table>
<listItem confidence="0.866775833333333">
• the training set of aligned source and target
parses resulting from the alignment process;
• a set of alignment constraints which identify
the subtrees of interest in the aligned source
and target parses (Section 4.2.1);
• a set of attribute constraints which determine
</listItem>
<figureCaption confidence="0.929809076923077">
what parts of the aligned subtrees to include
in the transfer rule candidates’ source and
target patterns (Section 4.2.2).
The alignment and attribute constraints are nec-
essary to keep the set of candidate transfer rules
manageable in size.
4.2.1 Alignment constraints
Figure 4 shows an example alignment constraint.
This constraint, which matches the structural pat-
terns of the transfer rule illustrated in Figure 2,
uses the aid alignment attribute to indicate that
Figure 2: Transfer rule for English lexicalization
and preposition insertion
</figureCaption>
<table confidence="0.850171777777778">
@KOREAN:
$X [class=vbma ente={ra}]
@ENGLISH:
$X [class=verb mood=imp]
@-2xLOG_LIKELIHOOD: 33.37
Figure 3: Transfer rule for imperative forms
tionary is created from lexical transfer entries ex-
tracted from the bi-texts using statistical methods.
To simulate this scenario, we created our baseline
transfer dictionary by taking the lexico-syntactic
transfer dictionary developed by Han et al. (2000)
for this corpus and removing the (more general)
rules that were not fully lexicalized. Starting with
this purely lexical baseline transfer dictionary en-
abled us to examine whether these more general
rules could be discovered through induction.
4 Transfer Rule Induction
The induced lexico-structural transfer rules are
represented in a formalism similar to the one de-
scribed in Nasr et al. (1997), and extended to also
include log likelihood ratios. Figures 2 and 3
illustrate two entry samples that can be used to
transfer a Korean syntactic representation for ci-
to-reul po-ra to an English syntactic representa-
tion for look at the map. The first rule lexicalizes
the English predicate and inserts the correspond-
ing preposition while the second rule inserts the
English imperative attribute. This formalism uses
notation similar to the syntactic dependency nota-
tion shown in Figure 1, augmented with variable
arguments prefixed with $ characters.
@KOREAN:
$X1 [aid=$1] (
$R1 $X2 [aid=$2]
Each node of a candidate transfer rule must have its relation
attribute (relationship with its governor) specified if it is an
internal node, otherwise this relation must not be specified:
) e.g. 0 $X1 ( $R $X2 )
@ENGLISH:
$Y1 [aid=$1] (
$R2 $Y2 (
$R3 $Y3 [aid=$2]
)
Figure 5: Independent attribute constraint
)
</table>
<tableCaption confidence="0.2015805">
In a candidate transfer rule, inclusion of the lexemes of two
aligned nodes must be done concurrently:
</tableCaption>
<figureCaption confidence="0.996993">
Figure 4: Alignment constraint
</figureCaption>
<equation confidence="0.6624605">
e.g.
$X [aid=$1]
</equation>
<bodyText confidence="0.978458285714286">
and
in a Korean and English parse pair, any source
and target sub-trees matching this alignment con-
straint (where $X1 and $Y1 are aligned or have
the same attribute aid values and where $X2 and
$Y3 are aligned) can be used as a point of depar-
ture for generating transfer rule candidates. We
suggest that alignment constraints such as this one
can be used to define most of the possible syntac-
tic divergences between languages (Dorr, 1994),
and that only a handful of them are necessary for
two given languages (we have identified 11 gen-
eral alignment constraints necessary for Korean to
English transfer so far).
</bodyText>
<subsectionHeader confidence="0.684">
4.2.2 Attribute constraints
</subsectionHeader>
<bodyText confidence="0.998856666666667">
Attribute constraints are used to limit the space
of possible transfer rule candidates that can be
generated from the sub-trees satisfying the align-
ment constraints. Candidate transfer rules must
satisfy all of the attribute constraints. Attribute
constraints can be divided into two types:
</bodyText>
<listItem confidence="0.929608142857143">
• independent attribute constraints, whose
scope covers only one part of a candidate
transfer rule and which are the same for the
source and target parts;
• concurrent attribute constraints, whose
scope extends to both the source and target
parts of a candidate transfer rule.
</listItem>
<bodyText confidence="0.999183428571429">
The examples of an independent attribute con-
straint and of a concurrent attribute constraint are
given in Figure 5 and Figure 6 respectively. As
with the alignment constraints, we suggest that a
relatively small number of attribute constraints is
necessary to generate most of the desired rules for
a given language pair.
</bodyText>
<figure confidence="0.713325">
$Y [aid=$1]
e.g.
0 [aid=$1]
and
0 [aid=$1]
</figure>
<figureCaption confidence="0.999038">
Figure 6: Concurrent attribute constraint
</figureCaption>
<subsectionHeader confidence="0.997154">
4.3 Ordering Rule Candidates
</subsectionHeader>
<bodyText confidence="0.999953333333333">
In the next step, transfer rule candidates are or-
dered as follows: first, by their log likelihood ra-
tios (Manning and Schutze, 1999: 172-175); sec-
ond, any transfer rule candidates with the same
log likelihood ratio are ordered by their speci-
ficity.
</bodyText>
<subsubsectionHeader confidence="0.366632">
4.3.1 Rule ordering by log likelihood ratio
</subsubsectionHeader>
<bodyText confidence="0.994142909090909">
We calculate the log likelihood ratio, log A, ap-
plied to a transfer rule candidate as indicated in
Figure 7. Note that log A is a negative value,
and following (Manning and Schutze, 1999), we
assign -2 log A to the transfer rule. Note also
that in the definitions of C1, C2, and C12 we are
currently only considering one occurrence or co-
occurrence of the source and/or target patterns per
parse pair, while in general there could be more
than one; in our initial experiments these defini-
tions have sufficed.
</bodyText>
<subsectionHeader confidence="0.63068">
4.3.2 Rule ordering by specificity
</subsectionHeader>
<bodyText confidence="0.998701142857143">
If two or more candidate transfer rules have the
same log likelihood ratio, ties are broken by a
specificity heuristic, with the result that more gen-
eral rules are ordered ahead of more specific ones.
The specificity of a rule is defined to be the fol-
lowing sum: the number of attributes found in
the source and target patterns, plus 1 for each for
</bodyText>
<equation confidence="0.997560666666667">
log A =
log L(C12, C1, p) + log L(C2 − C12, N − C1, p)
−log L(C12, C1, p1) −log L(C2 − C12, N − C1, p2)
</equation>
<bodyText confidence="0.993535">
where, not counting attributes aid,
</bodyText>
<listItem confidence="0.999174">
• C1 = number of source parses containing at least one
occurrence of C’s source pattern
• C2 = number of target parses containing at least one
occurrence of C’s target pattern
• C12 = number of source and target parse pairs contain-
ing at least one co-occurrence of C’s source pattern
and C’s target pattern satisfying the alignment con-
straints
• N = number of source and target parse pairs
• P = C2/N;
• P1 = C12/C1;
• P2 = (C2 − C12)/(N − C1);
• L(k, n, x) = xk(1 − x)n−k
</listItem>
<figureCaption confidence="0.992417">
Figure 7: Log likelihood ratios for transfer rule
candidates
</figureCaption>
<bodyText confidence="0.96285">
each lexeme attribute and for each dependency re-
lationship. In our initial experiments, this simple
heuristic has been satisfactory.
</bodyText>
<subsectionHeader confidence="0.999659">
4.4 Filtering Rule Candidates
</subsectionHeader>
<bodyText confidence="0.999981">
Once the candidate transfer rules have been or-
dered, error-driven filtering is used to select those
that yield improvements over the baseline trans-
fer dictionary. The algorithm works as follows.
First, in the initialization step, the set of accepted
transfer rules is set to just those appearing in the
baseline transfer dictionary, and the current er-
ror rate is established by applying these transfer
rules to all the source structures and calculating
the overall difference between the resulting trans-
ferred structures and the target parses. Then, in a
single pass through the ordered list of candidates,
each transfer rule candidate is tested to see if it
reduces the error rate. During each iteration, the
candidate transfer rule is provisionally added to
the current set of accepted rules and the updated
set is applied to all the source structures. If the
overall difference between the transferred struc-
tures and the target parses is lower than the cur-
rent error rate, then the candidate is accepted and
</bodyText>
<figure confidence="0.535401636363636">
@KOREAN:
{po} [class=vbma ente={ra}] (
s1 $X [ppca={reul}]
)
@ENGLISH:
look [class=verb mood=imp] (
attr at [class=preposition] (
ii $X
)
)
@-2xLOG_LIKELIHOOD: 11.40
</figure>
<figureCaption confidence="0.9532905">
Figure 8: Transfer rule for English imperative
with lexicalization and preposition insertion
</figureCaption>
<bodyText confidence="0.757918">
the current error rate is updated; otherwise, the
candidate is rejected and removed from the cur-
rent set.
</bodyText>
<subsectionHeader confidence="0.998314">
4.5 Discussion of Induced Rules
</subsectionHeader>
<bodyText confidence="0.999878206896552">
Experimentation with the training set of 882 parse
pairs described in Section 3.1 produced 12467
source and target sub-tree pairs using the align-
ment constraints, from which 20569 transfer rules
candidate were generated and 7565 were accepted
after filtering. We expect that the number of
accepted rules per parse pair will decrease with
larger training sets, though this remains to be ver-
ified.
The rule illustrated in Figure 3 was accepted as
the 65th best transfer rule with a log likelihood
ratio of 33.37, and the rule illustrated in Figure 2
was accepted as the 189th best transfer rule can-
didate with a log likelihood ratio of 12.77. An ex-
ample of a candidate transfer rule that was not ac-
cepted is the one that combines the features of the
two rules mentioned above, illustrated in Figure 8.
This transfer rule candidate had a lower log like-
lihood ratio of 11.40; consequently, it is only con-
sidered after the two rules mentioned above, and
since it provides no further improvement upon
these two rules, it is filtered out.
In an informal inspection of the top 100 ac-
cepted transfer rules, we found that most of them
appear to be fairly general rules that would nor-
mally be found in a general syntactic-based trans-
fer dictionary. In looking at the remaining rules,
we found that the rules tended to become increas-
ingly corpus-specific.
</bodyText>
<sectionHeader confidence="0.936067" genericHeader="method">
5 Initial Evaluation
5.1 Results
</sectionHeader>
<bodyText confidence="0.999991547619048">
In an initial evaluation of our approach, we ap-
plied both the baseline transfer dictionary and
the induced transfer dictionary (i.e., the baseline
transfer dictionary augmented with the transfer
rules induced from the training set) to the test half
of the 1763 higher quality parse pairs described in
Section 3.1, in order to produce two sets of trans-
ferred parses, the baseline set and the induced set.
For each set, we then calculated tree accuracy re-
call and precision measures as follows:
Tree accuracy recall The tree accuracy recall
for a transferred parse and a correspond-
ing target parse is determined the by C/Rq,
where C is the total number of features (at-
tributes, lexemes and dependency relation-
ships) that are found in both the nodes of
the transferred parse and in the correspond-
ing nodes in the target parse, and Rq is the
total number of features found in the nodes
of the target parse. The correspondence be-
tween the nodes of the transferred parse and
the nodes of the target parse is determined
with alignment information obtained using
the technique described in Section 4.1.
Tree accuracy precision The tree accuracy pre-
cision for a transferred parse and a corre-
sponding target parse is determined the by
C/Rt, where C is the total number of fea-
tures (attributes, lexemes and dependency
relationships) that are found in both the
nodes of the transferred parse and in the cor-
responding nodes in the target parse, and Rt
is the total number of features found in the
nodes of the transferred parse.
Table 1 shows the tree accuracy results, where
the f-score is equally weighted between recall and
precision. The results illustrated in Table 1 indi-
cate that the transferred parses obtained using in-
duction were moderately more similar to the tar-
get parses than the transferred parses obtained us-
ing the baseline transfer, with about 15 percent
improvement in the f-score.
</bodyText>
<table confidence="0.998873333333333">
Recall Precision F-Score
Baseline 37.77 46.81 41.18
Induction 55.35 58.20 55.82
</table>
<tableCaption confidence="0.999416">
Table 1: Tree accuracy results
</tableCaption>
<subsectionHeader confidence="0.94791">
5.2 Discussion
</subsectionHeader>
<bodyText confidence="0.9361304">
At the time of writing, the improvements in tree
accuracy do not yet appear to yield apprecia-
ble improvements in realization results. While
our syntactic realizer, RealPro, does produce rea-
sonable surface strings from the target depen-
dency trees, despite occasional errors in parsing
the target strings and converting the phrase struc-
ture trees to dependency trees, it appears that the
tree accuracy levels for the transferred parses will
need to be higher on average before the improve-
ments in tree accuracy become consistently visi-
ble in the realization results. At present, the fol-
lowing three problems represent the most impor-
tant obstacles we have identified to achieving bet-
ter end-to-end results:
• Since many of the test sentences require
transfer rules for which there are no similar
cases in the set of training sentences, it ap-
pears that the relatively small size of our cor-
pus is a significant barrier to better results.
</bodyText>
<listItem confidence="0.897168875">
• Some performance problems with the cur-
rent implementation have forced us to make
use of a perhaps overly strict set of alignment
and attribute constraints. With an improved
implementation, it may be possible to find
more valuable rules from the same training
data.
• A more refined treatment of rule conflicts is
</listItem>
<bodyText confidence="0.86628475">
needed in order to allow multiple rules to
access overlapping contexts, while avoiding
the introduction of multiple translations of
the same content in certain cases.
</bodyText>
<sectionHeader confidence="0.989462" genericHeader="conclusions">
6 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.999659066666667">
In this paper we have presented a novel approach
to transfer rule induction based on syntactic pat-
tern co-occurrence in parsed bi-texts. In an initial
evaluation on a relatively small corpus, we have
shown that the induced syntactic transfer rules
from Korean to English lead to a modest increase
in the accuracy of transferred parses when com-
pared to the target parses. In future work, we
hope to demonstrate that a combination of consid-
ering a larger set of transfer rule candiates, refin-
ing our treatment of rule conflicts, and making use
of more training data will lead to further improve-
ments in tree accuracy, and, following syntactic
realization, will yield to significant improvements
in end-to-end results.
</bodyText>
<sectionHeader confidence="0.996364" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998696">
We thank Richard Kittredge for helpful discus-
sion, Daryl McCullough and Ted Caldwell for
their help with evaluation, and Chung-hye Han,
Martha Palmer, Joseph Rosenzweig and Fei Xia
for their assistance with the handcrafted Korean-
English transfer dictionary and the conversion of
phrase structure parses to syntactic dependency
representations. This work has been partially sup-
ported by DARPA TIDES contract no. N66001-
00-C-8009.
</bodyText>
<sectionHeader confidence="0.999253" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999167559322034">
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of the
35th Meeting of the Association for Computational
Linguistics (ACL’97), Madrid, Spain.
Bonnie Dorr. 1994. Machine translation divergences:
A formal description and proposed solution. Com-
putational Linguistics, 20(4):597–635.
C. Han, B. Lavoie, M. Palmer, O. Rambow, R. Kit-
tredge, T. Korelsky, N. Kim, and M. Kim. 2000.
Handling structural divergences and recovering
dropped arguments in a Korean-English machine
translation system. In Proceedings of the Fourth
Conference on Machine Translation in the Ameri-
cas (AMTA’00), Misin Del Sol, Mexico.
Benoit Lavoie and Owen Rambow. 1997. RealPro –
a fast, portable sentence realizer. In Proceedings of
the Conference on Applied Natural Language Pro-
cessing (ANLP’97), Washington, DC.
C. D. Manning and H. Schutze. 1999. Foundations
of Statistical Natural Language Processing. MIT
Press.
H. Maruyama and H. Watanabe. 1992. Tree cover
search algorithm for example-based translation. In
Proceedings of the Fourth International Conference
on Theoretical and Methodological Issues in Ma-
chine Translation (TMI’92), pages 173–184.
Y. Matsumoto, H. Hishimoto, and T. Utsuro. 1993.
Structural matching of parallel texts. In Proceed-
ings of the 31st Annual Meetings of the Association
for Computational Linguistics (ACL’93), pages 23–
30.
Igor Mel’ˇcuk. 1988. Dependency Syntax. State Uni-
versity of New York Press, Albany, NY.
A. Meyers, R. Yangarber, R. Grishman, C. Macleod,
and A. Moreno-Sandoval. 1998. Deriving transfer
rules from dominance-preserving alignments. In
Proceedings of COLING-ACL’98, pages 843–847.
Makoto Nagao. 1984. A framework of a mechan-
ical translation between Japenese and English by
analogy principle. In A. Elithorn and R. Banerji,
editors, Artificial and Human Intelligence. NATO
Publications.
Alexis Nasr, Owen Rambow, Martha Palmer, and
Joseph Rosenzweig. 1997. Enriching lexical trans-
fer with cross-linguistic semantic features. In Pro-
ceedings of the Interlingua Workshop at the MT
Summit, San Diego, California.
S. Sato and M. Nagao. 1990. Toward memory-
based translation. In Proceedings of the 13th Inter-
national Conference on Computational Linguistics
(COLING’90), pages 247–252.
Fei Xia and Martha Palmer. 2001. Converting depen-
dency structures to phrase structures. In Notes of
the First Human Language Technology Conference,
San Diego, California.
J. Yoon, S. Kim, and M. Song. 1997. New parsing
method using global association table. In Proceed-
ings of the 5th International Workshop on Parsing
Technology.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.822550">
<title confidence="0.999757">Inducing Lexico-Structural Transfer Rules from Parsed Bi-texts</title>
<author confidence="0.994119">Benoit Lavoie</author>
<author confidence="0.994119">Michael White</author>
<author confidence="0.994119">Tanya</author>
<affiliation confidence="0.841032">CoGenTex,</affiliation>
<address confidence="0.9980375">840 Hanshaw Ithaca, NY 14850,</address>
<email confidence="0.999813">benoit,mike,tanya@cogentex.com</email>
<abstract confidence="0.997891625">This paper describes a novel approach to inducing lexico-structural transfer rules from parsed bi-texts using syntactic pattern matching, statistical cooccurrence and error-driven filtering. We present initial evaluation results and discuss future directions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Meeting of the Association for Computational Linguistics (ACL’97),</booktitle>
<location>Madrid,</location>
<contexts>
<context position="7092" citStr="Collins (1997)" startWordPosition="1098" endWordPosition="1099"> accuracy is calculated. • For a subset of the translated strings, human judgments of accuracy and grammaticality are gathered, and the correlations between the manual and automatic scores are calculated, in order to assess the meaningfulness of the automatic measures. 3 Data Preparation 3.1 Parsing the Bi-texts In our experiments to date, we have used a corpus consisting of a Korean dialog of 4183 sentences and their English human translations. We ran off-the-shelf parsers on each half of the corpus, namely the Korean parser developed by Yoon et al. (1997) and the English parser developed by Collins (1997). Neither parser was trained on our corpus. We automatically converted the phrase structure output of the Collins parser into the syntactic dependency representation used by our syntactic realizer, RealPro (Lavoie and Rambow, 1997). This representation is based on the deepsyntactic structures (DSyntS) of Meaning-Text Theory (Mel’ˇcuk, 1988). The important features of a DSyntS are as follows: • a DSyntS is an unordered tree with labeled nodes and labeled arcs; • a DSyntS is lexicalized, meaning that the nodes are labeled with lexemes (uninflected words) from the target language; • a DSyntS is a</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of the 35th Meeting of the Association for Computational Linguistics (ACL’97), Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Dorr</author>
</authors>
<title>Machine translation divergences: A formal description and proposed solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2926" citStr="Dorr, 1994" startWordPosition="444" endWordPosition="445"> provided by parsers (tense, number, person, etc.). The second difference concerns the node alignment; in (Meyers et al., 1998), the alignment of source and target nodes is designed in a way that preserves node dominancy in the source and target parses, while our approach does not have such restriction. One of the reasons for this difference is due to the different language pairs under study; (Meyers et al., 1998) deals with two languages that are closely related syntactically (Spanish and English) while we are dealing with languages that syntactically are quite divergent, Korean and English (Dorr, 1994). The third difference is in the process of identification of transfer rules candidates; in (Meyers et al., 1998), the identification is done by using the exact tree fragments in the source and target parse that are delimited by the alignment, while we use all source and target tree sub-patterns matching a subset of the parse features that satisfy a customizable set of alignment constraints and attribute constraints. The fourth third difference is in the level of abstraction of transfer rules candidates; in (Meyers et al., 1998), the source and target patterns of each transfer rule are fully l</context>
<context position="15307" citStr="Dorr, 1994" startWordPosition="2418" endWordPosition="2419">ttribute constraint ) In a candidate transfer rule, inclusion of the lexemes of two aligned nodes must be done concurrently: Figure 4: Alignment constraint e.g. $X [aid=$1] and in a Korean and English parse pair, any source and target sub-trees matching this alignment constraint (where $X1 and $Y1 are aligned or have the same attribute aid values and where $X2 and $Y3 are aligned) can be used as a point of departure for generating transfer rule candidates. We suggest that alignment constraints such as this one can be used to define most of the possible syntactic divergences between languages (Dorr, 1994), and that only a handful of them are necessary for two given languages (we have identified 11 general alignment constraints necessary for Korean to English transfer so far). 4.2.2 Attribute constraints Attribute constraints are used to limit the space of possible transfer rule candidates that can be generated from the sub-trees satisfying the alignment constraints. Candidate transfer rules must satisfy all of the attribute constraints. Attribute constraints can be divided into two types: • independent attribute constraints, whose scope covers only one part of a candidate transfer rule and whi</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Bonnie Dorr. 1994. Machine translation divergences: A formal description and proposed solution. Computational Linguistics, 20(4):597–635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Han</author>
<author>B Lavoie</author>
<author>M Palmer</author>
<author>O Rambow</author>
<author>R Kittredge</author>
<author>T Korelsky</author>
<author>N Kim</author>
<author>M Kim</author>
</authors>
<title>Handling structural divergences and recovering dropped arguments in a Korean-English machine translation system.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fourth Conference on Machine Translation in the Americas (AMTA’00),</booktitle>
<location>Misin Del Sol, Mexico.</location>
<contexts>
<context position="1072" citStr="Han et al., 2000" startWordPosition="149" endWordPosition="152">irections. 1 Introduction This paper describes a novel approach to inducing transfer rules from syntactic parses of bi-texts and available bilingual dictionaries. The approach consists of inducing transfer rules using the four major steps described in more detail below: (i) aligning the nodes of the parses; (ii) generating candidate rules from these alignments; (iii) ordering candidate rules by co- occurrence; and (iv) applying error-driven filtering to select the final set of rules. Our approach is based on lexico-structural transfer (Nasr et. al., 1997), and extends recent work reported in (Han et al., 2000) about Korean to English transfer in particular. Whereas Han et al. focus on high quality domain-specific translation using handcrafted transfer rules, in this work we instead focus on automating the acquisition of such rules. Our approach can be considered a generalization of syntactic approaches to example-based machine translation (EBMT) such as (Nagao, 1984; Sato and Nagao, 1990; Maruyama and Watanabe, 1992). While such approaches use syntactic transfer examples during the actual transfer of source parses, our approach instead uses syntactic transfer examples to induce general transfer rul</context>
<context position="13416" citStr="Han et al. (2000)" startWordPosition="2105" endWordPosition="2108">straint, which matches the structural patterns of the transfer rule illustrated in Figure 2, uses the aid alignment attribute to indicate that Figure 2: Transfer rule for English lexicalization and preposition insertion @KOREAN: $X [class=vbma ente={ra}] @ENGLISH: $X [class=verb mood=imp] @-2xLOG_LIKELIHOOD: 33.37 Figure 3: Transfer rule for imperative forms tionary is created from lexical transfer entries extracted from the bi-texts using statistical methods. To simulate this scenario, we created our baseline transfer dictionary by taking the lexico-syntactic transfer dictionary developed by Han et al. (2000) for this corpus and removing the (more general) rules that were not fully lexicalized. Starting with this purely lexical baseline transfer dictionary enabled us to examine whether these more general rules could be discovered through induction. 4 Transfer Rule Induction The induced lexico-structural transfer rules are represented in a formalism similar to the one described in Nasr et al. (1997), and extended to also include log likelihood ratios. Figures 2 and 3 illustrate two entry samples that can be used to transfer a Korean syntactic representation for cito-reul po-ra to an English syntact</context>
</contexts>
<marker>Han, Lavoie, Palmer, Rambow, Kittredge, Korelsky, Kim, Kim, 2000</marker>
<rawString>C. Han, B. Lavoie, M. Palmer, O. Rambow, R. Kittredge, T. Korelsky, N. Kim, and M. Kim. 2000. Handling structural divergences and recovering dropped arguments in a Korean-English machine translation system. In Proceedings of the Fourth Conference on Machine Translation in the Americas (AMTA’00), Misin Del Sol, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Lavoie</author>
<author>Owen Rambow</author>
</authors>
<title>RealPro – a fast, portable sentence realizer.</title>
<date>1997</date>
<booktitle>In Proceedings of the Conference on Applied Natural Language Processing (ANLP’97),</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="7323" citStr="Lavoie and Rambow, 1997" startWordPosition="1132" endWordPosition="1135">ss the meaningfulness of the automatic measures. 3 Data Preparation 3.1 Parsing the Bi-texts In our experiments to date, we have used a corpus consisting of a Korean dialog of 4183 sentences and their English human translations. We ran off-the-shelf parsers on each half of the corpus, namely the Korean parser developed by Yoon et al. (1997) and the English parser developed by Collins (1997). Neither parser was trained on our corpus. We automatically converted the phrase structure output of the Collins parser into the syntactic dependency representation used by our syntactic realizer, RealPro (Lavoie and Rambow, 1997). This representation is based on the deepsyntactic structures (DSyntS) of Meaning-Text Theory (Mel’ˇcuk, 1988). The important features of a DSyntS are as follows: • a DSyntS is an unordered tree with labeled nodes and labeled arcs; • a DSyntS is lexicalized, meaning that the nodes are labeled with lexemes (uninflected words) from the target language; • a DSyntS is a dependency structure and not a phrase- structure structure: there are no nonterminal nodes, and all nodes are labeled with lexemes; • a DSyntS is a syntactic representation, meaning that the arcs of the tree are labeled with synta</context>
</contexts>
<marker>Lavoie, Rambow, 1997</marker>
<rawString>Benoit Lavoie and Owen Rambow. 1997. RealPro – a fast, portable sentence realizer. In Proceedings of the Conference on Applied Natural Language Processing (ANLP’97), Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schutze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="16645" citStr="Manning and Schutze, 1999" startWordPosition="2628" endWordPosition="2631">the source and target parts of a candidate transfer rule. The examples of an independent attribute constraint and of a concurrent attribute constraint are given in Figure 5 and Figure 6 respectively. As with the alignment constraints, we suggest that a relatively small number of attribute constraints is necessary to generate most of the desired rules for a given language pair. $Y [aid=$1] e.g. 0 [aid=$1] and 0 [aid=$1] Figure 6: Concurrent attribute constraint 4.3 Ordering Rule Candidates In the next step, transfer rule candidates are ordered as follows: first, by their log likelihood ratios (Manning and Schutze, 1999: 172-175); second, any transfer rule candidates with the same log likelihood ratio are ordered by their specificity. 4.3.1 Rule ordering by log likelihood ratio We calculate the log likelihood ratio, log A, applied to a transfer rule candidate as indicated in Figure 7. Note that log A is a negative value, and following (Manning and Schutze, 1999), we assign -2 log A to the transfer rule. Note also that in the definitions of C1, C2, and C12 we are currently only considering one occurrence or cooccurrence of the source and/or target patterns per parse pair, while in general there could be more </context>
</contexts>
<marker>Manning, Schutze, 1999</marker>
<rawString>C. D. Manning and H. Schutze. 1999. Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Maruyama</author>
<author>H Watanabe</author>
</authors>
<title>Tree cover search algorithm for example-based translation.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI’92),</booktitle>
<pages>173--184</pages>
<contexts>
<context position="1487" citStr="Maruyama and Watanabe, 1992" startWordPosition="212" endWordPosition="215">currence; and (iv) applying error-driven filtering to select the final set of rules. Our approach is based on lexico-structural transfer (Nasr et. al., 1997), and extends recent work reported in (Han et al., 2000) about Korean to English transfer in particular. Whereas Han et al. focus on high quality domain-specific translation using handcrafted transfer rules, in this work we instead focus on automating the acquisition of such rules. Our approach can be considered a generalization of syntactic approaches to example-based machine translation (EBMT) such as (Nagao, 1984; Sato and Nagao, 1990; Maruyama and Watanabe, 1992). While such approaches use syntactic transfer examples during the actual transfer of source parses, our approach instead uses syntactic transfer examples to induce general transfer rules that can be compiled into a transfer dictionary for use in the actual translation process. Our approach is similar to the recent work of (Meyers et al., 1998) where transfer rules are also derived after aligning the source and target nodes of corresponding parses. However, it also differs from (Meyers et al., 1998) in several important points. The first difference concerns the content of parses and the result</context>
</contexts>
<marker>Maruyama, Watanabe, 1992</marker>
<rawString>H. Maruyama and H. Watanabe. 1992. Tree cover search algorithm for example-based translation. In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI’92), pages 173–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>H Hishimoto</author>
<author>T Utsuro</author>
</authors>
<title>Structural matching of parallel texts.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meetings of the Association for Computational Linguistics (ACL’93),</booktitle>
<pages>23--30</pages>
<marker>Matsumoto, Hishimoto, Utsuro, 1993</marker>
<rawString>Y. Matsumoto, H. Hishimoto, and T. Utsuro. 1993. Structural matching of parallel texts. In Proceedings of the 31st Annual Meetings of the Association for Computational Linguistics (ACL’93), pages 23– 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>Albany, NY.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>Igor Mel’ˇcuk. 1988. Dependency Syntax. State University of New York Press, Albany, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Yangarber</author>
<author>R Grishman</author>
<author>C Macleod</author>
<author>A Moreno-Sandoval</author>
</authors>
<title>Deriving transfer rules from dominance-preserving alignments.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL’98,</booktitle>
<pages>843--847</pages>
<contexts>
<context position="1833" citStr="Meyers et al., 1998" startWordPosition="266" endWordPosition="269">fer rules, in this work we instead focus on automating the acquisition of such rules. Our approach can be considered a generalization of syntactic approaches to example-based machine translation (EBMT) such as (Nagao, 1984; Sato and Nagao, 1990; Maruyama and Watanabe, 1992). While such approaches use syntactic transfer examples during the actual transfer of source parses, our approach instead uses syntactic transfer examples to induce general transfer rules that can be compiled into a transfer dictionary for use in the actual translation process. Our approach is similar to the recent work of (Meyers et al., 1998) where transfer rules are also derived after aligning the source and target nodes of corresponding parses. However, it also differs from (Meyers et al., 1998) in several important points. The first difference concerns the content of parses and the resulting transfer rules; in (Meyers et al., 1998), parses contain only lexical labels and syntactic roles (as arc labels), while our approach uses parses containing lexical labels, syntactic roles, and any other syntactic information provided by parsers (tense, number, person, etc.). The second difference concerns the node alignment; in (Meyers et a</context>
<context position="3460" citStr="Meyers et al., 1998" startWordPosition="530" endWordPosition="533">with languages that syntactically are quite divergent, Korean and English (Dorr, 1994). The third difference is in the process of identification of transfer rules candidates; in (Meyers et al., 1998), the identification is done by using the exact tree fragments in the source and target parse that are delimited by the alignment, while we use all source and target tree sub-patterns matching a subset of the parse features that satisfy a customizable set of alignment constraints and attribute constraints. The fourth third difference is in the level of abstraction of transfer rules candidates; in (Meyers et al., 1998), the source and target patterns of each transfer rule are fully lexicalized (except possibly the terminal nodes), while in our approach the nodes of transfer rules do not have to be lexicalized. Section 2 describes our approach to transfer rules induction and its integration with data preparation and evaluation. Section 3 describes the data preparation process and resulting data. Section 4 describes the transfer induction process in detail. Section 5 describes the results of our initial evaluation. Finally, Section 6 concludes with a discussion of future directions. 2 Overall Approach In its </context>
</contexts>
<marker>Meyers, Yangarber, Grishman, Macleod, Moreno-Sandoval, 1998</marker>
<rawString>A. Meyers, R. Yangarber, R. Grishman, C. Macleod, and A. Moreno-Sandoval. 1998. Deriving transfer rules from dominance-preserving alignments. In Proceedings of COLING-ACL’98, pages 843–847.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Nagao</author>
</authors>
<title>A framework of a mechanical translation between Japenese and English by analogy principle.</title>
<date>1984</date>
<editor>In A. Elithorn and R. Banerji, editors,</editor>
<publisher>NATO Publications.</publisher>
<contexts>
<context position="1435" citStr="Nagao, 1984" startWordPosition="206" endWordPosition="207"> ordering candidate rules by co- occurrence; and (iv) applying error-driven filtering to select the final set of rules. Our approach is based on lexico-structural transfer (Nasr et. al., 1997), and extends recent work reported in (Han et al., 2000) about Korean to English transfer in particular. Whereas Han et al. focus on high quality domain-specific translation using handcrafted transfer rules, in this work we instead focus on automating the acquisition of such rules. Our approach can be considered a generalization of syntactic approaches to example-based machine translation (EBMT) such as (Nagao, 1984; Sato and Nagao, 1990; Maruyama and Watanabe, 1992). While such approaches use syntactic transfer examples during the actual transfer of source parses, our approach instead uses syntactic transfer examples to induce general transfer rules that can be compiled into a transfer dictionary for use in the actual translation process. Our approach is similar to the recent work of (Meyers et al., 1998) where transfer rules are also derived after aligning the source and target nodes of corresponding parses. However, it also differs from (Meyers et al., 1998) in several important points. The first diff</context>
</contexts>
<marker>Nagao, 1984</marker>
<rawString>Makoto Nagao. 1984. A framework of a mechanical translation between Japenese and English by analogy principle. In A. Elithorn and R. Banerji, editors, Artificial and Human Intelligence. NATO Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Nasr</author>
<author>Owen Rambow</author>
<author>Martha Palmer</author>
<author>Joseph Rosenzweig</author>
</authors>
<title>Enriching lexical transfer with cross-linguistic semantic features.</title>
<date>1997</date>
<booktitle>In Proceedings of the Interlingua Workshop at the MT Summit,</booktitle>
<location>San Diego, California.</location>
<contexts>
<context position="13813" citStr="Nasr et al. (1997)" startWordPosition="2167" endWordPosition="2170">nsfer entries extracted from the bi-texts using statistical methods. To simulate this scenario, we created our baseline transfer dictionary by taking the lexico-syntactic transfer dictionary developed by Han et al. (2000) for this corpus and removing the (more general) rules that were not fully lexicalized. Starting with this purely lexical baseline transfer dictionary enabled us to examine whether these more general rules could be discovered through induction. 4 Transfer Rule Induction The induced lexico-structural transfer rules are represented in a formalism similar to the one described in Nasr et al. (1997), and extended to also include log likelihood ratios. Figures 2 and 3 illustrate two entry samples that can be used to transfer a Korean syntactic representation for cito-reul po-ra to an English syntactic representation for look at the map. The first rule lexicalizes the English predicate and inserts the corresponding preposition while the second rule inserts the English imperative attribute. This formalism uses notation similar to the syntactic dependency notation shown in Figure 1, augmented with variable arguments prefixed with $ characters. @KOREAN: $X1 [aid=$1] ( $R1 $X2 [aid=$2] Each no</context>
</contexts>
<marker>Nasr, Rambow, Palmer, Rosenzweig, 1997</marker>
<rawString>Alexis Nasr, Owen Rambow, Martha Palmer, and Joseph Rosenzweig. 1997. Enriching lexical transfer with cross-linguistic semantic features. In Proceedings of the Interlingua Workshop at the MT Summit, San Diego, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
<author>M Nagao</author>
</authors>
<title>Toward memorybased translation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING’90),</booktitle>
<pages>247--252</pages>
<contexts>
<context position="1457" citStr="Sato and Nagao, 1990" startWordPosition="208" endWordPosition="211">didate rules by co- occurrence; and (iv) applying error-driven filtering to select the final set of rules. Our approach is based on lexico-structural transfer (Nasr et. al., 1997), and extends recent work reported in (Han et al., 2000) about Korean to English transfer in particular. Whereas Han et al. focus on high quality domain-specific translation using handcrafted transfer rules, in this work we instead focus on automating the acquisition of such rules. Our approach can be considered a generalization of syntactic approaches to example-based machine translation (EBMT) such as (Nagao, 1984; Sato and Nagao, 1990; Maruyama and Watanabe, 1992). While such approaches use syntactic transfer examples during the actual transfer of source parses, our approach instead uses syntactic transfer examples to induce general transfer rules that can be compiled into a transfer dictionary for use in the actual translation process. Our approach is similar to the recent work of (Meyers et al., 1998) where transfer rules are also derived after aligning the source and target nodes of corresponding parses. However, it also differs from (Meyers et al., 1998) in several important points. The first difference concerns the co</context>
</contexts>
<marker>Sato, Nagao, 1990</marker>
<rawString>S. Sato and M. Nagao. 1990. Toward memorybased translation. In Proceedings of the 13th International Conference on Computational Linguistics (COLING’90), pages 247–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Martha Palmer</author>
</authors>
<title>Converting dependency structures to phrase structures.</title>
<date>2001</date>
<booktitle>In Notes of the First Human Language Technology Conference,</booktitle>
<location>San Diego, California.</location>
<marker>Xia, Palmer, 2001</marker>
<rawString>Fei Xia and Martha Palmer. 2001. Converting dependency structures to phrase structures. In Notes of the First Human Language Technology Conference, San Diego, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yoon</author>
<author>S Kim</author>
<author>M Song</author>
</authors>
<title>New parsing method using global association table.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th International Workshop on Parsing Technology.</booktitle>
<contexts>
<context position="7041" citStr="Yoon et al. (1997)" startWordPosition="1088" endWordPosition="1091">get strings are measured, and the improvement in string accuracy is calculated. • For a subset of the translated strings, human judgments of accuracy and grammaticality are gathered, and the correlations between the manual and automatic scores are calculated, in order to assess the meaningfulness of the automatic measures. 3 Data Preparation 3.1 Parsing the Bi-texts In our experiments to date, we have used a corpus consisting of a Korean dialog of 4183 sentences and their English human translations. We ran off-the-shelf parsers on each half of the corpus, namely the Korean parser developed by Yoon et al. (1997) and the English parser developed by Collins (1997). Neither parser was trained on our corpus. We automatically converted the phrase structure output of the Collins parser into the syntactic dependency representation used by our syntactic realizer, RealPro (Lavoie and Rambow, 1997). This representation is based on the deepsyntactic structures (DSyntS) of Meaning-Text Theory (Mel’ˇcuk, 1988). The important features of a DSyntS are as follows: • a DSyntS is an unordered tree with labeled nodes and labeled arcs; • a DSyntS is lexicalized, meaning that the nodes are labeled with lexemes (uninflect</context>
</contexts>
<marker>Yoon, Kim, Song, 1997</marker>
<rawString>J. Yoon, S. Kim, and M. Song. 1997. New parsing method using global association table. In Proceedings of the 5th International Workshop on Parsing Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>