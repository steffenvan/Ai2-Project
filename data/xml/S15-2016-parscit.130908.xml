<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002188">
<title confidence="0.991286">
TrWP: Text Relatedness using Word and Phrase Relatedness
</title>
<author confidence="0.974689">
Md Rashadul Hasan Rakib Aminul Islam Evangelos Milios
</author>
<affiliation confidence="0.99525">
Faculty of Computer Science
Dalhousie University, Canada
</affiliation>
<email confidence="0.998236">
{rakib,islam,eem}@cs.dal.ca
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994227705882353">
Text is composed of words and phrases. In
bag-of-word model, phrases in texts are split
into words. This may discard the inner seman-
tics of phrases which in turn may give incon-
sistent relatedness score between two texts.
TrWP, the unsupervised text relatedness ap-
proach combines both word and phrase relat-
edness. The word relatedness is computed
using an existing unsupervised co-occurrence
based method. The phrase relatedness is com-
puted using an unsupervised phrase related-
ness function f that adopts Sum-Ratio tech-
nique based on the statistics in the Google n-
gram corpus of overlapping n-grams associ-
ated with the two input phrases. The second
run of TrWP ranked 30th out of 73 runs in
SemEval-2015 task2a (English STS).
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999328833333333">
Generally, a phrase is an ordered sequence of mul-
tiple words that all together refer to a particular
meaning (Zamir and Etzioni, 1999). Phrase related-
ness quantifies how two phrases relate to each other.
It plays an important role in different Text Mining
tasks; for instance, document similarity 1, classifica-
tion and clustering are performed on the documents
composed of phrases. Several document clustering
methods use phrase similarity to determine the simi-
larity between documents so as to improve the clus-
tering result (Chim and Deng, 2008; Shrivastava et
al., 2013). SpamED (Pera and Ng, 2009) uses the
</bodyText>
<footnote confidence="0.942199">
1We use ‘relatedness’ and ‘similarity’ interchangeably in
our paper, albeit ‘similarity’ is a special case of ‘relatedness’.
</footnote>
<bodyText confidence="0.999778166666667">
bi-gram and tri-gram phrase similarity between an
incoming e-mail message and a previously marked
spam to enhance the accuracy of spam detection.
Most works on text relatedness can be abstracted
as a function of word relatedness (Ho et al., 2010).
The classical Bag-of-Word (BoW) text relatedness
methods split phrases into words; then compute text-
pair relatedness by word-pair relatedness (Islam and
Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al.,
2010). TrWP considers text as Bag-of-Word-and-
Phrase (BoWP). It considers a (word, bi-gram) or
(bi-gram, bi-gram) pair as a phrase-pair 2 and com-
putes text relatedness using both word and phrase
relatedness.
There are phrase relatedness tasks that use com-
positional distributional semantic (CDS) model (An-
nesi et al., 2012; Hartung and Frank, 2011).
Some use different tools and knowledge-based re-
sources (Han et al., 2013; Tsatsaronis et al., 2010).
These methods split phrases into words without con-
sidering the word order that might change the mean-
ing of phrases leading to inconsistent phrase relat-
edness score (Turney and Pantel, 2010). For exam-
ple, if we split the phrases “boat house” and “house
boat” into words, we get the relatedness score one,
nonetheless as a whole unit, these two phrases do not
refer to exactly the same meaning (Turney and Pan-
tel, 2010). To preserve the phrase meaning, TrWP
uses the phrase relatedness function f that considers
a phrase as a single unit.
</bodyText>
<footnote confidence="0.995707">
2We consider the bi-grams as phrases. A word is also con-
sidered as a phrase when relatedness is computed between word
and bi-gram.
</footnote>
<page confidence="0.976849">
90
</page>
<note confidence="0.615304">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 90–95,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.772756" genericHeader="method">
2 Terminology used in Phrase Relatedness
</sectionHeader>
<bodyText confidence="0.997164">
The terminologies used in measuring phrase related-
ness are described below.
</bodyText>
<subsectionHeader confidence="0.977147">
2.1 Bi-gram Context
</subsectionHeader>
<bodyText confidence="0.9987042">
Bi-gram context is a bi-gram, extracted by placing
a phrase in the left most, middle and right position
within the Google n(=3,4)-grams. Sample bi-gram
contexts for the bi-gram phrase “large number” are
shown in Table 1.
</bodyText>
<table confidence="0.98548175">
Phrase position Google 4-grams
Left most large number of files
Middle very large number generator
Right most multiply a large number
</table>
<tableCaption confidence="0.950197666666667">
Table 1: Positions of the bi-gram phrase (“large
number”) in Google 4-grams and corresponding bi-
gram contexts marked bold.
</tableCaption>
<subsectionHeader confidence="0.999864">
2.2 Overlapping Bi-gram Context
</subsectionHeader>
<bodyText confidence="0.999979714285714">
The overlapping bi-gram context is a bi-gram which
is overlapped between two Google n(=3,4)-grams
that contain two target phrases at the same posi-
tion. Consider two Google 4-grams “large number
of death” and “vast amount of death” where “large
number” and “vast amount” are the target phrases
and “of death” is an overlapping bi-gram context.
</bodyText>
<subsectionHeader confidence="0.994716">
2.3 Sum-Ratio (SR)
</subsectionHeader>
<bodyText confidence="0.999641222222222">
Sum-Ratio refers to the product of sum and ratio be-
tween the minimum (min) and maximum (max) of
two numbers. The Sum-Ratio of two numbers in-
dicates the strength of association between them by
maximizing the sum of two numbers with respect to
their ratio. The objective of Sum-Ratio is to capture
the strength of association between two overlapping
Google n(=3,4)-grams. Given two numbers a and b,
the Sum-Ratio of a and b is defined as follows.
</bodyText>
<construct confidence="0.774554333333333">
Sum(a, b) = a + b
Ratio(a, b) = min(a, b)/max(a, b)
Sum-Ratio(a, b) = Sum × Ratio
</construct>
<subsectionHeader confidence="0.998027">
2.4 Relatedness Strength
</subsectionHeader>
<bodyText confidence="0.9974268">
Relatedness strength is the strength of association
between two phrases P1 and P2, computed using
the Sum-Ratio values between the counts of any two
Google n(=3,4)-grams that contain P1 and P2, re-
spectively and an overlapping bi-gram context.
</bodyText>
<sectionHeader confidence="0.984575" genericHeader="method">
3 Phrase Detection
</sectionHeader>
<bodyText confidence="0.999473130434783">
Given a specific text, we elicit bi-grams of in-
terest as candidate phrases if they are highly
frequent in the Google bi-gram corpus, as-
serted in the Google Book-Ngram-Viewer
(books.google.com/ngrams/info). We adopt a
naive approach to detect the bi-gram phrases using
the mean (ubg) and standard deviation (sdbg) of all
Google bi-gram frequencies which are computed
once. At first, the whole text is split by stop-words
producing a list of c-grams 3. Then for each c-gram,
the following two steps are executed.
Step 1: If the c-gram is a bi-gram and its fre-
quency is greater than ubg + sdbg, then we add it
to the list of bi-gram phrases.
Step 2: If the length of c-gram is greater than
two, we generate an array of bi-grams from the c-
gram and find the most frequent bi-gram (mfbg)
among them; If the frequency of mfbg is greater
than ubg + sdbg, then we add mfbg to the list of
bi-gram phrases and split the c-gram into two parts
(e.g., left, right) by mfbg. After splitting, for each
of the left and right parts, we examine the Step 1 and
Step 2 recursively.
</bodyText>
<sectionHeader confidence="0.967394" genericHeader="method">
4 Computing Phrase Relatedness
</sectionHeader>
<bodyText confidence="0.999949166666667">
The phrase relatedness function f, computes relat-
edness strength between two phrases P1 and P2 us-
ing the Google n-gram corpus (Brants and Franz,
2006) which is then normalized between 0 and 1 us-
ing NGD (Cilibrasi and Vitanyi, 2007) in conjunc-
tion with NGD´ (Gracia et al., 2006).
</bodyText>
<subsectionHeader confidence="0.999339">
4.1 Lexical Pruning on the Bi-gram Contexts
</subsectionHeader>
<bodyText confidence="0.9999818">
At first the bi-gram contexts of phrases are extracted.
However some phrases along with their bi-gram
contexts do not convey meaningful insight due to the
improper positioning of stop-words within bi-gram
contexts. Therefore lexical pruning 4 is performed
</bodyText>
<footnote confidence="0.785372">
3c-gram: A chunk of uni-grams with no stop-word.
4Perform pruning on the bi-gram contexts implies to the
pruning of the Google n(=3,4)-grams from which those contexts
are extracted.
</footnote>
<page confidence="0.997681">
91
</page>
<bodyText confidence="0.999994636363637">
based on the position of stop-words inside the bi-
gram contexts. When the target phrase is placed at
the left or right most positions respectively, then the
Google n(=3,4)-gram is pruned if the right or left
most word is a stop-word. When the phrase is in the
middle surrounded by two context words, then the
Google n(=3,4)-gram is pruned if both the surround-
ing context words are stop-words. After perform-
ing lexical pruning, we have two sets of non-pruned
Google n(=3,4)-grams containing the bi-gram con-
texts of two phrases, respectively.
</bodyText>
<subsectionHeader confidence="0.999712">
4.2 Finding Overlapping Bi-gram Contexts
</subsectionHeader>
<bodyText confidence="0.9999942">
We find the overlapping bi-gram contexts between
two sets of non-pruned Google n(=3,4)-grams. The
Google n(=3,4)-grams having overlapping bi-gram
contexts are separated from the Google n(=3,4)-
grams that have no overlapping contexts.
</bodyText>
<subsectionHeader confidence="0.99964">
4.3 Statistical Pruning on the Overlapping
Bi-gram Contexts
</subsectionHeader>
<bodyText confidence="0.9999795625">
Each Google n(=3,4)-gram pair with overlapping bi-
gram context possesses a strength of association. We
presume that if most of the Google n(=3,4)-gram
pairs have higher strengths of association, the relat-
edness score between two phrases tends to be higher
and vice versa. However some strengths of associa-
tion do not lie within the group of maximum num-
ber of strengths of association called outliers and be-
cause of the outliers the relatedness score between
two phrases becomes inconsistent. Hence we apply
statistical pruning on the strengths of association to
prune the outliers. To find the group of maximum
number of strengths of association and prune the
outliers, we adopt the Normal Distribution (Bohm
and Zech, 2010) for statistical pruning. It has been
shown that in Normal Distribution most of the sam-
ples exist within the mean ± standard deviation.
We divide each Google n(=3,4)-gram count (fre-
quency) within a pair by the count of its corre-
sponding n(=1,2)-gram phrase, resulting a normal-
ized count. For each Google n(=3,4)-gram pair, the
minimum and maximum among the two normal-
ized counts are determined. After that we calculate
the ratio (e.g., minimum/maximum) between them.
Following that, for each Google n(=3,4)-gram pair,
we multiply the ratio with the sum of two Google
n(=3,4)-gram counts, producing a resultant product
(e.g., strength of association). Later on we compute
the mean (usr) and standard deviation (sdsr) from
the strengths of association of the Google n(=3,4)-
gram pairs. If the strength of association is within
the usr ± sdsr, it is kept otherwise pruned.
</bodyText>
<subsectionHeader confidence="0.998453">
4.4 Computing Relatedness Strength
</subsectionHeader>
<bodyText confidence="0.995299333333333">
Relatedness strength between P1 and P2 is com-
puted by multiplying the relatedness strengths from
overlapping and all bi-gram contexts.
</bodyText>
<subsectionHeader confidence="0.885376">
4.4.1 Relatedness Strength using Overlapping
Bi-gram Contexts
</subsectionHeader>
<bodyText confidence="0.999671368421053">
For each non-pruned Google n(=3,4)-gram pair
having overlapping bi-gram context, the strength of
association is calculated following the Sum-Ratio
technique. We sum the two Google n(=3,4)-gram
counts and find the minimum and maximum among
them. After that we calculate the ratio (e.g., min-
imum/maximum) between them. Then the Sum-
Ratio value is calculated by multiplying the sum
with ratio which signifies the strength of associa-
tion for a Google n(=3,4)-gram pair. By summing up
the strength of association of each Google n(=3,4)-
gram pair, we get the relatedness strength between
the phrases P1 and P2 denoted by R5OB(P1, P2)
as shown in Eq. 1. GP1 and GP2 are the Google
n(=3,4)-grams that contain P1 and P2, respectively
and an overlapping bi-gram context. C(GP1) and
C(GP2) are the counts of GP1 and GP2, respec-
tively. k is the number of non-pruned Google
n(=3,4)-gram pairs.
</bodyText>
<equation confidence="0.99939625">
R5OB(P1, P2) =
n min(C(GP1), C(GP2)) × sum(C(GP1), C(GP2))
max(C(GP1), C(GP2))
(1)
</equation>
<subsectionHeader confidence="0.6979835">
4.4.2 Relatedness Strength using all Bi-gram
Contexts
</subsectionHeader>
<bodyText confidence="0.9998295">
All bi-gram contexts of a phrase P1 include both
non-pruned overlapping and non-overlapping bi-
gram contexts, extracted from the Google n(=3,4)-
grams where P1 appears. Two vectors V1 and V2
in Vector Space Model are constructed for P1 and
P2, respectively using their corresponding all bi-
gram Contexts. The elements of V1 and V2 are bi-
nary and reflect the presence or absence of a bi-gram
</bodyText>
<page confidence="0.990806">
92
</page>
<bodyText confidence="0.9999424">
context belonging to the phrases P1 and P2, corre-
spondingly. The relatedness strength between P1
and P2 using all bi-gram contexts is designated as
cosSim(V1, V2), and computed by the cosine simi-
larity between V1 and V2, defined in Eq. 2.
</bodyText>
<equation confidence="0.9975115">
V1.V2
cosSim(V1,V2) = ||V1  |V2||
</equation>
<subsectionHeader confidence="0.496357">
4.4.3 Multiplying Relatedness Strengths from
Overlapping and all Bi-gram Contexts
</subsectionHeader>
<bodyText confidence="0.74432725">
We multiply the relatedness strengths
RSOB(P1, P2) and cosSim(V1, V2) obtained
from overlapping and all bi-gram contexts, respec-
tively to compute the overall relatedness strength
f(P1, P2) between the phrases P1 and P2, defined
in Eq. 3. The purpose of multiplying these two
strengths is to quantify RSOB(P1, P2) with respect
to cosSim(V1, V2).
</bodyText>
<equation confidence="0.912261">
f(P1, P2) = RSOB(P1, P2) × cosSim(V1, V2)
</equation>
<subsectionHeader confidence="0.796289">
4.5 Normalizing Overall Relatedness Strength
</subsectionHeader>
<bodyText confidence="0.999575857142857">
The relatedness between phrases P1 and P2 is
computed by normalizing the overall relatedness
strength between 0 and 1 using NGD in conjunction
with NGD´ as defined in Eq. 4. C(P) is the count of
phrase P where P is a Google n(=1,2)-gram. N =
total number of web documents used in the Google
n-gram corpus.
</bodyText>
<equation confidence="0.964251666666667">
NGDf(P1, P2) =
−2× max(log C(P1),log C(P2))−log f(P1,P2)
elog N−min(log C(P1),log C(P2))
</equation>
<sectionHeader confidence="0.980815" genericHeader="method">
5 Computing Text Relatedness
</sectionHeader>
<bodyText confidence="0.976836676470588">
At first punctuations are removed from texts. The
phrases are extracted using phrase detection algo-
rithm. Other than phrases the rest of the text is split
into non stop-words. The relatedness between two
texts is calculated by the word-pair and phrase-pair
relatedness following the notion of text relatedness
in (Islam et al., 2012). Word-pair relatedness is com-
puted by the word relatedness method in (Islam et
al., 2012).
Step 1: We assume that the two texts A =
{a1, a2,..., ap} and B = {b1, b2,..., bq} have p and
q tokens, respectively and p ≤ q. Otherwise we
switch A and B. A token is a word or bi-gram
phrase.
Step 2: We count the number of common tokens
(S) in both A and B where S ≤ p. Common tokens
are determined by applying PorterStemmer (Porter,
1980) on each token pair. Common tokens are re-
moved from A and B. So, A = {a1, a2,..., ap−δ}
and B = {b1, b2,..., bq−δ}. If all tokens match e.g.,
p − S = 0, go to step Step 5.
Step 3: We construct a (p − S) × (q − S) ‘seman-
tic relatedness matrix’ (Say, M = (αij)(p−δ)×(q−δ))
using the following process. We set αij ←
relatedness(ai, bj) × w2 where i = 1...p − S, j =
1...q − S, w = weighting factor to boost the related-
ness score. The value of w is the average number of
words within a word or phrase-pair. The reason for
boosting is that same relatedness score of a phrase-
pair is more weighted than that of a word-pair.
If (ai, bj) is a word-pair, relatedness(ai, bj) =
word-pair relatedness (Islam et al., 2012); otherwise
relatedness(ai, bj) = phrase-pair relatedness from
Eq. 4.
</bodyText>
<equation confidence="0.8974418">
α1,1 ··· α1,j ··· α1,q−δ
α2,1 ··· α2,j ··· α2,q−δ
...
.. . ....
. .
αi,1 ··· αi,j ··· αi,q−δ
...
.. . ....
. .
αp−δ,1 ··· αp−δ,j ··· αp−δ,q−δ
</equation>
<bodyText confidence="0.999679181818182">
Step 4: For each row we compute the mean
(u) and standard deviation (sd) of the relatedness
scores and select the scores which are larger than
u+sd. The idea is to find more related tokens among
(q − S), for each (p − S) tokens. The average of the
selected scores is computed for a row and for (p−S)
rows we get (p − S) averages. We sum the (p − S)
average values denoted by SAvg.
Step 5: To compute relatedness between the texts
A and B, we use the normalization in (Islam et al.,
2012) with minor modification, given in Eq. 5.
</bodyText>
<equation confidence="0.9948055">
rel.(A, B) = (2|S |+ SAvg) × (2|A |+ 2|B|)
2 · 2|A |· 2|B|
</equation>
<bodyText confidence="0.9088504">
(5)
Number of words in A, B and S are denoted by
|A|, |B|, |S|, respectively. Since we multiply w with
relatedness score while constructing the matrix M;
|A|,|B |and |S |are multiplied by 2.
</bodyText>
<figure confidence="0.991256857142857">
⎛
⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝
M=
...
...
⎞
⎠⎟⎟⎟⎟⎟⎟⎟⎟
</figure>
<page confidence="0.823567">
93
</page>
<sectionHeader confidence="0.698631" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.996874">
statistical pruning. Unlike other phrase relatedness
methods based on word relatedness, f considers the
whole phrase as a single unit without losing inner
semantic meaning within a phrase.
We submit three runs of TrWP on 5 datasets of
SemEval-2015 task2a (English STS) (Agirre et al.,
2015).
</bodyText>
<subsectionHeader confidence="0.997451">
6.1 Run1
</subsectionHeader>
<bodyText confidence="0.9999815">
In the first run we consider words, phrases and num-
bers as tokens. After removing punctuations and
stop-words, if any sentence within a pair has no to-
kens, then the relatedness of that sentence pair is 0.
</bodyText>
<subsectionHeader confidence="0.999413">
6.2 Run2
</subsectionHeader>
<bodyText confidence="0.99972625">
The tokens are same as in the first run. After remov-
ing punctuations and stop-words, if any sentence
within a pair has no tokens, then we keep the stop-
words.
</bodyText>
<subsectionHeader confidence="0.997313">
6.3 Run3
</subsectionHeader>
<bodyText confidence="0.9999845">
We consider words and phrases as tokens. The fol-
lowing steps are same as in the first run.
</bodyText>
<sectionHeader confidence="0.999677" genericHeader="method">
7 Result
</sectionHeader>
<bodyText confidence="0.955347">
The result from three different runs of TrWP are
shown in Table 2.
</bodyText>
<table confidence="0.993489777777778">
SemEval-2015 task2a Run1 (r) Run2 (r) Run3 (r)
Dataset (English STS)
answers-forums 0.6857 0.6857 0.6857
answers-students 0.6618 0.6618 0.6612
belief 0.6769 0.7245 0.6772
headlines 0.7709 0.7709 0.7710
images 0.7865 0.7865 0.7865
Weighted mean 0.7251 0.7311 0.7250
Ranking out of 73 runs 31 30 32
</table>
<tableCaption confidence="0.9715935">
Table 2: Pearson’s r on five datasets, obtained from
three different runs of TrWP.
</tableCaption>
<sectionHeader confidence="0.997386" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999959375">
TrWP is an unsupervised text relatedness method
that combines both word and phrase relatedness.
Both the word and phrase relatedness are computed
in unsupervised manner. The word relatedness is
computed using the co-occurrences of two words in
the Google 3-gram corpus. To compute phrase re-
latedness, TrWP uses an unsupervised function f
based on the Sum-Ratio technique along with the
</bodyText>
<sectionHeader confidence="0.996016" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99909302173913">
Eneko Agirre, Carmen Banea, Claire Cardie, Daniel
Cer, Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo,
Iigo Lopez-Gazpio, Montse Maritxalar, Rada Mihal-
cea, German Rigau, Larraitz Uria, and Janyce Wiebe.
2015. SemEval-2015 Task 2: Semantic Textual Simi-
larity, English, Spanish and Pilot on Interpretability. In
Proceedings of the 9th International Workshop on Se-
mantic Evaluation (SemEval 2015), Denver, CO, June.
Paolo Annesi, Valerio Storch, and Roberto Basili. 2012.
Space projections as distributional models for seman-
tic composition. In Proceedings of the 13th In-
ternational Conference on Computational Linguistics
and Intelligent Text Processing - Volume Part I, CI-
CLing’12, pages 323–335, Berlin, Heidelberg.
Gerhard Bohm and Gnter Zech. 2010. Introduction to
statistics and data analysis for physicists.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
corpus version 1.1. Linguistic Data Consortium.
Hung Chim and Xiaotie Deng. 2008. Efficient phrase-
based document similarity for clustering. IEEE Trans.
on Knowl. and Data Eng., 20(9):1217–1229, Septem-
ber.
Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The
google similarity distance. IEEE Trans. on Knowl. and
Data Eng., 19(3):370–383, March.
Jorge Gracia, Raquel Trillo, Mauricio Espinoza, and Ed-
uardo Mena. 2006. Querying the web: A multiontol-
ogy disambiguation method. In Proceedings of the 6th
International Conference on Web Engineering, ICWE
’06, pages 241–248, New York, NY, USA.
Lushan Han, Abhay L. Kashyap, Tim Finin,
James Mayfield, and Johnathan Weese. 2013.
UMBC EBIQUITY-CORE: Semantic Textual Sim-
ilarity Systems. In Proceedings of the Second Joint
Conference on Lexical and Computational Semantics,
June.
Matthias Hartung and Anette Frank. 2011. Assessing in-
terpretable, attribute-related meaning representations
for adjective-noun phrases in a similarity prediction
task. In Proceedings of the GEMS 2011 Workshop on
GEometrical Models of Natural Language Semantics,
GEMS ’11, pages 52–61, Stroudsburg, PA, USA.
Chukfong Ho, Masrah Azrifah Azmi Murad, Rabiah Ab-
dul Kadir, and Shyamala C. Doraisamy. 2010. Word
sense disambiguation-based sentence similarity. In
Proceedings of the 23rd International Conference on
</reference>
<page confidence="0.990828">
94
</page>
<reference confidence="0.999931470588235">
Computational Linguistics: Posters, COLING ’10,
pages 418–426, Stroudsburg, PA, USA.
Aminul Islam and Diana Inkpen. 2008. Semantic
text similarity using corpus-based word similarity and
string similarity. ACM Trans. Knowl. Discov. Data,
2(2):10:1–10:25, July.
Aminul Islam, Evangelos Milios, and Vlado Keˇselj.
2012. Text similarity using google tri-grams. In
Proceedings of the 25th Canadian conference on
Advances in Artificial Intelligence, Canadian AI’12,
pages 312–317, Berlin, Heidelberg.
Maria Soledad Pera and Yiu-Kai Ng. 2009. Spamed: A
spam e-mail detection approach based on phrase sim-
ilarity. J. Am. Soc. Inf. Sci. Technol., 60(2):393–409,
February.
Martin Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137, July.
Shailendra Kumar Shrivastava, J. L. Rana, and R. C. Jain.
2013. Article: Text document clustering based on
phrase similarity using affinity propagation. Interna-
tional Journal of Computer Applications, 61(18):38–
44, January. Published by Foundation of Computer
Science, New York, USA.
George Tsatsaronis, Iraklis Varlamis, and Michalis Vazir-
giannis. 2010. Text relatedness based on a word the-
saurus. J. Artif. Int. Res., 37(1):1–40, January.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of semantics.
J. Artif. Int. Res., 37(1):141–188, January.
Oren Zamir and Oren Etzioni. 1999. Grouper: A dy-
namic clustering interface to web search results. In
Proceedings of the Eighth International Conference on
World Wide Web, WWW ’99, pages 1361–1374, New
York, NY, USA.
</reference>
<page confidence="0.99908">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.185499">
<title confidence="0.998894">Text Relatedness using Word and Phrase Relatedness</title>
<author confidence="0.60194">Md Rashadul Hasan Rakib Aminul Islam Evangelos Milios</author>
<affiliation confidence="0.975408">Faculty of Computer Dalhousie University, Canada</affiliation>
<abstract confidence="0.991287588235294">Text is composed of words and phrases. In bag-of-word model, phrases in texts are split into words. This may discard the inner semantics of phrases which in turn may give inconsistent relatedness score between two texts. the unsupervised text relatedness approach combines both word and phrase relatedness. The word relatedness is computed using an existing unsupervised co-occurrence based method. The phrase relatedness is computed using an unsupervised phrase relatedfunction adopts Sum-Ratio technique based on the statistics in the Google ngram corpus of overlapping n-grams associated with the two input phrases. The second of 30th out of 73 runs in</abstract>
<intro confidence="0.315819">SemEval-2015 task2a (English STS).</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Eneko Agirre</author>
<author>Carmen Banea</author>
<author>Claire Cardie</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
</authors>
<title>Aitor Gonzalez-Agirre, Weiwei Guo, Iigo Lopez-Gazpio, Montse Maritxalar, Rada Mihalcea, German Rigau, Larraitz Uria, and Janyce Wiebe.</title>
<date>2015</date>
<booktitle>SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),</booktitle>
<location>Denver, CO,</location>
<contexts>
<context position="15254" citStr="Agirre et al., 2015" startWordPosition="2542" endWordPosition="2545">on, given in Eq. 5. rel.(A, B) = (2|S |+ SAvg) × (2|A |+ 2|B|) 2 · 2|A |· 2|B| (5) Number of words in A, B and S are denoted by |A|, |B|, |S|, respectively. Since we multiply w with relatedness score while constructing the matrix M; |A|,|B |and |S |are multiplied by 2. ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ M= ... ... ⎞ ⎠⎟⎟⎟⎟⎟⎟⎟⎟ 93 6 Experiments statistical pruning. Unlike other phrase relatedness methods based on word relatedness, f considers the whole phrase as a single unit without losing inner semantic meaning within a phrase. We submit three runs of TrWP on 5 datasets of SemEval-2015 task2a (English STS) (Agirre et al., 2015). 6.1 Run1 In the first run we consider words, phrases and numbers as tokens. After removing punctuations and stop-words, if any sentence within a pair has no tokens, then the relatedness of that sentence pair is 0. 6.2 Run2 The tokens are same as in the first run. After removing punctuations and stop-words, if any sentence within a pair has no tokens, then we keep the stopwords. 6.3 Run3 We consider words and phrases as tokens. The following steps are same as in the first run. 7 Result The result from three different runs of TrWP are shown in Table 2. SemEval-2015 task2a Run1 (r) Run2 (r) Run</context>
</contexts>
<marker>Agirre, Banea, Cardie, Cer, Diab, 2015</marker>
<rawString>Eneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, Iigo Lopez-Gazpio, Montse Maritxalar, Rada Mihalcea, German Rigau, Larraitz Uria, and Janyce Wiebe. 2015. SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), Denver, CO, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Annesi</author>
<author>Valerio Storch</author>
<author>Roberto Basili</author>
</authors>
<title>Space projections as distributional models for semantic composition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics and Intelligent Text Processing - Volume Part I, CICLing’12,</booktitle>
<pages>323--335</pages>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="2456" citStr="Annesi et al., 2012" startWordPosition="376" endWordPosition="380">on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrWP considers text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-based resources (Han et al., 2013; Tsatsaronis et al., 2010). These methods split phrases into words without considering the word order that might change the meaning of phrases leading to inconsistent phrase relatedness score (Turney and Pantel, 2010). For example, if we split the phrases “boat house” and “house boat” into words, we get the relatedness score one, nonetheless as a whole unit, these two phrases do not refer to exactly the same meaning (Turney and Pantel, 2010). To preserve the phrase meaning, TrWP uses the phrase</context>
</contexts>
<marker>Annesi, Storch, Basili, 2012</marker>
<rawString>Paolo Annesi, Valerio Storch, and Roberto Basili. 2012. Space projections as distributional models for semantic composition. In Proceedings of the 13th International Conference on Computational Linguistics and Intelligent Text Processing - Volume Part I, CICLing’12, pages 323–335, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Bohm</author>
<author>Gnter Zech</author>
</authors>
<title>Introduction to statistics and data analysis for physicists.</title>
<date>2010</date>
<contexts>
<context position="8715" citStr="Bohm and Zech, 2010" startWordPosition="1405" endWordPosition="1408">resume that if most of the Google n(=3,4)-gram pairs have higher strengths of association, the relatedness score between two phrases tends to be higher and vice versa. However some strengths of association do not lie within the group of maximum number of strengths of association called outliers and because of the outliers the relatedness score between two phrases becomes inconsistent. Hence we apply statistical pruning on the strengths of association to prune the outliers. To find the group of maximum number of strengths of association and prune the outliers, we adopt the Normal Distribution (Bohm and Zech, 2010) for statistical pruning. It has been shown that in Normal Distribution most of the samples exist within the mean ± standard deviation. We divide each Google n(=3,4)-gram count (frequency) within a pair by the count of its corresponding n(=1,2)-gram phrase, resulting a normalized count. For each Google n(=3,4)-gram pair, the minimum and maximum among the two normalized counts are determined. After that we calculate the ratio (e.g., minimum/maximum) between them. Following that, for each Google n(=3,4)-gram pair, we multiply the ratio with the sum of two Google n(=3,4)-gram counts, producing a </context>
</contexts>
<marker>Bohm, Zech, 2010</marker>
<rawString>Gerhard Bohm and Gnter Zech. 2010. Introduction to statistics and data analysis for physicists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram corpus version 1.1. Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="6501" citStr="Brants and Franz, 2006" startWordPosition="1055" endWordPosition="1058">of bi-gram phrases. Step 2: If the length of c-gram is greater than two, we generate an array of bi-grams from the cgram and find the most frequent bi-gram (mfbg) among them; If the frequency of mfbg is greater than ubg + sdbg, then we add mfbg to the list of bi-gram phrases and split the c-gram into two parts (e.g., left, right) by mfbg. After splitting, for each of the left and right parts, we examine the Step 1 and Step 2 recursively. 4 Computing Phrase Relatedness The phrase relatedness function f, computes relatedness strength between two phrases P1 and P2 using the Google n-gram corpus (Brants and Franz, 2006) which is then normalized between 0 and 1 using NGD (Cilibrasi and Vitanyi, 2007) in conjunction with NGD´ (Gracia et al., 2006). 4.1 Lexical Pruning on the Bi-gram Contexts At first the bi-gram contexts of phrases are extracted. However some phrases along with their bi-gram contexts do not convey meaningful insight due to the improper positioning of stop-words within bi-gram contexts. Therefore lexical pruning 4 is performed 3c-gram: A chunk of uni-grams with no stop-word. 4Perform pruning on the bi-gram contexts implies to the pruning of the Google n(=3,4)-grams from which those contexts are</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram corpus version 1.1. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hung Chim</author>
<author>Xiaotie Deng</author>
</authors>
<title>Efficient phrasebased document similarity for clustering.</title>
<date>2008</date>
<journal>IEEE Trans. on Knowl. and Data Eng.,</journal>
<volume>20</volume>
<issue>9</issue>
<contexts>
<context position="1490" citStr="Chim and Deng, 2008" startWordPosition="229" endWordPosition="232"> 30th out of 73 runs in SemEval-2015 task2a (English STS). 1 Introduction Generally, a phrase is an ordered sequence of multiple words that all together refer to a particular meaning (Zamir and Etzioni, 1999). Phrase relatedness quantifies how two phrases relate to each other. It plays an important role in different Text Mining tasks; for instance, document similarity 1, classification and clustering are performed on the documents composed of phrases. Several document clustering methods use phrase similarity to determine the similarity between documents so as to improve the clustering result (Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’. bi-gram and tri-gram phrase similarity between an incoming e-mail message and a previously marked spam to enhance the accuracy of spam detection. Most works on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2</context>
</contexts>
<marker>Chim, Deng, 2008</marker>
<rawString>Hung Chim and Xiaotie Deng. 2008. Efficient phrasebased document similarity for clustering. IEEE Trans. on Knowl. and Data Eng., 20(9):1217–1229, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudi L Cilibrasi</author>
<author>Paul M B Vitanyi</author>
</authors>
<title>The google similarity distance.</title>
<date>2007</date>
<journal>IEEE Trans. on Knowl. and Data Eng.,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="6582" citStr="Cilibrasi and Vitanyi, 2007" startWordPosition="1070" endWordPosition="1073">generate an array of bi-grams from the cgram and find the most frequent bi-gram (mfbg) among them; If the frequency of mfbg is greater than ubg + sdbg, then we add mfbg to the list of bi-gram phrases and split the c-gram into two parts (e.g., left, right) by mfbg. After splitting, for each of the left and right parts, we examine the Step 1 and Step 2 recursively. 4 Computing Phrase Relatedness The phrase relatedness function f, computes relatedness strength between two phrases P1 and P2 using the Google n-gram corpus (Brants and Franz, 2006) which is then normalized between 0 and 1 using NGD (Cilibrasi and Vitanyi, 2007) in conjunction with NGD´ (Gracia et al., 2006). 4.1 Lexical Pruning on the Bi-gram Contexts At first the bi-gram contexts of phrases are extracted. However some phrases along with their bi-gram contexts do not convey meaningful insight due to the improper positioning of stop-words within bi-gram contexts. Therefore lexical pruning 4 is performed 3c-gram: A chunk of uni-grams with no stop-word. 4Perform pruning on the bi-gram contexts implies to the pruning of the Google n(=3,4)-grams from which those contexts are extracted. 91 based on the position of stop-words inside the bigram contexts. Wh</context>
</contexts>
<marker>Cilibrasi, Vitanyi, 2007</marker>
<rawString>Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The google similarity distance. IEEE Trans. on Knowl. and Data Eng., 19(3):370–383, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Gracia</author>
<author>Raquel Trillo</author>
<author>Mauricio Espinoza</author>
<author>Eduardo Mena</author>
</authors>
<title>Querying the web: A multiontology disambiguation method.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th International Conference on Web Engineering, ICWE ’06,</booktitle>
<pages>241--248</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="6629" citStr="Gracia et al., 2006" startWordPosition="1079" endWordPosition="1082">he most frequent bi-gram (mfbg) among them; If the frequency of mfbg is greater than ubg + sdbg, then we add mfbg to the list of bi-gram phrases and split the c-gram into two parts (e.g., left, right) by mfbg. After splitting, for each of the left and right parts, we examine the Step 1 and Step 2 recursively. 4 Computing Phrase Relatedness The phrase relatedness function f, computes relatedness strength between two phrases P1 and P2 using the Google n-gram corpus (Brants and Franz, 2006) which is then normalized between 0 and 1 using NGD (Cilibrasi and Vitanyi, 2007) in conjunction with NGD´ (Gracia et al., 2006). 4.1 Lexical Pruning on the Bi-gram Contexts At first the bi-gram contexts of phrases are extracted. However some phrases along with their bi-gram contexts do not convey meaningful insight due to the improper positioning of stop-words within bi-gram contexts. Therefore lexical pruning 4 is performed 3c-gram: A chunk of uni-grams with no stop-word. 4Perform pruning on the bi-gram contexts implies to the pruning of the Google n(=3,4)-grams from which those contexts are extracted. 91 based on the position of stop-words inside the bigram contexts. When the target phrase is placed at the left or r</context>
</contexts>
<marker>Gracia, Trillo, Espinoza, Mena, 2006</marker>
<rawString>Jorge Gracia, Raquel Trillo, Mauricio Espinoza, and Eduardo Mena. 2006. Querying the web: A multiontology disambiguation method. In Proceedings of the 6th International Conference on Web Engineering, ICWE ’06, pages 241–248, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lushan Han</author>
<author>Abhay L Kashyap</author>
<author>Tim Finin</author>
<author>James Mayfield</author>
<author>Johnathan Weese</author>
</authors>
<title>UMBC EBIQUITY-CORE: Semantic Textual Similarity Systems.</title>
<date>2013</date>
<booktitle>In Proceedings of the Second Joint Conference on Lexical and Computational Semantics,</booktitle>
<contexts>
<context position="2556" citStr="Han et al., 2013" startWordPosition="393" endWordPosition="396">l Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrWP considers text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-based resources (Han et al., 2013; Tsatsaronis et al., 2010). These methods split phrases into words without considering the word order that might change the meaning of phrases leading to inconsistent phrase relatedness score (Turney and Pantel, 2010). For example, if we split the phrases “boat house” and “house boat” into words, we get the relatedness score one, nonetheless as a whole unit, these two phrases do not refer to exactly the same meaning (Turney and Pantel, 2010). To preserve the phrase meaning, TrWP uses the phrase relatedness function f that considers a phrase as a single unit. 2We consider the bi-grams as phras</context>
</contexts>
<marker>Han, Kashyap, Finin, Mayfield, Weese, 2013</marker>
<rawString>Lushan Han, Abhay L. Kashyap, Tim Finin, James Mayfield, and Johnathan Weese. 2013. UMBC EBIQUITY-CORE: Semantic Textual Similarity Systems. In Proceedings of the Second Joint Conference on Lexical and Computational Semantics, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Hartung</author>
<author>Anette Frank</author>
</authors>
<title>Assessing interpretable, attribute-related meaning representations for adjective-noun phrases in a similarity prediction task.</title>
<date>2011</date>
<booktitle>In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, GEMS ’11,</booktitle>
<pages>52--61</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2482" citStr="Hartung and Frank, 2011" startWordPosition="381" endWordPosition="384">an be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrWP considers text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-based resources (Han et al., 2013; Tsatsaronis et al., 2010). These methods split phrases into words without considering the word order that might change the meaning of phrases leading to inconsistent phrase relatedness score (Turney and Pantel, 2010). For example, if we split the phrases “boat house” and “house boat” into words, we get the relatedness score one, nonetheless as a whole unit, these two phrases do not refer to exactly the same meaning (Turney and Pantel, 2010). To preserve the phrase meaning, TrWP uses the phrase relatedness function f th</context>
</contexts>
<marker>Hartung, Frank, 2011</marker>
<rawString>Matthias Hartung and Anette Frank. 2011. Assessing interpretable, attribute-related meaning representations for adjective-noun phrases in a similarity prediction task. In Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics, GEMS ’11, pages 52–61, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chukfong Ho</author>
<author>Masrah Azrifah Azmi Murad</author>
<author>Rabiah Abdul Kadir</author>
<author>Shyamala C Doraisamy</author>
</authors>
<title>Word sense disambiguation-based sentence similarity.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10,</booktitle>
<pages>418--426</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1926" citStr="Ho et al., 2010" startWordPosition="297" endWordPosition="300">osed of phrases. Several document clustering methods use phrase similarity to determine the similarity between documents so as to improve the clustering result (Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’. bi-gram and tri-gram phrase similarity between an incoming e-mail message and a previously marked spam to enhance the accuracy of spam detection. Most works on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrWP considers text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-bas</context>
</contexts>
<marker>Ho, Murad, Kadir, Doraisamy, 2010</marker>
<rawString>Chukfong Ho, Masrah Azrifah Azmi Murad, Rabiah Abdul Kadir, and Shyamala C. Doraisamy. 2010. Word sense disambiguation-based sentence similarity. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10, pages 418–426, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Semantic text similarity using corpus-based word similarity and string similarity.</title>
<date>2008</date>
<journal>ACM Trans. Knowl. Discov. Data,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="2093" citStr="Islam and Inkpen, 2008" startWordPosition="320" endWordPosition="323">Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’. bi-gram and tri-gram phrase similarity between an incoming e-mail message and a previously marked spam to enhance the accuracy of spam detection. Most works on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrWP considers text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-based resources (Han et al., 2013; Tsatsaronis et al., 2010). These methods split phrases into words without considering the word order that might change the meaning of p</context>
</contexts>
<marker>Islam, Inkpen, 2008</marker>
<rawString>Aminul Islam and Diana Inkpen. 2008. Semantic text similarity using corpus-based word similarity and string similarity. ACM Trans. Knowl. Discov. Data, 2(2):10:1–10:25, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Evangelos Milios</author>
<author>Vlado Keˇselj</author>
</authors>
<title>Text similarity using google tri-grams.</title>
<date>2012</date>
<booktitle>In Proceedings of the 25th Canadian conference on Advances in Artificial Intelligence, Canadian AI’12,</booktitle>
<pages>312--317</pages>
<location>Berlin, Heidelberg.</location>
<marker>Islam, Milios, Keˇselj, 2012</marker>
<rawString>Aminul Islam, Evangelos Milios, and Vlado Keˇselj. 2012. Text similarity using google tri-grams. In Proceedings of the 25th Canadian conference on Advances in Artificial Intelligence, Canadian AI’12, pages 312–317, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Soledad Pera</author>
<author>Yiu-Kai Ng</author>
</authors>
<title>Spamed: A spam e-mail detection approach based on phrase similarity.</title>
<date>2009</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>60</volume>
<issue>2</issue>
<contexts>
<context position="1545" citStr="Pera and Ng, 2009" startWordPosition="238" endWordPosition="241">). 1 Introduction Generally, a phrase is an ordered sequence of multiple words that all together refer to a particular meaning (Zamir and Etzioni, 1999). Phrase relatedness quantifies how two phrases relate to each other. It plays an important role in different Text Mining tasks; for instance, document similarity 1, classification and clustering are performed on the documents composed of phrases. Several document clustering methods use phrase similarity to determine the similarity between documents so as to improve the clustering result (Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’. bi-gram and tri-gram phrase similarity between an incoming e-mail message and a previously marked spam to enhance the accuracy of spam detection. Most works on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Tsatsaronis et al., 2010). TrW</context>
</contexts>
<marker>Pera, Ng, 2009</marker>
<rawString>Maria Soledad Pera and Yiu-Kai Ng. 2009. Spamed: A spam e-mail detection approach based on phrase similarity. J. Am. Soc. Inf. Sci. Technol., 60(2):393–409, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="13204" citStr="Porter, 1980" startWordPosition="2141" endWordPosition="2142">t into non stop-words. The relatedness between two texts is calculated by the word-pair and phrase-pair relatedness following the notion of text relatedness in (Islam et al., 2012). Word-pair relatedness is computed by the word relatedness method in (Islam et al., 2012). Step 1: We assume that the two texts A = {a1, a2,..., ap} and B = {b1, b2,..., bq} have p and q tokens, respectively and p ≤ q. Otherwise we switch A and B. A token is a word or bi-gram phrase. Step 2: We count the number of common tokens (S) in both A and B where S ≤ p. Common tokens are determined by applying PorterStemmer (Porter, 1980) on each token pair. Common tokens are removed from A and B. So, A = {a1, a2,..., ap−δ} and B = {b1, b2,..., bq−δ}. If all tokens match e.g., p − S = 0, go to step Step 5. Step 3: We construct a (p − S) × (q − S) ‘semantic relatedness matrix’ (Say, M = (αij)(p−δ)×(q−δ)) using the following process. We set αij ← relatedness(ai, bj) × w2 where i = 1...p − S, j = 1...q − S, w = weighting factor to boost the relatedness score. The value of w is the average number of words within a word or phrase-pair. The reason for boosting is that same relatedness score of a phrasepair is more weighted than that</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shailendra Kumar Shrivastava</author>
<author>J L Rana</author>
<author>R C Jain</author>
</authors>
<title>Article: Text document clustering based on phrase similarity using affinity propagation.</title>
<date>2013</date>
<journal>International Journal of Computer Applications,</journal>
<volume>61</volume>
<issue>18</issue>
<pages>44</pages>
<institution>Foundation of Computer Science,</institution>
<location>New York, USA.</location>
<note>Published by</note>
<contexts>
<context position="1517" citStr="Shrivastava et al., 2013" startWordPosition="233" endWordPosition="236">in SemEval-2015 task2a (English STS). 1 Introduction Generally, a phrase is an ordered sequence of multiple words that all together refer to a particular meaning (Zamir and Etzioni, 1999). Phrase relatedness quantifies how two phrases relate to each other. It plays an important role in different Text Mining tasks; for instance, document similarity 1, classification and clustering are performed on the documents composed of phrases. Several document clustering methods use phrase similarity to determine the similarity between documents so as to improve the clustering result (Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’. bi-gram and tri-gram phrase similarity between an incoming e-mail message and a previously marked spam to enhance the accuracy of spam detection. Most works on text relatedness can be abstracted as a function of word relatedness (Ho et al., 2010). The classical Bag-of-Word (BoW) text relatedness methods split phrases into words; then compute textpair relatedness by word-pair relatedness (Islam and Inkpen, 2008; Islam et al., 2012; Ts</context>
</contexts>
<marker>Shrivastava, Rana, Jain, 2013</marker>
<rawString>Shailendra Kumar Shrivastava, J. L. Rana, and R. C. Jain. 2013. Article: Text document clustering based on phrase similarity using affinity propagation. International Journal of Computer Applications, 61(18):38– 44, January. Published by Foundation of Computer Science, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Tsatsaronis</author>
</authors>
<title>Iraklis Varlamis, and Michalis Vazirgiannis.</title>
<date>2010</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>Tsatsaronis, 2010</marker>
<rawString>George Tsatsaronis, Iraklis Varlamis, and Michalis Vazirgiannis. 2010. Text relatedness based on a word thesaurus. J. Artif. Int. Res., 37(1):1–40, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="2774" citStr="Turney and Pantel, 2010" startWordPosition="428" endWordPosition="431">siders text as Bag-of-Word-andPhrase (BoWP). It considers a (word, bi-gram) or (bi-gram, bi-gram) pair as a phrase-pair 2 and computes text relatedness using both word and phrase relatedness. There are phrase relatedness tasks that use compositional distributional semantic (CDS) model (Annesi et al., 2012; Hartung and Frank, 2011). Some use different tools and knowledge-based resources (Han et al., 2013; Tsatsaronis et al., 2010). These methods split phrases into words without considering the word order that might change the meaning of phrases leading to inconsistent phrase relatedness score (Turney and Pantel, 2010). For example, if we split the phrases “boat house” and “house boat” into words, we get the relatedness score one, nonetheless as a whole unit, these two phrases do not refer to exactly the same meaning (Turney and Pantel, 2010). To preserve the phrase meaning, TrWP uses the phrase relatedness function f that considers a phrase as a single unit. 2We consider the bi-grams as phrases. A word is also considered as a phrase when relatedness is computed between word and bi-gram. 90 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 90–95, Denver, Colorado, Ju</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. J. Artif. Int. Res., 37(1):141–188, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Zamir</author>
<author>Oren Etzioni</author>
</authors>
<title>Grouper: A dynamic clustering interface to web search results.</title>
<date>1999</date>
<booktitle>In Proceedings of the Eighth International Conference on World Wide Web, WWW ’99,</booktitle>
<pages>1361--1374</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="1079" citStr="Zamir and Etzioni, 1999" startWordPosition="165" endWordPosition="168">elatedness approach combines both word and phrase relatedness. The word relatedness is computed using an existing unsupervised co-occurrence based method. The phrase relatedness is computed using an unsupervised phrase relatedness function f that adopts Sum-Ratio technique based on the statistics in the Google ngram corpus of overlapping n-grams associated with the two input phrases. The second run of TrWP ranked 30th out of 73 runs in SemEval-2015 task2a (English STS). 1 Introduction Generally, a phrase is an ordered sequence of multiple words that all together refer to a particular meaning (Zamir and Etzioni, 1999). Phrase relatedness quantifies how two phrases relate to each other. It plays an important role in different Text Mining tasks; for instance, document similarity 1, classification and clustering are performed on the documents composed of phrases. Several document clustering methods use phrase similarity to determine the similarity between documents so as to improve the clustering result (Chim and Deng, 2008; Shrivastava et al., 2013). SpamED (Pera and Ng, 2009) uses the 1We use ‘relatedness’ and ‘similarity’ interchangeably in our paper, albeit ‘similarity’ is a special case of ‘relatedness’.</context>
</contexts>
<marker>Zamir, Etzioni, 1999</marker>
<rawString>Oren Zamir and Oren Etzioni. 1999. Grouper: A dynamic clustering interface to web search results. In Proceedings of the Eighth International Conference on World Wide Web, WWW ’99, pages 1361–1374, New York, NY, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>