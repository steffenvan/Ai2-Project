<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.932958">
Bootstrapping into Filler-Gap: An Acquisition Story
</title>
<author confidence="0.951055">
Marten van Schijndel Micha Elsner
</author>
<affiliation confidence="0.958386">
The Ohio State University
</affiliation>
<email confidence="0.997117">
{vanschm,melsner}@ling.ohio-state.edu
</email>
<sectionHeader confidence="0.995622" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999380782608696">
Analyses of filler-gap dependencies usu-
ally involve complex syntactic rules or
heuristics; however recent results suggest
that filler-gap comprehension begins ear-
lier than seemingly simpler constructions
such as ditransitives or passives. Therefore,
this work models filler-gap acquisition as a
byproduct of learning word orderings (e.g.
SVO vs OSV), which must be done at a
very young age anyway in order to extract
meaning from language. Specifically, this
model, trained on part-of-speech tags, rep-
resents the preferred locations of semantic
roles relative to a verb as Gaussian mix-
tures over real numbers.
This approach learns role assignment in
filler-gap constructions in a manner con-
sistent with current developmental findings
and is extremely robust to initialization
variance. Additionally, this model is shown
to be able to account for a characteristic er-
ror made by learners during this period (A
and B gorped interpreted as A gorped B).
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992657578947368">
The phenomenon of filler-gap, where the argument
of a predicate appears outside its canonical posi-
tion in the phrase structure (e.g. [the apple]i that
the boy ate ti or [what]i did the boy eat ti), has long
been an object of study for syntacticians (Ross,
1967) due to its apparent processing complexity.
Such complexity is due, in part, to the arbitrary
length of the dependency between a filler and its
gap (e.g. [the apple]i that Mary said the boy ate ti).
Recent studies indicate that comprehension of
filler-gap constructions begins around 15 months
(Seidl et al., 2003; Gagliardi et al., 2014). This
finding raises the question of how such a complex
phenomenon could be acquired so early since chil-
dren at that age do not yet have a very advanced
grasp of language (e.g. ditransitives do not seem
to be generalized until at least 31 months; Gold-
berg et al. 2004, Bello 2012). This work shows
that filler-gap comprehension in English may be
</bodyText>
<figureCaption confidence="0.729857">
Figure 1: The developmental timeline of subject
(Wh-S) and object (Wh-O) wh-clause extraction
</figureCaption>
<bodyText confidence="0.9541149375">
comprehension suggested by experimental results
(Seidl et al., 2003; Gagliardi et al., 2014). Paren-
theses indicate weak comprehension. The final row
shows the timeline of 1-1 role bias errors (Naigles,
1990; Gertner and Fisher, 2012). Missing nodes de-
note a lack of studies.
acquired through learning word orderings rather
than relying on hierarchical syntactic knowledge.
This work describes a cognitive model of the de-
velopmental timecourse of filler-gap comprehension
with the goal of setting a lower bound on the mod-
eling assumptions necessary for an ideal learner
to display filler-gap comprehension. In particular,
the model described in this paper takes chunked
child-directed speech as input and learns orderings
over semantic roles. These orderings then permit
the model to successfully resolve filler-gap depen-
dencies.&apos; Further, the model presented here is also
shown to initially reflect an idiosyncratic role as-
signment error observed in development (e.g. A
and B kradded interpreted as A kradded B; Gert-
ner and Fisher, 2012), though after training, the
model is able to avoid the error. As such, this work
may be said to model a learner from 15 months to
between 25 and 30 months.
&apos;This model does not explicitly learn gap positions,
but rather assigns thematic roles to arguments based
on where those arguments are expected to manifest.
This approach to filler-gap comprehension is supported
by findings that show people do not actually link fillers
to gap positions but instead link the filler to a verb
with missing arguments (Pickering and Barry, 1991)
</bodyText>
<figure confidence="0.998005166666666">
Yes
Yes
No
Wh-O
(Yes)
1-1
Age
Wh-S
13mo
No
15mo
Yes
20mo
Yes
25mo
Yes
No
Yes
</figure>
<page confidence="0.969839">
1084
</page>
<note confidence="0.86237">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1084–1093,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.889135" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.987141198275862">
The developmental timeline during which children
acquire the ability to process filler-gap construc-
tions is not well-understood. Language comprehen-
sion precedes production, and the developmental
literature on the acquisition of filler-gap construc-
tions is sparsely populated due to difficulties in de-
signing experiments to test filler-gap comprehen-
sion in preverbal infants. Older studies typically
looked at verbal children and the mistakes they
make to gain insight into the acquisition process
(de Villiers and Roeper, 1995).
Recent studies, however, indicate that filler-
gap comprehension likely begins earlier than pro-
duction (Seidl et al., 2003; Gagliardi and Lidz,
2010; Gagliardi et al., 2014). Therefore, studies
of verbal children are probably actually testing
the acquisition of production mechanisms (plan-
ning, motor skills, greater facility with lexical ac-
cess, etc) rather than the acquisition of filler-
gap. Note that these may be related since filler-
gap could introduce greater processing load which
could overwhelm the child’s fragile production ca-
pacity (Phillips, 2010).
Seidl et al. (2003) showed that children are able
to process wh-extractions from subject position
(e.g. [who]i ti ate pie) as young as 15 months
while similar extractions from object position (e.g.
[what]i did the boy eat ti) remain unparseable until
around 20 months of age.2 This line of investiga-
tion has been reopened and expanded by Gagliardi
et al. (2014) whose results suggest that the ex-
perimental methodology employed by Seidl et al.
(2003) was flawed in that it presumed infants have
ideal performance mechanisms. By providing more
trials of each condition and controlling for the prag-
matic felicity of test statements, Gagliardi et al.
(2014) provide evidence that 15-month old infants
can process wh-extractions from both subject and
object positions. Object extractions are more diffi-
cult to comprehend than subject extractions, how-
ever, perhaps due to additional processing load in
object extractions (Gibson, 1998; Phillips, 2010).
Similarly, Gagliardi and Lidz (2010) show that rel-
ativized extractions with a wh-relativizer (e.g. find
[the boy]i who ti ate the apple) are easier to com-
prehend than relativized extractions with that as
the relativizer (e.g. find [the boy]i that ti ate the
apple).
Yuan et al. (2012) demonstrate that 19-month
olds use their knowledge of nouns to learn both
verbs and their associated argument structure. In
2Since the wh-phrase is in the same (or a very simi-
lar) position as the original subject when the wh-phrase
takes subject position, it is not clear that these con-
structions are true extractions (Culicover, 2013), how-
ever, this paper will continue to refer to them as such
for ease of exposition.
their study, infants were shown video of a person
talking on a phone using a nonce verb with ei-
ther one or two nouns (e.g. Mary kradded Susan).
Under the assumption that infants look longer at
things that correspond to their understanding of
a prompt, the infants were then shown two im-
ages that potentially depicted the described action
– one picture where two actors acted independently
(reflecting an intransitive proposition) and one pic-
ture where one actor acted on the other (reflecting
a transitive proposition).3 Even though the infants
had no extralinguistic knowledge about the verb,
they consistently treated the verb as transitive if
two nouns were present and intransitive if only one
noun was present.
Similarly, Gertner and Fisher (2012) show that
intransitive phrases with conjoined subjects (e.g.
John and Mary gorped) are given a transitive in-
terpretation (i.e. John gorped Mary) at 21 months
(henceforth termed ‘1-1 role bias’), though this ef-
fect is no longer present at 25 months (Naigles,
1990). This finding suggests both that learners
will ignore canonical structure in favor of using
all possible arguments and that children have a
bias to assign a unique semantic role to each argu-
ment. It is important to note, however, that cross-
linguistically children do not seem to generalize be-
yond two arguments until after at least 31 months
of age (Goldberg et al., 2004; Bello, 2012), so a
predicate occurring with three nouns would still
likely be interpreted as merely transitive rather
than ditransitive.
Computational modeling provides a way to test
the computational level of processing (Marr, 1982).
That is, given the input (child-directed speech,
adult-directed speech, and environmental experi-
ences), it is possible to probe the computational
processes that result in the observed output. How-
ever, previous computational models of grammar
induction (Klein and Manning, 2004), including in-
fant grammar induction (Kwiatkowski et al., 2012),
have not addressed filler-gap comprehension.4
The closest work to that presented here is the
work on BabySRL (Connor et al., 2008; Connor et
al., 2009; Connor et al., 2010). BabySRL is a com-
putational model of semantic role acquistion using
a similar set of assumptions to the current work.
BabySRL learns weights over ordering constraints
(e.g. preverbal, second noun, etc.) to acquire se-
mantic role labelling while still exhibiting 1-1 role
bias. However, no analysis has evaluated the abil-
3There were two actors in each image to avoid bias-
ing the infants to look at the image with more actors.
4As one reviewer notes, Joshi et al. (1990) and sub-
sequent work show that filler-gap phenomena can be
formally captured by mildly context-sensitive grammar
formalisms; these have the virtue of scaling up to adult
grammar, but due to their complexity, do not seem to
have been described as models of early acquisition.
</bodyText>
<page confidence="0.99206">
1085
</page>
<bodyText confidence="0.335905">
Susan said John gave girl book
</bodyText>
<equation confidence="0.386644">
-3 -2 -1 0 1 2
</equation>
<tableCaption confidence="0.985477">
Table 1: An example of a chunked sentence (Su-
</tableCaption>
<bodyText confidence="0.925451666666667">
san said John gave the girl a red book) with the
sentence positions labelled. Nominal heads of noun
chunks are in bold.
ity of BabySRL to acquire filler-gap constructions.
Further comparison to BabySRL may be found in
Section 6.
</bodyText>
<sectionHeader confidence="0.994986" genericHeader="method">
3 Assumptions
</sectionHeader>
<bodyText confidence="0.999931727272727">
The present work restricts itself to acquiring filler-
gap comprehension in English. The model pre-
sented here learns a single, non-recursive ordering
for the semantic roles in each sentence relative to
the verb since several studies have suggested that
early child grammars may consist of simple lin-
ear grammars that are dictated by semantic roles
(Diessel and Tomasello, 2001; Jackendoff and Wit-
tenberg, in press). This work assumes learners can
already identify nouns and verbs, which is sup-
ported by Shi et al. (1999) who show that chil-
dren at an extremely young age can distinguish be-
tween content and function words and by Waxman
and Booth (2001) who show that children can dis-
tinguish between different types of content words.
Further, since Waxman and Booth (2001) demon-
strate that, by 14 months, children are able to dis-
tinguish nouns from modifiers, this work assumes
learners can already chunk nouns and access the
nominal head. To handle recursion, this work as-
sumes that children treat the final verb in each
sentence as the main verb (implicitly assuming sen-
tence segmentation), which ideally assigns roles to
each of the nouns in the sentence.
Due to the findings of Yuan et al. (2012),
this work adopts a ‘syntactic bootstrapping’ the-
ory of acquisition (Gleitman, 1990), where struc-
tural properties (e.g. number of nouns) inform the
learner about semantic properties of a predicate
(e.g. how many semantic roles it confers). Since
infants infer the number of semantic roles, this
work further assumes they already have expecta-
tions about where these roles tend to be realized
in sentences, if they appear. These positions may
correspond to different semantic roles for different
predicates (e.g. the subject of run and of melt);
however, the role for predicates with a single argu-
ment is usually assigned to the noun that precedes
the verb while a second argument is usually as-
signed after the verb. The semantic properties of
these roles may be learned lexically for each pred-
icate, but that is beyond the scope of this work.
Therefore, this work uses syntactic and semantic
roles interchangeably (e.g. subject and agent).
</bodyText>
<table confidence="0.996344833333333">
µ Q π
GSC -1 0.5 .999
GSN -1 3 .001
GOC 1 0.5 .999
GON 1 3 .001
Φ .00001
</table>
<tableCaption confidence="0.969422">
Table 2: Initial values for the mean (µ), standard
</tableCaption>
<bodyText confidence="0.983426111111111">
deviation (Q), and prior (π) of each Gaussian as
well as the skip penalty (Φ) used in this paper.
Finally, following the finding by Gertner and
Fisher (2012) that children interpret intransitives
with conjoined subjects as transitives, this work as-
sumes that semantic roles have a one-to-one corre-
spondence with nouns in a sentence (similarly used
as a soft constraint in the semantic role labelling
work of Titov and Klementiev, 2012).
</bodyText>
<sectionHeader confidence="0.995788" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.999943108108108">
The model represents the preferred locations of
semantic roles relative to the verb as distribu-
tions over real numbers. This idea is adapted from
Boersma (1997) who uses it to learn constraint
rankings in optimality theory.
In this work, the final (main) verb is placed at
position 0; words (and chunks) before the verb are
given progressively more negative positions, and
words after the verb are given progressively more
positive positions (see Table 1). Learner expecta-
tions of where an argument will appear relative
to the verb are modelled as two-component Gaus-
sian mixtures: one mixture of Gaussians (GS·) cor-
responds to the subject argument, another (GO·)
corresponds to the object argument. There is no
mixture for a third argument since children do not
generalize beyond two arguments until later in de-
velopment (Goldberg et al., 2004; Bello, 2012).
One component of each mixture learns to repre-
sent the canonical position for the argument (G·C)
while the other (G·N) represents some alternate,
non-canonical position such as the filler position
in filler-gap constructions. To reflect the fact that
learners have had 15 months of exposure to their
language before acquiring filler-gap, the mixture is
initialized so that there is a stronger probability
associated with the canonical Gaussian than with
the non-canonical Gaussian of each mixture.,&apos; Fi-
nally, the one-to-one role bias is explicitly encoded
such that the model cannot use a label that has
already been used elsewhere in the sentence.
&apos;Akhtar (1999) finds that learners may not have
strong expectations of canonical argument positions
until four years of age, but the results of the current
study are extremely robust to changes in initialization,
as discussed in Section 7 of this paper, so this assump-
tion is mostly adopted for ease of exposition.
</bodyText>
<page confidence="0.974618">
1086
</page>
<figure confidence="0.985732666666667">
Probability
Probability
Position relative to verb Position relative to verb
</figure>
<figureCaption confidence="0.715917666666667">
Figure 2: Visual representations of (Left) the initial model’s expectations of where arguments will appear,
given the initial parameters in Table 2 and (Right) the converged model’s expectations of where arguments
will appear.
</figureCaption>
<bodyText confidence="0.999971555555555">
Thus, the initial model conditions (see Figure 2)
are most likely to realize an SVO ordering, al-
though it is possible to obtain SOV (by sampling
a negative number from the blue curve) or even
OSV (by also sampling the red curve very close
to 0). The model is most likely to hypothesize a
preverbal object when it has already assigned the
subject role to something and, in addition, there is
no postverbal noun competing for the object label.
In other words, the model infers that an object ex-
traction may have occurred if there is a ‘missing’
postverbal argument.
Finally, the probability of a given sequence is the
product of the label probabilities for the compo-
nent argument positions (e.g. GSC generating an
argument at position -2, etc). Since many sentences
have more than two nouns, the model is allowed to
skip nouns by multiplying a penalty term (Φ) into
the product for each skipped noun; the cost is set
at 0.00001 for this study, though see Section 7 for a
discussion of the constraints on this parameter. See
Table 2 for initialization parameters and Figure 2
for a visual representation of the initial expecta-
tions of the model.
This work uses a model with 2-component mix-
tures for both subjects and objects (termed the
symmetric model). This formulation achieves the
best fit to the training data according to the
Bayesian Information Criterion (BIC).&apos; However,
follow-up experiments find that the non-canonical
subject Gaussian only improves the likelihood of
the data by erroneously modeling postverbal nouns
in imperative statements. The lack of a canonical
subject in English imperatives allows the model to
improve the likelihood of the data by using the
non-canonical subject Gaussian to capture ficti-
</bodyText>
<footnote confidence="0.788818">
6The BIC rewards improved log-likelihood but pe-
nalizes increased model complexity.
</footnote>
<bodyText confidence="0.999286037037037">
tious postverbal arguments. When imperatives are
filtered out of the training corpus, the symmetric
model obtains a worse BIC fit than a model that
lacks the non-canonical subject Gaussian. There-
fore, if one makes the assumption that impera-
tives are prosodically-marked for learners (e.g. the
learner is the implicit subject), the best model is
one that lacks a non-canonical subject.? The re-
mainder of this paper assumes a symmetric model
to demonstrate what happens if such an assump-
tion is not made; for the evaluations described in
this paper, the results are similar in either case.
This model differs from other non-recursive
computational models of grammar induction (e.g.
Goldwater and Griffiths, 2007) since it is not based
on Hidden Markov Models. Instead, it determines
the best ordering for the sentence as a whole. This
approach bears some similarity to a Generalized
Mallows model (Chen et al., 2009), but the current
formulation was chosen due to being independently
posited as cognitively plausible (Boersma, 1997).
Figure 2 (Right) shows the converged, final state
of the model. The model expects the first argu-
ment (usually agent) to be assigned preverbally
and expects the second (say, patient) to be assigned
postverbally; however, there is now a larger chance
that the second argument will appear preverbally.
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.812127888888889">
The model in this work is trained using transcribed
child-directed speech (CDS) from the BabySRL
portions (Connor et al., 2008) of CHILDES
(MacWhinney, 2000). Chunking is performed us-
7This finding suggests that a Dirichlet Process or
other means of dynamically determining the number
of components in each mixture would converge to a
model that lacks non-canonical subjects if imperative
filtering were employed.
</bodyText>
<page confidence="0.85108">
1087
</page>
<table confidence="0.999910166666667">
Eve (n = 4820) Adam (n = 4461)
P R F P R F
Initial .54 .64 .59 .53 .60 .56
Trained .52 .69 .59* .51 .65 .57*
Initial, .56 .66 .60 .55 .62 .58
Trained, .54 .71 .61* .53 .67 .59*
</table>
<tableCaption confidence="0.983851">
Table 3: Overall accuracy on the Eve and Adam
sections of the BabySRL corpus. Bottom rows re-
flect accuracy when non-agent roles are collapsed
into a single role. Note that improvements are nu-
merically slight since filler-gap is relatively rare
(Schuler, 2011). *p &lt;&lt; .01
</tableCaption>
<table confidence="0.995456">
Subject Extraction filter: S x V ...
Object Extraction filter: O ... V ...
Eve (n = 1345) Adam (n = 1287)
P R F P R F
Initial, .53 .57 .55 .53 .52 .52
Trained, .55 .67 .61* .54 .63 .58*
</table>
<tableCaption confidence="0.981347">
Table 4: (Above) Filters to extract filler-gap con-
</tableCaption>
<bodyText confidence="0.991490714285714">
structions: A) the subject and verb are not ad-
jacent, B) the object precedes the verb. (Below)
Filler-gap accuracy on the Eve and Adam sections
of the BabySRL corpus when non-agent roles are
collapsed into a single role. *p &lt;&lt; .01
ing a basic noun-chunker from NLTK (Bird et al.,
2009). Based on an initial analysis of chunker per-
formance, yes is hand-corrected to not be a noun.
Poor chunker perfomance is likely due to a mis-
match in chunker training and testing domains
(Wall Street Journal text vs transcribed speech),
but chunking noise may be a good estimation of
learner uncertainty, so the remaining text is left
uncorrected. All noun phrase chunks are then re-
placed with their final noun (presumed the head)
to approximate the ability of children to distin-
guish nouns from modifiers (Waxman and Booth,
2001). Finally, for each sentence, the model assigns
sentence positions to each word with the final verb
at zero.
Viterbi Expectation-Maximization is performed
over each sentence in the corpus to infer the pa-
rameters of the model. During the Expectation
step, the model uses the current Gaussian param-
eters to label the nouns in each sentence with ar-
gument roles. Since the model is not lexicalized,
these roles correspond to the semantic roles most
commonly associated with subject and object. The
model then chooses the best label sequence for each
sentence.
These newly labelled sentences are used during
the Maximization step to determine the Gaussian
parameters that maximize the likelihood of that
labelling. The mean of each Gaussian is updated
to the mean position of the words it labels. Sim-
ilarly, the standard deviation of each Gaussian is
updated with the standard deviation of the posi-
tions it labels. A learning rate of 0.3 is used to
prevent large parameter jumps. The prior proba-
bility of each Gaussian is updated as the ratio of
that Gaussian’s labellings to the total number of
labellings from that mixture in the corpus:
</bodyText>
<equation confidence="0.770434">
_ GPe
πPe - |GP |
</equation>
<bodyText confidence="0.999849023809524">
where ρ ∈ {S, O} and θ ∈ {C, N}.
Best results seem to be obtained when the skip-
penalty is loosened by an order of magnitude dur-
ing testing. Essentially, this forces the model to
tightly adhere to the perceived argument struc-
ture during training to learn more rigid parame-
ters, but the model is allowed more leeway to skip
arguments it has less confidence in during testing.
Convergence (see Figure 2) tends to occur after
four iterations but can take up to ten iterations
depending on the initial parameters.
Since the model is unsupervised, it is trained on
a given corpus (e.g. Eve) before being tested on
the role annotations of that same corpus. The Eve
corpus was used for development purposes,8 and
the Adam data was used only for testing.
For testing, this study uses the semantic role
annotations in the BabySRL corpus. These anno-
tations were obtained by automatically semantic
role labelling portions of CHILDES with the sys-
tem of Punyakanok et al. (2008) before roughly
hand-correcting them (Connor et al., 2008). The
BabySRL corpus is annotated with 5 different
roles, but the model described in this paper only
uses 2 roles. Therefore, overall accuracy results (see
Table 3) are presented both for the raw BabySRL
corpus and for a collapsed BabySRL corpus where
all non-agent roles are collapsed into a single role
(denoted by a subscript , in all tables).
Since children do not generalize above two ar-
guments during the modelled age range (Goldberg
et al., 2004; Bello, 2012), the collapsed numbers
more closely reflect the performance of a learner
at this age than the raw numbers. The increase in
accuracy obtained from collapsing non-agent ar-
guments indicates that children may initially gen-
eralize incorrectly to some verbs and would need
to learn lexically-specific role assignments (e.g.
double-object constructions of give). Since the cur-
rent work is interested in general filler-gap com-
prehension at this age, including over unknown
verbs, the remaining analyses in this paper con-
</bodyText>
<footnote confidence="0.9036255">
8This is included for transparency, though the ini-
tial parameters have very little bearing on the final re-
sults as stated in Section 7, so the danger of overfitting
to development data is very slight.
</footnote>
<equation confidence="0.515259">
(1)
</equation>
<page confidence="0.950687">
1088
</page>
<table confidence="0.999748714285714">
P R F P R F
Eve Subj (n = 691) Obj (n = 654)
Initial, .66 .83 .74 .35 .31 .33
Trained, .64 .84 .72† .45 .52 .48*
Adam Subj (n = 886) Obj (n = 1050)
Initial, .69 .81 .74 .33 .27 .30
Trained, .66 .81 .73 .44 .48 .46*
P R F P R F
Eve Wh- (n = 689) That (n = 125)
Initial, .63 .45 .53 .43 .48 .45
Trained, .73 .75 .74* .44 .57 .50†
Adam Wh- (n = 748) That (n = 189)
Initial, .50 .37 .42 .50 .50 .50
Trained, .61 .65 .63* .47 .56 .51†
</table>
<tableCaption confidence="0.958657333333333">
Table 5: (Left) Subject-extraction accuracy and object-extraction accuracy and (Right) Wh-relative ac-
curacy and that-relative accuracy; calculated over the Eve and Adam sections of the BabySRL corpus
with non-agent roles collapsed into a single role. †p = .02 *p &lt;&lt; .01
</tableCaption>
<bodyText confidence="0.994670625">
sider performance when non-agent arguments are
collapsed.9
Next, a filler-gap version of the BabySRL cor-
pus is created using a coarse filtering process: the
new corpus is comprised of all sentences where an
associated object precedes the final verb and all
sentences where the relevant subject is not imme-
diately followed by the final verb (see Table 4). For
these filler-gap evaluations, the model is trained on
the full version of the corpus in question (e.g. Eve)
before being tested on the filler-gap subset of that
corpus. The overall results of the filler-gap evalua-
tion (see Table 4) indicate that the model improves
significantly at parsing filler-gap constructions af-
ter training.
The performance of the model on role-
assignment in filler-gap constructions may be
analyzed further in terms of how the model
performs on subject-extractions compared with
object-extractions and in terms of how the model
performs on that-relatives compared with wh-
relatives (see Table 5).
The model actually performs worse at subject-
extractions after training than before training.
This is unsurprising because, prior to training,
subjects have little-to-no competition for prever-
bal role assignments; after training, there is a pre-
verbal extracted object category, which the model
can erroneously use. This slight, though signifi-
cant in Eve, deficit is counter-balanced by a very
substantial and significant improvement in object-
extraction labelling accuracy.
Similarly, training confers a large and significant
improvement for role assignment in wh-relative
constructions, but it yields less of an improve-
ment for that-relative constructions. This differ-
ence mimics a finding observed in the developmen-
tal literature where children seem slower to ac-
quire comprehension of that-relatives than of wh-
relatives (Gagliardi and Lidz, 2010).
</bodyText>
<footnote confidence="0.9219155">
9Though performance is slightly worse when argu-
ments are not collapsed, all the same patterns emerge.
</footnote>
<sectionHeader confidence="0.918789" genericHeader="method">
6 Comparison to BabySRL
</sectionHeader>
<bodyText confidence="0.99993958974359">
The acquisition of semantic role labelling (SRL) by
the BabySRL model (Connor et al., 2008; Connor
et al., 2009; Connor et al., 2010) bears many sim-
ilarities to the current work and is, to our knowl-
edge, the only comparable line of inquiry to the
current one. The primary function of BabySRL is
to model the acquisition of semantic role labelling
while making an idiosyncratic error which infants
also make (Gertner and Fisher, 2012), the 1-1 role
bias error (John and Mary gorped interpreted as
John gorped Mary). Similar to the model presented
in this paper, BabySRL is based on simple ordering
features such as argument position relative to the
verb and argument position relative to the other
arguments.
This section will demonstrate that the model in
this paper initially reflects 1-1 role bias comparably
to BabySRL, though it progresses beyond this bias
after training.10 Further, the model in this paper is
able to reflect the concurrent acquisition of filler-
gap whereas BabySRL does not seem well-suited
to such a task. Finally, BabySRL performs unde-
sirably in intransitive settings whereas the model
in this paper does not.
Connor et al. (2008) demonstrate that a super-
vised perceptron classifier, based on positional fea-
tures and trained on the silver role label annota-
tions of the BabySRL corpus, manifests 1-1 role
bias errors. Follow-up studies show that supervi-
sion may be lessened (Connor et al., 2009) or re-
moved (Connor et al., 2010) and BabySRL will still
reflect a substantial 1-1 role bias.
Connor et al. (2008) and Connor et al. (2009)
run direct analyses of how frequently their mod-
els make 1-1 role bias errors. A comparable eval-
uation may be run on the current model by
generating 1000 sentences with a structure of
NNV and reporting how many times the model
chooses a subject-first labelling (see Table 6).11
</bodyText>
<footnote confidence="0.99237725">
10All evaluations in this section are preceded by
training on the chunked Eve corpus.
11While Table 6 analyzes erroneous labellings of
NNV structure, the ‘Obj’ column of Table 5 (Left)
</footnote>
<page confidence="0.977554">
1089
</page>
<table confidence="0.998944222222222">
Error rate
Initial .36
Trained .11
Initial (given 2 args) .66
Trained (given 2 args) .13
2008 arg-arg position .65
2008 arg-verb position 0
2009 arg-arg position .82
2009 arg-verb position .63
</table>
<tableCaption confidence="0.946653">
Table 6: 1-1 role bias error in this model compared
</tableCaption>
<bodyText confidence="0.996236972972973">
to the models of Connor et al. (2008) and Connor
et al. (2009). That is, how frequently each model
labelled an NNV sentence SOV. Since the Connor
et al. models are perceptron-based, they require
both arguments be labelled. The model presented
in this paper does not share this restriction, so the
raw error rate for this model is presented in the
first two lines; the error rate once this additional
restriction is imposed is given in the second two
lines.
The results of Connor et al. (2008) and Connor
et al. (2009) depend on whether BabySRL uses
argument-argument relative position as a feature
or argument-verb relative position as a feature
(there is no combined model). Further, the model
presented here from Connor et al. (2009) has a
unique argument constraint, similar to the model
in this paper, in order to make comparison as di-
rect as possible.
The 1-1 role bias error rate (before training) of
the model presented in this paper is comparable
to that of Connor et al. (2008) and Connor et al.
(2009), which shows that the current model pro-
vides comparable developmental modeling benefits
to the BabySRL models. Further, similar to real
children (see Figure 1) the model presented in this
paper develops beyond this error by the end of its
training,12 whereas the BabySRL models still make
this error after training.
Connor et al. (2010) look at how frequently
their model correctly labels the agent in transitive
and intransitive sentences with unknown verbs (to
demonstrate that it exhibits an agent-first bias).
This evaluation can be replicated for the current
study by generating 1,000 sentences with the tran-
sitive form of NVN and a further 1,000 sentences
with the intransitive form of NV (see Table 7).
</bodyText>
<note confidence="0.38659">
Since Connor et al. (2010) investigate the effects
</note>
<footnote confidence="0.930833714285714">
shows model accuracy on NNV structures.
12It is important to note that the unique argument
constraint prevents the current model from actually
getting the correct, conjoined-subject parse, but it no
longer exhibits agent-first bias, an important step for
acquiring passives, which occurs between 3 and 4 years
(Thatcher et al., 2008).
</footnote>
<table confidence="0.999566125">
NVN NV
Sentsin Eve 1173 1513
Sents in Adam 1029 1353
Initial .67 1
Trained .65 .96
Weak (10) lexical .71 .59
Strong (365) lexical .74 .41
Gold Args .77 .58
</table>
<tableCaption confidence="0.996557">
Table 7: Agent-prediction recall accuracy in tran-
</tableCaption>
<bodyText confidence="0.997922565217392">
sitive (NVN) and intransitive (NV) settings of the
model presented in this paper (middle) and the
combined model of Connor et al. (2010) (bottom),
which has features for argument-argument relative
position as well as argument-predicate relative po-
sition and so is closest to the model presented in
this paper.
of different initial lexicons, this evaluation com-
pares against the resulting BabySRL from each ini-
tializer: they initially seed their part-of-speech tag-
ger with either the 10 or 365 most frequent nouns
in the corpus or they dispense with the tagger and
use gold part-of-speech tags.
As with subject extraction, the model in this
paper gets less accurate after training because of
the newly minted extracted object category that
can be mistakenly used in these canonical settings.
While the model of Connor et al. (2010) outper-
forms the model presented here when in a tran-
sitive setting, their model does much worse in an
intransitive setting. The difference in transitive set-
tings stems from increased lexicalization, as is ap-
parent from their results alone; the model pre-
sented here initially performs close to their weakly
lexicalized model, though training impedes agent-
prediction accuracy due to an increased probability
of non-canonical objects.
For the intransitive case, however, whereas the
model presented in this paper is generally able to
successfully label the lone noun as the subject, the
model of Connor et al. (2010) chooses to label lone
nouns as objects about 40% of the time. This likely
stems from their model’s reliance on argument-
argument relative position as a feature; when there
is no additional argument to use for reference, the
model’s accuracy decreases. This is borne out by
their model (not shown in Table 7) that omits
the argument-argument relative position feature
and solely relies on verb-argument position, which
achieves up to 70% accuracy in intransitive set-
tings. Even in that case, however, BabySRL still
chooses to label lone nouns as objects 30% of the
time. The fact that intransitive sentences are more
common than transitive sentences in both the Eve
and Adam sections of the BabySRL corpus sug-
gests that learners should be more likely to assign
</bodyText>
<page confidence="0.983165">
1090
</page>
<bodyText confidence="0.99990675">
correct roles in an intransitive setting, which is not
reflected in the BabySRL results.
The overall reason for the different results be-
tween the current work and BabySRL is that
BabySRL relies on positional features that mea-
sure the relative position of two individual ele-
ments (e.g. where a given noun is relative to the
verb). Since the model in this paper operates over
global orderings, it implicitly takes into account
the positions of other nouns as it models argument
position relative to the verb; object and subject
are in competition as labels for preverbal nouns,
so a preverbal object is usually only assigned once
a subject has already been detected.
Further, while BabySRL consistently reflects 1-
1 role bias (corresponding to a pre 25-month old
learner), it also learns to productively label five
roles, which developmental studies have shown
does not take place until at least 31 months (Gold-
berg et al., 2004; Bello, 2012). Finally, it does not
seem likely that BabySRL could be easily extended
to capture filler-gap acquisition. The argument-
verb position features impede acquisition of filler-
gap by classifying preverbal arguments as agents,
and the argument-argument position features in-
hibit accurate labelling in intransitive settings and
result in an agent-first bias which would tend to
label extracted objects as agents. In fact, these ob-
servations suggest that any linear classifier which
relies on positioning features will have difficulties
modeling filler-gap acquisition.
In sum, the unlexicalized model presented in this
paper is able to achieve greater labelling accuracy
than the lexicalized BabySRL models in intran-
sitive settings, though this model does perform
slightly worse in the less common transitive set-
ting. Further, the unsupervised model in this pa-
per initially reflects developmental 1-1 role bias as
well as the supervised BabySRL models, and it
is able to progress beyond this bias. Finally, un-
like BabySRL, the model presented here provides a
cognitive model of the acquisition of filler-gap com-
prehension, which BabySRL does not seem well-
suited to model.
</bodyText>
<sectionHeader confidence="0.998899" genericHeader="discussions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999991857142857">
This paper has presented a simple cognitive model
of filler-gap acquisition, which is able to capture
several findings from developmental psychology.
Training significantly improves role labelling in
the case of object-extractions, which improves the
overall accuracy of the model. This boost is ac-
companied by a slight decrease in labelling ac-
curacy in subject-extraction settings. The asym-
metric ease of subject versus object comprehen-
sion is well-documented in both children and
adults (Gibson, 1998), and while training improves
the model’s ability to process object-extractions,
there is still a gap between object-extraction and
subject-extraction comprehension even after train-
ing.
Further, the model exhibits better comprehen-
sion of wh-relatives than that-relatives similar to
children (Gagliardi and Lidz, 2010). This could
also be an area where a lexicalized model could
do better. As Gagliardi and Lidz (2010) point
out, whereas wh-relatives such as who or which
always signify a filler-gap construction, that can
occur for many different reasons (demonstrative,
determiner, complementizer, etc) and so is a much
weaker filler-gap cue. A lexical model could poten-
tially pick up on clues which could indicate when
that is a relativizer or simply improve on its com-
prehension of wh-relatives even more.
It is interesting to note that the cuurent model
does not make use of that as a cue at all and
yet is still slower at acquiring that-relatives than
wh-relatives. This fact suggests that the findings
of Gagliardi and Lidz (2010) may be partially ex-
plained by a frequency effect: perhaps the input to
children is simply biased such that wh-relatives are
much more common than that-relatives (as shown
in Table 5).
This model also initially reflects the 1-1 role bias
observed in children (Gertner and Fisher, 2012) as
well as previous models (Connor et al., 2008; Con-
nor et al., 2009; Connor et al., 2010) without sac-
rificing accuracy in canonical intransitive settings.
Finally, this model is extremely robust to differ-
ent initializations. The canonical Gaussian expec-
tations can begin far from the verb (±3) or close
to the verb (±0.1), and the standard deviations
of the distributions and the skip-penalty can vary
widely; the model always converges to give compa-
rable results to those presented here. The only con-
straint on the initial parameters is that the proba-
bility of the extracted object occurring preverbally
must exceed the skip-penalty (i.e. extraction must
be possible). In short, this paper describes a sim-
ple, robust cognitive model of the development of
a learner between 15 months until somewhere be-
tween 25- and 30-months old (since 1-1 role bias is
no longer present but no more than two arguments
are being generalized).
In future, it would be interesting to incorporate
lexicalization into the model presented in this pa-
per, as this feature seems likely to bridge the gap
between this model and BabySRL in transitive set-
tings. Lexicalization should also help further dis-
tinguish modifiers from arguments and improve the
overall accuracy of the model.
It would also be interesting to investigate how
well this model generalizes to languages besides
English. Since the model is able to use the verb
position as a semi-permeable boundary between
canonical subjects and objects, it may not work as
</bodyText>
<page confidence="0.978523">
1091
</page>
<bodyText confidence="0.999913578947369">
well in verb-final languages, and thus makes the
prediction that filler-gap comprehension may be
acquired later in development in such languages
due to a greater reliance on hierarchical syntax.
Ordering is one of the definining characteris-
tics of a language that must be acquired by learn-
ers (e.g. SVO vs SOV), and this work shows that
filler-gap comprehension can be acquired as a by-
product of learning orderings rather than having to
resort to higher-order syntax. Note that this model
cannot capture the constraints on filler-gap usage
which require a hierarchical grammar (e.g. subja-
cency), but such knowledge is really only needed
for successful production of filler-gap construc-
tions, which occurs much later (around 5 years;
de Villiers and Roeper, 1995). Further, the kind of
ordering system proposed in this paper may form
an initial basis for learning such grammars (Jack-
endoff and Wittenberg, in press).
</bodyText>
<sectionHeader confidence="0.998432" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99971625">
Thanks to Peter Culicover, William Schuler, Laura
Wagner, and the attendees of the OSU 2013 Fall
Linguistics Colloquium Fest for feedback on this
work. This work was partially funded by an OSU
Dept. of Linguistics Targeted Investment for Ex-
cellence (TIE) grant for collaborative interdisci-
plinary projects conducted during the academic
year 2012-13.
</bodyText>
<sectionHeader confidence="0.988372" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.778819">
Nameera Akhtar. 1999. Acquiring basic word or-
der: evidence for data-driven learning of syn-
tactic structure. Journal of Child Language,
26:339–356.
Sophia Bello. 2012. Identifying indirect objects
in French: An elicitation task. In Proceedings
of the 2012 annual conference of the Canadian
Linguistic Association.
</bodyText>
<reference confidence="0.994996917808219">
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python:
Analyzing Text with the Natural Language
Toolkit. O’Reilly, Beijing.
Paul Boersma. 1997. How we learn variation, op-
tionality, and probability. Proceedings of the In-
stitute of Phonetic Sciences of the University of
Amsterdam, 21:43–58.
Harr Chen, S.R.K. Branavan, Regina Barzilay, and
David R. Karger. 2009. Content modeling using
latent permutations. Journal of Artificial Intel-
ligence Research, 36:129–163.
Michael Connor, Yael Gertner, Cynthia Fisher, and
Dan Roth. 2008. Baby srl: Modeling early lan-
guage acquisition. In Proceedings of the Twelfth
Conference on Computational Natural Language
Learning.
Michael Connor, Yael Gertner, Cynthia Fisher, and
Dan Roth. 2009. Minimally supervised model of
early language acquisition. In Proceedings of the
Thirteenth Conference on Computational Natu-
ral Language Learning.
Michael Connor, Yael Gertner, Cynthia Fisher, and
Dan Roth. 2010. Starting from scratch in se-
mantic role labelling. In Proceedings of ACL
2010.
Peter Culicover. 2013. Explaining syntax: repre-
sentations, structures, and computation. Oxford
University Press.
Jill de Villiers and Thomas Roeper. 1995. Bar-
riers, binding, and acquisition of the dp-np dis-
tinction. Language Acquisition, 4(1):73–104.
Holger Diessel and Michael Tomasello. 2001. The
acquisition of finite complement clauses in en-
glish: A corpus-based analysis. Cognitive Lin-
guistics, 12:1–45.
Annie Gagliardi and Jeffrey Lidz. 2010. Mor-
phosyntactic cues impact filler-gap dependency
resolution in 20- and 30-month-olds. In Poster
session of BUCLD35.
Annie Gagliardi, Tara M. Mease, and Jeffrey
Lidz. 2014. Discontinuous development
in the acquisition of filler-gap dependen-
cies: Evidence from 15- and 20-month-
olds. Harvard unpublished manuscript:
http://www.people.fas.harvard.edu/∼gagliardi.
Yael Gertner and Cynthia Fisher. 2012. Predicted
errors in children’s early sentence comprehen-
sion. Cognition, 124:85–94.
Edward Gibson. 1998. Linguistic complexity:
Locality of syntactic dependencies. Cognition,
68(1):1–76.
Lila R. Gleitman. 1990. The structural sources of
verb meanings. Language Acquisition, 1:3–55.
Adele E. Goldberg, Devin Casenhiser, and Nitya
Sethuraman. 2004. Learning argument struc-
ture generalizations. Cognitive Linguistics,
14(3):289–316.
Sharon Goldwater and Tom Griffiths. 2007. A
fully Bayesian approach to unsupervised part-
of-speech tagging. In Proceedings of the 45th
Annual Meeting of the Association for Compu-
tational Linguistics.
Ray Jackendoff and Eva Wittenberg. in press.
What you can say without syntax: A hierarchy
of grammatical complexity. In Fritz Newmeyer
and Lauren Preston, editors, Measuring Linguis-
tic Complexity. Oxford University Press.
Aravind K. Joshi, K. Vijay Shanker, and David
Weir. 1990. The convergence of mildly context-
sensitive grammar formalisms. Technical Report
MS-CIS-90-01, Department of Computer and In-
formation Science, University of Pennsylvania.
</reference>
<page confidence="0.850718">
1092
</page>
<reference confidence="0.999481015625">
Dan Klein and Christopher D. Manning. 2004.
Corpus-based induction of syntactic structure:
Models of dependency and constituency. In Pro-
ceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics.
Tom Kwiatkowski, Sharon Goldwater, Luke S.
Zettlemoyer, and Mark Steedman. 2012. A
probabilistic model of syntactic and semantic
acquisition from child-directed utterances and
their meanings. In Proceedings of EACL 2012.
Brian MacWhinney. 2000. The CHILDES project:
Tools for analyzing talk. Lawrence Elrbaum As-
sociates, Mahwah, NJ, third edition.
David Marr. 1982. Vision. A Computational In-
vestigation into the Human Representation and
Processing of Visual Information. W.H. Free-
man and Company.
Letitia R. Naigles. 1990. Children use syntax to
learn verb meanings. The Journal Child Lan-
guage, 17:357–374.
Colin Phillips. 2010. Some arguments and non-
arguments for reductionist accounts of syntactic
phenomena. Language and Cognitive Processes,
28:156–187.
Martin Pickering and Guy Barry. 1991. Sentence
processing without empty categories. Language
and Cognitive Processes, 6(3):229–259.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2008. The importance of syntactic parsing and
inference in semantic role labeling. Computa-
tional Linguistics, 34(2):257–287.
John R. Ross. 1967. Constraints on Variables in
Syntax. Ph.D. thesis, Massachusetts Institute of
Technology.
William Schuler. 2011. Effects of filler-gap de-
pendencies on working memory requirements for
parsing. In Proceedings of COGSCI, pages 501–
506, Austin, TX. Cognitive Science Society.
Amanda Seidl, George Hollich, and Peter W.
Jusczyk. 2003. Early understanding of subject
and object wh-questions. Infancy, 4(3):423–436.
Rushen Shi, Janet F. Werker, and James L. Mor-
gan. 1999. Newborn infants’ sensitivity to per-
ceptual cues to lexical and grammatical words.
Cognition, 72(2):B11–B21.
Katherine Thatcher, Holly Branigan, Janet
McLean, and Antonella Sorace. 2008. Chil-
dren’s early acquisition of the passive: Evidence
from syntactic priming. In Proceedings of the
Child Language Seminar 2007, pages 195–205,
University of Reading.
Ivan Titov and Alexandre Klementiev. 2012.
Crosslingual induction of semantic roles. In Pro-
ceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics (ACL-
2011).
Sandra R. Waxman and Amy E. Booth. 2001. See-
ing pink elephants: Fourteen-month-olds’ inter-
pretations of novel nouns and adjectives. Cogni-
tive Psychology, 43:217–242.
Sylvia Yuan, Cynthia Fisher, and Jesse Snedeker.
2012. Counting the nouns: Simple structural
cues to verb meaning. Child Development,
83(4):1382–1399.
</reference>
<page confidence="0.976203">
1093
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.424352">
<title confidence="0.997989">Bootstrapping into Filler-Gap: An Acquisition Story</title>
<author confidence="0.999977">Marten van_Schijndel Micha Elsner</author>
<affiliation confidence="0.995704">The Ohio State University</affiliation>
<abstract confidence="0.997961043478261">Analyses of filler-gap dependencies usually involve complex syntactic rules or heuristics; however recent results suggest that filler-gap comprehension begins earlier than seemingly simpler constructions such as ditransitives or passives. Therefore, this work models filler-gap acquisition as a byproduct of learning word orderings (e.g. SVO vs OSV), which must be done at a very young age anyway in order to extract meaning from language. Specifically, this model, trained on part-of-speech tags, represents the preferred locations of semantic roles relative to a verb as Gaussian mixtures over real numbers. This approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance. Additionally, this model is shown to be able to account for a characteristic ermade by learners during this period</abstract>
<intro confidence="0.438577">B gorped as gorped</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<title>Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit.</title>
<date>2009</date>
<location>O’Reilly, Beijing.</location>
<contexts>
<context position="19359" citStr="Bird et al., 2009" startWordPosition="3135" endWordPosition="3138">provements are numerically slight since filler-gap is relatively rare (Schuler, 2011). *p &lt;&lt; .01 Subject Extraction filter: S x V ... Object Extraction filter: O ... V ... Eve (n = 1345) Adam (n = 1287) P R F P R F Initial, .53 .57 .55 .53 .52 .52 Trained, .55 .67 .61* .54 .63 .58* Table 4: (Above) Filters to extract filler-gap constructions: A) the subject and verb are not adjacent, B) the object precedes the verb. (Below) Filler-gap accuracy on the Eve and Adam sections of the BabySRL corpus when non-agent roles are collapsed into a single role. *p &lt;&lt; .01 ing a basic noun-chunker from NLTK (Bird et al., 2009). Based on an initial analysis of chunker performance, yes is hand-corrected to not be a noun. Poor chunker perfomance is likely due to a mismatch in chunker training and testing domains (Wall Street Journal text vs transcribed speech), but chunking noise may be a good estimation of learner uncertainty, so the remaining text is left uncorrected. All noun phrase chunks are then replaced with their final noun (presumed the head) to approximate the ability of children to distinguish nouns from modifiers (Waxman and Booth, 2001). Finally, for each sentence, the model assigns sentence positions to </context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit. O’Reilly, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
</authors>
<title>How we learn variation, optionality, and probability.</title>
<date>1997</date>
<booktitle>Proceedings of the Institute of Phonetic Sciences of the University of Amsterdam,</booktitle>
<pages>21--43</pages>
<contexts>
<context position="12853" citStr="Boersma (1997)" startWordPosition="2065" endWordPosition="2066">standard deviation (Q), and prior (π) of each Gaussian as well as the skip penalty (Φ) used in this paper. Finally, following the finding by Gertner and Fisher (2012) that children interpret intransitives with conjoined subjects as transitives, this work assumes that semantic roles have a one-to-one correspondence with nouns in a sentence (similarly used as a soft constraint in the semantic role labelling work of Titov and Klementiev, 2012). 4 Model The model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers. This idea is adapted from Boersma (1997) who uses it to learn constraint rankings in optimality theory. In this work, the final (main) verb is placed at position 0; words (and chunks) before the verb are given progressively more negative positions, and words after the verb are given progressively more positive positions (see Table 1). Learner expectations of where an argument will appear relative to the verb are modelled as two-component Gaussian mixtures: one mixture of Gaussians (GS·) corresponds to the subject argument, another (GO·) corresponds to the object argument. There is no mixture for a third argument since children do no</context>
<context position="17658" citStr="Boersma, 1997" startWordPosition="2836" endWordPosition="2837">sumes a symmetric model to demonstrate what happens if such an assumption is not made; for the evaluations described in this paper, the results are similar in either case. This model differs from other non-recursive computational models of grammar induction (e.g. Goldwater and Griffiths, 2007) since it is not based on Hidden Markov Models. Instead, it determines the best ordering for the sentence as a whole. This approach bears some similarity to a Generalized Mallows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997). Figure 2 (Right) shows the converged, final state of the model. The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will appear preverbally. 5 Evaluation The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000). Chunking is performed us7This finding suggests that a Dirichlet Process or other means of dynamically determining the number of</context>
</contexts>
<marker>Boersma, 1997</marker>
<rawString>Paul Boersma. 1997. How we learn variation, optionality, and probability. Proceedings of the Institute of Phonetic Sciences of the University of Amsterdam, 21:43–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harr Chen</author>
<author>S R K Branavan</author>
<author>Regina Barzilay</author>
<author>David R Karger</author>
</authors>
<title>Content modeling using latent permutations.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>36--129</pages>
<contexts>
<context position="17542" citStr="Chen et al., 2009" startWordPosition="2818" endWordPosition="2821">rner is the implicit subject), the best model is one that lacks a non-canonical subject.? The remainder of this paper assumes a symmetric model to demonstrate what happens if such an assumption is not made; for the evaluations described in this paper, the results are similar in either case. This model differs from other non-recursive computational models of grammar induction (e.g. Goldwater and Griffiths, 2007) since it is not based on Hidden Markov Models. Instead, it determines the best ordering for the sentence as a whole. This approach bears some similarity to a Generalized Mallows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997). Figure 2 (Right) shows the converged, final state of the model. The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will appear preverbally. 5 Evaluation The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000). Chunking is</context>
</contexts>
<marker>Chen, Branavan, Barzilay, Karger, 2009</marker>
<rawString>Harr Chen, S.R.K. Branavan, Regina Barzilay, and David R. Karger. 2009. Content modeling using latent permutations. Journal of Artificial Intelligence Research, 36:129–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Connor</author>
<author>Yael Gertner</author>
<author>Cynthia Fisher</author>
<author>Dan Roth</author>
</authors>
<title>Baby srl: Modeling early language acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="8862" citStr="Connor et al., 2008" startWordPosition="1387" endWordPosition="1390">ed as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avoid biasing the infants to look at the image with more actors. 4As one reviewer notes, Joshi et al. (1990) and subsequent work show that filler-gap phenomena can be formally captured by mildly co</context>
<context position="18099" citStr="Connor et al., 2008" startWordPosition="2904" endWordPosition="2907">e similarity to a Generalized Mallows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997). Figure 2 (Right) shows the converged, final state of the model. The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will appear preverbally. 5 Evaluation The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000). Chunking is performed us7This finding suggests that a Dirichlet Process or other means of dynamically determining the number of components in each mixture would converge to a model that lacks non-canonical subjects if imperative filtering were employed. 1087 Eve (n = 4820) Adam (n = 4461) P R F P R F Initial .54 .64 .59 .53 .60 .56 Trained .52 .69 .59* .51 .65 .57* Initial, .56 .66 .60 .55 .62 .58 Trained, .54 .71 .61* .53 .67 .59* Table 3: Overall accuracy on the Eve and Adam sections of the BabySRL corpus. Bottom rows reflect accuracy when non-agent roles are </context>
<context position="22064" citStr="Connor et al., 2008" startWordPosition="3594" endWordPosition="3597">ends to occur after four iterations but can take up to ten iterations depending on the initial parameters. Since the model is unsupervised, it is trained on a given corpus (e.g. Eve) before being tested on the role annotations of that same corpus. The Eve corpus was used for development purposes,8 and the Adam data was used only for testing. For testing, this study uses the semantic role annotations in the BabySRL corpus. These annotations were obtained by automatically semantic role labelling portions of CHILDES with the system of Punyakanok et al. (2008) before roughly hand-correcting them (Connor et al., 2008). The BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles. Therefore, overall accuracy results (see Table 3) are presented both for the raw BabySRL corpus and for a collapsed BabySRL corpus where all non-agent roles are collapsed into a single role (denoted by a subscript , in all tables). Since children do not generalize above two arguments during the modelled age range (Goldberg et al., 2004; Bello, 2012), the collapsed numbers more closely reflect the performance of a learner at this age than the raw numbers. The increase in accuracy o</context>
<context position="25995" citStr="Connor et al., 2008" startWordPosition="4245" endWordPosition="4248">action labelling accuracy. Similarly, training confers a large and significant improvement for role assignment in wh-relative constructions, but it yields less of an improvement for that-relative constructions. This difference mimics a finding observed in the developmental literature where children seem slower to acquire comprehension of that-relatives than of whrelatives (Gagliardi and Lidz, 2010). 9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge. 6 Comparison to BabySRL The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one. The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mary gorped interpreted as John gorped Mary). Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the</context>
<context position="27437" citStr="Connor et al. (2008)" startWordPosition="4485" endWordPosition="4488">is able to reflect the concurrent acquisition of fillergap whereas BabySRL does not seem well-suited to such a task. Finally, BabySRL performs undesirably in intransitive settings whereas the model in this paper does not. Connor et al. (2008) demonstrate that a supervised perceptron classifier, based on positional features and trained on the silver role label annotations of the BabySRL corpus, manifests 1-1 role bias errors. Follow-up studies show that supervision may be lessened (Connor et al., 2009) or removed (Connor et al., 2010) and BabySRL will still reflect a substantial 1-1 role bias. Connor et al. (2008) and Connor et al. (2009) run direct analyses of how frequently their models make 1-1 role bias errors. A comparable evaluation may be run on the current model by generating 1000 sentences with a structure of NNV and reporting how many times the model chooses a subject-first labelling (see Table 6).11 10All evaluations in this section are preceded by training on the chunked Eve corpus. 11While Table 6 analyzes erroneous labellings of NNV structure, the ‘Obj’ column of Table 5 (Left) 1089 Error rate Initial .36 Trained .11 Initial (given 2 args) .66 Trained (given 2 args) .13 2008 arg-arg posit</context>
<context position="28667" citStr="Connor et al. (2008)" startWordPosition="4698" endWordPosition="4701">08 arg-verb position 0 2009 arg-arg position .82 2009 arg-verb position .63 Table 6: 1-1 role bias error in this model compared to the models of Connor et al. (2008) and Connor et al. (2009). That is, how frequently each model labelled an NNV sentence SOV. Since the Connor et al. models are perceptron-based, they require both arguments be labelled. The model presented in this paper does not share this restriction, so the raw error rate for this model is presented in the first two lines; the error rate once this additional restriction is imposed is given in the second two lines. The results of Connor et al. (2008) and Connor et al. (2009) depend on whether BabySRL uses argument-argument relative position as a feature or argument-verb relative position as a feature (there is no combined model). Further, the model presented here from Connor et al. (2009) has a unique argument constraint, similar to the model in this paper, in order to make comparison as direct as possible. The 1-1 role bias error rate (before training) of the model presented in this paper is comparable to that of Connor et al. (2008) and Connor et al. (2009), which shows that the current model provides comparable developmental modeling b</context>
<context position="36687" citStr="Connor et al., 2008" startWordPosition="5984" endWordPosition="5987">ly improve on its comprehension of wh-relatives even more. It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives. This fact suggests that the findings of Gagliardi and Lidz (2010) may be partially explained by a frequency effect: perhaps the input to children is simply biased such that wh-relatives are much more common than that-relatives (as shown in Table 5). This model also initially reflects the 1-1 role bias observed in children (Gertner and Fisher, 2012) as well as previous models (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) without sacrificing accuracy in canonical intransitive settings. Finally, this model is extremely robust to different initializations. The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here. The only constraint on the initial parameters is that the probability of the extracted object occurring preverbally must exceed the skip-penalty (i.e. extrac</context>
</contexts>
<marker>Connor, Gertner, Fisher, Roth, 2008</marker>
<rawString>Michael Connor, Yael Gertner, Cynthia Fisher, and Dan Roth. 2008. Baby srl: Modeling early language acquisition. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Connor</author>
<author>Yael Gertner</author>
<author>Cynthia Fisher</author>
<author>Dan Roth</author>
</authors>
<title>Minimally supervised model of early language acquisition.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="8883" citStr="Connor et al., 2009" startWordPosition="1391" endWordPosition="1394">ve rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avoid biasing the infants to look at the image with more actors. 4As one reviewer notes, Joshi et al. (1990) and subsequent work show that filler-gap phenomena can be formally captured by mildly context-sensitive gramm</context>
<context position="26016" citStr="Connor et al., 2009" startWordPosition="4249" endWordPosition="4252">racy. Similarly, training confers a large and significant improvement for role assignment in wh-relative constructions, but it yields less of an improvement for that-relative constructions. This difference mimics a finding observed in the developmental literature where children seem slower to acquire comprehension of that-relatives than of whrelatives (Gagliardi and Lidz, 2010). 9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge. 6 Comparison to BabySRL The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one. The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mary gorped interpreted as John gorped Mary). Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments. Thi</context>
<context position="27323" citStr="Connor et al., 2009" startWordPosition="4464" endWordPosition="4467">s comparably to BabySRL, though it progresses beyond this bias after training.10 Further, the model in this paper is able to reflect the concurrent acquisition of fillergap whereas BabySRL does not seem well-suited to such a task. Finally, BabySRL performs undesirably in intransitive settings whereas the model in this paper does not. Connor et al. (2008) demonstrate that a supervised perceptron classifier, based on positional features and trained on the silver role label annotations of the BabySRL corpus, manifests 1-1 role bias errors. Follow-up studies show that supervision may be lessened (Connor et al., 2009) or removed (Connor et al., 2010) and BabySRL will still reflect a substantial 1-1 role bias. Connor et al. (2008) and Connor et al. (2009) run direct analyses of how frequently their models make 1-1 role bias errors. A comparable evaluation may be run on the current model by generating 1000 sentences with a structure of NNV and reporting how many times the model chooses a subject-first labelling (see Table 6).11 10All evaluations in this section are preceded by training on the chunked Eve corpus. 11While Table 6 analyzes erroneous labellings of NNV structure, the ‘Obj’ column of Table 5 (Left</context>
<context position="28692" citStr="Connor et al. (2009)" startWordPosition="4703" endWordPosition="4706">09 arg-arg position .82 2009 arg-verb position .63 Table 6: 1-1 role bias error in this model compared to the models of Connor et al. (2008) and Connor et al. (2009). That is, how frequently each model labelled an NNV sentence SOV. Since the Connor et al. models are perceptron-based, they require both arguments be labelled. The model presented in this paper does not share this restriction, so the raw error rate for this model is presented in the first two lines; the error rate once this additional restriction is imposed is given in the second two lines. The results of Connor et al. (2008) and Connor et al. (2009) depend on whether BabySRL uses argument-argument relative position as a feature or argument-verb relative position as a feature (there is no combined model). Further, the model presented here from Connor et al. (2009) has a unique argument constraint, similar to the model in this paper, in order to make comparison as direct as possible. The 1-1 role bias error rate (before training) of the model presented in this paper is comparable to that of Connor et al. (2008) and Connor et al. (2009), which shows that the current model provides comparable developmental modeling benefits to the BabySRL mo</context>
<context position="36708" citStr="Connor et al., 2009" startWordPosition="5988" endWordPosition="5992">prehension of wh-relatives even more. It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives. This fact suggests that the findings of Gagliardi and Lidz (2010) may be partially explained by a frequency effect: perhaps the input to children is simply biased such that wh-relatives are much more common than that-relatives (as shown in Table 5). This model also initially reflects the 1-1 role bias observed in children (Gertner and Fisher, 2012) as well as previous models (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) without sacrificing accuracy in canonical intransitive settings. Finally, this model is extremely robust to different initializations. The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here. The only constraint on the initial parameters is that the probability of the extracted object occurring preverbally must exceed the skip-penalty (i.e. extraction must be possible</context>
</contexts>
<marker>Connor, Gertner, Fisher, Roth, 2009</marker>
<rawString>Michael Connor, Yael Gertner, Cynthia Fisher, and Dan Roth. 2009. Minimally supervised model of early language acquisition. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Connor</author>
<author>Yael Gertner</author>
<author>Cynthia Fisher</author>
<author>Dan Roth</author>
</authors>
<title>Starting from scratch in semantic role labelling.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="8905" citStr="Connor et al., 2010" startWordPosition="1395" endWordPosition="1398">sitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avoid biasing the infants to look at the image with more actors. 4As one reviewer notes, Joshi et al. (1990) and subsequent work show that filler-gap phenomena can be formally captured by mildly context-sensitive grammar formalisms; these h</context>
<context position="26038" citStr="Connor et al., 2010" startWordPosition="4253" endWordPosition="4256">ning confers a large and significant improvement for role assignment in wh-relative constructions, but it yields less of an improvement for that-relative constructions. This difference mimics a finding observed in the developmental literature where children seem slower to acquire comprehension of that-relatives than of whrelatives (Gagliardi and Lidz, 2010). 9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge. 6 Comparison to BabySRL The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one. The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mary gorped interpreted as John gorped Mary). Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments. This section will demonst</context>
<context position="27356" citStr="Connor et al., 2010" startWordPosition="4471" endWordPosition="4474">t progresses beyond this bias after training.10 Further, the model in this paper is able to reflect the concurrent acquisition of fillergap whereas BabySRL does not seem well-suited to such a task. Finally, BabySRL performs undesirably in intransitive settings whereas the model in this paper does not. Connor et al. (2008) demonstrate that a supervised perceptron classifier, based on positional features and trained on the silver role label annotations of the BabySRL corpus, manifests 1-1 role bias errors. Follow-up studies show that supervision may be lessened (Connor et al., 2009) or removed (Connor et al., 2010) and BabySRL will still reflect a substantial 1-1 role bias. Connor et al. (2008) and Connor et al. (2009) run direct analyses of how frequently their models make 1-1 role bias errors. A comparable evaluation may be run on the current model by generating 1000 sentences with a structure of NNV and reporting how many times the model chooses a subject-first labelling (see Table 6).11 10All evaluations in this section are preceded by training on the chunked Eve corpus. 11While Table 6 analyzes erroneous labellings of NNV structure, the ‘Obj’ column of Table 5 (Left) 1089 Error rate Initial .36 Tra</context>
<context position="29523" citStr="Connor et al. (2010)" startWordPosition="4841" endWordPosition="4844"> (2009) has a unique argument constraint, similar to the model in this paper, in order to make comparison as direct as possible. The 1-1 role bias error rate (before training) of the model presented in this paper is comparable to that of Connor et al. (2008) and Connor et al. (2009), which shows that the current model provides comparable developmental modeling benefits to the BabySRL models. Further, similar to real children (see Figure 1) the model presented in this paper develops beyond this error by the end of its training,12 whereas the BabySRL models still make this error after training. Connor et al. (2010) look at how frequently their model correctly labels the agent in transitive and intransitive sentences with unknown verbs (to demonstrate that it exhibits an agent-first bias). This evaluation can be replicated for the current study by generating 1,000 sentences with the transitive form of NVN and a further 1,000 sentences with the intransitive form of NV (see Table 7). Since Connor et al. (2010) investigate the effects shows model accuracy on NNV structures. 12It is important to note that the unique argument constraint prevents the current model from actually getting the correct, conjoined-s</context>
<context position="31318" citStr="Connor et al. (2010)" startWordPosition="5132" endWordPosition="5135">ell as argument-predicate relative position and so is closest to the model presented in this paper. of different initial lexicons, this evaluation compares against the resulting BabySRL from each initializer: they initially seed their part-of-speech tagger with either the 10 or 365 most frequent nouns in the corpus or they dispense with the tagger and use gold part-of-speech tags. As with subject extraction, the model in this paper gets less accurate after training because of the newly minted extracted object category that can be mistakenly used in these canonical settings. While the model of Connor et al. (2010) outperforms the model presented here when in a transitive setting, their model does much worse in an intransitive setting. The difference in transitive settings stems from increased lexicalization, as is apparent from their results alone; the model presented here initially performs close to their weakly lexicalized model, though training impedes agentprediction accuracy due to an increased probability of non-canonical objects. For the intransitive case, however, whereas the model presented in this paper is generally able to successfully label the lone noun as the subject, the model of Connor </context>
<context position="36730" citStr="Connor et al., 2010" startWordPosition="5993" endWordPosition="5996">tives even more. It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives. This fact suggests that the findings of Gagliardi and Lidz (2010) may be partially explained by a frequency effect: perhaps the input to children is simply biased such that wh-relatives are much more common than that-relatives (as shown in Table 5). This model also initially reflects the 1-1 role bias observed in children (Gertner and Fisher, 2012) as well as previous models (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) without sacrificing accuracy in canonical intransitive settings. Finally, this model is extremely robust to different initializations. The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here. The only constraint on the initial parameters is that the probability of the extracted object occurring preverbally must exceed the skip-penalty (i.e. extraction must be possible). In short, this pape</context>
</contexts>
<marker>Connor, Gertner, Fisher, Roth, 2010</marker>
<rawString>Michael Connor, Yael Gertner, Cynthia Fisher, and Dan Roth. 2010. Starting from scratch in semantic role labelling. In Proceedings of ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Culicover</author>
</authors>
<title>Explaining syntax: representations, structures, and computation.</title>
<date>2013</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6681" citStr="Culicover, 2013" startWordPosition="1041" endWordPosition="1042">larly, Gagliardi and Lidz (2010) show that relativized extractions with a wh-relativizer (e.g. find [the boy]i who ti ate the apple) are easier to comprehend than relativized extractions with that as the relativizer (e.g. find [the boy]i that ti ate the apple). Yuan et al. (2012) demonstrate that 19-month olds use their knowledge of nouns to learn both verbs and their associated argument structure. In 2Since the wh-phrase is in the same (or a very similar) position as the original subject when the wh-phrase takes subject position, it is not clear that these constructions are true extractions (Culicover, 2013), however, this paper will continue to refer to them as such for ease of exposition. their study, infants were shown video of a person talking on a phone using a nonce verb with either one or two nouns (e.g. Mary kradded Susan). Under the assumption that infants look longer at things that correspond to their understanding of a prompt, the infants were then shown two images that potentially depicted the described action – one picture where two actors acted independently (reflecting an intransitive proposition) and one picture where one actor acted on the other (reflecting a transitive propositi</context>
</contexts>
<marker>Culicover, 2013</marker>
<rawString>Peter Culicover. 2013. Explaining syntax: representations, structures, and computation. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill de Villiers</author>
<author>Thomas Roeper</author>
</authors>
<title>Barriers, binding, and acquisition of the dp-np distinction.</title>
<date>1995</date>
<journal>Language Acquisition,</journal>
<volume>4</volume>
<issue>1</issue>
<marker>de Villiers, Roeper, 1995</marker>
<rawString>Jill de Villiers and Thomas Roeper. 1995. Barriers, binding, and acquisition of the dp-np distinction. Language Acquisition, 4(1):73–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Diessel</author>
<author>Michael Tomasello</author>
</authors>
<title>The acquisition of finite complement clauses in english: A corpus-based analysis. Cognitive Linguistics,</title>
<date>2001</date>
<pages>12--1</pages>
<contexts>
<context position="10361" citStr="Diessel and Tomasello, 2001" startWordPosition="1640" endWordPosition="1643">ntence (Susan said John gave the girl a red book) with the sentence positions labelled. Nominal heads of noun chunks are in bold. ity of BabySRL to acquire filler-gap constructions. Further comparison to BabySRL may be found in Section 6. 3 Assumptions The present work restricts itself to acquiring fillergap comprehension in English. The model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles (Diessel and Tomasello, 2001; Jackendoff and Wittenberg, in press). This work assumes learners can already identify nouns and verbs, which is supported by Shi et al. (1999) who show that children at an extremely young age can distinguish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words. Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head. To handle recursion, this work assume</context>
</contexts>
<marker>Diessel, Tomasello, 2001</marker>
<rawString>Holger Diessel and Michael Tomasello. 2001. The acquisition of finite complement clauses in english: A corpus-based analysis. Cognitive Linguistics, 12:1–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Gagliardi</author>
<author>Jeffrey Lidz</author>
</authors>
<title>Morphosyntactic cues impact filler-gap dependency resolution in 20- and 30-month-olds. In Poster session of BUCLD35.</title>
<date>2010</date>
<contexts>
<context position="4701" citStr="Gagliardi and Lidz, 2010" startWordPosition="727" endWordPosition="730">quire the ability to process filler-gap constructions is not well-understood. Language comprehension precedes production, and the developmental literature on the acquisition of filler-gap constructions is sparsely populated due to difficulties in designing experiments to test filler-gap comprehension in preverbal infants. Older studies typically looked at verbal children and the mistakes they make to gain insight into the acquisition process (de Villiers and Roeper, 1995). Recent studies, however, indicate that fillergap comprehension likely begins earlier than production (Seidl et al., 2003; Gagliardi and Lidz, 2010; Gagliardi et al., 2014). Therefore, studies of verbal children are probably actually testing the acquisition of production mechanisms (planning, motor skills, greater facility with lexical access, etc) rather than the acquisition of fillergap. Note that these may be related since fillergap could introduce greater processing load which could overwhelm the child’s fragile production capacity (Phillips, 2010). Seidl et al. (2003) showed that children are able to process wh-extractions from subject position (e.g. [who]i ti ate pie) as young as 15 months while similar extractions from object posi</context>
<context position="6097" citStr="Gagliardi and Lidz (2010)" startWordPosition="941" endWordPosition="944">14) whose results suggest that the experimental methodology employed by Seidl et al. (2003) was flawed in that it presumed infants have ideal performance mechanisms. By providing more trials of each condition and controlling for the pragmatic felicity of test statements, Gagliardi et al. (2014) provide evidence that 15-month old infants can process wh-extractions from both subject and object positions. Object extractions are more difficult to comprehend than subject extractions, however, perhaps due to additional processing load in object extractions (Gibson, 1998; Phillips, 2010). Similarly, Gagliardi and Lidz (2010) show that relativized extractions with a wh-relativizer (e.g. find [the boy]i who ti ate the apple) are easier to comprehend than relativized extractions with that as the relativizer (e.g. find [the boy]i that ti ate the apple). Yuan et al. (2012) demonstrate that 19-month olds use their knowledge of nouns to learn both verbs and their associated argument structure. In 2Since the wh-phrase is in the same (or a very similar) position as the original subject when the wh-phrase takes subject position, it is not clear that these constructions are true extractions (Culicover, 2013), however, this </context>
<context position="25777" citStr="Gagliardi and Lidz, 2010" startWordPosition="4210" endWordPosition="4213">aining, there is a preverbal extracted object category, which the model can erroneously use. This slight, though significant in Eve, deficit is counter-balanced by a very substantial and significant improvement in objectextraction labelling accuracy. Similarly, training confers a large and significant improvement for role assignment in wh-relative constructions, but it yields less of an improvement for that-relative constructions. This difference mimics a finding observed in the developmental literature where children seem slower to acquire comprehension of that-relatives than of whrelatives (Gagliardi and Lidz, 2010). 9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge. 6 Comparison to BabySRL The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one. The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mar</context>
<context position="35635" citStr="Gagliardi and Lidz, 2010" startWordPosition="5807" endWordPosition="5810">g in the case of object-extractions, which improves the overall accuracy of the model. This boost is accompanied by a slight decrease in labelling accuracy in subject-extraction settings. The asymmetric ease of subject versus object comprehension is well-documented in both children and adults (Gibson, 1998), and while training improves the model’s ability to process object-extractions, there is still a gap between object-extraction and subject-extraction comprehension even after training. Further, the model exhibits better comprehension of wh-relatives than that-relatives similar to children (Gagliardi and Lidz, 2010). This could also be an area where a lexicalized model could do better. As Gagliardi and Lidz (2010) point out, whereas wh-relatives such as who or which always signify a filler-gap construction, that can occur for many different reasons (demonstrative, determiner, complementizer, etc) and so is a much weaker filler-gap cue. A lexical model could potentially pick up on clues which could indicate when that is a relativizer or simply improve on its comprehension of wh-relatives even more. It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still </context>
</contexts>
<marker>Gagliardi, Lidz, 2010</marker>
<rawString>Annie Gagliardi and Jeffrey Lidz. 2010. Morphosyntactic cues impact filler-gap dependency resolution in 20- and 30-month-olds. In Poster session of BUCLD35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Gagliardi</author>
<author>Tara M Mease</author>
<author>Jeffrey Lidz</author>
</authors>
<title>Discontinuous development in the acquisition of filler-gap dependencies: Evidence from 15- and 20-montholds.</title>
<date>2014</date>
<note>Harvard unpublished manuscript: http://www.people.fas.harvard.edu/∼gagliardi.</note>
<contexts>
<context position="1722" citStr="Gagliardi et al., 2014" startWordPosition="261" endWordPosition="264">rped B). 1 Introduction The phenomenon of filler-gap, where the argument of a predicate appears outside its canonical position in the phrase structure (e.g. [the apple]i that the boy ate ti or [what]i did the boy eat ti), has long been an object of study for syntacticians (Ross, 1967) due to its apparent processing complexity. Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti). Recent studies indicate that comprehension of filler-gap constructions begins around 15 months (Seidl et al., 2003; Gagliardi et al., 2014). This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012). This work shows that filler-gap comprehension in English may be Figure 1: The developmental timeline of subject (Wh-S) and object (Wh-O) wh-clause extraction comprehension suggested by experimental results (Seidl et al., 2003; Gagliardi et al., 2014). Parentheses indicate weak comprehension. The final row shows the </context>
<context position="4726" citStr="Gagliardi et al., 2014" startWordPosition="731" endWordPosition="734">ss filler-gap constructions is not well-understood. Language comprehension precedes production, and the developmental literature on the acquisition of filler-gap constructions is sparsely populated due to difficulties in designing experiments to test filler-gap comprehension in preverbal infants. Older studies typically looked at verbal children and the mistakes they make to gain insight into the acquisition process (de Villiers and Roeper, 1995). Recent studies, however, indicate that fillergap comprehension likely begins earlier than production (Seidl et al., 2003; Gagliardi and Lidz, 2010; Gagliardi et al., 2014). Therefore, studies of verbal children are probably actually testing the acquisition of production mechanisms (planning, motor skills, greater facility with lexical access, etc) rather than the acquisition of fillergap. Note that these may be related since fillergap could introduce greater processing load which could overwhelm the child’s fragile production capacity (Phillips, 2010). Seidl et al. (2003) showed that children are able to process wh-extractions from subject position (e.g. [who]i ti ate pie) as young as 15 months while similar extractions from object position (e.g. [what]i did th</context>
</contexts>
<marker>Gagliardi, Mease, Lidz, 2014</marker>
<rawString>Annie Gagliardi, Tara M. Mease, and Jeffrey Lidz. 2014. Discontinuous development in the acquisition of filler-gap dependencies: Evidence from 15- and 20-montholds. Harvard unpublished manuscript: http://www.people.fas.harvard.edu/∼gagliardi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Gertner</author>
<author>Cynthia Fisher</author>
</authors>
<title>Predicted errors in children’s early sentence comprehension.</title>
<date>2012</date>
<journal>Cognition,</journal>
<pages>124--85</pages>
<contexts>
<context position="2396" citStr="Gertner and Fisher, 2012" startWordPosition="371" endWordPosition="374">complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012). This work shows that filler-gap comprehension in English may be Figure 1: The developmental timeline of subject (Wh-S) and object (Wh-O) wh-clause extraction comprehension suggested by experimental results (Seidl et al., 2003; Gagliardi et al., 2014). Parentheses indicate weak comprehension. The final row shows the timeline of 1-1 role bias errors (Naigles, 1990; Gertner and Fisher, 2012). Missing nodes denote a lack of studies. acquired through learning word orderings rather than relying on hierarchical syntactic knowledge. This work describes a cognitive model of the developmental timecourse of filler-gap comprehension with the goal of setting a lower bound on the modeling assumptions necessary for an ideal learner to display filler-gap comprehension. In particular, the model described in this paper takes chunked child-directed speech as input and learns orderings over semantic roles. These orderings then permit the model to successfully resolve filler-gap dependencies.&apos; Fur</context>
<context position="7518" citStr="Gertner and Fisher (2012)" startWordPosition="1177" endWordPosition="1180"> kradded Susan). Under the assumption that infants look longer at things that correspond to their understanding of a prompt, the infants were then shown two images that potentially depicted the described action – one picture where two actors acted independently (reflecting an intransitive proposition) and one picture where one actor acted on the other (reflecting a transitive proposition).3 Even though the infants had no extralinguistic knowledge about the verb, they consistently treated the verb as transitive if two nouns were present and intransitive if only one noun was present. Similarly, Gertner and Fisher (2012) show that intransitive phrases with conjoined subjects (e.g. John and Mary gorped) are given a transitive interpretation (i.e. John gorped Mary) at 21 months (henceforth termed ‘1-1 role bias’), though this effect is no longer present at 25 months (Naigles, 1990). This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument. It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 </context>
<context position="12405" citStr="Gertner and Fisher (2012)" startWordPosition="1992" endWordPosition="1995">ment is usually assigned to the noun that precedes the verb while a second argument is usually assigned after the verb. The semantic properties of these roles may be learned lexically for each predicate, but that is beyond the scope of this work. Therefore, this work uses syntactic and semantic roles interchangeably (e.g. subject and agent). µ Q π GSC -1 0.5 .999 GSN -1 3 .001 GOC 1 0.5 .999 GON 1 3 .001 Φ .00001 Table 2: Initial values for the mean (µ), standard deviation (Q), and prior (π) of each Gaussian as well as the skip penalty (Φ) used in this paper. Finally, following the finding by Gertner and Fisher (2012) that children interpret intransitives with conjoined subjects as transitives, this work assumes that semantic roles have a one-to-one correspondence with nouns in a sentence (similarly used as a soft constraint in the semantic role labelling work of Titov and Klementiev, 2012). 4 Model The model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers. This idea is adapted from Boersma (1997) who uses it to learn constraint rankings in optimality theory. In this work, the final (main) verb is placed at position 0; words (and chunks) before t</context>
<context position="26338" citStr="Gertner and Fisher, 2012" startWordPosition="4304" endWordPosition="4307">of that-relatives than of whrelatives (Gagliardi and Lidz, 2010). 9Though performance is slightly worse when arguments are not collapsed, all the same patterns emerge. 6 Comparison to BabySRL The acquisition of semantic role labelling (SRL) by the BabySRL model (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) bears many similarities to the current work and is, to our knowledge, the only comparable line of inquiry to the current one. The primary function of BabySRL is to model the acquisition of semantic role labelling while making an idiosyncratic error which infants also make (Gertner and Fisher, 2012), the 1-1 role bias error (John and Mary gorped interpreted as John gorped Mary). Similar to the model presented in this paper, BabySRL is based on simple ordering features such as argument position relative to the verb and argument position relative to the other arguments. This section will demonstrate that the model in this paper initially reflects 1-1 role bias comparably to BabySRL, though it progresses beyond this bias after training.10 Further, the model in this paper is able to reflect the concurrent acquisition of fillergap whereas BabySRL does not seem well-suited to such a task. Fina</context>
<context position="36639" citStr="Gertner and Fisher, 2012" startWordPosition="5975" endWordPosition="5978">hich could indicate when that is a relativizer or simply improve on its comprehension of wh-relatives even more. It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that-relatives than wh-relatives. This fact suggests that the findings of Gagliardi and Lidz (2010) may be partially explained by a frequency effect: perhaps the input to children is simply biased such that wh-relatives are much more common than that-relatives (as shown in Table 5). This model also initially reflects the 1-1 role bias observed in children (Gertner and Fisher, 2012) as well as previous models (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010) without sacrificing accuracy in canonical intransitive settings. Finally, this model is extremely robust to different initializations. The canonical Gaussian expectations can begin far from the verb (±3) or close to the verb (±0.1), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here. The only constraint on the initial parameters is that the probability of the extracted object occurring preve</context>
</contexts>
<marker>Gertner, Fisher, 2012</marker>
<rawString>Yael Gertner and Cynthia Fisher. 2012. Predicted errors in children’s early sentence comprehension. Cognition, 124:85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
</authors>
<title>Linguistic complexity: Locality of syntactic dependencies.</title>
<date>1998</date>
<journal>Cognition,</journal>
<volume>68</volume>
<issue>1</issue>
<contexts>
<context position="6042" citStr="Gibson, 1998" startWordPosition="936" endWordPosition="937">pened and expanded by Gagliardi et al. (2014) whose results suggest that the experimental methodology employed by Seidl et al. (2003) was flawed in that it presumed infants have ideal performance mechanisms. By providing more trials of each condition and controlling for the pragmatic felicity of test statements, Gagliardi et al. (2014) provide evidence that 15-month old infants can process wh-extractions from both subject and object positions. Object extractions are more difficult to comprehend than subject extractions, however, perhaps due to additional processing load in object extractions (Gibson, 1998; Phillips, 2010). Similarly, Gagliardi and Lidz (2010) show that relativized extractions with a wh-relativizer (e.g. find [the boy]i who ti ate the apple) are easier to comprehend than relativized extractions with that as the relativizer (e.g. find [the boy]i that ti ate the apple). Yuan et al. (2012) demonstrate that 19-month olds use their knowledge of nouns to learn both verbs and their associated argument structure. In 2Since the wh-phrase is in the same (or a very similar) position as the original subject when the wh-phrase takes subject position, it is not clear that these constructions</context>
<context position="35318" citStr="Gibson, 1998" startWordPosition="5767" endWordPosition="5768">of the acquisition of filler-gap comprehension, which BabySRL does not seem wellsuited to model. 7 Discussion This paper has presented a simple cognitive model of filler-gap acquisition, which is able to capture several findings from developmental psychology. Training significantly improves role labelling in the case of object-extractions, which improves the overall accuracy of the model. This boost is accompanied by a slight decrease in labelling accuracy in subject-extraction settings. The asymmetric ease of subject versus object comprehension is well-documented in both children and adults (Gibson, 1998), and while training improves the model’s ability to process object-extractions, there is still a gap between object-extraction and subject-extraction comprehension even after training. Further, the model exhibits better comprehension of wh-relatives than that-relatives similar to children (Gagliardi and Lidz, 2010). This could also be an area where a lexicalized model could do better. As Gagliardi and Lidz (2010) point out, whereas wh-relatives such as who or which always signify a filler-gap construction, that can occur for many different reasons (demonstrative, determiner, complementizer, e</context>
</contexts>
<marker>Gibson, 1998</marker>
<rawString>Edward Gibson. 1998. Linguistic complexity: Locality of syntactic dependencies. Cognition, 68(1):1–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lila R Gleitman</author>
</authors>
<title>The structural sources of verb meanings.</title>
<date>1990</date>
<journal>Language Acquisition,</journal>
<pages>1--3</pages>
<contexts>
<context position="11269" citStr="Gleitman, 1990" startWordPosition="1796" endWordPosition="1797">ldren can distinguish between different types of content words. Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head. To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles to each of the nouns in the sentence. Due to the findings of Yuan et al. (2012), this work adopts a ‘syntactic bootstrapping’ theory of acquisition (Gleitman, 1990), where structural properties (e.g. number of nouns) inform the learner about semantic properties of a predicate (e.g. how many semantic roles it confers). Since infants infer the number of semantic roles, this work further assumes they already have expectations about where these roles tend to be realized in sentences, if they appear. These positions may correspond to different semantic roles for different predicates (e.g. the subject of run and of melt); however, the role for predicates with a single argument is usually assigned to the noun that precedes the verb while a second argument is us</context>
</contexts>
<marker>Gleitman, 1990</marker>
<rawString>Lila R. Gleitman. 1990. The structural sources of verb meanings. Language Acquisition, 1:3–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adele E Goldberg</author>
<author>Devin Casenhiser</author>
<author>Nitya Sethuraman</author>
</authors>
<title>Learning argument structure generalizations.</title>
<date>2004</date>
<journal>Cognitive Linguistics,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="1990" citStr="Goldberg et al. 2004" startWordPosition="310" endWordPosition="314">s (Ross, 1967) due to its apparent processing complexity. Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti). Recent studies indicate that comprehension of filler-gap constructions begins around 15 months (Seidl et al., 2003; Gagliardi et al., 2014). This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012). This work shows that filler-gap comprehension in English may be Figure 1: The developmental timeline of subject (Wh-S) and object (Wh-O) wh-clause extraction comprehension suggested by experimental results (Seidl et al., 2003; Gagliardi et al., 2014). Parentheses indicate weak comprehension. The final row shows the timeline of 1-1 role bias errors (Naigles, 1990; Gertner and Fisher, 2012). Missing nodes denote a lack of studies. acquired through learning word orderings rather than relying on hierarchical syntactic knowledge. This work describes a cognitive model of the developme</context>
<context position="8154" citStr="Goldberg et al., 2004" startWordPosition="1284" endWordPosition="1287">ansitive phrases with conjoined subjects (e.g. John and Mary gorped) are given a transitive interpretation (i.e. John gorped Mary) at 21 months (henceforth termed ‘1-1 role bias’), though this effect is no longer present at 25 months (Naigles, 1990). This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument. It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed fi</context>
<context position="13536" citStr="Goldberg et al., 2004" startWordPosition="2174" endWordPosition="2177">. In this work, the final (main) verb is placed at position 0; words (and chunks) before the verb are given progressively more negative positions, and words after the verb are given progressively more positive positions (see Table 1). Learner expectations of where an argument will appear relative to the verb are modelled as two-component Gaussian mixtures: one mixture of Gaussians (GS·) corresponds to the subject argument, another (GO·) corresponds to the object argument. There is no mixture for a third argument since children do not generalize beyond two arguments until later in development (Goldberg et al., 2004; Bello, 2012). One component of each mixture learns to represent the canonical position for the argument (G·C) while the other (G·N) represents some alternate, non-canonical position such as the filler position in filler-gap constructions. To reflect the fact that learners have had 15 months of exposure to their language before acquiring filler-gap, the mixture is initialized so that there is a stronger probability associated with the canonical Gaussian than with the non-canonical Gaussian of each mixture.,&apos; Finally, the one-to-one role bias is explicitly encoded such that the model cannot us</context>
<context position="22516" citStr="Goldberg et al., 2004" startWordPosition="3671" endWordPosition="3674">tained by automatically semantic role labelling portions of CHILDES with the system of Punyakanok et al. (2008) before roughly hand-correcting them (Connor et al., 2008). The BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles. Therefore, overall accuracy results (see Table 3) are presented both for the raw BabySRL corpus and for a collapsed BabySRL corpus where all non-agent roles are collapsed into a single role (denoted by a subscript , in all tables). Since children do not generalize above two arguments during the modelled age range (Goldberg et al., 2004; Bello, 2012), the collapsed numbers more closely reflect the performance of a learner at this age than the raw numbers. The increase in accuracy obtained from collapsing non-agent arguments indicates that children may initially generalize incorrectly to some verbs and would need to learn lexically-specific role assignments (e.g. double-object constructions of give). Since the current work is interested in general filler-gap comprehension at this age, including over unknown verbs, the remaining analyses in this paper con8This is included for transparency, though the initial parameters have ve</context>
<context position="33623" citStr="Goldberg et al., 2004" startWordPosition="5509" endWordPosition="5513"> relative to the verb). Since the model in this paper operates over global orderings, it implicitly takes into account the positions of other nouns as it models argument position relative to the verb; object and subject are in competition as labels for preverbal nouns, so a preverbal object is usually only assigned once a subject has already been detected. Further, while BabySRL consistently reflects 1- 1 role bias (corresponding to a pre 25-month old learner), it also learns to productively label five roles, which developmental studies have shown does not take place until at least 31 months (Goldberg et al., 2004; Bello, 2012). Finally, it does not seem likely that BabySRL could be easily extended to capture filler-gap acquisition. The argumentverb position features impede acquisition of fillergap by classifying preverbal arguments as agents, and the argument-argument position features inhibit accurate labelling in intransitive settings and result in an agent-first bias which would tend to label extracted objects as agents. In fact, these observations suggest that any linear classifier which relies on positioning features will have difficulties modeling filler-gap acquisition. In sum, the unlexicalize</context>
</contexts>
<marker>Goldberg, Casenhiser, Sethuraman, 2004</marker>
<rawString>Adele E. Goldberg, Devin Casenhiser, and Nitya Sethuraman. 2004. Learning argument structure generalizations. Cognitive Linguistics, 14(3):289–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Tom Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised partof-speech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="17338" citStr="Goldwater and Griffiths, 2007" startWordPosition="2783" endWordPosition="2786">rpus, the symmetric model obtains a worse BIC fit than a model that lacks the non-canonical subject Gaussian. Therefore, if one makes the assumption that imperatives are prosodically-marked for learners (e.g. the learner is the implicit subject), the best model is one that lacks a non-canonical subject.? The remainder of this paper assumes a symmetric model to demonstrate what happens if such an assumption is not made; for the evaluations described in this paper, the results are similar in either case. This model differs from other non-recursive computational models of grammar induction (e.g. Goldwater and Griffiths, 2007) since it is not based on Hidden Markov Models. Instead, it determines the best ordering for the sentence as a whole. This approach bears some similarity to a Generalized Mallows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997). Figure 2 (Right) shows the converged, final state of the model. The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Tom Griffiths. 2007. A fully Bayesian approach to unsupervised partof-speech tagging. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ray Jackendoff</author>
<author>Eva Wittenberg</author>
</authors>
<title>in press. What you can say without syntax: A hierarchy of grammatical complexity.</title>
<booktitle>Measuring Linguistic Complexity.</booktitle>
<editor>In Fritz Newmeyer and Lauren Preston, editors,</editor>
<publisher>Oxford University Press.</publisher>
<marker>Jackendoff, Wittenberg, </marker>
<rawString>Ray Jackendoff and Eva Wittenberg. in press. What you can say without syntax: A hierarchy of grammatical complexity. In Fritz Newmeyer and Lauren Preston, editors, Measuring Linguistic Complexity. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>K Vijay Shanker</author>
<author>David Weir</author>
</authors>
<title>The convergence of mildly contextsensitive grammar formalisms.</title>
<date>1990</date>
<tech>Technical Report MS-CIS-90-01,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="9373" citStr="Joshi et al. (1990)" startWordPosition="1474" endWordPosition="1477">ller-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avoid biasing the infants to look at the image with more actors. 4As one reviewer notes, Joshi et al. (1990) and subsequent work show that filler-gap phenomena can be formally captured by mildly context-sensitive grammar formalisms; these have the virtue of scaling up to adult grammar, but due to their complexity, do not seem to have been described as models of early acquisition. 1085 Susan said John gave girl book -3 -2 -1 0 1 2 Table 1: An example of a chunked sentence (Susan said John gave the girl a red book) with the sentence positions labelled. Nominal heads of noun chunks are in bold. ity of BabySRL to acquire filler-gap constructions. Further comparison to BabySRL may be found in Section 6. </context>
</contexts>
<marker>Joshi, Shanker, Weir, 1990</marker>
<rawString>Aravind K. Joshi, K. Vijay Shanker, and David Weir. 1990. The convergence of mildly contextsensitive grammar formalisms. Technical Report MS-CIS-90-01, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8668" citStr="Klein and Manning, 2004" startWordPosition="1357" endWordPosition="1360">en do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avo</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher D. Manning. 2004. Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Sharon Goldwater</author>
<author>Luke S Zettlemoyer</author>
<author>Mark Steedman</author>
</authors>
<title>A probabilistic model of syntactic and semantic acquisition from child-directed utterances and their meanings.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="8731" citStr="Kwiatkowski et al., 2012" startWordPosition="1366" endWordPosition="1369">at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set of assumptions to the current work. BabySRL learns weights over ordering constraints (e.g. preverbal, second noun, etc.) to acquire semantic role labelling while still exhibiting 1-1 role bias. However, no analysis has evaluated the abil3There were two actors in each image to avoid biasing the infants to look at the image with more actors. 4</context>
</contexts>
<marker>Kwiatkowski, Goldwater, Zettlemoyer, Steedman, 2012</marker>
<rawString>Tom Kwiatkowski, Sharon Goldwater, Luke S. Zettlemoyer, and Mark Steedman. 2012. A probabilistic model of syntactic and semantic acquisition from child-directed utterances and their meanings. In Proceedings of EACL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES project: Tools for analyzing talk. Lawrence Elrbaum Associates, Mahwah, NJ, third edition.</title>
<date>2000</date>
<contexts>
<context position="18129" citStr="MacWhinney, 2000" startWordPosition="2910" endWordPosition="2911">lows model (Chen et al., 2009), but the current formulation was chosen due to being independently posited as cognitively plausible (Boersma, 1997). Figure 2 (Right) shows the converged, final state of the model. The model expects the first argument (usually agent) to be assigned preverbally and expects the second (say, patient) to be assigned postverbally; however, there is now a larger chance that the second argument will appear preverbally. 5 Evaluation The model in this work is trained using transcribed child-directed speech (CDS) from the BabySRL portions (Connor et al., 2008) of CHILDES (MacWhinney, 2000). Chunking is performed us7This finding suggests that a Dirichlet Process or other means of dynamically determining the number of components in each mixture would converge to a model that lacks non-canonical subjects if imperative filtering were employed. 1087 Eve (n = 4820) Adam (n = 4461) P R F P R F Initial .54 .64 .59 .53 .60 .56 Trained .52 .69 .59* .51 .65 .57* Initial, .56 .66 .60 .55 .62 .58 Trained, .54 .71 .61* .53 .67 .59* Table 3: Overall accuracy on the Eve and Adam sections of the BabySRL corpus. Bottom rows reflect accuracy when non-agent roles are collapsed into a single role. </context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. 2000. The CHILDES project: Tools for analyzing talk. Lawrence Elrbaum Associates, Mahwah, NJ, third edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Marr</author>
</authors>
<date>1982</date>
<booktitle>Vision. A Computational Investigation into the Human Representation and Processing of Visual Information. W.H.</booktitle>
<publisher>Freeman and Company.</publisher>
<contexts>
<context position="8389" citStr="Marr, 1982" startWordPosition="1320" endWordPosition="1321">990). This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument. It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr, 1982). That is, given the input (child-directed speech, adult-directed speech, and environmental experiences), it is possible to probe the computational processes that result in the observed output. However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al., 2012), have not addressed filler-gap comprehension.4 The closest work to that presented here is the work on BabySRL (Connor et al., 2008; Connor et al., 2009; Connor et al., 2010). BabySRL is a computational model of semantic role acquistion using a similar set o</context>
</contexts>
<marker>Marr, 1982</marker>
<rawString>David Marr. 1982. Vision. A Computational Investigation into the Human Representation and Processing of Visual Information. W.H. Freeman and Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Letitia R Naigles</author>
</authors>
<title>Children use syntax to learn verb meanings.</title>
<date>1990</date>
<journal>The Journal Child Language,</journal>
<pages>17--357</pages>
<contexts>
<context position="2369" citStr="Naigles, 1990" startWordPosition="369" endWordPosition="370"> of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012). This work shows that filler-gap comprehension in English may be Figure 1: The developmental timeline of subject (Wh-S) and object (Wh-O) wh-clause extraction comprehension suggested by experimental results (Seidl et al., 2003; Gagliardi et al., 2014). Parentheses indicate weak comprehension. The final row shows the timeline of 1-1 role bias errors (Naigles, 1990; Gertner and Fisher, 2012). Missing nodes denote a lack of studies. acquired through learning word orderings rather than relying on hierarchical syntactic knowledge. This work describes a cognitive model of the developmental timecourse of filler-gap comprehension with the goal of setting a lower bound on the modeling assumptions necessary for an ideal learner to display filler-gap comprehension. In particular, the model described in this paper takes chunked child-directed speech as input and learns orderings over semantic roles. These orderings then permit the model to successfully resolve fi</context>
<context position="7782" citStr="Naigles, 1990" startWordPosition="1222" endWordPosition="1223">n intransitive proposition) and one picture where one actor acted on the other (reflecting a transitive proposition).3 Even though the infants had no extralinguistic knowledge about the verb, they consistently treated the verb as transitive if two nouns were present and intransitive if only one noun was present. Similarly, Gertner and Fisher (2012) show that intransitive phrases with conjoined subjects (e.g. John and Mary gorped) are given a transitive interpretation (i.e. John gorped Mary) at 21 months (henceforth termed ‘1-1 role bias’), though this effect is no longer present at 25 months (Naigles, 1990). This finding suggests both that learners will ignore canonical structure in favor of using all possible arguments and that children have a bias to assign a unique semantic role to each argument. It is important to note, however, that crosslinguistically children do not seem to generalize beyond two arguments until after at least 31 months of age (Goldberg et al., 2004; Bello, 2012), so a predicate occurring with three nouns would still likely be interpreted as merely transitive rather than ditransitive. Computational modeling provides a way to test the computational level of processing (Marr</context>
</contexts>
<marker>Naigles, 1990</marker>
<rawString>Letitia R. Naigles. 1990. Children use syntax to learn verb meanings. The Journal Child Language, 17:357–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Phillips</author>
</authors>
<title>Some arguments and nonarguments for reductionist accounts of syntactic phenomena.</title>
<date>2010</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>28--156</pages>
<contexts>
<context position="5112" citStr="Phillips, 2010" startWordPosition="790" endWordPosition="791">o the acquisition process (de Villiers and Roeper, 1995). Recent studies, however, indicate that fillergap comprehension likely begins earlier than production (Seidl et al., 2003; Gagliardi and Lidz, 2010; Gagliardi et al., 2014). Therefore, studies of verbal children are probably actually testing the acquisition of production mechanisms (planning, motor skills, greater facility with lexical access, etc) rather than the acquisition of fillergap. Note that these may be related since fillergap could introduce greater processing load which could overwhelm the child’s fragile production capacity (Phillips, 2010). Seidl et al. (2003) showed that children are able to process wh-extractions from subject position (e.g. [who]i ti ate pie) as young as 15 months while similar extractions from object position (e.g. [what]i did the boy eat ti) remain unparseable until around 20 months of age.2 This line of investigation has been reopened and expanded by Gagliardi et al. (2014) whose results suggest that the experimental methodology employed by Seidl et al. (2003) was flawed in that it presumed infants have ideal performance mechanisms. By providing more trials of each condition and controlling for the pragmat</context>
</contexts>
<marker>Phillips, 2010</marker>
<rawString>Colin Phillips. 2010. Some arguments and nonarguments for reductionist accounts of syntactic phenomena. Language and Cognitive Processes, 28:156–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Pickering</author>
<author>Guy Barry</author>
</authors>
<title>Sentence processing without empty categories.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--3</pages>
<contexts>
<context position="3732" citStr="Pickering and Barry, 1991" startWordPosition="584" endWordPosition="587">ved in development (e.g. A and B kradded interpreted as A kradded B; Gertner and Fisher, 2012), though after training, the model is able to avoid the error. As such, this work may be said to model a learner from 15 months to between 25 and 30 months. &apos;This model does not explicitly learn gap positions, but rather assigns thematic roles to arguments based on where those arguments are expected to manifest. This approach to filler-gap comprehension is supported by findings that show people do not actually link fillers to gap positions but instead link the filler to a verb with missing arguments (Pickering and Barry, 1991) Yes Yes No Wh-O (Yes) 1-1 Age Wh-S 13mo No 15mo Yes 20mo Yes 25mo Yes No Yes 1084 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1084–1093, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Background The developmental timeline during which children acquire the ability to process filler-gap constructions is not well-understood. Language comprehension precedes production, and the developmental literature on the acquisition of filler-gap constructions is sparsely populated due to difficulties in designin</context>
</contexts>
<marker>Pickering, Barry, 1991</marker>
<rawString>Martin Pickering and Guy Barry. 1991. Sentence processing without empty categories. Language and Cognitive Processes, 6(3):229–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The importance of syntactic parsing and inference in semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="22006" citStr="Punyakanok et al. (2008)" startWordPosition="3586" endWordPosition="3589">ess confidence in during testing. Convergence (see Figure 2) tends to occur after four iterations but can take up to ten iterations depending on the initial parameters. Since the model is unsupervised, it is trained on a given corpus (e.g. Eve) before being tested on the role annotations of that same corpus. The Eve corpus was used for development purposes,8 and the Adam data was used only for testing. For testing, this study uses the semantic role annotations in the BabySRL corpus. These annotations were obtained by automatically semantic role labelling portions of CHILDES with the system of Punyakanok et al. (2008) before roughly hand-correcting them (Connor et al., 2008). The BabySRL corpus is annotated with 5 different roles, but the model described in this paper only uses 2 roles. Therefore, overall accuracy results (see Table 3) are presented both for the raw BabySRL corpus and for a collapsed BabySRL corpus where all non-agent roles are collapsed into a single role (denoted by a subscript , in all tables). Since children do not generalize above two arguments during the modelled age range (Goldberg et al., 2004; Bello, 2012), the collapsed numbers more closely reflect the performance of a learner at</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008. The importance of syntactic parsing and inference in semantic role labeling. Computational Linguistics, 34(2):257–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Ross</author>
</authors>
<date>1967</date>
<booktitle>Constraints on Variables in Syntax. Ph.D. thesis,</booktitle>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="1384" citStr="Ross, 1967" startWordPosition="208" endWordPosition="209"> approach learns role assignment in filler-gap constructions in a manner consistent with current developmental findings and is extremely robust to initialization variance. Additionally, this model is shown to be able to account for a characteristic error made by learners during this period (A and B gorped interpreted as A gorped B). 1 Introduction The phenomenon of filler-gap, where the argument of a predicate appears outside its canonical position in the phrase structure (e.g. [the apple]i that the boy ate ti or [what]i did the boy eat ti), has long been an object of study for syntacticians (Ross, 1967) due to its apparent processing complexity. Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti). Recent studies indicate that comprehension of filler-gap constructions begins around 15 months (Seidl et al., 2003; Gagliardi et al., 2014). This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al</context>
</contexts>
<marker>Ross, 1967</marker>
<rawString>John R. Ross. 1967. Constraints on Variables in Syntax. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Schuler</author>
</authors>
<title>Effects of filler-gap dependencies on working memory requirements for parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of COGSCI,</booktitle>
<pages>501--506</pages>
<publisher>Cognitive Science Society.</publisher>
<location>Austin, TX.</location>
<contexts>
<context position="18826" citStr="Schuler, 2011" startWordPosition="3033" endWordPosition="3034">means of dynamically determining the number of components in each mixture would converge to a model that lacks non-canonical subjects if imperative filtering were employed. 1087 Eve (n = 4820) Adam (n = 4461) P R F P R F Initial .54 .64 .59 .53 .60 .56 Trained .52 .69 .59* .51 .65 .57* Initial, .56 .66 .60 .55 .62 .58 Trained, .54 .71 .61* .53 .67 .59* Table 3: Overall accuracy on the Eve and Adam sections of the BabySRL corpus. Bottom rows reflect accuracy when non-agent roles are collapsed into a single role. Note that improvements are numerically slight since filler-gap is relatively rare (Schuler, 2011). *p &lt;&lt; .01 Subject Extraction filter: S x V ... Object Extraction filter: O ... V ... Eve (n = 1345) Adam (n = 1287) P R F P R F Initial, .53 .57 .55 .53 .52 .52 Trained, .55 .67 .61* .54 .63 .58* Table 4: (Above) Filters to extract filler-gap constructions: A) the subject and verb are not adjacent, B) the object precedes the verb. (Below) Filler-gap accuracy on the Eve and Adam sections of the BabySRL corpus when non-agent roles are collapsed into a single role. *p &lt;&lt; .01 ing a basic noun-chunker from NLTK (Bird et al., 2009). Based on an initial analysis of chunker performance, yes is hand-</context>
</contexts>
<marker>Schuler, 2011</marker>
<rawString>William Schuler. 2011. Effects of filler-gap dependencies on working memory requirements for parsing. In Proceedings of COGSCI, pages 501– 506, Austin, TX. Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda Seidl</author>
<author>George Hollich</author>
<author>Peter W Jusczyk</author>
</authors>
<title>Early understanding of subject and object wh-questions.</title>
<date>2003</date>
<journal>Infancy,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="1697" citStr="Seidl et al., 2003" startWordPosition="257" endWordPosition="260"> interpreted as A gorped B). 1 Introduction The phenomenon of filler-gap, where the argument of a predicate appears outside its canonical position in the phrase structure (e.g. [the apple]i that the boy ate ti or [what]i did the boy eat ti), has long been an object of study for syntacticians (Ross, 1967) due to its apparent processing complexity. Such complexity is due, in part, to the arbitrary length of the dependency between a filler and its gap (e.g. [the apple]i that Mary said the boy ate ti). Recent studies indicate that comprehension of filler-gap constructions begins around 15 months (Seidl et al., 2003; Gagliardi et al., 2014). This finding raises the question of how such a complex phenomenon could be acquired so early since children at that age do not yet have a very advanced grasp of language (e.g. ditransitives do not seem to be generalized until at least 31 months; Goldberg et al. 2004, Bello 2012). This work shows that filler-gap comprehension in English may be Figure 1: The developmental timeline of subject (Wh-S) and object (Wh-O) wh-clause extraction comprehension suggested by experimental results (Seidl et al., 2003; Gagliardi et al., 2014). Parentheses indicate weak comprehension.</context>
<context position="4675" citStr="Seidl et al., 2003" startWordPosition="723" endWordPosition="726">ng which children acquire the ability to process filler-gap constructions is not well-understood. Language comprehension precedes production, and the developmental literature on the acquisition of filler-gap constructions is sparsely populated due to difficulties in designing experiments to test filler-gap comprehension in preverbal infants. Older studies typically looked at verbal children and the mistakes they make to gain insight into the acquisition process (de Villiers and Roeper, 1995). Recent studies, however, indicate that fillergap comprehension likely begins earlier than production (Seidl et al., 2003; Gagliardi and Lidz, 2010; Gagliardi et al., 2014). Therefore, studies of verbal children are probably actually testing the acquisition of production mechanisms (planning, motor skills, greater facility with lexical access, etc) rather than the acquisition of fillergap. Note that these may be related since fillergap could introduce greater processing load which could overwhelm the child’s fragile production capacity (Phillips, 2010). Seidl et al. (2003) showed that children are able to process wh-extractions from subject position (e.g. [who]i ti ate pie) as young as 15 months while similar ex</context>
</contexts>
<marker>Seidl, Hollich, Jusczyk, 2003</marker>
<rawString>Amanda Seidl, George Hollich, and Peter W. Jusczyk. 2003. Early understanding of subject and object wh-questions. Infancy, 4(3):423–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rushen Shi</author>
<author>Janet F Werker</author>
<author>James L Morgan</author>
</authors>
<title>Newborn infants’ sensitivity to perceptual cues to lexical and grammatical words.</title>
<date>1999</date>
<journal>Cognition,</journal>
<volume>72</volume>
<issue>2</issue>
<contexts>
<context position="10505" citStr="Shi et al. (1999)" startWordPosition="1665" endWordPosition="1668">e filler-gap constructions. Further comparison to BabySRL may be found in Section 6. 3 Assumptions The present work restricts itself to acquiring fillergap comprehension in English. The model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles (Diessel and Tomasello, 2001; Jackendoff and Wittenberg, in press). This work assumes learners can already identify nouns and verbs, which is supported by Shi et al. (1999) who show that children at an extremely young age can distinguish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words. Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head. To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles </context>
</contexts>
<marker>Shi, Werker, Morgan, 1999</marker>
<rawString>Rushen Shi, Janet F. Werker, and James L. Morgan. 1999. Newborn infants’ sensitivity to perceptual cues to lexical and grammatical words. Cognition, 72(2):B11–B21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Thatcher</author>
<author>Holly Branigan</author>
<author>Janet McLean</author>
<author>Antonella Sorace</author>
</authors>
<title>Children’s early acquisition of the passive: Evidence from syntactic priming.</title>
<date>2008</date>
<booktitle>In Proceedings of the Child Language Seminar</booktitle>
<pages>195--205</pages>
<institution>University of Reading.</institution>
<contexts>
<context position="30281" citStr="Thatcher et al., 2008" startWordPosition="4960" endWordPosition="4963">te that it exhibits an agent-first bias). This evaluation can be replicated for the current study by generating 1,000 sentences with the transitive form of NVN and a further 1,000 sentences with the intransitive form of NV (see Table 7). Since Connor et al. (2010) investigate the effects shows model accuracy on NNV structures. 12It is important to note that the unique argument constraint prevents the current model from actually getting the correct, conjoined-subject parse, but it no longer exhibits agent-first bias, an important step for acquiring passives, which occurs between 3 and 4 years (Thatcher et al., 2008). NVN NV Sentsin Eve 1173 1513 Sents in Adam 1029 1353 Initial .67 1 Trained .65 .96 Weak (10) lexical .71 .59 Strong (365) lexical .74 .41 Gold Args .77 .58 Table 7: Agent-prediction recall accuracy in transitive (NVN) and intransitive (NV) settings of the model presented in this paper (middle) and the combined model of Connor et al. (2010) (bottom), which has features for argument-argument relative position as well as argument-predicate relative position and so is closest to the model presented in this paper. of different initial lexicons, this evaluation compares against the resulting BabyS</context>
</contexts>
<marker>Thatcher, Branigan, McLean, Sorace, 2008</marker>
<rawString>Katherine Thatcher, Holly Branigan, Janet McLean, and Antonella Sorace. 2008. Children’s early acquisition of the passive: Evidence from syntactic priming. In Proceedings of the Child Language Seminar 2007, pages 195–205, University of Reading.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>Crosslingual induction of semantic roles.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL2011).</booktitle>
<contexts>
<context position="12683" citStr="Titov and Klementiev, 2012" startWordPosition="2035" endWordPosition="2038">tactic and semantic roles interchangeably (e.g. subject and agent). µ Q π GSC -1 0.5 .999 GSN -1 3 .001 GOC 1 0.5 .999 GON 1 3 .001 Φ .00001 Table 2: Initial values for the mean (µ), standard deviation (Q), and prior (π) of each Gaussian as well as the skip penalty (Φ) used in this paper. Finally, following the finding by Gertner and Fisher (2012) that children interpret intransitives with conjoined subjects as transitives, this work assumes that semantic roles have a one-to-one correspondence with nouns in a sentence (similarly used as a soft constraint in the semantic role labelling work of Titov and Klementiev, 2012). 4 Model The model represents the preferred locations of semantic roles relative to the verb as distributions over real numbers. This idea is adapted from Boersma (1997) who uses it to learn constraint rankings in optimality theory. In this work, the final (main) verb is placed at position 0; words (and chunks) before the verb are given progressively more negative positions, and words after the verb are given progressively more positive positions (see Table 1). Learner expectations of where an argument will appear relative to the verb are modelled as two-component Gaussian mixtures: one mixtu</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. Crosslingual induction of semantic roles. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra R Waxman</author>
<author>Amy E Booth</author>
</authors>
<title>Seeing pink elephants: Fourteen-month-olds’ interpretations of novel nouns and adjectives. Cognitive Psychology,</title>
<date>2001</date>
<pages>43--217</pages>
<contexts>
<context position="10636" citStr="Waxman and Booth (2001)" startWordPosition="1689" endWordPosition="1692"> itself to acquiring fillergap comprehension in English. The model presented here learns a single, non-recursive ordering for the semantic roles in each sentence relative to the verb since several studies have suggested that early child grammars may consist of simple linear grammars that are dictated by semantic roles (Diessel and Tomasello, 2001; Jackendoff and Wittenberg, in press). This work assumes learners can already identify nouns and verbs, which is supported by Shi et al. (1999) who show that children at an extremely young age can distinguish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words. Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head. To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles to each of the nouns in the sentence. Due to the findings of Yuan et al. (2012), this work adopts a ‘syntactic bootstrapping’ theor</context>
<context position="19889" citStr="Waxman and Booth, 2001" startWordPosition="3224" endWordPosition="3227">ollapsed into a single role. *p &lt;&lt; .01 ing a basic noun-chunker from NLTK (Bird et al., 2009). Based on an initial analysis of chunker performance, yes is hand-corrected to not be a noun. Poor chunker perfomance is likely due to a mismatch in chunker training and testing domains (Wall Street Journal text vs transcribed speech), but chunking noise may be a good estimation of learner uncertainty, so the remaining text is left uncorrected. All noun phrase chunks are then replaced with their final noun (presumed the head) to approximate the ability of children to distinguish nouns from modifiers (Waxman and Booth, 2001). Finally, for each sentence, the model assigns sentence positions to each word with the final verb at zero. Viterbi Expectation-Maximization is performed over each sentence in the corpus to infer the parameters of the model. During the Expectation step, the model uses the current Gaussian parameters to label the nouns in each sentence with argument roles. Since the model is not lexicalized, these roles correspond to the semantic roles most commonly associated with subject and object. The model then chooses the best label sequence for each sentence. These newly labelled sentences are used duri</context>
</contexts>
<marker>Waxman, Booth, 2001</marker>
<rawString>Sandra R. Waxman and Amy E. Booth. 2001. Seeing pink elephants: Fourteen-month-olds’ interpretations of novel nouns and adjectives. Cognitive Psychology, 43:217–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvia Yuan</author>
<author>Cynthia Fisher</author>
<author>Jesse Snedeker</author>
</authors>
<title>Counting the nouns: Simple structural cues to verb meaning.</title>
<date>2012</date>
<journal>Child Development,</journal>
<volume>83</volume>
<issue>4</issue>
<contexts>
<context position="6345" citStr="Yuan et al. (2012)" startWordPosition="984" endWordPosition="987">test statements, Gagliardi et al. (2014) provide evidence that 15-month old infants can process wh-extractions from both subject and object positions. Object extractions are more difficult to comprehend than subject extractions, however, perhaps due to additional processing load in object extractions (Gibson, 1998; Phillips, 2010). Similarly, Gagliardi and Lidz (2010) show that relativized extractions with a wh-relativizer (e.g. find [the boy]i who ti ate the apple) are easier to comprehend than relativized extractions with that as the relativizer (e.g. find [the boy]i that ti ate the apple). Yuan et al. (2012) demonstrate that 19-month olds use their knowledge of nouns to learn both verbs and their associated argument structure. In 2Since the wh-phrase is in the same (or a very similar) position as the original subject when the wh-phrase takes subject position, it is not clear that these constructions are true extractions (Culicover, 2013), however, this paper will continue to refer to them as such for ease of exposition. their study, infants were shown video of a person talking on a phone using a nonce verb with either one or two nouns (e.g. Mary kradded Susan). Under the assumption that infants l</context>
<context position="11184" citStr="Yuan et al. (2012)" startWordPosition="1782" endWordPosition="1785">uish between content and function words and by Waxman and Booth (2001) who show that children can distinguish between different types of content words. Further, since Waxman and Booth (2001) demonstrate that, by 14 months, children are able to distinguish nouns from modifiers, this work assumes learners can already chunk nouns and access the nominal head. To handle recursion, this work assumes that children treat the final verb in each sentence as the main verb (implicitly assuming sentence segmentation), which ideally assigns roles to each of the nouns in the sentence. Due to the findings of Yuan et al. (2012), this work adopts a ‘syntactic bootstrapping’ theory of acquisition (Gleitman, 1990), where structural properties (e.g. number of nouns) inform the learner about semantic properties of a predicate (e.g. how many semantic roles it confers). Since infants infer the number of semantic roles, this work further assumes they already have expectations about where these roles tend to be realized in sentences, if they appear. These positions may correspond to different semantic roles for different predicates (e.g. the subject of run and of melt); however, the role for predicates with a single argument</context>
</contexts>
<marker>Yuan, Fisher, Snedeker, 2012</marker>
<rawString>Sylvia Yuan, Cynthia Fisher, and Jesse Snedeker. 2012. Counting the nouns: Simple structural cues to verb meaning. Child Development, 83(4):1382–1399.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>