<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000057">
<title confidence="0.994007">
DIPPER: Description and Formalisation of an
Information-State Update Dialogue System Architecture
</title>
<author confidence="0.999688">
Johan Bos, Ewan Klein, Oliver Lemon, Tetsushi Oka
</author>
<affiliation confidence="0.99838">
ICCS, School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.6458915">
2 Buccleuch Place, Edinburgh EH8 9LW
Scotland, United Kingdom
</address>
<email confidence="0.998897">
{jbos,ewan,olemon,okat}@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99978476923077">
The DIPPER architecture is a collection
of software agents for prototyping spoken
dialogue systems. Implemented on top
of the Open Agent Architecture (OAA),
it comprises agents for speech input and
output, dialogue management, and fur-
ther supporting agents. We define a for-
mal syntax and semantics for the DIP-
PER information state update language.
The language is independent of particular
programming languages, and incorporates
procedural attachments for access to ex-
ternal resources using OAA.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964075471698">
Spoken dialogue systems are complex frameworks,
involving the integration of speech recognition,
speech synthesis, natural language understanding
and generation, dialogue management, and interac-
tion with domain-specific applications. These com-
ponents might be written in different programming
languages or running on different platforms. Fur-
thermore, with current developments in speech tech-
nology, many components for a dialogue system
can be obtained “off-the-shelf”, particularly those
involving speech recognition and speech synthesis,
and to a lesser extent those for parsing and genera-
tion. The overall behaviour of a dialogue system is
controlled by the dialogue management component,
where interaction between the different components
is managed in a flexible way. Allowing for plug-
and-play and easy adaptation to new domains is a
challenging task for dialogue system architectures.
This paper presents DIPPER, an architecture
tailored for prototyping spoken dialogue systems,
based on the Open Agent Architecture (OAA). Al-
though DIPPER supports many off-the-shelf com-
ponents useful for spoken dialogue systems, it
comes with its own dialogue management compo-
nent, based on the information-state approach to di-
alogue modelling (Traum et al., 1999; Larsson and
Traum, 2000).
The TrindiKit (Larsson et al., 1999; Larsson,
2002) is regarded as the first implementation of the
information-state approach. However impressive it
is, on many occasions the TrindiKit tends to give
the impression of a “Rube Goldberg” machine for
what is a relatively straightforward task: updating
the information state of the dialogue with the help of
declaratively stated update rules. What should be a
transparent operation is often obscured by the com-
plexity of the TrindiKit framework. The dialogue
management component of DIPPER borrows many
of the core ideas of the TrindiKit, but is stripped
down to the essentials, uses a revised update lan-
guage (independent of Prolog), and is more tightly
integrated with OAA. We argue that the resulting
formalism offers several advantages for developing
flexible spoken dialogue systems.
We will first introduce OAA and DIPPER agents
for building spoken dialogue systems, and explain
how dialogue management interfaces with compo-
nents in a flexible way (Section 2). Then we review
the information-state approach to dialogue mod-
elling, introduce the DIPPER update language (Sec-
tion 3), and compare it to the TrindiKit (Section 4).
Finally, we list some practical results obtained using
the DIPPER framework (Section 5).
</bodyText>
<sectionHeader confidence="0.993136" genericHeader="introduction">
2 The DIPPER Environment
</sectionHeader>
<bodyText confidence="0.9998728">
This section gives an overview of DIPPER. First
we introduce the Open Agent Architecture, then we
present the various agents that play a role in spoken
dialogue systems. We focus on the dialogue move
engine in particular.
</bodyText>
<subsectionHeader confidence="0.960638">
2.1 The Open Agent Architecture
</subsectionHeader>
<bodyText confidence="0.99996522">
The Open Agent Architecture, OAA for short, is a
framework for integrating several software agents,
possibly coded in different programming languages
(C/C++, Java, Prolog) and running on different plat-
forms (Unix, Linux, Windows), in a distributed en-
vironment (Martin et al., 1999). Because dialogue
systems are typically built out of a set of indepen-
dent components performing particular tasks (where
in many cases some of them are “out-of-the-box”
packages, such as speech recognition or speech syn-
thesis), the OAA framework forms an ideal medium
to allow easy integration of software agents for di-
alogue systems in a prototyping development envi-
ronment.
The term “agent” within OAA refers to a software
process meeting the conventions of the OAA frame-
work. Basically, this means providing services to
other agents in a particular form, using the Inter-
agent Communication Language (ICL). Within the
community of agents, service requests can be sub-
mitted to the “facilitator”. This is a special agent
with knowledge of available agents and their ca-
pabilities. It mediates all interactions between the
agents involved in submitting and fulfilling a re-
quest.
A prototypical spoken dialogue system built on
top of OAA consists of an agent for speech recog-
nition, an agent for dialogue management, an agent
for speech synthesis, and several supporting agents
for specific tasks such as parsing, semantic interpre-
tation, and generation. A distributed agent architec-
ture allows the implementation of flexible and adapt-
able dialogue systems, where individual agents can
easily be added (or substituted by others) to extend
functionality of the overall system. It also allows
the integration of multi-modal input or output in a
straightforward way.
The current collection of DIPPER agents consists
of the following: (1) agents for input/output modali-
ties, (2) agents for the dialogue move engine, and (3)
supporting agents. We will describe the functional-
ity of the DIPPER agents in the remainder of this
section in terms of the services they provide. We will
use the OAA term “solvable” to describe the services
offered by agents. The solvables of an agent are reg-
istered with the facilitator, and are implemented by
function calls (in C++ and Java) or predicate defi-
nitions (in Prolog) by the agents that provide them.
We will use + and - in front of arguments to indicate
passing or returning values.
</bodyText>
<subsectionHeader confidence="0.962773">
2.2 Input/Output Agents
</subsectionHeader>
<bodyText confidence="0.999488464285714">
DIPPER supports agents for Nuance speech recog-
nition software (www.nuance.com) by providing
wrappers written in C++ or Java. The speech
recognition agent can be used in two different
modes: continuous speech recognition, calling
the solvable apply effects(+Effects) and
thereby updating the information state of the dia-
logue (see Section 3); and in callback mode, where
the solvable recognize(+Grammar,+Time,-
Input) starts recognition using the speech gram-
mar Grammar and returns Input, within a time
specified by Time. The value of Input is deter-
mined by the grammar used as language model for
speech recognition. Callback mode makes it easy to
plug in new grammars during different stages of the
dialogue so as to increase speech recognition perfor-
mance.
On the output side, DIPPER provides
agents for the speech synthesisers Fes-
tival (Taylor et al., 1998) and rVoice
(www.rhetorical.com). The solvables for these
output agents are text2speech(+Text) and
sable2speech(+Sable). The latter can be
used to synthesise strings marked up in SABLE,
an XML schema for text-to-speech (Sproat et al.,
1998). A further agent is available to control Greta,
a three-dimensional talking head (Pasquariello and
Pelachaud, 2001).
</bodyText>
<subsectionHeader confidence="0.998117">
2.3 Dialogue Management Agents
</subsectionHeader>
<bodyText confidence="0.998891704918033">
The dialogue manager forms the heart of a dialogue
system, reading the input modalities, updating the
current state of the dialogue, deciding what to do
next, and generating output. In terms of interac-
tion with other agents, it is the most complex com-
ponent. In fact, the DIPPER dialogue manager is
implemented as two cooperating OAA agents: the
dialogue move engine (DME), and a DME server.
The DME does the real work by dealing
with input from other agents (normally the in-
put modalities, such as speech recognition),
updating its internal state, and calling other
agents (normally the output modalities, such as
speech synthesis). The solvables of the DME
are check conds(+Conditions) and ap-
ply effects(+Effects). The former is used
for other agents to check the current state of the di-
alogue, the latter is used to change the state (for in-
stance by integrating results of speech recognition).
(At this point these services might seem fairly ab-
stract, but they will be made more concrete in Sec-
tion 3.)
The DME server is an agent mediating between
the DME and other agents. It collects requests
submitted by the DME, waits for the results, and
posts these back to the DME. The DME server
enables the DME to manage information-state up-
dates in an asynchronous way. Because the DME
server is implemented as a multi-threaded system, it
is able to cope with multiple requests at the same
time. The solvable that the DME server supports is
dme(+Call,+Effects). On receiving this call,
the DME server posts the solvable Call to the fa-
cilitator, waits for the result, and subsequently re-
turns the results to the DME using its solveable ap-
ply effects(+Effects).
Let’s illustrate this with an example. Suppose
that the dialogue system just asked the user a yes-no
question, and is ready to accept a yes-no answer. It
will need to tell the speech recognition agent to load
the grammar for yes/no-answers and return a result
(say, within 7 seconds) at the isinput field of the
dialogue state (see Section 3 for more details). This
is done by posting the solvable:
dme(recognize(’.YesNo’,7,X),
[set(isinput,X)I)
To summarise the functionality of the DME,
there are three ways it is able to communi-
cate with other agents in a dialogue system:
(1) agents can call the DME agent directly, us-
ing check conds(+Conditions) and ap-
ply effects(+Effects); (2) the DME agent
can call other agents directly, in particular if it is
not interested in the results of those requests; (3) the
DME agent can use the DME server as a mediating
agent, normally when the results are needed for up-
dating the information state of the DME.
The advantage of this architecture is the flexibil-
ity imposed by it, while at the same time allow-
ing asynchronous interaction of the input/output and
supporting agents with the dialogue move engine.
</bodyText>
<subsectionHeader confidence="0.998795">
2.4 Supporting Agents
</subsectionHeader>
<bodyText confidence="0.9999802">
OAA itself comes with agents for parsing and gen-
erating based on the Gemini system (Dowding et
al., 1993). DIPPER provides a further set of agents
to deal with natural language understanding, based
on Discourse Representation Theory (Kamp and
Reyle, 1993). There is an ambiguity resolution
agent that resolves underspecified DRSs into fully
resolved DRSs, and there is an inference agent that
checks consistency of DRSs, using standard first-
order theorem proving techniques, including the the-
orem prover SPASS (Weidenbach et al., 1999) and
the model builder MACE (McCune, 1998). DIPPER
also includes a high-level dialogue planning compo-
nent using O-Plan (Currie and Tate, 1991) which can
be used to build domain-specific content plans.
</bodyText>
<sectionHeader confidence="0.969092" genericHeader="method">
3 The Information-state Approach
</sectionHeader>
<bodyText confidence="0.999866">
In this section we will briefly review the
information-state approach and then introduce
a revised version of the TrindiKit’s dialogue move
engine (Traum et al., 1999), including a new update
language for information states.
</bodyText>
<subsectionHeader confidence="0.9997">
3.1 Some History
</subsectionHeader>
<bodyText confidence="0.9999323125">
Traditional approaches to dialogue modelling can
roughly be classified as dialogue state approaches
or plan-based approaches. In the former the dia-
logue dynamics are specified by a set of dialogue
states, each state representing the results of perform-
ing a dialogue move in some previous state. The lat-
ter are used for more complex tasks requiring flex-
ible dialogue behaviour. The information-state ap-
proach (Traum et al., 1999) is intended to combine
the strengths of each paradigm, using aspects of dia-
logue state as well as the potential to include detailed
semantic representations and notions of obligation,
commitment, beliefs, and plans.
The information-state approach allows a declara-
tive representation of dialogue modelling. It is char-
acterised by the following components:
</bodyText>
<listItem confidence="0.999629">
1. a specification of the contents of the informa-
tion state of the dialogue,
2. the datatypes used to structure the information
state,
3. a set of update rules covering the dynamic
changes of the information state, and
4. a control strategy for information state updates.
</listItem>
<bodyText confidence="0.9999664375">
As mentioned earlier, the first fully fledged imple-
mentation of the information-state approach was the
TrindiKit (Larsson et al., 1999). Written in Prolog,
the TrindiKit implements dialogue systems by defin-
ing information states, update and selection rules,
and control algorithms governing the rules to be ap-
plied to the information state. The DIPPER dialogue
move engine builds on the TrindiKit by adopting its
record structure and datatypes to define information
states. However, there are some fundamental dif-
ferences, the most important being that there are no
update algorithms in the DIPPER DME, there is no
separation between update and selection rules, and
the update rules are abstracted away from Prolog.
We will consider these differences in more detail in
Section 4.
</bodyText>
<subsectionHeader confidence="0.999771">
3.2 Specifying Information States
</subsectionHeader>
<bodyText confidence="0.9999738">
The information state of a dialogue “represents the
information necessary to distinguish it from other di-
alogues, representing the cumulative additions from
previous actions in the dialogue, and motivating fu-
ture action” (Traum et al., 1999). The term informa-
tion state is very abstract, and concepts such as men-
tal model, discourse context, state of affairs, conver-
sational score, and other variations on this theme can
be seen as instances of an information state.
Like TrindiKit, DIPPER defines information
states using a rich set of datatypes, including
records, stacks, and queues.1 The TrindiKit allows
developers to define specific information states, tai-
lored to a particular theory or a special task. An
information state is normally defined as a recursive
structure of the form Name:Type, where Name is an
identifier, and Type a datatype. Here is a simple ex-
ample:
This example defines an information state as a
record named is, consisting of the fields grammar,
input, and sem. The field input is itself defined
as a queue of atomic typed structures, and the field
sem is defined as a stack of records containing the
fields int and context.
As in the TrindiKit, DIPPER uses a system of ref-
erences to anchor conditions and actions in the infor-
mation state. Each record consists of a set of fields.
Following the convention of the TrindiKit, we use
the operator -, where a-b refers to the value of field
b in record a, and call these paths. For instance, the
path is-input in the above example refers to a
queue of terms of type atomic. Note that paths can
be arbitrarily long and may be used in conjunction
with functions defined in the update language, which
we will introduce in the next section.
</bodyText>
<subsectionHeader confidence="0.996394">
3.3 The DIPPER Update Language
</subsectionHeader>
<bodyText confidence="0.99985025">
We will present the DIPPER update language here
in a rather informal way, merely by using examples.
(The reader is referred to the appendix for a precise
definition of the update language.) The update lan-
guage defines the core of the formalism underlying
the information state approach: the update rules.
An update rule is a triple (name, conditions, ef-
fects), with name a rule identifier, conditions a set of
tests on the current information state, and effects an
ordered set of operations on the information state.
Update rules specify the information state change
potential in a declarative way: applying an update
</bodyText>
<footnote confidence="0.9572445">
1For the purpose of this paper, we restrict ourselves to a
small number of datatypes, although the implementation sup-
ports further types including sets, ordered sets, numbers, and
discourse representation structures.
</footnote>
<figure confidence="0.8502068">
Example 1 Information State Definition
is:record([grammar:atomic,
input:queue(atomic),
sem:stack(record([int:atomic,
context:drs]))]).
</figure>
<bodyText confidence="0.999896090909091">
rule to an information state (assuming a shared vo-
cabulary of fields) results in a new state.
The conditions and effects of update rules are both
recursively defined over terms. The terms allow one
to refer to a specific value within the information
state, either for testing a condition, or for applying
an effect. There are two kinds of terms: standard
terms and anchored terms. The standard terms de-
fine the data structures for the types (atomic types,
queue, stack, records, and so on), whereas the an-
chored terms allow us to refer to sub-structures of
the information state (such as first and last to
refer to the first respectively last item of a queue).
A particularly useful anchored term is of the form
Tf, referring to a field f in a record T.
As we saw earlier the information state itself is a
structure of type record. We refer to the information
state object with the unique fixed name is (which
belongs to the anchored terms). To illustrate refer-
ence of terms with respect to a certain information
state, consider the following example, using the def-
inition as given in Example 1.
</bodyText>
<table confidence="0.5412212">
Example 2 Information State
is: grammar: ’.YesNo’
input: &lt;&gt;
sem: &lt; int: model(...)
drs: drs([X,Y],[...]) &gt;
</table>
<bodyText confidence="0.999887243243243">
As defined in the Appendix, we will use the
interpretation function [.]s for (standard and an-
chored) terms with respect to an information state
s. Now, with respect to the information state in
Example 2, the value of [isgrammar]s denotes
’.YesNo’, whereas the value of [grammar]s
denotes grammar, because the term is not an-
chored. Similarly, [top(issem)drs]s yields
drs([X,Y],[...]). However, note that
[top(sem)drs]s is undefined. This term is not
well-formed since sem is of type atomic and not of
type record.
This example (and the ones that follow) illustrates
the power and ease with which we can refer to spe-
cific attributes of the information state, and thereby
specify the conditions and effects of update rules.
The crucial property of conditions is that they must
not change the content of the information state, and
are only used to inspect values denoted by paths in
the record defining the information state (such as
checking identity of terms or whether a queue is
empty or not), in order to trigger the effects of an up-
date rule. Effects, on the other hand are responsible
for changing the information state. There are two
kinds of effects: operations (defined over terms),
and solvables. The former include assignments of
values to information state attributes and operations
on datatypes such as stacks and queues. The latter
are OAA-solvables that allow us to fulfil requests
by supporting agents or input/output agents of the
dialogue system, which is a useful way of incorpo-
rating procedural attachment using the functionality
provided by OAA as described in Section 2. As a re-
sult, external actions are able to update the informa-
tion state, giving the properties of an asynchronous
architecture while maintaining a central unit for data
processing.
</bodyText>
<subsectionHeader confidence="0.921811">
3.4 A simple example
</subsectionHeader>
<bodyText confidence="0.981952296875">
The following (extremely simple) example illus-
trates the DIPPER architecture and the information
state update language. The example implements a
“parrot”, where the system simply repeats what the
user says. Four OAA agents are involved: one agent
for the speech recogniser, one for the synthesiser,
and an agent each for the DME and the DME server.
We will use the following information structure:
is:record([input:queue(basic),
listening:basic,
output:queue(basic)]).
That is, there are three fields: a queue containing
the input of the speech recogniser (we’re assuming
that the objects returned by the speech recogniser are
strings), an auxiliary field keeping track of whether
speech recognition is active or not, and an output
field for the text-to-speech synthesiser.
There are four update rules. The first rule,
timeout, deals with the situation where the
speech recognition returned ‘timeout’ (no speech
was recognised in the given time). In that case we
simply remove it from the queue.
urule(timeout,
[first(isinput)=timeout],
[dequeue(isinput)]).
By virtue of the second rule, process, we sim-
ply move the string from the input queue to the out-
put queue. (This is just done for the sake of the ex-
ample, we could have directly sent it to the synthe-
siser).
urule(process,
[non-empty(is&amp;quot;input)],
[enqueue(is&amp;quot;output,first(is&amp;quot;input)),
dequeue(is&amp;quot;input)]).
The third rule, synthesise, gives the string to
the synthesiser, by posting an OAA solvable. We are
not interested in any result that could be yielded by
the solvable, so the set of effects is empty here.
urule(synthesise,
[non-empty(is&amp;quot;output)],
[solve(text2speech(first(is&amp;quot;output)),[]),
dequeue(is&amp;quot;output)]).
A slightly more complicated rule is recog-
nise. It activates the speech recognition agent
(with the grammar ’.Simple’) when the system
is currently not listening, then sets the listening flag
to yes (to prevent application of the update rule
again). The results of speech recognition will be in-
tegrated by the effects stated as the third argument
of solve: the results will be placed in the input
field, and the flag listening is set to no again.
urule(recognise,
[is&amp;quot;listening=no],
[solve(X,recognise(’.Simple’,10),
[enqueue(is&amp;quot;input,X),
assign(is&amp;quot;listening,no)]),
assign(is&amp;quot;listening,yes)]).
Finally, we would like to make a remarks about
the dynamics of effects in update rules. The effects
are ordered, because the information state is updated
after each single effect, and hence the order in which
the effects are applied to the information state mat-
ters. Conditions in update rules, however, are not
ordered.
</bodyText>
<sectionHeader confidence="0.963298" genericHeader="method">
4 Comparison with TrindiKit
</sectionHeader>
<bodyText confidence="0.999917166666667">
Now that we have introduced the DIPPER informa-
tion state update language, we are in a good position
to compare DIPPER’s approach to dialogue man-
agement that of the TrindiKit. We will consider the
use of variables, controlling update rules, and dis-
tributed processing.
</bodyText>
<subsectionHeader confidence="0.999521">
4.1 Use of Variables
</subsectionHeader>
<bodyText confidence="0.999995552631579">
The DIPPER update language is essentially a
variable-free language (apart from the variables that
are used in solve/3 to return answers which are
then substituted for the variable’s occurrences in the
effects). In the TrindiKit, Prolog variables are used
for references to objects in the information state.
The scope of such variables includes the conditions
and effects of the update rule. The system of refer-
ence in DIPPER is functional rather than relational,
which we will illustrate with two examples.
Example 3 In DIPPER, pushing the top el-
ement of stack is&amp;quot;a on another stack is&amp;quot;b,
and consequently pop the first stack, the effects
[push(is&amp;quot;b,top(is&amp;quot;a)), pop(is&amp;quot;a)]
will be the way to achieve this. In the TrindiKit,
one would need the effects [is::fst(a,X),
is::pop(a), is::push(b,X)] to get the
same result, where X denotes a Prolog variable.
Example 4 Given the information state struc-
ture presented at the beginning of this section,
the term assign(top(is&amp;quot;sem)&amp;quot;int,m)
picks the first record out of a stack, and refers
to one of its fields (here, the field int).
In the TrindiKit, this needs to be coded as
[is::fst(sem,X),X::set(int,m)],
where again X denotes a Prolog variable.
In both examples the TrindiKit relies on Prolog
unification to obtain the correct results. As a con-
sequence, the order of conditions in the TrindiKit
is crucial. Furthermore, in the TrindiKit it is com-
mon practice to use variables in the conditions to re-
fer to values in the effects of update rules. Unifica-
tion combined with Prolog’s backtracking can some-
times lead to unexpected behaviour, causing errors
that are difficult to debug (Burke et al., 2002). The
DIPPER update language does not rely on Prolog,
and therefore poses no such problems for dialogue
system developers unfamiliar with Prolog.
</bodyText>
<subsectionHeader confidence="0.98776">
4.2 Control in DIPPER
</subsectionHeader>
<bodyText confidence="0.9994957">
In contrast to the TrindiKit, which comes with a spe-
cial language to define the update control algorithm,
the control strategy used in DIPPER to select up-
date rules is simple and completely determined by
the update rules. Furthermore, there is no distinc-
tion between update and selection rules (used for
selecting a new dialogue move to be made by the
system) which the TrindiKit makes. The DIPPER
update algorithm is characterised by the following
pseudo-code:
</bodyText>
<footnote confidence="0.782823">
1 WHILE running
2 deal with OAA-events;
</footnote>
<figure confidence="0.56891">
3 IF there is a rule whose condi-
tions are satisfied by the informa-
tion state
4 THEN apply its effects;
5 ENDWHILE
</figure>
<bodyText confidence="0.999721928571429">
Line 2 deals with external OAA agents requesting
a service from the DME, in this case the solvable
apply effects(+Effects). If there are any
such requests, the information state gets updated,
and the algorithm proceeds with line 3. Here we
simply choose the first rule in the database whose
conditions are satisfied by the information state and
apply its effects to the information state (line 4).
If there is no such rule, no updates take place and
only an external event can change the information
state. Note that the effects of at most one rule will
be applied before proceeding to the end of the while-
loop, ensuring that incoming OAA-events are regu-
larly checked.
</bodyText>
<subsectionHeader confidence="0.993288">
4.3 OAA Integration
</subsectionHeader>
<bodyText confidence="0.99998515">
Allowing OAA-solvables in the effects of update
rules, a facility that the TrindiKit lacks, is an intu-
itive way of interfacing other components of a dia-
logue system (see the example update rules in Sec-
tion 3.4). This feature allows components to be eas-
ily replaced by others with the same functionality,
which is defined purely in terms of the OAA solv-
ables. For instance, changing the synthesiser does
not affect the dialogue management component.
The direct handle on OAA technology further al-
lows one to implement advanced functionality for
dialogue systems such as dealing with barge-in and
multi-modal input. Most spoken dialogue systems
exhibit a pipelined architecture with the following
components: automatic speech recognition —* nat-
ural language understanding —* dialogue manage-
ment —* natural language generation —* speech syn-
thesis. Because DIPPER builds on the OAA frame-
work, it allows developers to design asynchronous
dialogue systems in a relatively straightforward way.
</bodyText>
<sectionHeader confidence="0.941999" genericHeader="method">
5 Practical Results
</sectionHeader>
<subsectionHeader confidence="0.98983">
5.1 Prototyping
</subsectionHeader>
<bodyText confidence="0.999945636363636">
As the example in the previous section demon-
strated, relatively little effort is required to build the
core of a new dialogue system. First of all, the de-
veloper needs to select the OAA agents. A skeleton
for a spoken dialogue system could consists of the
Nuance speech recognition agent, the DME, and a
synthesiser. Further work involves defining the in-
formation state, and the update rules. Once a core
system has been built, it is often easy to switch to
new domains, using a similar configuration as in pre-
viously implemented systems.
</bodyText>
<subsectionHeader confidence="0.999043">
5.2 Debugging
</subsectionHeader>
<bodyText confidence="0.999980558823529">
A disadvantage of the information-state approach is
that it makes testing and debugging of dialogue sys-
tems notoriously difficult. The more advanced ap-
plications require at least a couple of dozen update
rules, and even for a relatively small set of rules de-
velopers tend to lose the overview of the intended
behaviour of their system.
Formal testing is one possibility, where intended
effects of update rules could be verified by future in-
formation states, or testing whether the conditions
of an update rule guarantee that its effects can be ap-
plied to any information state defined over the same
vocabulary. Given the formal specification of con-
ditions and effects, an interesting topic for future
research would be to apply model checking tech-
niques to dialogue system development. Most of
the model checking tools do not work on the more
complex datatypes required by the information-state
approach, although these probably can be translated
into some kind of propositional representation.
Practically, the DIPPER environment offers a
graphical user interface that assists during develop-
ment (Figure 1). This GUI starts and stops the DME
and keeps a history of updates. In addition, the de-
veloper is able to engage in “time-travelling”, by
backtracking in the dialogue and restarting the di-
alogue from any point in the past.
Further functionality of the GUI includes the
‘Step’ function, which applies just one update rule
before returning control to the GUI. This function
is particularly helpful in verifying the intended ef-
fect of an update rule. Finally, the ‘Spy’ function
displays all rules that are satisfied by the current in-
formation state.
</bodyText>
<subsectionHeader confidence="0.970816">
5.3 DIPPER Prototypes
</subsectionHeader>
<bodyText confidence="0.976722333333333">
The number of successful spoken dialogue proto-
types implemented using DIPPER is a convincing
proof-of-concept. Applications include conversa-
</bodyText>
<figureCaption confidence="0.948483333333333">
Figure 1: The Graphical User Interface of the DIP-
PER DME, showing the current information state,
the last applied update rule, and system messages.
</figureCaption>
<bodyText confidence="0.999852181818182">
tion with domestic appliances, as initiated by the
EU project D’Homme (Bos and Oka, 2002), ex-
plaining route descriptions to a mobile robot in a
miniature town, an EPSRC-funded project (Lauria
et al., 2001), and meaningful conversation with a
mobile robot in the basement of our department
(Theobalt et al., 2002). Currently we are work-
ing on a prototype dialogue system including the
Greta three-dimensional talking head (Pasquariello
and Pelachaud, 2001) as part of the EU project Mag-
iCster.
</bodyText>
<sectionHeader confidence="0.99671" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999980285714286">
We presented the DIPPER framework for build-
ing spoken dialogue systems, based on the infor-
mation state theory of dialogue management. In
comparison to TrindiKit, we showed that DIPPER
provides a transparent and elegant way of declar-
ing update rules—independent of any particular pro-
gramming language, and with the ability to use ar-
bitrary procedural attachment via OAA. The sys-
tem incorporates many off-the-shelf OAA agents,
which we described, as well as a variety of sup-
port agents. The DIPPER resources are available at
http://www.ltg.ed.ac.uk/dipper.
We also presented the formal syntax and seman-
tics of our information-state update language. Al-
though it is up to the developer to ensure the va-
lidity of update rules, this formalisation could form
the basis of implementing an interpreter that proves
validity of update rules. This is an attractive task
for future work, and similar directions have been
suggested by (Ljungl¨of, 2000; Fern´andez, 2003) for
proving generic properties of dialogue systems.
</bodyText>
<sectionHeader confidence="0.994726" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.994206">
Part of this work was supported by the EU Project
MagiCster (IST 1999-29078). We thank Nuance for
permission to use their software and tools.
</bodyText>
<sectionHeader confidence="0.998888" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999457225352113">
J. Bos and T. Oka. 2002. An Inference-based Ap-
proach to Dialogue System Design. In COLING 2002.
Proceedings of the 19th International Conference on
Computational Linguistics, pages 113–119, Taipei.
C. Burke, L. Harper, and D. Loehr. 2002. A Dialogue
Architecture for Multimodal Control of Robots. In In-
ternational CLASS Workshop on Natural, Intelligent
and Effective Interaction in Multimodal Dialogue Sys-
tems.
K. Currie and A. Tate. 1991. O-Plan: the open planning
architecture. Artificial Intelligence, 52:49–86.
J. Dowding, M. Gawron, D. Appelt, L. Cherny, R. Moore,
and D. Moran. 1993. Gemini: A natural language sys-
tem for spoken language understanding. In Proceed-
ings of the Thirty-First Annual Meeting of the Associ-
ation for Computational Linguistics.
R. Fern´andez. 2003. A dynamic logic formalisation of
the dialogue gameboard. In Proceedings of the 10th
Conference of the European Chapter of the ACL. Stu-
dent Research Workshop, pages 17–24, Budapest.
H. Kamp and U. Reyle. 1993. From Discourse to Logic;
An Introduction to Modeltheoretic Semantics of Natu-
ral Language, Formal Logic and DRT. Kluwer, Dor-
drecht.
S. Larsson and D. Traum. 2000. Information state and di-
alogue management in the trindi dialogue move engine
toolkit. Natural Language Engineering, 5(3–4):323–
340.
S. Larsson, A. Berman, J. Bos, L. Gr¨onqvist, P. Ljungl¨of,
and D. Traum. 1999. A model of dialogue moves
and information state revision. Technical Report D5.1,
Trindi (Task Oriented Instructional Dialogue).
S. Larsson. 2002. Issue-based Dialogue Management.
Ph.D. thesis, Goteborg University.
S. Lauria, G. Bugmann, T. Kyriacou, J.Bos, and E. Klein.
2001. Training Personal Robots Using Natural
Language Instruction. IEEE Intelligent Systems,
16(5):38–45, Sept./Oct.
P. Ljungl¨of. 2000. Formalizing the dialogue move en-
gine. In G¨otalog workshop on semantics and prag-
matics of dialogue.
D. L. Martin, A. J. Cheyer, and D. B. Moran. 1999. The
open agent architecture: A framework for building dis-
tributed software systems. Applied Artificial Intelli-
gence, 13.
W. McCune. 1998. Automatic Proofs and Counterex-
amples for Some Ortholattice Identities. Information
Processing Letters, 65(6):285–291.
S. Pasquariello and C. Pelachaud. 2001. Greta: A simple
facial animation engine. In 6th Online World Confer-
ence on Soft Computing in Industrial Appications.
R. Sproat, A. Hunt, M. Ostendorf, P. Taylor, A. Black,
and K. Lenzo. 1998. Sable: A standard for tts markup.
In ICSLP98, pages 1719–1724.
P. A. Taylor, A. Black, and R. Caley. 1998. The archi-
tecture of the festival speech synthesis system. In The
Third ESCA Workshop in Speech Synthesis.
C. Theobalt, J. Bos, T. Chapman, A. Espinosa-Romero,
M. Fraser, G. Hayes, E. Klein, T. Oka, and R. Reeve.
2002. Talking to Godot: Dialogue with a Mobile
Robot. In Proceedings ofIROS 2002.
D. Traum, J. Bos, R. Cooper, S. Larsson, I. Lewin,
C. Matheson, and M. Poesio. 1999. A model of dia-
logue moves and information state revision. Technical
Report D2.1, Trindi.
C. Weidenbach, B. Afshordel, U. Brahm, C. Cohrs, T. En-
gel, E. Keen, C. Theobalt, and D. Topic. 1999. System
description: Spass version 1.0.0. In Harald Ganzinger,
editor, 16th International Conference on Automated
Deduction, CADE-16, volume 1632 of LNAI, pages
314–318. Springer-Verlag, Berlin.
</reference>
<sectionHeader confidence="0.982834" genericHeader="method">
Appendix: Syntax and Semantics of the
DIPPER Update Language
</sectionHeader>
<bodyText confidence="0.99899825">
The terms of the update language refer to a specific
value within the information state, either for testing
a condition, or for applying an effect. There are two
kinds of terms: standard terms and anchored terms.
</bodyText>
<listItem confidence="0.946693714285714">
Definition: Standard Terms.
1. All constants are standard terms of type atomic.
2. If T1, ... ,Tn are standard terms of type , then
(T1, ... ,Tn) is a standard term of type stack().
3. If T1,... ,Tn are standard terms of type , then
(T1, ...Tn) is a standard term of type queue().
4. If f1, ... ,fn are record fields, T1, ... ,Tn
</listItem>
<bodyText confidence="0.891710333333333">
are terms of type 1, ... , n, then
[f1:T1, ... ,fn:Tn] is a standard term of
type record(f1:1,. . .,fn:n).
</bodyText>
<listItem confidence="0.950674777777778">
5. Standard Terms are only defined on the basis of
(1)–(4).
Definition: Anchored Terms.
1. is is an anchored term of type
record(f1:1,.. .,fn:n).
2. If T is an anchored term of type
record(...,f:,...), then T-f is an anchored
term of type .
3. If T is an anchored term of type queue(), then
first(T) and last(T) are anchored terms of
type .
4. If T is an anchored term of type stack(), then
top(T) is an anchored term of type .
5. If T is an anchored term of type queue() or
stack(), then member(T) is an anchored term
of type .
6. Anchored terms are only defined on the basis
of (1)–(5).
</listItem>
<bodyText confidence="0.8893015">
The interpretation function [.]s for (standard and an-
chored) terms with respect to an information state s
is defined as follows.
Definition: Reference of Terms.
</bodyText>
<listItem confidence="0.972114142857143">
1. [T]s = T iff T is a standard term.
2. [is]s = s.
3. [T-f]s = the value of field f in [T]s.
4. [top(T)]s = the top member of [T]s iff T is of
type stack().
5. [first(T)]s = the first member of [T]s iff T
is of type queue().
</listItem>
<bodyText confidence="0.925888071428571">
2. If T1 is an anchored term of type stack() and
T2 a (standard or anchored) term of type ,
then clear(T1), pop(T1), and push(T1,T2)
are effects.
6. [last(T)]s = the last member of [T]s iff T is
of type queue().
7. [member(T)]s = a member of [T]s iff T is of
type stack() or of type queue().
Now we define the syntax and semantics of update
rule conditions in DIPPER. For the interpretation
of conditions we use a truth-conditional semantics
mapping conditions to one of the values 1 (‘true’) or
0 (‘false’), defined with the help of an interpretation
function I with respect to an information state s.
</bodyText>
<listItem confidence="0.5800915625">
Definition: Syntax of Conditions.
1. If T1 and T2 are (standard or anchored) terms
of the same type, then T1=T2 and T17�T2 are
conditions.
2. If T is a (standard or anchored) term of type
stack(), or queue(), then empty(T) and
non empty(T) are conditions.
3. Conditions are only defined on the basis of (1)
and (2).
Definition: Semantics of Conditions.
1. Is(T1=T2) = 1 iff [T1]s = [T2]s
2. Is(T17�T2) = 1 iff [T1]s =� [T2]s
3. Is(empty(T)) = 1 iff [T]s denotes a stack or
queue containing no elements.
4. Is(non empty(T)) = 1 iff [T]s denotes a stack
or queue containing at least one element.
</listItem>
<sectionHeader confidence="0.636867" genericHeader="method">
Definition: Information State Satisfaction.
</sectionHeader>
<bodyText confidence="0.915682166666667">
An information state s satisfies a set of conditions C
iff Vc : c E C —* [c]s = 1.
The effects in an update rule are responsible for
changing the information state. There are two kinds
of effects: operations defined over terms, and solv-
ables.
</bodyText>
<listItem confidence="0.594938">
Definition: Syntax of Effects.
1. If T1 is an anchored term of type  and T2
a (standard or anchored) term of type , then
assign(T1,T2) is an effect.
3. If T1 is an anchored term of type queue()
and T2 a (standard or anchored) term of type
, then clear(T1), dequeue(T1), and en-
queue(T1,T2) are effects.
4. If the term S is an n-place OAA-solvable,
T1,...,Tn are (standard or anchored) terms,
E(x) an ordered (possibly empty) set of
effects with free occurrences of x, then
solve(x,S(T1,...,Tn),E) is an effect.
5. Effects are only defined on the basis of (1)–(4).
</listItem>
<bodyText confidence="0.998420714285714">
The semantics of the effects are defined with the
help of the function U: s x E—*s from an informa-
tion state and an effect to a new information state.
(Some notational conventions: We will use the nota-
tion s[T]s to mean that the information states s and
s are the same except for the value of [T]s. We will
use E[t/u] to mean substituting t for u in E).
</bodyText>
<listItem confidence="0.9215971875">
Definition: Semantics of Effects.
1. U(s,assign(T,T)) = s if s[T]s and [T]s =
[T]s.
2. U(s,clear(T)) = s if s[T]s and [T]s = ().
3. U(s,pop(T)) = s if s[T]s and [T]s =
(t1, t2, ... , tn) and [T]s = (t2, ... , tn).
4. U(s,push(T,T)) = s if s[T]s and [T]s =
(t1, ...,tn) and [T]s = ([T]s, t1, ... , tn).
5. U(s,dequeue(T)) = s if s[T]s and [T]s =
(t1, t2, ... , tn) and [T]s = (t2, ... , tn).
6. U(s,enqueue(T,T)) = s if s[T]s and [T]s =
(t1, ...,tn) and [T]s = (t1, ...,tn, [T]s).
7. U(s,solve(x,S(T1,...,Tn),E)) = s if for all an-
swers a returned by solve(S([T1]s,...,[Tn]s))
there is an s such that the effects E[a/x] are ap-
plied to s.
</listItem>
<bodyText confidence="0.91189">
Definition: Update.
An ordered set of effects {e1, ... , en} are success-
fully applied to an information state s, resulting an
information state s if U(e1,s)=s1 ,..., U(ei,si−1)=si
,..., U(en,sn−1)=s.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.296649">
<title confidence="0.997808">DIPPER: Description and Formalisation of Information-State Update Dialogue System Architecture</title>
<author confidence="0.999732">Johan Bos</author>
<author confidence="0.999732">Ewan Klein</author>
<author confidence="0.999732">Oliver Lemon</author>
<author confidence="0.999732">Tetsushi</author>
<affiliation confidence="0.983213">ICCS, School of University of</affiliation>
<note confidence="0.425617">2 Buccleuch Place, Edinburgh EH8 Scotland, United</note>
<abstract confidence="0.996809142857143">The DIPPER architecture is a collection of software agents for prototyping spoken dialogue systems. Implemented on top of the Open Agent Architecture (OAA), it comprises agents for speech input and output, dialogue management, and further supporting agents. We define a formal syntax and semantics for the DIP- PER information state update language. The language is independent of particular programming languages, and incorporates procedural attachments for access to external resources using OAA.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bos</author>
<author>T Oka</author>
</authors>
<title>An Inference-based Approach to Dialogue System Design.</title>
<date>2002</date>
<booktitle>In COLING 2002. Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>113--119</pages>
<location>Taipei.</location>
<contexts>
<context position="28388" citStr="Bos and Oka, 2002" startWordPosition="4496" endWordPosition="4499">eturning control to the GUI. This function is particularly helpful in verifying the intended effect of an update rule. Finally, the ‘Spy’ function displays all rules that are satisfied by the current information state. 5.3 DIPPER Prototypes The number of successful spoken dialogue prototypes implemented using DIPPER is a convincing proof-of-concept. Applications include conversaFigure 1: The Graphical User Interface of the DIPPER DME, showing the current information state, the last applied update rule, and system messages. tion with domestic appliances, as initiated by the EU project D’Homme (Bos and Oka, 2002), explaining route descriptions to a mobile robot in a miniature town, an EPSRC-funded project (Lauria et al., 2001), and meaningful conversation with a mobile robot in the basement of our department (Theobalt et al., 2002). Currently we are working on a prototype dialogue system including the Greta three-dimensional talking head (Pasquariello and Pelachaud, 2001) as part of the EU project MagiCster. 6 Conclusion We presented the DIPPER framework for building spoken dialogue systems, based on the information state theory of dialogue management. In comparison to TrindiKit, we showed that DIPPER</context>
</contexts>
<marker>Bos, Oka, 2002</marker>
<rawString>J. Bos and T. Oka. 2002. An Inference-based Approach to Dialogue System Design. In COLING 2002. Proceedings of the 19th International Conference on Computational Linguistics, pages 113–119, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Burke</author>
<author>L Harper</author>
<author>D Loehr</author>
</authors>
<title>A Dialogue Architecture for Multimodal Control of Robots.</title>
<date>2002</date>
<booktitle>In International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems.</booktitle>
<contexts>
<context position="23285" citStr="Burke et al., 2002" startWordPosition="3666" endWordPosition="3669">rs to one of its fields (here, the field int). In the TrindiKit, this needs to be coded as [is::fst(sem,X),X::set(int,m)], where again X denotes a Prolog variable. In both examples the TrindiKit relies on Prolog unification to obtain the correct results. As a consequence, the order of conditions in the TrindiKit is crucial. Furthermore, in the TrindiKit it is common practice to use variables in the conditions to refer to values in the effects of update rules. Unification combined with Prolog’s backtracking can sometimes lead to unexpected behaviour, causing errors that are difficult to debug (Burke et al., 2002). The DIPPER update language does not rely on Prolog, and therefore poses no such problems for dialogue system developers unfamiliar with Prolog. 4.2 Control in DIPPER In contrast to the TrindiKit, which comes with a special language to define the update control algorithm, the control strategy used in DIPPER to select update rules is simple and completely determined by the update rules. Furthermore, there is no distinction between update and selection rules (used for selecting a new dialogue move to be made by the system) which the TrindiKit makes. The DIPPER update algorithm is characterised </context>
</contexts>
<marker>Burke, Harper, Loehr, 2002</marker>
<rawString>C. Burke, L. Harper, and D. Loehr. 2002. A Dialogue Architecture for Multimodal Control of Robots. In International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Currie</author>
<author>A Tate</author>
</authors>
<title>O-Plan: the open planning architecture.</title>
<date>1991</date>
<journal>Artificial Intelligence,</journal>
<pages>52--49</pages>
<contexts>
<context position="10822" citStr="Currie and Tate, 1991" startWordPosition="1691" endWordPosition="1694"> based on the Gemini system (Dowding et al., 1993). DIPPER provides a further set of agents to deal with natural language understanding, based on Discourse Representation Theory (Kamp and Reyle, 1993). There is an ambiguity resolution agent that resolves underspecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build domain-specific content plans. 3 The Information-state Approach In this section we will briefly review the information-state approach and then introduce a revised version of the TrindiKit’s dialogue move engine (Traum et al., 1999), including a new update language for information states. 3.1 Some History Traditional approaches to dialogue modelling can roughly be classified as dialogue state approaches or plan-based approaches. In the former the dialogue dynamics are specified by a set of dialogue states, each state representing the results of performing a dialogue </context>
</contexts>
<marker>Currie, Tate, 1991</marker>
<rawString>K. Currie and A. Tate. 1991. O-Plan: the open planning architecture. Artificial Intelligence, 52:49–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dowding</author>
<author>M Gawron</author>
<author>D Appelt</author>
<author>L Cherny</author>
<author>R Moore</author>
<author>D Moran</author>
</authors>
<title>Gemini: A natural language system for spoken language understanding.</title>
<date>1993</date>
<booktitle>In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10250" citStr="Dowding et al., 1993" startWordPosition="1605" endWordPosition="1608"> apply effects(+Effects); (2) the DME agent can call other agents directly, in particular if it is not interested in the results of those requests; (3) the DME agent can use the DME server as a mediating agent, normally when the results are needed for updating the information state of the DME. The advantage of this architecture is the flexibility imposed by it, while at the same time allowing asynchronous interaction of the input/output and supporting agents with the dialogue move engine. 2.4 Supporting Agents OAA itself comes with agents for parsing and generating based on the Gemini system (Dowding et al., 1993). DIPPER provides a further set of agents to deal with natural language understanding, based on Discourse Representation Theory (Kamp and Reyle, 1993). There is an ambiguity resolution agent that resolves underspecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build </context>
</contexts>
<marker>Dowding, Gawron, Appelt, Cherny, Moore, Moran, 1993</marker>
<rawString>J. Dowding, M. Gawron, D. Appelt, L. Cherny, R. Moore, and D. Moran. 1993. Gemini: A natural language system for spoken language understanding. In Proceedings of the Thirty-First Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fern´andez</author>
</authors>
<title>A dynamic logic formalisation of the dialogue gameboard.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the European Chapter of the ACL. Student Research Workshop,</booktitle>
<pages>17--24</pages>
<location>Budapest.</location>
<marker>Fern´andez, 2003</marker>
<rawString>R. Fern´andez. 2003. A dynamic logic formalisation of the dialogue gameboard. In Proceedings of the 10th Conference of the European Chapter of the ACL. Student Research Workshop, pages 17–24, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>U Reyle</author>
</authors>
<title>From Discourse to Logic; An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and DRT.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="10400" citStr="Kamp and Reyle, 1993" startWordPosition="1627" endWordPosition="1630">) the DME agent can use the DME server as a mediating agent, normally when the results are needed for updating the information state of the DME. The advantage of this architecture is the flexibility imposed by it, while at the same time allowing asynchronous interaction of the input/output and supporting agents with the dialogue move engine. 2.4 Supporting Agents OAA itself comes with agents for parsing and generating based on the Gemini system (Dowding et al., 1993). DIPPER provides a further set of agents to deal with natural language understanding, based on Discourse Representation Theory (Kamp and Reyle, 1993). There is an ambiguity resolution agent that resolves underspecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build domain-specific content plans. 3 The Information-state Approach In this section we will briefly review the information-state approach and then introdu</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>H. Kamp and U. Reyle. 1993. From Discourse to Logic; An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and DRT. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>D Traum</author>
</authors>
<title>Information state and dialogue management in the trindi dialogue move engine toolkit. Natural Language Engineering,</title>
<date>2000</date>
<pages>5--3</pages>
<contexts>
<context position="2100" citStr="Larsson and Traum, 2000" startWordPosition="291" endWordPosition="294"> the dialogue management component, where interaction between the different components is managed in a flexible way. Allowing for plugand-play and easy adaptation to new domains is a challenging task for dialogue system architectures. This paper presents DIPPER, an architecture tailored for prototyping spoken dialogue systems, based on the Open Agent Architecture (OAA). Although DIPPER supports many off-the-shelf components useful for spoken dialogue systems, it comes with its own dialogue management component, based on the information-state approach to dialogue modelling (Traum et al., 1999; Larsson and Traum, 2000). The TrindiKit (Larsson et al., 1999; Larsson, 2002) is regarded as the first implementation of the information-state approach. However impressive it is, on many occasions the TrindiKit tends to give the impression of a “Rube Goldberg” machine for what is a relatively straightforward task: updating the information state of the dialogue with the help of declaratively stated update rules. What should be a transparent operation is often obscured by the complexity of the TrindiKit framework. The dialogue management component of DIPPER borrows many of the core ideas of the TrindiKit, but is stripp</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>S. Larsson and D. Traum. 2000. Information state and dialogue management in the trindi dialogue move engine toolkit. Natural Language Engineering, 5(3–4):323– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>A Berman</author>
<author>J Bos</author>
<author>L Gr¨onqvist</author>
<author>P Ljungl¨of</author>
<author>D Traum</author>
</authors>
<title>A model of dialogue moves and information state revision.</title>
<date>1999</date>
<tech>Technical Report D5.1,</tech>
<institution>Trindi (Task Oriented Instructional Dialogue).</institution>
<marker>Larsson, Berman, Bos, Gr¨onqvist, Ljungl¨of, Traum, 1999</marker>
<rawString>S. Larsson, A. Berman, J. Bos, L. Gr¨onqvist, P. Ljungl¨of, and D. Traum. 1999. A model of dialogue moves and information state revision. Technical Report D5.1, Trindi (Task Oriented Instructional Dialogue).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
</authors>
<title>Issue-based Dialogue Management.</title>
<date>2002</date>
<journal>IEEE Intelligent Systems,</journal>
<tech>Ph.D. thesis,</tech>
<volume>16</volume>
<issue>5</issue>
<pages>Sept./Oct.</pages>
<institution>Goteborg University.</institution>
<contexts>
<context position="2153" citStr="Larsson, 2002" startWordPosition="301" endWordPosition="302">he different components is managed in a flexible way. Allowing for plugand-play and easy adaptation to new domains is a challenging task for dialogue system architectures. This paper presents DIPPER, an architecture tailored for prototyping spoken dialogue systems, based on the Open Agent Architecture (OAA). Although DIPPER supports many off-the-shelf components useful for spoken dialogue systems, it comes with its own dialogue management component, based on the information-state approach to dialogue modelling (Traum et al., 1999; Larsson and Traum, 2000). The TrindiKit (Larsson et al., 1999; Larsson, 2002) is regarded as the first implementation of the information-state approach. However impressive it is, on many occasions the TrindiKit tends to give the impression of a “Rube Goldberg” machine for what is a relatively straightforward task: updating the information state of the dialogue with the help of declaratively stated update rules. What should be a transparent operation is often obscured by the complexity of the TrindiKit framework. The dialogue management component of DIPPER borrows many of the core ideas of the TrindiKit, but is stripped down to the essentials, uses a revised update lang</context>
</contexts>
<marker>Larsson, 2002</marker>
<rawString>S. Larsson. 2002. Issue-based Dialogue Management. Ph.D. thesis, Goteborg University. S. Lauria, G. Bugmann, T. Kyriacou, J.Bos, and E. Klein. 2001. Training Personal Robots Using Natural Language Instruction. IEEE Intelligent Systems, 16(5):38–45, Sept./Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ljungl¨of</author>
</authors>
<title>Formalizing the dialogue move engine. In G¨otalog workshop on semantics and pragmatics of dialogue.</title>
<date>2000</date>
<marker>Ljungl¨of, 2000</marker>
<rawString>P. Ljungl¨of. 2000. Formalizing the dialogue move engine. In G¨otalog workshop on semantics and pragmatics of dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Martin</author>
<author>A J Cheyer</author>
<author>D B Moran</author>
</authors>
<title>The open agent architecture: A framework for building distributed software systems.</title>
<date>1999</date>
<journal>Applied Artificial Intelligence,</journal>
<volume>13</volume>
<contexts>
<context position="3928" citStr="Martin et al., 1999" startWordPosition="575" endWordPosition="578">al results obtained using the DIPPER framework (Section 5). 2 The DIPPER Environment This section gives an overview of DIPPER. First we introduce the Open Agent Architecture, then we present the various agents that play a role in spoken dialogue systems. We focus on the dialogue move engine in particular. 2.1 The Open Agent Architecture The Open Agent Architecture, OAA for short, is a framework for integrating several software agents, possibly coded in different programming languages (C/C++, Java, Prolog) and running on different platforms (Unix, Linux, Windows), in a distributed environment (Martin et al., 1999). Because dialogue systems are typically built out of a set of independent components performing particular tasks (where in many cases some of them are “out-of-the-box” packages, such as speech recognition or speech synthesis), the OAA framework forms an ideal medium to allow easy integration of software agents for dialogue systems in a prototyping development environment. The term “agent” within OAA refers to a software process meeting the conventions of the OAA framework. Basically, this means providing services to other agents in a particular form, using the Interagent Communication Languag</context>
</contexts>
<marker>Martin, Cheyer, Moran, 1999</marker>
<rawString>D. L. Martin, A. J. Cheyer, and D. B. Moran. 1999. The open agent architecture: A framework for building distributed software systems. Applied Artificial Intelligence, 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W McCune</author>
</authors>
<title>Automatic Proofs and Counterexamples for Some Ortholattice Identities.</title>
<date>1998</date>
<journal>Information Processing Letters,</journal>
<volume>65</volume>
<issue>6</issue>
<contexts>
<context position="10722" citStr="McCune, 1998" startWordPosition="1678" endWordPosition="1679"> move engine. 2.4 Supporting Agents OAA itself comes with agents for parsing and generating based on the Gemini system (Dowding et al., 1993). DIPPER provides a further set of agents to deal with natural language understanding, based on Discourse Representation Theory (Kamp and Reyle, 1993). There is an ambiguity resolution agent that resolves underspecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build domain-specific content plans. 3 The Information-state Approach In this section we will briefly review the information-state approach and then introduce a revised version of the TrindiKit’s dialogue move engine (Traum et al., 1999), including a new update language for information states. 3.1 Some History Traditional approaches to dialogue modelling can roughly be classified as dialogue state approaches or plan-based approaches. In the former the dialogue dynamics are </context>
</contexts>
<marker>McCune, 1998</marker>
<rawString>W. McCune. 1998. Automatic Proofs and Counterexamples for Some Ortholattice Identities. Information Processing Letters, 65(6):285–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pasquariello</author>
<author>C Pelachaud</author>
</authors>
<title>Greta: A simple facial animation engine.</title>
<date>2001</date>
<booktitle>In 6th Online World Conference on Soft Computing in Industrial Appications.</booktitle>
<contexts>
<context position="7283" citStr="Pasquariello and Pelachaud, 2001" startWordPosition="1104" endWordPosition="1107">age model for speech recognition. Callback mode makes it easy to plug in new grammars during different stages of the dialogue so as to increase speech recognition performance. On the output side, DIPPER provides agents for the speech synthesisers Festival (Taylor et al., 1998) and rVoice (www.rhetorical.com). The solvables for these output agents are text2speech(+Text) and sable2speech(+Sable). The latter can be used to synthesise strings marked up in SABLE, an XML schema for text-to-speech (Sproat et al., 1998). A further agent is available to control Greta, a three-dimensional talking head (Pasquariello and Pelachaud, 2001). 2.3 Dialogue Management Agents The dialogue manager forms the heart of a dialogue system, reading the input modalities, updating the current state of the dialogue, deciding what to do next, and generating output. In terms of interaction with other agents, it is the most complex component. In fact, the DIPPER dialogue manager is implemented as two cooperating OAA agents: the dialogue move engine (DME), and a DME server. The DME does the real work by dealing with input from other agents (normally the input modalities, such as speech recognition), updating its internal state, and calling other </context>
<context position="28754" citStr="Pasquariello and Pelachaud, 2001" startWordPosition="4552" endWordPosition="4555"> Applications include conversaFigure 1: The Graphical User Interface of the DIPPER DME, showing the current information state, the last applied update rule, and system messages. tion with domestic appliances, as initiated by the EU project D’Homme (Bos and Oka, 2002), explaining route descriptions to a mobile robot in a miniature town, an EPSRC-funded project (Lauria et al., 2001), and meaningful conversation with a mobile robot in the basement of our department (Theobalt et al., 2002). Currently we are working on a prototype dialogue system including the Greta three-dimensional talking head (Pasquariello and Pelachaud, 2001) as part of the EU project MagiCster. 6 Conclusion We presented the DIPPER framework for building spoken dialogue systems, based on the information state theory of dialogue management. In comparison to TrindiKit, we showed that DIPPER provides a transparent and elegant way of declaring update rules—independent of any particular programming language, and with the ability to use arbitrary procedural attachment via OAA. The system incorporates many off-the-shelf OAA agents, which we described, as well as a variety of support agents. The DIPPER resources are available at http://www.ltg.ed.ac.uk/di</context>
</contexts>
<marker>Pasquariello, Pelachaud, 2001</marker>
<rawString>S. Pasquariello and C. Pelachaud. 2001. Greta: A simple facial animation engine. In 6th Online World Conference on Soft Computing in Industrial Appications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>A Hunt</author>
<author>M Ostendorf</author>
<author>P Taylor</author>
<author>A Black</author>
<author>K Lenzo</author>
</authors>
<title>Sable: A standard for tts markup. In</title>
<date>1998</date>
<booktitle>ICSLP98,</booktitle>
<pages>1719--1724</pages>
<contexts>
<context position="7167" citStr="Sproat et al., 1998" startWordPosition="1088" endWordPosition="1091">s Input, within a time specified by Time. The value of Input is determined by the grammar used as language model for speech recognition. Callback mode makes it easy to plug in new grammars during different stages of the dialogue so as to increase speech recognition performance. On the output side, DIPPER provides agents for the speech synthesisers Festival (Taylor et al., 1998) and rVoice (www.rhetorical.com). The solvables for these output agents are text2speech(+Text) and sable2speech(+Sable). The latter can be used to synthesise strings marked up in SABLE, an XML schema for text-to-speech (Sproat et al., 1998). A further agent is available to control Greta, a three-dimensional talking head (Pasquariello and Pelachaud, 2001). 2.3 Dialogue Management Agents The dialogue manager forms the heart of a dialogue system, reading the input modalities, updating the current state of the dialogue, deciding what to do next, and generating output. In terms of interaction with other agents, it is the most complex component. In fact, the DIPPER dialogue manager is implemented as two cooperating OAA agents: the dialogue move engine (DME), and a DME server. The DME does the real work by dealing with input from other</context>
</contexts>
<marker>Sproat, Hunt, Ostendorf, Taylor, Black, Lenzo, 1998</marker>
<rawString>R. Sproat, A. Hunt, M. Ostendorf, P. Taylor, A. Black, and K. Lenzo. 1998. Sable: A standard for tts markup. In ICSLP98, pages 1719–1724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Taylor</author>
<author>A Black</author>
<author>R Caley</author>
</authors>
<title>The architecture of the festival speech synthesis system.</title>
<date>1998</date>
<booktitle>In The Third ESCA Workshop in Speech</booktitle>
<contexts>
<context position="6927" citStr="Taylor et al., 1998" startWordPosition="1054" endWordPosition="1057">le apply effects(+Effects) and thereby updating the information state of the dialogue (see Section 3); and in callback mode, where the solvable recognize(+Grammar,+Time,- Input) starts recognition using the speech grammar Grammar and returns Input, within a time specified by Time. The value of Input is determined by the grammar used as language model for speech recognition. Callback mode makes it easy to plug in new grammars during different stages of the dialogue so as to increase speech recognition performance. On the output side, DIPPER provides agents for the speech synthesisers Festival (Taylor et al., 1998) and rVoice (www.rhetorical.com). The solvables for these output agents are text2speech(+Text) and sable2speech(+Sable). The latter can be used to synthesise strings marked up in SABLE, an XML schema for text-to-speech (Sproat et al., 1998). A further agent is available to control Greta, a three-dimensional talking head (Pasquariello and Pelachaud, 2001). 2.3 Dialogue Management Agents The dialogue manager forms the heart of a dialogue system, reading the input modalities, updating the current state of the dialogue, deciding what to do next, and generating output. In terms of interaction with </context>
</contexts>
<marker>Taylor, Black, Caley, 1998</marker>
<rawString>P. A. Taylor, A. Black, and R. Caley. 1998. The architecture of the festival speech synthesis system. In The Third ESCA Workshop in Speech Synthesis. C. Theobalt, J. Bos, T. Chapman, A. Espinosa-Romero, M. Fraser, G. Hayes, E. Klein, T. Oka, and R. Reeve. 2002. Talking to Godot: Dialogue with a Mobile Robot. In Proceedings ofIROS 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
<author>J Bos</author>
<author>R Cooper</author>
<author>S Larsson</author>
<author>I Lewin</author>
<author>C Matheson</author>
<author>M Poesio</author>
</authors>
<title>A model of dialogue moves and information state revision.</title>
<date>1999</date>
<tech>Technical Report D2.1, Trindi.</tech>
<contexts>
<context position="2074" citStr="Traum et al., 1999" startWordPosition="287" endWordPosition="290">tem is controlled by the dialogue management component, where interaction between the different components is managed in a flexible way. Allowing for plugand-play and easy adaptation to new domains is a challenging task for dialogue system architectures. This paper presents DIPPER, an architecture tailored for prototyping spoken dialogue systems, based on the Open Agent Architecture (OAA). Although DIPPER supports many off-the-shelf components useful for spoken dialogue systems, it comes with its own dialogue management component, based on the information-state approach to dialogue modelling (Traum et al., 1999; Larsson and Traum, 2000). The TrindiKit (Larsson et al., 1999; Larsson, 2002) is regarded as the first implementation of the information-state approach. However impressive it is, on many occasions the TrindiKit tends to give the impression of a “Rube Goldberg” machine for what is a relatively straightforward task: updating the information state of the dialogue with the help of declaratively stated update rules. What should be a transparent operation is often obscured by the complexity of the TrindiKit framework. The dialogue management component of DIPPER borrows many of the core ideas of th</context>
<context position="11081" citStr="Traum et al., 1999" startWordPosition="1730" endWordPosition="1733">ecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build domain-specific content plans. 3 The Information-state Approach In this section we will briefly review the information-state approach and then introduce a revised version of the TrindiKit’s dialogue move engine (Traum et al., 1999), including a new update language for information states. 3.1 Some History Traditional approaches to dialogue modelling can roughly be classified as dialogue state approaches or plan-based approaches. In the former the dialogue dynamics are specified by a set of dialogue states, each state representing the results of performing a dialogue move in some previous state. The latter are used for more complex tasks requiring flexible dialogue behaviour. The information-state approach (Traum et al., 1999) is intended to combine the strengths of each paradigm, using aspects of dialogue state as well a</context>
<context position="13267" citStr="Traum et al., 1999" startWordPosition="2068" endWordPosition="2071">tatypes to define information states. However, there are some fundamental differences, the most important being that there are no update algorithms in the DIPPER DME, there is no separation between update and selection rules, and the update rules are abstracted away from Prolog. We will consider these differences in more detail in Section 4. 3.2 Specifying Information States The information state of a dialogue “represents the information necessary to distinguish it from other dialogues, representing the cumulative additions from previous actions in the dialogue, and motivating future action” (Traum et al., 1999). The term information state is very abstract, and concepts such as mental model, discourse context, state of affairs, conversational score, and other variations on this theme can be seen as instances of an information state. Like TrindiKit, DIPPER defines information states using a rich set of datatypes, including records, stacks, and queues.1 The TrindiKit allows developers to define specific information states, tailored to a particular theory or a special task. An information state is normally defined as a recursive structure of the form Name:Type, where Name is an identifier, and Type a da</context>
</contexts>
<marker>Traum, Bos, Cooper, Larsson, Lewin, Matheson, Poesio, 1999</marker>
<rawString>D. Traum, J. Bos, R. Cooper, S. Larsson, I. Lewin, C. Matheson, and M. Poesio. 1999. A model of dialogue moves and information state revision. Technical Report D2.1, Trindi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Weidenbach</author>
<author>B Afshordel</author>
<author>U Brahm</author>
<author>C Cohrs</author>
<author>T Engel</author>
<author>E Keen</author>
<author>C Theobalt</author>
<author>D Topic</author>
</authors>
<title>System description: Spass version 1.0.0.</title>
<date>1999</date>
<booktitle>16th International Conference on Automated Deduction, CADE-16,</booktitle>
<volume>1632</volume>
<pages>314--318</pages>
<editor>In Harald Ganzinger, editor,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="10680" citStr="Weidenbach et al., 1999" startWordPosition="1669" endWordPosition="1672"> input/output and supporting agents with the dialogue move engine. 2.4 Supporting Agents OAA itself comes with agents for parsing and generating based on the Gemini system (Dowding et al., 1993). DIPPER provides a further set of agents to deal with natural language understanding, based on Discourse Representation Theory (Kamp and Reyle, 1993). There is an ambiguity resolution agent that resolves underspecified DRSs into fully resolved DRSs, and there is an inference agent that checks consistency of DRSs, using standard firstorder theorem proving techniques, including the theorem prover SPASS (Weidenbach et al., 1999) and the model builder MACE (McCune, 1998). DIPPER also includes a high-level dialogue planning component using O-Plan (Currie and Tate, 1991) which can be used to build domain-specific content plans. 3 The Information-state Approach In this section we will briefly review the information-state approach and then introduce a revised version of the TrindiKit’s dialogue move engine (Traum et al., 1999), including a new update language for information states. 3.1 Some History Traditional approaches to dialogue modelling can roughly be classified as dialogue state approaches or plan-based approaches</context>
</contexts>
<marker>Weidenbach, Afshordel, Brahm, Cohrs, Engel, Keen, Theobalt, Topic, 1999</marker>
<rawString>C. Weidenbach, B. Afshordel, U. Brahm, C. Cohrs, T. Engel, E. Keen, C. Theobalt, and D. Topic. 1999. System description: Spass version 1.0.0. In Harald Ganzinger, editor, 16th International Conference on Automated Deduction, CADE-16, volume 1632 of LNAI, pages 314–318. Springer-Verlag, Berlin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>