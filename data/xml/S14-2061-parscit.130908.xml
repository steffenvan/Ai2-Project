<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016586">
<title confidence="0.99527">
IxaMed: Applying Freeling and a Perceptron Sequential Tagger at the
Shared Task on Analyzing Clinical Texts
</title>
<author confidence="0.749212">
Koldo Gojenola, Maite Oronoz, Alicia P´erez, Arantza Casillas
</author>
<affiliation confidence="0.362756">
IXA Taldea (UPV-EHU)
</affiliation>
<email confidence="0.8675405">
maite.oronoz@ehu.es
http://ixa.si.ehu.es
</email>
<sectionHeader confidence="0.989756" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961933333333">
This paper presents the results of the Ix-
aMed team at the SemEval-2014 Shared
Task 7 on Analyzing Clinical Texts.
We have developed three different sys-
tems based on: a) exact match, b) a
general-purpose morphosyntactic analyzer
enriched with the SNOMED CT termi-
nology content, and c) a perceptron se-
quential tagger based on a Global Linear
Model. The three individual systems re-
sult in similar f-score while they vary in
their precision and recall. We have also
tried direct combinations of the individual
systems, obtaining considerable improve-
ments in performance.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.90506464">
This paper presents the results of the IxaMed team.
The task is focused on the identification (Task A)
and normalization (Task B) of diseases and disor-
ders in clinical reports.
We have developed three different systems
based on: a) exact match, b) a general-
purpose morphosyntactic analyzer enriched with
the SNOMED CT terminology content, and c) a
perceptron sequential tagger based on a Global
Linear Model. The first system can be seen as
a baseline that can be compared with other ap-
proaches, while the other two represent two alter-
native approaches based on knowledge organized
in dictionaries/ontologies and machine learning,
respectively. We also tried direct combinations of
the individual systems, obtaining considerable im-
provements in performance.
These approaches are representative of different
solutions that have been proposed in the literature
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organizers. License details:
http://creativecommons.org/licenses/by/4.0/
(Pradhan et al., 2013), which can be broadly clas-
sified in the following types:
</bodyText>
<listItem confidence="0.994061409090909">
• Knowledge-based. This approach makes use
of large-scale dictionaries and ontologies,
that are sometimes integrated in general tools
adapted to the clinical domain, as MetaMap
(Aronson and Lang, 2010) and cTAKES (Xia
et al., 2013).
• Rule-based. For example, in (Wang and
Akella, 2013) the authors show the use
of a rule-based approach on the output of
MetaMap.
• Statistical techniques. These systems take a
training set as input and apply different vari-
ants of machine learning, such as sequen-
tial taggers based on hidden Markov mod-
els (HMMs) or conditional random fields
(CRFs) (Zuccon et al., 2013; Bodnari et al.,
2013; Gung, 2013; Hervas et al., 2013; Lea-
man et al., 2013).
• Combinations. These approaches try to take
the advantages of different system types, us-
ing methods such as voting or metaclassi-
fiers (Liu et al., 2013).
</listItem>
<bodyText confidence="0.99973575">
In the rest of the paper, we will first introduce
the different systems that we have developed in
section 2, presenting the main results in section 3,
and ending with the main conclusions.
</bodyText>
<sectionHeader confidence="0.982235" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.9996195">
The task of detecting diseases and their corre-
sponding concept unique identifiers (CUI) has
been faced using three methods that are described
in the following subsections.
</bodyText>
<subsectionHeader confidence="0.980537">
2.1 Exact Match
</subsectionHeader>
<bodyText confidence="0.995189">
The system based on Exact Match (EM) simply
obtained a list of terms and their corresponding
</bodyText>
<page confidence="0.984062">
361
</page>
<note confidence="0.7057935">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 361–365,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.74773975">
CUI identifier from the training set and marked
any appearance of those terms in the evaluation
set. This simple method was improved with some
additional extensions:
</bodyText>
<listItem confidence="0.9860436875">
• Improving precision. In order to reduce the
number of false positives (FP), we applied
first the EM system to the training set it-
self. This process helped to measure FPs,
for example, blood gave 184 FPs and 2 true
positives (TPs). For the sake of not hurting
the recall, we allowed the system to detect
only those terms where TP &gt; FP, that is,
“blood” would not be classified as disorder.
• Treatment of discontinuous terms. For
these terms, our system performed a soft-
matching comparison allowing a limited vari-
ation for the text comprised between the
term elements (for example “right atrium is
mildly/moderately dilated”). These patterns
were tuned manually.
</listItem>
<subsectionHeader confidence="0.999559">
2.2 Adapting Freeling to the Medical Domain
</subsectionHeader>
<bodyText confidence="0.999960851851852">
Freeling is an open-source multilingual language
processing library providing a wide range of ana-
lyzers for several languages (Padr´o et al., 2010),
Spanish and English among others. We had al-
ready adapted Freeling to the medical domain in
Spanish (Oronoz et al., 2013), so we used our pre-
vious experience to adapt the English version to
the same domain. For the sake of clarity, we will
refer to this system as FreeMed henceforth.
The linguistic resources (lexica, grammars,...)
in Freeling can be modified, so we took advantage
of this flexibility extending two standard Freel-
ing dictionaries: a basic dictionary of terms con-
sisting of a unique word, and a multiword-term
dictionary. Both of them were enriched with a
dictionary of medical abbreviations1 and with the
Systematized Nomenclature of Medicine Clinical
Terms (SNOMED CT) version dated 31st of July
of 2013. In addition to the changes in the lexica,
we added regular expressions in the tokenizer to
recognize medical terms as “Alzheimer’s disease”
as a unique term.
In our approach, the system distinguishes be-
tween morphology and syntax on one side and
semantics on the other side. First, on the mor-
phosyntactic processing, our system only catego-
rizes word-forms using their basic part-of-speech
</bodyText>
<footnote confidence="0.831646">
1http://www.jdmd.com/abbreviations-glossary.asp
</footnote>
<bodyText confidence="0.999882568627451">
(POS) categories. Next, the semantic distinctions
are applied (the identification of the term as sub-
stance, disorder, procedure,...). Following this
approach, whenever the specific term on the new
domain (biomedicine in this case) was already in
Freeling’s standard dictionaries, the specific en-
tries will not be added to the lexicon. Instead,
medical meanings are added in a later semantic
tagging stage. For example: the widely used term
“fever”, as common noun, was not added to the
lexicon but its semantic class is given in a sec-
ond stage. Only very specific terms not appear-
ing in the lexica as, for instance, “diskospondyli-
tis” were inserted. This solution helps to avoid
an explosion of ambiguity in the morphosyntactic
analysis and, besides, it enables a clear separation
between morphosyntax and semantics.
In figure 1 the results of both levels of anal-
ysis, morphosyntactic and semantic, are shown.
The linguistic and medical information of medical
texts is stored in the Kyoto Annotation Format or
KAF (Bosma et al., 2009) that is based in the eX-
tended Markup Language (XML). In this example
the term aneurysm is analyzed as NN (meaning
noun) and it is semantically categorized as mor-
phological abnormality and disorder.
SNOMED CT is part of the Metathesaurus,
one of the elements of the Unified Medical Lan-
guage System (UMLS). We used the Metathe-
saurus vocabulary database to extract the map-
ping between SNOMED CT’s concept identifiers
and their corresponding UMLS’s concept unique
identifier (CUI). All the medical terms appearing
in SNOMED CT and analyzed with FreeMed are
tagged with both identifiers. For instance, the term
aneurysm in figure 1 has the 85659009 SNOMED
CT identifier when the term is classified in the
morphological abnormality content hierarchy and
the 432119003 identifier as disorder. Both are
linked to the same concept identifier, C0002940,
in UMLS. This mapping has been used for Task
B, whenever the CUI is the same in all the analy-
sis of the same term.
All the terms from all the 19 content hierarchies
of SNOMED CT were tagged with semantic infor-
mation in the provided texts.
The training corpus was linguistically analyzed
and its format was changed from XML to the for-
mat specified at the shared task. After a manual
inspection of the results and the Gold Standard,
some selection of terms was performed:
</bodyText>
<page confidence="0.974444">
362
</page>
<figure confidence="0.867964666666667">
&lt;term tid=”t241” lemma=”aneurysm” pos=”NN”&gt;
&lt;extRefs&gt;
&lt;extRef resource=”SCT 20130731” reference=”85659009”
reftype=”morphologic abnormality” &gt;
&lt;extRef resource=”UMLS-2010AB” reference=”C0002940”/ &gt;
&lt;/extRef&gt;
&lt;extRef resource=”SCT 20130731” reference=”432119003”
reftype=”disorder” &gt;
&lt;extRef resource=”UMLS-2010AB” reference=”C0002940”/&gt;
&lt;/extRef&gt;
&lt;/extRefs&gt;
&lt;/term&gt;
</figure>
<figureCaption confidence="0.998283">
Figure 1: Analysis with augmented information.
</figureCaption>
<listItem confidence="0.995634866666667">
• Selection and combination of semantic
classes. All the terms from the disor-
der semantic class (for example “Hypothy-
roidism”) and from the finding class (for in-
stance “headache”) are chosen, as well as
some tag combinations (see figure 1). After
analyzing the train corpus we decided to join
into a unique term a body structure immedi-
ately followed by a disorder/finding. In this
way, we identify terms as “MCA aneurysm”
that are composed of the MCA abbreviation
(meaning “middle cerebral artery”) and the
inmediately following “aneurysm” disorder.
• Filtering. Not all the terms from the men-
tioned SNOMED CT hierarchies are identi-
</listItem>
<bodyText confidence="0.906760846153846">
fied as disorders in the Gold Standard. Some
terms are discarded following these criteria:
i) findings describing personal situations (e.g.
“alcoholic”), ii) findings describing current
situations (e.g. “awake”), iii) findings with
words indicating a negation or normal situ-
ation (e.g. “stable blood pressure”) and iv)
too general terms (e.g. “problems”).
The medical terms indicating disorders that are
linked to more than one CUI identifier, were
tagged as CUI-less. That is, we did not perform
any CUI disambiguation.
In subsequent iterations and after analyzing our
misses, new terms and term variations (Hina et
al., 2013) are added to the lexica in Freeling with
the restriction that, at least, one synonym should
appear in SNOMED CT. Thus, equivalent forms
were created for all the terms indicating a cancer,
a tumor, a syndrome, or a specific disease. For in-
stance, variants for the term “cancer of colon” and
with the same SNOMED CT concept identifier
(number 363406005) are created with the forms
“colon cancer”, “cancer of the colon” and “can-
cer in colon”. Some abbreviation variations found
in the Gold Standard are added in the lexica too,
following the same criteria.
</bodyText>
<subsectionHeader confidence="0.997861">
2.3 Perceptron Sequential Tagger
</subsectionHeader>
<bodyText confidence="0.99984525">
This system uses a Global Linear Model (GLM),
a sequential tagger using the perceptron algorithm
(Collins, 2002), that relies on Viterbi decoding of
training examples combined with simple additive
updates. The algorithm is competitive to other op-
tions such as maximum-entropy taggers or CRFs.
The original textual files are firstly processed by
FreeMed, and then the tagger uses all the available
information to assign tags to the text. Each token
contains information about the word form, lemma,
part of speech, and SNOMED CT category.
Our GLM system only deals with Task A, and
it will not tackle the problem of concept normal-
ization, due to time constraints. In this respect, for
Task B the GLM system will simply return the first
SNOMED CT category given by FreeMed. This
does not mean that GLM and FreeMed will give
the same result for Task B, as the GLM system
first categorizes each element as a disease, and it
gives a CUI only when that element is identified.
</bodyText>
<subsectionHeader confidence="0.984358">
2.4 Combinations
</subsectionHeader>
<bodyText confidence="0.99999225">
The previous subsections presented three differ-
ent approaches to the problem that obtain com-
parable scores (see table 1). In the area of auto-
matic tagging, there are several works that com-
bine disparate systems, usually getting good re-
sults. For this reason, we tried the simplest ap-
proach of merging the outputs of the three individ-
ual systems into a single file.
</bodyText>
<sectionHeader confidence="0.999952" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.999939933333333">
Table 1 presents the results of the individual and
combined systems on the development set. Look-
ing at the individual systems on Task A, we can see
that all of them obtain a similar f-score, although
there are important differences in terms of preci-
sion and recall. Contrary to our initial intuition,
the FreeMed system, based on dictionaries and on-
tologies, gives the best precision and the lowest re-
call. In principle, having SNOMED CT as a base,
we could expect that the coverage would be more
complete (attaining the highest recall). However,
the results show that there is a gap between the
writing of the standard SNOMED CT terms and
the terms written by doctors in their notes. On the
other hand, the sequential tagger gives the best re-
</bodyText>
<page confidence="0.997411">
363
</page>
<table confidence="0.984425428571429">
Task A Task B
Strict
Relaxed
Strict Relaxed
System Precision Recall F-Score Precision Recall F-Score Accuracy
INDIVIDUAL SYSTEMS
Exact Match (EM) 0.804 0.505 0.620 0.958 0.604 0.740 0.479 0.948
FreeMed 0.822 0.501 0.622 0.947 0.578 0.718 0.240 0.479
GLM 0.715 0.570 0.634 0.908 0.735 0.813 0.298 0.522
COMBINATIONS
FreeMed + EM 0.766 0.652 0.704 0.936 0.754 0.835 0.556 0.855
FreeMed + GLM 0.689 0.668 0.678 0.903 0.790 0.843 0.345 0.518
EM + GLM 0.680 0.679 0.679 0.907 0.819 0.861 0.398 0.598
FreeMed + EM + GLM 0.659 0.724 0.690 0.899 0.845 0.871 0.421 0.584
</table>
<tableCaption confidence="0.998732">
Table 1: Results of the different systems on the development set.
</tableCaption>
<table confidence="0.9996895">
Task A Task B
Strict Relaxed Strict Relaxed
System Precision Recall F-Score Precision Recall F-Score Accuracy
FreeMed + EM 0.729 0.701 0.715 0.885 0.808 0.845 0.604 0.862
FreeMed + EM + GLM 0.681 0.786 0.730 0.872 0.890 0.881 0.439 0.558
Best system 0.843 0.786 0.813 0.936 0.866 0.900 0.741 0.873
</table>
<tableCaption confidence="0.999849">
Table 2: Results on the test set.
</tableCaption>
<bodyText confidence="0.999908073170732">
call. Since the tagger uses both contextual words
and prefixes and suffixes as features for learning,
this method has proven helpful for the recognition
of terms that do not appear in the training data (see
the difference with the EM approach).
Looking at the different combinations in table 1,
we see that two approaches work best, either com-
bining FreeMed and EM, or combining the three
individual systems. The inclusion of GLM results
in the best coverage, but at the expense of preci-
sion. On the other hand, combining FreeMed and
EM gives a better precision but lower coverage.
As pointed out by Collins (2002), the results of
the perceptron tagger are competitive with respect
to other statistical approaches such as CRFs (Zuc-
con et al., 2013; Bodnari et al., 2013; Gung, 2013;
Hervas et al., 2013; Leaman et al., 2013).
Regarding Task B, we can see that the EM sys-
tem is by far the most accurate, while FreeMed
is well below its a priori potential. The reason of
this low result is mainly due to the high ambiguity
found on the output of the SNOMED CT tagger, as
many terms are associated with more than one CUI
and, consequently, are left untagged. This problem
deserves future work on automatic semantic dis-
ambiguation. On the combinations, FreeMed and
EM together give the best result. However, as we
told before, the GLM system was only trained for
Task A, so it is not surprising to see that its results
deteriorate the accuracy in Task B.
We chose these best two combinations for the
evaluation on the test set (using training and de-
velopment for experimentation or training), which
are presented in table 2. Here we can see that re-
sults on the development also hold on the test set.
Given the unsophisticated approach to combine
the systems, we can figure out more elaborated so-
lutions, such as majority or weighted voting, or
even more, the definition of a machine learning
classifier to select the best system for every pro-
posed term. These ideas are left for future work.
</bodyText>
<sectionHeader confidence="0.999685" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999928071428572">
We have presented the IxaMed approach, com-
posed of three systems that are based on exact
match, linguistic and knowledge repositories, and
a statistical tagger, respectively. The results of in-
dividual systems are comparable, with differences
in precision and recall. We also tested a sim-
ple combination of the systems, which proved to
give significant improvements over each individ-
ual system. The results are competitive, although
still far from the winning system.
For future work, we plan to further improve the
individual systems. Besides, we hope that the ex-
perimentation with new combination approaches
will offer room for improvement.
</bodyText>
<sectionHeader confidence="0.996518" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9985206">
This work was partially supported by the Euro-
pean Commission (325099 and SEP-210087649),
the Spanish Ministry of Science and Innovation
(TIN2012-38584-C06-02) and the Industry of the
Basque Government (IT344-10).
</bodyText>
<page confidence="0.998118">
364
</page>
<sectionHeader confidence="0.989343" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99958">
Alan R Aronson and Francois-Michel Lang. 2010. An
overview of MetaMap: historical perspective and re-
cent advances. Journal of the American Medical In-
formatics Association (JAMIA), 17:229–236.
Andreea Bodnari, Louise Deleger, Thomas Lavergne,
Aurelie Neveol, and Pierre Zweigenbaum. 2013.
A Supervised Named-Entity Extraction System for
Medical Text. In Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, September.
Wauter Bosma, Piek Vossen, Aitor Soroa, German
Rigau, Maurizio Tesconi, Andrea Marchetti, Mon-
ica Monachini, and Carlo Aliprandi. 2009. KAF: a
Generic Semantic Annotation Format. In Proceed-
ings of the 5th International Conference on Gener-
ative Approaches to the Lexicon GL, pages 17–19,
Septembre.
Michael Collins. 2002. Discriminative Training Meth-
ods for Hidden Markov Models: Theory and Ex-
periments with Perceptron Algorithms. In Proceed-
ings of the 2002 Conference on Empirical Methods
in Natural Language Processing, pages 1–8. Asso-
ciation for Computational Linguistics, July.
James Gung. 2013. Using Relations for Identification
and Normalization of Disorders: Team CLEAR in
the ShARe/CLEF 2013 eHealth Evaluation Lab. In
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, September.
Lucia Hervas, Victor Martinez, Irene Sanchez, and Al-
berto Diaz. 2013. UCM at CLEF eHealth 2013
Shared Task1. In Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, September.
Saman Hina, Eric Atwell, and Owen Johnson. 2013.
SnoMedTagger: A semantic tagger for medical nar-
ratives. In Conference on Intelligent Text Processing
and Computational Linguistics (CICLING).
Robert Leaman, Ritu Khare, and Zhiyong Lu. 2013.
NCBI at 2013 ShARe/CLEF eHealth Shared Task:
Disorder Normalization in Clinical Notes with
Dnorm. In Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, September.
Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jon-
nalagadda, and Sunghwan Sohn. 2013. Integrated
cTAKES for Concept Mention Detection and Nor-
malization. In Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, September.
Maite Oronoz, Arantza Casillas, Koldo Gojenola, and
Alicia Perez. 2013. Automatic Annotation of
Medical Records in Spanish with Disease, Drug
and Substance Names. In Lecture Notes in Com-
puter Science, 8259. Progress in Pattern Recogni-
tion, ImageAnalysis, ComputerVision, and Applica-
tions 18th Iberoamerican Congress, CIARP 2013,
Havana, Cuba, November 20-23.
Lluis Padr´o, Samuel Reese, Eneko Agirre, and Aitor
Soroa. 2010. Semantic Services in Freeling 2.1:
WordNet and UKB. In Global Wordnet Conference,
Mumbai, India.
Sameer Pradhan, Noemie Elhadad, Brett R. South,
David Martinez, Lee Christensen, Amy Vogel,
Hanna Suominen, Wendy W. Chapman, and Guer-
gana Savova. 2013. Task 1: ShARe/CLEF eHealth
Evaluation Lab 2013. In Online Working Notes
of the CLEF 2013 Evaluation Labs and Workshop,
September.
Chunye Wang and Ramakrishna Akella. 2013. UCSCs
System for CLEF eHealth 2013 Task 1. In Online
Working Notes of the CLEF 2013 Evaluation Labs
and Workshop, September.
Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan,
Sen Na, Qinan Hu, and Yaohai Huang. 2013. Com-
bining MetaMap and cTAKES in Disorder Recogni-
tion: THCIB at CLEF eHealth Lab 2013 Task 1. In
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, September.
Guido Zuccon, Alexander Holloway, Bevan Koop-
man, and Anthony Nguyen. 2013. Identify Disor-
ders in Health Records using Conditional Random
Fields and Metamap AEHRC at ShARe/CLEF 2013
eHealth Evaluation Lab Task 1. In Online Working
Notes of the CLEF 2013 Evaluation Labs and Work-
shop, September.
</reference>
<page confidence="0.999087">
365
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.710875">
<title confidence="0.9951865">IxaMed: Applying Freeling and a Perceptron Sequential Tagger at Shared Task on Analyzing Clinical Texts</title>
<author confidence="0.919071">Koldo Gojenola</author>
<author confidence="0.919071">Maite Oronoz</author>
<author confidence="0.919071">Alicia P´erez</author>
<author confidence="0.919071">Arantza Casillas</author>
<affiliation confidence="0.797227">IXA Taldea</affiliation>
<web confidence="0.989398">http://ixa.si.ehu.es</web>
<abstract confidence="0.995293375">paper presents the results of the Ixat the SemEval-2014 Shared Task 7 on Analyzing Clinical Texts. We have developed three different systems based on: a) exact match, b) a general-purpose morphosyntactic analyzer enriched with the SNOMED CT terminology content, and c) a perceptron sequential tagger based on a Global Linear Model. The three individual systems result in similar f-score while they vary in their precision and recall. We have also tried direct combinations of the individual systems, obtaining considerable improvements in performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
<author>Francois-Michel Lang</author>
</authors>
<title>An overview of MetaMap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association (JAMIA),</journal>
<pages>17--229</pages>
<contexts>
<context position="2175" citStr="Aronson and Lang, 2010" startWordPosition="320" endWordPosition="323">improvements in performance. These approaches are representative of different solutions that have been proposed in the literature This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ (Pradhan et al., 2013), which can be broadly classified in the following types: • Knowledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or m</context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>Alan R Aronson and Francois-Michel Lang. 2010. An overview of MetaMap: historical perspective and recent advances. Journal of the American Medical Informatics Association (JAMIA), 17:229–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreea Bodnari</author>
<author>Louise Deleger</author>
<author>Thomas Lavergne</author>
<author>Aurelie Neveol</author>
<author>Pierre Zweigenbaum</author>
</authors>
<title>A Supervised Named-Entity Extraction System for Medical Text.</title>
<date>2013</date>
<booktitle>In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2598" citStr="Bodnari et al., 2013" startWordPosition="393" endWordPosition="396">owledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the following subsections. 2.1 Ex</context>
<context position="14074" citStr="Bodnari et al., 2013" startWordPosition="2251" endWordPosition="2254">ion of terms that do not appear in the training data (see the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic disambiguation. On the combinations, FreeMed and EM together give the best result. However, as we told before, the GLM system was only trained for Task A, so</context>
</contexts>
<marker>Bodnari, Deleger, Lavergne, Neveol, Zweigenbaum, 2013</marker>
<rawString>Andreea Bodnari, Louise Deleger, Thomas Lavergne, Aurelie Neveol, and Pierre Zweigenbaum. 2013. A Supervised Named-Entity Extraction System for Medical Text. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wauter Bosma</author>
<author>Piek Vossen</author>
<author>Aitor Soroa</author>
<author>German Rigau</author>
<author>Maurizio Tesconi</author>
<author>Andrea Marchetti</author>
<author>Monica Monachini</author>
<author>Carlo Aliprandi</author>
</authors>
<title>KAF: a Generic Semantic Annotation Format.</title>
<date>2009</date>
<booktitle>In Proceedings of the 5th International Conference on Generative Approaches to the Lexicon GL,</booktitle>
<pages>17--19</pages>
<contexts>
<context position="6658" citStr="Bosma et al., 2009" startWordPosition="1044" endWordPosition="1047">le: the widely used term “fever”, as common noun, was not added to the lexicon but its semantic class is given in a second stage. Only very specific terms not appearing in the lexica as, for instance, “diskospondylitis” were inserted. This solution helps to avoid an explosion of ambiguity in the morphosyntactic analysis and, besides, it enables a clear separation between morphosyntax and semantics. In figure 1 the results of both levels of analysis, morphosyntactic and semantic, are shown. The linguistic and medical information of medical texts is stored in the Kyoto Annotation Format or KAF (Bosma et al., 2009) that is based in the eXtended Markup Language (XML). In this example the term aneurysm is analyzed as NN (meaning noun) and it is semantically categorized as morphological abnormality and disorder. SNOMED CT is part of the Metathesaurus, one of the elements of the Unified Medical Language System (UMLS). We used the Metathesaurus vocabulary database to extract the mapping between SNOMED CT’s concept identifiers and their corresponding UMLS’s concept unique identifier (CUI). All the medical terms appearing in SNOMED CT and analyzed with FreeMed are tagged with both identifiers. For instance, th</context>
</contexts>
<marker>Bosma, Vossen, Soroa, Rigau, Tesconi, Marchetti, Monachini, Aliprandi, 2009</marker>
<rawString>Wauter Bosma, Piek Vossen, Aitor Soroa, German Rigau, Maurizio Tesconi, Andrea Marchetti, Monica Monachini, and Carlo Aliprandi. 2009. KAF: a Generic Semantic Annotation Format. In Proceedings of the 5th International Conference on Generative Approaches to the Lexicon GL, pages 17–19, Septembre.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="10349" citStr="Collins, 2002" startWordPosition="1614" endWordPosition="1615">should appear in SNOMED CT. Thus, equivalent forms were created for all the terms indicating a cancer, a tumor, a syndrome, or a specific disease. For instance, variants for the term “cancer of colon” and with the same SNOMED CT concept identifier (number 363406005) are created with the forms “colon cancer”, “cancer of the colon” and “cancer in colon”. Some abbreviation variations found in the Gold Standard are added in the lexica too, following the same criteria. 2.3 Perceptron Sequential Tagger This system uses a Global Linear Model (GLM), a sequential tagger using the perceptron algorithm (Collins, 2002), that relies on Viterbi decoding of training examples combined with simple additive updates. The algorithm is competitive to other options such as maximum-entropy taggers or CRFs. The original textual files are firstly processed by FreeMed, and then the tagger uses all the available information to assign tags to the text. Each token contains information about the word form, lemma, part of speech, and SNOMED CT category. Our GLM system only deals with Task A, and it will not tackle the problem of concept normalization, due to time constraints. In this respect, for Task B the GLM system will si</context>
<context position="13919" citStr="Collins (2002)" startWordPosition="2227" endWordPosition="2228">call. Since the tagger uses both contextual words and prefixes and suffixes as features for learning, this method has proven helpful for the recognition of terms that do not appear in the training data (see the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic di</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1–8. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Gung</author>
</authors>
<title>Using Relations for Identification and Normalization of Disorders:</title>
<date>2013</date>
<booktitle>Team CLEAR in the ShARe/CLEF 2013 eHealth Evaluation Lab. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2610" citStr="Gung, 2013" startWordPosition="397" endWordPosition="398">proach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the following subsections. 2.1 Exact Match Th</context>
<context position="14086" citStr="Gung, 2013" startWordPosition="2255" endWordPosition="2256">ot appear in the training data (see the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic disambiguation. On the combinations, FreeMed and EM together give the best result. However, as we told before, the GLM system was only trained for Task A, so it is not s</context>
</contexts>
<marker>Gung, 2013</marker>
<rawString>James Gung. 2013. Using Relations for Identification and Normalization of Disorders: Team CLEAR in the ShARe/CLEF 2013 eHealth Evaluation Lab. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Hervas</author>
<author>Victor Martinez</author>
<author>Irene Sanchez</author>
<author>Alberto Diaz</author>
</authors>
<date>2013</date>
<booktitle>UCM at CLEF eHealth 2013 Shared Task1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2631" citStr="Hervas et al., 2013" startWordPosition="399" endWordPosition="402"> use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the following subsections. 2.1 Exact Match The system based on Exa</context>
<context position="14107" citStr="Hervas et al., 2013" startWordPosition="2257" endWordPosition="2260"> the training data (see the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic disambiguation. On the combinations, FreeMed and EM together give the best result. However, as we told before, the GLM system was only trained for Task A, so it is not surprising to see that</context>
</contexts>
<marker>Hervas, Martinez, Sanchez, Diaz, 2013</marker>
<rawString>Lucia Hervas, Victor Martinez, Irene Sanchez, and Alberto Diaz. 2013. UCM at CLEF eHealth 2013 Shared Task1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saman Hina</author>
<author>Eric Atwell</author>
<author>Owen Johnson</author>
</authors>
<title>SnoMedTagger: A semantic tagger for medical narratives.</title>
<date>2013</date>
<booktitle>In Conference on Intelligent Text Processing and Computational Linguistics (CICLING).</booktitle>
<contexts>
<context position="9649" citStr="Hina et al., 2013" startWordPosition="1497" endWordPosition="1500">isorders in the Gold Standard. Some terms are discarded following these criteria: i) findings describing personal situations (e.g. “alcoholic”), ii) findings describing current situations (e.g. “awake”), iii) findings with words indicating a negation or normal situation (e.g. “stable blood pressure”) and iv) too general terms (e.g. “problems”). The medical terms indicating disorders that are linked to more than one CUI identifier, were tagged as CUI-less. That is, we did not perform any CUI disambiguation. In subsequent iterations and after analyzing our misses, new terms and term variations (Hina et al., 2013) are added to the lexica in Freeling with the restriction that, at least, one synonym should appear in SNOMED CT. Thus, equivalent forms were created for all the terms indicating a cancer, a tumor, a syndrome, or a specific disease. For instance, variants for the term “cancer of colon” and with the same SNOMED CT concept identifier (number 363406005) are created with the forms “colon cancer”, “cancer of the colon” and “cancer in colon”. Some abbreviation variations found in the Gold Standard are added in the lexica too, following the same criteria. 2.3 Perceptron Sequential Tagger This system </context>
</contexts>
<marker>Hina, Atwell, Johnson, 2013</marker>
<rawString>Saman Hina, Eric Atwell, and Owen Johnson. 2013. SnoMedTagger: A semantic tagger for medical narratives. In Conference on Intelligent Text Processing and Computational Linguistics (CICLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Ritu Khare</author>
<author>Zhiyong Lu</author>
</authors>
<date>2013</date>
<booktitle>NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with Dnorm. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2653" citStr="Leaman et al., 2013" startWordPosition="403" endWordPosition="407">ictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the following subsections. 2.1 Exact Match The system based on Exact Match (EM) simply o</context>
<context position="14129" citStr="Leaman et al., 2013" startWordPosition="2261" endWordPosition="2264">ee the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic disambiguation. On the combinations, FreeMed and EM together give the best result. However, as we told before, the GLM system was only trained for Task A, so it is not surprising to see that its results deteriora</context>
</contexts>
<marker>Leaman, Khare, Lu, 2013</marker>
<rawString>Robert Leaman, Ritu Khare, and Zhiyong Lu. 2013. NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with Dnorm. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongfang Liu</author>
<author>Kavishwar Wagholikar</author>
<author>Siddhartha Jonnalagadda</author>
<author>Sunghwan Sohn</author>
</authors>
<title>Integrated cTAKES for Concept Mention Detection and Normalization.</title>
<date>2013</date>
<booktitle>In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2808" citStr="Liu et al., 2013" startWordPosition="430" endWordPosition="433"> et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the following subsections. 2.1 Exact Match The system based on Exact Match (EM) simply obtained a list of terms and their corresponding 361 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 361–365, Dub</context>
</contexts>
<marker>Liu, Wagholikar, Jonnalagadda, Sohn, 2013</marker>
<rawString>Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jonnalagadda, and Sunghwan Sohn. 2013. Integrated cTAKES for Concept Mention Detection and Normalization. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Oronoz</author>
<author>Arantza Casillas</author>
<author>Koldo Gojenola</author>
<author>Alicia Perez</author>
</authors>
<title>Automatic Annotation of Medical Records in Spanish with Disease, Drug and Substance Names.</title>
<date>2013</date>
<booktitle>In Lecture Notes in Computer Science, 8259. Progress in Pattern Recognition, ImageAnalysis, ComputerVision, and Applications 18th Iberoamerican Congress, CIARP 2013,</booktitle>
<location>Havana, Cuba,</location>
<contexts>
<context position="4585" citStr="Oronoz et al., 2013" startWordPosition="718" endWordPosition="721">ld not be classified as disorder. • Treatment of discontinuous terms. For these terms, our system performed a softmatching comparison allowing a limited variation for the text comprised between the term elements (for example “right atrium is mildly/moderately dilated”). These patterns were tuned manually. 2.2 Adapting Freeling to the Medical Domain Freeling is an open-source multilingual language processing library providing a wide range of analyzers for several languages (Padr´o et al., 2010), Spanish and English among others. We had already adapted Freeling to the medical domain in Spanish (Oronoz et al., 2013), so we used our previous experience to adapt the English version to the same domain. For the sake of clarity, we will refer to this system as FreeMed henceforth. The linguistic resources (lexica, grammars,...) in Freeling can be modified, so we took advantage of this flexibility extending two standard Freeling dictionaries: a basic dictionary of terms consisting of a unique word, and a multiword-term dictionary. Both of them were enriched with a dictionary of medical abbreviations1 and with the Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT) version dated 31st of July of 2013</context>
</contexts>
<marker>Oronoz, Casillas, Gojenola, Perez, 2013</marker>
<rawString>Maite Oronoz, Arantza Casillas, Koldo Gojenola, and Alicia Perez. 2013. Automatic Annotation of Medical Records in Spanish with Disease, Drug and Substance Names. In Lecture Notes in Computer Science, 8259. Progress in Pattern Recognition, ImageAnalysis, ComputerVision, and Applications 18th Iberoamerican Congress, CIARP 2013, Havana, Cuba, November 20-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lluis Padr´o</author>
<author>Samuel Reese</author>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<date>2010</date>
<booktitle>Semantic Services in Freeling 2.1: WordNet and UKB. In Global Wordnet Conference,</booktitle>
<location>Mumbai, India.</location>
<marker>Padr´o, Reese, Agirre, Soroa, 2010</marker>
<rawString>Lluis Padr´o, Samuel Reese, Eneko Agirre, and Aitor Soroa. 2010. Semantic Services in Freeling 2.1: WordNet and UKB. In Global Wordnet Conference, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Noemie Elhadad</author>
<author>Brett R South</author>
<author>David Martinez</author>
<author>Lee Christensen</author>
<author>Amy Vogel</author>
<author>Hanna Suominen</author>
<author>Wendy W Chapman</author>
<author>Guergana Savova</author>
</authors>
<date>2013</date>
<booktitle>Task 1: ShARe/CLEF eHealth Evaluation Lab 2013. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="1916" citStr="Pradhan et al., 2013" startWordPosition="281" endWordPosition="284"> with other approaches, while the other two represent two alternative approaches based on knowledge organized in dictionaries/ontologies and machine learning, respectively. We also tried direct combinations of the individual systems, obtaining considerable improvements in performance. These approaches are representative of different solutions that have been proposed in the literature This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ (Pradhan et al., 2013), which can be broadly classified in the following types: • Knowledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HM</context>
</contexts>
<marker>Pradhan, Elhadad, South, Martinez, Christensen, Vogel, Suominen, Chapman, Savova, 2013</marker>
<rawString>Sameer Pradhan, Noemie Elhadad, Brett R. South, David Martinez, Lee Christensen, Amy Vogel, Hanna Suominen, Wendy W. Chapman, and Guergana Savova. 2013. Task 1: ShARe/CLEF eHealth Evaluation Lab 2013. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunye Wang</author>
<author>Ramakrishna Akella</author>
</authors>
<date>2013</date>
<booktitle>UCSCs System for CLEF eHealth 2013 Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2260" citStr="Wang and Akella, 2013" startWordPosition="335" endWordPosition="338">s that have been proposed in the literature This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ (Pradhan et al., 2013), which can be broadly classified in the following types: • Knowledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce </context>
</contexts>
<marker>Wang, Akella, 2013</marker>
<rawString>Chunye Wang and Ramakrishna Akella. 2013. UCSCs System for CLEF eHealth 2013 Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Xiaoshi Zhong</author>
<author>Peng Liu</author>
<author>Cheng Tan</author>
<author>Sen Na</author>
<author>Qinan Hu</author>
<author>Yaohai Huang</author>
</authors>
<title>Combining MetaMap and cTAKES in Disorder Recognition:</title>
<date>2013</date>
<booktitle>THCIB at CLEF eHealth Lab 2013 Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2205" citStr="Xia et al., 2013" startWordPosition="326" endWordPosition="329">pproaches are representative of different solutions that have been proposed in the literature This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ (Pradhan et al., 2013), which can be broadly classified in the following types: • Knowledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 20</context>
</contexts>
<marker>Xia, Zhong, Liu, Tan, Na, Hu, Huang, 2013</marker>
<rawString>Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan, Sen Na, Qinan Hu, and Yaohai Huang. 2013. Combining MetaMap and cTAKES in Disorder Recognition: THCIB at CLEF eHealth Lab 2013 Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Zuccon</author>
<author>Alexander Holloway</author>
<author>Bevan Koopman</author>
<author>Anthony Nguyen</author>
</authors>
<date>2013</date>
<booktitle>Identify Disorders in Health Records using Conditional Random Fields and Metamap AEHRC at ShARe/CLEF 2013 eHealth Evaluation Lab Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop,</booktitle>
<contexts>
<context position="2576" citStr="Zuccon et al., 2013" startWordPosition="389" endWordPosition="392">following types: • Knowledge-based. This approach makes use of large-scale dictionaries and ontologies, that are sometimes integrated in general tools adapted to the clinical domain, as MetaMap (Aronson and Lang, 2010) and cTAKES (Xia et al., 2013). • Rule-based. For example, in (Wang and Akella, 2013) the authors show the use of a rule-based approach on the output of MetaMap. • Statistical techniques. These systems take a training set as input and apply different variants of machine learning, such as sequential taggers based on hidden Markov models (HMMs) or conditional random fields (CRFs) (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). • Combinations. These approaches try to take the advantages of different system types, using methods such as voting or metaclassifiers (Liu et al., 2013). In the rest of the paper, we will first introduce the different systems that we have developed in section 2, presenting the main results in section 3, and ending with the main conclusions. 2 System Description The task of detecting diseases and their corresponding concept unique identifiers (CUI) has been faced using three methods that are described in the followi</context>
<context position="14052" citStr="Zuccon et al., 2013" startWordPosition="2246" endWordPosition="2250">pful for the recognition of terms that do not appear in the training data (see the difference with the EM approach). Looking at the different combinations in table 1, we see that two approaches work best, either combining FreeMed and EM, or combining the three individual systems. The inclusion of GLM results in the best coverage, but at the expense of precision. On the other hand, combining FreeMed and EM gives a better precision but lower coverage. As pointed out by Collins (2002), the results of the perceptron tagger are competitive with respect to other statistical approaches such as CRFs (Zuccon et al., 2013; Bodnari et al., 2013; Gung, 2013; Hervas et al., 2013; Leaman et al., 2013). Regarding Task B, we can see that the EM system is by far the most accurate, while FreeMed is well below its a priori potential. The reason of this low result is mainly due to the high ambiguity found on the output of the SNOMED CT tagger, as many terms are associated with more than one CUI and, consequently, are left untagged. This problem deserves future work on automatic semantic disambiguation. On the combinations, FreeMed and EM together give the best result. However, as we told before, the GLM system was only </context>
</contexts>
<marker>Zuccon, Holloway, Koopman, Nguyen, 2013</marker>
<rawString>Guido Zuccon, Alexander Holloway, Bevan Koopman, and Anthony Nguyen. 2013. Identify Disorders in Health Records using Conditional Random Fields and Metamap AEHRC at ShARe/CLEF 2013 eHealth Evaluation Lab Task 1. In Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>