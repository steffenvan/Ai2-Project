<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.030164">
<title confidence="0.993979">
Using LazyBoosting for Word Sense Disambiguation
</title>
<author confidence="0.991395">
G. Escudero, L. Marquez and G. Rigau
</author>
<affiliation confidence="0.955105">
TALP Research Center
</affiliation>
<address confidence="0.820158666666667">
Universitat Politecnica de Catalunya
Jordi Girona Salgado, 1-3
Barcelona, Catalonia, Spain
</address>
<email confidence="0.997823">
fescudero,lluism,g.rigaul@lsi.upc.es
</email>
<sectionHeader confidence="0.995619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987111111111">
This paper describes the architecture and results of
the TALP system presented at the SENSEVAL-2
exercise for the English lexical—sample task. This
system is based on the LazyBoosting algorithm
for Word Sense Disambiguation (Escudero et al.,
2000), and incorporates some improvements and
adaptations to this task. The evaluation reported
here includes an analysis of the contribution of each
component to the overall system performance.
</bodyText>
<sectionHeader confidence="0.952383" genericHeader="keywords">
1 System Description
</sectionHeader>
<bodyText confidence="0.999985181818182">
The TALP system has been developed on the ba-
sis of LazyBoosting (Escudero et al., 2000), a
boosting—based approach for Word Sense Disam-
biguation. In order to better fit the SENSEVAL-
2 domain, some improvements have been made on
the basic system, including: features that take into
account domain information, an specific treatment
of multiwords, and a hierarchical decomposition of
the multiclass classification problem, similar to that
of (Yarowslcy, 2000). All these issues will be briefly
described in the following sections.
</bodyText>
<subsectionHeader confidence="0.989339">
1.1 LazyBoosting
</subsectionHeader>
<bodyText confidence="0.999828921052631">
The purpose of boosting—based algorithms is to find
a highly accurate classification rule by combining
many weak classifiers (or weak hypotheses), each
of which may be only moderately accurate. The
weak hypotheses are learned sequentially, one at a
time, and, conceptually, at each iteration the weak
hypothesis is biased to classify the examples which
were most difficult to classify by the preceding
weak hypotheses. The learned weak hypotheses are
linearly combined into a single rule called the com-
bined hypothesis.
The particular algorithm used in our system to
perform the classification of senses is the gener-
alized AdaBoost.MH with confidence—rated pre-
dictions (Schapire and Singer, 1999). This algo-
rithm is able to deal straightforwardly with mul-
ticlass multi—label problems, and has been previ-
ously applied, with significant success, to a num-
ber of NLP disambiguation tasks, including, among
others: Part—of—speech tagging and PP—attachment
(Abney et al., 1999), text categorization (Schapire
and Singer, 2000), and shallow parsing (Carreras
and Marquez, 2001). The weak hypotheses used in
this work are decision stumps, which can be seen
as extremely simple decision trees with one internal
node testing the value of a single binary feature (e.g.
&amp;quot;the word dark appears in the context of the word to
be disambiguated?&amp;quot;) and two leaves that give the
prediction of the senses based on the feature value.
The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of
the AdaBoost.MH algorithm, which consists of re-
ducing the feature space that is explored when learn-
ing each weak classifier. More specifically, a small
proportion of attributes are randomly selected and
the best weak rule is selected only among them.
This modification significantly increases the effi-
ciency of the learning process with no loss in ac-
curacy (Escudero et al., 2000).
</bodyText>
<subsectionHeader confidence="0.982474">
1.2 Feature Space
</subsectionHeader>
<bodyText confidence="0.853747857142857">
Three kinds of information have been used to de-
scribe the examples and to train the classifiers.
These features refer to local and topical contexts,
and domain labels.
More particularly, let &amp;quot;... w_2 w_i w w±i
w+2 w+3 ...&amp;quot; be the context of consecutive words
around the word w to be disambiguated, and p±i
</bodyText>
<page confidence="0.998287">
71
</page>
<bodyText confidence="0.998564333333333">
(-3&lt;i&lt;3) be the part—of—speech tag of word w±,1.
Feature patterns referring to local context are the
following 13:
</bodyText>
<equation confidence="0.9798615">
P+&apos;3, P-2, P-1, P+1, P+2, P+3, W-2, W-1, W4-1,
W4-2, (W-21 W-1), (tv—i, w+i), and (w+i, 111+2),
</equation>
<bodyText confidence="0.9999615">
where the last three correspond to collocations of
two consecutive words.
The topical context is formed by CI , , Cm,
which stand for the unordered set of open class
words appearing in a medium—size 21-word win-
dow centered around the target word.
The more innovative use of semantic domain in-
formation is detailed in the next section.
</bodyText>
<subsubsectionHeader confidence="0.661212">
1.2.1 Domain Information
</subsubsectionHeader>
<bodyText confidence="0.999991529411765">
We have enriched the basic set of features by adding
semantic information in the form of domain labels.
These domain labels are computed during a pre-
processing step using the 164 domain labels linked
to the nominal part of WordNet 1.6 (Magnini and
Cavaglia, 2000).
For each training example, a program gathers,
from its context, all nouns and their synsets with
the attached domain labels, and scores them accord-
ing to a certain scoring function. The weights as-
signed by this function depend on the number of
domain labels assigned to each noun and their rel-
ative frequencies in the whole WordNet. The re-
sult of this procedure is the set of domain labels that
achieve a score higher than a certain experimentally
set threshold, which are incorporated as regular fea-
tures for describing the example.
</bodyText>
<subsectionHeader confidence="0.9839885">
1.3 Preprocessing and Hierarchical
Decomposition
</subsectionHeader>
<bodyText confidence="0.998719777777778">
We began this exercise by selecting a representa-
tive sample, containing the most frequent words
of the SENSEVAL-2 training data, and applying
the LazyBoosting system straightforwardly on this
sample. The results achieved after a 10—fold cross—
validation procedure were very bad, mainly due to
the fact that most of the words contain too many
senses and too few examples per sense to induce
reliable classifiers. With the aim of improving the
performance of the learning algorithm, we have re-
duced the number of senses by performing a hier-
archical decomposition of the multiclass problem,
following the idea of (Yarowsky, 2000).
&apos;In this work, the English versions of MACO+ morphologi-
cal analyzer and RELAX part—of—speech tagger have been used
for tagging (Carmona et al., 1998).
Two different simplifications have been carried
out. Firstly, multiword training examples have been
processed separately. During training, multiwords
have been saved into a separate file. At test time,
all examples found in this multiword file are auto-
matically tagged as multiwords. As an example,
the word bar appears in the training set with 22
labels. But only the 10 senses showed in the left
table of figure 1 are single words. The remaining
12 are multiwords which are considered unambigu-
ous (Yarowsky, 1993).
</bodyText>
<figure confidence="0.97674675">
Full senses
Senses Exs.
bar%1:06:04:: 127
bar%1:06:00:: 29
bar%1:06:05:: 28
bar%1:14:00:: 17
bar%1:10:00:: 12
bar%1:06:06:: 11
bar%1: 04: 00: : 5
bar%1:06:02:: 4
bar%1:23:00:: 3
bar%1:17:00:: 1
</figure>
<figureCaption confidence="0.999946">
Figure 1: Sense treatment for word &apos;bar&apos;
</figureCaption>
<bodyText confidence="0.99996212">
Secondly, we have reduced the sense granularity,
by hierarchically decomposing the learning process
in two steps. In the first level, the learning algorithm
is trained to classify between the labels correspond-
ing to the WordNet semantic files, and, addition-
ally the semantic—file labels with less than 10 train-
ing examples are automatically discarded. If less
than two senses remain, no training is performed
and, simply, the Most-frequent-sense Classifier is
applied.
As an example, for the word &apos;bar&apos;, in this first
step the system is trained to classify between the
labels of the top—right table of figure 1. Note that
senses bar%1:04, bar%1:23 and bar%1:17 have
been dropped out because there are not enough
training examples.
In the second level, one classifier is trained for
each of the resulting semantic—file labels of the first
step in order to distinguish between their particular
senses. Note that the same simplifying rules of the
previous level are also applied. For instance, the
bottom—right table of figure 1 shows the labels for
bar%):06, where 02:: has been rejected.
When classifying a new test example, the classi-
fiers of the two levels are applied sequentially. That
</bodyText>
<figure confidence="0.989888">
1st level
Senses Exs.
bar%1:06 199
bar%1:14 17
bar%1:10 12
2nd level
Senses Exs.
127
00:: 29
28
11
</figure>
<page confidence="0.983115">
72
</page>
<bodyText confidence="0.999913777777778">
is, the semantic—file classifier is applied first. Then,
depending on the semantic—file label output by this
classifier, the appropriate 2nd level classifier is se-
lected. The resulting label assigned to the test ex-
ample is formed by the concatenation of the outputs
of both previous levels.
In the official competition, labels &apos;IP and &apos;P&apos;
have been completely ignored. Thus, the examples
labelled with these classes have not been considered
during the training, and no test examples have been
tagged with them.
Despite the simplifying assumptions and the loss
of information, we have observed that all these
changes together significantly improved the accu-
racy on the training set. However, the components
of the system were not tested separately due to the
lack of time. Next section includes some evaluation
about this issue.
</bodyText>
<sectionHeader confidence="0.994239" genericHeader="introduction">
2 Evaluation
</sectionHeader>
<bodyText confidence="0.820381">
The official results achieved by the TALP system
are presented in table 1. The evaluation setting cor-
responding to these results contains all the modifi-
cations explained in the previous sections, including
the hierarchical approach to all words.
Accuracy
fine—grained 59.4%
coarse—grained 67.1%
</bodyText>
<tableCaption confidence="0.989615">
Table 1: Official results
</tableCaption>
<bodyText confidence="0.9998313">
After the SENSEVAL-2 event, we added a very
simple Named—entity Recognizer to the part—of—
speech tagger that was not finished at the time of
the event, but the system continues ignoring the `1J&apos;
label. We also have evaluated which parts of the
system contributed most to the improvement in per-
formance.
Table 2 shows the accuracy results of the
four combinations resulting from using (or not)
domain—label features and hierarchical decomposi-
tion. These results have been calculated over the test
set of SENSEVAL-2.
On the one hand, it becomes clear that enrich-
ing the feature set with domain labels systematically
improves the results in all cases, and that this dif-
ference is specially noticeable in the case of nouns
(over 3 points of improvement). On the other hand,
the use of the hierarchies is unexpectedly useless in
all cases. Although it is productive in some partic-
ular words (3 nouns, 12 verbs and 5 adjectives) the
</bodyText>
<table confidence="0.9984046">
nouns
without dom. with dom.
fine coarse fine coarse
not hien 64.25 72.35 67.90 75.60
hien 63.00 71.10 64.31 71.49
verbs
without dom. with dom.
fine coarse fine coarse
not hien 51.61 61.63 52.10 62.62
hien 50.28 60.80 51.11 61.96
adjectives
without dom. with dom.
fine coarse fine coarse
not hien 66.17 66.17 68.90 68.90
hien 65.35 65.35 68.21 68.21
</table>
<tableCaption confidence="0.9142405">
Table 2: Fine/coarse—grained evaluation for differ-
ent settings and part—of—speech
</tableCaption>
<bodyText confidence="0.99706403125">
overall performance is significantly lower. A fact
that can explain this situation is that the first—level
classifiers do not succeed on classifying semantic—
file labels with high precision (the average accuracy
of first—level classifiers is only slightly over 71%)
and that this important error is dramatically propa-
gated to the second—level, not allowing the greedy
sequential application of classifiers. A possible ex-
planation of this fact is the way semantic classes are
defined in WordNet. Consider for instance work#1
(activity) and work#2 (production), they seem quite
close but a system trying to differentiate among se-
mantic files needs to distinguish among these two
senses. On the other extreme, such a classifier
should collapse house#2 (legislature) with house#4
(family), which are quite different. Of course, join-
ing both situations makes a pretty hard task.
Regarding multiword preprocessing (not in-
cluded in table 2), we have seen that is slightly use-
ful in all cases. It improves the non—hierarchical
scheme with domain information by almost 1 point
in accuracy. By part—of—speech, the improvement is
about 1 point for nouns, 0.1 for verbs and about 2
points for adjectives.
In conclusion, the best results obtained by our
system on this test set correspond to the application
of multiword preprocessing and domain—labels for
all words, but no hierarchical decomposition at all,
achieving a fine—grained accuracy of 61.51% and a
coarse—grained accuracy of 69.00%. We know that
it is not fair to consider these results for compari-
son, since the system is tuned over the test set. Our
</bodyText>
<page confidence="0.996081">
73
</page>
<bodyText confidence="0.999330333333333">
aim is simply to fully inspect the TALP system to
know which parts are useful for a real Word Sense
Disambiguation system.
</bodyText>
<sectionHeader confidence="0.855384" genericHeader="method">
3 Work in progress
</sectionHeader>
<bodyText confidence="0.9999454">
We think that the system presented in this paper still
has a large room for improvement. Among all the
research lines and developments that we are cur-
rently performing on the TALP system for WSD,
we would like to mention the following:
</bodyText>
<listItem confidence="0.953259176470588">
• Tuning the preprocessing procedure with im-
proved versions of the Named—entity Recog-
nizer and Domain taggers.
• Studying in more detail the promising use of
domain information in the feature set.
• Enriching the set of features with the most rel-
evant features used by the SENSEVAL-2 sys-
tems, and using the Minipar2 parser to obtain
dependency and role information.
• Exploring more appropriate ways of making
the hierarchical decomposition, not based on
semantic files, and improve the sequential ap-
plication of classifiers in order to reduce the
cascade errors.
• Using unlabeled data to obtain larger sets of
accurate training data, especially for those
words/senses with few training examples.
</listItem>
<sectionHeader confidence="0.996878" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999936705882353">
This paper has presented the main characteristics
and current performance of the TALP system within
the framework of SENSE VAL-2 English lexical—
sample task competition.
The system is mainly based on LazyBoost-
ing (Escudero et al., 2000), which uses an improved
version of the boosting algorithm AdaBoost.MH to
perform the WSD classification problem.
We used a common set of features including lo-
cal and topical context enriched with domain infor-
mation. We obtained better performance separating
multiword examples and also adding domain infor-
mation.
Due to the small number of examples for train-
ing, we also tried to concentrate evidence reduc-
ing the fine-grained sense distinctions of WordNet.
We perform a hierarchical procedure grouping those
</bodyText>
<footnote confidence="0.990701">
2Available at http://www.cs.ualberta.car lindek .
</footnote>
<bodyText confidence="0.999855875">
senses belonging to the same semantic file, prepro-
cessing multiwords and ignoring &apos;U&apos; label. After
the competition, we have shown that the hierarchi-
cal decomposition fails to improve performance in
this domain, while preprocessing of tnultiwords is
quite useful. The improved system achieved a fine—
grained accuracy of 61.51% and a coarse—grained
accuracy of 69.00%.
</bodyText>
<sectionHeader confidence="0.998333" genericHeader="acknowledgments">
5 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999833714285714">
We would like to thank Xavier Carreras, Lillis
Padro, Victoria Arranz, and the anonymous refer-
ees for their helpful comments. This research has
been partially funded by the European Commission
(NAMIC project, IST-1999-12392) and the Spanish
Research Department (HERMES project, TIC2000-
0335-0O3-02).
</bodyText>
<sectionHeader confidence="0.998472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999847620689655">
S. Abney, R. E. Schapire and Y. Singer. 1999.
Boosting Applied to Tagging and PP—attachment.
In Proceedings of EMNLP—VLC&apos;99.
J. Carmona, S. Cervell, L. Marquez, M. A. Marti,
L. Padr6, R. Placer, H. Rodriguez, M. Taul6
and J. Turmo. 1998. An Environment for Mor-
phosyntactic Processing of Unrestricted Spanish
Text. In Proceedings of LREC&apos;98.
X. Carreras and L. Marquez. 2001. Boosting
Trees for Clause Splitting. In Proceedings of
CoNLL&apos;01.
G. Escudero, L. Marquez and G. Rigau. 2000.
Boosting Applied to Word Sense Disambigua-
tion. In Proceedings of ECML&apos;00.
B. Magnini and G. Cavaglia. 2000. Integrating
Subject Field Codes into WordNet. In Proceed-
ings of LREC&apos;00.
R. E. Schapire and Y. Singer. 1999. Improved
Boosting Algorithms Using Confidence-rated
Predictions. Machine Learning, 37(3):297-336.
R. E. Schapire and Y. Singer. 2000. BoosTexter A
Boosting-based System for Text Categorization.
Machine Learning, 29(3/4):135-168.
D. Yarowsky. 1993. One Sense per Collocation. In
Proceedings of the DARPA Workshop on Human
Language Technology.
D. Yarowsky. 2000. Hierarchical Decision Lists for
Word Sense Disambiguation. Computer and the
Humanities, 34:179-186.
</reference>
<page confidence="0.999134">
74
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001838">
<title confidence="0.999923">Using LazyBoosting for Word Sense Disambiguation</title>
<author confidence="0.847536">G Escudero</author>
<author confidence="0.847536">L Marquez</author>
<author confidence="0.847536">G</author>
<affiliation confidence="0.988554">TALP Research Universitat Politecnica de Jordi Girona Salgado,</affiliation>
<address confidence="0.985084">Barcelona, Catalonia,</address>
<email confidence="0.994627">fescudero,lluism,g.rigaul@lsi.upc.es</email>
<abstract confidence="0.997525590909091">This paper describes the architecture and results of the TALP system presented at the SENSEVAL-2 exercise for the English lexical—sample task. This system is based on the LazyBoosting algorithm for Word Sense Disambiguation (Escudero et al., 2000), and incorporates some improvements and adaptations to this task. The evaluation reported here includes an analysis of the contribution of each component to the overall system performance. 1 System Description The TALP system has been developed on the basis of LazyBoosting (Escudero et al., 2000), a boosting—based approach for Word Sense Disam- In order to better fit the SENSEVAL- 2 domain, some improvements have been made on the basic system, including: features that take into account domain information, an specific treatment of multiwords, and a hierarchical decomposition of the multiclass classification problem, similar to that of (Yarowslcy, 2000). All these issues will be briefly described in the following sections. 1.1 LazyBoosting The purpose of boosting—based algorithms is to find a highly accurate classification rule by combining classifiers weak hypotheses), each of which may be only moderately accurate. The weak hypotheses are learned sequentially, one at a time, and, conceptually, at each iteration the weak hypothesis is biased to classify the examples which were most difficult to classify by the preceding weak hypotheses. The learned weak hypotheses are combined into a single rule called the combined hypothesis. The particular algorithm used in our system to perform the classification of senses is the generalized AdaBoost.MH with confidence—rated predictions (Schapire and Singer, 1999). This algorithm is able to deal straightforwardly with multiclass multi—label problems, and has been previously applied, with significant success, to a number of NLP disambiguation tasks, including, among others: Part—of—speech tagging and PP—attachment (Abney et al., 1999), text categorization (Schapire and Singer, 2000), and shallow parsing (Carreras and Marquez, 2001). The weak hypotheses used in work are stumps, can be seen as extremely simple decision trees with one internal node testing the value of a single binary feature (e.g. word in the context of the word to be disambiguated?&amp;quot;) and two leaves that give the prediction of the senses based on the feature value. The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of the AdaBoost.MH algorithm, which consists of reducing the feature space that is explored when learning each weak classifier. More specifically, a small proportion of attributes are randomly selected and the best weak rule is selected only among them. This modification significantly increases the efficiency of the learning process with no loss in accuracy (Escudero et al., 2000). 1.2 Feature Space Three kinds of information have been used to describe the examples and to train the classifiers. These features refer to local and topical contexts, and domain labels. More particularly, let &amp;quot;... w_2 w_i w w±i w+2 w+3 ...&amp;quot; be the context of consecutive words the word w to be disambiguated, and 71 be the part—of—speech tag of word Feature patterns referring to local context are the following 13: P-2, P+2, P+3, W-1, (W-21 W-1), w+i), and (w+i, where the last three correspond to collocations of two consecutive words. topical context is formed by CI , , which stand for the unordered set of open class words appearing in a medium—size 21-word window centered around the target word. The more innovative use of semantic domain information is detailed in the next section. 1.2.1 Domain Information We have enriched the basic set of features by adding semantic information in the form of domain labels. domain labels are computed during preprocessing step using the 164 domain labels linked to the nominal part of WordNet 1.6 (Magnini and Cavaglia, 2000). For each training example, a program gathers, from its context, all nouns and their synsets with the attached domain labels, and scores them according to a certain scoring function. The weights assigned by this function depend on the number of domain labels assigned to each noun and their relative frequencies in the whole WordNet. The result of this procedure is the set of domain labels that achieve a score higher than a certain experimentally set threshold, which are incorporated as regular features for describing the example. 1.3 Preprocessing and Hierarchical Decomposition We began this exercise by selecting a representative sample, containing the most frequent words of the SENSEVAL-2 training data, and applying the LazyBoosting system straightforwardly on this sample. The results achieved after a 10—fold cross— validation procedure were very bad, mainly due to the fact that most of the words contain too many senses and too few examples per sense to induce reliable classifiers. With the aim of improving the performance of the learning algorithm, we have reduced the number of senses by performing a hierarchical decomposition of the multiclass problem, following the idea of (Yarowsky, 2000). &apos;In this work, the English versions of MACO+ morphological analyzer and RELAX part—of—speech tagger have been used for tagging (Carmona et al., 1998). Two different simplifications have been carried out. Firstly, multiword training examples have been processed separately. During training, multiwords have been saved into a separate file. At test time, all examples found in this multiword file are automatically tagged as multiwords. As an example, word in the training set with 22 labels. But only the 10 senses showed in the left table of figure 1 are single words. The remaining 12 are multiwords which are considered unambiguous (Yarowsky, 1993). Full senses Senses Exs.</abstract>
<phone confidence="0.719175444444444">bar%1:06:04:: 127 bar%1:06:00:: 29 bar%1:06:05:: 28 bar%1:14:00:: 17 bar%1:10:00:: 12 bar%1:06:06:: 11 bar%1: 04: 00: : 5 bar%1:06:02:: 4 bar%1:23:00:: 3</phone>
<abstract confidence="0.978262005128205">bar%1:17:00:: 1 Figure 1: Sense treatment for word &apos;bar&apos; Secondly, we have reduced the sense granularity, by hierarchically decomposing the learning process in two steps. In the first level, the learning algorithm is trained to classify between the labels corresponding to the WordNet semantic files, and, additionally the semantic—file labels with less than 10 training examples are automatically discarded. If less than two senses remain, no training is performed simply, the Classifier applied. an example, for the word this first step the system is trained to classify between the labels of the top—right table of figure 1. Note that bar%1:23 been dropped out because there are not enough training examples. In the second level, one classifier is trained for each of the resulting semantic—file labels of the first step in order to distinguish between their particular senses. Note that the same simplifying rules of the previous level are also applied. For instance, the bottom—right table of figure 1 shows the labels for been rejected. When classifying a new test example, the classifiers of the two levels are applied sequentially. That 1st level Senses Exs. bar%1:06 199 bar%1:14 17 bar%1:10 12 2nd level Senses Exs. 127 00:: 29 28 11 72 is, the semantic—file classifier is applied first. Then, depending on the semantic—file label output by this classifier, the appropriate 2nd level classifier is selected. The resulting label assigned to the test example is formed by the concatenation of the outputs of both previous levels. In the official competition, labels &apos;IP and &apos;P&apos; have been completely ignored. Thus, the examples labelled with these classes have not been considered during the training, and no test examples have been tagged with them. Despite the simplifying assumptions and the loss of information, we have observed that all these changes together significantly improved the accuracy on the training set. However, the components of the system were not tested separately due to the lack of time. Next section includes some evaluation about this issue. 2 Evaluation The official results achieved by the TALP system are presented in table 1. The evaluation setting corresponding to these results contains all the modifications explained in the previous sections, including the hierarchical approach to all words. Accuracy fine—grained 59.4% coarse—grained 67.1% Table 1: Official results After the SENSEVAL-2 event, we added a very simple Named—entity Recognizer to the part—of— speech tagger that was not finished at the time of the event, but the system continues ignoring the `1J&apos; label. We also have evaluated which parts of the system contributed most to the improvement in performance. Table 2 shows the accuracy results of the four combinations resulting from using (or not) domain—label features and hierarchical decomposition. These results have been calculated over the test set of SENSEVAL-2. On the one hand, it becomes clear that enriching the feature set with domain labels systematically improves the results in all cases, and that this difference is specially noticeable in the case of nouns (over 3 points of improvement). On the other hand, the use of the hierarchies is unexpectedly useless in all cases. Although it is productive in some particular words (3 nouns, 12 verbs and 5 adjectives) the nouns without dom. with dom. fine coarse fine coarse not hien hien 64.25 72.35 67.90 75.60 63.00 71.10 64.31 71.49 verbs without dom. with dom. fine coarse fine coarse not hien hien 51.61 61.63 52.10 62.62 50.28 60.80 51.11 61.96 adjectives without dom. with dom. fine coarse fine coarse not hien hien 66.17 66.17 68.90 68.90 65.35 65.35 68.21 68.21 Table 2: Fine/coarse—grained evaluation for different settings and part—of—speech overall performance is significantly lower. A fact that can explain this situation is that the first—level classifiers do not succeed on classifying semantic— file labels with high precision (the average accuracy of first—level classifiers is only slightly over 71%) and that this important error is dramatically propagated to the second—level, not allowing the greedy sequential application of classifiers. A possible explanation of this fact is the way semantic classes are defined in WordNet. Consider for instance work#1 (activity) and work#2 (production), they seem quite close but a system trying to differentiate among semantic files needs to distinguish among these two senses. On the other extreme, such a classifier should collapse house#2 (legislature) with house#4 (family), which are quite different. Of course, joining both situations makes a pretty hard task. Regarding multiword preprocessing (not included in table 2), we have seen that is slightly useful in all cases. It improves the non—hierarchical scheme with domain information by almost 1 point in accuracy. By part—of—speech, the improvement is about 1 point for nouns, 0.1 for verbs and about 2 points for adjectives. In conclusion, the best results obtained by our system on this test set correspond to the application of multiword preprocessing and domain—labels for all words, but no hierarchical decomposition at all, achieving a fine—grained accuracy of 61.51% and a coarse—grained accuracy of 69.00%. We know that it is not fair to consider these results for comparison, since the system is tuned over the test set. Our 73 aim is simply to fully inspect the TALP system to know which parts are useful for a real Word Sense Disambiguation system. 3 Work in progress We think that the system presented in this paper still has a large room for improvement. Among all the research lines and developments that we are currently performing on the TALP system for WSD, we would like to mention the following: • Tuning the preprocessing procedure with improved versions of the Named—entity Recognizer and Domain taggers. • Studying in more detail the promising use of domain information in the feature set. • Enriching the set of features with the most relevant features used by the SENSEVAL-2 sysand using the parser to obtain dependency and role information. • Exploring more appropriate ways of making the hierarchical decomposition, not based on semantic files, and improve the sequential application of classifiers in order to reduce the cascade errors. • Using unlabeled data to obtain larger sets of accurate training data, especially for those words/senses with few training examples. 4 Conclusions This paper has presented the main characteristics and current performance of the TALP system within the framework of SENSE VAL-2 English lexical— sample task competition. The system is mainly based on LazyBoosting (Escudero et al., 2000), which uses an improved version of the boosting algorithm AdaBoost.MH to perform the WSD classification problem. We used a common set of features including local and topical context enriched with domain information. We obtained better performance separating multiword examples and also adding domain information. Due to the small number of examples for training, we also tried to concentrate evidence reducing the fine-grained sense distinctions of WordNet. We perform a hierarchical procedure grouping those at http://www.cs.ualberta.car lindek . senses belonging to the same semantic file, preprocessing multiwords and ignoring &apos;U&apos; label. After the competition, we have shown that the hierarchical decomposition fails to improve performance in this domain, while preprocessing of tnultiwords is quite useful. The improved system achieved a fine— grained accuracy of 61.51% and a coarse—grained accuracy of 69.00%. 5 Acknowledgements We would like to thank Xavier Carreras, Lillis Padro, Victoria Arranz, and the anonymous referees for their helpful comments. This research has been partially funded by the European Commission</abstract>
<note confidence="0.917284">(NAMIC project, IST-1999-12392) and the Spanish Research Department (HERMES project, TIC2000- 0335-0O3-02). References S. Abney, R. E. Schapire and Y. Singer. 1999. Boosting Applied to Tagging and PP—attachment. of EMNLP—VLC&apos;99. J. Carmona, S. Cervell, L. Marquez, M. A. Marti, L. Padr6, R. Placer, H. Rodriguez, M. Taul6 and J. Turmo. 1998. An Environment for Morphosyntactic Processing of Unrestricted Spanish In of LREC&apos;98. X. Carreras and L. Marquez. 2001. Boosting for Clause Splitting. In of CoNLL&apos;01. G. Escudero, L. Marquez and G. Rigau. 2000. Boosting Applied to Word Sense Disambigua- In of ECML&apos;00. B. Magnini and G. Cavaglia. 2000. Integrating Field Codes into WordNet. In Proceedings of LREC&apos;00. R. E. Schapire and Y. Singer. 1999. Improved Boosting Algorithms Using Confidence-rated Learning, E. Schapire and Y. Singer. 2000. Boosting-based System for Text Categorization. Learning, D. Yarowsky. 1993. One Sense per Collocation. In Proceedings of the DARPA Workshop on Human Language Technology. D. Yarowsky. 2000. Hierarchical Decision Lists for Sense Disambiguation. and the 74</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>Boosting Applied to Tagging and PP—attachment.</title>
<date>1999</date>
<booktitle>In Proceedings of EMNLP—VLC&apos;99.</booktitle>
<contexts>
<context position="2218" citStr="Abney et al., 1999" startWordPosition="322" endWordPosition="325"> were most difficult to classify by the preceding weak hypotheses. The learned weak hypotheses are linearly combined into a single rule called the combined hypothesis. The particular algorithm used in our system to perform the classification of senses is the generalized AdaBoost.MH with confidence—rated predictions (Schapire and Singer, 1999). This algorithm is able to deal straightforwardly with multiclass multi—label problems, and has been previously applied, with significant success, to a number of NLP disambiguation tasks, including, among others: Part—of—speech tagging and PP—attachment (Abney et al., 1999), text categorization (Schapire and Singer, 2000), and shallow parsing (Carreras and Marquez, 2001). The weak hypotheses used in this work are decision stumps, which can be seen as extremely simple decision trees with one internal node testing the value of a single binary feature (e.g. &amp;quot;the word dark appears in the context of the word to be disambiguated?&amp;quot;) and two leaves that give the prediction of the senses based on the feature value. The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of the AdaBoost.MH algorithm, which consists of reducing the feature space that is explored when learning each w</context>
</contexts>
<marker>Abney, Schapire, Singer, 1999</marker>
<rawString>S. Abney, R. E. Schapire and Y. Singer. 1999. Boosting Applied to Tagging and PP—attachment. In Proceedings of EMNLP—VLC&apos;99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carmona</author>
<author>S Cervell</author>
<author>L Marquez</author>
<author>M A Marti</author>
<author>L Padr6</author>
<author>R Placer</author>
<author>H Rodriguez</author>
<author>M Taul6</author>
<author>J Turmo</author>
</authors>
<title>An Environment for Morphosyntactic Processing of Unrestricted Spanish Text.</title>
<date>1998</date>
<booktitle>In Proceedings of LREC&apos;98.</booktitle>
<marker>Carmona, Cervell, Marquez, Marti, Padr6, Placer, Rodriguez, Taul6, Turmo, 1998</marker>
<rawString>J. Carmona, S. Cervell, L. Marquez, M. A. Marti, L. Padr6, R. Placer, H. Rodriguez, M. Taul6 and J. Turmo. 1998. An Environment for Morphosyntactic Processing of Unrestricted Spanish Text. In Proceedings of LREC&apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L Marquez</author>
</authors>
<title>Boosting Trees for Clause Splitting.</title>
<date>2001</date>
<booktitle>In Proceedings of CoNLL&apos;01.</booktitle>
<contexts>
<context position="2317" citStr="Carreras and Marquez, 2001" startWordPosition="335" endWordPosition="338">ses are linearly combined into a single rule called the combined hypothesis. The particular algorithm used in our system to perform the classification of senses is the generalized AdaBoost.MH with confidence—rated predictions (Schapire and Singer, 1999). This algorithm is able to deal straightforwardly with multiclass multi—label problems, and has been previously applied, with significant success, to a number of NLP disambiguation tasks, including, among others: Part—of—speech tagging and PP—attachment (Abney et al., 1999), text categorization (Schapire and Singer, 2000), and shallow parsing (Carreras and Marquez, 2001). The weak hypotheses used in this work are decision stumps, which can be seen as extremely simple decision trees with one internal node testing the value of a single binary feature (e.g. &amp;quot;the word dark appears in the context of the word to be disambiguated?&amp;quot;) and two leaves that give the prediction of the senses based on the feature value. The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of the AdaBoost.MH algorithm, which consists of reducing the feature space that is explored when learning each weak classifier. More specifically, a small proportion of attributes are randomly selected and the b</context>
</contexts>
<marker>Carreras, Marquez, 2001</marker>
<rawString>X. Carreras and L. Marquez. 2001. Boosting Trees for Clause Splitting. In Proceedings of CoNLL&apos;01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L Marquez</author>
<author>G Rigau</author>
</authors>
<title>Boosting Applied to Word Sense Disambiguation.</title>
<date>2000</date>
<booktitle>In Proceedings of ECML&apos;00.</booktitle>
<contexts>
<context position="789" citStr="Escudero et al., 2000" startWordPosition="108" endWordPosition="111">-3 Barcelona, Catalonia, Spain fescudero,lluism,g.rigaul@lsi.upc.es Abstract This paper describes the architecture and results of the TALP system presented at the SENSEVAL-2 exercise for the English lexical—sample task. This system is based on the LazyBoosting algorithm for Word Sense Disambiguation (Escudero et al., 2000), and incorporates some improvements and adaptations to this task. The evaluation reported here includes an analysis of the contribution of each component to the overall system performance. 1 System Description The TALP system has been developed on the basis of LazyBoosting (Escudero et al., 2000), a boosting—based approach for Word Sense Disambiguation. In order to better fit the SENSEVAL2 domain, some improvements have been made on the basic system, including: features that take into account domain information, an specific treatment of multiwords, and a hierarchical decomposition of the multiclass classification problem, similar to that of (Yarowslcy, 2000). All these issues will be briefly described in the following sections. 1.1 LazyBoosting The purpose of boosting—based algorithms is to find a highly accurate classification rule by combining many weak classifiers (or weak hypothes</context>
<context position="3089" citStr="Escudero et al., 2000" startWordPosition="464" endWordPosition="467">alue of a single binary feature (e.g. &amp;quot;the word dark appears in the context of the word to be disambiguated?&amp;quot;) and two leaves that give the prediction of the senses based on the feature value. The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of the AdaBoost.MH algorithm, which consists of reducing the feature space that is explored when learning each weak classifier. More specifically, a small proportion of attributes are randomly selected and the best weak rule is selected only among them. This modification significantly increases the efficiency of the learning process with no loss in accuracy (Escudero et al., 2000). 1.2 Feature Space Three kinds of information have been used to describe the examples and to train the classifiers. These features refer to local and topical contexts, and domain labels. More particularly, let &amp;quot;... w_2 w_i w w±i w+2 w+3 ...&amp;quot; be the context of consecutive words around the word w to be disambiguated, and p±i 71 (-3&lt;i&lt;3) be the part—of—speech tag of word w±,1. Feature patterns referring to local context are the following 13: P+&apos;3, P-2, P-1, P+1, P+2, P+3, W-2, W-1, W4-1, W4-2, (W-21 W-1), (tv—i, w+i), and (w+i, 111+2), where the last three correspond to collocations of two conse</context>
<context position="13114" citStr="Escudero et al., 2000" startWordPosition="2088" endWordPosition="2091">btain dependency and role information. • Exploring more appropriate ways of making the hierarchical decomposition, not based on semantic files, and improve the sequential application of classifiers in order to reduce the cascade errors. • Using unlabeled data to obtain larger sets of accurate training data, especially for those words/senses with few training examples. 4 Conclusions This paper has presented the main characteristics and current performance of the TALP system within the framework of SENSE VAL-2 English lexical— sample task competition. The system is mainly based on LazyBoosting (Escudero et al., 2000), which uses an improved version of the boosting algorithm AdaBoost.MH to perform the WSD classification problem. We used a common set of features including local and topical context enriched with domain information. We obtained better performance separating multiword examples and also adding domain information. Due to the small number of examples for training, we also tried to concentrate evidence reducing the fine-grained sense distinctions of WordNet. We perform a hierarchical procedure grouping those 2Available at http://www.cs.ualberta.car lindek . senses belonging to the same semantic fi</context>
</contexts>
<marker>Escudero, Marquez, Rigau, 2000</marker>
<rawString>G. Escudero, L. Marquez and G. Rigau. 2000. Boosting Applied to Word Sense Disambiguation. In Proceedings of ECML&apos;00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglia</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC&apos;00.</booktitle>
<contexts>
<context position="4252" citStr="Magnini and Cavaglia, 2000" startWordPosition="663" endWordPosition="666">2), where the last three correspond to collocations of two consecutive words. The topical context is formed by CI , , Cm, which stand for the unordered set of open class words appearing in a medium—size 21-word window centered around the target word. The more innovative use of semantic domain information is detailed in the next section. 1.2.1 Domain Information We have enriched the basic set of features by adding semantic information in the form of domain labels. These domain labels are computed during a preprocessing step using the 164 domain labels linked to the nominal part of WordNet 1.6 (Magnini and Cavaglia, 2000). For each training example, a program gathers, from its context, all nouns and their synsets with the attached domain labels, and scores them according to a certain scoring function. The weights assigned by this function depend on the number of domain labels assigned to each noun and their relative frequencies in the whole WordNet. The result of this procedure is the set of domain labels that achieve a score higher than a certain experimentally set threshold, which are incorporated as regular features for describing the example. 1.3 Preprocessing and Hierarchical Decomposition We began this e</context>
</contexts>
<marker>Magnini, Cavaglia, 2000</marker>
<rawString>B. Magnini and G. Cavaglia. 2000. Integrating Subject Field Codes into WordNet. In Proceedings of LREC&apos;00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>Improved Boosting Algorithms Using Confidence-rated Predictions.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>37--3</pages>
<contexts>
<context position="1943" citStr="Schapire and Singer, 1999" startWordPosition="281" endWordPosition="284">classification rule by combining many weak classifiers (or weak hypotheses), each of which may be only moderately accurate. The weak hypotheses are learned sequentially, one at a time, and, conceptually, at each iteration the weak hypothesis is biased to classify the examples which were most difficult to classify by the preceding weak hypotheses. The learned weak hypotheses are linearly combined into a single rule called the combined hypothesis. The particular algorithm used in our system to perform the classification of senses is the generalized AdaBoost.MH with confidence—rated predictions (Schapire and Singer, 1999). This algorithm is able to deal straightforwardly with multiclass multi—label problems, and has been previously applied, with significant success, to a number of NLP disambiguation tasks, including, among others: Part—of—speech tagging and PP—attachment (Abney et al., 1999), text categorization (Schapire and Singer, 2000), and shallow parsing (Carreras and Marquez, 2001). The weak hypotheses used in this work are decision stumps, which can be seen as extremely simple decision trees with one internal node testing the value of a single binary feature (e.g. &amp;quot;the word dark appears in the context </context>
</contexts>
<marker>Schapire, Singer, 1999</marker>
<rawString>R. E. Schapire and Y. Singer. 1999. Improved Boosting Algorithms Using Confidence-rated Predictions. Machine Learning, 37(3):297-336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>BoosTexter A Boosting-based System for Text Categorization.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>29--3</pages>
<contexts>
<context position="2267" citStr="Schapire and Singer, 2000" startWordPosition="328" endWordPosition="331">eceding weak hypotheses. The learned weak hypotheses are linearly combined into a single rule called the combined hypothesis. The particular algorithm used in our system to perform the classification of senses is the generalized AdaBoost.MH with confidence—rated predictions (Schapire and Singer, 1999). This algorithm is able to deal straightforwardly with multiclass multi—label problems, and has been previously applied, with significant success, to a number of NLP disambiguation tasks, including, among others: Part—of—speech tagging and PP—attachment (Abney et al., 1999), text categorization (Schapire and Singer, 2000), and shallow parsing (Carreras and Marquez, 2001). The weak hypotheses used in this work are decision stumps, which can be seen as extremely simple decision trees with one internal node testing the value of a single binary feature (e.g. &amp;quot;the word dark appears in the context of the word to be disambiguated?&amp;quot;) and two leaves that give the prediction of the senses based on the feature value. The &amp;quot;Lazy&amp;quot; Boosting, is a simple modification of the AdaBoost.MH algorithm, which consists of reducing the feature space that is explored when learning each weak classifier. More specifically, a small propor</context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>R. E. Schapire and Y. Singer. 2000. BoosTexter A Boosting-based System for Text Categorization. Machine Learning, 29(3/4):135-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>One Sense per Collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the DARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="6132" citStr="Yarowsky, 1993" startWordPosition="968" endWordPosition="969">logical analyzer and RELAX part—of—speech tagger have been used for tagging (Carmona et al., 1998). Two different simplifications have been carried out. Firstly, multiword training examples have been processed separately. During training, multiwords have been saved into a separate file. At test time, all examples found in this multiword file are automatically tagged as multiwords. As an example, the word bar appears in the training set with 22 labels. But only the 10 senses showed in the left table of figure 1 are single words. The remaining 12 are multiwords which are considered unambiguous (Yarowsky, 1993). Full senses Senses Exs. bar%1:06:04:: 127 bar%1:06:00:: 29 bar%1:06:05:: 28 bar%1:14:00:: 17 bar%1:10:00:: 12 bar%1:06:06:: 11 bar%1: 04: 00: : 5 bar%1:06:02:: 4 bar%1:23:00:: 3 bar%1:17:00:: 1 Figure 1: Sense treatment for word &apos;bar&apos; Secondly, we have reduced the sense granularity, by hierarchically decomposing the learning process in two steps. In the first level, the learning algorithm is trained to classify between the labels corresponding to the WordNet semantic files, and, additionally the semantic—file labels with less than 10 training examples are automatically discarded. If less tha</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>D. Yarowsky. 1993. One Sense per Collocation. In Proceedings of the DARPA Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Hierarchical Decision Lists for Word Sense Disambiguation. Computer and the Humanities,</title>
<date>2000</date>
<pages>34--179</pages>
<contexts>
<context position="5464" citStr="Yarowsky, 2000" startWordPosition="861" endWordPosition="862">s exercise by selecting a representative sample, containing the most frequent words of the SENSEVAL-2 training data, and applying the LazyBoosting system straightforwardly on this sample. The results achieved after a 10—fold cross— validation procedure were very bad, mainly due to the fact that most of the words contain too many senses and too few examples per sense to induce reliable classifiers. With the aim of improving the performance of the learning algorithm, we have reduced the number of senses by performing a hierarchical decomposition of the multiclass problem, following the idea of (Yarowsky, 2000). &apos;In this work, the English versions of MACO+ morphological analyzer and RELAX part—of—speech tagger have been used for tagging (Carmona et al., 1998). Two different simplifications have been carried out. Firstly, multiword training examples have been processed separately. During training, multiwords have been saved into a separate file. At test time, all examples found in this multiword file are automatically tagged as multiwords. As an example, the word bar appears in the training set with 22 labels. But only the 10 senses showed in the left table of figure 1 are single words. The remaining</context>
</contexts>
<marker>Yarowsky, 2000</marker>
<rawString>D. Yarowsky. 2000. Hierarchical Decision Lists for Word Sense Disambiguation. Computer and the Humanities, 34:179-186.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>