<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.9987805">
Using Search Engine to Construct a Scalable Corpus for
Vietnamese Lexical Development for Word Segmentation
</title>
<author confidence="0.95946">
Doan Nguyen
</author>
<affiliation confidence="0.884695">
Hewlett-Packard Company
</affiliation>
<email confidence="0.983264">
doan.nguyen@hp.com
</email>
<sectionHeader confidence="0.982423" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999664">
As the web content becomes more accessible
to the Vietnamese community across the
globe, there is a need to process Vietnamese
query texts properly to find relevant informa-
tion. The recent deployment of a Vietnamese
translation tool on a well-known search en-
gine justifies its importance in gaining popu-
larity with the World Wide Web. There are
still problems in the translation and retrieval
of Vietnamese language as its word recogni-
tion is not fully addressed. In this paper we
introduce a semi-supervised approach in
building a general scalable web corpus for
Vietnamese using search engine to facilitate
the word segmentation process. Moreover,
we also propose a segmentation algorithm
which recognizes effectively Out-Of-
Vocabulary (OOV) words. The result indi-
cates that our solution is scalable and can be
applied for real time translation program and
other linguistic applications. This work is
here is a continuation of the work of Nguyen
D. (2008).
</bodyText>
<sectionHeader confidence="0.995114" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962302325581">
The Vietnamese language as a minority language
is gaining popularity including content and au-
dience. It is important to emphasize a need for
natural language such as search engines or trans-
lation tools to process the data correctly. With
this emphasis, we need to have a way to improve
and automate the training process as well as ex-
panding its training data. Previous works in con-
structing segmentation systems for the Vietnam-
ese language relied on single source of informa-
tion such as newspapers or electronic dictionaries
(Le H. Phuong et al. 2008, Dinh Dien and Vu
Thuy, 2006, Le T. Ha et al., 2005). Mono-source
corpora would work best within their domain,
and might not work well externally per O’Neil
(2007). Le A. Ha, (2003) described the dictio-
nary based approach as problematic due to the
lack of consistency and completeness. This
speaks to the need of standardizations between
dictionaries, concrete grammar theories, and be-
ing up-to-date with the arrival of new words. In
the work of Nguyen C. T. et al. (2007), corpus
training was done manually by linguists. This
was very time-consuming and costly. Because
the task is performed only once, a corpus will go
stale and will get out-of-date. Dinh et al. (2008),
in a comparison with major Vietnamese segmen-
tation approaches, concluded that the handling of
unknown compound words is a much greater
source of segmenting errors and underscored that
future effort should be geared at prioritizing to-
wards the automatic detection of new com-
pounds.
In this paper, we first present the main issues
with the Vietnamese word segmentation prob-
lem. We describe the two approaches in obtain-
ing raw text from the Web. Then, we present our
approach in building a large web corpus for a
word segmentation function and compare our
result against a sophisticated algorithm built on a
human trained corpus. Finally, we provide our
conclusion and offer suggestions for future re-
search directions.
</bodyText>
<sectionHeader confidence="0.8190915" genericHeader="introduction">
2 Vietnamese Word Segmentation
Problems
</sectionHeader>
<bodyText confidence="0.9994028">
Vietnamese (Tiếng Việt) is the official language
of Vietnam. The current writing system origi-
nates from the Latin alphabet, with diacritics for
tones and certain letters. Vietnamese is often
mistakenly judged as a “monosyllabic” language.
However, the majority of the words are disyllab-
ic (Le A. Ha, 2003) covering reduplication and
adjectives. Its grammar depends on word order-
ing and sentence structure rather than morpholo-
gy. Even though there is a space separating
</bodyText>
<page confidence="0.425405">
171
</page>
<note confidence="0.9991315">
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 171–178,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.992545428571429">
sound units, there is nothing used to identify
word boundary.
Examples in Figure 1. are used to illustrate the
difficulty of Vietnamese word segmentation
when compared it to English. There are 256
possible sequences (2n-1) of segmentation in this
example.
</bodyText>
<figureCaption confidence="0.994315">
Figure 1. Ambiguity of word segmentation
</figureCaption>
<bodyText confidence="0.9999735">
The major segmentation problems with the
Vietnamese word segmentation include: the han-
dling of word ambiguities, detection of unknown
words, and recognition of named entities.
</bodyText>
<subsectionHeader confidence="0.998932">
2.1 Addressing Words Ambiguities
</subsectionHeader>
<bodyText confidence="0.9999368">
In a sequence of Vietnamese syllables, S, com-
posing of two syllables A and B occurring next
to one another, if S, A, and B are each words,
then there is a conjunctive ambiguity in S. In
contrast, in a sequence of Vietnamese syllables,
S, composing of three syllables A, B, and C ap-
pearing contiguously, if A B and B C are each
words, then there is a disjunctive ambiguity in S.
In order to attain a higher precision rating, word
ambiguity must be addressed.
</bodyText>
<subsectionHeader confidence="0.999875">
2.2 Detection of Unknown Words
</subsectionHeader>
<bodyText confidence="0.999978">
In a dictionary word segmentation based ap-
proach, only the words that are in the dictionary
can be identified. The unknown words might
belong to one of the following categories: (1)
Morphologically Derived Word (MDW). There
are some lexical elements that never stand alone,
which express negation such as: “bất” in “bất
quy tắc” (irregular) or transformation such as
“hoá” in “công nghiệp hoá” (industrialize). (2)
Interchanging usage of vowels i and y and
changing in position of tone. For example: “duợc
sĩ” and “duợc sỹ”. Both mean “pharmacist”. (3)
Phonetically transcribed words. This can be seen
in naturalized words like: “phô mai” (fromage),
“híp hóp” (hip hop music), or “iPhône” (Apple
iPhone).
</bodyText>
<subsectionHeader confidence="0.999922">
2.3 Recognition of Named Entities
</subsectionHeader>
<bodyText confidence="0.999794">
Unlike other Asian languages, Vietnamese per-
sonal, location, and organizational names all
have the initial letter capitalized. For example:
“Nguyễn Du” (a famous Vietnamese poet). Due
to the language syntax standardization, a proper
name could be written in many different forms.
The following organizational name has three ac-
ceptable forms: Bộ Nông Nghiệp, Bộ Nông
nghiệp, or Bộ nông nghiệp (Department of Agri-
culture). We use the following shape features
(pattern) to assist with the recognition process:
</bodyText>
<table confidence="0.999565666666667">
Word Shape Examples
Capitalized Sài Gòn (Location )
All Caps WTO (World Trade
Organization)
Containing digit H5N1 (Bird flu)
Containing hyphen Vn-Index (Securities
market of Việt Nam)
Mixed case VnExpress (Vietnam
News Daily)
</table>
<tableCaption confidence="0.9270305">
Table 1. Word Shape features for identifying
Vietnamese Name Entities
</tableCaption>
<sectionHeader confidence="0.688748" genericHeader="method">
3 Using World Wide Web as a Resource
to Build Corpora
</sectionHeader>
<bodyText confidence="0.999811166666667">
There are two approaches to obtain linguistics
data from the Web. The first approach is to
crawl the web (Baroni et al., 2006 and O’Neil,
2007). This option gives flexibility in choosing
or restricting sites to crawl upon. To have good
coverage, it requires extensive hardware resource
to support storage of content documented in the
work of Baroni et al. (2006). Other complexities
include a filtering capability to recognize content
of a target language from crawling data, remov-
ing html code, and handling page duplication.
The work of Le V. B (2003) indicated that it is
very difficult to crawl on Web pages located in
Vietnam due to a low network communication
bandwidth.
A second approach is to use search engines via
a web service API to find linguistic data. In the
work of Ghani et al. (2001), a term selection me-
thod is used to select words from documents to
use for a query. Documents from a search result
list are downloaded locally to process and build
corpus data. The technical challenges of this
approach are: (1) Corpus being biased and being
dictated by a ranking of a search engine. (2) Li-
</bodyText>
<page confidence="0.826561">
172
</page>
<bodyText confidence="0.9553005">
mited number of search queries is allowed by a
search engine per day.
</bodyText>
<sectionHeader confidence="0.827152" genericHeader="method">
4 Our Approach to build corpus
</sectionHeader>
<bodyText confidence="0.992753739130435">
We are structuring our system with two main
components. The first component works as a
word training and recognition system. The
second component utilizes the training informa-
tion provided from the first component to per-
form just a word segmentation task by leveraging
the computed lexical statistics. This is a clear
distinction between our work and Nguyen D.
(2008). Because there is a limited number of
search request imposed by commercial search
engines each day, this approach is not practical
for a condition where there is constant usage of
search requests, for word segmentation purpose.
Aside from this limitation, lexical statistics have
to be recomputed for each new word segmenta-
tion request.
Figure 2. depicts the overall system consists of
two components: The training Processing in-
cludes a new word discovery function and Nor-
mal Segmentation process. The training process
would execute continuously and feed the lexical
statistics to the second process for segmentation
task purely.
</bodyText>
<figureCaption confidence="0.7990255">
Figure 2. Vietnamese Words Corpus Construc-
tion Process
</figureCaption>
<subsectionHeader confidence="0.999277">
4.1 Word Training and Recognition System
</subsectionHeader>
<bodyText confidence="0.999846058823529">
This component trains identified words inside a
Vietnamese Word Database with its frequency of
occurrences. Newly encountered OOV words are
recognized by the system then verified by a
check against the Vietnamese Wikipedia pro-
grammatically. We do not wish to include all
words from the Vietnamese Wikipedia as there
are many foreign words. For examples: St. He-
lens, Oregon. The remained frequently found
OOV words are evaluated by linguists for validi-
ty and will be included into the word database as
confirmed. Unlike the work of Ghani (2001), in
our work, a query to submit to an engine is a sen-
tence derived from an unknown document title.
The reason here is to enable the system to dis-
cover the unknown words and their frequencies
naturally. This system performs:
</bodyText>
<listItem confidence="0.998740705882353">
• Seed the queries database with an initial set
of queries, Qn.
• Randomly select a query from Qn and send to
a search engine.
• From a search result list, process on docu-
ment titles and snippet texts directly.
• Perform Vietnamese word segmentation on
recognized sentences using question mark,
exclamation mark, periods as separators.
Update the word database with recognized
segmented words and their computed fre-
quencies and weights.
• Recognize and validate OOV words, using
the Vietnamese Wikipedia or through mor-
phological rules programmatically.
• Bootstrap Qn with retrieved document titles.
• Return to step 2 above.
</listItem>
<sectionHeader confidence="0.548076" genericHeader="method">
5 Word Segmentation System
</sectionHeader>
<bodyText confidence="0.999974333333333">
In the Vietnamese language, as the white space
cannot be used to denote word boundary, the
function of a word segmentation system is to
segment a sentence into a sequence of segmented
words such that a context (or meaning) of a sen-
tence is preserved.
</bodyText>
<subsectionHeader confidence="0.999226">
5.1 Data Gathering and Words Extraction
</subsectionHeader>
<bodyText confidence="0.999997375">
In the first step, a search query is submitted to a
search engine API and requests for N returned
documents. The engine returns a search result
list, which consists of document titles and their
summary text. We parse the data and extract the
required text. Syllables in the search query are
then matched against the parsed text to extract
potential words covering both monosyllabic and
polysyllabic words. This function keeps track
and counts their occurrences. At this stage, we
also determine if a word is a proper name. We
use the various word shape features in capitaliza-
tion forms to assist with the recognition process.
We compute the likelihood of extracted words to
be proper names by taking the account of the
number of identified capitalized words over the
</bodyText>
<page confidence="0.744248">
173
</page>
<bodyText confidence="0.997351217391304">
total of the same words in appearing the docu-
ments set, N documents. Once the extraction
process is complete, we perform additional vali-
dation steps to discard incorrect generated words.
To be accepted as a potential word, a word must
satisfy one of the following rules: (1) It appears
in the word database. (2) It is recognized as a
proper name word. (3) It is a MDR word. (4) It
is an OOV word with strong world collocation as
defined below.
An OOV word is identified when there is a
strong collocation (cohesion) attached between
its syllables. That is the following condition(s)
is/are met: (1) For two syllable words to collo-
cate: P(s, s2) &gt; P(s,)P(s2), (2) For three syllable
words to collocate: P(s, s2 s3) &gt; MAX{
P(s,)P(s2)P(s3), P(s,)P(s2s3), P(s,s2)P(s3) } where
w = s, s2 s3, P(s,...sn) = Freq(s,...sn )/N, and N is
the number of documents returning from a search
engine.
Collocation concept has been utilized in the
merging syllables to determine the best possible
segment in the work of Wirote (2002).
</bodyText>
<table confidence="0.9994353">
Suffix Translation Result Lexi- Morphological Rules Examples
cal Category
hoc &amp;quot;&apos;-logy, -ics&amp;quot; Noun IF Syllable_Suffix(&amp;quot;hoc&amp;quot;) AND Pre- ngôn ng* (lan-
fix_With_Word((Noun(W)) THEN guage) + hoc 4
WORD(W+ &amp;quot; &amp;quot;+ &amp;quot;hoc&amp;quot;) ngôn ng* hoc
(linguistics)
hóa &amp;quot;-ize, -ify&amp;quot; Verb IF Syllable_Suffix(&amp;quot;hóa&amp;quot;) AND (Pre- công nghiep (in-
fix_With_Word((NOUN(W) ) OR dustry) + hóa 4
Prefix_With_Word((ADJECTIVE(W) công nghiep hóa
) ) THEN WORD(W+ &amp;quot; &amp;quot; +&amp;quot;hóa&amp;quot;) (industrialize)
Prefix Translation Result Lexi- Morphological Rules Examples
cal Category
su &amp;quot;Action-&amp;quot; Noun IF Syllable_Prexix(&amp;quot;su&amp;quot;) AND (Suf- su + thao luan
fix_With_Word((Verb(W)) OR Suf- (discuss, debate)
fix_With_Word((Adjective(W))) 4 su thao luan
THEN WORD(su+ &amp;quot; &amp;quot;+ W) (discussion)
bat &amp;quot;Un-&amp;quot; Noun IF Syllable_Prexix(&amp;quot;bat&amp;quot;) AND (Suf- bat + hop pháp
fix_With_Word((Verb(W)) OR Suf- (legal, lawful)
fix_With_Word((Adjective(W))) 4bat hop pháp
THEN WORD(bat+ &amp;quot; &amp;quot;+ W) (Not legal)
</table>
<tableCaption confidence="0.98403">
Table 2. Examples of derivational morphology and morphological rules
to construct compound words
</tableCaption>
<bodyText confidence="0.9998236">
To recognize for morphological derived words
(MDW), we have identified a range of prefixes
and suffixes (Goddard, 2005). When a mor-
pheme modifies another morpheme, it produc-
es a subordinate compound word (Ngo, 2001).
For example: nhà (as a prefix) + báo (newspa-
per) 4 nhà báo (journalist). The table 2. pro-
vides a few examples of Vietnamese suffixes,
prefixes, and Morphological Rules to derive
subordinate compound words.
</bodyText>
<subsectionHeader confidence="0.996137">
5.2 Sentences Construction
</subsectionHeader>
<bodyText confidence="0.999978">
Given a set of potential segmented words ob-
tained from step 5.1, applied only for training
process or for a normal segmentation process
(Figure 2.), the task of sentences constructor is to
assemble the identified words in such a way that
they appear in the same order as the original
query. We use Greedy algorithm to construct
sentences using the following heuristic strate-
gies: (1) Selection of polysyllabic words over
monosyllabic words whenever possible. (2) Eli-
minating segments which have already ex-
amined. (3) Declaring a solution when a con-
structed sentence has all of segmented words
appearing in the same order as in the original
query text.
</bodyText>
<subsectionHeader confidence="0.9891305">
5.3 Sentences Refinement and Reduction
through Ambiguity Resolution
</subsectionHeader>
<bodyText confidence="0.9999206">
Since there is only a single solution to present to
a user, we need to have an algorithm to improve
upon proposed sentences and reduce them to a
manageable size. The algorithm Sen-
tences_Refine_Reduce below describes the
</bodyText>
<page confidence="0.683634">
174
</page>
<bodyText confidence="0.999686882352941">
steps in refining the sentences to a finer solu-
tion(s).
Definition: Let the pipe symbol, |, be designated
as a boundary of a segment. Two segments, in
two sentences, are overlapped if their first and
last syllables are: (1) located next to a segmented
boundary. (2) Identical and positioned at the
same location. For example, in the following
two sentences:
Sentence #1: tốc độ  |truyền  |thông tin  |s6  |tăng |
cao
Sentence #2: tốc độ  |truyền thông  |tin  |s6  |tăng |
cao
The overlapped segments are: “tốc độ”, “s6”,
“tăng”, and “cao”. We are now describing an
algorithm to perform sentences refinement and
reduction as follows:
</bodyText>
<table confidence="0.999216166666667">
Algorithm : Sentences_Refine_Reduce()
Input: SBuffer - for input sentences
Output: SBuffer - for output sentences
Until Converged(SBuffer) Do:
Itr_Sentences_Buf = {}
For si in SBuffer Do:
Find sj such that Max {|Overlapped_Segment
(si,sj)|} for sj SBuffer and si != sj
Res_Segments=Overlapped_Segments(si,sj)
U Conjunctive_Segments_Resolutions(si,sj)
Freq (s1 . . .sn )
U Disjunctive_Segments_Resolutions(si,sj)
P (s . . .s ) 
1 nN
Itr_Sentences_Buf = Itr_Sentences_Buf U
Sentence(Res_Segments)
SBuffer=(SBuffer!=Itr_Sentences_Buf)
? Itr_Sentences_Buf : SBuffer
</table>
<bodyText confidence="0.9909504">
For conjunctive ambiguity resolution, to de-
termine if all syllables should be classified as a
single word or appeared as individual words, we
utilize word collocation strength. We define col-
locating strength as follows.
</bodyText>
<equation confidence="0.954039">
P(s1) ...P(sn)  Fre s1) ... Fre sn N N
</equation>
<bodyText confidence="0.9997254">
We compare it against a probability of finding
the syllables occur independently in N docu-
ments as shown in equation (3). The outcome
determines if the syllables should be collocated
or separately appeared:
has the highest probability of success. This is
discussed further in the section “Sentences Scor-
ing and Ordering” below. Figure 3 illustrates a
process where sentences are refined through dis-
ambiguating words.
</bodyText>
<figureCaption confidence="0.654385">
Figure 3. An Example of Sentences Refinement
</figureCaption>
<bodyText confidence="0.9999771">
After the 1st iteration, the sentences 1 and 2 are
combined through a resolution of conjunctive
ambiguity between “tốc độ” vs. “tốc |
độ” . After the 2nd iteration, sentences 1 and 2
are combined through a resolution of disjunctive
ambiguity between “truyền  |thông tin” vs.
“truyền thông  |tin”. The process exits when a
converged condition is reached. The final seg-
mented sentence is translated in English as “The
speed of information transmission will increase”.
</bodyText>
<equation confidence="0.46223">
) (
</equation>
<subsectionHeader confidence="0.996792">
5.4 Sentences Scoring and Ordering
</subsectionHeader>
<bodyText confidence="0.999424166666667">
The task in this phase is to score and order the
candidates. A language model is usually formu-
lated as a probability distribution p(s) over
strings s that attempts to reflect how frequently a
string s occurs as a sentence in a corpus, Chen et
al. (1998). For a segmented sentence S
</bodyText>
<equation confidence="0.9989278">
p(s) (
� P
i �
i �
1
</equation>
<bodyText confidence="0.99871475">
= w, w2...wn , where w is an identified segmented
word, using a bigram model, we compute the
probability distribution of a sentence s as fol-
lows:
</bodyText>
<equation confidence="0.992922714285714">
1...
i-1) ^
wi|w
w
P(x&apos;i  |wi-1
P(w
wi
</equation>
<bodyText confidence="0.845806">
1)= 0. To handle this condition, we
applied Additive Smoothing to estimate its prob-
ability. The formula was experimented an
</bodyText>
<equation confidence="0.91384">
i|

</equation>
<bodyText confidence="0.911873666666667">
d
slightly modified to fit our needs and defined as
follows:
</bodyText>
<equation confidence="0.984206181818182">
Theta (wi  |wi 1 )
  Freq
( )
w w
i 1 i
(
2)
n
H
1
PAdd
</equation>
<bodyText confidence="0.982564666666667">
For disjunctive ambiguity resolution, because
a determination involves multiple words with
overlapping text, we determine the best possible
segments by computing their probability distri-
bution of word segments to find out which one
)
</bodyText>
<page confidence="0.360201">

</page>
<figure confidence="0.70479075">
W w Freq(wi
(3)
1
)
(
wi
5
)
n
4)
However, there is an event such that
_
</figure>
<bodyText confidence="0.771695166666667">
We define8 parameter as Freq( w;
where
)/|W|
|W |is an estimate number of the total
words appears in N returned documents and 0 &lt;
&lt; 1.
</bodyText>
<page confidence="0.829365">
175
</page>
<sectionHeader confidence="0.992881" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.999973428571429">
With no restriction, there were 167,735 searches
performed using the Yahoo! Boss Web Service
API. We bootstrapped the initial core lexicons
from Ho’s Word List (2004) and built up to
gather lexical statistics and discovered new OOV
words. The corpus syllables classifications and
their occurrences are shown in Figure 4.
</bodyText>
<figureCaption confidence="0.866804">
Figure 4. Syllables Types by Frequency
</figureCaption>
<bodyText confidence="0.999946538461539">
We compared our collected lexical data, using
our approach, against VietLex (Dinh et al., 2008)
and found a resembling to one, three, four, and
five syllables. For the two syllables, there is a big
difference: roughly about 19,000 words. This
contributes to the fact that the original Ho’s word
list had already covered 49,583 two-syllable
words to begin with. On top of it, we have in-
cluded 3,000 additional new OOV words includ-
ing MDW and proper names words. According
to the Wiki’s - Vietnamese_morphology, it esti-
mates about 80% of the lexicon being disyllabic.
In our corpus, we have 72% of disyllabic words.
</bodyText>
<tableCaption confidence="0.5952585">
Table 3. The top 20th one-syllable words compar-
ing with corpus of Le A. H1 (2003)
</tableCaption>
<bodyText confidence="0.99445925">
Table 3 provides a top 20 one-syllable words
obtained from our word database. The star mark-
er indicates the same word is also co-occurred in
Le’s of top unigram listing.
The following disyllabic words, in Table 4,
are a few of the new OOV words identified by
our approach and absent from Ho’s Word List
(2004) .
</bodyText>
<table confidence="0.999488944444444">
Common Fre- Uncom- Fre-
Disyllabic quency mon quency
Words Disyllab-
ic Words
Việt Nam 206704 lan rộng 263
(Viet Nam) (spread)
Ngưori Việt 41260 ga lông 14
(Vietnam- (gallon)
ese)
Trung Quốc 35345 Cồn 9
(China) Phụng
(Island)
Tiếng Việt 28460 nghị sỹ 22
(Vietnam- (congress
ese) gress-
man)
Hoa Kỳ 21262 công xôn 2
(America) (console)
</table>
<tableCaption confidence="0.999875">
Table 4. Some OOV disyllabic words
</tableCaption>
<bodyText confidence="0.999826153846154">
We evaluated our segmentation system against
a popular Vietnamese word segmentation tool -
the JVnSegmenter (Nguyen C. T, 2007): A Java-
based Vietnamese Word Segmentation Tool
(SVM). This tool was also a part of Dinh et al.
(2008) evaluation aforementioned. With a source
data provided by a neutral evaluator, and about
9600 sentences with an estimate of 100K words,
we ran an experiment. The texts were input into
both methods. To keep the fairness of the evalu-
ation, the segmented output texts were sent out to
a neutral assessor to analyze for results. The per-
formance results are presented in Table 5. below.
</bodyText>
<table confidence="0.99929">
Evaluation JVnSegmenter Our Ap-
Areas proach
Recall 0.814 0.821
Precision 0.883 0.897
F-Measure 0.847 0.857
OOV Rate 0.06 0.06
OOV Recall 0.921 0.951
IV Recall 0.807 0.813
</table>
<tableCaption confidence="0.993199">
Table 5. Performance Results Comparison
</tableCaption>
<note confidence="0.6709295">
1 The star marker indicates the same word is co-occurred in
Le’s of top unigram listing.
</note>
<page confidence="0.829426">
176
</page>
<bodyText confidence="0.999767923076923">
From the data above, the low OOV rate and
high OOV recall in both systems could be ex-
plained by the nature of the testing corpus: Viet-
namese novels/stories chosen by a neutral evalu-
ator. With this type of content, the numbers of
OOV words are much lesser when compared to
other areas such as news, technology. Even
though the results don’t seem much higher than
those obtained by JVnSegmenter, given the fact
that JVnSegmenter used a manual trained corpus,
our result is worth encouragements. Table 6
provides a few examples of the segmentation
results.
</bodyText>
<table confidence="0.998450571428572">
Q1: tốc độ truyen Q2: hàn mặc tử là một
thông tin s6 tăng cao nhà thơ nổi tiếng
(Ambiguity) (Proper Name)
JVnSegmenter: [tốc độ] JVnSegmenter: [hàn
[truyen thông tin] [s6] mặc] [tử] [là] [một]
[tăng] [cao] [nhà thơ] [nổi tiếng]
Our Approach: tốc độ  |Our Approach: hàn
truyen  |thông tin  |s6  |mặc tử  |là  |một  |nhà
tăng  |cao thơ  |nổi tiếng
Q3: một ngưoi đàn bà Q4: thio tướng trung
làm nghề bán nuớc quốc ôn gia bio
trà ven đưong (Ambi- (Proper name)
guity) JVnSegmenter: [thio
JVnSegmenter: [một] tướng] [trung] [quốc]
[ngưoi đàn bà] [làm [ôn] [gia bio]
nghề] [bán nuớc] [trà] Our Approach: thio
[ven đưong] tướng  |trung quốc  |ôn
Our Approach: một  |gia bio
ngưoi đàn bà  |làm nghề
 |bán  |nuớc trà  |ven
đưong
</table>
<bodyText confidence="0.6624435">
Table 6. Sample outputs of the two approaches:
Our approach vs. JVnSegmenter
</bodyText>
<sectionHeader confidence="0.99546" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.975444512195122">
We presented our approach to segment Viet-
namese text and to build a web corpus for the
function. We made use of the web document
titles and their snippet text to build a scalable
corpus for segmenting query text. The results so
far have shown that this approach has the follow-
ing benefits:
• From a practical and performance perspective,
this approach does not require extended ma-
nual effort in building a corpus. The learning
from the training engine, running continuously,
discovers new OOV words and feeds them into
a normal word segmentation process where it
supplies solutions to requesters efficiently.
• The approach discovers new OOV words and
disambiguates words. Additionally, we discov-
ered new proper nouns which are not a part of
any dictionaries continuously. We integrated
the finding knowledge from the Vietnamese
Wikipedia into our OOV words confirmation
process automatically. This makes the valida-
tion of new words much easier as suppose to
rely on word adjudicators manually as per
O’Neil (2007). And last, the evaluation result
is a better edge when comparing to a popular
Vietnamese segmentation tool in all the me-
trics considered. This tool has a corpus trained
manually.
• Frequently found OOV words identified by our
process which are not available in the Viet-
namese Wikipedia can be suggested to Wiki
authors’ communities to create content and
make them available for the worldwide au-
diences for their benefit.
For future works, we would like to look into
the possibility of applying grammatical rules in
conjunction with our current statistical based sys-
tem to obtain a higher identification rate. Spel-
ling suggestion and cross-lingual search are other
interesting aspects, as now words can be identi-
fied along with their lexical statistics.
</bodyText>
<sectionHeader confidence="0.9674" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9997954">
Our work is credited from the works of Nguyen
Bon et al. (2006), Ho Ngoc Duc (The Free Viet-
namese Dictionary Project), Cam T Nguyen et al.
(JVnSegmenter - 2007), O’Neil (2007), and Ya-
hoo! Boss Web Service, which made the API
available limitlessly during the course of the
work, and many anonymous contributors and
reviewers. A Special thank to Mr. Thuy Vu who
contributed to an assessment of our approach and
the JVnSegmenter.
</bodyText>
<sectionHeader confidence="0.955954" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999469363636364">
C. T. Nguyen, T. K. Nguyen, X. H. Phan, L. M.
Nguyen, and Q. T. Ha. 2006. Vietnamese word
segmentation with CRFs and SVMs: An investiga-
tion. In Proceedings of the 20th Pacific Asia Confe-
rence on Language, Information and Computation
(PACLIC 2006), Wuhan, CH.
Cliff Goddard. 2005. The Languages of East and
Southeast Asia (pages 70-71)
Dinh Dien, Vu Thuy. 2006. A Maximum Entropy
Approach for Vietnamese Word Segmentation. In
Proceedings of the 4th IEEE International Confe-
</reference>
<page confidence="0.497661">
177
</page>
<reference confidence="0.993948344262295">
rence on Computer Science- Research, Innovation
and Vision of the Future 2006, HCM City, Viet-
nam, pp.247–252.
Dinh Quan Thang, et al, 2008. Word Segmentation of
Vietnamese Texts: a comparison of approaches.
LREC : 2008
Ghani, R., Jones, R., Mladenic, D. 2001. Using the
Web to create minority language corpora’. Pro-
ceedings of the 10th International Conference on
Information and Knowledge Management
Ho Ngoc Duc, 2004: Vietnamese word list: Ho Ngoc
Duc’s word list – http://www.informatik.uni-
leipzig.de/~duc/software/misc/wordlist.html
John O’Neil. 2007. Large Corpus Construction for
Chinese Lexical Development, Government Users
Conference: http://www.basistech.com/knowledge-
center/unicode/emerson-iuc29.pdf
Le Thanh Ha, Huynh Quyet Thang, Luong Chi Mai.
2005. A Primary Study on Summarization of Doc-
uments in Vietnamese. The First International
Congress of the International Federation for Sys-
tems Research, Japan.
L. H. Phuong and H. T. Vinh, 2008, Maximum Entro-
py Approach to Sentence Boundary Detection of
Vietnamese Texts, IEEE International Conference
on Research, Innovation and Vision for the Future
RIVF 2008, Vietnam.
L. A. Ha. 2003. A method for word segmentation in
Vietnamese. In Proceedings of the International
Conference on Corpus Linguistics, Lancaster, UK.
Marco Baroni, Motoko Ueyama. 2006. Building gen-
eral and special-purpose corpora by Web Crawling.
Proceedings of the 13th NIJL International Sympo-
sium, Language Corpora: Their Compilation and
Application. 31-40.
Ngo. N. Binh, B. H. Tran. 2001. Vietnamese Lan-
guage Learning Framework – Part One: s Linguis-
tic.
Nguyen D. 2008. Query preprocessing: improving
web search through a Vietnamese word tokeniza-
tion approach. SIGIR 2008: 765-766.
Stanley F. Chen, J. Goodman. 1998. An empirical
study of smoothing techniques for language model-
ing. Center Research in Computing Technology,
Harvard University, TR-10-98
Thanh Bon Nguyen, Thi Minh Huyen Nguyen, Lau-
rent Romary, Xuan Luong Vu. 2006. A lexicon for
Vietnamese language processing. Language Re-
sources and Evaluation. Springer Netherlands
V-B. Le, B. Bigi, L. Besacier, E. Castelli, 2003. Using
the Web for fast language model construction in
minority languages&amp;quot;, Eurospeech&apos;03, Geneva,
Switzerland, September 2003
Wirote Aroonmanakun. 2002. Collocation and Thai
Word Segmentation, Proceedings of SNLP-
Oriental COCOSDA 2002
Vietnamese morphology: From Wikipedia:
http://en.wikipedia.org/wiki/Vietnamese morpholo
gy
Yahoo! Boss Web Service API
http://developer.yahoo.com/search/boss
</reference>
<page confidence="0.737516">
178
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.296611">
<title confidence="0.998236">Using Search Engine to Construct a Scalable Corpus Vietnamese Lexical Development for Word Segmentation</title>
<author confidence="0.99267">Doan Nguyen</author>
<affiliation confidence="0.595677">Hewlett-Packard</affiliation>
<email confidence="0.998904">doan.nguyen@hp.com</email>
<abstract confidence="0.97654875">As the web content becomes more accessible to the Vietnamese community across the globe, there is a need to process Vietnamese query texts properly to find relevant information. The recent deployment of a Vietnamese translation tool on a well-known search engine justifies its importance in gaining popularity with the World Wide Web. There are still problems in the translation and retrieval of Vietnamese language as its word recognition is not fully addressed. In this paper we introduce a semi-supervised approach in building a general scalable web corpus for Vietnamese using search engine to facilitate the word segmentation process. Moreover, we also propose a segmentation algorithm which recognizes effectively Out-Of- Vocabulary (OOV) words. The result indicates that our solution is scalable and can be applied for real time translation program and other linguistic applications. This work is here is a continuation of the work of Nguyen D. (2008).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C T Nguyen</author>
<author>T K Nguyen</author>
<author>X H Phan</author>
<author>L M Nguyen</author>
<author>Q T Ha</author>
</authors>
<title>Vietnamese word segmentation with CRFs and SVMs: An investigation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation (PACLIC</booktitle>
<location>Wuhan, CH.</location>
<marker>Nguyen, Nguyen, Phan, Nguyen, Ha, 2006</marker>
<rawString>C. T. Nguyen, T. K. Nguyen, X. H. Phan, L. M. Nguyen, and Q. T. Ha. 2006. Vietnamese word segmentation with CRFs and SVMs: An investigation. In Proceedings of the 20th Pacific Asia Conference on Language, Information and Computation (PACLIC 2006), Wuhan, CH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cliff Goddard</author>
</authors>
<date>2005</date>
<booktitle>The Languages of East and Southeast Asia</booktitle>
<pages>70--71</pages>
<contexts>
<context position="13271" citStr="Goddard, 2005" startWordPosition="2142" endWordPosition="2143">tegory su &amp;quot;Action-&amp;quot; Noun IF Syllable_Prexix(&amp;quot;su&amp;quot;) AND (Suf- su + thao luan fix_With_Word((Verb(W)) OR Suf- (discuss, debate) fix_With_Word((Adjective(W))) 4 su thao luan THEN WORD(su+ &amp;quot; &amp;quot;+ W) (discussion) bat &amp;quot;Un-&amp;quot; Noun IF Syllable_Prexix(&amp;quot;bat&amp;quot;) AND (Suf- bat + hop pháp fix_With_Word((Verb(W)) OR Suf- (legal, lawful) fix_With_Word((Adjective(W))) 4bat hop pháp THEN WORD(bat+ &amp;quot; &amp;quot;+ W) (Not legal) Table 2. Examples of derivational morphology and morphological rules to construct compound words To recognize for morphological derived words (MDW), we have identified a range of prefixes and suffixes (Goddard, 2005). When a morpheme modifies another morpheme, it produces a subordinate compound word (Ngo, 2001). For example: nhà (as a prefix) + báo (newspaper) 4 nhà báo (journalist). The table 2. provides a few examples of Vietnamese suffixes, prefixes, and Morphological Rules to derive subordinate compound words. 5.2 Sentences Construction Given a set of potential segmented words obtained from step 5.1, applied only for training process or for a normal segmentation process (Figure 2.), the task of sentences constructor is to assemble the identified words in such a way that they appear in the same order a</context>
</contexts>
<marker>Goddard, 2005</marker>
<rawString>Cliff Goddard. 2005. The Languages of East and Southeast Asia (pages 70-71)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dinh Dien</author>
<author>Vu Thuy</author>
</authors>
<title>A Maximum Entropy Approach for Vietnamese Word Segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 4th IEEE International Conference on Computer Science- Research, Innovation and Vision of the Future 2006, HCM City, Vietnam,</booktitle>
<pages>247--252</pages>
<marker>Dien, Thuy, 2006</marker>
<rawString>Dinh Dien, Vu Thuy. 2006. A Maximum Entropy Approach for Vietnamese Word Segmentation. In Proceedings of the 4th IEEE International Conference on Computer Science- Research, Innovation and Vision of the Future 2006, HCM City, Vietnam, pp.247–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dinh Quan Thang</author>
</authors>
<title>Word Segmentation of Vietnamese Texts: a comparison of approaches. LREC :</title>
<date>2008</date>
<marker>Thang, 2008</marker>
<rawString>Dinh Quan Thang, et al, 2008. Word Segmentation of Vietnamese Texts: a comparison of approaches. LREC : 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ghani</author>
<author>R Jones</author>
<author>D Mladenic</author>
</authors>
<title>Using the Web to create minority language corpora’.</title>
<date>2001</date>
<booktitle>Proceedings of the 10th International Conference on Information and Knowledge Management</booktitle>
<contexts>
<context position="7140" citStr="Ghani et al. (2001)" startWordPosition="1148" endWordPosition="1151">sing or restricting sites to crawl upon. To have good coverage, it requires extensive hardware resource to support storage of content documented in the work of Baroni et al. (2006). Other complexities include a filtering capability to recognize content of a target language from crawling data, removing html code, and handling page duplication. The work of Le V. B (2003) indicated that it is very difficult to crawl on Web pages located in Vietnam due to a low network communication bandwidth. A second approach is to use search engines via a web service API to find linguistic data. In the work of Ghani et al. (2001), a term selection method is used to select words from documents to use for a query. Documents from a search result list are downloaded locally to process and build corpus data. The technical challenges of this approach are: (1) Corpus being biased and being dictated by a ranking of a search engine. (2) Li172 mited number of search queries is allowed by a search engine per day. 4 Our Approach to build corpus We are structuring our system with two main components. The first component works as a word training and recognition system. The second component utilizes the training information provided</context>
</contexts>
<marker>Ghani, Jones, Mladenic, 2001</marker>
<rawString>Ghani, R., Jones, R., Mladenic, D. 2001. Using the Web to create minority language corpora’. Proceedings of the 10th International Conference on Information and Knowledge Management</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ho Ngoc Duc</author>
</authors>
<title>Vietnamese word list: Ho Ngoc Duc’s</title>
<date>2004</date>
<note>word list – http://www.informatik.unileipzig.de/~duc/software/misc/wordlist.html</note>
<marker>Duc, 2004</marker>
<rawString>Ho Ngoc Duc, 2004: Vietnamese word list: Ho Ngoc Duc’s word list – http://www.informatik.unileipzig.de/~duc/software/misc/wordlist.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>John O’Neil</author>
</authors>
<title>Large Corpus Construction for Chinese Lexical Development, Government Users Conference:</title>
<date>2007</date>
<note>http://www.basistech.com/knowledgecenter/unicode/emerson-iuc29.pdf</note>
<marker>O’Neil, 2007</marker>
<rawString>John O’Neil. 2007. Large Corpus Construction for Chinese Lexical Development, Government Users Conference: http://www.basistech.com/knowledgecenter/unicode/emerson-iuc29.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Thanh Ha</author>
<author>Huynh Quyet Thang</author>
<author>Luong Chi Mai</author>
</authors>
<title>A Primary Study on Summarization of Documents in Vietnamese.</title>
<date>2005</date>
<booktitle>The First International Congress of the International Federation for Systems Research,</booktitle>
<location>Japan.</location>
<contexts>
<context position="1748" citStr="Ha et al., 2005" startWordPosition="276" endWordPosition="279">Introduction The Vietnamese language as a minority language is gaining popularity including content and audience. It is important to emphasize a need for natural language such as search engines or translation tools to process the data correctly. With this emphasis, we need to have a way to improve and automate the training process as well as expanding its training data. Previous works in constructing segmentation systems for the Vietnamese language relied on single source of information such as newspapers or electronic dictionaries (Le H. Phuong et al. 2008, Dinh Dien and Vu Thuy, 2006, Le T. Ha et al., 2005). Mono-source corpora would work best within their domain, and might not work well externally per O’Neil (2007). Le A. Ha, (2003) described the dictionary based approach as problematic due to the lack of consistency and completeness. This speaks to the need of standardizations between dictionaries, concrete grammar theories, and being up-to-date with the arrival of new words. In the work of Nguyen C. T. et al. (2007), corpus training was done manually by linguists. This was very time-consuming and costly. Because the task is performed only once, a corpus will go stale and will get out-of-date.</context>
</contexts>
<marker>Ha, Thang, Mai, 2005</marker>
<rawString>Le Thanh Ha, Huynh Quyet Thang, Luong Chi Mai. 2005. A Primary Study on Summarization of Documents in Vietnamese. The First International Congress of the International Federation for Systems Research, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L H Phuong</author>
<author>H T Vinh</author>
</authors>
<title>Maximum Entropy Approach to Sentence Boundary Detection of Vietnamese Texts,</title>
<date>2008</date>
<booktitle>IEEE International Conference on Research, Innovation and Vision for the Future RIVF</booktitle>
<marker>Phuong, Vinh, 2008</marker>
<rawString>L. H. Phuong and H. T. Vinh, 2008, Maximum Entropy Approach to Sentence Boundary Detection of Vietnamese Texts, IEEE International Conference on Research, Innovation and Vision for the Future RIVF 2008, Vietnam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ha</author>
</authors>
<title>A method for word segmentation in Vietnamese.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Corpus Linguistics,</booktitle>
<location>Lancaster, UK.</location>
<contexts>
<context position="1877" citStr="Ha, (2003)" startWordPosition="299" endWordPosition="300">phasize a need for natural language such as search engines or translation tools to process the data correctly. With this emphasis, we need to have a way to improve and automate the training process as well as expanding its training data. Previous works in constructing segmentation systems for the Vietnamese language relied on single source of information such as newspapers or electronic dictionaries (Le H. Phuong et al. 2008, Dinh Dien and Vu Thuy, 2006, Le T. Ha et al., 2005). Mono-source corpora would work best within their domain, and might not work well externally per O’Neil (2007). Le A. Ha, (2003) described the dictionary based approach as problematic due to the lack of consistency and completeness. This speaks to the need of standardizations between dictionaries, concrete grammar theories, and being up-to-date with the arrival of new words. In the work of Nguyen C. T. et al. (2007), corpus training was done manually by linguists. This was very time-consuming and costly. Because the task is performed only once, a corpus will go stale and will get out-of-date. Dinh et al. (2008), in a comparison with major Vietnamese segmentation approaches, concluded that the handling of unknown compou</context>
<context position="3430" citStr="Ha, 2003" startWordPosition="549" endWordPosition="550">present our approach in building a large web corpus for a word segmentation function and compare our result against a sophisticated algorithm built on a human trained corpus. Finally, we provide our conclusion and offer suggestions for future research directions. 2 Vietnamese Word Segmentation Problems Vietnamese (Tiếng Việt) is the official language of Vietnam. The current writing system originates from the Latin alphabet, with diacritics for tones and certain letters. Vietnamese is often mistakenly judged as a “monosyllabic” language. However, the majority of the words are disyllabic (Le A. Ha, 2003) covering reduplication and adjectives. Its grammar depends on word ordering and sentence structure rather than morphology. Even though there is a space separating 171 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 171–178, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP sound units, there is nothing used to identify word boundary. Examples in Figure 1. are used to illustrate the difficulty of Vietnamese word segmentation when compared it to English. There are 256 possible sequences (2n-1) of segmentation in this example. Figure 1. Ambiguity of wor</context>
</contexts>
<marker>Ha, 2003</marker>
<rawString>L. A. Ha. 2003. A method for word segmentation in Vietnamese. In Proceedings of the International Conference on Corpus Linguistics, Lancaster, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Motoko Ueyama</author>
</authors>
<title>Building general and special-purpose corpora by Web Crawling.</title>
<date>2006</date>
<booktitle>Proceedings of the 13th NIJL International Symposium, Language Corpora: Their Compilation and Application.</booktitle>
<pages>31--40</pages>
<marker>Baroni, Ueyama, 2006</marker>
<rawString>Marco Baroni, Motoko Ueyama. 2006. Building general and special-purpose corpora by Web Crawling. Proceedings of the 13th NIJL International Symposium, Language Corpora: Their Compilation and Application. 31-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Binh</author>
<author>B H Tran</author>
</authors>
<date>2001</date>
<booktitle>Vietnamese Language Learning Framework – Part One: s Linguistic.</booktitle>
<marker>Binh, Tran, 2001</marker>
<rawString>Ngo. N. Binh, B. H. Tran. 2001. Vietnamese Language Learning Framework – Part One: s Linguistic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nguyen</author>
</authors>
<title>Query preprocessing: improving web search through a Vietnamese word tokenization approach. SIGIR</title>
<date>2008</date>
<pages>765--766</pages>
<marker>Nguyen, 2008</marker>
<rawString>Nguyen D. 2008. Query preprocessing: improving web search through a Vietnamese word tokenization approach. SIGIR 2008: 765-766.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>J Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<booktitle>Center Research in Computing Technology,</booktitle>
<pages>10--98</pages>
<institution>Harvard University,</institution>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen, J. Goodman. 1998. An empirical study of smoothing techniques for language modeling. Center Research in Computing Technology, Harvard University, TR-10-98</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thanh Bon Nguyen</author>
</authors>
<title>Thi Minh Huyen Nguyen, Laurent Romary, Xuan Luong Vu.</title>
<date>2006</date>
<publisher>Springer</publisher>
<location>Netherlands</location>
<marker>Nguyen, 2006</marker>
<rawString>Thanh Bon Nguyen, Thi Minh Huyen Nguyen, Laurent Romary, Xuan Luong Vu. 2006. A lexicon for Vietnamese language processing. Language Resources and Evaluation. Springer Netherlands</rawString>
</citation>
<citation valid="true">
<authors>
<author>V-B Le</author>
<author>B Bigi</author>
<author>L Besacier</author>
<author>E Castelli</author>
</authors>
<title>Using the Web for fast language model construction in minority languages&amp;quot;,</title>
<date>2003</date>
<location>Eurospeech&apos;03, Geneva, Switzerland,</location>
<marker>Le, Bigi, Besacier, Castelli, 2003</marker>
<rawString>V-B. Le, B. Bigi, L. Besacier, E. Castelli, 2003. Using the Web for fast language model construction in minority languages&amp;quot;, Eurospeech&apos;03, Geneva, Switzerland, September 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wirote Aroonmanakun</author>
</authors>
<title>Collocation and Thai Word Segmentation,</title>
<date>2002</date>
<booktitle>Proceedings of SNLPOriental COCOSDA</booktitle>
<marker>Aroonmanakun, 2002</marker>
<rawString>Wirote Aroonmanakun. 2002. Collocation and Thai Word Segmentation, Proceedings of SNLPOriental COCOSDA 2002</rawString>
</citation>
<citation valid="false">
<title>Vietnamese morphology: From Wikipedia: http://en.wikipedia.org/wiki/Vietnamese morpholo gy</title>
<marker></marker>
<rawString>Vietnamese morphology: From Wikipedia: http://en.wikipedia.org/wiki/Vietnamese morpholo gy</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yahoo</author>
</authors>
<title>Boss Web Service API</title>
<marker>Yahoo, </marker>
<rawString>Yahoo! Boss Web Service API</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>