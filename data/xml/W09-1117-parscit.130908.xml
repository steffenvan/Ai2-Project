<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000387">
<title confidence="0.9787845">
Improving Translation Lexicon Induction from Monolingual Corpora via
Dependency Contexts and Part-of-Speech Equivalences
</title>
<author confidence="0.997177">
Nikesh Garera, Chris Callison-Burch, David Yarowsky
</author>
<affiliation confidence="0.999714">
Department of Computer Science, Johns Hopkins University
</affiliation>
<address confidence="0.9557">
Baltimore MD, USA
</address>
<email confidence="0.999713">
{ngarera,ccb,yarowsky}@cs.jhu.edu
</email>
<sectionHeader confidence="0.994821" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999875105263158">
This paper presents novel improvements
to the induction of translation lexicons
from monolingual corpora using multilin-
gual dependency parses. We introduce a
dependency-based context model that in-
corporates long-range dependencies, vari-
able context sizes, and reordering. It pro-
vides a 16% relative improvement over
the baseline approach that uses a fixed
context window of adjacent words. Its
Top 10 accuracy for noun translation is
higher than that of a statistical translation
model trained on a Spanish-English par-
allel corpus containing 100,000 sentence
pairs. We generalize the evaluation to
other word-types, and show that the per-
formance can be increased to 18% rela-
tive by preserving part-of-speech equiva-
lencies during translation.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999775527777777">
Recent trends in machine translation illustrate that
highly accurate word and phrase translations can be
learned automatically given enough parallel training
data (Koehn et al., 2003; Chiang, 2007). However,
large parallel corpora exist for only a small frac-
tion of the world’s languages, leading to a bottleneck
for building translation systems in low-density lan-
guages such as Swahili, Uzbek or Punjabi. While
parallel training data is uncommon for such lan-
guages, more readily available resources include
small translation dictionaries, comparable corpora,
and large amounts of monolingual data.
The marked difference in the availability of
monolingual vs parallel corpora has led several
researchers to develop methods for automatically
learning bilingual lexicons, either by using mono-
lingual corpora (Rapp, 1999; Koehn and Knight,
2002; Schafer and Yarowsky, 2002; Haghighi et al.,
2008) or by exploiting the cross-language evidence
of closely related “bridge” languages that have more
resources (Mann and Yarowsky, 2001).
This paper investigates new ways of learning
translations from monolingual corpora. We extend
the Rapp (1999) model of context vector projection
using a seed lexicon. It is based on the intuition that
translations will have similar lexical context, even in
unrelated corpora. For example, in order to translate
the word “airplane”, the algorithm builds a context
vector which might contain terms such as “passen-
gers”, “runway”, “airport”, etc. and words in tar-
get language that have their translations (obtained
via seed lexicon) in surrounding context can be con-
sidered as likely translations. We extend the basic
approach by formulating a context model that uses
dependency trees. The use of dependencies has the
following advantages:
</bodyText>
<listItem confidence="0.946051846153846">
• Long distance dependencies allow associated
words to be included in the context vector even
if they fall outside of the fixed-window used in
the baseline model.
• Using relationships like parent and child in-
stead of absolute positions alleviates problems
when projecting vectors between languages
with different word orders.
• It achieves better performance than baseline
context models across the board, and better
performance than statistical translation models
on Top-10 accuracy for noun translation when
trained on identical data.
</listItem>
<page confidence="0.979579">
129
</page>
<note confidence="0.9898895">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 129–137,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9996605">
We further show that an extension based on part-
of-speech clustering can give similar accuracy gains
for learning translations of all word-types, deepen-
ing the findings of previous literature which mainly
focused on translating nouns (Rapp, 1999; Koehn
and Knight, 2002; Haghighi et al., 2008).
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99995871875">
The literature on translation lexicon induction for
low-density languages falls in to two broad cate-
gories: 1) Effectively utilizing similarity between
languages by choosing a high-resource “bridge” lan-
guage for translation (Mann and Yarowsky, 2001;
Schafer and Yarowsky, 2002) and 2) Extracting
noisy clues (such as similar context) from mono-
lingual corpora with help of a seed lexicon (Rapp,
1999; Koehn and Knight, 2002; Schafer and
Yarowsky, 2002, Haghighi et al., 2008). The lat-
ter category is more relevant to this work and is ex-
plained in detail below.
The idea of words with similar meaning having
similar contexts in the same language comes from
the Distributional Hypothesis (Harris, 1985) and
Rapp (1999) was the first to propose using context of
a given word as a clue to its translation. Given a Ger-
man word with an unknown translation, a German
context vector is constructed by counting its sur-
rounding words in a monolingual German corpus.
Using an incomplete bilingual dictionary, the counts
of the German context words with known transla-
tions are projected onto an English vector. The pro-
jected vector for the German word is compared to
the vectors constructed for all English words using
a monolingual English corpus. The English words
with the highest vector similarity are treated as trans-
lation candidates. The original work employed a rel-
atively large bilingual dictionary containing approx-
imately 16,000 words and tested only on a small col-
lection of 100 manually selected nouns.
Koehn and Knight (2002) tested this idea on a
larger test set consisting of the 1000 most frequent
words from a German-English lexicon. They also
incorporated clues such as frequency and ortho-
graphic similarity in addition to context. Schafer
and Yarowsky, (2002) independently proposed us-
ing frequency, orthographic similarity and also
showed improvements using temporal and word-
burstiness similarity measures, in addition to con-
text. Haghighi et al., (2008) made use of contex-
tual and orthographic clues for learning a generative
model from monolingual corpora and a seed lexicon.
All of the aforementioned work defines context
similarity in terms of the adjacent words over a win-
dow of some arbitary size (usually 2 to 4 words), as
initially proposed by Rapp (1999). We show that the
model for surrounding context can be improved by
using dependency information rather than strictly re-
lying on adjacent words, based on the success of de-
pendency trees for monolingual clustering and dis-
ambiguation tasks (Lin and Pantel, 2002; Pado and
Lapata, 2007) and the recent developments in multi-
lingual dependency parsing literature (Buchholz and
Marsi, 2006; Nivre et al., 2007).
We further differentiate ourselves from previous
work by conducting a second evaluation which ex-
amines the accuracy of translating all word types,
rather than just nouns. While the straightforward ap-
plication of context-based model gives a lower over-
all accuracy than nouns alone, we show how learn-
ing a mapping of part-of-speech tagsets between the
source and target language can result in comparable
performance to that of noun translation.
</bodyText>
<sectionHeader confidence="0.9259575" genericHeader="method">
3 Translation by Context Vector
Projection
</sectionHeader>
<bodyText confidence="0.999961933333333">
This section details how translations are discovered
from monolingual corpora through context vector
projection. Section 3.1 defines alternative ways of
modeling context vectors, and including baseline
models and our dependency-based model.
The central idea of Rapp’s method for learning
translations is that of context vector projection and
vector similarity. The goodness of semantic “fit” of
candidate translations is measured as the vector sim-
ilarity between two words. Those vectors are drawn
from two different languages, so the vector for one
word must first be projected onto the language space
of the other. The algorithm for creating, projecting
and comparing vectors is described below, and illus-
trated in Figure 1.
</bodyText>
<sectionHeader confidence="0.746055" genericHeader="method">
Algorithm:
</sectionHeader>
<footnote confidence="0.46817525">
1. Extract context vectors:
Given a word in source language, say sw, create
a vector using the surrounding context words
and call this reference source vector rss. for
</footnote>
<page confidence="0.995879">
130
</page>
<figureCaption confidence="0.9967215">
Figure 1: Illustration of (Rapp, 1999) model for translating spanish word “crecimiento (growth)” via dependency context vectors
extracted from respective monolingual corpora as explained in Section 3.1.2
</figureCaption>
<equation confidence="0.9799826">
ci
r
+ci2 ·r2+....+cin ·rn
1·
1
</equation>
<bodyText confidence="0.999763">
source word sw. The actual composition of this
vector varies depending on how the surround-
ing context is modeled. The context model is
independent of the algorithm, and various mod-
els are explained in later sections.
</bodyText>
<listItem confidence="0.951481">
2. Project reference source vector:
</listItem>
<bodyText confidence="0.9931292">
Project all the source vector words contained in
the projection dictionary onto the vector space
for the target language, retaining the counts
from source corpus. This vector now exists in
the target language space and is called the ref-
erence target vector rtsw. This vector may be
sparse, depending on how complete the bilin-
gual dictionary is, because words without dic-
tionary entires will receive zero counts in the
reference target vector.
</bodyText>
<listItem confidence="0.976536">
3. Rank candidates by vector similarity:
</listItem>
<bodyText confidence="0.98682225">
For each word twi in the target language a con-
text vector is created using the target language
monolingual corpora as in Step 1. Compute a
similarity score between the context vector of
twi = (ci1, ci2, ...., cin) and reference target vec-
tor rtsw = (r1, r2, ...., rn). The word with the
maximum similarity score t∗wi is chosen as the
candidate translation of sw.
The vector similarity can be computed in a
number of ways. Our setup we used cosine
similarity:
t∗wi =argmaxtwi V cz1+c2i2 +...+c � �rl +r22+...+r2 n
Rapp (1999) used l1-norm metric after nor-
malizing the vectors to unit length, Koehn and
Knight (2002) used Spearman rank order cor-
relation, and Schafer and Yarowsky (2002) use
cosine similarity. We found that cosine simi-
larity gave the best results in our experimental
conditions. Other similarity measures may be
used equally well.
</bodyText>
<subsectionHeader confidence="0.999971">
3.1 Models of Context
</subsectionHeader>
<bodyText confidence="0.999992">
We compared several context models. Empirical re-
sults for their ability to find accurate translations are
given in Section 5.
</bodyText>
<subsectionHeader confidence="0.739433">
3.1.1 Baseline model
</subsectionHeader>
<bodyText confidence="0.999989">
In the baseline model, the context is computed
using adjacent words as in (Rapp,1999; Koehn
and Knight, 2002; Schafer and Yarowsky, 2002;
Haghighi et al., 2008). Given a word in source lan-
guage, say sw, count all its immediate context words
appearing in a window of four words. The counts
are collected seperately for each position by keeping
track of four seperate vectors for positions -2, -1, +1
and +2. Thus each vector is a sparse vector, having
the # of dimensions as the size of source language
vocabulary. Each dimension is also reweighted by
multiplying the inverse document frequency (IDF)
</bodyText>
<page confidence="0.996435">
131
</page>
<figureCaption confidence="0.999762">
Figure 2: Illustration of using dependency trees to model richer contexts for projection
</figureCaption>
<bodyText confidence="0.9999812">
as in the standard TF.IDF weighting scheme1. These
vectors are then concatenated into a single vector,
having dimension four times the size of the vocabu-
lary. This vector is called the reference source vector
rss. for source word sw.
</bodyText>
<subsectionHeader confidence="0.940861">
3.1.2 Modeling context using dependency trees
</subsectionHeader>
<bodyText confidence="0.999725">
We use dependency parsing to extend the con-
text model. Our context vectors use contexts derived
from head-words linked by dependency trees instead
of using the immediate adjacent lexical words. The
use of dependency trees for modeling contexts has
been shown to help in monolingual clustering tasks
of finding words with similar meaning (Lin and Pan-
tel, 2002) and we show how they can be effectively
used for translation lexicon induction.
</bodyText>
<subsectionHeader confidence="0.899403">
Position Adjacent Dependency
Context Context
</subsectionHeader>
<figure confidence="0.7794725">
-2 para camino
-1 el para
+1 y prosperidad, y, el
+2 la econ´omica
</figure>
<tableCaption confidence="0.896708">
Table 1: Contrasting context words derived from the adjacent
vs dependency models for the above example
</tableCaption>
<bodyText confidence="0.970934714285714">
The four vectors for positions -1, +1, -2 and +2
in the baseline model get mapped to immediate par-
ent (-1), immediate child (+1), grandparent (-2) and
grandchild (+2). An example of using the depen-
dency tree context is shown in Figure 2, and the de-
pendency context is shown in contrast with the ad-
jacent context in Table 1, showing the selection of
more salient words by using the dependencies.
Note that while we are limiting to four positions
in the tree, it does not imply that only a maximum of
four context words are selected since the word can
have multiple immediate children depending upon
the dependency parse of the sentence. Hence, this
approach allows for a dynamic context size, with the
1In order to compute the IDF, while there were no clear doc-
ument boundaries in our corpus, a virtual document boundary
was created by binning after every 1000 words.
number of context words varying with the number of
children and parents at the two levels.
Another advantage of this method is that it al-
leviates the reordering problem as we use tree po-
sitions (consisting of head-words) as compared to
the adjacent position in the baseline context model.
For example, if the source spanish word to be trans-
lated was “prosperidad”, then in the example shown
in Figure 2, in case of adjacent context, the con-
text word “econ´omica” will show up in +1 position
in Spanish and -1 position in English (as adjectives
come before nouns in English) but in case of depen-
dency context, the adjective will be the child of noun
and hence will show up in +1 position in both lan-
guages. Thus, we do not need to use a bag of word
model as in Section 3 in order to avoid learning the
explicit mapping that adjectives and nouns in Span-
ish and English are reversed.
</bodyText>
<sectionHeader confidence="0.997806" genericHeader="method">
4 Experimental Design
</sectionHeader>
<bodyText confidence="0.9904345">
For our initial set of experiments we compared sev-
eral different vector-based context models:
</bodyText>
<listItem confidence="0.988960352941177">
• Adjbow – A baseline model which used bag of
words model with a fixed window of 4 words,
two on either side of the word to be translated.
• Adjposn – A second baseline that used a fixed
window of 4 words but which took positional
into account.
• Depbow – A dependency model which did not
distinguish between grandparent, parent, child
and grandparent relations, analogous to the bag
of words model.
• Depposn – A dependency model which did in-
clude such relationships, and was analogous to
the position-based baseline.
• Depposn + rev – The above Depposn model ap-
plied in both directions (Spanish-to-English
and English-to-Spanish) using their sum as the
final translation score.
</listItem>
<bodyText confidence="0.9943755">
We contrasted the accuracy of the above methods,
which use monolingual corpora, with a statistical
</bodyText>
<page confidence="0.991113">
132
</page>
<bodyText confidence="0.999850666666667">
model trained on bilingual parallel corpora. We re-
fer to that model as Mosesen-es-100k, because it was
trained using the Moses toolkit (Koehn et al., 2007).
</bodyText>
<subsectionHeader confidence="0.99722">
4.1 Training Data
</subsectionHeader>
<bodyText confidence="0.998094318181818">
All context models were trained on a Spanish cor-
pus containing 100,000 sentences with 2.13 million
words and an English corpus containing 100,000
sentences with 2.07 million words. The Spanish cor-
pus was parsed using the MST dependency parser
(McDonald et al., 2005) trained using dependency
trees generated from the the English Penn Treebank
(Marcus et al., 1993) and Spanish CoNLL-X data
(Buchholz and Marsi, 2006).
So that we could directly compare against sta-
tistical translation models, our Spanish and English
monolingual corpora were drawn from the Europarl
parallel corpus (Koehn, 2005). The fact that our
two monolingual corpora are taken from a parallel
corpus ensures that the assumption that similar con-
texts are a good indicator of translation holds. This
assumption underlies in all work of translation lex-
icon induction from comparable monolingual cor-
pora, and here we strongly bias toward that assump-
tion. Despite the bias, the comparison of different
context models holds, since all models are trained
on the same data.
</bodyText>
<subsectionHeader confidence="0.948181">
4.2 Evaluation Criterion
</subsectionHeader>
<bodyText confidence="0.999950894736842">
The models were evaluated in terms of exact-match
translation accuracy of the 1000 most frequent
nouns in a English-Spanish dictionary. The accuracy
was calculated by counting how many mappings ex-
actly match one of the entries in the dictionary. This
evaluation criterion is similar to the setup used by
Koehn and Knight (2002). We compute the Top N
accuracy in the standard way as the number of Span-
ish test words whose Top N English translation can-
didates contain a lexicon translation entry out of the
total number of Spanish words that can be mapped
correctly using the lexicon entries. Thus if “crec-
imiento, growth” is the correct mapping based on the
lexicon entries, the translation for “crecimiento” will
be counted as correct if “growth” occurs in the Top
N English translation candidates for “crecimiento”.
Note that the exact-match accuracy is a conser-
vative estimate as it is possible that the algorithm
may propose a reasonable translation for the given
</bodyText>
<table confidence="0.99864925">
camino
Depposn Cntxt Model Adjbow Cntxt Model
way 0.124 intentions 0.22
solution 0.097 way 0.21
steps 0.094 idea 0.20
path 0.093 thing 0.20
debate 0.085 faith 0.18
account 0.082 steps 0.17
means 0.080 example 0.17
work 0.079 news 0.16
approach 0.074 work 0.16
issue 0.073 attitude 0.15
</table>
<tableCaption confidence="0.996499">
Table 2: Top 10 translation candidates for the spanish word
</tableCaption>
<figureCaption confidence="0.89854">
“camino (way)” for the best adjacent context model (Adjbow)
and best dependency context model (Depposn). The bold English
terms show the acceptable translations.
Figure 3: Precision/Recall curve showing superior perfor-
mance of dependency context model as compared to adjacent
context at different recall points. Precision is the fraction of
tested Spanish words with Top 1 translation correct and Recall
is fraction of the 1000 Spanish words tested upon.
</figureCaption>
<bodyText confidence="0.999957888888889">
Spanish word but is marked incorrect if it does not
exist in the lexicon. Because it would be intractable
to compare each projected vector against the vectors
for all possible English words, we limited ourselves
to comparing the projected vector from each Spanish
word against the vectors for the 1000 most frequent
English nouns, following along the lines of previ-
ous work (Koehn and Knight, 2002; Haghighi et al.,
2008).
</bodyText>
<sectionHeader confidence="0.999941" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999885666666667">
Table 3 gives the Top 1 and Top 10 accuracy for
each of the models on their ability to translate Span-
ish nouns into English. Examples of the top 10
translations using the best performing baseline and
dependency-based models are shown in Table 2. The
baseline models Adjposn and Adjbow differ in that the
</bodyText>
<page confidence="0.997643">
133
</page>
<table confidence="0.999938142857143">
Model AccTop 1 AccTop 10
Adjbow 35.3% 59.8%
Adjposn 20.9% 46.9%
Depbow 41.0% 62.0%
Depposn 41.0% 64.1%
Depposn + rev 42.9% 65.5%
Mosesen-es-100k 56.4% 62.7%
</table>
<tableCaption confidence="0.996596333333333">
Table 3: Performance of various context-based models
learned from monolingual corpora and phrase-table learned
from parallel corpora on Noun translation.
</tableCaption>
<bodyText confidence="0.999384">
latter disregards the position information in the con-
text vector and simply uses a bag of words instead.
Table 3 shows that Adjbow gains using this simplifi-
cation. A bag of words vector approach pools counts
together, which helps to reduce data sparsity. In
the position based model the vector is four times as
long. Additionally, the bag of words model can help
when there is local re-ordering between the two lan-
guages. For instance, Spanish adjectives often fol-
low nouns whereas in English the the ordering is
reversed. Thus, one can either learn position map-
pings, that is, position +1 for adjectives in Spanish is
the same as position -1 in English or just add the the
word counts from different positions into one com-
mon vector as considered in the bag of words ap-
proach.
Using dependency trees also alleviates the prob-
lem of position mapping between source and target
language. Table 3 shows the performance using the
dependency based models outperforms the baseline
models substantially. Comparing Depbow to Depposn
shows that ignoring the tree depth and treating it as
a bag of words does not increase the performance.
This contrasts with the baseline models. The de-
pendency positions account for re-ordering automat-
ically. The precision-recall curve in Figure 3 shows
that the dependency-based context performs better
than adjancet context at almost all recall levels.
The Mosesen-es-100k model shows the performance
of the statistical translation model trained on a bilin-
gual parallel corpus. While the system performs best
in Top 1 accuracy, the dependency context-based
model that ignores the sentence alignments surpris-
ingly performs better in case of Top 10 accuracy,
showing substantial promise.
While computing the accuracy using the phrase-
table learned from parallel corpora (Mosesen-es-100k),
the translation probabilities from both directions
(p(esIen) and p(enIes)) were used to rank the can-
didates. We also apply the monolingual context-
based model in the reverse direction (from English
to Spanish) and the row with label Depposn + rev in
Table 3 shows further gains using both directions.
</bodyText>
<table confidence="0.997328818181818">
Spanish English Sim Is present
Score in lexicon
se˜nores gentlemen 0.99 NO
xenofobia xenophobia 0.87 YES
diversidad diversity 0.73 YES
chipre cyprus 0.66 YES
mujeres women 0.65 YES
alemania germany 0.65 YES
explotaci´on exploitation 0.63 YES
hombres men 0.62 YES
rep´ublica republic 0.60 YES
racismo racism 0.59 YES
comercio commerce 0.58 YES
continente continent 0.53 YES
gobierno government 0.52 YES
israel israel 0.52 YES
francia france 0.52 YES
fundamento certainty 0.51 NO
suecia sweden 0.50 YES
tr´afico space 0.49 NO
televisi´on tv 0.48 YES
francesa portuguese 0.48 NO
</table>
<tableCaption confidence="0.6387386">
Table 4: List of 20 most confident mappings using the de-
pendency context based model for noun translation. Note that
although the first mapping is the correct one, it was not present
in the lexicon used for evaluation and hence is marked as incor-
rect.
</tableCaption>
<sectionHeader confidence="0.843686" genericHeader="method">
6 Further Extensions: Generalizing to
</sectionHeader>
<bodyText confidence="0.97531605">
other word types via tagset mapping
Most of the previous literature on this problem fo-
cuses on evaluating on nouns (Rapp, 1999; Koehn
and Knight 2002; Haghighi et al., 2008). However
the vector projection approach is general, and should
be applicable to other word-types as well. We eval-
uated the models with new test set containing 1000
most frequent words (not just nouns) in the English-
Spanish lexicon.
We used the dependency-based context model to
create translations for this new set. The row labeled
Depposn in Table 5 shows that the accuracy on this
set is lower when compared to evaluating only on
nouns. The main reason for lower accuracy is that
closed class words are often the most frequent and
tend to have a wide range of contexts resulting in
reasonable translation for most words include open
class words via the context model. For instance, the
English preposition “to” appears as the most confi-
dent translation for 147 out of the 1000 Spanish test
</bodyText>
<page confidence="0.998001">
134
</page>
<figureCaption confidence="0.999418">
Figure 4: Illustration of using part-of-speech tag mapping to
restrict candidate space of translations
</figureCaption>
<bodyText confidence="0.982365944444445">
words and in none (rightly so) after restricting the
translations by part-of-speech categories.
This problem can be greatly reduced by making
use of the intuition that part-of-speech is often pre-
served in translation, thus the space of possible can-
didate translation can be largely reduced based on
the part-of-speech restrictions. For example, a noun
in source language will usually be translated as noun
in target language, determiner will be translated as
determiner and so on. This idea is more clearly il-
lustrated in in Figure 4. We do not impose a hard
restriction but rather compute a ranking based on
the conditional probability of candidate translation’s
part-of-speech tag given source word’s tag.
An interesting problem in using part-of-speech re-
strictions is that corpora in different languages have
been tagged using widely different tagsets and the
following subsection explains this problem in detail:
</bodyText>
<subsectionHeader confidence="0.9946315">
6.1 Mapping Part-of-Speech tagsets in
different languages
</subsectionHeader>
<bodyText confidence="0.999879416666667">
The English tagset was derived from the Penn tree-
bank consisting of 53 tags (including punctuation
markers) and the Spanish tagset was derived from
the Cast3LB dataset consisting of 57 tags but there
is a large difference in the morphological and syn-
tactic features marked by the tagset. For example,
the Spanish tagset as different tags for masculine and
feminine nouns and also has a different tag for coor-
dinated nouns, all of which need to be mapped to the
singular or plural noun category available in English
tagset. Figure 5 shows an illustration of the mapping
problem between the Spanish and English POS tags.
</bodyText>
<figureCaption confidence="0.9963695">
Figure 5: Illustration of mapping Spanish part-of-speech
tagset to English tagset. The tagsets vary greatly in notation and
the morphological/syntactic constituents represented and need
to be mapped first, using the algorithm described in Section 6.1.
</figureCaption>
<bodyText confidence="0.999975333333333">
We now describe an empirical approach for learn-
ing the mapping between tagsets using the English-
Spanish projection dictionary used in the monolin-
gual context-based models for translation. Given a
small English-Spanish bilingual dictionary and a n-
best list of part-of-speech tags for each word in the
dictionary2, we compute conditional probability of
translating a source word with pos tag sposi to a tar-
get with pos tag tposj as follows:
</bodyText>
<equation confidence="0.990736">
p(tposj  |sposi)(— c(sposi)
Esw ES, twET ASposi  |sw) - p(tposj|tw) - Idict(sw, tw)
K
swES p(sposi|sw)
</equation>
<bodyText confidence="0.997395">
where
</bodyText>
<listItem confidence="0.950265625">
• S and T are the source and target vocabulary in
the seed dictionary, with sw and tw being any
of the words in the respective sets.
• p(sposi|sw), p(tposj|tw) are obtained using rel-
ative frequencies in a part-of-speech tagged
corpus in the source/target languages respec-
tively, and are used as soft counts.
• Idict(sw, tw) is the indicator function with
</listItem>
<bodyText confidence="0.9791152">
value 1 if the pair (sw, tw) occurs in the seed
dictionary and 0 otherwise.
In essence, the mapping between tagsets is
learned using the known translations from a small
dictionary.
Given a source word sw to translate, its most
likely tag sus, and the most likely mapping of this
tag into English tis computed as above, the transla-
tion candidates with part-of-speech tag t�pos are con-
sidered for comparison with vector similarity and
</bodyText>
<footnote confidence="0.873564">
2The n-best part-of-speech tag list for any word in the dic-
tionary was derived using the relative frequencies in a part-of-
speech annotated corpora in the respective languages
</footnote>
<equation confidence="0.672888">
c(sposi, tposj) =
</equation>
<page confidence="0.990066">
135
</page>
<figureCaption confidence="0.997241">
Figure 6: Precision/Recall curve showing superior perfor-
mance of using part-of-speech equivalences for translating all
word-types. Precision is the fraction of tested Spanish words
with Top 1 translation correct and Recall is fraction of the 1000
Spanish words tested upon.
</figureCaption>
<bodyText confidence="0.99919">
the other candidates with tpos3 =� t∗pos are discarded
from the candidate space. Figure 4 shows an exam-
ple of restricting the candidate space using POS tags.
</bodyText>
<table confidence="0.999714666666667">
Model AccTop 1 AccTop 10
Depposn 35.1% 62.9%
+ POS 41.3% 66.4%
</table>
<tableCaption confidence="0.954265333333333">
Table 5: Performance of dependency context-based model
along with addition of part-of-speech mapping model on trans-
lating all word-types.
</tableCaption>
<bodyText confidence="0.9997308">
The row labeled +POS in Table 5 shows the part-
of-speech tags provides substantial gain as com-
pared to direct application of dependency context-
based model and is also comparable to the accuracy
obtained evaluating just on nouns in Table 3.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999917916666667">
This paper presents a novel contribution to the stan-
dard context models used when learning transla-
tion lexicons from monolingual corpora by vector
projection. We show that using contexts based on
dependency parses can provide more salient con-
texts, allow for dynamic context size, and account
for word reordering in the source and target lan-
guage. An exact-match evaluation shows 16% rela-
tive improvement by using a dependency-based con-
text model over the standard approach. Furthermore,
we show that our model, which is trained only on
monolingual corpora, outperforms the standard sta-
</bodyText>
<table confidence="0.996816272727273">
Spanish English Sim Is present
Score in lexicon
se˜nores gentlemen 0.99 NO
chipre cyprus 0.66 YES
mujeres women 0.65 YES
alemania germany 0.65 YES
hombres men 0.62 YES
expresar express 0.60 YES
racismo racism 0.59 YES
interior internal 0.55 YES
gobierno government 0.52 YES
francia france 0.52 YES
cultural cultural 0.51 YES
suecia sweden 0.50 YES
fundamento basis 0.48 YES
francesa french 0.48 YES
entre between 0.47 YES
origen origin 0.46 YES
tr´afico traffic 0.45 YES
de of 0.44 YES
social social 0.43 YES
ruego thank 0.43 NO
</table>
<tableCaption confidence="0.980703">
Table 6: List of 20 most confident mappings using the depen-
</tableCaption>
<bodyText confidence="0.9947038">
dency context with the part-of-speech mapping model translat-
ing all word-types. Note that although the second best mapping
in Table4 for noun-translation is for xenofobia with score 0.87,
xenofobia is not among the 1000 most frequent words (of all
word-types) and thus is not in this test set.
tistical MT approach to learning phrase tables when
trained on the same amount of sentence-aligned par-
allel corpora, when evaluated on Top 10 accuracy.
As a second contribution, we go beyond previ-
ous literature which evaluated only on nouns. We
showed how preserving a word’s part-of-speech in
translation can improve performance. We further
proposed a solution to an interesting sub-problem
encountered on the way. Since part-of-speeech
tagsets are not identical across two languages, we
propose a way of learning their mapping automat-
ically. Restricting candidate space based on this
learned tagset mapping resulted in 18% improve-
ment over the direct application of context-based
model to all word-types.
Dependency trees help improve the context for
translation substantially and their use opens up the
question of how the context can be enriched further
making use of the hidden structure that may provide
clues for a word’s translation. We also believe that
the problem of learning the mapping between tagsets
in two different languages can be used in general for
other NLP tasks making use of projection of words
and its morphological/syntactic properties between
languages.
</bodyText>
<page confidence="0.998429">
136
</page>
<sectionHeader confidence="0.993895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923396551724">
S. Buchholz and E. Marsi. 2006. Conll-X shared task
on multilingual dependency parsing. Proceedings of
CoNLL, pages 189–210.
Y. Cao and H. Li. 2002. Base Noun Phrase translation
using web data and the EM algorithm. Proceedings of
COLING-Volume 1, pages 1–7.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201–228.
P. Fung and L.Y. Yee. 1998. An IR Approach for
Translating New Words from Nonparallel, Compara-
ble Texts. Proceedings of ACL, 36:414–420.
A. Haghighi, P. Liang, T. Berg-Kirkpatrick, and D. Klein.
2008. Learning bilingual lexicons from monolingual
corpora. Proceedings of ACL-HLT, pages 771–779.
Z. Harris. 1985. Distributional structure. Katz, J. J. (ed.),
The Philosophy of Linguistics, pages 26–47.
P. Koehn and K. Knight. 2002. Learning a translation
lexicon from monolingual corpora. Proceedings of
ACL Workshop on Unsupervised Lexical Acquisition,
pages 9–16.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proceedings of NAACL-
HLT, pages 48–54.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. Proceedings
of ACL, companian volume, pages 177–180.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. MT Summit X.
D. Lin and P. Pantel. 2002. Discovery of inference rules
for question-answering. Natural Language Engineer-
ing, 7(04):343–360.
G.S. Mann and D. Yarowsky. 2001. Multipath transla-
tion lexicon induction via bridge languages. Proceed-
ings of NAACL, pages 151–158.
M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of En-
glish: the Penn treebank. Computational Linguistics,
19(2):313–330.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005.
Non-projective dependency parsing using spanning
tree algorithms. Proceedings of EMNLP-HLT, pages
523–530.
J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The conll 2007
shared task on dependency parsing. Proceedings of
the CoNLL Shared Task Session of EMNLP-CoNLL,
pages 915–932.
S. Pado and M. Lapata. 2007. Dependency-Based Con-
struction of Semantic Space Models. Computational
Linguistics, 33(2):161–199.
R. Rapp. 1999. Automatic identification of word trans-
lations from unrelated English and German corpora.
Proceedings of ACL, pages 519–526.
C. Schafer and D. Yarowsky. 2002. Inducing translation
lexicons via diverse similarity measures and bridge
languages. Proceedings of COLING, pages 1–7.
</reference>
<page confidence="0.997826">
137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.841432">
<title confidence="0.9919725">Improving Translation Lexicon Induction from Monolingual Corpora Dependency Contexts and Part-of-Speech Equivalences</title>
<author confidence="0.979398">Nikesh Garera</author>
<author confidence="0.979398">Chris Callison-Burch</author>
<author confidence="0.979398">David</author>
<affiliation confidence="0.946111">Department of Computer Science, Johns Hopkins Baltimore MD,</affiliation>
<abstract confidence="0.9985971">This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses. We introduce a dependency-based context model that incorporates long-range dependencies, variable context sizes, and reordering. It provides a 16% relative improvement over the baseline approach that uses a fixed context window of adjacent words. Its Top 10 accuracy for noun translation is higher than that of a statistical translation model trained on a Spanish-English parallel corpus containing 100,000 sentence pairs. We generalize the evaluation to other word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equivalencies during translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>Conll-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>Proceedings of CoNLL,</booktitle>
<pages>189--210</pages>
<contexts>
<context position="6506" citStr="Buchholz and Marsi, 2006" startWordPosition="978" endWordPosition="981">tive model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the recent developments in multilingual dependency parsing literature (Buchholz and Marsi, 2006; Nivre et al., 2007). We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types, rather than just nouns. While the straightforward application of context-based model gives a lower overall accuracy than nouns alone, we show how learning a mapping of part-of-speech tagsets between the source and target language can result in comparable performance to that of noun translation. 3 Translation by Context Vector Projection This section details how translations are discovered from monolingual corpora through conte</context>
<context position="14780" citStr="Buchholz and Marsi, 2006" startWordPosition="2347" endWordPosition="2350">l corpora, with a statistical 132 model trained on bilingual parallel corpora. We refer to that model as Mosesen-es-100k, because it was trained using the Moses toolkit (Koehn et al., 2007). 4.1 Training Data All context models were trained on a Spanish corpus containing 100,000 sentences with 2.13 million words and an English corpus containing 100,000 sentences with 2.07 million words. The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus (Koehn, 2005). The fact that our two monolingual corpora are taken from a parallel corpus ensures that the assumption that similar contexts are a good indicator of translation holds. This assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption. Despite the bias, the comparison of different context models holds, since all models are train</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. Conll-X shared task on multilingual dependency parsing. Proceedings of CoNLL, pages 189–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Cao</author>
<author>H Li</author>
</authors>
<title>Base Noun Phrase translation using web data and the EM algorithm.</title>
<date>2002</date>
<booktitle>Proceedings of</booktitle>
<volume>1</volume>
<pages>1--7</pages>
<marker>Cao, Li, 2002</marker>
<rawString>Y. Cao and H. Li. 2002. Base Noun Phrase translation using web data and the EM algorithm. Proceedings of COLING-Volume 1, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical Phrase-Based Translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1245" citStr="Chiang, 2007" startWordPosition="169" endWordPosition="170">t uses a fixed context window of adjacent words. Its Top 10 accuracy for noun translation is higher than that of a statistical translation model trained on a Spanish-English parallel corpus containing 100,000 sentence pairs. We generalize the evaluation to other word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equivalencies during translation. 1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (Koehn et al., 2003; Chiang, 2007). However, large parallel corpora exist for only a small fraction of the world’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical Phrase-Based Translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>L Y Yee</author>
</authors>
<title>An IR Approach for Translating New Words from Nonparallel, Comparable Texts.</title>
<date>1998</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>36--414</pages>
<marker>Fung, Yee, 1998</marker>
<rawString>P. Fung and L.Y. Yee. 1998. An IR Approach for Translating New Words from Nonparallel, Comparable Texts. Proceedings of ACL, 36:414–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>P Liang</author>
<author>T Berg-Kirkpatrick</author>
<author>D Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-HLT,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="1941" citStr="Haghighi et al., 2008" startWordPosition="269" endWordPosition="272">orld’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related “bridge” languages that have more resources (Mann and Yarowsky, 2001). This paper investigates new ways of learning translations from monolingual corpora. We extend the Rapp (1999) model of context vector projection using a seed lexicon. It is based on the intuition that translations will have similar lexical context, even in unrelated corpora. For example, in order to translate the word “airplane”, the algorithm builds a context vector which might contain terms such as “passengers”, “runway”, “airport”, etc. and words in target </context>
<context position="3835" citStr="Haghighi et al., 2008" startWordPosition="550" endWordPosition="553"> board, and better performance than statistical translation models on Top-10 accuracy for noun translation when trained on identical data. 129 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 129–137, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics We further show that an extension based on partof-speech clustering can give similar accuracy gains for learning translations of all word-types, deepening the findings of previous literature which mainly focused on translating nouns (Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). 2 Related Work The literature on translation lexicon induction for low-density languages falls in to two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is explained in detail below. The idea of words with </context>
<context position="5814" citStr="Haghighi et al., (2008)" startWordPosition="865" endWordPosition="868">l work employed a relatively large bilingual dictionary containing approximately 16,000 words and tested only on a small collection of 100 manually selected nouns. Koehn and Knight (2002) tested this idea on a larger test set consisting of the 1000 most frequent words from a German-English lexicon. They also incorporated clues such as frequency and orthographic similarity in addition to context. Schafer and Yarowsky, (2002) independently proposed using frequency, orthographic similarity and also showed improvements using temporal and wordburstiness similarity measures, in addition to context. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the</context>
<context position="10073" citStr="Haghighi et al., 2008" startWordPosition="1547" endWordPosition="1550">rmalizing the vectors to unit length, Koehn and Knight (2002) used Spearman rank order correlation, and Schafer and Yarowsky (2002) use cosine similarity. We found that cosine similarity gave the best results in our experimental conditions. Other similarity measures may be used equally well. 3.1 Models of Context We compared several context models. Empirical results for their ability to find accurate translations are given in Section 5. 3.1.1 Baseline model In the baseline model, the context is computed using adjacent words as in (Rapp,1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008). Given a word in source language, say sw, count all its immediate context words appearing in a window of four words. The counts are collected seperately for each position by keeping track of four seperate vectors for positions -2, -1, +1 and +2. Thus each vector is a sparse vector, having the # of dimensions as the size of source language vocabulary. Each dimension is also reweighted by multiplying the inverse document frequency (IDF) 131 Figure 2: Illustration of using dependency trees to model richer contexts for projection as in the standard TF.IDF weighting scheme1. These vectors are then</context>
<context position="17615" citStr="Haghighi et al., 2008" startWordPosition="2803" endWordPosition="2806"> compared to adjacent context at different recall points. Precision is the fraction of tested Spanish words with Top 1 translation correct and Recall is fraction of the 1000 Spanish words tested upon. Spanish word but is marked incorrect if it does not exist in the lexicon. Because it would be intractable to compare each projected vector against the vectors for all possible English words, we limited ourselves to comparing the projected vector from each Spanish word against the vectors for the 1000 most frequent English nouns, following along the lines of previous work (Koehn and Knight, 2002; Haghighi et al., 2008). 5 Results Table 3 gives the Top 1 and Top 10 accuracy for each of the models on their ability to translate Spanish nouns into English. Examples of the top 10 translations using the best performing baseline and dependency-based models are shown in Table 2. The baseline models Adjposn and Adjbow differ in that the 133 Model AccTop 1 AccTop 10 Adjbow 35.3% 59.8% Adjposn 20.9% 46.9% Depbow 41.0% 62.0% Depposn 41.0% 64.1% Depposn + rev 42.9% 65.5% Mosesen-es-100k 56.4% 62.7% Table 3: Performance of various context-based models learned from monolingual corpora and phrase-table learned from paralle</context>
<context position="21397" citStr="Haghighi et al., 2008" startWordPosition="3411" endWordPosition="3414">.52 YES francia france 0.52 YES fundamento certainty 0.51 NO suecia sweden 0.50 YES tr´afico space 0.49 NO televisi´on tv 0.48 YES francesa portuguese 0.48 NO Table 4: List of 20 most confident mappings using the dependency context based model for noun translation. Note that although the first mapping is the correct one, it was not present in the lexicon used for evaluation and hence is marked as incorrect. 6 Further Extensions: Generalizing to other word types via tagset mapping Most of the previous literature on this problem focuses on evaluating on nouns (Rapp, 1999; Koehn and Knight 2002; Haghighi et al., 2008). However the vector projection approach is general, and should be applicable to other word-types as well. We evaluated the models with new test set containing 1000 most frequent words (not just nouns) in the EnglishSpanish lexicon. We used the dependency-based context model to create translations for this new set. The row labeled Depposn in Table 5 shows that the accuracy on this set is lower when compared to evaluating only on nouns. The main reason for lower accuracy is that closed class words are often the most frequent and tend to have a wide range of contexts resulting in reasonable tran</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>A. Haghighi, P. Liang, T. Berg-Kirkpatrick, and D. Klein. 2008. Learning bilingual lexicons from monolingual corpora. Proceedings of ACL-HLT, pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1985</date>
<booktitle>The Philosophy of Linguistics,</booktitle>
<pages>26--47</pages>
<editor>Katz, J. J. (ed.),</editor>
<contexts>
<context position="4551" citStr="Harris, 1985" startWordPosition="665" endWordPosition="666">two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is explained in detail below. The idea of words with similar meaning having similar contexts in the same language comes from the Distributional Hypothesis (Harris, 1985) and Rapp (1999) was the first to propose using context of a given word as a clue to its translation. Given a German word with an unknown translation, a German context vector is constructed by counting its surrounding words in a monolingual German corpus. Using an incomplete bilingual dictionary, the counts of the German context words with known translations are projected onto an English vector. The projected vector for the German word is compared to the vectors constructed for all English words using a monolingual English corpus. The English words with the highest vector similarity are treate</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Z. Harris. 1985. Distributional structure. Katz, J. J. (ed.), The Philosophy of Linguistics, pages 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>Proceedings of ACL Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="1889" citStr="Koehn and Knight, 2002" startWordPosition="261" endWordPosition="264">lel corpora exist for only a small fraction of the world’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related “bridge” languages that have more resources (Mann and Yarowsky, 2001). This paper investigates new ways of learning translations from monolingual corpora. We extend the Rapp (1999) model of context vector projection using a seed lexicon. It is based on the intuition that translations will have similar lexical context, even in unrelated corpora. For example, in order to translate the word “airplane”, the algorithm builds a context vector which might contain terms such as “passeng</context>
<context position="3811" citStr="Koehn and Knight, 2002" startWordPosition="546" endWordPosition="549">ontext models across the board, and better performance than statistical translation models on Top-10 accuracy for noun translation when trained on identical data. 129 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 129–137, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics We further show that an extension based on partof-speech clustering can give similar accuracy gains for learning translations of all word-types, deepening the findings of previous literature which mainly focused on translating nouns (Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). 2 Related Work The literature on translation lexicon induction for low-density languages falls in to two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is explained in detail below.</context>
<context position="5378" citStr="Koehn and Knight (2002)" startWordPosition="800" endWordPosition="803">s surrounding words in a monolingual German corpus. Using an incomplete bilingual dictionary, the counts of the German context words with known translations are projected onto an English vector. The projected vector for the German word is compared to the vectors constructed for all English words using a monolingual English corpus. The English words with the highest vector similarity are treated as translation candidates. The original work employed a relatively large bilingual dictionary containing approximately 16,000 words and tested only on a small collection of 100 manually selected nouns. Koehn and Knight (2002) tested this idea on a larger test set consisting of the 1000 most frequent words from a German-English lexicon. They also incorporated clues such as frequency and orthographic similarity in addition to context. Schafer and Yarowsky, (2002) independently proposed using frequency, orthographic similarity and also showed improvements using temporal and wordburstiness similarity measures, in addition to context. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines c</context>
<context position="9512" citStr="Koehn and Knight (2002)" startWordPosition="1458" endWordPosition="1461">ilarity: For each word twi in the target language a context vector is created using the target language monolingual corpora as in Step 1. Compute a similarity score between the context vector of twi = (ci1, ci2, ...., cin) and reference target vector rtsw = (r1, r2, ...., rn). The word with the maximum similarity score t∗wi is chosen as the candidate translation of sw. The vector similarity can be computed in a number of ways. Our setup we used cosine similarity: t∗wi =argmaxtwi V cz1+c2i2 +...+c � �rl +r22+...+r2 n Rapp (1999) used l1-norm metric after normalizing the vectors to unit length, Koehn and Knight (2002) used Spearman rank order correlation, and Schafer and Yarowsky (2002) use cosine similarity. We found that cosine similarity gave the best results in our experimental conditions. Other similarity measures may be used equally well. 3.1 Models of Context We compared several context models. Empirical results for their ability to find accurate translations are given in Section 5. 3.1.1 Baseline model In the baseline model, the context is computed using adjacent words as in (Rapp,1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008). Given a word in source language, say </context>
<context position="15753" citStr="Koehn and Knight (2002)" startWordPosition="2501" endWordPosition="2504">is assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption. Despite the bias, the comparison of different context models holds, since all models are trained on the same data. 4.2 Evaluation Criterion The models were evaluated in terms of exact-match translation accuracy of the 1000 most frequent nouns in a English-Spanish dictionary. The accuracy was calculated by counting how many mappings exactly match one of the entries in the dictionary. This evaluation criterion is similar to the setup used by Koehn and Knight (2002). We compute the Top N accuracy in the standard way as the number of Spanish test words whose Top N English translation candidates contain a lexicon translation entry out of the total number of Spanish words that can be mapped correctly using the lexicon entries. Thus if “crecimiento, growth” is the correct mapping based on the lexicon entries, the translation for “crecimiento” will be counted as correct if “growth” occurs in the Top N English translation candidates for “crecimiento”. Note that the exact-match accuracy is a conservative estimate as it is possible that the algorithm may propose</context>
<context position="17591" citStr="Koehn and Knight, 2002" startWordPosition="2799" endWordPosition="2802">endency context model as compared to adjacent context at different recall points. Precision is the fraction of tested Spanish words with Top 1 translation correct and Recall is fraction of the 1000 Spanish words tested upon. Spanish word but is marked incorrect if it does not exist in the lexicon. Because it would be intractable to compare each projected vector against the vectors for all possible English words, we limited ourselves to comparing the projected vector from each Spanish word against the vectors for the 1000 most frequent English nouns, following along the lines of previous work (Koehn and Knight, 2002; Haghighi et al., 2008). 5 Results Table 3 gives the Top 1 and Top 10 accuracy for each of the models on their ability to translate Spanish nouns into English. Examples of the top 10 translations using the best performing baseline and dependency-based models are shown in Table 2. The baseline models Adjposn and Adjbow differ in that the 133 Model AccTop 1 AccTop 10 Adjbow 35.3% 59.8% Adjposn 20.9% 46.9% Depbow 41.0% 62.0% Depposn 41.0% 64.1% Depposn + rev 42.9% 65.5% Mosesen-es-100k 56.4% 62.7% Table 3: Performance of various context-based models learned from monolingual corpora and phrase-ta</context>
<context position="21373" citStr="Koehn and Knight 2002" startWordPosition="3407" endWordPosition="3410">.52 YES israel israel 0.52 YES francia france 0.52 YES fundamento certainty 0.51 NO suecia sweden 0.50 YES tr´afico space 0.49 NO televisi´on tv 0.48 YES francesa portuguese 0.48 NO Table 4: List of 20 most confident mappings using the dependency context based model for noun translation. Note that although the first mapping is the correct one, it was not present in the lexicon used for evaluation and hence is marked as incorrect. 6 Further Extensions: Generalizing to other word types via tagset mapping Most of the previous literature on this problem focuses on evaluating on nouns (Rapp, 1999; Koehn and Knight 2002; Haghighi et al., 2008). However the vector projection approach is general, and should be applicable to other word-types as well. We evaluated the models with new test set containing 1000 most frequent words (not just nouns) in the EnglishSpanish lexicon. We used the dependency-based context model to create translations for this new set. The row labeled Depposn in Table 5 shows that the accuracy on this set is lower when compared to evaluating only on nouns. The main reason for lower accuracy is that closed class words are often the most frequent and tend to have a wide range of contexts resu</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>P. Koehn and K. Knight. 2002. Learning a translation lexicon from monolingual corpora. Proceedings of ACL Workshop on Unsupervised Lexical Acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACLHLT,</booktitle>
<pages>48--54</pages>
<contexts>
<context position="1230" citStr="Koehn et al., 2003" startWordPosition="165" endWordPosition="168">aseline approach that uses a fixed context window of adjacent words. Its Top 10 accuracy for noun translation is higher than that of a statistical translation model trained on a Spanish-English parallel corpus containing 100,000 sentence pairs. We generalize the evaluation to other word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equivalencies during translation. 1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (Koehn et al., 2003; Chiang, 2007). However, large parallel corpora exist for only a small fraction of the world’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by us</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of NAACLHLT, pages 48–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>Proceedings of ACL, companian volume,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="14344" citStr="Koehn et al., 2007" startWordPosition="2278" endWordPosition="2281">t, parent, child and grandparent relations, analogous to the bag of words model. • Depposn – A dependency model which did include such relationships, and was analogous to the position-based baseline. • Depposn + rev – The above Depposn model applied in both directions (Spanish-to-English and English-to-Spanish) using their sum as the final translation score. We contrasted the accuracy of the above methods, which use monolingual corpora, with a statistical 132 model trained on bilingual parallel corpora. We refer to that model as Mosesen-es-100k, because it was trained using the Moses toolkit (Koehn et al., 2007). 4.1 Training Data All context models were trained on a Spanish corpus containing 100,000 sentences with 2.13 million words and an English corpus containing 100,000 sentences with 2.07 million words. The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. Proceedings of ACL, companian volume, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation. MT Summit X.</title>
<date>2005</date>
<contexts>
<context position="14958" citStr="Koehn, 2005" startWordPosition="2375" endWordPosition="2376">4.1 Training Data All context models were trained on a Spanish corpus containing 100,000 sentences with 2.13 million words and an English corpus containing 100,000 sentences with 2.07 million words. The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus (Koehn, 2005). The fact that our two monolingual corpora are taken from a parallel corpus ensures that the assumption that similar contexts are a good indicator of translation holds. This assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption. Despite the bias, the comparison of different context models holds, since all models are trained on the same data. 4.2 Evaluation Criterion The models were evaluated in terms of exact-match translation accuracy of the 1000 most frequent nouns in a English-Spanish dictiona</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. MT Summit X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of inference rules for question-answering.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>04</issue>
<contexts>
<context position="6382" citStr="Lin and Pantel, 2002" startWordPosition="960" endWordPosition="963">res, in addition to context. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the recent developments in multilingual dependency parsing literature (Buchholz and Marsi, 2006; Nivre et al., 2007). We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types, rather than just nouns. While the straightforward application of context-based model gives a lower overall accuracy than nouns alone, we show how learning a mapping of part-of-speech tagsets between the source and target language can result in comparable performance to that of noun translation. 3 Translat</context>
<context position="11245" citStr="Lin and Pantel, 2002" startWordPosition="1738" endWordPosition="1742"> TF.IDF weighting scheme1. These vectors are then concatenated into a single vector, having dimension four times the size of the vocabulary. This vector is called the reference source vector rss. for source word sw. 3.1.2 Modeling context using dependency trees We use dependency parsing to extend the context model. Our context vectors use contexts derived from head-words linked by dependency trees instead of using the immediate adjacent lexical words. The use of dependency trees for modeling contexts has been shown to help in monolingual clustering tasks of finding words with similar meaning (Lin and Pantel, 2002) and we show how they can be effectively used for translation lexicon induction. Position Adjacent Dependency Context Context -2 para camino -1 el para +1 y prosperidad, y, el +2 la econ´omica Table 1: Contrasting context words derived from the adjacent vs dependency models for the above example The four vectors for positions -1, +1, -2 and +2 in the baseline model get mapped to immediate parent (-1), immediate child (+1), grandparent (-2) and grandchild (+2). An example of using the dependency tree context is shown in Figure 2, and the dependency context is shown in contrast with the adjacent</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>D. Lin and P. Pantel. 2002. Discovery of inference rules for question-answering. Natural Language Engineering, 7(04):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Mann</author>
<author>D Yarowsky</author>
</authors>
<title>Multipath translation lexicon induction via bridge languages.</title>
<date>2001</date>
<booktitle>Proceedings of NAACL,</booktitle>
<pages>151--158</pages>
<contexts>
<context position="2075" citStr="Mann and Yarowsky, 2001" startWordPosition="288" endWordPosition="291">i. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related “bridge” languages that have more resources (Mann and Yarowsky, 2001). This paper investigates new ways of learning translations from monolingual corpora. We extend the Rapp (1999) model of context vector projection using a seed lexicon. It is based on the intuition that translations will have similar lexical context, even in unrelated corpora. For example, in order to translate the word “airplane”, the algorithm builds a context vector which might contain terms such as “passengers”, “runway”, “airport”, etc. and words in target language that have their translations (obtained via seed lexicon) in surrounding context can be considered as likely translations. We </context>
<context position="4100" citStr="Mann and Yarowsky, 2001" startWordPosition="588" endWordPosition="591">rado, June 2009. c�2009 Association for Computational Linguistics We further show that an extension based on partof-speech clustering can give similar accuracy gains for learning translations of all word-types, deepening the findings of previous literature which mainly focused on translating nouns (Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). 2 Related Work The literature on translation lexicon induction for low-density languages falls in to two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is explained in detail below. The idea of words with similar meaning having similar contexts in the same language comes from the Distributional Hypothesis (Harris, 1985) and Rapp (1999) was the first to propose using context of a given word as a clue to its translation. Given a German word with an unknown translation</context>
</contexts>
<marker>Mann, Yarowsky, 2001</marker>
<rawString>G.S. Mann and D. Yarowsky. 2001. Multipath translation lexicon induction via bridge languages. Proceedings of NAACL, pages 151–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>M A Marcinkiewicz</author>
<author>B Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="14728" citStr="Marcus et al., 1993" startWordPosition="2339" endWordPosition="2342">racy of the above methods, which use monolingual corpora, with a statistical 132 model trained on bilingual parallel corpora. We refer to that model as Mosesen-es-100k, because it was trained using the Moses toolkit (Koehn et al., 2007). 4.1 Training Data All context models were trained on a Spanish corpus containing 100,000 sentences with 2.13 million words and an English corpus containing 100,000 sentences with 2.07 million words. The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus (Koehn, 2005). The fact that our two monolingual corpora are taken from a parallel corpus ensures that the assumption that similar contexts are a good indicator of translation holds. This assumption underlies in all work of translation lexicon induction from comparable monolingual corpora, and here we strongly bias toward that assumption. Despite the bias, the comparison of differ</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini. 1993. Building a large annotated corpus of English: the Penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>Proceedings of EMNLP-HLT,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="14630" citStr="McDonald et al., 2005" startWordPosition="2324" endWordPosition="2327">glish and English-to-Spanish) using their sum as the final translation score. We contrasted the accuracy of the above methods, which use monolingual corpora, with a statistical 132 model trained on bilingual parallel corpora. We refer to that model as Mosesen-es-100k, because it was trained using the Moses toolkit (Koehn et al., 2007). 4.1 Training Data All context models were trained on a Spanish corpus containing 100,000 sentences with 2.13 million words and an English corpus containing 100,000 sentences with 2.07 million words. The Spanish corpus was parsed using the MST dependency parser (McDonald et al., 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al., 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus (Koehn, 2005). The fact that our two monolingual corpora are taken from a parallel corpus ensures that the assumption that similar contexts are a good indicator of translation holds. This assumption underlies in all work of translation lexicon induction from comparable monolingual cor</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. Proceedings of EMNLP-HLT, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The conll</title>
<date>2007</date>
<booktitle>Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL,</booktitle>
<pages>915--932</pages>
<contexts>
<context position="6527" citStr="Nivre et al., 2007" startWordPosition="982" endWordPosition="985">l corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the recent developments in multilingual dependency parsing literature (Buchholz and Marsi, 2006; Nivre et al., 2007). We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types, rather than just nouns. While the straightforward application of context-based model gives a lower overall accuracy than nouns alone, we show how learning a mapping of part-of-speech tagsets between the source and target language can result in comparable performance to that of noun translation. 3 Translation by Context Vector Projection This section details how translations are discovered from monolingual corpora through context vector projection.</context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The conll 2007 shared task on dependency parsing. Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pado</author>
<author>M Lapata</author>
</authors>
<title>Dependency-Based Construction of Semantic Space Models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="6406" citStr="Pado and Lapata, 2007" startWordPosition="964" endWordPosition="967">ntext. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the recent developments in multilingual dependency parsing literature (Buchholz and Marsi, 2006; Nivre et al., 2007). We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types, rather than just nouns. While the straightforward application of context-based model gives a lower overall accuracy than nouns alone, we show how learning a mapping of part-of-speech tagsets between the source and target language can result in comparable performance to that of noun translation. 3 Translation by Context Vector Pr</context>
</contexts>
<marker>Pado, Lapata, 2007</marker>
<rawString>S. Pado and M. Lapata. 2007. Dependency-Based Construction of Semantic Space Models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="1865" citStr="Rapp, 1999" startWordPosition="259" endWordPosition="260"> large parallel corpora exist for only a small fraction of the world’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related “bridge” languages that have more resources (Mann and Yarowsky, 2001). This paper investigates new ways of learning translations from monolingual corpora. We extend the Rapp (1999) model of context vector projection using a seed lexicon. It is based on the intuition that translations will have similar lexical context, even in unrelated corpora. For example, in order to translate the word “airplane”, the algorithm builds a context vector which might contai</context>
<context position="3787" citStr="Rapp, 1999" startWordPosition="544" endWordPosition="545">n baseline context models across the board, and better performance than statistical translation models on Top-10 accuracy for noun translation when trained on identical data. 129 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 129–137, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics We further show that an extension based on partof-speech clustering can give similar accuracy gains for learning translations of all word-types, deepening the findings of previous literature which mainly focused on translating nouns (Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). 2 Related Work The literature on translation lexicon induction for low-density languages falls in to two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is ex</context>
<context position="6123" citStr="Rapp (1999)" startWordPosition="920" endWordPosition="921">d clues such as frequency and orthographic similarity in addition to context. Schafer and Yarowsky, (2002) independently proposed using frequency, orthographic similarity and also showed improvements using temporal and wordburstiness similarity measures, in addition to context. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency information rather than strictly relying on adjacent words, based on the success of dependency trees for monolingual clustering and disambiguation tasks (Lin and Pantel, 2002; Pado and Lapata, 2007) and the recent developments in multilingual dependency parsing literature (Buchholz and Marsi, 2006; Nivre et al., 2007). We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types, rather than just nouns. While the straightforwa</context>
<context position="7963" citStr="Rapp, 1999" startWordPosition="1204" endWordPosition="1205"> and vector similarity. The goodness of semantic “fit” of candidate translations is measured as the vector similarity between two words. Those vectors are drawn from two different languages, so the vector for one word must first be projected onto the language space of the other. The algorithm for creating, projecting and comparing vectors is described below, and illustrated in Figure 1. Algorithm: 1. Extract context vectors: Given a word in source language, say sw, create a vector using the surrounding context words and call this reference source vector rss. for 130 Figure 1: Illustration of (Rapp, 1999) model for translating spanish word “crecimiento (growth)” via dependency context vectors extracted from respective monolingual corpora as explained in Section 3.1.2 ci r +ci2 ·r2+....+cin ·rn 1· 1 source word sw. The actual composition of this vector varies depending on how the surrounding context is modeled. The context model is independent of the algorithm, and various models are explained in later sections. 2. Project reference source vector: Project all the source vector words contained in the projection dictionary onto the vector space for the target language, retaining the counts from s</context>
<context position="9422" citStr="Rapp (1999)" startWordPosition="1445" endWordPosition="1446">e zero counts in the reference target vector. 3. Rank candidates by vector similarity: For each word twi in the target language a context vector is created using the target language monolingual corpora as in Step 1. Compute a similarity score between the context vector of twi = (ci1, ci2, ...., cin) and reference target vector rtsw = (r1, r2, ...., rn). The word with the maximum similarity score t∗wi is chosen as the candidate translation of sw. The vector similarity can be computed in a number of ways. Our setup we used cosine similarity: t∗wi =argmaxtwi V cz1+c2i2 +...+c � �rl +r22+...+r2 n Rapp (1999) used l1-norm metric after normalizing the vectors to unit length, Koehn and Knight (2002) used Spearman rank order correlation, and Schafer and Yarowsky (2002) use cosine similarity. We found that cosine similarity gave the best results in our experimental conditions. Other similarity measures may be used equally well. 3.1 Models of Context We compared several context models. Empirical results for their ability to find accurate translations are given in Section 5. 3.1.1 Baseline model In the baseline model, the context is computed using adjacent words as in (Rapp,1999; Koehn and Knight, 2002;</context>
<context position="21350" citStr="Rapp, 1999" startWordPosition="3405" endWordPosition="3406">government 0.52 YES israel israel 0.52 YES francia france 0.52 YES fundamento certainty 0.51 NO suecia sweden 0.50 YES tr´afico space 0.49 NO televisi´on tv 0.48 YES francesa portuguese 0.48 NO Table 4: List of 20 most confident mappings using the dependency context based model for noun translation. Note that although the first mapping is the correct one, it was not present in the lexicon used for evaluation and hence is marked as incorrect. 6 Further Extensions: Generalizing to other word types via tagset mapping Most of the previous literature on this problem focuses on evaluating on nouns (Rapp, 1999; Koehn and Knight 2002; Haghighi et al., 2008). However the vector projection approach is general, and should be applicable to other word-types as well. We evaluated the models with new test set containing 1000 most frequent words (not just nouns) in the EnglishSpanish lexicon. We used the dependency-based context model to create translations for this new set. The row labeled Depposn in Table 5 shows that the accuracy on this set is lower when compared to evaluating only on nouns. The main reason for lower accuracy is that closed class words are often the most frequent and tend to have a wide</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>R. Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. Proceedings of ACL, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Schafer</author>
<author>D Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages.</title>
<date>2002</date>
<booktitle>Proceedings of COLING,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="1917" citStr="Schafer and Yarowsky, 2002" startWordPosition="265" endWordPosition="268">ly a small fraction of the world’s languages, leading to a bottleneck for building translation systems in low-density languages such as Swahili, Uzbek or Punjabi. While parallel training data is uncommon for such languages, more readily available resources include small translation dictionaries, comparable corpora, and large amounts of monolingual data. The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related “bridge” languages that have more resources (Mann and Yarowsky, 2001). This paper investigates new ways of learning translations from monolingual corpora. We extend the Rapp (1999) model of context vector projection using a seed lexicon. It is based on the intuition that translations will have similar lexical context, even in unrelated corpora. For example, in order to translate the word “airplane”, the algorithm builds a context vector which might contain terms such as “passengers”, “runway”, “airport”, e</context>
<context position="4129" citStr="Schafer and Yarowsky, 2002" startWordPosition="592" endWordPosition="595">ssociation for Computational Linguistics We further show that an extension based on partof-speech clustering can give similar accuracy gains for learning translations of all word-types, deepening the findings of previous literature which mainly focused on translating nouns (Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). 2 Related Work The literature on translation lexicon induction for low-density languages falls in to two broad categories: 1) Effectively utilizing similarity between languages by choosing a high-resource “bridge” language for translation (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002) and 2) Extracting noisy clues (such as similar context) from monolingual corpora with help of a seed lexicon (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002, Haghighi et al., 2008). The latter category is more relevant to this work and is explained in detail below. The idea of words with similar meaning having similar contexts in the same language comes from the Distributional Hypothesis (Harris, 1985) and Rapp (1999) was the first to propose using context of a given word as a clue to its translation. Given a German word with an unknown translation, a German context vector is </context>
<context position="5618" citStr="Schafer and Yarowsky, (2002)" startWordPosition="838" endWordPosition="841"> is compared to the vectors constructed for all English words using a monolingual English corpus. The English words with the highest vector similarity are treated as translation candidates. The original work employed a relatively large bilingual dictionary containing approximately 16,000 words and tested only on a small collection of 100 manually selected nouns. Koehn and Knight (2002) tested this idea on a larger test set consisting of the 1000 most frequent words from a German-English lexicon. They also incorporated clues such as frequency and orthographic similarity in addition to context. Schafer and Yarowsky, (2002) independently proposed using frequency, orthographic similarity and also showed improvements using temporal and wordburstiness similarity measures, in addition to context. Haghighi et al., (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon. All of the aforementioned work defines context similarity in terms of the adjacent words over a window of some arbitary size (usually 2 to 4 words), as initially proposed by Rapp (1999). We show that the model for surrounding context can be improved by using dependency informatio</context>
<context position="9582" citStr="Schafer and Yarowsky (2002)" startWordPosition="1469" endWordPosition="1472"> is created using the target language monolingual corpora as in Step 1. Compute a similarity score between the context vector of twi = (ci1, ci2, ...., cin) and reference target vector rtsw = (r1, r2, ...., rn). The word with the maximum similarity score t∗wi is chosen as the candidate translation of sw. The vector similarity can be computed in a number of ways. Our setup we used cosine similarity: t∗wi =argmaxtwi V cz1+c2i2 +...+c � �rl +r22+...+r2 n Rapp (1999) used l1-norm metric after normalizing the vectors to unit length, Koehn and Knight (2002) used Spearman rank order correlation, and Schafer and Yarowsky (2002) use cosine similarity. We found that cosine similarity gave the best results in our experimental conditions. Other similarity measures may be used equally well. 3.1 Models of Context We compared several context models. Empirical results for their ability to find accurate translations are given in Section 5. 3.1.1 Baseline model In the baseline model, the context is computed using adjacent words as in (Rapp,1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008). Given a word in source language, say sw, count all its immediate context words appearing in a window of fou</context>
</contexts>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>C. Schafer and D. Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. Proceedings of COLING, pages 1–7.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>