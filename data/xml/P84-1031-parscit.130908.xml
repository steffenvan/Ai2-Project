<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000085">
<note confidence="0.4188078">
A CONNECTIONIST MODEL OF SOME ASPECTS OF ANAPHOR RESOLUTION
Ronan G. Reilly
Educational Research Centre
St Patrick&apos;s College, Drumcondra
Dublin 9, Ireland
</note>
<sectionHeader confidence="0.683107" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9992695">
This paper describes some recent developments in
language processing involving computational
models which more closely resemble the brain in
both structure and function. These models employ
a large number of interconnected parallel
computational units which communicate via
weighted levels of excitation and inhibition. A
specific model is described which uses this
approach to process some fragments of connected
discourse.
</bodyText>
<sectionHeader confidence="0.991791" genericHeader="method">
I CONNECTIONIST MODELS
</sectionHeader>
<bodyText confidence="0.999470961038961">
The human brain consists of about 100,000
million neuronal units with between a 1000 and
10,000 connections each. The two main classes of
cells in the cortex are the striate and pyramidal
cells. The pyramidal cells are generally large
and heavily arborized. They are the main output
cells of a region of cortex, and they mediate
connections between one region and the next. The
striate cells are smaller, and act more locally.
The neural circuitry of the cortex is, apart from
some minor variations, remarkably consistent. Its
dominant characteristics are its parallelism, its
large number processing units, and the extensive
interconnection of these units. This is a
fundamentally different structure from the
traditional von Neumann model. Those in favor of
adopting a connectionist approach to modelling
human cognition argue that the structure of the
human nervous system is so different from the
structure implicit in current information-
processing models that the standard approach
cannot ultimately be successful. They argue that
even at an abstract level, removed from immediate
neural considerations, the fundamental structure
of the human nervous system has a pervasive
effect.
Connectionist models form a class of
spreading activation or active semantic network
model. Each primitive computing unit in the
network can be thought of as a stylized neuron.
Its output is a function of a vector of inputs
from neighbouring units and a current level of
excitation. The inputs can be both excitatory
and inhibtory. The output of each unit has a
restricted range (in the case of the model
described here, it can have a value between 1 and
10). Associated with each unit are a number of
computational functions. At each input site
there are Junctions which determine how the
inputs are to be summarized. A potential
function determines the relationship between the
summarized site inputs and the unit&apos;s overall
potential. Finally, an output function
determines the relationship between a unit&apos;s
potential and the value that it transmits to its
neighbours.
There are a number of constraints inhererent
in a neurally based model. One of the most
significant is that the coinage of the brain is
frequency of firing. This means that the inputs
and outputs cannot carry more than a few bits of
information. There are not enough bits in firing
frequency to allow symbol passing between
individual units. This is perhaps the single
biggest difference between this approach and and
that of standard information-processing models.
Another important constraint is that decisions in
the network are completely distributed, each unit
computes its output solely on the basis of its
inputs; it cannot &amp;quot;look around&amp;quot; to see what
others are doing, and no central controller gives
it instructions.
A number of language related applications
have been developed using this type of approach.
The most notable of these is the model of
McClelland and Rumelhart (1981). They
demonstrated that a model based on connectionist
principles could reproduce many of the
characteristcs of the so-called word-superiority
effect. This is an effect in which letters in
briefly presented words and pseudo-words are more
easily identifiable than letters in non-words.
At a higher level in the processing hierarchy,
connectionist schemes have been proposed for
modelling wor,d_sense disambiguation (Cottrell &amp;
Small, 1983), and for sentence parsing in general
(Small, Cottrell, &amp; Shastri, 1982).
</bodyText>
<page confidence="0.997934">
144
</page>
<bodyText confidence="0.999923909090909">
The model described in this paper is
basically an extension of the work of Cottrell
and Small (1983), and of Small (1982). It
extends their sentence-centred model to deal with
connected text, or discourse, and specifically
with anaphoric resolution in discourse. The
model is not proposed as definitive in any way.
It merely sets out to illustrate the properties
of connectionist models, and to show how such
models might be extended beyond simple word
recognition applications.
</bodyText>
<sectionHeader confidence="0.942222" genericHeader="method">
II ANAPHORA
</sectionHeader>
<bodyText confidence="0.9975124375">
The term anaphor derives from the Greek for
&amp;quot;pointing back&amp;quot;. What is pointed to is often
referred to as the antecedent of the anaphor.
However, the precise definition of an antecedent
is problematic. Superficially, it might be
thought of as a preceding text element. However,
as Sidner (1983) pointed out words do not refer
to other words; people use words to refer to
objects, and anaphora are used to refer to
objects which have already been mentioned in a
discourse. Sidner also maintains that the
concept of co-reference is inadequate to explain
the relationship between anaphor and antecedent.
Co-reference means that anaphor and antecedent
both refer to the same object. This explanation
suffices for a sentence like:
</bodyText>
<listItem confidence="0.5583265">
(1) I think green apples are best and they
make the best cooking apples too.
</listItem>
<bodyText confidence="0.999008090909091">
where both they and green apples refer to the
same object. However, it is inadequate when
dealing with the following discourse:
(2) My neighbour has an Irish Wolfhound.
They are really huge, but friendly dogs.
In this case they refers to the class of Irish
Wolfhounds, but the antecedent phrase refers to a
member of that set. Therefore, the anaphor and
antecedent cannot be said to co-refer. Sidner
introduces the concept of specification and
co-specification to get around this problem.
Instead of referring to objects in the real
world, the anaphor and its antecedent specify a
cognitive element in the hearer&apos;s mind. Even
though the same element is not co-specified one
specification may be used generate the other.
This is not possible with co-reference because,
as Sidner puts it:
Co-specification, unlike co-reference,
allows one to construct abstract
representations and define relationships
between them which can be studied in a
computational framework. With coreference,
no such use is possible, since the object
referred to exists in the world and is not
available for examination by the
computational process. (Sidner, 1983; p.
269).
Sidner proposes two major sources of constraint
on what can become the co-specification of an
anaphoric reference. One is the shared knowledge
of speaker and hearer, and the other is the
concept of focus. At any given time the focus of
a discourse is that discourse element which is
currently being elaborated upon, and on which the
speakers have centered their attention. This
concept of focus will be implemented in the model
to be described, though differently from the way
Sidner (1983) has envisaged it. In her model
possible focuses are examined serially, and a
decision is not made until a sentence has been
completely analyzed. In the model proposed here,
the focus is arrived at on-line, and the process
used is a parallel one.
</bodyText>
<sectionHeader confidence="0.983688" genericHeader="method">
III THE SIMULATOR
</sectionHeader>
<bodyText confidence="0.999988047619047">
The model described here was constructed
using an interactive connectionist simulator
written in Salford LISP and based on the design
for the University of Rochester&apos;s ISCON simulator
(Small, Shastri, Brucks, Kaufman, Cottrell, &amp;
Addanki, 1983). The simulator allows the user to
design different types of units. These can have
any number of input sites, each with an
associated site function. Units also have an
associated potential and output function. As
well as unit types, ISCON allows the user to
design different types of weighted link. A
network is constructed by generating units of
various types and connecting them up. Processing
is initiated by activating designated input
units. The simulator is implemented on a Prime
550. A network of about 50 units and 300 links
takes approximately 30 CPU seconds per iteration.
As the number of units increases the simulator
takes exponentially longer, making it very
unwieldy for networks of more than 100 units. One
solution to the speed problem is to compile the
networks so that they can be executed faster. A
more radical solution, and one which we are
currently working on, is to develop a programming
language which has as its basic unit a network.
This language would involve a batch system rather
than an interactive one. There would, therefore,
be a trade-off between the ease of use of an
interactive system and the speed and power of a
batch approach. Although ISCON is an excellent
medium for the construction of networks, it is
inadequate for any form of sophisticated
execution of networks. The proposed Network
Programming Language (NPL) would permit the
definition and construction of networks in much
the same way as ISCON. However, with NPL it will
also be possible to selectively activate sections
of a particular network, to create new networks
by combining separate sub-networks, to calculate
summary indices of any network, and to use these
indices in guiding the flow of control in the
</bodyText>
<page confidence="0.994523">
145
</page>
<bodyText confidence="0.9999365">
program. NPL will have a number of modern flow
of control facilities (for example, FOR and WHILE
loops). Unfortunately, this language is still at
the design stage and is not available for use.
</bodyText>
<sectionHeader confidence="0.9557" genericHeader="method">
IV THE MODEL
</sectionHeader>
<bodyText confidence="0.7714565">
The model consists of five main components
which interact in the manner illustrated in
</bodyText>
<figureCaption confidence="0.997884">
Figure 1. The lines ending in filled circles
</figureCaption>
<bodyText confidence="0.998398833333333">
indicate inhibitory connections, the ordinary
lines, excitatory ones. Each component consists
of sets of neuron-like units which can either
excite or inhibit neighbouring nodes, and nodes
in connected components. A successful parsing of
a sentence is deemed to have taken place if,
during the processing of the discourse, the focus
is accurately followed, and if at its end there
is a stable coalition of only those units central
to the discourse. A set of units is deemed a
stable coalition if their level of activity is
above threshold and non-decreasing.
</bodyText>
<figureCaption confidence="0.9620395">
Figure 1. The main components of the model.
A. Lexical Level
</figureCaption>
<bodyText confidence="0.9999554">
There is one unit at the lexical level for
every word in the model&apos;s lexicon. Most of the
units are connected to the word sense level by
unidirectional links, and after activation they
decay rapidly. Units which do not have a word
sense representation, such as function words and
pronouns, are connected by unidirectional link to
the case and schema levels. A lexical unit is
connected to all the possible senses of the word.
These connections are weighted according to the
frequency of occurence of the senses. To
simulate hearing or reading a sentence the
lexical units are activated one after another
from left to right, in the order they occur in
the sentence.
</bodyText>
<subsectionHeader confidence="0.508373">
B. Word Sense Level
</subsectionHeader>
<bodyText confidence="0.99994925">
The units at this level represent the
&amp;quot;meaning&amp;quot; of the morphemes in the sentence.
Ambiguous words are connected to all their
possible meaning units, which are connected to
each other by inhibitory links. As Cottrell and
Small (1983) have shown, this arrangement
provides an accuraate model of the processes
involved in word sense disambiguation.
Grammatical morphemes, function words, and
pronouns do not have explicit representations at
this level, rather they connect directly to the
case and schema levels.
</bodyText>
<sectionHeader confidence="0.779722" genericHeader="method">
C. Focus Level
</sectionHeader>
<bodyText confidence="0.9994611875">
The units at this level represent possible
focuses of the discourse in the sense that Sidner
(1983) intends. The focus with the strongest
activation inhibits competeing focuses. At any
one time there is a single dominant focus, though
it may shift as the discourse progresses. A
shift in focus occurs when evidence for the new
focus pushes its level of activation above that
of the old one. In keeping with Sidner&apos;s (1983)
position there are two types of focus used in
this model, an actor focus and a discourse focus.
The actor focus represents the animate object in
the agent case in the most recent sentence. The
discourse focus is, as its name suggests, the
central theme of the discourse. The actor focus
and discourse focus can be one and the same.
</bodyText>
<sectionHeader confidence="0.409446" genericHeader="method">
D. Case Level
</sectionHeader>
<bodyText confidence="0.999709214285714">
This model employs what Cottrell and Small
(1982) call an &amp;quot;exploded case&amp;quot; representation.
Instead of general cases such as Agent, Object,
Patient, and so on, more specific case categories
are used. For instance, the sentence John kicked
the ball would activate the specific cases of
Kick-agent and Kick-object. The units at this
level only fire when there is evidence from the
predicate and at least one filler. Their output
then goes to the appropriate units at the focus
level. In the example above, the predicate for
Kick-agent is kick, and its filler is John. The
unit Kick-agent then activates the actor focus
unit for John.
</bodyText>
<subsectionHeader confidence="0.337118">
E. Schema Level
</subsectionHeader>
<bodyText confidence="0.992112285714286">
This model employs a partial implementation
of Small&apos;s (1982) proposal for an exploded system
of schemas. The schema level consists of a
hierarchy of ever more abstract schemas. At the
bottom of the hierarchy there are schemas which
are so specifc that the number of possible
options for filling their slots is highly
</bodyText>
<figure confidence="0.99796">
CASE SCHEMA
C4)
FOCUS
WORD
SENSE
LEXICAL
</figure>
<page confidence="0.996967">
146
</page>
<bodyText confidence="0.996228166666667">
constrained, and the activation of each schema
serves, in turn, to activate all its slot
fillers. Levels further up in the hierarchy
contain more general schema details, and the
connections between slots and their potential
fillers are less strong.
</bodyText>
<figure confidence="0.779616">
WORK PLACE MEETING schema
WPM_location: library
tom office
my_office
WPM time: morning
V THE MODEL&apos;S PERFORMANCE afternoon
</figure>
<bodyText confidence="0.995276833333333">
At its current stage of development the
model can handle discourse involving pronoun
anaphora in which the discourse focus is made to
shift. It can resolve the type of reference
involved in the following two discourse examples
(based on examples by Sidner, 1983; p. 276):
</bodyText>
<listItem confidence="0.927898363636364">
D1-1: I&apos;ve arranged a meeting with Mick and
Peter.
2: It should be in the afternoon.
3: We can meet in my office.
4: Invite Pat to come too.
D2-1: I&apos;ve arranged a meeting with Mick, Peter,
and Pat.
2: It should be in the afternoon.
3: We can meet in my office.
4: It&apos;s kind of small,
5: but we&apos;ll only need it for an hour.
</listItem>
<bodyText confidence="0.999507545454546">
In discourse D1, the focus throughout is the
meeting mentioned in D1-1. The it in 01-2 can be
seen to co-specify the focus. In order to
determine this a human listner must use their
knowledge that meetings have times, among other
things. Although no mention is made of the
meeting in D1-3 to D1-4 human listners can
interpret the sentences as being consistent with
a meeting focus. In the discourse D2 the initial
focus is the meeting, but at 02-4 the focus has
clearly shifted to my office, and remains there
until the end of the discourse.
The network which handles this discourse
does not parse it in its entirety. The aim is not
for completeness, but to illustrate the operation
of the schema level of the model, and to show how
it aids in determining the focus of the
discourse. Initially, in analyzing D1 the word
meeting activates the schema WORK PLACE MEETING.
This schema gets activated, rather than any other
meeting schema, because the overall context of
the discourse is that of an office memo. Below,
is a representation of the schema. On the left
are its component slots, and on the right are all
the possible fillers for these slots.
WPM participants: tom
vincent
patricia
mick
peter
me
When this schema is activated the slots
become active, and generate a low level of
subthreshold activity in their potential fillers.
When one or more fillers become active, as they
do when the words Mick and Peter are encountered
at the end of D1-1, the slot forms a feedback
loop with the fillers which lasts until the
activity of the sense representation of meeting
declines below a threshold. A slot can only be
active if the word activating the schema is
active, which in this case is meeting. When a
number of fillers can fill a slot, as is the case
with the WPM_Rarticipant slot, a form of
regulated sub-network is used. On the other
hand, when there can only be one filler for a
slot, as with the WPM_location slot, a winner-
take-all network is used (both these types of
sub-network are described in Feldman and Ballard,
1982).
Associated with each unit at the sense level
is a focus unit. A focus unit is connected to
its corresponding sense unit by a bidirectional
excitatory link, and to other focus units by
inhibitory links. As mentioned above, there are
two separate networks of focus units,
corresponding to actor focuses and discourse
focuses, respectively. Actors are animate objects
which can serve as agents for verbs. An actor
focus unit can only become active if its
associated sense level unit is a filler for an
agent case slot. The discourse focus and actor
focus can be, but need not be, one and the same.
The distinction between the two types of focus is
in line with a similar distinction made by Sidner
(1983). The structure of the focus level network
ensures that there can only be one discourse
focus and one actor focus at a given time. In
discourses D1 and 02 the actor focus throughout
is the speaker.
At the end of the sentence 01-1 the
WORK_PLACE_MEETING schema is in a stable
coalition with the sense units representing Mick
and Peter. The focus units active at this stage
are those representing the speaker of the
discourse (the actor focus), and the meeting (the
discourse focus). When the sentence 01-2 is
</bodyText>
<page confidence="0.996134">
147
</page>
<bodyText confidence="0.9999503">
encountered the system must determine the
co-specification of it. The lexical unit it is
connected to all focus units of inanimate
objects. It serves to boost the potential of all
the focus units active at the time. At this
stage, if there are a number of competitors for
co-specification, a number of focus units will be
activated. However, by the end of the sentence,
if the discourse is coherent, one or other of the
focuses should have received sufficient
activation to suppress the activation of its
competitors. In the case of 01 there is no
competitor for the focus, so the it serves to
further activate the meeting focus, and does so
right from the beginning of the sentence.
The sentence 01-3 serves to fill the
WPM location slot. The stable coalition is then
enlarged to include the sense unit my office.
The activation of my office activates a schema,
which might look like this:
</bodyText>
<sectionHeader confidence="0.630454" genericHeader="method">
MY OFFICE schema
</sectionHeader>
<bodyText confidence="0.983939391752578">
MO_location: Prefab 1
MO size: small
MO windows: two
It is not strictly correct to call the above
structure a schema. Being so specific, there are
only single fillers for any of its slots. It is
really a representation of the properties of a
specific office, rather than predictions
concerning offices in general. However, in the
context of this type of model, with the emphasis
on highly specific rather than general
structures, the differences between the two
schemes presented above is not a clearcut one.
When my office is activated, its focus unit
also receives some activation. This is not
enough to switch the focus away from meeting.
However, it is enough to make it a focus
candidate, which would permit a switch in focus
in the very next sentence. If a switch does not
take place, the candidate&apos;s level of activity
rapidly decays. This is what happens in 01-4,
where the sentence specifies another participant,
and the focus stays with meeting. The final
result of the analysis of discourse DI is a
stable coalition of the elements of the
WORK PLACE_MEETING frame, and the various
participants, times, and locations mentioned in
the discourse. The final actor focus is the
speaker, and the final discourse focus is the
meeting.
The analysis of discourse 02 proceeds
identically up to D2-4, where the focus shifts
from meeting to my office. At the beginning of
02-4 there are two candidates for the discourse
focus, meeting and my office. The occurence of
the &apos;word it then causes both these focuses to
become equally active. This situation reflects
our intuitions that at this stage in the sentence
the co-specifier of it is ambiguous. However,
the occurence of the word small causes a stable
coalition to form with the MY OFFICE schema, and
gives the my office focus the extra activation it
needs to overcome the competing meeting focus.
Thus, by the end of the sentence, the focus has
shifted from meeting to my office. By the time
the it in the final sentence is encountered,
there is no competing focus, and the anaphor is
resolved immediately.
There are a number of fairly obvious
drawbacks with the above model. The most
important of these being the specificity of the
the schema representations. There is no obvious
way of implementing a system of variable binding,
where a general schema can be used, and various
fillers can be bound to, and unbound from, the
slots. It is not possible to have such symbol
passing in a connectionist network. Instead, all
possible slot fillers must be already bound to
their slots, and selectively activated when
needed. To make this selective activation less
unwieldy, a logical step is to use a large
number of very specific schemes, rather than a
few general ones.
Another drawback of the model proposed here
is that there is no obvious way of showing how
new schemas might be developed, or how existing
ones might be modified. One of the basic rules
in building connectionist models is that the
connections themselves cannot be modified,
although their associated weights can be. This
means that any new knowledge must be incorporated
in an old structure by changing the weights on
the connections between the old structure and the
new knowledge. This also implies that the new
and old elements must already be connected up. In
spite of the apparent oversupply of neuronal
elements in the human cortex, to have everything
connected to virtually everything else seems to
be profligate.
Another problem with connectionist models is
their potential &amp;quot;brittleness&amp;quot;. When trying to
program a network to behave in a particular way,
it is difficult to resist the urge to patch in
arbitrary fixes here and there. There are, as
yet, no equivalents of structured programming
techniques for networks. However, there are some
hopeful signs that researchers are identifying
basic network types whose behavior is robust over
a range of conditions. In particular, there are
the winner-take-all and regulated networks. The
latter type, permits the specification of upper
and lower bounds on the activity of a sub-
network, which allows the designer to avoid the
twin perils of total saturation of the network on
the one hand, and total silence on the other. A
reliable taxonomy of sub-networks would greatly
aid the designer in building robust networks.
</bodyText>
<page confidence="0.997223">
148
</page>
<sectionHeader confidence="0.920359" genericHeader="method">
VI CONCLUSION
</sectionHeader>
<bodyText confidence="0.999459846153846">
This paper briefly described the
connectionist approach to cognitive modelling,
and showed how it might be applied to langauge
processing. A connectionist model of language
processing was outlined, which employed schemes
and focusing techniques to analyze fragments of
discourse. The paper described how the model was
successfully able to resolve simple it anaphora.
A tape of the simulator used in this paper,
&apos; along with a specification of the network used to
analyze the sample discourses, is available from
the author at the above address, upon receipt of
a blank tape.
</bodyText>
<sectionHeader confidence="0.876467" genericHeader="method">
VII REFERENCES
</sectionHeader>
<reference confidence="0.998027363636364">
Cottrell, G.W., &amp; Small, S.L. (1983). A
connectionist scheme for modelling word sense
disambiguation. Cognition and Brain Theory,
6, 89-120.
Feldman, J.A., &amp; Ballard, D.H. (1982).
Connectionist models and their properties.
Cognitive Science, 6, 205-254.
McClelland, J.L., &amp; Rumelhart, D.E. (1981). An
interactive activation model of context
effects in letter perception: Part 1. An
account of basic findings. Psychological
Review, 88, 375-407.
Sidner, C.L. (1983). Focussing in the
comprehension of definite anaphora. In M.
Brady &amp; R.C. Berwick (Eds.), Computational
models of discourse, Cambridge,
Massachusetts: MIT Press.
Small, S.L. (1982). Exploded connections:
Unchunking schematic knowledge.
In Proceedings of the Fourth Annual
Conference of the Cognitive Science
Society, Ann Arbor, Michigan.
Small, S.L., Cottrell, G.W., &amp; Shastri, L.
(1982). Toward connectionist parsing.
In Proceedings of the National
Conference on Artificial
Intelligence, Pittsburgh, Pennsylvania.
Small, S.L., Shastri, L., Brucks, M.L., Kaufman,
S.C., Cottrell, G.W., &amp; Addanki, S. (1983).
ISCON: a network construction aid and
simulator for connectionist models. TR109.
Department of Computer Science, University of
Rochester.
</reference>
<page confidence="0.998968">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002964">
<title confidence="0.99986">A CONNECTIONIST MODEL OF SOME ASPECTS OF ANAPHOR RESOLUTION</title>
<author confidence="0.999967">Ronan G Reilly</author>
<affiliation confidence="0.997976">Educational Research Centre</affiliation>
<address confidence="0.9306495">St Patrick&apos;s College, Drumcondra Dublin 9, Ireland</address>
<abstract confidence="0.996757108655618">This paper describes some recent developments in language processing involving computational models which more closely resemble the brain in both structure and function. These models employ a large number of interconnected parallel computational units which communicate via weighted levels of excitation and inhibition. A specific model is described which uses this approach to process some fragments of connected discourse. The human brain consists of about 100,000 million neuronal units with between a 1000 and 10,000 connections each. The two main classes of cells in the cortex are the striate and pyramidal cells. The pyramidal cells are generally large and heavily arborized. They are the main output cells of a region of cortex, and they mediate connections between one region and the next. The striate cells are smaller, and act more locally. The neural circuitry of the cortex is, apart from some minor variations, remarkably consistent. Its dominant characteristics are its parallelism, its large number processing units, and the extensive interconnection of these units. This is a fundamentally different structure from the traditional von Neumann model. Those in favor of adopting a connectionist approach to modelling human cognition argue that the structure of the human nervous system is so different from the structure implicit in current informationprocessing models that the standard approach cannot ultimately be successful. They argue that even at an abstract level, removed from immediate neural considerations, the fundamental structure of the human nervous system has a pervasive effect. Connectionist models form a class of spreading activation or active semantic network model. Each primitive computing unit in the network can be thought of as a stylized neuron. Its output is a function of a vector of inputs from neighbouring units and a current level of excitation. The inputs can be both excitatory and inhibtory. The output of each unit has a restricted range (in the case of the model described here, it can have a value between 1 and 10). Associated with each unit are a number of computational functions. At each input site there are Junctions which determine how the inputs are to be summarized. A potential function determines the relationship between the summarized site inputs and the unit&apos;s overall potential. Finally, an output function determines the relationship between a unit&apos;s potential and the value that it transmits to its neighbours. There are a number of constraints inhererent in a neurally based model. One of the most significant is that the coinage of the brain is frequency of firing. This means that the inputs and outputs cannot carry more than a few bits of information. There are not enough bits in firing frequency to allow symbol passing between individual units. This is perhaps the single biggest difference between this approach and and that of standard information-processing models. Another important constraint is that decisions in the network are completely distributed, each unit computes its output solely on the basis of its inputs; it cannot &amp;quot;look around&amp;quot; to see what others are doing, and no central controller gives it instructions. A number of language related applications have been developed using this type of approach. The most notable of these is the model of McClelland and Rumelhart (1981). They demonstrated that a model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrell and Small (1983), and of Small (1982). It extends their sentence-centred model to deal with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from the Greek for &amp;quot;pointing back&amp;quot;. What is pointed to is often referred to as the antecedent of the anaphor. However, the precise definition of an antecedent is problematic. Superficially, it might be thought of as a preceding text element. However, as Sidner (1983) pointed out words do not refer to other words; people use words to refer to objects, and anaphora are used to refer to objects which have already been mentioned in a discourse. Sidner also maintains that the concept of co-reference is inadequate to explain the relationship between anaphor and antecedent. Co-reference means that anaphor and antecedent both refer to the same object. This explanation suffices for a sentence like: I think applesare best and make the best cooking apples too. both theyand applesrefer to the same object. However, it is inadequate when dealing with the following discourse: My neighbour has an Wolfhound. Theyare really huge, but friendly dogs. this case theyrefers to the class of Irish Wolfhounds, but the antecedent phrase refers to a member of that set. Therefore, the anaphor and antecedent cannot be said to co-refer. Sidner introduces the concept of specification and co-specification to get around this problem. Instead of referring to objects in the real world, the anaphor and its antecedent specify a cognitive element in the hearer&apos;s mind. Even though the same element is not co-specified one specification may be used generate the other. This is not possible with co-reference because, as Sidner puts it: Co-specification, unlike co-reference, allows one to construct abstract representations and define relationships between them which can be studied in a computational framework. With coreference, no such use is possible, since the object referred to exists in the world and is not available for examination by the computational process. (Sidner, 1983; p. 269). Sidner proposes two major sources of constraint on what can become the co-specification of an anaphoric reference. One is the shared knowledge of speaker and hearer, and the other is the concept of focus. At any given time the focus of a discourse is that discourse element which is currently being elaborated upon, and on which the speakers have centered their attention. This concept of focus will be implemented in the model to be described, though differently from the way Sidner (1983) has envisaged it. In her model possible focuses are examined serially, and a decision is not made until a sentence has been completely analyzed. In the model proposed here, the focus is arrived at on-line, and the process used is a parallel one. III THE SIMULATOR The model described here was constructed using an interactive connectionist simulator written in Salford LISP and based on the design for the University of Rochester&apos;s ISCON simulator (Small, Shastri, Brucks, Kaufman, Cottrell, &amp; Addanki, 1983). The simulator allows the user to design different types of units. These can have any number of input sites, each with an associated site function. Units also have an potential and output function. well as unit types, ISCON allows the user to design different types of weighted link. A network is constructed by generating units of various types and connecting them up. Processing is initiated by activating designated input units. The simulator is implemented on a Prime 550. A network of about 50 units and 300 links takes approximately 30 CPU seconds per iteration. number of units increases the simulator takes exponentially longer, making it very unwieldy for networks of more than 100 units. One solution to the speed problem is to compile the networks so that they can be executed faster. A more radical solution, and one which we are currently working on, is to develop a programming language which has as its basic unit a network. This language would involve a batch system rather than an interactive one. There would, therefore, be a trade-off between the ease of use of an interactive system and the speed and power of a batch approach. Although ISCON is an excellent medium for the construction of networks, it is inadequate for any form of sophisticated execution of networks. The proposed Network Programming Language (NPL) would permit the definition and construction of networks in much the same way as ISCON. However, with NPL it will also be possible to selectively activate sections of a particular network, to create new networks by combining separate sub-networks, to calculate summary indices of any network, and to use these indices in guiding the flow of control in the 145 program. NPL will have a number of modern flow of control facilities (for example, FOR and WHILE loops). Unfortunately, this language is still at the design stage and is not available for use. IV THE MODEL The model consists of five main components which interact in the manner illustrated in Figure 1. The lines ending in filled circles indicate inhibitory connections, the ordinary lines, excitatory ones. Each component consists of sets of neuron-like units which can either excite or inhibit neighbouring nodes, and nodes in connected components. A successful parsing of a sentence is deemed to have taken place if, during the processing of the discourse, the focus is accurately followed, and if at its end there is a stable coalition of only those units central to the discourse. A set of units is deemed a stable coalition if their level of activity is above threshold and non-decreasing. Figure 1. The main components of the model. Level There is one unit at the lexical level for every word in the model&apos;s lexicon. Most of the units are connected to the word sense level by unidirectional links, and after activation they decay rapidly. Units which do not have a word sense representation, such as function words and pronouns, are connected by unidirectional link to the case and schema levels. A lexical unit is connected to all the possible senses of the word. These connections are weighted according to the frequency of occurence of the senses. To simulate hearing or reading a sentence the lexical units are activated one after another from left to right, in the order they occur in the sentence. Sense Level The units at this level represent the &amp;quot;meaning&amp;quot; of the morphemes in the sentence. Ambiguous words are connected to all their possible meaning units, which are connected to each other by inhibitory links. As Cottrell and Small (1983) have shown, this arrangement provides an accuraate model of the processes involved in word sense disambiguation. Grammatical morphemes, function words, and pronouns do not have explicit representations at this level, rather they connect directly to the case and schema levels. C. Focus Level The units at this level represent possible focuses of the discourse in the sense that Sidner (1983) intends. The focus with the strongest activation inhibits competeing focuses. At any one time there is a single dominant focus, though it may shift as the discourse progresses. A shift in focus occurs when evidence for the new focus pushes its level of activation above that of the old one. In keeping with Sidner&apos;s (1983) position there are two types of focus used in this model, an actor focus and a discourse focus. The actor focus represents the animate object in the agent case in the most recent sentence. The discourse focus is, as its name suggests, the central theme of the discourse. The actor focus and discourse focus can be one and the same. D. Case Level This model employs what Cottrell and Small (1982) call an &amp;quot;exploded case&amp;quot; representation. Instead of general cases such as Agent, Object, Patient, and so on, more specific case categories used. For instance, the sentence kicked ballwould activate the specific cases of Kick-agent and Kick-object. The units at this level only fire when there is evidence from the predicate and at least one filler. Their output then goes to the appropriate units at the focus level. In the example above, the predicate for Kick-agent is kick, and its filler is John. The unit Kick-agent then activates the actor focus unit for John. Level This model employs a partial implementation of Small&apos;s (1982) proposal for an exploded system of schemas. The schema level consists of a hierarchy of ever more abstract schemas. At the bottom of the hierarchy there are schemas which are so specifc that the number of possible options for filling their slots is highly CASE SCHEMA FOCUS WORD SENSE LEXICAL 146 constrained, and the activation of each schema serves, in turn, to activate all its slot fillers. Levels further up in the hierarchy contain more general schema details, and the connections between slots and their potential fillers are less strong. WORK PLACE MEETING schema WPM_location: library tom office my_office WPM time: morning V THE MODEL&apos;S PERFORMANCE afternoon At its current stage of development the model can handle discourse involving pronoun anaphora in which the discourse focus is made to shift. It can resolve the type of reference involved in the following two discourse examples (based on examples by Sidner, 1983; p. 276): D1-1: I&apos;ve arranged a meeting with Mick and Peter. 2: It should be in the afternoon. 3: We can meet in my office. 4: Invite Pat to come too. D2-1: I&apos;ve arranged a meeting with Mick, Peter, and Pat. 2: It should be in the afternoon. 3: We can meet in my office. 4: It&apos;s kind of small, 5: but we&apos;ll only need it for an hour. In discourse D1, the focus throughout is the meeting mentioned in D1-1. The it in 01-2 can be seen to co-specify the focus. In order to determine this a human listner must use their knowledge that meetings have times, among other things. Although no mention is made of the meeting in D1-3 to D1-4 human listners can interpret the sentences as being consistent with meetingfocus. In the discourse D2 the initial focus is the meeting, but at 02-4 the focus has shifted to office,and remains there until the end of the discourse. The network which handles this discourse does not parse it in its entirety. The aim is not for completeness, but to illustrate the operation of the schema level of the model, and to show how it aids in determining the focus of the discourse. Initially, in analyzing D1 the word meetingactivates the schema WORK PLACE MEETING. This schema gets activated, rather than any other meeting schema, because the overall context of the discourse is that of an office memo. Below, is a representation of the schema. On the left are its component slots, and on the right are all the possible fillers for these slots. WPM participants: tom vincent patricia mick peter me When this schema is activated the slots become active, and generate a low level of subthreshold activity in their potential fillers. When one or more fillers become active, as they do when the words Mick and Peter are encountered at the end of D1-1, the slot forms a feedback loop with the fillers which lasts until the of the sense representation of declines below a threshold. A slot can only be active if the word activating the schema is which in this case is meeting.When a number of fillers can fill a slot, as is the case with the WPM_Rarticipant slot, a form of regulatedsub-network is used. On the other hand, when there can only be one filler for a as with the WPM_location slot, a winnertake-allnetwork is used (both these types of sub-network are described in Feldman and Ballard, 1982). Associated with each unit at the sense level a A is connected to its corresponding sense unit by a bidirectional link, and to other by inhibitory links. As mentioned above, there are two separate networks of focus units, corresponding to actor focuses and discourse focuses, respectively. Actors are animate objects which can serve as agents for verbs. An actor focus unit can only become active if its associated sense level unit is a filler for an agent case slot. The discourse focus and actor focus can be, but need not be, one and the same. The distinction between the two types of focus is in line with a similar distinction made by Sidner (1983). The structure of the focus level network ensures that there can only be one discourse focus and one actor focus at a given time. In discourses D1 and 02 the actor focus throughout is the speaker. At the end of the sentence 01-1 the WORK_PLACE_MEETING schema is in a stable coalition with the sense units representing Mick and Peter. The focus units active at this stage are those representing the speaker of the (the actor the meeting (the the sentence 01-2 is 147 encountered the system must determine the co-specification of it. The lexical unit it is connected to all focus units of inanimate objects. It serves to boost the potential of all the focus units active at the time. At this stage, if there are a number of competitors for co-specification, a number of focus units will be activated. However, by the end of the sentence, if the discourse is coherent, one or other of the focuses should have received sufficient activation to suppress the activation of its competitors. In the case of 01 there is no competitor for the focus, so the it serves to further activate the meeting focus, and does so right from the beginning of the sentence. The sentence 01-3 serves to fill the WPM location slot. The stable coalition is then to include the sense unit office. activation of officeactivates a schema, which might look like this: MY OFFICE schema MO_location: Prefab 1 MO size: small MO windows: two It is not strictly correct to call the above structure a schema. Being so specific, there are only single fillers for any of its slots. It is really a representation of the properties of a specific office, rather than predictions concerning offices in general. However, in the context of this type of model, with the emphasis on highly specific rather than general structures, the differences between the two schemes presented above is not a clearcut one. officeis activated, its focus unit also receives some activation. This is not to switch the focus away from However, it is enough to make it a focus candidate, which would permit a switch in focus in the very next sentence. If a switch does not take place, the candidate&apos;s level of activity rapidly decays. This is what happens in 01-4, where the sentence specifies another participant, the focus stays with meeting.The final result of the analysis of discourse DI is a stable coalition of the elements of the WORK PLACE_MEETING frame, and the various and locations mentioned in the discourse. The final actor focus is the speaker, and the final discourse focus is the meeting. The analysis of discourse 02 proceeds identically up to D2-4, where the focus shifts meetingto office.At the beginning of 02-4 there are two candidates for the discourse meetingand office.The occurence of the &apos;word it then causes both these focuses to become equally active. This situation reflects our intuitions that at this stage in the sentence the co-specifier of it is ambiguous. However, the occurence of the word small causes a stable coalition to form with the MY OFFICE schema, and the officefocus the extra activation it to overcome the competing meetingfocus. Thus, by the end of the sentence, the focus has from meetingto office.By the time the it in the final sentence is encountered, there is no competing focus, and the anaphor is resolved immediately. There are a number of fairly obvious drawbacks with the above model. The most important of these being the specificity of the the schema representations. There is no obvious way of implementing a system of variable binding, where a general schema can be used, and various fillers can be bound to, and unbound from, the slots. It is not possible to have such symbol passing in a connectionist network. Instead, all possible slot fillers must be already bound to their slots, and selectively activated when needed. To make this selective activation less unwieldy, a logical step is to use a large number of very specific schemes, rather than a few general ones. Another drawback of the model proposed here is that there is no obvious way of showing how new schemas might be developed, or how existing ones might be modified. One of the basic rules in building connectionist models is that the connections themselves cannot be modified, although their associated weights can be. This means that any new knowledge must be incorporated in an old structure by changing the weights on the connections between the old structure and the new knowledge. This also implies that the new and old elements must already be connected up. In spite of the apparent oversupply of neuronal elements in the human cortex, to have everything connected to virtually everything else seems to be profligate. Another problem with connectionist models is their potential &amp;quot;brittleness&amp;quot;. When trying to program a network to behave in a particular way, it is difficult to resist the urge to patch in arbitrary fixes here and there. There are, as yet, no equivalents of structured programming techniques for networks. However, there are some hopeful signs that researchers are identifying basic network types whose behavior is robust over a range of conditions. In particular, there are winner-take-alland regulatednetworks. The latter type, permits the specification of upper and lower bounds on the activity of a subnetwork, which allows the designer to avoid the twin perils of total saturation of the network on the one hand, and total silence on the other. A reliable taxonomy of sub-networks would greatly aid the designer in building robust networks. 148 VI CONCLUSION This paper briefly described the connectionist approach to cognitive modelling, and showed how it might be applied to langauge processing. A connectionist model of language processing was outlined, which employed schemes and focusing techniques to analyze fragments of discourse. The paper described how the model was successfully able to resolve simple it anaphora. A tape of the simulator used in this paper, &apos; along with a specification of the network used to analyze the sample discourses, is available from the author at the above address, upon receipt of a blank tape.</abstract>
<affiliation confidence="0.454926">VII REFERENCES</affiliation>
<address confidence="0.427853">Cottrell, G.W., &amp; Small, S.L. (1983). A</address>
<title confidence="0.285632">connectionist scheme for modelling word sense</title>
<author confidence="0.518872">Cognitionand Brain Theory</author>
<note confidence="0.832384935483871">6, 89-120. Feldman, J.A., &amp; Ballard, D.H. (1982). Connectionist models and their properties. Science,6, 205-254. McClelland, J.L., &amp; Rumelhart, D.E. (1981). An interactive activation model of context effects in letter perception: Part 1. An of basic findings. Review,88, 375-407. Sidner, C.L. (1983). Focussing in the comprehension of definite anaphora. In M. &amp; R.C. Berwick (Eds.), modelsof discourse,Cambridge, Massachusetts: MIT Press. Small, S.L. (1982). Exploded connections: Unchunking schematic knowledge. Proceedingsof the Annual Conferenceof the Science Society,Ann Arbor, Michigan. Small, S.L., Cottrell, G.W., &amp; Shastri, L. (1982). Toward connectionist parsing. Proceedingsof the Conferenceon Intelligence,Pittsburgh, Pennsylvania. Small, S.L., Shastri, L., Brucks, M.L., Kaufman, S.C., Cottrell, G.W., &amp; Addanki, S. (1983). ISCON: a network construction aid and simulator for connectionist models. TR109. Department of Computer Science, University of Rochester. 149</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G W Cottrell</author>
<author>S L Small</author>
</authors>
<title>A connectionist scheme for modelling word sense disambiguation.</title>
<date>1983</date>
<journal>Cognition and Brain Theory,</journal>
<volume>6</volume>
<pages>89--120</pages>
<contexts>
<context position="4176" citStr="Cottrell and Small (1983)" startWordPosition="642" endWordPosition="645"> (1981). They demonstrated that a model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrell and Small (1983), and of Small (1982). It extends their sentence-centred model to deal with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from the Greek for &amp;quot;pointing back&amp;quot;. What is pointed to is often referred to as the antecedent of the anaphor. However, the precise definition of an antecedent is problematic. Superfici</context>
<context position="11108" citStr="Cottrell and Small (1983)" startWordPosition="1779" endWordPosition="1782">e connected by unidirectional link to the case and schema levels. A lexical unit is connected to all the possible senses of the word. These connections are weighted according to the frequency of occurence of the senses. To simulate hearing or reading a sentence the lexical units are activated one after another from left to right, in the order they occur in the sentence. B. Word Sense Level The units at this level represent the &amp;quot;meaning&amp;quot; of the morphemes in the sentence. Ambiguous words are connected to all their possible meaning units, which are connected to each other by inhibitory links. As Cottrell and Small (1983) have shown, this arrangement provides an accuraate model of the processes involved in word sense disambiguation. Grammatical morphemes, function words, and pronouns do not have explicit representations at this level, rather they connect directly to the case and schema levels. C. Focus Level The units at this level represent possible focuses of the discourse in the sense that Sidner (1983) intends. The focus with the strongest activation inhibits competeing focuses. At any one time there is a single dominant focus, though it may shift as the discourse progresses. A shift in focus occurs when e</context>
<context position="3998" citStr="Cottrell &amp; Small, 1983" startWordPosition="612" endWordPosition="615">s it instructions. A number of language related applications have been developed using this type of approach. The most notable of these is the model of McClelland and Rumelhart (1981). They demonstrated that a model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrell and Small (1983), and of Small (1982). It extends their sentence-centred model to deal with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from t</context>
</contexts>
<marker>Cottrell, Small, 1983</marker>
<rawString>Cottrell, G.W., &amp; Small, S.L. (1983). A connectionist scheme for modelling word sense disambiguation. Cognition and Brain Theory, 6, 89-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Feldman</author>
<author>D H Ballard</author>
</authors>
<title>Connectionist models and their properties.</title>
<date>1982</date>
<journal>Cognitive Science,</journal>
<volume>6</volume>
<pages>205--254</pages>
<contexts>
<context position="16180" citStr="Feldman and Ballard, 1982" startWordPosition="2654" endWordPosition="2657">d Peter are encountered at the end of D1-1, the slot forms a feedback loop with the fillers which lasts until the activity of the sense representation of meeting declines below a threshold. A slot can only be active if the word activating the schema is active, which in this case is meeting. When a number of fillers can fill a slot, as is the case with the WPM_Rarticipant slot, a form of regulated sub-network is used. On the other hand, when there can only be one filler for a slot, as with the WPM_location slot, a winnertake-all network is used (both these types of sub-network are described in Feldman and Ballard, 1982). Associated with each unit at the sense level is a focus unit. A focus unit is connected to its corresponding sense unit by a bidirectional excitatory link, and to other focus units by inhibitory links. As mentioned above, there are two separate networks of focus units, corresponding to actor focuses and discourse focuses, respectively. Actors are animate objects which can serve as agents for verbs. An actor focus unit can only become active if its associated sense level unit is a filler for an agent case slot. The discourse focus and actor focus can be, but need not be, one and the same. The</context>
</contexts>
<marker>Feldman, Ballard, 1982</marker>
<rawString>Feldman, J.A., &amp; Ballard, D.H. (1982). Connectionist models and their properties. Cognitive Science, 6, 205-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L McClelland</author>
<author>D E Rumelhart</author>
</authors>
<title>An interactive activation model of context effects in letter perception: Part 1. An account of basic findings.</title>
<date>1981</date>
<journal>Psychological Review,</journal>
<volume>88</volume>
<pages>375--407</pages>
<contexts>
<context position="3558" citStr="McClelland and Rumelhart (1981)" startWordPosition="550" endWordPosition="553">ot enough bits in firing frequency to allow symbol passing between individual units. This is perhaps the single biggest difference between this approach and and that of standard information-processing models. Another important constraint is that decisions in the network are completely distributed, each unit computes its output solely on the basis of its inputs; it cannot &amp;quot;look around&amp;quot; to see what others are doing, and no central controller gives it instructions. A number of language related applications have been developed using this type of approach. The most notable of these is the model of McClelland and Rumelhart (1981). They demonstrated that a model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrel</context>
</contexts>
<marker>McClelland, Rumelhart, 1981</marker>
<rawString>McClelland, J.L., &amp; Rumelhart, D.E. (1981). An interactive activation model of context effects in letter perception: Part 1. An account of basic findings. Psychological Review, 88, 375-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Focussing in the comprehension of definite anaphora.</title>
<date>1983</date>
<booktitle>In M. Brady &amp; R.C. Berwick (Eds.), Computational models of discourse,</booktitle>
<publisher>MIT Press.</publisher>
<location>Cambridge, Massachusetts:</location>
<contexts>
<context position="4859" citStr="Sidner (1983)" startWordPosition="752" endWordPosition="753"> with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from the Greek for &amp;quot;pointing back&amp;quot;. What is pointed to is often referred to as the antecedent of the anaphor. However, the precise definition of an antecedent is problematic. Superficially, it might be thought of as a preceding text element. However, as Sidner (1983) pointed out words do not refer to other words; people use words to refer to objects, and anaphora are used to refer to objects which have already been mentioned in a discourse. Sidner also maintains that the concept of co-reference is inadequate to explain the relationship between anaphor and antecedent. Co-reference means that anaphor and antecedent both refer to the same object. This explanation suffices for a sentence like: (1) I think green apples are best and they make the best cooking apples too. where both they and green apples refer to the same object. However, it is inadequate when d</context>
<context position="6504" citStr="Sidner, 1983" startWordPosition="1015" endWordPosition="1016">the real world, the anaphor and its antecedent specify a cognitive element in the hearer&apos;s mind. Even though the same element is not co-specified one specification may be used generate the other. This is not possible with co-reference because, as Sidner puts it: Co-specification, unlike co-reference, allows one to construct abstract representations and define relationships between them which can be studied in a computational framework. With coreference, no such use is possible, since the object referred to exists in the world and is not available for examination by the computational process. (Sidner, 1983; p. 269). Sidner proposes two major sources of constraint on what can become the co-specification of an anaphoric reference. One is the shared knowledge of speaker and hearer, and the other is the concept of focus. At any given time the focus of a discourse is that discourse element which is currently being elaborated upon, and on which the speakers have centered their attention. This concept of focus will be implemented in the model to be described, though differently from the way Sidner (1983) has envisaged it. In her model possible focuses are examined serially, and a decision is not made </context>
<context position="11500" citStr="Sidner (1983)" startWordPosition="1841" endWordPosition="1842">t this level represent the &amp;quot;meaning&amp;quot; of the morphemes in the sentence. Ambiguous words are connected to all their possible meaning units, which are connected to each other by inhibitory links. As Cottrell and Small (1983) have shown, this arrangement provides an accuraate model of the processes involved in word sense disambiguation. Grammatical morphemes, function words, and pronouns do not have explicit representations at this level, rather they connect directly to the case and schema levels. C. Focus Level The units at this level represent possible focuses of the discourse in the sense that Sidner (1983) intends. The focus with the strongest activation inhibits competeing focuses. At any one time there is a single dominant focus, though it may shift as the discourse progresses. A shift in focus occurs when evidence for the new focus pushes its level of activation above that of the old one. In keeping with Sidner&apos;s (1983) position there are two types of focus used in this model, an actor focus and a discourse focus. The actor focus represents the animate object in the agent case in the most recent sentence. The discourse focus is, as its name suggests, the central theme of the discourse. The a</context>
<context position="13812" citStr="Sidner, 1983" startWordPosition="2227" endWordPosition="2228">activation of each schema serves, in turn, to activate all its slot fillers. Levels further up in the hierarchy contain more general schema details, and the connections between slots and their potential fillers are less strong. WORK PLACE MEETING schema WPM_location: library tom office my_office WPM time: morning V THE MODEL&apos;S PERFORMANCE afternoon At its current stage of development the model can handle discourse involving pronoun anaphora in which the discourse focus is made to shift. It can resolve the type of reference involved in the following two discourse examples (based on examples by Sidner, 1983; p. 276): D1-1: I&apos;ve arranged a meeting with Mick and Peter. 2: It should be in the afternoon. 3: We can meet in my office. 4: Invite Pat to come too. D2-1: I&apos;ve arranged a meeting with Mick, Peter, and Pat. 2: It should be in the afternoon. 3: We can meet in my office. 4: It&apos;s kind of small, 5: but we&apos;ll only need it for an hour. In discourse D1, the focus throughout is the meeting mentioned in D1-1. The it in 01-2 can be seen to co-specify the focus. In order to determine this a human listner must use their knowledge that meetings have times, among other things. Although no mention is made </context>
<context position="16883" citStr="Sidner (1983)" startWordPosition="2778" endWordPosition="2779">to its corresponding sense unit by a bidirectional excitatory link, and to other focus units by inhibitory links. As mentioned above, there are two separate networks of focus units, corresponding to actor focuses and discourse focuses, respectively. Actors are animate objects which can serve as agents for verbs. An actor focus unit can only become active if its associated sense level unit is a filler for an agent case slot. The discourse focus and actor focus can be, but need not be, one and the same. The distinction between the two types of focus is in line with a similar distinction made by Sidner (1983). The structure of the focus level network ensures that there can only be one discourse focus and one actor focus at a given time. In discourses D1 and 02 the actor focus throughout is the speaker. At the end of the sentence 01-1 the WORK_PLACE_MEETING schema is in a stable coalition with the sense units representing Mick and Peter. The focus units active at this stage are those representing the speaker of the discourse (the actor focus), and the meeting (the discourse focus). When the sentence 01-2 is 147 encountered the system must determine the co-specification of it. The lexical unit it is</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, C.L. (1983). Focussing in the comprehension of definite anaphora. In M. Brady &amp; R.C. Berwick (Eds.), Computational models of discourse, Cambridge, Massachusetts: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Small</author>
</authors>
<title>Exploded connections: Unchunking schematic knowledge.</title>
<date>1982</date>
<booktitle>In Proceedings of the Fourth Annual Conference of the Cognitive Science Society,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="4197" citStr="Small (1982)" startWordPosition="648" endWordPosition="649">model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrell and Small (1983), and of Small (1982). It extends their sentence-centred model to deal with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from the Greek for &amp;quot;pointing back&amp;quot;. What is pointed to is often referred to as the antecedent of the anaphor. However, the precise definition of an antecedent is problematic. Superficially, it might be tho</context>
<context position="12219" citStr="Small (1982)" startWordPosition="1967" endWordPosition="1968">ingle dominant focus, though it may shift as the discourse progresses. A shift in focus occurs when evidence for the new focus pushes its level of activation above that of the old one. In keeping with Sidner&apos;s (1983) position there are two types of focus used in this model, an actor focus and a discourse focus. The actor focus represents the animate object in the agent case in the most recent sentence. The discourse focus is, as its name suggests, the central theme of the discourse. The actor focus and discourse focus can be one and the same. D. Case Level This model employs what Cottrell and Small (1982) call an &amp;quot;exploded case&amp;quot; representation. Instead of general cases such as Agent, Object, Patient, and so on, more specific case categories are used. For instance, the sentence John kicked the ball would activate the specific cases of Kick-agent and Kick-object. The units at this level only fire when there is evidence from the predicate and at least one filler. Their output then goes to the appropriate units at the focus level. In the example above, the predicate for Kick-agent is kick, and its filler is John. The unit Kick-agent then activates the actor focus unit for John. E. Schema Level Thi</context>
</contexts>
<marker>Small, 1982</marker>
<rawString>Small, S.L. (1982). Exploded connections: Unchunking schematic knowledge. In Proceedings of the Fourth Annual Conference of the Cognitive Science Society, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Small</author>
<author>G W Cottrell</author>
<author>L Shastri</author>
</authors>
<title>Toward connectionist parsing.</title>
<date>1982</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="4069" citStr="Small, Cottrell, &amp; Shastri, 1982" startWordPosition="622" endWordPosition="626">ave been developed using this type of approach. The most notable of these is the model of McClelland and Rumelhart (1981). They demonstrated that a model based on connectionist principles could reproduce many of the characteristcs of the so-called word-superiority effect. This is an effect in which letters in briefly presented words and pseudo-words are more easily identifiable than letters in non-words. At a higher level in the processing hierarchy, connectionist schemes have been proposed for modelling wor,d_sense disambiguation (Cottrell &amp; Small, 1983), and for sentence parsing in general (Small, Cottrell, &amp; Shastri, 1982). 144 The model described in this paper is basically an extension of the work of Cottrell and Small (1983), and of Small (1982). It extends their sentence-centred model to deal with connected text, or discourse, and specifically with anaphoric resolution in discourse. The model is not proposed as definitive in any way. It merely sets out to illustrate the properties of connectionist models, and to show how such models might be extended beyond simple word recognition applications. II ANAPHORA The term anaphor derives from the Greek for &amp;quot;pointing back&amp;quot;. What is pointed to is often referred to a</context>
</contexts>
<marker>Small, Cottrell, Shastri, 1982</marker>
<rawString>Small, S.L., Cottrell, G.W., &amp; Shastri, L. (1982). Toward connectionist parsing. In Proceedings of the National Conference on Artificial Intelligence, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Small</author>
<author>L Shastri</author>
<author>M L Brucks</author>
<author>S C Kaufman</author>
<author>G W Cottrell</author>
<author>S Addanki</author>
</authors>
<title>ISCON: a network construction aid and simulator for connectionist models.</title>
<date>1983</date>
<tech>TR109.</tech>
<institution>Department of Computer Science, University of Rochester.</institution>
<contexts>
<context position="7513" citStr="Small, Shastri, Brucks, Kaufman, Cottrell, &amp; Addanki, 1983" startWordPosition="1174" endWordPosition="1181">s have centered their attention. This concept of focus will be implemented in the model to be described, though differently from the way Sidner (1983) has envisaged it. In her model possible focuses are examined serially, and a decision is not made until a sentence has been completely analyzed. In the model proposed here, the focus is arrived at on-line, and the process used is a parallel one. III THE SIMULATOR The model described here was constructed using an interactive connectionist simulator written in Salford LISP and based on the design for the University of Rochester&apos;s ISCON simulator (Small, Shastri, Brucks, Kaufman, Cottrell, &amp; Addanki, 1983). The simulator allows the user to design different types of units. These can have any number of input sites, each with an associated site function. Units also have an associated potential and output function. As well as unit types, ISCON allows the user to design different types of weighted link. A network is constructed by generating units of various types and connecting them up. Processing is initiated by activating designated input units. The simulator is implemented on a Prime 550. A network of about 50 units and 300 links takes approximately 30 CPU seconds per iteration. As the number o</context>
</contexts>
<marker>Small, Shastri, Brucks, Kaufman, Cottrell, Addanki, 1983</marker>
<rawString>Small, S.L., Shastri, L., Brucks, M.L., Kaufman, S.C., Cottrell, G.W., &amp; Addanki, S. (1983). ISCON: a network construction aid and simulator for connectionist models. TR109. Department of Computer Science, University of Rochester.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>