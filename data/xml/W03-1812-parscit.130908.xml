<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001364">
<title confidence="0.987364">
An Empirical Model of Multiword Expression Decomposability
</title>
<author confidence="0.946577">
Timothy Baldwin†, Colin Bannard‡, Takaaki Tanaka* and Dominic Widdows†
</author>
<affiliation confidence="0.5936035">
† CSLI
Stanford University
</affiliation>
<address confidence="0.474227">
Stanford CA 94305, USA
</address>
<email confidence="0.942869">
Itbaldwin,dwiddowsl@csli.stanford.edu
</email>
<affiliation confidence="0.7199645">
‡ School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.8308695">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.998728">
c.j.bannard@ed.ac.uk
</email>
<note confidence="0.954243333333333">
* Communication Science
Labs
NTT Corporation
</note>
<address confidence="0.548896">
Kyoto, Japan
</address>
<email confidence="0.989615">
takaaki@cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.99373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999907882352941">
This paper presents a construction-
inspecific model of multiword expression
decomposability based on latent semantic
analysis. We use latent semantic analysis
to determine the similarity between a
multiword expression and its constituent
words, and claim that higher similarities
indicate greater decomposability. We
test the model over English noun-noun
compounds and verb-particles, and eval-
uate its correlation with similarities and
hyponymy values in WordNet. Based on
mean hyponymy over partitions of data
ranked on similarity, we furnish evidence
for the calculated similarities being corre-
lated with the semantic relational content
of WordNet.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995726984127">
This paper is concerned with an empirical model of
multiword expression decomposability. Multiword
expressions (MWEs) are defined to be cohesive lex-
emes that cross word boundaries (Sag et al., 2002;
Copestake et al., 2002; Calzolari et al., 2002). They
occur in a wide variety of syntactic configurations
in different languages (e.g. in the case of English,
compound nouns: post office, verbal idioms: pull
strings, verb-particle constructions: push on, etc.).
Decomposability is a description of the degree to
which the semantics of an MWE can be ascribed
to those of its parts (Riehemann, 2001; Sag et al.,
2002). Analysis of the semantic correlation between
the constituent parts and whole of an MWE is per-
haps more commonly discussed under the banner of
compositionality (Nunberg et al., 1994; Lin, 1999).
Our claim here is that the semantics of the MWE are
deconstructed and the parts coerced into often id-
iosyncratic interpretations to attain semantic align-
ment, rather than the other way around. One id-
iom which illustrates this process is spill the beans,
where the semantics of reveal&apos;(secret&apos;) are de-
composed such that spill is coerced into the idiosyn-
cratic interpretation of reveal&apos; and beans into the
idiosyncratic interpretation of secret&apos;. Given that
these senses for spill and beans are not readily avail-
able at the simplex level other than in the context
of this particular MWE, it seems fallacious to talk
about them composing together to form the seman-
tics of the idiom.
Ideally, we would like to be able to differ-
entiate between three classes of MWEs: non-
decomposable, idiosyncratically decomposable and
simple decomposable (derived from Nunberg et al.’s
sub-classification of idioms (1994)). With non-
decomposable MWEs (e.g. kick the bucket, shoot
the breeze, hot dog), no decompositional anal-
ysis is possible, and the MWE is semantically
impenetrable. The only syntactic variation that
non-decomposable MWEs undergo is verbal in-
flection (e.g. kicked the bucket, kicks the bucket)
and pronominal reflexivisation (e.g. wet oneself,
wet themselves). Idiosyncratically decomposable
MWEs (e.g. spill the beans, let the cat out of the
bag, radar footprint) are decomposable but co-
erce their parts into taking semantics unavailable
outside the MWE. They undergo a certain degree
of syntactic variation (e.g. the cat was let out of
the bag). Finally, simple decomposable MWEs
(also known as “institutionalised” MWEs, e.g. kin-
dle excitement, traffic light) decompose into simplex
senses and generally display high syntactic variabil-
ity. What makes simple decomposable expressions
true MWEs rather than productive word combina-
tions is that they tend to block compositional al-
ternates with the expected semantics (termed anti-
collocations by Pearce (2001b)). For example, mo-
tor car cannot be rephrased as *engine car or *mo-
tor automobile. Note that the existence of anti-
collocations is also a test for non-decomposable and
idiosyncratically decomposable MWEs (e.g. hot dog
vs. #warm dog or #hot canine).
Our particular interest in decomposability stems
from ongoing work on grammatical means for cap-
turing MWEs. Nunberg et al. (1994) observed that
idiosyncratically decomposable MWEs (in particu-
lar idioms) undergo much greater syntactic variation
than non-decomposable MWEs, and that the vari-
ability can be partially predicted from the decompo-
sitional analysis. We thus aim to capture the decom-
posability of MWEs in the grammar and use this to
constrain the syntax of MWEs in parsing and gen-
eration. Note that it is arguable whether simple de-
composable MWEs belong in the grammar proper,
or should be described instead as lexical affinities
between particular word combinations.
As the first step down the path toward an empir-
ical model of decomposability, we focus on demar-
cating simple decomposable MWEs from idiosyn-
cratically decomposable and non-decomposable
MWEs. This is largely equivalent to classifying
MWEs as being endocentric (i.e., a hyponym of
their head) or ezocentric (i.e., not a hyponym of
their head: Haspelmath (2002)).
We attempt to achieve this by looking at the se-
mantic similarity between an MWE and its con-
stituent words, and hypothesising that where the
similarity between the constituents of an MWE and
the whole is sufficiently high, the MWE must be of
simple decomposable type.
The particular similarity method we adopt is la-
tent semantic analysis, or LSA (Deerwester et al.,
1990). LSA allows us to calculate the similarity
between an arbitrary word pair, offering the advan-
tage of being able to measure the similarity between
the MWE and each of its constituent words. For
MWEs such as house boat, therefore, we can expect
to capture the fact that the MWE is highly similar in
meaning to both constituent words (i.e. the modifier
house and head noun boat). More importantly, LSA
makes no assumptions about the lexical or syntac-
tic composition of the inputs, and thus constitutes a
fully construction- and language-inspecific method
of modelling decomposability. This has clear advan-
tages over a more conventional supervised classifier-
style approach, where training data would have to be
customised to a particular language and construction
type.
Evaluation is inevitably a difficulty when it comes
to the analysis of MWEs, due to the lack of con-
cise consistency checks on what MWEs should and
should not be incorporated into dictionaries. While
recognising the dangers associated with dictionary-
based evaluation, we commit ourselves to this
paradigm and focus on searching for appropriate
means of demonstrating the correlation between
dictionary- and corpus-based similarities.
The remainder of this paper is structured as fol-
lows. Section 2 describes past research on MWE
compositionality of relevance to this effort. Sec-
tion 3 provides a basic outline of the resources used
in this research, LSA, the MWE extraction methods,
and measures used to evaluate our method. Section 4
then provides evaluation of the proposed method,
and the paper is concluded with a brief discussion
in Section 5.
</bodyText>
<sectionHeader confidence="0.872099" genericHeader="method">
2 Past research
</sectionHeader>
<bodyText confidence="0.99998372">
Although there has been some useful work on com-
positionality in statistical machine translation (e.g.
Melamed (1997)), there has been little work on de-
tecting “non-compositional” (i.e. non-decomposable
and idiosyncratically decomposable) items of vari-
able syntactic type in monolingual corpora. One in-
teresting exception is Lin (1999), whose approach is
explained as follows:
The intuitive idea behind the method is
that the metaphorical usage of a non-
compositional expression causes it to
have a different distributional characteris-
tic than expressions that are similar to its
literal meaning.
The expressions he uses are taken from a colloca-
tion database (Lin, 1998b). These “expressions that
are similar to [their] literal meaning” are found by
substituting each of the words in the expression with
the 10 most similar words according to a corpus de-
rived thesaurus (Lin, 1998a). Lin models the dis-
tributional difference as a significant difference in
mutual information. Significance here is defined as
the absence of overlap between the 95% confidence
interval of the mutual information scores. Lin pro-
vides some examples that suggest he has identified
a successful measure of “compositionality”. He of-
fers an evaluation where an item is said to be non-
compositional if it occurs in a dictionary of idioms.
This produces the unconvincing scores of 15.7% for
precision and 13.7% for recall.
We claim that substitution-based tests are use-
ful in demarcating MWEs from productive word
combinations (as attested by Pearce (2001a) in a
MWE detection task), but not in distinguishing the
different classes of decomposability. As observed
above, simple decomposable MWEs such as mo-
tor car fail the substitution test not because of non-
decomposability, but because the expression is in-
stitutionalised to the point of blocking alternates.
Thus, we expect Lin’s method to return a wide ar-
ray of both decomposable and non-decomposable
MWEs.
Bannard (2002) focused on distributional tech-
niques for describing the meaning of verb-particle
constructions at the level of logical form. The
semantic similarity between a multiword expres-
sion and its head was used as an indicator of
decomposability. The assumption was that if a
verb-particle was sufficiently similar to its head
verb, then the verb contributed its simplex mean-
ing. It gave empirical backing to this assump-
tion by showing that annotator judgements for verb-
particle decomposability correlate significantly with
non-expert human judgements on the similarity be-
tween a verb-particle construction and its head verb.
Bannard et al. (2003) extended this research in look-
ing explicitly at the task of classifying verb-particles
as being compositional or not. They successfully
combined statistical and distributional techniques
(including LSA) with a substitution test in analysing
compositionality. McCarthy et al. (2003) also tar-
geted verb-particles for a study on compositionality,
and judged compositionality according to the degree
of overlap in the N most similar words to the verb-
particle and head verb, e.g., to determine composi-
tionality.
We are not the first to consider applying LSA to
MWEs. Schone and Jurafsky (2001) applied LSA to
the analysis of MWEs in the task of MWE discov-
ery, by way of rescoring MWEs extracted from a
corpus. The major point of divergence from this re-
search is that Schone and Jurafsky focused specifi-
cally on MWE extraction, whereas we are interested
in the downstream task of semantically classifying
attested MWEs.
</bodyText>
<sectionHeader confidence="0.989504" genericHeader="method">
3 Resources and Techniques
</sectionHeader>
<bodyText confidence="0.999911666666667">
In this section, we outline the resources used in eval-
uation, give an informal introduction to the LSA
model, sketch how we extracted the MWEs from
corpus data, and describe a number of methods
for modelling decomposability within a hierarchical
lexicon.
</bodyText>
<subsectionHeader confidence="0.994902">
3.1 Resources and target MWEs
</subsectionHeader>
<bodyText confidence="0.999990222222222">
The particular reference lexicon we use to eval-
uate our technique is WordNet 1.7 (Miller et
al., 1990), due to its public availability, hier-
archical structure and wide coverage. Indeed,
Schone and Jurafsky (2001) provide evidence that
suggests that WordNet is as effective an evaluation
resource as the web for MWE detection methods,
despite its inherent size limitations and static nature.
Two MWE types that are particularly well repre-
sented in WordNet are compound nouns (47,000 en-
tries) and multiword verbs (2,600 entries). Of these,
we chose to specifically target two types of MWE:
noun-noun (NN) compounds (e.g. computer net-
work, workforce) and verb-particles (e.g. look on,
eat up) due to their frequent occurrence in both de-
composable and non-decomposable configurations,
and also their disparate syntactic behaviours.
We extracted the NN compounds from the 1996
Wall Street Journal data (WSJ, 31m words), and
the verb-particles from the British National Corpus
(BNC, 90m words: Burnard (2000)). The WSJ data
is more tightly domain-constrained, and thus a more
suitable source for NN compounds if we are to ex-
pect sentential context to reliably predict the seman-
tics of the compound. The BNC data, on the other
hand, contains more colloquial and prosaic texts and
is thus a richer source of verb-particles.
</bodyText>
<subsectionHeader confidence="0.999769">
3.2 Description of the LSA model
</subsectionHeader>
<bodyText confidence="0.989802661290323">
Our goal was to compare the distribution of differ-
ent compound terms with their constituent words, to
see if this indicated similarity of meaning. For this
purpose, we used latent semantic analysis (LSA) to
build a vector space model in which term-term sim-
ilarities could be measured.
LSA is a method for representing words as points
in a vector space, whereby words which are related
in meaning should be represented by points which
are near to one another, first developed as a method
for improving the vector model for information re-
trieval (Deerwester et al., 1990). As a technique for
measuring similarity between words, LSA has been
shown to capture semantic properties, and has been
used successfully for recognising synonymy (Lan-
dauer and Dumais, 1997), word-sense disambigua-
tion (Sch¨utze, 1998) and for finding correct transla-
tions of individual terms (Widdows et al., 2002).
The LSA model we built is similar to that de-
scribed in (Sch¨utze, 1998). First, 1000 frequent con-
tent words (i.e. not on the stoplist)l were chosen
as “content-bearing words”. Using these content-
bearing words as column labels, the 50,000 most
frequent terms in the corpus were assigned row
vectors by counting the number of times they oc-
&apos;A “stoplist” is a list of frequent words which have little
independent semantic content, such as prepositions and deter-
miners (Baeza-Yates and Ribiero-Neto, 1999, p167).
curred within the same sentence as a content-bearing
word. Singular-value decomposition (Deerwester et
al., 1990) was then used to reduce the number of
dimensions from 1000 to 100. Similarity between
two vectors (points) was measured using the cosine
of the angle between them, in the same way as the
similarity between a query and a document is often
measured in information retrieval (Baeza-Yates and
Ribiero-Neto, 1999, p28). Effectively, we could use
LSA to measure the extent to which two words or
MWEs x and y usually occur in similar contexts.
Since the corpora had been tagged with parts-of-
speech, we could build syntactic distinctions into the
LSA models — instead of just giving a vector for
the string test we were able to build separate vec-
tors for the nouns, verbs and adjectives test. This
combination of technologies was also used to good
effect by Widdows (2003): an example of the con-
tribution of part-of-speech information to extracting
semantic neighbours of the word fire is shown in
Table 1. As can be seen, the noun fire (as in the
substance/element) and the verb fire (mainly used
to mean firing some sort of weapon) are related to
quite different areas of meaning. Building a single
vector for the string fire confuses this distinction —
the neighbours offire treated just as a string include
words related to both the meaning offire as a noun
(more frequent in the BNC) and as a verb. The ap-
propriate granularity of syntactic classifications is an
open question for this kind of research: treating all
the possible verbs categories as different (e.g. dis-
tinguishing infinitive from finite from gerund forms)
led to data sparseness, and instead we considered
“verb” as a single part-of-speech type.
</bodyText>
<subsectionHeader confidence="0.975054">
3.3 MWE extraction methods
</subsectionHeader>
<bodyText confidence="0.999984125">
NN compounds were extracted from the WSJ by
first tagging the data with fnTBL 1.0 (Ngai and Flo-
rian, 2001) and then simply taking noun bigrams
(adjoined on both sides by non-nouns to assure the
bigram is not part of a larger compound nominal).
Out of these, we selected those compounds that are
listed in WordNet, resulting in 5,405 NN compound
types (208,000 tokens).
Extraction of the verb-particles was consider-
ably more involved, and drew on the method of
Baldwin and Villavicencio (2002). Essentially, we
used a POS tagger and chunker (both built using
fnTBL 1.0 (Ngai and Florian, 2001)) to first (re)tag
the BNC. This allowed us to extract verb-particle to-
kens through use of the particle POS and chunk tags
returned by the two systems. This produces high-
precision, but relatively low-recall results, so we
performed the additional step of running a chunk-
based grammar over the chunker output to detect
candidate mistagged particles. In the case that a
noun phrase followed the particle candidate, we per-
formed attachment disambiguation to determine the
transitivity of the particle candidate. These three
methods produced three distinct sets of verb-particle
tokens, which we carried out weighted voting over
to determine the final set of verb-particle tokens. A
total of 461 verb-particles attested in WordNet were
extracted (160,765 tokens).
For both the NN compound and verb-particle
data, we replaced each token occurrence with a
single-word POS-tagged token to feed into the LSA
model.
</bodyText>
<sectionHeader confidence="0.9661435" genericHeader="method">
3.4 Techniques for evaluating correlation with
WordNet
</sectionHeader>
<bodyText confidence="0.999947272727273">
In order to evaluate our approach, we employed the
lexical relations as defined in the WordNet lexical
hierarchy (Miller et al., 1990). WordNet groups
words into sets with similar meaning (known as
“synsets”), e.g. {car, auto, automobile, machine,
motorcar } . These are organised into a hierarchy
employing multiple inheritance. The hierarchy is
structured according to different principles for each
of nouns, verbs, adjectives and adverbs. The nouns
are arranged according to hyponymy or ISA rela-
tions, e.g. a car is a kind of automobile. The verbs
are arranged according to troponym or “manner-of”
relations, where murder is a manner of killing, so
kill immediately dominates murder in the hierarchy.
We used WordNet for evaluation by way of look-
ing at: (a) hyponymy, and (b) semantic distance.
Hyponymy provides the most immediate way of
evaluating decomposability. With simple decompos-
able MWEs, we can expect the constituents (and
particularly the head) to be hypernyms (ancestor
nodes) or synonyms of the MWE. That is, simple
decomposable MWEs are generally endocentric, al-
though there are some exceptions to this generali-
sation such as vice president arguably not being a
hyponym of president. No hyponymy relation holds
with non-decomposable or idiosyncratically decom-
posable MWEs (i.e., they are exocentric), as even if
the semantics of the head noun can be determined
through decomposition, by definition this will not
correspond to a simplex sense of the word.
We deal with polysemy of the constituent words
and/or MWE by simply looking for the exis-
tence of a sense of the constituent words which
</bodyText>
<table confidence="0.991745960784314">
fire (string only)
fire 1.000000
Iames 0.709939
smoke 0.680601
blaze 0.668504
firemen 0.627065
fires 0.617494
explosion 0.572138
burning 0.559897
destroyed 0.558699
brigade 0.532248
arson 0.528909
accidental 0.519310
chimney 0.489577
blast 0.488617
guns 0.487226
damaged 0.484897
fire nn1
fire nn1 1.000000
Iames nn2 0.700575
smoke nn1 0.696028
brigade nn1 0.589625
fires nn2 0.584643
firemen nn2 0.567170
explosion nn1 0.551594
destroyed vvn 0.547631
burning aj0 0.533586
blaze nn1 0.529126
arson nn1 0.522844
alarms nn2 0.512332
destroyed vvd 0.512130
burning vvg 0.502052
burnt vvn 0.500864
blast nn1 0.498635
fire vvi
fire vvi 1.000000
guns nn2 0.663820
firing vvg 0.537778
cannon nn0 0.523442
gun nn1 0.484106
fired vvd 0.478572
detectors nn2 0.477025
artillery nn1 0.469173
attack vvb 0.468767
firing nn1 0.459000
volley nn1 0.458717
trained vvn 0.447797
enemy nn1 0.445523
alert aj0 0.443610
shoot vvi 0.443308
defenders nn2 0.438886
</table>
<tableCaption confidence="0.999942">
Table 1: Semantic neighbours offire with different parts-of-speech. The scores are cosine similarities
</tableCaption>
<bodyText confidence="0.910785583333333">
subsumes a sense of the MWE. The function
hyponym(wordi, mwe) thus returns a value of 1 if
some sense of wordz subsumes a sense of mwe, and
a value of 0 otherwise.
A more proactive means of utilising the WordNet
hierarchy is to derive a semantic distance based on
analysis of the relative location of senses in Word-
Net. Budanitsky and Hirst (2001) evaluated the per-
formance of five different methods that measure
the semantic distance between words in the Word-
Net Hierarchy, which Patwardhan et al. (2003) have
then implemented and made available for general
use as the Perl package distance-0.11.2 We fo-
cused in particular on the following three measures,
the first two of which are based on information the-
oretic principles, and the third on sense topology:
• Resnik (1995) combined WordNet with corpus
statistics. He defines the similarity between
two words as the information content of the
lowest superordinate in the hierarchy, defining
the information content of a concept c (where
a concept is the WordNet class containing the
word) to be the negative of its log likelihood.
This is calculated over a corpus of text.
</bodyText>
<listItem confidence="0.91333125">
• Lin (1998c) also employs the idea of corpus-
derived information content, and defines the
similarity between two concepts in the follow-
ing way:
</listItem>
<equation confidence="0.9434405">
2log P(C0)
sim(C1, C2) = log P(C1) + log P(C2) (1)
</equation>
<bodyText confidence="0.7757355">
where C0 is the lowest class in the hierarchy
that subsumes both classes.
</bodyText>
<footnote confidence="0.9452165">
2http://www.d.umn.edu/˜tpederse/
distance.html
</footnote>
<listItem confidence="0.923279">
• Hirst and St-Onge (1998) use a system of “re-
</listItem>
<bodyText confidence="0.8981440625">
lations” of different strength to determine the
similarity of word senses, conditioned on the
type, direction and relative distance of edges
separating them.
The Patwardhan et al. (2003) implementation that
we used calculates the information values from
SemCor, a semantically tagged subset of the Brown
corpus. Note that the first two similarity measures
operate over nouns only, while the last can be ap-
plied to any word class.
The similarity measures described above calcu-
late the similarity between a pair of senses. In the
case that a given constituent word and/or MWE oc-
cur with more than one sense, we calculate a similar-
ity for sense pairing between them, and average over
them to produce a consolidated similarity value.
</bodyText>
<sectionHeader confidence="0.998855" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999945764705883">
LSA was used to build models in which MWEs
could be compared with their constituent words.
Two models were built, one from the WSJ corpus
(indexing NN compounds) and one from the BNC
(indexing verb-particles). After removing stop-
words, the 50,000 most frequent terms were indexed
in each model. From the WSJ, these 50,000 terms
included 1,710 NN compounds (with corpus fre-
quency of at least 13) and from the BNC, 461 verb-
particles (with corpus frequency of at least 49).
We used these models to compare different words,
and to find their neighbours. For example, the neigh-
bours of the simplex verb cut and the verb-particles
cut out and cut off (from the BNC model) are shown
in Table 2. As can be seen, several of the neighbours
of cut out are from similar semantic areas as those
of cut, whereas those of cut off are quite different.
</bodyText>
<table confidence="0.989692946428572">
cut (verb)
cut off (verb)
cut out (verb)
cut verb 1.000000
trim verb 0.529886
cut nns 0.520345
cut nn 0.502100
reduce verb 0.465364
cut out verb 0.433465
pull verb 0.431929
fall verb 0.426111
hook verb 0.419564
recycle verb 0.413206
project verb 0.401246
recycled jj 0.396315
prune verb 0.395656
pare verb 0.394991
tie verb 0.392964
cut out verb 1.000000
fondant nn 0.516956
strip nns 0.475293
piece nns 0.449555
roll nnp 0.440769
stick jj 0.434082
cut verb 0.433465
icing nn 0.432307
piece nn 0.418780
paste nn 0.416581
tip nn 0.413603
hole nns 0.412813
straw nn 0.411617
hook nn 0.402947
strip nn 0.399974
cutoff verb 1.000000
knot nn 0.448871
choke verb 0.440587
vigorously rb 0.438071
suck verb 0.413003
crush verb 0.412301
ministry nn 0.408702
glycerol nn 0.395148
tap verb 0.383932
shake verb 0.381581
jerk verb 0.381284
put down verb 0.380368
circumference nn 0.378097
jn nnp 0.375634
pump verb 0.373984
nell nnp 0.373768
slash verb 0.522370 fondant jj 0.501266
Table 2: Semantic neighbours of the verbs cut, cut out, and cut off.
Construction Method Pearson R2
Resnik .108 .012
NN compound Lin .101 .010
HSO .072 .005
verb-particle HSO .255 .065
</table>
<tableCaption confidence="0.814133">
Table 3: Correlation between LSA and WordNet
similarities
</tableCaption>
<bodyText confidence="0.999588666666667">
This reflects the fact that in most of its instances the
verb cut off is used to mean “forcibly isolate”.
In order to measure this effect quantitatively, we
can simply take the cosine similarities between these
verbs, finding that sim(cut, cutout) = 0.433 and
sim(cut, cut off) = 0.183 from which we infer di-
rectly that, relative to the sense of cut, cut out is a
clearer case of a simple decomposable MWE than
cut off.
</bodyText>
<subsectionHeader confidence="0.999845">
4.1 Statistical analysis
</subsectionHeader>
<bodyText confidence="0.999735444444444">
In order to get an initial feel for how well
the LSA-based similarities for MWEs and their
head words correlate with the WordNet-based
similarities over those same word pairs, we
did a linear regression and Pearson’s correla-
tion analysis of the paired data (i.e. the pair-
ing (simLSA(wordi, mwe), simWN(wordi, mwe))
for each WordNet similarity measure simWN). For
both tests, values closer to 0 indicate random distri-
bution of the data, whereas values closer to 1 indi-
cate a strong correlation. The correlation results for
NN compounds and verb-particles are presented in
Table 3, where R2 refers to the output of the linear
regression test and HSO refers to Hirst and St-Onge
similarity measure. In the case of NN compounds,
the correlation with LSA is very low for all tests,
that is LSA is unable to reproduce the relative sim-
ilarity values derived from WordNet with any reli-
</bodyText>
<figure confidence="0.9994475">
Mean Hyponymy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
1
1 2 3
Partition No.
VPC(head) ALL
NN(mod)
NN(head) ALL
ALL
VPC(head) LOW
VPC(head)
NN(head) LOW
NN(head) HIGH
HIGH
</figure>
<figureCaption confidence="0.999995">
Figure 1: Hyponymy correlation
</figureCaption>
<bodyText confidence="0.999560363636364">
ability. With verb-particles, correlation is notably
higher than for NN compounds,3 but still at a low
level.
Based on these results, LSA would appear to
correlate poorly with WordNet-based similarities.
However, our main interest is not in similarity per
se, but how reflective LSA similarities are of the de-
composability of the MWE in question. While tak-
ing note of the low correlation with WordNet simi-
larities, therefore, we move straight on to look at the
hyponymy test.
</bodyText>
<subsectionHeader confidence="0.996532">
4.2 Hyponymy-based analysis
</subsectionHeader>
<bodyText confidence="0.996297820895523">
We next turn to analysis of correlation between LSA
similarities and hyponymy values. Our expectation
is that for constituent word–MWE pairs with higher
LSA similarities, there is a greater likelihood of the
MWE being a hyponym of the constituent word. We
test this hypothesis by ranking the constituent word–
MWE pairs in decreasing order of LSA similarity,
3Recall that HSO is the only similarity measure which oper-
ates over verbs.
and partitioning the ranking up into m partitions of
equal size. We then calculate the average number of
hyponyms per partition. If our hypothesis is correct,
the earlier partitions (with higher LSA similarities)
will have higher occurrences of hyponyms than the
latter partitions.
Figure 1 presents the mean hyponymy values
across partitions of the NN compound data and verb-
particle data, with m set to 3 in each case. For the
NN compounds, we derive two separate rankings,
based on the similarity between the head noun and
NN compound (NN(head)) and the modifier noun
and the NN compound (NN(mod)). In the case of
the verb-particle data, WordNet has no classification
of prepositions or particles, so we can only calcu-
late the similarity between the head verb and verb-
particle (VPC(head)). Looking to the curves for
these three rankings, we see that they are all fairly
flat, nondescript curves. If we partition the data up
into low- and high-frequency MWEs, as defined by a
threshold of 100 corpus occurrences, we find that the
graphs for the low-frequency data (NN(head)LOW
and VPC(head)LOW) are both monotonically de-
creasing, whereas those for high-frequency data
(NN(head)HIGH and VPC(head)HIGH) are more hap-
hazard in nature. Our hypothesis of lesser instances
of hyponymy for lower similarities is thus supported
for low-frequency items but not for high-frequency
items, suggesting that LSA similarities are more
brittle over high-frequency items for this particu-
lar task. The results for the low-frequency items
are particularly encouraging given that the LSA-
based similarities were found to correlate poorly
with WordNet-derived similarities. The results for
NN(mod) are more erratic for both low- and high-
frequency terms, that is the modifier noun is not as
strong a predictor of decomposability as the head
noun. This is partially supported by the statistics on
the relative occurrence of NN compounds in Word-
Net subsumed by their head noun (71.4%) as com-
pared to NN compounds subsumed by their modifier
(13.7%).
In an ideal world, we would hope that the val-
ues for mean hyponymy were nearly 1 for the first
partition and nearly 0 for the last. Naturally, this
presumes perfect correlation of the LSA similarities
with decomposability, but classificational inconsis-
tencies in WordNet also work against us. For ex-
ample, vice chairman is an immediate hyponym of
both chairman and president, but vice president is
not a hyponym of president. According to LSA,
however, sim(chairman, vice chairman) = .508 and
sim(president, vice president) = .551.
It remains to be determined why LSA should per-
form better over low-frequency items, although the
higher polysemy of high-frequency items is one po-
tential cause. We intend to further investigate this
matter in future research.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="discussions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99994172">
While evaluation pointed to a moderate correlation
between LSA similarities and occurrences of hy-
ponymy, we have yet to answer the question of
exactly where the cutoffs between simple decom-
posable, idiosyncratically decomposable and non-
decomposable MWEs lie. While it would be pos-
sible to set arbitrary thresholds to artificially parti-
tion up the space of MWEs based on LSA similarity
(or alternatively use statistical tests to derive confi-
dence intervals for similarity values), we feel that
more work needs to be done in establishing exactly
what different LSA similarities for different MWE–
constituent word combinations mean.
One area in which we plan to extend this research
is the analysis of MWEs in languages other than
English. Because of LSA’s independence from lin-
guistic constraints, it is equally applicable to all lan-
guages, assuming there is some way of segmenting
inputs into constituent words.
To summarise, we have proposed a construction-
inspecific empirical model of MWE decomposabil-
ity, based on latent semantic analysis. We evaluated
the method over English NN compounds and verb-
particles, and showed it to correlate moderately with
WordNet-based hyponymy values.
</bodyText>
<sectionHeader confidence="0.995035" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.988577">
This material is partly based upon work supported by the Na-
tional Science Foundation under Grant No. BCS-0094638 and
also the Research Collaboration between NTT Communication
Science Laboratories, Nippon Telegraph and Telephone Corpo-
ration and CSLI, Stanford University. We would like to thank
the anonymous reviewers for their valuable input on this re-
search.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684745762712">
Ricardo Baeza-Yates and Berthier Ribiero-Neto. 1999. Modern
Information Retrieval. Addison Wesley / ACM press.
Timothy Baldwin and Aline Villavicencio. 2002. Extracting
the unextractable: A case study on verb-particles. In Proc. of
the 6th Conference on Natural Language Learning (CoNLL-
2002), Taipei, Taiwan.
Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003.
A statistical approach to the semantics of verb-particles. In
Proc. of the ACL-2003 Workshop on Multiword Expressions:
Analysis, Acquisition and Treatment. (this volume).
Colin Bannard. 2002. Statistical techniques for automati-
cally inferring the semantics of verb-particle constructions.
LinGO Working Paper No. 2002-06.
Alexander Budanitsky and Graeme Hirst. 2001. Semantic dis-
tance in WordNet: An experimental, application-oriented
evaluation of five measures. In Workshop on Wordnet and
Other Lexical Resources, Second meeting of the NAACL,
Pittsburgh, USA.
Lou Burnard. 2000. User Reference Guide for the British Na-
tional Corpus. Technical report, Oxford University Comput-
ing Services.
Nicoletta Calzolari, Charles Fillmore, Ralph Grishman, Nancy
Ide, Alessandro Lenci, Catherine MacLeod, and Antonio
Zampolli. 2002. Towards best practice for multiword ex-
pressions in computational lexicons. In Proceedings of the
Third International Conference on Language Resources and
Evaluation (LREC 2002), pages 1934–40, Las Palmas, Ca-
nary Islands.
Ann Copestake, Fabre Lambeau, Aline Villavicencio, Francis
Bond, Timothy Baldwin, Ivan A. Sag, and Dan Flickinger.
2002. Multiword expressions: Linguistic precision and
reusability. In Proc. of the 3rd International Conference
on Language Resources and Evaluation (LREC 2002), pages
1941–7, Las Palmas, Canary Islands.
Scott Deerwester, Susan Dumais, George Furnas, Thomas Lan-
dauer, and Richard Harshman. 1990. Indexing by latent
semantic analysis. Journal of the American Society for In-
formation Science, 41(6):391–407.
Martin Haspelmath. 2002. Understanding Morphology.
Arnold Publishers.
Graeme Hirst and David St-Onge. 1998. Lexical chains as
representations of context for the detection and correction
of malapropism. In Christiane Fellbaum, editor, WordNet:
An Electronic Lexical Database, pages 305–32. MIT Press,
Cambridge, USA.
Thomas Landauer and Susan Dumais. 1997. A solution to
Plato’s problem: The latent semantic analysis theory of ac-
quisition. Psychological Review, 104(2):211–240.
Dekang Lin. 1998a. Automatic retrieval and clustering of simi-
lar words. In Proceedings of the 36th Annual Meeting of the
ACL and 17th International Conference on Computational
Linguistics (COLING/ACL-98).
Dekang Lin. 1998b. Extracting collocations from text corpora.
In First Workshop on Computational Terminology.
Dekang Lin. 1998c. An information-theoretic definition of
similarity. In Proceedings of the 15th International Confer-
ence on Machine Learning.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proc. of the 37th Annual Meeting
of the ACL, pages 317–24, College Park, USA.
Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting
a continuum of compositionality in phrasal verbs. In Proc. of
the ACL-2003 Workshop on Multiword Expressions: Analy-
sis, Acquisition and Treatment. (this volume).
I. Dan Melamed. 1997. Automatic discovery of non-
compositional compounds in parallel data. In Proc. of the
2nd Conference on Empirical Methods in Natural Language
Processing (EMNLP-97), Providence, USA.
George A. Miller, Richard Beckwith, Christiane Fellbaum,
Derek Gross, and Katherine J. Miller. 1990. Introduction
to WordNet: an on-line lexical database. International Jour-
nal ofLexicography, 3(4):235–44.
Grace Ngai and Radu Florian. 2001. Transformation-based
learning in the fast lane. In Proc. of the 2nd Annual Meeting
of the North American Chapter of Association for Compu-
tational Linguistics (NAACL2001), pages 40–7, Pittsburgh,
USA.
Geoffrey Nunberg, Ivan A. Sag, and Tom Wasow. 1994. Id-
ioms. Language, 70:491–538.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted Pedersen.
2003. Using measures of semantic relatedness for word
sense disambiguation. In Proc. of the 4th International Con-
ference on Intelligent Text Processing and Computational
Linguistics (CICLing-2003), Mexico City, Mexico.
Darren Pearce. 2001a. Synonymy in collocation extraction. In
Proc. of the NAACL 2001 Workshop on WordNet and Other
Lexical Resources: Applications, Extensions and Customiza-
tions, Pittsburgh, USA.
Darren Pearce. 2001b. Using conceptual similarity for collo-
cation extraction. In Proc. of the 4th UK Special Interest
Group for Computational Linguistics (CLUK4).
Philip Resnik. 1995. Using information content to evaluate
semantic similarity. In Proceedings of the 14th International
Joint Conference on Artificial Intelligence.
Susanne Riehemann. 2001. A Constructional Approach to Id-
ioms and Word Formation. Ph.D. thesis, Stanford.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake,
and Dan Flickinger. 2002. Multiword expressions: A pain in
the neck for NLP. In Proc. of the 3rd International Confer-
ence on Intelligent Text Processing and Computational Lin-
guistics (CICLing-2002), pages 1–15, Mexico City, Mexico.
Patrick Schone and Dan Jurafsky. 2001. Is knowledge-free
induction of multiword unit dictionary headwords a solved
problem? In Proc. of the 6th Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP 2001), pages
100–108.
Hinrich Sch¨utze. 1998. Automatic word sense discrimination.
Computational Linguistics, 24(1):97–124.
Dominic Widdows, Beate Dorow, and Chiu-Ki Chan. 2002.
Using parallel corpora to enrich multilingual lexical re-
sources. In Third International Conference on Language Re-
sources and Evaluation, pages 240–245, Las Palmas, Spain,
May.
Dominic Widdows. 2003. Unsupervised methods for develop-
ing taxonomies by combining syntactic and statistical infor-
mation. In Proc. of the 3rd International Conference on Hu-
man Language Technology Research and 4th Annual Meet-
ing of the NAACL (HLT-NAACL 2003). (to appear).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.231250">
<title confidence="0.999689">An Empirical Model of Multiword Expression Decomposability</title>
<author confidence="0.910786">Colin Takaaki</author>
<author confidence="0.910786">Dominic</author>
<affiliation confidence="0.923051">Stanford</affiliation>
<address confidence="0.6904575">Stanford CA 94305, USA of</address>
<affiliation confidence="0.9889985">University of 2 Buccleuch</affiliation>
<address confidence="0.99806">Edinburgh EH8 9LW, UK</address>
<email confidence="0.992993">c.j.bannard@ed.ac.uk</email>
<affiliation confidence="0.753889">NTT</affiliation>
<address confidence="0.777496">Kyoto, Japan</address>
<email confidence="0.979343">takaaki@cslab.kecl.ntt.co.jp</email>
<abstract confidence="0.992933888888889">This paper presents a constructioninspecific model of multiword expression decomposability based on latent semantic analysis. We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Ribiero-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>Addison Wesley / ACM press.</publisher>
<contexts>
<context position="13683" citStr="Baeza-Yates and Ribiero-Neto, 1999" startWordPosition="2128" endWordPosition="2131">is, 1997), word-sense disambiguation (Sch¨utze, 1998) and for finding correct translations of individual terms (Widdows et al., 2002). The LSA model we built is similar to that described in (Sch¨utze, 1998). First, 1000 frequent content words (i.e. not on the stoplist)l were chosen as “content-bearing words”. Using these contentbearing words as column labels, the 50,000 most frequent terms in the corpus were assigned row vectors by counting the number of times they oc&apos;A “stoplist” is a list of frequent words which have little independent semantic content, such as prepositions and determiners (Baeza-Yates and Ribiero-Neto, 1999, p167). curred within the same sentence as a content-bearing word. Singular-value decomposition (Deerwester et al., 1990) was then used to reduce the number of dimensions from 1000 to 100. Similarity between two vectors (points) was measured using the cosine of the angle between them, in the same way as the similarity between a query and a document is often measured in information retrieval (Baeza-Yates and Ribiero-Neto, 1999, p28). Effectively, we could use LSA to measure the extent to which two words or MWEs x and y usually occur in similar contexts. Since the corpora had been tagged with p</context>
</contexts>
<marker>Baeza-Yates, Ribiero-Neto, 1999</marker>
<rawString>Ricardo Baeza-Yates and Berthier Ribiero-Neto. 1999. Modern Information Retrieval. Addison Wesley / ACM press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Aline Villavicencio</author>
</authors>
<title>Extracting the unextractable: A case study on verb-particles.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th Conference on Natural Language Learning (CoNLL2002),</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="15934" citStr="Baldwin and Villavicencio (2002)" startWordPosition="2504" endWordPosition="2507">ite from gerund forms) led to data sparseness, and instead we considered “verb” as a single part-of-speech type. 3.3 MWE extraction methods NN compounds were extracted from the WSJ by first tagging the data with fnTBL 1.0 (Ngai and Florian, 2001) and then simply taking noun bigrams (adjoined on both sides by non-nouns to assure the bigram is not part of a larger compound nominal). Out of these, we selected those compounds that are listed in WordNet, resulting in 5,405 NN compound types (208,000 tokens). Extraction of the verb-particles was considerably more involved, and drew on the method of Baldwin and Villavicencio (2002). Essentially, we used a POS tagger and chunker (both built using fnTBL 1.0 (Ngai and Florian, 2001)) to first (re)tag the BNC. This allowed us to extract verb-particle tokens through use of the particle POS and chunk tags returned by the two systems. This produces highprecision, but relatively low-recall results, so we performed the additional step of running a chunkbased grammar over the chunker output to detect candidate mistagged particles. In the case that a noun phrase followed the particle candidate, we performed attachment disambiguation to determine the transitivity of the particle ca</context>
</contexts>
<marker>Baldwin, Villavicencio, 2002</marker>
<rawString>Timothy Baldwin and Aline Villavicencio. 2002. Extracting the unextractable: A case study on verb-particles. In Proc. of the 6th Conference on Natural Language Learning (CoNLL2002), Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verb-particles.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and</booktitle>
<contexts>
<context position="9722" citStr="Bannard et al. (2003)" startWordPosition="1493" endWordPosition="1496">butional techniques for describing the meaning of verb-particle constructions at the level of logical form. The semantic similarity between a multiword expression and its head was used as an indicator of decomposability. The assumption was that if a verb-particle was sufficiently similar to its head verb, then the verb contributed its simplex meaning. It gave empirical backing to this assumption by showing that annotator judgements for verbparticle decomposability correlate significantly with non-expert human judgements on the similarity between a verb-particle construction and its head verb. Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. They successfully combined statistical and distributional techniques (including LSA) with a substitution test in analysing compositionality. McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality. We are not the first to consider applying LSA to MWEs. Schone and Jurafsky (2001) applied LS</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verb-particles. In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment. (this volume).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
</authors>
<title>Statistical techniques for automatically inferring the semantics of verb-particle constructions.</title>
<date>2002</date>
<tech>LinGO Working Paper No. 2002-06.</tech>
<contexts>
<context position="9083" citStr="Bannard (2002)" startWordPosition="1398" endWordPosition="1399">onvincing scores of 15.7% for precision and 13.7% for recall. We claim that substitution-based tests are useful in demarcating MWEs from productive word combinations (as attested by Pearce (2001a) in a MWE detection task), but not in distinguishing the different classes of decomposability. As observed above, simple decomposable MWEs such as motor car fail the substitution test not because of nondecomposability, but because the expression is institutionalised to the point of blocking alternates. Thus, we expect Lin’s method to return a wide array of both decomposable and non-decomposable MWEs. Bannard (2002) focused on distributional techniques for describing the meaning of verb-particle constructions at the level of logical form. The semantic similarity between a multiword expression and its head was used as an indicator of decomposability. The assumption was that if a verb-particle was sufficiently similar to its head verb, then the verb contributed its simplex meaning. It gave empirical backing to this assumption by showing that annotator judgements for verbparticle decomposability correlate significantly with non-expert human judgements on the similarity between a verb-particle construction a</context>
</contexts>
<marker>Bannard, 2002</marker>
<rawString>Colin Bannard. 2002. Statistical techniques for automatically inferring the semantics of verb-particle constructions. LinGO Working Paper No. 2002-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Semantic distance in WordNet: An experimental, application-oriented evaluation of five measures.</title>
<date>2001</date>
<booktitle>In Workshop on Wordnet and Other Lexical Resources, Second meeting of the NAACL,</booktitle>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="19996" citStr="Budanitsky and Hirst (2001)" startWordPosition="3136" endWordPosition="3139">ry nn1 0.469173 attack vvb 0.468767 firing nn1 0.459000 volley nn1 0.458717 trained vvn 0.447797 enemy nn1 0.445523 alert aj0 0.443610 shoot vvi 0.443308 defenders nn2 0.438886 Table 1: Semantic neighbours offire with different parts-of-speech. The scores are cosine similarities subsumes a sense of the MWE. The function hyponym(wordi, mwe) thus returns a value of 1 if some sense of wordz subsumes a sense of mwe, and a value of 0 otherwise. A more proactive means of utilising the WordNet hierarchy is to derive a semantic distance based on analysis of the relative location of senses in WordNet. Budanitsky and Hirst (2001) evaluated the performance of five different methods that measure the semantic distance between words in the WordNet Hierarchy, which Patwardhan et al. (2003) have then implemented and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the </context>
</contexts>
<marker>Budanitsky, Hirst, 2001</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2001. Semantic distance in WordNet: An experimental, application-oriented evaluation of five measures. In Workshop on Wordnet and Other Lexical Resources, Second meeting of the NAACL, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>User Reference Guide for the British National Corpus.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>Oxford University Computing Services.</institution>
<contexts>
<context position="11951" citStr="Burnard (2000)" startWordPosition="1845" endWordPosition="1846">e. Two MWE types that are particularly well represented in WordNet are compound nouns (47,000 entries) and multiword verbs (2,600 entries). Of these, we chose to specifically target two types of MWE: noun-noun (NN) compounds (e.g. computer network, workforce) and verb-particles (e.g. look on, eat up) due to their frequent occurrence in both decomposable and non-decomposable configurations, and also their disparate syntactic behaviours. We extracted the NN compounds from the 1996 Wall Street Journal data (WSJ, 31m words), and the verb-particles from the British National Corpus (BNC, 90m words: Burnard (2000)). The WSJ data is more tightly domain-constrained, and thus a more suitable source for NN compounds if we are to expect sentential context to reliably predict the semantics of the compound. The BNC data, on the other hand, contains more colloquial and prosaic texts and is thus a richer source of verb-particles. 3.2 Description of the LSA model Our goal was to compare the distribution of different compound terms with their constituent words, to see if this indicated similarity of meaning. For this purpose, we used latent semantic analysis (LSA) to build a vector space model in which term-term </context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>Lou Burnard. 2000. User Reference Guide for the British National Corpus. Technical report, Oxford University Computing Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
<author>Charles Fillmore</author>
<author>Ralph Grishman</author>
<author>Nancy Ide</author>
<author>Alessandro Lenci</author>
<author>Catherine MacLeod</author>
<author>Antonio Zampolli</author>
</authors>
<title>Towards best practice for multiword expressions in computational lexicons.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1934--40</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="1334" citStr="Calzolari et al., 2002" startWordPosition="177" endWordPosition="180">greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet. 1 Introduction This paper is concerned with an empirical model of multiword expression decomposability. Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999). Our claim here is that the semantics</context>
</contexts>
<marker>Calzolari, Fillmore, Grishman, Ide, Lenci, MacLeod, Zampolli, 2002</marker>
<rawString>Nicoletta Calzolari, Charles Fillmore, Ralph Grishman, Nancy Ide, Alessandro Lenci, Catherine MacLeod, and Antonio Zampolli. 2002. Towards best practice for multiword expressions in computational lexicons. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC 2002), pages 1934–40, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Fabre Lambeau</author>
<author>Aline Villavicencio</author>
<author>Francis Bond</author>
<author>Timothy Baldwin</author>
<author>Ivan A Sag</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: Linguistic precision and reusability.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1941--7</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="1309" citStr="Copestake et al., 2002" startWordPosition="173" endWordPosition="176">r similarities indicate greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet. 1 Introduction This paper is concerned with an empirical model of multiword expression decomposability. Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999). Our claim h</context>
</contexts>
<marker>Copestake, Lambeau, Villavicencio, Bond, Baldwin, Sag, Flickinger, 2002</marker>
<rawString>Ann Copestake, Fabre Lambeau, Aline Villavicencio, Francis Bond, Timothy Baldwin, Ivan A. Sag, and Dan Flickinger. 2002. Multiword expressions: Linguistic precision and reusability. In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC 2002), pages 1941–7, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>George Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="5507" citStr="Deerwester et al., 1990" startWordPosition="834" endWordPosition="837">le decomposable MWEs from idiosyncratically decomposable and non-decomposable MWEs. This is largely equivalent to classifying MWEs as being endocentric (i.e., a hyponym of their head) or ezocentric (i.e., not a hyponym of their head: Haspelmath (2002)). We attempt to achieve this by looking at the semantic similarity between an MWE and its constituent words, and hypothesising that where the similarity between the constituents of an MWE and the whole is sufficiently high, the MWE must be of simple decomposable type. The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990). LSA allows us to calculate the similarity between an arbitrary word pair, offering the advantage of being able to measure the similarity between the MWE and each of its constituent words. For MWEs such as house boat, therefore, we can expect to capture the fact that the MWE is highly similar in meaning to both constituent words (i.e. the modifier house and head noun boat). More importantly, LSA makes no assumptions about the lexical or syntactic composition of the inputs, and thus constitutes a fully construction- and language-inspecific method of modelling decomposability. This has clear ad</context>
<context position="12867" citStr="Deerwester et al., 1990" startWordPosition="1999" endWordPosition="2002">ce of verb-particles. 3.2 Description of the LSA model Our goal was to compare the distribution of different compound terms with their constituent words, to see if this indicated similarity of meaning. For this purpose, we used latent semantic analysis (LSA) to build a vector space model in which term-term similarities could be measured. LSA is a method for representing words as points in a vector space, whereby words which are related in meaning should be represented by points which are near to one another, first developed as a method for improving the vector model for information retrieval (Deerwester et al., 1990). As a technique for measuring similarity between words, LSA has been shown to capture semantic properties, and has been used successfully for recognising synonymy (Landauer and Dumais, 1997), word-sense disambiguation (Sch¨utze, 1998) and for finding correct translations of individual terms (Widdows et al., 2002). The LSA model we built is similar to that described in (Sch¨utze, 1998). First, 1000 frequent content words (i.e. not on the stoplist)l were chosen as “content-bearing words”. Using these contentbearing words as column labels, the 50,000 most frequent terms in the corpus were assign</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, George Furnas, Thomas Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Haspelmath</author>
</authors>
<title>Understanding Morphology.</title>
<date>2002</date>
<publisher>Arnold Publishers.</publisher>
<contexts>
<context position="5134" citStr="Haspelmath (2002)" startWordPosition="773" endWordPosition="774"> grammar and use this to constrain the syntax of MWEs in parsing and generation. Note that it is arguable whether simple decomposable MWEs belong in the grammar proper, or should be described instead as lexical affinities between particular word combinations. As the first step down the path toward an empirical model of decomposability, we focus on demarcating simple decomposable MWEs from idiosyncratically decomposable and non-decomposable MWEs. This is largely equivalent to classifying MWEs as being endocentric (i.e., a hyponym of their head) or ezocentric (i.e., not a hyponym of their head: Haspelmath (2002)). We attempt to achieve this by looking at the semantic similarity between an MWE and its constituent words, and hypothesising that where the similarity between the constituents of an MWE and the whole is sufficiently high, the MWE must be of simple decomposable type. The particular similarity method we adopt is latent semantic analysis, or LSA (Deerwester et al., 1990). LSA allows us to calculate the similarity between an arbitrary word pair, offering the advantage of being able to measure the similarity between the MWE and each of its constituent words. For MWEs such as house boat, therefor</context>
</contexts>
<marker>Haspelmath, 2002</marker>
<rawString>Martin Haspelmath. 2002. Understanding Morphology. Arnold Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropism.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database,</booktitle>
<pages>305--32</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="21116" citStr="Hirst and St-Onge (1998)" startWordPosition="3318" endWordPosition="3321">between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated over a corpus of text. • Lin (1998c) also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: 2log P(C0) sim(C1, C2) = log P(C1) + log P(C2) (1) where C0 is the lowest class in the hierarchy that subsumes both classes. 2http://www.d.umn.edu/˜tpederse/ distance.html • Hirst and St-Onge (1998) use a system of “relations” of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them. The Patwardhan et al. (2003) implementation that we used calculates the information values from SemCor, a semantically tagged subset of the Brown corpus. Note that the first two similarity measures operate over nouns only, while the last can be applied to any word class. The similarity measures described above calculate the similarity between a pair of senses. In the case that a given constituent word and/or MWE occur </context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Graeme Hirst and David St-Onge. 1998. Lexical chains as representations of context for the detection and correction of malapropism. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, pages 305–32. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>Susan Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="13058" citStr="Landauer and Dumais, 1997" startWordPosition="2027" endWordPosition="2031"> of meaning. For this purpose, we used latent semantic analysis (LSA) to build a vector space model in which term-term similarities could be measured. LSA is a method for representing words as points in a vector space, whereby words which are related in meaning should be represented by points which are near to one another, first developed as a method for improving the vector model for information retrieval (Deerwester et al., 1990). As a technique for measuring similarity between words, LSA has been shown to capture semantic properties, and has been used successfully for recognising synonymy (Landauer and Dumais, 1997), word-sense disambiguation (Sch¨utze, 1998) and for finding correct translations of individual terms (Widdows et al., 2002). The LSA model we built is similar to that described in (Sch¨utze, 1998). First, 1000 frequent content words (i.e. not on the stoplist)l were chosen as “content-bearing words”. Using these contentbearing words as column labels, the 50,000 most frequent terms in the corpus were assigned row vectors by counting the number of times they oc&apos;A “stoplist” is a list of frequent words which have little independent semantic content, such as prepositions and determiners (Baeza-Yat</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas Landauer and Susan Dumais. 1997. A solution to Plato’s problem: The latent semantic analysis theory of acquisition. Psychological Review, 104(2):211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL-98).</booktitle>
<contexts>
<context position="7805" citStr="Lin, 1998" startWordPosition="1195" endWordPosition="1196">ty in statistical machine translation (e.g. Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora. One interesting exception is Lin (1999), whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning. The expressions he uses are taken from a collocation database (Lin, 1998b). These “expressions that are similar to [their] literal meaning” are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus (Lin, 1998a). Lin models the distributional difference as a significant difference in mutual information. Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores. Lin provides some examples that suggest he has identified a successful measure of “compositionality”. He offers an evaluation where an item is said to be noncomposition</context>
<context position="20785" citStr="Lin (1998" startWordPosition="3268" endWordPosition="3269"> and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated over a corpus of text. • Lin (1998c) also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: 2log P(C0) sim(C1, C2) = log P(C1) + log P(C2) (1) where C0 is the lowest class in the hierarchy that subsumes both classes. 2http://www.d.umn.edu/˜tpederse/ distance.html • Hirst and St-Onge (1998) use a system of “relations” of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them. The Patwardhan et al. (2003) implementation that we used calculates the information values </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998a. Automatic retrieval and clustering of similar words. In Proceedings of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL-98).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Extracting collocations from text corpora.</title>
<date>1998</date>
<booktitle>In First Workshop on Computational Terminology.</booktitle>
<contexts>
<context position="7805" citStr="Lin, 1998" startWordPosition="1195" endWordPosition="1196">ty in statistical machine translation (e.g. Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora. One interesting exception is Lin (1999), whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning. The expressions he uses are taken from a collocation database (Lin, 1998b). These “expressions that are similar to [their] literal meaning” are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus (Lin, 1998a). Lin models the distributional difference as a significant difference in mutual information. Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores. Lin provides some examples that suggest he has identified a successful measure of “compositionality”. He offers an evaluation where an item is said to be noncomposition</context>
<context position="20785" citStr="Lin (1998" startWordPosition="3268" endWordPosition="3269"> and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated over a corpus of text. • Lin (1998c) also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: 2log P(C0) sim(C1, C2) = log P(C1) + log P(C2) (1) where C0 is the lowest class in the hierarchy that subsumes both classes. 2http://www.d.umn.edu/˜tpederse/ distance.html • Hirst and St-Onge (1998) use a system of “relations” of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them. The Patwardhan et al. (2003) implementation that we used calculates the information values </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998b. Extracting collocations from text corpora. In First Workshop on Computational Terminology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="7805" citStr="Lin, 1998" startWordPosition="1195" endWordPosition="1196">ty in statistical machine translation (e.g. Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora. One interesting exception is Lin (1999), whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning. The expressions he uses are taken from a collocation database (Lin, 1998b). These “expressions that are similar to [their] literal meaning” are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus (Lin, 1998a). Lin models the distributional difference as a significant difference in mutual information. Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores. Lin provides some examples that suggest he has identified a successful measure of “compositionality”. He offers an evaluation where an item is said to be noncomposition</context>
<context position="20785" citStr="Lin (1998" startWordPosition="3268" endWordPosition="3269"> and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated over a corpus of text. • Lin (1998c) also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: 2log P(C0) sim(C1, C2) = log P(C1) + log P(C2) (1) where C0 is the lowest class in the hierarchy that subsumes both classes. 2http://www.d.umn.edu/˜tpederse/ distance.html • Hirst and St-Onge (1998) use a system of “relations” of different strength to determine the similarity of word senses, conditioned on the type, direction and relative distance of edges separating them. The Patwardhan et al. (2003) implementation that we used calculates the information values </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998c. An information-theoretic definition of similarity. In Proceedings of the 15th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proc. of the 37th Annual Meeting of the ACL,</booktitle>
<pages>317--24</pages>
<location>College Park, USA.</location>
<contexts>
<context position="1896" citStr="Lin, 1999" startWordPosition="269" endWordPosition="270"> Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999). Our claim here is that the semantics of the MWE are deconstructed and the parts coerced into often idiosyncratic interpretations to attain semantic alignment, rather than the other way around. One idiom which illustrates this process is spill the beans, where the semantics of reveal&apos;(secret&apos;) are decomposed such that spill is coerced into the idiosyncratic interpretation of reveal&apos; and beans into the idiosyncratic interpretation of secret&apos;. Given that these senses for spill and beans are not readily available at the simplex level other than in the context of this particular MWE, it seems fal</context>
<context position="7472" citStr="Lin (1999)" startWordPosition="1142" endWordPosition="1143">ides a basic outline of the resources used in this research, LSA, the MWE extraction methods, and measures used to evaluate our method. Section 4 then provides evaluation of the proposed method, and the paper is concluded with a brief discussion in Section 5. 2 Past research Although there has been some useful work on compositionality in statistical machine translation (e.g. Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora. One interesting exception is Lin (1999), whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning. The expressions he uses are taken from a collocation database (Lin, 1998b). These “expressions that are similar to [their] literal meaning” are found by substituting each of the words in the expression with the 10 most similar words according to a corpus derived thesaurus (Lin, 1998a). Lin models the distributional difference as a signif</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proc. of the 37th Annual Meeting of the ACL, pages 317–24, College Park, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and</booktitle>
<contexts>
<context position="10004" citStr="McCarthy et al. (2003)" startWordPosition="1531" endWordPosition="1534">similar to its head verb, then the verb contributed its simplex meaning. It gave empirical backing to this assumption by showing that annotator judgements for verbparticle decomposability correlate significantly with non-expert human judgements on the similarity between a verb-particle construction and its head verb. Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. They successfully combined statistical and distributional techniques (including LSA) with a substitution test in analysing compositionality. McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality. We are not the first to consider applying LSA to MWEs. Schone and Jurafsky (2001) applied LSA to the analysis of MWEs in the task of MWE discovery, by way of rescoring MWEs extracted from a corpus. The major point of divergence from this research is that Schone and Jurafsky focused specifically on MWE extraction, whereas we are interested in the downstream task of semanti</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment. (this volume).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic discovery of noncompositional compounds in parallel data.</title>
<date>1997</date>
<booktitle>In Proc. of the 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP-97),</booktitle>
<location>Providence, USA.</location>
<contexts>
<context position="7254" citStr="Melamed (1997)" startWordPosition="1112" endWordPosition="1113">the correlation between dictionary- and corpus-based similarities. The remainder of this paper is structured as follows. Section 2 describes past research on MWE compositionality of relevance to this effort. Section 3 provides a basic outline of the resources used in this research, LSA, the MWE extraction methods, and measures used to evaluate our method. Section 4 then provides evaluation of the proposed method, and the paper is concluded with a brief discussion in Section 5. 2 Past research Although there has been some useful work on compositionality in statistical machine translation (e.g. Melamed (1997)), there has been little work on detecting “non-compositional” (i.e. non-decomposable and idiosyncratically decomposable) items of variable syntactic type in monolingual corpora. One interesting exception is Lin (1999), whose approach is explained as follows: The intuitive idea behind the method is that the metaphorical usage of a noncompositional expression causes it to have a different distributional characteristic than expressions that are similar to its literal meaning. The expressions he uses are taken from a collocation database (Lin, 1998b). These “expressions that are similar to [their</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997. Automatic discovery of noncompositional compounds in parallel data. In Proc. of the 2nd Conference on Empirical Methods in Natural Language Processing (EMNLP-97), Providence, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to WordNet: an on-line lexical database.</title>
<date>1990</date>
<journal>International Journal ofLexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="11051" citStr="Miller et al., 1990" startWordPosition="1706" endWordPosition="1709"> major point of divergence from this research is that Schone and Jurafsky focused specifically on MWE extraction, whereas we are interested in the downstream task of semantically classifying attested MWEs. 3 Resources and Techniques In this section, we outline the resources used in evaluation, give an informal introduction to the LSA model, sketch how we extracted the MWEs from corpus data, and describe a number of methods for modelling decomposability within a hierarchical lexicon. 3.1 Resources and target MWEs The particular reference lexicon we use to evaluate our technique is WordNet 1.7 (Miller et al., 1990), due to its public availability, hierarchical structure and wide coverage. Indeed, Schone and Jurafsky (2001) provide evidence that suggests that WordNet is as effective an evaluation resource as the web for MWE detection methods, despite its inherent size limitations and static nature. Two MWE types that are particularly well represented in WordNet are compound nouns (47,000 entries) and multiword verbs (2,600 entries). Of these, we chose to specifically target two types of MWE: noun-noun (NN) compounds (e.g. computer network, workforce) and verb-particles (e.g. look on, eat up) due to their</context>
<context position="17130" citStr="Miller et al., 1990" startWordPosition="2691" endWordPosition="2694">ivity of the particle candidate. These three methods produced three distinct sets of verb-particle tokens, which we carried out weighted voting over to determine the final set of verb-particle tokens. A total of 461 verb-particles attested in WordNet were extracted (160,765 tokens). For both the NN compound and verb-particle data, we replaced each token occurrence with a single-word POS-tagged token to feed into the LSA model. 3.4 Techniques for evaluating correlation with WordNet In order to evaluate our approach, we employed the lexical relations as defined in the WordNet lexical hierarchy (Miller et al., 1990). WordNet groups words into sets with similar meaning (known as “synsets”), e.g. {car, auto, automobile, machine, motorcar } . These are organised into a hierarchy employing multiple inheritance. The hierarchy is structured according to different principles for each of nouns, verbs, adjectives and adverbs. The nouns are arranged according to hyponymy or ISA relations, e.g. a car is a kind of automobile. The verbs are arranged according to troponym or “manner-of” relations, where murder is a manner of killing, so kill immediately dominates murder in the hierarchy. We used WordNet for evaluation</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1990. Introduction to WordNet: an on-line lexical database. International Journal ofLexicography, 3(4):235–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>Radu Florian</author>
</authors>
<title>Transformation-based learning in the fast lane.</title>
<date>2001</date>
<booktitle>In Proc. of the 2nd Annual Meeting of the North American Chapter of Association for Computational Linguistics (NAACL2001),</booktitle>
<pages>40--7</pages>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="15548" citStr="Ngai and Florian, 2001" startWordPosition="2440" endWordPosition="2444"> confuses this distinction — the neighbours offire treated just as a string include words related to both the meaning offire as a noun (more frequent in the BNC) and as a verb. The appropriate granularity of syntactic classifications is an open question for this kind of research: treating all the possible verbs categories as different (e.g. distinguishing infinitive from finite from gerund forms) led to data sparseness, and instead we considered “verb” as a single part-of-speech type. 3.3 MWE extraction methods NN compounds were extracted from the WSJ by first tagging the data with fnTBL 1.0 (Ngai and Florian, 2001) and then simply taking noun bigrams (adjoined on both sides by non-nouns to assure the bigram is not part of a larger compound nominal). Out of these, we selected those compounds that are listed in WordNet, resulting in 5,405 NN compound types (208,000 tokens). Extraction of the verb-particles was considerably more involved, and drew on the method of Baldwin and Villavicencio (2002). Essentially, we used a POS tagger and chunker (both built using fnTBL 1.0 (Ngai and Florian, 2001)) to first (re)tag the BNC. This allowed us to extract verb-particle tokens through use of the particle POS and ch</context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>Grace Ngai and Radu Florian. 2001. Transformation-based learning in the fast lane. In Proc. of the 2nd Annual Meeting of the North American Chapter of Association for Computational Linguistics (NAACL2001), pages 40–7, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
<author>Ivan A Sag</author>
<author>Tom Wasow</author>
</authors>
<date>1994</date>
<journal>Idioms. Language,</journal>
<pages>70--491</pages>
<contexts>
<context position="1884" citStr="Nunberg et al., 1994" startWordPosition="265" endWordPosition="268">ies (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999). Our claim here is that the semantics of the MWE are deconstructed and the parts coerced into often idiosyncratic interpretations to attain semantic alignment, rather than the other way around. One idiom which illustrates this process is spill the beans, where the semantics of reveal&apos;(secret&apos;) are decomposed such that spill is coerced into the idiosyncratic interpretation of reveal&apos; and beans into the idiosyncratic interpretation of secret&apos;. Given that these senses for spill and beans are not readily available at the simplex level other than in the context of this particular MWE, </context>
<context position="4230" citStr="Nunberg et al. (1994)" startWordPosition="630" endWordPosition="633">high syntactic variability. What makes simple decomposable expressions true MWEs rather than productive word combinations is that they tend to block compositional alternates with the expected semantics (termed anticollocations by Pearce (2001b)). For example, motor car cannot be rephrased as *engine car or *motor automobile. Note that the existence of anticollocations is also a test for non-decomposable and idiosyncratically decomposable MWEs (e.g. hot dog vs. #warm dog or #hot canine). Our particular interest in decomposability stems from ongoing work on grammatical means for capturing MWEs. Nunberg et al. (1994) observed that idiosyncratically decomposable MWEs (in particular idioms) undergo much greater syntactic variation than non-decomposable MWEs, and that the variability can be partially predicted from the decompositional analysis. We thus aim to capture the decomposability of MWEs in the grammar and use this to constrain the syntax of MWEs in parsing and generation. Note that it is arguable whether simple decomposable MWEs belong in the grammar proper, or should be described instead as lexical affinities between particular word combinations. As the first step down the path toward an empirical m</context>
</contexts>
<marker>Nunberg, Sag, Wasow, 1994</marker>
<rawString>Geoffrey Nunberg, Ivan A. Sag, and Tom Wasow. 1994. Idioms. Language, 70:491–538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Using measures of semantic relatedness for word sense disambiguation.</title>
<date>2003</date>
<booktitle>In Proc. of the 4th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2003),</booktitle>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="20154" citStr="Patwardhan et al. (2003)" startWordPosition="3161" endWordPosition="3164">rs nn2 0.438886 Table 1: Semantic neighbours offire with different parts-of-speech. The scores are cosine similarities subsumes a sense of the MWE. The function hyponym(wordi, mwe) thus returns a value of 1 if some sense of wordz subsumes a sense of mwe, and a value of 0 otherwise. A more proactive means of utilising the WordNet hierarchy is to derive a semantic distance based on analysis of the relative location of senses in WordNet. Budanitsky and Hirst (2001) evaluated the performance of five different methods that measure the semantic distance between words in the WordNet Hierarchy, which Patwardhan et al. (2003) have then implemented and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated ove</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2003</marker>
<rawString>Siddharth Patwardhan, Satanjeev Banerjee, and Ted Pedersen. 2003. Using measures of semantic relatedness for word sense disambiguation. In Proc. of the 4th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2003), Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In Proc. of the NAACL 2001 Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations,</booktitle>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="3851" citStr="Pearce (2001" startWordPosition="571" endWordPosition="572">ag, radar footprint) are decomposable but coerce their parts into taking semantics unavailable outside the MWE. They undergo a certain degree of syntactic variation (e.g. the cat was let out of the bag). Finally, simple decomposable MWEs (also known as “institutionalised” MWEs, e.g. kindle excitement, traffic light) decompose into simplex senses and generally display high syntactic variability. What makes simple decomposable expressions true MWEs rather than productive word combinations is that they tend to block compositional alternates with the expected semantics (termed anticollocations by Pearce (2001b)). For example, motor car cannot be rephrased as *engine car or *motor automobile. Note that the existence of anticollocations is also a test for non-decomposable and idiosyncratically decomposable MWEs (e.g. hot dog vs. #warm dog or #hot canine). Our particular interest in decomposability stems from ongoing work on grammatical means for capturing MWEs. Nunberg et al. (1994) observed that idiosyncratically decomposable MWEs (in particular idioms) undergo much greater syntactic variation than non-decomposable MWEs, and that the variability can be partially predicted from the decompositional a</context>
<context position="8663" citStr="Pearce (2001" startWordPosition="1332" endWordPosition="1333">ifference as a significant difference in mutual information. Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores. Lin provides some examples that suggest he has identified a successful measure of “compositionality”. He offers an evaluation where an item is said to be noncompositional if it occurs in a dictionary of idioms. This produces the unconvincing scores of 15.7% for precision and 13.7% for recall. We claim that substitution-based tests are useful in demarcating MWEs from productive word combinations (as attested by Pearce (2001a) in a MWE detection task), but not in distinguishing the different classes of decomposability. As observed above, simple decomposable MWEs such as motor car fail the substitution test not because of nondecomposability, but because the expression is institutionalised to the point of blocking alternates. Thus, we expect Lin’s method to return a wide array of both decomposable and non-decomposable MWEs. Bannard (2002) focused on distributional techniques for describing the meaning of verb-particle constructions at the level of logical form. The semantic similarity between a multiword expression</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>Darren Pearce. 2001a. Synonymy in collocation extraction. In Proc. of the NAACL 2001 Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>Using conceptual similarity for collocation extraction.</title>
<date>2001</date>
<booktitle>In Proc. of the 4th UK Special Interest Group for Computational Linguistics (CLUK4).</booktitle>
<contexts>
<context position="3851" citStr="Pearce (2001" startWordPosition="571" endWordPosition="572">ag, radar footprint) are decomposable but coerce their parts into taking semantics unavailable outside the MWE. They undergo a certain degree of syntactic variation (e.g. the cat was let out of the bag). Finally, simple decomposable MWEs (also known as “institutionalised” MWEs, e.g. kindle excitement, traffic light) decompose into simplex senses and generally display high syntactic variability. What makes simple decomposable expressions true MWEs rather than productive word combinations is that they tend to block compositional alternates with the expected semantics (termed anticollocations by Pearce (2001b)). For example, motor car cannot be rephrased as *engine car or *motor automobile. Note that the existence of anticollocations is also a test for non-decomposable and idiosyncratically decomposable MWEs (e.g. hot dog vs. #warm dog or #hot canine). Our particular interest in decomposability stems from ongoing work on grammatical means for capturing MWEs. Nunberg et al. (1994) observed that idiosyncratically decomposable MWEs (in particular idioms) undergo much greater syntactic variation than non-decomposable MWEs, and that the variability can be partially predicted from the decompositional a</context>
<context position="8663" citStr="Pearce (2001" startWordPosition="1332" endWordPosition="1333">ifference as a significant difference in mutual information. Significance here is defined as the absence of overlap between the 95% confidence interval of the mutual information scores. Lin provides some examples that suggest he has identified a successful measure of “compositionality”. He offers an evaluation where an item is said to be noncompositional if it occurs in a dictionary of idioms. This produces the unconvincing scores of 15.7% for precision and 13.7% for recall. We claim that substitution-based tests are useful in demarcating MWEs from productive word combinations (as attested by Pearce (2001a) in a MWE detection task), but not in distinguishing the different classes of decomposability. As observed above, simple decomposable MWEs such as motor car fail the substitution test not because of nondecomposability, but because the expression is institutionalised to the point of blocking alternates. Thus, we expect Lin’s method to return a wide array of both decomposable and non-decomposable MWEs. Bannard (2002) focused on distributional techniques for describing the meaning of verb-particle constructions at the level of logical form. The semantic similarity between a multiword expression</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>Darren Pearce. 2001b. Using conceptual similarity for collocation extraction. In Proc. of the 4th UK Special Interest Group for Computational Linguistics (CLUK4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="20424" citStr="Resnik (1995)" startWordPosition="3208" endWordPosition="3209">. A more proactive means of utilising the WordNet hierarchy is to derive a semantic distance based on analysis of the relative location of senses in WordNet. Budanitsky and Hirst (2001) evaluated the performance of five different methods that measure the semantic distance between words in the WordNet Hierarchy, which Patwardhan et al. (2003) have then implemented and made available for general use as the Perl package distance-0.11.2 We focused in particular on the following three measures, the first two of which are based on information theoretic principles, and the third on sense topology: • Resnik (1995) combined WordNet with corpus statistics. He defines the similarity between two words as the information content of the lowest superordinate in the hierarchy, defining the information content of a concept c (where a concept is the WordNet class containing the word) to be the negative of its log likelihood. This is calculated over a corpus of text. • Lin (1998c) also employs the idea of corpusderived information content, and defines the similarity between two concepts in the following way: 2log P(C0) sim(C1, C2) = log P(C1) + log P(C2) (1) where C0 is the lowest class in the hierarchy that subs</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using information content to evaluate semantic similarity. In Proceedings of the 14th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susanne Riehemann</author>
</authors>
<title>A Constructional Approach to Idioms and Word Formation.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford.</institution>
<contexts>
<context position="1683" citStr="Riehemann, 2001" startWordPosition="234" endWordPosition="235">Net. 1 Introduction This paper is concerned with an empirical model of multiword expression decomposability. Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994; Lin, 1999). Our claim here is that the semantics of the MWE are deconstructed and the parts coerced into often idiosyncratic interpretations to attain semantic alignment, rather than the other way around. One idiom which illustrates this process is spill the beans, where the semantics of reveal&apos;(secret&apos;) are decomposed such that spill is coerced into the idiosyncratic interpretation of reveal&apos; </context>
</contexts>
<marker>Riehemann, 2001</marker>
<rawString>Susanne Riehemann. 2001. A Constructional Approach to Idioms and Word Formation. Ph.D. thesis, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002),</booktitle>
<pages>1--15</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="1285" citStr="Sag et al., 2002" startWordPosition="169" endWordPosition="172">d claim that higher similarities indicate greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet. 1 Introduction This paper is concerned with an empirical model of multiword expression decomposability. Multiword expressions (MWEs) are defined to be cohesive lexemes that cross word boundaries (Sag et al., 2002; Copestake et al., 2002; Calzolari et al., 2002). They occur in a wide variety of syntactic configurations in different languages (e.g. in the case of English, compound nouns: post office, verbal idioms: pull strings, verb-particle constructions: push on, etc.). Decomposability is a description of the degree to which the semantics of an MWE can be ascribed to those of its parts (Riehemann, 2001; Sag et al., 2002). Analysis of the semantic correlation between the constituent parts and whole of an MWE is perhaps more commonly discussed under the banner of compositionality (Nunberg et al., 1994;</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002), pages 1–15, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Dan Jurafsky</author>
</authors>
<title>Is knowledge-free induction of multiword unit dictionary headwords a solved problem?</title>
<date>2001</date>
<booktitle>In Proc. of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>100--108</pages>
<contexts>
<context position="10311" citStr="Schone and Jurafsky (2001)" startWordPosition="1582" endWordPosition="1585"> its head verb. Bannard et al. (2003) extended this research in looking explicitly at the task of classifying verb-particles as being compositional or not. They successfully combined statistical and distributional techniques (including LSA) with a substitution test in analysing compositionality. McCarthy et al. (2003) also targeted verb-particles for a study on compositionality, and judged compositionality according to the degree of overlap in the N most similar words to the verbparticle and head verb, e.g., to determine compositionality. We are not the first to consider applying LSA to MWEs. Schone and Jurafsky (2001) applied LSA to the analysis of MWEs in the task of MWE discovery, by way of rescoring MWEs extracted from a corpus. The major point of divergence from this research is that Schone and Jurafsky focused specifically on MWE extraction, whereas we are interested in the downstream task of semantically classifying attested MWEs. 3 Resources and Techniques In this section, we outline the resources used in evaluation, give an informal introduction to the LSA model, sketch how we extracted the MWEs from corpus data, and describe a number of methods for modelling decomposability within a hierarchical l</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Patrick Schone and Dan Jurafsky. 2001. Is knowledge-free induction of multiword unit dictionary headwords a solved problem? In Proc. of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP 2001), pages 100–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
<author>Chiu-Ki Chan</author>
</authors>
<title>Using parallel corpora to enrich multilingual lexical resources.</title>
<date>2002</date>
<booktitle>In Third International Conference on Language Resources and Evaluation,</booktitle>
<pages>240--245</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="13182" citStr="Widdows et al., 2002" startWordPosition="2046" endWordPosition="2049">es could be measured. LSA is a method for representing words as points in a vector space, whereby words which are related in meaning should be represented by points which are near to one another, first developed as a method for improving the vector model for information retrieval (Deerwester et al., 1990). As a technique for measuring similarity between words, LSA has been shown to capture semantic properties, and has been used successfully for recognising synonymy (Landauer and Dumais, 1997), word-sense disambiguation (Sch¨utze, 1998) and for finding correct translations of individual terms (Widdows et al., 2002). The LSA model we built is similar to that described in (Sch¨utze, 1998). First, 1000 frequent content words (i.e. not on the stoplist)l were chosen as “content-bearing words”. Using these contentbearing words as column labels, the 50,000 most frequent terms in the corpus were assigned row vectors by counting the number of times they oc&apos;A “stoplist” is a list of frequent words which have little independent semantic content, such as prepositions and determiners (Baeza-Yates and Ribiero-Neto, 1999, p167). curred within the same sentence as a content-bearing word. Singular-value decomposition (D</context>
</contexts>
<marker>Widdows, Dorow, Chan, 2002</marker>
<rawString>Dominic Widdows, Beate Dorow, and Chiu-Ki Chan. 2002. Using parallel corpora to enrich multilingual lexical resources. In Third International Conference on Language Resources and Evaluation, pages 240–245, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
</authors>
<title>Unsupervised methods for developing taxonomies by combining syntactic and statistical information.</title>
<date>2003</date>
<booktitle>In Proc. of the 3rd International Conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL</booktitle>
<note>(to appear).</note>
<contexts>
<context position="14570" citStr="Widdows (2003)" startWordPosition="2278" endWordPosition="2279">between them, in the same way as the similarity between a query and a document is often measured in information retrieval (Baeza-Yates and Ribiero-Neto, 1999, p28). Effectively, we could use LSA to measure the extent to which two words or MWEs x and y usually occur in similar contexts. Since the corpora had been tagged with parts-ofspeech, we could build syntactic distinctions into the LSA models — instead of just giving a vector for the string test we were able to build separate vectors for the nouns, verbs and adjectives test. This combination of technologies was also used to good effect by Widdows (2003): an example of the contribution of part-of-speech information to extracting semantic neighbours of the word fire is shown in Table 1. As can be seen, the noun fire (as in the substance/element) and the verb fire (mainly used to mean firing some sort of weapon) are related to quite different areas of meaning. Building a single vector for the string fire confuses this distinction — the neighbours offire treated just as a string include words related to both the meaning offire as a noun (more frequent in the BNC) and as a verb. The appropriate granularity of syntactic classifications is an open </context>
</contexts>
<marker>Widdows, 2003</marker>
<rawString>Dominic Widdows. 2003. Unsupervised methods for developing taxonomies by combining syntactic and statistical information. In Proc. of the 3rd International Conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL 2003). (to appear).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>