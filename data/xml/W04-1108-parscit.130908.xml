<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000063">
<title confidence="0.9986925">
Combining Neural Networks and Statistics for
Chinese Word sense disambiguation
</title>
<author confidence="0.999281">
Zhimao Lu Ting Liu Sheng Li
</author>
<affiliation confidence="0.997318">
Information Retrieval Laboratory of Computer Science &amp; Technology School,
Harbin Institute of Technology
</affiliation>
<address confidence="0.904277">
Harbin, China, 150001
</address>
<email confidence="0.983848">
{lzm, tliu}@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.992398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99987235">
The input of network is the key problem for
Chinese Word sense disambiguation utilizing
the Neural Network. This paper presents an
input model of Neural Network that calculates
the Mutual Information between contextual
words and ambiguous word by using statistical
method and taking the contextual words to
certain number beside the ambiguous word
according to (-M, +N). The experiment adopts
triple-layer BP Neural Network model and
proves how the size of training set and the
value of M and N affect the performance of
Neural Network model. The experimental
objects are six pseudowords owning three
word-senses constructed according to certain
principles. Tested accuracy of our approach on
a close-corpus reaches 90.31%,, and 89.62% on
a open-corpus. The experiment proves that the
Neural Network model has good performance
on Word sense disambiguation.
</bodyText>
<sectionHeader confidence="0.999001" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997815222222222">
It is general that one word with many senses in
natural language. According statistics, there are
about 42% ambiguous words in Chinese corpus (Lu,
2001). Word sense disambiguation (WSD) is a
method to determine the sense of ambiguous word
given the context circumstance.
WSD, a long-standing problem in NLP, has been
a very active research topic,, which can be well
applied in many NLP systems, such as Information
</bodyText>
<sectionHeader confidence="0.611756666666667" genericHeader="introduction">
Retrieval, Text Mining, Machine Translation, Text
Categorization, Text Summarization, Speech
Recognition, Text to Speech, and so on.
</sectionHeader>
<bodyText confidence="0.987952">
With rising of Corpus linguistics, the machine
learning methods based on statistics are booming
(Yarowsky, 1992). These methods draw the support
from the high-powered computers, get the statistics of
large real-world corpus, find and acquire knowledge
of linguistics automatically. They deal with all change
by invariability, thus it is easy to trace the evaluation
and development of natural language. So the statistic
methods of NLP has attracted the attention of
professional researchers and become the mainstream
bit by bit. Corpus-based Statistical approaches are
Decision Tree (Pedersen, 2001), Decision List,
Genetic Algorithm, Naive-Bayesian Classifier
(Escudero, 2000)、Maximum Entropy Model (Adam,
1996; Li, 1999), and so on.
Corpus-based statistical approaches can be divided
into supervised and unsupervised according to whether
training corpus is sense-labeled text. Supervised
learning methods have the good learning ability and
can get better accuracy in WSD experiments (Schütze,
1998). Obviously the data sparseness problem is a
bottleneck for supervised learning algorithm. If you
want to get better learning and disambiguating effect,
you can enlarge the size and smooth the data of
training corpus. According to practical demand, it
would spend much more time and manpower to
enlarge the size of training corpus. Smoothing data is
merely a subsidiary measure. The sufficient large size
of training corpus is still the foundation to get a
satisfied effect in WSD experiment.
Unsupervised WSD never depend on tagged
corpus and could realize the training of large real
corpus coming from all kinds of applying field. So
researchers begin to pay attention to this kind of
methods (Lu, 2002). The kind of methods can
overcome the sparseness problem in a degree.
It is obvious that the two kinds of methods based
on statistic have their own advantages and
disadvantages, and cannot supersede each other.
This paper researches the Chinese WSD using the
model of artificial neural network and investigates
the effect on WSD from input model of neural
network constructed by the context words and the
size of training corpus.
</bodyText>
<sectionHeader confidence="0.912607" genericHeader="method">
2 BP Neural Network
</sectionHeader>
<bodyText confidence="0.99965525">
At the moment, there are about more than 30 kinds of
artificial neural network (ANN) in the domain of
research and application. Especially, BP neural
network is a most popular model of ANN nowadays.
</bodyText>
<subsectionHeader confidence="0.998233">
2.1 The structure of BP Neural Network
</subsectionHeader>
<bodyText confidence="0.9999443">
The BP model provides a simple method to
calculate the variation of network performance
cased by variation of single weight. This model
contains not only input nodes and output nodes, but
also multi-layer or mono-layer hidden nodes. Fig1.1
is a construction chart of triple-layer BP neural
network. As it is including the weights modifying
process from the output layer to the input layer
resulting from the total errors, the BP neural
network is called Error Back Propagation network.
</bodyText>
<equation confidence="0.963371666666667">
y1 y2 y3 ym
Outputs
Hidden
Inputs
x1 x2 x3 xn
Fig. 1.1 BP Network
</equation>
<bodyText confidence="0.998435375">
Fig.1.1 The structure of BP neural network
Except for the nodes of input layer, all nodes of
other layers are non-linear input and output. So the
feature function should be differential on every part
of function. General speaking, we can choose the
sigmoid, tangent inspired, or linear function as the
feature function because they are convenient for
searching and solving by gradient technique.
</bodyText>
<equation confidence="0.838205333333333">
Formula (1) is a sigmoid function.
1
f (x) = 1 + ——— e-x
</equation>
<bodyText confidence="0.985022111111111">
The output of sigmoid function ranges between 0
and 1, increasing monotonically with its input.
Because it maps a very large input domain to a
small range of outputs, it is often referred to as the
squashing function of the unit. The output layer and
hidden layer should adopt the sigmoid inspired
function under the condition of intervention on the
output, such as confining the output between 0 and
1.
</bodyText>
<subsectionHeader confidence="0.966085">
2.2 Back Propagation function of BP
neural network
</subsectionHeader>
<bodyText confidence="0.956310923076923">
The joint weights should be revised many times
during the progress of the error propagating back in
BP networks. The variation of joint weights every
time is solved by the method of gradient descent.
Because there is no objective output in hidden layer,
the variation of joint weight in hidden layer is
solved under the help of error back propagation in
output layer. If there are many hidden layers, this
method can reason out the rest to the first layer by
analogy.
1) the variation of joint weights in output layer
To calculate the variation of joint weights from
input i’th to output k’th is as following:
</bodyText>
<equation confidence="0.997195555555556">
ƏOk
∆wik = -η = -η (2)
ƏE ƏE
——— ——— ———
Əwik ƏOk Ə wik
= η(tk - Ok )f2΄ O΄i = η δik O΄i
δik = (tk - Ok)f2&amp;quot; (3)
ƏE lJ _ ƏE ƏOk
∆bki = -η Əbki — — a0 abki (4)= η(tk - Ok )f2΄ = η δik
</equation>
<bodyText confidence="0.857170666666667">
2) the variation of joint weights in hidden layer
To calculate the variation of joint weights from
input j’th to output i’th is as following:
</bodyText>
<equation confidence="0.998624875">
∆w΄ �n aE n ƏE ƏOk ƏO΄i
i� _ -tll a w&amp;quot;ii= -η1 ƏOk a0&amp;quot;i a w&apos;ij (5)
(1)
n
= η 1 (tk - Ok, f2&apos; wikfl pj= η Sij pj
n
where: Sij = ei �1&apos;,ei = 1 Sik wik (6)
db&apos;ki = η Sij (7)
</equation>
<sectionHeader confidence="0.80385" genericHeader="method">
3. The construction of WSD model
</sectionHeader>
<bodyText confidence="0.998390588235294">
Under the consideration of fact that only
numerical data can be accepted by the input and
output of neural network, if BP neural network is
used on WSD, the prerequisite is to vector the part of
semantic meaning (words or phrases) and sense.
In the event of training BP model, the input vector
P and objective vector O of WSD should be
determined firstly. And then we should choose the
construction of neural network that needs to be
designed, say, how many layers is network, how
many neural nodes are in every layer, and the
inspired function of hidden layer and output layer.
The training of model still needs the vector added
weight, output, and error vector. The training is over
when the sum of square errors is less than the
objection of error. Or the errors of output very to
adjust the joint weight back and repeat the training.
</bodyText>
<subsectionHeader confidence="0.994087">
3.1 To vector the vocabulary
</subsectionHeader>
<bodyText confidence="0.9999042">
WSD depends on the context to judge the meaning
of ambiguous words. So the input of model should
be the ambiguous words and the contextual words
round them. In order to vector the words in the
context, the Mutual Information (MI) of ambiguous
words and context should be calculated. So MI can
show the opposite distance of ambiguous words and
contextual words. MI can replace every contextual
word. That is suitable to as the input model. The
function of MI is as follow:
</bodyText>
<equation confidence="0.694856">
MI(w1, w2) =
P(w1) and P(w2) are the probability of word w1
</equation>
<bodyText confidence="0.992979142857143">
and w2 to appear in the corpus separately. While
P(w1, w2) is the probability of word w1 and w2 to
appear together.
The experimental corpus in this article stems
from the People Daily of 1998. The extent is
123,882 lines (10,000,000 words), including
121,400 words and phrases.
</bodyText>
<subsectionHeader confidence="0.99854">
3.2 The pretreatment of BP network model
</subsectionHeader>
<bodyText confidence="0.999979444444444">
The supervised WSD need artificial mark of
meaning. But it is time consuming to mark artificially.
So it is difficult to get the large scope and high quality
training linguistic corpus. In order to overcome this
difficulty and get large enough experimental linguistic
corpuses, we should turn to seek the new way.
We use pseudoword in place of the real word. That
can get the arbitrary large experimental corpus
according to the real demand.
</bodyText>
<subsubsectionHeader confidence="0.584126">
3.2.1 The construction of Pseudoword
</subsubsectionHeader>
<bodyText confidence="0.998305551724138">
Pseudoword is the artificial combination of
several real words on the basis of experimental
demand to form an unreal word that possesses
many features of real words and instead of real
word as the experimental object in natural language
research.
In the real world, one word has many meanings
derives from the variation and flexible application
of words. That needs a long-term natural evolution.
Frankly speaking, that evolution never ceases at all
times. For example, the word –‘ ’(da3) extends
some new uses in recent years. Actually, in the
endless history river of human beings, the
development and variation of words meaning are
rapid so far as to be more rapid than the
replacement of dictionaries sometimes. Usually that
makes an awkward position when you use
dictionary to define the words meanings. Definitely,
it is inconvenient for the research of natural
linguistics based on dictionary.
But the meaning of pseudoword (Schütze, 1992)
need not defined with the aid of dictionary and
simulates the real ambiguous word to survey the
effect of various algorithms of classified meanings.
To form a pseudoword need the single meaning
word as a morpheme.
Set: Wp = w1 / w2 / ... / wi
Wp is a pseudoword formed with wi which
contains i algorithms and meanings for every
</bodyText>
<equation confidence="0.99438025">
P(w1, w2)
P(w1)P(w2)
log
(8)
</equation>
<bodyText confidence="0.999822777777778">
algorithm of pseudoword is single meaning and
every living example is about equal to a
pseudoword marked meaning in corpus. That is
similar to the effect of artificial marked meaning.
But the effect is more stable and reliable than
artificial marked meaning. What’s more, the scope
of corpus can enlarge endless according to the
demand to avoid the phenomenon of sparse data.
To define the number of algorithm, we count the
average number of meanings according to the
large-sized Chinese dictionaries (Table 3.1). Table
3.2 show the overall number of ambiguous word
and percentage of ambiguous word having 2~4
meanings in all ambiguous word. These two charts
indicate that verb is most active in Chinese and its
average number of meanings is most, about 2.56.
The percentage of ambiguous word having 2~4
meanings is most in all ambiguous word.
</bodyText>
<table confidence="0.997847">
part of Average Average sense
speech sense (only
( including ambiguous
single-sense word)
word)
noun 1.136452 2.361200
verb 1.220816 2.558158
adjective 1.144717 2.300774
adverb 1.059524 2.078431
</table>
<tableCaption confidence="0.7429065">
Table 3.1 the average number of a Chinese
word’s sense
</tableCaption>
<subsectionHeader confidence="0.657368">
3.2.2 Define the input vector
</subsectionHeader>
<bodyText confidence="0.996058">
It should be based on context to determine the
sense of ambiguous word. The model’s input should
be the vector of the ambiguous word and context
words. It is well-known that the number of context
</bodyText>
<table confidence="0.997763875">
ambiguous 7955 /
word
Bi-senses 5799 72.80%
word
Tri-senses 1154 14.51%
word
Four-senses 450 5.66%
word
</table>
<tableCaption confidence="0.901018333333333">
Table 3.2 the distributing of ambiguous word
words showing on the both sides of ambiguous
word is not fixed in different sentences. But the
</tableCaption>
<bodyText confidence="0.999789285714286">
number of vectors needed by BP network is fixed.
In other words, the number of neural nodes of input
model is fixed in the training. If the extracting
method of feature vector is (-M, +N) in context, in
other words there are M vectors on the left of
ambiguous word and N vectors on the right, the
extraction of feature vectors must span the limit of
sentences. If the number of feature vectors is not
enough, the ambiguous words on the left and right
boundaries of whole corpus do not participate in the
training.
According to the extracting method of feature
vector (-M, +N), the vector of model input is as
following:
</bodyText>
<equation confidence="0.98066275">
VVA = {MI11,MI 12,...,MI1i,MI 11΄,MI 12΄,...,
MI 1j΄,MI21,MI 22,...,MI2i,MI 21΄,MI 22΄,...,
MI2j΄,MI31,MI 32,...,MI3i,MI 31΄,MI 32΄,...,
MI 3j΄},1≤i≤M;1≤j≤N.
</equation>
<bodyText confidence="0.995544111111111">
Where, MI1i , MI1j΄ are the MI of context and the
first meaning of ambiguous word;MI2i , MI2j΄ are
the MI of context and the second meaning of
ambiguous word;MI3i .MI3j΄ are the MI of context
and the third meaning of ambiguous word. MI1i,
MI2i and MI3i are the feature words of ambiguous
word on the left and MI of ambiguous word. MI1j΄,
MI2j΄ and MI2j΄ are the feature words of ambiguous
word on the right and MI of ambiguous word.
</bodyText>
<table confidence="0.995308714285714">
pseudo- word sample pseudo- word sample
words ID number words ID number
W1 34466 5550 W4 84323 3773
71345 3715 12751 2284
31796 12098 52915 3900
total 21363 total 9957
W2 71072 9296 W5 53333 1362
78031 6024 29053 6135
48469 1509 75941 1205
total 16829 total 8702
W3 7464 25925 W6 39945 2346
77375 2478 71335 1640
23077 4704 51491 1012
total 33107 total 4998
</table>
<tableCaption confidence="0.996269">
Table 3.3 the total number of the feature -vector
sample of ambiguous word
</tableCaption>
<bodyText confidence="0.99514275">
Training corpus are 105,000 lines, and each line
is a paragraph, totally about 10,000,000 words.
Table 3.3 shows the number of collected feature
vector samples (the frequency of ambiguous word).
</bodyText>
<subsectionHeader confidence="0.983818">
3.3 The definition of output model
</subsectionHeader>
<bodyText confidence="0.942301428571429">
Every ambiguous word has three meanings,
totally eighteen meanings for six ambiguous words.
Every ambiguous word trains a model and every
model has three outputs showed by three-bit integer
of binary system, such as the three meanings of
ambiguous word W are showed as followed:
si1 = 100 si2 = 010 si3 = 001
</bodyText>
<subsectionHeader confidence="0.917294">
3.4 The definition of network structure
</subsectionHeader>
<bodyText confidence="0.999960931034483">
According to statistics, when (-M, +N) are (-8,
+9) using the method of feature extraction, the
cover percentage of effective information is more
than 87% (Lu, 2001). However, if the sentence is
very short, collecting the contextual feature words
on the basis of (-8, +9) can include much useless
information to the input model. Undoubtedly, that
will increase more noisy effect and deduce the
meaning-distinguish ability of verve network.
This article makes an on-the-spot investigation of
experimental corpus, a fairly integrated meaning
unit (the marks of border including comma,
semicolon, ellipsis, period, question mark,
exclamation mark, and the like), which average
length is between 9~10 words. So this article
collects the contextual feature words on the basis of
(-5, +5) in the experiments, 10 feature words
available that calculate MI with each meaning of
ambiguous word separately to get 30 vectors. All
punctuation marks should be filtered while the
feature words are collected. The input layer of
neural network model is regarded as 30 neural
nodes. The triple-layer neural network adopts the
inspired S function. From that, the number of neural
nodes in hidden layer is defined as 12 on the basis
of experimental contrast, and 3 neural nodes in
output layer. Hence, the structure of model is 30 ×
12 × 3, and the precision of differential training is
defined as 0.3 based on the experimental contrast.
</bodyText>
<subsectionHeader confidence="0.976888">
3.5 The test and training of model
</subsectionHeader>
<bodyText confidence="0.999729043478261">
The experimental corpus appeared in front are
123,882 lines. It is divided to three parts according
to the demand of experiment, C1 (15,000 lines), C2
(60,000 lines), and C3 (105,000 lines). The open
test corpus is 18,882 lines.
Table 3.3 tells us that there is a great disparity
between the sample numbers of different
ambiguous words in the experimental corpus of the
same class. And the distribution of different
meanings is not even for same ambiguous word.
For the trained neural network has the good ability
of differentiation for each word, the number of
training sample should be about equal to each other
for each meaning. So this experiment selects the
least training samples. For example, there are 200
samples of the first meaning in training corpus, the
second 400, and the third 500. To balance the input,
each meaning merely has 200 samples to be elected
for training.
Three groups of training corpus can train 3 neural
networks possessing different vectors for every
ambiguous word and make the unclose and open
test for these networks separately.
</bodyText>
<sectionHeader confidence="0.944255" genericHeader="method">
4 The result of experiment
</sectionHeader>
<bodyText confidence="0.999987636363637">
In order to analyze the effect that the extent of
training corpus influences the meaning distinguish
ability of neural network, this article trains the
model of neural network using the experimental
corpus individually, C1, C2 and C3, and makes the
close and open test for 6 ambiguities separately.
The close test means the corpus are same in test
and training.
The experiment is divided into two groups
according to the extracting method of contextual
feature words.
</bodyText>
<subsectionHeader confidence="0.924659">
4.1 The first experiment one
</subsectionHeader>
<bodyText confidence="0.998685142857143">
Table 4.1 shows the result of the first experiment
which extracts the contextual feature words using
the method of (–5,+ 5).
In addition, the first experiment investigates that
the extent of training corpus (the number of training
samples big or small) influences the ability to
distinguish the models. The result of test for 6
</bodyText>
<table confidence="0.9991031">
pseudo- close-test open-test
words
accuracy Training accuracy Training
set set
W, 0.8800 C2 0.8951 C3
W2 0.8867 C2 0.8775 C2
W3 0.8652 C3 0.8574 C3
W4 0.8532 C3 0.8687 C3
W5 0.8769 C3 0.8745 C3
W6 0.8868 C2 0.8951 C3
</table>
<tableCaption confidence="0.9552955">
Table 4.1 The contrast chat of experimental result
for six ambiguities
</tableCaption>
<bodyText confidence="0.95461225">
ambiguities is showed in table 4.2 (close test), table
4.3 (open test), and table 4.4. Considering the
length of this article, table 4.2 and table 4.3 shows
the detailed data, and table 4.4 is brief.
</bodyText>
<table confidence="0.997487454545454">
pseudo- Training set
words
C1 C2 C3
W1 sense 1 0.9226 0.8169 0.8991
sense 2 0.5513 0.8017 0.6872
sense 3 0.8027 0.9564 0.9510
average 0.7589 0.8800 0.8720
W6 sense 1 0.8121 0.8780 0.9377
sense 2 0.8389 0.8968 0.8804
sense 3 0.7248 0.8856 0.8370
average 0.7919 0.8868 0.8850
</table>
<tableCaption confidence="0.9278965">
Table 4.2 The result of W1 and W6 in close test
under the different training corpus
</tableCaption>
<subsectionHeader confidence="0.984129">
4.2 The second experiment
</subsectionHeader>
<bodyText confidence="0.99976775">
The second experiment investigates emphatically
the effect that the method to collect the feature
words influences the ability to distinguish BP
model.
</bodyText>
<table confidence="0.988304090909091">
pseudo- Training set
words
C1 C2 C3
W1 sense 1 0.9019 0.7827 0.8942
sense 2 0.4607 0.8097 0.7175
sense 3 0.7792 0.9500 0.9515
average 0.7573 0.8798 0.8951
W6 sense 1 0.8233 0.9093 0.9535
sense 2 0.8799 0.8182 0.8604
sense 3 0.7278 0.8544 0.8038
average 0.8259 0.8683 0.8951
</table>
<tableCaption confidence="0.91979">
Table 4.3 The result of W1 and W6 in open test
under the different training corpus
</tableCaption>
<bodyText confidence="0.97835275">
There are many methods adopted in this
experiment, including (–10,+ 10),(–3,+ 3),(–3,
+ 7),(–7,+ 3),(–4,+ 6)and(–6,+ 4). Merely
the ambiguous words W1 and W6 are regarded as the
</bodyText>
<table confidence="0.99805925">
pseudo- Training set
words
C1 C2 C3
W2 close 0.6628 0.8867 0.8772
W3 0.6695 0.8453 0.8652
W4 0.7414 0.8452 0.8532
W5 0.8283 0.8537 0.8769
W2 open 0.7287 0.8613 0.8700
W4
W3 0.8085 0.8384 0.8574
0.7920 0.8655 0.8687
W5 0.8288 0.8775 0.8745
</table>
<tableCaption confidence="0.966883">
Table 4.4 The contrast chart of experimental
result for four ambiguities
</tableCaption>
<table confidence="0.994754611111111">
pseudo- accuracy Training
words set
feature
collecting
method
close-test open-test
W, (–10,+10) 0.8897 0.8685 C1
(–3,+3) 0.7917 0.7176 C2
(–4,+6) 0.8600 0.8888 C3
(–6,+4) 0.8797 0.8938 C2
(–3,+7) 0.8514 0.8827 C3
(–7,+3) 0.8431 0.8825 C3
W6 (–10,+10) 0.9031 0.8962 C2
(–3,+3) 0.8487 0.8460 C2
(–4,+6) 0.8982 0.8873 C3
(–6,+4) 0.8480 0.8772 C2
(–3,+7) 0.8669 0.8359 C3
(–7,+3) 0.8982 0.8895 C3
</table>
<tableCaption confidence="0.559209">
Table 4.5 the experimental result under different
feature collecting method
</tableCaption>
<bodyText confidence="0.966247">
experimental objects in this group experiment. See
table 4.5 for the correct percentage of WSD.
</bodyText>
<sectionHeader confidence="0.66459" genericHeader="evaluation">
5. Analysis and discussion
</sectionHeader>
<bodyText confidence="0.999856461538462">
See table 5.1 for the number of experimental
corpus samples in experiment.
According to the table 3.3 and 5.1, the frequency of
the each meaning (morpheme) of ambiguous word
showing in corpus is quite different. That accords
with the distribution of the every meanings of
ambiguous word. However, there is one different
point that the frequency of the each meaning of
ambiguous word is rather high (that is the outcome
selected by morpheme.). In other words, there are
many examples showing for the each meaning of
ambiguous word in training and test corpus. On the
contrast, the difference of frequency is quite
</bodyText>
<table confidence="0.99833">
pseudo- Morpheme sample pseudo- Morpheme sample
words ID number words ID number
W1 34466 1040 W4 84323 591
71345 662 12751 484
31796 2101 52915 829
W2 71072 1296 W5 53333 274
78031 1043 29053 1153
48469 315 75941 238
W3 7464 4389 W6 39945 430
77375 469 71335 308
23077 865 51491 158
</table>
<tableCaption confidence="0.998679">
Table 5.1 The number of experimental samples
</tableCaption>
<bodyText confidence="0.999975769230769">
obvious for the each meaning of real ambiguous
word, because some meanings are used in oral
language. But that never or seldom appears in
experimental corpus.
The statistics can uncover this linguistic
phenomenon. We find that the meaning of the most
percentage of ambiguous word showing in the
corpus is 83.54% on the whole percentage of each
meaning. That illustrates the distribution of each
meaning has a great disparity in real ambiguous
word. Seeing that condition, to differentiate the
meaning of ambiguous word is harder than that of
real ambiguous word absolutely.
</bodyText>
<subsectionHeader confidence="0.9207395">
5.1 The analysis and discussion of the first
experiment
</subsectionHeader>
<bodyText confidence="0.999985551724138">
Table 4.1 records the results of close and open
tests in detail and the training materials to get these
results.
Seeing from the experimental results, the correct
percentage reaches 89.51% most (ambiguous word
W1 and W6) in open test of WSD, and 85.74% the
least (ambiguous word W3).
The relationship of correct percentage and the
extent of training corpus can be deduced from the
experimental results of table 4.2, 4.3 and 4.4.
The larger the extent of training corpus (the
number of training sample), the larger the result of
close test. It is obvious to see that from C1 to C2.
From C2 to C3 one or two experimental results
fluctuate more or less.
With the growing of training sample, the
experimental results of open test increase steadily,
except ambiguous word W2 (a little bit difference).
The experimental data prove the growing of
training samples rise the correct percentage.
However, when the rising reaches to a certain
degree, more rising is not good for the improvement
of model. What’s more, the effect of noise is more
and more remarkable. That decreases the model’s
ability of differentiation in a certain degree. On the
other hand, after the growing of training corpus, the
linguistic phenomenon around ambiguities is richer
and richer, more and more complex. That makes it
harder to determine the meaning.
</bodyText>
<subsectionHeader confidence="0.921527">
5.2 The analysis and discussion of the second
experiment
</subsectionHeader>
<bodyText confidence="0.999987694444445">
This article emphasizes on the collecting method
of contextual feature words in experiment two, in
other words, the effect that the different values of M
and N influence the model of BP network. The
experimental results (table 4.1 and 4.5) tell us that
the context windows influence the correct
percentage heavily. The correct percentage
increases almost by leaps and bounds from (–3,+ 3)
to(–5,+5). The discrepancy is obvious despite
close test or open test. The correct percentage
increase again to(–10,+ 10), in which the close test
of ambiguous word W6 is more than 90% and
89.62% the close test, with the exception of W1
which open test is slightly special. That illustrates
the more widely the context windows open, the
more the effective information is caught to benefit
the WSD more.
Comparing the four feature methods of collection,
including (–3,+ 7),(–7,+ 3),(–4,+ 6)
and(–6,+ 4) with(–5,+ 5), the number of feature
words besides the ambiguous word is various and
the experimental results (table 4.1 and 4.5) are not
same, although the windows are same. Among them,
the correct percentage of (–5,+ 5)is the highest.
And that of(–4,+ 6)and(–6,+ 4)is better than
that of(–3,+ 7)and(–7,+ 3)a bit. That shows
the more balanceable the feature words besides
ambiguous word, the more advantageous to judge
meaning, and the better the experimental results.
In addition, some experimental results of open
test are better than that of close test. The main
reason is the experimental corpus of open test is
smaller than training corpus. So the contextual
meanings of ambiguous word in experimental
corpus are rather explicit. Thereby, that explains
why should be this kind of experimental result.
</bodyText>
<subsectionHeader confidence="0.930434">
5.3 Conclusions
</subsectionHeader>
<bodyText confidence="0.999892833333333">
Considering the analysis of experimental data,
the conclusions are as following:
First, the artificial model of neural network
established in this article has good ability of
differentiation for Chinese meaning.
Next, higher correct percentage of WSD stems
from the large enough corpus.
At last, the larger the windows of contextual
feature words, the more the effective information.
At the same time, the more balanceable the number
of feature words beside the ambiguous word, the
more beneficial that for WSD.
</bodyText>
<sectionHeader confidence="0.993741" genericHeader="conclusions">
6 Concluding remarks
</sectionHeader>
<bodyText confidence="0.999455115384615">
Although the BP network is a classified model
applied extensively, the report of research on WSD
about it is seldom. Especially the report about the
Chinese WSD is less, and only one report (Zhang,
2001) is available in internal reports.
Zhang (2001) uses 96 semantic classes to instead
the all words in training corpus according to the
TongyiciCilin. The input model is the codes of
semantic class of contextual words and ambiguities.
The experiment of WSD merely makes for one
’(cai2liao4) in this document and the
correct percentage of open test is 80.4%. ‘
has 3 meanings and that is similar to the
ambiguities structured in my article.
Using BP for Chinese WSD, the key point and
difficulty are on the determination of input model.
The performance of input model may influence the
construction of BP network and the output result
directly.
We make the experiment on the input of BP
network many times and finally find the input
model introduced as above (table 3.1) which test
result is satisfied.
Acknowledgements This work was supported by
the National Natural Science Foundation of China
(Grant No. 60203020).
</bodyText>
<sectionHeader confidence="0.939831" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999647219512195">
Lu Song, Bai Shuo, et al. 2001. Supervised word
sense disambiguation bassed on Vector Space
Model, Journal of Comouter Research &amp;
Development, 38(6): 662-667.
Pedersen. 2001. Lexical semantic ambiguous word
resolution with bigram-based decision trees, In
Proceedings of the Second International Conference
on Intelligent Text Processing and Computational
Linguistics, pages 157-168, Mexico City, February.
Escudero, G., Marquez,L., et al, 2000. Naive Bayes
and examplar based approaches to word sense
disambiguation revisited. In Proceedings of the 14th
Europear Conference on Artificial Intelligence,
ECAI.
Adam,L.B. 1996. A maximum entropy approach to
natural language proceeding. Computational
Linguistics, 22(1):39-71.
Li, J. Z. 1999. An improved maximum language
and its application. Journal of software, 3:257-263.
Yarowsky, D. Word sense disambiguation using
statistical models of Roget’s categories trained on
large corpora. In: Zampolli, A., ed. Computation
Linguistic’92. Nantas: Association for
Computational Linguistics, 1992. 454~460.
Hinrich Schütze, 1998. Automatic word sense
discrimination. Computational Linguistics, 24(1):
97-124.
Lu Song., Bai Shuo. 2002. An unsupervised
approach to word sense disambiguation based on
sense-word in vector space model. Journal of
Software. 13(06):1082-08
Hinrich Schütze. 1992. Context space. In AAAI
Fall Symposium on Probabilistic Approaches to
Natural Language, pages 113–120, Cambridge,
MA.
Lu Song Bai Shuo. 2001. Quantitative Analysis of
Context Field. In Natural Language Processing,
CHINESEJ.COMPUTERS, 24(7) , 742-747
Zhang Guoqing, Zhang Yongkui. 2001. A
Neural-network Based Word Sense Disambiguation
Method. Computer Engineering, 27(12).
</reference>
<figure confidence="0.714379">
phrase ‘
’
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.877323">
<title confidence="0.997955">Combining Neural Networks and Statistics Chinese Word sense disambiguation</title>
<author confidence="0.999363">Zhimao Lu Ting Liu Sheng Li</author>
<affiliation confidence="0.99933">Information Retrieval Laboratory of Computer Science &amp; Technology Harbin Institute of Technology</affiliation>
<address confidence="0.900539">Harbin, China,</address>
<email confidence="0.986485">lzm@ir.hit.edu.cn</email>
<email confidence="0.986485">tliu@ir.hit.edu.cn</email>
<abstract confidence="0.999541761904762">The input of network is the key problem for Chinese Word sense disambiguation utilizing the Neural Network. This paper presents an input model of Neural Network that calculates the Mutual Information between contextual words and ambiguous word by using statistical method and taking the contextual words to certain number beside the ambiguous word according to (-M, +N). The experiment adopts triple-layer BP Neural Network model and proves how the size of training set and the value of M and N affect the performance of Neural Network model. The experimental objects are six pseudowords owning three word-senses constructed according to certain principles. Tested accuracy of our approach on a close-corpus reaches 90.31%,, and 89.62% on a open-corpus. The experiment proves that the Neural Network model has good performance on Word sense disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lu Song</author>
<author>Bai Shuo</author>
</authors>
<title>Supervised word sense disambiguation bassed on Vector Space Model,</title>
<date>2001</date>
<journal>Journal of Comouter Research &amp; Development,</journal>
<volume>38</volume>
<issue>6</issue>
<pages>662--667</pages>
<marker>Song, Shuo, 2001</marker>
<rawString>Lu Song, Bai Shuo, et al. 2001. Supervised word sense disambiguation bassed on Vector Space Model, Journal of Comouter Research &amp; Development, 38(6): 662-667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedersen</author>
</authors>
<title>Lexical semantic ambiguous word resolution with bigram-based decision trees,</title>
<date>2001</date>
<booktitle>In Proceedings of the Second International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>157--168</pages>
<location>Mexico City,</location>
<contexts>
<context position="2288" citStr="Pedersen, 2001" startWordPosition="338" endWordPosition="339">ech, and so on. With rising of Corpus linguistics, the machine learning methods based on statistics are booming (Yarowsky, 1992). These methods draw the support from the high-powered computers, get the statistics of large real-world corpus, find and acquire knowledge of linguistics automatically. They deal with all change by invariability, thus it is easy to trace the evaluation and development of natural language. So the statistic methods of NLP has attracted the attention of professional researchers and become the mainstream bit by bit. Corpus-based Statistical approaches are Decision Tree (Pedersen, 2001), Decision List, Genetic Algorithm, Naive-Bayesian Classifier (Escudero, 2000)、Maximum Entropy Model (Adam, 1996; Li, 1999), and so on. Corpus-based statistical approaches can be divided into supervised and unsupervised according to whether training corpus is sense-labeled text. Supervised learning methods have the good learning ability and can get better accuracy in WSD experiments (Schütze, 1998). Obviously the data sparseness problem is a bottleneck for supervised learning algorithm. If you want to get better learning and disambiguating effect, you can enlarge the size and smooth the data o</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>Pedersen. 2001. Lexical semantic ambiguous word resolution with bigram-based decision trees, In Proceedings of the Second International Conference on Intelligent Text Processing and Computational Linguistics, pages 157-168, Mexico City, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L Marquez</author>
</authors>
<title>Naive Bayes and examplar based approaches to word sense disambiguation revisited.</title>
<date>2000</date>
<booktitle>In Proceedings of the 14th Europear Conference on Artificial Intelligence, ECAI.</booktitle>
<marker>Escudero, Marquez, 2000</marker>
<rawString>Escudero, G., Marquez,L., et al, 2000. Naive Bayes and examplar based approaches to word sense disambiguation revisited. In Proceedings of the 14th Europear Conference on Artificial Intelligence, ECAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L B Adam</author>
</authors>
<title>A maximum entropy approach to natural language proceeding.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="2400" citStr="Adam, 1996" startWordPosition="350" endWordPosition="351">wsky, 1992). These methods draw the support from the high-powered computers, get the statistics of large real-world corpus, find and acquire knowledge of linguistics automatically. They deal with all change by invariability, thus it is easy to trace the evaluation and development of natural language. So the statistic methods of NLP has attracted the attention of professional researchers and become the mainstream bit by bit. Corpus-based Statistical approaches are Decision Tree (Pedersen, 2001), Decision List, Genetic Algorithm, Naive-Bayesian Classifier (Escudero, 2000)、Maximum Entropy Model (Adam, 1996; Li, 1999), and so on. Corpus-based statistical approaches can be divided into supervised and unsupervised according to whether training corpus is sense-labeled text. Supervised learning methods have the good learning ability and can get better accuracy in WSD experiments (Schütze, 1998). Obviously the data sparseness problem is a bottleneck for supervised learning algorithm. If you want to get better learning and disambiguating effect, you can enlarge the size and smooth the data of training corpus. According to practical demand, it would spend much more time and manpower to enlarge the size</context>
</contexts>
<marker>Adam, 1996</marker>
<rawString>Adam,L.B. 1996. A maximum entropy approach to natural language proceeding. Computational Linguistics, 22(1):39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Z Li</author>
</authors>
<title>An improved maximum language and its application.</title>
<date>1999</date>
<journal>Journal of software,</journal>
<pages>3--257</pages>
<contexts>
<context position="2411" citStr="Li, 1999" startWordPosition="352" endWordPosition="353"> These methods draw the support from the high-powered computers, get the statistics of large real-world corpus, find and acquire knowledge of linguistics automatically. They deal with all change by invariability, thus it is easy to trace the evaluation and development of natural language. So the statistic methods of NLP has attracted the attention of professional researchers and become the mainstream bit by bit. Corpus-based Statistical approaches are Decision Tree (Pedersen, 2001), Decision List, Genetic Algorithm, Naive-Bayesian Classifier (Escudero, 2000)、Maximum Entropy Model (Adam, 1996; Li, 1999), and so on. Corpus-based statistical approaches can be divided into supervised and unsupervised according to whether training corpus is sense-labeled text. Supervised learning methods have the good learning ability and can get better accuracy in WSD experiments (Schütze, 1998). Obviously the data sparseness problem is a bottleneck for supervised learning algorithm. If you want to get better learning and disambiguating effect, you can enlarge the size and smooth the data of training corpus. According to practical demand, it would spend much more time and manpower to enlarge the size of trainin</context>
</contexts>
<marker>Li, 1999</marker>
<rawString>Li, J. Z. 1999. An improved maximum language and its application. Journal of software, 3:257-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Word sense disambiguation using statistical models of Roget’s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>Computation Linguistic’92. Nantas: Association for Computational Linguistics,</booktitle>
<pages>454--460</pages>
<editor>In: Zampolli, A., ed.</editor>
<contexts>
<context position="1801" citStr="Yarowsky, 1992" startWordPosition="267" endWordPosition="268">in natural language. According statistics, there are about 42% ambiguous words in Chinese corpus (Lu, 2001). Word sense disambiguation (WSD) is a method to determine the sense of ambiguous word given the context circumstance. WSD, a long-standing problem in NLP, has been a very active research topic,, which can be well applied in many NLP systems, such as Information Retrieval, Text Mining, Machine Translation, Text Categorization, Text Summarization, Speech Recognition, Text to Speech, and so on. With rising of Corpus linguistics, the machine learning methods based on statistics are booming (Yarowsky, 1992). These methods draw the support from the high-powered computers, get the statistics of large real-world corpus, find and acquire knowledge of linguistics automatically. They deal with all change by invariability, thus it is easy to trace the evaluation and development of natural language. So the statistic methods of NLP has attracted the attention of professional researchers and become the mainstream bit by bit. Corpus-based Statistical approaches are Decision Tree (Pedersen, 2001), Decision List, Genetic Algorithm, Naive-Bayesian Classifier (Escudero, 2000)、Maximum Entropy Model (Adam, 1996;</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>Yarowsky, D. Word sense disambiguation using statistical models of Roget’s categories trained on large corpora. In: Zampolli, A., ed. Computation Linguistic’92. Nantas: Association for Computational Linguistics, 1992. 454~460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>97--124</pages>
<contexts>
<context position="2689" citStr="Schütze, 1998" startWordPosition="391" endWordPosition="392">atural language. So the statistic methods of NLP has attracted the attention of professional researchers and become the mainstream bit by bit. Corpus-based Statistical approaches are Decision Tree (Pedersen, 2001), Decision List, Genetic Algorithm, Naive-Bayesian Classifier (Escudero, 2000)、Maximum Entropy Model (Adam, 1996; Li, 1999), and so on. Corpus-based statistical approaches can be divided into supervised and unsupervised according to whether training corpus is sense-labeled text. Supervised learning methods have the good learning ability and can get better accuracy in WSD experiments (Schütze, 1998). Obviously the data sparseness problem is a bottleneck for supervised learning algorithm. If you want to get better learning and disambiguating effect, you can enlarge the size and smooth the data of training corpus. According to practical demand, it would spend much more time and manpower to enlarge the size of training corpus. Smoothing data is merely a subsidiary measure. The sufficient large size of training corpus is still the foundation to get a satisfied effect in WSD experiment. Unsupervised WSD never depend on tagged corpus and could realize the training of large real corpus coming f</context>
</contexts>
<marker>Schütze, 1998</marker>
<rawString>Hinrich Schütze, 1998. Automatic word sense discrimination. Computational Linguistics, 24(1): 97-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Song</author>
<author>Bai Shuo</author>
</authors>
<title>An unsupervised approach to word sense disambiguation based on sense-word in vector space model.</title>
<date>2002</date>
<journal>Journal of Software.</journal>
<pages>13--06</pages>
<marker>Song, Shuo, 2002</marker>
<rawString>Lu Song., Bai Shuo. 2002. An unsupervised approach to word sense disambiguation based on sense-word in vector space model. Journal of Software. 13(06):1082-08</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Context space.</title>
<date>1992</date>
<booktitle>In AAAI Fall Symposium on Probabilistic Approaches to Natural Language,</booktitle>
<pages>113--120</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="9823" citStr="Schütze, 1992" startWordPosition="1644" endWordPosition="1645"> application of words. That needs a long-term natural evolution. Frankly speaking, that evolution never ceases at all times. For example, the word –‘ ’(da3) extends some new uses in recent years. Actually, in the endless history river of human beings, the development and variation of words meaning are rapid so far as to be more rapid than the replacement of dictionaries sometimes. Usually that makes an awkward position when you use dictionary to define the words meanings. Definitely, it is inconvenient for the research of natural linguistics based on dictionary. But the meaning of pseudoword (Schütze, 1992) need not defined with the aid of dictionary and simulates the real ambiguous word to survey the effect of various algorithms of classified meanings. To form a pseudoword need the single meaning word as a morpheme. Set: Wp = w1 / w2 / ... / wi Wp is a pseudoword formed with wi which contains i algorithms and meanings for every P(w1, w2) P(w1)P(w2) log (8) algorithm of pseudoword is single meaning and every living example is about equal to a pseudoword marked meaning in corpus. That is similar to the effect of artificial marked meaning. But the effect is more stable and reliable than artificial</context>
</contexts>
<marker>Schütze, 1992</marker>
<rawString>Hinrich Schütze. 1992. Context space. In AAAI Fall Symposium on Probabilistic Approaches to Natural Language, pages 113–120, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Song Bai Shuo</author>
</authors>
<title>Quantitative Analysis of Context Field.</title>
<date>2001</date>
<booktitle>In Natural Language Processing, CHINESEJ.COMPUTERS, 24(7) ,</booktitle>
<pages>742--747</pages>
<marker>Shuo, 2001</marker>
<rawString>Lu Song Bai Shuo. 2001. Quantitative Analysis of Context Field. In Natural Language Processing, CHINESEJ.COMPUTERS, 24(7) , 742-747</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhang Guoqing</author>
<author>Zhang Yongkui</author>
</authors>
<title>A Neural-network Based Word Sense Disambiguation Method.</title>
<date>2001</date>
<journal>Computer Engineering,</journal>
<volume>27</volume>
<issue>12</issue>
<marker>Guoqing, Yongkui, 2001</marker>
<rawString>Zhang Guoqing, Zhang Yongkui. 2001. A Neural-network Based Word Sense Disambiguation Method. Computer Engineering, 27(12).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>