<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.196752">
<title confidence="0.997867">
SAIL-GRS: Grammar Induction for Spoken Dialogue Systems using
CF-IRF Rule Similarity
</title>
<author confidence="0.946387">
Kalliopi Zervanou, Nikolaos Malandrakis and Shrikanth Narayanan
</author>
<affiliation confidence="0.9602575">
Signal Analysis and Interpretation Laboratory (SAIL),
University of Southern California, Los Angeles, CA 90089, USA
</affiliation>
<email confidence="0.996456">
kzervanou@gmail.com,malandra@usc.edu,shri@sipi.usc.edu
</email>
<sectionHeader confidence="0.993847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998036">
The SAIL-GRS system is based on a
widely used approach originating from in-
formation retrieval and document index-
ing, the TF-IDF measure. In this im-
plementation for spoken dialogue system
grammar induction, rule constituent fre-
quency and inverse rule frequency mea-
sures are used for estimating lexical and
semantic similarity of candidate grammar
rules to a seed set of rule pattern instances.
The performance of the system is evalu-
ated for the English language in three dif-
ferent domains, travel, tourism and finance
and in the travel domain, for Greek. The
simplicity of our approach makes it quite
easy and fast to implement irrespective of
language and domain. The results show
that the SAIL-GRS system performs quite
well in all three domains and in both lan-
guages.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999883153846154">
Spoken dialogue systems typically rely on gram-
mars which define the semantic frames and re-
spective fillers in dialogue scenarios (Chen et al.,
2013). Such systems are tailored for specific
domains for which the respective grammars are
mostly manually developed (Ward, 1990; Seneff,
1992). In order to address this issue, numerous
current approaches attempt to infer these grammar
rules automatically (Pargellis et al., 2001; Meng
and Siu, 2002; Yoshino et al., 2011; Chen et al.,
2013).
The acquisition of grammar rules for spoken
language systems is defined as a task comprising
</bodyText>
<footnote confidence="0.88751275">
This work is licensed under a Creative Commons Attribution
4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.947531">
of two subtasks (Meng and Siu, 2002; Iosif and
Potamianos, 2007), the acquisition of:
</bodyText>
<listItem confidence="0.997195071428572">
(i) Low-level rules These are rules defining
domain-specific entities, such as names of lo-
cations, hotels, airports, e.g. CountryName:
“USA”, Date: “July 15th, 2014”, CardType:
“VISA” and other common domain multi-word ex-
pressions, e.g. DoYouKnowQ: “do you know”.
(ii) High-level rules These are larger,
frame-like rule patterns which contain as
semantic slot fillers multi-word entities
identified by low-level rules. For exam-
ple: DirectionsQ: “&lt;DoYouKnowQ&gt;
&lt;where&gt; the &lt;MuseumName&gt; is lo-
cated”, ExpressionCardProblem: “my
&lt;CardType&gt; has expired”.
</listItem>
<bodyText confidence="0.9999281">
The shared task of Grammar Induction for Spo-
ken Dialogue Systems, where our system partic-
ipated, focused on the induction of high-level
grammar rules and in particular on the identifica-
tion and semantic classification of new rule pat-
terns based on their semantic similarity to known
rule instances.
Within this research framework, the work de-
scribed in this paper proposes a methodology for
estimating rule semantic similarity using a varia-
tion of the well-known measure of TF-IDF as
rule constituent frequency vs. inverse rule fre-
quency, henceforth CF-IRF.
In the remainder of this paper, we start in Sec-
tion 2 by a detailed description of our system. Sub-
sequently, in Section 3, we present the datasets
used and the evaluation process, and in Section 4
we discuss our results. We conclude in Section 5
with a summary of our observations and directions
for future work.
</bodyText>
<sectionHeader confidence="0.982213" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999521333333333">
The SAIL-GRS system is based on a widely used
approach in information retrieval and document
indexing, the TF-IDF measure. TF-IDF is
</bodyText>
<page confidence="0.949329">
508
</page>
<note confidence="0.7317465">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 508–511,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999826269230769">
an approach that has found numerous applications
in information management applications, such as
document keyword extraction, (e.g., Dillon and
Gray (1983)), document clustering, summarisa-
tion, (e.g., Gong and Liu (2001)), event cluster-
ing, (e.g., De Smet and Moens (2013)). In dia-
logue systems, TF-IDF has been used, among
other applications, for discovering local coher-
ence (Gandhe and Traum, 2007) and for acquir-
ing predicate-argument rule fragments in an open
domain, information extraction-based spoken dia-
logue system (Yoshino et al., 2011). In their ap-
proach, Yoshino et al. (2011) use the TF-IDF
measure to determine the importance of a given
word for a given domain or topic, so as to select
the most salient predicate-argument structure rule
patterns from their corpus.
In our implementation for spoken dialogue
system grammar induction, rule constituent fre-
quency (CF) and inverse rule frequency (IRF)
measures are used for estimating lexical and se-
mantic similarity of candidate grammar rules to a
seed set of rule pattern instances. As illustrated in
Table 1, the SAIL-GRS algorithm has two main
steps, the training stage and the rule induction
stage.
</bodyText>
<tableCaption confidence="0.988644">
Table 1: The SAIL-GRS system algorithm.
</tableCaption>
<bodyText confidence="0.999979172413793">
In the first, the Training stage, known rule in-
stances are parsed and, for each rule semantic cat-
egory, the respective high-level rule pattern in-
stances are acquired. These patterns are subse-
quently split into unigram and bigram constituents
and the respective constituent frequencies and in-
verse rule frequencies are estimated. Finally, for
each rule category, a vector representation is cre-
ated for the respective rule pattern instance, based
on the CF-IRF value of its unigram and bigram
constituents.
In the second step, the Rule induction stage, the
unknown text fragments are parsed and split into
unigrams and bigrams. Subsequently, we lookup
the known rule instance unigram and bigram rep-
resentations for potential lexical matches to these
new unigrams and bigrams. If these are found,
then the new n-grams acquire the respective CF-
IRF values found in the training instances and the
respective CF-IRF vector for the unknown text
fragments is created. Finally, we estimate the co-
sine similarity of this unknown text vector to each
known rule vector. The unknown text fragments
that are most similar to a given rule category are
selected as candidate rule patterns and are classi-
fied in the known rule semantic category. An un-
known text fragment that is selected as candidate
rule pattern is assigned only to one, the most sim-
ilar, rule category.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.997937">
The overall objective in spoken dialogue system
grammar induction is the fast and efficient devel-
opment and portability of grammar resources. In
the Grammar Induction for Spoken Dialogue Sys-
tems task, this challenge was addressed by pro-
viding datasets in three different domains, travel,
tourism and finance, and by attempting to cover
more than one language for the travel domain,
namely English and Greek.
As illustrated in Table 2, the travel domain data
for the two languages are comparable, with 32 and
35 number of known rule categories, for English
and Greek, comprising of 982 and 956 high-level
rule pattern instances respectively. The smallest
dataset is the finance dataset, with 9 rule categories
and 136 rule pattern instances, while the tourism
dataset has a relatively low number of rule cate-
gories comprising of the highest number of rule
pattern instances. Interestingly, as indicated in the
column depicting the percent of unknown n-grams
in the test-set, i.e. the unigrams and the bigrams
without a CF-IRF value in the training data, the
tourism domain test-set appears also to be the one
Input: known rule pattern instances
Output: new candidate rule patterns
</bodyText>
<figure confidence="0.982035176470588">
Training stage:
1. Known rule instance parsing
2. Rule constituent extraction (uni-/bigrams)
3. Rule constituent frequency count (CF)
4. Inverse rule frequency count (IRF)
5. CF-IRF rule instance vector creation
Rule induction stage:
1. Unknown text fragment parsing
2. Unigram &amp; bigram extraction
3. Uni-/bigram CF-IRF value lookup
4. Creation of CF-IRF vector for
unknown text fragment
5. Estimation of cosine similarity of
unknown fragment to rule instances
6. New candidate rule selection &amp; rule
semantic category classification using
maximum cosine similarity
</figure>
<page confidence="0.995361">
509
</page>
<bodyText confidence="0.9998812">
with the greatest overlap with the training data,
with a mere 0.72% and 4.84% of unknown uni-
grams and bigrams respectively.
For the evaluation, the system performance is
estimated in terms of precision (P), recall (R) and
F-score measures, for the correct classification of
an unknown text fragment to a given rule cate-
gory cluster of pattern instances. In addition to
these measures, the weighted average of the per
rule scores is computed as follows:
</bodyText>
<equation confidence="0.999316166666667">
N−1 N−1
PP = Ei=1 Pici R — Ei=1 Rini (1)
. N-1,w N-1
Ei=1 ciEi=1 ni
(2)
Pw + Rw
</equation>
<bodyText confidence="0.999959">
where N − 1 is the total number of rule cate-
gories, Pi and Ri are the per rule i scores for preci-
sion and recall, ci the unknown patterns correctly
assigned to rule i, and ni the total number of cor-
rect rule instance patterns for rule i indicated in
the ground truth data.
</bodyText>
<sectionHeader confidence="0.999945" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999952148148148">
The results of the SAIL-GRS system outperform
the Baseline in all dataset categories, except the
Tourism domain, as illustrated in Table 3. In this
domain, both systems present the highest scores
compared to the other domains. The high results
in the travel domain are probably due to the high
data overlap between the train and the test data, as
discussed in the previous section and illustrated in
Table 2. However, this domain was also the one
with the highest average number of rule instances
per rule category, compared to the other domains,
thus presenting an additional challenge in the cor-
rect classification of unknown rule fragments.
We observe that the overall higher F measures
of the SAIL-GRS system in the travel and fi-
nance domains are due to higher precision scores,
whereas Baseline system displays higher recall but
lower precision scores and lower F-measure in
these domains.
The overall lowest scores for both systems are
reached in the Travel domain for Greek, which
is also the dataset with the lowest overlap with
the training data. However, the performance of
the SAIL-GRS system does not deteriorate to the
same extent as the Baseline, the precision of which
falls to a mere 0.16-0.17, compared to 0.49-0.46
for the SAIL-GRS system.
</bodyText>
<sectionHeader confidence="0.989403" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999984852941176">
In this work, we have presented the SAIL-GRS
system used for the Grammar Induction for Spo-
ken Dialogue Systems task. Our approach uses
a fairly simple, language independent method for
measuring lexical and semantic similarity of rule
pattern instances. Our rule constituent frequency
vs. inverse rule frequency measure, CF-IRF is a
modification the TF-IDF measure for estimating
rule similarity in the induction process of new rule
instances.
The performance of our system in rule induc-
tion and rule pattern semantic classification was
tested in three different domains, travel, tourism
and finance in four datasets, three for English
and an additional dataset for the travel domain
in Greek. SAIL-GRS outperforms the Baseline
in all datasets, except the travel domain for En-
glish. Moreover, our results showed that our sys-
tem achieved an overall better score in precision
and respective F-measure, in the travel and finance
domains, even when applied to a language other
than English. Finally, in cases of a larger percent-
age of unknown data in the test set, as in the Greek
travel dataset, the smooth degradation of SAIL-
GRS results compared to the Baseline indicates
the robustness of our method.
A limitation of our system in its current version
lies in the requirement for absolute lexical match
with unknown rule unigrams and bigrams. Fu-
ture extensions of the system could include rule
constituent expansion using synonyms, variants or
semantically or lexically similar words, so as to
improve recall and the overall F-measure perfor-
mance.
</bodyText>
<sectionHeader confidence="0.99852" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9749505">
Yun-Nung Chen, William Yang Wang, and Alexan-
der I. Rudnicky. 2013. Unsupervised induction and
filling of semantic slots for spoken dialogue systems
using frame-semantic parsing. In Proceedings of the
2013 IEEE Workshop on Automatic Speech Recogni-
tion and Understanding, pages 120–125.
Wim De Smet and Marie-Francine Moens. 2013. Rep-
resentations for multi-document event clustering.
Data Mining and Knowledge Discovery, 26(3):533–
558.
Martin Dillon and Ann S. Gray. 1983. FASIT: A
fully automatic syntactically based indexing system.
Journal of the American Society forInformation Sci-
ence, 34(2):99–108.
</reference>
<equation confidence="0.979405">
Fw =
2 · Pw · Rw
</equation>
<page confidence="0.988529">
510
</page>
<table confidence="0.999846285714286">
High-Level Rule Rule Patterns # Test-set: Unknown n-grams %
Domain Categories #
Training-set Test-set Unigrams Bigrams
Travel EN 32 982 284 5.13% 20.71%
Travel GR 35 956 324 17.26% 33.09%
Tourism EN 24 1004 285 0.72% 4.84%
Finance EN 9 136 37 12.35% 36.74%
</table>
<tableCaption confidence="0.97037">
Table 2: Characteristics of training and test datasets.
</tableCaption>
<table confidence="0.999960666666666">
Domain SAIL-GRS Baseline
P P,,, R R,,, F F,,, P P,,, R R,,, F F,,,
Travel EN 0.57 0.54 0.66 0.62 0.61 0.58 0.38 0.40 0.67 0.69 0.48 0.51
Travel GR 0.49 0.46 0.62 0.51 0.55 0.49 0.16 0.17 0.73 0.65 0.26 0.26
Tourism EN 0.75 0.75 0.90 0.90 0.82 0.82 0.82 0.80 0.94 0.94 0.87 0.87
Finance EN 0.67 0.78 0.62 0.78 0.65 0.78 0.40 0.48 0.63 0.78 0.49 0.60
</table>
<tableCaption confidence="0.997138">
Table 3: Evaluation results for SAIL-GRS system compared to the baseline in all four datasets in terms
</tableCaption>
<reference confidence="0.986254761904762">
of per rule Precision P, Recall R, and F-score F. In the grey column, P,,,, R,,,, and F,,, stand for the
weighted average of the per rule precision, recall and F-score respectively, as defined in Equ. 1 and 2.
Sudeep Gandhe and David Traum. 2007. First steps
towards dialogue modelling from an un-annotated
human-human corpus. In Proceedings of the Fifth
IJCAI Workshop on Knowledge and Reasoning in
Practical Dialogue Systems, pages 22–27.
Yihong Gong and Xin Liu. 2001. Generic text summa-
rization using relevance measure and latent semantic
analysis. In Proceedings of the 24th Annual Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval, SIGIR ’01,
pages 19–25, New York, NY, USA. ACM.
Elias Iosif and Alexandros Potamianos. 2007. A soft-
clustering algorithm for automatic induction of se-
mantic classes. In Proceedings of the 8th Annual
Conference of the International Speech Communi-
cation Association, pages 1609–1612. ISCA.
Helen M. Meng and Kai-Chung Siu. 2002. Semi-
automatic acquisition of semantic structures for
understanding domain-specific natural language
queries. IEEE Transactions on Knowledge and Data
Engineering, 14(1):172–181.
Andrew N. Pargellis, Eric Fosler-Lussier, Alexandros
Potamianos, and Chin-Hui Lee. 2001. Metrics
for measuring domain independence of semantic
classes. In Proceedings of the 7th European Con-
ference on Speech Communication and Technology,
pages 447–450. ISCA.
Stephanie Seneff. 1992. TINA: A natural language
system for spoken language applications. Computa-
tional Linguistics, 18(1):61–86, March.
Wayne Ward. 1990. The CMU air travel informa-
tion service: Understanding spontaneous speech.
In Speech and Natural Language: Proceedings of
a Workshop Held at Hidden Valley, Pennsylvania,
pages 127–129.
Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-
hara. 2011. Spoken dialogue system based on in-
formation extraction using similarity of predicate ar-
gument structures. In Proceedings of the SIGDIAL
2011 Conference, pages 59–66.
</reference>
<page confidence="0.997714">
511
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.647506">
<title confidence="0.9682335">SAIL-GRS: Grammar Induction for Spoken Dialogue Systems CF-IRF Rule Similarity</title>
<author confidence="0.953479">Kalliopi Zervanou</author>
<author confidence="0.953479">Nikolaos Malandrakis</author>
<author confidence="0.953479">Shrikanth</author>
<affiliation confidence="0.923543">Signal Analysis and Interpretation Laboratory University of Southern California, Los Angeles, CA 90089,</affiliation>
<abstract confidence="0.992474142857143">The SAIL-GRS system is based on a widely used approach originating from information retrieval and document indexthe In this implementation for spoken dialogue system grammar induction, rule constituent frequency and inverse rule frequency measures are used for estimating lexical and semantic similarity of candidate grammar rules to a seed set of rule pattern instances. The performance of the system is evaluated for the English language in three different domains, travel, tourism and finance and in the travel domain, for Greek. The simplicity of our approach makes it quite easy and fast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 IEEE Workshop on Automatic Speech Recognition and Understanding,</booktitle>
<pages>120--125</pages>
<contexts>
<context position="1262" citStr="Chen et al., 2013" startWordPosition="184" endWordPosition="187">imilarity of candidate grammar rules to a seed set of rule pattern instances. The performance of the system is evaluated for the English language in three different domains, travel, tourism and finance and in the travel domain, for Greek. The simplicity of our approach makes it quite easy and fast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: </context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2013</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I. Rudnicky. 2013. Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing. In Proceedings of the 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, pages 120–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Representations for multi-document event clustering.</title>
<date>2013</date>
<journal>Data Mining and Knowledge Discovery,</journal>
<volume>26</volume>
<issue>3</issue>
<pages>558</pages>
<marker>De Smet, Moens, 2013</marker>
<rawString>Wim De Smet and Marie-Francine Moens. 2013. Representations for multi-document event clustering. Data Mining and Knowledge Discovery, 26(3):533– 558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Dillon</author>
<author>Ann S Gray</author>
</authors>
<title>FASIT: A fully automatic syntactically based indexing system.</title>
<date>1983</date>
<journal>Journal of the American Society forInformation Science,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="3863" citStr="Dillon and Gray (1983)" startWordPosition="575" endWordPosition="578">asets used and the evaluation process, and in Section 4 we discuss our results. We conclude in Section 5 with a summary of our observations and directions for future work. 2 System Description The SAIL-GRS system is based on a widely used approach in information retrieval and document indexing, the TF-IDF measure. TF-IDF is 508 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 508–511, Dublin, Ireland, August 23-24, 2014. an approach that has found numerous applications in information management applications, such as document keyword extraction, (e.g., Dillon and Gray (1983)), document clustering, summarisation, (e.g., Gong and Liu (2001)), event clustering, (e.g., De Smet and Moens (2013)). In dialogue systems, TF-IDF has been used, among other applications, for discovering local coherence (Gandhe and Traum, 2007) and for acquiring predicate-argument rule fragments in an open domain, information extraction-based spoken dialogue system (Yoshino et al., 2011). In their approach, Yoshino et al. (2011) use the TF-IDF measure to determine the importance of a given word for a given domain or topic, so as to select the most salient predicate-argument structure rule pat</context>
</contexts>
<marker>Dillon, Gray, 1983</marker>
<rawString>Martin Dillon and Ann S. Gray. 1983. FASIT: A fully automatic syntactically based indexing system. Journal of the American Society forInformation Science, 34(2):99–108.</rawString>
</citation>
<citation valid="false">
<authors>
<author>of per rule Precision P</author>
<author>R Recall</author>
<author>F F-score</author>
</authors>
<title>In the grey column, P,,,, R,,,, and F,,, stand for the weighted average of the per rule precision, recall and F-score respectively, as defined in Equ.</title>
<volume>1</volume>
<marker>P, Recall, F-score, </marker>
<rawString>of per rule Precision P, Recall R, and F-score F. In the grey column, P,,,, R,,,, and F,,, stand for the weighted average of the per rule precision, recall and F-score respectively, as defined in Equ. 1 and 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sudeep Gandhe</author>
<author>David Traum</author>
</authors>
<title>First steps towards dialogue modelling from an un-annotated human-human corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fifth IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems,</booktitle>
<pages>22--27</pages>
<contexts>
<context position="4108" citStr="Gandhe and Traum, 2007" startWordPosition="613" endWordPosition="616">ach in information retrieval and document indexing, the TF-IDF measure. TF-IDF is 508 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 508–511, Dublin, Ireland, August 23-24, 2014. an approach that has found numerous applications in information management applications, such as document keyword extraction, (e.g., Dillon and Gray (1983)), document clustering, summarisation, (e.g., Gong and Liu (2001)), event clustering, (e.g., De Smet and Moens (2013)). In dialogue systems, TF-IDF has been used, among other applications, for discovering local coherence (Gandhe and Traum, 2007) and for acquiring predicate-argument rule fragments in an open domain, information extraction-based spoken dialogue system (Yoshino et al., 2011). In their approach, Yoshino et al. (2011) use the TF-IDF measure to determine the importance of a given word for a given domain or topic, so as to select the most salient predicate-argument structure rule patterns from their corpus. In our implementation for spoken dialogue system grammar induction, rule constituent frequency (CF) and inverse rule frequency (IRF) measures are used for estimating lexical and semantic similarity of candidate grammar r</context>
</contexts>
<marker>Gandhe, Traum, 2007</marker>
<rawString>Sudeep Gandhe and David Traum. 2007. First steps towards dialogue modelling from an un-annotated human-human corpus. In Proceedings of the Fifth IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems, pages 22–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01,</booktitle>
<pages>pages</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3928" citStr="Gong and Liu (2001)" startWordPosition="584" endWordPosition="587">ur results. We conclude in Section 5 with a summary of our observations and directions for future work. 2 System Description The SAIL-GRS system is based on a widely used approach in information retrieval and document indexing, the TF-IDF measure. TF-IDF is 508 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 508–511, Dublin, Ireland, August 23-24, 2014. an approach that has found numerous applications in information management applications, such as document keyword extraction, (e.g., Dillon and Gray (1983)), document clustering, summarisation, (e.g., Gong and Liu (2001)), event clustering, (e.g., De Smet and Moens (2013)). In dialogue systems, TF-IDF has been used, among other applications, for discovering local coherence (Gandhe and Traum, 2007) and for acquiring predicate-argument rule fragments in an open domain, information extraction-based spoken dialogue system (Yoshino et al., 2011). In their approach, Yoshino et al. (2011) use the TF-IDF measure to determine the importance of a given word for a given domain or topic, so as to select the most salient predicate-argument structure rule patterns from their corpus. In our implementation for spoken dialogu</context>
</contexts>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’01, pages 19–25, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elias Iosif</author>
<author>Alexandros Potamianos</author>
</authors>
<title>A softclustering algorithm for automatic induction of semantic classes.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th Annual Conference of the International Speech Communication Association,</booktitle>
<pages>1609--1612</pages>
<publisher>ISCA.</publisher>
<contexts>
<context position="1971" citStr="Iosif and Potamianos, 2007" startWordPosition="288" endWordPosition="291"> are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisition of: (i) Low-level rules These are rules defining domain-specific entities, such as names of locations, hotels, airports, e.g. CountryName: “USA”, Date: “July 15th, 2014”, CardType: “VISA” and other common domain multi-word expressions, e.g. DoYouKnowQ: “do you know”. (ii) High-level rules These are larger, frame-like rule patterns which contain as semantic slot fillers multi-word entities identified by low-level rules. For example: DirectionsQ: “&lt;DoYouKnowQ&gt; &lt;where&gt; the &lt;MuseumName&gt; is located”, ExpressionCardProblem: “my &lt;CardType&gt; has expired”. The shared task of Grammar In</context>
</contexts>
<marker>Iosif, Potamianos, 2007</marker>
<rawString>Elias Iosif and Alexandros Potamianos. 2007. A softclustering algorithm for automatic induction of semantic classes. In Proceedings of the 8th Annual Conference of the International Speech Communication Association, pages 1609–1612. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helen M Meng</author>
<author>Kai-Chung Siu</author>
</authors>
<title>Semiautomatic acquisition of semantic structures for understanding domain-specific natural language queries.</title>
<date>2002</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="1557" citStr="Meng and Siu, 2002" startWordPosition="228" endWordPosition="231">ast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisition of: (i) Low-level rules These are rules defining domain-specific entities, such as names of locations, hotels, airports, e.g. CountryName: “USA”, Date: “July 15th, 2014</context>
</contexts>
<marker>Meng, Siu, 2002</marker>
<rawString>Helen M. Meng and Kai-Chung Siu. 2002. Semiautomatic acquisition of semantic structures for understanding domain-specific natural language queries. IEEE Transactions on Knowledge and Data Engineering, 14(1):172–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew N Pargellis</author>
<author>Eric Fosler-Lussier</author>
<author>Alexandros Potamianos</author>
<author>Chin-Hui Lee</author>
</authors>
<title>Metrics for measuring domain independence of semantic classes.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th European Conference on Speech Communication and Technology,</booktitle>
<pages>447--450</pages>
<publisher>ISCA.</publisher>
<contexts>
<context position="1537" citStr="Pargellis et al., 2001" startWordPosition="224" endWordPosition="227">akes it quite easy and fast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisition of: (i) Low-level rules These are rules defining domain-specific entities, such as names of locations, hotels, airports, e.g. CountryName: “USA”, Da</context>
</contexts>
<marker>Pargellis, Fosler-Lussier, Potamianos, Lee, 2001</marker>
<rawString>Andrew N. Pargellis, Eric Fosler-Lussier, Alexandros Potamianos, and Chin-Hui Lee. 2001. Metrics for measuring domain independence of semantic classes. In Proceedings of the 7th European Conference on Speech Communication and Technology, pages 447–450. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: A natural language system for spoken language applications.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="1401" citStr="Seneff, 1992" startWordPosition="206" endWordPosition="207">e in three different domains, travel, tourism and finance and in the travel domain, for Greek. The simplicity of our approach makes it quite easy and fast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisition of: (i) Low-</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Stephanie Seneff. 1992. TINA: A natural language system for spoken language applications. Computational Linguistics, 18(1):61–86, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Ward</author>
</authors>
<title>The CMU air travel information service: Understanding spontaneous speech.</title>
<date>1990</date>
<booktitle>In Speech and Natural Language: Proceedings of a Workshop Held at Hidden</booktitle>
<pages>127--129</pages>
<location>Valley, Pennsylvania,</location>
<contexts>
<context position="1386" citStr="Ward, 1990" startWordPosition="204" endWordPosition="205">lish language in three different domains, travel, tourism and finance and in the travel domain, for Greek. The simplicity of our approach makes it quite easy and fast to implement irrespective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisiti</context>
</contexts>
<marker>Ward, 1990</marker>
<rawString>Wayne Ward. 1990. The CMU air travel information service: Understanding spontaneous speech. In Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania, pages 127–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koichiro Yoshino</author>
<author>Shinsuke Mori</author>
<author>Tatsuya Kawahara</author>
</authors>
<title>Spoken dialogue system based on information extraction using similarity of predicate argument structures.</title>
<date>2011</date>
<booktitle>In Proceedings of the SIGDIAL 2011 Conference,</booktitle>
<pages>59--66</pages>
<contexts>
<context position="1579" citStr="Yoshino et al., 2011" startWordPosition="232" endWordPosition="235">espective of language and domain. The results show that the SAIL-GRS system performs quite well in all three domains and in both languages. 1 Introduction Spoken dialogue systems typically rely on grammars which define the semantic frames and respective fillers in dialogue scenarios (Chen et al., 2013). Such systems are tailored for specific domains for which the respective grammars are mostly manually developed (Ward, 1990; Seneff, 1992). In order to address this issue, numerous current approaches attempt to infer these grammar rules automatically (Pargellis et al., 2001; Meng and Siu, 2002; Yoshino et al., 2011; Chen et al., 2013). The acquisition of grammar rules for spoken language systems is defined as a task comprising This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http: //creativecommons.org/licenses/by/4.0/ of two subtasks (Meng and Siu, 2002; Iosif and Potamianos, 2007), the acquisition of: (i) Low-level rules These are rules defining domain-specific entities, such as names of locations, hotels, airports, e.g. CountryName: “USA”, Date: “July 15th, 2014”, CardType: “VISA” an</context>
<context position="4254" citStr="Yoshino et al., 2011" startWordPosition="634" endWordPosition="637">uation (SemEval 2014), pages 508–511, Dublin, Ireland, August 23-24, 2014. an approach that has found numerous applications in information management applications, such as document keyword extraction, (e.g., Dillon and Gray (1983)), document clustering, summarisation, (e.g., Gong and Liu (2001)), event clustering, (e.g., De Smet and Moens (2013)). In dialogue systems, TF-IDF has been used, among other applications, for discovering local coherence (Gandhe and Traum, 2007) and for acquiring predicate-argument rule fragments in an open domain, information extraction-based spoken dialogue system (Yoshino et al., 2011). In their approach, Yoshino et al. (2011) use the TF-IDF measure to determine the importance of a given word for a given domain or topic, so as to select the most salient predicate-argument structure rule patterns from their corpus. In our implementation for spoken dialogue system grammar induction, rule constituent frequency (CF) and inverse rule frequency (IRF) measures are used for estimating lexical and semantic similarity of candidate grammar rules to a seed set of rule pattern instances. As illustrated in Table 1, the SAIL-GRS algorithm has two main steps, the training stage and the rul</context>
</contexts>
<marker>Yoshino, Mori, Kawahara, 2011</marker>
<rawString>Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawahara. 2011. Spoken dialogue system based on information extraction using similarity of predicate argument structures. In Proceedings of the SIGDIAL 2011 Conference, pages 59–66.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>