<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000363">
<title confidence="0.996273">
KCDC: Word Sense Induction by Using Grammatical Dependencies and
Sentence Phrase Structure
</title>
<author confidence="0.976438">
Roman Kern
</author>
<affiliation confidence="0.805305">
Know-Center
</affiliation>
<address confidence="0.241351">
Graz, Austria
</address>
<email confidence="0.324787">
rkern@know-center.at
</email>
<author confidence="0.599551">
Markus Muhr
</author>
<affiliation confidence="0.537665">
Know-Center
</affiliation>
<address confidence="0.220688">
Graz, Austria
</address>
<email confidence="0.336669">
mmuhr@know-center.at
</email>
<author confidence="0.94291">
Michael Granitzer
</author>
<affiliation confidence="0.9346905">
Graz University of Technology,
Know-Center
</affiliation>
<address confidence="0.436849">
Graz, Austria
</address>
<email confidence="0.734964">
mgrani@know-center.at
</email>
<sectionHeader confidence="0.993968" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996595">
Word sense induction and discrimination
(WSID) identifies the senses of an am-
biguous word and assigns instances of this
word to one of these senses. We have build
a WSID system that exploits syntactic and
semantic features based on the results of
a natural language parser component. To
achieve high robustness and good general-
ization capabilities, we designed our sys-
tem to work on a restricted, but grammat-
ically rich set of features. Based on the
results of the evaluations our system pro-
vides a promising performance and robust-
ness.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999987294117647">
The goal of the SemEval-2 word sense induc-
tion and discrimination task, see Manandhar et
al. (2010), is to identify the senses of ambiguous
nouns and verbs in an unsupervised manner and to
label unseen instances of these words with one of
the induced senses. The most common approach
towards this task is to apply clustering or graph
partitioning algorithms on a representation of the
words that surround an ambiguous target word, see
for example Niu et al. (2007) and Pedersen (2007).
We followed this approach by employing a cluster-
ing algorithm to detect the individual senses, but
focused on generating feature sets different to the
mainstream approach. Our feature sets utilize the
output of a linguistic processing pipeline that cap-
tures the syntax and semantics of sentence parts
closely related with the target word.
</bodyText>
<sectionHeader confidence="0.967434" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.999904277777778">
The base of our system is to apply a parser on the
sentence in which the target word occurs. Contex-
tual information, for example the sentences sur-
rounding the target sentence, are currently not
exploited by our system. To analyze the sen-
tences we applied the Stanford Parser (Version
1.6.2), which is based on lexicalized probabilis-
tic context free grammars, see Klein and Man-
ning (2003). This open-source parser not only ex-
tracts the phrase structure of a given sentence, but
also provides a list of so called grammatical rela-
tions (typed dependencies), see de Marneffe et al.
(2006). These relations reflect the dependencies
between the words within the sentence, for exam-
ple the relationship between the verb and the sub-
ject. See Chen et al. (2009) for an application of
grammatical dependencies for word sense disam-
biguation.
</bodyText>
<subsectionHeader confidence="0.996222">
2.1 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.996649875">
The phrase structure and the grammatical depen-
dencies are sources for the feature extraction stage.
To illustrate the result of the parser and feature ex-
traction stages we use an example sentence, where
the target word is the verb “file”:
Afterward, I watched as a butt-ton of good, but
misguided people filed out of the theater , and
immediately lit up a smoke.
</bodyText>
<subsectionHeader confidence="0.96549">
2.1.1 Grammatical Dependency Features
</subsectionHeader>
<bodyText confidence="0.9999391875">
The Stanford Parser provides 55 different gram-
matical dependency types. Figure 2 depicts the list
of the grammatical dependencies identified by the
Stanford Parser for the example sentence. Only a
limited subset of these dependencies are selected
to build the grammatical feature set. This subset
has been defined based on preliminary tests on the
trial dataset. For verbs only dependencies that rep-
resent the association of a verb with prepositional
modifiers and phrasal verb particles are selected
(prep, prepc, prt). If the verb is not associated
with a preposition or particle, a synthetic “miss-
ing” feature is added instead (!prep, !prt). For
nouns the selected dependencies are the preposi-
tions (for head nouns that are the object of a prepo-
sition) and noun compound modifiers (pobj, nn).
</bodyText>
<page confidence="0.965852">
351
</page>
<note confidence="0.6955275">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 351–354,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9884606">
Figure 1: Phrase tree of the example sentence. The noun phrase “misguided people” is connected to the
target word via the nsubj dependency and the phrase “the theater” is associated with the target verb via
the prep and pobj dependencies.
Figure 2: List of grammatical dependencies as de-
tected by the Stanford Parser.
</figureCaption>
<bodyText confidence="0.995951090909091">
If the noun is associated with a verb the grammati-
cal dependencies of this verb are also added to the
feature set.
The name of the dependency and the word (i.e.
preposition or particle) are used to construct the
grammatical feature. The different features are
weighted. The weights have been derived from
their frequencies within the trial dataset and listed
in table 1. For the example sentence the extracted
grammatical features are:
’out’, ’of’, prep, prt
</bodyText>
<subsectionHeader confidence="0.917122">
2.1.2 Phrase Term Features
</subsectionHeader>
<bodyText confidence="0.967369838709677">
The second set of features are generated from the
sentence phrase structure. In figure 1 the parse tree
for the example sentence is depicted.
Again we tried to keep the feature set as small
as possible. Starting with the target word only
phrases that are directly associated with the am-
biguous word are selected. To identify these
phrases the grammatical dependencies are ex-
ploited. For nouns as target words the associated
verb is searched at first. Given a verb the phrases
containing the head noun of a subject or object re-
lationship are identified. If the verb is accompa-
Feature Weight
prepc, prt, nn, pobj 0.9
prep 0.45
!prep, !prt 0.5
’prepositions’, ’particles’ 0.97
Table 1: Weights of the grammatical features,
which were derived from their distribution within
the trial dataset.
nied by a preposition, the phrase carrying the ob-
ject of the preposition is also added. All nouns and
adjectives from these these phrases are then col-
lected. The phrase words together with the verb,
prepositions and particles are lemmatized using
tools also provided by the Stanford Parser project.
The weights of the phrase term features are
based on the frequency of the words within the
training dataset, where N is the total number of
sentences and Nf is the number of sentences in
which the lemmatized phrase term occurs in:
</bodyText>
<equation confidence="0.994688">
weightf = log( N
Nf + 1) + 1 (1)
</equation>
<bodyText confidence="0.994766666666667">
In our example sentence the extracted phrase
term features are:
of, misguided, file, theater, people, out
</bodyText>
<subsectionHeader confidence="0.998954">
2.2 Phrase Term Expansion
</subsectionHeader>
<bodyText confidence="0.996105125">
The feature space of the phrase terms is expected
to be very sparse. Additionally different phrase
terms may have similar semantics. Therefore the
phrase terms are optionally expanded with asso-
ciated terms, where semantically similar terms
should be associated with the same terms.
To calculate the statistics for term expansion we
used the training dataset (although other datasets
</bodyText>
<page confidence="0.992634">
352
</page>
<bodyText confidence="0.999504666666667">
would be more suitable for this purpose). The
dataset is split into sentences. Stopwords and
rarely used words, which occur in less than 3 sen-
tences, were removed. The remaining words were
finally lemmatized. For a given phrase term the
top 100 associated terms are used to build the
feature set. The association weight between two
terms is based on the Pointwise Mutual Informa-
tion:
</bodyText>
<equation confidence="0.975420333333333">
2
1 ()
log2(P (tj))
</equation>
<bodyText confidence="0.9703515">
For example the top 10 associated terms for
theater are:
</bodyText>
<construct confidence="0.45864025">
theater.n, movie.n, opera.n,
vaudeville.n, wnxt-abc.n, imax.n,
orpheum.n, pullulate.v, projector.n,
psychomania.n
</construct>
<subsectionHeader confidence="0.992631">
2.3 Sense Induction
</subsectionHeader>
<bodyText confidence="0.999950260869565">
To detect the individual senses within the training
dataset we applied unsupervised machine learning
techniques. For each ambiguous word a matrix
- M|Instances|x|Features |- is created and a clus-
tering algorithm is applied, namely the Growing
k-Means, see Daszykowski et al. (2002). This
algorithm needs the number of clusters and cen-
troids as initialization parameters, where the initial
centroids are calculated using a directed random
seed finder as described in Arthur and Vassilvitskii
(2007). We used the Jensen-Shannon Divergence
function for the grammatical dependency features
and the Cosine Similarity for the phrase term fea-
ture sets as relatedness function.
For each cluster number we re-run the clus-
tering with different random initial centroids (30
times) and for each run we calculate a cluster qual-
ity criterion. The overall cluster quality criterion is
the mean of all feature quality criteria, which are
calculated based on the set of clusters the feature
occurs in - Cf - the number of instances of each
cluster - Nc - and the number of instances within
a cluster where the feature occurs in - Nc,f:
</bodyText>
<equation confidence="0.985201333333333">
FQCf = weightf Nc,f |Cf
|∗ EccCf Nc (3 )
QCrun = FQCf (4)
</equation>
<bodyText confidence="0.998872285714286">
The cluster quality criterion is calculated for
each run and the combination of the mean and
standard deviations are then used to calculate a
stability criterion to detect the number of clusters,
which is based on the intuition that the correct
cluster count yields the lowest variation of QC
values:
</bodyText>
<equation confidence="0.997096">
SCk = mean(QC)(5)
stdev(QC)
</equation>
<bodyText confidence="0.999959428571429">
Starting with two clusters the number of clusters
is incremented until the stability criterion starts to
decline. For the cluster number with the highest
stability criterion the run with the highest qual-
ity criterion is selected as final clustering solution.
The result of the sense induction processing is a
list of centroids for the identified clusters.
</bodyText>
<subsectionHeader confidence="0.997684">
2.4 Sense Assignment
</subsectionHeader>
<bodyText confidence="0.9999895">
The final processing step is to assign an instance
of an ambiguous word to one of the pre-calculated
senses. The sentence with the target word is pro-
cessed exactly like the training sentences to gener-
ate a set of features. Finally the word is assigned
to the sense cluster with the maximum relatedness.
</bodyText>
<sectionHeader confidence="0.998495" genericHeader="method">
3 System Configurations &amp; Results
</sectionHeader>
<bodyText confidence="0.999888620689655">
Our system can be configured to use a combina-
tion of feature sets for the word sense induction
and discrimination calculations: a) KCDC-GD:
Grammatical dependency features, b) KCDC-PT:
Phrase terms features, c) KCDC-PC: Expanded
phrase term features, d) KCDC-PCGD: All train-
ing sentences are first processed by using the ex-
panded phrase term features and then by using
the grammatical dependency features with an ad-
ditional feature that encodes the cluster id found
by the phrase features.
In the evaluation we also submitted multiple
runs of the same configuration1 to assess the in-
fluence of the random initialization of the cluster-
ing algorithm. Judging from the results the ran-
dom seeding has no pronounced impact and it in-
fluence should decrease when the number of clus-
tering runs for each cluster number is increased.
All configurations found on average about 3
senses for target words in the test set (2.8 for verbs,
3.3 for nouns), with exception of the KCDC-PT
configuration which identified only 1.5 senses on
average. In the gold standard the number of senses
for verbs is 3.12 and for nouns 4.46, which shows
that the stability criterion tends to underestimate
the number of senses slightly.
To compare the performance of the differ-
ent configurations, one can use the average rank
within the evaluation result lists. Judging from the
</bodyText>
<footnote confidence="0.999446">
1labeled KCDC-GD-2, KCDC-GDC for configuration ’a’
and KCDC-PC-2 for the configuration ’c’
</footnote>
<equation confidence="0.996965666666667">
weightpmi(ti, tj) =
P(ti|tj))
log2( P(tj
</equation>
<page confidence="0.996019">
353
</page>
<bodyText confidence="0.999955264705882">
rankings, the configurations that utilize the gram-
matical dependencies and the expanded phrase
terms provide similar performance. The config-
uration that takes the phrase terms directly as fea-
tures comes in last, which is expected due to the
sparse nature of the feature representation and the
low number of detected senses.
Comparing the performance of our system with
the two baselines shows that our system did out-
perform the random baseline in all evaluation runs
and the most frequent baseline (MFS) in all runs
with the exception of the F-Score based unsuper-
vised evaluation, where the MFS baseline has not
been beaten by any system. Although none of our
submitted configurations was ranked first in any of
the evaluations, their ranking was still better than
average, with the exception of the KCDC-PT con-
figuration.
Another observation that can be made is the dif-
ference in performance between nouns and verbs.
Our system, especially the grammatical depen-
dency based configurations, is tailored towards
verbs. Therefore the better performance of verbs
in the evaluation is in line with the expectations.
When looking at the results of the individual tar-
get words one can notice that for a set of words
the quality of the sense detection is above average.
For 16 of the 100 words a V-Measure of more than
30% in at least one configuration was achieved
(average: 7.8%)2. This can be seen as indicator
that our selection of features is effective for a spe-
cific group of words. For the remaining words an
according feature set has to be developed in future
work.
</bodyText>
<sectionHeader confidence="0.999492" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999903076923077">
For the SemEval 2010 word sense induction and
discrimination task we have tried to build a system
that uses a minimal amount of information while
still providing a competitive performance. This
system contains a parser component to analyze the
phrase structure of a sentence and the grammat-
ical dependencies between words. The extracted
features are then clustered to detect the senses of
ambiguous words. In the evaluation runs our sys-
tem did demonstrate a satisfying performance for
a number of words.
The design of our system offers a wide range
of possible enhancements. For example the inte-
</bodyText>
<footnote confidence="0.825783">
2The best performing target words are: root.v,
presume.v, figure.v, weigh.v, cheat.v
</footnote>
<bodyText confidence="0.9995825">
gration of preposition disambiguation and noun-
phrase co-reference resolution could help to fur-
ther improve the word sense discrimination effec-
tiveness.
</bodyText>
<sectionHeader confidence="0.999186" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.768005625">
The Know-Center is funded within the Austrian COMET
Program - Competence Centers for Excellent Technologies -
under the auspices of the Austrian Federal Ministry of Trans-
port, Innovation and Technology, the Austrian Federal Min-
istry of Economy, Family and Youth and by the State of
Styria. COMET is managed by the Austrian Research Pro-
motion Agency FFG. Results are partially funded by the EU-
ROSTARS project 4811 MAKIN’IT.
</reference>
<sectionHeader confidence="0.968135" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99939827027027">
D. Arthur and S. Vassilvitskii. 2007. k-means++:
The advantages of careful seeding. In Proceedings
of the eighteenth annual ACM-SIAM symposium on
Discrete algorithms, page 10271035. Society for In-
dustrial and Applied Mathematics Philadelphia, PA,
USA.
Ping Chen, Wei Ding, Chris Bowes, and David Brown.
2009. A fully unsupervised word sense disambigua-
tion method using dependency knowledge. Human
Language Technology Conference.
M Daszykowski, B Walczak, and D L Massart. 2002.
On the optimal partitioning of data with K-means,
growing K-means, neural gas, and growing neural
gas. Journal of chemical information and computer
sciences, 42(6):1378–89.
M.C. de Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In LREC 2006.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. Proceedings of the 41st
Annual Meeting on Association for Computational
Linguistics - ACL ’03, pages 423–430.
Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dli-
gach, and Sameer S. Pradhan. 2010. SemEval-
2010 Task 14: Word Sense Induction &amp; Disam-
biguation. In Proceedings of SemEval-2, Uppsala,
Sweden, ACL.
Zheng-yu Niu, Dong-hong Ji, and Chew-lim Tan.
2007. I2R: Three Systems for Word Sense Discrim-
ination, Chinese Word Sense Disambiguation, and
English Word Sense Disambiguation. In Proceed-
ings of the 4th International Workshop on Semantic
Evaluations. ACL.
T. Pedersen. 2007. Umnd2: Senseclusters applied to
the sense induction task of senseval-4. In Proceed-
ings of the 4th International Workshop on Semantic
Evaluations. ACL.
</reference>
<page confidence="0.999136">
354
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.418488">
<title confidence="0.99696">KCDC: Word Sense Induction by Using Grammatical Dependencies and Sentence Phrase Structure</title>
<author confidence="0.999985">Roman Kern</author>
<affiliation confidence="0.918804">Know-Center</affiliation>
<address confidence="0.997397">Graz, Austria</address>
<email confidence="0.994749">rkern@know-center.at</email>
<author confidence="0.999708">Markus Muhr</author>
<affiliation confidence="0.873277">Know-Center</affiliation>
<address confidence="0.988698">Graz, Austria</address>
<email confidence="0.996041">mmuhr@know-center.at</email>
<author confidence="0.999376">Michael Granitzer</author>
<affiliation confidence="0.999962">Graz University of Technology,</affiliation>
<address confidence="0.7935575">Know-Center Graz, Austria</address>
<email confidence="0.995882">mgrani@know-center.at</email>
<abstract confidence="0.993933">Word sense induction and discrimination (WSID) identifies the senses of an ambiguous word and assigns instances of this word to one of these senses. We have build a WSID system that exploits syntactic and semantic features based on the results of a natural language parser component. To achieve high robustness and good generalization capabilities, we designed our system to work on a restricted, but grammatically rich set of features. Based on the results of the evaluations our system provides a promising performance and robustness.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>The Know-Center is funded within the Austrian COMET Program - Competence Centers for Excellent Technologies -under the auspices of the Austrian Federal Ministry of Transport, Innovation and Technology, the Austrian Federal Ministry of Economy, Family and Youth and by the State of Styria. COMET is managed by the Austrian Research Promotion Agency FFG. Results are partially funded by the EUROSTARS project 4811 MAKIN’IT.</title>
<marker></marker>
<rawString>The Know-Center is funded within the Austrian COMET Program - Competence Centers for Excellent Technologies -under the auspices of the Austrian Federal Ministry of Transport, Innovation and Technology, the Austrian Federal Ministry of Economy, Family and Youth and by the State of Styria. COMET is managed by the Austrian Research Promotion Agency FFG. Results are partially funded by the EUROSTARS project 4811 MAKIN’IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Arthur</author>
<author>S Vassilvitskii</author>
</authors>
<title>k-means++: The advantages of careful seeding.</title>
<date>2007</date>
<booktitle>In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms,</booktitle>
<pages>10271035</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="7708" citStr="Arthur and Vassilvitskii (2007)" startWordPosition="1231" endWordPosition="1234">theater.n, movie.n, opera.n, vaudeville.n, wnxt-abc.n, imax.n, orpheum.n, pullulate.v, projector.n, psychomania.n 2.3 Sense Induction To detect the individual senses within the training dataset we applied unsupervised machine learning techniques. For each ambiguous word a matrix - M|Instances|x|Features |- is created and a clustering algorithm is applied, namely the Growing k-Means, see Daszykowski et al. (2002). This algorithm needs the number of clusters and centroids as initialization parameters, where the initial centroids are calculated using a directed random seed finder as described in Arthur and Vassilvitskii (2007). We used the Jensen-Shannon Divergence function for the grammatical dependency features and the Cosine Similarity for the phrase term feature sets as relatedness function. For each cluster number we re-run the clustering with different random initial centroids (30 times) and for each run we calculate a cluster quality criterion. The overall cluster quality criterion is the mean of all feature quality criteria, which are calculated based on the set of clusters the feature occurs in - Cf - the number of instances of each cluster - Nc - and the number of instances within a cluster where the feat</context>
</contexts>
<marker>Arthur, Vassilvitskii, 2007</marker>
<rawString>D. Arthur and S. Vassilvitskii. 2007. k-means++: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, page 10271035. Society for Industrial and Applied Mathematics Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ping Chen</author>
<author>Wei Ding</author>
<author>Chris Bowes</author>
<author>David Brown</author>
</authors>
<title>A fully unsupervised word sense disambiguation method using dependency knowledge. Human Language Technology Conference.</title>
<date>2009</date>
<contexts>
<context position="2460" citStr="Chen et al. (2009)" startWordPosition="388" endWordPosition="391">sentences surrounding the target sentence, are currently not exploited by our system. To analyze the sentences we applied the Stanford Parser (Version 1.6.2), which is based on lexicalized probabilistic context free grammars, see Klein and Manning (2003). This open-source parser not only extracts the phrase structure of a given sentence, but also provides a list of so called grammatical relations (typed dependencies), see de Marneffe et al. (2006). These relations reflect the dependencies between the words within the sentence, for example the relationship between the verb and the subject. See Chen et al. (2009) for an application of grammatical dependencies for word sense disambiguation. 2.1 Feature Extraction The phrase structure and the grammatical dependencies are sources for the feature extraction stage. To illustrate the result of the parser and feature extraction stages we use an example sentence, where the target word is the verb “file”: Afterward, I watched as a butt-ton of good, but misguided people filed out of the theater , and immediately lit up a smoke. 2.1.1 Grammatical Dependency Features The Stanford Parser provides 55 different grammatical dependency types. Figure 2 depicts the list</context>
</contexts>
<marker>Chen, Ding, Bowes, Brown, 2009</marker>
<rawString>Ping Chen, Wei Ding, Chris Bowes, and David Brown. 2009. A fully unsupervised word sense disambiguation method using dependency knowledge. Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Daszykowski</author>
<author>B Walczak</author>
<author>D L Massart</author>
</authors>
<title>On the optimal partitioning of data with K-means, growing K-means, neural gas, and growing neural gas. Journal of chemical information and computer sciences,</title>
<date>2002</date>
<pages>42--6</pages>
<contexts>
<context position="7492" citStr="Daszykowski et al. (2002)" startWordPosition="1199" endWordPosition="1202">ated terms are used to build the feature set. The association weight between two terms is based on the Pointwise Mutual Information: 2 1 () log2(P (tj)) For example the top 10 associated terms for theater are: theater.n, movie.n, opera.n, vaudeville.n, wnxt-abc.n, imax.n, orpheum.n, pullulate.v, projector.n, psychomania.n 2.3 Sense Induction To detect the individual senses within the training dataset we applied unsupervised machine learning techniques. For each ambiguous word a matrix - M|Instances|x|Features |- is created and a clustering algorithm is applied, namely the Growing k-Means, see Daszykowski et al. (2002). This algorithm needs the number of clusters and centroids as initialization parameters, where the initial centroids are calculated using a directed random seed finder as described in Arthur and Vassilvitskii (2007). We used the Jensen-Shannon Divergence function for the grammatical dependency features and the Cosine Similarity for the phrase term feature sets as relatedness function. For each cluster number we re-run the clustering with different random initial centroids (30 times) and for each run we calculate a cluster quality criterion. The overall cluster quality criterion is the mean of</context>
</contexts>
<marker>Daszykowski, Walczak, Massart, 2002</marker>
<rawString>M Daszykowski, B Walczak, and D L Massart. 2002. On the optimal partitioning of data with K-means, growing K-means, neural gas, and growing neural gas. Journal of chemical information and computer sciences, 42(6):1378–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C de Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In LREC</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M.C. de Marneffe, B. MacCartney, and C.D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - ACL ’03,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="2096" citStr="Klein and Manning (2003)" startWordPosition="326" endWordPosition="330"> feature sets different to the mainstream approach. Our feature sets utilize the output of a linguistic processing pipeline that captures the syntax and semantics of sentence parts closely related with the target word. 2 System Overview The base of our system is to apply a parser on the sentence in which the target word occurs. Contextual information, for example the sentences surrounding the target sentence, are currently not exploited by our system. To analyze the sentences we applied the Stanford Parser (Version 1.6.2), which is based on lexicalized probabilistic context free grammars, see Klein and Manning (2003). This open-source parser not only extracts the phrase structure of a given sentence, but also provides a list of so called grammatical relations (typed dependencies), see de Marneffe et al. (2006). These relations reflect the dependencies between the words within the sentence, for example the relationship between the verb and the subject. See Chen et al. (2009) for an application of grammatical dependencies for word sense disambiguation. 2.1 Feature Extraction The phrase structure and the grammatical dependencies are sources for the feature extraction stage. To illustrate the result of the pa</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - ACL ’03, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suresh Manandhar</author>
<author>Ioannis P Klapaftis</author>
<author>Dmitriy Dligach</author>
<author>Sameer S Pradhan</author>
</authors>
<date>2010</date>
<booktitle>SemEval2010 Task 14: Word Sense Induction &amp; Disambiguation. In Proceedings of SemEval-2,</booktitle>
<location>Uppsala, Sweden, ACL.</location>
<contexts>
<context position="965" citStr="Manandhar et al. (2010)" startWordPosition="140" endWordPosition="143">crimination (WSID) identifies the senses of an ambiguous word and assigns instances of this word to one of these senses. We have build a WSID system that exploits syntactic and semantic features based on the results of a natural language parser component. To achieve high robustness and good generalization capabilities, we designed our system to work on a restricted, but grammatically rich set of features. Based on the results of the evaluations our system provides a promising performance and robustness. 1 Introduction The goal of the SemEval-2 word sense induction and discrimination task, see Manandhar et al. (2010), is to identify the senses of ambiguous nouns and verbs in an unsupervised manner and to label unseen instances of these words with one of the induced senses. The most common approach towards this task is to apply clustering or graph partitioning algorithms on a representation of the words that surround an ambiguous target word, see for example Niu et al. (2007) and Pedersen (2007). We followed this approach by employing a clustering algorithm to detect the individual senses, but focused on generating feature sets different to the mainstream approach. Our feature sets utilize the output of a </context>
</contexts>
<marker>Manandhar, Klapaftis, Dligach, Pradhan, 2010</marker>
<rawString>Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dligach, and Sameer S. Pradhan. 2010. SemEval2010 Task 14: Word Sense Induction &amp; Disambiguation. In Proceedings of SemEval-2, Uppsala, Sweden, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng-yu Niu</author>
<author>Dong-hong Ji</author>
<author>Chew-lim Tan</author>
</authors>
<title>I2R: Three Systems for Word Sense Discrimination, Chinese Word Sense Disambiguation, and English Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations. ACL.</booktitle>
<contexts>
<context position="1330" citStr="Niu et al. (2007)" startWordPosition="202" endWordPosition="205">t grammatically rich set of features. Based on the results of the evaluations our system provides a promising performance and robustness. 1 Introduction The goal of the SemEval-2 word sense induction and discrimination task, see Manandhar et al. (2010), is to identify the senses of ambiguous nouns and verbs in an unsupervised manner and to label unseen instances of these words with one of the induced senses. The most common approach towards this task is to apply clustering or graph partitioning algorithms on a representation of the words that surround an ambiguous target word, see for example Niu et al. (2007) and Pedersen (2007). We followed this approach by employing a clustering algorithm to detect the individual senses, but focused on generating feature sets different to the mainstream approach. Our feature sets utilize the output of a linguistic processing pipeline that captures the syntax and semantics of sentence parts closely related with the target word. 2 System Overview The base of our system is to apply a parser on the sentence in which the target word occurs. Contextual information, for example the sentences surrounding the target sentence, are currently not exploited by our system. To</context>
</contexts>
<marker>Niu, Ji, Tan, 2007</marker>
<rawString>Zheng-yu Niu, Dong-hong Ji, and Chew-lim Tan. 2007. I2R: Three Systems for Word Sense Discrimination, Chinese Word Sense Disambiguation, and English Word Sense Disambiguation. In Proceedings of the 4th International Workshop on Semantic Evaluations. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
</authors>
<title>Umnd2: Senseclusters applied to the sense induction task of senseval-4.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations. ACL.</booktitle>
<contexts>
<context position="1350" citStr="Pedersen (2007)" startWordPosition="207" endWordPosition="208">et of features. Based on the results of the evaluations our system provides a promising performance and robustness. 1 Introduction The goal of the SemEval-2 word sense induction and discrimination task, see Manandhar et al. (2010), is to identify the senses of ambiguous nouns and verbs in an unsupervised manner and to label unseen instances of these words with one of the induced senses. The most common approach towards this task is to apply clustering or graph partitioning algorithms on a representation of the words that surround an ambiguous target word, see for example Niu et al. (2007) and Pedersen (2007). We followed this approach by employing a clustering algorithm to detect the individual senses, but focused on generating feature sets different to the mainstream approach. Our feature sets utilize the output of a linguistic processing pipeline that captures the syntax and semantics of sentence parts closely related with the target word. 2 System Overview The base of our system is to apply a parser on the sentence in which the target word occurs. Contextual information, for example the sentences surrounding the target sentence, are currently not exploited by our system. To analyze the sentenc</context>
</contexts>
<marker>Pedersen, 2007</marker>
<rawString>T. Pedersen. 2007. Umnd2: Senseclusters applied to the sense induction task of senseval-4. In Proceedings of the 4th International Workshop on Semantic Evaluations. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>