<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000114">
<note confidence="0.8610232">
Controlling Lexical Substitution in Computer Text Generationl
Robert Granville
MIT Laboratory for Computer Science
545 Technology Square
Cambridge, Massachusetts 02139
</note>
<sectionHeader confidence="0.912823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99991725">
This report describes Paul. a computer text generation system
designed to create cohesive text through the use of lexical substitutions.
Specifically. this system is designed to deterministically choose between
pronominalization, superordinate substitution, and definite noun phrase
reiteration. The system identities a strength of antecedence recovery for
each of the lexical substitutions, and matches them against the strength
of potential antecedence of each element in the text to select the proper
substitutions for these elements.
</bodyText>
<sectionHeader confidence="0.992191" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999944764705882">
This report describes Paul. a computer text generation system
designed to create cohesive text through the use of lexical substitutions.
Specifically. this system is designed In deterministically choose between
pronominalization. suucrordinate substitution, and definite noun phrase
reiteration. The system identifies a strength of antecedence recovery for
each of the lexical substitutions, and matches them against the strength
of potential antecedenc.e of each element in the text to select the proper
substitutions for these elements.
Paul is a natural language generation program initially developed at
IBM&apos;s Thomas J. Watson Hesearch Center as part of the ongoing Epistle
project [5. 6]. The emphasis of the the work reported here is in the
research of discourse phenomena, the study of cohesion and its effects
on multisentential texts [3, 9]. Paul accepts as input LISP knowledge
structures consisting of case frame ] formalisms representing each
sentence to be generated. These knowledge structures are translated into
English, with the appropriate lexical substitutions being made at this time.
No attempt is made by the system to create these knowledge structures.
</bodyText>
<sectionHeader confidence="0.988007" genericHeader="introduction">
2. Cohesion
</sectionHeader>
<bodyText confidence="0.990911047619048">
The purpose of communication is for one person (the speaker or
writer) to express her thoughts and ideas so that another (the listener or
reader) can understand them. There aie many restrictions placed on the
realization of these thoughts into language so that the listener may
understand. One ot the most important requirements for an utterance is
that it seem to be unified, that it form a text. The theory of text and what
distinguishes it from isolated sentences that is used in Paul is that of
Halliday and Hasan [3j.
One of the items that enhances the unity of text is cohesion.
Cohesion refers to the linguistic phenomena that establish relationships
between sentences, thereby tying them together. There are two major
goals that are accomplished through coliesioil that enhance a passage&apos;s
quality of text. The first is the obvious uesire to avoid unnecessary
repetition. The other goal is to distinguish new information from old, so
that the listener can fully understand what is being said.
(1) The room has a large window. The room has a window
facing east.
{1} appears to he describing two windows, because there is no
device indicating that the window ot the second sentence is the same as
the window of the first sentence. If in fact the speaker merint to describe
the seine window, she must somehow inform the listener that this is
</bodyText>
<footnote confidence="0.87770725">
1
This research was supported (in part) by Office of Naval Research contract
NO0 14-80-C.0505. and (in pair) by National Institutes of Health Grant No, 1 P01 LM
03374.04 from the National Library of Medicine.
</footnote>
<bodyText confidence="0.9678935">
indeed the case. Cohesion is a device that will accomplish this goal.
Cohesion is created when the interpretation of an element is
dependent on the meaning of another. The element in question cannot be
fully understood unto the element it is dependent on is identified. The first
presupposes [3] the second in that it requires for its understanding the
existence of the second. An element of a sentence presupposes the
existence of another when its interpretation requires reference 10
another. Once we can trace these references to their sources, we can
correctly interpret the elements of the sentences.
The very some devices that create these dependencies for
interpretation help distinguish old information from new. If the use of a
cohesive element prebupposes the existence of another reference of the
element for its interpretation, then the listener can be assured that the
other reference exists, and that the element in question can be
understood as old information. &apos;f herefore, that act oT associating
sentences through reference dependencies heips make the text
unambiguous, and cohesion can be seen to be a very important part of
text.
</bodyText>
<sectionHeader confidence="0.903333" genericHeader="method">
3. Lexical Substitution
</sectionHeader>
<bodyText confidence="0.9998393">
In [3]. Halliday and Hasan catalog and discuss many devices used
in English to achieve cohesion. These include reference, substitution
ellipsis, and conjunction. Another family of devices they discuss is known
as lexical substitution. The lexical substitution devices incorporated into
Paul are pronominalization, superorciinate substitution, and definite noun
phrase reiteration.
Superordinate substitution is the replacement of an element with a
noun or phrase that is a more general term for the element. As an
example, consider Figure 1, a sample hierarchy the system uses to
generate sentences.
</bodyText>
<equation confidence="0.353292166666667">
ANIMAL
MAMMAL REPTILE
POSSUM SKUNK TURTLE
POGO HEPZIBAH CHURCH?
Figure la
I. POGO IS A MALE POSSUM.
</equation>
<listItem confidence="0.983308571428571">
2. HEPZIBAH IS A FEMALE SKUNK.
3. CHURCHY IS A MALE TURILE.
4. POSSUMS ARE SMALL, GREY MAMMALS.
5. SKUNKS ARE SMALL. BLACK MAMMALS.
6. TURTLES ARE SMALL, GREEN REPTILES.
7. MAMMALS ARE FURRY ANIMALS.
B. REPTILES ARE SCALED ANIMALS.
</listItem>
<figureCaption confidence="0.809764">
Figure lb: A Sample Hierarchy for Paul
</figureCaption>
<page confidence="0.991373">
381
</page>
<bodyText confidence="0.999679067567568">
In this example. the superoiclinate of Pee30 is POS:31.8.,/, that of
POSSUM is 1iI41,1MAL. and again for MAMMA/ the supei ordinate is
AtVIMAI Superordinates can continue for as long as the hierarchical tree
will suppoit.
The inechenice to performing superordinate suestilikon is fairly
easy. All one ricer Is In no ;5 to ;:feate a list el sone; ordinates by tractile up
the hierarchical lieu. and ;a bilorily f hineSO In [411 lil.S 11Si. However, there
are Several iesues that irust Le addressed to prevent Sr purordioate
subetaution from being anitereieris or teasing elf Â°news connotations.
The erroneous co, motatiuns essair it the list or eupercedinetee is allowed
to extend too long An ex:imeir will make this :seer. Let us as.euine that we
have a !serer dry in writs!) Mere is an (eery O. lie superordinate of
FRED is MAN. for MIN HOLLIN. -11,1fA.1At or HOMAN. and THING for
ANIMAL. therefore. the superortheate liet for r.HED Is MIAN HUMAN
ANIMAL THING). While feteninci to Fred as tea man seems Sac, calling
him the air runt seeins a littre strange. And furthermore. using the animal
or the thing to refer to Fred is actually insulting.
The reason these superordinates have negative connotations is
that there are essential qualities that hi snails pessess that seperate
from other animals. Calling Fred an &amp;quot;animal&amp;quot; implies that he leeks these
qualities. and is trereiore insulting. &amp;quot;Fluinan&amp;quot; sounds se ange because it
is the biellest entry in the sementic hierarchy that exhibits theca qualities.
talking about &amp;quot;the human&amp;quot; eives one the feeling that there are other
creatures in the discourse that aren&apos;t human.
Paul is sensitive to the connotations that are possible through
superordinate substitution. The- system identifies an essential quality,
usually intelligence. which acts as a block far further superordinate
substitution. If the item to be replaced with a superordinate has the
property of intelligence, either directly or through semantic inheritance, a
supeterdinate list is made only of !hove entries that have themselves the
quality of intelheence. atria&amp;quot; either directly or through inheritance. If the
item doesi it have intelligence the list is allowed to extend as far as the
hierarchical entries will allow. Once the proper list of superordinates ix
established, Paul randomly chooses one, preventing repetition by
remembering previous choices.
The other problem with superordinate substitution is that it may
introduce einbiguity. Again consider Figure 1. If we wanted to perform a
superordinate substitution for POGO. we would have the superordinate
list (POSSUM MAMMAL ANIMAL) to choose from. But ilEPZIBAH is also a
mammal, so the mammal could refer to either POGO or 11CPZIBAH. And
not only are both P000 and HEPZIBAll animals, but so is 0111.IRCHY, so
the animal could be any ore of them. Therefore, saying the mammal or
the animal would form an ambiguous reference which the listener or
reader would have no way to understand.
Paul recognizes this ambiguity. Once the superordinate has been
selected, it is tested agsanst all the other nouns mentioned so far in the
text. If any other noun is a member of the superordinale set in question,
the reference is ambigeous. 1 his reference can be disambiguated by
using some feature of the element being replaced as a modifier. In our
example of Figure 1. we find that all possums are grey. and therefore
P000 is grey. Thus, the grey mamma! can refer only to POGO. and is not
ambiguous. In the Pogo world, the features the system n uses to
diserrioiguate these references are gender. size, color, and skin type
(luny. scaled, or featiks feta Once the feature is arbitrarily selected and
the correct value has been determined, it is tested to see that it genuinely
disambiguates the reference. It any of the nouns that were members of
the superordinate set have the same value ice this feature, it cannot be
used to disambiguate the reference, and it is rejected. For instance, the
srze of P000 is small. but saying the small mammal is still ambiguous
because HE/ea/BAH is also small, and the phrase could just as likely refer
to her. The search for a disambiguating feature continues until one is
found.
Pronominalization, the use of personal pronouns in place of an
element, is mechanically simple. The selection of the appropriate
personal pronoun is strictly grammatical. Once the syntactic case, the
(lender, and the number of the element are known, the correct pronoun is
dictated by the language.
the final lexical substitution available to Paul is the definite noun
phrase. the use of a definite article, tee in English, as opposed to an
indefinite article, a or soryie The definite edictÂ° clearly marks an item as
one that has been previously mentioned, and is therefore old information.
Tee indefinite article similarly marks an item as not having been
preeously mentioned. and therefore is new information. This capacity of
the definite article makes its use required with superordinates.
</bodyText>
<listItem confidence="0.4557845">
{21 My collie is smart. The dog fetches my newspaper every day.
â¢ My collie is smart. A dog fetches my newspaper every day.
</listItem>
<bodyText confidence="0.994781">
While the mechanisms for performing the various lexical
substitutions are Conceptually straightforward. they don&apos;t solve the entire
problem of using lexical suestautton. Nothing has been said about how
the system chooses wnich iesimrnit substitution to use. This is a serious
issoe because lexical substitution devices are net interchangeable. This is
true because lesiCal substitutions, as with most cohesive devices, Create
text by using presupposed dependencies for their interpretations, as we
have seen. It those presupposed elements do not exist, or if it is not
passible to correctly identify which of the many possible elements is the
one presuppnsed, then it is impossible to correctly interpret the element,
and the only possible result is confusion. A computer text generation
system mat incorporates lexical substitution in its output must insure that
tire presupposed element exists, and that it can be readily identified by
the reader.
Paul controls the selection of lexical substitution devices by
conceptually dividing the pi oblein into Iwo tesks. The first is to identify the
strength of antecedence recovery of lire lexical substitution devices. The
second is to identify the strength ol potential antecedence of each
element in the passage, and determine which if any lexical substitution
would be appropriate.
</bodyText>
<listItem confidence="0.639568">
4. Strength of Antecedence Recovery
</listItem>
<bodyText confidence="0.966670466666667">
Each time a cohesive device is used, a presupposition dependency
is created. The item that is being presupposed must be correctly
identified for the correct interpi elation of the element. The relative ease
with which one can recover this presupposed item from the cohesive
element is called the stiength of antecedence recoveq. The stronger an
element&apos;s strength of antecedence recovery, the easier it is to identify the
presupposed element.
The lexical substitution with the highest strength of antecedence
recovery is the definite noun. This is because the element is actually a
reeetition of the original item, with a definite article to mark the fact that it
is old information. There is no real need to refer to the presupposed
element, since all the information is being repeated.
Superordinate substitution is the lexical substitution with the next
highest strength of antecedence recovery. Presupposition dependency
genuinely does exist with the use of superordinates, because some
information is lost When win move up the semantic hierarchy, all the traits
that are specific to the element in question are lost. To recover this and
fully underStand the reference at hanu. we must trace back to the original
element in the hierarchy. Fortunately, the manner in which Paul pert arms
superordinate substitution facilitates this recovery. By insuring that the
superordinate Substitution will never be ambiguous, the system only
generates superoluinate et,bstauttons that are readily recoverable.
The third device used by Pau/, the personal pronoun, has the lowest
strength of antecedence recovery. Pr000uns genuinely are nothing more
than plaee holders. variables that maintain the positioes of the elements
they are replacing A pronoun contains no real semantic information. The
only readily available pieces oh information from a pronoun are the
syntactic role in the current sentence, the gender. and the number of the
replaced item. For this reason. pronouns are the hardest to recover of the
substitutions discussed.
</bodyText>
<listItem confidence="0.603298">
5. Strength of Potential Antecedence
</listItem>
<bodyText confidence="0.998529071428571">
While the forms of lexical substitution provide clues (to various
degrees) that aid the reader in recovering the presupposed element. the
actual way in which the element is currently being used, how it was
previously used, its be:elm:lances within the current sentence and within
the entire text, can provice additional clues. These factors combine to
give trio specific relerence a stret:gtli of potential antecedence. Some
elements, by the eature of their current and previous usage. will be easier
to recover independent of time lexical substitution device selected.
Strength of potential antecedence involves several factors. One is
the syntactic role the element is playing in the current sentence, as well
as in the previous reference. Another is the distance of the previous
reference from the current. Here distance is defined as the number of
clauses between the references. and Paul arbitrarily uses a distance of no
more than two clauses as an acceptable distance. The current expected
</bodyText>
<page confidence="0.996507">
382
</page>
<bodyText confidence="0.996958285714286">
focus of the text also affects an element&apos;s potential strength of
antecedence. In order to identify the current expected locus, Paul uses
the detailed algorithm for focus developed by Sidner [10].
Paul identifies five classes of potential antecedence strength. Class
I being the strongest and Class V the weakest, as well as a sixth &amp;quot;non-
class&amp;quot; for elements being mentioned for the first time. These five classes
are shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.477948">
Class I:
</subsectionHeader>
<listItem confidence="0.99762">
1. The sole referent of a given gender and number (singular or
plural) last mentioned within an acceptable distance. OR
2. The locus or the head of the expected locus list for the previous
sentence.
</listItem>
<subsectionHeader confidence="0.708891">
Class II:
</subsectionHeader>
<bodyText confidence="0.9973045">
The last referent of a given gender and number last mentioned
within an acceptable distance.
</bodyText>
<subsectionHeader confidence="0.703274">
Class III:
</subsectionHeader>
<bodyText confidence="0.8525485">
An element that filled the same syntactic role in the previous
sentence.
</bodyText>
<figure confidence="0.740875333333333">
Class IV:
1.A referent that has been previously mentioned, OR
2. A referent that is a member of a previously mentioned set that has
been mentioned within an acceptable distance.
Class V:
A referent that is known lobe a part of a previously mentioned item.
</figure>
<figureCaption confidence="0.999923">
Figure 2: The Five Classes of Potential Antecedence
</figureCaption>
<bodyText confidence="0.9986813">
Once an element&apos;s class of potential antecedence is identified, the
selection of the proper lexical substitution is easy. The stronger an
element&apos;s potential antecedence. the weaker the antecedence of the
lexical substitution Fiume 3 illustrates the mappings from potential
antecedence to lexical substitution devices. Note that Class Ill elements
are unusual in that the device used to replace them can vary. If the
previous instance Cl the element was of Class I. if it was replaced with a
pronoun. then the cunent instance is replaced with a pronoun. too.
Otnorwise, Class Ill elements are replaced with superordinates, the same
as Class II.
</bodyText>
<table confidence="0.955064142857143">
Class I Pronoun Substitution
Class II Superordinate Substitution
Class III (previous reference Class I)
Pronoun Substitution
Class III Superordinate Substitution
Class IV Definite Noun Phrase
Class V Definite Noun Phrase
</table>
<figureCaption confidence="0.9601935">
Figure 3: Mapping of Potential Antecedence
Classes to Lexical Substitutions
</figureCaption>
<sectionHeader confidence="0.805647" genericHeader="method">
6. An Example
</sectionHeader>
<bodyText confidence="0.979028">
To see the effects of controlled lexical substitution, and to help
clarify the ideas discussed, an example is provided. The following is an
actual example of text generated by Paul The domain is the so-called
children&apos;s story, and the example discussed here is one about characters
from Walt Kelly&apos;s Pogo comic strip, as shown in Figure 1 above.
Figure 4 contains the semantic representation for the example story
to be generated, in the syntax of NLP [4] records.2
</bodyText>
<figure confidence="0.9833818125">
a2( &apos;pogo&apos;
a3( &apos;hepzibah&apos;);
b2(&apos;churchy&apos;);
active,effect:.&apos;c3&apos;);
c2(&apos;rose&apos;);
c3(&apos;enjoyV.recip:----a3&apos;.stative):
dI(&apos;want\&apos;,exp:.&apos;a3&apos;.recip:.&apos;d2&apos;,ne9,stative);
d2(rose..pussess:=.b2.):
e1(&apos;b2&apos;,char:.&apos;jealous&apos;,entity);
fI(&apos;hitV.agnt:.&apos;b2&apos;,aff:=&apos;a2&apos;.active);
recip:m&apos;a3&apos;,active);
g2(&apos;rose&apos;);
hI(&apos;droW,exp:.&apos;h2.,stative):
h2(&apos;peta1&apos;,partof:.&apos;92&apos;,p1ur):
i1(&apos;upsetY,recip:m&apos;a3&apos;,cause:.&apos;h1&apos;,stative);
jI(&apos;cry\&apos;,agnt:.&apos;a3.,active)[]
</figure>
<figureCaption confidence="0.999895">
Figure 4: NLP Records for Example Story
</figureCaption>
<bodyText confidence="0.996613">
If the story were to be generated without any lexical substitutions at all, it
would look like the following.
</bodyText>
<sectionHeader confidence="0.999796333333333" genericHeader="method">
POGO CARES FOR HEPZIBAH. CHURCHY LIKES HEPZIBAH,
TOO. POGO GIVES A ROSE TO HEPZIBAH, WHICH PLEASES
HEPZIBAH. HEPZIBAH DOES NOT WANT CHURCHY&apos;S ROSE.
CHURCHY IS JEALOUS. CHURCHY HITS POGO. CHURCHY
GIVES A ROSE TO HEPZIBAH. PETALS DROP OFF. THIS
UPSETS HEPZIBAH. HEPZIBAH CRIES.
</sectionHeader>
<bodyText confidence="0.999713">
While this version of the story would be unacceptable as the final product
of a text generator, and it is not the text Paul would produce from the
input of Figure 4. it is shown here so that the reader can more easily
understand the story represented semantically in Figure 4.
To go to the other extreme, uncontrolled pronominalization would
be at least as unacceptable as no lexical substitutions at all.
</bodyText>
<sectionHeader confidence="0.999483" genericHeader="method">
POGO LIKES HEPZIBAH. CHURCHY CARES FOR HER, TOO.
HE GIVES A ROSE TO 11E11. WHICH PLEASES HER. SHE
DOES NOT WANT HIS HOSE. HE IS JEALOUS. HE SLUGS
HIM. HE GIVES A ROSE TO HER. PETALS DROP OFF.
THIS UPSETS HER. SHE CRIES.
</sectionHeader>
<bodyText confidence="0.999852">
Again, this is unacceptable text, and the system would not generate it, but
it is shown here to dramatize the need for control over lexical
substitutions.
The text that Paul actually does produce from the input of Figure 4
is the following story.
</bodyText>
<sectionHeader confidence="0.9982872" genericHeader="method">
POGO CARES F011 HEPZICAH. CHURCHY LIKES HER, TOO.
POGO GIVES A ROSE TO HER, WHICH PLEASES HER. SHE
DOES NOT WANT CHURCHY &apos;S ROSE. HE IS JEALOUS. HE
PUNCHES POGO. HE GIVES A ROSE TO HEPZIBAH. THE
PETALS DROP OFF. THIS UPSETS HER. SHE CRIES.
</sectionHeader>
<footnote confidence="0.906711">
2For a discussion of the implementation of NI.P for Paul see [2].
</footnote>
<page confidence="0.998479">
383
</page>
<sectionHeader confidence="0.964372" genericHeader="conclusions">
7. Conclusions
</sectionHeader>
<bodyText confidence="0.999981769230769">
The need for good text generation is rapidly increasing. One
requirement for generated output to be Considered text is to exhibit
cohesion. Lexical substitution is a family of cohesive devices that help
provide cohesion and achieve the two major goals of cohesion, the
avoiding of unnecessary repetition and the distinguishing of old
information from new. However. uncontrolled use of lexical substitution
devices will produce text that is unintelligible and nonsensical. Paul is the
first text get-1(4,01m systrm that incorporates lexical substitutions in a
controlled manner. tnereby producing cohesive text that is
Hodersbndable. By identifying the strength of antecedence recovery for
each of the lexical substitutions, and the strength of potential
antecedence for each element in the discourse, the system ia able to
choose the appropriate lexical substitutions.
</bodyText>
<sectionHeader confidence="0.877069" genericHeader="acknowledgments">
8. Acknowledgments
</sectionHeader>
<bodyText confidence="0.9995024">
I would like to thank Pete Stolovas and Bob Berwick for their advice
and encouragement whiie supervising this work. I would also like to thank
Ceorue. I ieidorn and Karen Jensen for originally introducing me to the
problem addressed here, as well as their expert help at the early stages of
this project.
</bodyText>
<sectionHeader confidence="0.835043" genericHeader="references">
9. References
</sectionHeader>
<reference confidence="0.99996921875">
1. Fillmore, Charles J. The Case for Case. In Universals in Linguistic
Theory. Enimon Bach and Robert T. Harms, Ed., Holt, Rinehart and
Winston, Inc., New York, 1968.
2. Granville, Robert Alan. Cohesion in Computer Text Generation:
Lexical Substitution. Tech. Rep. M1T/LCS/TR-310, MIT,Cambridge,
1983.
3. Halliday, M. A. K., and Ruquaiya Hasan. Cohesion in English.
Longman Group Limited, London, 1976.
4. Heidorn. George E. Natural Language Inputs to a Simulation
Programming System. Tech. Rep. NPS-5511072101A, Naval Postgraduate
School, Monterey, Cal., 1972.
5. Heidorn, G. E., K. Jensen, L. A. Miller, R. J. Byrd, and M. S. Chodorow.
The Epistle Text-Critiquing System. IBM Systems Journal 21, 3 (1982).
6. Jensen, Karen, and George E. Heidorn. The Fitted Parse: 100%
Parsing Capability in a Syntactic Grammar of English. Tech. Rep. RC
9729 ( # 42958), IBM Thomas J. Watson Research Center, 1982.
7. Jensen. K.. R. Ambrosio, R. Granville, M. Kluger, and A. Zwarico.
Computer Generation of Topic Paragraphs: Structure and Style.
Proceedings of the 19th Annual Meeting of the Association for
Computational Linguistics, Association for Computational Linguistics,
1981.
8. Mann. William C., Madeline Bates, Barbara J. Grosz, David
D. McDonald. Kathleen R. McKeown. and William R. Swartout. Text
Generation: Ther State of the Art and the Literature. Tech. Rep. IS1/111-1-
81-101, Information Sciences Institute, Marina del Rey, Cal., 1981. Also
University of Pennsylvania MS-CIS-81-9.
9. Quirk, Randolph. Sidney Greenbaum. Geoffrey Leech, and Jan
Svartik. A Grammar of Contemporary English. Longman Group Limited,
London, 1972.
10. Sidner, Candace Lee. Towards a Computational Theory of Definite
Anaphora Comprehension in English Discourse. Tech. Rep. Al-TR 537,
MIT, Cambridge, 1979.
</reference>
<page confidence="0.998987">
384
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.986906">
<title confidence="0.997211">Lexical Substitution in Computer Text</title>
<author confidence="0.999941">Robert Granville</author>
<affiliation confidence="0.999939">MIT Laboratory for Computer Science</affiliation>
<address confidence="0.9982745">545 Technology Square Cambridge, Massachusetts 02139</address>
<abstract confidence="0.999201888888889">report describes computer text generation system designed to create cohesive text through the use of lexical substitutions. Specifically. this system is designed to deterministically choose between pronominalization, superordinate substitution, and definite noun phrase The system identities a of antecedence recovery of the lexical substitutions, and matches them against the potential antecedence each element in the text to select the proper substitutions for these elements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>The Case for Case. In Universals in Linguistic Theory. Enimon Bach</title>
<date>1968</date>
<publisher>Inc.,</publisher>
<location>New York,</location>
<contexts>
<context position="2923" citStr="(1)" startWordPosition="439" endWordPosition="439"> theory of text and what distinguishes it from isolated sentences that is used in Paul is that of Halliday and Hasan [3j. One of the items that enhances the unity of text is cohesion. Cohesion refers to the linguistic phenomena that establish relationships between sentences, thereby tying them together. There are two major goals that are accomplished through coliesioil that enhance a passage&apos;s quality of text. The first is the obvious uesire to avoid unnecessary repetition. The other goal is to distinguish new information from old, so that the listener can fully understand what is being said. (1) The room has a large window. The room has a window facing east. {1} appears to he describing two windows, because there is no device indicating that the window ot the second sentence is the same as the window of the first sentence. If in fact the speaker merint to describe the seine window, she must somehow inform the listener that this is 1 This research was supported (in part) by Office of Naval Research contract NO0 14-80-C.0505. and (in pair) by National Institutes of Health Grant No, 1 P01 LM 03374.04 from the National Library of Medicine. indeed the case. Cohesion is a device that will </context>
</contexts>
<marker>1.</marker>
<rawString>Fillmore, Charles J. The Case for Case. In Universals in Linguistic Theory. Enimon Bach and Robert T. Harms, Ed., Holt, Rinehart and Winston, Inc., New York, 1968.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert Alan Granville</author>
</authors>
<title>Cohesion in Computer Text Generation: Lexical Substitution.</title>
<tech>Tech. Rep. M1T/LCS/TR-310, MIT,Cambridge,</tech>
<contexts>
<context position="19747" citStr="[2]" startWordPosition="3110" endWordPosition="3110">O HER. PETALS DROP OFF. THIS UPSETS HER. SHE CRIES. Again, this is unacceptable text, and the system would not generate it, but it is shown here to dramatize the need for control over lexical substitutions. The text that Paul actually does produce from the input of Figure 4 is the following story. POGO CARES F011 HEPZICAH. CHURCHY LIKES HER, TOO. POGO GIVES A ROSE TO HER, WHICH PLEASES HER. SHE DOES NOT WANT CHURCHY &apos;S ROSE. HE IS JEALOUS. HE PUNCHES POGO. HE GIVES A ROSE TO HEPZIBAH. THE PETALS DROP OFF. THIS UPSETS HER. SHE CRIES. 2For a discussion of the implementation of NI.P for Paul see [2]. 383 7. Conclusions The need for good text generation is rapidly increasing. One requirement for generated output to be Considered text is to exhibit cohesion. Lexical substitution is a family of cohesive devices that help provide cohesion and achieve the two major goals of cohesion, the avoiding of unnecessary repetition and the distinguishing of old information from new. However. uncontrolled use of lexical substitution devices will produce text that is unintelligible and nonsensical. Paul is the first text get-1(4,01m systrm that incorporates lexical substitutions in a controlled manner. t</context>
</contexts>
<marker>2.</marker>
<rawString>Granville, Robert Alan. Cohesion in Computer Text Generation: Lexical Substitution. Tech. Rep. M1T/LCS/TR-310, MIT,Cambridge,</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>Ruquaiya Hasan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman Group Limited,</publisher>
<location>London,</location>
<contexts>
<context position="1580" citStr="[3, 9]" startWordPosition="221" endWordPosition="222"> substitution, and definite noun phrase reiteration. The system identifies a strength of antecedence recovery for each of the lexical substitutions, and matches them against the strength of potential antecedenc.e of each element in the text to select the proper substitutions for these elements. Paul is a natural language generation program initially developed at IBM&apos;s Thomas J. Watson Hesearch Center as part of the ongoing Epistle project [5. 6]. The emphasis of the the work reported here is in the research of discourse phenomena, the study of cohesion and its effects on multisentential texts [3, 9]. Paul accepts as input LISP knowledge structures consisting of case frame ] formalisms representing each sentence to be generated. These knowledge structures are translated into English, with the appropriate lexical substitutions being made at this time. No attempt is made by the system to create these knowledge structures. 2. Cohesion The purpose of communication is for one person (the speaker or writer) to express her thoughts and ideas so that another (the listener or reader) can understand them. There aie many restrictions placed on the realization of these thoughts into language so that </context>
<context position="3770" citStr="[3]" startWordPosition="586" endWordPosition="586">the speaker merint to describe the seine window, she must somehow inform the listener that this is 1 This research was supported (in part) by Office of Naval Research contract NO0 14-80-C.0505. and (in pair) by National Institutes of Health Grant No, 1 P01 LM 03374.04 from the National Library of Medicine. indeed the case. Cohesion is a device that will accomplish this goal. Cohesion is created when the interpretation of an element is dependent on the meaning of another. The element in question cannot be fully understood unto the element it is dependent on is identified. The first presupposes [3] the second in that it requires for its understanding the existence of the second. An element of a sentence presupposes the existence of another when its interpretation requires reference 10 another. Once we can trace these references to their sources, we can correctly interpret the elements of the sentences. The very some devices that create these dependencies for interpretation help distinguish old information from new. If the use of a cohesive element prebupposes the existence of another reference of the element for its interpretation, then the listener can be assured that the other referen</context>
</contexts>
<marker>3.</marker>
<rawString>Halliday, M. A. K., and Ruquaiya Hasan. Cohesion in English. Longman Group Limited, London, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E George</author>
</authors>
<title>Natural Language Inputs to a Simulation Programming System.</title>
<date>1972</date>
<tech>Tech. Rep. NPS-5511072101A,</tech>
<institution>Naval Postgraduate School,</institution>
<location>Monterey, Cal.,</location>
<contexts>
<context position="17708" citStr="[4]" startWordPosition="2808" endWordPosition="2808">lass IV Definite Noun Phrase Class V Definite Noun Phrase Figure 3: Mapping of Potential Antecedence Classes to Lexical Substitutions 6. An Example To see the effects of controlled lexical substitution, and to help clarify the ideas discussed, an example is provided. The following is an actual example of text generated by Paul The domain is the so-called children&apos;s story, and the example discussed here is one about characters from Walt Kelly&apos;s Pogo comic strip, as shown in Figure 1 above. Figure 4 contains the semantic representation for the example story to be generated, in the syntax of NLP [4] records.2 a2( &apos;pogo&apos; a3( &apos;hepzibah&apos;); b2(&apos;churchy&apos;); active,effect:.&apos;c3&apos;); c2(&apos;rose&apos;); c3(&apos;enjoyV.recip:----a3&apos;.stative): dI(&apos;want\&apos;,exp:.&apos;a3&apos;.recip:.&apos;d2&apos;,ne9,stative); d2(rose..pussess:=.b2.): e1(&apos;b2&apos;,char:.&apos;jealous&apos;,entity); fI(&apos;hitV.agnt:.&apos;b2&apos;,aff:=&apos;a2&apos;.active); recip:m&apos;a3&apos;,active); g2(&apos;rose&apos;); hI(&apos;droW,exp:.&apos;h2.,stative): h2(&apos;peta1&apos;,partof:.&apos;92&apos;,p1ur): i1(&apos;upsetY,recip:m&apos;a3&apos;,cause:.&apos;h1&apos;,stative); jI(&apos;cry\&apos;,agnt:.&apos;a3.,active)[] Figure 4: NLP Records for Example Story If the story were to be generated without any lexical substitutions at all, it would look like the following. POGO CARES FOR</context>
</contexts>
<marker>4.</marker>
<rawString>Heidorn. George E. Natural Language Inputs to a Simulation Programming System. Tech. Rep. NPS-5511072101A, Naval Postgraduate School, Monterey, Cal., 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Heidorn</author>
<author>K Jensen</author>
<author>L A Miller</author>
<author>R J Byrd</author>
<author>M S Chodorow</author>
</authors>
<title>The Epistle Text-Critiquing System.</title>
<date>1982</date>
<journal>IBM Systems Journal</journal>
<volume>21</volume>
<marker>5.</marker>
<rawString>Heidorn, G. E., K. Jensen, L. A. Miller, R. J. Byrd, and M. S. Chodorow. The Epistle Text-Critiquing System. IBM Systems Journal 21, 3 (1982).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
<author>George E Heidorn</author>
</authors>
<title>The Fitted Parse: 100% Parsing Capability in a Syntactic Grammar of English.</title>
<date>1982</date>
<journal>Tech. Rep. RC 9729 ( # 42958), IBM Thomas J. Watson Research</journal>
<location>Center,</location>
<marker>6.</marker>
<rawString>Jensen, Karen, and George E. Heidorn. The Fitted Parse: 100% Parsing Capability in a Syntactic Grammar of English. Tech. Rep. RC 9729 ( # 42958), IBM Thomas J. Watson Research Center, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K R Ambrosio</author>
<author>R Granville</author>
<author>M Kluger</author>
<author>A Zwarico</author>
</authors>
<title>Computer Generation of Topic Paragraphs: Structure and Style.</title>
<booktitle>Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics,</booktitle>
<marker>7.</marker>
<rawString>Jensen. K.. R. Ambrosio, R. Granville, M. Kluger, and A. Zwarico. Computer Generation of Topic Paragraphs: Structure and Style. Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics,</rawString>
</citation>
<citation valid="true">
<authors>
<author>C William</author>
<author>Madeline Bates</author>
<author>Barbara J Grosz</author>
<author>David D McDonald Kathleen R McKeown</author>
<author>William R Swartout</author>
</authors>
<title>Text Generation: Ther State of the Art and the Literature.</title>
<date>1981</date>
<tech>Tech. Rep. IS1/111-1-81-101,</tech>
<pages>81--9</pages>
<institution>Information Sciences Institute, Marina</institution>
<marker>8.</marker>
<rawString>Mann. William C., Madeline Bates, Barbara J. Grosz, David D. McDonald. Kathleen R. McKeown. and William R. Swartout. Text Generation: Ther State of the Art and the Literature. Tech. Rep. IS1/111-1-81-101, Information Sciences Institute, Marina del Rey, Cal., 1981. Also University of Pennsylvania MS-CIS-81-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Greenbaum Geoffrey Leech</author>
<author>Jan Svartik</author>
</authors>
<title>A Grammar of Contemporary English.</title>
<date>1972</date>
<publisher>Longman Group Limited,</publisher>
<location>London,</location>
<contexts>
<context position="1580" citStr="[3, 9]" startWordPosition="221" endWordPosition="222"> substitution, and definite noun phrase reiteration. The system identifies a strength of antecedence recovery for each of the lexical substitutions, and matches them against the strength of potential antecedenc.e of each element in the text to select the proper substitutions for these elements. Paul is a natural language generation program initially developed at IBM&apos;s Thomas J. Watson Hesearch Center as part of the ongoing Epistle project [5. 6]. The emphasis of the the work reported here is in the research of discourse phenomena, the study of cohesion and its effects on multisentential texts [3, 9]. Paul accepts as input LISP knowledge structures consisting of case frame ] formalisms representing each sentence to be generated. These knowledge structures are translated into English, with the appropriate lexical substitutions being made at this time. No attempt is made by the system to create these knowledge structures. 2. Cohesion The purpose of communication is for one person (the speaker or writer) to express her thoughts and ideas so that another (the listener or reader) can understand them. There aie many restrictions placed on the realization of these thoughts into language so that </context>
</contexts>
<marker>9.</marker>
<rawString>Quirk, Randolph. Sidney Greenbaum. Geoffrey Leech, and Jan Svartik. A Grammar of Contemporary English. Longman Group Limited, London, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace Lee Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<tech>Tech. Rep. Al-TR 537,</tech>
<location>MIT, Cambridge,</location>
<contexts>
<context position="15354" citStr="[10]" startWordPosition="2424" endWordPosition="2424">antecedence involves several factors. One is the syntactic role the element is playing in the current sentence, as well as in the previous reference. Another is the distance of the previous reference from the current. Here distance is defined as the number of clauses between the references. and Paul arbitrarily uses a distance of no more than two clauses as an acceptable distance. The current expected 382 focus of the text also affects an element&apos;s potential strength of antecedence. In order to identify the current expected locus, Paul uses the detailed algorithm for focus developed by Sidner [10]. Paul identifies five classes of potential antecedence strength. Class I being the strongest and Class V the weakest, as well as a sixth &amp;quot;nonclass&amp;quot; for elements being mentioned for the first time. These five classes are shown in Figure 2. Class I: 1. The sole referent of a given gender and number (singular or plural) last mentioned within an acceptable distance. OR 2. The locus or the head of the expected locus list for the previous sentence. Class II: The last referent of a given gender and number last mentioned within an acceptable distance. Class III: An element that filled the same syntac</context>
</contexts>
<marker>10.</marker>
<rawString>Sidner, Candace Lee. Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Tech. Rep. Al-TR 537, MIT, Cambridge, 1979.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>