<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000028">
<title confidence="0.859685">
Scruffy Text Understanding:
Design and Implementation of &apos;Tolerant&apos; Understanders
Richard H. Granger
Artificial Intelligence Project
Computer Science Department
University of California
Irvine, California 92717
</title>
<sectionHeader confidence="0.618946" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999687391304348">
Most large text-understanding systems have
been designed under the assumption that the input
text will be in reasonably &amp;quot;neat&amp;quot; form, e.g.,
newspaper stories and other edited texts. However,
a great deal of natural language text, e.g., memos,
rough dratts, conversation transcripts, etc., have
features that differ significantly from &amp;quot;neat&amp;quot;
texts, posing special problems for readers, such as
misspelled words, missing words, poor syntactic
construction, missing periods, etc. Our solution
to these problems is to make use of expectations,
based both on knowledge of surface English and on
world knowledge of the situation being described.
These syntactic and semantic expectations can be
used to figure out unknown words from context,
constrain the possible word-senses of words with
multiple meanings (ambiguity), fill in missing
words (ellipsis), and resolve referents (anaphora).
This method of using expectations to aid the un-
derstanding of &amp;quot;scruffy&amp;quot; texts has been incorp-
orated into a working computer program called
NOMAD, which understands scruffy texts in the do-
main of Navy messages.
</bodyText>
<sectionHeader confidence="0.944008" genericHeader="keywords">
1.0 Introduction
</sectionHeader>
<bodyText confidence="0.993595147058824">
Consider the following (scribbled) message,
left by a computer science professor on a
colleague&apos;s desk:
[1] Met w/chrmn agreed on changes to prposl nxt
mtg 3 Feb.
A good deal of informal text such as everyday mes-
sages like the one above are very ill-formed gram-
matically and contain misspellings, ad hoc abbre-
viations and lack of important punctuation such as
periods between sentences. Yet people seem to
easily understand such messages, and in fact most
people would probably understand the above message
just as readily as they would a more &amp;quot;well-formed&amp;quot;
version:
&amp;quot;I met with the chairman, and we agreed on what
changes had to be made to the proposal. Our next
meeting will be on Feb. 3.&amp;quot;
This research was supported in part by the Naval
Ocean Systems Center under contract
N-00123-81-C-1078.
No extra information seems to be conveyed by this
longer version, and message-writers appear to take
advantage of this fact by writing extremely terse
messages such as [1], apparently counting on read-
ers&apos; ability to analyze them in spite of their
messiness.
If &amp;quot;scruffy&amp;quot; messages such as this one were
only intended for a readership of one, there
wouldn&apos;t be a real problem. However, this informal
type of &apos;memo&apos; message is commonly used for infor-
mation transfer in many businesses, universities,
government offices, etc. An extreme case of such
an organization is the Navy, which every hour re-
ceives many thousands of short messages, each of
which must be encoded into computer-readable form
for entry into a database. Currently, these mes-
sages come in in very scruffy form, and a growing
number of man-hours is spent on the encoding-by-
hand process. Hence there is an obvious benefit to
partially automating this encoding process. The
problem is that most existing text-understanding
systems (e.g. ELI [Riesbeck and Schank 76], SAM
[Cullingford 77], FRUMP [DeJong 79], IPP [Lebowitz
80]) would fait to successfully analyze ill-formed
texts like [1], because they have been designed
under the assumption that they will receive
&apos;neater&apos; input, e.g., edited input such as is found
in newspapers or books.
This paper briefly outlines some of the prop-
erties of texts like [11, that allow readers to
understand it in spite of its scruffiness; and
some of the knowledge and mechanisms that seem to
underlie readers&apos; ability to understand such texts.
A text-processing system called NOMAD is discussed
which makes use of the theories described here to
process scruffy text in the domain of everyday Navy
messages. NOMAD&apos;s operation is based on the use of
expectations during understanding, based both on
knowledge of surface English and on world knowledge
of the situation being described. These syntactic
and semantic expectations can be used to aid
naturally in the solution of a wide range of prob-
lems that arise in understanding both &amp;quot;scruffy&amp;quot;
texts and pre-edited texts, such as figuring out
unknown words from context, constraining the pos-
sible word-senses of words with multiple meanings
(ambiguity), filling in missing words (ellipsis),
and resolving unknown referents (anaphora).
</bodyText>
<page confidence="0.978753">
157
</page>
<figure confidence="0.1930595">
2.0 Background: Tolerant text processing
2.1 FOUL-UP figured out unknown words from context
</figure>
<bodyText confidence="0.980091222222222">
The FOUL-UP program (Figuring Out Unknown
Lexemes in the Understanding Process) [Granger
19771 was the first program that could figure out
meanings of unknown words encountered during text
understanding. FOUL-UP was an attempt to model the
corresponding human ability commonly known as
&amp;quot;figuring out a word from context&amp;quot;. FOUL-UP worked
with the SAM system [Cul].ingford 1977], using the
expectations generated by scripts [Schank and
Abelson 19771 to restrict the possible meanings of
a word, based on what object or action would have
occurred in that position according to the script
for the story.
For instance, consider the following excerpt
from a newspaper report of a car accident:
[2] Friday, a car swerved off Route 69. The
vehicle struck an embankment&apos;.
The word &amp;quot;embankment&amp;quot; was unknown to the SAM sys-
tem, but it had encoded predictions about certain
attributes of the expected conceptual object of the
PROPEL action (the object that the vehicle struck);
namely, that it would be a physical object, and
would function as an &amp;quot;obstruction&amp;quot; in the
vehicle-accident script. (In addition, the con-
ceptual analyzer (ELI - (Riesbeck and Schenk 19761)
had the expectation that the word in that sentence
position would be a noun.)
Hence, when the unknown word was encountered,
FOUL-UP would make use of those expected attributes
to construct a memory entry for the word
&amp;quot;embankment&amp;quot;, indicating that it was a noun, a
physical object, and an &amp;quot;obstruction&amp;quot; in vehicle-
accident situations. It would then create a dic-
tionary definition that the system would use from
then on whenever the word was encountered in this
context.
</bodyText>
<subsectionHeader confidence="0.995807">
2.2 Blame Assignment in the NOMAD system
</subsectionHeader>
<bodyText confidence="0.998632129032258">
But even if the SAM system had known the word
&amp;quot;embankment&amp;quot;, it would not have been able to handle
a less edited version of the story, such as this:
[3] Vehcle acc Rt69; car strck embankment; drivr
dead one psngr inj; ser dmg to car full rpt
frtucmng.
While human readers would have little difficulty
understanding this text, no existing computer pro-
grams could do so.
The scope of this problem is wide; examples
of texts that present &amp;quot;scruffy&amp;quot; difficulties to
readers are completely unedited texts, such as
messages composed in a hurry, with little or no
re-writing, rough drafts, memos, transcripts of
conversations, etc. Such texts may contain missing
words, ad hoc abbreviations of words, poor syntax,
confusing order of presentation of ideas, mis-
spellings, lack of punctuation, etc. Even edited
texts such as newspaper stories often contain mis-
spellings, words unknown to the reader, and am-
biguities; and even apparently very simple texts
may contain alternative possible interpretations,
which can cause a reader to construct erroneous
initial inferences that must later be corrected
(see [Granger 1980,1981]).
The following sections describe the NOMAD
system, which incorporates FOUL-UP&apos;s abilities as
well as significantly extended abilities to use
syntactic and semantic expectations to resolve
these difficulties, in the context of Naval mes-
sages.
</bodyText>
<sectionHeader confidence="0.801495" genericHeader="introduction">
3.0 How NOMAD Recognizes and Corrects Errors
3.1 Introduction
</sectionHeader>
<bodyText confidence="0.999924176470588">
NOMAD incorporates ideas from, and builds on,
earlier work on conceptual analysis (e.g.,
[Riesbeck and Schank 1976], [Birnbaum and Selfridge
1979]); situation and intention inference (e.g.,
(Cullingford 19771, [Wilensky 1978]); and English
generation (e.g. [Goldman 1973], [McGuire 1980]).
What differentiates NOMAD significantly from its
predecessors are its error recognition and error
correction abilities, which enable it to read texts
more complex than those that can be handled by
other text understanding systems.
We have so far identified the following five
types of problems that occur often in scruffy un-
edited texts. Each problem is illustrated by an
example from the domain of Navy messages. The next
section will then describe how NOMAD deals with
each type of error.
</bodyText>
<listItem confidence="0.99365025">
1. Unknown words (e.g., Enemy &apos;scudded&apos; bombs at
us. -- the verb is unknown to the system);
2. Missing subject, object, etc. of sentences.
(e.g., Sighted enemy ship. Fired -- the actor
who fired is not explicitly stated);
3. Missing sentence and clause boundaries. (e.g.,
Locked on opened fire. -- two actions, aiming
and firing);
4. Missing situational (scripty) events. (e.g.,
Midway lost contact on Kashin. -- no previous
contact mentioned);
5. Ambiguous word usage. (e.g., Returned bombs to
</listItem>
<bodyText confidence="0.99943025">
Kashin. -- &amp;quot;returned&amp;quot; in the sense of re-
taliation after a previous attack, or &amp;quot;return-
ed&amp;quot; in the sense of &amp;quot;peaceably delivered to&amp;quot;?)
When these problems arise in a message, NOMAD must
first recognize what the problem is (which is often
difficult to do), and then attempt to- ,orrect the
error. These two processes are briefly described
in the fnllowing sections.
</bodyText>
<page confidence="0.995797">
158
</page>
<subsectionHeader confidence="0.997306">
3.2 Recognizing and correcting errors
</subsectionHeader>
<bodyText confidence="0.99993875">
For each of the above examples of problems
encountered, NOMAD&apos;s method of recognizing and
correcting the problem are described here, along
with actual English input and output from NOMAD.
</bodyText>
<listItem confidence="0.90492975">
1. INPUT:
ENEMY SCUDDED BOMBS AT US.
Problem: Unknown word. The unknown word &amp;quot;scudded&amp;quot;
is trivial to recognize, since it is the only word
without a dictionary entry. Once it has been
recognized, NOMAD checks it to see if it could be
(a) a misspelling, (b) an abbreviation or (c) a
regular verb-tense of some known word.
</listItem>
<bodyText confidence="0.939927090909091">
Solution: Use expectations to figure out word
meaning from context. When the spelling checkers
fail, a FOUL-UP mechanisms is called which uses
knowledge of what actions can be done by an enemy
actor, to a weapon object, directed at us. It in-
fers that the action is probably a propel. Again,
this is only an educated guess by the system, and
may have to be corrected later on the basis of
future information.
NOMAD OUTPUT:
An enemy ship fired bombs at our ship.
</bodyText>
<listItem confidence="0.776817">
2. INPUT:
MIDWAY SIGHTED ENEMY. FIRED.
</listItem>
<bodyText confidence="0.933489888888889">
Problem: Missing subject and objects. &apos;Fired&apos;
builds a PROPEL, and expects a subject and objects
to play the conceptual roles of ACTOR (who did the
PROPELing), OBJECT (what got PROPELed) and RECIPI-
ENT (who got PROPELed at). However, no surface
subjects or objects are presented here.
Solution: Use expectations to fill in conceptual
cases. NOMAD uses situational expectations from
the known typical sequence of events in an &amp;quot;ATTACK&amp;quot;
(which consists of a movement (PTRANS), a sighting
(ATTEND) and firing (PROPEL)). Those expectations
say (among other things) that the actor and recip-
ient of the PROPEL will be the same as the actor
and direction of the ATTEND, and that the OBJECT
that got PROPELed will be some kind of projectile,
which is not further specified here.
NOMAD OUTPUT:
We sighted an enemy ship. We fired at the ship.
</bodyText>
<sectionHeader confidence="0.539323" genericHeader="method">
4.0 Conclusions
</sectionHeader>
<bodyText confidence="0.998442333333333">
tence position. Hence, NOMAD saves &amp;quot;locked on&amp;quot; as
one sentence, and continues to process the rest of
the text as a new sentence.
</bodyText>
<note confidence="0.386671">
NOMAD OUTPUT:
</note>
<bodyText confidence="0.9538465">
We aimed at an unknown object. We fired at the
object.
</bodyText>
<sectionHeader confidence="0.612772" genericHeader="method">
4. INPUT:
LOST CONTACT ON ENEMY SHIP.
</sectionHeader>
<bodyText confidence="0.994691555555556">
Problem: Missing event in event sequence. NOMAD&apos;s
knowledge of the &amp;quot;Tracking&amp;quot; situation cannot un-
derstand a ship losing contact until some contact
has been gained.
Solution: Use situational expectations to infer
missing events. NOMAD assumes that the message
implies the previous event of gaining contact with
the enemy ship, based on the known sequence of
events in the &amp;quot;Tracking&amp;quot; situation.
</bodyText>
<sectionHeader confidence="0.31906" genericHeader="method">
NOMAD OUTPUT:
</sectionHeader>
<bodyText confidence="0.912716">
We sighted an enemy ship. Then we lost radar or
visual contact with the ship.
</bodyText>
<sectionHeader confidence="0.7427135" genericHeader="method">
5. INPUT:
RETURNED BOMBS TO ENEMY SHIP.
</sectionHeader>
<bodyText confidence="0.924652647058824">
Problem: Ambiguous interpretation of action.
NOMAD cannot tell whether the action here is &amp;quot;re-
turning&amp;quot; fire to the enemy, i.e., firing back at
them (after they presumably had fired at us), or
peaceably delivering bombs, with no firing implied.
Solution: Use expectations of probable goals of
actors. NOMAD first interprets the sentence as
&amp;quot;peaceably delivering&amp;quot; some bombs to the ship.
However, NOMAD contains the knowledge that enemies
do not give weapons, information, personnel, etc.,
to each other. Hence it attempts to find an al-
ternative interpretation of the sentence, in this
case finding the &amp;quot;returned fire&amp;quot; interpretation,
which does not violate any of NOMAD&apos;s knowledge
about goals. It then infers, as in the above ex-
ample, that the enemy ship must have previously
fired on us.
</bodyText>
<sectionHeader confidence="0.687777" genericHeader="method">
NOMAD OUTPUT:
</sectionHeader>
<bodyText confidence="0.9371895">
An unknown enemy ship fired on us. Then we fired
bombs at them.
</bodyText>
<sectionHeader confidence="0.920298" genericHeader="method">
3. INPUT:
LOCKED ON OPENED FIRE.
</sectionHeader>
<bodyText confidence="0.984443227272727">
Problem: Missing sentence boundaries. NOMAD has
no expectations for a new verb (&amp;quot;opened&amp;quot;) to appear
immediately after the completed clause &amp;quot;locked on&amp;quot;.
It tries but fails to connect &amp;quot;opened&amp;quot; to the
phrase &amp;quot;locked on&amp;quot;.
Solution: Assume the syntactic expectations failed
because a clause boundary was not adequately marked
in the message; assume such a boundary is there.
NOMAD assumes that there may have been an intended
sentence separation before &amp;quot;opened&amp;quot;, since no
expectations can account for the word in this sen-
The ability to understand text is dependent on
the ability to understand what is being described
in the text. Hence, a reader of, say, English text
must have applicable knowledge of both the situa-
tions that may be described in texts (e.g., ac-
tions, states, sequences of events, goals, methods
of achieving goals, etc.) and the the surface
structures that appear in the language, i.e., the
relations between the surface order of appearance
of words and phrases, and their corresponding
meaning structures.
</bodyText>
<page confidence="0.99649">
159
</page>
<bodyText confidence="0.999951388888889">
The process of text understanding is the com-
bined application of these knowledge sources as a
reader proceeds through a text. This fact becomes
clearest when we investigate the understanding of
texts that present particular problems to a reader.
Human understanding is inherently tolerant; people
are naturally able to ignore many types of errors,
omissions, poor constructions, etc., and get
straight to the meaning of the text.
Our theories have tried to take this ability
into account by including knowledge and mechanisms
of error noticing and correcting as implicit parts
of our process models of language understanding.
The NOMAD system is the latest in a line of
&apos;tolerant language understanders, beginning with
FOUL-UP, all based on the use of knowledge of syn-
tax, semantics and pragmatics at all stages of the
understanding process to cope with errors.
</bodyText>
<sectionHeader confidence="0.880755" genericHeader="method">
5.0 References
</sectionHeader>
<reference confidence="0.998972523809524">
Birnbaum, L. and Selfridge, M. 1980. Conceptual
Analysis of Natural Language, in R. Schank and
C. Riesbeck, eds., Inside Computer Understanding.
Lawrence Erlbaum Associates, Hillsdale, N.J.
Cullingford, R. 1977. Controlling Inferences in
Story Understanding. Proceedings 2f. the Fifth
International Joint Conference 2m Artificial
Intelligence (IJCAI), Cambridge, Mass.
DeJong, G. 1979. Skimming Stories in Real Time: An
Experiment in Integrated Understanding. Ph.D.
Thesis, Yale Computer Science Dept.
Goldman, N. 1973. The generation of English Sen-
tences from a deep conceptual base. Ph.D. Thesis,
Stanford University.
Granger, R. 1977. FOUL-UP: A program that figures
out meanings of words from context. Proceedings g_
the Fifth IJCAI, Cambridge, Mass.
Granger, R.H. 1980. When expectation fails: Towards
a self-correcting inference system. In Proceedings
of the First National Conference on Artificial
Intelligence, Stanford University.
Granger, R.H. 1981. Directing and re-directing in-
ference pursuit: Extra-textual influences on text
interpretation. In Proceedings of the Seventh
International Joint Conference on Artificial
Intelligence (IJCAI), Vancouver, British Columbia.
Lebowitz, M. 1981. Generalization and Memory in an
Integrated Understanding System. Computer Science
Research Report 186, Yale University.
McGuire, R. 1980. Political Primaries and Words of
Pain. Unpublished ms., Dept. of Computer Science,
Yale University.
Riesbeck, C. and Schank, R. 1976. Comprehension by
computer: Expectation-based analysis of sentences
in context. Computer Science Research Report 78,
Yale University.
Schenk, R.C., and Abelson, R. 1977 Scripts. Plans.
Goals and Understanding. Lawrence Erlbaum
Associates, Hillsdale, N.J.
Wilensky, R. 1978. Understanding Goal-Based
Stories. Computer Science Technical Report 140,
Yale University.
</reference>
<page confidence="0.997458">
160
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960995">
<title confidence="0.999448">Scruffy Text Understanding: Design and Implementation of &apos;Tolerant&apos; Understanders</title>
<author confidence="0.999997">Richard H Granger</author>
<affiliation confidence="0.999307333333333">Artificial Intelligence Project Computer Science Department University of California</affiliation>
<address confidence="0.999917">Irvine, California 92717</address>
<abstract confidence="0.998446125">Most large text-understanding systems have been designed under the assumption that the input text will be in reasonably &amp;quot;neat&amp;quot; form, e.g., newspaper stories and other edited texts. However, a great deal of natural language text, e.g., memos, rough dratts, conversation transcripts, etc., have features that differ significantly from &amp;quot;neat&amp;quot; texts, posing special problems for readers, such as misspelled words, missing words, poor syntactic construction, missing periods, etc. Our solution these problems is to make use of expectations, based both on knowledge of surface English and on world knowledge of the situation being described. These syntactic and semantic expectations can be used to figure out unknown words from context, constrain the possible word-senses of words with multiple meanings (ambiguity), fill in missing words (ellipsis), and resolve referents (anaphora). This method of using expectations to aid the understanding of &amp;quot;scruffy&amp;quot; texts has been incorporated into a working computer program called NOMAD, which understands scruffy texts in the domain of Navy messages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Birnbaum</author>
<author>M Selfridge</author>
</authors>
<title>Conceptual Analysis of Natural Language,</title>
<date>1980</date>
<booktitle>Inside Computer Understanding. Lawrence Erlbaum Associates,</booktitle>
<editor>in R. Schank and C. Riesbeck, eds.,</editor>
<location>Hillsdale, N.J.</location>
<marker>Birnbaum, Selfridge, 1980</marker>
<rawString>Birnbaum, L. and Selfridge, M. 1980. Conceptual Analysis of Natural Language, in R. Schank and C. Riesbeck, eds., Inside Computer Understanding. Lawrence Erlbaum Associates, Hillsdale, N.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cullingford</author>
</authors>
<title>Controlling Inferences in Story Understanding.</title>
<date>1977</date>
<booktitle>Proceedings 2f. the Fifth International Joint Conference 2m Artificial Intelligence (IJCAI),</booktitle>
<location>Cambridge, Mass.</location>
<contexts>
<context position="7792" citStr="Cullingford 1977" startWordPosition="1217" endWordPosition="1218"> reader to construct erroneous initial inferences that must later be corrected (see [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980]). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. We have so far identified the following five types of problems that occur often in scruffy unedited texts. Each problem is illustrated by an example from the domain of Navy messages. The next section will then describe how NOMAD deals with each type of error. 1. Unknown words (e.g., En</context>
</contexts>
<marker>Cullingford, 1977</marker>
<rawString>Cullingford, R. 1977. Controlling Inferences in Story Understanding. Proceedings 2f. the Fifth International Joint Conference 2m Artificial Intelligence (IJCAI), Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G DeJong</author>
</authors>
<title>Skimming Stories in Real Time: An Experiment in Integrated Understanding.</title>
<date>1979</date>
<tech>Ph.D. Thesis,</tech>
<institution>Yale Computer Science Dept.</institution>
<marker>DeJong, 1979</marker>
<rawString>DeJong, G. 1979. Skimming Stories in Real Time: An Experiment in Integrated Understanding. Ph.D. Thesis, Yale Computer Science Dept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Goldman</author>
</authors>
<title>The generation of English Sentences from a deep conceptual base.</title>
<date>1973</date>
<tech>Ph.D. Thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="7855" citStr="Goldman 1973" startWordPosition="1225" endWordPosition="1226">e corrected (see [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980]). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. We have so far identified the following five types of problems that occur often in scruffy unedited texts. Each problem is illustrated by an example from the domain of Navy messages. The next section will then describe how NOMAD deals with each type of error. 1. Unknown words (e.g., Enemy &apos;scudded&apos; bombs at us. -- the verb is unknown to the system</context>
</contexts>
<marker>Goldman, 1973</marker>
<rawString>Goldman, N. 1973. The generation of English Sentences from a deep conceptual base. Ph.D. Thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Granger</author>
</authors>
<title>FOUL-UP: A program that figures out meanings of words from context.</title>
<date>1977</date>
<booktitle>Proceedings g_ the Fifth IJCAI,</booktitle>
<location>Cambridge, Mass.</location>
<contexts>
<context position="4597" citStr="Granger 1977" startWordPosition="713" endWordPosition="714">uation being described. These syntactic and semantic expectations can be used to aid naturally in the solution of a wide range of problems that arise in understanding both &amp;quot;scruffy&amp;quot; texts and pre-edited texts, such as figuring out unknown words from context, constraining the possible word-senses of words with multiple meanings (ambiguity), filling in missing words (ellipsis), and resolving unknown referents (anaphora). 157 2.0 Background: Tolerant text processing 2.1 FOUL-UP figured out unknown words from context The FOUL-UP program (Figuring Out Unknown Lexemes in the Understanding Process) [Granger 19771 was the first program that could figure out meanings of unknown words encountered during text understanding. FOUL-UP was an attempt to model the corresponding human ability commonly known as &amp;quot;figuring out a word from context&amp;quot;. FOUL-UP worked with the SAM system [Cul].ingford 1977], using the expectations generated by scripts [Schank and Abelson 19771 to restrict the possible meanings of a word, based on what object or action would have occurred in that position according to the script for the story. For instance, consider the following excerpt from a newspaper report of a car accident: [2] F</context>
</contexts>
<marker>Granger, 1977</marker>
<rawString>Granger, R. 1977. FOUL-UP: A program that figures out meanings of words from context. Proceedings g_ the Fifth IJCAI, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>When expectation fails: Towards a self-correcting inference system.</title>
<date>1980</date>
<booktitle>In Proceedings of the First National Conference on Artificial Intelligence,</booktitle>
<location>Stanford University.</location>
<contexts>
<context position="7273" citStr="Granger 1980" startWordPosition="1146" endWordPosition="1147">ts, such as messages composed in a hurry, with little or no re-writing, rough drafts, memos, transcripts of conversations, etc. Such texts may contain missing words, ad hoc abbreviations of words, poor syntax, confusing order of presentation of ideas, misspellings, lack of punctuation, etc. Even edited texts such as newspaper stories often contain misspellings, words unknown to the reader, and ambiguities; and even apparently very simple texts may contain alternative possible interpretations, which can cause a reader to construct erroneous initial inferences that must later be corrected (see [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980])</context>
</contexts>
<marker>Granger, 1980</marker>
<rawString>Granger, R.H. 1980. When expectation fails: Towards a self-correcting inference system. In Proceedings of the First National Conference on Artificial Intelligence, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>Directing and re-directing inference pursuit: Extra-textual influences on text interpretation.</title>
<date>1981</date>
<booktitle>In Proceedings of the Seventh International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<location>Vancouver, British Columbia.</location>
<marker>Granger, 1981</marker>
<rawString>Granger, R.H. 1981. Directing and re-directing inference pursuit: Extra-textual influences on text interpretation. In Proceedings of the Seventh International Joint Conference on Artificial Intelligence (IJCAI), Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lebowitz</author>
</authors>
<title>Generalization and Memory in an Integrated Understanding System.</title>
<date>1981</date>
<journal>Computer Science Research Report</journal>
<volume>186</volume>
<institution>Yale University.</institution>
<marker>Lebowitz, 1981</marker>
<rawString>Lebowitz, M. 1981. Generalization and Memory in an Integrated Understanding System. Computer Science Research Report 186, Yale University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McGuire</author>
</authors>
<title>Political Primaries and Words of Pain. Unpublished ms.,</title>
<date>1980</date>
<institution>Dept. of Computer Science, Yale University.</institution>
<contexts>
<context position="7871" citStr="McGuire 1980" startWordPosition="1227" endWordPosition="1228"> [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980]). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. We have so far identified the following five types of problems that occur often in scruffy unedited texts. Each problem is illustrated by an example from the domain of Navy messages. The next section will then describe how NOMAD deals with each type of error. 1. Unknown words (e.g., Enemy &apos;scudded&apos; bombs at us. -- the verb is unknown to the system); 2. Missing su</context>
</contexts>
<marker>McGuire, 1980</marker>
<rawString>McGuire, R. 1980. Political Primaries and Words of Pain. Unpublished ms., Dept. of Computer Science, Yale University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Riesbeck</author>
<author>R Schank</author>
</authors>
<title>Comprehension by computer: Expectation-based analysis of sentences in context.</title>
<date>1976</date>
<journal>Computer Science Research Report</journal>
<volume>78</volume>
<institution>Yale University.</institution>
<contexts>
<context position="7699" citStr="Riesbeck and Schank 1976" startWordPosition="1204" endWordPosition="1207">even apparently very simple texts may contain alternative possible interpretations, which can cause a reader to construct erroneous initial inferences that must later be corrected (see [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980]). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. We have so far identified the following five types of problems that occur often in scruffy unedited texts. Each problem is illustrated by an example from the domain of Navy messages. The next s</context>
</contexts>
<marker>Riesbeck, Schank, 1976</marker>
<rawString>Riesbeck, C. and Schank, R. 1976. Comprehension by computer: Expectation-based analysis of sentences in context. Computer Science Research Report 78, Yale University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schenk</author>
<author>R Abelson</author>
</authors>
<title>Scripts. Plans. Goals and Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hillsdale, N.J.</location>
<marker>Schenk, Abelson, 1977</marker>
<rawString>Schenk, R.C., and Abelson, R. 1977 Scripts. Plans. Goals and Understanding. Lawrence Erlbaum Associates, Hillsdale, N.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Understanding Goal-Based Stories. Computer Science</title>
<date>1978</date>
<tech>Technical Report 140,</tech>
<institution>Yale University.</institution>
<contexts>
<context position="7809" citStr="Wilensky 1978" startWordPosition="1219" endWordPosition="1220"> erroneous initial inferences that must later be corrected (see [Granger 1980,1981]). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the context of Naval messages. 3.0 How NOMAD Recognizes and Corrects Errors 3.1 Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (e.g., [Riesbeck and Schank 1976], [Birnbaum and Selfridge 1979]); situation and intention inference (e.g., (Cullingford 19771, [Wilensky 1978]); and English generation (e.g. [Goldman 1973], [McGuire 1980]). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. We have so far identified the following five types of problems that occur often in scruffy unedited texts. Each problem is illustrated by an example from the domain of Navy messages. The next section will then describe how NOMAD deals with each type of error. 1. Unknown words (e.g., Enemy &apos;scudded&apos; bom</context>
</contexts>
<marker>Wilensky, 1978</marker>
<rawString>Wilensky, R. 1978. Understanding Goal-Based Stories. Computer Science Technical Report 140, Yale University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>