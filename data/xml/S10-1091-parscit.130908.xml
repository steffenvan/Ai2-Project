<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018260">
<title confidence="0.993467">
HIT-CIR: An Unsupervised WSD System Based on Domain Most
Frequent Sense Estimation
</title>
<author confidence="0.999556">
Yuhang Guo, Wanxiang Che, Wei He, Ting Liu, Sheng Li
</author>
<affiliation confidence="0.996761">
Harbin Institute of Technolgy
</affiliation>
<address confidence="0.9195">
Harbin, Heilongjiang, PRC
</address>
<email confidence="0.998863">
yhguo@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.993895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999630909090909">
This paper presents an unsupervised sys-
tem for all-word domain specific word
sense disambiguation task. This system
tags target word with the most frequent
sense which is estimated using a thesaurus
and the word distribution information in
the domain. The thesaurus is automati-
cally constructed from bilingual parallel
corpus using paraphrase technique. The
recall of this system is 43.5% on SemEval-
2 task 17 English data set.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995734888888889">
Tagging polysemous word with its most frequent
sense (MFS) is a popular back-off heuristic in
word sense disambiguation (WSD) systems when
the training data is inadequate. In past evalua-
tions, MFS from WordNet performed even bet-
ter than most of the unsupervised systems (Snyder
and Palmer, 2004; Navigli et al., 2007).
MFS is usually obtained from a large scale
sense tagged corpus, such as SemCor (Miller et al.,
1994). However, some polysemous words have
different MFS in different domains. For example,
in the Koeling et al. (2005) corpus, target word
coach means “manager” mostly in the SPORTS
domain but means “bus” mostly in the FINANCE
domain. So when the MFS is applied to specific
domains, it needs to be re-estimated.
McCarthy et al. (2007) proposed an unsuper-
vised predominant word sense acquisition method
which obtains domain specific MFS without sense
tagged corpus. In their method, a thesaurus, in
which words are connected with their distribu-
tional similarity, is constructed from the domain
raw text. Word senses are ranked by their preva-
lence score which is calculated using the thesaurus
and the sense inventory.
In this paper, we propose another way to con-
struct the thesaurus. We use statistical machine
</bodyText>
<figureCaption confidence="0.999832">
Figure 1: The architecture of HIT-CIR
</figureCaption>
<bodyText confidence="0.999796071428571">
translation (SMT) techniques to extract paraphrase
pairs from bilingual parallel text. In this way, we
avoid calculating similarities between every pair
of words and could find semantic similar words or
compounds which have dissimilar distributions.
Our system is comprised of two parts: the word
sense ranking part and the word sense tagging part.
Senses are ranked according to their prevalence
score in the target domain, and the predominant
sense is used to tag the occurrences of the target
word in the test data. The architecture of this sys-
tem is shown in Figure 1.
The word sense ranking part includes following
steps.
</bodyText>
<listItem confidence="0.997318">
1. Tag the POS of the background text, count
the word frequency in each POS, and get the
polysemous word list of the POS.
2. Using SMT techniques to extract phrase table
</listItem>
<page confidence="0.971331">
407
</page>
<note confidence="0.7578115">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 407–410,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.998823">
Figure 2: Word sense ranking for the noun backbone
</figureCaption>
<bodyText confidence="0.975397380952381">
from the bilingual corpus. Extract the para-
phrases (called as neighbor words) with the
phrase table for each word in the polysemous
word list.
3. Calculate the prevalence score of each sense
of the target words, rank the senses with the
score and obtain the predominant sense.
We applied our system on the English data set
of SemEval-2 specific domain WSD task. This
task is an all word WSD task in the environ-
mental domain. We employed the domain back-
ground raw text provided by the task organizer as
well as the English WordNet 3.0 (Fellbaum, 1998)
and the English-Spanish parallel corpus from Eu-
roparl (Koehn, 2005).
This paper is organized as follows. Section 2
introduces how to rank word senses. Section 3
presents how to obtain the most related words of
the target words. We describe the system settings
in Section 4 and offer some discussions in Sec-
tion 5.
</bodyText>
<sectionHeader confidence="0.888367" genericHeader="method">
2 Word Sense Ranking
</sectionHeader>
<bodyText confidence="0.999965666666667">
In our method, word senses are ranked according
to their prevalence score in the specific domain.
According to the assumption of McCarthy et al.
(2007), the prevalence score is affected by the fol-
lowing two factors: (1) The relatedness score be-
tween a given sense of the target word and the
target word’s neighbor word. (2) The similarity
between the target word and its neighbor word.
In addition, we add another factor, (3) the impor-
tance of the neighbor word in the specific domain.
In this paper, “neighbor words” means the words
which are most semantically similar to the target
word.
Figure 2 illustrates the word sense ranking pro-
cess of noun backbone. The contribution of a
neighbor word to a given word sense is measured
by the similarity between them and weighted by
the importance of the neighbor word in the tar-
get domain and the relatedness between the neigh-
bor word and the target word. Sum up the con-
tributions of each neighbor words, and we get the
prevalence score of the word sense.
Formally, the prevalence score of sense si of a
target word w is assigned as follows:
</bodyText>
<equation confidence="0.886764333333333">
�ps(w, si) = rs(w, nj) x ns(si, nj) x dw(nj)
njENw
(1)
</equation>
<bodyText confidence="0.692589">
where
</bodyText>
<equation confidence="0.99517575">
ns(si, sss(si nj) = (2)
, nj) sss(si′ &apos;
3i′∈senses(w) , n j)
sss(si, nj) = maxs.Esenses(nj)sss′(si, sx). (3)
</equation>
<bodyText confidence="0.9576119">
rs(w, nj) is the relatedness score between w and
a neighbor word nj. N,,, = {n1, n2,... , nk}
is the top k relatedness score neighbor word set.
ns(si, nj) is the normalized form of the sense sim-
ilarity score between sense si and the neighbor
word nj (i.e. sss(si,nj)). We define this score
with the maximum WordNet similarity score be-
tween si and the senses of nj (i.e. sss′(si,nj)).
In our system, lesk algorithm is used to measure
the sense similarity score between word senses.
</bodyText>
<page confidence="0.996554">
408
</page>
<figureCaption confidence="0.999565">
Figure 3: Finding the neighbor words of noun backbone
</figureCaption>
<bodyText confidence="0.999813333333333">
The similarity of this algorithm is the count of
the number of overlap words in the gloss or the
definition of the senses (Banerjee and Pedersen,
2002). The domain importance weight dw(nj) is
assigned with the count of nj in the domain back-
ground corpus. For the neighbor word that does
not occur in the domain background text, we use
the add-one strategy. We will describe how to ob-
tain nj and rs in Section 3.
</bodyText>
<sectionHeader confidence="0.996362" genericHeader="method">
3 Thesaurus Construction
</sectionHeader>
<bodyText confidence="0.999985333333333">
The neighbor words of the target word as well as
the relatedness score are obtained by extracting
paraphrases from bilingual parallel texts. When
a word is translated from source language to tar-
get language and then translated back to the source
language, the final translation may have the same
meaning to the original word but with different ex-
pressions (e.g. different word or compound). The
translation in the same language could be viewed
as a paraphrase term or, at least, related term of the
original word.
For example, in Figure 3, English noun back-
bone can be translated to columna, columna verte-
bral, pilar and convicciones etc. in Spanish, and
these words also have other relevant translations
in English, such as vertebral column, column, pil-
lar and convictions etc., which are semantically re-
lated to the target word backbone.
We use a statistical machine translation sys-
tem to calculate the translation probability from
English to another language (called as pivot lan-
guage) as well as the translation probability from
that language to English. By multiplying these
two probabilities, we get a paraphrase probabil-
ity. This method was defined in (Bannard and
Callison-Burch, 2005).
In our system, we choose the top k paraphrases
as the neighbor words of the target word, which
have the highest paraphrase probability. Note that
there are two directions of the paraphrase, from
target word to its neighbor word and from the
neighbor word to the target word. We choose
the paraphrase score of the former direction as
the relatedness score (rs). Because the higher
of the score in this direction, the target word is
more likely paraphrased to that neighbor word,
and hence the prevalence of the relevant target
word sense will be higher than other senses. For-
mally, the relatedness score is given by
</bodyText>
<equation confidence="0.98111">
�rs(w, nj) � p(f|w)p(nj|f), (4)
f
</equation>
<bodyText confidence="0.999900285714286">
where f is the pivot language word.
We use the English-Spanish parallel text from
Europarl (Koehn, 2005). We choose Spanish as
the pivot language because in the both directions
the BLEU score of the translation between English
and Spanish is relatively higher than other English
and other languages (Koehn, 2005).
</bodyText>
<sectionHeader confidence="0.794074" genericHeader="method">
4 Data set and System Settings
</sectionHeader>
<bodyText confidence="0.995729928571429">
The organizers of the SemEval-2 specific domain
WSD task provide no training data but raw back-
ground data in the environmental domain. The En-
glish background data is obtained from the offi-
cial web site of World Wide Fund (WWF), Euro-
pean Centre for Nature Conservation (ECNC), Eu-
ropean Commission and the United Nations Eco-
nomic Commission for Europe (UNECE). The
size of the raw text is around 15.5MB after sim-
ple text cleaning. The test data is from WWF and
ECNC, and contains 1398 occurrence of 436 tar-
get words.
For the implementation, we used bpos (Shen et
al., 2007) for the POS tagging. The maximum
</bodyText>
<page confidence="0.998174">
409
</page>
<bodyText confidence="0.999896">
number of the neighbor word of each target word k
was set to 50. We employed Giza++1 and Moses2
to get the phrase table from the bilingual paral-
lel corpus. The WordNet::Similarity package3 was
applied for the implement of the lesk word sense
similarity algorithm.
For the target word that is not in the polysemous
word list, we use the MFS from WordNet as the
back-off method.
</bodyText>
<sectionHeader confidence="0.990177" genericHeader="conclusions">
5 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.9999759375">
The recall of our system is 43.5%, which is lower
than that of the MFS baseline, 50.5% (Agirre et
al., 2010). The baseline uses the most frequent
sense from the SemCor corpus (i.e. the MFS of
WordNet). This means that for some target words,
the MFS from SemCor is better than the domain
MFS we estimated in the environmental domain.
In the future, we will analysis errors in detail to
find the effects of the domain on the MFS.
For the domain specific task, it is better to use
parallel text in the domain of the test data in our
method. However, we didn’t find any available
parallel text in the environmental domain yet. In
the future, we will try some parallel corpus acqui-
sition techniques to obtain relevant corpus for en-
vironmental domain for our method.
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999054">
This work was supported by National Natural
Science Foundation of China (NSFC) via grant
60803093, 60975055, the “863” National High-
Tech Research and Development of China via
grant 2008AA01Z144, and Natural Scientific Re-
search Innovation Foundation in Harbin Institute
of Technology (HIT.NSRIF.2009069).
</bodyText>
<sectionHeader confidence="0.992938" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.5417332">
Eneko Agirre, Oier Lopez de Lacalle, Christiane Fell-
baum, Shu kai Hsieh, Maurizio Tesconi, Mon-
ica Monachini, Piek Vossen, and Roxanne Segers.
2010. Semeval-2010 task 17: All-words word sense
disambiguation on a specific domain. In Proceed-
</reference>
<construct confidence="0.809429">
ings of the 5th International Workshop on Semantic
Evaluations (SemEval-2010), Association for Com-
putational Linguistics.
</construct>
<bodyText confidence="0.721869666666667">
Satanjeev Banerjee and Ted Pedersen. 2002. An
adapted lesk algorithm for word sense disambigua-
tion using wordnet. In CICLing ’02: Proceedings
</bodyText>
<footnote confidence="0.999860333333333">
1http://www.fjoch.com/GIZA++.html
2http://www.statmt.org/moses/
3http://wn-similarity.sourceforge.net/
</footnote>
<reference confidence="0.99794275">
of the Third International Conference on Compu-
tational Linguistics and Intelligent Text Processing,
pages 136–145, London, UK. Springer-Verlag.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In ACL
’05: Proceedings of the 43rd Annual Meeting on As-
sociation for Computational Linguistics, pages 597–
604, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In The Tenth Ma-
chine Translation Summit, Phuket, Thailand.
Rob Koeling, Diana McCarthy, and John Carroll.
2005. Domain-specific sense distributions and pre-
dominant sense acquisition. In Proceedings of Hu-
man Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language
Processing, pages 419–426, Vancouver, British
Columbia, Canada, October. Association for Com-
putational Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised acquisition of pre-
dominant word senses. Computational Linguistics,
33(4):553–590, December.
G. A. Miller, C. Leacock, R. Tengi, and R. Bunker.
1994. A semantic concordance. In Proc. ARPA
Human Language Technology Workshop ’93, pages
303–308, Princeton, NJ, March. distributed as Hu-
man Language Technology by San Mateo, CA: Mor-
gan Kaufmann Publishers.
Roberto Navigli, Kenneth C. Litkowski, and Orin Har-
graves. 2007. Semeval-2007 task 07: Coarse-
grained english all-words task. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), pages 30–35, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classi-
fication. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 760–767, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Benjamin Snyder and Martha Palmer. 2004. The en-
glish all-words task. In Rada Mihalcea and Phil
Edmonds, editors, Senseval-3: Third International
Workshop on the Evaluation of Systems for the Se-
mantic Analysis of Text, pages 41–43, Barcelona,
Spain, July. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.997019">
410
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.644733">
<title confidence="0.999068">HIT-CIR: An Unsupervised WSD System Based on Domain Most Frequent Sense Estimation</title>
<author confidence="0.99795">Yuhang Guo</author>
<author confidence="0.99795">Wanxiang Che</author>
<author confidence="0.99795">Wei He</author>
<author confidence="0.99795">Ting Liu</author>
<author confidence="0.99795">Sheng Li</author>
<affiliation confidence="0.999947">Harbin Institute of Technolgy</affiliation>
<address confidence="0.992335">Harbin, Heilongjiang, PRC</address>
<email confidence="0.924414">yhguo@ir.hit.edu.cn</email>
<abstract confidence="0.972472666666667">This paper presents an unsupervised system for all-word domain specific word sense disambiguation task. This system tags target word with the most frequent sense which is estimated using a thesaurus and the word distribution information in the domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval- 2 task 17 English data set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
<author>Christiane Fellbaum</author>
<author>Shu kai Hsieh</author>
<author>Maurizio Tesconi</author>
<author>Monica Monachini</author>
<author>Piek Vossen</author>
<author>Roxanne Segers</author>
</authors>
<title>Semeval-2010 task 17: All-words word sense disambiguation on a specific domain.</title>
<date>2010</date>
<booktitle>In Proceedof the Third International Conference on Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>136--145</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<marker>Agirre, de Lacalle, Fellbaum, Hsieh, Tesconi, Monachini, Vossen, Segers, 2010</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, Christiane Fellbaum, Shu kai Hsieh, Maurizio Tesconi, Monica Monachini, Piek Vossen, and Roxanne Segers. 2010. Semeval-2010 task 17: All-words word sense disambiguation on a specific domain. In Proceedof the Third International Conference on Computational Linguistics and Intelligent Text Processing, pages 136–145, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>597--604</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7269" citStr="Bannard and Callison-Burch, 2005" startWordPosition="1215" endWordPosition="1218">e can be translated to columna, columna vertebral, pilar and convicciones etc. in Spanish, and these words also have other relevant translations in English, such as vertebral column, column, pillar and convictions etc., which are semantically related to the target word backbone. We use a statistical machine translation system to calculate the translation probability from English to another language (called as pivot language) as well as the translation probability from that language to English. By multiplying these two probabilities, we get a paraphrase probability. This method was defined in (Bannard and Callison-Burch, 2005). In our system, we choose the top k paraphrases as the neighbor words of the target word, which have the highest paraphrase probability. Note that there are two directions of the paraphrase, from target word to its neighbor word and from the neighbor word to the target word. We choose the paraphrase score of the former direction as the relatedness score (rs). Because the higher of the score in this direction, the target word is more likely paraphrased to that neighbor word, and hence the prevalence of the relevant target word sense will be higher than other senses. Formally, the relatedness s</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597– 604, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3507" citStr="Fellbaum, 1998" startWordPosition="567" endWordPosition="568">l Linguistics Figure 2: Word sense ranking for the noun backbone from the bilingual corpus. Extract the paraphrases (called as neighbor words) with the phrase table for each word in the polysemous word list. 3. Calculate the prevalence score of each sense of the target words, rank the senses with the score and obtain the predominant sense. We applied our system on the English data set of SemEval-2 specific domain WSD task. This task is an all word WSD task in the environmental domain. We employed the domain background raw text provided by the task organizer as well as the English WordNet 3.0 (Fellbaum, 1998) and the English-Spanish parallel corpus from Europarl (Koehn, 2005). This paper is organized as follows. Section 2 introduces how to rank word senses. Section 3 presents how to obtain the most related words of the target words. We describe the system settings in Section 4 and offer some discussions in Section 5. 2 Word Sense Ranking In our method, word senses are ranked according to their prevalence score in the specific domain. According to the assumption of McCarthy et al. (2007), the prevalence score is affected by the following two factors: (1) The relatedness score between a given sense </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In The Tenth Machine Translation</booktitle>
<location>Summit, Phuket, Thailand.</location>
<contexts>
<context position="3575" citStr="Koehn, 2005" startWordPosition="577" endWordPosition="578">he bilingual corpus. Extract the paraphrases (called as neighbor words) with the phrase table for each word in the polysemous word list. 3. Calculate the prevalence score of each sense of the target words, rank the senses with the score and obtain the predominant sense. We applied our system on the English data set of SemEval-2 specific domain WSD task. This task is an all word WSD task in the environmental domain. We employed the domain background raw text provided by the task organizer as well as the English WordNet 3.0 (Fellbaum, 1998) and the English-Spanish parallel corpus from Europarl (Koehn, 2005). This paper is organized as follows. Section 2 introduces how to rank word senses. Section 3 presents how to obtain the most related words of the target words. We describe the system settings in Section 4 and offer some discussions in Section 5. 2 Word Sense Ranking In our method, word senses are ranked according to their prevalence score in the specific domain. According to the assumption of McCarthy et al. (2007), the prevalence score is affected by the following two factors: (1) The relatedness score between a given sense of the target word and the target word’s neighbor word. (2) The simi</context>
<context position="8024" citStr="Koehn, 2005" startWordPosition="1346" endWordPosition="1347">that there are two directions of the paraphrase, from target word to its neighbor word and from the neighbor word to the target word. We choose the paraphrase score of the former direction as the relatedness score (rs). Because the higher of the score in this direction, the target word is more likely paraphrased to that neighbor word, and hence the prevalence of the relevant target word sense will be higher than other senses. Formally, the relatedness score is given by �rs(w, nj) � p(f|w)p(nj|f), (4) f where f is the pivot language word. We use the English-Spanish parallel text from Europarl (Koehn, 2005). We choose Spanish as the pivot language because in the both directions the BLEU score of the translation between English and Spanish is relatively higher than other English and other languages (Koehn, 2005). 4 Data set and System Settings The organizers of the SemEval-2 specific domain WSD task provide no training data but raw background data in the environmental domain. The English background data is obtained from the official web site of World Wide Fund (WWF), European Centre for Nature Conservation (ECNC), European Commission and the United Nations Economic Commission for Europe (UNECE). </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In The Tenth Machine Translation Summit, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Koeling</author>
<author>Diana McCarthy</author>
<author>John Carroll</author>
</authors>
<title>Domain-specific sense distributions and predominant sense acquisition.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>419--426</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="1197" citStr="Koeling et al. (2005)" startWordPosition="183" endWordPosition="186">he recall of this system is 43.5% on SemEval2 task 17 English data set. 1 Introduction Tagging polysemous word with its most frequent sense (MFS) is a popular back-off heuristic in word sense disambiguation (WSD) systems when the training data is inadequate. In past evaluations, MFS from WordNet performed even better than most of the unsupervised systems (Snyder and Palmer, 2004; Navigli et al., 2007). MFS is usually obtained from a large scale sense tagged corpus, such as SemCor (Miller et al., 1994). However, some polysemous words have different MFS in different domains. For example, in the Koeling et al. (2005) corpus, target word coach means “manager” mostly in the SPORTS domain but means “bus” mostly in the FINANCE domain. So when the MFS is applied to specific domains, it needs to be re-estimated. McCarthy et al. (2007) proposed an unsupervised predominant word sense acquisition method which obtains domain specific MFS without sense tagged corpus. In their method, a thesaurus, in which words are connected with their distributional similarity, is constructed from the domain raw text. Word senses are ranked by their prevalence score which is calculated using the thesaurus and the sense inventory. I</context>
</contexts>
<marker>Koeling, McCarthy, Carroll, 2005</marker>
<rawString>Rob Koeling, Diana McCarthy, and John Carroll. 2005. Domain-specific sense distributions and predominant sense acquisition. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 419–426, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Unsupervised acquisition of predominant word senses.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1413" citStr="McCarthy et al. (2007)" startWordPosition="220" endWordPosition="223">stems when the training data is inadequate. In past evaluations, MFS from WordNet performed even better than most of the unsupervised systems (Snyder and Palmer, 2004; Navigli et al., 2007). MFS is usually obtained from a large scale sense tagged corpus, such as SemCor (Miller et al., 1994). However, some polysemous words have different MFS in different domains. For example, in the Koeling et al. (2005) corpus, target word coach means “manager” mostly in the SPORTS domain but means “bus” mostly in the FINANCE domain. So when the MFS is applied to specific domains, it needs to be re-estimated. McCarthy et al. (2007) proposed an unsupervised predominant word sense acquisition method which obtains domain specific MFS without sense tagged corpus. In their method, a thesaurus, in which words are connected with their distributional similarity, is constructed from the domain raw text. Word senses are ranked by their prevalence score which is calculated using the thesaurus and the sense inventory. In this paper, we propose another way to construct the thesaurus. We use statistical machine Figure 1: The architecture of HIT-CIR translation (SMT) techniques to extract paraphrase pairs from bilingual parallel text.</context>
<context position="3994" citStr="McCarthy et al. (2007)" startWordPosition="648" endWordPosition="651">l domain. We employed the domain background raw text provided by the task organizer as well as the English WordNet 3.0 (Fellbaum, 1998) and the English-Spanish parallel corpus from Europarl (Koehn, 2005). This paper is organized as follows. Section 2 introduces how to rank word senses. Section 3 presents how to obtain the most related words of the target words. We describe the system settings in Section 4 and offer some discussions in Section 5. 2 Word Sense Ranking In our method, word senses are ranked according to their prevalence score in the specific domain. According to the assumption of McCarthy et al. (2007), the prevalence score is affected by the following two factors: (1) The relatedness score between a given sense of the target word and the target word’s neighbor word. (2) The similarity between the target word and its neighbor word. In addition, we add another factor, (3) the importance of the neighbor word in the specific domain. In this paper, “neighbor words” means the words which are most semantically similar to the target word. Figure 2 illustrates the word sense ranking process of noun backbone. The contribution of a neighbor word to a given word sense is measured by the similarity bet</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2007</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2007. Unsupervised acquisition of predominant word senses. Computational Linguistics, 33(4):553–590, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>C Leacock</author>
<author>R Tengi</author>
<author>R Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1994</date>
<booktitle>In Proc. ARPA Human Language Technology Workshop ’93,</booktitle>
<pages>303--308</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>Princeton, NJ,</location>
<contexts>
<context position="1082" citStr="Miller et al., 1994" startWordPosition="165" endWordPosition="168">he domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval2 task 17 English data set. 1 Introduction Tagging polysemous word with its most frequent sense (MFS) is a popular back-off heuristic in word sense disambiguation (WSD) systems when the training data is inadequate. In past evaluations, MFS from WordNet performed even better than most of the unsupervised systems (Snyder and Palmer, 2004; Navigli et al., 2007). MFS is usually obtained from a large scale sense tagged corpus, such as SemCor (Miller et al., 1994). However, some polysemous words have different MFS in different domains. For example, in the Koeling et al. (2005) corpus, target word coach means “manager” mostly in the SPORTS domain but means “bus” mostly in the FINANCE domain. So when the MFS is applied to specific domains, it needs to be re-estimated. McCarthy et al. (2007) proposed an unsupervised predominant word sense acquisition method which obtains domain specific MFS without sense tagged corpus. In their method, a thesaurus, in which words are connected with their distributional similarity, is constructed from the domain raw text. </context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1994</marker>
<rawString>G. A. Miller, C. Leacock, R. Tengi, and R. Bunker. 1994. A semantic concordance. In Proc. ARPA Human Language Technology Workshop ’93, pages 303–308, Princeton, NJ, March. distributed as Human Language Technology by San Mateo, CA: Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Kenneth C Litkowski</author>
<author>Orin Hargraves</author>
</authors>
<title>Semeval-2007 task 07: Coarsegrained english all-words task.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>30--35</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="980" citStr="Navigli et al., 2007" startWordPosition="147" endWordPosition="150">the most frequent sense which is estimated using a thesaurus and the word distribution information in the domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval2 task 17 English data set. 1 Introduction Tagging polysemous word with its most frequent sense (MFS) is a popular back-off heuristic in word sense disambiguation (WSD) systems when the training data is inadequate. In past evaluations, MFS from WordNet performed even better than most of the unsupervised systems (Snyder and Palmer, 2004; Navigli et al., 2007). MFS is usually obtained from a large scale sense tagged corpus, such as SemCor (Miller et al., 1994). However, some polysemous words have different MFS in different domains. For example, in the Koeling et al. (2005) corpus, target word coach means “manager” mostly in the SPORTS domain but means “bus” mostly in the FINANCE domain. So when the MFS is applied to specific domains, it needs to be re-estimated. McCarthy et al. (2007) proposed an unsupervised predominant word sense acquisition method which obtains domain specific MFS without sense tagged corpus. In their method, a thesaurus, in whi</context>
</contexts>
<marker>Navigli, Litkowski, Hargraves, 2007</marker>
<rawString>Roberto Navigli, Kenneth C. Litkowski, and Orin Hargraves. 2007. Semeval-2007 task 07: Coarsegrained english all-words task. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 30–35, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>760--767</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="8836" citStr="Shen et al., 2007" startWordPosition="1484" endWordPosition="1487"> (Koehn, 2005). 4 Data set and System Settings The organizers of the SemEval-2 specific domain WSD task provide no training data but raw background data in the environmental domain. The English background data is obtained from the official web site of World Wide Fund (WWF), European Centre for Nature Conservation (ECNC), European Commission and the United Nations Economic Commission for Europe (UNECE). The size of the raw text is around 15.5MB after simple text cleaning. The test data is from WWF and ECNC, and contains 1398 occurrence of 436 target words. For the implementation, we used bpos (Shen et al., 2007) for the POS tagging. The maximum 409 number of the neighbor word of each target word k was set to 50. We employed Giza++1 and Moses2 to get the phrase table from the bilingual parallel corpus. The WordNet::Similarity package3 was applied for the implement of the lesk word sense similarity algorithm. For the target word that is not in the polysemous word list, we use the MFS from WordNet as the back-off method. 5 Discussion and Future Work The recall of our system is 43.5%, which is lower than that of the MFS baseline, 50.5% (Agirre et al., 2010). The baseline uses the most frequent sense from</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Libin Shen, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 760–767, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The english all-words task.</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>41--43</pages>
<editor>In Rada Mihalcea and Phil Edmonds, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="957" citStr="Snyder and Palmer, 2004" startWordPosition="143" endWordPosition="146">em tags target word with the most frequent sense which is estimated using a thesaurus and the word distribution information in the domain. The thesaurus is automatically constructed from bilingual parallel corpus using paraphrase technique. The recall of this system is 43.5% on SemEval2 task 17 English data set. 1 Introduction Tagging polysemous word with its most frequent sense (MFS) is a popular back-off heuristic in word sense disambiguation (WSD) systems when the training data is inadequate. In past evaluations, MFS from WordNet performed even better than most of the unsupervised systems (Snyder and Palmer, 2004; Navigli et al., 2007). MFS is usually obtained from a large scale sense tagged corpus, such as SemCor (Miller et al., 1994). However, some polysemous words have different MFS in different domains. For example, in the Koeling et al. (2005) corpus, target word coach means “manager” mostly in the SPORTS domain but means “bus” mostly in the FINANCE domain. So when the MFS is applied to specific domains, it needs to be re-estimated. McCarthy et al. (2007) proposed an unsupervised predominant word sense acquisition method which obtains domain specific MFS without sense tagged corpus. In their meth</context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The english all-words task. In Rada Mihalcea and Phil Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 41–43, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>