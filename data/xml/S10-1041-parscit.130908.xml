<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008937">
<title confidence="0.945925">
KP-Miner: Participation in SemEval-2
</title>
<author confidence="0.492378">
Samhaa R. El-Beltagy Ahmed Rafea
</author>
<affiliation confidence="0.3370055">
Cairo University The American University in Cairo
Giza, Egypt. New Cairo, Egypt.
</affiliation>
<email confidence="0.991204">
samhaa@computer.org rafea@aucegypt.edu
</email>
<sectionHeader confidence="0.997278" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996693625">
This paper briefly describes the KP-Miner sys-
tem which is a system developed for the ex-
traction of keyphrases from English and Arab-
ic documents, irrespective of their nature. The
paper also outlines the performance of the sys-
tem in the “Automatic Keyphrase Extraction
from Scientific Articles” task which is part of
SemEval-2.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99971365">
KP-Miner (El-Beltagy, 2006) (El-Beltagy, 2009)
is a system for the extraction of keyphrases from
English and Arabic documents. When develop-
ing the system, the goal was to build a general
purpose keyphrase extraction system that can be
easily configured by users based on their under-
standing of the documents from which keyphras-
es are to be extracted and without the need for
any training documents or the use of any sophis-
ticated natural language processing or linguistic
tools. As such, the keyphrase extraction process
in KP-Miner is an un-supervised one. When
building a general purpose keyphrase extraction
system, this was an important objective, as train-
ing data is not always readily available for any
type of data. The goal of entering the KP-Miner
system into the SemEval-2 competition, was to
see how well it will perform on a specific task,
without making any changes in its default para-
meters.
</bodyText>
<sectionHeader confidence="0.991614" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.9993385">
Keyphrase extraction in the KP-Miner system is
a three step process: candidate keyphrase selec-
tion, candidate keyphrase weight calculation and
finally keyphrase refinement. Each of these
steps, is explained in the following sub-sections.
More details about the employed algorithm, and
justification for using certain values for selected
parameters, can be found in (El-Beltagy, 2009).
</bodyText>
<subsectionHeader confidence="0.992138">
2.1 Candidate keyphrase selection
</subsectionHeader>
<bodyText confidence="0.999963972972973">
In KP-Miner, a set of rules is employed in order
to elicit candidate keyphrases. As a phrase will
never be separated by punctuation marks within
some given text and will rarely have stop words
within it, the first condition a sequence of words
has to display in order to be considered a candi-
date keyphrase, is that it is not be separated by
punctuation marks or stop words. A total of 187
common stopwords (the, then, in, above, etc)
are used in the candidate keyphrase extraction
step. After applying this first condition on any
given document, too many candidates will be
generated; some of which will make no sense to
a human reader. To filter these out, two further
conditions are applied. The first condition states
that a phrase has to have appeared at least n
times in the document from which keyphrases
are to be extracted, in order to be considered a
candidate keyphrase. This is called the least al-
lowable seen frequency(lasf) factor and in the
English version of the system, this is set to 3.
However, if a document is short, n is decre-
mented depending on the length of the document.
The second condition is related to the position
where a candidate keyphrase first appears within
an input document. Through observation as well
as experimentation, it was found that in long
documents, phrases occurring for the first time
after a given threshold, are very rarely keyphras-
es. So a cutoff constant CutOff is defined in
terms of a number of words after which if a
phrase appears for the first time, it is filtered out
and ignored. The initial prototype of the KP-
Miner system (El-Beltagy, 2006), set this cutoff
value to a constant (850). Further experimenta-
tion carried out in (El-Beltagy, 2009) revealed
that an optimum value for this constant is 400. In
</bodyText>
<page confidence="0.991396">
190
</page>
<bodyText confidence="0.967997576923077">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 190–193,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
the implementation of the KP-Miner system, the
phrase extraction step described above is carried
out in two phases. In the first phase, words are
scanned until either a punctuation mark or a stop
word is encountered. The scanned sequence of
words and all possible n-grams within the en-
countered sequence where n can vary from 1 to
sequence length-1, are stemmed and stored in
both their original and stemmed forms. If the
phrase (in its stemmed or original form) or any
of its sub-phrases, has been seen before, then the
count of the previously seen term is incremented
by one, otherwise the previously unseen term is
assigned a count of one. Very weak stemming is
performed in this step using only the first step of
the Porter stemmer (Porter, 1980). In the second
phase, the document is scanned again for the
longest possible sequence that fulfills the condi-
tions mentioned above. This is then considered
as a candidate keyphrase. Unlike most of the
other keyphrase extraction systems, the devised
algorithm places no limit on the length of keyp-
hrases, but it was found that extracted keyphrases
rarely exceed three terms.
</bodyText>
<subsectionHeader confidence="0.9737045">
2.2 Candidate keyphrases weight calcula-
tion
</subsectionHeader>
<bodyText confidence="0.987727467741936">
Single key features obtained from documents by
models such as TF-IDF (Salton and Buckley,
1988) have already been shown to be representa-
tive of documents from which they’ve been ex-
tracted as demonstrated by their wide and suc-
cessful use in clustering and classification tasks.
However, when applied to the task of keyphrase
extraction, these same models performed very
poorly (Turney, 1999). By looking at almost
any document, it can be observed that the occur-
rences of phrases is much less frequent than the
occurrence of single terms within the same doc-
ument. So it can be concluded that one of the
reasons that TF-IDF performs poorly on its own
when applied to the task of keyphrase extraction,
is that it does not take this fact into consideration
which results in a bias towards single words as
they occur in larger numbers. So, a boosting fac-
tor is needed for compound terms in order to bal-
ance this bias towards single terms. In this work
for each input document d from which keyphras-
es are to be extracted, a boosting factor Bd is
calculated as follows:
Bd= |Nd |/(|Pd |*∝)
and if Bd &gt; σ then Bd = σ
Here |Nd |is the number of all candidate terms in
document d, |Pd |is the number of candidate
terms whose length exceeds one in document d
and ∝ and σ are weight adjustment constants.
The values used by the implemented system are
3 for σ and 2.3 for ∝ .
To calculate the weights of document terms, the
TF-IDF model in conjunction with the intro-
duced boosting factor, is used. However, another
thing to consider when applying TF-IDF for a
general application rather than a corpus specific
one, is that keyphrase combinations do not occur
as frequently within a document set as do single
terms. In other words, while it is possible to col-
lect frequency information for use by a general
single keyword extractor from a moderately large
set of random documents, the same is not true for
keyphrase information. There are two possible
approaches to address this observation. In the
first, a very large corpus of a varied nature can
be used to collect keyphrase related frequency
information. In the second, which is adopted in
this work, any encountered phrase is considered
to have appeared only once in the corpus. This
means that for compound phrases, frequency
within a document as well as the boosting factor
are really what determine its weight as the idf
value for all compound phrases will be a constant
c determined by the size of the corpus used to
build frequency information for single terms. If
the position rules described in (El-Beltagy, 2009)
are also employed, then the position factor is also
used in the calculation for the term weights. In
summary, the following equation is used to cal-
culate the weight of candidate keyphrases wheth-
er single or compound:
wij = tfij* idf * Bi* Pf
</bodyText>
<sectionHeader confidence="0.503062" genericHeader="method">
Where:
</sectionHeader>
<bodyText confidence="0.953429571428572">
wij = weight of term tj in Document Di
tfij = frequency of term tj in Document Di
idf = log2 N/n where N is the number of doc-
uments in the collection and n is num-
ber of documents where term tj occurs
at least once. If the term is compound, n
is set to 1.
</bodyText>
<figure confidence="0.6050556">
Bi = the boosting factor associated with doc-
ument Di
Pf= the term position associated factor. If
position rules are not used this is set to
1.
</figure>
<subsectionHeader confidence="0.996502">
2.3 Final Candidate Phrase List Refinement
</subsectionHeader>
<bodyText confidence="0.9999758">
The KP-Miner system, allows the user to
specify a number n of keyphrases s/he wants
back and uses the sorted list to return the top n
keyphrases requested by the user. The default
number of n is five. As stated in step one, when
</bodyText>
<page confidence="0.993943">
191
</page>
<bodyText confidence="0.99999">
generating candidate keyphrases, the longest
possible sequence of words that are un-
interrupted by possible phrase terminators, are
sought and stored and so are sub-phrases con-
tained within that sequence provided that they
appear somewhere in the text on their own. For
example, if the phrase ‘excess body weight’ is
encountered five times in a document, the phrase
itself will be stored along with a count of five. If
the sub-phrase , ‘body weight’, is also encoun-
tered on its own, than it will also be stored along
with the number of times it appeared in the text
including the number of times it appeared as part
of the phrase ‘excess body weight’. This means
that an overlap between the count of two or more
phrases can exist. Aiming to eliminate this over-
lap in counting early on can contribute to the
dominance of possibly noisy phrases or to over-
looking potential keyphrases that are encoun-
tered as sub-phrases. However, once the weight
calculation step has been performed and a clear
picture of which phrases are most likely to be
key ones is obtained, this overlap can be ad-
dressed through refinement. To refine results in
the KP-Miner system, the top n keys are scanned
to see if any of them is a sub-phrase of another.
If any of them are, then its count is decremented
by the frequency of the term of which it is a part.
After this step is completed, weights are re-
calculated and a final list of phrases sorted by
weight, is produced. The reason the top n keys
rather than all candidates, are used in this step is
so that lower weighted keywords do not affect
the outcome of the final keyphrase list. It is im-
portant to note that the refinement step is an op-
tional one, but experiments have shown that in
the English version of the system, omitting this
step leads to the production of keyphrase lists
that match better with author assigned keyword.
In (El-Beltagy, 2009) the authors suggested that
employing this step leads to the extraction of
higher quality keyphrases. Experimentation car-
ried out on the Gold standard dataset provided by
the organizers of the SemEval-2 competition on
“Keyphrase Extraction from Scientific Docu-
ments” and described in the next section, seems
to suggest that this idea is a valid one.
</bodyText>
<sectionHeader confidence="0.990228" genericHeader="method">
3 Participation in the SemEval-2 Com-
petition
</sectionHeader>
<bodyText confidence="0.999873224489796">
One of the new tracks introduced to SemEval
this year is a track dedicated entirely to keyp-
hrase extraction from scientific articles. The task
was proposed with the aim of providing partici-
pants with “the chance to compete and bench-
mark” this technology (SemEval2, 2010).
In this competition, participants were provided
with 40 trial documents, 144 training documents,
and 100 test documents. For the trial and training
data, three sets of answers were provided: au-
thor-assigned keyphrases, reader-assigned keyp-
hrases, and finally a set that is simply a combina-
tion between the 2 previous sets. Unlike author-
assigned keyphrases, which may or may not oc-
cur in the content, all reader-assigned keyphrases
were said to have been extracted from the papers.
The participants were then asked to produce the
top 15 keyphrases for each article in the test doc-
ument set and to submit the stemmed version of
these to the organizers.
Evaluation was carried out in the traditional
way in which keyphrase sets extracted by each of
the participants were matched against answer
sets (i.e. author-assigned keyphrases and reader-
assigned keyphrases) to calculate precision, re-
call and F-score. Participants were then ranked
by F-score when extracting all 15 keyphrases.
Since the KP-miner system is an unsupervised
keyphrase extraction system, no use was made of
the trial and training data. The system was simp-
ly run of the set of test documents, and the output
was sent to the organizers. 2 different runs were
submitted: one produced used the initial proto-
type of the system, (El-Beltagy, 2006), while the
second was produced using the more mature ver-
sion of the system (El-Beltagy, 2009). Both sys-
tems were run without making any changes to
their default parameters. The idea was to see how
well the KP-Miner would fair among other
keyphrase extraction systems without any addi-
tional configuration. The more mature version of
the system performed better when its results
were compared to the author-reader combined
keyphrase set and consequently was the one
whose final results were taken into consideration
in the competition. The system ranked at 2 , with
a tie between it and another system when extract-
ing 15 keyphrases from the combined keypharse
set. The results are shown in table 1.
</bodyText>
<table confidence="0.992937636363636">
Precision Recall F-Score
HUMB 27.2% 27.8% 27.5%
WINGNUS 24.9% 25.5% 25.2%
KP-Miner 24.9% 25.5% 25.2%
SZTERGAK 24.8% 25.4% 25.1%
ICL 24.6% 25.2% 24.9%
SEERLAB 24.1% 24.6% 24.3%
192
KX_FBK 23.6% 24.2% 23.9%
DERIUNLP 22.0% 22.5% 22.3%
Maui 20.3% 20.8% 20.6%
DFKI 20.3% 20.7% 20.5%
BUAP 19.0% 19.4% 19.2%
SJTULTLAB 18.4% 18.8% 18.6%
UNICE 18.3% 18.8% 18.5%
UNPMC 18.1% 18.6% 18.3%
JU_CSE 17.8% 18.2% 18.0%
LIKEY 16.3% 16.7% 16.5%
UvT 14.6% 14.9% 14.8%
NIRAJIIITH 14.1% 14.5% 14.3%
POLYU 13.9% 14.2% 14.0%
UKP 5.3% 5.4% 5.3%
</table>
<tableCaption confidence="0.998785">
Table 1: Performance of all participating systems over
combined keywords when extracting 15 keyphrases
</tableCaption>
<bodyText confidence="0.999627916666667">
When evaluating the system on reader as-
signed keyphrases only (again when extracting
15 keyphrases), the KP-Miner system ranked at 6
with a tie between it and another system. The
system’s precision, recall, and f-score were:
19.3%, 24.1% , 21.5% respectively.
To test whether the phrase refinement step de-
scribed in section 2.3 would improve the results
or not, this option was turned on, and the results
were evaluated using the script and the golden
dataset provided by the competition organizers.
The results are shown in tables 2 and 3.
</bodyText>
<table confidence="0.9997045">
Precision Recall F-Score
Top 5 29.6% 12.3% 17.4%
Top 10 23.3% 20.5% 24.3%
Top 15 25.3% 26.1% 25.8%
</table>
<tableCaption confidence="0.964887">
Table 2: Performance over combined keywords when
extracting, 5, 10, and 15 keyphrases
</tableCaption>
<table confidence="0.99995075">
Precision Recall F-Score
Top 5 37.8% 12.9% 19.2%
Top 10 30.3% 19.4% 21.1%
Top 15 20.1% 25.1% 22.3%
</table>
<tableCaption confidence="0.981057">
Table 3: Performance over reader assigned keywords
when extracting, 5, 10, and 15 keyphrases
</tableCaption>
<bodyText confidence="0.999897555555555">
Had these results been submitted, the system
would have still ranked at number 2 (but more
comfortably so) when comparing its results to
the combined author-reader set of keywords, but
it would jumped to third place for the reader as-
signed keyphrases. This improvement confirms
what the authors hypothesized in (El-Beltagy,
2009) which is that the usage of the final refine-
ment step does lead to better quality keyphrases.
</bodyText>
<sectionHeader confidence="0.966847" genericHeader="conclusions">
4 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999979043478261">
Despite the fact that the KP-Miner was de-
signed as a general purpose keyphrase extraction
system, and despite the simplicity of the system
and the fact that it requires no training to func-
tion, it seems to have performed relatively well
when carrying out the task of keyphrase extrac-
tion from scientific documents. The fact that it
was outperformed, seems to indicate that for op-
timal performance for this specific task, further
tweaking of the system’s parameters should be
carried out. In future work, the authors will in-
vestigate the usage of machine learning tech-
niques for configuring the system for specific
tasks. A further improvement to the system can
entail allowing certain stopwords to appear with-
in the produced keyphrases. It is worth noting
that the organizers stated that 55 of the reader
assigned keyphrases and 6 of the author assigned
keyphrases (making a total of 61 keyphrases in
the combined dataset), contained the “of&apos; stop-
word. However, none of these would have been
detected by the KP-Miner system as currently
“of&apos; is considered as a phrase terminator.
</bodyText>
<sectionHeader confidence="0.999116" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997745611111111">
M Porter. 1980. An Algorithm for Suffix Stripping,
Program, 14, 130-137.
G. Salton and C. Buckley. 1988. Term-weighting Ap-
proaches in Automatic Text Retrieval, Informa-
tion Processing and Management, 24:513-523.
Peter D. Turney. 1999. Learning to Extract Keyphras-
es from Text, National Research Council, Institute
for Information Technology, ERB-1057.
Samhaa. R. El-Beltagy and Ahmed Rafea. 2009. KP-
Miner: A Keyphrase Extraction System for Eng-
lish and Arabic Documents Information Systems,
34(1):132-144.
Samhaa R. El-Beltagy. 2006. KP-Miner: A Simple
System for Effective Keyphrase Extraction. Pro-
ceeding of the 3rd IEEE International Confe-
rence on Innovations in Information Technol-
ogy (IIT ’06), Dubai, UAE.
SemEval. 2010. http://semeval2.fbk.eu/semeval2.php
</reference>
<page confidence="0.999211">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479583">
<title confidence="0.977644">KP-Miner: Participation in SemEval-2</title>
<author confidence="0.998965">Samhaa R El-Beltagy Ahmed Rafea</author>
<affiliation confidence="0.999044">Cairo University The American University in Cairo</affiliation>
<address confidence="0.985516">Giza, Egypt. New Cairo, Egypt.</address>
<email confidence="0.999757">samhaa@computer.orgrafea@aucegypt.edu</email>
<abstract confidence="0.963915714285714">This paper briefly describes the KP-Miner system which is a system developed for the extraction of keyphrases from English and Arabic documents, irrespective of their nature. The paper also outlines the performance of the system in the “Automatic Keyphrase Extraction</abstract>
<note confidence="0.757543">from Scientific Articles” task which is part of SemEval-2.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Porter</author>
</authors>
<title>An Algorithm for Suffix Stripping,</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<pages>130--137</pages>
<contexts>
<context position="4581" citStr="Porter, 1980" startWordPosition="749" endWordPosition="750">ords are scanned until either a punctuation mark or a stop word is encountered. The scanned sequence of words and all possible n-grams within the encountered sequence where n can vary from 1 to sequence length-1, are stemmed and stored in both their original and stemmed forms. If the phrase (in its stemmed or original form) or any of its sub-phrases, has been seen before, then the count of the previously seen term is incremented by one, otherwise the previously unseen term is assigned a count of one. Very weak stemming is performed in this step using only the first step of the Porter stemmer (Porter, 1980). In the second phase, the document is scanned again for the longest possible sequence that fulfills the conditions mentioned above. This is then considered as a candidate keyphrase. Unlike most of the other keyphrase extraction systems, the devised algorithm places no limit on the length of keyphrases, but it was found that extracted keyphrases rarely exceed three terms. 2.2 Candidate keyphrases weight calculation Single key features obtained from documents by models such as TF-IDF (Salton and Buckley, 1988) have already been shown to be representative of documents from which they’ve been ext</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M Porter. 1980. An Algorithm for Suffix Stripping, Program, 14, 130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<date>1988</date>
<booktitle>Term-weighting Approaches in Automatic Text Retrieval, Information Processing and Management,</booktitle>
<pages>24--513</pages>
<contexts>
<context position="5095" citStr="Salton and Buckley, 1988" startWordPosition="828" endWordPosition="831">ne. Very weak stemming is performed in this step using only the first step of the Porter stemmer (Porter, 1980). In the second phase, the document is scanned again for the longest possible sequence that fulfills the conditions mentioned above. This is then considered as a candidate keyphrase. Unlike most of the other keyphrase extraction systems, the devised algorithm places no limit on the length of keyphrases, but it was found that extracted keyphrases rarely exceed three terms. 2.2 Candidate keyphrases weight calculation Single key features obtained from documents by models such as TF-IDF (Salton and Buckley, 1988) have already been shown to be representative of documents from which they’ve been extracted as demonstrated by their wide and successful use in clustering and classification tasks. However, when applied to the task of keyphrase extraction, these same models performed very poorly (Turney, 1999). By looking at almost any document, it can be observed that the occurrences of phrases is much less frequent than the occurrence of single terms within the same document. So it can be concluded that one of the reasons that TF-IDF performs poorly on its own when applied to the task of keyphrase extractio</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>G. Salton and C. Buckley. 1988. Term-weighting Approaches in Automatic Text Retrieval, Information Processing and Management, 24:513-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Learning to Extract Keyphrases from Text,</title>
<date>1999</date>
<institution>National Research Council, Institute for Information Technology,</institution>
<contexts>
<context position="5390" citStr="Turney, 1999" startWordPosition="877" endWordPosition="878">f the other keyphrase extraction systems, the devised algorithm places no limit on the length of keyphrases, but it was found that extracted keyphrases rarely exceed three terms. 2.2 Candidate keyphrases weight calculation Single key features obtained from documents by models such as TF-IDF (Salton and Buckley, 1988) have already been shown to be representative of documents from which they’ve been extracted as demonstrated by their wide and successful use in clustering and classification tasks. However, when applied to the task of keyphrase extraction, these same models performed very poorly (Turney, 1999). By looking at almost any document, it can be observed that the occurrences of phrases is much less frequent than the occurrence of single terms within the same document. So it can be concluded that one of the reasons that TF-IDF performs poorly on its own when applied to the task of keyphrase extraction, is that it does not take this fact into consideration which results in a bias towards single words as they occur in larger numbers. So, a boosting factor is needed for compound terms in order to balance this bias towards single terms. In this work for each input document d from which keyphra</context>
</contexts>
<marker>Turney, 1999</marker>
<rawString>Peter D. Turney. 1999. Learning to Extract Keyphrases from Text, National Research Council, Institute for Information Technology, ERB-1057.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R El-Beltagy</author>
<author>Ahmed Rafea</author>
</authors>
<title>KPMiner: A Keyphrase Extraction System for English and Arabic Documents Information Systems,</title>
<date>2009</date>
<pages>34--1</pages>
<marker>El-Beltagy, Rafea, 2009</marker>
<rawString>Samhaa. R. El-Beltagy and Ahmed Rafea. 2009. KPMiner: A Keyphrase Extraction System for English and Arabic Documents Information Systems, 34(1):132-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samhaa R El-Beltagy</author>
</authors>
<title>KP-Miner: A Simple System for Effective Keyphrase Extraction.</title>
<date>2006</date>
<booktitle>Proceeding of the 3rd IEEE International Conference on Innovations in Information Technology (IIT ’06),</booktitle>
<location>Dubai, UAE.</location>
<contexts>
<context position="3486" citStr="El-Beltagy, 2006" startWordPosition="568" endWordPosition="569">, this is set to 3. However, if a document is short, n is decremented depending on the length of the document. The second condition is related to the position where a candidate keyphrase first appears within an input document. Through observation as well as experimentation, it was found that in long documents, phrases occurring for the first time after a given threshold, are very rarely keyphrases. So a cutoff constant CutOff is defined in terms of a number of words after which if a phrase appears for the first time, it is filtered out and ignored. The initial prototype of the KPMiner system (El-Beltagy, 2006), set this cutoff value to a constant (850). Further experimentation carried out in (El-Beltagy, 2009) revealed that an optimum value for this constant is 400. In 190 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 190–193, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics the implementation of the KP-Miner system, the phrase extraction step described above is carried out in two phases. In the first phase, words are scanned until either a punctuation mark or a stop word is encountered. The scanned sequence of words and all </context>
<context position="12339" citStr="El-Beltagy, 2006" startWordPosition="2099" endWordPosition="2100">tional way in which keyphrase sets extracted by each of the participants were matched against answer sets (i.e. author-assigned keyphrases and readerassigned keyphrases) to calculate precision, recall and F-score. Participants were then ranked by F-score when extracting all 15 keyphrases. Since the KP-miner system is an unsupervised keyphrase extraction system, no use was made of the trial and training data. The system was simply run of the set of test documents, and the output was sent to the organizers. 2 different runs were submitted: one produced used the initial prototype of the system, (El-Beltagy, 2006), while the second was produced using the more mature version of the system (El-Beltagy, 2009). Both systems were run without making any changes to their default parameters. The idea was to see how well the KP-Miner would fair among other keyphrase extraction systems without any additional configuration. The more mature version of the system performed better when its results were compared to the author-reader combined keyphrase set and consequently was the one whose final results were taken into consideration in the competition. The system ranked at 2 , with a tie between it and another system</context>
</contexts>
<marker>El-Beltagy, 2006</marker>
<rawString>Samhaa R. El-Beltagy. 2006. KP-Miner: A Simple System for Effective Keyphrase Extraction. Proceeding of the 3rd IEEE International Conference on Innovations in Information Technology (IIT ’06), Dubai, UAE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SemEval</author>
</authors>
<date>2010</date>
<note>http://semeval2.fbk.eu/semeval2.php</note>
<marker>SemEval, 2010</marker>
<rawString>SemEval. 2010. http://semeval2.fbk.eu/semeval2.php</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>