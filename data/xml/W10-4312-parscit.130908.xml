<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988632">
Negotiating causal implicatures
</title>
<author confidence="0.576439">
Luciana Benotti
</author>
<note confidence="0.491216">
Universidad Nacional de C´ordoba
Grupo PLN
Ciudad Universitaria
5000 C´ordoba, Argentina
</note>
<email confidence="0.992118">
luciana.benotti@gmail.com
</email>
<note confidence="0.716764">
Patrick Blackburn
INRIA Nancy Grand-Est
Equipe TALARIS
615, rue du Jardin Botanique
54602 Villers l`es Nancy, France
</note>
<email confidence="0.996856">
patrick.blackburn@loria.fr
</email>
<sectionHeader confidence="0.993905" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99899825">
In this paper we motivate and describe
a dialogue manager which is able to in-
fer and negotiate causal implicatures. A
causal implicature is a type of Gricean re-
lation implicature, and the ability to infer
them is crucial in situated dialogue. Be-
cause situated dialogue interleaves conver-
sational acts and physical acts, the dia-
logue manager needs to have a grasp on
causal implicatures in order not only to de-
cide what physical acts to do next but also
to generate causally-aware clarifications.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994890065573771">
In conversation, an important part of the content
conveyed is not explicitly said, rather it is impli-
cated. However, Grice (1975)’s classic concept of
conversational implicature (CI) is far from fully
understood. Traditionally CIs have been classified
using the Gricean maxims: there are relation CIs
(also known as relevance CIs), quantity CIs, qual-
ity CIs and manner CIs. In formal pragmatics, the
most studied CIs are quantity CIs, probably be-
cause they are the ones most obviously amenable
to theoretical analysis; see (Geurts, in press) for
a survey of the state of the art. Far less studied
(and traditionally regarded as somewhat obscure)
are relation CIs. Obscure perhaps, but crucial: it
has been argued that they subsume all other types
of CIs (Wilson and Sperber, 2004). This paper is a
first step towards their formalization.
We shall analyze a kind of CI that we call causal
CIs. Causal CIs are relation CIs as defined by
Grice (1975) where the crucial relation is task do-
main causality. Consider the following example:
Mary: The chest is locked, the crown is inside
Bill: Give me the crown
Bill causally implicated: Unlock the chest
In order to carry out the task action required by
Bill (to give him the crown) it is necessary to un-
lock the chest. Hence we say that Bill is implicat-
ing, by trading on the domain causal relations (af-
ter all, the contents of a chest are not accessible un-
less the chest is unlock) that Mary is to unlock the
chest. Now, once Mary has inferred the causal CI,
she may accept this inference silently or negotiate
it. Mary might decide to silently accept it because
she knows how to get the key; in this case we will
say that Mary constructed an internal bridge from
the current task situation (that is, the crown being
inside the locked chest) to the proposal made by
Bill (giving him the crown). If Mary decides she
has insufficient information to construct the inter-
nal bridge (maybe she has no key, or sees that the
lock is rusty) she may start a sub-dialogue that we
will call an external bridge; she might say, for ex-
ample: But how can I unlock the chest? The in-
ternal process of bridging is what in the literature
has been called accommodation (Lewis, 1979) or
bridging (Clark, 1975). The external processes of
bridging constitutes a large part of what we call
conversation.
This paper presents a dialogue system (called
Frolog) which infers and negotiates causal CIs in
the context of situated task-oriented dialogue; the
framework is intended as a proof-of-concept of the
ideas just sketched. We proceed as follows. In
Section 2, we motivate the study of causal CIs in
dialogue. In Section 3 we present Frolog’s dia-
logue manager which infers causal CIs in situated
dialogue. And in Section 4 we illustrate how the
negotiation (external bridging) of causal CIs incre-
mentally grounds a pragmatic goal proposed by
one of the dialogue participants. Section 5 con-
cludes the paper.
</bodyText>
<sectionHeader confidence="0.849287" genericHeader="method">
2 Causal implicatures and dialogue
</sectionHeader>
<bodyText confidence="0.9987625">
The motivation for our work is both theoretical
and practical. On the theoretical side, we believe
</bodyText>
<subsubsectionHeader confidence="0.677147">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 67–70,
</subsubsectionHeader>
<affiliation confidence="0.890975">
The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999831">
67
</page>
<bodyText confidence="0.999783613636364">
that it is crucial to explore CIs in the setting of
naturally occurring dialogues. Strangely enough
(after all, Grice did call them conversational im-
plicatures) this view appears to be novel, perhaps
even controversial. In the formal pragmatics lit-
erature, CIs are often simply viewed as inferences
drawn by a hearer on the basis of a speaker’s ut-
terance, contextual information, and the Gricean
maxims. We find this perspective too static. CIs
(especially relations CIs) are better viewed as in-
trinsically interactional inferences that arise from
the dynamics of conversation. As conversations
progress, speakers and hearers switch roles: mean-
ing are negotiated and inference becomes bidirec-
tional (Thomason et al., 2006). Moreover, even
within a single turn, hearers are not restricted to
simply drawing (or failing to draw) “the” CI: in
fact, choosing between internal and external bridg-
ing is better viewed as part of the process of nego-
tiating what the CI at stake actually is. We be-
lieve that interactive perspectives will be neces-
sary to extend the theory of CIs beyond the rel-
atively narrow domain of quantity CIs. We also
believe that the dialog-centered approach we ad-
vocate may have practical consequences. In par-
ticular, modeling the external process of bridging
is a step towards having a pragmatically incremen-
tal dialogue manager in the spirit of that sketched
in (Buß and Schlangen, 2010).
This is a broad goal, in this paper we focus on
clausal implicatures. This restriction gives us an
empirical handle of CIs. It is not controversial that
(in non-conversational activities) the causal rela-
tions between acts define the expectations of the
interaction. But also in conversational activities
situated in a physical task causal relations guide
the interaction; we did an empirical study on such
a kind of corpus (Benotti, 2009) and we found that,
in this corpus, most CIs for which there is evidence
(because they are made explicit in a clarification
request) can be explained in terms of causal rela-
tions. For our empirical study, we annotated and
classified the clarification requests (CRs) that ap-
pear in the SCARE corpus (Stoia et al., 2008).
</bodyText>
<sectionHeader confidence="0.981864" genericHeader="method">
3 Inferring causal implicatures
</sectionHeader>
<bodyText confidence="0.986592315789474">
In order to model the causal CIs that we observed
in the SCARE corpus, and to experiment with dif-
ferent strategies for negotiating these CIs, we de-
signed a system that mimics the instruction giving
setup of the SCARE corpus. In our setup, the DF
is a dialogue system that we will call Frolog. The
human participant that plays the role of the DG we
will call “the player”.
In a nutshell, Frolog uses an off-the-shelf plan-
ner to compute causal implicatures. That is, it
uses classical planning (a well explored and com-
putationally efficient AI technique) to fill out the
micro-structure of discourse (the bridging infor-
mation required in the next step).1 We do so us-
ing the planner BLACKBOX (Kautz and Selman,
1999). Like all classical planners, BLACKBOX
takes three inputs: the initial state, the goal, and
the available actions. The question of what these
three elements should be raises a number of issues.
In Frolog, two types of information are regis-
tered: complete and accurate information about
the game world in the world KB and a represen-
tation of the common ground in the interaction
KB. Which of these should be used in the initial
state? In fact, we need both: we infer the actions
intended by the player using the information in the
interaction KB but we have to verify this sequence
of actions on the world KB to check if it can actu-
ally be executed.
Let us now define what the goal of the planning
problem should be. Frolog should act to make the
preconditions of the action true with one restric-
tion. The restriction is that it must be possible for
Frolog to manipulate these preconditions. How-
ever, we don’t need to worry about this restric-
tion because the planner should take care of which
propositions are manipulable by Frolog and which
are not, given the current state. So we can just de-
fine the goal as the conjunction of all the precon-
ditions of the command uttered by the player.
To complete the picture, the actions available to
the planner are all the actions in the game action
database. This means that we are assuming that
all the actions that can be executed, are mutually
known to Frolog and the player.
In order to be able to perform bridging to the
mutual information it must be mutually known
what the preconditions and the effects of the ac-
tions involved are. The assumption that the player
and Frolog know the exact specification of all the
actions that can be executed in the game world is
1Thus the work reported here is very different from the
traditional work of (Perrault and Allen, 1980; Allen and
Allen, 1994): classic papers in the plan-based tradition use
plan recognition (a more computationally expensive task) to
interpret utterances by inserting them into the plan the macro-
structure (the global shape) of discourse.
</bodyText>
<page confidence="0.997349">
68
</page>
<bodyText confidence="0.9979102">
a simplifying assumption. We make it because it
enables us to avoid deciding (and implementing)
how differing knowledge about actions get coordi-
nated; dealing with such issues simply too difficult
at present.
</bodyText>
<sectionHeader confidence="0.632878" genericHeader="method">
4 Negotiating with a dialogue system
</sectionHeader>
<bodyText confidence="0.999970727272727">
In this section we present a worked out example of
how the solutions of the planning problems intro-
duced in the previous section can be used in order
to perform internal bridging and trigger external
bridging when appropriate.
In this example Frolog does not have enough
knowledge yet in order to infer the bridge.2 This
is the case in instruction (37) in Figure 1. In this
instruction the player wants Frolog to open the
chest but Frolog does not know how to do this.
In the screen-shot in the right you can see state of
the interaction KB from turns (37) to (39). In this
model we can see that the player does not have
information about what fits into the chest, in or-
der to unlock it. This is why the planner is not
able to find a plan that achieves the precondition
(unlocked chest1) of the command “open the
chest” in instruction (37). The instruction in (39)
fails as well making the obstacle explicit. Utter-
ance (40) is an example of a CR caused by a re-
quired and unknown thematic relation filler (the
second most frequent CR in the SCARE corpus).
</bodyText>
<figureCaption confidence="0.170831">
Player(32): look at the chest
Frolog(33): the chest is closed and
locked and wooden
Player(34): look at Frolog
Frolog(35): Frolog is alive
Frolog(36): Frolog holds the sword, the worm
and the golden key
</figureCaption>
<figure confidence="0.1865432">
Player(37): open the chest
Frolog(38): Frolog can&apos;t do that!
the chest is not unlocked
Player(39): unlock the chest
Frolog(40): Frolog can&apos;t do that!
Frolog doesn&apos;t know what fits into the chest
Player(41): unlock the chest with the golden key
Fro log142): [Frolog unlocks the chest]
Frolog 4&apos;3 the chest is unlocked
Player(44): lock the chest with the key
Frolog(45): [Frolog locks the chest]
Frolog(46): the chest is locked
Player(47): open the chest
Frolog(48): Frolog can&apos;t do that!
the chest is not unlocked
</figure>
<figureCaption confidence="0.999733">
Figure 1: External bridging in Frolog
</figureCaption>
<bodyText confidence="0.976507348837209">
Frolog’s behavior continues as expected until
turn (48) in which Frolog again is not able to
bridge the command open the chest. It is to be
expected that the fact that the golden key fits into
2For illustrations of other reasons that trigger negotiation
of CIs see (Benotti, 2010).
the chest is mutual knowledge by now but Frolog
is not reacting accordingly.
In order to overcome this issue there are two
options: (1) either we allow different sources to
update the mutual information loosing uniformity
in the update process or (2) we add actions that
manipulate this kind of information. Here we de-
scribe option (1) that turns out to be the proce-
dural version of “strict accommodation” (as de-
fined in (Beaver and Geurts, in press)), and when
generalized is of a piece with abduction (Hobbs,
1985). For an discussion of (2) we refer the reader
to (Benotti, 2010).
We could say that the intuition behind the strict
notion of accommodation is that when the speaker
utters a sentence, she is not only trying to achieve
the obvious effects of the utterance, but is also
communicating the ways in which she assumes the
world to be, and on which the success of the utter-
ance depends. Following this intuition it can be
argued that the intention behind the utterance “un-
lock the chest with the golden key” in turn (41) is
twofold. It is clear that the player wants to achieve
the effects of the action, that is, she wants to have
the chest unlocked. But the player also expects
Frolog to recognize the assumptions she is making
and on which the success of the utterance depends.
In particular, she expects Frolog to recognize that
she is assuming that the golden key fits into the
chest lock (this is why Frolog can coherently ask
why do you think that the golden key will fit?).
This means that, when an action is executed, the
interaction KB will be updated not only with the
effects of the action but also with its preconditions.
And those preconditions that were not in the inter-
action KB before will be verbalized as in turn (9)
in Figure 2.
</bodyText>
<equation confidence="0.698877090909091">
:action unlock
:arguments
(agent ?w) (theme ?x) (inst ?y)
:precondition
(accessible ?x)
(locked ?x)
(fitsin ?y ?x)
(hold ?w ?y)
:effect
(not(locked ?x))
(unlocked ?x)
</equation>
<note confidence="0.279596">
Player(15): open the chest
</note>
<footnote confidence="0.9716378">
Frolog(16): [Frolog unlocks the chest with the golden key]
Frolog(17): the chest is unlocked
Frolog(18): [Frolog opens the chest]
Frolog(19): the chest is open
Frolog(20): the chest hold a golden crown
</footnote>
<figureCaption confidence="0.985967">
Figure 2: External bridging becomes internal
</figureCaption>
<figure confidence="0.526402774193548">
fitsin ?
Player(1): unlock the chest
Frolog(2): Frolog can&apos;t do that!
Frolog doesn&apos;t know
what fits-into the chest
Player(3): look at you
Frolog(4): you are alive
Frolog(5): you hold a golden key
Player(6): unlock the chest
with the golden key
Frolog(7): [Frolog unlocks the chest
with the golden key]
Frolog(8): the chest is unlocked
Frolog(9): the key fits-into the chest
Player(10): lock the chest
Frolog(11): [Frolog locks the chest
with the golden key]
Frolog(12): the chest is locked
Player(13): look at the chest
Frolog(14): the chest is closed and
locked and wooden
:action open
:arguments
(agent ?w) (theme ?x)
:precondition
(accessible ?x)
(closed ?x)
(unlocked ?x)
:effect
(not(closed ?x))
(open ?x)
</figure>
<page confidence="0.995369">
69
</page>
<bodyText confidence="0.999932142857143">
The rest of the interaction (from turns (10)
to (15)) show that once the proposition (fitsin
key1 chest1) is added to the interaction KB the
action “open the chest” can be internally bridged
even when the chest is locked. Because the player
and Frolog mutually know which key fits into the
chest.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999986818181818">
Clearly, our inference framework is limited in
many ways. But we think we’ve made a small
step in the right direction. Dialogue systems are
reaching a development level in which they cannot
elude drawing inferences for much longer. This
paper is a step in this direction.
Causal implicatures are a kind of relation
implicature (historically Grice’s most obscure
and crucial implicature) whose inference—we’ve
argued—is essential in situated dialogue if our di-
alogue systems are not to violate the expectations
of the user. Causal relations have a direct impact
on the coherence structure of situated dialogues
such as those in the SCARE corpus; in the SCARE
corpus most pragmatic clarification requests make
explicit causal implicatures.
We need to have a grasp on causal impli-
catures in order for our dialogue systems not
only to decide what physical acts to do next—
internal bridging—but also to generate causally-
aware clarification requests—external bridging.
Of course the inference framework presented here
has many limitations that we discussed through-
out the paper and probably classical planning is
not the formalism that we will finally want to use
in our dialogue systems (at least not in its present
form). Our model is intended as a proof of con-
cept, and intentionally stays at a level of formal-
ization that is still simple enough so as not to loose
our intuitions. The two intuitions that we don’t
want to loose sight of are (1) utterances are to be
interpreted in a context and need to be connected
to this context (through some kind of relation, be-
ing causality one of the most important ones in
situated dialogue) in order to be grounded (2) the
process of connecting utterances to the context is
a joint process, it is a negotiation that involves de-
cisions of all the dialogue participants.
With the intuitions in place we plan to extend
this work mainly by porting the inference frame-
work into new domains.
There is lot to do yet, but we believe that the
negotiation of causal implicatures is a step towards
an incremental dialogue manager.
</bodyText>
<sectionHeader confidence="0.996441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999236875">
James Allen and Richard Allen. 1994. Natural lan-
guage understanding. Addison Wesley, 2nd edition.
David Beaver and Bart Geurts. in press. Presup-
position. In Handbook of Semantics. Mouton de
Gruyter.
Luciana Benotti. 2009. Clarification potential of in-
structions. In Proc. of SIGDIAL, pages 196–205,
London, United Kingdom.
Luciana Benotti. 2010. Implicature as an Interactive
Process. Ph.D. thesis, Universit´e Henri Poincar´e,
INRIA Nancy Grand Est, France. Supervised by
P. Blackburn. Reviewed by N. Asher and B. Geurts.
Okko Buß and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In The 2010 Workshop on the Semantics and
Pragmatics of Dialogue, Pozna´n, Poland.
Herbert Clark. 1975. Bridging. In Proc. of the Work-
shop on Theoretical issues in natural language pro-
cessing, pages 169–174, Morristown, USA. ACL.
Bart Geurts. in press. Quantity implicatures. Cam-
bridge University Press.
Paul Grice. 1975. Logic and conversation. In P. Cole
and J. Morgan, editors, Syntax and Semantics, vol-
ume 3, pages 41–58. Academic Press, New York.
Jerry Hobbs. 1985. Granularity. In Proceedings of
the 9th International Joint Conference on Artificial
Intelligence, pages 432–435. Morgan Kaufmann.
Henry Kautz and Bart Selman. 1999. Unifying SAT-
based and graph-based planning. In Proceedings of
the 16th International Joint Conference on Artificial
Intelligence, pages 318–325, Stockholm, Sweden.
David Lewis. 1979. Scorekeeping in a language game.
Journal of Philosophical Logic, 8:339–359.
Raymond Perrault and James Allen. 1980. A plan-
based analysis of indirect speech acts. Computa-
tional Linguistics, 6(3-4):167–182.
Laura Stoia, Darla Shockley, Donna Byron, and Eric
Fosler-Lussier. 2008. SCARE: A situated corpus
with annotated referring expressions. In Proc. of
LREC.
Richmond Thomason, Matthew Stone, and David De-
Vault. 2006. Enlightened update: A computa-
tional architecture for presupposition and other prag-
matic phenomena. In Presupposition Accommoda-
tion. Ohio State Pragmatics Initiative.
Deirdre Wilson and Dan Sperber. 2004. Relevance
theory. In Handbook of Pragmatics, pages 607–632.
Blackwell, Oxford.
</reference>
<page confidence="0.998481">
70
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.120475">
<title confidence="0.993602">Negotiating causal implicatures</title>
<author confidence="0.782401">Luciana</author>
<affiliation confidence="0.503485333333333">Universidad Nacional de Grupo Ciudad</affiliation>
<address confidence="0.958398">5000 C´ordoba,</address>
<email confidence="0.999931">luciana.benotti@gmail.com</email>
<author confidence="0.995048">Patrick</author>
<affiliation confidence="0.8661095">INRIA Nancy Equipe</affiliation>
<address confidence="0.981909">615, rue du Jardin 54602 Villers l`es Nancy,</address>
<email confidence="0.997114">patrick.blackburn@loria.fr</email>
<abstract confidence="0.998940846153846">In this paper we motivate and describe a dialogue manager which is able to infer and negotiate causal implicatures. A causal implicature is a type of Gricean relation implicature, and the ability to infer them is crucial in situated dialogue. Because situated dialogue interleaves conversational acts and physical acts, the dialogue manager needs to have a grasp on causal implicatures in order not only to decide what physical acts to do next but also to generate causally-aware clarifications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Richard Allen</author>
</authors>
<title>Natural language understanding.</title>
<date>1994</date>
<publisher>Addison Wesley,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="8859" citStr="Allen and Allen, 1994" startWordPosition="1485" endWordPosition="1488">he actions available to the planner are all the actions in the game action database. This means that we are assuming that all the actions that can be executed, are mutually known to Frolog and the player. In order to be able to perform bridging to the mutual information it must be mutually known what the preconditions and the effects of the actions involved are. The assumption that the player and Frolog know the exact specification of all the actions that can be executed in the game world is 1Thus the work reported here is very different from the traditional work of (Perrault and Allen, 1980; Allen and Allen, 1994): classic papers in the plan-based tradition use plan recognition (a more computationally expensive task) to interpret utterances by inserting them into the plan the macrostructure (the global shape) of discourse. 68 a simplifying assumption. We make it because it enables us to avoid deciding (and implementing) how differing knowledge about actions get coordinated; dealing with such issues simply too difficult at present. 4 Negotiating with a dialogue system In this section we present a worked out example of how the solutions of the planning problems introduced in the previous section can be u</context>
</contexts>
<marker>Allen, Allen, 1994</marker>
<rawString>James Allen and Richard Allen. 1994. Natural language understanding. Addison Wesley, 2nd edition.</rawString>
</citation>
<citation valid="false">
<authors>
<author>David Beaver</author>
<author>Bart Geurts</author>
</authors>
<title>in press. Presupposition.</title>
<booktitle>In Handbook of Semantics. Mouton de Gruyter.</booktitle>
<marker>Beaver, Geurts, </marker>
<rawString>David Beaver and Bart Geurts. in press. Presupposition. In Handbook of Semantics. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciana Benotti</author>
</authors>
<title>Clarification potential of instructions.</title>
<date>2009</date>
<booktitle>In Proc. of SIGDIAL,</booktitle>
<pages>196--205</pages>
<location>London, United Kingdom.</location>
<contexts>
<context position="5957" citStr="Benotti, 2009" startWordPosition="975" endWordPosition="976">r, modeling the external process of bridging is a step towards having a pragmatically incremental dialogue manager in the spirit of that sketched in (Buß and Schlangen, 2010). This is a broad goal, in this paper we focus on clausal implicatures. This restriction gives us an empirical handle of CIs. It is not controversial that (in non-conversational activities) the causal relations between acts define the expectations of the interaction. But also in conversational activities situated in a physical task causal relations guide the interaction; we did an empirical study on such a kind of corpus (Benotti, 2009) and we found that, in this corpus, most CIs for which there is evidence (because they are made explicit in a clarification request) can be explained in terms of causal relations. For our empirical study, we annotated and classified the clarification requests (CRs) that appear in the SCARE corpus (Stoia et al., 2008). 3 Inferring causal implicatures In order to model the causal CIs that we observed in the SCARE corpus, and to experiment with different strategies for negotiating these CIs, we designed a system that mimics the instruction giving setup of the SCARE corpus. In our setup, the DF is</context>
</contexts>
<marker>Benotti, 2009</marker>
<rawString>Luciana Benotti. 2009. Clarification potential of instructions. In Proc. of SIGDIAL, pages 196–205, London, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciana Benotti</author>
</authors>
<title>Implicature as an Interactive Process.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e Henri Poincar´e, INRIA Nancy Grand Est, France.</institution>
<note>Supervised by</note>
<contexts>
<context position="11411" citStr="Benotti, 2010" startWordPosition="1921" endWordPosition="1922"> chest with the golden key Fro log142): [Frolog unlocks the chest] Frolog 4&apos;3 the chest is unlocked Player(44): lock the chest with the key Frolog(45): [Frolog locks the chest] Frolog(46): the chest is locked Player(47): open the chest Frolog(48): Frolog can&apos;t do that! the chest is not unlocked Figure 1: External bridging in Frolog Frolog’s behavior continues as expected until turn (48) in which Frolog again is not able to bridge the command open the chest. It is to be expected that the fact that the golden key fits into 2For illustrations of other reasons that trigger negotiation of CIs see (Benotti, 2010). the chest is mutual knowledge by now but Frolog is not reacting accordingly. In order to overcome this issue there are two options: (1) either we allow different sources to update the mutual information loosing uniformity in the update process or (2) we add actions that manipulate this kind of information. Here we describe option (1) that turns out to be the procedural version of “strict accommodation” (as defined in (Beaver and Geurts, in press)), and when generalized is of a piece with abduction (Hobbs, 1985). For an discussion of (2) we refer the reader to (Benotti, 2010). We could say th</context>
</contexts>
<marker>Benotti, 2010</marker>
<rawString>Luciana Benotti. 2010. Implicature as an Interactive Process. Ph.D. thesis, Universit´e Henri Poincar´e, INRIA Nancy Grand Est, France. Supervised by P. Blackburn. Reviewed by N. Asher and B. Geurts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Okko Buß</author>
<author>David Schlangen</author>
</authors>
<title>Modelling sub-utterance phenomena in spoken dialogue systems.</title>
<date>2010</date>
<booktitle>In The 2010 Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<location>Pozna´n, Poland.</location>
<contexts>
<context position="5517" citStr="Buß and Schlangen, 2010" startWordPosition="903" endWordPosition="906">tricted to simply drawing (or failing to draw) “the” CI: in fact, choosing between internal and external bridging is better viewed as part of the process of negotiating what the CI at stake actually is. We believe that interactive perspectives will be necessary to extend the theory of CIs beyond the relatively narrow domain of quantity CIs. We also believe that the dialog-centered approach we advocate may have practical consequences. In particular, modeling the external process of bridging is a step towards having a pragmatically incremental dialogue manager in the spirit of that sketched in (Buß and Schlangen, 2010). This is a broad goal, in this paper we focus on clausal implicatures. This restriction gives us an empirical handle of CIs. It is not controversial that (in non-conversational activities) the causal relations between acts define the expectations of the interaction. But also in conversational activities situated in a physical task causal relations guide the interaction; we did an empirical study on such a kind of corpus (Benotti, 2009) and we found that, in this corpus, most CIs for which there is evidence (because they are made explicit in a clarification request) can be explained in terms o</context>
</contexts>
<marker>Buß, Schlangen, 2010</marker>
<rawString>Okko Buß and David Schlangen. 2010. Modelling sub-utterance phenomena in spoken dialogue systems. In The 2010 Workshop on the Semantics and Pragmatics of Dialogue, Pozna´n, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Clark</author>
</authors>
<date>1975</date>
<booktitle>Bridging. In Proc. of the Workshop on Theoretical issues in natural language processing,</booktitle>
<pages>169--174</pages>
<publisher>ACL.</publisher>
<location>Morristown, USA.</location>
<contexts>
<context position="3059" citStr="Clark, 1975" startWordPosition="512" endWordPosition="513">w to get the key; in this case we will say that Mary constructed an internal bridge from the current task situation (that is, the crown being inside the locked chest) to the proposal made by Bill (giving him the crown). If Mary decides she has insufficient information to construct the internal bridge (maybe she has no key, or sees that the lock is rusty) she may start a sub-dialogue that we will call an external bridge; she might say, for example: But how can I unlock the chest? The internal process of bridging is what in the literature has been called accommodation (Lewis, 1979) or bridging (Clark, 1975). The external processes of bridging constitutes a large part of what we call conversation. This paper presents a dialogue system (called Frolog) which infers and negotiates causal CIs in the context of situated task-oriented dialogue; the framework is intended as a proof-of-concept of the ideas just sketched. We proceed as follows. In Section 2, we motivate the study of causal CIs in dialogue. In Section 3 we present Frolog’s dialogue manager which infers causal CIs in situated dialogue. And in Section 4 we illustrate how the negotiation (external bridging) of causal CIs incrementally grounds</context>
</contexts>
<marker>Clark, 1975</marker>
<rawString>Herbert Clark. 1975. Bridging. In Proc. of the Workshop on Theoretical issues in natural language processing, pages 169–174, Morristown, USA. ACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bart Geurts</author>
</authors>
<title>in press. Quantity implicatures.</title>
<publisher>Cambridge University Press.</publisher>
<marker>Geurts, </marker>
<rawString>Bart Geurts. in press. Quantity implicatures. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>3</volume>
<pages>41--58</pages>
<editor>In P. Cole and J. Morgan, editors,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="956" citStr="Grice (1975)" startWordPosition="141" endWordPosition="142">d describe a dialogue manager which is able to infer and negotiate causal implicatures. A causal implicature is a type of Gricean relation implicature, and the ability to infer them is crucial in situated dialogue. Because situated dialogue interleaves conversational acts and physical acts, the dialogue manager needs to have a grasp on causal implicatures in order not only to decide what physical acts to do next but also to generate causally-aware clarifications. 1 Introduction In conversation, an important part of the content conveyed is not explicitly said, rather it is implicated. However, Grice (1975)’s classic concept of conversational implicature (CI) is far from fully understood. Traditionally CIs have been classified using the Gricean maxims: there are relation CIs (also known as relevance CIs), quantity CIs, quality CIs and manner CIs. In formal pragmatics, the most studied CIs are quantity CIs, probably because they are the ones most obviously amenable to theoretical analysis; see (Geurts, in press) for a survey of the state of the art. Far less studied (and traditionally regarded as somewhat obscure) are relation CIs. Obscure perhaps, but crucial: it has been argued that they subsum</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Paul Grice. 1975. Logic and conversation. In P. Cole and J. Morgan, editors, Syntax and Semantics, volume 3, pages 41–58. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<date>1985</date>
<booktitle>Granularity. In Proceedings of the 9th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>432--435</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="11929" citStr="Hobbs, 1985" startWordPosition="2010" endWordPosition="2011">s into 2For illustrations of other reasons that trigger negotiation of CIs see (Benotti, 2010). the chest is mutual knowledge by now but Frolog is not reacting accordingly. In order to overcome this issue there are two options: (1) either we allow different sources to update the mutual information loosing uniformity in the update process or (2) we add actions that manipulate this kind of information. Here we describe option (1) that turns out to be the procedural version of “strict accommodation” (as defined in (Beaver and Geurts, in press)), and when generalized is of a piece with abduction (Hobbs, 1985). For an discussion of (2) we refer the reader to (Benotti, 2010). We could say that the intuition behind the strict notion of accommodation is that when the speaker utters a sentence, she is not only trying to achieve the obvious effects of the utterance, but is also communicating the ways in which she assumes the world to be, and on which the success of the utterance depends. Following this intuition it can be argued that the intention behind the utterance “unlock the chest with the golden key” in turn (41) is twofold. It is clear that the player wants to achieve the effects of the action, t</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry Hobbs. 1985. Granularity. In Proceedings of the 9th International Joint Conference on Artificial Intelligence, pages 432–435. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Kautz</author>
<author>Bart Selman</author>
</authors>
<title>Unifying SATbased and graph-based planning.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>318--325</pages>
<location>Stockholm,</location>
<contexts>
<context position="7022" citStr="Kautz and Selman, 1999" startWordPosition="1157" endWordPosition="1160">ith different strategies for negotiating these CIs, we designed a system that mimics the instruction giving setup of the SCARE corpus. In our setup, the DF is a dialogue system that we will call Frolog. The human participant that plays the role of the DG we will call “the player”. In a nutshell, Frolog uses an off-the-shelf planner to compute causal implicatures. That is, it uses classical planning (a well explored and computationally efficient AI technique) to fill out the micro-structure of discourse (the bridging information required in the next step).1 We do so using the planner BLACKBOX (Kautz and Selman, 1999). Like all classical planners, BLACKBOX takes three inputs: the initial state, the goal, and the available actions. The question of what these three elements should be raises a number of issues. In Frolog, two types of information are registered: complete and accurate information about the game world in the world KB and a representation of the common ground in the interaction KB. Which of these should be used in the initial state? In fact, we need both: we infer the actions intended by the player using the information in the interaction KB but we have to verify this sequence of actions on the </context>
</contexts>
<marker>Kautz, Selman, 1999</marker>
<rawString>Henry Kautz and Bart Selman. 1999. Unifying SATbased and graph-based planning. In Proceedings of the 16th International Joint Conference on Artificial Intelligence, pages 318–325, Stockholm, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Lewis</author>
</authors>
<title>Scorekeeping in a language game.</title>
<date>1979</date>
<journal>Journal of Philosophical Logic,</journal>
<pages>8--339</pages>
<contexts>
<context position="3033" citStr="Lewis, 1979" startWordPosition="508" endWordPosition="509">pt it because she knows how to get the key; in this case we will say that Mary constructed an internal bridge from the current task situation (that is, the crown being inside the locked chest) to the proposal made by Bill (giving him the crown). If Mary decides she has insufficient information to construct the internal bridge (maybe she has no key, or sees that the lock is rusty) she may start a sub-dialogue that we will call an external bridge; she might say, for example: But how can I unlock the chest? The internal process of bridging is what in the literature has been called accommodation (Lewis, 1979) or bridging (Clark, 1975). The external processes of bridging constitutes a large part of what we call conversation. This paper presents a dialogue system (called Frolog) which infers and negotiates causal CIs in the context of situated task-oriented dialogue; the framework is intended as a proof-of-concept of the ideas just sketched. We proceed as follows. In Section 2, we motivate the study of causal CIs in dialogue. In Section 3 we present Frolog’s dialogue manager which infers causal CIs in situated dialogue. And in Section 4 we illustrate how the negotiation (external bridging) of causal</context>
</contexts>
<marker>Lewis, 1979</marker>
<rawString>David Lewis. 1979. Scorekeeping in a language game. Journal of Philosophical Logic, 8:339–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond Perrault</author>
<author>James Allen</author>
</authors>
<title>A planbased analysis of indirect speech acts.</title>
<date>1980</date>
<journal>Computational Linguistics,</journal>
<pages>6--3</pages>
<contexts>
<context position="8835" citStr="Perrault and Allen, 1980" startWordPosition="1481" endWordPosition="1484">To complete the picture, the actions available to the planner are all the actions in the game action database. This means that we are assuming that all the actions that can be executed, are mutually known to Frolog and the player. In order to be able to perform bridging to the mutual information it must be mutually known what the preconditions and the effects of the actions involved are. The assumption that the player and Frolog know the exact specification of all the actions that can be executed in the game world is 1Thus the work reported here is very different from the traditional work of (Perrault and Allen, 1980; Allen and Allen, 1994): classic papers in the plan-based tradition use plan recognition (a more computationally expensive task) to interpret utterances by inserting them into the plan the macrostructure (the global shape) of discourse. 68 a simplifying assumption. We make it because it enables us to avoid deciding (and implementing) how differing knowledge about actions get coordinated; dealing with such issues simply too difficult at present. 4 Negotiating with a dialogue system In this section we present a worked out example of how the solutions of the planning problems introduced in the p</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>Raymond Perrault and James Allen. 1980. A planbased analysis of indirect speech acts. Computational Linguistics, 6(3-4):167–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Stoia</author>
<author>Darla Shockley</author>
<author>Donna Byron</author>
<author>Eric Fosler-Lussier</author>
</authors>
<title>SCARE: A situated corpus with annotated referring expressions.</title>
<date>2008</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="6275" citStr="Stoia et al., 2008" startWordPosition="1028" endWordPosition="1031">troversial that (in non-conversational activities) the causal relations between acts define the expectations of the interaction. But also in conversational activities situated in a physical task causal relations guide the interaction; we did an empirical study on such a kind of corpus (Benotti, 2009) and we found that, in this corpus, most CIs for which there is evidence (because they are made explicit in a clarification request) can be explained in terms of causal relations. For our empirical study, we annotated and classified the clarification requests (CRs) that appear in the SCARE corpus (Stoia et al., 2008). 3 Inferring causal implicatures In order to model the causal CIs that we observed in the SCARE corpus, and to experiment with different strategies for negotiating these CIs, we designed a system that mimics the instruction giving setup of the SCARE corpus. In our setup, the DF is a dialogue system that we will call Frolog. The human participant that plays the role of the DG we will call “the player”. In a nutshell, Frolog uses an off-the-shelf planner to compute causal implicatures. That is, it uses classical planning (a well explored and computationally efficient AI technique) to fill out t</context>
</contexts>
<marker>Stoia, Shockley, Byron, Fosler-Lussier, 2008</marker>
<rawString>Laura Stoia, Darla Shockley, Donna Byron, and Eric Fosler-Lussier. 2008. SCARE: A situated corpus with annotated referring expressions. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richmond Thomason</author>
<author>Matthew Stone</author>
<author>David DeVault</author>
</authors>
<title>Enlightened update: A computational architecture for presupposition and other pragmatic phenomena. In Presupposition Accommodation. Ohio State Pragmatics Initiative.</title>
<date>2006</date>
<contexts>
<context position="4835" citStr="Thomason et al., 2006" startWordPosition="787" endWordPosition="790">(after all, Grice did call them conversational implicatures) this view appears to be novel, perhaps even controversial. In the formal pragmatics literature, CIs are often simply viewed as inferences drawn by a hearer on the basis of a speaker’s utterance, contextual information, and the Gricean maxims. We find this perspective too static. CIs (especially relations CIs) are better viewed as intrinsically interactional inferences that arise from the dynamics of conversation. As conversations progress, speakers and hearers switch roles: meaning are negotiated and inference becomes bidirectional (Thomason et al., 2006). Moreover, even within a single turn, hearers are not restricted to simply drawing (or failing to draw) “the” CI: in fact, choosing between internal and external bridging is better viewed as part of the process of negotiating what the CI at stake actually is. We believe that interactive perspectives will be necessary to extend the theory of CIs beyond the relatively narrow domain of quantity CIs. We also believe that the dialog-centered approach we advocate may have practical consequences. In particular, modeling the external process of bridging is a step towards having a pragmatically increm</context>
</contexts>
<marker>Thomason, Stone, DeVault, 2006</marker>
<rawString>Richmond Thomason, Matthew Stone, and David DeVault. 2006. Enlightened update: A computational architecture for presupposition and other pragmatic phenomena. In Presupposition Accommodation. Ohio State Pragmatics Initiative.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deirdre Wilson</author>
<author>Dan Sperber</author>
</authors>
<title>Relevance theory.</title>
<date>2004</date>
<booktitle>In Handbook of Pragmatics,</booktitle>
<pages>607--632</pages>
<publisher>Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="1607" citStr="Wilson and Sperber, 2004" startWordPosition="244" endWordPosition="247">ersational implicature (CI) is far from fully understood. Traditionally CIs have been classified using the Gricean maxims: there are relation CIs (also known as relevance CIs), quantity CIs, quality CIs and manner CIs. In formal pragmatics, the most studied CIs are quantity CIs, probably because they are the ones most obviously amenable to theoretical analysis; see (Geurts, in press) for a survey of the state of the art. Far less studied (and traditionally regarded as somewhat obscure) are relation CIs. Obscure perhaps, but crucial: it has been argued that they subsume all other types of CIs (Wilson and Sperber, 2004). This paper is a first step towards their formalization. We shall analyze a kind of CI that we call causal CIs. Causal CIs are relation CIs as defined by Grice (1975) where the crucial relation is task domain causality. Consider the following example: Mary: The chest is locked, the crown is inside Bill: Give me the crown Bill causally implicated: Unlock the chest In order to carry out the task action required by Bill (to give him the crown) it is necessary to unlock the chest. Hence we say that Bill is implicating, by trading on the domain causal relations (after all, the contents of a chest </context>
</contexts>
<marker>Wilson, Sperber, 2004</marker>
<rawString>Deirdre Wilson and Dan Sperber. 2004. Relevance theory. In Handbook of Pragmatics, pages 607–632. Blackwell, Oxford.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>