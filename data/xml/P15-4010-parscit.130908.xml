<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.708798">
A system for fine-grained aspect-based sentiment analysis of Chinese
</title>
<author confidence="0.717213">
Janna Lipenkova
</author>
<affiliation confidence="0.552657">
Anacode
</affiliation>
<email confidence="0.91467">
janna.lipenkova@anacode.de
</email>
<sectionHeader confidence="0.992859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998631">
This paper presents a pipeline for aspect-
based sentiment analysis of Chinese texts in
the automotive domain. The input to the
pipeline is a string of Chinese characters;
the output is a set of relationships between
evaluations and their targets. The main goal
is to demonstrate how knowledge about sen-
tence structure can increase the precision,
insight value and granularity of the output.
We formulate the task of sentiment analysis
in two steps, namely unit identification and
relation extraction. In unit identification,
we identify fairly well-delimited linguistic
units which describe features, emotions and
evaluations. In relation extraction, we dis-
cover the relations between evaluations and
their “target” features.
</bodyText>
<sectionHeader confidence="0.998781" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999313">
Whereas most work on sentiment analysis, and es-
pecially on less covered languages such as Chi-
nese, is based on probabilistic models and the
use of general sentiment lexica, we believe that
a holistic approach should also take into ac-
count general linguistic knowledge. On the one
hand, this allows to leverage the results of several
decades of research in theoretical linguistics. On
the other hand, the hard-coding of general prin-
ciples of language structure allows us to create a
linguistically adequate training space for further
application of probabilistic models.
In the following, we present the “bottom-up”
component of our sentiment system which builds
opinion representations by a progression along
three levels - the lexical, the phrasal and the sen-
tence level. The system has been conceptualized
manually and bootstrapped on a corpus of about 1
mio. automotive reviews with an average length
of 135 Chinese characters.1 We use a prebuilt lex-
</bodyText>
<footnote confidence="0.647366">
1The reviews were crawled from popular automo-
</footnote>
<bodyText confidence="0.999891717948718">
icon with ca. 2000 entries which contains opin-
ion words, their modifiers, car features as well as
a large number of functional categories relevant
for the syntactic analysis of phrases and sentences.
The performance of the system is evaluated on a
testset of 800 annotated sentences. In practice, the
presented model is complemented by a probabilis-
tic model which performs topic and polarity clas-
sification on the sentence and the document levels;
this component will not be described below due to
space limitations.
The basic assumption on which the model
builds is that language follows rules. Many of
these rules have been extensively studied in the
linguistic literature and have been taken to a level
of abstraction which allows for a straightforward
encoding. Incorporating these rules spares us the
construction of probabilistic models for the dis-
covery of already established general knowledge
about linguistic structure. For example, it has
long been observed that Chinese phrase struc-
ture is largely head-final (Huang 1982, Li 1990,
i. a.): nominal modifiers precede their head nouns,
whereas degree and negation adverbs normally
precede the adjectives or verbs they modify. Due
to the relative rigidity of word order in Chinese
on the phrasal level, a small set of correspond-
ing phrase-level rules achieves a high coverage on
our dataset. Rules do not perform as well on sen-
tence level; nevertheless, some general observa-
tions are possible: for example, AP targets precede
their APs. These high-level observations form the
basis of a sequence classifier which determines
whether a sequence of words between two syntac-
tic phrases establishes or disrupts one of the target
relations between these phrases.
The paper is structured as follows: after a very
brief review of research on aspect-based senti-
ment analysis (henceforth ABSA), we formulate
</bodyText>
<footnote confidence="0.9919005">
tive sites: http://www.autohome.com.cn, http://
auto.16888.com, http://auto.qq.com.
</footnote>
<page confidence="0.980045">
55
</page>
<note confidence="0.697485">
Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 55–60,
Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP
</note>
<bodyText confidence="0.999565571428571">
our task and, specifically, present the output for-
mat of the system (Section 3). In the second step,
we briefly describe the categories used in our lex-
ical resources (Section 4). In the third step, we
describe the three levels of processing (Section 5).
Finally, we present the evaluation of our system
(Section 6).
</bodyText>
<sectionHeader confidence="0.994278" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999927033333333">
ABSA has been exploited as a refined alternative
to sentiment analysis on the sentence and the doc-
ument level: whereas the latter targets the general
sentiment or polarity of a piece of text, ABSA out-
puts a mapping from specific aspects of the dis-
cussed topic to their evaluations. Different ABSA
approaches have been exploited; thus, Popescu
and Etzioni (2005) and Kim and Hovy (2006)
present unsupervised algorithms for extracting as-
pects and determining sentiment in review text.
Ding et al. (2008) and Liu (2012) describe ap-
proaches based on rules of semantic composition
and distance metrics for the identification of rela-
tions between aspects and their opinions. Due to
the relatively fine granularity of the task, parsing-
based approaches have been proposed to capture
the aspect/sentiment relations based on sentence
structure (Jiang et al. 2011, Boiy and Moens 2009,
i. a.). Further, the SemEval-2014 task on ABSA
(Pontiki et al., 2014) has been addressed with a
number of promising approaches and also signif-
icantly contributed to a unified understanding of
ABSA.
Still, most research is focussed on the English
language; for Chinese, most approaches to senti-
ment analysis are targeted on lexicon construction
(e. g. Liu et al. 2013) or sentence/document-level
sentiment classification.2 Only few contributions
aim at a finer-grained analysis at the aspect level
(Ku et al. (2009), Su et al. (2008)).
</bodyText>
<sectionHeader confidence="0.99538" genericHeader="method">
3 Task
</sectionHeader>
<bodyText confidence="0.956988105263158">
The goal of aspect-based sentiment analysis is
to derive the opinions of a speaker about an entity
and its features (Liu, 2012, p. 58). In our frame-
work, opinions can be subclassified into evalua-
tions and emotions. Evaluations express how the
author evaluates a specific feature (e. g. good, ex-
pensive), whereas emotions express how the au-
2Cf. Proceedings of the evaluation task on polarity anal-
ysis organized by the Professional Committee of Information
Retrieval (���fr7��������) 2008 - 2014.
thor feels about a specific feature (e. g. to please,
angry).
We formulate the task in two stages - the iden-
tification of syntactic units and the extraction of
relations between the syntactic units. Thus, given
an opinion statement on a specific product, we
“translate” the statement into a set of (feature, &lt;
evaluation|emotion &gt; ) pairs in two processing
steps:
</bodyText>
<listItem confidence="0.944391">
1. Build three sets of syntactic units F (fea-
tures), EV (evaluations) and EM (emo-
tions). For convenience, we will use E =
EM U EV in cases where the evalua-
tion/emotion distinction is not relevant.
2. For each e E E, find whether it has an opin-
ion target f E F.
</listItem>
<bodyText confidence="0.999872333333333">
A word is in place about the semantic orga-
nization of evaluations and emotions in our sys-
tem. It has long been observed that many evalu-
ation words come with implicit features; for ex-
ample, the evaluation beautiful implicitly contains
the feature VisualAppearance. In order to preserve
this meaning, we adopt a scalar representation of
evaluations (cf. Kennedy and McNally (2005) for
a linguistic analysis of scalar expressions): eval-
uations are represented as pairs of a feature and
a numerical value which “maps” the evaluation
to some point on the feature scale [-3, 3]. Thus,
beautiful gets the representation (VisualAppear-
ance, 2), whereas ugly gets the representation (Vi-
sualAppearance, -2). Similarly, emotions are also
represented as pairs of the emotion concept and a
numerical value representing the intensity of the
emotion (e. g. angry: (Anger, 2)).
The final mapping goes from sequences of fea-
tures to numerical evaluations. In a feature se-
quence [f1, f2 ... fn], features are ordered by the
subfeature relation, such that fi (with i &gt; 0) is a
subfeature of fi−1. Consider the following feature
expression:
</bodyText>
<equation confidence="0.881858">
(1) )ifr7-A 0 �, IR Pt
</equation>
<bodyText confidence="0.988047">
steering.wheel DE indicator
the indicator of the steering wheel
Our representation is [SteeringWheel, Indica-
tor], whereby Indicator is interpreted as a subfea-
ture of SteeringWheel.
Further, implicit features that are contained in
associated evaluations are also “moved” into the
feature sequence:
</bodyText>
<page confidence="0.978792">
56
</page>
<bodyText confidence="0.983397444444444">
(2) )inA
steering.wheel
The indicator of the steering wheel is very
precise.
This sentence contains the evaluation ‘precise’.
According to the above description, it is decom-
posed into a feature (Precision) and a positive eval-
uation. The feature is moved into the feature se-
quence. The resulting mapping is as follows:
</bodyText>
<listItem confidence="0.9844895">
(3) [SteeringWheel, Indicator, Precision] →
+2
</listItem>
<bodyText confidence="0.9999034">
Thus, instead of limiting ourselves to entities
and restricted sets of their immediate features, we
adapt a “higher-order” view and allow a hierarchi-
cal feature sequence of arbitrary depth. This struc-
ture seamlessly integrates implicit features and
flexibly captures any granularity that is intended
by the author of the text. At the same time, the
value of the evaluation is reduced to a single nu-
merical value, which allows for a straightforward
aggregation of the final results.
</bodyText>
<sectionHeader confidence="0.956578" genericHeader="method">
4 Lexical basis
</sectionHeader>
<bodyText confidence="0.995951142857143">
Out lexical resources contain functional and se-
mantic categories. Members of “functional” cat-
egories (e. g. conjunctions, phrase-final markers)
are only relevant for the syntactic analysis. Se-
mantic categories are relevant for the interpreta-
tion of opinions. The top-level semantic categories
are:
</bodyText>
<listItem confidence="0.840075615384616">
• Features, e. g. �All (‘look’), F-4- (‘seat’),
UIS (‘color’)
• Evaluations:
– with implicit features, e. g. ff 8
(‘beautiful’ → VisualAppearance), fE
t (‘cheap’ → Price)
– without implicit features, e. g. T r
(‘not bad’), (‘ordinary’), Øïå
(‘OK’)
• Emotions, e. g. RX (‘admire’), kNA (‘an-
noying’)
• Degree adverbs and negation words, e. g.
8 (‘very’), MM (‘a little bit’), T (‘not’)
</listItem>
<bodyText confidence="0.99846125">
Each of these categories is in turn subclassified
into more fine-grained classes which capture in-
formation about the linguistic use of the subclass
members.
</bodyText>
<sectionHeader confidence="0.920083" genericHeader="method">
5 Processing steps
</sectionHeader>
<bodyText confidence="0.999079666666667">
Figure illustrates the in- and output, the three
processing steps as well as the resources involved
in these steps.
</bodyText>
<subsectionHeader confidence="0.99308">
5.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.9999095">
We use the third-party tool jieba3 for word seg-
mentation and POS tagging; both steps are cus-
tomized in order to achieve a better performance
on domain- and task-specific data. Specifically,
the dictionary provided by the tool is inter-
sected with a user-specified dictionary. This user-
specified dictionary contains all words from our
lexical resources. The user-added words are anno-
tated with customized POS tags, such as ‘F’ for
feature, ‘EV’ for evaluation etc. The following
two examples depict the same sentence as output
by jieba without and with customization:
</bodyText>
<listItem confidence="0.723563">
(4) a. original jieba output without cus-
tomization:
</listItem>
<figure confidence="0.50945125">
EtDd
already
T,M/a
not.bad
The rear space is already quite not
bad.
b. after customization:
fw:�-41��ô/F
</figure>
<bodyText confidence="0.938663615384615">
rear.space
TR/D TrH/EV T/ul o/x
very not.bad PFV
The rear space is already quite not
bad.
Thus, we see that the two words fw:�-41� (‘rear
row’) and �ô (‘space’) are merged into one word
in the customized output since this combination
occurs frequently in automotive texts and has a
quasi-lexicalized meaning; the resulting word gets
our custom POS tag ‘F’ (feature). Further, the
POS tag of TM is changed from the original jieba
tag ‘a’ to the custom tag ‘EV’ (evaluation).
</bodyText>
<subsectionHeader confidence="0.997344">
5.2 Unit identification
</subsectionHeader>
<bodyText confidence="0.9989235">
In the next step, we identify phrasal units corre-
sponding to features, evaluations, emotions. We
use a phrase rule grammar which is based on reg-
ular expressions involving the POS tags of the
</bodyText>
<footnote confidence="0.533838">
3https://github.com/fxsjy/jieba
</footnote>
<figure confidence="0.996992944444444">
0 �, IR Pt TR NJ��
DE indicator very precise
fw:�-41�/vn �ô/n
rear.row space
�/v
make
f4/ud
DE
TR/d
very
T/ul o/x
PFV
EtDd
already
�/v
make
f4/ud
DE
</figure>
<page confidence="0.828913">
57
</page>
<figureCaption confidence="0.999913">
Figure 1: Overall architecture of the system
Figure 2: Phrasal analysis of the sentence Fw �R EOr t $4 TR T- 7
</figureCaption>
<bodyText confidence="0.869679076923077">
words. Figure 2 shows the parsed version of ex-
ample (4b).
In the following, we present some of the most
common phrase structures for features and evalu-
ations/emotions that are used in our system.
Feature phrases Besides simple NPs consisting
only of one feature word, the most frequent types
of feature phrases are phrases with nominal mod-
ifiers, coordinated NPs and NPs with pronominal
modifiers:
(5) NP modifier:
F-10151 0 �&apos; f )4
seat DE material
the material of the seats
verbs. However, evaluations and emotions get a
unified treatment at the unit level, since Chinese
stative verbs behave similarly to adjectives: they
can also be modified by degree adverbs, used in
comparative constructions etc.
Besides simple lexical units, the following are
the most frequent phrase types for the E class:
(8) a. Verb or adjective preceded by nega-
tion or degree adverb:
TV, %9�f_
very difficult.to.bear
very difficult to bear
</bodyText>
<figure confidence="0.986108923076923">
b. Adjective followed by degree adverb:
,J.
small
T
PFV
1
a.bit
(6) 1� 0 �&apos; ikit
it DE design
its design
(7) u4l� (W/V fw:�-41�
front.row (and) rear.row
a bit small
</figure>
<bodyText confidence="0.94615025">
Evaluations can be coordinated in various ways;
for example, coordination can be expressed by
simple juxtaposition, with a comma or in the R
E1 R E2 construction:
the front and the rear row
Evaluation and emotion chunks The class of
evaluations consists of adjectives, whereas the
class of emotions consists both of adjectives and
</bodyText>
<listItem confidence="0.790164">
(9) a. juxtaposition / punctuation:
</listItem>
<bodyText confidence="0.605373666666667">
XM
flexible
precise and flexible
</bodyText>
<page confidence="0.604423">
rN
</page>
<figure confidence="0.761425333333333">
precise
(�)
(,)
</figure>
<page confidence="0.724775">
58
</page>
<table confidence="0.385803666666667">
b. R E1 R E2: (12) a. Single argument of an AP:
R rN R XM ikit &amp;quot;VI Hf&apos;a-
CONJ precise CONJ flexible design particularly fashionable
</table>
<bodyText confidence="0.9330594">
both precise and flexible
Besides, evaluations are often expressed by so-
called “possessed features”: the evaluation value
is derived from the “amount” to which a feature is
possessed by the discussed entity:
</bodyText>
<equation confidence="0.877849">
(10) { c
NEG
</equation>
<bodyText confidence="0.523428">
not vigorous
</bodyText>
<subsectionHeader confidence="0.995968">
5.3 Relation extraction
</subsectionHeader>
<bodyText confidence="0.999972321428571">
After identifying the syntactic units of interest, we
proceed with identifying sentence-level relations
between these units. In the literature, there are
two major approaches to the identification of rela-
tions between evaluations and their targets. On the
one hand, some authors recur to parsing and iden-
tify evaluation targets based on dependency rela-
tions (Wu et al. 2009, Jiang et al. 2011, i. a.). On
the other hand, distance metrics can be used (Ding
et al., 2008; Liu, 2012). Since we want to avoid the
overhead of full-fledged syntactic parsing, but also
want to improve the accuracy of simple distance
metrics, we develop a sequence classifier which
determines whether a given sequence of words be-
tween a feature and an evaluation/emotion phrase
indicates a target relation.
The two semantic relations of interest are the
causer and the theme relation. Additionally, the
system analyzes a third non-semantic relation –
the topic – which provides relevant discourse-
structural information on the overall aspect dis-
cussed in a sentence.
The causer relation The causer relation is a
fairly well-delimited relation which describes the
causer of some state of event. In our model, it
is applied to emotions caused by specific features.
In the most basic cases, the causer is expressed as
subject of one of the causative verbs (-±, - etc.):
</bodyText>
<equation confidence="0.4672085">
(11)r,�Jfj
power
</equation>
<bodyText confidence="0.995382428571429">
The power really makes me desperate.
The theme relation The theme relation is ex-
pressed differently for evaluations and emotions.
In the case of evaluations, it can be realized as the
single argument of an AP or the nominal head of
an adjectival modifier:
The design is particularly fashionable.
</bodyText>
<figure confidence="0.4200612">
b. Nominal head of an adjectival modi-
fier:
&amp;quot;VI
particularly
a particularly fashionable design
</figure>
<bodyText confidence="0.756255142857143">
With respect to emotions, the theme relation is
only relevant for verbs; the feature targets of ad-
jectives are covered by the causer relation. Thus,
themes can be expressed as (possibly topicalized)
objects of emotion verbs:
(13) a. Object in canonical postverbal posi-
tion:
ikit
design
I like its design a lot.
b. Topicalized object:
ikit
design
The design, I like it a lot, ...
</bodyText>
<subsectionHeader confidence="0.991479">
5.4 Relation extraction
</subsectionHeader>
<bodyText confidence="0.99998775">
In the above examples, relations hold between ad-
joined constituents and can thus be easily recog-
nized. However, in many cases, several words oc-
cur between the evaluation/emotion and its target:
</bodyText>
<equation confidence="0.57800125">
A
already
T-
not.bad PFV
</equation>
<bodyText confidence="0.994844428571429">
The rear space is already quite not bad.
From our corpus, we bootstrap the most fre-
quent sequences that occur between themes and
emotions/evaluations, emotions and themes as
well as causers and emotions. We then apply a
simple classifier for the classification of unseen se-
quences.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9998348">
The system is evaluated on a testset of 800 sen-
tences annotated for feature, evaluation and emo-
tion phrases and for relations between them. The
annotation was carried out according to previously
developed annotation guidelines; we worked with
</bodyText>
<figure confidence="0.999134428571429">
�
have
nt
vigor
YI__ M-
desperate
R
me
-±
CAUS
4
very
R &apos;a 0 �, ikit
fashionable DE design
�
it
0 �,
DE
R
me
��
like
TV,
very
TV, �� ...
very like
, ...
(14) Etz
rear.row space
TV,
DE
14
make
T,M
very
</figure>
<page confidence="0.990874">
59
</page>
<table confidence="0.99963475">
Precision Recall
F-phrases 87.43% 85.37%
EV-phrases 89.21 % 84.29%
EM-phrases 88.56% 85.32%
</table>
<tableCaption confidence="0.998148">
Table 1: Results of unit identification
</tableCaption>
<table confidence="0.99994625">
Precision Recall
F-EV relations - theme 89.2% 87.33%
F-EM relations - theme 84.01% 83.10%
F-EM relations - causer 86.49% 87.90%
</table>
<tableCaption confidence="0.99977">
Table 2: Results of relation extraction
</tableCaption>
<bodyText confidence="0.999927266666667">
two independent annotators - a native Chinese stu-
dent without specialized linguistic knowledge and
a non-native linguist with very good mastery of
the Chinese language. They proceeded in three
steps: at the phrase level, the total F-score of inter-
annotator agreement was 91.3%. The diverging
items were discussed with a third team member
to create a unified phrase-level annotation. The re-
viewed corpus was then annotated for relations be-
tween opinion and their targets; in this step, inter-
annotator agreement reached 93.4%.
Table 1 shows the results achieved in unit iden-
tification; table 2 shows the results achieved for
relation extraction on the test set with finalized an-
notation of F/EV/EM phrases.
</bodyText>
<sectionHeader confidence="0.999582" genericHeader="conclusions">
7 Outlook
</sectionHeader>
<bodyText confidence="0.999987">
We have shown that the use of a prebuilt lexicon
together with the application of general language
rules allows to achieve a considerable accuracy in
ABSA for Chinese. Currently, the presented sys-
tem is being extended with a number of more com-
plex sentence-level relations, specifically compar-
ative structures and modal operators. Further,
</bodyText>
<sectionHeader confidence="0.983124" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.664146">
Boiy, Erik and Moens, Marie-Francine. 2009. A
machine learning approach to sentiment analy-
sis in multilingual Web texts. Inf. Retr. 12(5),
526–558.
</bodyText>
<reference confidence="0.999701888888889">
Ding, Xiaowen, Liu, Bing and Yu, Philip S. 2008.
A Holistic Lexicon-based Approach to Opinion
Mining. In Proceedings of WSDM’08, WSDM
’08, pages 231–240.
Huang, James C.-T. 1982. Logical relations
in Chinese and the theory of grammar.
Ph. D.thesis, MIT, Massachusetts.
Jiang, Long, Yu, Mo, Zhou, Ming, Liu, Xiaohua
and Zhao, Tiejun. 2011. Target-dependent Twit-
ter Sentiment Classification. In Proceedings of
ACL’11 - Volume 1, pages 151–160.
Kennedy, Christopher and McNally, Louise. 2005.
Scale structure, degree modification, and the se-
mantics of gradable predicates. Language 81,
345 – 381.
Kim, Soo-Min and Hovy, Eduard. 2006. Extract-
ing Opinions, Opinion Holders, and Topics Ex-
pressed in Online News Media Text. In Pro-
ceedings of the Workshop on Sentiment and
Subjectivity in Text, SST ’06, pages 1–8.
Ku, Lunwei, Huang, Tinghao and Chen, Hsinhsi.
2009. Using Morphological and Syntactic
Structures for Chinese Opinion Analysis. In
Proceedings of EMNLP’09, pages 1260–1269.
Li, Audrey Yen-Hui. 1990. Order and Con-
stituency in Mandarin Chinese. Studies in Natu-
ral Language and Linguistic Theory, Dordrecht:
Kluwer Academic Publishers.
Liu, Bing. 2012. Sentiment Analysis and Opinion
Mining.
Liu, Lizhen, Lei, Mengyun and Wang, Hanshi.
2013. Combining Domain-Specific Sentiment
Lexicon with Hownet for Chinese Sentiment
Analysis. Journal of Computers 8(4).
Pontiki, Maria, Galanis, Dimitris, Pavlopoulos,
John, Papageorgiou, Harris, Androutsopoulos,
Ion and Manandhar, Suresh. 2014. SemEval-
2014 Task 4: Aspect Based Sentiment Analy-
sis. In Proceedings of the SemEval’14, pages
27–35, Dublin, Ireland: ACL and Dublin City
University.
Popescu, Ana Maria and Etzioni, Oren. 2005. Ex-
tracting Product Features and Opinions from
Reviews. In Proceedings of HLT &amp; EMNLP’05,
pages 339–346, Stroudsburg, USA.
Su, Qi, Xu, Xinying, Guo, Honglei, Guo, Zhili,
Wu, Xian, Zhang, Xiaoxun, Swen, Bin and Su,
Zhong. 2008. Hidden Sentiment Association in
Chinese Web Opinion Mining. In Proceedings
of WWW’08.
Wu, Yuanbin, Zhang, Qi, Huang, Xuanjing and
Wu, Lide. 2009. Phrase Dependency Parsing for
Opinion Mining. In Proceedings of EMNLP’09,
pages 1533–1541, Stroudsburg, USA.
</reference>
<page confidence="0.998414">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.418311">
<title confidence="0.962908">A system for fine-grained aspect-based sentiment analysis of Chinese</title>
<author confidence="0.6810505">Janna Anacode</author>
<email confidence="0.973897">janna.lipenkova@anacode.de</email>
<abstract confidence="0.999115833333333">This paper presents a pipeline for aspectbased sentiment analysis of Chinese texts in the automotive domain. The input to the pipeline is a string of Chinese characters; the output is a set of relationships between evaluations and their targets. The main goal is to demonstrate how knowledge about sentence structure can increase the precision, insight value and granularity of the output. We formulate the task of sentiment analysis in two steps, namely unit identification and relation extraction. In unit identification, we identify fairly well-delimited linguistic units which describe features, emotions and evaluations. In relation extraction, we discover the relations between evaluations and their “target” features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A Holistic Lexicon-based Approach to Opinion Mining.</title>
<date>2008</date>
<booktitle>In Proceedings of WSDM’08, WSDM ’08,</booktitle>
<pages>231--240</pages>
<contexts>
<context position="4765" citStr="Ding et al. (2008)" startWordPosition="735" endWordPosition="738">hree levels of processing (Section 5). Finally, we present the evaluation of our system (Section 6). 2 Previous work ABSA has been exploited as a refined alternative to sentiment analysis on the sentence and the document level: whereas the latter targets the general sentiment or polarity of a piece of text, ABSA outputs a mapping from specific aspects of the discussed topic to their evaluations. Different ABSA approaches have been exploited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focu</context>
<context position="14168" citStr="Ding et al., 2008" startWordPosition="2274" endWordPosition="2277">uation value is derived from the “amount” to which a feature is possessed by the discussed entity: (10) { c NEG not vigorous 5.3 Relation extraction After identifying the syntactic units of interest, we proceed with identifying sentence-level relations between these units. In the literature, there are two major approaches to the identification of relations between evaluations and their targets. On the one hand, some authors recur to parsing and identify evaluation targets based on dependency relations (Wu et al. 2009, Jiang et al. 2011, i. a.). On the other hand, distance metrics can be used (Ding et al., 2008; Liu, 2012). Since we want to avoid the overhead of full-fledged syntactic parsing, but also want to improve the accuracy of simple distance metrics, we develop a sequence classifier which determines whether a given sequence of words between a feature and an evaluation/emotion phrase indicates a target relation. The two semantic relations of interest are the causer and the theme relation. Additionally, the system analyzes a third non-semantic relation – the topic – which provides relevant discoursestructural information on the overall aspect discussed in a sentence. The causer relation The ca</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Ding, Xiaowen, Liu, Bing and Yu, Philip S. 2008. A Holistic Lexicon-based Approach to Opinion Mining. In Proceedings of WSDM’08, WSDM ’08, pages 231–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James C-T Huang</author>
</authors>
<date>1982</date>
<booktitle>Logical relations in Chinese and the theory of grammar. Ph.</booktitle>
<location>D.thesis, MIT, Massachusetts.</location>
<contexts>
<context position="2899" citStr="Huang 1982" startWordPosition="443" endWordPosition="444"> and the document levels; this component will not be described below due to space limitations. The basic assumption on which the model builds is that language follows rules. Many of these rules have been extensively studied in the linguistic literature and have been taken to a level of abstraction which allows for a straightforward encoding. Incorporating these rules spares us the construction of probabilistic models for the discovery of already established general knowledge about linguistic structure. For example, it has long been observed that Chinese phrase structure is largely head-final (Huang 1982, Li 1990, i. a.): nominal modifiers precede their head nouns, whereas degree and negation adverbs normally precede the adjectives or verbs they modify. Due to the relative rigidity of word order in Chinese on the phrasal level, a small set of corresponding phrase-level rules achieves a high coverage on our dataset. Rules do not perform as well on sentence level; nevertheless, some general observations are possible: for example, AP targets precede their APs. These high-level observations form the basis of a sequence classifier which determines whether a sequence of words between two syntactic </context>
</contexts>
<marker>Huang, 1982</marker>
<rawString>Huang, James C.-T. 1982. Logical relations in Chinese and the theory of grammar. Ph. D.thesis, MIT, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent Twitter Sentiment Classification.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL’11 -</booktitle>
<volume>1</volume>
<pages>151--160</pages>
<contexts>
<context position="5116" citStr="Jiang et al. 2011" startWordPosition="789" endWordPosition="792">s of the discussed topic to their evaluations. Different ABSA approaches have been exploited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focussed on the English language; for Chinese, most approaches to sentiment analysis are targeted on lexicon construction (e. g. Liu et al. 2013) or sentence/document-level sentiment classification.2 Only few contributions aim at a finer-grained analysis at the aspect level (Ku et al. (2009), Su et al. (2008)). 3 Task The goal of aspect-based sentiment </context>
<context position="14092" citStr="Jiang et al. 2011" startWordPosition="2259" endWordPosition="2262">, evaluations are often expressed by socalled “possessed features”: the evaluation value is derived from the “amount” to which a feature is possessed by the discussed entity: (10) { c NEG not vigorous 5.3 Relation extraction After identifying the syntactic units of interest, we proceed with identifying sentence-level relations between these units. In the literature, there are two major approaches to the identification of relations between evaluations and their targets. On the one hand, some authors recur to parsing and identify evaluation targets based on dependency relations (Wu et al. 2009, Jiang et al. 2011, i. a.). On the other hand, distance metrics can be used (Ding et al., 2008; Liu, 2012). Since we want to avoid the overhead of full-fledged syntactic parsing, but also want to improve the accuracy of simple distance metrics, we develop a sequence classifier which determines whether a given sequence of words between a feature and an evaluation/emotion phrase indicates a target relation. The two semantic relations of interest are the causer and the theme relation. Additionally, the system analyzes a third non-semantic relation – the topic – which provides relevant discoursestructural informati</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Jiang, Long, Yu, Mo, Zhou, Ming, Liu, Xiaohua and Zhao, Tiejun. 2011. Target-dependent Twitter Sentiment Classification. In Proceedings of ACL’11 - Volume 1, pages 151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Louise McNally</author>
</authors>
<title>Scale structure, degree modification, and the semantics of gradable predicates.</title>
<date>2005</date>
<journal>Language</journal>
<volume>81</volume>
<pages>345--381</pages>
<contexts>
<context position="7179" citStr="Kennedy and McNally (2005)" startWordPosition="1133" endWordPosition="1136">e sets of syntactic units F (features), EV (evaluations) and EM (emotions). For convenience, we will use E = EM U EV in cases where the evaluation/emotion distinction is not relevant. 2. For each e E E, find whether it has an opinion target f E F. A word is in place about the semantic organization of evaluations and emotions in our system. It has long been observed that many evaluation words come with implicit features; for example, the evaluation beautiful implicitly contains the feature VisualAppearance. In order to preserve this meaning, we adopt a scalar representation of evaluations (cf. Kennedy and McNally (2005) for a linguistic analysis of scalar expressions): evaluations are represented as pairs of a feature and a numerical value which “maps” the evaluation to some point on the feature scale [-3, 3]. Thus, beautiful gets the representation (VisualAppearance, 2), whereas ugly gets the representation (VisualAppearance, -2). Similarly, emotions are also represented as pairs of the emotion concept and a numerical value representing the intensity of the emotion (e. g. angry: (Anger, 2)). The final mapping goes from sequences of features to numerical evaluations. In a feature sequence [f1, f2 ... fn], fe</context>
</contexts>
<marker>Kennedy, McNally, 2005</marker>
<rawString>Kennedy, Christopher and McNally, Louise. 2005. Scale structure, degree modification, and the semantics of gradable predicates. Language 81, 345 – 381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST ’06,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="4649" citStr="Kim and Hovy (2006)" startWordPosition="718" endWordPosition="721">p, we briefly describe the categories used in our lexical resources (Section 4). In the third step, we describe the three levels of processing (Section 5). Finally, we present the evaluation of our system (Section 6). 2 Previous work ABSA has been exploited as a refined alternative to sentiment analysis on the sentence and the document level: whereas the latter targets the general sentiment or polarity of a piece of text, ABSA outputs a mapping from specific aspects of the discussed topic to their evaluations. Different ABSA approaches have been exploited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of prom</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Kim, Soo-Min and Hovy, Eduard. 2006. Extracting Opinions, Opinion Holders, and Topics Expressed in Online News Media Text. In Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST ’06, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lunwei Ku</author>
<author>Tinghao Huang</author>
<author>Hsinhsi Chen</author>
</authors>
<title>Using Morphological and Syntactic Structures for Chinese Opinion Analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP’09,</booktitle>
<pages>1260--1269</pages>
<contexts>
<context position="5653" citStr="Ku et al. (2009)" startWordPosition="873" endWordPosition="876">e the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focussed on the English language; for Chinese, most approaches to sentiment analysis are targeted on lexicon construction (e. g. Liu et al. 2013) or sentence/document-level sentiment classification.2 Only few contributions aim at a finer-grained analysis at the aspect level (Ku et al. (2009), Su et al. (2008)). 3 Task The goal of aspect-based sentiment analysis is to derive the opinions of a speaker about an entity and its features (Liu, 2012, p. 58). In our framework, opinions can be subclassified into evaluations and emotions. Evaluations express how the author evaluates a specific feature (e. g. good, expensive), whereas emotions express how the au2Cf. Proceedings of the evaluation task on polarity analysis organized by the Professional Committee of Information Retrieval (���fr7��������) 2008 - 2014. thor feels about a specific feature (e. g. to please, angry). We formulate th</context>
</contexts>
<marker>Ku, Huang, Chen, 2009</marker>
<rawString>Ku, Lunwei, Huang, Tinghao and Chen, Hsinhsi. 2009. Using Morphological and Syntactic Structures for Chinese Opinion Analysis. In Proceedings of EMNLP’09, pages 1260–1269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Audrey Yen-Hui Li</author>
</authors>
<title>Order and Constituency</title>
<date>1990</date>
<booktitle>in Mandarin Chinese. Studies in Natural Language and Linguistic Theory,</booktitle>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="2908" citStr="Li 1990" startWordPosition="445" endWordPosition="446">ument levels; this component will not be described below due to space limitations. The basic assumption on which the model builds is that language follows rules. Many of these rules have been extensively studied in the linguistic literature and have been taken to a level of abstraction which allows for a straightforward encoding. Incorporating these rules spares us the construction of probabilistic models for the discovery of already established general knowledge about linguistic structure. For example, it has long been observed that Chinese phrase structure is largely head-final (Huang 1982, Li 1990, i. a.): nominal modifiers precede their head nouns, whereas degree and negation adverbs normally precede the adjectives or verbs they modify. Due to the relative rigidity of word order in Chinese on the phrasal level, a small set of corresponding phrase-level rules achieves a high coverage on our dataset. Rules do not perform as well on sentence level; nevertheless, some general observations are possible: for example, AP targets precede their APs. These high-level observations form the basis of a sequence classifier which determines whether a sequence of words between two syntactic phrases e</context>
</contexts>
<marker>Li, 1990</marker>
<rawString>Li, Audrey Yen-Hui. 1990. Order and Constituency in Mandarin Chinese. Studies in Natural Language and Linguistic Theory, Dordrecht: Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<contexts>
<context position="4780" citStr="Liu (2012)" startWordPosition="740" endWordPosition="741">ng (Section 5). Finally, we present the evaluation of our system (Section 6). 2 Previous work ABSA has been exploited as a refined alternative to sentiment analysis on the sentence and the document level: whereas the latter targets the general sentiment or polarity of a piece of text, ABSA outputs a mapping from specific aspects of the discussed topic to their evaluations. Different ABSA approaches have been exploited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focussed on the Eng</context>
<context position="14180" citStr="Liu, 2012" startWordPosition="2278" endWordPosition="2279">ived from the “amount” to which a feature is possessed by the discussed entity: (10) { c NEG not vigorous 5.3 Relation extraction After identifying the syntactic units of interest, we proceed with identifying sentence-level relations between these units. In the literature, there are two major approaches to the identification of relations between evaluations and their targets. On the one hand, some authors recur to parsing and identify evaluation targets based on dependency relations (Wu et al. 2009, Jiang et al. 2011, i. a.). On the other hand, distance metrics can be used (Ding et al., 2008; Liu, 2012). Since we want to avoid the overhead of full-fledged syntactic parsing, but also want to improve the accuracy of simple distance metrics, we develop a sequence classifier which determines whether a given sequence of words between a feature and an evaluation/emotion phrase indicates a target relation. The two semantic relations of interest are the causer and the theme relation. Additionally, the system analyzes a third non-semantic relation – the topic – which provides relevant discoursestructural information on the overall aspect discussed in a sentence. The causer relation The causer relatio</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Liu, Bing. 2012. Sentiment Analysis and Opinion Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lizhen Liu</author>
<author>Mengyun Lei</author>
<author>Hanshi Wang</author>
</authors>
<title>Combining Domain-Specific Sentiment Lexicon with Hownet for Chinese Sentiment Analysis.</title>
<date>2013</date>
<journal>Journal of Computers</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="5506" citStr="Liu et al. 2013" startWordPosition="853" endWordPosition="856">ations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focussed on the English language; for Chinese, most approaches to sentiment analysis are targeted on lexicon construction (e. g. Liu et al. 2013) or sentence/document-level sentiment classification.2 Only few contributions aim at a finer-grained analysis at the aspect level (Ku et al. (2009), Su et al. (2008)). 3 Task The goal of aspect-based sentiment analysis is to derive the opinions of a speaker about an entity and its features (Liu, 2012, p. 58). In our framework, opinions can be subclassified into evaluations and emotions. Evaluations express how the author evaluates a specific feature (e. g. good, expensive), whereas emotions express how the au2Cf. Proceedings of the evaluation task on polarity analysis organized by the Professi</context>
</contexts>
<marker>Liu, Lei, Wang, 2013</marker>
<rawString>Liu, Lizhen, Lei, Mengyun and Wang, Hanshi. 2013. Combining Domain-Specific Sentiment Lexicon with Hownet for Chinese Sentiment Analysis. Journal of Computers 8(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitris Galanis</author>
<author>John Pavlopoulos</author>
<author>Harris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>SemEval2014 Task 4: Aspect Based Sentiment Analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the SemEval’14,</booktitle>
<pages>27--35</pages>
<institution>ACL and Dublin City University.</institution>
<location>Dublin, Ireland:</location>
<contexts>
<context position="5208" citStr="Pontiki et al., 2014" startWordPosition="805" endWordPosition="808">ited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been addressed with a number of promising approaches and also significantly contributed to a unified understanding of ABSA. Still, most research is focussed on the English language; for Chinese, most approaches to sentiment analysis are targeted on lexicon construction (e. g. Liu et al. 2013) or sentence/document-level sentiment classification.2 Only few contributions aim at a finer-grained analysis at the aspect level (Ku et al. (2009), Su et al. (2008)). 3 Task The goal of aspect-based sentiment analysis is to derive the opinions of a speaker about an entity and its features (Liu, 2012,</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Pontiki, Maria, Galanis, Dimitris, Pavlopoulos, John, Papageorgiou, Harris, Androutsopoulos, Ion and Manandhar, Suresh. 2014. SemEval2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the SemEval’14, pages 27–35, Dublin, Ireland: ACL and Dublin City University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT &amp; EMNLP’05,</booktitle>
<pages>339--346</pages>
<location>Stroudsburg, USA.</location>
<contexts>
<context position="4625" citStr="Popescu and Etzioni (2005)" startWordPosition="713" endWordPosition="716"> (Section 3). In the second step, we briefly describe the categories used in our lexical resources (Section 4). In the third step, we describe the three levels of processing (Section 5). Finally, we present the evaluation of our system (Section 6). 2 Previous work ABSA has been exploited as a refined alternative to sentiment analysis on the sentence and the document level: whereas the latter targets the general sentiment or polarity of a piece of text, ABSA outputs a mapping from specific aspects of the discussed topic to their evaluations. Different ABSA approaches have been exploited; thus, Popescu and Etzioni (2005) and Kim and Hovy (2006) present unsupervised algorithms for extracting aspects and determining sentiment in review text. Ding et al. (2008) and Liu (2012) describe approaches based on rules of semantic composition and distance metrics for the identification of relations between aspects and their opinions. Due to the relatively fine granularity of the task, parsingbased approaches have been proposed to capture the aspect/sentiment relations based on sentence structure (Jiang et al. 2011, Boiy and Moens 2009, i. a.). Further, the SemEval-2014 task on ABSA (Pontiki et al., 2014) has been address</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, Ana Maria and Etzioni, Oren. 2005. Extracting Product Features and Opinions from Reviews. In Proceedings of HLT &amp; EMNLP’05, pages 339–346, Stroudsburg, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Su</author>
</authors>
<title>Hidden Sentiment Association in Chinese Web Opinion Mining.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW’08.</booktitle>
<location>Xu, Xinying, Guo, Honglei, Guo, Zhili, Wu, Xian, Zhang, Xiaoxun, Swen, Bin</location>
<marker>Su, 2008</marker>
<rawString>Su, Qi, Xu, Xinying, Guo, Honglei, Guo, Zhili, Wu, Xian, Zhang, Xiaoxun, Swen, Bin and Su, Zhong. 2008. Hidden Sentiment Association in Chinese Web Opinion Mining. In Proceedings of WWW’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase Dependency Parsing for Opinion Mining.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP’09,</booktitle>
<pages>1533--1541</pages>
<location>Stroudsburg, USA.</location>
<contexts>
<context position="14073" citStr="Wu et al. 2009" startWordPosition="2255" endWordPosition="2258">flexible Besides, evaluations are often expressed by socalled “possessed features”: the evaluation value is derived from the “amount” to which a feature is possessed by the discussed entity: (10) { c NEG not vigorous 5.3 Relation extraction After identifying the syntactic units of interest, we proceed with identifying sentence-level relations between these units. In the literature, there are two major approaches to the identification of relations between evaluations and their targets. On the one hand, some authors recur to parsing and identify evaluation targets based on dependency relations (Wu et al. 2009, Jiang et al. 2011, i. a.). On the other hand, distance metrics can be used (Ding et al., 2008; Liu, 2012). Since we want to avoid the overhead of full-fledged syntactic parsing, but also want to improve the accuracy of simple distance metrics, we develop a sequence classifier which determines whether a given sequence of words between a feature and an evaluation/emotion phrase indicates a target relation. The two semantic relations of interest are the causer and the theme relation. Additionally, the system analyzes a third non-semantic relation – the topic – which provides relevant discourses</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Wu, Yuanbin, Zhang, Qi, Huang, Xuanjing and Wu, Lide. 2009. Phrase Dependency Parsing for Opinion Mining. In Proceedings of EMNLP’09, pages 1533–1541, Stroudsburg, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>