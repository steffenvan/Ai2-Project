<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001039">
<title confidence="0.992559">
Unsupervised Alignment of Privacy Policies using Hidden Markov Models
</title>
<author confidence="0.998092">
Rohan Ramanath Fei Liu Norman Sadeh Noah A. Smith
</author>
<affiliation confidence="0.886832333333333">
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998763">
{rrohan,feiliu,sadeh,nasmith}@cs.cmu.edu
</email>
<sectionHeader confidence="0.993893" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932">
To support empirical study of online pri-
vacy policies, as well as tools for users
with privacy concerns, we consider the
problem of aligning sections of a thousand
policy documents, based on the issues they
address. We apply an unsupervised HMM;
in two new (and reusable) evaluations, we
find the approach more effective than clus-
tering and topic models.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932357142857">
Privacy policy documents are verbose, often eso-
teric legal documents that many people encounter
as clients of companies that provide services on
the web. McDonald and Cranor (2008) showed
that, if users were to read the privacy policies of
every website they access during the course of a
year, they would end up spending a substantial
amount of their time doing just that and would
often still not be able to answer basic questions
about what these policies really say. Unsurpris-
ingly, many people do not read them (Federal
Trade Commission, 2012).
Such policies therefore offer an excellent op-
portunity for NLP tools that summarize or ex-
tract key information that (i) helps users under-
stand the implications of agreeing to these poli-
cies and (ii) helps legal analysts understand the
contents of these policies and make recommenda-
tions on how they can be improved or made more
clear. Past applications of NLP have sought to
parse privacy policies into machine-readable rep-
resentations (Brodie et al., 2006) or extract sub-
policies from larger documents (Xiao et al., 2012).
Machine learning has been applied to assess cer-
tain attributes of policies (Costante et al., 2012;
Ammar et al., 2012; Costante et al., 2013; Zim-
meck and Bellovin, 2013).
This paper instead analyzes policies in aggre-
gate, seeking to align sections of policies. This
task is motivated by an expectation that many poli-
cies will address similar issues,1 such as collec-
tion of a user’s contact, location, health, and fi-
nancial information, sharing with third parties, and
deletion of data. This expectation is supported
by recommendation by privacy experts (Gellman,
2014) and policymakers (Federal Trade Commis-
sion, 2012); in the financial services sector, the
Gramm-Leach-Bliley Act requires these institu-
tions to address a specific set of issues. Aligning
policy sections is a first step toward our aforemen-
tioned summarization and extraction goals.
We present the following contributions:
</bodyText>
<listItem confidence="0.898192142857143">
• A new corpus of over 1,000 privacy policies
gathered from widely used websites, manually
segmented into subtitled sections by crowdwork-
ers (§2).
• An unsupervised approach to aligning the policy
sections based on the issues they discuss. For
example, sections that discuss “user data on the
</listItem>
<bodyText confidence="0.7357142">
company’s server” should be grouped together.
The approach is inspired by the application of
hidden Markov models to sequence alignment in
computational biology (Durbin et al., 1998; §3).
• Two reusable evaluation benchmarks for the re-
sulting alignment of policy sections (§4). We
demonstrate that our approach outperforms naive
methods (§5).
Our corpus and benchmarks are available at
http://usableprivacy.org/data.
</bodyText>
<sectionHeader confidence="0.979687" genericHeader="method">
2 Data Collection
</sectionHeader>
<bodyText confidence="0.992884">
We collected 1,010 unique privacy policy
documents from the top websites ranked by
Alexa.com.2 These policies were collected during
a period of six weeks during December 2013 and
January 2014. They are a snapshot of privacy
policies of mainstream websites covering fifteen
</bodyText>
<footnote confidence="0.9999545">
1Personal communication, Joel Reidenberg.
2http://www.alexa.com
</footnote>
<page confidence="0.929875">
605
</page>
<note confidence="0.4612945">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 605–610,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<table confidence="0.9818555">
Business Computers Games Health
Home News Recreation Shopping
Arts Kids and Teens Reference Regional
Science Society Sports
</table>
<tableCaption confidence="0.912026">
Table 1: Fifteen website categories provided by Alexa.com.
We collect privacy policies from the top 100 websites in each.
</tableCaption>
<bodyText confidence="0.993963704545455">
of Alexa.com’s seventeen categories (Table 1).3
Finding a website’s policy is not trivial. Though
many well-regulated commercial websites provide
a “privacy” link on their homepages, not all do.
We found university websites to be exceptionally
unlikely to provide such a link. Even once the pol-
icy’s URL is identified, extracting the text presents
the usual challenges associated with scraping doc-
uments from the web. Since every site is differ-
ent in its placement of the document (e.g., buried
deep within the website, distributed across several
pages, or mingled together with Terms of Service)
and format (e.g., HTML, PDF, etc.), and since we
wish to preserve as much document structure as
possible (e.g., section labels), full automation was
not a viable solution.
We therefore crowdsourced the privacy policy
document collection using Amazon Mechanical
Turk. For each website, we created a HIT in
which a worker was asked to copy and paste the
following privacy policy-related information into
text boxes: (i) privacy policy URL; (ii) last up-
dated date (or effective date) of the current privacy
policy; (iii) privacy policy full text; and (iv) the
section subtitles in the top-most layer of the pri-
vacy policy. To identify the privacy policy URL,
workers were encouraged to go to the website and
search for the privacy link. Alternatively, they
could form a search query using the website name
and “privacy policy” (e.g., “Amazon.com privacy
policy”) and search in the returned results for the
most appropriate privacy policy URL. Given the
privacy policy full text and the section subtitles,
we partition the full privacy document into differ-
ent sections, delimited by the section subtitles. A
privacy policy is then converted into XML.
Each HIT was completed by three workers, paid
$0.05, for a total cost of $380 (including Ama-
zon’s surcharge).
3The “Adult” category was excluded; the “World” cate-
gory was excluded since it contains mainly popular websites
in different languages, and we opted to focus on policies in
English in this first stage of research, though mulitlingual pol-
icy analysis presents interesting challenges for future work.
</bodyText>
<sectionHeader confidence="0.99383" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999985258064516">
Given the corpus of privacy policies described in
§2, we designed a model to efficiently infer an
alignment of policy sections. While we expect that
different kinds of websites will likely address dif-
ferent privacy issues, we believe that many poli-
cies will discuss roughly the same set of issues.
Aligning the policies is a first step in a larger effort
to (i) automatically analyze policies to make them
less opaque to users and (ii) support legal experts
who wish to characterize the state of privacy on-
line and make recommendations (Costante et al.,
2012; Ammar et al., 2012; Costante et al., 2013).
We are inspired by multiple sequence alignment
methods in computational biology (Durbin et al.,
1998) and by Barzilay and Lee (2004), who de-
scribed a hidden Markov model (HMM) for doc-
ument content where each state corresponds to a
distinct topic and generates sentences relevant to
that topic according to a language model. We
estimate an HMM-like model on our corpus, ex-
ploiting similarity across privacy policies to the
extent it is evident in the data. In our formula-
tion, each hidden state corresponds to an issue or
topic, characterized by a distribution over words
and bigrams appearing in privacy policy sections
addressing that issue. The transition distribution
captures tendencies of privacy policy authors to
organize these sections in similar orders, though
with some variation.
The generative story for our model is as follows.
Let S denote the set of hidden states.
</bodyText>
<listItem confidence="0.924531">
1. Choose a start state yi from S according to the
start-state distribution.
2. For t = 1, 2, ..., until yt is the stopping state:
(a) Sample the tth section of the document by
</listItem>
<bodyText confidence="0.983331769230769">
drawing a bag of terms, ot, according to the
emission multinomial distribution for state yt.
Note the difference from traditional HMMs, in
which a single observation symbol is drawn
at each time step. ot is generated by repeat-
edly sampling from a distribution over terms
that includes all unigrams and bigrams except
those that occur in fewer than 5% of the doc-
uments and in more than 98% of the docu-
ments. This filtering rule was designed to
eliminate uninformative stopwords as well as
company-specific terms (e.g., the name of the
company).4
</bodyText>
<footnote confidence="0.913052">
4The emission distributions are not a proper language
</footnote>
<page confidence="0.992944">
606
</page>
<table confidence="0.999870777777778">
Category Websites with Unique privacy Unique privacy Ave. sections Ave. tokens
privacy URL policies policies w/ date per policy per policy
Arts 94 80 72 11.1 (f 3.8) 2894 (f 1815)
Business 100 95 75 10.1 (f 4.9) 2531 (f 1562)
Computers 100 78 62 10.7 (f 4.9) 2535 (f 1763)
Games 92 80 51 10.2 (f 4.9) 2662 (f 2267)
Health 92 86 57 10.0 (f 4.4) 2325 (f 1891)
Home 100 84 68 11.5 (f 3.8) 2493 (f 1405)
Kids and Teens 96 86 62 10.3 (f 4.5) 2683 (f 1979)
News 96 91 68 10.7 (f 3.9) 2588 (f 2493)
Recreation 98 97 67 11.9 (f 4.5) 2678 (f 1421)
Reference 84 86 55 9.9 (f 4.1) 2002 (f 1454)
Regional 98 91 72 11.2 (f 4.2) 2557 (f 1359)
Science 71 75 49 9.2 (f 4.1) 1705 (f 1136)
Shopping 100 99 84 12.0 (f 4.1) 2683 (f 1154)
Society 96 94 65 10.2 (f 4.6) 2505 (f 1587)
Sports 96 62 38 10.9 (f 4.0) 2222 (f 1241)
Average 94.2 85.6 63.0 10.7 (f 4.3) 2471 (f 1635)
</table>
<tableCaption confidence="0.9151162">
Table 2: Statistics of each website category, including (i) the number of websites with an identified privacy policy link; (ii)
number of unique privacy policies in each category (note that in rare cases, multiple unique privacy policies were identified
for the same website, e.g., a website that contains links to both new and old versions of its privacy policy); (iii) number of
websites with an identified privacy modification date; (iv) average number of sections per policy; (v) average number of tokens
per policy.
</tableCaption>
<bodyText confidence="0.976490727272727">
(b) Sample the next state, yt+1, according to the
transition distribution over S.
This model can nearly be understood as a hid-
den semi-Markov model (Baum and Petrie, 1966),
though we treat the section lengths as observable.
Indeed, our model does not even generate these
lengths, since doing so would force the states to
“explain” the length of each section, not just its
content. The likelihood function for the model is
shown in Figure 1.
The parameters of the model are almost iden-
tical to those of a classic HMM (start state dis-
tribution, emission distributions, and transition
distributions), except that emissions are char-
acterized by multinomial rather than a cate-
gorical distributions. These are learned us-
ing Expectation-Maximization, with a forward-
backward algorithm to calculate marginals (E-
step) and smoothed maximum likelihood estima-
tion for the M-step (Rabiner, 1989). After learn-
ing, the most probable assignment of a policy’s
sections to states can be recovered using a variant
of the Viterbi algorithm.
We consider three HMM variants. “Vanilla” al-
lows all transitions. The other two posit an order-
ing on the states S = {s1, s2, ... , sK}, and re-
strict the set of transitions that are possible, impos-
ing bias on the learner. “All Forward” only allows
models (e.g., a bigram may be generated by as many as three
draws from the emission distribution: once for each unigram
it contains and once for the bigram).
sk to transition to {sk, sk+1, ... , sK}. “Strict For-
ward” only allows sk to transition to sk or sk+1.
</bodyText>
<sectionHeader confidence="0.999074" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999923888888889">
Developing a gold-standard alignment of privacy
policies would either require an interface that al-
lows each annotator to interact with the entire cor-
pus of previously aligned documents while read-
ing the one she is annotating, or the definition (and
likely iterative refinement) of a set of categories
for manually labeling policy sections. These were
too costly for us to consider, so we instead pro-
pose two generic methods to evaluate models
for sequence alignment of a collection of docu-
ments with generally similar content. Though our
model (particularly the restricted variants) treats
the problem as one of alignment, our evaluations
consider groupings of policy sections. In the se-
quel, a grouping on a set X is defined as a collec-
tion of subsets Xi C X; these may overlap (i.e.,
there might be x E Xi n Xj) and need not be ex-
haustive (i.e., there might be x E X \ Ui Xi).
</bodyText>
<subsectionHeader confidence="0.99512">
4.1 Evaluation by Human QA
</subsectionHeader>
<bodyText confidence="0.9999465">
This study was carried out as part of a larger col-
laboration with legal scholars who study privacy.
In that work, we have formulated a set of nine mul-
tiple choice questions about a single policy that
ask about collection of contact, location, health,
and financial information, sharing of each with
</bodyText>
<page confidence="0.974744">
607
</page>
<figure confidence="0.855702">
Pπ,η,γ ((yt, ot)n t=1  |(ft)nt=1) = π(y1) n �`t n(ot,i  |�yi) γ(yt+1  |yt)
H i=1
t=1
</figure>
<figureCaption confidence="0.992787">
Figure 1: The likelihood function for the alignment model (one privacy policy). yt is the hidden state for the tth section, ot is
the bag of unigram and bigram terms observed in that section, and 2t is the size of the bag. Start-state, emission, and transition
distributions are denoted respectively by ir, η, and γ. yn+1 is the silent stopping state.
</figureCaption>
<bodyText confidence="0.999655324324324">
third parties, and deletion of data.5 The questions
were inspired primarily by the substantive interest
of these domain experts—not by this particular al-
gorithmic study.
For thirty policies, we obtained answers from
each of six domain experts who were not involved
in designing the questions. For the purposes of this
study, the experts’ answers are not important. In
addition to answering each question for each pol-
icy, we also asked each expert to copy and paste
the text of the policy that contains the answer.
Experts were allowed to select as many sections
for each question as they saw fit, since answering
some questions may require synthesizing informa-
tion from different sections.
For each of the nine questions, we take the
union of all policy sections that contain text se-
lected by any annotator as support for her answer.
This results in nine groups of policy sections,
which we call answer-sets denoted A1, ... , A9.
Our method allows these to overlap (63% of the
sections in any Ai occurred in more than one Ai),
and they are not exhaustive (since many sections
of the policies were not deemed to contain answers
to any of the nine questions by any expert).
Together, these can be used as a gold standard
grouping of policy sections, against which we can
compare our system’s output. To do this, we define
the set of section pairs that are grouped together
in answer sets, G = |{(a, b)  |]Ai D a, b}|, and
a similar set of pairs H from a model’s grouping.
From these sets, we calculate estimates of preci-
sion (|G n H|/|H|) and recall (|G n H|/|G|).
One shortcoming of this approach, for which
the second evaluation seeks to compensate, is that
a very small, and likely biased, subset of the policy
sections is considered.
</bodyText>
<subsectionHeader confidence="0.988176">
4.2 Evaluation by Direct Judgment
</subsectionHeader>
<bodyText confidence="0.999903333333333">
We created a separate gold standard of judgments
of pairs of privacy policy sections. The data se-
lected for judgment was a sample of pairs stratified
</bodyText>
<footnote confidence="0.8795115">
5The questions are available in an online appendix at
http://usableprivacy.org/data.
</footnote>
<bodyText confidence="0.999793642857143">
by a simple measure of text similarity. We derived
unigram tfidf vectors for each section in each of
50 randomly sampled policies per category. We
then binned pairs of sections by cosine similarity
(into four bins bounded by 0.25, 0.5, and 0.75).
We sampled 994 section pairs uniformly across the
15 categories’ four bins each.
Crowdsourcing was used to determine, for each
pair, whether the two sections should be grouped
together. A HIT consisted of a pair of policy sec-
tions and a multiple choice question, “After read-
ing the two sections given below, would you say
that they broadly discuss the same topic?” The
possible answers were:
</bodyText>
<listItem confidence="0.992028428571429">
1. Yes, both the sections essentially convey the
same message in a privacy policy.
2. Although, the sections do not convey the same
message, the broadly discuss the same topic.
(For ease of understanding, some examples of
content on “the same topic” were included.)
3. No, the sections discuss two different topics.
</listItem>
<bodyText confidence="0.9998996">
The first two options were considered a “yes” for
the majority voting and for defining a gold stan-
dard. Every section-pair was annotated by at least
three annotators (as many as 15, increased until
an absolute majority was reached). Turkers with
an acceptance rate greater than 95% with an ex-
perience of at least 100 HITs were allowed and
paid $0.03 per annotation. The total cost includ-
ing some initial trials was $130. 535 out of the
994 pairs were annotated to be similar in topic. An
example is shown in Figure 2.
As in §4.1, we calculate precision and recall on
pairs. This does not penalize the model for group-
ing together a “no” pair; we chose it nonetheless
because it is interpretable.
</bodyText>
<sectionHeader confidence="0.997057" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<bodyText confidence="0.999750666666667">
In this section, we evaluate the three HMM vari-
ants described in §3, and two baselines, using the
methods in §4. All of the methods require the
specification of the number of groups or hidden
states, which we fix to ten, the average number of
sections per policy.
</bodyText>
<page confidence="0.995854">
608
</page>
<bodyText confidence="0.853051714285714">
Section 5 of classmates.com:
[46 words] ... You may also be required to use a password to access certain pages on the Services where certain
types of your personal information can be changed or deleted. ... [113 words]
Section 2 of 192.com:
[50 words] ... This Policy sets out the means by which You can have Your Personal Information removed from
the Service. 192.com is also committed to keeping Personal Information of users of the Service secure and only to
use it for the purposes set out in this Policy and as agreed by You.... [24 words]
</bodyText>
<figureCaption confidence="0.959320333333333">
Figure 2: Selections from sections that discuss the issue of “deletion of personal information” and were labeled as discussing
the same issue by crowdworkers. Both naive grouping and LDA put them in two different groups, but the Strict Forward variant
of our model correctly groups them together.
</figureCaption>
<table confidence="0.999979">
Precision Recall Fl
Mean S.D. Mean S.D. Mean S.D.
Clust. 0.63 – 0.30 – 0.40 –
LDA 0.56 0.03 0.20 0.05 0.29 0.06
Vanilla 0.62 0.04 0.41 0.04 0.49 0.03
All F. 0.63 0.03 0.47 0.12 0.53 0.06
Strict F. 0.62 0.05 0.46 0.18 0.51 0.07
Clust. 0.62 – 0.23 – 0.34 –
LDA 0.57 0.03 0.18 0.01 0.28 0.02
Vanilla 0.57 0.01 0.30 0.03 0.39 0.02
All F. 0.58 0.02 0.32 0.06 0.41 0.04
Strict F. 0.58 0.03 0.32 0.14 0.40 0.08
</table>
<tableCaption confidence="0.82553475">
Table 3: Evaluation by human QA (above) and direct judg-
ment (below), aggregated across ten independent runs where
appropriate (see text). Vanilla, All F(orward), and Strict
F(orward) are three variants of our HMM.
</tableCaption>
<bodyText confidence="0.999908916666666">
Baselines. Our first baseline is a greedy divisive
clustering algorithm6 to partition the policy sec-
tions into ten clusters. In this method, the de-
sired K-way clustering solution is computed by
performing a sequence of bisections. The imple-
mentation uses unigram features and cosine simi-
larity. Our second baseline is latent Dirichlet allo-
cation (LDA; Blei et al., 2003), with ten topics and
online variational Bayes for inference (Hoffman et
al., 2010).7 To more closely match our models,
LDA is given access to the same unigram and bi-
gram tokens.
Results. Table 3 shows the results. For LDA
and the HMM variants (which use random initial-
ization), we report mean and standard deviation
across ten independent runs. All three variants
of the HMM improve over the baselines on both
tasks, in terms of F1. In the human QA evalu-
ation, this is mostly due to recall improvements
(i.e., more pairs of sections relevant to the same
policy question were grouped together).
The three variants of the model performed sim-
ilarly on average, though Strict Forward had very
high variance. Its maximum performance across
</bodyText>
<footnote confidence="0.985700666666667">
6As implemented in CLUTO, http://glaros.dtc.
umn.edu/gkhome/cluto/cluto/overview
7As implemented in gensim (ˇReh˚uˇrek and Sojka, 2010).
</footnote>
<bodyText confidence="0.997283">
ten runs was very high (67% and 53% F1 on the
two tasks), suggesting the potential benefits of
good initialization or model selection.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99998925">
We considered the task of aligning sections of
a collection of roughly similarly-structured legal
documents, based on the issues they address. We
introduced an unsupervised model for this task
along with two new (and reusable) evaluations.
Our experiments show the approach to be more ef-
fective than clustering and topic models. The cor-
pus and evaluation data have been made available
athttp://usableprivacy.org/data.In
future work, policy section alignments will be
used in automated analysis to extract useful infor-
mation for users and privacy scholars.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998726">
The authors gratefully acknowledge helpful com-
ments from Lorrie Cranor, Joel Reidenberg, Flo-
rian Schaub, and several anonymous reviewers.
This research was supported by NSF grant SaTC-
1330596.
</bodyText>
<sectionHeader confidence="0.998607" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999557266666667">
Waleed Ammar, Shomir Wilson, Norman Sadeh, and
Noah A. Smith. 2012. Automatic categorization of
privacy policies: A pilot study. Technical Report
CMU-LTI-12-019, Carnegie Mellon University.
Regina Barzilay and Lillian Lee. 2004. Catching the
drift: Probabilistic content models, with applications
to generation and summarization. In Proc. of HLT-
NAACL.
Leonard E. Baum and Ted Petrie. 1966. Statistical
inference for probabilistic functions of finite state
Markov chains. Annals of Mathematical Statistics,
37:1554–1563.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet allocation. the Journal of
machine Learning research, 3:993–1022.
</reference>
<page confidence="0.986503">
609
</page>
<reference confidence="0.999106959183673">
Carolyn A. Brodie, Clare-Marie Karat, and John Karat.
2006. An empirical study of natural language pars-
ing of privacy policy rules using the SPARCLE pol-
icy workbench. In Proc. of the Symposium on Us-
able Privacy and Security.
Elisa Costante, Yuanhao Sun, Milan Petkovi´c, and
Jerry den Hartog. 2012. A machine learning solu-
tion to assess privacy policy completeness. In Proc.
of the ACM Workshop on Privacy in the Electronic
Society.
Elisa Costante, Jerry Hartog, and Milan Petkovi.
2013. What websites know about you. In Roberto
Pietro, Javier Herranz, Ernesto Damiani, and Radu
State, editors, Data Privacy Management and Au-
tonomous Spontaneous Security, volume 7731 of
Lecture Notes in Computer Science, pages 146–159.
Springer Berlin Heidelberg.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological Sequence
Analysis: Probabilistic Models of Proteins and Nu-
cleic Acids. Cambridge University Press.
Federal Trade Commission. 2012. Protecting con-
sumer privacy in an era of rapid change: Recom-
mendations for businesses and policymakers.
Robert Gellman. 2014. Fair information prac-
tices: a basic history (v. 2.11). Available at
http://www.bobgellman.com/rg-docs/
rg-FIPShistory.pdf.
Matthew D Hoffman, David M Blei, and Francis R
Bach. 2010. Online learning for latent Dirichlet al-
location. In NIPS.
Aleecia M. McDonald and Lorrie Faith Cranor. 2008.
The cost of reading privacy policies. I/S: A Journal
of Law and Policy for the Information Society, 4(3).
Lawrence Rabiner. 1989. A tutorial on hidden Markov
models and selected applications in speech recogni-
tion. Proceedings of the IEEE, 77(2):257–286.
Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software frame-
work for topic modelling with large corpora. In
Proc. of the LREC Workshop on New Challenges for
NLP Frameworks.
Xusheng Xiao, Amit Paradkar, Suresh Thum-
malapenta, and Tao Xie. 2012. Automated ex-
traction of security policies from natural-language
software documents. In Proc. of the ACM SIGSOFT
International Symposium on the Foundations of
Software Engineering.
Sebastian Zimmeck and Steven M. Bellovin. 2013.
Machine learning for privacy policy.
</reference>
<page confidence="0.996885">
610
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.931723">
<title confidence="0.999246">Unsupervised Alignment of Privacy Policies using Hidden Markov Models</title>
<author confidence="0.999976">Rohan Ramanath Fei Liu Norman Sadeh Noah A Smith</author>
<affiliation confidence="0.9999575">School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.999497">Pittsburgh, PA 15213, USA</address>
<abstract confidence="0.9932766">To support empirical study of online privacy policies, as well as tools for users with privacy concerns, we consider the problem of aligning sections of a thousand policy documents, based on the issues they address. We apply an unsupervised HMM; in two new (and reusable) evaluations, we find the approach more effective than clustering and topic models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Waleed Ammar</author>
<author>Shomir Wilson</author>
<author>Norman Sadeh</author>
<author>Noah A Smith</author>
</authors>
<title>Automatic categorization of privacy policies: A pilot study.</title>
<date>2012</date>
<tech>Technical Report CMU-LTI-12-019,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="1811" citStr="Ammar et al., 2012" startWordPosition="286" endWordPosition="289"> offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear. Past applications of NLP have sought to parse privacy policies into machine-readable representations (Brodie et al., 2006) or extract subpolicies from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation by privacy experts (Gellman, 2014) and policymakers (Federal Trade Commission, 2012); in the financial services sector, the Gramm-Leach-Bliley Act requires these institutions to addre</context>
<context position="6851" citStr="Ammar et al., 2012" startWordPosition="1067" endWordPosition="1070"> challenges for future work. 3 Approach Given the corpus of privacy policies described in §2, we designed a model to efficiently infer an alignment of policy sections. While we expect that different kinds of websites will likely address different privacy issues, we believe that many policies will discuss roughly the same set of issues. Aligning the policies is a first step in a larger effort to (i) automatically analyze policies to make them less opaque to users and (ii) support legal experts who wish to characterize the state of privacy online and make recommendations (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013). We are inspired by multiple sequence alignment methods in computational biology (Durbin et al., 1998) and by Barzilay and Lee (2004), who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model. We estimate an HMM-like model on our corpus, exploiting similarity across privacy policies to the extent it is evident in the data. In our formulation, each hidden state corresponds to an issue or topic, characterized by a distribution over words and</context>
</contexts>
<marker>Ammar, Wilson, Sadeh, Smith, 2012</marker>
<rawString>Waleed Ammar, Shomir Wilson, Norman Sadeh, and Noah A. Smith. 2012. Automatic categorization of privacy policies: A pilot study. Technical Report CMU-LTI-12-019, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In Proc. of HLTNAACL.</booktitle>
<contexts>
<context position="7009" citStr="Barzilay and Lee (2004)" startWordPosition="1092" endWordPosition="1095">licy sections. While we expect that different kinds of websites will likely address different privacy issues, we believe that many policies will discuss roughly the same set of issues. Aligning the policies is a first step in a larger effort to (i) automatically analyze policies to make them less opaque to users and (ii) support legal experts who wish to characterize the state of privacy online and make recommendations (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013). We are inspired by multiple sequence alignment methods in computational biology (Durbin et al., 1998) and by Barzilay and Lee (2004), who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model. We estimate an HMM-like model on our corpus, exploiting similarity across privacy policies to the extent it is evident in the data. In our formulation, each hidden state corresponds to an issue or topic, characterized by a distribution over words and bigrams appearing in privacy policy sections addressing that issue. The transition distribution captures tendencies of privacy policy authors to organize the</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proc. of HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard E Baum</author>
<author>Ted Petrie</author>
</authors>
<title>Statistical inference for probabilistic functions of finite state Markov chains.</title>
<date>1966</date>
<journal>Annals of Mathematical Statistics,</journal>
<pages>37--1554</pages>
<contexts>
<context position="10084" citStr="Baum and Petrie, 1966" startWordPosition="1644" endWordPosition="1647"> of websites with an identified privacy policy link; (ii) number of unique privacy policies in each category (note that in rare cases, multiple unique privacy policies were identified for the same website, e.g., a website that contains links to both new and old versions of its privacy policy); (iii) number of websites with an identified privacy modification date; (iv) average number of sections per policy; (v) average number of tokens per policy. (b) Sample the next state, yt+1, according to the transition distribution over S. This model can nearly be understood as a hidden semi-Markov model (Baum and Petrie, 1966), though we treat the section lengths as observable. Indeed, our model does not even generate these lengths, since doing so would force the states to “explain” the length of each section, not just its content. The likelihood function for the model is shown in Figure 1. The parameters of the model are almost identical to those of a classic HMM (start state distribution, emission distributions, and transition distributions), except that emissions are characterized by multinomial rather than a categorical distributions. These are learned using Expectation-Maximization, with a forwardbackward algo</context>
</contexts>
<marker>Baum, Petrie, 1966</marker>
<rawString>Leonard E. Baum and Ted Petrie. 1966. Statistical inference for probabilistic functions of finite state Markov chains. Annals of Mathematical Statistics, 37:1554–1563.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<date>2003</date>
<booktitle>Latent Dirichlet allocation. the Journal of machine Learning research,</booktitle>
<pages>3--993</pages>
<contexts>
<context position="18862" citStr="Blei et al., 2003" startWordPosition="3163" endWordPosition="3166"> F. 0.58 0.03 0.32 0.14 0.40 0.08 Table 3: Evaluation by human QA (above) and direct judgment (below), aggregated across ten independent runs where appropriate (see text). Vanilla, All F(orward), and Strict F(orward) are three variants of our HMM. Baselines. Our first baseline is a greedy divisive clustering algorithm6 to partition the policy sections into ten clusters. In this method, the desired K-way clustering solution is computed by performing a sequence of bisections. The implementation uses unigram features and cosine similarity. Our second baseline is latent Dirichlet allocation (LDA; Blei et al., 2003), with ten topics and online variational Bayes for inference (Hoffman et al., 2010).7 To more closely match our models, LDA is given access to the same unigram and bigram tokens. Results. Table 3 shows the results. For LDA and the HMM variants (which use random initialization), we report mean and standard deviation across ten independent runs. All three variants of the HMM improve over the baselines on both tasks, in terms of F1. In the human QA evaluation, this is mostly due to recall improvements (i.e., more pairs of sections relevant to the same policy question were grouped together). The t</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn A Brodie</author>
<author>Clare-Marie Karat</author>
<author>John Karat</author>
</authors>
<title>An empirical study of natural language parsing of privacy policy rules using the SPARCLE policy workbench.</title>
<date>2006</date>
<booktitle>In Proc. of the Symposium on Usable Privacy and Security.</booktitle>
<contexts>
<context position="1627" citStr="Brodie et al., 2006" startWordPosition="255" endWordPosition="258">n still not be able to answer basic questions about what these policies really say. Unsurprisingly, many people do not read them (Federal Trade Commission, 2012). Such policies therefore offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear. Past applications of NLP have sought to parse privacy policies into machine-readable representations (Brodie et al., 2006) or extract subpolicies from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation</context>
</contexts>
<marker>Brodie, Karat, Karat, 2006</marker>
<rawString>Carolyn A. Brodie, Clare-Marie Karat, and John Karat. 2006. An empirical study of natural language parsing of privacy policy rules using the SPARCLE policy workbench. In Proc. of the Symposium on Usable Privacy and Security.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisa Costante</author>
<author>Yuanhao Sun</author>
<author>Milan Petkovi´c</author>
<author>Jerry den Hartog</author>
</authors>
<title>A machine learning solution to assess privacy policy completeness.</title>
<date>2012</date>
<booktitle>In Proc. of the ACM Workshop on Privacy in the Electronic Society.</booktitle>
<marker>Costante, Sun, Petkovi´c, den Hartog, 2012</marker>
<rawString>Elisa Costante, Yuanhao Sun, Milan Petkovi´c, and Jerry den Hartog. 2012. A machine learning solution to assess privacy policy completeness. In Proc. of the ACM Workshop on Privacy in the Electronic Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisa Costante</author>
<author>Jerry Hartog</author>
<author>Milan Petkovi</author>
</authors>
<title>What websites know about you.</title>
<date>2013</date>
<booktitle>Data Privacy Management and Autonomous Spontaneous Security,</booktitle>
<volume>7731</volume>
<pages>146--159</pages>
<editor>In Roberto Pietro, Javier Herranz, Ernesto Damiani, and Radu State, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="1834" citStr="Costante et al., 2013" startWordPosition="290" endWordPosition="293">opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear. Past applications of NLP have sought to parse privacy policies into machine-readable representations (Brodie et al., 2006) or extract subpolicies from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation by privacy experts (Gellman, 2014) and policymakers (Federal Trade Commission, 2012); in the financial services sector, the Gramm-Leach-Bliley Act requires these institutions to address a specific set of is</context>
<context position="6875" citStr="Costante et al., 2013" startWordPosition="1071" endWordPosition="1074">re work. 3 Approach Given the corpus of privacy policies described in §2, we designed a model to efficiently infer an alignment of policy sections. While we expect that different kinds of websites will likely address different privacy issues, we believe that many policies will discuss roughly the same set of issues. Aligning the policies is a first step in a larger effort to (i) automatically analyze policies to make them less opaque to users and (ii) support legal experts who wish to characterize the state of privacy online and make recommendations (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013). We are inspired by multiple sequence alignment methods in computational biology (Durbin et al., 1998) and by Barzilay and Lee (2004), who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model. We estimate an HMM-like model on our corpus, exploiting similarity across privacy policies to the extent it is evident in the data. In our formulation, each hidden state corresponds to an issue or topic, characterized by a distribution over words and bigrams appearing in pr</context>
</contexts>
<marker>Costante, Hartog, Petkovi, 2013</marker>
<rawString>Elisa Costante, Jerry Hartog, and Milan Petkovi. 2013. What websites know about you. In Roberto Pietro, Javier Herranz, Ernesto Damiani, and Radu State, editors, Data Privacy Management and Autonomous Spontaneous Security, volume 7731 of Lecture Notes in Computer Science, pages 146–159. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Durbin</author>
<author>Sean R Eddy</author>
<author>Anders Krogh</author>
<author>Graeme Mitchison</author>
</authors>
<title>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3057" citStr="Durbin et al., 1998" startWordPosition="477" endWordPosition="480">. Aligning policy sections is a first step toward our aforementioned summarization and extraction goals. We present the following contributions: • A new corpus of over 1,000 privacy policies gathered from widely used websites, manually segmented into subtitled sections by crowdworkers (§2). • An unsupervised approach to aligning the policy sections based on the issues they discuss. For example, sections that discuss “user data on the company’s server” should be grouped together. The approach is inspired by the application of hidden Markov models to sequence alignment in computational biology (Durbin et al., 1998; §3). • Two reusable evaluation benchmarks for the resulting alignment of policy sections (§4). We demonstrate that our approach outperforms naive methods (§5). Our corpus and benchmarks are available at http://usableprivacy.org/data. 2 Data Collection We collected 1,010 unique privacy policy documents from the top websites ranked by Alexa.com.2 These policies were collected during a period of six weeks during December 2013 and January 2014. They are a snapshot of privacy policies of mainstream websites covering fifteen 1Personal communication, Joel Reidenberg. 2http://www.alexa.com 605 Proce</context>
<context position="6978" citStr="Durbin et al., 1998" startWordPosition="1086" endWordPosition="1089">tly infer an alignment of policy sections. While we expect that different kinds of websites will likely address different privacy issues, we believe that many policies will discuss roughly the same set of issues. Aligning the policies is a first step in a larger effort to (i) automatically analyze policies to make them less opaque to users and (ii) support legal experts who wish to characterize the state of privacy online and make recommendations (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013). We are inspired by multiple sequence alignment methods in computational biology (Durbin et al., 1998) and by Barzilay and Lee (2004), who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model. We estimate an HMM-like model on our corpus, exploiting similarity across privacy policies to the extent it is evident in the data. In our formulation, each hidden state corresponds to an issue or topic, characterized by a distribution over words and bigrams appearing in privacy policy sections addressing that issue. The transition distribution captures tendencies of privacy</context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1998</marker>
<rawString>Richard Durbin, Sean R. Eddy, Anders Krogh, and Graeme Mitchison. 1998. Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<title>Federal Trade Commission.</title>
<date>2012</date>
<marker>2012</marker>
<rawString>Federal Trade Commission. 2012. Protecting consumer privacy in an era of rapid change: Recommendations for businesses and policymakers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Gellman</author>
</authors>
<title>Fair information practices: a basic history (v.</title>
<date>2014</date>
<note>2.11). Available at http://www.bobgellman.com/rg-docs/ rg-FIPShistory.pdf.</note>
<contexts>
<context position="2262" citStr="Gellman, 2014" startWordPosition="359" endWordPosition="360">es from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation by privacy experts (Gellman, 2014) and policymakers (Federal Trade Commission, 2012); in the financial services sector, the Gramm-Leach-Bliley Act requires these institutions to address a specific set of issues. Aligning policy sections is a first step toward our aforementioned summarization and extraction goals. We present the following contributions: • A new corpus of over 1,000 privacy policies gathered from widely used websites, manually segmented into subtitled sections by crowdworkers (§2). • An unsupervised approach to aligning the policy sections based on the issues they discuss. For example, sections that discuss “use</context>
</contexts>
<marker>Gellman, 2014</marker>
<rawString>Robert Gellman. 2014. Fair information practices: a basic history (v. 2.11). Available at http://www.bobgellman.com/rg-docs/ rg-FIPShistory.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Hoffman</author>
<author>David M Blei</author>
<author>Francis R Bach</author>
</authors>
<title>Online learning for latent Dirichlet allocation.</title>
<date>2010</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="18945" citStr="Hoffman et al., 2010" startWordPosition="3176" endWordPosition="3179">rect judgment (below), aggregated across ten independent runs where appropriate (see text). Vanilla, All F(orward), and Strict F(orward) are three variants of our HMM. Baselines. Our first baseline is a greedy divisive clustering algorithm6 to partition the policy sections into ten clusters. In this method, the desired K-way clustering solution is computed by performing a sequence of bisections. The implementation uses unigram features and cosine similarity. Our second baseline is latent Dirichlet allocation (LDA; Blei et al., 2003), with ten topics and online variational Bayes for inference (Hoffman et al., 2010).7 To more closely match our models, LDA is given access to the same unigram and bigram tokens. Results. Table 3 shows the results. For LDA and the HMM variants (which use random initialization), we report mean and standard deviation across ten independent runs. All three variants of the HMM improve over the baselines on both tasks, in terms of F1. In the human QA evaluation, this is mostly due to recall improvements (i.e., more pairs of sections relevant to the same policy question were grouped together). The three variants of the model performed similarly on average, though Strict Forward ha</context>
</contexts>
<marker>Hoffman, Blei, Bach, 2010</marker>
<rawString>Matthew D Hoffman, David M Blei, and Francis R Bach. 2010. Online learning for latent Dirichlet allocation. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aleecia M McDonald</author>
<author>Lorrie Faith Cranor</author>
</authors>
<title>The cost of reading privacy policies. I/S:</title>
<date>2008</date>
<journal>A Journal of Law and Policy for the Information Society,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="800" citStr="McDonald and Cranor (2008)" startWordPosition="116" endWordPosition="119">Pittsburgh, PA 15213, USA {rrohan,feiliu,sadeh,nasmith}@cs.cmu.edu Abstract To support empirical study of online privacy policies, as well as tools for users with privacy concerns, we consider the problem of aligning sections of a thousand policy documents, based on the issues they address. We apply an unsupervised HMM; in two new (and reusable) evaluations, we find the approach more effective than clustering and topic models. 1 Introduction Privacy policy documents are verbose, often esoteric legal documents that many people encounter as clients of companies that provide services on the web. McDonald and Cranor (2008) showed that, if users were to read the privacy policies of every website they access during the course of a year, they would end up spending a substantial amount of their time doing just that and would often still not be able to answer basic questions about what these policies really say. Unsurprisingly, many people do not read them (Federal Trade Commission, 2012). Such policies therefore offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand</context>
</contexts>
<marker>McDonald, Cranor, 2008</marker>
<rawString>Aleecia M. McDonald and Lorrie Faith Cranor. 2008. The cost of reading privacy policies. I/S: A Journal of Law and Policy for the Information Society, 4(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>77--2</pages>
<contexts>
<context position="10794" citStr="Rabiner, 1989" startWordPosition="1757" endWordPosition="1758">ese lengths, since doing so would force the states to “explain” the length of each section, not just its content. The likelihood function for the model is shown in Figure 1. The parameters of the model are almost identical to those of a classic HMM (start state distribution, emission distributions, and transition distributions), except that emissions are characterized by multinomial rather than a categorical distributions. These are learned using Expectation-Maximization, with a forwardbackward algorithm to calculate marginals (Estep) and smoothed maximum likelihood estimation for the M-step (Rabiner, 1989). After learning, the most probable assignment of a policy’s sections to states can be recovered using a variant of the Viterbi algorithm. We consider three HMM variants. “Vanilla” allows all transitions. The other two posit an ordering on the states S = {s1, s2, ... , sK}, and restrict the set of transitions that are possible, imposing bias on the learner. “All Forward” only allows models (e.g., a bigram may be generated by as many as three draws from the emission distribution: once for each unigram it contains and once for the bigram). sk to transition to {sk, sk+1, ... , sK}. “Strict Forwar</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>Lawrence Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radim ˇReh˚uˇrek</author>
<author>Petr Sojka</author>
</authors>
<title>Software framework for topic modelling with large corpora.</title>
<date>2010</date>
<booktitle>In Proc. of the LREC Workshop on New Challenges for NLP Frameworks.</booktitle>
<marker>ˇReh˚uˇrek, Sojka, 2010</marker>
<rawString>Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software framework for topic modelling with large corpora. In Proc. of the LREC Workshop on New Challenges for NLP Frameworks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xusheng Xiao</author>
<author>Amit Paradkar</author>
<author>Suresh Thummalapenta</author>
<author>Tao Xie</author>
</authors>
<title>Automated extraction of security policies from natural-language software documents.</title>
<date>2012</date>
<booktitle>In Proc. of the ACM SIGSOFT International Symposium on the Foundations of Software Engineering.</booktitle>
<contexts>
<context position="1692" citStr="Xiao et al., 2012" startWordPosition="266" endWordPosition="269">cies really say. Unsurprisingly, many people do not read them (Federal Trade Commission, 2012). Such policies therefore offer an excellent opportunity for NLP tools that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear. Past applications of NLP have sought to parse privacy policies into machine-readable representations (Brodie et al., 2006) or extract subpolicies from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation by privacy experts (Gellman, 2014) and policymakers (Federal Tra</context>
</contexts>
<marker>Xiao, Paradkar, Thummalapenta, Xie, 2012</marker>
<rawString>Xusheng Xiao, Amit Paradkar, Suresh Thummalapenta, and Tao Xie. 2012. Automated extraction of security policies from natural-language software documents. In Proc. of the ACM SIGSOFT International Symposium on the Foundations of Software Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Zimmeck</author>
<author>Steven M Bellovin</author>
</authors>
<title>Machine learning for privacy policy.</title>
<date>2013</date>
<contexts>
<context position="1863" citStr="Zimmeck and Bellovin, 2013" startWordPosition="294" endWordPosition="298">ls that summarize or extract key information that (i) helps users understand the implications of agreeing to these policies and (ii) helps legal analysts understand the contents of these policies and make recommendations on how they can be improved or made more clear. Past applications of NLP have sought to parse privacy policies into machine-readable representations (Brodie et al., 2006) or extract subpolicies from larger documents (Xiao et al., 2012). Machine learning has been applied to assess certain attributes of policies (Costante et al., 2012; Ammar et al., 2012; Costante et al., 2013; Zimmeck and Bellovin, 2013). This paper instead analyzes policies in aggregate, seeking to align sections of policies. This task is motivated by an expectation that many policies will address similar issues,1 such as collection of a user’s contact, location, health, and financial information, sharing with third parties, and deletion of data. This expectation is supported by recommendation by privacy experts (Gellman, 2014) and policymakers (Federal Trade Commission, 2012); in the financial services sector, the Gramm-Leach-Bliley Act requires these institutions to address a specific set of issues. Aligning policy section</context>
</contexts>
<marker>Zimmeck, Bellovin, 2013</marker>
<rawString>Sebastian Zimmeck and Steven M. Bellovin. 2013. Machine learning for privacy policy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>