<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.148847">
<title confidence="0.993421">
Multimodal DBN for Predicting High-Quality Answers in cQA portals
</title>
<author confidence="0.999757">
Haifeng Hu, Bingquan Liu, Baoxun Wang, Ming Liu, Xiaolong Wang
</author>
<affiliation confidence="0.9983265">
School of Computer Science and Technology
Harbin Institute of Technology, China
</affiliation>
<email confidence="0.979312">
{hfhu, liubq, bxwang, mliu, wangxl}@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.993647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968692307692">
In this paper, we address the problem for
predicting cQA answer quality as a clas-
sification task. We propose a multimodal
deep belief nets based approach that op-
erates in two stages: First, the joint rep-
resentation is learned by taking both tex-
tual and non-textual features into a deep
learning network. Then, the joint repre-
sentation learned by the network is used
as input features for a linear classifier. Ex-
tensive experimental results conducted on
two cQA datasets demonstrate the effec-
tiveness of our proposed approach.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999901">
Predicting the quality of answers in communi-
ty based Question Answering (cQA) portals is a
challenging task. One straightforward approach
is to use textual features as a text classification
task (Agichtein et al., 2008). However, due to
the word over-sparsity and inherent noise of user-
generated content, the classical bag-of-words rep-
resentation, is not appropriate to estimate the qual-
ity of short texts (Huang et al., 2011). Another typ-
ical approach is to leverage non-textual features to
automatically identify high quality answers (Jeon
et al., 2006; Zhou et al., 2012). However, in this
way, the mining of meaningful textual features
usually tends to be ignored.
Intuitively, combining both textual and non-
textual information extracted from answers is
helpful to improve the performance for predict-
ing the answer quality. However, textual and non-
textual features usually have different kinds of rep-
resentations and the correlations between them are
highly non-linear. Previous study (Ngiam et al.,
2011) has shown that it is hard for a shallow model
to discover the correlations over multiple sources.
To this end, a deep learning approach, called
multimodal deep belief nets (mDBN), is intro-
duced to address the above problems to predict the
answer quality. The approach includes two stages:
feature learning and supervised training. In the
former stage, a specially designed deep network is
given to learn the unified representation using both
textual and non-textual information. In the latter
stage, the outputs of the network are then used as
inputs for a linear classifier to make prediction.
The rest of this paper is organized as follows:
The related work is surveyed in Section 2. Then,
the proposed approach and experimental results
are presented in Section 3 and Section 4 respec-
tively. Finally, conclusions and future directions
are drawn in Section 5.
</bodyText>
<sectionHeader confidence="0.999747" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999952625">
The typical way to predict the answer quality is
exploring various features and employing machine
learning methods. For example, Jeon et al. (2006)
have proposed a framework to predict the qual-
ity of answers by incorporating non-textual fea-
tures into a maximum entropy model. Subsequent-
ly, Agichtein et al. (2008) and Bian et al. (2009)
both leverage a larger range of features to find high
quality answers. The deep research on evaluating
answer quality has been taken by Shah and Pomer-
antz (2010) using the logistic regression model.
We borrow some of their ideas in this paper.
In deep learning field, extensive studies have
been done by Hinton and his co-workers (Hin-
ton et al., 2006; Hinton and Salakhutdinov, 2006;
Salakhutdinov and Hinton, 2009), who initial-
ly propose the deep belief nets (DBN). Wang
et.al (2010; 2011) firstly apply the DBNs to model
semantic relevance for qa pairs in social communi-
ties. Meanwhile, the feature learning for disparate
sources has also been the hot research topic. Lee
et al. (2009) demonstrate that the hidden represen-
tations computed by a convolutional DBN make
excellent features for visual recognition.
</bodyText>
<page confidence="0.983693">
843
</page>
<note confidence="0.5308875">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843–847,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.993989" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.99883225">
We consider the problem of high-quality answer
prediction as a classification task. Figure 1 sum-
marizes the framework of our proposed approach.
First, textual features and non-textual features ex-
</bodyText>
<figureCaption confidence="0.999497">
Figure 1: Framework of our proposed approach.
</figureCaption>
<bodyText confidence="0.999922">
tracted from cQA portals are used to train two DB-
N models to learn the high-level representation-
s independently for answers. The two high-level
representations learned by the deep architectures
are then joined together to train a RBM model.
Finally, a linear classifier is trained with the final
shared representation as input to make prediction.
In this section, a deep network for the cQA an-
swer quality prediction is presented. Textual and
non-textual features are typically characterized by
distinct statistical properties and the correlations
between them are highly non-linear. It is very dif-
ficult for a shallow model to discover these corre-
lations and form an informative unified represen-
tation. Our motivation of proposing the mDBN is
to tackle these problems using an unified represen-
tation to enhance the classification performance.
</bodyText>
<subsectionHeader confidence="0.999677">
3.1 The Restricted Boltzmann Machines
</subsectionHeader>
<bodyText confidence="0.999980923076923">
The basic building block of our feature leaning
component is the Restricted Boltzmann Machine
(RBM). The classical RBM is a two-layer undi-
rected graphical model with stochastic visible u-
nits v and stochastic hidden units h.The visible
layer and the hidden layer are fully connected to
the units in the other layer by a symmetric matrix
w. The classical RBM has been used effectively in
modeling distributions over binary-value data. As
for real-value inputs, the gaussian RBM (Bengio
et al., 2007) can be employed. Different from the
former, the hypothesis for the visible unit in the
gaussian RBM is the normal distribution.
</bodyText>
<subsectionHeader confidence="0.999416">
3.2 Feature Learning
</subsectionHeader>
<bodyText confidence="0.999924888888889">
The illustration of the feature learning model is
given by Figure 2. Basically, the model consists
of two parts.
In the bottom part (i.e., V -H1, H1-H2), each
data modality is modeled by a two-layer DBN sep-
arately. For clarity, we take the textual modality
as an example to illustrate the construction of the
mDBN in this part. Given a textual input vector v,
the visible layer generates the hidden vector h, by
</bodyText>
<equation confidence="0.948879666666667">
p(hj = 11v) = u(cj + Ei wijvi).
Then the conditional distribution of v given h, is
p(vi = 11h) = u(bi + Ej wijhj).
</equation>
<bodyText confidence="0.999841764705882">
where u(x) = (1 + e−x)−1 denotes the logistic
function. The parameters are updated by perform-
ing gradient ascent using Contrastive Divergence
(CD) algorithm (Hinton, 2002).
After learning the RBMs in the bottom layer,
we treat the activation probabilities of its hidden
units driven by the inputs, as the training data for
training a new layer. The construction procedures
for the non-textual modality are similar to the tex-
tual one, except that we use the gaussian RBM to
model the real-value inputs in the bottom layer.
Finally, we combine the two models by adding
an additional layer, H3, on the top of them to form
the mDBN. The training method is also similar to
the bottom’s, but the input vector is the concatena-
tion of the mapped textual vector and the mapped
non-textual vector.
</bodyText>
<figureCaption confidence="0.986239">
Figure 2: mDBN for Feature Learning
</figureCaption>
<bodyText confidence="0.999959333333333">
It should be noted in the network, the bottom
part is essential to form the joint representation
because the correlations between the textual and
non-textual features are highly non-linear. It is
hard for a RBM directly combining the two dis-
parate sources to learn their correlations.
</bodyText>
<subsectionHeader confidence="0.999903">
3.3 Supervised Training and Classification
</subsectionHeader>
<bodyText confidence="0.9998432">
After the above steps, a deep network for feature
learning between textual and non-textual data is
established. Classifiers, either support vector ma-
chine (SVM) or logistic regression (LR), can then
be trained with the unified representation (Ngiam
</bodyText>
<figure confidence="0.978376916666667">
Feature
Supervised Training
Learning Fusion Representation
Classifier
High-quality
Answers
CQA
Archives
Textual
Features
Non-textual
Features
</figure>
<page confidence="0.994181">
844
</page>
<bodyText confidence="0.999975">
et al., 2011; Srivastava and Salakhutdinov, 2012).
Specifically, the LR classifier is used to make the
final prediction in our experiments since it keeps
to deliver the best performance.
</bodyText>
<subsectionHeader confidence="0.987218">
3.4 Basic Features
</subsectionHeader>
<bodyText confidence="0.999614769230769">
Textual Features: The textual features ex-
tract from 1,500 most frequent words in the train-
ing dataset after standard preprocessing steps,
namely word segmentation, stopwords removal
and stemming1. As a result, each answer is repre-
sented as a vector containing 1,500 distinct terms
weighted by binary scheme.
Non-textual Features: Referring to
the previous work (Jeon et al., 2006; Shah and
Pomerantz, 2010), we adopt some features used
in theirs and also explore three additional features
marked by ‡ sign. The complete list is described
in Table 1.
</bodyText>
<table confidence="0.999658571428571">
Features Type
Length of question title (description) Integer
Length of answer Integer
Number of unique words for the answer $ Integer
Ratio of the qa length $ Float
Answer’s relative position $ Integer
Number of answers for the question Integer
Number of comments for the question Integer
Number of questions asked by asker (answerer) Integer
Number of questions resolved by asker (answerer) Integer
Asker’s (Answerer’s) total points Integer
Asker’s (Answerer’s) level Integer
Asker’s (Answerer’s) total stars Integer
Asker’s (Answerer’s) best answer ratio Float
</table>
<tableCaption confidence="0.999437">
Table 1: Summary of non-textual features.
</tableCaption>
<sectionHeader confidence="0.999294" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997204">
4.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999288384615385">
Datasets: We carry out experiments on two
datasets. One dataset comes from Baidu Zhi-
dao2, which contains 33,740 resolved questions
crawled by us from the “travel” category. The oth-
er dataset is built by Chen and Nayak (2008) from
Yahoo! Answers3. We refer to these two dataset-
s as ZHIDAO and YAHOO respectively and ran-
domly sample 10,000 questions from each to form
our experimental datasets. According to the us-
er name, we have crawled all the user profile web
pages for non-textual feature collection. To allevi-
ate unnecessary noise, we only select those ques-
tions with number of answers no less than 3 (one
</bodyText>
<footnote confidence="0.999663666666667">
1The stemming step is only used in English corpus.
2http://zhidao.baidu.com
3http://answers.yahoo.com
</footnote>
<bodyText confidence="0.946522666666667">
best answer among them), and those answers at
least have 10 tokens. The statistics on the datasets
used for experiments are summarized in Table 2.
</bodyText>
<table confidence="0.9995564">
Statistics Items YAHOO ZHIDAO
# of questions 6841 5368
# of answers 74485 22435
# of answers per question 10.9 4.1
# of users 28812 12734
</table>
<tableCaption confidence="0.999671">
Table 2: Statistics on experimental datasets.
</tableCaption>
<bodyText confidence="0.995747029411765">
Baselines and Evaluation Metrics: We com-
pare against the following methods as our base-
lines. (1) Logistic Regression (LR): We imple-
ment the approach used by Shah and Pomer-
antz (2010) with textual features LR-T, non-
textual features LR-N and their simple combina-
tion LR-C. (2) DBN: Similar to the mDBN, the
outputs of the last hidden layer by the DBN are
used as inputs for LR model. Based on the fea-
ture sets, we have DBN-T for textual features and
DBN-N for non-textual features.
Since we mainly focus on the high quality an-
swers, the precision, recall and f1 for positive class
and the overall accuracy for both classes are em-
ployed as our evaluation metrics.
Model Architecture and Training Details: To
create the mDBN architecture, we use the classi-
cal RBM with 1500 visible units followed by 2
hidden layers with 1000 and 800 units respective-
ly for the textual branch, and the gaussian RBM
with 20 visible units followed by 2 hidden layers
with 100 and 200 units respectively for the non-
textual branch. On the joint layer of the network,
the layer contains 1000 real-value units.
Each RBM is trained using 1-step CD algorith-
m. During the training stage, a small weight-cost
of 0.0002 is used, and the learning rate for textu-
al data modal is 0.05 while the non-textual data is
0.001. We also adopt a monument of 0.5 for the
first five epochs and 0.9 for the rest epochs. In
addition, all non-textual data vectors are normal-
ized to have zero mean and unit standard variance.
More details for training the deep architecture can
be found in Hinton (2012).
</bodyText>
<subsectionHeader confidence="0.730349">
4.2 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.9999308">
In the first experiment, we compare the perfor-
mance of mDBN with different methods. To make
a fare comparison, we use the liblinear toolkit4 for
logistic regression model with L2 regularization
and randomly select 70% QA pairs as training data
</bodyText>
<footnote confidence="0.99911">
4available at http://www.csie.ntu.edu.tw/ cjlin/liblinear
</footnote>
<page confidence="0.998714">
845
</page>
<bodyText confidence="0.999086333333333">
and the rest 30% as testing data. Table 3 and Ta-
ble 4 summarize the average results of the 5 round
experiments on YAHOO and ZHIDAO respectively.
</bodyText>
<table confidence="0.999819857142857">
Methods P R F1 Accu.
LR-T 0.374 0.558 0.448 0.542
LR-N 0.524 0.614 0.566 0.686
LR-C 0.493 0.557 0.523 0.662
DBN-T 0.496 0.571 0.531 0.663
DBN-N 0.505 0.578 0.539 0.670
mDBN 0.534 0.631 0.579 0.694
</table>
<tableCaption confidence="0.999923">
Table 3: Comparing results on YAHOO
</tableCaption>
<bodyText confidence="0.999868833333333">
It is promising to see that the proposed mDBN
method notably outperforms almost all the other
methods on both datasets over all the metrics as
expected, except for the recall on ZHIDAO. The
main reason for the improvements is that the joint
representation learned by mDBN is able to com-
plement each modality perfectly. In addition, the
mDBN can extract stronger representation through
modeling semantic relationship between textual
and non-textual information, which can effectively
help distinguish more complicated answers from
high quality to low quality.
</bodyText>
<table confidence="0.999851857142857">
Methods P R F1 Accu.
LR-T 0.380 0.540 0.446 0.553
LR-N 0.523 0.735 0.611 0.688
LR-C 0.537 0.695 0.606 0.698
DBN-T 0.527 0.730 0.612 0.692
DBN-N 0.539 0.760 0.631 0.703
mDBN 0.590 0.755 0.662 0.743
</table>
<tableCaption confidence="0.999828">
Table 4: Comparing results on ZHIDAO
</tableCaption>
<bodyText confidence="0.999981297297298">
The classification performance of the textu-
al features are worse on average compared with
non-textual features, even when the feature learn-
ing strategy is employed. More interestingly, we
find the simple combinations of textual and non-
textual features don’t improve the classification
results compared with using non-textual features
alone.We conjecture that there are mainly three
reasons for the phenomena: First, this is due to the
fact that user-generated content is inherently noisy
with low word frequency, resulting in the sparsity
of employing textual feature. Second, non-textual
features (e.g., answer length) usually own strongly
statistical properties and feature sparsity problem
can be better relieved to some extent. Finally, s-
ince correlations between the textual features and
non-textual features are highly non-linear, con-
catenating these features simply sometimes can
submerge classification performance. In contrast,
mDBN enjoys the advantage of the shared repre-
sentation between textual features and non-textual
features using the deep learning architecture.
We also note that neither the mDBN nor other
approaches perform very well in predicting answer
quality across the two datasets. The best precision
on ZHIDAO and YAHOO are respectively 59.0%
and 53.4%, which means that there are nearly half
of the high quality answers not effectively identi-
fied. One of the possible reason is that the quali-
ty of the corpora influences the result significant-
ly. As shown in Table 2, each question on aver-
age receives more than 4 answers on ZHIDAO and
more than 10 on YAHOO. Therefore, it is possi-
ble that there are several answers with high quali-
ty to the same question. Selecting only one as the
high quality answer is relatively difficult for our
humans, not to mention for the models.
</bodyText>
<figureCaption confidence="0.996679">
Figure 3: Influences of iterations for mDBN
</figureCaption>
<bodyText confidence="0.9999868">
In the second experiment, we intend to exam-
ine the performance of mDBN with different num-
ber of iterations. Figure 3 depicts the metrics on
ZHIDAO when the iteration number is varied from
100 to 5000. From the result, the first observa-
tion is that increasing the number of iterations the
performance of mDBN can improve significant-
ly, obtaining the best results for iteration of 1000.
This clearly shows the representation power of the
mDBN again. However, after a large number of it-
erations (large than 1000), the mDBN has a detri-
mental performance. This may be explained by
with large number of iterations, the deep learning
architecture is easier to be overfitting. The similar
trend is also observed on YAHOO.
</bodyText>
<sectionHeader confidence="0.998745" genericHeader="conclusions">
5 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.999751833333333">
In this paper, we have provided a new perspec-
tive to predict the cQA answer quality: learning
an informative unified representation between tex-
tual and non-textual features instead of concate-
nating them simply. Specifically, we have pro-
posed a multimodal deep learning framework to
</bodyText>
<figure confidence="0.9934803">
0.80
Precision Recall F1 Accuracy
100 500 1000 2000 5000
# iterations
0.75
0.70
0.65
0.60
0.55
0.50
</figure>
<page confidence="0.995981">
846
</page>
<bodyText confidence="0.999928083333333">
form the unified representation. We compare this
with the basic features both in isolation and in
combination. Experimental results have demon-
strated that our proposed approach can capture the
complementarity between textual and non-textual
features, which is helpful to improve the perfor-
mance for cQA answer quality prediction.
For the future work, we plan to explore more se-
mantic analysis to approach the issue for short tex-
t quality evaluation. Additionally, more research
will be taken to put forward other approaches for
learning multimodal representation.
</bodyText>
<sectionHeader confidence="0.997384" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997865">
The authors are grateful to the anonymous re-
viewers for their constructive comments. Spe-
cial thanks to Chengjie Sun and Deyuan Zhang
for insightful suggestions. This work is supported
by National Natural Science Foundation of China
(NSFC) via grant 61272383 and 61100094.
</bodyText>
<sectionHeader confidence="0.998162" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99920382051282">
E. Agichtein, C. Castillo, D. Donato, A. Gionis, and
G. Mishne. 2008. Finding high-quality content in
social media. In Proceedings of the internation-
al conference on Web search and web data mining,
pages 183–194. ACM.
Yoshua Bengio, Pascal Lamblin, Dan Popovici, and
Hugo Larochelle. 2007. Greedy layer-wise training
of deep networks. In Advances in Neural Informa-
tion Processing Systems, pages 153–160.
Jiang Bian, Yandong Liu, Ding Zhou, Eugene
Agichtein, and Hongyuan Zha. 2009. Learning to
recognize reliable users and content in social media
with coupled mutual reinforcement. In Proceedings
of the 18th international conference on World wide
web, pages 51–60. ACM.
L. Chen and R. Nayak. 2008. Expertise analysis in a
question answer portal for author ranking. In Inter-
national Conference on Web Intelligence and Intel-
ligent Agent Technology, volume 1, pages 134–140.
G.E. Hinton and R.R. Salakhutdinov. 2006. Reduc-
ing the dimensionality of data with neural networks.
Science, 313(5786):504–507.
G.E. Hinton, S. Osindero, and Y.W. Teh. 2006. A fast
learning algorithm for deep belief nets. Neural com-
putation, 18(7):1527–1554.
G.E. Hinton. 2002. Training products of experts by
minimizing contrastive divergence. Neural compu-
tation, 14(8):1771–1800.
G.E. Hinton. 2012. A practical guide to training re-
stricted boltzmann machines. Lecture Notes in Com-
puter Science, pages 599–619.
Minlie Huang, Yi Yang, and Xiaoyan Zhu. 2011.
Quality-biased ranking of short texts in microblog-
ging services. In Proceedings of the 5th Internation-
al Joint Conference on Natural Language Process-
ing, pages 373–382.
J. Jeon, W.B. Croft, J.H. Lee, and S. Park. 2006. A
framework to predict the quality of answers with
non-textual features. In Proceedings of the 29th an-
nual international ACM SIGIR conference on Re-
search and development in information retrieval,
pages 228–235. ACM.
H. Lee, R. Grosse, R. Ranganath, and A.Y. Ng. 2009.
Convolutional deep belief networks for scalable un-
supervised learning of hierarchical representation-
s. In Proceedings of the 26th Annual International
Conference on Machine Learning, pages 609–616.
J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A.Y.
Ng. 2011. Multimodal deep learning. In Proceed-
ings of the 28th International Conference on Ma-
chine Learning (ICML), pages 689–696.
R. Salakhutdinov and G.E. Hinton. 2009. Deep boltz-
mann machines. In Proceedings of the internation-
al conference on artificial intelligence and statistics,
volume 5, pages 448–455.
C. Shah and J. Pomerantz. 2010. Evaluating and pre-
dicting answer quality in community qa. In Pro-
ceeding of the 33rd international ACM SIGIR con-
ference on Research and development in information
retrieval, pages 411–418.
N. Srivastava and R. Salakhutdinov. 2012. Multi-
modal learning with deep boltzmann machines. In
Advances in Neural Information Processing System-
s, pages 2231–2239.
B. Wang, X. Wang, C. Sun, B. Liu, and L. Sun. 2010.
Modeling semantic relevance for question-answer
pairs in web social communities. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1230–1238. ACL.
B. Wang, B. Liu, X. Wang, C. Sun, and D. Zhang.
2011. Deep learning approaches to semantic rele-
vance modeling for chinese question-answer pairs.
ACM Transactions on Asian Language Information
Processing, 10(4):21:1–21:16.
Z.M. Zhou, M. Lan, Z.Y. Niu, and Y. Lu. 2012. Ex-
ploiting user profile information for answer ranking
in cqa. In Proceedings of the 21st international con-
ference on World Wide Web, pages 767–774. ACM.
</reference>
<page confidence="0.998215">
847
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.859292">
<title confidence="0.998608">Multimodal DBN for Predicting High-Quality Answers in cQA portals</title>
<author confidence="0.996217">Haifeng Hu</author>
<author confidence="0.996217">Bingquan Liu</author>
<author confidence="0.996217">Baoxun Wang</author>
<author confidence="0.996217">Ming Liu</author>
<author confidence="0.996217">Xiaolong</author>
<affiliation confidence="0.999943">School of Computer Science and Harbin Institute of Technology,</affiliation>
<email confidence="0.901649">liubq,bxwang,mliu,</email>
<abstract confidence="0.996961571428571">In this paper, we address the problem for predicting cQA answer quality as a classification task. We propose a multimodal deep belief nets based approach that operates in two stages: First, the joint representation is learned by taking both textual and non-textual features into a deep learning network. Then, the joint representation learned by the network is used as input features for a linear classifier. Extensive experimental results conducted on two cQA datasets demonstrate the effectiveness of our proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>C Castillo</author>
<author>D Donato</author>
<author>A Gionis</author>
<author>G Mishne</author>
</authors>
<title>Finding high-quality content in social media.</title>
<date>2008</date>
<booktitle>In Proceedings of the international conference on Web</booktitle>
<pages>183--194</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1031" citStr="Agichtein et al., 2008" startWordPosition="155" endWordPosition="158">s based approach that operates in two stages: First, the joint representation is learned by taking both textual and non-textual features into a deep learning network. Then, the joint representation learned by the network is used as input features for a linear classifier. Extensive experimental results conducted on two cQA datasets demonstrate the effectiveness of our proposed approach. 1 Introduction Predicting the quality of answers in community based Question Answering (cQA) portals is a challenging task. One straightforward approach is to use textual features as a text classification task (Agichtein et al., 2008). However, due to the word over-sparsity and inherent noise of usergenerated content, the classical bag-of-words representation, is not appropriate to estimate the quality of short texts (Huang et al., 2011). Another typical approach is to leverage non-textual features to automatically identify high quality answers (Jeon et al., 2006; Zhou et al., 2012). However, in this way, the mining of meaningful textual features usually tends to be ignored. Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer </context>
<context position="3011" citStr="Agichtein et al. (2008)" startWordPosition="469" endWordPosition="472">assifier to make prediction. The rest of this paper is organized as follows: The related work is surveyed in Section 2. Then, the proposed approach and experimental results are presented in Section 3 and Section 4 respectively. Finally, conclusions and future directions are drawn in Section 5. 2 Related Work The typical way to predict the answer quality is exploring various features and employing machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities</context>
</contexts>
<marker>Agichtein, Castillo, Donato, Gionis, Mishne, 2008</marker>
<rawString>E. Agichtein, C. Castillo, D. Donato, A. Gionis, and G. Mishne. 2008. Finding high-quality content in social media. In Proceedings of the international conference on Web search and web data mining, pages 183–194. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Pascal Lamblin</author>
<author>Dan Popovici</author>
<author>Hugo Larochelle</author>
</authors>
<title>Greedy layer-wise training of deep networks.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>153--160</pages>
<contexts>
<context position="5669" citStr="Bengio et al., 2007" startWordPosition="886" endWordPosition="889"> problems using an unified representation to enhance the classification performance. 3.1 The Restricted Boltzmann Machines The basic building block of our feature leaning component is the Restricted Boltzmann Machine (RBM). The classical RBM is a two-layer undirected graphical model with stochastic visible units v and stochastic hidden units h.The visible layer and the hidden layer are fully connected to the units in the other layer by a symmetric matrix w. The classical RBM has been used effectively in modeling distributions over binary-value data. As for real-value inputs, the gaussian RBM (Bengio et al., 2007) can be employed. Different from the former, the hypothesis for the visible unit in the gaussian RBM is the normal distribution. 3.2 Feature Learning The illustration of the feature learning model is given by Figure 2. Basically, the model consists of two parts. In the bottom part (i.e., V -H1, H1-H2), each data modality is modeled by a two-layer DBN separately. For clarity, we take the textual modality as an example to illustrate the construction of the mDBN in this part. Given a textual input vector v, the visible layer generates the hidden vector h, by p(hj = 11v) = u(cj + Ei wijvi). Then t</context>
</contexts>
<marker>Bengio, Lamblin, Popovici, Larochelle, 2007</marker>
<rawString>Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. 2007. Greedy layer-wise training of deep networks. In Advances in Neural Information Processing Systems, pages 153–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Bian</author>
<author>Yandong Liu</author>
<author>Ding Zhou</author>
<author>Eugene Agichtein</author>
<author>Hongyuan Zha</author>
</authors>
<title>Learning to recognize reliable users and content in social media with coupled mutual reinforcement.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th international conference on World wide web,</booktitle>
<pages>51--60</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3034" citStr="Bian et al. (2009)" startWordPosition="474" endWordPosition="477"> The rest of this paper is organized as follows: The related work is surveyed in Section 2. Then, the proposed approach and experimental results are presented in Section 3 and Section 4 respectively. Finally, conclusions and future directions are drawn in Section 5. 2 Related Work The typical way to predict the answer quality is exploring various features and employing machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the featur</context>
</contexts>
<marker>Bian, Liu, Zhou, Agichtein, Zha, 2009</marker>
<rawString>Jiang Bian, Yandong Liu, Ding Zhou, Eugene Agichtein, and Hongyuan Zha. 2009. Learning to recognize reliable users and content in social media with coupled mutual reinforcement. In Proceedings of the 18th international conference on World wide web, pages 51–60. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Chen</author>
<author>R Nayak</author>
</authors>
<title>Expertise analysis in a question answer portal for author ranking.</title>
<date>2008</date>
<booktitle>In International Conference on Web Intelligence and Intelligent Agent Technology,</booktitle>
<volume>1</volume>
<pages>134--140</pages>
<contexts>
<context position="9513" citStr="Chen and Nayak (2008)" startWordPosition="1503" endWordPosition="1506">r Number of comments for the question Integer Number of questions asked by asker (answerer) Integer Number of questions resolved by asker (answerer) Integer Asker’s (Answerer’s) total points Integer Asker’s (Answerer’s) level Integer Asker’s (Answerer’s) total stars Integer Asker’s (Answerer’s) best answer ratio Float Table 1: Summary of non-textual features. 4 Experiments 4.1 Experiment Setup Datasets: We carry out experiments on two datasets. One dataset comes from Baidu Zhidao2, which contains 33,740 resolved questions crawled by us from the “travel” category. The other dataset is built by Chen and Nayak (2008) from Yahoo! Answers3. We refer to these two datasets as ZHIDAO and YAHOO respectively and randomly sample 10,000 questions from each to form our experimental datasets. According to the user name, we have crawled all the user profile web pages for non-textual feature collection. To alleviate unnecessary noise, we only select those questions with number of answers no less than 3 (one 1The stemming step is only used in English corpus. 2http://zhidao.baidu.com 3http://answers.yahoo.com best answer among them), and those answers at least have 10 tokens. The statistics on the datasets used for expe</context>
</contexts>
<marker>Chen, Nayak, 2008</marker>
<rawString>L. Chen and R. Nayak. 2008. Expertise analysis in a question answer portal for author ranking. In International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 134–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Hinton</author>
<author>R R Salakhutdinov</author>
</authors>
<title>Reducing the dimensionality of data with neural networks.</title>
<date>2006</date>
<journal>Science,</journal>
<volume>313</volume>
<issue>5786</issue>
<contexts>
<context position="3417" citStr="Hinton and Salakhutdinov, 2006" startWordPosition="539" endWordPosition="542"> machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the feature learning for disparate sources has also been the hot research topic. Lee et al. (2009) demonstrate that the hidden representations computed by a convolutional DBN make excellent features for visual recognition. 843 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843–847, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Compu</context>
</contexts>
<marker>Hinton, Salakhutdinov, 2006</marker>
<rawString>G.E. Hinton and R.R. Salakhutdinov. 2006. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Hinton</author>
<author>S Osindero</author>
<author>Y W Teh</author>
</authors>
<title>A fast learning algorithm for deep belief nets.</title>
<date>2006</date>
<booktitle>Neural computation,</booktitle>
<pages>18--7</pages>
<contexts>
<context position="3385" citStr="Hinton et al., 2006" startWordPosition="534" endWordPosition="538">eatures and employing machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the feature learning for disparate sources has also been the hot research topic. Lee et al. (2009) demonstrate that the hidden representations computed by a convolutional DBN make excellent features for visual recognition. 843 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843–847, Sofia, Bulgaria, August 4-9 20</context>
</contexts>
<marker>Hinton, Osindero, Teh, 2006</marker>
<rawString>G.E. Hinton, S. Osindero, and Y.W. Teh. 2006. A fast learning algorithm for deep belief nets. Neural computation, 18(7):1527–1554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Hinton</author>
</authors>
<title>Training products of experts by minimizing contrastive divergence.</title>
<date>2002</date>
<booktitle>Neural computation,</booktitle>
<pages>14--8</pages>
<contexts>
<context position="6517" citStr="Hinton, 2002" startWordPosition="1036" endWordPosition="1037">odel consists of two parts. In the bottom part (i.e., V -H1, H1-H2), each data modality is modeled by a two-layer DBN separately. For clarity, we take the textual modality as an example to illustrate the construction of the mDBN in this part. Given a textual input vector v, the visible layer generates the hidden vector h, by p(hj = 11v) = u(cj + Ei wijvi). Then the conditional distribution of v given h, is p(vi = 11h) = u(bi + Ej wijhj). where u(x) = (1 + e−x)−1 denotes the logistic function. The parameters are updated by performing gradient ascent using Contrastive Divergence (CD) algorithm (Hinton, 2002). After learning the RBMs in the bottom layer, we treat the activation probabilities of its hidden units driven by the inputs, as the training data for training a new layer. The construction procedures for the non-textual modality are similar to the textual one, except that we use the gaussian RBM to model the real-value inputs in the bottom layer. Finally, we combine the two models by adding an additional layer, H3, on the top of them to form the mDBN. The training method is also similar to the bottom’s, but the input vector is the concatenation of the mapped textual vector and the mapped non</context>
</contexts>
<marker>Hinton, 2002</marker>
<rawString>G.E. Hinton. 2002. Training products of experts by minimizing contrastive divergence. Neural computation, 14(8):1771–1800.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Hinton</author>
</authors>
<title>A practical guide to training restricted boltzmann machines.</title>
<date>2012</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>599--619</pages>
<contexts>
<context position="11886" citStr="Hinton (2012)" startWordPosition="1915" endWordPosition="1916">rs with 100 and 200 units respectively for the nontextual branch. On the joint layer of the network, the layer contains 1000 real-value units. Each RBM is trained using 1-step CD algorithm. During the training stage, a small weight-cost of 0.0002 is used, and the learning rate for textual data modal is 0.05 while the non-textual data is 0.001. We also adopt a monument of 0.5 for the first five epochs and 0.9 for the rest epochs. In addition, all non-textual data vectors are normalized to have zero mean and unit standard variance. More details for training the deep architecture can be found in Hinton (2012). 4.2 Results and Analysis In the first experiment, we compare the performance of mDBN with different methods. To make a fare comparison, we use the liblinear toolkit4 for logistic regression model with L2 regularization and randomly select 70% QA pairs as training data 4available at http://www.csie.ntu.edu.tw/ cjlin/liblinear 845 and the rest 30% as testing data. Table 3 and Table 4 summarize the average results of the 5 round experiments on YAHOO and ZHIDAO respectively. Methods P R F1 Accu. LR-T 0.374 0.558 0.448 0.542 LR-N 0.524 0.614 0.566 0.686 LR-C 0.493 0.557 0.523 0.662 DBN-T 0.496 0.</context>
</contexts>
<marker>Hinton, 2012</marker>
<rawString>G.E. Hinton. 2012. A practical guide to training restricted boltzmann machines. Lecture Notes in Computer Science, pages 599–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minlie Huang</author>
<author>Yi Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Quality-biased ranking of short texts in microblogging services.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>373--382</pages>
<contexts>
<context position="1238" citStr="Huang et al., 2011" startWordPosition="188" endWordPosition="191">e network is used as input features for a linear classifier. Extensive experimental results conducted on two cQA datasets demonstrate the effectiveness of our proposed approach. 1 Introduction Predicting the quality of answers in community based Question Answering (cQA) portals is a challenging task. One straightforward approach is to use textual features as a text classification task (Agichtein et al., 2008). However, due to the word over-sparsity and inherent noise of usergenerated content, the classical bag-of-words representation, is not appropriate to estimate the quality of short texts (Huang et al., 2011). Another typical approach is to leverage non-textual features to automatically identify high quality answers (Jeon et al., 2006; Zhou et al., 2012). However, in this way, the mining of meaningful textual features usually tends to be ignored. Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer quality. However, textual and nontextual features usually have different kinds of representations and the correlations between them are highly non-linear. Previous study (Ngiam et al., 2011) has shown that i</context>
</contexts>
<marker>Huang, Yang, Zhu, 2011</marker>
<rawString>Minlie Huang, Yi Yang, and Xiaoyan Zhu. 2011. Quality-biased ranking of short texts in microblogging services. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 373–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jeon</author>
<author>W B Croft</author>
<author>J H Lee</author>
<author>S Park</author>
</authors>
<title>A framework to predict the quality of answers with non-textual features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>228--235</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1366" citStr="Jeon et al., 2006" startWordPosition="207" endWordPosition="210">ate the effectiveness of our proposed approach. 1 Introduction Predicting the quality of answers in community based Question Answering (cQA) portals is a challenging task. One straightforward approach is to use textual features as a text classification task (Agichtein et al., 2008). However, due to the word over-sparsity and inherent noise of usergenerated content, the classical bag-of-words representation, is not appropriate to estimate the quality of short texts (Huang et al., 2011). Another typical approach is to leverage non-textual features to automatically identify high quality answers (Jeon et al., 2006; Zhou et al., 2012). However, in this way, the mining of meaningful textual features usually tends to be ignored. Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer quality. However, textual and nontextual features usually have different kinds of representations and the correlations between them are highly non-linear. Previous study (Ngiam et al., 2011) has shown that it is hard for a shallow model to discover the correlations over multiple sources. To this end, a deep learning approach, called </context>
<context position="2845" citStr="Jeon et al. (2006)" startWordPosition="442" endWordPosition="445">he unified representation using both textual and non-textual information. In the latter stage, the outputs of the network are then used as inputs for a linear classifier to make prediction. The rest of this paper is organized as follows: The related work is surveyed in Section 2. Then, the proposed approach and experimental results are presented in Section 3 and Section 4 respectively. Finally, conclusions and future directions are drawn in Section 5. 2 Related Work The typical way to predict the answer quality is exploring various features and employing machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, </context>
<context position="8478" citStr="Jeon et al., 2006" startWordPosition="1342" endWordPosition="1345">atures Non-textual Features 844 et al., 2011; Srivastava and Salakhutdinov, 2012). Specifically, the LR classifier is used to make the final prediction in our experiments since it keeps to deliver the best performance. 3.4 Basic Features Textual Features: The textual features extract from 1,500 most frequent words in the training dataset after standard preprocessing steps, namely word segmentation, stopwords removal and stemming1. As a result, each answer is represented as a vector containing 1,500 distinct terms weighted by binary scheme. Non-textual Features: Referring to the previous work (Jeon et al., 2006; Shah and Pomerantz, 2010), we adopt some features used in theirs and also explore three additional features marked by ‡ sign. The complete list is described in Table 1. Features Type Length of question title (description) Integer Length of answer Integer Number of unique words for the answer $ Integer Ratio of the qa length $ Float Answer’s relative position $ Integer Number of answers for the question Integer Number of comments for the question Integer Number of questions asked by asker (answerer) Integer Number of questions resolved by asker (answerer) Integer Asker’s (Answerer’s) total po</context>
</contexts>
<marker>Jeon, Croft, Lee, Park, 2006</marker>
<rawString>J. Jeon, W.B. Croft, J.H. Lee, and S. Park. 2006. A framework to predict the quality of answers with non-textual features. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 228–235. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lee</author>
<author>R Grosse</author>
<author>R Ranganath</author>
<author>A Y Ng</author>
</authors>
<title>Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning,</booktitle>
<pages>609--616</pages>
<contexts>
<context position="3722" citStr="Lee et al. (2009)" startWordPosition="589" endWordPosition="592"> The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the feature learning for disparate sources has also been the hot research topic. Lee et al. (2009) demonstrate that the hidden representations computed by a convolutional DBN make excellent features for visual recognition. 843 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843–847, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 3 Approach We consider the problem of high-quality answer prediction as a classification task. Figure 1 summarizes the framework of our proposed approach. First, textual features and non-textual features exFigure 1: Framework of our proposed approach. tracted from cQA portals are use</context>
</contexts>
<marker>Lee, Grosse, Ranganath, Ng, 2009</marker>
<rawString>H. Lee, R. Grosse, R. Ranganath, and A.Y. Ng. 2009. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 609–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ngiam</author>
<author>A Khosla</author>
<author>M Kim</author>
<author>J Nam</author>
<author>H Lee</author>
<author>A Y Ng</author>
</authors>
<title>Multimodal deep learning.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th International Conference on Machine Learning (ICML),</booktitle>
<pages>689--696</pages>
<contexts>
<context position="1821" citStr="Ngiam et al., 2011" startWordPosition="276" endWordPosition="279"> of short texts (Huang et al., 2011). Another typical approach is to leverage non-textual features to automatically identify high quality answers (Jeon et al., 2006; Zhou et al., 2012). However, in this way, the mining of meaningful textual features usually tends to be ignored. Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer quality. However, textual and nontextual features usually have different kinds of representations and the correlations between them are highly non-linear. Previous study (Ngiam et al., 2011) has shown that it is hard for a shallow model to discover the correlations over multiple sources. To this end, a deep learning approach, called multimodal deep belief nets (mDBN), is introduced to address the above problems to predict the answer quality. The approach includes two stages: feature learning and supervised training. In the former stage, a specially designed deep network is given to learn the unified representation using both textual and non-textual information. In the latter stage, the outputs of the network are then used as inputs for a linear classifier to make prediction. The </context>
</contexts>
<marker>Ngiam, Khosla, Kim, Nam, Lee, Ng, 2011</marker>
<rawString>J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A.Y. Ng. 2011. Multimodal deep learning. In Proceedings of the 28th International Conference on Machine Learning (ICML), pages 689–696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Salakhutdinov</author>
<author>G E Hinton</author>
</authors>
<title>Deep boltzmann machines.</title>
<date>2009</date>
<booktitle>In Proceedings of the international conference on artificial intelligence and statistics,</booktitle>
<volume>5</volume>
<pages>448--455</pages>
<contexts>
<context position="3450" citStr="Salakhutdinov and Hinton, 2009" startWordPosition="543" endWordPosition="546">xample, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the feature learning for disparate sources has also been the hot research topic. Lee et al. (2009) demonstrate that the hidden representations computed by a convolutional DBN make excellent features for visual recognition. 843 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843–847, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 3 Approach W</context>
</contexts>
<marker>Salakhutdinov, Hinton, 2009</marker>
<rawString>R. Salakhutdinov and G.E. Hinton. 2009. Deep boltzmann machines. In Proceedings of the international conference on artificial intelligence and statistics, volume 5, pages 448–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Shah</author>
<author>J Pomerantz</author>
</authors>
<title>Evaluating and predicting answer quality in community qa.</title>
<date>2010</date>
<booktitle>In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>411--418</pages>
<contexts>
<context position="3196" citStr="Shah and Pomerantz (2010)" startWordPosition="501" endWordPosition="505">ted in Section 3 and Section 4 respectively. Finally, conclusions and future directions are drawn in Section 5. 2 Related Work The typical way to predict the answer quality is exploring various features and employing machine learning methods. For example, Jeon et al. (2006) have proposed a framework to predict the quality of answers by incorporating non-textual features into a maximum entropy model. Subsequently, Agichtein et al. (2008) and Bian et al. (2009) both leverage a larger range of features to find high quality answers. The deep research on evaluating answer quality has been taken by Shah and Pomerantz (2010) using the logistic regression model. We borrow some of their ideas in this paper. In deep learning field, extensive studies have been done by Hinton and his co-workers (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Salakhutdinov and Hinton, 2009), who initially propose the deep belief nets (DBN). Wang et.al (2010; 2011) firstly apply the DBNs to model semantic relevance for qa pairs in social communities. Meanwhile, the feature learning for disparate sources has also been the hot research topic. Lee et al. (2009) demonstrate that the hidden representations computed by a convolutional D</context>
<context position="8505" citStr="Shah and Pomerantz, 2010" startWordPosition="1346" endWordPosition="1349">Features 844 et al., 2011; Srivastava and Salakhutdinov, 2012). Specifically, the LR classifier is used to make the final prediction in our experiments since it keeps to deliver the best performance. 3.4 Basic Features Textual Features: The textual features extract from 1,500 most frequent words in the training dataset after standard preprocessing steps, namely word segmentation, stopwords removal and stemming1. As a result, each answer is represented as a vector containing 1,500 distinct terms weighted by binary scheme. Non-textual Features: Referring to the previous work (Jeon et al., 2006; Shah and Pomerantz, 2010), we adopt some features used in theirs and also explore three additional features marked by ‡ sign. The complete list is described in Table 1. Features Type Length of question title (description) Integer Length of answer Integer Number of unique words for the answer $ Integer Ratio of the qa length $ Float Answer’s relative position $ Integer Number of answers for the question Integer Number of comments for the question Integer Number of questions asked by asker (answerer) Integer Number of questions resolved by asker (answerer) Integer Asker’s (Answerer’s) total points Integer Asker’s (Answe</context>
<context position="10514" citStr="Shah and Pomerantz (2010)" startWordPosition="1668" endWordPosition="1672">an 3 (one 1The stemming step is only used in English corpus. 2http://zhidao.baidu.com 3http://answers.yahoo.com best answer among them), and those answers at least have 10 tokens. The statistics on the datasets used for experiments are summarized in Table 2. Statistics Items YAHOO ZHIDAO # of questions 6841 5368 # of answers 74485 22435 # of answers per question 10.9 4.1 # of users 28812 12734 Table 2: Statistics on experimental datasets. Baselines and Evaluation Metrics: We compare against the following methods as our baselines. (1) Logistic Regression (LR): We implement the approach used by Shah and Pomerantz (2010) with textual features LR-T, nontextual features LR-N and their simple combination LR-C. (2) DBN: Similar to the mDBN, the outputs of the last hidden layer by the DBN are used as inputs for LR model. Based on the feature sets, we have DBN-T for textual features and DBN-N for non-textual features. Since we mainly focus on the high quality answers, the precision, recall and f1 for positive class and the overall accuracy for both classes are employed as our evaluation metrics. Model Architecture and Training Details: To create the mDBN architecture, we use the classical RBM with 1500 visible unit</context>
</contexts>
<marker>Shah, Pomerantz, 2010</marker>
<rawString>C. Shah and J. Pomerantz. 2010. Evaluating and predicting answer quality in community qa. In Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 411–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Srivastava</author>
<author>R Salakhutdinov</author>
</authors>
<title>Multimodal learning with deep boltzmann machines.</title>
<date>2012</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>2231--2239</pages>
<contexts>
<context position="7942" citStr="Srivastava and Salakhutdinov, 2012" startWordPosition="1259" endWordPosition="1262">tual and non-textual features are highly non-linear. It is hard for a RBM directly combining the two disparate sources to learn their correlations. 3.3 Supervised Training and Classification After the above steps, a deep network for feature learning between textual and non-textual data is established. Classifiers, either support vector machine (SVM) or logistic regression (LR), can then be trained with the unified representation (Ngiam Feature Supervised Training Learning Fusion Representation Classifier High-quality Answers CQA Archives Textual Features Non-textual Features 844 et al., 2011; Srivastava and Salakhutdinov, 2012). Specifically, the LR classifier is used to make the final prediction in our experiments since it keeps to deliver the best performance. 3.4 Basic Features Textual Features: The textual features extract from 1,500 most frequent words in the training dataset after standard preprocessing steps, namely word segmentation, stopwords removal and stemming1. As a result, each answer is represented as a vector containing 1,500 distinct terms weighted by binary scheme. Non-textual Features: Referring to the previous work (Jeon et al., 2006; Shah and Pomerantz, 2010), we adopt some features used in thei</context>
</contexts>
<marker>Srivastava, Salakhutdinov, 2012</marker>
<rawString>N. Srivastava and R. Salakhutdinov. 2012. Multimodal learning with deep boltzmann machines. In Advances in Neural Information Processing Systems, pages 2231–2239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wang</author>
<author>X Wang</author>
<author>C Sun</author>
<author>B Liu</author>
<author>L Sun</author>
</authors>
<title>Modeling semantic relevance for question-answer pairs in web social communities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1230--1238</pages>
<publisher>ACL.</publisher>
<marker>Wang, Wang, Sun, Liu, Sun, 2010</marker>
<rawString>B. Wang, X. Wang, C. Sun, B. Liu, and L. Sun. 2010. Modeling semantic relevance for question-answer pairs in web social communities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1230–1238. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wang</author>
<author>B Liu</author>
<author>X Wang</author>
<author>C Sun</author>
<author>D Zhang</author>
</authors>
<title>Deep learning approaches to semantic relevance modeling for chinese question-answer pairs.</title>
<date>2011</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>10</volume>
<issue>4</issue>
<marker>Wang, Liu, Wang, Sun, Zhang, 2011</marker>
<rawString>B. Wang, B. Liu, X. Wang, C. Sun, and D. Zhang. 2011. Deep learning approaches to semantic relevance modeling for chinese question-answer pairs. ACM Transactions on Asian Language Information Processing, 10(4):21:1–21:16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z M Zhou</author>
<author>M Lan</author>
<author>Z Y Niu</author>
<author>Y Lu</author>
</authors>
<title>Exploiting user profile information for answer ranking in cqa.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>767--774</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1386" citStr="Zhou et al., 2012" startWordPosition="211" endWordPosition="214">ss of our proposed approach. 1 Introduction Predicting the quality of answers in community based Question Answering (cQA) portals is a challenging task. One straightforward approach is to use textual features as a text classification task (Agichtein et al., 2008). However, due to the word over-sparsity and inherent noise of usergenerated content, the classical bag-of-words representation, is not appropriate to estimate the quality of short texts (Huang et al., 2011). Another typical approach is to leverage non-textual features to automatically identify high quality answers (Jeon et al., 2006; Zhou et al., 2012). However, in this way, the mining of meaningful textual features usually tends to be ignored. Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer quality. However, textual and nontextual features usually have different kinds of representations and the correlations between them are highly non-linear. Previous study (Ngiam et al., 2011) has shown that it is hard for a shallow model to discover the correlations over multiple sources. To this end, a deep learning approach, called multimodal deep beli</context>
</contexts>
<marker>Zhou, Lan, Niu, Lu, 2012</marker>
<rawString>Z.M. Zhou, M. Lan, Z.Y. Niu, and Y. Lu. 2012. Exploiting user profile information for answer ranking in cqa. In Proceedings of the 21st international conference on World Wide Web, pages 767–774. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>