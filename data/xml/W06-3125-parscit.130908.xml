<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008279">
<title confidence="0.941142">
N-gram-based SMT System Enhanced with Reordering Patterns
</title>
<author confidence="0.844193333333333">
Josep M. Crego Adri`a de Gispert Patrik Lambert
Marta R. Costa-juss`a Maxim Khalilov Rafael E. Banchs
Jos´e B. Mari˜no Jos´e A. R. Fonollosa
</author>
<affiliation confidence="0.801858">
Department of Signal Theory and Communications
TALP Research Center (UPC)
</affiliation>
<address confidence="0.934925">
Barcelona 08034, Spain
</address>
<email confidence="0.999778">
{jmcrego,agispert,lambert,mruiz,khalilov,rbanchs,canton,adrian}@gps.tsc.upc.edu
</email>
<sectionHeader confidence="0.998605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999428125">
This work presents translation results for
the three data sets made available in the
shared task “Exploiting Parallel Texts for
Statistical Machine Translation” of the
HLT-NAACL 2006 Workshop on Statisti-
cal Machine Translation. All results pre-
sented were generated by using the N-
gram-based statistical machine translation
system which has been enhanced from the
last year’s evaluation with a tagged target
language model (using Part-Of-Speech
tags). For both Spanish-English transla-
tion directions and the English-to-French
translation task, the baseline system al-
lows for linguistically motivated source-
side reorderings.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999395">
The statistical machine translation approach used
in this work implements a log-linear combination
of feature functions along with a translation model
which is based on bilingual n-grams (de Gispert and
Mari˜no, 2002).
This translation model differs from the well
known phrase-based translation approach (Koehn
et al., 2003) in two basic issues: first, training data
is monotonously segmented into bilingual units; and
second, the model considers n-gram probabilities in-
stead of relative frequencies. This translation ap-
proach is described in detail in (Mari˜no et al., 2005).
For those translation tasks with Spanish or En-
glish as target language, an additional tagged (us-
ing POS information) target language model is used.
Additionally a reordering strategy that includes POS
information is described and evaluated.
Translation results for all six translation directions
proposed in the shared task are presented and dis-
cussed. Both translation directions are considered
for the pairs: English-Spanish, English-French,
and English-German.
The paper is structured as follows: Section 2
briefly outlines the baseline system. Section 3 de-
scribes in detail the implemented POS-based re-
ordering strategy. Section 4 presents and discusses
the shared task results and, finally, section 5 presents
some conclusions and further work.
</bodyText>
<sectionHeader confidence="0.977209" genericHeader="method">
2 Baseline N-gram-based SMT System
</sectionHeader>
<bodyText confidence="0.999925">
As already mentioned, the translation model used
here is based on bilingual n-grams. It actually con-
stitutes a language model of bilingual units, referred
to as tuples, which approximates the joint probabil-
ity between source and target languages by using
bilingual n-grams (de Gispert and Mari˜no, 2002).
Tuples are extracted from a word-to-word aligned
corpus according to the following two constraints:
first, tuple extraction should produce a monotonic
segmentation of bilingual sentence pairs; and sec-
ond, no smaller tuples can be extracted without vi-
olating the previous constraint. See (Crego et al.,
2004) for further details.
For all experiments presented here, the translation
model consisted of a 4-gram language model of tu-
ples. In addition to this bilingual n-gram translation
model, the baseline system implements a log linear
combination of five feature functions.
</bodyText>
<page confidence="0.977731">
162
</page>
<subsectionHeader confidence="0.771585">
Proceedings of the Workshop on Statistical Machine Translation, pages 162–165,
New York City, June 2006. c�2006 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.978084">
These five additional models are:
</bodyText>
<listItem confidence="0.99783425">
• A target language model. 5-gram of the target
side of the bilingual corpus.
• A word bonus. Based on the number of tar-
get words in the partial-translation hypothesis,
to compensate the LM preference for short sen-
tences.
• A Source-to-target lexicon model. Based on
IBM Model 1 lexical parameters(Brown et al.,
1993), providing a complementary probability
for each tuple in the translation table. These
parameters are obtained from source-to-target
alignments.
• A Target-to-source lexicon model. Analo-
gous to the previous feature, but obtained from
target-to-source alignments.
• A Tagged (POS) target language model. This
</listItem>
<bodyText confidence="0.994145840909091">
feature implements a 5-gram language model
of target POS-tags. In this case, each trans-
lation unit carried the information of its target
side POS-tags, though this is not used for trans-
lation model estimation (only in order to eval-
uate the target POS language model at decod-
ing time). Due to the non-availability of POS-
taggers for French and German, it was not pos-
sible to incorporate this feature in all transla-
tion tasks considered, being only used for those
translation tasks with Spanish and English as
target languages.
The search engine for this translation system is
described in (Crego et al., 2005) and implements
a beam-search strategy based on dynamic program-
ming, taking into account all feature functions de-
scribed above, along with the bilingual n-gram trans-
lation model. Monotone search is performed, in-
cluding histogram and threshold pruning and hy-
pothesis recombination.
An optimization tool, which is based on a down-
hill simplex method was developed and used for
computing log-linear weights for each of the feature
functions. This algorithm adjusts the weights so that
a non-linear combination of BLEU and NIST scores
is maximized over the development set for each of
the six translation directions considered.
This baseline system is actually very similar to
the system used for last year’s shared task “Exploit-
ing Parallel Texts for Statistical Machine Transla-
tion” of ACL’05 Workshop on Building and Us-
ing Parallel Texts: Data-Driven Machine Translation
and Beyond (Banchs et al., 2005), whose results
are available at: http://www.statmt.org/wpt05/
mt-shared-task/. A more detailed description of
the system can be found in (2005).
The tools used for POS-tagging were Freel-
ing (Carreras et al., 2004) for Spanish and
TnT (Brants, 2000) for English. All language mod-
els were estimated using the SRI language mod-
eling toolkit. Word-to-word alignments were ex-
tracted with GIZA++. Improvements in word-to-
word alignments were achieved through verb group
classification as described in (de Gispert, 2005).
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="method">
3 Reordering Framework
</sectionHeader>
<bodyText confidence="0.999834636363636">
In this section we outline the reordering framework
used for the experiments (Crego and Mari˜no, 2006).
A highly constrained reordered search is performed
by means of a set of reordering patterns (linguisti-
cally motivated rewrite patterns) which are used to
extend the monotone search graph with additional
arcs.
To extract patterns, we use the word-to-word
alignments (the union of both alignment directions)
and source-side POS tags. The main procedure con-
sists of identifying all crossings produced in the
</bodyText>
<figureCaption confidence="0.9889365">
Figure 1: Reordering patterns are extracted using
word-to-word alignments. The generalization power
</figureCaption>
<bodyText confidence="0.606905333333333">
is achieved through the POS tags. Three instances of
different patterns are extracted using the sentences
in the example.
</bodyText>
<page confidence="0.995284">
163
</page>
<bodyText confidence="0.999769526315789">
word-to-word alignments. Once a crossing has been
detected, its source POS tags and alignments are
used to account for a new instance of pattern. The
target side of a pattern (source-side positions after
reordering), is computed using the original order
of the target words to which the source words are
aligned. See figure 1 for a clarifying example of
pattern extraction.
The monotone search graph is extended with re-
orderings following the patterns found in training.
The procedure identifies first the sequences of words
in the input sentence that match any available pat-
tern. Then, each of the matchings implies the ad-
dition of an arc into the search graph (encoding the
reordering learnt in the pattern). However, this ad-
dition of a new arc is not performed if a translation
unit with the same source-side words already exists
in the training. Figure 2 shows an example of the
procedure.
</bodyText>
<figureCaption confidence="0.84676525">
Figure 2: Three additional arcs have been added
to the original monotone graph (bold arcs) given
the reordering patterns found matching any of the
source POS tags sequence.
</figureCaption>
<bodyText confidence="0.999688714285714">
Once the search graph is built, the decoder tra-
verses the graph looking for the best translation.
Hence, the winner hypothesis is computed using
all the available information (the whole SMT mod-
els). The reordering strategy is additionally sup-
ported by a 5-gram language model of reordered
source POS-tags. In training, POS-tags are re-
ordered according with the extracted reordering pat-
terns and word-to-word links. The resulting se-
quence of source POS-tags are used to train the n-
gram LM.
Notice that this reordering framework has only
been used for some translation tasks (Spanish-
to-English, English-to-Spanish and English-to-
French). The reason is double: first, because we
did not have available a French POS-tagger. Second,
because the technique used to learn reorderings (de-
tailed below) does not seem to apply for language
pairs like German-English, because the agglutina-
tive characteristic of German (words are formed by
joining morphemes together).
</bodyText>
<tableCaption confidence="0.904221">
Table 1: BLEU, NIST and mWER scores (com-
</tableCaption>
<bodyText confidence="0.389548333333333">
puted using two reference translations) obtained for
both translation directions (Spanish-to-English and
English-to-Spanish).
</bodyText>
<sectionHeader confidence="0.483233" genericHeader="method">
Conf BLEU NIST mWER
</sectionHeader>
<subsectionHeader confidence="0.540558">
Spanish-to-English
</subsectionHeader>
<bodyText confidence="0.694121">
base 55.23 10.69 34.40
+rgraph 55.59 10.70 34.23
+pos 56.39 10.75 33.75
</bodyText>
<subsectionHeader confidence="0.766517">
English-to-Spanis
</subsectionHeader>
<bodyText confidence="0.977580444444445">
base 48.03 9.84 41.18
+rgraph 48.53 9.81 41.15
+pos 48.91 9.91 40.29
Table 1 shows the improvement of the original
baseline system described in section 2 (base), en-
hanced using reordering graphs (+rgraph) and pro-
vided the tagged-source language model (+pos).
The experiments in table 1 were not carried out over
the official corpus of this shared task. The Spanish-
English corpus of the TC-Star 2005 Evaluation was
used. Due to the high similarities between both cor-
pus (this shared task corpus consists of a subset of
the whole corpus used in the TC-Star 2005 Evalua-
tion), it makes sense to think that comparable results
would be obtained.
It is worth mentioning that the official corpus of
the shared task (HLT-NAACL 2006) was used when
building and tuning the present shared task system.
</bodyText>
<sectionHeader confidence="0.990582" genericHeader="method">
4 Shared Task Results
</sectionHeader>
<bodyText confidence="0.998924666666667">
The data provided for this shared task corresponds
to a subset of the official transcriptions of the Euro-
pean Parliament Plenary Sessions. The development
set used to tune the system consists of a subset (500
first sentences) of the official development set made
available for the Shared Task.
</bodyText>
<page confidence="0.996853">
164
</page>
<bodyText confidence="0.999158181818182">
Table 2 presents the BLEU, NIST and mWER
scores obtained for the development-test data set.
The last column shows whether the target POS lan-
guage model feature was used or not. Computed
scores are case sensitive and compare to one refer-
ence translation. Tasks in bold were conducted al-
lowing for the reordering framework. For French-
to-English task, block reordering strategy was used,
which is described in (Costa-juss`a et al., 2006). As it
can be seen, for the English-to-German task we did
not use any of the previous enhancements.
</bodyText>
<tableCaption confidence="0.990521">
Table 2: Translation results
</tableCaption>
<table confidence="0.990238142857143">
Task BLEU NIST mWER tPOS
en -&gt; es 29.50 7.32 58.95 yes
es -&gt; en 30.29 7.51 57.72 yes
en -&gt; fr 30.23 7.40 59.76 no
fr -&gt; en 30.21 7.61 56.97 yes
en -&gt; de 17.40 5.61 71.18 no
de -&gt; en 23.78 6.70 65.83 yes
</table>
<bodyText confidence="0.9993483">
Important differences can be observed between
the German-English and the rest of translation tasks.
They result from the greater differences in word
order present in this language pair (the German-
English results are obtained under monotone decod-
ing conditions). Also because the greater vocabulary
of words of German, which increases sparseness in
any task where German is envolved. As expected,
differences in translation accuracy between Spanish-
English and French-English are smaller.
</bodyText>
<sectionHeader confidence="0.997794" genericHeader="conclusions">
5 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.999917875">
As it can be concluded from the presented results,
although in principle some language pairs (Spanish-
English-French) seem to have very little need for re-
orderings (due to their similar word order), the use
of linguistically-based reorderings proves to be use-
ful to improve translation accuracy.
Additional work is to be conducted to allow for
reorderings when translating from/to German.
</bodyText>
<sectionHeader confidence="0.999597" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9054382">
This work was partly funded by the European Union
under the integrated project TC-STAR&apos;: Technology
and Corpora for Speech to Speech Translation (IST-
2002-FP6-506738) and the European Social Fund.
lhttp://www.tc-star.org
</bodyText>
<sectionHeader confidence="0.975965" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9978438125">
R. E. Banchs, J. M. Crego, A. de Gispert, P. Lambert, and
J. B. Mari˜no. 2005. Statistical machine translation of
euparl data by using bilingual n-grams. Proc. of the
ACL Workshop on Building and Using Parallel Texts
(ACL’05/Wkshp), pages 67–72, June.
T. Brants. 2000. TnT – a statistical part-of-speech tag-
ger. In Proc. of the Sixth Applied Natural Language
Processing (ANLP-2000), Seattle, WA.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of statistical machine transla-
tion. Computational Linguistics, 19(2):263–311.
X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.
Freeling: An open-source suite of language analyzers.
4th Int. Conf. on Language Resources and Evaluation,
LREC’04, May.
M.R. Costa-juss`a, J.M. Crego, A. de Gispert, P. Lam-
bert, M. Khalilov, R. Banchs, J.B. Mari˜no, and J.A.R.
Fonollosa. 2006. Talp phrase-based statistical transla-
tion system for european language pairs. Proc. of the
HLT/NAACL Workshop on Statistical Machine Trans-
lation, June.
J. M. Crego and J. Mari˜no. 2006. A reordering frame-
work for statistical machine translation. Internal Re-
port.
J. M. Crego, J. Mari˜no, and A. de Gispert. 2004. Finite-
state-based and phrase-based statistical machine trans-
lation. Proc. of the 8th Int. Conf. on Spoken Language
Processing, ICSLP’04, pages 37–40, October.
J. M. Crego, J. Mari˜no, and A. Gispert. 2005. An ngram-
based statistical machine translation decoder. Proc. of
the 9th European Conference on Speech Communica-
tion and Technology, Interspeech’05, September.
A. de Gispert and J. Mari˜no. 2002. Using X-grams
for speech-to-speech translation. Proc. of the 7th
Int. Conf. on Spoken Language Processing, ICSLP’02,
September.
A. de Gispert. 2005. Phrase linguistic classification and
generalization for improving statistical machine trans-
lation. Proc. of the ACL Student Research Workshop
(ACL’05/SRW), June.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statisti-
cal phrase-based translation. Proc. of the Human
Language Technology Conference, HLT-NAACL’2003,
May.
J.B. Mari˜no, R Banchs, J.M. Crego, A. de Gispert,
P. Lambert, M. R. Costa-juss`a, and J.A.R. Fonollosa.
2005. Bilingual n–gram statistical machine transla-
tion. Proc. of the MT Summit X, September.
</reference>
<page confidence="0.998744">
165
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910837">
<title confidence="0.999585">N-gram-based SMT System Enhanced with Reordering Patterns</title>
<author confidence="0.992054333333333">Josep M Crego Adri`a de_Gispert Patrik Lambert Marta R Costa-juss`a Maxim Khalilov Rafael E Banchs B Jos´e A R Fonollosa</author>
<affiliation confidence="0.9989105">Department of Signal Theory and TALP Research Center</affiliation>
<address confidence="0.982952">Barcelona 08034,</address>
<abstract confidence="0.996998647058824">This work presents translation results for the three data sets made available in the task Parallel Texts for Machine Translation” the HLT-NAACL 2006 Workshop on Statistical Machine Translation. All results presented were generated by using the Ngram-based statistical machine translation system which has been enhanced from the last year’s evaluation with a tagged target language model (using Part-Of-Speech tags). For both Spanish-English translation directions and the English-to-French translation task, the baseline system allows for linguistically motivated sourceside reorderings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R E Banchs</author>
<author>J M Crego</author>
<author>A de Gispert</author>
<author>P Lambert</author>
<author>J B Mari˜no</author>
</authors>
<title>Statistical machine translation of euparl data by using bilingual n-grams.</title>
<date>2005</date>
<booktitle>Proc. of the ACL Workshop on Building and Using Parallel Texts (ACL’05/Wkshp),</booktitle>
<pages>67--72</pages>
<marker>Banchs, Crego, de Gispert, Lambert, Mari˜no, 2005</marker>
<rawString>R. E. Banchs, J. M. Crego, A. de Gispert, P. Lambert, and J. B. Mari˜no. 2005. Statistical machine translation of euparl data by using bilingual n-grams. Proc. of the ACL Workshop on Building and Using Parallel Texts (ACL’05/Wkshp), pages 67–72, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT – a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proc. of the Sixth Applied Natural Language Processing (ANLP-2000),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="5837" citStr="Brants, 2000" startWordPosition="867" endWordPosition="868">mized over the development set for each of the six translation directions considered. This baseline system is actually very similar to the system used for last year’s shared task “Exploiting Parallel Texts for Statistical Machine Translation” of ACL’05 Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond (Banchs et al., 2005), whose results are available at: http://www.statmt.org/wpt05/ mt-shared-task/. A more detailed description of the system can be found in (2005). The tools used for POS-tagging were Freeling (Carreras et al., 2004) for Spanish and TnT (Brants, 2000) for English. All language models were estimated using the SRI language modeling toolkit. Word-to-word alignments were extracted with GIZA++. Improvements in word-toword alignments were achieved through verb group classification as described in (de Gispert, 2005). 3 Reordering Framework In this section we outline the reordering framework used for the experiments (Crego and Mari˜no, 2006). A highly constrained reordered search is performed by means of a set of reordering patterns (linguistically motivated rewrite patterns) which are used to extend the monotone search graph with additional arcs.</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000. TnT – a statistical part-of-speech tagger. In Proc. of the Sixth Applied Natural Language Processing (ANLP-2000), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="3772" citStr="Brown et al., 1993" startWordPosition="543" endWordPosition="546"> n-gram translation model, the baseline system implements a log linear combination of five feature functions. 162 Proceedings of the Workshop on Statistical Machine Translation, pages 162–165, New York City, June 2006. c�2006 Association for Computational Linguistics These five additional models are: • A target language model. 5-gram of the target side of the bilingual corpus. • A word bonus. Based on the number of target words in the partial-translation hypothesis, to compensate the LM preference for short sentences. • A Source-to-target lexicon model. Based on IBM Model 1 lexical parameters(Brown et al., 1993), providing a complementary probability for each tuple in the translation table. These parameters are obtained from source-to-target alignments. • A Target-to-source lexicon model. Analogous to the previous feature, but obtained from target-to-source alignments. • A Tagged (POS) target language model. This feature implements a 5-gram language model of target POS-tags. In this case, each translation unit carried the information of its target side POS-tags, though this is not used for translation model estimation (only in order to evaluate the target POS language model at decoding time). Due to </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>Freeling: An open-source suite of language analyzers.</title>
<date>2004</date>
<booktitle>4th Int. Conf. on Language Resources and Evaluation, LREC’04,</booktitle>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004. Freeling: An open-source suite of language analyzers. 4th Int. Conf. on Language Resources and Evaluation, LREC’04, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Costa-juss`a</author>
<author>J M Crego</author>
<author>A de Gispert</author>
<author>P Lambert</author>
<author>M Khalilov</author>
<author>R Banchs</author>
<author>J B Mari˜no</author>
<author>J A R Fonollosa</author>
</authors>
<title>Talp phrase-based statistical translation system for european language pairs.</title>
<date>2006</date>
<booktitle>Proc. of the HLT/NAACL Workshop on Statistical Machine Translation,</booktitle>
<marker>Costa-juss`a, Crego, de Gispert, Lambert, Khalilov, Banchs, Mari˜no, Fonollosa, 2006</marker>
<rawString>M.R. Costa-juss`a, J.M. Crego, A. de Gispert, P. Lambert, M. Khalilov, R. Banchs, J.B. Mari˜no, and J.A.R. Fonollosa. 2006. Talp phrase-based statistical translation system for european language pairs. Proc. of the HLT/NAACL Workshop on Statistical Machine Translation, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Mari˜no</author>
</authors>
<title>A reordering framework for statistical machine translation.</title>
<date>2006</date>
<tech>Internal Report.</tech>
<marker>Crego, Mari˜no, 2006</marker>
<rawString>J. M. Crego and J. Mari˜no. 2006. A reordering framework for statistical machine translation. Internal Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Mari˜no</author>
<author>A de Gispert</author>
</authors>
<title>Finitestate-based and phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>Proc. of the 8th Int. Conf. on Spoken Language Processing, ICSLP’04,</booktitle>
<pages>37--40</pages>
<marker>Crego, Mari˜no, de Gispert, 2004</marker>
<rawString>J. M. Crego, J. Mari˜no, and A. de Gispert. 2004. Finitestate-based and phrase-based statistical machine translation. Proc. of the 8th Int. Conf. on Spoken Language Processing, ICSLP’04, pages 37–40, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Mari˜no</author>
<author>A Gispert</author>
</authors>
<title>An ngrambased statistical machine translation decoder.</title>
<date>2005</date>
<booktitle>Proc. of the 9th European Conference on Speech Communication and Technology, Interspeech’05,</booktitle>
<marker>Crego, Mari˜no, Gispert, 2005</marker>
<rawString>J. M. Crego, J. Mari˜no, and A. Gispert. 2005. An ngrambased statistical machine translation decoder. Proc. of the 9th European Conference on Speech Communication and Technology, Interspeech’05, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
<author>J Mari˜no</author>
</authors>
<title>Using X-grams for speech-to-speech translation.</title>
<date>2002</date>
<booktitle>Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02,</booktitle>
<marker>de Gispert, Mari˜no, 2002</marker>
<rawString>A. de Gispert and J. Mari˜no. 2002. Using X-grams for speech-to-speech translation. Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP’02, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A de Gispert</author>
</authors>
<title>Phrase linguistic classification and generalization for improving statistical machine translation.</title>
<date>2005</date>
<booktitle>Proc. of the ACL Student Research Workshop (ACL’05/SRW),</booktitle>
<marker>de Gispert, 2005</marker>
<rawString>A. de Gispert. 2005. Phrase linguistic classification and generalization for improving statistical machine translation. Proc. of the ACL Student Research Workshop (ACL’05/SRW), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>Proc. of the Human Language Technology Conference, HLT-NAACL’2003,</booktitle>
<contexts>
<context position="1346" citStr="Koehn et al., 2003" startWordPosition="178" endWordPosition="181">n enhanced from the last year’s evaluation with a tagged target language model (using Part-Of-Speech tags). For both Spanish-English translation directions and the English-to-French translation task, the baseline system allows for linguistically motivated sourceside reorderings. 1 Introduction The statistical machine translation approach used in this work implements a log-linear combination of feature functions along with a translation model which is based on bilingual n-grams (de Gispert and Mari˜no, 2002). This translation model differs from the well known phrase-based translation approach (Koehn et al., 2003) in two basic issues: first, training data is monotonously segmented into bilingual units; and second, the model considers n-gram probabilities instead of relative frequencies. This translation approach is described in detail in (Mari˜no et al., 2005). For those translation tasks with Spanish or English as target language, an additional tagged (using POS information) target language model is used. Additionally a reordering strategy that includes POS information is described and evaluated. Translation results for all six translation directions proposed in the shared task are presented and discu</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical phrase-based translation. Proc. of the Human Language Technology Conference, HLT-NAACL’2003, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Mari˜no</author>
<author>R Banchs</author>
<author>J M Crego</author>
<author>A de Gispert</author>
<author>P Lambert</author>
<author>M R Costa-juss`a</author>
<author>J A R Fonollosa</author>
</authors>
<title>Bilingual n–gram statistical machine translation.</title>
<date>2005</date>
<booktitle>Proc. of the MT Summit X,</booktitle>
<marker>Mari˜no, Banchs, Crego, de Gispert, Lambert, Costa-juss`a, Fonollosa, 2005</marker>
<rawString>J.B. Mari˜no, R Banchs, J.M. Crego, A. de Gispert, P. Lambert, M. R. Costa-juss`a, and J.A.R. Fonollosa. 2005. Bilingual n–gram statistical machine translation. Proc. of the MT Summit X, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>